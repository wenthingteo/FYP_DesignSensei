from typing import Optional, Dict, List, Any, Tuple
import logging
import re # Needed for keyword-based mocks and potential future concept extraction
from collections import deque # For session history (though it's managed externally for this module now)

# Import actual Neo4j driver and client
from neo4j import GraphDatabase
from knowledge_graph.connection.neo4j_client import Neo4jClient

# Import embedding service
from search_module.embedding_service import get_embedding

logger = logging.getLogger(__name__)

# Load environment variables for Neo4j connection (if not handled by Neo4jClient internally)
# If Neo4jClient handles loading these, you can remove this section.
import os
from dotenv import load_dotenv
load_dotenv()
NEO4J_URI = os.getenv("NEO4J_URI")
NEO4J_USERNAME = os.getenv("NEO4J_USERNAME")
NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD")

# Initialize Neo4j driver for direct use in this module if Neo4jClient is not fully abstracting it
# This part might be better managed by your Neo4jClient or as a singleton/app-level object
# based on your project's architecture. For now, ensuring it's available.
neo4j_driver = None
try:
    if NEO4J_URI and NEO4J_USERNAME and NEO4J_PASSWORD:
        neo4j_driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))
        neo4j_driver.verify_connectivity()
        logger.info("Neo4j driver initialized and connected successfully within GraphSearchService.")
    else:
        logger.warning("Neo4j environment variables not fully set. Neo4j driver not initialized.")
except Exception as e:
    logger.error(f"Failed to initialize Neo4j driver: {e}", exc_info=True)
    neo4j_driver = None


class GraphSearchService:
    def __init__(self, neo4j_client: Neo4jClient):
        # The Neo4jClient object (which wraps the driver) will be passed from ChatbotAPIView
        self.neo4j_client = neo4j_client
        # Assuming embedding_service.py's get_embedding is a standalone function
        # No need to initialize a client for it if it's a direct function call.

        # Session history (managed for _build_contextual_query, if still used here)
        # Note: If context is fully managed by ContextManager, this might be redundant.
        self.session_histories = {}


    def search(self, user_query_text: str, search_params: Dict, session_id: str) -> Dict:
        """
        Performs a graph search based on the user query and structured search parameters.

        Args:
            user_query_text (str): The original user query, used for embedding generation.
            search_params (Dict): A dictionary containing structured search parameters
                                  like 'topic_filter_labels', 'search_depth',
                                  'relationship_types', 'extracted_concepts', etc.,
                                  generated by the IntentClassifier.
            session_id (str): The ID of the current user session (for context-aware search).

        Returns:
            Dict: The results from the graph search, typically in the format
                  {'results': [{'id': ..., 'name': ..., 'label': ..., 'relevance_score': ...}, ...]}
        """
        logger.info(f"GraphSearchService: Received user_query_text='{user_query_text}', search_params={search_params}, session_id='{session_id}'")

        if not self.neo4j_client or not neo4j_driver: # Check if Neo4j is available
            logger.error("Neo4j client or driver not initialized. Cannot perform graph search.")
            # Fallback to simple mock or raise an error if critical
            # For testing, we'll return a basic mock based on user_query_text
            return self._get_fallback_mock_results(user_query_text, search_params)


        # --- 1. Generate Embedding for the user_query_text (for semantic search) ---
        user_query_embedding = None
        try:
            # Use the actual embedding service function
            user_query_embedding = get_embedding(user_query_text)
            if user_query_embedding is None:
                logger.warning(f"Embedding service returned None for query: '{user_query_text}'")
        except Exception as e:
            logger.error(f"Failed to generate embedding for '{user_query_text}': {e}", exc_info=True)
            # Continue without embedding if it fails

        # --- 2. Extract parameters from search_params dictionary ---
        # These are generated by the IntentClassifier
        topic_labels = search_params.get('topic_filter_labels', [])
        search_depth = search_params.get('search_depth', 2)
        relationship_types = search_params.get('relationship_types', [])
        extracted_concepts = search_params.get('extracted_concepts', [])
        min_relevance_score = search_params.get('min_relevance_score', 0.7)
        # Note: The 'keywords' from IntentClassifier are also available in search_params
        keywords_from_intent = search_params.get('keywords', [])


        # --- 3. Build Dynamic Cypher Query and Execute ---
        # This is the core logic where your teammate will implement the complex Cypher generation
        # and execution, combining all search parameters.
        try:
            cypher_query, cypher_params = self._build_cypher_query(
                user_query_text,
                user_query_embedding, # Pass embedding for vector search
                topic_labels,
                search_depth,
                relationship_types,
                extracted_concepts,
                min_relevance_score,
                keywords_from_intent
            )
            logger.debug(f"Generated Cypher Query: {cypher_query} with params: {cypher_params}")

            # Execute query using the Neo4jClient instance
            # The run_cypher method in Neo4jClient should handle session management
            raw_graph_results = self.neo4j_client.run_cypher(cypher_query, cypher_params)
           
            # Process raw results from Neo4j (e.g., convert Neo4j Records to Python dicts)
            processed_results = self._process_neo4j_results(raw_graph_results, user_query_embedding)
           
            # Filter by relevance if needed (your _rank_results will also do this)
            final_results = [
                res for res in processed_results if res.get('relevance_score', 0.0) >= min_relevance_score
            ]
           
            logger.info(f"GraphSearchService: Retrieved {len(final_results)} results from Neo4j.")
            return {'results': final_results}

        except Exception as e:
            logger.error(f"Error during Cypher query execution or processing: {e}", exc_info=True)
            # Fallback to simple mock if real search fails
            return self._get_fallback_mock_results(user_query_text, search_params)

    # --- Private Helper Methods ---

    def _get_embedding(self, text: str) -> List[float]:
        """
        Calls the gpt-4.1-nano embedding service to get an embedding for the given text.
        This uses the imported `get_embedding` function from `embedding_service.py`.
        """
        # Ensure text is valid before calling embedding service
        if not isinstance(text, str) or not text.strip():
            logger.warning("Attempted to get embedding for empty or non-string text.")
            return []
        try:
            embedding = get_embedding(text)
            if not isinstance(embedding, list):
                logger.warning(f"Embedding service returned non-list type: {type(embedding)}. Returning empty list.")
                return []
            return embedding
        except Exception as e:
            logger.error(f"Error calling embedding service for '{text[:50]}...': {e}", exc_info=True)
            return [] # Return empty list on error

    def _cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """
        Calculates cosine similarity between two vectors.
        Assumes vectors are non-empty and of same dimension.
        """
        if not vec1 or not vec2:
            return 0.0
        # Ensure same dimension, pad with zeros if not (though ideally they should be same)
        min_len = min(len(vec1), len(vec2))
        if min_len == 0:
            return 0.0
       
        vec1_cropped = vec1[:min_len]
        vec2_cropped = vec2[:min_len]

        dot_product = sum(v1 * v2 for v1, v2 in zip(vec1_cropped, vec2_cropped))
        magnitude_vec1 = sum(v1**2 for v1 in vec1_cropped)**0.5
        magnitude_vec2 = sum(v2**2 for v2 in vec2_cropped)**0.5

        if magnitude_vec1 == 0 or magnitude_vec2 == 0:
            return 0.0
        return dot_product / (magnitude_vec1 * magnitude_vec2)
   
    def _build_cypher_query(self, user_query_text: str, user_embedding: Optional[List[float]],
                            topic_labels: List[str], search_depth: int,
                            relationship_types: List[str], extracted_concepts: List[str],
                            min_relevance_score: float, keywords_from_intent: List[str]) -> Tuple[str, Dict]:
        """
        Constructs a dynamic Cypher query based on all provided search parameters.
        This is the most complex part of the search module.

        It should combine:
        1.  **Full-text search:** Using user_query_text and keywords_from_intent on relevant node properties.
        2.  **Vector similarity search:** If `user_embedding` is provided and Neo4j has a vector index,
            query for semantically similar nodes.
        3.  **Label filtering:** Using `topic_labels` to constrain the search space.
        4.  **Relationship traversal:** Using `relationship_types` and `search_depth` to explore connections.
        5.  **Direct concept matching:** Using `extracted_concepts` for direct node lookups (e.g., specific pattern names).

        Returns: A tuple of (cypher_query_string, parameters_dictionary_for_cypher)
        """
        logger.info(f"Building Cypher Query: user_query_text='{user_query_text}', topic_labels={topic_labels}, extracted_concepts={extracted_concepts}, depth={search_depth}, rel_types={relationship_types}")
       
        cypher_query_parts = []
        params = {}
       
        # Start with a base match for nodes
        match_clause = "MATCH (n)"
        where_conditions = []
       
        # 1. Full-text search (example, assumes you have a full-text index 'node_fts')
        if user_query_text:
            cypher_query_parts.append(f"CALL db.index.fulltext.queryNodes('node_fts', $searchText) YIELD node AS n_fts, score AS fts_score")
            where_conditions.append("n = n_fts")
            params['searchText'] = user_query_text
       
        # 2. Vector similarity search (example, assumes you have a vector index 'node_embeddings')
        if user_embedding and self.neo4j_client: # Only add if embedding exists and Neo4j is connected
            # This is a conceptual placeholder; actual vector search might differ
            cypher_query_parts.append(f"CALL db.index.vector.queryNodes('node_embeddings', $k, $embedding) YIELD node AS n_vec, score AS vec_score")
            where_conditions.append("n = n_vec")
            params['embedding'] = user_embedding
            params['k'] = 10 # Retrieve top 10 most similar nodes

        # 3. Direct concept matching (using extracted_concepts)
        if extracted_concepts:
            # Match nodes by name or ID if extracted_concepts are specific
            concept_conditions = [f"n.name IN $extracted_concepts_{i}" for i in range(len(extracted_concepts))]
            where_conditions.append(f"({ ' OR '.join(concept_conditions) })")
            for i, concept in enumerate(extracted_concepts):
                params[f'extracted_concepts_{i}'] = concept # Parameterize each concept

        # 4. Label filtering (using topic_labels)
        if topic_labels:
            label_conditions = " OR ".join([f"'{label}' IN labels(n)" for label in topic_labels])
            where_conditions.append(f"({label_conditions})")
           
        # 5. Relationship traversal (conceptual - this needs proper Cypher paths)
        # This is a complex part that would dynamically build paths.
        # Example: if relationship_types contains 'RELATES_TO' and depth is 2
        # MATCH (n)-[r*1..2]-(m) WHERE type(r) IN $relTypes
        if relationship_types and search_depth > 0:
            # This is a simplified example. Real traversal needs care.
            # You might want to get connected nodes and include them.
            # cypher_query_parts.append(f"OPTIONAL MATCH (n)-[r*1..{search_depth}]-(m) WHERE type(r) IN $relationship_types")
            # params['relationship_types'] = relationship_types
            pass # Keep it simple for the initial fix, focus on direct node match

        # Combine MATCH and WHERE clauses
        final_cypher_query = match_clause
        if cypher_query_parts: # If FTS or vector search used, combine them
            final_cypher_query = " ".join(cypher_query_parts) + " WITH n, fts_score, vec_score" # Consolidate from sub-queries
       
        if where_conditions:
            final_cypher_query += " WHERE " + " AND ".join(where_conditions)
       
        # Add a RETURN clause to get the nodes and their properties, and calculated scores
        # Prioritize relevant nodes. Add semantic_score if applicable.
        final_cypher_query += " RETURN n, fts_score, vec_score, n.embedding as embedding " # Return embedding for processing
        final_cypher_query += " ORDER BY (COALESCE(fts_score, 0) * 0.5 + COALESCE(vec_score, 0) * 0.5) DESC LIMIT 20" # Example ranking

        return final_cypher_query, params

    def _process_neo4j_results(self, raw_results: List[Any], user_query_embedding: Optional[List[float]]) -> List[Dict]:
        """
        Processes raw results from Neo4j (Neo4j Records) into a standardized dictionary format
        expected by the PromptManager.
        Calculates a relevance score combining FTS, vector similarity, and node properties.
        """
        processed_results = []
        for record in raw_results:
            node = record["n"]
            fts_score = record.get("fts_score", 0.0)
            vec_score = record.get("vec_score", 0.0)
            node_embedding = record.get("embedding") # Get embedding from Neo4j node property

            # Calculate semantic similarity if both embeddings are available
            semantic_sim_score = 0.0
            if user_query_embedding and node_embedding and isinstance(node_embedding, list): # Ensure node_embedding is a list
                semantic_sim_score = self._cosine_similarity(user_query_embedding, node_embedding)
           
            # Combine scores (adjust weights as needed)
            # This is a simple combined score. You can make this more sophisticated.
            combined_relevance_score = (fts_score * 0.3) + (vec_score * 0.4) + (semantic_sim_score * 0.3)
            combined_relevance_score = min(combined_relevance_score, 1.0) # Cap score at 1.0

            node_data = {
                "id": node.element_id,
                "title": node.get("name") or node.get("title", "Untitled Concept"), # Prefer 'name', fallback to 'title'
                "content": node.get("description") or node.get("content", ""), # Prefer 'description', fallback to 'content'
                "label": list(node.labels)[0] if node.labels else "Unknown", # Get primary label
                "relevance_score": round(combined_relevance_score, 2), # Rounded for cleaner output
                "embedding": node_embedding # Include embedding for PromptManager's use if needed
                # Add other properties as needed, e.g., 'source', 'page', 'relationships'
            }
            processed_results.append(node_data)
       
        # Sort by relevance score before returning
        processed_results = sorted(processed_results, key=lambda x: x['relevance_score'], reverse=True)
        return processed_results

    def _get_fallback_mock_results(self, user_query_text: str, search_params: Dict) -> Dict:
        """Provides mock search results if Neo4j or main search logic fails."""
        mock_results = []
        extracted_concepts = search_params.get('extracted_concepts', [])
        topic_labels = search_params.get('topic_filter_labels', [])

        # Prioritize mocks based on extracted concepts
        for concept in extracted_concepts:
            if "single responsibility" in concept.lower() or "srp" in concept.lower():
                mock_results.append({'id': 'n_srp', 'name': 'Single Responsibility Principle', 'label': 'DesignPrinciple', 'relevance_score': 0.9, 'description': 'A class should have only one reason to change.'})
            elif "factory" in concept.lower():
                mock_results.append({'id': 'n_factory', 'name': 'Factory Method Pattern', 'label': 'DesignPattern', 'relevance_score': 0.8, 'description': 'Provides an interface for creating objects.'})
            elif "singleton" in concept.lower():
                mock_results.append({'id': 'n_singleton', 'name': 'Singleton Pattern', 'label': 'DesignPattern', 'relevance_score': 0.85, 'description': 'Ensures a class has only one instance.'})
            # Add more specific concept mocks as needed

        # If no specific concepts matched, fallback to general keyword matching for mock
        if not mock_results:
            if "solid" in user_query_text.lower() or "principle" in user_query_text.lower():
                mock_results.append({'id': 'n_srp', 'name': 'Single Responsibility Principle', 'label': 'DesignPrinciple', 'relevance_score': 0.9, 'description': 'A class should have only one reason to change.'})
                mock_results.append({'id': 'n_ocp', 'name': 'Open/Closed Principle', 'label': 'DesignPrinciple', 'relevance_score': 0.88, 'description': 'Entities should be open for extension, but closed for modification.'})
            elif "pattern" in user_query_text.lower():
                mock_results.append({'id': 'n_factory', 'name': 'Factory Method Pattern', 'label': 'DesignPattern', 'relevance_score': 0.8, 'description': 'Provides an interface for creating objects.'})
            elif "architecture" in user_query_text.lower() or "microservices" in user_query_text.lower():
                mock_results.append({'id': 'n_microservices', 'name': 'Microservices Architecture', 'label': 'Architecture', 'relevance_score': 0.9, 'description': 'A style of developing a single application as a suite of small services.'})
            elif "parser" in user_query_text.lower():
                mock_results.append({'id': 'n_parser', 'name': 'Parser', 'label': 'CodeStructure', 'description': 'A component of the compiler.', 'relevance_score': 0.9})
            elif "quality" in user_query_text.lower():
                mock_results.append({'id': 'n_quality_code', 'name': 'Code Quality', 'label': 'QualityAttribute', 'relevance_score': 0.7, 'description': 'Overall goodness of code.'})

        # Apply topic label filtering to mock results as well
        if topic_labels:
            mock_results = [
                res for res in mock_results
                if res.get('label') in topic_labels or res.get('name') in extracted_concepts
            ]
       
        return {'results': mock_results}
