# search_module/graph_search_service.py

from typing import Dict, List, Any, Tuple, Optional
import logging
import re

# Import actual Neo4j driver and client
from neo4j import GraphDatabase 
from knowledge_graph.connection.neo4j_client import Neo4jClient 

# Import embedding service
from search_module.embedding_service import get_embedding
from prompt_engine.intent_classifier import QuestionType # Needed for early exit logic

logger = logging.getLogger(__name__)

# Global neo4j_driver initialization (for direct use or if Neo4jClient relies on it being initialized globally)
neo4j_driver = None
import os
from dotenv import load_dotenv
load_dotenv() 
try:
    _uri = os.getenv("NEO4J_URI")
    _username = os.getenv("NEO4J_USERNAME")
    _password = os.getenv("NEO4J_PASSWORD")
    if _uri and _username and _password:
        neo4j_driver = GraphDatabase.driver(_uri, auth=(_username, _password))
        neo4j_driver.verify_connectivity()
        logger.info("Global Neo4j driver initialized and connected successfully.")
    else:
        logger.warning("Global Neo4j driver not initialized due to missing environment variables.")
except Exception as e:
    logger.error(f"Failed to initialize global Neo4j driver: {e}", exc_info=True)
    neo4j_driver = None


class GraphSearchService:
    def __init__(self, neo4j_client: Neo4jClient):
        self.neo4j_client = neo4j_client
        self.session_histories = {} 


    def search(self, user_query_text: str, search_params: Dict, session_id: str) -> Dict:
        """
        Performs a graph search based on the user query and structured search parameters.

        Args:
            user_query_text (str): The original user query, used for embedding generation.
            search_params (Dict): A dictionary containing structured search parameters
                                  like 'topic_filter_labels', 'search_depth',
                                  'relationship_types', 'extracted_concepts', etc.,
                                  generated by the IntentClassifier.
            session_id (str): The ID of the current user session (for context-aware search).

        Returns:
            Dict: The results from the graph search, typically in the format
                  {'results': [{'id': ..., 'name': ..., 'label': ..., 'relevance_score': ...}, ...]}
        """
        logger.info(f"GraphSearchService: Received user_query_text='{user_query_text}', search_params={search_params}, session_id='{session_id}'")

        # --- IMPORTANT FIX: Early exit if intent is not for graph search ---
        if not search_params or search_params.get('question_type') in [QuestionType.GREETING.value, QuestionType.OUT_OF_SCOPE_GENERAL.value]:
            logger.info("GraphSearchService: Intent is greeting or general out-of-scope, returning empty results.")
            return {'results': []}

        # --- FIX: Rely only on self.neo4j_client for connection check ---
        if not self.neo4j_client or not self.neo4j_client._driver: 
            logger.error("Neo4j client or its driver not initialized. Cannot perform graph search.")
            return self._get_fallback_mock_results(user_query_text, search_params)


        # 1. Generate Embedding for the user_query_text (for semantic search)
        user_query_embedding = None
        try:
            user_query_embedding = get_embedding(user_query_text)
            if user_query_embedding is None:
                logger.warning(f"Embedding service returned None for query: '{user_query_text}'")
        except Exception as e:
            logger.error(f"Failed to generate embedding for '{user_query_text}': {e}", exc_info=True)

        # 2. Extract parameters from search_params dictionary
        topic_labels = search_params.get('topic_filter_labels', [])
        search_depth = search_params.get('search_depth', 2)
        relationship_types = search_params.get('relationship_types', [])
        extracted_concepts = search_params.get('extracted_concepts', [])
        min_relevance_score = search_params.get('min_relevance_score', 0.7)
        keywords_from_intent = search_params.get('keywords', [])


        # 3. Build Dynamic Cypher Query and Execute
        try:
            cypher_query, cypher_params = self._build_cypher_query(
                user_query_text,
                user_query_embedding,
                topic_labels,
                search_depth,
                relationship_types,
                extracted_concepts,
                min_relevance_score,
                keywords_from_intent
            )
            logger.debug(f"Generated Cypher Query: {cypher_query} with params: {cypher_params}")

            raw_graph_results = self.neo4j_client.run_cypher(cypher_query, cypher_params)
            
            processed_results = self._process_neo4j_results(raw_graph_results, user_query_embedding)
            
            final_results = [
                res for res in processed_results if res.get('relevance_score', 0.0) >= min_relevance_score
            ]
            
            logger.info(f"GraphSearchService: Retrieved {len(final_results)} results from Neo4j.")
            return {'results': final_results}

        except Exception as e:
            logger.error(f"Error during Cypher query execution or processing: {e}", exc_info=True)
            return self._get_fallback_mock_results(user_query_text, search_params)

    # Private Helper Methods ---

    def _get_embedding(self, text: str) -> List[float]:
        """Calls the gpt-4.1-nano embedding service to get an embedding for the given text."""
        if not isinstance(text, str) or not text.strip():
            logger.warning("Attempted to get embedding for empty or non-string text.")
            return []
        try:
            embedding = get_embedding(text)
            if not isinstance(embedding, list):
                logger.warning(f"Embedding service returned non-list type: {type(embedding)}. Returning empty list.")
                return []
            return embedding
        except Exception as e:
            logger.error(f"Error calling embedding service for '{text[:50]}...': {e}", exc_info=True)
            return []

    def _cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """Calculates cosine similarity between two vectors."""
        if not vec1 or not vec2:
            return 0.0
        # Ensure same dimension, pad with zeros if not (though ideally they should be same)
        min_len = min(len(vec1), len(vec2))
        if min_len == 0:
            return 0.0
        
        vec1_cropped = vec1[:min_len]
        vec2_cropped = vec2[:min_len]

        dot_product = sum(v1 * v2 for v1, v2 in zip(vec1_cropped, vec2_cropped))
        magnitude_vec1 = sum(v1**2 for v1 in vec1_cropped)**0.5
        magnitude_vec2 = sum(v2**2 for v2 in vec2_cropped)**0.5

        if magnitude_vec1 == 0 or magnitude_vec2 == 0:
            return 0.0
        return dot_product / (magnitude_vec1 * magnitude_vec2)
    
    def _build_cypher_query(self, user_query_text: str, user_embedding: Optional[List[float]],
                            topic_labels: List[str], search_depth: int,
                            relationship_types: List[str], extracted_concepts: List[str],
                            min_relevance_score: float, keywords_from_intent: List[str]) -> Tuple[str, Dict]:
        """
        Constructs a dynamic Cypher query based on all provided search parameters.
        Fixed the Cypher syntax error by structuring CALLs and WITH clauses correctly.
        """
        logger.info(f"Building Cypher Query: user_query_text='{user_query_text}', topic_labels={topic_labels}, extracted_concepts={extracted_concepts}, depth={search_depth}, rel_types={relationship_types}")
        
        params = {}
        
        # Start building the query based on search components
        query_parts = []
        
        # Part 1: Full-text search
        if user_query_text:
            query_parts.append(f"""
                CALL db.index.fulltext.queryNodes('node_fts', $searchText) YIELD node AS n, score AS fts_score
                WITH n, fts_score, 0.0 AS vec_score // Initialize vec_score to 0.0 for all nodes from FTS
            """)
            params['searchText'] = user_query_text
        
        # Part 2: Vector similarity search
        if user_embedding: 
            query_parts.append(f"""
                CALL db.index.vector.queryNodes('concept_embeddings', $k, $embedding) YIELD node AS n, score AS vec_score
                WITH n, 0.0 AS fts_score, vec_score // Initialize fts_score to 0.0 for all nodes from vector search
            """)
            params['embedding'] = user_embedding
            params['k'] = 10 

        # Combine FTS and Vector search results using UNION
        if len(query_parts) > 1:
            main_query = " UNION ALL ".join(query_parts)
            # After UNION, consolidate distinct nodes and take max scores
            main_query = f"""
            {main_query}
            WITH n, max(fts_score) AS fts_score, max(vec_score) AS vec_score
            """
        elif query_parts:
            main_query = query_parts[0]
        else:
            # Fallback for software design questions without FTS or embedding
            logger.warning("No FTS or embedding provided for a software design query. Performing broad node match.")
            main_query = "MATCH (n) WITH n, 0.0 AS fts_score, 0.0 AS vec_score"

        # Initialize where conditions
        where_conditions = []
        
        # Apply additional filtering (labels, extracted concepts) to the `n` now in scope
        # 3. Direct concept matching (using extracted_concepts)
        if extracted_concepts:
            concept_match_clauses = []
            for i, concept in enumerate(extracted_concepts):
                concept_param_name = f'extracted_concept_{i}'
                # Use toLower and CONTAINS for case-insensitive partial matching
                concept_match_clauses.append(f"toLower(n.name) CONTAINS toLower(${concept_param_name})")
                params[concept_param_name] = concept
            if concept_match_clauses:
                where_conditions.append(f"({' OR '.join(concept_match_clauses)})")

        # 4. Label filtering (using topic_labels)
        if topic_labels:
            # Ensure label filtering applies to nodes that have these labels
            label_conditions = " OR ".join([f"'{label}' IN labels(n)" for label in topic_labels])
            where_conditions.append(f"({label_conditions})")
            
        # 5. Relationship traversal (conceptual - this needs proper Cypher paths)
        if relationship_types and search_depth > 0:
            # This part is more complex to integrate into the UNION-based query structure.
            # For simplicity, we'll keep direct node property/label matching as primary.
            # If relationship traversal is critical, it would likely involve another UNION
            # or a more advanced query structure like shortestPath.
            pass

        # Append WHERE clause if conditions exist
        if where_conditions:
            main_query += " WHERE " + " AND ".join(where_conditions)
        
        # Add a RETURN clause to get the nodes and their properties, and calculated scores
        final_cypher_query = f"""
        {main_query}
        OPTIONAL MATCH (n)-[rel]->(target)
        OPTIONAL MATCH (n)<-[rev_rel]-(source)
        RETURN DISTINCT n, 
               COALESCE(fts_score, 0) AS fts_score, 
               COALESCE(vec_score, 0) AS vec_score, 
               n.embedding AS embedding,
               (COALESCE(fts_score, 0) * 0.5 + COALESCE(vec_score, 0) * 0.5) AS relevance_score, 
               collect(DISTINCT {{type: type(rel), target_node_name: target.name, target_labels: labels(target), target_id: id(target)}}) AS relationships,
               collect(DISTINCT {{type: type(rev_rel), source_node_name: source.name, source_labels: labels(source), source_id: id(source)}}) AS reverse_relationships
        ORDER BY relevance_score DESC
        LIMIT 20
        """
        
        logger.debug(f"Final Constructed Cypher Query: {final_cypher_query} with params: {params}")
        return final_cypher_query, params

    def _process_neo4j_results(self, raw_results: List[Dict], user_query_embedding: Optional[List[float]]) -> List[Dict]:
        """
        Processes raw results from Neo4j (dictionaries returned by run_cypher) into a standardized dictionary format.
        Calculates a relevance score combining FTS, vector similarity, and node properties.
        """
        processed_data = []
        for record in raw_results:
            # Access the node object directly from the record dictionary
            node_data_from_record = record.get("n")
            if not node_data_from_record or not isinstance(node_data_from_record, dict):
                logger.warning(f"Skipping record due to missing or invalid 'n' key: {record}")
                continue

            fts_score = record.get("fts_score", 0.0)
            vec_score = record.get("vec_score", 0.0)
            
            # The embedding property should be directly in the record if returned by the query
            node_embedding = record.get("embedding") 

            semantic_sim_score = 0.0
            if user_query_embedding and isinstance(node_embedding, list) and isinstance(user_query_embedding, list):
                if len(user_query_embedding) == len(node_embedding):
                    semantic_sim_score = self._cosine_similarity(user_query_embedding, node_embedding)
                else:
                    logger.warning(f"Embedding dimension mismatch for node {node_data_from_record.get('__id__', 'N/A')}. User: {len(user_query_embedding)}, Node: {len(node_embedding)}")
            
            # Use the relevance score calculated in Cypher primarily
            calculated_relevance_score = record.get("relevance_score", 0.0) 
            
            node_data = {
                "node_id": node_data_from_record.get('__id__', 'N/A'),
                "name": node_data_from_record.get("name") or node_data_from_record.get("title", "Untitled Concept"), 
                "description": node_data_from_record.get("description") or node_data_from_record.get("content", ""), 
                "label": node_data_from_record.get('__labels__', ['Unknown'])[0], 
                "relevance_score": round(calculated_relevance_score, 2),
                "source": node_data_from_record.get("source", "N/A"),
                "page": node_data_from_record.get("page", "N/A"),
                "relationships": record.get("relationships", []) + record.get("reverse_relationships", []) 
            }
            processed_data.append(node_data)
        
        return sorted(processed_data, key=lambda x: x.get('relevance_score', 0.0), reverse=True)

    def _get_fallback_mock_results(self, user_query_text: str, search_params: Dict) -> Dict:
        """Provides mock search results if Neo4j or main search logic fails."""
        mock_results = []
        extracted_concepts = search_params.get('extracted_concepts', [])
        topic_labels = search_params.get('topic_filter_labels', [])

        for concept in extracted_concepts:
            if "single responsibility" in concept.lower() or "srp" in concept.lower():
                mock_results.append({'node_id': 'n_srp', 'name': 'Single Responsibility Principle', 'label': 'DesignPrinciple', 'relevance_score': 0.9, 'description': 'A class should have only one reason to change.'})
            elif "factory" in concept.lower():
                mock_results.append({'node_id': 'n_factory', 'name': 'Factory Method Pattern', 'label': 'DesignPattern', 'relevance_score': 0.8, 'description': 'Provides an interface for creating objects.'})
            elif "singleton" in concept.lower():
                mock_results.append({'node_id': 'n_singleton', 'name': 'Singleton Pattern', 'label': 'DesignPattern', 'relevance_score': 0.85, 'description': 'Ensures a class has only one instance.'})
            
        if not mock_results:
            if "solid" in user_query_text.lower() or "principle" in user_query_text.lower():
                mock_results.append({'node_id': 'n_srp', 'name': 'Single Responsibility Principle', 'label': 'DesignPrinciple', 'relevance_score': 0.9, 'description': 'A class should have only one reason to change.'})
                mock_results.append({'node_id': 'n_ocp', 'name': 'Open/Closed Principle', 'label': 'DesignPrinciple', 'relevance_score': 0.88, 'description': 'Entities should be open for extension, but closed for modification.'})
            elif "pattern" in user_query_text.lower():
                mock_results.append({'id': 'n_factory', 'name': 'Factory Method Pattern', 'label': 'DesignPattern', 'relevance_score': 0.8, 'description': 'Provides an interface for creating objects.'})
            elif "architecture" in user_query_text.lower() or "microservices" in user_query_text.lower():
                mock_results.append({'id': 'n_microservices', 'name': 'Microservices Architecture', 'label': 'Architecture', 'relevance_score': 0.9, 'description': 'A style of developing a single application as a suite of small services.'})
            elif "parser" in user_query_text.lower():
                mock_results.append({'id': 'n_parser', 'name': 'Parser', 'label': 'CodeStructure', 'description': 'A component of the compiler.', 'relevance_score': 0.9})
            elif "quality" in user_query_text.lower():
                mock_results.append({'id': 'n_quality_code', 'name': 'Code Quality', 'label': 'QualityAttribute', 'relevance_score': 0.7, 'description': 'Overall goodness of code.'})

        if topic_labels:
            mapped_mock_results = []
            for res in mock_results:
                is_match = False
                if res.get('label') and res['label'] in topic_labels:
                    is_match = True
                elif res.get('name') and any(concept.lower() in res['name'].lower() for concept in extracted_concepts):
                    is_match = True
                
                if is_match:
                    mapped_mock_results.append(res)
            mock_results = mapped_mock_results

        for res in mock_results:
            if 'source' not in res:
                res['source'] = 'Mock Data'
            if 'page' not in res:
                res['page'] = 'N/A' 

        return {'results': mock_results}