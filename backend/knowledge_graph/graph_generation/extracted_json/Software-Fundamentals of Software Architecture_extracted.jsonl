{"text": "Mark Richards & Neal Ford\nFundamentals of  \nSoftware  \n \nArchitecture\nAn Engineering Approach\n", "page": 1, "type": "text", "section": "Page 1"}
{"text": "Praise for Fundamentals of Software Architecture\nNeal and Mark aren\u2019t just outstanding software architects; they are also exceptional\nteachers. With Fundamentals of Software Architecture, they have managed to\ncondense the sprawling topic of architecture into a concise work that reflects their\ndecades of experience. Whether you\u2019re new to the role or you\u2019ve been a practicing\narchitect for many years, this book will help you be better at your job.\nI only wish they\u2019d written this earlier in my career.\n\u2014Nathaniel Schutta, Architect as a Service, ntschutta.io\nMark and Neal set out to achieve a formidable goal\u2014to elucidate the many, layered\nfundamentals required to excel in software architecture\u2014and they completed their quest.\nThe software architecture field continuously evolves, and the role requires a\ndaunting breadth and depth of knowledge and skills. This book will serve as a\nguide for many as they navigate their journey to software architecture mastery.\n\u2014Rebecca J. Parsons, CTO, ThoughtWorks\nMark and Neal truly capture real world advice for technologists to drive architecture\nexcellence. They achieve this by identifying common architecture characteristics\nand the trade-offs that are necessary to drive success.\n\u2014Cassie Shum, Technical Director, ThoughtWorks\n", "page": 3, "type": "text", "section": "Page 3"}
{"text": "Mark Richards and Neal Ford\nFundamentals of Software\nArchitecture\nAn Engineering Approach\nBoston\nFarnham\nSebastopol\nTokyo\nBeijing\nBoston\nFarnham\nSebastopol\nTokyo\nBeijing\n", "page": 5, "type": "text", "section": "Page 5"}
{"text": "978-1-492-04345-4\n[LSCH]\nFundamentals of Software Architecture\nby Mark Richards and Neal Ford\nCopyright \u00a9 2020 Mark Richards, Neal Ford. All rights reserved.\nPrinted in the United States of America.\nPublished by O\u2019Reilly Media, Inc., 1005 Gravenstein Highway North, Sebastopol, CA 95472.\nO\u2019Reilly books may be purchased for educational, business, or sales promotional use. Online editions are\nalso available for most titles (http://oreilly.com). For more information, contact our corporate/institutional\nsales department: 800-998-9938 or corporate@oreilly.com.\nAcquisitions Editor: Chris Guzikowski\nDevelopment Editors: Alicia Young and Virginia\nWilson\nProduction Editor: Christopher Faucher\nCopyeditor: Sonia Saruba\nProofreader: Amanda Kersey\nIndexer: Ellen Troutman-Zaig\nInterior Designer: David Futato\nCover Designer: Karen Montgomery\nIllustrator: Rebecca Demarest\nFebruary 2020:\n First Edition\nRevision History for the First Edition\n2020-01-27: First Release\n2020-06-12: Second Release\n2020-11-06: Third Release\n2021-02-12: Fourth Release\nSee http://oreilly.com/catalog/errata.csp?isbn=9781492043454 for release details.\nThe O\u2019Reilly logo is a registered trademark of O\u2019Reilly Media, Inc. Fundamentals of Software Architecture,\nthe cover image, and related trade dress are trademarks of O\u2019Reilly Media, Inc.\nThe views expressed in this work are those of the authors, and do not represent the publisher\u2019s views.\nWhile the publisher and the authors have used good faith efforts to ensure that the information and\ninstructions contained in this work are accurate, the publisher and the authors disclaim all responsibility\nfor errors or omissions, including without limitation responsibility for damages resulting from the use of\nor reliance on this work. Use of the information and instructions contained in this work is at your own\nrisk. If any code samples or other technology this work contains or describes is subject to open source\nlicenses or the intellectual property rights of others, it is your responsibility to ensure that your use\nthereof complies with such licenses and/or rights.\n", "page": 6, "type": "text", "section": "Page 6"}
{"text": "Table of Contents\nPreface: Invalidating Axioms. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  xiii\n1. Introduction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  1\nDefining Software Architecture                                                                                       3\nExpectations of an Architect                                                                                            8\nMake Architecture Decisions                                                                                       9\nContinually Analyze the Architecture                                                                         9\nKeep Current with Latest Trends                                                                               10\nEnsure Compliance with Decisions                                                                           10\nDiverse Exposure and Experience                                                                             11\nHave Business Domain Knowledge                                                                           11\nPossess Interpersonal Skills                                                                                         12\nUnderstand and Navigate Politics                                                                              12\nIntersection of Architecture and\u2026                                                                               13\nEngineering Practices                                                                                                  14\nOperations/DevOps                                                                                                     17\nProcess                                                                                                                           18\nData                                                                                                                                19\nLaws of Software Architecture                                                                                       19\nPart I. \nFoundations\n2. Architectural Thinking. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  23\nArchitecture Versus Design                                                                                          23\nTechnical Breadth                                                                                                          25\nv\n", "page": 7, "type": "text", "section": "Page 7"}
{"text": "Analyzing Trade-Offs                                                                                                    30\nUnderstanding Business Drivers                                                                                 34\nBalancing Architecture and Hands-On Coding                                                        34\n3. Modularity. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  37\nDefinition                                                                                                                        38\nMeasuring Modularity                                                                                                  40\nCohesion                                                                                                                      40\nCoupling                                                                                                                      44\nAbstractness, Instability, and Distance from the Main Sequence                       44\nDistance from the Main Sequence                                                                           46\nConnascence                                                                                                               48\nUnifying Coupling and Connascence Metrics                                                       52\nFrom Modules to Components                                                                                    53\n4. Architecture Characteristics Defined. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  55\nArchitectural Characteristics (Partially) Listed                                                         58\nOperational Architecture Characteristics                                                               58\nStructural Architecture Characteristics                                                                  59\nCross-Cutting Architecture Characteristics                                                           59\nTrade-Offs and Least Worst Architecture                                                                  63\n5. Identifying Architectural Characteristics. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  65\nExtracting Architecture Characteristics from Domain Concerns                          65\nExtracting Architecture Characteristics from Requirements                                  67\nCase Study: Silicon Sandwiches                                                                                   69\nExplicit Characteristics                                                                                              70\nImplicit Characteristics                                                                                             73\n6. Measuring and Governing Architecture Characteristics. . . . . . . . . . . . . . . . . . . . . . . . . .  77\nMeasuring Architecture Characteristics                                                                     77\nOperational Measures                                                                                                78\nStructural Measures                                                                                                   79\nProcess Measures                                                                                                        81\nGovernance and Fitness Functions                                                                             82\nGoverning Architecture Characteristics                                                                 82\nFitness Functions                                                                                                        83\n7. Scope of Architecture Characteristics. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  91\nCoupling and Connascence                                                                                         92\nvi \n| \nTable of Contents\n", "page": 8, "type": "text", "section": "Page 8"}
{"text": "Architectural Quanta and Granularity                                                                       92\nCase Study: Going, Going, Gone                                                                             95\n8. Component-Based Thinking. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  99\nComponent Scope                                                                                                          99\nArchitect Role                                                                                                               101\nArchitecture Partitioning                                                                                        102\nCase Study: Silicon Sandwiches: Partitioning                                                      105\nDeveloper Role                                                                                                             108\nComponent Identification Flow                                                                                108\nIdentifying Initial Components                                                                             108\nAssign Requirements to Components                                                                  109\nAnalyze Roles and Responsibilities                                                                       109\nAnalyze Architecture Characteristics                                                                    109\nRestructure Components                                                                                        109\nComponent Granularity                                                                                             110\nComponent Design                                                                                                     110\nDiscovering Components                                                                                       110\nCase Study: Going, Going, Gone: Discovering Components                               112\nArchitecture Quantum Redux: Choosing Between Monolithic Versus\nDistributed Architectures                                                                                       115\nPart II. \nArchitecture Styles\n9. Foundations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  119\nFundamental Patterns                                                                                                 119\nBig Ball of Mud                                                                                                         120\nUnitary Architecture                                                                                               121\nClient/Server                                                                                                             121\nMonolithic Versus Distributed Architectures                                                         123\nFallacy #1: The Network Is Reliable                                                                      124\nFallacy #2: Latency Is Zero                                                                                      125\nFallacy #3: Bandwidth Is Infinite                                                                           126\nFallacy #4: The Network Is Secure                                                                         127\nFallacy #5: The Topology Never Changes                                                             128\nFallacy #6: There Is Only One Administrator                                                      129\nFallacy #7: Transport Cost Is Zero                                                                         130\nFallacy #8: The Network Is Homogeneous                                                           131\nOther Distributed Considerations                                                                         131\nTable of Contents \n| \nvii\n", "page": 9, "type": "text", "section": "Page 9"}
{"text": "10. Layered Architecture Style. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  133\nTopology                                                                                                                       133\nLayers of Isolation                                                                                                        135\nAdding Layers                                                                                                              136\nOther Considerations                                                                                                  138\nWhy Use This Architecture Style                                                                              139\nArchitecture Characteristics Ratings                                                                        139\n11. Pipeline Architecture Style. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  143\nTopology                                                                                                                       143\nPipes                                                                                                                           144\nFilters                                                                                                                         144\nExample                                                                                                                         145\nArchitecture Characteristics Ratings                                                                        146\n12. Microkernel Architecture Style. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  149\nTopology                                                                                                                       149\nCore System                                                                                                              150\nPlug-In Components                                                                                               153\nRegistry                                                                                                                         157\nContracts                                                                                                                       158\nExamples and Use Cases                                                                                             158\nArchitecture Characteristics Ratings                                                                        160\n13. Service-Based Architecture Style. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  163\nTopology                                                                                                                       163\nTopology Variants                                                                                                        165\nService Design and Granularity                                                                                 167\nDatabase Partitioning                                                                                                  169\nExample Architecture                                                                                                 172\nArchitecture Characteristics Ratings                                                                        174\nWhen to Use This Architecture Style                                                                       177\n14. Event-Driven Architecture Style. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  179\nTopology                                                                                                                       180\nBroker Topology                                                                                                          180\nMediator Topology                                                                                                      185\nAsynchronous Capabilities                                                                                        196\nError Handling                                                                                                             197\nPreventing Data Loss                                                                                                   201\nviii \n| \nTable of Contents\n", "page": 10, "type": "text", "section": "Page 10"}
{"text": "Broadcast Capabilities                                                                                                 203\nRequest-Reply                                                                                                              204\nChoosing Between Request-Based and Event-Based                                             206\nHybrid Event-Driven Architectures                                                                          207\nArchitecture Characteristics Ratings                                                                        207\n15. Space-Based Architecture Style. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  211\nGeneral Topology                                                                                                        212\nProcessing Unit                                                                                                        213\nVirtualized Middleware                                                                                           214\nData Pumps                                                                                                               219\nData Writers                                                                                                              221\nData Readers                                                                                                             222\nData Collisions                                                                                                             224\nCloud Versus On-Premises Implementations                                                         226\nReplicated Versus Distributed Caching                                                                    227\nNear-Cache Considerations                                                                                       230\nImplementation Examples                                                                                          231\nConcert Ticketing System                                                                                       231\nOnline Auction System                                                                                           232\nArchitecture Characteristics Ratings                                                                        233\n16. Orchestration-Driven Service-Oriented Architecture. . . . . . . . . . . . . . . . . . . . . . . . . . .  235\nHistory and Philosophy                                                                                              235\nTopology                                                                                                                       236\nTaxonomy                                                                                                                     236\nBusiness Services                                                                                                      237\nEnterprise Services                                                                                                   237\nApplication Services                                                                                                237\nInfrastructure Services                                                                                            237\nOrchestration Engine                                                                                              238\nMessage Flow                                                                                                            238\nReuse\u2026and Coupling                                                                                                 239\nArchitecture Characteristics Ratings                                                                        241\n17. Microservices Architecture. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  245\nHistory                                                                                                                          245\nTopology                                                                                                                       246\nDistributed                                                                                                                    247\nBounded Context                                                                                                         247\nTable of Contents \n| \nix\n", "page": 11, "type": "text", "section": "Page 11"}
{"text": "Granularity                                                                                                                248\nData Isolation                                                                                                            249\nAPI Layer                                                                                                                      249\nOperational Reuse                                                                                                       250\nFrontends                                                                                                                      253\nCommunication                                                                                                           254\nChoreography and Orchestration                                                                          256\nTransactions and Sagas                                                                                            260\nArchitecture Characteristics Ratings                                                                        263\nAdditional References                                                                                                 265\n18. Choosing the Appropriate Architecture Style. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  267\nShifting \u201cFashion\u201d in Architecture                                                                            267\nDecision Criteria                                                                                                          269\nMonolith Case Study: Silicon Sandwiches                                                               271\nModular Monolith                                                                                                   271\nMicrokernel                                                                                                              272\nDistributed Case Study: Going, Going, Gone                                                         274\nPart III. \nTechniques and Soft Skills\n19. Architecture Decisions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  281\nArchitecture Decision Anti-Patterns                                                                        281\nCovering Your Assets Anti-Pattern                                                                       282\nGroundhog Day Anti-Pattern                                                                                282\nEmail-Driven Architecture Anti-Pattern                                                             283\nArchitecturally Significant                                                                                          284\nArchitecture Decision Records                                                                                  285\nBasic Structure                                                                                                          285\nStoring ADRs                                                                                                            291\nADRs as Documentation                                                                                        293\nUsing ADRs for Standards                                                                                      293\nExample                                                                                                                     294\n20. Analyzing Architecture Risk. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  297\nRisk Matrix                                                                                                                   297\nRisk Assessments                                                                                                         298\nRisk Storming                                                                                                               302\nIdentification                                                                                                             303\nx \n| \nTable of Contents\n", "page": 12, "type": "text", "section": "Page 12"}
{"text": "Consensus                                                                                                                 304\nAgile Story Risk Analysis                                                                                            308\nRisk Storming Examples                                                                                             308\nAvailability                                                                                                                310\nElasticity                                                                                                                    312\nSecurity                                                                                                                      313\n21. Diagramming and Presenting Architecture. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  315\nDiagramming                                                                                                               316\nTools                                                                                                                           316\nDiagramming Standards: UML, C4, and ArchiMate                                          318\nDiagram Guidelines                                                                                                 319\nPresenting                                                                                                                     321\nManipulating Time                                                                                                  321\nIncremental Builds                                                                                                   322\nInfodecks Versus Presentations                                                                              324\nSlides Are Half of the Story                                                                                    324\nInvisibility                                                                                                                  324\n22. Making Teams Effective. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  325\nTeam Boundaries                                                                                                         325\nArchitect Personalities                                                                                                326\nControl Freak                                                                                                            327\nArmchair Architect                                                                                                  328\nEffective Architect                                                                                                    330\nHow Much Control?                                                                                                    331\nTeam Warning Signs                                                                                                    335\nLeveraging Checklists                                                                                                  338\nDeveloper Code Completion Checklist                                                                340\nUnit and Functional Testing Checklist                                                                 341\nSoftware Release Checklist                                                                                     342\nProviding Guidance                                                                                                    343\nSummary                                                                                                                       346\n23. Negotiation and Leadership Skills. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  347\nNegotiation and Facilitation                                                                                       347\nNegotiating with Business Stakeholders                                                               348\nNegotiating with Other Architects                                                                        350\nNegotiating with Developers                                                                                  351\nThe Software Architect as a Leader                                                                           353\nTable of Contents \n| \nxi\n", "page": 13, "type": "text", "section": "Page 13"}
{"text": "The 4 C\u2019s of Architecture                                                                                        353\nBe Pragmatic, Yet Visionary                                                                                   355\nLeading Teams by Example                                                                                    357\nIntegrating with the Development Team                                                                 360\nSummary                                                                                                                       363\n24. Developing a Career Path. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  365\nThe 20-Minute Rule                                                                                                    365\nDeveloping a Personal Radar                                                                                     367\nThe ThoughtWorks Technology Radar                                                                367\nOpen Source Visualization Bits                                                                              371\nUsing Social Media                                                                                                      371\nParting Words of Advice                                                                                             372\nAppendix. Self-Assessment Questions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  373\nIndex. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  383\nxii \n| \nTable of Contents\n", "page": 14, "type": "text", "section": "Page 14"}
{"text": "Preface: Invalidating Axioms\nAxiom\nA statement or proposition which is regarded as being established, accepted, or\nself-evidently true.\nMathematicians create theories based on axioms, assumptions for things indisputably\ntrue. Software architects also build theories atop axioms, but the software world is,\nwell, softer than mathematics: fundamental things continue to change at a rapid pace,\nincluding the axioms we base our theories upon.\nThe software development ecosystem exists in a constant state of dynamic equili\u2010\nbrium: while it exists in a balanced state at any given point in time, it exhibits\ndynamic behavior over the long term. A great modern example of the nature of this\necosystem follows the ascension of containerization and the attendant changes: tools\nlike Kubernetes didn\u2019t exist a decade ago, yet now entire software conferences exist to\nservice its users. The software ecosystem changes chaotically: one small change\ncauses another small change; when repeated hundreds of times, it generates a new\necosystem.\nArchitects have an important responsibility to question assumptions and axioms left\nover from previous eras. Many of the books about software architecture were written\nin an era that only barely resembles the current world. In fact, the authors believe that\nwe must question fundamental axioms on a regular basis, in light of improved engi\u2010\nneering practices, operational ecosystems, software development processes\u2014every\u2010\nthing that makes up the messy, dynamic equilibrium where architects and developers\nwork each day.\nCareful observers of software architecture over time witnessed an evolution of capa\u2010\nbilities. Starting with the engineering practices of Extreme Programming, continuing\nwith Continuous Delivery, the DevOps revolution, microservices, containerization,\nand now cloud-based resources, all of these innovations led to new capabilities and\ntrade-offs. As capabilities changed, so did architects\u2019 perspectives on the industry. For\nmany years, the tongue-in-cheek definition of software architecture was \u201cthe stuff\nxiii\n", "page": 15, "type": "text", "section": "Page 15"}
{"text": "that\u2019s hard to change later.\u201d Later, the microservices architecture style appeared, where\nchange is a first-class design consideration.\nEach new era requires new practices, tools, measurements, patterns, and a host of\nother changes. This book looks at software architecture in modern light, taking into\naccount all the innovations from the last decade, along with some new metrics and\nmeasures suited to today\u2019s new structures and perspectives.\nThe subtitle of our book is \u201cAn Engineering Approach.\u201d Developers have long wished\nto change software development from a craft, where skilled artisans can create one-\noff works, to an engineering discipline, which implies repeatability, rigor, and effective\nanalysis. While software engineering still lags behind other types of engineering disci\u2010\nplines by many orders of magnitude (to be fair, software is a very young discipline\ncompared to most other types of engineering), architects have made huge improve\u2010\nments, which we\u2019ll discuss. In particular, modern Agile engineering practices have\nallowed great strides in the types of systems that architects design.\nWe also address the critically important issue of trade-off analysis. As a software\ndeveloper, it\u2019s easy to become enamored with a particular technology or approach.\nBut architects must always soberly assess the good, bad, and ugly of every choice, and\nvirtually nothing in the real world offers convenient binary choices\u2014everything is a\ntrade-off. Given this pragmatic perspective, we strive to eliminate value judgments\nabout technology and instead focus on analyzing trade-offs to equip our readers with\nan analytic eye toward technology choices.\nThis book won\u2019t make someone a software architect overnight\u2014it\u2019s a nuanced field\nwith many facets. We want to provide existing and burgeoning architects a good\nmodern overview of software architecture and its many aspects, from structure to soft\nskills. While this book covers well-known patterns, we take a new approach, leaning\non lessons learned, tools, engineering practices, and other input. We take many exist\u2010\ning axioms in software architecture and rethink them in light of the current ecosys\u2010\ntem, and design architectures, taking the modern landscape into account.\nConventions Used in This Book\nThe following typographical conventions are used in this book:\nItalic\nIndicates new terms, URLs, email addresses, filenames, and file extensions.\nConstant width\nUsed for program listings, as well as within paragraphs to refer to program ele\u2010\nments such as variable or function names, databases, data types, environment\nvariables, statements, and keywords.\nxiv \n| \nPreface: Invalidating Axioms\n", "page": 16, "type": "text", "section": "Page 16"}
{"text": "Constant width bold\nShows commands or other text that should be typed literally by the user.\nConstant width italic\nShows text that should be replaced with user-supplied values or by values deter\u2010\nmined by context.\nThis element signifies a tip or suggestion.\nUsing Code Examples\nSupplemental material (code examples, exercises, etc.) is available for download at\nhttp://fundamentalsofsoftwarearchitecture.com.\nIf you have a technical question or a problem using the code examples, please send\nemail to bookquestions@oreilly.com.\nThis book is here to help you get your job done. In general, if example code is offered\nwith this book, you may use it in your programs and documentation. You do not\nneed to contact us for permission unless you\u2019re reproducing a significant portion of\nthe code. For example, writing a program that uses several chunks of code from this\nbook does not require permission. Selling or distributing examples from O\u2019Reilly\nbooks does require permission. Answering a question by citing this book and quoting\nexample code does not require permission. Incorporating a significant amount of\nexample code from this book into your product\u2019s documentation does require\npermission.\nWe appreciate, but generally do not require, attribution. An attribution usually\nincludes the title, author, publisher, and ISBN. For example: \u201cFundamentals of Soft\u2010\nware Architecture by Mark Richards and Neal Ford (O\u2019Reilly). Copyright 2020 Mark\nRichards, Neal Ford, 978-1-492-04345-4.\u201d\nIf you feel your use of code examples falls outside fair use or the permission given\nabove, feel free to contact us at permissions@oreilly.com.\nPreface: Invalidating Axioms \n| \nxv\n", "page": 17, "type": "text", "section": "Page 17"}
{"text": "O\u2019Reilly Online Learning\nFor more than 40 years, O\u2019Reilly Media has provided technol\u2010\nogy and business training, knowledge, and insight to help\ncompanies succeed.\nOur unique network of experts and innovators share their knowledge and expertise\nthrough books, articles, and our online learning platform. O\u2019Reilly\u2019s online learning\nplatform gives you on-demand access to live training courses, in-depth learning\npaths, interactive coding environments, and a vast collection of text and video from\nO\u2019Reilly and 200+ other publishers. For more information, please visit http://\noreilly.com.\nHow to Contact Us\nPlease address comments and questions concerning this book to the publisher:\nO\u2019Reilly Media, Inc.\n1005 Gravenstein Highway North\nSebastopol, CA 95472\n800-998-9938 (in the United States or Canada)\n707-829-0515 (international or local)\n707-829-0104 (fax)\nWe have a web page for this book, where we list errata, examples, and any additional\ninformation. You can access this page at https://oreil.ly/fundamentals-of-software-\narchitecture.\nEmail bookquestions@oreilly.com to comment or ask technical questions about this\nbook.\nFor news and information about our books and courses, visit http://oreilly.com.\nFind us on Facebook: http://facebook.com/oreilly\nFollow us on Twitter: http://twitter.com/oreillymedia\nWatch us on YouTube: http://www.youtube.com/oreillymedia\nxvi \n| \nPreface: Invalidating Axioms\n", "page": 18, "type": "text", "section": "Page 18"}
{"text": "Acknowledgments\nMark and Neal would like to thank all the people who attended our classes, work\u2010\nshops, conference sessions, user group meetings, as well as all the other people who\nlistened to versions of this material and provided invaluable feedback. We would also\nlike to thank the publishing team at O\u2019Reilly, who made this as painless an experience\nas writing a book can be. We would also like to thank No Stuff Just Fluff director Jay\nZimmerman for creating a conference series that allows good technical content to\ngrow and spread, and all the other speakers whose feedback and tear-soaked should\u2010\ners we appreciate. We would also like to thank a few random oases of sanity-\npreserving and idea-sparking groups that have names like Pasty Geeks and the\nHacker B&B.\nAcknowledgments from Mark Richards\nIn addition to the preceding acknowledgments, I would like to thank my lovely wife,\nRebecca. Taking everything else on at home and sacrificing the opportunity to work\non your own book allowed me to do additional consulting gigs and speak at more\nconferences and training classes, giving me the opportunity to practice and hone the\nmaterial for this book. You are the best.\nAcknowledgments from Neal Ford\nNeal would like to thank his extended family, ThoughtWorks as a collective, and\nRebecca Parsons and Martin Fowler as individual parts of it. ThoughtWorks is an\nextraordinary group who manage to produce value for customers while keeping a\nkeen eye toward why things work so that that we can improve them. ThoughtWorks\nsupported this book in many myriad ways and continues to grow ThoughtWorkers\nwho challenge and inspire every day. Neal would also like to thank our neighborhood\ncocktail club for a regular escape from routine. Lastly, Neal would like to thank his\nwife, Candy, whose tolerance for things like book writing and conference speaking\napparently knows no bounds. For decades she\u2019s kept me grounded and sane enough\nto function, and I hope she will for decades more as the love of my life.\nPreface: Invalidating Axioms \n| \nxvii\n", "page": 19, "type": "text", "section": "Page 19"}
{"text": "CHAPTER 1\nIntroduction\nThe job \u201csoftware architect\u201d appears near the top of numerous lists of best jobs across\nthe world. Yet when readers look at the other jobs on those lists (like nurse practi\u2010\ntioner or finance manager), there\u2019s a clear career path for them. Why is there no path\nfor software architects?\nFirst, the industry doesn\u2019t have a good definition of software architecture itself. When\nwe teach foundational classes, students often ask for a concise definition of what a\nsoftware architect does, and we have adamantly refused to give one. And we\u2019re not\nthe only ones. In his famous whitepaper \u201cWho Needs an Architect?\u201d Martin Fowler\nfamously refused to try to define it, instead falling back on the famous quote:\nArchitecture is about the important stuff\u2026whatever that is.\n\u2014Ralph Johnson\nWhen pressed, we created the mindmap shown in Figure 1-1, which is woefully\nincomplete but indicative of the scope of software architecture. We will, in fact, offer\nour definition of software architecture shortly.\nSecond, as illustrated in the mindmap, the role of software architect embodies a mas\u2010\nsive amount and scope of responsibility that continues to expand. A decade ago, soft\u2010\nware architects dealt only with the purely technical aspects of architecture, like\nmodularity, components, and patterns. Since then, because of new architectural styles\nthat leverage a wider swath of capabilities (like microservices), the role of software\narchitect has expanded. We cover the many intersections of architecture and the\nremainder of the organization in \u201cIntersection of Architecture and\u2026\u201d on page 13.\n1\n", "page": 21, "type": "text", "section": "Page 21"}
{"text": "Figure 1-1. The responsibilities of a software architect encompass technical abilities, soft\nskills, operational awareness, and a host of others\nThird, software architecture is a constantly moving target because of the rapidly\nevolving software development ecosystem. Any definition cast today will be hope\u2010\nlessly outdated in a few years. The Wikipedia definition of software architecture pro\u2010\nvides a reasonable overview, but many statements are outdated, such as \u201cSoftware\narchitecture is about making fundamental structural choices which are costly to\nchange once implemented.\u201d Yet architects designed modern architectural styles like\nmicroservices with the idea of incremental built in\u2014it is no longer expensive to make\nstructural changes in microservices. Of course, that capability means trade-offs with\nother concerns, such as coupling. Many books on software architecture treat it as a\nstatic problem; once solved, we can safely ignore it. However, we recognize the inher\u2010\nent dynamic nature of software architecture, including the definition itself, through\u2010\nout the book.\nFourth, much of the material about software architecture has only historical rele\u2010\nvance. Readers of the Wikipedia page won\u2019t fail to notice the bewildering array of\nacronyms and cross-references to an entire universe of knowledge. Yet, many of these\nacronyms represent outdated or failed attempts. Even solutions that were perfectly\nvalid a few years ago cannot work now because the context has changed. The history\nof software architecture is littered with things architects have tried, only to realize the\ndamaging side effects. We cover many of those lessons in this book.\n2 \n| \nChapter 1: Introduction\n", "page": 22, "type": "text", "section": "Page 22"}
{"text": "Why a book on software architecture fundamentals now? The scope of software\narchitecture isn\u2019t the only part of the development world that constantly changes.\nNew technologies, techniques, capabilities\u2026in fact, it\u2019s easier to find things that\nhaven\u2019t changed over the last decade than to list all the changes. Software architects\nmust make decisions within this constantly changing ecosystem. Because everything\nchanges, including foundations upon which we make decisions, architects should\nreexamine some core axioms that informed earlier writing about software architec\u2010\nture. For example, earlier books about software architecture don\u2019t consider the impact\nof DevOps because it didn\u2019t exist when these books were written.\nWhen studying architecture, readers must keep in mind that, like much art, it can\nonly be understood in context. Many of the decisions architects made were based on\nrealities of the environment they found themselves in. For example, one of the major\ngoals of late 20th-century architecture included making the most efficient use of\nshared resources, because all the infrastructure at the time was expensive and com\u2010\nmercial: operating systems, application servers, database servers, and so on. Imagine\nstrolling into a 2002 data center and telling the head of operations \u201cHey, I have a great\nidea for a revolutionary style of architecture, where each service runs on its own iso\u2010\nlated machinery, with its own dedicated database (describing what we now know as\nmicroservices). So, that means I\u2019ll need 50 licenses for Windows, another 30 applica\u2010\ntion server licenses, and at least 50 database server licenses.\u201d In 2002, trying to build\nan architecture like microservices would be inconceivably expensive. Yet, with the\nadvent of open source during the intervening years, coupled with updated engineer\u2010\ning practices via the DevOps revolution, we can reasonably build an architecture as\ndescribed. Readers should keep in mind that all architectures are a product of their\ncontext.\nDefining Software Architecture\nThe industry as a whole has struggled to precisely define \u201csoftware architecture.\u201d\nSome architects refer to software architecture as the blueprint of the system, while\nothers define it as the roadmap for developing a system. The issue with these com\u2010\nmon definitions is understanding what the blueprint or roadmap actually contains.\nFor example, what is analyzed when an architect analyzes an architecture?\nDefining Software Architecture \n| \n3\n", "page": 23, "type": "text", "section": "Page 23"}
{"text": "Figure 1-2 illustrates a way to think about software architecture. In this definition,\nsoftware architecture consists of the structure of the system (denoted as the heavy\nblack lines supporting the architecture), combined with architecture characteristics\n(\u201c-ilities\u201d) the system must support, architecture decisions, and finally design princi\u2010\nples.\nFigure 1-2. Architecture consists of the structure combined with architecture characteris\u2010\ntics (\u201c-ilities\u201d), architecture decisions, and design principles\n4 \n| \nChapter 1: Introduction\n", "page": 24, "type": "text", "section": "Page 24"}
{"text": "The structure of the system, as illustrated in Figure 1-3, refers to the type of architec\u2010\nture style (or styles) the system is implemented in (such as microservices, layered, or\nmicrokernel). Describing an architecture solely by the structure does not wholly elu\u2010\ncidate an architecture. For example, suppose an architect is asked to describe an\narchitecture, and that architect responds \u201cit\u2019s a microservices architecture.\u201d Here, the\narchitect is only talking about the structure of the system, but not the architecture of\nthe system. Knowledge of the architecture characteristics, architecture decisions, and\ndesign principles is also needed to fully understand the architecture of the system.\nFigure 1-3. Structure refers to the type of architecture styles used in the system\nDefining Software Architecture \n| \n5\n", "page": 25, "type": "text", "section": "Page 25"}
{"text": "Architecture characteristics are another dimension of defining software architecture\n(see Figure 1-4). The architecture characteristics define the success criteria of a sys\u2010\ntem, which is generally orthogonal to the functionality of the system. Notice that all\nof the characteristics listed do not require knowledge of the functionality of the sys\u2010\ntem, yet they are required in order for the system to function properly. Architecture\ncharacteristics are so important that we\u2019ve devoted several chapters in this book to\nunderstanding and defining them.\nFigure 1-4. Architecture characteristics refers to the \u201c-ilities\u201d that the system must\nsupport\nThe next factor that defines software architecture is architecture decisions. Architec\u2010\nture decisions define the rules for how a system should be constructed. For example,\nan architect might make an architecture decision that only the business and services\nlayers within a layered architecture can access the database (see Figure 1-5), restrict\u2010\ning the presentation layer from making direct database calls. Architecture decisions\nform the constraints of the system and direct the development teams on what is and\nwhat isn\u2019t allowed.\n6 \n| \nChapter 1: Introduction\n", "page": 26, "type": "text", "section": "Page 26"}
{"text": "Figure 1-5. Architecture decisions are rules for constructing systems\nIf a particular architecture decision cannot be implemented in one part of the system\ndue to some condition or other constraint, that decision (or rule) can be broken\nthrough something called a variance. Most organizations have variance models that\nare used by an architecture review board (ARB) or chief architect. Those models for\u2010\nmalize the process for seeking a variance to a particular standard or architecture deci\u2010\nsion. An exception to a particular architecture decision is analyzed by the ARB (or\nchief architect if no ARB exists) and is either approved or denied based on justifica\u2010\ntions and trade-offs.\nThe last factor in the definition of architecture is design principles. A design principle\ndiffers from an architecture decision in that a design principle is a guideline rather\nthan a hard-and-fast rule. For example, the design principle illustrated in Figure 1-6\nstates that the development teams should leverage asynchronous messaging between\nservices within a microservices architecture to increase performance. An architecture\ndecision (rule) could never cover every condition and option for communication\nbetween services, so a design principle can be used to provide guidance for the pre\u2010\nferred method (in this case, asynchronous messaging) to allow the developer to\nchoose a more appropriate communication protocol (such as REST or gRPC) given a\nspecific circumstance.\nDefining Software Architecture \n| \n7\n", "page": 27, "type": "text", "section": "Page 27"}
{"text": "Figure 1-6. Design principles are guidelines for constructing systems\nExpectations of an Architect\nDefining the role of a software architect presents as much difficulty as defining soft\u2010\nware architecture. It can range from expert programmer up to defining the strategic\ntechnical direction for the company. Rather than waste time on the fool\u2019s errand of\ndefining the role, we recommend focusing on the expectations of an architect.\nThere are eight core expectations placed on a software architect, irrespective of any\ngiven role, title, or job description:\n\u2022 Make architecture decisions\n\u2022 Continually analyze the architecture\n\u2022 Keep current with latest trends\n\u2022 Ensure compliance with decisions\n\u2022 Diverse exposure and experience\n\u2022 Have business domain knowledge\n\u2022 Possess interpersonal skills\n\u2022 Understand and navigate politics\n8 \n| \nChapter 1: Introduction\n", "page": 28, "type": "text", "section": "Page 28"}
{"text": "The first key to effectiveness and success in the software architect role depends on\nunderstanding and practicing each of these expectations.\nMake Architecture Decisions\nAn architect is expected to define the architecture decisions and design principles used to\nguide technology decisions within the team, the department, or across the enterprise.\nGuide is the key operative word in this first expectation. An architect should guide\nrather than specify technology choices. For example, an architect might make a deci\u2010\nsion to use React.js for frontend development. In this case, the architect is making a\ntechnical decision rather than an architectural decision or design principle that will\nhelp the development team make choices. An architect should instead instruct devel\u2010\nopment teams to use a reactive-based framework for frontend web development, hence\nguiding the development team in making the choice between Angular, Elm, React.js,\nVue, or any of the other reactive-based web frameworks.\nGuiding technology choices through architecture decisions and design principles is\ndifficult. The key to making effective architectural decisions is asking whether the\narchitecture decision is helping to guide teams in making the right technical choice or\nwhether the architecture decision makes the technical choice for them. That said, an\narchitect on occasion might need to make specific technology decisions in order to\npreserve a particular architectural characteristic such as scalability, performance, or\navailability. In this case it would be still considered an architectural decision, even\nthough it specifies a particular technology. Architects often struggle with finding the\ncorrect line, so Chapter 19 is entirely about architecture decisions.\nContinually Analyze the Architecture\nAn architect is expected to continually analyze the architecture and current technology\nenvironment and then recommend solutions for improvement.\nThis expectation of an architect refers to architecture vitality, which assesses how via\u2010\nble the architecture that was defined three or more years ago is today, given changes\nin both business and technology. In our experience, not enough architects focus their\nenergies on continually analyzing existing architectures. As a result, most architec\u2010\ntures experience elements of structural decay, which occurs when developers make\ncoding or design changes that impact the required architectural characteristics, such\nas performance, availability, and scalability.\nOther forgotten aspects of this expectation that architects frequently forget are testing\nand release environments. Agility for code modification has obvious benefits, but if it\ntakes teams weeks to test changes and months for releases, then architects cannot\nachieve agility in the overall architecture.\nExpectations of an Architect \n| \n9\n", "page": 29, "type": "text", "section": "Page 29"}
{"text": "An architect must holistically analyze changes in technology and problem domains to\ndetermine the soundness of the architecture. While this kind of consideration rarely\nappears in a job posting, architects must meet this expectation to keep applications\nrelevant.\nKeep Current with Latest Trends\nAn architect is expected to keep current with the latest technology and industry trends.\nDevelopers must keep up to date on the latest technologies they use on a daily basis to\nremain relevant (and to retain a job!). An architect has an even more critical require\u2010\nment to keep current on the latest technical and industry trends. The decisions an\narchitect makes tend to be long-lasting and difficult to change. Understanding and\nfollowing key trends helps the architect prepare for the future and make the correct\ndecision.\nTracking trends and keeping current with those trends is hard, particularly for a soft\u2010\nware architect. In Chapter 24 we discuss various techniques and resources on how to\ndo this.\nEnsure Compliance with Decisions\nAn architect is expected to ensure compliance with architecture decisions and design\nprinciples.\nEnsuring compliance means that the architect is continually verifying that develop\u2010\nment teams are following the architecture decisions and design principles defined,\ndocumented, and communicated by the architect. Consider the scenario where an\narchitect makes a decision to restrict access to the database in a layered architecture\nto only the business and services layers (and not the presentation layer). This means\nthat the presentation layer must go through all layers of the architecture to make even\nthe simplest of database calls. A user interface developer might disagree with this\ndecision and access the database (or the persistence layer) directly for performance\nreasons. However, the architect made that architecture decision for a specific reason:\nto control change. By closing the layers, database changes can be made without\nimpacting the presentation layer. By not ensuring compliance with architecture deci\u2010\nsions, violations like this can occur, the architecture will not meet the required archi\u2010\ntectural characteristics (\u201c-ilities\u201d), and the application or system will not work as\nexpected.\nIn Chapter 6 we talk more about measuring compliance using automated fitness\nfunctions and automated tools.\n10 \n| \nChapter 1: Introduction\n", "page": 30, "type": "text", "section": "Page 30"}
{"text": "Diverse Exposure and Experience\nAn architect is expected to have exposure to multiple and diverse technologies, frame\u2010\nworks, platforms, and environments.\nThis expectation does not mean an architect must be an expert in every framework,\nplatform, and language, but rather that an architect must at least be familiar with a\nvariety of technologies. Most environments these days are heterogeneous, and at a\nminimum an architect should know how to interface with multiple systems and serv\u2010\nices, irrespective of the language, platform, and technology those systems or services\nare written in.\nOne of the best ways of mastering this expectation is for the architect to stretch their\ncomfort zone. Focusing only on a single technology or platform is a safe haven. An\neffective software architect should be aggressive in seeking out opportunities to gain\nexperience in multiple languages, platforms, and technologies. A good way of master\u2010\ning this expectation is to focus on technical breadth rather than technical depth.\nTechnical breadth includes the stuff you know about, but not at a detailed level, com\u2010\nbined with the stuff you know a lot about. For example, it is far more valuable for an\narchitect to be familiar with 10 different caching products and the associated pros\nand cons of each rather than to be an expert in only one of them.\nHave Business Domain Knowledge\nAn architect is expected to have a certain level of business domain expertise.\nEffective software architects understand not only technology but also the business\ndomain of a problem space. Without business domain knowledge, it is difficult to\nunderstand the business problem, goals, and requirements, making it difficult to\ndesign an effective architecture to meet the requirements of the business. Imagine\nbeing an architect at a large financial institution and not understanding common\nfinancial terms such as an average directional index, aleatory contracts, rates rally, or\neven nonpriority debt. Without this knowledge, an architect cannot communicate\nwith stakeholders and business users and will quickly lose credibility.\nThe most successful architects we know are those who have broad, hands-on techni\u2010\ncal knowledge coupled with a strong knowledge of a particular domain. These soft\u2010\nware architects are able to effectively communicate with C-level executives and\nbusiness users using the domain knowledge and language that these stakeholders\nknow and understand. This in turn creates a strong level of confidence that the soft\u2010\nware architect knows what they are doing and is competent to create an effective and\ncorrect architecture.\nExpectations of an Architect \n| \n11\n", "page": 31, "type": "text", "section": "Page 31"}
{"text": "Possess Interpersonal Skills\nAn architect is expected to possess exceptional interpersonal skills, including teamwork,\nfacilitation, and leadership.\nHaving exceptional leadership and interpersonal skills is a difficult expectation for\nmost developers and architects. As technologists, developers and architects like to\nsolve technical problems, not people problems. However, as Gerald Weinberg was\nfamous for saying, \u201cno matter what they tell you, it\u2019s always a people problem.\u201d An\narchitect is not only expected to provide technical guidance to the team, but is also\nexpected to lead the development teams through the implementation of the architec\u2010\nture. Leadership skills are at least half of what it takes to become an effective software\narchitect, regardless of the role or title the architect has.\nThe industry is flooded with software architects, all competing for a limited number\nof architecture positions. Having strong leadership and interpersonal skills is a good\nway for an architect to differentiate themselves from other architects and stand out\nfrom the crowd. We\u2019ve known many software architects who are excellent technolo\u2010\ngists but are ineffective architects due to the inability to lead teams, coach and mentor\ndevelopers, and effectively communicate ideas and architecture decisions and princi\u2010\nples. Needless to say, those architects have difficulties holding a position or job.\nUnderstand and Navigate Politics\nAn architect is expected to understand the political climate of the enterprise and be able\nto navigate the politics.\nIt might seem rather strange talk about negotiation and navigating office politics in a\nbook about software architecture. To illustrate how important and necessary negotia\u2010\ntion skills are, consider the scenario where a developer makes the decision to leverage\nthe strategy pattern to reduce the overall cyclomatic complexity of a particular piece\nof complex code. Who really cares? One might applaud the developer for using such a\npattern, but in almost all cases the developer does not need to seek approval for such\na decision.\nNow consider the scenario where an architect, responsible for a large customer rela\u2010\ntionship management system, is having issues controlling database access from other\nsystems, securing certain customer data, and making any database schema change\nbecause too many other systems are using the CRM database. The architect therefore\nmakes the decision to create what are called application silos, where each application\ndatabase is only accessible from the application owning that database. Making this\ndecision will give the architect better control over the customer data, security, and\nchange control. However, unlike the previous developer scenario, this decision will\nalso be challenged by almost everyone in the company (with the possible exception of\nthe CRM application team, of course). Other applications need the customer manage\u2010\n12 \n| \nChapter 1: Introduction\n", "page": 32, "type": "text", "section": "Page 32"}
{"text": "ment data. If those applications are no longer able to access the database directly, they\nmust now ask the CRM system for the data, requiring remote access calls through\nREST, SOAP, or some other remote access protocol.\nThe main point is that almost every decision an architect makes will be challenged.\nArchitectural decisions will be challenged by product owners, project managers, and\nbusiness stakeholders due to increased costs or increased effort (time) involved.\nArchitectural decisions will also be challenged by developers who feel their approach\nis better. In either case, the architect must navigate the politics of the company and\napply basic negotiation skills to get most decisions approved. This fact can be very\nfrustrating to a software architect, because most decisions made as a developer did\nnot require approval or even a review. Programming aspects such as code structure,\nclass design, design pattern selection, and sometimes even language choice are all\npart of the art of programming. However, an architect, now able to finally be able to\nmake broad and important decisions, must justify and fight for almost every one of\nthose decisions. Negotiation skills, like leadership skills, are so critical and necessary\nthat we\u2019ve dedicated an entire chapter in the book to understanding them (see\nChapter 23).\nIntersection of Architecture and\u2026\nThe scope of software architecture has grown over the last decade to encompass more\nand more responsibility and perspective. A decade ago, the typical relationship\nbetween architecture and operations was contractual and formal, with lots of\nbureaucracy. Most companies, trying to avoid the complexity of hosting their own\noperations, frequently outsourced operations to a third-party company, with contrac\u2010\ntual obligations for service-level agreements, such as uptime, scale, responsiveness,\nand a host of other important architectural characteristics. Now, architectures such as\nmicroservices freely leverage former solely operational concerns. For example, elastic\nscale was once painfully built into architectures (see Chapter 15), while microservices\nhandled it less painfully via a liaison between architects and DevOps.\nHistory: Pets.com and Why We Have Elastic Scale\nThe history of software development contains rich lessons, both good and bad. We\nassume that current capabilities (like elastic scale) just appeared one day because of\nsome clever developer, but those ideas were often born of hard lessons. Pets.com rep\u2010\nresents an early example of hard lessons learned. Pets.com appeared in the early days\nof the internet, hoping to become the Amazon.com of pet supplies. Fortunately, they\nhad a brilliant marketing department, which invented a compelling mascot: a sock\npuppet with a microphone that said irreverent things. The mascot became a superstar,\nappearing in public at parades and national sporting events.\nIntersection of Architecture and\u2026 \n| \n13\n", "page": 33, "type": "text", "section": "Page 33"}
{"text": "Unfortunately, management at Pets.com apparently spent all the money on the mas\u2010\ncot, not on infrastructure. Once orders started pouring in, they weren\u2019t prepared. The\nwebsite was slow, transactions were lost, deliveries delayed, and so on\u2026pretty much\nthe worst-case scenario. So bad, in fact, that the business closed shortly after its disas\u2010\ntrous Christmas rush, selling the only remaining valuable asset (the mascot) to a\ncompetitor.\nWhat the company needed was elastic scale: the ability to spin up more instances of\nresources, as needed. Cloud providers offer this feature as a commodity, but in the\nearly days of the internet, companies had to manage their own infrastructure, and\nmany fell victim to a previously unheard of phenomenon: too much success can kill\nthe business. Pets.com and other similar horror stories led engineers to develop the\nframeworks that architects enjoy now.\nThe following sections delve into some of the newer intersections between the role of\narchitect and other parts of an organization, highlighting new capabilities and\nresponsibilities for architects.\nEngineering Practices\nTraditionally, software architecture was separate from the development process used\nto create software. Dozens of popular methodologies exist to build software, includ\u2010\ning Waterfall and many flavors of Agile (such as Scrum, Extreme Programming, Lean,\nand Crystal), which mostly don\u2019t impact software architecture.\nHowever, over the last few years, engineering advances have thrust process concerns\nupon software architecture. It is useful to separate software development process from\nengineering practices. By process, we mean how teams are formed and managed, how\nmeetings are conducted, and workflow organization; it refers to the mechanics of\nhow people organize and interact. Software engineering practices, on the other hand,\nrefer to process-agnostic practices that have illustrated, repeatable benefit. For exam\u2010\nple, continuous integration is a proven engineering practice that doesn\u2019t rely on a par\u2010\nticular process.\nThe Path from Extreme Programming to Continuous Delivery\nThe origins of Extreme Programming (XP) nicely illustrate the difference between\nprocess and engineering. In the early 1990s, a group of experienced software develop\u2010\ners, led by Kent Beck, started questioning the dozens of different development pro\u2010\ncesses popular at the time. In their experience, it seemed that none of them created\nrepeatably good outcomes. One of the XP founders said that choosing one of the\nextant processes was \u201cno more guarantee of project success than flipping a coin.\u201d\nThey decided to rethink how to build software, and they started the XP project in\nMarch of 1996. To inform their process, they rejected the conventional wisdom and\n14 \n| \nChapter 1: Introduction\n", "page": 34, "type": "text", "section": "Page 34"}
{"text": "focused on the practices that led to project success in the past, pushed to the extreme.\nTheir reasoning was that they\u2019d seen a correlation on previous projects between more\ntests and higher quality. Thus, the XP approach to testing took the practice to the\nextreme: do test-first development, ensuring that all code is tested before it enters the\ncode base.\nXP was lumped into other popular Agile processes that shared similar perspectives,\nbut it was one of the few methodologies that included engineering practices such as\nautomation, testing, continuous integration, and other concrete, experienced-based\ntechniques. The efforts to continue advancing the engineering side of software\ndevelopment continued with the book Continuous Delivery (Addison-Wesley Profes\u2010\nsional)\u2014an updated version of many XP practices\u2014and came to fruition in the\nDevOps movement. In many ways, the DevOps revolution occurred when operations\nadopted engineering practices originally espoused by XP: automation, testing, declar\u2010\native single source of truth, and others.\nWe strongly support these advances, which form the incremental steps that will even\u2010\ntually graduate software development into a proper engineering discipline.\nFocusing on engineering practices is important. First, software development lacks\nmany of the features of more mature engineering disciplines. For example, civil engi\u2010\nneers can predict structural change with much more accuracy than similarly impor\u2010\ntant aspects of software structure. Second, one of the Achilles heels of software\ndevelopment is estimation\u2014how much time, how many resources, how much\nmoney? Part of this difficulty lies with antiquated accounting practices that cannot\naccommodate the exploratory nature of software development, but another part is\nbecause we\u2019re traditionally bad at estimation, at least in part because of unknown\nunknowns.\n\u2026because as we know, there are known knowns; there are things we know we know.\nWe also know there are known unknowns; that is to say we know there are some things\nwe do not know. But there are also unknown unknowns\u2014the ones we don\u2019t know we\ndon\u2019t know.\n\u2014Former United States Secretary of Defense Donald Rumsfeld\nUnknown unknowns are the nemesis of software systems. Many projects start with a\nlist of known unknowns: things developers must learn about the domain and technol\u2010\nogy they know are upcoming. However, projects also fall victim to unknown\nunknowns: things no one knew were going to crop up yet have appeared unexpect\u2010\nedly. This is why all \u201cBig Design Up Front\u201d software efforts suffer: architects cannot\ndesign for unknown unknowns. To quote Mark (one of your authors):\nAll architectures become iterative because of unknown unknowns, Agile just recognizes\nthis and does it sooner.\nIntersection of Architecture and\u2026 \n| \n15\n", "page": 35, "type": "text", "section": "Page 35"}
{"text": "Thus, while process is mostly separate from architecture, an iterative process fits the\nnature of software architecture better. Teams trying to build a modern system such as\nmicroservices using an antiquated process like Waterfall will find a great deal of fric\u2010\ntion from an antiquated process that ignores the reality of how software comes\ntogether.\nOften, the architect is also the technical leader on projects and therefore determines\nthe engineering practices the team uses. Just as architects must carefully consider the\nproblem domain before choosing an architecture, they must also ensure that the\narchitectural style and engineering practices form a symbiotic mesh. For example, a\nmicroservices architecture assumes automated machine provisioning, automated\ntesting and deployment, and a raft of other assumptions. Trying to build one of these\narchitectures with an antiquated operations group, manual processes, and little test\u2010\ning creates tremendous friction and challenges to success. Just as different problem\ndomains lend themselves toward certain architectural styles, engineering practices\nhave the same kind of symbiotic relationship.\nThe evolution of thought leading from Extreme Programming to Continuous Deliv\u2010\nery continues. Recent advances in engineering practices allow new capabilities within\narchitecture. Neal\u2019s most recent book, Building Evolutionary Architectures (O\u2019Reilly),\nhighlights new ways to think about the intersection of engineering practices and\narchitecture, allowing better automation of architectural governance. While we won\u2019t\nsummarize that book here, it gives an important new nomenclature and way of think\u2010\ning about architectural characteristics that will infuse much of the remainder of this\nbook. Neal\u2019s book covers techniques for building architectures that change gracefully\nover time. In Chapter 4, we describe architecture as the combination of requirements\nand additional concerns, as illustrated in Figure 1-7.\nFigure 1-7. The architecture for a software system consists of both requirements and all\nthe other architectural characteristics\nAs any experience in the software development world illustrates, nothing remains\nstatic. Thus, architects may design a system to meet certain criteria, but that design\nmust survive both implementation (how can architects make sure that their design is\nimplemented correctly) and the inevitable change driven by the software develop\u2010\nment ecosystem. What we need is an evolutionary architecture.\n16 \n| \nChapter 1: Introduction\n", "page": 36, "type": "text", "section": "Page 36"}
{"text": "Building Evolutionary Architectures introduces the concept of using fitness functions to\nprotect (and govern) architectural characteristics as change occurs over time. The\nconcept comes from evolutionary computing. When designing a genetic algorithm,\ndevelopers have a variety of techniques to mutate the solution, evolving new solutions\niteratively. When designing such an algorithm for a specific goal, developers must\nmeasure the outcome to see if it is closer or further away from an optimal solution;\nthat measure is a fitness function. For example, if developers designed a genetic algo\u2010\nrithm to solve the traveling salesperson problem (whose goal is the shortest route\nbetween various cities), the fitness function would look at the path length.\nBuilding Evolutionary Architectures co-opts this idea to create architectural fitness\nfunctions: an objective integrity assessment of some architectural characteristic(s).\nThis assessment may include a variety of mechanisms, such as metrics, unit tests,\nmonitors, and chaos engineering. For example, an architect may identify page load\ntime as an importance characteristic of the architecture. To allow the system to\nchange without degrading performance, the architecture builds a fitness function as a\ntest that measures page load time for each page and then runs the test as part of the\ncontinuous integration for the project. Thus, architects always know the status of crit\u2010\nical parts of the architecture because they have a verification mechanism in the form\nof fitness functions for each part.\nWe won\u2019t go into the full details of fitness functions here. However, we will point out\nopportunities and examples of the approach where applicable. Note the correlation\nbetween how often fitness functions execute and the feedback they provide. You\u2019ll see\nthat adopting Agile engineering practices such as continuous integration, automated\nmachine provisioning, and similar practices makes building resilient architectures\neasier. It also illustrates how intertwined architecture has become with engineering\npractices.\nOperations/DevOps\nThe most obvious recent intersection between architecture and related fields occur\u2010\nred with the advent of DevOps, driven by some rethinking of architectural axioms.\nFor many years, many companies considered operations as a separate function from\nsoftware development; they often outsource operations to another company as a cost-\nsaving measure. Many architectures designed during the 1990s and 2000s assumed\nthat architects couldn\u2019t control operations and were built defensively around that\nrestriction (for a good example of this, see Space-Based Architecture in Chapter 15).\nHowever, a few years ago, several companies started experimenting with new forms of\narchitecture that combine many operational concerns with the architecture. For\nexample, in older-style architectures, such as ESB-driven SOA, the architecture was\ndesigned to handle things like elastic scale, greatly complicating the architecture in\nthe process. Basically, architects were forced to defensively design around the limita\u2010\nIntersection of Architecture and\u2026 \n| \n17\n", "page": 37, "type": "text", "section": "Page 37"}
{"text": "tions introduced because of the cost-saving measure of outsourcing operations. Thus,\nthey built architectures that could handle scale, performance, elasticity, and a host of\nother capabilities internally. The side effect of that design was vastly more complex\narchitecture.\nThe builders of the microservices style of architecture realized that these operational\nconcerns are better handled by operations. By creating a liaison between architecture\nand operations, the architects can simplify the design and rely on operations for the\nthings they handle best. Thus, realizing a misappropriation of resources led to acci\u2010\ndental complexity, and architects and operations teamed up to create microservices,\nthe details of which we cover in Chapter 17.\nProcess\nAnother axiom is that software architecture is mostly orthogonal to the software\ndevelopment process; the way that you build software (process) has little impact on\nthe software architecture (structure). Thus, while the software development process a\nteam uses has some impact on software architecture (especially around engineering\npractices), historically they have been thought of as mostly separate. Most books on\nsoftware architecture ignore the software development process, making specious\nassumptions about things like predictability. However, the process by which teams\ndevelop software has an impact on many facets of software architecture. For example,\nmany companies over the last few decades have adopted Agile development method\u2010\nologies because of the nature of software. Architects in Agile projects can assume iter\u2010\native development and therefore a faster feedback loop for decisions. That in turn\nallows architects to be more aggressive about experimentation and other knowledge\nthat relies on feedback.\nAs the previous quote from Mark observes, all architecture becomes iterative; it\u2019s only\na matter of time. Toward that end, we\u2019re going assume a baseline of Agile methodolo\u2010\ngies throughout and call out exceptions where appropriate. For example, it is still\ncommon for many monolithic architectures to use older processes because of their\nage, politics, or other mitigating factors unrelated to software.\nOne critical aspect of architecture where Agile methodologies shine is restructuring.\nTeams often find that they need to migrate their architecture from one pattern to\nanother. For example, a team started with a monolithic architecture because it was\neasy and fast to bootstrap, but now they need to move it to a more modern architec\u2010\nture. Agile methodologies support these kinds of changes better than planning-heavy\nprocesses because of the tight feedback loop and encouragement of techniques like\nthe Strangler Pattern and feature toggles.\n18 \n| \nChapter 1: Introduction\n", "page": 38, "type": "text", "section": "Page 38"}
{"text": "Data\nA large percentage of serious application development includes external data storage,\noften in the form of a relational (or, increasingly, NoSQL) database. However, many \nbooks about software architecture include only a light treatment of this important\naspect of architecture. Code and data have a symbiotic relationship: one isn\u2019t useful\nwithout the other.\nDatabase administrators often work alongside architects to build data architecture for\ncomplex systems, analyzing how relationships and reuse will affect a portfolio of\napplications. We won\u2019t delve into that level of specialized detail in this book. At the\nsame time, we won\u2019t ignore the existence and dependence on external storage. In par\u2010\nticular, when we talk about the operational aspects of architecture and architectural\nquantum (see \u201cArchitectural Quanta and Granularity\u201d on page 92), we include impor\u2010\ntant external concerns such as databases.\nLaws of Software Architecture\nWhile the scope of software architecture is almost impossibly broad, unifying ele\u2010\nments do exist. The authors have first and foremost learned the First Law of Software\nArchitecture by constantly stumbling across it:\nEverything in software architecture is a trade-off.\n\u2014First Law of Software Architecture\nNothing exists on a nice, clean spectrum for software architects. Every decision must\ntake into account many opposing factors.\nIf an architect thinks they have discovered something that isn\u2019t a trade-off, more likely\nthey just haven\u2019t identified the trade-off yet.\n\u2014Corollary 1\nWe define software architecture in terms beyond structural scaffolding, incorporating\nprinciples, characteristics, and so on. Architecture is broader than just the combina\u2010\ntion of structural elements, reflected in our Second Law of Software Architecture:\nWhy is more important than how.\n\u2014Second Law of Software Architecture\nThe authors discovered the importance of this perspective when we tried keeping the\nresults of exercises done by students during workshop as they crafted architecture\nsolutions. Because the exercises were timed, the only artifacts we kept were the dia\u2010\ngrams representing the topology. In other words, we captured how they solved the\nproblem but not why the team made particular choices. An architect can look at an\nexisting system they have no knowledge of and ascertain how the structure of the\nLaws of Software Architecture \n| \n19\n", "page": 39, "type": "text", "section": "Page 39"}
{"text": "architecture works, but will struggle explaining why certain choices were made versus\nothers.\nThroughout the book, we highlight why architects make certain decisions along with\ntrade-offs. We also highlight good techniques for capturing important decisions in\n\u201cArchitecture Decision Records\u201d on page 285.\n20 \n| \nChapter 1: Introduction\n", "page": 40, "type": "text", "section": "Page 40"}
{"text": "PART I\nFoundations\nTo understand important trade-offs in architecture, developers must understand\nsome basic concepts and terminology concerning components, modularity, coupling,\nand connascence.\n", "page": 41, "type": "text", "section": "Page 41"}
{"text": "CHAPTER 2\nArchitectural Thinking\nAn architect sees things differently from a developer\u2019s point of view, much in the\nsame way a meteorologist might see clouds differently from an artist\u2019s point of view.\nThis is called architectural thinking. Unfortunately, too many architects believe that\narchitectural thinking is simply just \u201cthinking about the architecture.\u201d\nArchitectural thinking is much more than that. It is seeing things with an architec\u2010\ntural eye, or an architectural point of view. There are four main aspects of thinking\nlike an architect. First, it\u2019s understanding the difference between architecture and\ndesign and knowing how to collaborate with development teams to make architecture\nwork. Second, it\u2019s about having a wide breadth of technical knowledge while still\nmaintaining a certain level of technical depth, allowing the architect to see solutions\nand possibilities that others do not see. Third, it\u2019s about understanding, analyzing,\nand reconciling trade-offs between various solutions and technologies. Finally, it\u2019s\nabout understanding the importance of business drivers and how they translate to\narchitectural concerns.\nIn this chapter we explore these four aspects of thinking like an architect and seeing\nthings with an architectural eye.\nArchitecture Versus Design\nThe difference between architecture and design is often a confusing one. Where does\narchitecture end and design begin? What responsibilities does an architect have ver\u2010\nsus those of a developer? Thinking like an architect is knowing the difference\nbetween architecture and design and seeing how the two integrate closely to form sol\u2010\nutions to business and technical problems.\nConsider Figure 2-1, which illustrates the traditional responsibilities an architect has,\nas compared to those of a developer. As shown in the diagram, an architect is respon\u2010\n23\n", "page": 43, "type": "text", "section": "Page 43"}
{"text": "sible for things like analyzing business requirements to extract and define the archi\u2010\ntectural characteristics (\u201c-ilities\u201d), selecting which architecture patterns and styles\nwould fit the problem domain, and creating components (the building blocks of the\nsystem). The artifacts created from these activities are then handed off to the develop\u2010\nment team, which is responsible for creating class diagrams for each component, cre\u2010\nating user interface screens, and developing and testing source code.\nFigure 2-1. Traditional view of architecture versus design\nThere are several issues with the traditional responsibility model illustrated in\nFigure 2-1. As a matter of fact, this illustration shows exactly why architecture rarely\nworks. Specifically, it is the unidirectional arrow passing though the virtual and phys\u2010\nical barriers separating the architect from the developer that causes all of the prob\u2010\nlems associated with architecture. Decisions an architect makes sometimes never\nmake it to the development teams, and decisions development teams make that\nchange the architecture rarely get back to the architect. In this model the architect is\ndisconnected from the development teams, and as such the architecture rarely pro\u2010\nvides what it was originally set out to do.\nTo make architecture work, both the physical and virtual barriers that exist between\narchitects and developers must be broken down, thus forming a strong bidirectional\nrelationship between architects and development teams. The architect and developer\nmust be on the same virtual team to make this work, as depicted in Figure 2-2. Not\nonly does this model facilitate strong bidirectional communication between architec\u2010\nture and development, but it also allows the architect to provide mentoring and\ncoaching to developers on the team.\n24 \n| \nChapter 2: Architectural Thinking\n", "page": 44, "type": "text", "section": "Page 44"}
{"text": "Figure 2-2. Making architecture work through collaboration\nUnlike the old-school waterfall approaches to static and rigid software architecture,\nthe architecture of today\u2019s systems changes and evolves every iteration or phase of a\nproject. A tight collaboration between the architect and the development team is\nessential for the success of any software project. So where does architecture end and\ndesign begin? It doesn\u2019t. They are both part of the circle of life within a software\nproject and must always be kept in synchronization with each other in order to\nsucceed.\nTechnical Breadth\nThe scope of technological detail differs between developers and architects. Unlike a\ndeveloper, who must have a significant amount of technical depth to perform their\njob, a software architect must have a significant amount of technical breadth to think\nlike an architect and see things with an architecture point of view. This is illustrated\nby the knowledge pyramid shown in Figure 2-3, which encapsulates all the technical\nknowledge in the world. It turns out that the kind of information a technologist\nshould value differs with career stages.\nTechnical Breadth \n| \n25\n", "page": 45, "type": "text", "section": "Page 45"}
{"text": "Figure 2-3. The pyramid representing all knowledge\nAs shown in Figure 2-3, any individual can partition all their knowledge into three\nsections: stuff you know, stuff you know you don\u2019t know, and stuff you don\u2019t know you\ndon\u2019t know.\nStuff you know includes the technologies, frameworks, languages, and tools a technol\u2010\nogist uses on a daily basis to perform their job, such as knowing Java as a Java pro\u2010\ngrammer. Stuff you know you don\u2019t know includes those things a technologist knows a\nlittle about or has heard of but has little or no expertise in. A good example of this\nlevel of knowledge is the Clojure programming language. Most technologists have\nheard of Clojure and know it\u2019s a programming language based on Lisp, but they can\u2019t\ncode in the language. Stuff you don\u2019t know you don\u2019t know is the largest part of the\nknowledge triangle and includes the entire host of technologies, tools, frameworks,\nand languages that would be the perfect solution to a problem a technologist is trying\nto solve, but the technologist doesn\u2019t even know those things exist.\n26 \n| \nChapter 2: Architectural Thinking\n", "page": 46, "type": "text", "section": "Page 46"}
{"text": "A developer\u2019s early career focuses on expanding the top of the pyramid, to build\nexperience and expertise. This is the ideal focus early on, because developers need\nmore perspective, working knowledge, and hands-on experience. Expanding the top\nincidentally expands the middle section; as developers encounter more technologies\nand related artifacts, it adds to their stock of stuff you know you don\u2019t know.\nIn Figure 2-4, expanding the top of the pyramid is beneficial because expertise is val\u2010\nued. However, the stuff you know is also the stuff you must maintain\u2014nothing is static\nin the software world. If a developer becomes an expert in Ruby on Rails, that exper\u2010\ntise won\u2019t last if they ignore Ruby on Rails for a year or two. The things at the top of\nthe pyramid require time investment to maintain expertise. Ultimately, the size of the\ntop of an individual\u2019s pyramid is their technical depth.\nFigure 2-4. Developers must maintain expertise to retain it\nTechnical Breadth \n| \n27\n", "page": 47, "type": "text", "section": "Page 47"}
{"text": "However, the nature of knowledge changes as developers transition into the architect\nrole. A large part of the value of an architect is a broad understanding of technology\nand how to use it to solve particular problems. For example, as an architect, it is more\nbeneficial to know that five solutions exist for a particular problem than to have sin\u2010\ngular expertise in only one. The most important parts of the pyramid for architects\nare the top and middle sections; how far the middle section penetrates into the bot\u2010\ntom section represents an architect\u2019s technical breadth, as shown in Figure 2-5.\nFigure 2-5. What someone knows is technical depth, and how much someone knows is\ntechnical breadth\nAs an architect, breadth is more important than depth. Because architects must make\ndecisions that match capabilities to technical constraints, a broad understanding of a\nwide variety of solutions is valuable. Thus, for an architect, the wise course of action\nis to sacrifice some hard-won expertise and use that time to broaden their portfolio,\nas shown in Figure 2-6. As illustrated in the diagram, some areas of expertise will\nremain, probably in particularly enjoyable technology areas, while others usefully\natrophy.\n28 \n| \nChapter 2: Architectural Thinking\n", "page": 48, "type": "text", "section": "Page 48"}
{"text": "Figure 2-6. Enhanced breadth and shrinking depth for the architect role\nOur knowledge pyramid illustrates how fundamentally different the role of architect\ncompares to developer. Developers spend their whole careers honing expertise, and\ntransitioning to the architect role means a shift in that perspective, which many indi\u2010\nviduals find difficult. This in turn leads to two common dysfunctions: first, an archi\u2010\ntect tries to maintain expertise in a wide variety of areas, succeeding in none of them\nand working themselves ragged in the process. Second, it manifests as stale expertise\n\u2014the mistaken sensation that your outdated information is still cutting edge. We see\nthis often in large companies where the developers who founded the company have\nmoved into leadership roles yet still make technology decisions using ancient criteria\n(see \u201cFrozen Caveman Anti-Pattern\u201d on page 30).\nArchitects should focus on technical breadth so that they have a larger quiver from\nwhich to draw arrows. Developers transitioning to the architect role may have to\nchange the way they view knowledge acquisition. Balancing their portfolio of knowl\u2010\nedge regarding depth versus breadth is something every developer should consider\nthroughout their career.\nTechnical Breadth \n| \n29\n", "page": 49, "type": "text", "section": "Page 49"}
{"text": "Frozen Caveman Anti-Pattern\nA behavioral anti-pattern commonly observed in the wild, the Frozen Caveman Anti-\nPattern, describes an architect who always reverts back to their pet irrational concern\nfor every architecture. For example, one of Neal\u2019s colleagues worked on a system that\nfeatured a centralized architecture. Yet, each time they delivered the design to the cli\u2010\nent architects, the persistent question was \u201cBut what if we lose Italy?\u201d Several years\nbefore, a freak communication problem had prevented headquarters from communi\u2010\ncating with its stores in Italy, causing great inconvenience. While the chances of a\nreoccurrence were extremely small, the architects had become obsessed about this\nparticular architectural characteristic.\nGenerally, this anti-pattern manifests in architects who have been burned in the past\nby a poor decision or unexpected occurrence, making them particularly cautious in\nthe future. While risk assessment is important, it should be realistic as well. Under\u2010\nstanding the difference between genuine versus perceived technical risk is part of the\nongoing learning process for architects. Thinking like an architect requires overcom\u2010\ning these \u201cfrozen caveman\u201d ideas and experiences, seeing other solutions, and asking\nmore relevant questions.\nAnalyzing Trade-Offs\nThinking like an architect is all about seeing trade-offs in every solution, technical or\notherwise, and analyzing those trade-offs to determine what is the best solution. To\nquote Mark (one of your authors):\nArchitecture is the stuff you can\u2019t Google.\nEverything in architecture is a trade-off, which is why the famous answer to every\narchitecture question in the universe is \u201cit depends.\u201d While many people get increas\u2010\ningly annoyed at this answer, it is unfortunately true. You cannot Google the answer\nto whether REST or messaging would be better, or whether microservices is the right\narchitecture style, because it does depend. It depends on the deployment environ\u2010\nment, business drivers, company culture, budgets, timeframes, developer skill set, and\ndozens of other factors. Everyone\u2019s environment, situation, and problem is different,\nhence why architecture is so hard. To quote Neal (another one of your authors):\nThere are no right or wrong answers in architecture\u2014only trade-offs.\n30 \n| \nChapter 2: Architectural Thinking\n", "page": 50, "type": "text", "section": "Page 50"}
{"text": "For example, consider an item auction system, as illustrated in Figure 2-7, where\nsomeone places a bid for an item up for auction.\nFigure 2-7. Auction system example of a trade-off\u2014queues or topics?\nThe Bid Producer service generates a bid from the bidder and then sends that bid\namount to the Bid Capture, Bid Tracking, and Bid Analytics services. This could\nbe done by using queues in a point-to-point messaging fashion or by using a topic in\na publish-and-subscribe messaging fashion. Which one should the architect use? You\ncan\u2019t Google the answer. Architectural thinking requires the architect to analyze the\ntrade-offs associated with each option and select the best one given the specific\nsituation.\nThe two messaging options for the item auction system are shown in Figures 2-8 and\n2-9, with Figure 2-8 illustrating the use of a topic in a publish-and-subscribe messag\u2010\ning model, and Figure 2-9 illustrating the use of queues in a point-to-point messaging\nmodel.\nFigure 2-8. Use of a topic for communication between services\nAnalyzing Trade-Offs \n| \n31\n", "page": 51, "type": "text", "section": "Page 51"}
{"text": "Figure 2-9. Use of queues for communication between services\nThe clear advantage (and seemingly obvious solution) to this problem in Figure 2-8 is\nthat of architectural extensibility. The Bid Producer service only requires a single\nconnection to a topic, unlike the queue solution in Figure 2-9 where the Bid Pro\nducer needs to connect to three different queues. If a new service called Bid History\nwere to be added to this system due to the requirement to provide each bidder with a\nhistory of all the bids they made in each auction, no changes at all would be needed to\nthe existing system. When the new Bid History service is created, it could simply\nsubscribe to the topic already containing the bid information. In the queue option\nshown in Figure 2-9, however, a new queue would be required for the Bid History\nservice, and the Bid Producer would need to be modified to add an additional con\u2010\nnection to the new queue. The point here is that using queues requires significant\nchange to the system when adding new bidding functionality, whereas with the topic\napproach no changes are needed at all in the existing infrastructure. Also, notice that\nthe Bid Producer is more decoupled in the topic option\u2014the Bid Producer doesn\u2019t\nknow how the bidding information will be used or by which services. In the queue\noption the Bid Producer knows exactly how the bidding information is used (and by\nwhom), and hence is more coupled to the system.\nWith this analysis it seems clear that the topic approach using the publish-and-\nsubscribe messaging model is the obvious and best choice. However, to quote Rich\nHickey, the creator of the Clojure programming language:\nProgrammers know the benefits of everything and the trade-offs of nothing. Architects\nneed to understand both.\n32 \n| \nChapter 2: Architectural Thinking\n", "page": 52, "type": "text", "section": "Page 52"}
{"text": "Thinking architecturally is looking at the benefits of a given solution, but also analyz\u2010\ning the negatives, or trade-offs, associated with a solution. Continuing with the auc\u2010\ntion system example, a software architect would analyze the negatives of the topic\nsolution. In analyzing the differences, notice first in Figure 2-8 that with a topic, any\u2010\none can access bidding data, which introduces a possible issue with data access and\ndata security. In the queue model illustrated in Figure 2-9, the data sent to the queue\ncan only be accessed by the specific consumer receiving that message. If a rogue ser\u2010\nvice did listen in on a queue, those bids would not be received by the corresponding\nservice, and a notification would immediately be sent about the loss of data (and\nhence a possible security breach). In other words, it is very easy to wiretap into a\ntopic, but not a queue.\nIn addition to the security issue, the topic solution in Figure 2-8 only supports homo\u2010\ngeneous contracts. All services receiving the bidding data must accept the same con\u2010\ntract and set of bidding data. In the queue option in Figure 2-9, each consumer can\nhave its own contract specific to the data it needs. For example, suppose the new Bid\nHistory service requires the current asking price along with the bid, but no other ser\u2010\nvice needs that information. In this case, the contract would need to be modified,\nimpacting all other services using that data. In the queue model, this would be a sepa\u2010\nrate channel, hence a separate contract not impacting any other service.\nAnother disadvantage of the topic model illustrated in Figure 2-8 is that it does not\nsupport monitoring of the number of messages in the topic and hence auto-scaling\ncapabilities. However, with the queue option in Figure 2-9, each queue can be moni\u2010\ntored individually, and programmatic load balancing applied to each bidding con\u2010\nsumer so that each can be automatically scaled independency from one another. Note\nthat this trade-off is technology specific in that the Advanced Message Queuing Pro\u2010\ntocol (AMQP) can support programmatic load balancing and monitoring because of\nthe separation between an exchange (what the producer sends to) and a queue (what\nthe consumer listens to).\nGiven this trade-off analysis, now which is the better option? And the answer? It\ndepends! Table 2-1 summarizes these trade-offs.\nTable 2-1. Trade-offs for topics\nTopic advantages\nTopic disadvantages\nArchitectural extensibility\nData access and data security concerns\nService decoupling\nNo heterogeneous contracts\nMonitoring and programmatic\nscalability\nAnalyzing Trade-Offs \n| \n33\n", "page": 53, "type": "text", "section": "Page 53"}
{"text": "The point here is that everything in software architecture has a trade-off: an advantage\nand disadvantage. Thinking like an architect is analyzing these trade-offs, then asking\n\u201cwhich is more important: extensibility or security?\u201d The decision between different\nsolutions will always depend on the business drivers, environment, and a host of\nother factors.\nUnderstanding Business Drivers\nThinking like an architect is understanding the business drivers that are required for\nthe success of the system and translating those requirements into architecture charac\u2010\nteristics (such as scalability, performance, and availability). This is a challenging task\nthat requires the architect to have some level of business domain knowledge and\nhealthy, collaborative relationships with key business stakeholders. We\u2019ve devoted\nseveral chapters in the book on this specific topic. In Chapter 4 we define various\narchitecture characteristics. In Chapter 5 we describe ways to identify and qualify\narchitecture characteristics. And in Chapter 6 we describe how to measure each of\nthese characteristics to ensure the business needs of the system are met.\nBalancing Architecture and Hands-On Coding\nOne of the difficult tasks an architect faces is how to balance hands-on coding with\nsoftware architecture. We firmly believe that every architect should code and be able\nto maintain a certain level of technical depth (see \u201cTechnical Breadth\u201d on page 25).\nWhile this may seem like an easy task, it is sometimes rather difficult to accomplish.\nThe first tip in striving for a balance between hands-on coding and being a software \narchitect is avoiding the bottleneck trap. The bottleneck trap occurs when the archi\u2010\ntect has taken ownership of code within the critical path of a project (usually the\nunderlying framework code) and becomes a bottleneck to the team. This happens\nbecause the architect is not a full-time developer and therefore must balance between\nplaying the developer role (writing and testing source code) and the architect role\n(drawing diagrams, attending meetings, and well, attending more meetings).\nOne way to avoid the bottleneck trap as an effective software architect is to delegate\nthe critical path and framework code to others on the development team and then\nfocus on coding a piece of business functionality (a service or a screen) one to three\niterations down the road. Three positive things happen by doing this. First, the archi\u2010\ntect is gaining hands-on experience writing production code while no longer becom\u2010\ning a bottleneck on the team. Second, the critical path and framework code is\ndistributed to the development team (where it belongs), giving them ownership and a\nbetter understanding of the harder parts of the system. Third, and perhaps most\nimportant, the architect is writing the same business-related source code as the devel\u2010\nopment team and is therefore better able to identify with the development team in\n34 \n| \nChapter 2: Architectural Thinking\n", "page": 54, "type": "text", "section": "Page 54"}
{"text": "terms of the pain they might be going through with processes, procedures, and the\ndevelopment environment.\nSuppose, however, that the architect is not able to develop code with the development\nteam. How can a software architect still remain hands-on and maintain some level of\ntechnical depth? There are four basic ways an architect can still remain hands-on at\nwork without having to \u201cpractice coding from home\u201d (although we recommend prac\u2010\nticing coding at home as well).\nThe first way is to do frequent proof-of-concepts or POCs. This practice not only\nrequires the architect to write source code, but it also helps validate an architecture\ndecision by taking the implementation details into account. For example, if an archi\u2010\ntect is stuck trying to make a decision between two caching solutions, one effective\nway to help make this decision is to develop a working example in each caching prod\u2010\nuct and compare the results. This allows the architect to see first-hand the implemen\u2010\ntation details and the amount of effort required to develop the full solution. It also\nallows the architect to better compare architectural characteristics such as scalability,\nperformance, or overall fault tolerance of the different caching solutions.\nOur advice when doing proof-of-concept work is that, whenever possible, the archi\u2010\ntect should write the best production-quality code they can. We recommend this\npractice for two reasons. First, quite often, throwaway proof-of-concept code goes\ninto the source code repository and becomes the reference architecture or guiding\nexample for others to follow. The last thing an architect would want is for their\nthrowaway, sloppy code to be a representation of their typical work. The second rea\u2010\nson is that by writing production-quality proof-of-concept code, the architect gets\npractice writing quality, well-structured code rather than continually developing bad\ncoding practices.\nAnother way an architect can remain hands-on is to tackle some of the technical debt\nstories or architecture stories, freeing the development team up to work on the criti\u2010\ncal functional user stories. These stories are usually low priority, so if the architect\ndoes not have the chance to complete a technical debt or architecture story within a\ngiven iteration, it\u2019s not the end of the world and generally does not impact the success\nof the iteration.\nSimilarly, working on bug fixes within an iteration is another way of maintaining\nhands-on coding while helping the development team as well. While certainly not\nglamorous, this technique allows the architect to identify where issues and weakness\nmay be within the code base and possibly the architecture.\nLeveraging automation by creating simple command-line tools and analyzers to help\nthe development team with their day-to-day tasks is another great way to maintain\nhands-on coding skills while making the development team more effective. Look for\nrepetitive tasks the development team performs and automate the process. The devel\u2010\nBalancing Architecture and Hands-On Coding \n| \n35\n", "page": 55, "type": "text", "section": "Page 55"}
{"text": "opment team will be grateful for the automation. Some examples are automated\nsource validators to help check for specific coding standards not found in other lint\ntests, automated checklists, and repetitive manual code refactoring tasks.\nAutomation can also be in the form of architectural analysis and fitness functions to\nensure the vitality and compliance of the architecture. For example, an architect can\nwrite Java code in ArchUnit in the Java platform to automate architectural compli\u2010\nance, or write custom fitness functions to ensure architectural compliance while gain\u2010\ning hands-on experience. We talk about these techniques in Chapter 6.\nA final technique to remain hands-on as an architect is to do frequent code reviews.\nWhile the architect is not actually writing code, at least they are involved in the source\ncode. Further, doing code reviews has the added benefits of being able to ensure com\u2010\npliance with the architecture and to seek out mentoring and coaching opportunities\non the team.\n36 \n| \nChapter 2: Architectural Thinking\n", "page": 56, "type": "text", "section": "Page 56"}
{"text": "CHAPTER 3\nModularity\nFirst, we want to untangle some common terms used and overused in discussions\nabout architecture surrounding modularity and provide definitions for use through\u2010\nout the book.\n95% of the words [about software architecture] are spent extolling the benefits of\n\u201cmodularity\u201d and that little, if anything, is said about how to achieve it.\n\u2014Glenford J. Myers (1978)\nDifferent platforms offer different reuse mechanisms for code, but all support some\nway of grouping related code together into modules. While this concept is universal in\nsoftware architecture, it has proven slippery to define. A casual internet search yields\ndozens of definitions, with no consistency (and some contradictions). As you can see\nfrom the quote from Myers, this isn\u2019t a new problem. However, because no recog\u2010\nnized definition exists, we must jump into the fray and provide our own definitions\nfor the sake of consistency throughout the book.\nUnderstanding modularity and its many incarnations in the development platform of\nchoice is critical for architects. Many of the tools we have to analyze architecture\n(such as metrics, fitness functions, and visualizations) rely on these modularity con\u2010\ncepts. Modularity is an organizing principle. If an architect designs a system without\npaying attention to how the pieces wire together, they end up creating a system that\npresents myriad difficulties. To use a physics analogy, software systems model com\u2010\nplex systems, which tend toward entropy (or disorder). Energy must be added to a\nphysical system to preserve order. The same is true for software systems: architects\nmust constantly expend energy to ensure good structural soundness, which won\u2019t\nhappen by accident.\n37\n", "page": 57, "type": "text", "section": "Page 57"}
{"text": "Preserving good modularity exemplifies our definition of an implicit architecture\ncharacteristic: virtually no project features a requirement that asks the architect to\nensure good modular distinction and communication, yet sustainable code bases\nrequire order and consistency.\nDefinition\nThe dictionary defines module as \u201ceach of a set of standardized parts or independent\nunits that can be used to construct a more complex structure.\u201d We use modularity to\ndescribe a logical grouping of related code, which could be a group of classes in an\nobject-oriented language or functions in a structured or functional language. Most\nlanguages provide mechanisms for modularity (package in Java, namespace in .NET,\nand so on). Developers typically use modules as a way to group related code together.\nFor example, the com.mycompany.customer package in Java should contain things\nrelated to customers.\nLanguages now feature a wide variety of packaging mechanisms, making a develo\u2010\nper\u2019s chore of choosing between them difficult. For example, in many modern lan\u2010\nguages, developers can define behavior in functions/methods, classes, or packages/\nnamespaces, each with different visibility and scoping rules. Other languages compli\u2010\ncate this further by adding programming constructs such as the metaobject protocol\nto provide developers even more extension mechanisms.\nArchitects must be aware of how developers package things because it has important\nimplications in architecture. For example, if several packages are tightly coupled\ntogether, reusing one of them for related work becomes more difficult.\nModular Reuse Before Classes\nDevelopers who predate object-oriented languages may puzzle over why so many dif\u2010\nferent separation schemes commonly exist. Much of the reason has to do with back\u2010\nward compatibility, not of code but rather for how developers think about things. In\nMarch of 1968, Edsger Dijkstra published a letter in the Communications of the ACM\nentitled \u201cGo To Statement Considered Harmful.\u201d He denigrated the common use of\nthe GOTO statement common in programming languages at the time that allowed non-\nlinear leaping around within code, making reasoning and debugging difficult.\nThis paper helped usher in the era of structured programming languages, exemplified\nby Pascal and C, which encouraged deeper thinking about how things fit together. \nDevelopers quickly realized that most of the languages had no good way to group like\nthings together logically. Thus, the short era of modular languages was born, such as\nModula (Pascal creator Niklaus Wirth\u2019s next language) and Ada. These languages had\nthe programming construct of a module, much as we think about packages or name\u2010\nspaces today (but without the classes).\n38 \n| \nChapter 3: Modularity\n", "page": 58, "type": "text", "section": "Page 58"}
{"text": "The modular programming era was short-lived. Object-oriented languages became\npopular because they offered new ways to encapsulate and reuse code. Still, language\ndesigners realized the utility of modules, retaining them in the form of packages,\nnamespaces, etc. Many odd compatibility features exist in languages to support these\ndifferent paradigms. For example, Java supports modular (via packages and package-\nlevel initialization using static initializers), object-oriented, and functional paradigms,\neach programming style with its own scoping rules and quirks.\nFor discussions about architecture, we use modularity as a general term to denote a\nrelated grouping of code: classes, functions, or any other grouping. This doesn\u2019t imply\na physical separation, merely a logical one; the difference is sometimes important. For\nexample, lumping a large number of classes together in a monolithic application may\nmake sense from a convenience standpoint. However, when it comes time to restruc\u2010\nture the architecture, the coupling encouraged by loose partitioning becomes an\nimpediment to breaking the monolith apart. Thus, it is useful to talk about modular\u2010\nity as a concept separate from the physical separation forced or implied by a particu\u2010\nlar platform.\nIt is worth noting the general concept of namespace, separate from the technical\nimplementation in the .NET platform. Developers often need precise, fully qualified\nnames for software assets to separate different software assets (components, classes,\nand so on) from each other. The most obvious example that people use every day is\nthe internet: unique, global identifiers tied to IP addresses. Most languages have some\nmodularity mechanism that doubles as a namespace to organize things: variables,\nfunctions, and/or methods. Sometimes the module structure is reflected physically.\nFor example, Java requires that its package structure must reflect the directory struc\u2010\nture of the physical class files.\nA Language with No Name Conflicts: Java 1.0\nThe original designers of Java had extensive experience dealing with name conflicts\nand clashes in the various programming platforms at the time. The original design of\nJava used a clever hack to avoid the possibility of ambiguity between two classes that\nhad the same name. For example, what if your problem domain included a catalog\norder and an installation order: both named order but with very different connota\u2010\ntions (and classes). The solution in Java was to create the package namespace mecha\u2010\nnism, along with the requirement that the physical directory structure just match the\npackage name. Because filesystems won\u2019t allow the same named file to reside in the\nsame directory, they leveraged the inherent features of the operating system to avoid\nthe possibility of ambiguity. Thus, the original classpath in Java contained only\ndirectories, disallowing the possibility of name conflicts.\nDefinition \n| \n39\n", "page": 59, "type": "text", "section": "Page 59"}
{"text": "However, as the language designers discovered, forcing every project to have a fully\nformed directory structure was cumbersome, especially as projects became larger.\nPlus, building reusable assets was difficult: frameworks and libraries must be \u201cexplo\u2010\nded\u201d into the directory structure. In the second major release of Java (1.2, called Java\n2), designers added the jar mechanism, allowing an archive file to act as a directory\nstructure on a classpath. For the next decade, Java developers struggled with getting\nthe classpath exactly right, as a combination of directories and JAR files. And, of\ncourse, the original intent was broken: now two JAR files could create conflicting\nnames on a classpath, leading to numerous war stories of debugging class loaders.\nMeasuring Modularity\nGiven the importance of modularity to architects, they need tools to understand it. \nFortunately, researchers created a variety of language-agnostic metrics to help archi\u2010\ntects understand modularity. We focus on three key concepts: cohesion, coupling, and\nconnascence.\nCohesion\nCohesion refers to what extent the parts of a module should be contained within the\nsame module. In other words, it is a measure of how related the parts are to one\nanother. Ideally, a cohesive module is one where all the parts should be packaged\ntogether, because breaking them into smaller pieces would require coupling the parts\ntogether via calls between modules to achieve useful results.\nAttempting to divide a cohesive module would only result in increased coupling and\ndecreased readability.\n\u2014Larry Constantine\nComputer scientists have defined a range of cohesion measures, listed here from best\nto worst:\nFunctional cohesion\nEvery part of the module is related to the other, and the module contains every\u2010\nthing essential to function.\nSequential cohesion\nTwo modules interact, where one outputs data that becomes the input for the\nother.\nCommunicational cohesion\nTwo modules form a communication chain, where each operates on information\nand/or contributes to some output. For example, add a record to the database\nand generate an email based on that information.\n40 \n| \nChapter 3: Modularity\n", "page": 60, "type": "text", "section": "Page 60"}
{"text": "Procedural cohesion\nTwo modules must execute code in a particular order.\nTemporal cohesion\nModules are related based on timing dependencies. For example, many systems\nhave a list of seemingly unrelated things that must be initialized at system\nstartup; these different tasks are temporally cohesive.\nLogical cohesion\nThe data within modules is related logically but not functionally. For example,\nconsider a module that converts information from text, serialized objects, or\nstreams. Operations are related, but the functions are quite different. A common\nexample of this type of cohesion exists in virtually every Java project in the form\nof the StringUtils package: a group of static methods that operate on String\nbut are otherwise unrelated.\nCoincidental cohesion\nElements in a module are not related other than being in the same source file;\nthis represents the most negative form of cohesion.\nDespite having seven variants listed, cohesion is a less precise metric than coupling.\nOften, the degree of cohesiveness of a particular module is at the discretion of a par\u2010\nticular architect. For example, consider this module definition:\nCustomer Maintenance\n\u2022 add customer\n\u2022 update customer\n\u2022 get customer\n\u2022 notify customer\n\u2022 get customer orders\n\u2022 cancel customer orders\nShould the last two entries reside in this module or should the developer create two\nseparate modules, such as:\nCustomer Maintenance\n\u2022 add customer\n\u2022 update customer\n\u2022 get customer\n\u2022 notify customer\nMeasuring Modularity \n| \n41\n", "page": 61, "type": "text", "section": "Page 61"}
{"text": "Order Maintenance\n\u2022 get customer orders\n\u2022 cancel customer orders\nWhich is the correct structure? As always, it depends:\n\u2022 Are those the only two operations for Order Maintenance? If so, it may make\nsense to collapse those operations back into Customer Maintenance.\n\u2022 Is Customer Maintenance expected to grow much larger, encouraging developers\nto look for opportunities to extract behavior?\n\u2022 Does Order Maintenance require so much knowledge of Customer information\nthat separating the two modules would require a high degree of coupling to make\nit functional? This relates back to the Larry Constantine quote.\nThese questions represent the kind of trade-off analysis at the heart of the job of a\nsoftware architect.\nSurprisingly, given the subjectiveness of cohesion, computer scientists have developed\na good structural metric to determine cohesion (or, more specifically, the lack of\ncohesion). A well-known set of metrics named the Chidamber and Kemerer Object-\noriented metrics suite was developed by the eponymous authors to measure particu\u2010\nlar aspects of object-oriented software systems. The suite includes many common\ncode metrics, such as cyclomatic complexity (see \u201cCyclomatic Complexity\u201d on page\n79) and several important coupling metrics discussed in \u201cCoupling\u201d on page 44.\nThe Chidamber and Kemerer Lack of Cohesion in Methods (LCOM) metric meas\u2010\nures the structural cohesion of a module, typically a component. The initial version\nappears in Equation 3-1.\nEquation 3-1. LCOM, version 1\nLCOM =\nP \u2212Q , if P > Q\n0,\notherwise\nP increases by one for any method that doesn\u2019t access a particular shared field and Q\ndecreases by one for methods that do share a particular shared field. The authors\nsympathize with those who don\u2019t understand this formulation. Worse, it has gradually\ngotten more elaborate over time. The second variation introduced in 1996 (thus the\nname LCOM96B) appears in Equation 3-2.\n42 \n| \nChapter 3: Modularity\n", "page": 62, "type": "text", "section": "Page 62"}
{"text": "Equation 3-2. LCOM 96b\nLCOM96b = 1\na \u2211\nj = 1\na\nm \u2212\u03bc Aj\nm\nWe wont bother untangling the variables and operators in Equation 3-2 because the\nfollowing written explanation is clearer. Basically, the LCOM metric exposes inciden\u2010\ntal coupling within classes. Here\u2019s a better definition of LCOM:\nLCOM\nThe sum of sets of methods not shared via sharing fields\nConsider a class with private fields a and b. Many of the methods only access a, and\nmany other methods only access b. The sum of the sets of methods not shared via\nsharing fields (a and b) is high; therefore, this class reports a high LCOM score, indi\u2010\ncating that it scores high in lack of cohesion in methods. Consider the three classes\nshown in Figure 3-1.\nFigure 3-1. Illustration of the LCOM metric, where fields are octagons and methods are\nsquares\nIn Figure 3-1, fields appear as single letters and methods appear as blocks. In Class\nX, the LCOM score is low, indicating good structural cohesion. Class Y, however,\nlacks cohesion; each of the field/method pairs in Class Y could appear in its own\nclass without affecting behavior. Class Z shows mixed cohesion, where developers\ncould refactor the last field/method combination into its own class.\nMeasuring Modularity \n| \n43\n", "page": 63, "type": "text", "section": "Page 63"}
{"text": "The LCOM metric is useful to architects who are analyzing code bases in order to\nmove from one architectural style to another. One of the common headaches when\nmoving architectures are shared utility classes. Using the LCOM metric can help\narchitects find classes that are incidentally coupled and should never have been a sin\u2010\ngle class to begin with.\nMany software metrics have serious deficiencies, and LCOM is not immune. All this\nmetric can find is structural lack of cohesion; it has no way to determine logically if\nparticular pieces fit together. This reflects back on our Second Law of Software Archi\u2010\ntecture: prefer why over how.\nCoupling\nFortunately, we have better tools to analyze coupling in code bases, based in part on\ngraph theory: because the method calls and returns form a call graph, analysis based\non mathematics becomes possible. In 1979, Edward Yourdon and Larry Constantine\npublished Structured Design: Fundamentals of a Discipline of Computer Program and\nSystems Design (Prentice-Hall), defining many core concepts, including the metrics\nafferent and efferent coupling. Afferent coupling measures the number of incoming\nconnections to a code artifact (component, class, function, and so on). Efferent cou\u2010\npling measures the outgoing connections to other code artifacts. For virtually every\nplatform tools exist that allow architects to analyze the coupling characteristics of\ncode in order to assist in restructuring, migrating, or understanding a code base.\nWhy Such Similar Names for Coupling Metrics?\nWhy are two critical metrics in the architecture world that represent opposite con\u2010\ncepts named virtually the same thing, differing in only the vowels that sound the most\nalike? These terms originate from Yourdon and Constantine\u2019s Structured Design. Bor\u2010\nrowing concepts from mathematics, they coined the now-common afferent and effer\u2010\nent coupling terms, which should have been called incoming and outgoing coupling.\nHowever, because the original authors leaned toward mathematical symmetry rather\nthan clarity, developers came up with several mnemonics to help out: a appears\nbefore e in the English alphabet, corresponding to incoming being before outgoing, or\nthe observation that the letter e in efferent matches the initial letter in exit, corre\u2010\nsponding to outgoing connections.\nAbstractness, Instability, and Distance from the Main Sequence\nWhile the raw value of component coupling has value to architects, several other\nderived metrics allow a deeper evaluation. These metrics were created by Robert Mar\u2010\ntin for a C++ book, but are widely applicable to other object-oriented languages.\n44 \n| \nChapter 3: Modularity\n", "page": 64, "type": "text", "section": "Page 64"}
{"text": "Abstractness is the ratio of abstract artifacts (abstract classes, interfaces, and so on) to\nconcrete artifacts (implementation). It represents a measure of abstractness versus\nimplementation. For example, consider a code base with no abstractions, just a huge,\nsingle function of code (as in a single main() method). The flip side is a code base\nwith too many abstractions, making it difficult for developers to understand how\nthings wire together (for example, it takes developers a while to figure out what to do\nwith an AbstractSingletonProxyFactoryBean).\nThe formula for abstractness appears in Equation 3-3.\nEquation 3-3. Abstractness\nA = \u2211ma\n\u2211mc\nIn the equation, ma represents abstract elements (interfaces or abstract classes) with\nthe module, and mc represents concrete elements (nonabstract classes). This metric\nlooks for the same criteria. The easiest way to visualize this metric: consider an appli\u2010\ncation with 5,000 lines of code, all in one main() method. The abstractness numera\u2010\ntor is 1, while the denominator is 5,000, yielding an abstractness of almost 0. Thus,\nthis metric measures the ratio of abstractions in your code.\nArchitects calculate abstractness by calculating the ratio of the sum of abstract arti\u2010\nfacts to the sum of the concrete ones.\nAnother derived metric, instability, is defined as the ratio of efferent coupling to the\nsum of both efferent and afferent coupling, shown in Equation 3-4.\nEquation 3-4. Instability\nI =\nCe\nCe + Ca\nIn the equation, ce represents efferent (or outgoing) coupling, and ca represents affer\u2010\nent (or incoming) coupling.\nThe instability metric determines the volatility of a code base. A code base that exhib\u2010\nits high degrees of instability breaks more easily when changed because of high cou\u2010\npling. For example, if a class calls to many other classes to delegate work, the calling\nclass shows high susceptibility to breakage if one or more of the called methods\nchange.\nMeasuring Modularity \n| \n45\n", "page": 65, "type": "text", "section": "Page 65"}
{"text": "Distance from the Main Sequence\nOne of the few holistic metrics architects have for architectural structure is distance\nfrom the main sequence, a derived metric based on instability and abstractness, shown\nin Equation 3-5.\nEquation 3-5. Distance from the main sequence\nD = A + I \u22121\nIn the equation, A = abstractness and I = instability.\nNote that both abstractness and instability are fractions whose results will always fall\nbetween 0 and 1 (except in extreme cases of abstractness that wouldn\u2019t be practical).\nThus, when graphing the relationship, we see the graph in Figure 3-2.\nFigure 3-2. The main sequence defines the ideal relationship between abstractness and\ninstability\nThe distance metric imagines an ideal relationship between abstractness and instabil\u2010\nity; classes that fall near this idealized line exhibit a healthy mixture of these two com\u2010\npeting concerns. For example, graphing a particular class allows developers to\ncalculate the distance from the main sequence metric, illustrated in Figure 3-3.\n46 \n| \nChapter 3: Modularity\n", "page": 66, "type": "text", "section": "Page 66"}
{"text": "Figure 3-3. Normalized distance from the main sequence for a particular class\nIn Figure 3-3, developers graph the candidate class, then measure the distance from\nthe idealized line. The closer to the line, the better balanced the class. Classes that fall\ntoo far into the upper-righthand corner enter into what architects call the zone of use\u2010\nlessness: code that is too abstract becomes difficult to use. Conversely, code that falls\ninto the lower-lefthand corner enter the zone of pain: code with too much implemen\u2010\ntation and not enough abstraction becomes brittle and hard to maintain, illustrated in\nFigure 3-4.\nFigure 3-4. Zones of Uselessness and Pain\nMeasuring Modularity \n| \n47\n", "page": 67, "type": "text", "section": "Page 67"}
{"text": "Tools exist in many platforms to provide these measures, which assist architects when\nanalyzing code bases because of unfamiliarity, migration, or technical debt\nassessment.\nLimitations of Metrics\nWhile the industry has a few code-level metrics that provide valuable insight into\ncode bases, our tools are extremely blunt compared to analysis tools from other engi\u2010\nneering disciplines. Even metrics derived directly from the structure of code require\ninterpretation. For example, cyclomatic complexity (see \u201cCyclomatic Complexity\u201d on\npage 79) measures complexity in code bases but cannot distinguish from essential\ncomplexity (because the underlying problem is complex) or accidental complexity (the\ncode is more complex than it should be). Virtually all code-level metrics require inter\u2010\npretation, but it is still useful to establish baselines for critical metrics such as cyclo\u2010\nmatic complexity so that architects can assess which type they exhibit. We discuss\nsetting up just such tests in \u201cGovernance and Fitness Functions\u201d on page 82.\nNotice that the previously mentioned book by Edward Yourdon and and Larry Con\u2010\nstantine (Structured Design: Fundamentals of a Discipline of Computer Program and\nSystems Design) predates the popularity of object-oriented languages, focusing\ninstead on structured programming constructs, such as functions (not methods). It\nalso defined other types of coupling that we do not cover here because they have been\nsupplanted by connascence.\nConnascence\nIn 1996, Meilir Page-Jones published What Every Programmer Should Know About\nObject-Oriented Design (Dorset House), refining the afferent and efferent coupling\nmetrics and recasting them to object-oriented languages with a concept he named\nconnascence. Here\u2019s how he defined the term:\nTwo components are connascent if a change in one would require the other to be\nmodified in order to maintain the overall correctness of the system.\n\u2014Meilir Page-Jones\nHe developed two types of connascence: static and dynamic.\nStatic connascence\nStatic connascence refers to source-code-level coupling (as opposed to execution-time\ncoupling, covered in \u201cDynamic connascence\u201d on page 50); it is a refinement of the\nafferent and efferent couplings defined by Structured Design. In other words, archi\u2010\ntects view the following types of static connascence as the degree to which something\nis coupled, either afferently or efferently:\n48 \n| \nChapter 3: Modularity\n", "page": 68, "type": "text", "section": "Page 68"}
{"text": "Connascence of Name (CoN)\nMultiple components must agree on the name of an entity.\nNames of methods represents the most common way that code bases are coupled\nand the most desirable, especially in light of modern refactoring tools that make\nsystem-wide name changes trivial.\nConnascence of Type (CoT)\nMultiple components must agree on the type of an entity.\nThis type of connascence refers to the common facility in many statically typed\nlanguages to limit variables and parameters to specific types. However, this capa\u2010\nbility isn\u2019t purely a language feature\u2014some dynamically typed languages offer\nselective typing, notably Clojure and Clojure Spec.\nConnascence of Meaning (CoM) or Connascence of Convention (CoC)\nMultiple components must agree on the meaning of particular values.\nThe most common obvious case for this type of connascence in code bases is\nhard-coded numbers rather than constants. For example, it is common in some\nlanguages to consider defining somewhere int TRUE = 1; int FALSE = 0.\nImagine the problems if someone flips those values.\nConnascence of Position (CoP)\nMultiple components must agree on the order of values.\nThis is an issue with parameter values for method and function calls even in lan\u2010\nguages that feature static typing. For example, if a developer creates a method\nvoid updateSeat(String name, String seatLocation) and calls it with the\nvalues updateSeat(\"14D\", \"Ford, N\"), the semantics aren\u2019t correct even if the\ntypes are.\nConnascence of Algorithm (CoA)\nMultiple components must agree on a particular algorithm.\nA common case for this type of connascence occurs when a developer defines a\nsecurity hashing algorithm that must run on both the server and client and pro\u2010\nduce identical results to authenticate the user. Obviously, this represents a high\nform of coupling\u2014if either algorithm changes any details, the handshake will no\nlonger work.\nMeasuring Modularity \n| \n49\n", "page": 69, "type": "text", "section": "Page 69"}
{"text": "Dynamic connascence\nThe other type of connascence Page-Jones defined was dynamic connascence, which\nanalyzes calls at runtime. The following is a description of the different types of\ndynamic connascence:\nConnascence of Execution (CoE)\nThe order of execution of multiple components is important.\nConsider this code:\nemail = new Email();\nemail.setRecipient(\"foo@example.com\");\nemail.setSender(\"me@me.com\");\nemail.send();\nemail.setSubject(\"whoops\");\nIt won\u2019t work correctly because certain properties must be set in order.\nConnascence of Timing (CoT)\nThe timing of the execution of multiple components is important.\nThe common case for this type of connascence is a race condition caused by two\nthreads executing at the same time, affecting the outcome of the joint operation.\nConnascence of Values (CoV)\nOccurs when several values relate on one another and must change together.\nConsider the case where a developer has defined a rectangle as four points, repre\u2010\nsenting the corners. To maintain the integrity of the data structure, the developer\ncannot randomly change one of points without considering the impact on the\nother points.\nThe more common and problematic case involves transactions, especially in dis\u2010\ntributed systems. When an architect designs a system with separate databases, yet\nneeds to update a single value across all of the databases, all the values must\nchange together or not at all.\nConnascence of Identity (CoI)\nOccurs when multiple components must reference the same entity.\nThe common example of this type of connascence involves two independent compo\u2010\nnents that must share and update a common data structure, such as a distributed\nqueue.\nArchitects have a harder time determining dynamic connascence because we lack\ntools to analyze runtime calls as effectively as we can analyze the call graph.\n50 \n| \nChapter 3: Modularity\n", "page": 70, "type": "text", "section": "Page 70"}
{"text": "Connascence properties\nConnascence is an analysis tool for architect and developers, and some properties of\nconnascence help developers use it wisely. The following is a description of each of\nthese connascence properties:\nStrength\nArchitects determine the strength of connascence by the ease with which a devel\u2010\noper can refactor that type of coupling; different types of connascence are\ndemonstrably more desirable, as shown in Figure 3-5. Architects and developers\ncan improve the coupling characteristics of their code base by refactoring toward\nbetter types of connascence.\nArchitects should prefer static connascence to dynamic because developers can\ndetermine it by simple source code analysis, and modern tools make it trivial to\nimprove static connascence. For example, consider the case of connascence of\nmeaning, which developers can improve by refactoring to connascence of name by\ncreating a named constant rather than a magic value.\nFigure 3-5. The strength on connascence provides a good refactoring guide\nLocality\nThe locality of connascence measures how proximal the modules are to each\nother in the code base. Proximal code (in the same module) typically has more\nand higher forms of connascence than more separated code (in separate modules\nor code bases). In other words, forms of connascence that indicate poor coupling\nMeasuring Modularity \n| \n51\n", "page": 71, "type": "text", "section": "Page 71"}
{"text": "when far apart are fine when closer together. For example, if two classes in the\nsame component have connascence of meaning, it is less damaging to the code\nbase than if two components have the same form of connascence.\nDevelopers must consider strength and locality together. Stronger forms of con\u2010\nnascence found within the same module represent less code smell than the same\nconnascence spread apart.\nDegree\nThe degree of connascence relates to the size of its impact\u2014does it impact a few\nclasses or many? Lesser degrees of connascence damage code bases less. In other\nwords, having high dynamic connascence isn\u2019t terrible if you only have a few\nmodules. However, code bases tend to grow, making a small problem corre\u2010\nspondingly bigger.\nPage-Jones offers three guidelines for using connascence to improve systems\nmodularity:\n1. Minimize overall connascence by breaking the system into encapsulated elements\n2. Minimize any remaining connascence that crosses encapsulation boundaries\n3. Maximize the connascence within encapsulation boundaries\nThe legendary software architecture innovator Jim Weirich repopularized the concept\nof connascence and offers two great pieces of advice:\nRule of Degree: convert strong forms of connascence into weaker forms of\nconnascence\nRule of Locality: as the distance between software elements increases, use weaker forms\nof connascence\nUnifying Coupling and Connascence Metrics\nSo far, we\u2019ve discussed both coupling and connascence, measures from different eras\nand with different targets. However, from an architect\u2019s point of view, these two views\noverlap. What Page-Jones identifies as static connascence represents degrees of either\nincoming or outgoing coupling. Structured programming only cares about in or out,\nwhereas connascence cares about how things are coupled together.\nTo help visualize the overlap in concepts, consider Figure 3-6. The structured pro\u2010\ngramming coupling concepts appear on the left, while the connascence characteristics\nappear on the right. What structured programming called data coupling (method\ncalls), connascence provides advice for how that coupling should manifest. Struc\u2010\ntured programming didn\u2019t really address the areas covered by dynamic connascence;\nwe encapsulate that concept shortly in \u201cArchitectural Quanta and Granularity\u201d on\npage 92.\n52 \n| \nChapter 3: Modularity\n", "page": 72, "type": "text", "section": "Page 72"}
{"text": "Figure 3-6. Unifying coupling and connascence\nThe problems with 1990s connascence\nSeveral problems exist for architects when applying these useful metrics for analyzing\nand designing systems. First, these measures look at details at a low level of code,\nfocusing on code quality and hygiene than necessarily architectural structure. Archi\u2010\ntects tend to care more about how modules are coupled rather than the degree of cou\u2010\npling. For example, an architect cares about synchronous versus asynchronous\ncommunication, and doesn\u2019t care so much about how that\u2019s implemented.\nThe second problem with connascence lies with the fact that it doesn\u2019t really address a\nfundamental decision that many modern architects must make\u2014synchronous or\nasynchronous communication in distributed architectures like microservices? Refer\u2010\nring back to the First Law of Software Architecture, everything is a trade-off. After we\ndiscuss the scope of architecture characteristics in Chapter 7, we\u2019ll introduce new\nways to think about modern connascence.\nFrom Modules to Components\nWe use the term module throughout as a generic name for a bundling of related code.\nHowever, most platforms support some form of component, one of the key building\nblocks for software architects. The concept and corresponding analysis of the logical\nor physical separation has existed since the earliest days of computer science. Yet,\nwith all the writing and thinking about components and separation, developers and\narchitects still struggle with achieving good outcomes.\nWe\u2019ll discuss deriving components from problem domains in Chapter 8, but we must\nfirst discuss another fundamental aspect of software architecture: architecture charac\u2010\nteristics and their scope.\nFrom Modules to Components \n| \n53\n", "page": 73, "type": "text", "section": "Page 73"}
{"text": "CHAPTER 4\nArchitecture Characteristics Defined\nA company decides to solve a particular problem using software, so it gathers a list of\nrequirements for that system. A wide variety of techniques exist for the exercise of\nrequirements gathering, generally defined by the software development process used\nby the team. But the architect must consider many other factors in designing a soft\u2010\nware solution, as illustrated in Figure 4-1.\nFigure 4-1. A software solution consists of both domain requirements and architectural\ncharacteristics\nArchitects may collaborate on defining the domain or business requirements, but one\nkey responsibility entails defining, discovering, and otherwise analyzing all the things\nthe software must do that isn\u2019t directly related to the domain functionality: architec\u2010\ntural characteristics.\nWhat distinguishes software architecture from coding and design? Many things,\nincluding the role that architects have in defining architectural characteristics, the\nimportant aspects of the system independent of the problem domain. Many organiza\u2010\ntions describe these features of software with a variety of terms, including nonfunc\u2010\ntional requirements, but we dislike that term because it is self-denigrating. Architects\ncreated that term to distinguish architecture characteristics from functional require\u2010\nments, but naming something nonfunctional has a negative impact from a language\nstandpoint: how can teams be convinced to pay enough attention to something \u201cnon\u2010\nfunctional\u201d? Another popular term is quality attributes, which we dislike because it\n55\n", "page": 75, "type": "text", "section": "Page 75"}
{"text": "implies after-the-fact quality assessment rather than design. We prefer architecture\ncharacteristics because it describes concerns critical to the success of the architecture,\nand therefore the system as a whole, without discounting its importance.\nAn architecture characteristic meets three criteria:\n\u2022 Specifies a nondomain design consideration\n\u2022 Influences some structural aspect of the design\n\u2022 Is critical or important to application success\nThese interlocking parts of our definition are illustrated in Figure 4-2.\nFigure 4-2. The differentiating features of architecture characteristics\nThe definition illustrated in Figure 4-2 consists of the three components listed, in\naddition to a few modifiers:\nSpecifies a nondomain design consideration\nWhen designing an application, the requirements specify what the application\nshould do; architecture characteristics specify operational and design criteria for\nsuccess, concerning how to implement the requirements and why certain choices\nwere made. For example, a common important architecture characteristic speci\u2010\nfies a certain level of performance for the application, which often doesn\u2019t appear\nin a requirements document. Even more pertinent: no requirements document\nstates \u201cprevent technical debt,\u201d but it is a common design consideration for archi\u2010\ntects and developers. We cover this distinction between explicit and implicit\ncharacteristics in depth in \u201cExtracting Architecture Characteristics from Domain\nConcerns\u201d on page 65.\n56 \n| \nChapter 4: Architecture Characteristics Defined\n", "page": 76, "type": "text", "section": "Page 76"}
{"text": "Influences some structural aspect of the design\nThe primary reason architects try to describe architecture characteristics on\nprojects concerns design considerations: does this architecture characteristic\nrequire special structural consideration to succeed? For example, security is a\nconcern in virtually every project, and all systems must take a baseline of precau\u2010\ntions during design and coding. However, it rises to the level of architecture char\u2010\nacteristic when the architect needs to design something special. Consider two\ncases surrounding payment in a example system:\nThird-party payment processor\nIf an integration point handles payment details, then the architecture\nshouldn\u2019t require special structural considerations. The design should incor\u2010\nporate standard security hygiene, such as encryption and hashing, but\ndoesn\u2019t require special structure.\nIn-application payment processing\nIf the application under design must handle payment processing, the archi\u2010\ntect may design a specific module, component, or service for that purpose to\nisolate the critical security concerns structurally. Now, the architecture char\u2010\nacteristic has an impact on both architecture and design.\nOf course, even these two criteria aren\u2019t sufficient in many cases to make this\ndetermination: past security incidents, the nature of the integration with the third\nparty, and a host of other criteria may be present during this decision. Still, it\nshows some of the considerations architects must make when determining how\nto design for certain capabilities.\nCritical or important to application success\nApplications could support a huge number of architecture characteristics\u2026but\nshouldn\u2019t. Support for each architecture characteristic adds complexity to the\ndesign. Thus, a critical job for architects lies in choosing the fewest architecture\ncharacteristics rather than the most possible.\nWe further subdivide architecture characteristics into implicit versus explicit archi\u2010\ntecture characteristics. Implicit ones rarely appear in requirements, yet they\u2019re neces\u2010\nsary for project success. For example, availability, reliability, and security underpin\nvirtually all applications, yet they\u2019re rarely specified in design documents. Architects\nmust use their knowledge of the problem domain to uncover these architecture char\u2010\nacteristics during the analysis phase. For example, a high-frequency trading firm may\nnot have to specify low latency in every system, yet the architects in that problem\ndomain know how critical it is. Explicit architecture characteristics appear in require\u2010\nments documents or other specific instructions.\nIn Figure 4-2, the choice of a triangle is intentional: each of the definition elements\nsupports the others, which in turn support the overall design of the system. The ful\u2010\nArchitecture Characteristics Defined \n| \n57\n", "page": 77, "type": "text", "section": "Page 77"}
{"text": "crum created by the triangle illustrates the fact that these architecture characteristics\noften interact with one another, leading to the pervasive use among architects of the\nterm trade-off.\nArchitectural Characteristics (Partially) Listed\nArchitecture characteristics exist along a broad spectrum of the software system,\nranging from low-level code characteristics, such as modularity, to sophisticated\noperational concerns, such as scalability and elasticity. No true universal standard\nexists despite attempts to codify ones in the past. Instead, each organization creates\nits own interpretation of these terms. Additionally, because the software ecosystem\nchanges so fast, new concepts, terms, measures, and verifications constantly appear,\nproviding new opportunities for architecture characteristics definitions.\nDespite the volume and scale, architects commonly separate architecture characteris\u2010\ntics into broad categories. The following sections describe a few, along with some\nexamples.\nOperational Architecture Characteristics\nOperational architecture characteristics cover capabilities such as performance, scala\u2010\nbility, elasticity, availability, and reliability. Table 4-1 lists some operational architec\u2010\nture characteristics.\nTable 4-1. Common operational architecture characteristics\nTerm\nDefinition\nAvailability\nHow long the system will need to be available (if 24/7, steps need to be in place to allow the system to be\nup and running quickly in case of any failure).\nContinuity\nDisaster recovery capability.\nPerformance\nIncludes stress testing, peak analysis, analysis of the frequency of functions used, capacity required, and\nresponse times. Performance acceptance sometimes requires an exercise of its own, taking months to\ncomplete.\nRecoverability\nBusiness continuity requirements (e.g., in case of a disaster, how quickly is the system required to be on-\nline again?). This will affect the backup strategy and requirements for duplicated hardware.\nReliability/\nsafety\nAssess if the system needs to be fail-safe, or if it is mission critical in a way that affects lives. If it fails, will\nit cost the company large sums of money?\nRobustness\nAbility to handle error and boundary conditions while running if the internet connection goes down or if\nthere\u2019s a power outage or hardware failure.\nScalability\nAbility for the system to perform and operate as the number of users or requests increases.\nOperational architecture characteristics heavily overlap with operations and DevOps\nconcerns, forming the intersection of those concerns in many software projects.\n58 \n| \nChapter 4: Architecture Characteristics Defined\n", "page": 78, "type": "text", "section": "Page 78"}
{"text": "Structural Architecture Characteristics\nArchitects must concern themselves with code structure. In many cases, the architect\nhas sole or shared responsibility for code quality concerns, such as good modularity,\ncontrolled coupling between components, readable code, and a host of other internal\nquality assessments. Table 4-2 lists a few structural architecture characteristics.\nTable 4-2. Structural architecture characteristics\nTerm\nDefinition\nConfigurability\nAbility for the end users to easily change aspects of the software\u2019s configuration (through usable\ninterfaces).\nExtensibility\nHow important it is to plug new pieces of functionality in.\nInstallability\nEase of system installation on all necessary platforms.\nLeverageability/\nreuse\nAbility to leverage common components across multiple products.\nLocalization\nSupport for multiple languages on entry/query screens in data fields; on reports, multibyte character\nrequirements and units of measure or currencies.\nMaintainability\nHow easy it is to apply changes and enhance the system?\nPortability\nDoes the system need to run on more than one platform? (For example, does the frontend need to run\nagainst Oracle as well as SAP DB?\nSupportability\nWhat level of technical support is needed by the application? What level of logging and other facilities\nare required to debug errors in the system?\nUpgradeability\nAbility to easily/quickly upgrade from a previous version of this application/solution to a newer version\non servers and clients.\nCross-Cutting Architecture Characteristics\nWhile many architecture characteristics fall into easily recognizable categories, many\nfall outside or defy categorization yet form important design constraints and consid\u2010\nerations. Table 4-3 describes a few of these.\nTable 4-3. Cross-cutting architecture characteristics\nTerm\nDefinition\nAccessibility\nAccess to all your users, including those with disabilities like colorblindness or hearing loss.\nArchivability\nWill the data need to be archived or deleted after a period of time? (For example, customer accounts are\nto be deleted after three months or marked as obsolete and archived to a secondary database for future\naccess.)\nAuthentication\nSecurity requirements to ensure users are who they say they are.\nAuthorization\nSecurity requirements to ensure users can access only certain functions within the application (by use case,\nsubsystem, webpage, business rule, field level, etc.).\nLegal\nWhat legislative constraints is the system operating in (data protection, Sarbanes Oxley, GDPR, etc.)? What\nreservation rights does the company require? Any regulations regarding the way the application is to be\nbuilt or deployed?\nArchitectural Characteristics (Partially) Listed \n| \n59\n", "page": 79, "type": "text", "section": "Page 79"}
{"text": "Term\nDefinition\nPrivacy\nAbility to hide transactions from internal company employees (encrypted transactions so even DBAs and\nnetwork architects cannot see them).\nSecurity\nDoes the data need to be encrypted in the database? Encrypted for network communication between\ninternal systems? What type of authentication needs to be in place for remote user access?\nSupportability\nWhat level of technical support is needed by the application? What level of logging and other facilities are\nrequired to debug errors in the system?\nUsability/\nachievability\nLevel of training required for users to achieve their goals with the application/solution. Usability\nrequirements need to be treated as seriously as any other architectural issue.\nAny list of architecture characteristics will necessarily be an incomplete list; any soft\u2010\nware may invent important architectural characteristics based on unique factors (see\n\u201cItaly-ility\u201d on page 60 for an example).\nItaly-ility\nOne of Neal\u2019s colleagues recounts a story about the unique nature of architectural\ncharacteristics. She worked for a client whose mandate required a centralized archi\u2010\ntecture. Yet, for each proposed design, the first question from the client was \u201cBut what\nhappens if we lose Italy?\u201d Years ago, because of a freak communication outage, the\nhead office had lost communication with the Italian branches, and it was organiza\u2010\ntionally traumatic. Thus, a firm requirement of all future architectures insisted upon\nwhat the team eventually called Italy-ility, which they all knew meant a unique combi\u2010\nnation of availability, recoverability, and resilience.\nAdditionally, many of the preceding terms are imprecise and ambiguous, sometimes\nbecause of subtle nuance or the lack of objective definitions. For example, interopera\u2010\nbility and compatibility may appear equivalent, which will be true for some systems.\nHowever, they differ because interoperability implies ease of integration with other\nsystems, which in turn implies published, documented APIs. Compatibility, on the\nother hand, is more concerned with industry and domain standards. Another exam\u2010\nple is learnability. One definition is how easy it is for users to learn to use the soft\u2010\nware, and another definition is the level at which the system can automatically learn\nabout its environment in order to become self-configuring or self-optimizing using\nmachine learning algorithms.\nMany of the definitions overlap. For example, consider availability and reliability,\nwhich seem to overlap in almost all cases. Yet consider the internet protocol UDP,\nwhich underlies TCP. UDP is available over IP but not reliable: the packets may arrive\nout of order, and the receiver may have to ask for missing packets again.\nNo complete list of standards exists. The International Organization for Standards\n(ISO) publishes a list organized by capabilities, overlapping many of the ones we\u2019ve\n60 \n| \nChapter 4: Architecture Characteristics Defined\n", "page": 80, "type": "text", "section": "Page 80"}
{"text": "listed, but mainly establishing an incomplete category list. The following are some of\nthe ISO definitions:\nPerformance efficiency\nMeasure of the performance relative to the amount of resources used under\nknown conditions. This includes time behavior (measure of response, processing\ntimes, and/or throughput rates), resource utilization (amounts and types of\nresources used), and capacity (degree to which the maximum established limits\nare exceeded).\nCompatibility\nDegree to which a product, system, or component can exchange information\nwith other products, systems, or components and/or perform its required func\u2010\ntions while sharing the same hardware or software environment. It includes coex\u2010\nistence (can perform its required functions efficiently while sharing a common\nenvironment and resources with other products) and interoperability (degree to\nwhich two or more systems can exchange and utilize information).\nUsability\nUsers can use the system effectively, efficiently, and satisfactorily for its intended\npurpose. It includes appropriateness recognizability (users can recognize whether\nthe software is appropriate for their needs), learnability (how easy users can learn\nhow to use the software), user error protection (protection against users making\nerrors), and accessibility (make the software available to people with the widest\nrange of characteristics and capabilities).\nReliability\nDegree to which a system functions under specified conditions for a specified\nperiod of time. This characteristic includes subcategories such as maturity (does\nthe software meet the reliability needs under normal operation), availability\n(software is operational and accessible), fault tolerance (does the software operate\nas intended despite hardware or software faults), and recoverability (can the soft\u2010\nware recover from failure by recovering any affected data and reestablish the\ndesired state of the system.\nSecurity\nDegree the software protects information and data so that people or other prod\u2010\nucts or systems have the degree of data access appropriate to their types and lev\u2010\nels of authorization. This family of characteristics includes confidentiality (data is\naccessible only to those authorized to have access), integrity (the software pre\u2010\nvents unauthorized access to or modification of software or data), nonrepudia\u2010\ntion, (can actions or events be proven to have taken place), accountability (can\nuser actions of a user be traced), and authenticity (proving the identity of a user).\nArchitectural Characteristics (Partially) Listed \n| \n61\n", "page": 81, "type": "text", "section": "Page 81"}
{"text": "Maintainability\nRepresents the degree of effectiveness and efficiency to which developers can\nmodify the software to improve it, correct it, or adapt it to changes in environ\u2010\nment and/or requirements. This characteristic includes modularity (degree to\nwhich the software is composed of discrete components), reusability (degree to\nwhich developers can use an asset in more than one system or in building other\nassets), analyzability (how easily developers can gather concrete metrics about\nthe software), modifiability (degree to which developers can modify the software\nwithout introducing defects or degrading existing product quality), and testability\n(how easily developers and others can test the software).\nPortability\nDegree to which developers can transfer a system, product, or component from\none hardware, software, or other operational or usage environment to another.\nThis characteristic includes the subcharacteristics of adaptability (can developers\neffectively and efficiently adapt the software for different or evolving hardware,\nsoftware, or other operational or usage environments), installability (can the soft\u2010\nware be installed and/or uninstalled in a specified environment), and replaceabil\u2010\nity (how easily developers can replace the functionality with other software).\nThe last item in the ISO list addresses the functional aspects of software, which we do\nnot believe belongs in this list:\nFunctional suitability\nThis characteristic represents the degree to which a product or system provides\nfunctions that meet stated and implied needs when used under specified condi\u2010\ntions. This characteristic is composed of the following subcharacteristics:\nFunctional completeness\nDegree to which the set of functions covers all the specified tasks and user\nobjectives.\nFunctional correctness\nDegree to which a product or system provides the correct results with the\nneeded degree of precision.\nFunctional appropriateness\nDegree to which the functions facilitate the accomplishment of specified\ntasks and objectives. These are not architecture characteristics but rather the\nmotivational requirements to build the software. This illustrates how think\u2010\ning about the relationship between architecture characteristics and the prob\u2010\nlem domain has evolved. We cover this evolution in Chapter 7.\n62 \n| \nChapter 4: Architecture Characteristics Defined\n", "page": 82, "type": "text", "section": "Page 82"}
{"text": "The Many Ambiguities in Software Architecture\nA consistent frustration amongst architects is the lack of clear definitions of so many\ncritical things, including the activity of software architecture itself! This leads compa\u2010\nnies to define their own terms for common things, which leads to industry-wide con\u2010\nfusion because architects either use opaque terms or, worse yet, use the same terms\nfor wildly different meanings. As much as we\u2019d like, we can\u2019t impose a standard\nnomenclature on the software development world. However, we do follow and rec\u2010\nommend the advice from domain-driven design to establish and use a ubiquitous lan\u2010\nguage amongst fellow employees to help ensure fewer term-based misunderstandings.\nTrade-Offs and Least Worst Architecture\nApplications can only support a few of the architecture characteristics we\u2019ve listed for\na variety of reasons. First, each of the supported characteristics requires design effort\nand perhaps structural support. Second, the bigger problem lies with the fact that\neach architecture characteristic often has an impact on others. For example, if an\narchitect wants to improve security, it will almost certainly negatively impact perfor\u2010\nmance: the application must do more on-the-fly encryption, indirection for secrets\nhiding, and other activities that potentially degrade performance.\nA metaphor will help illustrate this interconnectivity. Apparently, pilots often struggle\nlearning to fly helicopters because it requires a control for each hand and each foot,\nand changing one impacts the others. Thus, flying a helicopter is a balancing exercise,\nwhich nicely describes the trade-off process when choosing architecture characteris\u2010\ntics. Each architecture characteristic that an architect designs support for potentially\ncomplicates the overall design.\nThus, architects rarely encounter the situation where they are able to design a system\nand maximize every single architecture characteristic. More often, the decisions come\ndown to trade-offs between several competing concerns.\nNever shoot for the best architecture, but rather the least worst\narchitecture.\nToo many architecture characteristics leads to generic solutions that are trying to\nsolve every business problem, and those architectures rarely work because the design\nbecomes unwieldy.\nThis suggests that architects should strive to design architecture to be as iterative as\npossible. If you can make changes to the architecture more easily, you can stress less\nTrade-Offs and Least Worst Architecture \n| \n63\n", "page": 83, "type": "text", "section": "Page 83"}
{"text": "about discovering the exact correct thing in the first attempt. One of the most impor\u2010\ntant lessons of Agile software development is the value of iteration; this holds true at\nall levels of software development, including architecture.\n64 \n| \nChapter 4: Architecture Characteristics Defined\n", "page": 84, "type": "text", "section": "Page 84"}
{"text": "CHAPTER 5\nIdentifying Architectural Characteristics\nIdentifying the driving architectural characteristics is one of the first steps in creating\nan architecture or determining the validity of an existing architecture. Identifying the\ncorrect architectural characteristics (\u201c-ilities\u201d) for a given problem or application\nrequires an architect to not only understand the domain problem, but also collabo\u2010\nrate with the problem domain stakeholders to determine what is truly important\nfrom a domain perspective.\nAn architect uncovers architecture characteristics in at least three ways by extracting\nfrom domain concerns, requirements, and implicit domain knowledge. We previ\u2010\nously discussed implicit characteristics and we cover the other two here.\nExtracting Architecture Characteristics from Domain\nConcerns\nAn architect must be able to translate domain concerns to identify the right architec\u2010\ntural characteristics. For example, is scalability the most important concern, or is it\nfault tolerance, security, or performance? Perhaps the system requires all four charac\u2010\nteristics combined. Understanding the key domain goals and domain situation allows\nan architect to translate those domain concerns to \u201c-ilities,\u201d which then forms the\nbasis for correct and justifiable architecture decisions.\nOne tip when collaborating with domain stakeholders to define the driving architec\u2010\nture characteristics is to work hard to keep the final list as short as possible. A com\u2010\nmon anti-pattern in architecture entails trying to design a generic architecture, one\nthat supports all the architecture characteristics. Each architecture characteristic the\narchitecture supports complicates the overall system design; supporting too many\narchitecture characteristics leads to greater and greater complexity before the archi\u2010\ntect and developers have even started addressing the problem domain, the original\n65\n", "page": 85, "type": "text", "section": "Page 85"}
{"text": "motivation for writing the software. Don\u2019t obsess over the number of charateristics,\nbut rather the motivation to keep design simple.\nCase Study: The Vasa\nThe original story of over-specifying architecture characteristics and ultimately kill\u2010\ning a project must be the Vasa. It was a Swedish warship built between 1626 and 1628\nby a king who wanted the most magnificent ship ever created. Up until that time,\nships were either troop transports or gunships\u2014the Vasa would be both! Most ships\nhad one deck\u2014the Vasa had two! All the cannons were twice the size of those on sim\u2010\nilar ships. Despite some trepidation by the expert ship builders (who ultimately\ncouldn\u2019t say no to King Adolphus), the shipbuilders finished the construction. In cele\u2010\nbration, the ship sailed out into the harbor and shot a cannon salute off one side.\nUnfortunately, because the ship was top-heavy, it capsized and sank to the bottom of\nthe bay in Sweden. In the early 20th century, salvagers rescued the ship, which now\nresides in a museum in Stockholm.\nMany architects and domain stakeholders want to prioritize the final list of architec\u2010\nture characteristics that the application or system must support. While this is cer\u2010\ntainly desirable, in most cases it is a fool\u2019s errand and will not only waste time, but\nalso produce a lot of unnecessary frustration and disagreement with the key stake\u2010\nholders. Rarely will all stakeholders agree on the priority of each and every character\u2010\nistic. A better approach is to have the domain stakeholders select the top three most\nimportant characteristics from the final list (in any order). Not only is this much eas\u2010\nier to gain consensus on, but it also fosters discussions about what is most important\nand helps the architect analyze trade-offs when making vital architecture decisions.\nMost architecture characteristics come from listening to key domain stakeholders\nand collaborating with them to determine what is important from a domain perspec\u2010\ntive. While this may seem like a straightforward activity, the problem is that architects\nand domain stakeholders speak different languages. Architects talk about scalability,\ninteroperability, fault tolerance, learnability, and availability. Domain stakeholders\ntalk about mergers and acquisitions, user satisfaction, time to market, and competi\u2010\ntive advantage. What happens is a \u201clost in translation\u201d problem where the architect\nand domain stakeholder don\u2019t understand each other. Architects have no idea how to\ncreate an architecture to support user satisfaction, and domain stakeholders don\u2019t\nunderstand why there is so much focus and talk about availability, interoperability,\nlearnability, and fault tolerance in the application. Fortunately, there is usually a\ntranslation from domain concerns to architecture characteristics. Table 5-1 shows\nsome of the more common domain concerns and the corresponding \u201c-ilities\u201d that\nsupport them.\n66 \n| \nChapter 5: Identifying Architectural Characteristics\n", "page": 86, "type": "text", "section": "Page 86"}
{"text": "Table 5-1. Translation of domain concerns to architecture characteristics\nDomain concern\nArchitecture characteristics\nMergers and acquisitions Interoperability, scalability, adaptability, extensibility\nTime to market\nAgility, testability, deployability\nUser satisfaction\nPerformance, availability, fault tolerance, testability, deployability, agility, security\nCompetitive advantage\nAgility, testability, deployability, scalability, availability, fault tolerance\nTime and budget\nSimplicity, feasibility\nOne important thing to note is that agility does not equal time to market. Rather, it is\nagility + testability + deployability. This is a trap many architects fall into when trans\u2010\nlating domain concerns. Focusing on only one of the ingredients is like forgetting to\nput the flour in the cake batter. For example, a domain stakeholder might say some\u2010\nthing like \u201cDue to regulatory requirements, it is absolutely imperative that we com\u2010\nplete end-of-day fund pricing on time.\u201d An ineffective architect might just focus on\nperformance because that seems to be the primary focus of that domain concern.\nHowever, that architect will fail for many reasons. First, it doesn\u2019t matter how fast the\nsystem is if it isn\u2019t available when needed. Second, as the domain grows and more\nfunds are created, the system must be able to also scale to finish end-of-day process\u2010\ning in time. Third, the system must not only be available, but must also be reliable so\nthat it doesn\u2019t crash as end-of-day fund prices are being calculated. Forth, what hap\u2010\npens if the end-of-day fund pricing is about 85% complete and the system crashes? It\nmust be able to recover and restart where the pricing left off. Finally, the system may\nbe fast, but are the fund prices being calculated correctly? So, in addition to perfor\u2010\nmance, the architect must also equally place a focus on availability, scalability, reliabil\u2010\nity, recoverability, and auditability.\nExtracting Architecture Characteristics from\nRequirements\nSome architecture characteristics come from explicit statements in requirements\ndocuments. For example, explicit expected numbers of users and scale commonly\nappear in domain or domain concerns. Others come from inherent domain knowl\u2010\nedge by architects, one of the many reasons that domain knowledge is always benefi\u2010\ncial for architects. For example, suppose an architect designs an application that\nhandles class registration for university students. To make the math easy, assume that\nthe school has 1,000 students and 10 hours for registration. Should an architect\ndesign a system assuming consistent scale, making the implicit assumption that the\nstudents during the registration process will distribute themselves evenly over time?\nOr, based on knowledge of university students habits and proclivities, should the\narchitect design a system that can handle all 1,000 students attempting to register in\nthe last 10 minutes? Anyone who understands how much students stereotypically\nExtracting Architecture Characteristics from Requirements \n| \n67\n", "page": 87, "type": "text", "section": "Page 87"}
{"text": "procrastinate knows the answer to this question! Rarely will details like this appear in\nrequirements documents, yet they do inform the design decisions.\nThe Origin of Architecture Katas\nA few years ago, Ted Neward, a well-known architect, devised architecture katas, a\nclever method to allow nascent architects a way to practice deriving architecture char\u2010\nacteristics from domain-targeted descriptions. From Japan and martial arts, a kata is\nan individual training exercise, where the emphasis lies on proper form and\ntechnique.\nHow do we get great designers? Great designers design, of course.\n\u2014Fred Brooks\nSo how are we supposed to get great architects if they only get the chance to architect\nfewer than a half dozen times in their career?\nTo provide a curriculum for aspiring architects, Ted created the first architecture\nkatas site, which your authors Neal and Mark adapted and updated. The basic prem\u2010\nise of the kata exercise provides architects with a problem stated in domain terms and\nadditional context (things that might not appear in requirements yet impact design).\nSmall teams work for 45 minutes on a design, then show results to the other groups,\nwho vote on who came up with the best architecture. True to its original purpose,\narchitecture katas provide a useful laboratory for aspiring architects.\nEach kata has predefined sections:\nDescription\nThe overall domain problem the system is trying to solve\nUsers\nThe expected number and/or types of users of the system\nRequirements\nDomain/domain-level requirements, as an architect might expect from domain\nusers/domain experts\nNeal updated the format a few years later on his blog to add the additional context\nsection to each kata with important additional considerations, making the exercises\nmore realistic.\nAdditional context\nMany of the considerations an architect must make aren\u2019t explicitly expressed in\nrequirements but rather by implicit knowledge of the problem domain\nWe encourage burgeoning architects to use the site to do their own kata exercise.\nAnyone can host a brown-bag lunch where a team of aspiring architects can solve a\nproblem and get an experienced architect to evaluate the design and trade-off\n68 \n| \nChapter 5: Identifying Architectural Characteristics\n", "page": 88, "type": "text", "section": "Page 88"}
{"text": "analysis, either on the spot or from a short analysis after the fact. The design won\u2019t be\nelaborate because the exercise is timeboxed. Team members ideally get feedback from\nthe experienced architecture about missed trade-offs and alternative designs.\nCase Study: Silicon Sandwiches\nTo illustrate several concepts, we use an architecture kata (see \u201cThe Origin of Archi\u2010\ntecture Katas\u201d on page 68 for the origin of the concept). To show how architects\nderive architecture characteristics from requirements, we introduce the Silicon Sand\u2010\nwiches kata.\nDescription\nA national sandwich shop wants to enable online ordering (in addition to its cur\u2010\nrent call-in service).\nUsers\nThousands, perhaps one day millions\nRequirements\n\u2022 Users will place their order, then be given a time to pick up their sandwich and\ndirections to the shop (which must integrate with several external mapping serv\u2010\nices that include traffic information)\n\u2022 If the shop offers a delivery service, dispatch the driver with the sandwich to the\nuser\n\u2022 Mobile-device accessibility\n\u2022 Offer national daily promotions/specials\n\u2022 Offer local daily promotions/specials\n\u2022 Accept payment online, in person, or upon delivery\nAdditional context\n\u2022 Sandwich shops are franchised, each with a different owner\n\u2022 Parent company has near-future plans to expand overseas\n\u2022 Corporate goal is to hire inexpensive labor to maximize profit\nGiven this scenario, how would an architect derive architecture characteristics? Each\npart of the requirement might contribute to one or more aspects of architecture (and\nmany will not). The architect doesn\u2019t design the entire system here\u2014considerable\neffort must still go into crafting code to solve the domain statement. Instead, the\narchitect looks for things that influence or impact the design, particularly structural.\nFirst, separate the candidate architecture characteristics into explicit and implicit\ncharacteristics.\nCase Study: Silicon Sandwiches \n| \n69\n", "page": 89, "type": "text", "section": "Page 89"}
{"text": "Explicit Characteristics\nExplicit architecture characteristics appear in a requirements specification as part of\nthe necessary design. For example, a shopping website may aspire to support a partic\u2010\nular number of concurrent users, which domain analysts specify in the requirements.\nAn architect should consider each part of the requirements to see if it contributes to\nan architecture characteristic. But first, an architect should consider domain-level\npredictions about expected metrics, as represented in the Users section of the kata.\nOne of the first details that should catch an architect\u2019s eye is the number of users: cur\u2010\nrently thousands, perhaps one day millions (this is a very ambitious sandwich shop!).\nThus, scalability\u2014the ability to handle a large number of concurrent users without\nserious performance degradation\u2014is one of the top architecture characteristics.\nNotice that the problem statement didn\u2019t explicitly ask for scalability, but rather\nexpressed that requirement as an expected number of users. Architects must often\ndecode domain language into engineering equivalents.\nHowever, we also probably need elasticity\u2014the ability to handle bursts of requests.\nThese two characteristics often appear lumped together, but they have different con\u2010\nstraints. Scalability looks like the graph shown in Figure 5-1.\nFigure 5-1. Scalability measures the performance of concurrent users\nElasticity, on the other hand, measures bursts of traffic, as shown in Figure 5-2.\n70 \n| \nChapter 5: Identifying Architectural Characteristics\n", "page": 90, "type": "text", "section": "Page 90"}
{"text": "Figure 5-2. Elastic systems must withstand bursts of users\nSome systems are scalable but not elastic. For example, consider a hotel reservation\nsystem. Absent special sales or events, the number of users is probably consistent. In\ncontrast, consider a concert ticket booking system. As new tickets go on sale, fervent\nfans will flood the site, requiring high degrees of elasticity. Often, elastic systems also\nneed scalability: the ability to handle bursts and high numbers of concurrent users.\nThe requirement for elasticity did not appear in the Silicon Sandwiches requirements,\nyet the architect should identify this as an important consideration. Requirements\nsometimes state architecture characteristics outright, but some lurk inside the prob\u2010\nlem domain. Consider a sandwich shop. Is its traffic consistent throughout the day?\nOr does it endure bursts of traffic around mealtimes? Almost certainly the latter.\nThus, a good architect should identify this potential architecture characteristic.\nAn architect should consider each of these business requirements in turn to see if\narchitecture characteristics exist:\n1. Users will place their order, then be given a time to pick up their sandwich and\ndirections to the shop (which must provide the option to integrate with external\nmapping services that include traffic information).\nExternal mapping services imply integration points, which may impact aspects\nsuch as reliability. For example, if a developer builds a system that relies on a\nthird-party system, yet calling it fails, it impacts the reliability of the calling\nsystem. However, architects must also be wary of over-specifying architecture\ncharacteristics. What if the external traffic service is down? Should the Silicon\nCase Study: Silicon Sandwiches \n| \n71\n", "page": 91, "type": "text", "section": "Page 91"}
{"text": "Sandwiches site fail, or should it just offer slightly less efficiency without traffic\ninformation? Architects should always guard against building unnecessary brit\u2010\ntleness or fragility into designs.\n2. If the shop offers a delivery service, dispatch the driver with the sandwich to the\nuser.\nNo special architecture characteristics seem necessary to support this\nrequirement.\n3. Mobile-device accessibility.\nThis requirement will primarily affect the design of the application, pointing\ntoward building either a portable web application or several native web applica\u2010\ntions. Given the budget constraints and simplicity of the application, an architect\nwould likely deem it overkill to build multiple applications, so the design points\ntoward a mobile-optimized web application. Thus, the architect may want to\ndefine some specific performance architecture characteristics for page load time\nand other mobile-sensitive characteristics. Notice that the architect shouldn\u2019t act\nalone in situations like this, but should instead collaborate with user experience\ndesigners, domain stakeholders, and other interested parties to vet decisions like\nthis.\n4. Offer national daily promotions/specials.\n5. Offer local daily promotions/specials.\nBoth of these requirements specify customizability across both promotions and\nspecials. Notice that requirement 1 also implies customized traffic information\nbased on address. Based on all three of these requirements, the architect may\nconsider customizability as an architecture characteristic. For example, an archi\u2010\ntecture style such as microkernel architecture supports customized behavior\nextremely well by defining a plug-in architecture. In this case, the default behav\u2010\nior appears in the core, and developers write the optional customized parts, based\non location, via plug-ins. However, a traditional design can also accommodate\nthis requirement via design patterns (such as Template Method). This conun\u2010\ndrum is common in architecture and requires architects to constantly weight\ntrade-offs between competing options. We discuss particular trade-off in more\ndetail in \u201cDesign Versus Architecture and Trade-Offs\u201d on page 74.\n6. Accept payment online, in person, or upon delivery.\nOnline payments imply security, but nothing in this requirement suggests a par\u2010\nticularly heightened level of security beyond what\u2019s implicit.\n7. Sandwich shops are franchised, each with a different owner.\nThis requirement may impose cost restrictions on the architecture\u2014the architect\nshould check the feasibility (applying constraints like cost, time, and staff skill\nset) to see if a simple or sacrificial architecture is warranted.\n72 \n| \nChapter 5: Identifying Architectural Characteristics\n", "page": 92, "type": "text", "section": "Page 92"}
{"text": "8. Parent company has near-future plans to expand overseas.\nThis requirement implies internationalization, or i18n. Many design techniques\nexist to handle this requirement, which shouldn\u2019t require special structure to\naccommodate. This will, however, certainly drive design decisions.\n9. Corporate goal is to hire inexpensive labor to maximize profit.\nThis requirement suggests that usability will be important, but again is more con\u2010\ncerned with design than architecture characteristics.\nThe third architecture characteristic we derive from the preceding requirements is\nperformance: no one wants to buy from a sandwich shop that has poor performance,\nespecially at peak times. However, performance is a nuanced concept\u2014what kind of\nperformance should the architect design for? We cover the various nuances of perfor\u2010\nmance in Chapter 6.\nWe also want to define performance numbers in conjunction with scalability num\u2010\nbers. In other words, we must establish a baseline of performance without particular\nscale, as well as determine what an acceptable level of performance is given a certain\nnumber of users. Quite often, architecture characteristics interact with one another,\nforcing architects to define them in relation to one another.\nImplicit Characteristics\nMany architecture characteristics aren\u2019t specified in requirements documents, yet\nthey make up an important aspect of the design. One implicit architecture character\u2010\nistic the system might want to support is availability: making sure users can access the\nsandwich site. Closely related to availability is reliability: making sure the site stays up\nduring interactions\u2014no one wants to purchase from a site that continues dropping\nconnections, forcing them to log in again.\nSecurity appears as an implicit characteristic in every system: no one wants to create\ninsecure software. However, it may be prioritized depending on criticality, which\nillustrates the interlocking nature of our definition. An architect considers security an\narchitecture characteristic if it influences some structural aspect of the design and is\ncritical or important to the application.\nFor Silicon Sandwiches, an architect might assume that payments should be handled\nby a third party. Thus, as long as developers follow general security hygiene (not pass\u2010\ning credit card numbers as plain text, not storing too much information, and so on),\nthe architect shouldn\u2019t need any special structural design to accommodate security;\ngood design in the application will suffice. Each architecture characteristic interacts\nwith the others, leading to the common pitfall of architects of over-specifying archi\u2010\ntecture characteristics, which is just as damaging as under-specifying them because it\novercomplicates the system design.\nCase Study: Silicon Sandwiches \n| \n73\n", "page": 93, "type": "text", "section": "Page 93"}
{"text": "The last major architecture characteristic that Silicon Sandwiches needs to support\nencompasses several details from the requirements: customizability. Notice that sev\u2010\neral parts of the problem domain offer custom behavior: recipes, local sales, and\ndirections that may be locally overridden. Thus, the architecture should support the\nability to facilitate custom behavior. Normally, this would fall into the design of the\napplication. However, as our definition specifies, a part of the problem domain that\nrelies on custom structure to support it moves into the realm of an architecture char\u2010\nacteristic. This design element isn\u2019t critical to the success of the application though. It\nis important to note that there are no correct answers in choosing architecture char\u2010\nacteristics, only incorrect ones (or, as Mark notes in one of his well-known quotes):\nThere are no wrong answers in architecture, only expensive ones.\nDesign Versus Architecture and Trade-Offs\nIn the Silicon Sandwiches kata, an architect would likely identify customizability as a\npart of the system, but the question then becomes: architecture or design? The archi\u2010\ntecture implies some structural component, whereas design resides within the archi\u2010\ntecture. In the customizability case of Silicon Sandwiches, the architect could choose\nan architecture style like microkernel and build structural support for customization.\nHowever, if the architect chose another style because of competing concerns, develop\u2010\ners could implement the customization using the Template Method design pattern,\nwhich allows parent classes to define workflow that can be overridden in child classes.\nWhich design is better?\nLike in all architecture, it depends on a number of factors. First, are there good rea\u2010\nsons, such as performance and coupling, not to implement a microkernel architec\u2010\nture? Second, are other desirable architecture characteristics more difficult in one\ndesign versus the other? Third, how much would it cost to support all the architecture\ncharacteristics in each design versus pattern? This type of architectural trade-off anal\u2010\nysis makes up an important part of an architect\u2019s role.\nAbove all, it is critical for the architect to collaborate with the developers, project\nmanager, operations team, and other co-constructors of the software system. No\narchitecture decision should be made isolated from the implementation team (which\nleads to the dreaded Ivory Tower Architect anti-pattern). In the case of Silicon Sand\u2010\nwiches, the architect, tech lead, developers, and domain analysts should collaborate to\ndecide how best to implement customizability.\nAn architect could design an architecture that doesn\u2019t accommodate customizability\nstructurally, requiring the design of the application itself to support that behavior (see\n\u201cDesign Versus Architecture and Trade-Offs\u201d on page 74). Architects shouldn\u2019t stress\ntoo much about discovering the exactly correct set of architecture characteristics\u2014\ndevelopers can implement functionality in a variety of ways. However, correctly iden\u2010\n74 \n| \nChapter 5: Identifying Architectural Characteristics\n", "page": 94, "type": "text", "section": "Page 94"}
{"text": "tifying important structural elements may facilitate a simpler or more elegant design.\nArchitects must remember: there is no best design in architecture, only a least worst\ncollection of trade-offs.\nArchitects must also prioritize these architecture characteristics toward trying to find\nthe simplest required sets. A useful exercise once the team has made a first pass at\nidentifying the architecture characteristics is to try to determine the least important\none\u2014if you must eliminate one, which would it be? Generally, architects are more\nlikely to cull the explicit architecture characteristics, as many of the implicit ones sup\u2010\nport general success. The way we define what\u2019s critical or important to success assists\narchitects in determining if the application truly requires each architecture character\u2010\nistic. By attempting to determine the least applicable one, architects can help deter\u2010\nmine critical necessity. In the case of Silicon Sandwiches, which architecture\ncharacteristic that we have identified is least important? Again, no absolute correct\nanswer exists. However, in this case, the solution could lose either customizability or\nperformance. We could eliminate customizability as an architecture characteristic\nand plan to implement that behavior as part of application design. Of the operational\narchitecture characteristics, performance is likely the least critical for success. Of\ncourse, the developers don\u2019t mean to build an application that has terrible perfor\u2010\nmance, but rather one that doesn\u2019t prioritize performance over other characteristics,\nsuch as scalability or availability.\nCase Study: Silicon Sandwiches \n| \n75\n", "page": 95, "type": "text", "section": "Page 95"}
{"text": "CHAPTER 6\nMeasuring and Governing\nArchitecture Characteristics\nArchitects must deal with the extraordinarily wide variety of architecture characteris\u2010\ntics across all different aspects of software projects. Operational aspects like perfor\u2010\nmance, elasticity, and scalability comingle with structural concerns such as\nmodularity and deployability. This chapter focuses on concretely defining some of\nthe more common architecture characteristics and building governance mechanisms\nfor them.\nMeasuring Architecture Characteristics\nSeveral common problems exist around the definition of architecture characteristics\nin organizations:\nThey aren\u2019t physics\nMany architecture characteristics in common usage have vague meanings. For\nexample, how does an architect design for agility or deployability? The industry\nhas wildly differing perspectives on common terms, sometimes driven by legiti\u2010\nmate differing contexts, and sometimes accidental.\nWildly varying definitions\nEven within the same organization, different departments may disagree on the\ndefinition of critical features such as performance. Until developers, architecture,\nand operations can unify on a common definition, a proper conversation is\ndifficult.\n77\n", "page": 97, "type": "text", "section": "Page 97"}
{"text": "Too composite\nMany desirable architecture characteristics comprise many others at a smaller\nscale. For example, developers can decompose agility into characteristics such as\nmodularity, deployability, and testability.\nObjective definitions for architecture characteristics solve all three problems: by\nagreeing organization-wide on concrete definitions for architecture characteristics,\nteams create a ubiquitous language around architecture. Also, by encouraging objec\u2010\ntive definitions, teams can unpack composite characteristics to uncover measurable\nfeatures they can objectively define.\nOperational Measures\nMany architecture characteristics have obvious direct measurements, such as perfor\u2010\nmance or scalability. However, even these offer many nuanced interpretations,\ndepending on the team\u2019s goals. For example, perhaps a team measures the average\nresponse time for certain requests, a good example of an operational architecture\ncharacteristics measure. But if teams only measure the average, what happens if some\nboundary condition causes 1% of requests to take 10 times longer than others? If the\nsite has enough traffic, the outliers may not even show up. Therefore, a team may also\nwant to measure the maximum response times to catch outliers.\nThe Many Flavors of Performance\nMany of the architecture characteristics we describe have multiple, nuanced defini\u2010\ntions. Performance is a great example. Many projects look at general performance: for\nexample, how long request and response cycles take for a web application. However,\narchitects and DevOps engineers have performed a tremendous amount of work on\nestablishing performance budgets: specific budgets for specific parts of the applica\u2010\ntion. For example, many organizations have researched user behavior and determined\nthat the optimum time for first-page render (the first visible sign of progress for a\nwebpage, in a browser or mobile device) is 500 ms\u2014half a second; Most applications\nfall in the double-digit range for this metric. But, for modern sites that attempt to\ncapture as many users as possible, this is an important metric to track, and the organi\u2010\nzations behind them have built extremely nuanced measures.\nSome of these metrics have additional implications for the design of applications.\nMany forward-thinking organizations place K-weight budgets for page downloads: a\nmaximum number of bytes\u2019 worth of libraries and frameworks allowed on a particu\u2010\nlar page. Their rationale behind this structure derives from physics constraints: only\nso many bytes can travel over a network at a time, especially for mobile devices in\nhigh-latency areas.\n78 \n| \nChapter 6: Measuring and Governing Architecture Characteristics\n", "page": 98, "type": "text", "section": "Page 98"}
{"text": "High-level teams don\u2019t just establish hard performance numbers; they base their defi\u2010\nnitions on statistical analysis. For example, say a video streaming service wants to\nmonitor scalability. Rather than set an arbitrary number as the goal, engineers meas\u2010\nure the scale over time and build statistical models, then raise alarms if the real-time\nmetrics fall outside the prediction models. A failure can mean two things: the model\nis incorrect (which teams like to know) or something is amiss (which teams also like\nto know).\nThe kinds of characteristics that teams can now measure are evolving rapidly, in con\u2010\njunction with tools and nuanced understanding. For example, many teams recently\nfocused on performance budgets for metrics such as first contentful paint and first\nCPU idle, both of which speak volumes about performance issues for users of web\u2010\npages on mobile devices. As devices, targets, capabilities, and myriad other things\nchange, teams will find new things and ways to measure.\nStructural Measures\nSome objective measures are not so obvious as performance. What about internal\nstructural characteristics, such as well-defined modularity? Unfortunately, compre\u2010\nhensive metrics for internal code quality don\u2019t yet exist. However, some metrics and\ncommon tools do allow architects to address some critical aspects of code structure,\nalbeit along narrow dimensions.\nAn obvious measurable aspect of code is complexity, defined by the cyclomatic com\u2010\nplexity metric.\nCyclomatic Complexity\nCyclomatic Complexity (CC) is a code-level metric designed to provide an object\nmeasure for the complexity of code, at the function/method, class, or application\nlevel, developed by Thomas McCabe, Sr., in 1976.\nIt is computed by applying graph theory to code, specifically decision points, which\ncause different execution paths. For example, if a function has no decision statements\n(such as if statements), then CC = 1. If the function had a single conditional, then CC\n= 2 because two possible execution paths exist.\nThe formula for calculating the CC for a single function or method is CC = E \u2212N + 2,\nwhere N represents nodes (lines of code), and E represents edges (possible decisions).\nConsider the C-like code shown in Example 6-1.\nMeasuring Architecture Characteristics \n| \n79\n", "page": 99, "type": "text", "section": "Page 99"}
{"text": "Example 6-1. Sample code for cyclomatic complexity evaluation\npublic void decision(int c1, int c2) {\n    if (c1 < 100)\n        return 0;\n    else if (c1 + C2 > 500)\n       return 1;\n    else\n      return -1;\n}\nThe cyclomatic complexity for Example 6-1 is 3 (=3 \u2013 2 + 2); the graph appears in\nFigure 6-1.\nFigure 6-1. Cyclomatic Complexity for the decision function\nThe number 2 appearing in the cyclomatic complexity formula represents a simplifi\u2010\ncation for a single function/method. For fan-out calls to other methods (known as\nconnected components in graph theory), the more general formula is CC = E \u2212N + 2P,\nwhere P represents the number of connected components.\nArchitects and developers universally agree that overly complex code represents a\ncode smell; it harms virtually every one of the desirable characteristics of code bases:\nmodularity, testability, deployability, and so on. Yet if teams don\u2019t keep an eye on\ngradually growing complexity, that complexity will dominate the code base.\n80 \n| \nChapter 6: Measuring and Governing Architecture Characteristics\n", "page": 100, "type": "text", "section": "Page 100"}
{"text": "What\u2019s a Good Value for Cyclomatic Complexity?\nA common question the authors receive when talking about this subject is: what\u2019s a\ngood threshold value for CC? Of course, like all answers in software architecture: it\ndepends! It depends on the complexity of the problem domain. For example, if you\nhave an algorithmically complex problem, the solution will yield complex functions.\nSome of the key aspects of CC for architects to monitor: are functions complex\nbecause of the problem domain or because of poor coding? Alternatively, is the code\npartitioned poorly? In other words, could a large method be broken down into\nsmaller, logical chunks, distributing the work (and complexity) into more well-\nfactored methods?\nIn general, the industry thresholds for CC suggest that a value under 10 is acceptable,\nbarring other considerations such as complex domains. We consider that threshold\nvery high and would prefer code to fall under five, indicating cohesive, well-factored\ncode. A metrics tool in the Java world, Crap4J, attempts to determine how poor\n(crappy) your code is by evaluating a combination of CC and code coverage; if CC\ngrows to over 50, no amount of code coverage rescues that code from crappiness. The\nmost terrifying professional artifact Neal ever encountered was a single C function\nthat served as the heart of a commercial software package whose CC was over 800! It\nwas a single function with over 4,000 lines of code, including the liberal use of GOTO\nstatements (to escape impossibly deeply nested loops).\nEngineering practices like test-driven development have the accidental (but positive)\nside effect of generating smaller, less complex methods on average for a given prob\u2010\nlem domain. When practicing TDD, developers try to write a simple test, then write\nthe smallest amount of code to pass the test. This focus on discrete behavior and good\ntest boundaries encourages well-factored, highly cohesive methods that exhibit low\nCC.\nProcess Measures\nSome architecture characteristics intersect with software development processes. For\nexample, agility often appears as a desirable feature. However, it is a composite archi\u2010\ntecture characteristic that architects may decompose into features such as testability,\nand deployability.\nTestability is measurable through code coverage tools for virtually all platforms that\nassess the completeness of testing. Like all software checks, it cannot replace thinking\nand intent. For example, a code base can have 100% code coverage yet poor assertions\nthat don\u2019t actually provide confidence in code correctness. However, testability is\nclearly an objectively measurable characteristic. Similarly, teams can measure deploy\u2010\nability via a variety of metrics: percentage of successful to failed deployments, how\nMeasuring Architecture Characteristics \n| \n81\n", "page": 101, "type": "text", "section": "Page 101"}
{"text": "long deployments take, issues/bugs raised by deployments, and a host of others. Each\nteam bears the responsibility to arrive at a good set of measurements that capture use\u2010\nful data for their organization, both in quality and quantity. Many of these measures\ncome down to team priorities and goals.\nAgility and its related parts clearly relate to the software development process. How\u2010\never, that process may impact the structure of the architecture. For example, if ease of\ndeployment and testability are high priorities, then an architect would place more\nemphasis on good modularity and isolation at the architecture level, an example of an\narchitecture characteristic driving a structural decision. Virtually anything within the\nscope of a software project may rise to the level of an architecture characteristic if it\nmanages to meet our three criteria, forcing an architect to make design decisions to\naccount for it.\nGovernance and Fitness Functions\nOnce architects have established architecture characteristics and prioritized them,\nhow can they make sure that developers will respect those priorities? Modularity is a\ngreat example of an aspect of architecture that is important but not urgent; on many\nsoftware projects, urgency dominates, yet architects still need a mechanism for\ngovernance.\nGoverning Architecture Characteristics\nGovernance, derived from the Greek word kubernan (to steer) is an important\nresponsibility of the architect role. As the name implies, the scope of architecture\ngovernance covers any aspect of the software development process that architects\n(including roles like enterprise architects) want to exert an influence upon. For exam\u2010\nple, ensuring software quality within an organization falls under the heading of archi\u2010\ntectural governance because it falls within the scope of architecture, and negligence\ncan lead to disastrous quality problems.\nFortunately, increasingly sophisticated solutions exist to relieve this problem from\narchitects, a good example of the incremental growth in capabilities within the soft\u2010\nware development ecosystem. The drive toward automation on software projects\nspawned by Extreme Programming created continuous integration, which led to fur\u2010\nther automation into operations, which we now call DevOps, continuing through to\narchitectural governance. The book Building Evolutionary Architectures (O\u2019Reilly)\ndescribes a family of techniques, called fitness functions, used to automate many\naspects of architecture governance.\n82 \n| \nChapter 6: Measuring and Governing Architecture Characteristics\n", "page": 102, "type": "text", "section": "Page 102"}
{"text": "Fitness Functions\nThe word \u201cevolutionary\u201d in Building Evolutionary Architectures comes more from\nevolutionary computing than biology. One of the authors, Dr. Rebecca Parsons, spent\nsome time in the evolutionary computing space, including tools like genetic algo\u2010\nrithms. A genetic algorithm executes and produces an answer and then undergoes\nmutation by well-known techniques defined within the evolutionary computing\nworld. If a developer tries to design a genetic algorithm to produce some beneficial\noutcome, they often want to guide the algorithm, providing an objective measure\nindicating the quality of the outcome. That guidance mechanism is called a fitness\nfunction: an object function used to assess how close the output comes to achieving\nthe aim. For example, suppose a developer needed to solve the traveling salesperson\nproblem, a famous problem used as a basis for machine learning. Given a salesperson\nand a list of cities they must visit, with distances between them, what is the optimum\nroute? If a developer designs a genetic algorithm to solve this problem, one fitness\nfunction might evaluate the length of the route, as the shortest possible one repre\u2010\nsents highest success. Another fitness function might be to evaluate the overall cost\nassociated with the route and attempt to keep cost at a minimum. Yet another might\nbe to evaluate the time the traveling salesperson is away and optimize to shorten the\ntotal travel time.\nPractices in evolutionary architecture borrow this concept to create an architecture\nfitness function:\nArchitecture fitness function\nAny mechanism that provides an objective integrity assessment of some architec\u2010\nture characteristic or combination of architecture characteristics\nFitness functions are not some new framework for architects to download, but rather\na new perspective on many existing tools. Notice in the definition the phrase any\nmechanism\u2014the verification techniques for architecture characteristics are as varied\nas the characteristics are. Fitness functions overlap many existing verification mecha\u2010\nnisms, depending on the way they are used: as metrics, monitors, unit testing libra\u2010\nries, chaos engineering, and so on, illustrated in Figure 6-2.\nGovernance and Fitness Functions \n| \n83\n", "page": 103, "type": "text", "section": "Page 103"}
{"text": "Figure 6-2. The mechanisms of fitness functions\nMany different tools may be used to implement fitness functions, depending on the\narchitecture characteristics. For example, in \u201cCoupling\u201d on page 44 we introduced\nmetrics to allow architects to assess modularity. Here are a couple of examples of fit\u2010\nness functions that test various aspects of modularity.\nCyclic dependencies\nModularity is an implicit architecture characteristic that most architects care about,\nbecause poorly maintained modularity harms the structure of a code base; thus,\narchitects should place a high priority on maintaining good modularity. However,\nforces work against the architect\u2019s good intentions on many platforms. For example,\nwhen coding in any popular Java or .NET development environment, as soon as a\ndeveloper references a class not already imported, the IDE helpfully presents a dialog\nasking the developers if they would like to auto-import the reference. This occurs so\noften that most programmers develop the habit of swatting the auto-import dialog\naway like a reflex action. However, arbitrarily importing classes or components\nbetween one another spells disaster for modularity. For example, Figure 6-3 illustrates\na particularly damaging anti-pattern that architects aspire to avoid.\n84 \n| \nChapter 6: Measuring and Governing Architecture Characteristics\n", "page": 104, "type": "text", "section": "Page 104"}
{"text": "Figure 6-3. Cyclic dependencies between components\nIn Figure 6-3, each component references something in the others. Having a network\nof components such as this damages modularity because a developer cannot reuse a\nsingle component without also bringing the others along. And, of course, if the other\ncomponents are coupled to other components, the architecture tends more and more\ntoward the Big Ball of Mud anti-pattern. How can architects govern this behavior\nwithout constantly looking over the shoulders of trigger-happy developers? Code\nreviews help but happen too late in the development cycle to be effective. If an archi\u2010\ntect allows a development team to rampantly import across the code base for a week\nuntil the code review, serious damage has already occurred in the code base.\nThe solution to this problem is to write a fitness function to look after cycles, as\nshown in Example 6-2.\nExample 6-2. Fitness function to detect component cycles\npublic class CycleTest {\n    private JDepend jdepend;\n    @BeforeEach\n    void init() {\n \n  jdepend = new JDepend();\n \n  jdepend.addDirectory(\"/path/to/project/persistence/classes\");\n \n  jdepend.addDirectory(\"/path/to/project/web/classes\");\n \n  jdepend.addDirectory(\"/path/to/project/thirdpartyjars\");\n    }\n    @Test\n    void testAllPackages() {\n \n  Collection packages = jdepend.analyze();\n \n  assertEquals(\"Cycles exist\", false, jdepend.containsCycles());\nGovernance and Fitness Functions \n| \n85\n", "page": 105, "type": "text", "section": "Page 105"}
{"text": "    }\n}\nIn the code, an architect uses the metrics tool JDepend to check the dependencies\nbetween packages. The tool understands the structure of Java packages and fails the\ntest if any cycles exist. An architect can wire this test into the continuous build on a\nproject and stop worrying about the accidental introduction of cycles by trigger-\nhappy developers. This is a great example of a fitness function guarding the impor\u2010\ntant rather than urgent practices of software development: it\u2019s an important concern\nfor architects yet has little impact on day-to-day coding.\nDistance from the main sequence fitness function\nIn \u201cCoupling\u201d on page 44, we introduced the more esoteric metric of distance from\nthe main sequence, which architects can also verify using fitness functions, as shown\nin Example 6-3.\nExample 6-3. Distance from the main sequence fitness function\n@Test\nvoid AllPackages() {\n    double ideal = 0.0;\n    double tolerance = 0.5; // project-dependent\n    Collection packages = jdepend.analyze();\n    Iterator iter = packages.iterator();\n    while (iter.hasNext()) {\n      JavaPackage p = (JavaPackage)iter.next();\n      assertEquals(\"Distance exceeded: \" + p.getName(),\n \n    ideal, p.distance(), tolerance);\n    }\n}\nIn the code, the architect uses JDepend to establish a threshold for acceptable values,\nfailing the test if a class falls outside the range.\nThis is both an example of an objective measure for an architecture characteristic and\nthe importance of collaboration between developers and architects when designing\nand implementing fitness functions. The intent is not for a group of architects to\nascend to an ivory tower and develop esoteric fitness functions that developers can\u2010\nnot understand.\nArchitects must ensure that developers understand the purpose of\nthe fitness function before imposing it on them.\n86 \n| \nChapter 6: Measuring and Governing Architecture Characteristics\n", "page": 106, "type": "text", "section": "Page 106"}
{"text": "The sophistication of fitness function tools has increased over the last few years,\nincluding some special purpose tools. One such tool is ArchUnit, a Java testing\nframework inspired by and using several parts of the JUnit ecosystem. ArchUnit pro\u2010\nvides a variety of predefined governance rules codified as unit tests and allows archi\u2010\ntects to write specific tests that address modularity. Consider the layered architecture\nillustrated in Figure 6-4.\nFigure 6-4. Layered architecture\nWhen designing a layered monolith such as the one in Figure 6-4, the architect\ndefines the layers for good reason (motivations, trade-offs, and other aspects of the\nlayered architecture are described in Chapter 10). However, how can the architect\nensure that developers will respect those layers? Some developers may not under\u2010\nstand the importance of the patterns, while others may adopt a \u201cbetter to ask forgive\u2010\nness than permission\u201d attitude because of some overriding local concern such as\nperformance. But allowing implementers to erode the reasons for the architecture\nhurts the long-term health of the architecture.\nArchUnit allows architects to address this problem via a fitness function, shown in\nExample 6-4.\nExample 6-4. ArchUnit fitness function to govern layers\nlayeredArchitecture()\n    .layer(\"Controller\").definedBy(\"..controller..\")\n    .layer(\"Service\").definedBy(\"..service..\")\n    .layer(\"Persistence\").definedBy(\"..persistence..\")\n    .whereLayer(\"Controller\").mayNotBeAccessedByAnyLayer()\n    .whereLayer(\"Service\").mayOnlyBeAccessedByLayers(\"Controller\")\n    .whereLayer(\"Persistence\").mayOnlyBeAccessedByLayers(\"Service\")\nIn Example 6-4, the architect defines the desirable relationship between layers and\nwrites a verification fitness function to govern it.\nGovernance and Fitness Functions \n| \n87\n", "page": 107, "type": "text", "section": "Page 107"}
{"text": "A similar tool in the .NET space, NetArchTest, allows similar tests for that platform; a\nlayer verification in C# appears in Example 6-5.\nExample 6-5. NetArchTest for layer dependencies\n// Classes in the presentation should not directly reference repositories\nvar result = Types.InCurrentDomain()\n    .That()\n    .ResideInNamespace(\"NetArchTest.SampleLibrary.Presentation\")\n    .ShouldNot()\n    .HaveDependencyOn(\"NetArchTest.SampleLibrary.Data\")\n    .GetResult()\n    .IsSuccessful;\nAnother example of fitness functions is Netflix\u2019s Chaos Monkey and the attendant\nSimian Army. In particular, the Conformity, Security, and Janitor Monkeys exemplify\nthis approach. The Conformity Monkey allows Netflix architects to define gover\u2010\nnance rules enforced by the monkey in production. For example, if the architects\ndecided that each service should respond usefully to all RESTful verbs, they build that\ncheck into the Conformity Monkey. Similarly, the Security Monkey checks each ser\u2010\nvice for well-known security defects, like ports that shouldn\u2019t be active and configura\u2010\ntion errors. Finally, the Janitor Monkey looks for instances that no other services\nroute to anymore. Netflix has an evolutionary architecture, so developers routinely\nmigrate to newer services, leaving old services running with no collaborators. Because\nservices running on the cloud consume money, the Janitor Monkey looks for orphan\nservices and disintegrates them out of production.\nThe Origin of the Simian Army\nWhen Netflix decided to move its operations to Amazon\u2019s cloud, the architects wor\u2010\nried over the fact that they no longer had control over operations\u2014what happens if a\ndefect appears operationally? To solve this problem, they spawned the discipline of\nChaos Engineering with the original Chaos Monkey, and eventually the Simian Army.\nThe Chaos Monkey simulated general chaos within the production environment to\nsee how well their system would endure it. Latency was a problem with some AWS\ninstances, thus the Chaos Monkey would simulate high latency (which was such a\nproblem, they eventually created a specialized monkey for it, the Latency Monkey). \nTools such as the Chaos Kong, which simulates an entire Amazon data center failure,\nhelped Netflix avoid such outages when they occured for real.\nChaos engineering offers an interesting new perspective on architecture: it\u2019s not a\nquestion of if something will eventually break, but when. Anticipating those break\u2010\nages and tests to prevent them makes systems much more robust.\n88 \n| \nChapter 6: Measuring and Governing Architecture Characteristics\n", "page": 108, "type": "text", "section": "Page 108"}
{"text": "A few years ago, the influential book The Checklist Manifesto by Atul Gawande (Pica\u2010\ndor) described how professions such as airline pilots and surgeons use checklists\n(sometimes legally mandated). It\u2019s not because those professionals don\u2019t know their\njobs or are forgetful. Rather, when professionals do a highly detailed job over and\nover, it becomes easy for details to slip by; a succinct checklist forms an effective\nreminder. This is the correct perspective on fitness functions\u2014rather than a heavy\u2010\nweight governance mechanism, fitness functions provide a mechanism for architects\nto express important architectural principles and automatically verify them. Develop\u2010\ners know that they shouldn\u2019t release insecure code, but that priority competes with\ndozens or hundreds of other priorities for busy developers. Tools like the Security\nMonkey specifically, and fitness functions generally, allow architects to codify impor\u2010\ntant governance checks into the substrate of the architecture.\nGovernance and Fitness Functions \n| \n89\n", "page": 109, "type": "text", "section": "Page 109"}
{"text": "CHAPTER 7\nScope of Architecture Characteristics\nA prevailing axiomatic assumption in the software architecture world had tradition\u2010\nally placed the scope of architecture characteristics at the system level. For example,\nwhen architects talk about scalability, they generally couch that discussion around the\nscalability of the entire system. That was a safe assumption a decade ago, when virtu\u2010\nally all systems were monolithic. With the advent of modern engineering techniques\nand the architecture styles they enabled, such as microservices, the scope of architec\u2010\nture characteristics has narrowed considerably. This is a prime example of an axiom\nslowly becoming outdated as the software development ecosystem continues its\nrelentless evolution.\nDuring the writing of the Building Evolutionary Architectures book, the authors\nneeded a technique to measure the structural evolvability of particular architecture\nstyles. None of the existing measures offered the correct level of detail. In \u201cStructural\nMeasures\u201d on page 79, we discuss a variety of code-level metrics that allow architects\nto analyze structural aspects of an architecture. However, all these metrics only reveal\nlow-level details about the code, and cannot evaluate dependent components (such as\ndatabases) outside the code base that still impact many architecture characteristics,\nespecially operational ones. For example, no matter how much an architect puts\neffort into designing a performant or elastic code base, if the system uses a database\nthat doesn\u2019t match those characteristics, the application won\u2019t be successful.\nWhen evaluating many operational architecture characteristics, an architect must\nconsider dependent components outside the code base that will impact those charac\u2010\nteristics. Thus, architects need another method to measure these kinds of dependen\u2010\ncies. That lead the Building Evolutionary Architectures authors to define the term\narchitecture quantum. To understand the architecture quantum definition, we must\npreview one key metric here, connascence.\n91\n", "page": 111, "type": "text", "section": "Page 111"}
{"text": "Coupling and Connascence\nMany of the code-level coupling metrics, such as afferent and efferent coupling\n(described in \u201cStructural Measures\u201d on page 79), reveal details at a too fine-grained\nlevel for architectural analysis. In 1996, Meilir Page-Jones published a book titled\nWhat Every Programmer Should Know About Object Oriented Design (Dorset House)\nthat included several new measures of coupling he named connascence, which is\ndefined as follows:\nConnascence\nTwo components are connascent if a change in one would require the other to be\nmodified in order to maintain the overall correctness of the system\nHe defined two types of connascence: static, discoverable via static code analysis, and\ndynamic, concerning runtime behavior. To define the architecture quantum, we\nneeded a measure of how components are \u201cwired\u201d together, which corresponds to the\nconnascence concept. For example, if two services in a microservices architecture\nshare the same class definition of some class, like address, we say they are statically\nconnascent with each other\u2014changing the shared class requires changes to both\nservices.\nFor dynamic connascence, we define two types: synchronous and asynchronous. Syn\u2010\nchronous calls between two distributed services have the caller wait for the response\nfrom the callee. On the other hand, asynchronous calls allow fire-and-forget seman\u2010\ntics in event-driven architectures, allowing two different services to differ in opera\u2010\ntional architecture\nArchitectural Quanta and Granularity\nComponent-level coupling isn\u2019t the only thing that binds software together. Many\nbusiness concepts semantically bind parts of the system together, creating functional\ncohesion. To successfully design, analyze, and evolve software, developers must con\u2010\nsider all the coupling points that could break.\nMany science-literate developers know of the concept of quantum from physics, the\nminimum amount of any physical entity involved in an interaction. The word quan\u2010\ntum derives from Latin, meaning \u201chow great\u201d or \u201chow much.\u201d We have adopted this\nnotion to define an architecture quantum:\nArchitecture quantum\nAn independently deployable artifact with high functional cohesion and syn\u2010\nchronous connascence\n92 \n| \nChapter 7: Scope of Architecture Characteristics\n", "page": 112, "type": "text", "section": "Page 112"}
{"text": "This definition contains several parts, dissected here:\nIndependently deployable\nAn architecture quantum includes all the necessary components to function\nindependently from other parts of the architecture. For example, if an application\nuses a database, it is part of the quantum because the system won\u2019t function\nwithout it. This requirement means that virtually all legacy systems deployed\nusing a single database by definition form a quantum of one. However, in the\nmicroservices architecture style, each service includes its own database (part of\nthe bounded context driving philosophy in microservices, described in detail in\nChapter 17), creating multiple quanta within that architecture.\nHigh functional cohesion\nCohesion in component design refers to how well the contained code is unified in\npurpose. For example, a Customer component with properties and methods all\npertaining to a Customer entity exhibits high cohesion; whereas a Utility com\u2010\nponent with a random collection of miscellaneous methods would not.\nHigh functional cohesion implies that an architecture quantum does something\npurposeful. This distinction matters little in traditional monolithic applications\nwith a single database. However, in microservices architectures, developers typi\u2010\ncally design each service to match a single workflow (a bounded context, as\ndescribed in \u201cDomain-Driven Design\u2019s Bounded Context\u201d on page 94), thus\nexhibiting high functional cohesion.\nSynchronous connascence\nSynchronous connascence implies synchronous calls within an application context\nor between distributed services that form this architecture quantum. For exam\u2010\nple, if one service in a microservices architecture calls another one synchro\u2010\nnously, each service cannot exhibit extreme differences in operational\narchitecture characteristics. If the caller is much more scalable than the callee,\ntimeouts and other reliability concerns will occur. Thus, synchronous calls create\ndynamic connascence for the length of the call\u2014if one is waiting for the other,\ntheir operational architecture characteristics must be the same for the duration of\nthe call.\nBack in Chapter 6, we defined the relationship between traditional coupling metrics\nand connascence, which didn\u2019t include our new communication connascence measure. \nWe update this diagram in Figure 7-1.\nArchitectural Quanta and Granularity \n| \n93\n", "page": 113, "type": "text", "section": "Page 113"}
{"text": "Figure 7-1. Adding quantum connascence to the unified diagram\nFor another example, consider a microservices architecture with a Payment service\nand an Auction service. When an auction ends, the Auction service sends payment\ninformation to the Payment service. However, let\u2019s say that the payment service can\nonly handle a payment every 500 ms\u2014what happens when a large number of auc\u2010\ntions end at once? A poorly designed architecture would allow the first call to go\nthrough and allow the others to time out. Alternatively, an architect might design an\nasynchronous communication link between Payment and Auction, allowing the mes\u2010\nsage queue to temporarily buffer differences. In this case, asynchronous connascence\ncreates a more flexible architecture. We cover this subject in great detail in\nChapter 14.\nDomain-Driven Design\u2019s Bounded Context\nEric Evans\u2019 book Domain-Driven Design (Addison-Wesley Professional) has deeply\ninfluenced modern architectural thinking. Domain-driven design (DDD) is a model\u2010\ning technique that allows for organized decomposition of complex problem domains.\nDDD defines the bounded context, where everything related to the domain is visible\ninternally but opaque to other bounded contexts. Before DDD, developers sought\nholistic reuse across common entities within the organization. Yet creating common\nshared artifacts causes a host of problems, such as coupling, more difficult coordina\u2010\ntion, and increased complexity. The bounded context concept recognizes that each\nentity works best within a localized context. Thus, instead of creating a unified Cus\ntomer class across the entire organization, each problem domain can create its own\nand reconcile differences at integration points.\n94 \n| \nChapter 7: Scope of Architecture Characteristics\n", "page": 114, "type": "text", "section": "Page 114"}
{"text": "The architecture quantum concept provides the new scope for architecture character\u2010\nistics. In modern systems, architects define architecture characteristics at the quan\u2010\ntum level rather than system level. By looking at a narrower scope for important\noperational concerns, architects may identify architectural challenges early, leading to\nhybrid architectures. To illustrate scoping provided by the architecture quantum\nmeasure, consider another architecture kata, Going, Going, Gone.\nCase Study: Going, Going, Gone\nIn Chapter 5, we introduced the concept of an architecture kata. Consider this one,\nconcerning an online auction company. Here is the description of the architecture\nkata:\nDescription\nAn auction company wants to take its auctions online to a nationwide scale. Cus\u2010\ntomers choose the auction to participate in, wait until the auction begins, then\nbid as if they are there in the room with the auctioneer.\nUsers\nScale up to hundreds of participants per auction, potentially up to thousands of\nparticipants, and as many simultaneous auctions as possible.\nRequirements\n\u2022 Auctions must be as real-time as possible.\n\u2022 Bidders register with a credit card; the system automatically charges the card if\nthe bidder wins.\n\u2022 Participants must be tracked via a reputation index.\n\u2022 Bidders can see a live video stream of the auction and all bids as they occur.\n\u2022 Both online and live bids must be received in the order in which they are placed.\nAdditional context\n\u2022 Auction company is expanding aggressively by merging with smaller\ncompetitors.\n\u2022 Budget is not constrained. This is a strategic direction.\n\u2022 Company just exited a lawsuit where it settled a suit alleging fraud.\nJust as in \u201cCase Study: Silicon Sandwiches\u201d on page 69, an architect must consider\neach of these requirements to ascertain architecture characteristics:\n1. \u201cNationwide scale,\u201d \u201cscale up to hundreds of participants per auction, potentially\nup to thousands of participants, and as many simultaneous auctions as possible,\u201d\n\u201cauctions must be as real-time as possible.\u201d\nArchitectural Quanta and Granularity \n| \n95\n", "page": 115, "type": "text", "section": "Page 115"}
{"text": "Each of these requirements implies both scalability to support the sheer number\nof users and elasticity to support the bursty nature of auctions. While the\nrequirements explicitly call out scalability, elasticity represents an implicit char\u2010\nacteristics based on the problem domain. When considering auctions, do users\nall politely spread themselves out during the course of bidding, or do they\nbecome more frantic near the end? Domain knowledge is crucial for architects to\npick up implicit architecture characteristics. Given the real-time nature of auc\u2010\ntions, an architect will certainly consider performance a key architecture\ncharacteristic.\n2. \u201cBidders register with a credit card; the system automatically charges the card if\nthe bidder wins,\u201d \u201ccompany just exited a lawsuit where it settled a suit alleging\nfraud.\u201d\nBoth these requirements clearly point to security as an architecture characteristic.\nAs covered in Chapter 5, security is an implicit architecture characteristic in vir\u2010\ntually every application. Thus, architects rely on the second part of the definition\nof architecture characteristics, that they influence some structural aspect of the\ndesign. Should an architect design something special to accommodate security,\nor will general design and coding hygiene suffice? Architects have developed\ntechniques for handling credit cards safely via design without necessarily build\u2010\ning special structure. For example, as long as developers make sure not to store\ncredit card numbers in plain text, to encrypt while in transit, and so on, then the\narchitect shouldn\u2019t have to build special considerations for security.\nHowever, the second phrase should make an architect pause and ask for further\nclarification. Clearly, some aspect of security (fraud) was a problem in the past,\nthus the architect should ask for further input no matter what level of security\nthey design.\n3. \u201cParticipants must be tracked via a reputation index.\u201d\nThis requirement suggests some fanciful names such as \u201canti-trollability,\u201d but the\ntrack part of the requirement might suggest some architecture characteristics\nsuch as auditability and loggability. The deciding factor again goes back to the\ndefining characteristic\u2014is this outside the scope of the problem domain? Archi\u2010\ntects must remember that the analysis to yield architecture characteristics repre\u2010\nsents only a small part of the overall effort to design and implement an\napplication\u2014a lot of design work happens past this phase! During this part of\narchitecture definition, architects look for requirements with structural impact\nnot already covered by the domain.\nHere\u2019s a useful litmus test architects use to make the determination between\ndomain versus architecture characteristics is: does it require domain knowledge\nto implement, or is it an abstract architecture characteristic? In the Going, Going,\nGone kata, an architect upon encountering the phrase \u201creputation index\u201d would\n96 \n| \nChapter 7: Scope of Architecture Characteristics\n", "page": 116, "type": "text", "section": "Page 116"}
{"text": "seek out a business analyst or other subject matter expert to explain what they\nhad in mind. In other words, the phrase \u201creputation index\u201d isn\u2019t a standard defi\u2010\nnition like more common architecture characteristics. As a counter example,\nwhen architects discuss elasticity, the ability to handle bursts of users, they can\ntalk about the architecture characteristic purely in the abstract\u2014it doesn\u2019t matter\nwhat kind of application they consider: banking, catalog site, streaming video,\nand so on. Architects must determine whether a requirement isn\u2019t already\nencompassed by the domain and requires particular structure, which elevates a\nconsideration to architecture characteristic.\n4. \u201c\nAuction company is expanding aggressively by merging with smaller\ncompetitors.\u201d\nWhile this requirement may not have an immediate impact on application\ndesign, it might become the determining factor in a trade-off between several\noptions. For example, architects must often choose details such as communica\u2010\ntion protocols for integration architecture: if integration with newly merged\ncompanies isn\u2019t a concern, it frees the architect to choose something highly spe\u2010\ncific to the problem. On the other hand, an architect may choose something that\u2019s\nless than perfect to accommodate some additional trade-off, such as interopera\u2010\nbility. Subtle implicit architecture characteristics such as this pervade architec\u2010\nture, illustrating why doing the job well presents challenges.\n5. \u201cBudget is not constrained. This is a strategic direction.\u201d\nSome architecture katas impose budget restrictions on the solution to represent a\ncommon real-world trade-off. However, in the Going, Going, Gone kata, it does\nnot. This allows the architect to choose more elaborate and/or special-purpose\narchitectures, which will be beneficial given the next requirements.\n6. \u201cBidders can see a live video stream of the auction and all bids as they occur,\u201d\n\u201cboth online and live bids must be received in the order in which they are\nplaced.\u201d\nThis requirement presents an interesting architectural challenge, definitely\nimpacting the structure of the application and exposing the futility of treating\narchitecture characteristics as a system-wide evaluation. Consider availability\u2014is\nthat need uniform throughout the architecture? In other words, is the availability\nof the one bidder more important than availability for one of the hundreds of\nbidders? Obviously, the architect desires good measures for both, but one is\nclearly more critical: if the auctioneer cannot access the site, online bids cannot\noccur for anyone. Reliability commonly appears with availability; it addresses\noperational aspects such as uptime, as well as data integrity and other measures\nof how reliable an application is. For example, in an auction site, the architect\nmust ensure that the message ordering is reliably correct, eliminating race condi\u2010\ntions and other problems.\nArchitectural Quanta and Granularity \n| \n97\n", "page": 117, "type": "text", "section": "Page 117"}
{"text": "This last requirement in the Going, Going, Gone kata highlights the need for a more\ngranular scope in architecture than the system level. Using the architecture quantum\nmeasure, architects scope architecture characteristics at the quantum level. For exam\u2010\nple, in Going, Going, Gone, an architect would notice that different parts of this\narchitecture need different characteristics: streaming bids, online bidders, and the\nauctioneer are three obvious choices. Architects use the architecture quantum meas\u2010\nure as a way to think about deployment, coupling, where data should reside, and\ncommunication styles within architectures. In this kata, an architect can analyze the\ndiffering architecture characteristics per architecture quantum, leading to hybrid\narchitecture design earlier in the process.\nThus, for Going, Going, Gone, we identified the following quanta and corresponding\narchitecture characteristics:\nBidder feedback\nEncompasses the bid stream and video stream of bids\n\u2022 Availability\n\u2022 Scalability\n\u2022 Performance\nAuctioneer\nThe live auctioneer\n\u2022 Availability\n\u2022 Reliability\n\u2022 Scalability\n\u2022 Elasticity\n\u2022 Performance\n\u2022 Security\nBidder\nOnline bidders and bidding\n\u2022 Reliability\n\u2022 Availability\n\u2022 Scalability\n\u2022 Elasticity\n98 \n| \nChapter 7: Scope of Architecture Characteristics\n", "page": 118, "type": "text", "section": "Page 118"}
{"text": "CHAPTER 8\nComponent-Based Thinking\nIn Chapter 3, we discussed modules as a collection of related code. However, archi\u2010\ntects typically think in terms of components, the physical manifestation of a module.\nDevelopers physically package modules in different ways, sometimes depending on\ntheir development platform. We call physical packaging of modules components. Most\nlanguages support physical packaging as well: jar files in Java, dll in .NET, gem in\nRuby, and so on. In this chapter, we discuss architectural considerations around com\u2010\nponents, ranging from scope to discovery.\nComponent Scope\nDevelopers find it useful to subdivide the concept of component based on a wide host\nof factors, a few of which appear in Figure 8-1.\nComponents offer a language-specific mechanism to group artifacts together, often\nnesting them to create stratification. As shown in Figure 8-1, the simplest component\nwraps code at a higher level of modularity than classes (or functions, in nonobject-\noriented languages). This simple wrapper is often called a library, which tends to run\nin the same memory address as the calling code and communicate via language func\u2010\ntion call mechanisms. Libraries are usually compile-time dependencies (with notable\nexceptions like dynamic link libraries [DLLs] that were the bane of Windows users\nfor many years).\n99\n", "page": 119, "type": "text", "section": "Page 119"}
{"text": "Figure 8-1. Different varieties of components\nComponents also appear as subsystems or layers in architecture, as the deployable\nunit of work for many event processors. Another type of component, a service, tends\nto run in its own address space and communicates via low-level networking protocols\nlike TCP/IP or higher-level formats like REST or message queues, forming stand-\nalone, deployable units in architectures like microservices.\nNothing requires an architect to use components\u2014it just so happens that it\u2019s often\nuseful to have a higher level of modularity than the lowest level offered by the lan\u2010\nguage. For example, in microservices architectures, simplicity is one of the architec\u2010\ntural principles. Thus, a service may consist of enough code to warrant components\nor may be simple enough to just contain a small bit of code, as illustrated in\nFigure 8-2.\nComponents form the fundamental modular building block in architecture, making\nthem a critical consideration for architects. In fact, one of the primary decisions an\narchitect must make concerns the top-level partitioning of components in the\narchitecture.\n100 \n| \nChapter 8: Component-Based Thinking\n", "page": 120, "type": "text", "section": "Page 120"}
{"text": "Figure 8-2. A microservice might have so little code that components aren\u2019t necessary\nArchitect Role\nTypically, the architect defines, refines, manages, and governs components within an\narchitecture. Software architects, in collaboration with business analysts, subject mat\u2010\nter experts, developers, QA engineers, operations, and enterprise architects, create the\ninitial design for software, incorporating the architecture characteristics discussed in\nChapter 4 and the requirements for the software system.\nVirtually all the details we cover in this book exist independently from whatever soft\u2010\nware development process teams use: architecture is independent from the develop\u2010\nment process. The primary exception to this rule entails the engineering practices\npioneered in the various flavors of Agile software development, particularly in the\nareas of deployment and automating governance. However, in general, software\narchitecture exists separate from the process. Thus, architects ultimately don\u2019t care\nwhere requirements originate: a formal Joint Application Design (JAD) process,\nlengthy waterfall-style analysis and design, Agile story cards\u2026or any hybrid variation\nof those.\nGenerally the component is the lowest level of the software system an architect inter\u2010\nacts directly with, with the exception of many of the code quality metrics discussed in\nChapter 6 that affect code bases holistically. Components consist of classes or func\u2010\ntions (depending on the implementation platform), whose design falls under the\nresponsibility of tech leads or developers. It\u2019s not that architects shouldn\u2019t involve\nthemselves in class design (particularly when discovering or applying design pat\u2010\nterns), but they should avoid micromanaging each decision from top to bottom in the\nsystem. If architects never allow other roles to make decisions of consequence, the\norganization will struggle with empowering the next generation of architects.\nArchitect Role \n| \n101\n", "page": 121, "type": "text", "section": "Page 121"}
{"text": "An architect must identify components as one of the first tasks on a new project. But\nbefore an architect can identify components, they must know how to partition the\narchitecture.\nArchitecture Partitioning\nThe First Law of Software Architecture states that everything in software is a trade-\noff, including how architects create components in an architecture. Because compo\u2010\nnents represent a general containership mechanism, an architect can build any type\nof partitioning they want. Several common styles exist, with different sets of trade-\noffs. We discuss architecture styles in depth in Part II. Here we discuss an important\naspect of styles, the top-level partitioning in an architecture.\nConsider the two types of architecture styles shown in Figure 8-3.\nFigure 8-3. Two types of top-level architecture partitioning: layered and modular\nIn Figure 8-3, one type of architecture familiar to many is the layered monolith (dis\u2010\ncussed in detail in Chapter 10). The other is an architecture style popularized by\nSimon Brown called a modular monolith, a single deployment unit associated with a\ndatabase and partitioned around domains rather than technical capabilities. These\ntwo styles represent different ways to top-level partition the architecture. Note that in\neach variation, each of the top-level components (layers or components) likely has\nother components embedded within. The top-level partitioning is of particular inter\u2010\nest to architects because it defines the fundamental architecture style and way of par\u2010\ntitioning code.\n102 \n| \nChapter 8: Component-Based Thinking\n", "page": 122, "type": "text", "section": "Page 122"}
{"text": "Organizing architecture based on technical capabilities like the layered monolith rep\u2010\nresents technical top-level partitioning. A common version of this appears in\nFigure 8-4.\nFigure 8-4. Two types of top-level partitioning in architecture\nIn Figure 8-4, the architect has partitioned the functionality of the system into techni\u2010\ncal capabilities: presentation, business rules, services, persistence, and so on. This way\nof organizing a code base certainly makes sense. All the persistence code resides in\none layer in the architecture, making it easy for developers to find persistence-related\ncode. Even though the basic concept of layered architecture predates it by decades,\nthe Model-View-Controller design pattern matches with this architectural pattern,\nmaking it easy for developers to understand. Thus, it is often the default architecture\nin many organizations.\nAn interesting side effect of the predominance of the layered architecture relates to\nhow companies seat different project roles. When using a layered architecture, it\nmakes some sense to have all the backend developers sit together in one department,\nthe DBAs in another, the presentation team in another, and so on. Because of Con\u2010\nway\u2019s law, this makes some sense in those organizations.\nConway\u2019s Law\nBack in the late 1960s, Melvin Conway made an observation that has become known\nas Conway\u2019s law:\nOrganizations which design systems \u2026 are constrained to produce designs which are\ncopies of the communication structures of these organizations.\nParaphrased, this law suggests that when a group of people designs some technical\nartifact, the communication structures between the people end up replicated in the\nArchitect Role \n| \n103\n", "page": 123, "type": "text", "section": "Page 123"}
{"text": "design. People at all levels of organizations see this law in action, and they sometimes\nmake decisions based on it. For example, it is common for organizations to partition\nworkers based on technical capabilities, which makes sense from a pure organiza\u2010\ntional sense but hampers collaboration because of artificial separation of common\nconcerns.\nA related observation coined by Jonny Leroy of ThoughtWorks is the Inverse Conway\nManeuver, which suggests evolving team and organizational structure together to\npromote the desired architecture.\nThe other architectural variation in Figure 8-4 represents domain partitioning,\ninspired by the Eric Evan book Domain-Driven Design, which is a modeling techni\u2010\nque for decomposing complex software systems. In DDD, the architect identifies\ndomains or workflows independent and decoupled from each other. The microservi\u2010\nces architecture style (discussed in Chapter 17) is based on this philosophy. In a mod\u2010\nular monolith, the architect partitions the architecture around domains or workflows\nrather than technical capabilities. As components often nest within one another, each\nof the components in Figure 8-4 in the domain partitioning (for example, Catalog\u2010\nCheckout) may use a persistence library and have a separate layer for business rules,\nbut the top-level partitioning revolves around domains.\nOne of the fundamental distinctions between different architecture patterns is what\ntype of top-level partitioning each supports, which we cover for each individual pat\u2010\ntern. It also has a huge impact on how an architect decides how to initially identify\ncomponents\u2014does the architect want to partition things technically or by domain?\nArchitects using technical partitioning organize the components of the system by\ntechnical capabilities: presentation, business rules, persistence, and so on. Thus, one\nof the organizing principles of this architecture is separation of technical concerns. \nThis in turn creates useful levels of decoupling: if the service layer is only connected\nto the persistence layer below and business rules layer above, then changes in persis\u2010\ntence will only potentially affect those layers. This style of partitioning provides a\ndecoupling technique, reducing rippling side effects on dependent components. We\ncover more details of this architecture style in the layered architecture pattern in\nChapter 10. It is certainly logical to organize systems using technical partitioning,\nbut, like all things in software architecture, this offers some trade-offs.\nThe separation enforced by technical partitioning enables developers to find certain\ncategories of the code base quickly, as it is organized by capabilities. However, most\nrealistic software systems require workflows that cut across technical capabilities.\nConsider the common business workflow of CatalogCheckout. The code to handle\nCatalogCheckout in the technically layered architecture appears in all the layers, as\nshown in Figure 8-5.\n104 \n| \nChapter 8: Component-Based Thinking\n", "page": 124, "type": "text", "section": "Page 124"}
{"text": "Figure 8-5. Where domains/workflows appear in technical- and domain-partitioned\narchitectures\nIn Figure 8-5, in the technically partitioned architecture, CatalogCheckout appears in\nall the layers; the domain is smeared across the technical layers. Contrast this with\ndomain partitioning, which uses a top-level partitioning that organizes components\nby domain rather than technical capabilities. In Figure 8-5, architects designing the\ndomain-partitioned architecture build top-level components around workflows\nand/or domains. Each component in the domain partitioning may have subcompo\u2010\nnents, including layers, but the top-level partitioning focuses on domains, which bet\u2010\nter reflects the kinds of changes that most often occur on projects.\nNeither of these styles is more correct than the other\u2014refer to the First Law of Soft\u2010\nware Architecture. That said, we have observed a decided industry trend over the last\nfew years toward domain partitioning for the monolithic and distributed (for exam\u2010\nple, microservices) architectures. However, it is one of the first decisions an architect\nmust make.\nCase Study: Silicon Sandwiches: Partitioning\nConsider the case of one of our example katas, \u201cCase Study: Silicon Sandwiches\u201d on\npage 69. When deriving components, one of the fundamental decisions facing an\narchitect is the top-level partitioning. Consider the first of two different possibilities\nfor Silicon Sandwiches, a domain partitioning, illustrated in Figure 8-6.\nArchitect Role \n| \n105\n", "page": 125, "type": "text", "section": "Page 125"}
{"text": "Figure 8-6. A domain-partitioned design for Silicon Sandwiches\nIn Figure 8-6, the architect has designed around domains (workflows), creating dis\u2010\ncrete components for Purchase, Promotion, MakeOrder, ManageInventory, Recipes,\nDelivery, and Location. Within many of these components resides a subcomponent\nto handle the various types of customization required, covering both common and\nlocal variations.\nAn alternative design isolates the common and local parts into their own partition,\nillustrated in Figure 8-7. Common and Local represent top-level components, with Pur\nchase and Delivery remaining to handle the workflow.\nWhich is better? It depends! Each partitioning offers different advantages and\ndrawbacks.\nFigure 8-7. A technically partitioned design for Silicon Sandwiches\n106 \n| \nChapter 8: Component-Based Thinking\n", "page": 126, "type": "text", "section": "Page 126"}
{"text": "Domain partitioning\nDomain-partitioned architectures separate top-level components by workflows\nand/or domains.\nAdvantages\n\u2022 Modeled more closely toward how the business functions rather than an imple\u2010\nmentation detail\n\u2022 Easier to utilize the Inverse Conway Maneuver to build cross-functional teams\naround domains\n\u2022 Aligns more closely to the modular monolith and microservices architecture\nstyles\n\u2022 Message flow matches the problem domain\n\u2022 Easy to migrate data and components to distributed architecture\nDisadvantage\n\u2022 Customization code appears in multiple places\nTechnical partitioning\nTechnically partitioned architectures separate top-level components based on techni\u2010\ncal capabilities rather than discrete workflows. This may manifest as layers inspired\nby Model-View-Controller separation or some other ad hoc technical partitioning.\nFigure 8-7 separates components based on customization.\nAdvantages\n\u2022 Clearly separates customization code.\n\u2022 Aligns more closely to the layered architecture pattern.\nDisadvantages\n\u2022 Higher degree of global coupling. Changes to either the Common or Local compo\u2010\nnent will likely affect all the other components.\n\u2022 Developers may have to duplicate domain concepts in both common and local\nlayers.\n\u2022 Typically higher coupling at the data level. In a system like this, the application\nand data architects would likely collaborate to create a single database, including\ncustomization and domains. That in turn creates difficulties in untangling the\ndata relationships if the architects later want to migrate this architecture to a dis\u2010\ntributed system.\nMany other factors contribute to an architect\u2019s decision on what architecture style to\nbase their design upon, covered in Part II.\nArchitect Role \n| \n107\n", "page": 127, "type": "text", "section": "Page 127"}
{"text": "Developer Role\nDevelopers typically take components, jointly designed with the architect role, and\nfurther subdivide them into classes, functions, or subcomponents. In general, class\nand function design is the shared responsibility of architects, tech leads, and develop\u2010\ners, with the lion\u2019s share going to developer roles.\nDevelopers should never take components designed by architects as the last word; all\nsoftware design benefits from iteration. Rather, that initial design should be viewed as\na first draft, where implementation will reveal more details and refinements.\nComponent Identification Flow\nComponent identification works best as an iterative process, producing candidates\nand refinements through feedback, illustrated in Figure 8-8.\nFigure 8-8. Component identification cycle\nThis cycle describes a generic architecture exposition cycle. Certain specialized\ndomains may insert other steps in this process or change it altogether. For example,\nin some domains, some code must undergo security or auditing steps in this process.\nDescriptions of each step in Figure 8-8 appear in the following sections.\nIdentifying Initial Components\nBefore any code exists for a software project, the architect must somehow determine\nwhat top-level components to begin with, based on what type of top-level partition\u2010\ning they choose. Outside that, an architect has the freedom to make up whatever\ncomponents they want, then map domain functionality to them to see where behavior\nshould reside. While this may sound arbitrary, it\u2019s hard to start with anything more\nconcrete if an architect designs a system from scratch. The likelihood of achieving a\ngood design from this initial set of components is disparagingly small, which is why\narchitects must iterate on component design to improve it.\n108 \n| \nChapter 8: Component-Based Thinking\n", "page": 128, "type": "text", "section": "Page 128"}
{"text": "Assign Requirements to Components\nOnce an architect has identified initial components, the next step aligns requirements\n(or user stories) to those components to see how well they fit. This may entail creat\u2010\ning new components, consolidating existing ones, or breaking components apart\nbecause they have too much responsibility. This mapping doesn\u2019t have to be exact\u2014\nthe architect is attempting to find a good coarse-grained substrate to allow further\ndesign and refinement by architects, tech leads, and/or developers.\nAnalyze Roles and Responsibilities\nWhen assigning stories to components, the architect also looks at the roles and\nresponsibilities elucidated during the requirements to make sure that the granularity\nmatches. Thinking about both the roles and behaviors the application must support\nallows the architect to align the component and domain granularity. One of the great\u2010\nest challenges for architects entails discovering the correct granularity for compo\u2010\nnents, which encourages the iterative approach described here.\nAnalyze Architecture Characteristics\nWhen assigning requirements to components, the architect should also look at the\narchitecture characteristics discovered earlier in order to think about how they might\nimpact component division and granularity. For example, while two parts of a system\nmight deal with user input, the part that deals with hundreds of concurrent users will\nneed different architecture characteristics than another part that needs to support\nonly a few. Thus, while a purely functional view of component design might yield a\nsingle component to handle user interaction, analyzing the architecture characteris\u2010\ntics will lead to a subdivision.\nRestructure Components\nFeedback is critical in software design. Thus, architects must continually iterate on\ntheir component design with developers. Designing software provides all kinds of\nunexpected difficulties\u2014no one can anticipate all the unknown issues that usually\noccur during software projects. Thus, an iterative approach to component design is\nkey. First, it\u2019s virtually impossible to account for all the different discoveries and edge\ncases that will arise that encourage redesign. Secondly, as the architecture and devel\u2010\nopers delve more deeply into building the application, they gain a more nuanced\nunderstanding of where behavior and roles should lie.\nComponent Identification Flow \n| \n109\n", "page": 129, "type": "text", "section": "Page 129"}
{"text": "Component Granularity\nFinding the proper granularity for components is one of an architect\u2019s most difficult\ntasks. Too fine-grained a component design leads to too much communication\nbetween components to achieve results. Too coarse-grained components encourage\nhigh internal coupling, which leads to difficulties in deployability and testability, as\nwell as modularity-related negative side effects.\nComponent Design\nNo accepted \u201ccorrect\u201d way exists to design components. Rather, a wide variety of\ntechniques exist, all with various trade-offs. In all processes, an architect takes\nrequirements and tries to determine what coarse-grained building blocks will make\nup the application. Lots of different techniques exist, all with varying trade-offs and\ncoupled to the software development process used by the team and organization.\nHere, we talk about a few general ways to discover components and traps to avoid.\nDiscovering Components\nArchitects, often in collaboration with other roles such as developers, business ana\u2010\nlysts, and subject matter experts, create an initial component design based on general\nknowledge of the system and how they choose to decompose it, based on technical or\ndomain partitioning. The team goal is an initial design that partitions the problem\nspace into coarse chunks that take into account differing architecture characteristics.\nEntity trap\nWhile there is no one true way to ascertain components, a common anti-pattern\nlurks: the entity trap. Say that an architect is working on designing components for\nour kata Going, Going, Gone and ends up with a design resembling Figure 8-9.\nFigure 8-9. Building an architecture as an object-relational mapping\n110 \n| \nChapter 8: Component-Based Thinking\n", "page": 130, "type": "text", "section": "Page 130"}
{"text": "In Figure 8-9, the architect has basically taken each entity identified in the require\u2010\nments and made a Manager component based on that entity. This isn\u2019t an architecture;\nit\u2019s an object-relational mapping (ORM) of a framework to a database. In other\nwords, if a system only needs simple database CRUD operations (create, read, update,\ndelete), then the architect can download a framework to create user interfaces directly\nfrom the database. Many popular ORM frameworks exist to solve this common\nCRUD behavior.\nNaked Objects and Similar Frameworks\nMore than a decade ago, a family of frameworks appeared that makes building simple\nCRUD applications trivial, exemplified by Naked Objects (which has since split into\ntwo projects, a .NET version still called NakedObjects, and a Java version that moved\nto the Apache open source foundation under the name Isis). The premise behind\nthese frameworks offers to build a user interface frontend on database entities. For\nexample, in Naked Objects, the developer points the framework to database tables,\nand the framework builds a user interface based on the tables and their defined rela\u2010\ntionships.\nSeveral other popular frameworks exist that basically provide a default user interface\nbased on database table structure: the scaffolding feature of the Ruby on Rails frame\u2010\nwork provides the same kind of default mappings from website to database (with\nmany options to extend and add sophistication to the resulting application).\nIf an architect\u2019s needs require merely a simple mapping from a database to a user\ninterface, full-blown architecture isn\u2019t necessary; one of these frameworks will suffice.\nThe entity trap anti-pattern arises when an architect incorrectly identifies the data\u2010\nbase relationships as workflows in the application, a correspondence that rarely man\u2010\nifests in the real world. Rather, this anti-pattern generally indicates lack of thought\nabout the actual workflows of the application. Components created with the entity\ntrap also tend to be too coarse-grained, offering no guidance whatsoever to the devel\u2010\nopment team in terms of the packaging and overall structuring of the source code.\nActor/Actions approach\nThe actor/actions approach is a popular way that architects use to map requirements\nto components. In this approach, originally defined by the Rational Unified Process,\narchitects identify actors who perform activities with the application and the actions\nthose actors may perform. It provides a technique for discovering the typical users of\nthe system and what kinds of things they might do with the system.\nThe actor/actions approach became popular in conjunction with particular software\ndevelopment processes, especially more formal processes that favor a significant por\u2010\nComponent Design \n| \n111\n", "page": 131, "type": "text", "section": "Page 131"}
{"text": "tion of upfront design. It is still popular and works well when the requirements fea\u2010\nture distinct roles and the kinds of actions they can perform. This style of component\ndecomposition works well for all types of systems, monolithic or distributed.\nEvent storming\nEvent storming as a component discovery technique comes from domain-driven\ndesign (DDD) and shares popularity with microservices, also heavily influenced by\nDDD. In event storming, the architect assumes the project will use messages and/or\nevents to communicate between the various components. To that end, the team tries\nto determine which events occur in the system based on requirements and identified\nroles, and build components around those event and message handlers. This works\nwell in distributed architectures like microservices that use events and messages,\nbecause it helps architects define the messages used in the eventual system.\nWorkflow approach\nAn alternative to event storming offers a more generic approach for architects not\nusing DDD or messaging. The workflow approach models the components around\nworkflows, much like event storming, but without the explicit constraints of building\na message-based system. A workflow approach identifies the key roles, determines\nthe kinds of workflows these roles engage in, and builds components around the\nidentified activities.\nNone of these techniques is superior to the others; all offer a different set of trade-\noffs. If a team uses a waterfall approach or other older software development pro\u2010\ncesses, they might prefer the Actor/Actions approach because it is general. When\nusing DDD and corresponding architectures like microservices, event storming\nmatches the software development process exactly.\nCase Study: Going, Going, Gone: Discovering Components\nIf a team has no special constraints and is looking for a good general-purpose compo\u2010\nnent decomposition, the Actor/Actions approach works well as a generic solution. It\u2019s\nthe one we use in our case study for Going, Going, Gone.\nIn Chapter 7, we introduced the architecture kata for Going, Going, Gone (GGG) and\ndiscovered architecture characteristics for this system. This system has three obvious\nroles: the bidder, the auctioneer, and a frequent participant in this modeling techni\u2010\nque, the system, for internal actions. The roles interact with the application, repre\u2010\nsented here by the system, which identifies when the application initiates an event\nrather than one of the roles. For example, in GGG, once the auction is complete, the\nsystem triggers the payment system to process payments.\n112 \n| \nChapter 8: Component-Based Thinking\n", "page": 132, "type": "text", "section": "Page 132"}
{"text": "We can also identify a starting set of actions for each of these roles:\nBidder\nView live video stream, view live bid stream, place a bid\nAuctioneer\nEnter live bids into system, receive online bids, mark item as sold\nSystem\nStart auction, make payment, track bidder activity\nGiven these actions, we can iteratively build a set of starter components for GGG; one\nsuch solution appears in Figure 8-10.\nFigure 8-10. Initial set of components for Going, Going, Gone\nIn Figure 8-10, each of the roles and actions maps to a component, which in turn may\nneed to collaborate on information. These are the components we identified for this\nsolution:\nVideoStreamer\nStreams a live auction to users.\nBidStreamer\nStreams bids as they occur to the users. Both VideoStreamer and BidStreamer\noffer read-only views of the auction to the bidder.\nCase Study: Going, Going, Gone: Discovering Components \n| \n113\n", "page": 133, "type": "text", "section": "Page 133"}
{"text": "BidCapture\nThis component captures bids from both the auctioneer and bidders.\nBidTracker\nTracks bids and acts as the system of record.\nAuctionSession\nStarts and stops an auction. When the bidder ends the auction, performs the pay\u2010\nment and resolution steps, including notifying bidders of ending.\nPayment\nThird-party payment processor for credit card payments.\nReferring to the component identification flow diagram in Figure 8-8, after the initial\nidentification of components, the architect next analyzes architecture characteristics\nto determine if that will change the design. For this system, the architect can defi\u2010\nnitely identify different sets of architecture characteristics. For example, the current\ndesign features a BidCapture component to capture bids from both bidders and the\nauctioneer, which makes sense functionally: capturing bids from anyone can be han\u2010\ndled the same. However, what about architecture characteristics around bid capture?\nThe auctioneer doesn\u2019t need the same level of scalability or elasticity as potentially\nthousands of bidders. By the same token, an architect must ensure that architecture\ncharacteristics like reliability (connections don\u2019t drop) and availability (the system is\nup) for the auctioneer could be higher than other parts of the system. For example,\nwhile it\u2019s bad for business if a bidder can\u2019t log in to the site or if they suffer from a\ndropped connection, it\u2019s disastrous to the auction if either of those things happen to\nthe auctioneer.\nBecause they have differing levels of architecture characteristics, the architect decides\nto split the Bid Capture component into Bid Capture and Auctioneer Capture so\nthat each of the two components can support differing architecture characteristics. \nThe updated design appears in Figure 8-11.\nThe architect creates a new component for Auctioneer Capture and updates infor\u2010\nmation links to both Bid Streamer (so that online bidders see the live bids) and Bid\nTracker, which is managing the bid streams. Note that Bid Tracker is now the com\u2010\nponent that will unify the two very different information streams: the single stream of\ninformation from the auctioneer and the multiple streams from bidders.\n114 \n| \nChapter 8: Component-Based Thinking\n", "page": 134, "type": "text", "section": "Page 134"}
{"text": "Figure 8-11. Incorporating architecture characteristics into GGG component design\nThe design shown in Figure 8-11 isn\u2019t likely the final design. More requirements must\nbe uncovered (how do people register, administration functions around payment, and\nso on). However, this example provides a good starting point to start iterating further\non the design.\nThis is one possible set of components to solve the GGG problem\u2014but it\u2019s not neces\u2010\nsarily correct, nor is it the only one. Few software systems have only one way that\ndevelopers can implement them; every design has different sets of trade-offs. As an\narchitect, don\u2019t obsess over finding the one true design, because many will suffice\n(and less likely overengineered). Rather, try to objectively assess the trade-offs\nbetween different design decisions, and choose the one that has the least worst set of\ntrade-offs.\nArchitecture Quantum Redux: Choosing Between\nMonolithic Versus Distributed Architectures\nRecalling the discussion defining architecture quantum in \u201cArchitectural Quanta and\nGranularity\u201d on page 92, the architecture quantum defines the scope of architecture\ncharacteristics. That in turn leads an architect toward an important decision as they\nfinish their initial component design: should the architecture be monolithic or\ndistributed?\nArchitecture Quantum Redux: Choosing Between Monolithic Versus Distributed Architectures \n| \n115\n", "page": 135, "type": "text", "section": "Page 135"}
{"text": "A monolithic architecture typically features a single deployable unit, including all\nfunctionality of the system that runs in the process, typically connected to a single\ndatabase. Types of monolithic architectures include the layered and modular mono\u2010\nlith, discussed fully in Chapter 10. A distributed architecture is the opposite\u2014the\napplication consists of multiple services running in their own ecosystem, communi\u2010\ncating via networking protocols. Distributed architectures may feature finer-grained\ndeployment models, where each service may have its own release cadence and engi\u2010\nneering practices, based on the development team and their priorities.\nEach architecture style offers a variety of trade-offs, covered in Part II. However, the\nfundamental decision rests on how many quanta the architecture discovers during\nthe design process. If the system can manage with a single quantum (in other words,\none set of architecture characteristics), then a monolith architecture offers many\nadvantages. On the other hand, differing architecture characteristics for components,\nas illustrated in the GGG component analysis, requires a distributed architecture to\naccommodate differing architecture characteristics. For example, the VideoStreamer\nand BidStreamer both offer read-only views of the auction to bidders. From a design\nstandpoint, an architect would rather not deal with read-only streaming mixed with\nhigh-scale updates. Along with the aforementioned differences between bidder and\nauctioneer, these differing characteristics lead an architect to choose a distributed\narchitecture.\nThe ability to determine a fundamental design characteristic of architecture (mono\u2010\nlith versus distributed) early in the design process highlights one of the advantages of\nusing the architecture quantum as a way of analyzing architecture characteristics\nscope and coupling.\n116 \n| \nChapter 8: Component-Based Thinking\n", "page": 136, "type": "text", "section": "Page 136"}
{"text": "PART II\nArchitecture Styles\nThe difference between an architecture style and an architecture pattern can be con\u2010\nfusing. We define an architecture style as the overarching structure of how the user\ninterface and backend source code are organized (such as within layers of a mono\u2010\nlithic deployment or separately deployed services) and how that source code interacts\nwith a datastore. Architecture patterns, on the other hand, are lower-level design\nstructures that help form specific solutions within an architecture style (such as how\nto achieve high scalability or high performance within a set of operations or between\nsets of services).\nUnderstanding architecture styles occupies much of the time and effort for new\narchitects because they share importance and abundance. Architects must under\u2010\nstand the various styles and the trade-offs encapsulated within each to make effective\ndecisions; each architecture style embodies a well-known set of trade-offs that help an\narchitect make the right choice for a particular business problem.\n", "page": 137, "type": "text", "section": "Page 137"}
{"text": "CHAPTER 9\nFoundations\nArchitecture styles, sometimes called architecture patterns, describe a named rela\u2010\ntionship of components covering a variety of architecture characteristics. An archi\u2010\ntecture style name, similar to design patterns, creates a single name that acts as\nshorthand between experienced architects. For example, when an architect talks\nabout a layered monolith, their target in the conversation understands aspects of\nstructure, which kinds of architecture characteristics work well (and which ones can\ncause problems), typical deployment models, data strategies, and a host of other\ninformation. Thus, architects should be familiar with the basic names of fundamental\ngeneric architecture styles.\nEach name captures a wealth of understood detail, one of the purposes of design pat\u2010\nterns. An architecture style describes the topology, assumed and default architecture\ncharacteristics, both beneficial and detrimental. We cover many common modern\narchitecture patterns in the remainder of this section of the book (Part II). However,\narchitects should be familiar with several fundamental patterns that appear embed\u2010\nded within the larger patterns.\nFundamental Patterns\nSeveral fundamental patterns appear again and again throughout the history of soft\u2010\nware architecture because they provide a useful perspective on organizing code,\ndeployments, or other aspects of architecture. For example, the concept of layers in\narchitecture, separating different concerns based on functionality, is as old as soft\u2010\nware itself. Yet, the layered pattern continues to manifest in different guises, including\nmodern variants discussed in Chapter 10.\n119\n", "page": 139, "type": "text", "section": "Page 139"}
{"text": "1 Made with a now-retired tool called XRay, an Eclipse plug-in.\nBig Ball of Mud\nArchitects refer to the absence of any discernible architecture structure as a Big Ball of\nMud, named after the eponymous anti-pattern defined in a paper released in 1997 by\nBrian Foote and Joseph Yoder:\nA Big Ball of Mud is a haphazardly structured, sprawling, sloppy, duct-tape-and-baling-\nwire, spaghetti-code jungle. These systems show unmistakable signs of unregulated\ngrowth, and repeated, expedient repair. Information is shared promiscuously among\ndistant elements of the system, often to the point where nearly all the important infor\u2010\nmation becomes global or duplicated.\nThe overall structure of the system may never have been well defined.\nIf it was, it may have eroded beyond recognition. Programmers with a shred of archi\u2010\ntectural sensibility shun these quagmires. Only those who are unconcerned about\narchitecture, and, perhaps, are comfortable with the inertia of the day-to-day chore of\npatching the holes in these failing dikes, are content to work on such systems.\n\u2014Brian Foote and Joseph Yoder\nIn modern terms, a big ball of mud might describe a simple scripting application with\nevent handlers wired directly to database calls, with no real internal structure. Many\ntrivial applications start like this then become unwieldy as they continue to grow.\nIn general, architects want to avoid this type of architecture at all costs. The lack of\nstructure makes change increasingly difficult. This type of architecture also suffers\nfrom problems in deployment, testability, scalability, and performance.\nUnfortunately, this architecture anti-pattern occurs quite commonly in the real\nworld. Few architects intend to create one, but many projects inadvertently manage\nto create a mess because of lack of governance around code quality and structure. For\nexample, Neal worked with a client project whose structure appears in Figure 9-1.\nThe client (whose name is withheld for obvious reasons) created a Java-based web\napplication as quickly as possible over several years. The technical visualization1\nshows their architectural coupling: each dot on the perimeter of the circle represents\na class, and each line represents connections between the classes, where bolder lines\nindicate stronger connections. In this code base, any change to a class makes it diffi\u2010\ncult to predict rippling side effects to other classes, making change a terrifying affair.\n120 \n| \nChapter 9: Foundations\n", "page": 140, "type": "text", "section": "Page 140"}
{"text": "Figure 9-1. A Big Ball of Mud architecture visualized from a real code base\nUnitary Architecture\nWhen software originated, there was only the computer, and software ran on it.\nThrough the various eras of hardware and software evolution, the two started as a\nsingle entity, then split as the need for more sophisticated capabilities grew. For exam\u2010\nple, mainframe computers started as singular systems, then gradually separated data\ninto its own kind of system. Similarly, when personal computers first appeared, much\nof the commercial development focused on single machines. As networking PCs\nbecame common, distributed systems (such as client/server) appeared.\nFew unitary architectures exist outside embedded systems and other highly con\u2010\nstrained environments. Generally, software systems tend to grow in functionality over\ntime, requiring separation of concerns to maintain operational architecture charac\u2010\nteristics, such as performance and scale.\nClient/Server\nOver time, various forces required partitioning away from a single system; how to do\nthat forms the basis for many of these styles. Many architecture styles deal with how\nto efficiently separate parts of the system.\nA fundamental style in architecture separates technical functionality between front\u2010\nend and backend, called a two-tier, or client/server, architecture. Many different fla\u2010\nvors of this architecture exist, depending on the era and computing capabilities.\nFundamental Patterns \n| \n121\n", "page": 141, "type": "text", "section": "Page 141"}
{"text": "Desktop + database server\nAn early personal computer architecture encouraged developers to write rich desktop\napplications in user interfaces like Windows, separating the data into a separate data\u2010\nbase server. This architecture coincided with the appearance of standalone database\nservers that could connect via standard network protocols. It allowed presentation\nlogic to reside on the desktop, while the more computationally intense action (both in\nvolume and complexity) occurred on more robust database servers.\nBrowser + web server\nOnce modern web development arrived, the common split became web browser con\u2010\nnected to web server (which in turn was connected to a database server). The separa\u2010\ntion of responsibilities was similar to the desktop variant but with even thinner\nclients as browsers, allowing a wider distribution both inside and outside firewalls.\nEven though the database is separate from the web server, architects often still con\u2010\nsider this a two-tier architecture because the web and database servers run on one\nclass of machine within the operations center and the user interface runs on the user\u2019s\nbrowser.\nThree-tier\nAn architecture that became quite popular during the late 1990s was a three-tier\narchitecture, which provided even more layers of separation. As tools like application\nservers became popular in Java and .NET, companies started building even more lay\u2010\ners in their topology: a database tier using an industrial-strength database server, an\napplication tier managed by an application server, frontend coded in generated\nHTML, and increasingly, JavaScript, as its capabilities expanded.\nThe three-tier architecture corresponded with network-level protocols such as Com\u2010\nmon Object Request Broker Architecture (CORBA) and Distributed Component\nObject Model (DCOM) that facilitated building distributed architectures.\nJust as developers today don\u2019t worry about how network protocols like TCP/IP work\n(they just work), most architects don\u2019t have to worry about this level of plumbing in\ndistributed architectures. The capabilities offered by such tools in that era exist today\nas either tools (like message queues) or architecture patterns (such as event-driven\narchitecture, covered in Chapter 14).\n122 \n| \nChapter 9: Foundations\n", "page": 142, "type": "text", "section": "Page 142"}
{"text": "Three-Tier, Language Design, and Long-Term Implications\nDuring the era in which the Java language was designed, three-tier computing was all\nthe rage. Thus, it was assumed that, in the future, all systems would be three-tier\narchitectures. One of the common headaches with existing languages such as C++\nwas how cumbersome it was to move objects over the network in a consistent way\nbetween systems. Thus, the designers of Java decided to build this capability into the\ncore of the language using a mechanism called serialization. Every Object in Java\nimplements an interface that requires it to support serialization. The designers figured\nthat since three-tiered architecture would forever be the architecture style, baking it\ninto the language would offer a great convenience. Of course, that architectural style\ncame and went, yet the leftovers appear in Java to this day, greatly frustrating the lan\u2010\nguage designer who wants to add modern features that, for backward compatibility,\nmust support serialization, which virtually no one uses today.\nUnderstanding the long-term implications of design decisions has always eluded us,\nin software, as in other engineering disciplines. The perpetual advice to favor simple\ndesigns is in many ways defense against future consequences.\nMonolithic Versus Distributed Architectures\nArchitecture styles can be classified into two main types: monolithic (single deploy\u2010\nment unit of all code) and distributed (multiple deployment units connected through\nremote access protocols). While no classification scheme is perfect, distributed archi\u2010\ntectures all share a common set of challenges and issues not found in the monolithic\narchitecture styles, making this classification scheme a good separation between the\nvarious architecture styles. In this book we will describe in detail the following archi\u2010\ntecture styles:\nMonolithic\n\u2022 Layered architecture (Chapter 10)\n\u2022 Pipeline architecture (Chapter 11)\n\u2022 Microkernel architecture (Chapter 12)\nDistributed\n\u2022 Service-based architecture (Chapter 13)\n\u2022 Event-driven architecture (Chapter 14)\n\u2022 Space-based architecture (Chapter 15)\n\u2022 Service-oriented architecture (Chapter 16)\n\u2022 Microservices architecture (Chapter 17)\nMonolithic Versus Distributed Architectures \n| \n123\n", "page": 143, "type": "text", "section": "Page 143"}
{"text": "Distributed architecture styles, while being much more powerful in terms of perfor\u2010\nmance, scalability, and availability than monolithic architecture styles, have signifi\u2010\ncant trade-offs for this power. The first group of issues facing all distributed\narchitectures are described in the fallacies of distributed computing, first coined by L.\nPeter Deutsch and other colleagues from Sun Microsystems in 1994. A fallacy is\nsomething that is believed or assumed to be true but is not. All eight of the fallacies of\ndistributed computing apply to distributed architectures today. The following sec\u2010\ntions describe each fallacy.\nFallacy #1: The Network Is Reliable\nFigure 9-2. The network is not reliable\nDevelopers and architects alike assume that the network is reliable, but it is not.\nWhile networks have become more reliable over time, the fact of the matter is that\nnetworks still remain generally unreliable. This is significant for all distributed archi\u2010\ntectures because all distributed architecture styles rely on the network for communi\u2010\ncation to and from services, as well as between services. As illustrated in Figure 9-2,\nService B may be totally healthy, but Service A cannot reach it due to a network\nproblem; or even worse, Service A made a request to Service B to process some\ndata and does not receive a response because of a network issue. This is why things\nlike timeouts and circuit breakers exist between services. The more a system relies on\nthe network (such as microservices architecture), the potentially less reliable it\nbecomes.\n124 \n| \nChapter 9: Foundations\n", "page": 144, "type": "text", "section": "Page 144"}
{"text": "Fallacy #2: Latency Is Zero\nFigure 9-3. Latency is not zero\nAs Figure 9-3 shows, when a local call is made to another component via a method or\nfunction call, that time (t_local) is measured in nanoseconds or microseconds.\nHowever, when that same call is made through a remote access protocol (such as\nREST, messaging, or RPC), the time measured to access that service (t_remote) is\nmeasured in milliseconds. Therefore, t_remote will always be greater that t_local.\nLatency in any distributed architecture is not zero, yet most architects ignore this fal\u2010\nlacy, insisting that they have fast networks. Ask yourself this question: do you know\nwhat the average round-trip latency is for a RESTful call in your production environ\u2010\nment? Is it 60 milliseconds? Is it 500 milliseconds?\nWhen using any distributed architecture, architects must know this latency average. It\nis the only way of determining whether a distributed architecture is feasible, particu\u2010\nlarly when considering microservices (see Chapter 17) due to the fine-grained nature\nof the services and the amount of communication between those services. Assuming\nan average of 100 milliseconds of latency per request, chaining together 10 service\ncalls to perform a particular business function adds 1,000 milliseconds to the request!\nKnowing the average latency is important, but even more important is also knowing\nthe 95th to 99th percentile. While an average latency might yield only 60 milliseconds\n(which is good), the 95th percentile might be 400 milliseconds! It\u2019s usually this \u201clong\ntail\u201d latency that will kill performance in a distributed architecture. In most cases,\narchitects can get latency values from a network administrator (see \u201cFallacy #6: There\nIs Only One Administrator\u201d on page 129).\nMonolithic Versus Distributed Architectures \n| \n125\n", "page": 145, "type": "text", "section": "Page 145"}
{"text": "Fallacy #3: Bandwidth Is Infinite\nFigure 9-4. Bandwidth is not infinite\nBandwidth is usually not a concern in monolithic architectures, because once pro\u2010\ncessing goes into a monolith, little or no bandwidth is required to process that busi\u2010\nness request. However, as shown in Figure 9-4, once systems are broken apart into\nsmaller deployment units (services) in a distributed architecture such as microservi\u2010\nces, communication to and between these services significantly utilizes bandwidth,\ncausing networks to slow down, thus impacting latency (fallacy #2) and reliability\n(fallacy #1).\nTo illustrate the importance of this fallacy, consider the two services shown in\nFigure 9-4. Let\u2019s say the lefthand service manages the wish list items for the website,\nand the righthand service manages the customer profile. Whenever a request for a\nwish list comes into the lefthand service, it must make an interservice call to the\nrighthand customer profile service to get the customer name because that data is\nneeded in the response contract for the wish list, but the wish list service on the left\u2010\nhand side doesn\u2019t have the name. The customer profile service returns 45 attributes\ntotaling 500 kb to the wish list service, which only needs the name (200 bytes). This is\na form of coupling referred to as stamp coupling. This may not sound significant, but\nrequests for the wish list items happen about 2,000 times a second. This means that\nthis interservice call from the wish list service to the customer profile service happens\n2,000 times a second. At 500 kb for each request, the amount of bandwidth used for\nthat one interservice call (out of hundreds being made that second) is 1 Gb!\nStamp coupling in distributed architectures consumes significant amounts of band\u2010\nwidth. If the customer profile service were to only pass back the data needed by the\nwish list service (in this case 200 bytes), the total bandwidth used to transmit the data\nis only 400 kb. Stamp coupling can be resolved in the following ways:\n126 \n| \nChapter 9: Foundations\n", "page": 146, "type": "text", "section": "Page 146"}
{"text": "\u2022 Create private RESTful API endpoints\n\u2022 Use field selectors in the contract\n\u2022 Use GraphQL to decouple contracts\n\u2022 Use value-driven contracts with consumer-driven contracts (CDCs)\n\u2022 Use internal messaging endpoints\nRegardless of the technique used, ensuring that the minimal amount of data is passed\nbetween services or systems in a distributed architecture is the best way to address\nthis fallacy.\nFallacy #4: The Network Is Secure\nFigure 9-5. The network is not secure\nMost architects and developers get so comfortable using virtual private networks\n(VPNs), trusted networks, and firewalls that they tend to forget about this fallacy of\ndistributed computing: the network is not secure. Security becomes much more chal\u2010\nlenging in a distributed architecture. As shown in Figure 9-5, each and every end\u2010\npoint to each distributed deployment unit must be secured so that unknown or bad\nrequests do not make it to that service. The surface area for threats and attacks\nincreases by magnitudes when moving from a monolithic to a distributed architec\u2010\nture. Having to secure every endpoint, even when doing interservice communication,\nis another reason performance tends to be slower in synchronous, highly-distributed\narchitectures such as microservices or service-based architecture.\nMonolithic Versus Distributed Architectures \n| \n127\n", "page": 147, "type": "text", "section": "Page 147"}
{"text": "Fallacy #5: The Topology Never Changes\nFigure 9-6. The network topology always changes\nThis fallacy refers to the overall network topology, including all of the routers, hubs,\nswitches, firewalls, networks, and appliances used within the overall network. Archi\u2010\ntects assume that the topology is fixed and never changes. Of course it changes. It\nchanges all the time. What is the significance of this fallacy?\nSuppose an architect comes into work on a Monday morning, and everyone is run\u2010\nning around like crazy because services keep timing out in production. The architect\nworks with the teams, frantically trying to figure out why this is happening. No new\nservices were deployed over the weekend. What could it be? After several hours the\narchitect discovers that a minor network upgrade happened at 2 a.m. that morning.\nThis supposedly \u201cminor\u201d network upgrade invalidated all of the latency assumptions,\ntriggering timeouts and circuit breakers.\nArchitects must be in constant communication with operations and network admin\u2010\nistrators to know what is changing and when so that they can make adjustments\naccordingly to reduce the type of surprise previously described. This may seem obvi\u2010\nous and easy, but it is not. As a matter of fact, this fallacy leads directly to the next\nfallacy.\n128 \n| \nChapter 9: Foundations\n", "page": 148, "type": "text", "section": "Page 148"}
{"text": "Fallacy #6: There Is Only One Administrator\nFigure 9-7. There are many network administrators, not just one\nArchitects all the time fall into this fallacy, assuming they only need to collaborate\nand communicate with one administrator. As shown in Figure 9-7, there are dozens\nof network administrators in a typical large company. Who should the architect talk\nto with regard to latency (\u201cFallacy #2: Latency Is Zero\u201d on page 125) or topology\nchanges (\u201cFallacy #5: The Topology Never Changes\u201d on page 128)? This fallacy points\nto the complexity of distributed architecture and the amount of coordination that\nmust happen to get everything working correctly. Monolithic applications do not\nrequire this level of communication and collaboration due to the single deployment\nunit characteristics of those architecture styles.\nMonolithic Versus Distributed Architectures \n| \n129\n", "page": 149, "type": "text", "section": "Page 149"}
{"text": "Fallacy #7: Transport Cost Is Zero\nFigure 9-8. Remote access costs money\nMany software architects confuse this fallacy for latency (\u201cFallacy #2: Latency Is Zero\u201d\non page 125). Transport cost here does not refer to latency, but rather to actual cost in\nterms of money associated with making a \u201csimple RESTful call.\u201d Architects assume\n(incorrectly) that the necessary infrastructure is in place and sufficient for making a\nsimple RESTful call or breaking apart a monolithic application. It is usually not. Dis\u2010\ntributed architectures cost significantly more than monolithic architectures, primar\u2010\nily due to increased needs for additional hardware, servers, gateways, firewalls, new\nsubnets, proxies, and so on.\nWhenever embarking on a distributed architecture, we encourage architects to ana\u2010\nlyze the current server and network topology with regard to capacity, bandwidth,\nlatency, and security zones to not get caught up in the trap of surprise with this\nfallacy.\n130 \n| \nChapter 9: Foundations\n", "page": 150, "type": "text", "section": "Page 150"}
{"text": "Fallacy #8: The Network Is Homogeneous\nFigure 9-9. The network is not homogeneous\nMost architects and developers assume a network is homogeneous\u2014made up by only\none network hardware vendor. Nothing could be farther from the truth. Most compa\u2010\nnies have multiple network hardware vendors in their infrastructure, if not more.\nSo what? The significance of this fallacy is that not all of those heterogeneous hard\u2010\nware vendors play together well. Most of it works, but does Juniper hardware\nseamlessly integrate with Cisco hardware? Networking standards have evolved over\nthe years, making this less of an issue, but the fact remains that not all situations,\nload, and circumstances have been fully tested, and as such, network packets occa\u2010\nsionally get lost. This in turn impacts network reliability (\u201cFallacy #1: The Network Is\nReliable\u201d on page 124), latency assumptions and assertions (\u201cFallacy #2: Latency Is\nZero\u201d on page 125), and assumptions made about the bandwidth (\u201cFallacy #3: Band\u2010\nwidth Is Infinite\u201d on page 126). In other words, this fallacy ties back into all of the\nother fallacies, forming an endless loop of confusion and frustration when dealing\nwith networks (which is necessary when using distributed architectures).\nOther Distributed Considerations\nIn addition to the eight fallacies of distributed computing previously described, there\nare other issues and challenges facing distributed architecture that aren\u2019t present in\nmonolithic architectures. Although the details of these other issues are out of scope\nfor this book, we list and summarize them in the following sections.\nDistributed logging\nPerforming root-cause analysis to determine why a particular order was dropped is\nvery difficult and time-consuming in a distributed architecture due to the distribu\u2010\ntion of application and system logs. In a monolithic application there is typically only\none log, making it easier to trace a request and determine the issue. However, dis\u2010\ntributed architectures contain dozens to hundreds of different logs, all located in a\nMonolithic Versus Distributed Architectures \n| \n131\n", "page": 151, "type": "text", "section": "Page 151"}
{"text": "different place and all with a different format, making it difficult to track down a\nproblem.\nLogging consolidation tools such as Splunk help to consolidate information from var\u2010\nious sources and systems together into one consolidated log and console, but these\ntools only scratch the surface of the complexities involved with distributed logging.\nDetailed solutions and patterns for distributed logging are outside the scope of this\nbook.\nDistributed transactions\nArchitects and developers take transactions for granted in a monolithic architecture\nworld because they are so straightforward and easy to manage. Standard commits and\nrollbacks executed from persistence frameworks leverage ACID (atomicity, consis\u2010\ntency, isolation, durability) transactions to guarantee that the data is updated in a cor\u2010\nrect way to ensure high data consistency and integrity. Such is not the case with\ndistributed architectures.\nDistributed architectures rely on what is called eventual consistency to ensure the data\nprocessed by separate deployment units is at some unspecified point in time all\nsynchronized into a consistent state. This is one of the trade-offs of distributed\narchitecture: high scalability, performance, and availability at the sacrifice of data\nconsistency and data integrity.\nTransactional sagas are one way to manage distributed transactions. Sagas utilize\neither event sourcing for compensation or finite state machines to manage the state of\ntransaction. In addition to sagas, BASE transactions are used. BASE stands for (B)asic\navailability, (S)oft state, and (E)ventual consistency. BASE transactions are not a piece\nof software, but rather a technique. Soft state in BASE refers to the transit of data\nfrom a source to a target, as well as the inconsistency between data sources. Based on\nthe basic availability of the systems or services involved, the systems will eventually\nbecome consistent through the use of architecture patterns and messaging.\nContract maintenance and versioning\nAnother particularly difficult challenge within distributed architecture is contract\ncreation, maintenance, and versioning. A contract is behavior and data that is agreed\nupon by both the client and the service. Contract maintenance is particularly difficult\nin distributed architectures, primarily due to decoupled services and systems owned\nby different teams and departments. Even more complex are the communication\nmodels needed for version deprecation.\n132 \n| \nChapter 9: Foundations\n", "page": 152, "type": "text", "section": "Page 152"}
{"text": "CHAPTER 10\nLayered Architecture Style\nThe layered architecture, also known as the n-tiered architecture style, is one of the\nmost common architecture styles. This style of architecture is the de facto standard\nfor most applications, primarily because of its simplicity, familiarity, and low cost. It is\nalso a very natural way to develop applications due to Conway\u2019s law, which states that\norganizations that design systems are constrained to produce designs which are\ncopies of the communication structures of these organizations. In most organizations\nthere are user interface (UI) developers, backend developers, rules developers, and\ndatabase experts (DBAs). These organizational layers fit nicely into the tiers of a tra\u2010\nditional layered architecture, making it a natural choice for many business applica\u2010\ntions. The layered architecture style also falls into several architectural anti-patterns,\nincluding the architecture by implication anti-pattern and the accidental architecture\nanti-pattern. If a developer or architect is unsure which architecture style they are\nusing, or if an Agile development team \u201cjust starts coding,\u201d chances are good that it is\nthe layered architecture style they are implementing.\nTopology\nComponents within the layered architecture style are organized into logical horizon\u2010\ntal layers, with each layer performing a specific role within the application (such as\npresentation logic or business logic). Although there are no specific restrictions in\nterms of the number and types of layers that must exist, most layered architectures\nconsist of four standard layers: presentation, business, persistence, and database, as\nillustrated in Figure 10-1. In some cases, the business layer and persistence layer are\ncombined into a single business layer, particularly when the persistence logic (such as\nSQL or HSQL) is embedded within the business layer components. Thus, smaller\napplications may have only three layers, whereas larger and more complex business\napplications may contain five or more layers.\n133\n", "page": 153, "type": "text", "section": "Page 153"}
{"text": "Figure 10-1. Standard logical layers within the layered architecture style\nFigure 10-2 illustrates the various topology variants from a physical layering (deploy\u2010\nment) perspective. The first variant combines the presentation, business, and persis\u2010\ntence layers into a single deployment unit, with the database layer typically\nrepresented as a separate external physical database (or filesystem). The second var\u2010\niant physically separates the presentation layer into its own deployment unit, with the\nbusiness and persistence layers combined into a second deployment unit. Again, with\nthis variant, the database layer is usually physically separated through an external\ndatabase or filesystem. A third variant combines all four standard layers into a single\ndeployment, including the database layer. This variant might be useful for smaller\napplications with either an internally embedded database or an in-memory database. \nMany on-premises (\u201con-prem\u201d) products are built and delivered to customers using\nthis third variant.\nFigure 10-2. Physical topology (deployment) variants\nEach layer of the layered architecture style has a specific role and responsibility\nwithin the architecture. For example, the presentation layer would be responsible for\nhandling all user interface and browser communication logic, whereas the business\nlayer would be responsible for executing specific business rules associated with the\n134 \n| \nChapter 10: Layered Architecture Style\n", "page": 154, "type": "text", "section": "Page 154"}
{"text": "request. Each layer in the architecture forms an abstraction around the work that\nneeds to be done to satisfy a particular business request. For example, the presenta\u2010\ntion layer doesn\u2019t need to know or worry about how to get customer data; it only\nneeds to display that information on a screen in a particular format. Similarly, the\nbusiness layer doesn\u2019t need to be concerned about how to format customer data for\ndisplay on a screen or even where the customer data is coming from; it only needs to\nget the data from the persistence layer, perform business logic against the data (such\nas calculating values or aggregating data), and pass that information up to the presen\u2010\ntation layer.\nThis separation of concerns concept within the layered architecture style makes it easy\nto build effective roles and responsibility models within the architecture. Compo\u2010\nnents within a specific layer are limited in scope, dealing only with the logic that per\u2010\ntains to that layer. For example, components in the presentation layer only handle\npresentation logic, whereas components residing in the business layer only handle\nbusiness logic. This allows developers to leverage their particular technical expertise\nto focus on the technical aspects of the domain (such as presentation logic or persis\u2010\ntence logic). The trade-off of this benefit, however, is a lack of overall agility (the abil\u2010\nity to respond quickly to change).\nThe layered architecture is a technically partitioned architecture (as opposed to a\ndomain-partitioned architecture). Groups of components, rather than being grouped\nby domain (such as customer), are grouped by their technical role in the architecture\n(such as presentation or business). As a result, any particular business domain is\nspread throughout all of the layers of the architecture. For example, the domain of\n\u201ccustomer\u201d is contained in the presentation layer, business layer, rules layer, services\nlayer, and database layer, making it difficult to apply changes to that domain. As a\nresult, a domain-driven design approach does not work as well with the layered\narchitecture style.\nLayers of Isolation\nEach layer in the layered architecture style can be either closed or open. A closed layer\nmeans that as a request moves top-down from layer to layer, the request cannot skip\nany layers, but rather must go through the layer immediately below it to get to the\nnext layer (see Figure 10-3). For example, in a closed-layered architecture, a request\noriginating from the presentation layer must first go through the business layer and\nthen to the persistence layer before finally making it to the database layer.\nLayers of Isolation \n| \n135\n", "page": 155, "type": "text", "section": "Page 155"}
{"text": "Figure 10-3. Closed layers within the layered architecture\nNotice that in Figure 10-3 it would be much faster and easier for the presentation\nlayer to access the database directly for simple retrieval requests, bypassing any\nunnecessary layers (what used to be known in the early 2000s as the fast-lane reader\npattern). For this to happen, the business and persistence layers would have to be\nopen, allowing requests to bypass other layers. Which is better\u2014open layers or closed\nlayers? The answer to this question lies in a key concept known as layers of isolation.\nThe layers of isolation concept means that changes made in one layer of the architec\u2010\nture generally don\u2019t impact or affect components in other layers, providing the con\u2010\ntracts between those layers remain unchanged. Each layer is independent of the other\nlayers, thereby having little or no knowledge of the inner workings of other layers in\nthe architecture. However, to support layers of isolation, layers involved with the\nmajor flow of the request necessarily have to be closed. If the presentation layer can\ndirectly access the persistence layer, then changes made to the persistence layer would\nimpact both the business layer and the presentation layer, producing a very tightly\ncoupled application with layer interdependencies between components. This type of\narchitecture then becomes very brittle, as well as difficult and expensive to change.\nThe layers of isolation concept also allows any layer in the architecture to be replaced\nwithout impacting any other layer (again, assuming well-defined contracts and the\nuse of the business delegate pattern). For example, you can leverage the layers of iso\u2010\nlation concept within the layered architecture style to replace your older JavaServer\nFaces (JSF) presentation layer with React.js without impacting any other layer in the\napplication.\nAdding Layers\nWhile closed layers facilitate layers of isolation and therefore help isolate change\nwithin the architecture, there are times when it makes sense for certain layers to be\nopen. For example, suppose there are shared objects within the business layer that\ncontain common functionality for business components (such as date and string util\u2010\n136 \n| \nChapter 10: Layered Architecture Style\n", "page": 156, "type": "text", "section": "Page 156"}
{"text": "ity classes, auditing classes, logging classes, and so on). Suppose there is an architec\u2010\nture decision stating that the presentation layer is restricted from using these shared\nbusiness objects. This constraint is illustrated in Figure 10-4, with the dotted line\ngoing from a presentation component to a shared business object in the business\nlayer. This scenario is difficult to govern and control because architecturally the pre\u2010\nsentation layer has access to the business layer, and hence has access to the shared\nobjects within that layer.\nFigure 10-4. Shared objects within the business layer\nOne way to architecturally mandate this restriction is to add to the architecture a new\nservices layer containing all of the shared business objects. Adding this new layer now\narchitecturally restricts the presentation layer from accessing the shared business\nobjects because the business layer is closed (see Figure 10-5). However, the new serv\u2010\nices layer must be marked as open; otherwise the business layer would be forced to go\nthrough the services layer to access the persistence layer. Marking the services layer as\nopen allows the business layer to either access that layer (as indicated by the solid\narrow), or bypass the layer and go to the next one down (as indicated by the dotted\narrow in Figure 10-5).\nAdding Layers \n| \n137\n", "page": 157, "type": "text", "section": "Page 157"}
{"text": "Figure 10-5. Adding a new services layer to the architecture\nLeveraging the concept of open and closed layers helps define the relationship\nbetween architecture layers and request flows. It also provides developers with the\nnecessary information and guidance to understand various layer access restrictions\nwithin the architecture. Failure to document or properly communicate which layers\nin the architecture are open and closed (and why) usually results in tightly coupled\nand brittle architectures that are very difficult to test, maintain, and deploy.\nOther Considerations\nThe layered architecture makes for a good starting point for most applications when\nit is not known yet exactly which architecture style will ultimately be used. This is a\ncommon practice for many microservices efforts when architects are still determin\u2010\ning whether microservices is the right architecture choice, but development must\nbegin. However, when using this technique, be sure to keep reuse at a minimum and\nkeep object hierarchies (depth of inheritance tree) fairly shallow so as to maintain a\ngood level of modularity. This will help facilitate the move to another architecture\nstyle later on.\nOne thing to watch out for with the layered architecture is the architecture sinkhole\nanti-pattern. This anti-pattern occurs when requests move from layer to layer as sim\u2010\nple pass-through processing with no business logic performed within each layer. For\nexample, suppose the presentation layer responds to a simple request from the user to\nretrieve basic customer data (such as name and address). The presentation layer\n138 \n| \nChapter 10: Layered Architecture Style\n", "page": 158, "type": "text", "section": "Page 158"}
{"text": "passes the request to the business layer, which does nothing but pass the request on to\nthe rules layer, which in turn does nothing but pass the request on to the persistence\nlayer, which then makes a simple SQL call to the database layer to retrieve the cus\u2010\ntomer data. The data is then passed all the way back up the stack with no additional\nprocessing or logic to aggregate, calculate, apply rules, or transform the data. This\nresults in unnecessary object instantiation and processing, impacting both memory\nconsumption and performance.\nEvery layered architecture will have at least some scenarios that fall into the architec\u2010\nture sinkhole anti-pattern. The key to determining whether the architecture sinkhole\nanti-pattern is at play is to analyze the percentage of requests that fall into this cate\u2010\ngory. The 80-20 rule is usually a good practice to follow. For example, it is acceptable\nif only 20 percent of the requests are sinkholes. However, if 80 percent of the requests\nare sinkholes, it a good indicator that the layered architecture is not the correct archi\u2010\ntecture style for the problem domain. Another approach to solving the architecture\nsinkhole anti-pattern is to make all the layers in the architecture open, realizing, of\ncourse, that the trade-off is increased difficulty in managing change within the\narchitecture.\nWhy Use This Architecture Style\nThe layered architecture style is a good choice for small, simple applications or web\u2010\nsites. It is also a good architecture choice, particularly as a starting point, for situa\u2010\ntions with very tight budget and time constraints. Because of the simplicity and\nfamiliarity among developers and architects, the layered architecture is perhaps one\nof the lowest-cost architecture styles, promoting ease of development for smaller\napplications. The layered architecture style is also a good choice when an architect is\nstill analyzing business needs and requirements and is unsure which architecture\nstyle would be best.\nAs applications using the layered architecture style grow, characteristics like main\u2010\ntainability, agility, testability, and deployability are adversely affected. For this reason,\nlarge applications and systems using the layered architecture might be better suited\nfor other, more modular architecture styles.\nArchitecture Characteristics Ratings\nA one-star rating in the characteristics ratings table (shown in Figure 10-6) means the\nspecific architecture characteristic isn\u2019t well supported in the architecture, whereas a\nfive-star rating means the architecture characteristic is one of the strongest features in\nthe architecture style. The definition for each characteristic identified in the score\u2010\ncard can be found in Chapter 4.\nWhy Use This Architecture Style \n| \n139\n", "page": 159, "type": "text", "section": "Page 159"}
{"text": "Figure 10-6. Layered architecture characteristics ratings\nOverall cost and simplicity are the primary strengths of the layered architecture style. \nBeing monolithic in nature, layered architectures don\u2019t have the complexities associ\u2010\nated with distributed architecture styles, are simple and easy to understand, and are\nrelatively low cost to build and maintain. However, as a cautionary note, these ratings\nstart to quickly diminish as monolithic layered architectures get bigger and conse\u2010\nquently more complex.\nBoth deployability and testability rate very low for this architecture style. Deployabil\u2010\nity rates low due to the ceremony of deployment (effort to deploy), high risk, and lack\nof frequent deployments. A simple three-line change to a class file in the layered\narchitecture style requires the entire deployment unit to be redeployed, taking in\npotential database changes, configuration changes, or other coding changes sneaking\nin alongside the original change. Furthermore, this simple three-line change is usu\u2010\nally bundled with dozens of other changes, thereby increasing deployment risk even\nfurther (as well as increasing the frequency of deployment). The low testability rating\n140 \n| \nChapter 10: Layered Architecture Style\n", "page": 160, "type": "text", "section": "Page 160"}
{"text": "also reflects this scenario; with a simple three-line change, most developers are not\ngoing to spend hours executing the entire regression test suite (even if such a thing\nwere to exist in the first place), particularly along with dozens of other changes being\nmade to the monolithic application at the same time. We gave testability a two-star\nrating (rather than one star) due to the ability to mock or stub components (or even\nan entire layer), which eases the overall testing effort.\nOverall reliability rates medium (three stars) in this architecture style, mostly due to\nthe lack of network traffic, bandwidth, and latency found in most distributed archi\u2010\ntectures. We only gave the layered architecture three stars for reliability because of the\nnature of the monolithic deployment, combined with the low ratings for testability\n(completeness of testing) and deployment risk.\nElasticity and scalability rate very low (one star) for the layered architecture, primar\u2010\nily due to monolithic deployments and the lack of architectural modularity. Although\nit is possible to make certain functions within a monolith scale more than others, this\neffort usually requires very complex design techniques such as multithreading, inter\u2010\nnal messaging, and other parallel processing practices, techniques this architecture\nisn\u2019t well suited for. However, because the layered architecture is always a single sys\u2010\ntem quantum due to the monolithic user interface, backend processing, and mono\u2010\nlithic database, applications can only scale to a certain point based on the single\nquantum.\nPerformance is always an interesting characteristic to rate for the layered architecture.\nWe gave it only two stars because the architecture style simply does not lend itself to\nhigh-performance systems due to the lack of parallel processing, closed layering, and\nthe sinkhole architecture anti-pattern. Like scalability, performance can be addressed\nthrough caching, multithreading, and the like, but it is not a natural characteristic of\nthis architecture style; architects and developers have to work hard to make all this\nhappen.\nLayered architectures don\u2019t support fault tolerance due to monolithic deployments\nand the lack of architectural modularity. If one small part of a layered architecture\ncauses an out-of-memory condition to occur, the entire application unit is impacted\nand crashes. Furthermore, overall availability is impacted due to the high mean-time-\nto-recovery (MTTR) usually experienced by most monolithic applications, with\nstartup times ranging anywhere from 2 minutes for smaller applications, up to 15\nminutes or more for most large applications.\nArchitecture Characteristics Ratings \n| \n141\n", "page": 161, "type": "text", "section": "Page 161"}
{"text": "CHAPTER 11\nPipeline Architecture Style\nOne of the fundamental styles in software architecture that appears again and again is\nthe pipeline architecture (also known as the pipes and filters architecture). As soon as\ndevelopers and architects decided to split functionality into discrete parts, this pat\u2010\ntern followed. Most developers know this architecture as this underlying principle\nbehind Unix terminal shell languages, such as Bash and Zsh.\nDevelopers in many functional programming languages will see parallels between\nlanguage constructs and elements of this architecture. In fact, many tools that utilize\nthe MapReduce programming model follow this basic topology. While these exam\u2010\nples show a low-level implementation of the pipeline architecture style, it can also be\nused for higher-level business applications.\nTopology\nThe topology of the pipeline architecture consists of pipes and filters, illustrated in\nFigure 11-1.\nFigure 11-1. Basic topology for pipeline architecture\n143\n", "page": 163, "type": "text", "section": "Page 163"}
{"text": "The pipes and filters coordinate in a specific fashion, with pipes forming one-way\ncommunication between filters, usually in a point-to-point fashion.\nPipes\nPipes in this architecture form the communication channel between filters. Each pipe\nis typically unidirectional and point-to-point (rather than broadcast) for performance\nreasons, accepting input from one source and always directing output to another. The\npayload carried on the pipes may be any data format, but architects favor smaller\namounts of data to enable high performance.\nFilters\nFilters are self-contained, independent from other filters, and generally stateless. Fil\u2010\nters should perform one task only. Composite tasks should be handled by a sequence\nof filters rather than a single one.\nFour types of filters exist within this architecture style:\nProducer\nThe starting point of a process, outbound only, sometimes called the source.\nTransformer\nAccepts input, optionally performs a transformation on some or all of the data,\nthen forwards it to the outbound pipe. Functional advocates will recognize this\nfeature as map.\nTester\nAccepts input, tests one or more criteria, then optionally produces output, based\non the test. Functional programmers will recognize this as similar to reduce.\nConsumer\nThe termination point for the pipeline flow. Consumers sometimes persist the\nfinal result of the pipeline process to a database, or they may display the final\nresults on a user interface screen.\nThe unidirectional nature and simplicity of each of the pipes and filters encourages\ncompositional reuse. Many developers have discovered this ability using shells. A\nfamous story from the blog \u201cMore Shell, Less Egg\u201d illustrates just how powerful these\nabstractions are. Donald Knuth was asked to write a program to solve this text han\u2010\ndling problem: read a file of text, determine the n most frequently used words, and\nprint out a sorted list of those words along with their frequencies. He wrote a pro\u2010\ngram consisting of more than 10 pages of Pascal, designing (and documenting) a new\nalgorithm along the way. Then, Doug McIlroy demonstrated a shell script that would\neasily fit within a Twitter post that solved the problem more simply, elegantly, and\nunderstandably (if you understand shell commands):\n144 \n| \nChapter 11: Pipeline Architecture Style\n", "page": 164, "type": "text", "section": "Page 164"}
{"text": "        tr -cs A-Za-z '\\n' |\n        tr A-Z a-z |\n        sort |\n        uniq -c |\n        sort -rn |\n        sed ${1}q\nEven the designers of Unix shells are often surprised at the inventive uses developers\nhave wrought with their simple but powerfully composite abstractions.\nExample\nThe pipeline architecture pattern appears in a variety of applications, especially tasks\nthat facilitate simple, one-way processing. For example, many Electronic Data Inter\u2010\nchange (EDI) tools use this pattern, building transformations from one document\ntype to another using pipes and filters. ETL tools (extract, transform, and load) lever\u2010\nage the pipeline architecture as well for the flow and modification of data from one\ndatabase or data source to another. Orchestrators and mediators such as Apache\nCamel utilize the pipeline architecture to pass information from one step in a busi\u2010\nness process to another.\nTo illustrate how the pipeline architecture can be used, consider the following exam\u2010\nple, as illustrated in Figure 11-2, where various service telemetry information is sent\nfrom services via streaming to Apache Kafka.\nFigure 11-2. Pipeline architecture example\nExample \n| \n145\n", "page": 165, "type": "text", "section": "Page 165"}
{"text": "Notice in Figure 11-2 the use of the pipeline architecture style to process the different\nkinds of data streamed to Kafka. The Service Info Capture filter (producer filter)\nsubscribes to the Kafka topic and receives service information. It then sends this cap\u2010\ntured data to a tester filter called Duration Filter to determine whether the data\ncaptured from Kafka is related to the duration (in milliseconds) of the service request.\nNotice the separation of concerns between the filters; the Service Metrics Capture\nfilter is only concerned about how to connect to a Kafka topic and receive streaming\ndata, whereas the Duration Filter is only concerned about qualifying the data and\noptionally routing it to the next pipe. If the data is related to the duration (in milli\u2010\nseconds) of the service request, then the Duration Filter passes the data on to the\nDuration Calculator transformer filter. Otherwise, it passes it on to the Uptime\nFilter tester filter to check if the data is related to uptime metrics. If it is not, then\nthe pipeline ends\u2014the data is of no interest to this particular processing flow. Other\u2010\nwise, if it is uptime metrics, it then passes the data along to the Uptime Calculator to\ncalculate the uptime metrics for the service. These transformers then pass the modi\u2010\nfied data to the Database Output consumer, which then persists the data in a Mon\u2010\ngoDB database.\nThis example shows the extensibility properties of the pipeline architecture. For\nexample, in Figure 11-2, a new tester filter could easily be added after the Uptime\nFilter to pass the data on to another newly gathered metric, such as the database\nconnection wait time.\nArchitecture Characteristics Ratings\nA one-star rating in the characteristics ratings table Figure 11-3 means the specific\narchitecture characteristic isn\u2019t well supported in the architecture, whereas a five-star\nrating means the architecture characteristic is one of the strongest features in the\narchitecture style. The definition for each characteristic identified in the scorecard\ncan be found in Chapter 4.\nThe pipeline architecture style is a technically partitioned architecture due to the par\u2010\ntitioning of application logic into filter types (producer, tester, transformer, and con\u2010\nsumer). Also, because the pipeline architecture is usually implemented as a\nmonolithic deployment, the architectural quantum is always one.\n146 \n| \nChapter 11: Pipeline Architecture Style\n", "page": 166, "type": "text", "section": "Page 166"}
{"text": "Figure 11-3. Pipeline architecture characteristics ratings\nOverall cost and simplicity combined with modularity are the primary strengths of\nthe pipeline architecture style. Being monolithic in nature, pipeline architectures\ndon\u2019t have the complexities associated with distributed architecture styles, are simple\nand easy to understand, and are relatively low cost to build and maintain. Architec\u2010\ntural modularity is achieved through the separation of concerns between the various\nfilter types and transformers. Any of these filters can be modified or replaced without\nimpacting the other filters. For instance, in the Kafka example illustrated in\nFigure 11-2, the Duration Calculator can be modified to change the duration calcu\u2010\nlation without impacting any other filter.\nDeployability and testability, while only around average, rate slightly higher than the \nlayered architecture due to the level of modularity achieved through filters. That said,\nthis architecture style is still a monolith, and as such, ceremony, risk, frequency of\ndeployment, and completion of testing still impact the pipeline architecture.\nArchitecture Characteristics Ratings \n| \n147\n", "page": 167, "type": "text", "section": "Page 167"}
{"text": "Like the layered architecture, overall reliability rates medium (three stars) in this\narchitecture style, mostly due to the lack of network traffic, bandwidth, and latency\nfound in most distributed architectures. We only gave it three stars for reliability\nbecause of the nature of the monolithic deployment of this architecture style in con\u2010\njunction with testability and deployability issues (such as having to test the entire\nmonolith and deploy the entire monolith for any given change).\nElasticity and scalability rate very low (one star) for the pipeline architecture, primar\u2010\nily due to monolithic deployments. Although it is possible to make certain functions\nwithin a monolith scale more than others, this effort usually requires very complex\ndesign techniques such as multithreading, internal messaging, and other parallel pro\u2010\ncessing practices, techniques this architecture isn\u2019t well suited for. However, because\nthe pipeline architecture is always a single system quantum due to the monolithic\nuser interface, backend processing, and monolithic database, applications can only\nscale to a certain point based on the single architecture quantum.\nPipeline architectures don\u2019t support fault tolerance due to monolithic deployments\nand the lack of architectural modularity. If one small part of a pipeline architecture\ncauses an out-of-memory condition to occur, the entire application unit is impacted\nand crashes. Furthermore, overall availability is impacted due to the high mean time\nto recovery (MTTR) usually experienced by most monolithic applications, with\nstartup times ranging anywhere from 2 minutes for smaller applications, up to 15\nminutes or more for most large applications.\n148 \n| \nChapter 11: Pipeline Architecture Style\n", "page": 168, "type": "text", "section": "Page 168"}
{"text": "CHAPTER 12\nMicrokernel Architecture Style\nThe microkernel architecture style (also referred to as the plug-in architecture) was\ncoined several decades ago and is still widely used today. This architecture style is a\nnatural fit for product-based applications (packaged and made available for download\nand installation as a single, monolithic deployment, typically installed on the custom\u2010\ner\u2019s site as a third-party product) but is widely used in many nonproduct custom\nbusiness applications as well.\nTopology\nThe microkernel architecture style is a relatively simple monolithic architecture con\u2010\nsisting of two architecture components: a core system and plug-in components.\nApplication logic is divided between independent plug-in components and the basic\ncore system, providing extensibility, adaptability, and isolation of application features\nand custom processing logic. Figure 12-1 illustrates the basic topology of the micro\u2010\nkernel architecture style.\n149\n", "page": 169, "type": "text", "section": "Page 169"}
{"text": "Figure 12-1. Basic components of the microkernel architecture style\nCore System\nThe core system is formally defined as the minimal functionality required to run the\nsystem. The Eclipse IDE is a good example of this. The core system of Eclipse is just a\nbasic text editor: open a file, change some text, and save the file. It\u2019s not until you add\nplug-ins that Eclipse starts becoming a usable product. However, another definition\nof the core system is the happy path (general processing flow) through the applica\u2010\ntion, with little or no custom processing. Removing the cyclomatic complexity of the\ncore system and placing it into separate plug-in components allows for better extensi\u2010\nbility and maintainability, as well as increased testability. For example, suppose an\nelectronic device recycling application must perform specific custom assessment rules\nfor each electronic device received. The Java code for this sort of processing might\nlook as follows:\npublic void assessDevice(String deviceID) {\n   if (deviceID.equals(\"iPhone6s\")) {\n      assessiPhone6s();\n   } else if (deviceID.equals(\"iPad1\"))\n      assessiPad1();\n   } else if (deviceID.equals(\"Galaxy5\"))\n      assessGalaxy5();\n   } else ...\n      ...\n   }\n}\n150 \n| \nChapter 12: Microkernel Architecture Style\n", "page": 170, "type": "text", "section": "Page 170"}
{"text": "Rather than placing all this client-specific customization in the core system with lots\nof cyclomatic complexity, it is much better to create a separate plug-in component for\neach electronic device being assessed. Not only do specific client plug-in components\nisolate independent device logic from the rest of the processing flow, but they also\nallow for expandability. Adding a new electronic device to assess is simply a matter of\nadding a new plug-in component and updating the registry. With the microkernel\narchitecture style, assessing an electronic device only requires the core system to\nlocate and invoke the corresponding device plug-ins as illustrated in this revised\nsource code:\npublic void assessDevice(String deviceID) {\n \nString plugin = pluginRegistry.get(deviceID);\n \nClass<?> theClass = Class.forName(plugin);\n \nConstructor<?> constructor = theClass.getConstructor();\n \nDevicePlugin devicePlugin =\n \n \n(DevicePlugin)constructor.newInstance();\n \nDevicePlugin.assess();\n}\nIn this example all of the complex rules and instructions for assessing a particular\nelectronic device are self-contained in a standalone, independent plug-in component\nthat can be generically executed from the core system.\nDepending on the size and complexity, the core system can be implemented as a lay\u2010\nered architecture or a modular monolith (as illustrated in Figure 12-2). In some cases,\nthe core system can be split into separately deployed domain services, with each\ndomain service containing specific plug-in components specific to that domain. For\nexample, suppose Payment Processing is the domain service representing the core\nsystem. Each payment method (credit card, PayPal, store credit, gift card, and pur\u2010\nchase order) would be separate plug-in components specific to the payment domain.\nIn all of these cases, it is typical for the entire monolithic application to share a single\ndatabase.\nTopology \n| \n151\n", "page": 171, "type": "text", "section": "Page 171"}
{"text": "Figure 12-2. Variations of the microkernel architecture core system\nThe presentation layer of the core system can be embedded within the core system or\nimplemented as a separate user interface, with the core system providing backend\nservices. As a matter of fact, a separate user interface can also be implemented as a\nmicrokernel architecture style. Figure 12-3 illustrates these presentation layer variants\nin relation to the core system.\n152 \n| \nChapter 12: Microkernel Architecture Style\n", "page": 172, "type": "text", "section": "Page 172"}
{"text": "Figure 12-3. User interface variants\nPlug-In Components\nPlug-in components are standalone, independent components that contain special\u2010\nized processing, additional features, and custom code meant to enhance or extend the\ncore system. Additionally, they can be used to isolate highly volatile code, creating\nTopology \n| \n153\n", "page": 173, "type": "text", "section": "Page 173"}
{"text": "better maintainability and testability within the application. Ideally, plug-in compo\u2010\nnents should be independent of each other and have no dependencies between them.\nThe communication between the plug-in components and the core system is gener\u2010\nally point-to-point, meaning the \u201cpipe\u201d that connects the plug-in to the core system is\nusually a method invocation or function call to the entry-point class of the plug-in\ncomponent. In addition, the plug-in component can be either compile-based or\nruntime-based. Runtime plug-in components can be added or removed at runtime\nwithout having to redeploy the core system or other plug-ins, and they are usually\nmanaged through frameworks such as Open Service Gateway Initiative (OSGi) for\nJava, Penrose (Java), Jigsaw (Java), or Prism (.NET). Compile-based plug-in compo\u2010\nnents are much simpler to manage but require the entire monolithic application to be\nredeployed when modified, added, or removed.\nPoint-to-point plug-in components can be implemented as shared libraries (such as a\nJAR, DLL, or Gem), package names in Java, or namespaces in C#. Continuing with\nthe electronics recycling assessment application example, each electronic device plug-\nin can be written and implemented as a JAR, DLL, or Ruby Gem (or any other shared\nlibrary), with the name of the device matching the name of the independent shared\nlibrary, as illustrated in Figure 12-4.\nFigure 12-4. Shared library plug-in implementation\nAlternatively, an easier approach shown in Figure 12-5 is to implement each plug-in\ncomponent as a separate namespace or package name within the same code base or\nIDE project. When creating the namespace, we recommend the following semantics:\napp.plug-in.<domain>.<context>. \nFor \nexample, \nconsider \nthe \nnamespace\napp.plugin.assessment.iphone6s. The second node (plugin) makes it clear this\ncomponent is a plug-in and therefore should strictly adhere to the basic rules\nregarding plug-in components (namely, that they are self-contained and separate\n154 \n| \nChapter 12: Microkernel Architecture Style\n", "page": 174, "type": "text", "section": "Page 174"}
{"text": "from other plug-ins). The third node describes the domain (in this case, assessment),\nthereby allowing plug-in components to be organized and grouped by a common\npurpose. The fourth node (iphone6s) describes the specific context for the plug-in,\nmaking it easy to locate the specific device plug-in for modification or testing.\nFigure 12-5. Package or namespace plug-in implementation\nPlug-in components do not always have to be point-to-point communication with the\ncore system. Other alternatives exist, including using REST or messaging as a means\nto invoke plug-in functionality, with each plug-in being a standalone service (or\nmaybe even a microservice implemented using a container). Although this may\nsound like a good way to increase overall scalability, note that this topology (illustra\u2010\nted in Figure 12-6) is still only a single architecture quantum due to the monolithic\ncore system. Every request must first go through the core system to get to the plug-in\nservice.\nFigure 12-6. Remote plug-in access using REST\nThe benefits of the remote access approach to accessing plug-in components imple\u2010\nmented as individual services is that it provides better overall component decoupling,\nTopology \n| \n155\n", "page": 175, "type": "text", "section": "Page 175"}
{"text": "allows for better scalability and throughput, and allows for runtime changes without\nany special frameworks like OSGi, Jigsaw, or Prism. It also allows for asynchronous\ncommunications to plug-ins, which, depending on the scenario, could significantly\nimprove overall user responsiveness. Using the electronics recycling example, rather\nthan having to wait for the electronic device assessment to run, the core system could\nmake an asynchronous request to kick off an assessment for a particular device. When\nthe assessment completes, the plug-in can notify the core system through another\nasynchronous messaging channel, which in turn would notify the user that the\nassessment is complete.\nWith these benefits comes trade-offs. Remote plug-in access turns the microkernel\narchitecture into a distributed architecture rather than a monolithic one, making it\ndifficult to implement and deploy for most third-party on-prem products. Further\u2010\nmore, it creates more overall complexity and cost and complicates the overall deploy\u2010\nment topology. If a plug-in becomes unresponsive or is not running, particularly\nwhen using REST, the request cannot be completed. This would not be the case with a\nmonolithic deployment. The choice of whether to make the communication to plug-\nin components from the core system point-to-point or remote should be based on\nspecific requirements and thus requires a careful trade-off analysis of the benefits and\ndrawbacks of such an approach.\nIt is not a common practice for plug-in components to connect directly to a centrally\nshared database. Rather, the core system takes on this responsibility, passing whatever\ndata is needed into each plug-in. The primary reason for this practice is decoupling.\nMaking a database change should only impact the core system, not the plug-in com\u2010\nponents. That said, plug-ins can have their own separate data stores only accessible to\nthat plug-in. For example, each electronic device assessment plug-in in the electronic\nrecycling system example can have its own simple database or rules engine containing\nall of the specific assessment rules for each product. The data store owned by the\nplug-in component can be external (as shown in Figure 12-7), or it could be embed\u2010\nded as part of the plug-in component or monolithic deployment (as in the case of an\nin-memory or embedded database).\n156 \n| \nChapter 12: Microkernel Architecture Style\n", "page": 176, "type": "text", "section": "Page 176"}
{"text": "Figure 12-7. Plug-in components can own their own data store\nRegistry\nThe core system needs to know about which plug-in modules are available and how\nto get to them. One common way of implementing this is through a plug-in registry.\nThis registry contains information about each plug-in module, including things like\nits name, data contract, and remote access protocol details (depending on how the\nplug-in is connected to the core system). For example, a plug-in for tax software that\nflags high-risk tax audit items might have a registry entry that contains the name of\nthe service (AuditChecker), the data contract (input data and output data), and the\ncontract format (XML).\nThe registry can be as simple as an internal map structure owned by the core system\ncontaining a key and the plug-in component reference, or it can be as complex as a\nregistry and discovery tool either embedded within the core system or deployed\nexternally (such as Apache ZooKeeper or Consul). Using the electronics recycling\nexample, the following Java code implements a simple registry within the core system,\nshowing a point-to-point entry, a messaging entry, and a RESTful entry example for\nassessing an iPhone 6S device:\nMap<String, String> registry = new HashMap<String, String>();\nstatic {\n  //point-to-point access example\n  registry.put(\"iPhone6s\", \"Iphone6sPlugin\");\n  //messaging example\n  registry.put(\"iPhone6s\", \"iphone6s.queue\");\n  //restful example\n  registry.put(\"iPhone6s\", \"https://atlas:443/assess/iphone6s\");\n}\nRegistry \n| \n157\n", "page": 177, "type": "text", "section": "Page 177"}
{"text": "Contracts\nThe contracts between the plug-in components and the core system are usually stan\u2010\ndard across a domain of plug-in components and include behavior, input data, and\noutput data returned from the plug-in component. Custom contracts are typically\nfound in situations where plug-in components are developed by a third party where\nyou have no control over the contract used by the plug-in. In such cases, it is com\u2010\nmon to create an adapter between the plug-in contract and your standard contract so\nthat the core system doesn\u2019t need specialized code for each plug-in.\nPlug-in contracts can be implemented in XML, JSON, or even objects passed back\nand forth between the plug-in and the core system. In keeping with the electronics\nrecycling application, the following contract (implemented as a standard Java inter\u2010\nface named AssessmentPlugin) defines the overall behavior (assess(), register(),\nand deregister()), along with the corresponding output data expected from the\nplug-in component (AssessmentOutput):\npublic interface AssessmentPlugin {\n \npublic AssessmentOutput assess();\n \npublic String register();\n \npublic String deregister();\n}\npublic class AssessmentOutput {\n \npublic String assessmentReport;\n \npublic Boolean resell;\n \npublic Double value;\n \npublic Double resellPrice;\n}\nIn this contract example, the device assessment plug-in is expected to return the\nassessment report as a formatted string; a resell flag (true or false) indicating whether\nthis device can be resold on a third-party market or safely disposed of; and finally, if it\ncan be resold (another form of recycling), what the calculated value is of the item and\nwhat the recommended resell price should be.\nNotice the roles and responsibility model between the core system and the plug-in\ncomponent in this example, specifically with the assessmentReport field. It is not the\nresponsibility of the core system to format and understand the details of the assess\u2010\nment report, only to either print it out or display it to the user.\nExamples and Use Cases\nMost of the tools used for developing and releasing software are implemented using\nthe microkernel architecture. Some examples include the Eclipse IDE, PMD, Jira, and\nJenkins, to name a few). Internet web browsers such as Chrome and Firefox are\nanother common product example using the microkernel architecture: viewers and\n158 \n| \nChapter 12: Microkernel Architecture Style\n", "page": 178, "type": "text", "section": "Page 178"}
{"text": "other plug-ins add additional capabilities that are not otherwise found in the basic\nbrowser representing the core system. The examples are endless for product-based\nsoftware, but what about large business applications? The microkernel architecture\napplies to these situations as well. To illustrate this point, consider an insurance com\u2010\npany example involving insurance claims processing.\nClaims processing is a very complicated process. Each jurisdiction has different rules\nand regulations for what is and isn\u2019t allowed in an insurance claim. For example,\nsome jurisdictions (e.g., states) allow free windshield replacement if your windshield\nis damaged by a rock, whereas other states do not. This creates an almost infinite set\nof conditions for a standard claims process.\nMost insurance claims applications leverage large and complex rules engines to han\u2010\ndle much of this complexity. However, these rules engines can grow into a complex\nbig ball of mud where changing one rule impacts other rules, or making a simple rule\nchange requires an army of analysts, developers, and testers to make sure nothing is\nbroken by a simple change. Using the microkernel architecture pattern can solve\nmany of these issues.\nThe claims rules for each jurisdiction can be contained in separate standalone plug-in\ncomponents (implemented as source code or a specific rules engine instance accessed\nby the plug-in component). This way, rules can be added, removed, or changed for a\nparticular jurisdiction without impacting any other part of the system. Furthermore,\nnew jurisdictions can be added and removed without impacting other parts of the\nsystem. The core system in this example would be the standard process for filing and\nprocessing a claim, something that doesn\u2019t change often.\nAnother example of a large and complex business application that can leverage the\nmicrokernel architecture is tax preparation software. For example, the United States\nhas a basic two-page tax form called the 1040 form that contains a summary of all the\ninformation needed to calculate a person\u2019s tax liability. Each line in the 1040 tax form\nhas a single number that requires many other forms and worksheets to arrive at that\nsingle number (such as gross income). Each of these additional forms and worksheets\ncan be implemented as a plug-in component, with the 1040 summary tax form being\nthe core system (the driver). This way, changes to tax law can be isolated to an inde\u2010\npendent plug-in component, making changes easier and less risky.\nExamples and Use Cases \n| \n159\n", "page": 179, "type": "text", "section": "Page 179"}
{"text": "Architecture Characteristics Ratings\nA one-star rating in the characteristics ratings in Figure 12-8 means the specific\narchitecture characteristic isn\u2019t well supported in the architecture, whereas a five-star\nrating means the architecture characteristic is one of the strongest features in the\narchitecture style. The definition for each characteristic identified in the scorecard\ncan be found in Chapter 4.\nFigure 12-8. Microkernel architecture characteristics ratings\nSimilar to the layered architecture style, simplicity and overall cost are the main\nstrengths of the microkernel architecture style, and scalability, fault tolerance, and\nextensibility its main weaknesses. These weaknesses are due to the typical monolithic\ndeployments found with the microkernel architecture. Also, like the layered architec\u2010\nture style, the number of quanta is always singular (one) because all requests must go\nthrough the core system to get to independent plug-in components. That\u2019s where the\nsimilarities end.\n160 \n| \nChapter 12: Microkernel Architecture Style\n", "page": 180, "type": "text", "section": "Page 180"}
{"text": "The microkernel architecture style is unique in that it is the only architecture style\nthat can be both domain partitioned and technically partitioned. While most micro\u2010\nkernel architectures are technically partitioned, the domain partitioning aspect comes\nabout mostly through a strong domain-to-architecture isomorphism. For example,\nproblems that require different configurations for each location or client match\nextremely well with this architecture style. Another example is a product or applica\u2010\ntion that places a strong emphasis on user customization and feature extensibility\n(such as Jira or an IDE like Eclipse).\nTestability, deployability, and reliability rate a little above average (three stars), pri\u2010\nmarily because functionality can be isolated to independent plug-in components. If\ndone right, this reduces the overall testing scope of changes and also reduces overall\nrisk of deployment, particularly if plug-in components are deployed in a runtime\nfashion.\nModularity and extensibility also rate a little above average (three stars). With the\nmicrokernel architecture style, additional functionality can be added, removed, and\nchanged through independent, self-contained plug-in components, thereby making it\nrelatively easy to extend and enhance applications created using this architecture style\nand allowing teams to respond to changes much faster. Consider the tax preparation\nsoftware example from the previous section. If the US tax law changes (which it does\nall the time), requiring a new tax form, that new tax form can be created as a plug-in\ncomponent and added to the application without much effort. Similarly, if a tax form\nor worksheet is no longer needed, that plug-in can simply be removed from the\napplication.\nPerformance is always an interesting characteristic to rate with the microkernel archi\u2010\ntecture style. We gave it three stars (a little above average) mostly because microker\u2010\nnel applications are generally small and don\u2019t grow as big as most layered\narchitectures. Also, they don\u2019t suffer as much from the architecture sinkhole anti-\npattern discussed in Chapter 10. Finally, microkernel architectures can be stream\u2010\nlined by unplugging unneeded functionality, therefore making the application run\nfaster. A good example of this is Wildfly (previously the JBoss Application Server). By\nunplugging unnecessary functionality like clustering, caching, and messaging, the\napplication server performs much faster than with these features in place.\nArchitecture Characteristics Ratings \n| \n161\n", "page": 181, "type": "text", "section": "Page 181"}
{"text": "CHAPTER 13\nService-Based Architecture Style\nService-based architecture is a hybrid of the microservices architecture style and is\nconsidered one of the most pragmatic architecture styles, mostly due to its architec\u2010\ntural flexibility. Although service-based architecture is a distributed architecture, it\ndoesn\u2019t have the same level of complexity and cost as other distributed architectures,\nsuch as microservices or event-driven architecture, making it a very popular choice\nfor many business-related applications.\nTopology\nThe basic topology of service-based architecture follows a distributed macro layered\nstructure consisting of a separately deployed user interface, separately deployed\nremote coarse-grained services, and a monolithic database. This basic topology is\nillustrated in Figure 13-1.\nServices within this architecture style are typically coarse-grained \u201cportions of an\napplication\u201d (usually called domain services) that are independent and separately\ndeployed. Services are typically deployed in the same manner as any monolithic\napplication would be (such as an EAR file, WAR file, or assembly) and as such do not\nrequire containerization (although you could deploy a domain service in a container\nsuch as Docker). Because the services typically share a single monolithic database, the\nnumber of services within an application context generally range between 4 and 12\nservices, with the average being about 7 services.\n163\n", "page": 183, "type": "text", "section": "Page 183"}
{"text": "Figure 13-1. Basic topology of the service-based architecture style\nIn most cases there is only a single instance of each domain service within a service-\nbased architecture. However, based on scalability, fault tolerance, and throughput\nneeds, multiple instances of a domain service can certainly exist. Multiple instances\nof a service usually require some sort of load-balancing capability between the user\ninterface and the domain service so that the user interface can be directed to a healthy\nand available service instance.\nServices are accessed remotely from a user interface using a remote access protocol.\nWhile REST is typically used to access services from the user interface, messaging,\nremote procedure call (RPC), or even SOAP could be used as well. While an API\nlayer consisting of a proxy or gateway can be used to access services from the user\ninterface (or other external requests), in most cases the user interface accesses the\nservices directly using a service locator pattern embedded within the user interface,\nAPI gateway, or proxy.\nOne important aspect of service-based architecture is that it typically uses a centrally\nshared database. This allows services to leverage SQL queries and joins in the same\nway a traditional monolithic layered architecture would. Because of the small number\nof services (4 to 12), database connections are not usually an issue in service-based\narchitecture. Database changes, however, can be an issue. The section \u201cDatabase Par\u2010\ntitioning\u201d on page 169 describes techniques for addressing and managing database\nchange within a service-based architecture.\n164 \n| \nChapter 13: Service-Based Architecture Style\n", "page": 184, "type": "text", "section": "Page 184"}
{"text": "Topology Variants\nMany topology variants exist within the service-based architecture style, making this\nperhaps one of the most flexible architecture styles. For example, the single mono\u2010\nlithic user interface, as illustrated in Figure 13-1, can be broken apart into user inter\u2010\nface domains, even to a level matching each domain service. These user interface\nvariants are illustrated in Figure 13-2.\nFigure 13-2. User interface variants\nTopology Variants \n| \n165\n", "page": 185, "type": "text", "section": "Page 185"}
{"text": "Similarly, opportunities may exist to break apart a single monolithic database into\nseparate databases, even going as far as domain-scoped databases matching each\ndomain service (similar to microservices). In these cases it is important to make sure\nthe data in each separate database is not needed by another domain service. This\navoids interservice communication between domain services (something to definitely\navoid with service-based architecture) and also the duplication of data between data\u2010\nbases. These database variants are illustrated in Figure 13-3.\nFigure 13-3. Database variants\n166 \n| \nChapter 13: Service-Based Architecture Style\n", "page": 186, "type": "text", "section": "Page 186"}
{"text": "Finally, it is also possible to add an API layer consisting of a reverse proxy or gateway\nbetween the user interface and services, as shown in Figure 13-4. This is a good prac\u2010\ntice when exposing domain service functionality to external systems or when consoli\u2010\ndating shared cross-cutting concerns and moving them outside of the user interface\n(such as metrics, security, auditing requirements, and service discovery).\nFigure 13-4. Adding an API layer between the user interface and domain services\nService Design and Granularity\nBecause domain services in a service-based architecture are generally coarse-grained,\neach domain service is typically designed using a layered architecture style consisting\nof an API facade layer, a business layer, and a persistence layer. Another popular\ndesign approach is to domain partition each domain service using sub-domains simi\u2010\nlar to the modular monolith architecture style. Each of these design approaches is\nillustrated in Figure 13-5.\nService Design and Granularity \n| \n167\n", "page": 187, "type": "text", "section": "Page 187"}
{"text": "Figure 13-5. Domain service design variants\nRegardless of the service design, a domain service must contain some sort of API\naccess facade that the user interface interacts with to execute some sort of business\nfunctionality. The API access facade typically takes on the responsibility of orches\u2010\ntrating the business request from the user interface. For example, consider a business\nrequest from the user interface to place an order (also known as catalog checkout).\nThis single request, received by the API access facade within the OrderService\ndomain service, internally orchestrates the single business request: place the order,\ngenerate an order ID, apply the payment, and update the product inventory for each\nproduct ordered. In the microservices architecture style, this would likely involve the\norchestration of many separately deployed remote single-purpose services to com\u2010\nplete the request. This difference between internal class-level orchestration and exter\u2010\nnal service orchestration points to one of the many significant differences between\nservice-based architecture and microservices in terms of granularity.\nBecause domain services are coarse-grained, regular ACID (atomicity, consistency,\nisolation, durability) database transactions involving database commits and rollbacks\nare used to ensure database integrity within a single domain service. Highly dis\u2010\n168 \n| \nChapter 13: Service-Based Architecture Style\n", "page": 188, "type": "text", "section": "Page 188"}
{"text": "tributed architectures like microservices, on the other hand, usually have fine-grained\nservices and use a distributed transaction technique known as BASE transactions\n(basic availability, soft state, eventual consistency) that rely on eventual consistency\nand hence do not support the same level of database integrity as ACID transactions in\na service-based architecture.\nTo illustrate this point, consider the example of a catalog checkout process within a\nservice-based architecture. Suppose the customer places an order and the credit card\nused for payment has expired. Since this is an atomic transaction within the same ser\u2010\nvice, everything added to the database can be removed using a rollback and a notice\nsent to the customer stating that the payment cannot be applied. Now consider this\nsame process in a microservices architecture with smaller fine-grained services. First,\nthe OrderPlacement service would accept the request, create the order, generate an\norder ID, and insert the order into the order tables. Once this is done, the order ser\u2010\nvice would then make a remote call to the PaymentService, which would try to apply\nthe payment. If the payment cannot be applied due to an expired credit card, then the\norder cannot be placed and the data is in an inconsistent state (the order information\nhas already been inserted but has not been approved). In this case, what about the\ninventory for that order? Should it be marked as ordered and decremented? What if\nthe inventory is low and another customer wishes to purchase the item? Should that\nnew customer be allowed to buy it, or should the reserved inventory be reserved for\nthe customer trying to place the order with an expired credit card? These are just a\nfew of the questions that would need to be addressed when orchestrating a business\nprocess with multiple finer-grained services.\nDomain services, being coarse-grained, allow for better data integrity and consis\u2010\ntency, but there is a trade-off. With service-based architecture, a change made to the\norder placement functionality in the OrderService would require testing the entire\ncoarse-grained service (including payment processing), whereas with microservices\nthe same change would only impact a small OrderPlacement service (requiring no\nchange to the PaymentService). Furthermore, because more code is being deployed,\nthere is more risk with service-based architecture that something might break\n(including payment processing), whereas with microservices each service has a single\nresponsibility, hence less chance of breaking other functionality when being changed.\nDatabase Partitioning\nAlthough not required, services within a service-based architecture usually share a\nsingle, monolithic database due to the small number of services (4 to 12) within a\ngiven application context. This database coupling can present an issue with respect to\ndatabase table schema changes. If not done properly, a table schema change can\npotentially impact every service, making database changes a very costly task in terms\nof effort and coordination.\nDatabase Partitioning \n| \n169\n", "page": 189, "type": "text", "section": "Page 189"}
{"text": "Within a service-based architecture, the shared class files representing the database\ntable schemas (usually referred to as entity objects) reside in a custom shared library\nused by all the domain services (such as a JAR file or DLL). Shared libraries might\nalso contain SQL code. The practice of creating a single shared library of entity\nobjects is the least effective way of implementing service-based architecture. Any\nchange to the database table structures would also require a change to the single\nshared library containing all of the corresponding entity objects, thus requiring a\nchange and redeployment to every service, regardless of whether or not the services\nactually access the changed table. Shared library versioning can help address this\nissue, but nevertheless, with a single shared library it is difficult to know which serv\u2010\nices are actually impacted by the table change without manual, detailed analysis. This\nsingle shared library scenario is illustrated in Figure 13-6.\nFigure 13-6. Using a single shared library for database entity objects\nOne way to mitigate the impact and risk of database changes is to logically partition\nthe database and manifest the logical partitioning through federated shared libraries.\nNotice in Figure 13-7 that the database is logically partitioned into five separate\ndomains (common, customer, invoicing, order, and tracking). Also notice that there\nare five corresponding shared libraries used by the domain services matching the log\u2010\nical partitions in the database. Using this technique, changes to a table within a par\u2010\nticular logical domain (in this case, invoicing) match the corresponding shared\nlibrary containing the entity objects (and possibly SQL as well), impacting only those\n170 \n| \nChapter 13: Service-Based Architecture Style\n", "page": 190, "type": "text", "section": "Page 190"}
{"text": "services using that shared library, which in this case is the invoicing service. No other\nservices are impacted by this change.\nFigure 13-7. Using multiple shared libraries for database entity objects\nNotice in Figure 13-7 the use of the common domain and the corresponding\ncommon_entities_lib shared library used by all services. This is a relatively common\noccurrence. These tables are common to all services, and as such, changes to these\ntables require coordination of all services accessing the shared database. One way to\nmitigate changes to these tables (and corresponding entity objects) is to lock the com\u2010\nmon entity objects in the version control system and restrict change access to only\nthe database team. This helps control change and emphasizes the significance of\nchanges to the common tables used by all services.\nMake the logical partitioning in the database as fine-grained as\npossible while still maintaining well-defined data domains to better\ncontrol database changes within a service-based architecture.\nDatabase Partitioning \n| \n171\n", "page": 191, "type": "text", "section": "Page 191"}
{"text": "Example Architecture\nTo illustrate the flexibility and power of the service-based architecture style, consider\nthe real-world example of an electronic recycling system used to recycle old elec\u2010\ntronic devices (such as an iPhone or Galaxy cell phone). The processing flow of recy\u2010\ncling old electronic devices works as follows: first, the customer asks the company\n(via a website or kiosk) how much money they can get for the old electronic device\n(called quoting). If satisfied, the customer will send the electronic device to the recy\u2010\ncling company, which in turn will receive the physical device (called receiving). Once\nreceived, the recycling company will then assess the device to determine if the device\nis in good working condition or not (called assessment). If the device is in good work\u2010\ning condition, the company will send the customer the money promised for the\ndevice (called accounting). Through this process, the customer can go to the website\nat any time to check on the status of the item (called item status). Based on the assess\u2010\nment, the device is then recycled by either safely destroying it or reselling it (called\nrecycling). Finally, the company periodically runs ad hoc and scheduled financial and\noperational reports based on recycling activity (called reporting).\nFigure 13-8 illustrates this system using a service-based architecture. Notice how each\ndomain area identified in the prior description is implemented as a separately\ndeployed independent domain service. Scalability can be achieved by only scaling\nthose services needing higher throughput (in this case, the customer-facing Quoting\nservice and ItemStatus service). The other services do not need to scale, and as such\nonly require a single service instance.\nAlso notice in how the user interface applications are federated into their respective\ndomains: Customer Facing, Receiving, and Recycling and Accounting. This federation\nallows for fault tolerance of the user interface, scalability, and security (external cus\u2010\ntomers have no network path to internal functionality). Finally, notice in this example\nthat there are two separate physical databases: one for external customer-facing oper\u2010\nations, and one for internal operations. This allows the internal data and operations\nto reside in a separate network zone from the external operations (denoted by the\nvertical line), providing much better security access restrictions and data protection.\nOne-way access through the firewall allows internal services to access and update the\ncustomer-facing information, but not vice versa. Alternatively, depending on the\ndatabase being used, internal table mirroring and table synchronization could also be\nused.\n172 \n| \nChapter 13: Service-Based Architecture Style\n", "page": 192, "type": "text", "section": "Page 192"}
{"text": "Figure 13-8. Electronics recycling example using service-based architecture\nThis example illustrates many of the benefits of the service-based architecture\napproach: scalability, fault tolerance, and security (data and functionality protection\nand access), in addition to agility, testability, and deployability. For example, the\nAssessment service is changed constantly to add assessment rules as new products\nare received. This frequent change is isolated to a single domain service, providing\nagility (the ability to respond quickly to change), as well as testability (the ease of and\ncompleteness of testing) and deployability (the ease, frequency, and risk of\ndeployment).\nExample Architecture \n| \n173\n", "page": 193, "type": "text", "section": "Page 193"}
{"text": "Architecture Characteristics Ratings\nA one-star rating in the characteristics ratings table in Figure 13-9 means the specific\narchitecture characteristic isn\u2019t well supported in the architecture, whereas a five-star\nrating means the architecture characteristic is one of the strongest features in the\narchitecture style. The definition for each characteristic identified in the scorecard\ncan be found in Chapter 4.\nFigure 13-9. Service-based architecture characteristics ratings\nService-based architecture is a domain-partitioned architecture, meaning that the\nstructure is driven by the domain rather than a technical consideration (such as pre\u2010\nsentation logic or persistence logic). Consider the prior example of the electronic\nrecycling application. Each service, being a separately deployed unit of software, is\nscoped to a specific domain (such as item assessment). Changes made within this\ndomain only impact the specific service, the corresponding user interface, and the\n174 \n| \nChapter 13: Service-Based Architecture Style\n", "page": 194, "type": "text", "section": "Page 194"}
{"text": "corresponding database. Nothing else needs to be modified to support a specific\nassessment change.\nBeing a distributed architecture, the number of quanta can be greater than or equal to\none. Even though there may be anywhere from 4 to 12 separately deployed services, if\nthose services all share the same database or user interface, that entire system would\nbe only a single quantum. However, as illustrated in \u201cTopology Variants\u201d on page 165,\nboth the user interface and database can be federated, resulting in multiple quanta\nwithin the overall system. In the electronics recycling example, the system contains\ntwo quanta, as illustrated in Figure 13-10: one for the customer-facing portion of the\napplication containing a separate customer user interface, database, and set of serv\u2010\nices (Quoting and Item Status); and one for the internal operations of receiving,\nassessing, and recycling the electronic device. Notice that even though the internal\noperations quantum contains separately deployed services and two separate user\ninterfaces, they all share the same database, making the internal operations portion of\nthe application a single quantum.\nFigure 13-10. Separate quanta in a service-based architecture\nArchitecture Characteristics Ratings \n| \n175\n", "page": 195, "type": "text", "section": "Page 195"}
{"text": "Although service-based architecture doesn\u2019t contain any five-star ratings, it neverthe\u2010\nless rates high (four stars) in many important and vital areas. Breaking apart an appli\u2010\ncation into separately deployed domain services using this architecture style allows\nfor faster change (agility), better test coverage due to the limited scope of the domain\n(testability), and the ability for more frequent deployments carrying less risk than a\nlarge monolith (deployability). These three characteristics lead to better time-to-\nmarket, allowing an organization to deliver new features and bug fixes at a relatively\nhigh rate.\nFault tolerance and overall application availability also rate high for service-based\narchitecture. Even though domain services tend to be coarse-grained, the four-star\nrating comes from the fact that with this architecture style, services are usually self-\ncontained and do not leverage interservice communication due to database sharing\nand code sharing. As a result, if one domain service goes down (e.g., the Receiving\nservice in the electronic recycling application example), it doesn\u2019t impact any of the\nother six services.\nScalability only rates three stars due to the coarse-grained nature of the services, and\ncorrespondingly, elasticity only two stars. Although programmatic scalability and\nelasticity are certainly possible with this architecture style, more functionality is repli\u2010\ncated than with finer-grained services (such as microservices) and as such is not as\nefficient in terms of machine resources and not as cost-effective. Typically there are\nonly single service instances with service-based architecture unless there is a need for\nbetter throughput or failover. A good example of this is the electronics recycling\napplication example\u2014only the Quoting and Item Status services need to scale to\nsupport high customer volumes, but the other operational services only require single\ninstances, making it easier to support such things as single in-memory caching and\ndatabase connection pooling.\nSimplicity and overall cost are two other drivers that differentiate this architecture\nstyle from other, more expensive and complex distributed architectures, such as\nmicroservices, event-driven architecture, or even space-based architecture. This\nmakes service-based one of the easiest and cost-effective distributed architectures to\nimplement. While this is an attractive proposition, there is a trade-off to this cost sav\u2010\nings and simplicity in all of the characteristics containing four-star ratings. The\nhigher the cost and complexity, the better these ratings become.\nService-based architectures tend to be more reliable than other distributed architec\u2010\ntures due to the coarse-grained nature of the domain services. Larger services mean\nless network traffic to and between services, fewer distributed transactions, and less\nbandwidth used, therefore increasing overall reliability with respect to the network.\n176 \n| \nChapter 13: Service-Based Architecture Style\n", "page": 196, "type": "text", "section": "Page 196"}
{"text": "When to Use This Architecture Style\nThe flexibility of this architecture style (see \u201cTopology Variants\u201d on page 165) com\u2010\nbined with the number of three-star and four-star architecture characteristics ratings\nmake service-based architecture one of the most pragmatic architecture styles avail\u2010\nable. While there are certainly other distributed architecture styles that are much\nmore powerful, some companies find that power comes at too steep of a price, while\nothers find that they quite simply don\u2019t need that much power. It\u2019s like having the\npower, speed, and agility of a Ferrari used only for driving back and forth to work in\nrush-hour traffic at 50 kilometers per hour\u2014sure it looks cool, but what a waste of\nresources and money!\nService-based architecture is also a natural fit when doing domain-driven design.\nBecause services are coarse-grained and domain-scoped, each domain fits nicely into\na separately deployed domain service. Each service in service-based architecture\nencompasses a particular domain (such as recycling in the electronic recycling appli\u2010\ncation), therefore compartmentalizing that functionality into a single unit of software,\nmaking it easier to apply changes to that domain.\nMaintaining and coordinating database transactions is always an issue with dis\u2010\ntributed architectures in that they typically rely on eventual consistency rather than\ntraditional ACID (atomicity, consistency, isolation, and durability) transactions.\nHowever, service-based architecture preserves ACID transactions better than any\nother distributed architecture due to the coarse-grained nature of the domain serv\u2010\nices. There are cases where the user interface or API gateway might orchestrate two or\nmore domain services, and in these cases the transaction would need to rely on sagas\nand BASE transactions. However, in most cases the transaction is scoped to a particu\u2010\nlar domain service, allowing for the traditional commit and rollback transaction\nfunctionality found in most monolithic applications.\nLastly, service-based architecture is a good choice for achieving a good level of archi\u2010\ntectural modularity without having to get tangled up in the complexities and pitfalls\nof granularity. As services become more fine-grained, issues surrounding orchestra\u2010\ntion and choreography start to appear. Both orchestration and choreography are\nrequired when multiple services must be coordinated to complete a certain business\ntransaction. Orchestration is the coordination of multiple services through the use of\na separate mediator service that controls and manages the workflow of the transac\u2010\ntion (like a conductor in an orchestra). Choreography, on the other hand, is the coor\u2010\ndination of multiple services by which each service talks to one another without the\nuse of a central mediator (like dancers in a dance). As services become more fine-\ngrained, both orchestration and choreography are necessary to tie the services\ntogether to complete the business transaction. However, because services within a\nservice-based architecture tend to be more coarse-grained, they don\u2019t require coordi\u2010\nnation nearly as much as other distributed architectures.\nWhen to Use This Architecture Style \n| \n177\n", "page": 197, "type": "text", "section": "Page 197"}
{"text": "CHAPTER 14\nEvent-Driven Architecture Style\nThe event-driven architecture style is a popular distributed asynchronous architecture\nstyle used to produce highly scalable and high-performance applications. It is also\nhighly adaptable and can be used for small applications and as well as large, complex\nones. Event-driven architecture is made up of decoupled event processing compo\u2010\nnents that asynchronously receive and process events. It can be used as a standalone\narchitecture style or embedded within other architecture styles (such as an event-\ndriven microservices architecture).\nMost applications follow what is called a request-based model (illustrated in\nFigure 14-1). In this model, requests made to the system to perform some sort of\naction are send to a request orchestrator. The request orchestrator is typically a user\ninterface, but it can also be implemented through an API layer or enterprise service\nbus. The role of the request orchestrator is to deterministically and synchronously\ndirect the request to various request processors. The request processors handle the\nrequest, either retrieving or updating information in a database.\nA good example of the request-based model is a request from a customer to retrieve\ntheir order history for the past six months. Retrieving order history information is a\ndata-driven, deterministic request made to the system for data within a specific con\u2010\ntext, not an event happening that the system must react to.\nAn event-based model, on the other hand, reacts to a particular situation and takes\naction based on that event. An example of an event-based model is submitting a bid\nfor a particular item within an online auction. Submitting the bid is not a request\nmade to the system, but rather an event that happens after the current asking price is\nannounced. The system must respond to this event by comparing the bid to others\nreceived at the same time to determine who is the current highest bidder.\n179\n", "page": 199, "type": "text", "section": "Page 199"}
{"text": "Figure 14-1. Request-based model\nTopology\nThere are two primary topologies within event-driven architecture: the mediator top\u2010\nology and the broker topology. The mediator topology is commonly used when you\nrequire control over the workflow of an event process, whereas the broker topology is\nused when you require a high degree of responsiveness and dynamic control over the\nprocessing of an event. Because the architecture characteristics and implementation\nstrategies differ between these two topologies, it is important to understand each one\nto know which is best suited for a particular situation.\nBroker Topology\nThe broker topology differs from the mediator topology in that there is no central\nevent mediator. Rather, the message flow is distributed across the event processor\ncomponents in a chain-like broadcasting fashion through a lightweight message\nbroker (such as RabbitMQ, ActiveMQ, HornetQ, and so on). This topology is useful\nwhen you have a relatively simple event processing flow and you do not need central\nevent orchestration and coordination.\n180 \n| \nChapter 14: Event-Driven Architecture Style\n", "page": 200, "type": "text", "section": "Page 200"}
{"text": "There are four primary architecture components within the broker topology: an ini\u2010\ntiating event, the event broker, an event processor, and a processing event. The initiat\u2010\ning event is the initial event that starts the entire event flow, whether it be a simple\nevent like placing a bid in an online auction or more complex events in a health bene\u2010\nfits system like changing a job or getting married. The initiating event is sent to an\nevent channel in the event broker for processing. Since there is no mediator compo\u2010\nnent in the broker topology managing and controlling the event, a single event pro\u2010\ncessor accepts the initiating event from the event broker and begins the processing of\nthat event. The event processor that accepted the initiating event performs a specific\ntask associated with the processing of that event, then asynchronously advertises what\nit did to the rest of the system by creating what is called a processing event. This pro\u2010\ncessing event is then asynchronously sent to the event broker for further processing,\nif needed. Other event processors listen to the processing event, react to that event by\ndoing something, then advertise through a new processing event what they did. This\nprocess continues until no one is interested in what a final event processor did.\nFigure 14-2 illustrates this event processing flow.\nThe event broker component is usually federated (meaning multiple domain-based\nclustered instances), where each federated broker contains all of the event channels\nused within the event flow for that particular domain. Because of the decoupled asyn\u2010\nchronous fire-and-forget broadcasting nature of the broker topology, topics (or topic\nexchanges in the case of AMQP) are usually used in the broker topology using a\npublish-and-subscribe messaging model.\nFigure 14-2. Broker topology\nBroker Topology \n| \n181\n", "page": 201, "type": "text", "section": "Page 201"}
{"text": "It is always a good practice within the broker topology for each event processor to\nadvertise what it did to the rest of the system, regardless of whether or not any other\nevent processor cares about what that action was. This practice provides architectural\nextensibility if additional functionality is required for the processing of that event.\nFor example, suppose as part of a complex event process, as illustrated in Figure 14-3,\nan email is generated and sent to a customer notifying them of a particular action\ntaken. The Notification event processor would generate and send the email, then\nadvertise that action to the rest of the system through a new processing event sent to a\ntopic. However, in this case, no other event processors are listening for events on that\ntopic, and as such the message simply goes away.\nFigure 14-3. Notification event is sent but ignored\nThis is a good example of architectural extensibility. While it may seem like a waste of\nresources sending messages that are ignored, it is not. Suppose a new requirement\ncomes along to analyze emails that have been sent to customers. This new event pro\u2010\ncessor can be added to the overall system with minimal effort because the email\ninformation is available via the email topic to the new analyzer without having to add\nany additional infrastructure or apply any changes to other event processors.\nTo illustrate how the broker topology works, consider the processing flow in a typical\nretail order entry system, as illustrated in Figure 14-4, where an order is placed for an\nitem (say, a book like this one). In this example, the OrderPlacement event processor\nreceives the initiating event (PlaceOrder), inserts the order in a database table, and\nreturns an order ID to the customer. It then advertises to the rest of the system that it\ncreated an order through an order-created processing event. Notice that three event\nprocessors are interested in that event: the Notification event processor, the\nPayment event processor, and the Inventory event processor. All three of these event\nprocessors perform their tasks in parallel.\n182 \n| \nChapter 14: Event-Driven Architecture Style\n", "page": 202, "type": "text", "section": "Page 202"}
{"text": "Figure 14-4. Example of the broker topology\nThe Notification event processor receives the order-created processing event and\nemails the customer. It then generates another processing event (email-sent). Notice\nthat no other event processors are listening to that event. This is normal and illus\u2010\ntrates the previous example describing architectural extensibility\u2014an in-place hook\nso that other event processors can eventually tap into that event feed, if needed.\nBroker Topology \n| \n183\n", "page": 203, "type": "text", "section": "Page 203"}
{"text": "The Inventory event processor also listens for the order-created processing event\nand decrements the corresponding inventory for that book. It then advertises this\naction through an inventory-updated processing event, which is in turn picked up\nby the Warehouse event processor to manage the corresponding inventory between\nwarehouses, reordering items if supplies get too low.\nThe Payment event processor also receives the order-created processing event and\ncharges the customer\u2019s credit card for the order that was just created. Notice in\nFigure 14-4 that two events are generated as a result of the actions taken by the\nPayment event processor: one to notify the rest of the system that the payment was\napplied (payment-applied) and one processing event to notify the rest of the system\nthat the payment was denied (payment-denied). Notice that the Notification event\nprocessor is interested in the payment-denied processing event, because it must, in\nturn, send an email to the customer informing them that they must update their\ncredit card information or choose a different payment method.\nThe OrderFulfillment event processor listens to the payment-applied processing\nevent and does order picking and packing. Once completed, it then advertises to the\nrest of the system that it fulfilled the order via an order-fulfilled processing event.\nNotice that both the Notification processing unit and the Shipping processing unit\nlisten to this processing event. Concurrently, the Notification event processor noti\u2010\nfies the customer that the order has been fulfilled and is ready for shipment, and at\nthe same time the Shipping event processor selects a shipping method. The Shipping\nevent processor ships the order and sends out an order-shipped processing event,\nwhich the Notification event processor also listens for to notify the customer of the\norder status change.\nIn analyzing the prior example, notice that all of the event processors are highly\ndecoupled and independent of each other. The best way to understand the broker\ntopology is to think about it as a relay race. In a relay race, runners hold a baton (a\nwooden stick) and run for a certain distance (say 1.5 kilometers), then hand off the\nbaton to the next runner, and so on down the chain until the last runner crosses the\nfinish line. In relay races, once a runner hands off the baton, that runner is done with\nthe race and moves on to other things. This is also true with the broker topology.\nOnce an event processor hands off the event, it is no longer involved with the pro\u2010\ncessing of that specific event and is available to react to other initiating or processing\nevents. In addition, each event processor can scale independently from one other to\nhandle varying load conditions or backups in the processing within that event. The\ntopics provide the back pressure point if an event processor comes down or slows\ndown due to some environment issue.\n184 \n| \nChapter 14: Event-Driven Architecture Style\n", "page": 204, "type": "text", "section": "Page 204"}
{"text": "While performance, responsiveness, and scalability are all great benefits of the broker\ntopology, there are also some negatives about it. First of all, there is no control over\nthe overall workflow associated with the initiating event (in this case, the PlaceOrder\nevent). It is very dynamic based on various conditions, and no one in the system\nreally knows when the business transaction of placing an order is actually complete.\nError handling is also a big challenge with the broker topology. Because there is no\nmediator monitoring or controlling the business transaction, if a failure occurs (such\nas the Payment event processor crashing and not completing its assigned task), no one\nin the system is aware of that crash. The business process gets stuck and is unable to\nmove without some sort of automated or manual intervention. Furthermore, all other\nprocesses are moving along without regard for the error. For example, the Inventory\nevent processor still decrements the inventory, and all other event processors react as\nthough everything is fine.\nThe ability to restart a business transaction (recoverability) is also something not\nsupported with the broker topology. Because other actions have asynchronously been\ntaken through the initial processing of the initiating event, it is not possible to resub\u2010\nmit the initiating event. No component in the broker topology is aware of the state or\neven owns the state of the original business request, and therefore no one is responsi\u2010\nble in this topology for restarting the business transaction (the initiating event) and\nknowing where it left off. The advantages and disadvantages of the broker topology\nare summarized in Table 14-1.\nTable 14-1. Trade-offs of the broker topology\nAdvantages\nDisadvantages\nHighly decoupled event processors\nWorkflow control\nHigh scalability\nError handling\nHigh responsiveness\nRecoverability\nHigh performance\nRestart capabilities\nHigh fault tolerance\nData inconsistency\nMediator Topology\nThe mediator topology of event-driven architecture addresses some of the shortcom\u2010\nings of the broker topology described in the previous section. Central to this topology\nis an event mediator, which manages and controls the workflow for initiating events\nthat require the coordination of multiple event processors. The architecture compo\u2010\nnents that make up the mediator topology are an initiating event, an event queue, an\nevent mediator, event channels, and event processors.\nMediator Topology \n| \n185\n", "page": 205, "type": "text", "section": "Page 205"}
{"text": "Like in the broker topology, the initiating event is the event that starts the whole\neventing process. Unlike the broker topology, the initiating event is sent to an initiat\u2010\ning event queue, which is accepted by the event mediator. The event mediator only\nknows the steps involved in processing the event and therefore generates correspond\u2010\ning processing events that are sent to dedicated event channels (usually queues) in a\npoint-to-point messaging fashion. Event processors then listen to dedicated event\nchannels, process the event, and usually respond back to the mediator that they have\ncompleted their work. Unlike the broker topology, event processors within the medi\u2010\nator topology do not advertise what they did to the rest of the system. The mediator\ntopology is illustrated in Figure 14-5.\nFigure 14-5. Mediator topology\nIn most implementations of the mediator topology, there are multiple mediators, usu\u2010\nally associated with a particular domain or grouping of events. This reduces the single\npoint of failure issue associated with this topology and also increases overall through\u2010\nput and performance. For example, there might be a customer mediator that handles\nall customer-related events (such as new customer registration and profile update),\nand another mediator that handles order-related activities (such as adding an item to\na shopping cart and checking out).\nThe event mediator can be implemented in a variety of ways, depending on the\nnature and complexity of the events it is processing. For example, for events requiring\nsimple error handling and orchestration, a mediator such as Apache Camel, Mule\nESB, or Spring Integration will usually suffice. Message flows and message routes\nwithin these types of mediators are typically custom written in programming code\n(such as Java or C#) to control the workflow of the event processing.\nHowever, if the event workflow requires lots of conditional processing and multiple\ndynamic paths with complex error handling directives, then a mediator such as\n186 \n| \nChapter 14: Event-Driven Architecture Style\n", "page": 206, "type": "text", "section": "Page 206"}
{"text": "Apache ODE or the Oracle BPEL Process Manager would be a good choice. These\nmediators are based on Business Process Execution Language (BPEL), an XML-like\nstructure that describes the steps involved in processing an event. BPEL artifacts also\ncontain structured elements used for error handling, redirection, multicasting, and so\non. BPEL is a powerful but relatively complex language to learn, and as such is usu\u2010\nally created using graphical interface tools provided in the product\u2019s BPEL engine\nsuite.\nBPEL is good for complex and dynamic workflows, but it does not work well for\nthose event workflows requiring long-running transactions involving human inter\u2010\nvention throughout the event process. For example, suppose a trade is being placed\nthrough a place-trade initiating event. The event mediator accepts this event, but\nduring the processing finds that a manual approval is required because the trade is\nover a certain amount of shares. In this case the event mediator would have to stop\nthe event processing, send a notification to a senior trader for the manual approval,\nand wait for that approval to occur. In these cases a Business Process Management\n(BPM) engine such as jBPM would be required.\nIt is important to know the types of events that will be processed through the media\u2010\ntor in order to make the correct choice for the implementation of the event mediator.\nChoosing Apache Camel for complex and long-running events involving human\ninteraction would be extremely difficult to write and maintain. By the same token,\nusing a BPM engine for simple event flows would take months of wasted effort when\nthe same thing could be accomplished in Apache Camel in a matter of days.\nGiven that it\u2019s rare to have all events of one class of complexity, we recommend classi\u2010\nfying events as simple, hard, or complex and having every event always go through a\nsimple mediator (such as Apache Camel or Mule). The simple mediator can then\ninterrogate the classification of the event, and based on that classification, handle the\nevent itself or forward it to another, more complex, event mediator. In this manner,\nall types of events can be effectively processed by the type of mediator needed for that\nevent. This mediator delegation model is illustrated in Figure 14-6.\nMediator Topology \n| \n187\n", "page": 207, "type": "text", "section": "Page 207"}
{"text": "Figure 14-6. Delegating the event to the appropriate type of event mediator\nNotice in Figure 14-6 that the Simple Event Mediator generates and sends a pro\u2010\ncessing event when the event workflow is simple and can be handled by the simple\nmediator. However, notice that when the initiating event coming into the Simple\nEvent Mediator is classified as either hard or complex, it forwards the original ini\u2010\ntiating event to the corresponding mediators (BPEL or BMP). The Simple Event\nMediator, having intercepted the original event, may still be responsible for knowing\nwhen that event is complete, or it simply delegates the entire workflow (including cli\u2010\nent notification) to the other mediators.\nTo illustrate how the mediator topology works, consider the same retail order entry\nsystem example described in the prior broker topology section, but this time using\nthe mediator topology. In this example, the mediator knows the steps required to pro\u2010\ncess this particular event. This event flow (internal to the mediator component) is\nillustrated in Figure 14-7.\n188 \n| \nChapter 14: Event-Driven Architecture Style\n", "page": 208, "type": "text", "section": "Page 208"}
{"text": "Figure 14-7. Mediator steps for placing an order\nIn keeping with the prior example, the same initiating event (PlaceOrder) is sent to\nthe customer-event-queue for processing. The Customer mediator picks up this ini\u2010\ntiating event and begins generating processing events based on the flow in\nFigure 14-7. Notice that the multiple events shown in steps 2, 3, and 4 are all done\nconcurrently and serially between steps. In other words, step 3 (fulfill order) must be\ncompleted and acknowledged before the customer can be notified that the order is\nready to be shipped in step 4 (ship order).\nOnce the initiating event has been received, the Customer mediator generates a\ncreate-order processing event and sends this message to the order-placement-\nqueue (see Figure 14-8). The OrderPlacement event processor accepts this event and\nvalidates and creates the order, returning to the mediator an acknowledgement along\nwith the order ID. At this point the mediator might send that order ID back to the\ncustomer, indicating that the order was placed, or it might have to continue until all\nthe steps are complete (this would be based on specific business rules about order\nplacement).\nMediator Topology \n| \n189\n", "page": 209, "type": "text", "section": "Page 209"}
{"text": "Figure 14-8. Step 1 of the mediator example\nNow that step 1 is complete, the mediator now moves to step 2 (see Figure 14-9) and\ngenerates three messages at the same time: email-customer, apply-payment, and\nadjust-inventory. These processing events are all sent to their respective queues. All\nthree event processors receive these messages, perform their respective tasks, and\nnotify the mediator that the processing has been completed. Notice that the mediator\nmust wait until it receives acknowledgement from all three parallel processes before\nmoving on to step 3. At this point, if an error occurs in one of the parallel event pro\u2010\ncessors, the mediator can take corrective action to fix the problem (this is discussed\nlater in this section in more detail).\n190 \n| \nChapter 14: Event-Driven Architecture Style\n", "page": 210, "type": "text", "section": "Page 210"}
{"text": "Figure 14-9. Step 2 of the mediator example\nMediator Topology \n| \n191\n", "page": 211, "type": "text", "section": "Page 211"}
{"text": "Once the mediator gets a successful acknowledgment from all of the event processors\nin step 2, it can move on to step 3 to fulfill the order (see Figure 14-10). Notice once\nagain that both of these events (fulfill-order and order-stock) can occur simulta\u2010\nneously. The OrderFulfillment and Warehouse event processors accept these events,\nperform their work, and return an acknowledgement to the mediator.\nFigure 14-10. Step 3 of the mediator example\n192 \n| \nChapter 14: Event-Driven Architecture Style\n", "page": 212, "type": "text", "section": "Page 212"}
{"text": "Once these events are complete, the mediator then moves on to step 4 (see\nFigure 14-11) to ship the order. This step generates another email-customer process\u2010\ning event with specific information about what to do (in this case, notify the customer\nthat the order is ready to be shipped), as well as a ship-order event.\nFigure 14-11. Step 4 of the mediator example\nFinally, the mediator moves to step 5 (see Figure 14-12) and generates another con\u2010\ntextual email-customer event to notify the customer that the order has been shipped.\nAt this point the workflow is done, and the mediator marks the initiating event flow\ncomplete and removes all state associated with the initiating event.\nMediator Topology \n| \n193\n", "page": 213, "type": "text", "section": "Page 213"}
{"text": "Figure 14-12. Step 5 of the mediator example\nThe mediator component has knowledge and control over the workflow, something\nthe broker topology does not have. Because the mediator controls the workflow, it\ncan maintain event state and manage error handling, recoverability, and restart capa\u2010\nbilities. For example, suppose in the prior example the payment was not applied due\nto the credit card being expired. In this case the mediator receives this error condi\u2010\ntion, and knowing the order cannot be fulfilled (step 3) until payment is applied,\nstops the workflow and records the state of the request in its own persistent datastore.\nOnce payment is eventually applied, the workflow can be restarted from where it left\noff (in this case, the beginning of step 3).\n194 \n| \nChapter 14: Event-Driven Architecture Style\n", "page": 214, "type": "text", "section": "Page 214"}
{"text": "Another inherent difference between the broker and mediator topology is how the\nprocessing events differ in terms of their meaning and how they are used. In the\nbroker topology example in the previous section, the processing events were pub\u2010\nlished as events that had occurred in the system (such as order-created, payment-\napplied, and email-sent). The event processors took some action, and other event\nprocessors react to that action. However, in the mediator topology, processing occur\u2010\nrences such as place-order, send-email, and fulfill-order are commands (things\nthat need to happen) as opposed to events (things that have already happened). Also,\nin the mediator topology, a command must be processed, whereas an event can be\nignored in the broker topology.\nWhile the mediator topology addresses the issues associated with the broker topol\u2010\nogy, there are some negatives associated with the mediator topology. First of all, it is\nvery difficult to declaratively model the dynamic processing that occurs within a\ncomplex event flow. As a result, many workflows within the mediator only handle the\ngeneral processing, and a hybrid model combining both the mediator and broker\ntopologies is used to address the dynamic nature of complex event processing (such\nas out-of-stock conditions or other nontypical errors). Furthermore, although the\nevent processors can easily scale in the same manner as the broker topology, the\nmediator must scale as well, something that occasionally produces a bottleneck in the\noverall event processing flow. Finally, event processors are not as highly decoupled in\nthe mediator topology as with the broker topology, and performance is not as good\ndue to the mediator controlling the processing of the event. These trade-offs are sum\u2010\nmarized in Table 14-2.\nTable 14-2. Trade-offs of the mediator topology\nAdvantages\nDisadvantages\nWorkflow control\nMore coupling of event processors\nError handling\nLower scalability\nRecoverability\nLower performance\nRestart capabilities\nLower fault tolerance\nBetter data consistency\nModeling complex workflows\nThe choice between the broker and mediator topology essentially comes down to a\ntrade-off between workflow control and error handling capability versus high perfor\u2010\nmance and scalability. Although performance and scalability are still good within the\nmediator topology, they are not as high as with the broker topology.\nMediator Topology \n| \n195\n", "page": 215, "type": "text", "section": "Page 215"}
{"text": "Asynchronous Capabilities\nThe event-driven architecture style offers a unique characteristic over other architec\u2010\nture styles in that it relies solely on asynchronous communication for both fire-and-\nforget processing (no response required) as well as request/reply processing\n(response required from the event consumer). Asynchronous communication can be\na powerful technique for increasing the overall responsiveness of a system.\nConsider the example illustrated in Figure 14-13 where a user is posting a comment\non a website for a particular product review. Assume the comment service in this\nexample takes 3,000 milliseconds to post the comment because it goes through sev\u2010\neral parsing engines: a bad word checker to check for unacceptable words, a grammar\nchecker to make sure that the sentence structures are not saying something abusive,\nand finally a context checker to make sure the comment is about a particular product\nand not just a political rant. Notice in Figure 14-13 that the top path utilizes a syn\u2010\nchronous RESTful call to post the comment: 50 milliseconds in latency for the service\nto receive the post, 3,000 milliseconds to post the comment, and 50 milliseconds in\nnetwork latency to respond back to the user that the comment was posted. This\ncreates a response time for the user of 3,100 milliseconds to post a comment. Now\nlook at the bottom path and notice that with the use of asynchronous messaging, the\nresponse time from the end user\u2019s perspective for posting a comment on the website\nis only 25 milliseconds (as opposed to 3,100 milliseconds). It still takes 3,025 milli\u2010\nseconds to post the comment (25 milliseconds to receive the message and 3,000 milli\u2010\nseconds to post the comment), but from the end user\u2019s perspective it\u2019s already been\ndone.\nFigure 14-13. Synchronous versus asynchronous communication\n196 \n| \nChapter 14: Event-Driven Architecture Style\n", "page": 216, "type": "text", "section": "Page 216"}
{"text": "This is a good example of the difference between responsiveness and performance.\nWhen the user does not need any information back (other than an acknowledgement\nor a thank you message), why make the user wait? Responsiveness is all about notify\u2010\ning the user that the action has been accepted and will be processed momentarily,\nwhereas performance is about making the end-to-end process faster. Notice that\nnothing was done to optimize the way the comment service processes the text\u2014in\nboth cases it is still taking 3,000 milliseconds. Addressing performance would have\nbeen optimizing the comment service to run all of the text and grammar parsing\nengines in parallel with the use of caching and other similar techniques. The bottom\nexample in Figure 14-13 addresses the overall responsiveness of the system but not\nthe performance of the system.\nThe difference in response time between the two examples in Figure 14-13 from\n3,100 milliseconds to 25 milliseconds is staggering. There is one caveat. On the syn\u2010\nchronous path shown on the top of the diagram, the end user is guaranteed that the\ncomment has been posted. However, on the bottom path there is only the acknowl\u2010\nedgement of the post, with a future promise that eventually the comment will get pos\u2010\nted. From the end user\u2019s perspective, the comment has been posted. But what\nhappens if the user had typed a bad word in the comment? In this case the comment\nwould be rejected, but there is no way to get back to the end user. Or is there? In this\nexample, assuming the user is registered with the website (which to post a comment\nthey would have to be), a message could be sent to the user indicating a problem with\nthe comment and some suggestions on how to repair it. This is a simple example.\nWhat about a more complicated example where the purchase of some stock is taking\nplace asynchronously (called a stock trade) and there is no way to get back to the\nuser?\nThe main issue with asynchronous communications is error handling. While respon\u2010\nsiveness is significantly improved, it is difficult to address error conditions, adding to\nthe complexity of the event-driven system. The next section addresses this issue with\na pattern of reactive architecture called the workflow event pattern.\nError Handling\nThe workflow event pattern of reactive architecture is one way of addressing the\nissues associated with error handling in an asynchronous workflow. This pattern is a\nreactive architecture pattern that addresses both resiliency and responsiveness. In\nother words, the system can be resilient in terms of error handling without an impact\nto responsiveness.\nThe workflow event pattern leverages delegation, containment, and repair through\nthe use of a workflow delegate, as illustrated in Figure 14-14. The event producer\nasynchronously passes data through a message channel to the event consumer. If the\nevent consumer experiences an error while processing the data, it immediately dele\u2010\nError Handling \n| \n197\n", "page": 217, "type": "text", "section": "Page 217"}
{"text": "gates that error to the workflow processor and moves on to the next message in the\nevent queue. In this way, overall responsiveness is not impacted because the next\nmessage is immediately processed. If the event consumer were to spend the time try\u2010\ning to figure out the error, then it is not reading the next message in the queue, there\u2010\nfore impacting the responsiveness not only of the next message, but all other\nmessages waiting in the queue to be processed.\nOnce the workflow processor receives an error, it tries to figure out what is wrong\nwith the message. This could be a static, deterministic error, or it could leverage some\nmachine learning algorithms to analyze the message to see some anomaly in the data.\nEither way, the workflow processor programmatically (without human intervention)\nmakes changes to the original data to try and repair it, and then sends it back to the\noriginating queue. The event consumer sees this message as a new one and tries to\nprocess it again, hopefully this time with some success. Of course, there are many\ntimes when the workflow processor cannot determine what is wrong with the mes\u2010\nsage. In these cases the workflow processor sends the message off to another queue,\nwhich is then received in what is usually called a \u201cdashboard,\u201d an application that\nlooks similar to the Microsoft\u2019s Outlook or Apple\u2019s Mail. This dashboard usually\nresides on the desktop of a person of importance, who then looks at the message,\napplies manual fixes to it, and then resubmits it to the original queue (usually\nthrough a reply-to message header variable).\nFigure 14-14. Workflow event pattern of reactive architecture\nTo illustrate the workflow event pattern, suppose a trading advisor in one part of the\ncountry accepts trade orders (instructions on what stock to buy and for how many\nshares) on behalf of a large trading firm in another part of the country. The advisor\nbatches up the trade orders (what is usually called a basket) and asynchronously\nsends those to the large trading firm to be placed with a broker so the stock can be\n198 \n| \nChapter 14: Event-Driven Architecture Style\n", "page": 218, "type": "text", "section": "Page 218"}
{"text": "purchased. To simplify the example, suppose the contract for the trade instructions\nmust adhere to the following:\nACCOUNT(String),SIDE(String),SYMBOL(String),SHARES(Long)\nSuppose the large trading firm receives the following basket of Apple (AAPL) trade\norders from the trading advisor:\n12654A87FR4,BUY,AAPL,1254\n87R54E3068U,BUY,AAPL,3122\n6R4NB7609JJ,BUY,AAPL,5433\n2WE35HF6DHF,BUY,AAPL,8756 SHARES\n764980974R2,BUY,AAPL,1211\n1533G658HD8,BUY,AAPL,2654\nNotice the forth trade instruction (2WE35HF6DHF,BUY,AAPL,8756 SHARES) has the\nword SHARES after the number of shares for the trade. When these asynchronous\ntrade orders are processed by the large trading firm without any error handling capa\u2010\nbilities, the following error occurs within the trade placement service:\nException in thread \"main\" java.lang.NumberFormatException:\n \nFor input string: \"8756 SHARES\"\n \nat java.lang.NumberFormatException.forInputString\n \n(NumberFormatException.java:65)\n \nat java.lang.Long.parseLong(Long.java:589)\n \nat java.lang.Long.<init>(Long.java:965)\n \nat trading.TradePlacement.execute(TradePlacement.java:23)\n \nat trading.TradePlacement.main(TradePlacement.java:29)\nWhen this exception occurs, there is nothing that the trade placement service can do,\nbecause this was an asynchronous request, except to possibly log the error condition.\nIn other words, there is no user to synchronously respond to and fix the error.\nApplying the workflow event pattern can programmatically fix this error. Because the\nlarge trading firm has no control over the trading advisor and the corresponding\ntrade order data it sends, it must react to fix the error itself (as illustrated in\nFigure 14-15). When the same error occurs (2WE35HF6DHF,BUY,AAPL,8756 SHARES),\nthe Trade Placement service immediately delegates the error via asynchronous mes\u2010\nsaging to the Trade Placement Error service for error handling, passing with the\nerror information about the exception:\nTrade Placed: 12654A87FR4,BUY,AAPL,1254\nTrade Placed: 87R54E3068U,BUY,AAPL,3122\nTrade Placed: 6R4NB7609JJ,BUY,AAPL,5433\nError Placing Trade: \"2WE35HF6DHF,BUY,AAPL,8756 SHARES\"\nSending to trade error processor  <-- delegate the error fixing and move on\nTrade Placed: 764980974R2,BUY,AAPL,1211\n...\nError Handling \n| \n199\n", "page": 219, "type": "text", "section": "Page 219"}
{"text": "The Trade Placement Error service (acting as the workflow delegate) receives the\nerror and inspects the exception. Seeing that it is an issue with the word SHARES in the\nnumber of shares field, the Trade Placement Error service strips off the word\nSHARES and resubmits the trade for reprocessing:\nReceived Trade Order Error: 2WE35HF6DHF,BUY,AAPL,8756 SHARES\nTrade fixed: 2WE35HF6DHF,BUY,AAPL,8756\nResubmitting Trade For Re-Processing\nThe fixed trade is then processed successfully by the trade placement service:\n...\ntrade placed: 1533G658HD8,BUY,AAPL,2654\ntrade placed: 2WE35HF6DHF,BUY,AAPL,8756 <-- this was the original trade in error\nFigure 14-15. Error handling with the workflow event pattern\nOne of the consequences of the workflow event pattern is that messages in error are\nprocessed out of sequence when they are resubmitted. In our trading example, the\norder of messages matters, because all trades within a given account must be pro\u2010\ncessed in order (for example, a SELL for IBM must occur before a BUY for AAPL\nwithin the same brokerage account). Although not impossible, it is a complex task to\nmaintain message order within a given context (in this case the brokerage account\nnumber). One way this can be addressed is by the Trade Placement service queueing\nand storing the account number of the trade in error. Any trade with that same\naccount number would be stored in a temporary queue for later processing (in FIFO\norder). Once the trade originally in error is fixed and processed, the Trade Place\nment service then de-queues the remaining trades for that same account and pro\u2010\ncesses them in order.\n200 \n| \nChapter 14: Event-Driven Architecture Style\n", "page": 220, "type": "text", "section": "Page 220"}
{"text": "Preventing Data Loss\nData loss is always a primary concern when dealing with asynchronous communica\u2010\ntions. Unfortunately, there are many places for data loss to occur within an event-\ndriven architecture. By data loss we mean a message getting dropped or never making\nit to its final destination. Fortunately, there are basic out-of-the-box techniques that\ncan be leveraged to prevent data loss when using asynchronous messaging.\nTo illustrate the issues associated with data loss within event-driven architecture, sup\u2010\npose Event Processor A asynchronously sends a message to a queue. Event\nProcessor B accepts the message and inserts the data within the message into a data\u2010\nbase. As illustrated in Figure 14-16, three areas of data loss can occur within this typi\u2010\ncal scenario:\n1. The message never makes it to the queue from Event Processor A; or even if it\ndoes, the broker goes down before the next event processor can retrieve the\nmessage.\n2. Event Processor B de-queues the next available message and crashes before it\ncan process the event.\n3. Event Processor B is unable to persist the message to the database due to some\ndata error.\nFigure 14-16. Where data loss can happen within an event-driven architecture\nEach of these areas of data loss can be mitigated through basic messaging techniques.\nIssue 1 (the message never makes it to the queue) is easily solved by leveraging persis\u2010\ntent message queues, along with something called synchronous send. Persisted mes\u2010\nsage queues support what is known as guaranteed delivery. When the message broker\nreceives the message, it not only stores it in memory for fast retrieval, but also persists\nthe message in some sort of physical data store (such as a filesystem or database). If\nthe message broker goes down, the message is physically stored on disk so that when\nthe message broker comes back up, the message is available for processing. Synchro\u2010\nnous send does a blocking wait in the message producer until the broker has\nacknowledged that the message has been persisted. With these two basic techniques\nPreventing Data Loss \n| \n201\n", "page": 221, "type": "text", "section": "Page 221"}
{"text": "there is no way to lose a message between the event producer and the queue because\nthe message is either still with the message producer or persisted within the queue.\nIssue 2 (Event Processor B de-queues the next available message and crashes before\nit can process the event) can also be solved using a basic technique of messaging\ncalled client acknowledge mode. By default, when a message is de-queued, it is imme\u2010\ndiately removed from the queue (something called auto acknowledge mode). Client\nacknowledge mode keeps the message in the queue and attaches the client ID to the\nmessage so that no other consumers can read the message. With this mode, if Event\nProcessor B crashes, the message is still preserved in the queue, preventing message\nloss in this part of the message flow.\nIssue 3 (Event Processor B is unable to persist the message to the database due to\nsome data error) is addressed through leveraging ACID (atomicity, consistency, isola\u2010\ntion, durability) transactions via a database commit. Once the database commit hap\u2010\npens, the data is guaranteed to be persisted in the database. Leveraging something\ncalled last participant support (LPS) removes the message from the persisted queue by\nacknowledging that processing has been completed and that the message has been\npersisted. This guarantees the message is not lost during the transit from Event\nProcessor A all the way to the database. These techniques are illustrated in\nFigure 14-17.\nFigure 14-17. Preventing data loss within an event-driven architecture\n202 \n| \nChapter 14: Event-Driven Architecture Style\n", "page": 222, "type": "text", "section": "Page 222"}
{"text": "Broadcast Capabilities\nOne of the other unique characteristics of event-driven architecture is the capability\nto broadcast events without knowledge of who (if anyone) is receiving the message\nand what they do with it. This technique, which is illustrated in Figure 14-18, shows\nthat when a producer publishes a message, that same message is received by multiple\nsubscribers.\nFigure 14-18. Broadcasting events to other event processors\nBroadcasting is perhaps the highest level of decoupling between event processors\nbecause the producer of the broadcast message usually does not know which event\nprocessors will be receiving the broadcast message and more importantly, what they\nwill do with the message. Broadcast capabilities are an essential part of patterns for\neventual consistency, complex event processing (CEP), and a host of other situations.\nConsider frequent changes in stock prices for instruments traded on the stock mar\u2010\nket. Every ticker (the current price of a particular stock) might influence a number of\nthings. However, the service publishing the latest price simply broadcasts it with no\nknowledge of how that information will be used.\nBroadcast Capabilities \n| \n203\n", "page": 223, "type": "text", "section": "Page 223"}
{"text": "Request-Reply\nSo far in this chapter we\u2019ve dealt with asynchronous requests that don\u2019t need an\nimmediate response from the event consumer. But what if an order ID is needed\nwhen ordering a book? What if a confirmation number is needed when booking a\nflight? These are examples of communication between services or event processors\nthat require some sort of synchronous communication.\nIn event-driven architecture, synchronous communication is accomplished through\nrequest-reply messaging (sometimes referred to as pseudosynchronous communica\u2010\ntions). Each event channel within request-reply messaging consists of two queues: a\nrequest queue and a reply queue. The initial request for information is asynchro\u2010\nnously sent to the request queue, and then control is returned to the message pro\u2010\nducer. The message producer then does a blocking wait on the reply queue, waiting\nfor the response. The message consumer receives and processes the message and then\nsends the response to the reply queue. The event producer then receives the message\nwith the response data. This basic flow is illustrated in Figure 14-19.\nFigure 14-19. Request-reply message processing\nThere are two primary techniques for implementing request-reply messaging. The\nfirst (and most common) technique is to use a correlation ID contained in the mes\u2010\nsage header. A correlation ID is a field in the reply message that is usually set to the\nmessage ID of the original request message. This technique, as illustrated in\nFigure 14-20, works as follows, with the message ID indicated with ID, and the corre\u2010\nlation ID indicated with CID:\n1. The event producer sends a message to the request queue and records the unique\nmessage ID (in this case ID 124). Notice that the correlation ID (CID) in this case\nis null.\n204 \n| \nChapter 14: Event-Driven Architecture Style\n", "page": 224, "type": "text", "section": "Page 224"}
{"text": "2. The event producer now does a blocking wait on the reply queue with a message\nfilter (also called a message selector), where the correlation ID in the message\nheader equals the original message ID (in this case 124). Notice there are two\nmessages in the reply queue: message ID 855 with correlation ID 120, and mes\u2010\nsage ID 856 with correlation ID 122. Neither of these messages will be picked up\nbecause the correlation ID does not match what the event consumer is looking\nfor (CID 124).\n3. The event consumer receives the message (ID 124) and processes the request.\n4. The event consumer creates the reply message containing the response and sets\nthe correlation ID (CID) in the message header to the original message ID (124).\n5. The event consumer sends the new message (ID 857) to the reply queue.\n6. The event producer receives the message because the correlation ID (124)\nmatches the message selector from step 2.\nFigure 14-20. Request-reply message processing using a correlation ID\nThe other technique used to implement request-reply messaging is to use a temporary\nqueue for the reply queue. A temporary queue is dedicated to the specific request, cre\u2010\nated when the request is made and deleted when the request ends. This technique, as\nillustrated in Figure 14-21, does not require a correlation ID because the temporary\nqueue is a dedicated queue only known to the event producer for the specific request.\nThe temporary queue technique works as follows:\n1. The event producer creates a temporary queue (or one is automatically created,\ndepending on the message broker) and sends a message to the request queue,\nRequest-Reply \n| \n205\n", "page": 225, "type": "text", "section": "Page 225"}
{"text": "passing the name of the temporary queue in the reply-to header (or some other\nagreed-upon custom attribute in the message header).\n2. The event producer does a blocking wait on the temporary reply queue. No mes\u2010\nsage selector is needed because any message sent to this queue belongs solely to\nthe event producer that originally sent to the message.\n3. The event consumer receives the message, processes the request, and sends a\nresponse message to the reply queue named in the reply-to header.\n4. The event processor receives the message and deletes the temporary queue.\nFigure 14-21. Request-reply message processing using a temporary queue\nWhile the temporary queue technique is much simpler, the message broker must cre\u2010\nate a temporary queue for each request made and then delete it immediately after\u2010\nward. Large messaging volumes can significantly slow down the message broker and\nimpact overall performance and responsiveness. For this reason we usually recom\u2010\nmend using the correlation ID technique.\nChoosing Between Request-Based and Event-Based\nThe request-based model and event-based model are both viable approaches for\ndesigning software systems. However, choosing the right model is essential to the\noverall success of the system. We recommend choosing the request-based model for\nwell-structured, data-driven requests (such as retrieving customer profile data) when\ncertainty and control over the workflow is needed. We recommend choosing the\nevent-based model for flexible, action-based events that require high levels of respon\u2010\nsiveness and scale, with complex and dynamic user processing.\n206 \n| \nChapter 14: Event-Driven Architecture Style\n", "page": 226, "type": "text", "section": "Page 226"}
{"text": "Understanding the trade-offs with the event-based model also helps decide which one\nis the best fit. Table 14-3 lists the advantages and disadvantages of the event-based\nmodel of event-driven architecture.\nTable 14-3. Trade-offs of the event-driven model\nAdvantages over request-based\nTrade-offs\nBetter response to dynamic user content\nOnly supports eventual consistency\nBetter scalability and elasticity\nLess control over processing flow\nBetter agility and change management\nLess certainty over outcome of event flow\nBetter adaptability and extensibility\nDifficult to test and debug\nBetter responsiveness and performance\nBetter real-time decision making\nBetter reaction to situational awareness\nHybrid Event-Driven Architectures\nWhile many applications leverage the event-driven architecture style as the primary\noverarching architecture, in many cases event-driven architecture is used in conjunc\u2010\ntion with other architecture styles, forming what is known as a hybrid architecture.\nSome common architecture styles that leverage event-driven architecture as part of\nanother architecture style include microservices and space-based architecture. Other\nhybrids that are possible include an event-driven microkernel architecture and an\nevent-driven pipeline architecture.\nAdding event-driven architecture to any architecture style helps remove bottlenecks,\nprovides a back pressure point in the event requests get backed up, and provides a\nlevel of user responsiveness not found in other architecture styles. Both microservices\nand space-based architecture leverage messaging for data pumps, asynchronously\nsending data to another processor that in turn updates data in a database. Both also\nleverage event-driven architecture to provide a level of programmatic scalability to\nservices in a microservices architecture and processing units in a space-based archi\u2010\ntecture when using messaging for interservice communication.\nArchitecture Characteristics Ratings\nA one-star rating in the characteristics ratings table in Figure 14-22 means the spe\u2010\ncific architecture characteristic isn\u2019t well supported in the architecture, whereas a five-\nstar rating means the architecture characteristic is one of the strongest features in the\narchitecture style. The definition for each characteristic identified in the scorecard\ncan be found in Chapter 4.\nHybrid Event-Driven Architectures \n| \n207\n", "page": 227, "type": "text", "section": "Page 227"}
{"text": "Event-driven architecture is primarily a technically partitioned architecture in that\nany particular domain is spread across multiple event processors and tied together\nthrough mediators, queues, and topics. Changes to a particular domain usually\nimpact many event processors, mediators, and other messaging artifacts, hence why\nevent-driven architecture is not domain partitioned.\nFigure 14-22. Event-driven architecture characteristics ratings\nThe number of quanta within event-driven architecture can vary from one to many\nquanta, which is usually based on the database interactions within each event\nprocessor and request-reply processing. Even though all communication in an event-\ndriven architecture is asynchronous, if multiple event processors share a single data\u2010\nbase instance, they would all be contained within the same architectural quantum.\nThe same is true for request-reply processing: even though the communication is still\nasynchronous between the event processors, if a request is needed right away from\nthe event consumer, it ties those event processors together synchronously; hence they\nbelong to the same quantum.\n208 \n| \nChapter 14: Event-Driven Architecture Style\n", "page": 228, "type": "text", "section": "Page 228"}
{"text": "To illustrate this point, consider the example where one event processor sends a\nrequest to another event processor to place an order. The first event processor must\nwait for an order ID from the other event processor to continue. If the second event\nprocessor that places the order and generates an order ID is down, the first event pro\u2010\ncessor cannot continue. Therefore, they are part of the same architecture quantum\nand share the same architectural characteristics, even though they are both sending\nand receiving asynchronous messages.\nEvent-driven architecture gains five stars for performance, scalability, and fault toler\u2010\nance, the primary strengths of this architecture style. High performance is achieved\nthrough asynchronous communications combined with highly parallel processing. \nHigh scalability is realized through the programmatic load balancing of event pro\u2010\ncessors (also called competing consumers). As the request load increases, additional\nevent processors can be programmatically added to handle the additional requests.\nFault tolerance is achieved through highly decoupled and asynchronous event pro\u2010\ncessors that provide eventual consistency and eventual processing of event workflows.\nProviding the user interface or an event processor making a request does not need an\nimmediate response, promises and futures can be leveraged to process the event at a\nlater time if other downstream processors are not available.\nOverall simplicity and testability rate relatively low with event-driven architecture,\nmostly due to the nondeterministic and dynamic event flows typically found within\nthis architecture style. While deterministic flows within the request-based model are\nrelatively easy to test because the paths and outcomes are generally known, such is\nnot the case with the event-driven model. Sometimes it is not known how event pro\u2010\ncessors will react to dynamic events, and what messages they might produce. These\n\u201cevent tree diagrams\u201d can be extremely complex, generating hundreds to even thou\u2010\nsands of scenarios, making it very difficult to govern and test.\nFinally, event-driven architectures are highly evolutionary, hence the five-star rating.\nAdding new features through existing or new event processors is relatively straight\u2010\nforward, particularly in the broker topology. By providing hooks via published mes\u2010\nsages in the broker topology, the data is already made available, hence no changes are\nrequired in the infrastructure or existing event processors to add that new\nfunctionality.\nArchitecture Characteristics Ratings \n| \n209\n", "page": 229, "type": "text", "section": "Page 229"}
{"text": "CHAPTER 15\nSpace-Based Architecture Style\nMost web-based business applications follow the same general request flow: a request\nfrom a browser hits the web server, then an application server, then finally the data\u2010\nbase server. While this pattern works great for a small set of users, bottlenecks start\nappearing as the user load increases, first at the web-server layer, then at the\napplication-server layer, and finally at the database-server layer. The usual response to\nbottlenecks based on an increase in user load is to scale out the web servers. This is\nrelatively easy and inexpensive, and it sometimes works to address the bottleneck\nissues. However, in most cases of high user load, scaling out the web-server layer just\nmoves the bottleneck down to the application server. Scaling application servers can\nbe more complex and expensive than web servers and usually just moves the bottle\u2010\nneck down to the database server, which is even more difficult and expensive to scale.\nEven if you can scale the database, what you eventually end up with is a triangle-\nshaped topology, with the widest part of the triangle being the web servers (easiest to\nscale) and the smallest part being the database (hardest to scale), as illustrated in\nFigure 15-1.\nIn any high-volume application with a large concurrent user load, the database will\nusually be the final limiting factor in how many transactions you can process concur\u2010\nrently. While various caching technologies and database scaling products help to\naddress these issues, the fact remains that scaling out a normal application for\nextreme loads is a very difficult proposition.\n211\n", "page": 231, "type": "text", "section": "Page 231"}
{"text": "Figure 15-1. Scalability limits within a traditional web-based topology\nThe space-based architecture style is specifically designed to address problems involv\u2010\ning high scalability, elasticity, and high concurrency issues. It is also a useful architec\u2010\nture style for applications that have variable and unpredictable concurrent user\nvolumes. Solving the extreme and variable scalability issue architecturally is often a\nbetter approach than trying to scale out a database or retrofit caching technologies\ninto a nonscalable architecture.\nGeneral Topology\nSpace-based architecture gets its name from the concept of tuple space, the technique\nof using multiple parallel processors communicating through shared memory. High\nscalability, high elasticity, and high performance are achieved by removing the central\ndatabase as a synchronous constraint in the system and instead leveraging replicated\nin-memory data grids. Application data is kept in-memory and replicated among all\nthe active processing units. When a processing unit updates data, it asynchronously\nsends that data to the database, usually via messaging with persistent queues. Process\u2010\ning units start up and shut down dynamically as user load increases and decreases,\nthereby addressing variable scalability. Because there is no central database involved\nin the standard transactional processing of the application, the database bottleneck is\nremoved, thus providing near-infinite scalability within the application.\n212 \n| \nChapter 15: Space-Based Architecture Style\n", "page": 232, "type": "text", "section": "Page 232"}
{"text": "There are several architecture components that make up a space-based architecture: a\nprocessing unit containing the application code, virtualized middleware used to man\u2010\nage and coordinate the processing units, data pumps to asynchronously send updated\ndata to the database, data writers that perform the updates from the data pumps, and\ndata readers that read database data and deliver it to processing units upon startup.\nFigure 15-2 illustrates these primary architecture components.\nFigure 15-2. Space-based architecture basic topology\nProcessing Unit\nThe processing unit (illustrated in Figure 15-3) contains the application logic (or por\u2010\ntions of the application logic). This usually includes web-based components as well as\nbackend business logic. The contents of the processing unit vary based on the type of\napplication. Smaller web-based applications would likely be deployed into a single\nprocessing unit, whereas larger applications may split the application functionality\ninto multiple processing units based on the functional areas of the application. The\nprocessing unit can also contain small, single-purpose services (as with microservi\u2010\nces). In addition to the application logic, the processing unit also contains an in-\nmemory data grid and replication engine usually implemented through such\nproducts as Hazelcast, Apache Ignite, and Oracle Coherence.\nGeneral Topology \n| \n213\n", "page": 233, "type": "text", "section": "Page 233"}
{"text": "Figure 15-3. Processing unit\nVirtualized Middleware\nThe virtualized middleware handles the infrastructure concerns within the architec\u2010\nture that control various aspects of data synchronization and request handling. The\ncomponents that make up the virtualized middleware include a messaging grid, data\ngrid, processing grid, and deployment manager. These components, which are\ndescribed in detail in the next sections, can be custom written or purchased as third-\nparty products.\nMessaging grid\nThe messaging grid, shown in Figure 15-4, manages input request and session state. \nWhen a request comes into the virtualized middleware, the messaging grid compo\u2010\nnent determines which active processing components are available to receive the\nrequest and forwards the request to one of those processing units. The complexity of\nthe messaging grid can range from a simple round-robin algorithm to a more com\u2010\nplex next-available algorithm that keeps track of which request is being processed by\nwhich processing unit. This component is usually implemented using a typical web\nserver with load-balancing capabilities (such as HA Proxy and Nginx).\n214 \n| \nChapter 15: Space-Based Architecture Style\n", "page": 234, "type": "text", "section": "Page 234"}
{"text": "Figure 15-4. Messaging grid\nData grid\nThe data grid component is perhaps the most important and crucial component in\nthis architecture style. In most modern implementations the data grid is implemented\nsolely within the processing units as a replicated cache. However, for those replicated\ncaching implementations that require an external controller, or when using a dis\u2010\ntributed cache, this functionality would reside in both the processing units as well as\nin the data grid component within the virtualized middleware. Since the messaging\ngrid can forward a request to any of the processing units available, it is essential that\neach processing unit contains exactly the same data in its in-memory data grid.\nAlthough Figure 15-5 shows a synchronous data replication between processing\nunits, in reality this is done asynchronously and very quickly, usually completing the\ndata synchronization in less than 100 milliseconds.\nGeneral Topology \n| \n215\n", "page": 235, "type": "text", "section": "Page 235"}
{"text": "Figure 15-5. Data grid\nData is synchronized between processing units that contain the same named data\ngrid. To illustrate this point, consider the following code in Java using Hazelcast that\ncreates an internal replicated data grid for processing units containing customer pro\u2010\nfile information:\nHazelcastInstance hz = Hazelcast.newHazelcastInstance();\nMap<String, CustomerProfile> profileCache =\n \nhz.getReplicatedMap(\"CustomerProfile\");\nAll processing units needing access to the customer profile information would con\u2010\ntain this code. Changes made to the CustomerProfile named cache from any of the\nprocessing units would have that change replicated to all other processing units con\u2010\ntaining that same named cache. A processing unit can contain as many replicated\ncaches as needed to complete its work. Alternatively, one processing unit can make a\nremote call to another processing unit to ask for data (choreography) or leverage the\nprocessing grid (described in the next section) to orchestrate the request.\n216 \n| \nChapter 15: Space-Based Architecture Style\n", "page": 236, "type": "text", "section": "Page 236"}
{"text": "Data replication within the processing units also allows service instances to come up\nand down without having to read data from the database, providing there is at least\none instance containing the named replicated cache. When a processing unit instance\ncomes up, it connects to the cache provider (such as Hazelcast) and makes a request\nto get the named cache. Once the connection is made to the other processing units,\nthe cache will be loaded from one of the other instances.\nEach processing unit knows about all other processing unit instances through the use\nof a member list. The member list contains the IP address and ports of all other pro\u2010\ncessing units using that same named cache. For example, suppose there is a single\nprocessing instance containing code and replicated cached data for the customer pro\u2010\nfile. In this case there is only one instance, so the member list for that instance only\ncontains itself, as illustrated in the following logging statements generated using\nHazelcast:\nInstance 1:\nMembers {size:1, ver:1} [\n \nMember [172.19.248.89]:5701 - 04a6f863-dfce-41e5-9d51-9f4e356ef268 this\n]\nWhen another processing unit starts up with the same named cache, the member list\nof both services is updated to reflect the IP address and port of each processing unit:\nInstance 1:\nMembers {size:2, ver:2} [\n \nMember [172.19.248.89]:5701 - 04a6f863-dfce-41e5-9d51-9f4e356ef268 this\n \nMember [172.19.248.90]:5702 - ea9e4dd5-5cb3-4b27-8fe8-db5cc62c7316\n]\nInstance 2:\nMembers {size:2, ver:2} [\n \nMember [172.19.248.89]:5701 - 04a6f863-dfce-41e5-9d51-9f4e356ef268\n \nMember [172.19.248.90]:5702 - ea9e4dd5-5cb3-4b27-8fe8-db5cc62c7316 this\n]\nWhen a third processing unit starts up, the member list of instance 1 and instance 2\nare both updated to reflect the new third instance:\nInstance 1:\nMembers {size:3, ver:3} [\n \nMember [172.19.248.89]:5701 - 04a6f863-dfce-41e5-9d51-9f4e356ef268 this\n \nMember [172.19.248.90]:5702 - ea9e4dd5-5cb3-4b27-8fe8-db5cc62c7316\n \nMember [172.19.248.91]:5703 - 1623eadf-9cfb-4b83-9983-d80520cef753\n]\nInstance 2:\nMembers {size:3, ver:3} [\n \nMember [172.19.248.89]:5701 - 04a6f863-dfce-41e5-9d51-9f4e356ef268\n \nMember [172.19.248.90]:5702 - ea9e4dd5-5cb3-4b27-8fe8-db5cc62c7316 this\n \nMember [172.19.248.91]:5703 - 1623eadf-9cfb-4b83-9983-d80520cef753\n]\nGeneral Topology \n| \n217\n", "page": 237, "type": "text", "section": "Page 237"}
{"text": "Instance 3:\nMembers {size:3, ver:3} [\n \nMember [172.19.248.89]:5701 - 04a6f863-dfce-41e5-9d51-9f4e356ef268\n \nMember [172.19.248.90]:5702 - ea9e4dd5-5cb3-4b27-8fe8-db5cc62c7316\n \nMember [172.19.248.91]:5703 - 1623eadf-9cfb-4b83-9983-d80520cef753 this\n]\nNotice that all three instances know about each other (including themselves). Sup\u2010\npose instance 1 receives a request to update the customer profile information. When\ninstance 1 updates the cache with a cache.put() or similar cache update method, the\ndata grid (such as Hazelcast) will asynchronously update the other replicated caches\nwith the same update, ensuring all three customer profile caches always remain in\nsync with one another.\nWhen processing unit instances go down, all other processing units are automatically\nupdated to reflect the lost member. For example, if instance 2 goes down, the member\nlists of instance 1 and 3 are updated as follows:\nInstance 1:\nMembers {size:2, ver:4} [\n \nMember [172.19.248.89]:5701 - 04a6f863-dfce-41e5-9d51-9f4e356ef268 this\n \nMember [172.19.248.91]:5703 - 1623eadf-9cfb-4b83-9983-d80520cef753\n]\nInstance 3:\nMembers {size:2, ver:4} [\n \nMember [172.19.248.89]:5701 - 04a6f863-dfce-41e5-9d51-9f4e356ef268\n \nMember [172.19.248.91]:5703 - 1623eadf-9cfb-4b83-9983-d80520cef753 this\n]\nProcessing grid\nThe processing grid, illustrated in Figure 15-6, is an optional component within the\nvirtualized middleware that manages orchestrated request processing when there are\nmultiple processing units involved in a single business request. If a request comes in\nthat requires coordination between processing unit types (e.g., an order processing\nunit and a payment processing unit), it is the processing grid that mediates and\norchestrates the request between those two processing units.\n218 \n| \nChapter 15: Space-Based Architecture Style\n", "page": 238, "type": "text", "section": "Page 238"}
{"text": "Figure 15-6. Processing grid\nDeployment manager\nThe deployment manager component manages the dynamic startup and shutdown of\nprocessing unit instances based on load conditions. This component continually\nmonitors response times and user loads, starts up new processing units when load\nincreases, and shuts down processing units when the load decreases. It is a critical\ncomponent to achieving variable scalability (elasticity) needs within an application.\nData Pumps\nA data pump is a way of sending data to another processor which then updates data\nin a database. Data pumps are a necessary component within space-based architec\u2010\nture, as processing units do not directly read from and write to a database. Data\npumps within a space-based architecture are always asynchronous, providing even\u2010\ntual consistency with the in-memory cache and the database. When a processing unit\ninstance receives a request and updates its cache, that processing unit becomes the\nowner of the update and is therefore responsible for sending that update through the\ndata pump so that the database can be updated eventually.\nGeneral Topology \n| \n219\n", "page": 239, "type": "text", "section": "Page 239"}
{"text": "Data pumps are usually implemented using messaging, as shown in Figure 15-7. Mes\u2010\nsaging is a good choice for data pumps when using a space-based architecture. Not\nonly does messaging support asynchronous communication, but it also supports\nguaranteed delivery and preserving message order through first-in, first-out (FIFO)\nqueueing. Furthermore, messaging provides a decoupling between the processing\nunit and the data writer so that if the data writer is not available, uninterrupted pro\u2010\ncessing can still take place within the processing units.\nFigure 15-7. Data pump used to send data to a database\nIn most cases there are multiple data pumps, each one usually dedicated to a particu\u2010\nlar domain or subdomain (such as customer or inventory). Data pumps can be dedi\u2010\ncated to each type of cache (such as CustomerProfile, CustomerWishlist, and so\non), or they can be dedicated to a processing unit domain (such as Customer) con\u2010\ntaining a much larger and general cache.\nData pumps usually have associated contracts, including an action associated with the\ncontract data (add, delete, or update). The contract can be a JSON schema, XML\nschema, an object, or even a value-driven message (map message containing name-\nvalue pairs). For updates, the data contained in the message of the data pump usually\nonly contains the new data values. For example, if a customer changes a phone num\u2010\nber on their profile, only the new phone number would be sent, along with the cus\u2010\ntomer ID and an action to update the data.\n220 \n| \nChapter 15: Space-Based Architecture Style\n", "page": 240, "type": "text", "section": "Page 240"}
{"text": "Data Writers\nThe data writer component accepts messages from a data pump and updates the data\u2010\nbase with the information contained in the message of the data pump (see\nFigure 15-7). Data writers can be implemented as services, applications, or data hubs\n(such as Ab Initio). The granularity of the data writers can vary based on the scope of\nthe data pumps and processing units.\nA domain-based data writer contains all of the necessary database logic to handle all\nthe updates within a particular domain (such as customer), regardless of the number\nof data pumps it is accepting. Notice in Figure 15-8 that there are four different pro\u2010\ncessing units and four different data pumps representing the customer domain\n(Profile, WishList, Wallet, and Preferences) but only one data writer. The single\ncustomer data writer listens to all four data pumps and contains the necessary data\u2010\nbase logic (such as SQL) to update the customer-related data in the database.\nFigure 15-8. Domain-based data writer\nGeneral Topology \n| \n221\n", "page": 241, "type": "text", "section": "Page 241"}
{"text": "Alternatively, each class of processing unit can have its own dedicated data writer\ncomponent, as illustrated in Figure 15-9. In this model the data writer is dedicated to\neach corresponding data pump and contains only the database processing logic for\nthat particular processing unit (such as Wallet). While this model tends to produce\ntoo many data writer components, it does provide better scalability and agility due to\nthe alignment of processing unit, data pump, and data writer.\nFigure 15-9. Dedicated data writers for each data pump\nData Readers\nWhereas data writers take on the responsibility for updating the database, data read\u2010\ners take on the responsibility for reading data from the database and sending it to the\nprocessing units via a reverse data pump. In space-based architecture, data readers\nare only invoked under one of three situations: a crash of all processing unit instances\nof the same named cache, a redeployment of all processing units within the same\nnamed cache, or retrieving archive data not contained in the replicated cache.\n222 \n| \nChapter 15: Space-Based Architecture Style\n", "page": 242, "type": "text", "section": "Page 242"}
{"text": "In the event where all instances come down (due to a system-wide crash or redeploy\u2010\nment of all instances), data must be read from the database (something that is gener\u2010\nally avoided in space-based architecture). When instances of a class of processing unit\nstart coming up, each one tries to grab a lock on the cache. The first one to get the\nlock becomes the temporary cache owner; the others go into a wait state until the lock\nis released (this might vary based on the type of cache implementation being used,\nbut regardless, there is one primary owner of the cache in this scenario). To load the\ncache, the instance that gained temporary cache owner status sends a message to a\nqueue requesting data. The data reader component accepts the read request and then\nperforms the necessary database query logic to retrieve the data needed by the pro\u2010\ncessing unit. As the data reader queries data from the database, it sends that data to a\ndifferent queue (called a reverse data pump). The temporary cache owner processing\nunit receives the data from the reverse data pump and loads the cache. Once all the\ndata is loaded, the temporary owner releases the lock on the cache, all other instances\nare then synchronized, and processing can begin. This processing flow is illustrated\nin Figure 15-10.\nFigure 15-10. Data reader with reverse data pump\nLike data writers, data readers can also be domain-based or dedicated to a specific\nclass of processing unit (which is usually the case). The implementation is also the\nsame as the data writers\u2014either service, application, or data hub.\nThe data writers and data readers essentially form what is usually known as a data\nabstraction layer (or data access layer in some cases). The difference between the two\nis in the amount of detailed knowledge the processing units have with regard to the\nstructure of the tables (or schema) in the database. A data access layer means that the\nprocessing units are coupled to the underlying data structures in the database, and\nGeneral Topology \n| \n223\n", "page": 243, "type": "text", "section": "Page 243"}
{"text": "only use the data readers and writers to indirectly access the database. A data abstrac\u2010\ntion layer, on the other hand, means that the processing unit is decoupled from the\nunderlying database table structures through separate contracts. Space-based archi\u2010\ntecture generally relies on a data abstraction layer model so that the replicated cache\nschema in each processing unit can be different than the underlying database table\nstructures. This allows for incremental changes to the database without necessarily\nimpacting the processing units. To facilitate this incremental change, the data writers\nand data readers contain transformation logic so that if a column type changes or a\ncolumn or table is dropped, the data readers and data writers can buffer the database\nchange until the necessary changes can be made to the processing unit caches.\nData Collisions\nWhen using replicated caching in an active/active state where updates can occur to\nany service instance containing the same named cache, there is the possibility of a\ndata collision due to replication latency. A data collision occurs when data is updated\nin one cache instance (cache A), and during replication to another cache instance\n(cache B), the same data is updated by that cache (cache B). In this scenario, the local\nupdate to cache B will be overridden through replication by the old data from cache\nA, and through replication the same data in cache A will be overridden by the update\nfrom cache B.\nTo illustrate this problem, assume there are two service instances (Service A and Ser\u2010\nvice B) containing a replicated cache of product inventory. The following flow dem\u2010\nonstrates the data collision problem:\n\u2022 The current inventory count for blue widgets is 500 units\n\u2022 Service A updates the inventory cache for blue widgets to 490 units (10 sold)\n\u2022 During replication, Service B updates the inventory cache for blue widgets to 495\nunits (5 sold)\n\u2022 The Service B cache gets updated to 490 units due to replication from Service A\nupdate\n\u2022 The Service A cache gets updates to 495 units due to replication from Service B\nupdate\n\u2022 Both caches in Service A and B are incorrect and out of sync (inventory should\nbe 485 units)\nThere are several factors that influence how many data collisions might occur: the\nnumber of processing unit instances containing the same cache, the update rate of the\ncache, the cache size, and finally the replication latency of the caching product. The\nformula used to determine probabilistically how many potential data collisions might\noccur based on these factors is as follows:\n224 \n| \nChapter 15: Space-Based Architecture Style\n", "page": 244, "type": "text", "section": "Page 244"}
{"text": "CollisionRate = N * UR2\nS\n* RL\nwhere N represents the number of service instances using the same named cache, UR\nrepresents the update rate in milliseconds (squared), S the cache size (in terms of\nnumber of rows), and RL the replication latency of the caching product.\nThis formula is useful for determining the percentage of data collisions that will likely\noccur and hence the feasibility of the use of replicated caching. For example, consider\nthe following values for the factors involved in this calculation:\nUpdate rate (UR):\n20 updates/second\nNumber of instances (N):\n5\nCache size (S):\n50,000 rows\nReplication latency (RL):\n100 milliseconds\nUpdates:\n72,000 per hour\nCollision rate:\n14.4 per hour\nPercentage:\n0.02%\nApplying these factors to the formula yields 72,000 updates and hour, with a high\nprobability that 14 updates to the same data may collide. Given the low percentage\n(0.02%), replication would be a viable option.\nVarying the replication latency has a significant impact on the consistency of data.\nReplication latency depends on many factors, including the type of network and the\nphysical distance between processing units. For this reason replication latency values\nare rarely published and must be calculated and derived from actual measurements in\na production environment. The value used in the prior example (100 milliseconds) is\na good planning number if the actual replication latency, a value we frequently use to\ndetermine the number of data collisions, is not available. For example, changing the\nreplication latency from 100 milliseconds to 1 millisecond yields the same number of\nupdates (72,000 per hour) but produces only the probability of 0.1 collisions per\nhour! This scenario is shown in the following table:\nUpdate rate (UR):\n20 updates/second\nNumber of instances (N):\n5\nCache size (S):\n50,000 rows\nReplication latency (RL):\n1 millisecond (changed from 100)\nUpdates:\n72,000 per hour\nCollision rate:\n0.1 per hour\nPercentage:\n0.0002%\nData Collisions \n| \n225\n", "page": 245, "type": "text", "section": "Page 245"}
{"text": "The number of processing units containing the same named cache (as represented\nthrough the number of instances factor) also has a direct proportional relationship to\nthe number of data collisions possible. For example, reducing the number of process\u2010\ning units from 5 instances to 2 instances yields a data collision rate of only 6 per hour\nout of 72,000 updates per hour:\nUpdate rate (UR):\n20 updates/second\nNumber of instances (N):\n2 (changed from 5)\nCache size (S):\n50,000 rows\nReplication latency (RL):\n100 milliseconds\nUpdates:\n72,000 per hour\nCollision rate:\n5.8 per hour\nPercentage:\n0.008%\nThe cache size is the only factor that is inversely proportional to the collision rate. As\nthe cache size decreases, collision rates increase. In our example, reducing the cache\nsize from 50,000 rows to 10,000 rows (and keeping everything the same as in the first\nexample) yields a collision rate of 72 per hour, significantly higher than with 50,000\nrows:\nUpdate rate (UR):\n20 updates/second\nNumber of instances (N):\n5\nCache size (S):\n10,000 rows (changed from 50,000)\nReplication latency (RL):\n100 milliseconds\nUpdates:\n72,000 per hour\nCollision rate:\n72.0 per hour\nPercentage:\n0.1%\nUnder normal circumstances, most systems do not have consistent update rates over\nsuch a long period of time. As such, when using this calculation it is helpful to under\u2010\nstand the maximum update rate during peak usage and calculate minimum, normal,\nand peak collision rates.\nCloud Versus On-Premises Implementations\nSpace-based architecture offers some unique options when it comes to the environ\u2010\nments in which it is deployed. The entire topology, including the processing units,\nvirtualized middleware, data pumps, data readers and writers, and the database, can\nbe deployed within cloud-based environments on-premises (\u201con-prem\u201d). However,\nthis architecture style can also be deployed between these environments, offering a\nunique feature not found in other architecture styles.\n226 \n| \nChapter 15: Space-Based Architecture Style\n", "page": 246, "type": "text", "section": "Page 246"}
{"text": "A powerful feature of this architecture style (as illustrated in Figure 15-11) is to\ndeploy applications via processing units and virtualized middleware in managed\ncloud-based environments while keeping the physical databases and corresponding\ndata on-prem. This topology supports very effective cloud-based data synchroniza\u2010\ntion due to the asynchronous data pumps and eventual consistency model of this\narchitecture style. Transactional processing can occur on dynamic and elastic cloud-\nbased environments while preserving physical data management, reporting, and data\nanalytics within secure and local on-prem environments.\nFigure 15-11. Hybrid cloud-based and on-prem topology\nReplicated Versus Distributed Caching\nSpace-based architecture relies on caching for the transactional processing of an\napplication. Removing the need for direct reads and writes to a database is how\nspace-based architecture is able to support high scalability, high elasticity, and high\nperformance. Space-based architecture mostly relies on replicated caching, although\ndistributed caching can be used as well.\nWith replicated caching, as illustrated in Figure 15-12, each processing unit contains\nits own in-memory data grid that is synchronized between all processing units using\nthat same named cache. When an update occurs to a cache within any of the process\u2010\nReplicated Versus Distributed Caching \n| \n227\n", "page": 247, "type": "text", "section": "Page 247"}
{"text": "ing units, the other processing units are automatically updated with the new\ninformation.\nFigure 15-12. Replicated caching between processing units\nReplicated caching is not only extremely fast, but it also supports high levels of fault\ntolerance. Since there is no central server holding the cache, replicated caching does\nnot have a single point of failure. There may be exceptions to this rule, however,\nbased on the implementation of the caching product used. Some caching products\nrequire the presence of an external controller to monitor and control the replication\nof data between processing units, but most product companies are moving away from\nthis model.\nWhile replicated caching is the standard caching model for space-based architecture,\nthere are some cases where it is not possible to use replicated caching. These situa\u2010\ntions include high data volumes (size of the cache) and high update rates to the cache\ndata. Internal memory caches in excess of 100 MB might start to cause issues with\nregard to elasticity and high scalability due to the amount of memory used by each\nprocessing unit. Processing units are generally deployed within a virtual machine (or\nin some cases represent the virtual machine). Each virtual machine only has a certain\namount of memory available for internal cache usage, limiting the number of pro\u2010\ncessing unit instances that can be started to process high-throughput situations. Fur\u2010\nthermore, as shown in \u201cData Collisions\u201d on page 224, if the update rate of the cache\ndata is too high, the data grid might be unable to keep up with that high update rate\nto ensure data consistency across all processing unit instances. When these situations\noccur, distributed caching can be used.\nDistributed caching, as illustrated in Figure 15-13, requires an external server or ser\u2010\nvice dedicated to holding a centralized cache. In this model the processing units do\nnot store data in internal memory, but rather use a proprietary protocol to access the\ndata from the central cache server. Distributed caching supports high levels of data\n228 \n| \nChapter 15: Space-Based Architecture Style\n", "page": 248, "type": "text", "section": "Page 248"}
{"text": "consistency because the data is all in one place and does not need to be replicated.\nHowever, this model has less performance than replicated caching because the cache\ndata must be accessed remotely, adding to the overall latency of the system. Fault tol\u2010\nerance is also an issue with distributed caching. If the cache server containing the\ndata goes down, no data can be accessed or updated from any of the processing units,\nrendering them nonoperational. Fault tolerance can be mitigated by mirroring the\ndistributed cache, but this could present consistency issues if the primary cache\nserver goes down unexpectedly and the data does not make it to the mirrored cache\nserver.\nFigure 15-13. Distributed caching between processing units\nWhen the size of the cache is relatively small (under 100 MB) and the update rate of\nthe cache is low enough that the replication engine of the caching product can keep\nup with the cache updates, the decision between using a replicated cache and a dis\u2010\ntributed cache becomes one of data consistency versus performance and fault toler\u2010\nance. A distributed cache will always offer better data consistency over a replicated\ncache because the cache of data is in a single place (as opposed to being spread across\nmultiple processing units). However, performance and fault tolerance will always be\nbetter when using a replicated cache. Many times this decision comes down to the\ntype of data being cached in the processing units. The need for highly consistent data\n(such as inventory counts of the available products) usually warrants a distributed\ncache, whereas data that does not change often (such as reference data like name/\nvalue pairs, product codes, and product descriptions) usually warrants a replicated\ncache for quick lookup. Some of the selection criteria that can be used as a guide for\nchoosing when to use a distributed cache versus a replicated cache are listed in\nTable 15-1.\nReplicated Versus Distributed Caching \n| \n229\n", "page": 249, "type": "text", "section": "Page 249"}
{"text": "Table 15-1. Distributed versus replicated caching\nDecision criteria\nReplicated cache\nDistributed cache\nOptimization\nPerformance\nConsistency\nCache size\nSmall (<100 MB)\nLarge (>500 MB)\nType of data\nRelatively static\nHighly dynamic\nUpdate frequency\nRelatively low\nHigh update rate\nFault tolerance\nHigh\nLow\nWhen choosing the type of caching model to use with space-based architecture,\nremember that in most cases both models will be applicable within any given applica\u2010\ntion context. In other words, neither replicated caching nor distributed caching solve\nevery problem. Rather than trying to seek compromises through a single consistent\ncaching model across the application, leverage each for its strengths. For example, for\na processing unit that maintains the current inventory, choose a distributed caching\nmodel for data consistency; for a processing unit that maintains the customer profile,\nchoose a replicated cache for performance and fault tolerance.\nNear-Cache Considerations\nA near-cache is a type of caching hybrid model bridging in-memory data grids with a\ndistributed cache. In this model (illustrated in Figure 15-14) the distributed cache is\nreferred to as the full backing cache, and each in-memory data grid contained within\neach processing unit is referred to as the front cache. The front cache always contains\na smaller subset of the full backing cache, and it leverages an eviction policy to remove\nolder items so that newer ones can be added. The front cache can be what is known as\na most recently used (MRU) cache containing the most recently used items or a most\nfrequently used (MFU) cache containing the most frequently used items. Alterna\u2010\ntively, a random replacement eviction policy can be used in the front cache so that\nitems are removed in a random manner when space is needed to add a new item.\nRandom replacement (RR) is a good eviction policy when there is no clear analysis of\nthe data with regard to keeping either the latest used versus the most frequently used.\n230 \n| \nChapter 15: Space-Based Architecture Style\n", "page": 250, "type": "text", "section": "Page 250"}
{"text": "Figure 15-14. Near-cache topology\nWhile the front caches are always kept in sync with the full backing cache, the front\ncaches contained within each processing unit are not synchronized between other\nprocessing units sharing the same data. This means that multiple processing units\nsharing the same data context (such as a customer profile) will likely all have different\ndata in their front cache. This creates inconsistencies in performance and responsive\u2010\nness between processing units because each processing unit contains different data in\nthe front cache. For this reason we do not recommended using a near-cache model\nfor space-based architecture.\nImplementation Examples\nSpace-based architecture is well suited for applications that experience high spikes in\nuser or request volume and applications that have throughput in excess of 10,000\nconcurrent users. Examples of space-based architecture include applications like\nonline concert ticketing systems and online auction systems. Both of these examples\nrequire high performance, high scalability, and high levels of elasticity.\nConcert Ticketing System\nConcert ticketing systems have a unique problem domain in that concurrent user\nvolume is relatively low until a popular concert is announced. Once concert tickets go\non sale, user volumes usually spike from several hundred concurrent users to several\nthousand (possibly in the tens of thousands, depending on the concert), all trying to\nacquire a ticket for the concert (hopefully, good seats!). Tickets usually sell out in a\nmatter of minutes, requiring the kind of architecture characteristics supported by\nspace-based architecture.\nImplementation Examples \n| \n231\n", "page": 251, "type": "text", "section": "Page 251"}
{"text": "There are many challenges associated with this sort of system. First, there are only a\ncertain number of tickets available, regardless of the seating preferences. Seating\navailability must continually be updated and made available as fast as possible given\nthe high number of concurrent requests. Also, assuming assigned seats are an option,\nseating availability must also be updated as fast as possible. Continually accessing a\ncentral database synchronously for this sort of system would likely not work\u2014it\nwould be very difficult for a typical database to handle tens of thousands of concur\u2010\nrent requests through standard database transactions at this level of scale and update\nfrequency.\nSpace-based architecture would be a good fit for a concert ticketing system due to the\nhigh elasticity requirements required of this type of application. An instantaneous\nincrease in the number of concurrent users wanting to purchase concert tickets\nwould be immediately recognized by the deployment manager, which in turn would\nstart up a large number of processing units to handle the large volume of requests.\nOptimally, the deployment manager would be configured to start up the necessary\nnumber of processing units shortly before the tickets went on sale, therefore having\nthose instances on standby right before the significant increase in user load.\nOnline Auction System\nOnline auction systems (bidding on items within an auction) share the same sort of\ncharacteristics as the online concert ticketing systems described previously\u2014both\nrequire high levels of performance and elasticity, and both have unpredictable spikes\nin user and request load. When an auction starts, there is no way of determining how\nmany people will be joining the auction, and of those people, how many concurrent\nbids will occur for each asking price.\nSpace-based architecture is well suited for this type of problem domain in that multi\u2010\nple processing units can be started as the load increases; and as the auction winds\ndown, unused processing units could be destroyed. Individual processing units can\nbe devoted to each auction, ensuring consistency with bidding data. Also, due to the\nasynchronous nature of the data pumps, bidding data can be sent to other processing\n(such as bid history, bid analytics, and auditing) without much latency, therefore\nincreasing the overall performance of the bidding process.\n232 \n| \nChapter 15: Space-Based Architecture Style\n", "page": 252, "type": "text", "section": "Page 252"}
{"text": "Architecture Characteristics Ratings\nA one-star rating in the characteristics ratings table in Figure 15-15 means the spe\u2010\ncific architecture characteristic isn\u2019t well supported in the architecture, whereas a five-\nstar rating means the architecture characteristic is one of the strongest features in the\narchitecture style. The definition for each characteristic identified in the scorecard\ncan be found in Chapter 4.\nFigure 15-15. Space-based architecture characteristics ratings\nNotice that space-based architecture maximizes elasticity, scalability, and perfor\u2010\nmance (all five-star ratings). These are the driving attributes and main advantages of\nthis architecture style. High levels of all three of these architecture characteristics are\nachieved by leveraging in-memory data caching and removing the database as a con\u2010\nstraint. As a result, processing millions of concurrent users is possible using this\narchitecture style.\nArchitecture Characteristics Ratings \n| \n233\n", "page": 253, "type": "text", "section": "Page 253"}
{"text": "While high levels of elasticity, scalability, and performance are advantages in this\narchitecture style, there is a trade-off for this advantage, specifically with regard to\noverall simplicity and testability. Space-based architecture is a very complicated\narchitecture style due to the use of caching and eventual consistency of the primary\ndata store, which is the ultimate system of record. Care must be taken to ensure no\ndata is lost in the event of a crash in any of the numerous moving parts of this archi\u2010\ntecture style (see \u201cPreventing Data Loss\u201d on page 201 in Chapter 14).\nTesting gets a one-star rating due to the complexity involved with simulating the high\nlevels of scalability and elasticity supported in this architecture style. Testing hun\u2010\ndreds of thousands of concurrent users at peak load is a very complicated and expen\u2010\nsive task, and as a result most high-volume testing occurs within production\nenvironments with actual extreme load. This produces significant risk for normal\noperations within a production environment.\nCost is another factor when choosing this architecture style. Space-based architecture\nis relatively expensive, mostly due to licensing fees for caching products and high\nresource utilization within cloud and on-prem systems due to high scalability and\nelasticity.\nIt is difficult to identify the partitioning type of space-based architecture, and as a\nresult we have identified it as both domain partitioned as well as technically parti\u2010\ntioned. Space-based architecture is domain partitioned not only because it aligns\nitself with a specific type of domain (highly elastic and scalable systems), but also\nbecause of the flexibility of the processing units. Processing units can act as domain\nservices in the same way services are defined in a service-based architecture or micro\u2010\nservices architecture. At the same time, space-based architecture is technically parti\u2010\ntioned in the way it separates the concerns about transactional processing using\ncaching from the actual storage of the data in the database via data pumps. The pro\u2010\ncessing units, data pumps, data readers and writers, and the database all form a tech\u2010\nnical layering in terms of how requests are processed, very similar with regard to how\na monolithic n-tiered layered architecture is structured.\nThe number of quanta within space-based architecture can vary based on how the\nuser interface is designed and how communication happens between processing\nunits. Because the processing units do not communicate synchronously with the\ndatabase, the database itself is not part of the quantum equation. As a result, quanta\nwithin a space-based architecture are typically delineated through the association\nbetween the various user interfaces and the processing units. Processing units that\nsynchronously communicate with each other (or synchronously through the process\u2010\ning grid for orchestration) would all be part of the same architectural quantum.\n234 \n| \nChapter 15: Space-Based Architecture Style\n", "page": 254, "type": "text", "section": "Page 254"}
{"text": "CHAPTER 16\nOrchestration-Driven\nService-Oriented Architecture\nArchitecture styles, like art movements, must be understood in the context of the era\nin which they evolved, and this architecture exemplifies this rule more than any\nother. The combination of external forces that often influence architecture decisions,\ncombined with a logical but ultimately disastrous organizational philosophy, doomed\nthis architecture to irrelevance. However, it provides a great example of how a partic\u2010\nular organizational idea can make logical sense yet hinder most important parts of\nthe development process.\nHistory and Philosophy\nThis style of service-oriented architecture appeared just as companies were becoming\nenterprises in the late 1990s: merging with smaller companies, growing at a break-\nneck pace, and requiring more sophisticated IT to accommodate this growth. How\u2010\never, computing resources were scarce, precious, and commercial. Distributed\ncomputing had just become possible and necessary, and many companies needed the\nvariable scalability and other beneficial characteristics.\nMany external drivers forced architects in this era toward distributed architectures\nwith significant constraints. Before open source operating systems were thought reli\u2010\nable enough for serious work, operating systems were expensive and licensed per\nmachine. Similarly, commercial database servers came with Byzantine licensing\nschemes, which caused application server vendors (which offered database connec\u2010\ntion pooling) to battle with database vendors. Thus, architects were expected to reuse\nas much as possible. In fact, reuse in all forms became the dominant philosophy in\nthis architecture, the side effects of which we cover in \u201cReuse\u2026and Coupling\u201d on\npage 239.\n235\n", "page": 255, "type": "text", "section": "Page 255"}
{"text": "This style of architecture also exemplifies how far architects can push the idea of\ntechnical partitioning, which had good motivations but bad consequences.\nTopology\nThe topology of this type of service-oriented architecture is shown in Figure 16-1.\nFigure 16-1. Topology of orchestration-driven service-oriented architecture\nNot all examples of this style of architecture had the exact layers illustrated in\nFigure 16-1, but they all followed the same idea of establishing a taxonomy of services\nwithin the architecture, each layer with a specific responsibility.\nService-oriented architecture is a distributed architecture; the exact demarcation of\nboundaries isn\u2019t shown in Figure 16-1 because it varied based on organization.\nTaxonomy\nThe architect\u2019s driving philosophy in this architecture centered around enterprise-\nlevel reuse. Many large companies were annoyed at how much they had to continue\nto rewrite software, and they struck on a strategy to gradually solve that problem.\nEach layer of the taxonomy supported this goal.\n236 \n| \nChapter 16: Orchestration-Driven Service-Oriented Architecture\n", "page": 256, "type": "text", "section": "Page 256"}
{"text": "Business Services\nBusiness services sit at the top of this architecture and provide the entry point. For\nexample, services like ExecuteTrade or PlaceOrder represent domain behavior. One\nlitmus test common at the time\u2014could an architect answer affirmatively to the ques\u2010\ntion \u201c\nAre we in the business of\u2026\u201d for each of these services?\nThese service definitions contained no code\u2014just input, output, and sometimes\nschema information. They were usually defined by business users, hence the name\nbusiness services.\nEnterprise Services\nThe enterprise services contain fine-grained, shared implementations. Typically, a\nteam of developers is tasked with building atomic behavior around particular busi\u2010\nness domains: CreateCustomer, CalculateQuote, and so on. These services are the\nbuilding blocks that make up the coarse-grained business services, tied together via\nthe orchestration engine.\nThis separation of responsibility flows from the reuse goal in this architecture. If\ndevelopers can build fine-grained enterprise services at just the correct level of granu\u2010\nlarity, the business won\u2019t have to rewrite that part of the business workflow again.\nGradually, the business will build up a collection of reusable assets in the form of\nreusable enterprise services.\nUnfortunately, the dynamic nature of reality defies these attempts. Business compo\u2010\nnents aren\u2019t like construction materials, where solutions last decades. Markets, tech\u2010\nnology changes, engineering practices, and a host of other factors confound attempts\nto impose stability on the software world.\nApplication Services\nNot all services in the architecture require the same level of granularity or reuse as the\nenterprise services. Application services are one-off, single-implementation services.\nFor example, perhaps one application needs geo-location, but the organization\ndoesn\u2019t want to take the time or effort to make that a reusable service. An application\nservice, typically owned by a single application team, solves these problems.\nInfrastructure Services\nInfrastructure services supply the operational concerns, such as monitoring, logging,\nauthentication, and authorization. These services tend to be concrete implementa\u2010\ntions, owned by a shared infrastructure team that works closely with operations.\nTaxonomy \n| \n237\n", "page": 257, "type": "text", "section": "Page 257"}
{"text": "Orchestration Engine\nThe orchestration engine forms the heart of this distributed architecture, stitching\ntogether the business service implementations using orchestration, including features\nlike transactional coordination and message transformation. This architecture is typi\u2010\ncally tied to a single relational database, or a few, rather than a database per service as\nin microservices architectures. Thus, transactional behavior is handled declaratively\nin the orchestration engine rather than in the database.\nThe orchestration engine defines the relationship between the business and enterprise\nservices, how they map together, and where transaction boundaries lie. It also acts as\nan integration hub, allowing architects to integrate custom code with package and\nlegacy software systems.\nBecause this mechanism forms the heart of the architecture, Conway\u2019s law (see \u201cCon\u2010\nway\u2019s Law\u201d on page 103) correctly predicts that the team of integration architects\nresponsible for this engine become a political force within an organization, and even\u2010\ntually a bureaucratic bottleneck.\nWhile this approach might sound appealing, in practice it was mostly a disaster. Off-\nloading transaction behavior to an orchestration tool sounded good, but finding the\ncorrect level of granularity of transactions became more and more difficult. While\nbuilding a few services wrapped in a distributed transaction is possible, the architec\u2010\nture becomes increasingly complex as developers must figure out where the appropri\u2010\nate transaction boundaries lie between services.\nMessage Flow\nAll requests go through the orchestration engine\u2014it is the location within this archi\u2010\ntecture where logic resides. Thus, message flow goes through the engine even for\ninternal calls, as shown in Figure 16-2.\n238 \n| \nChapter 16: Orchestration-Driven Service-Oriented Architecture\n", "page": 258, "type": "text", "section": "Page 258"}
{"text": "Figure 16-2. Message flow with service-oriented architecture\nIn Figure 16-2, the CreateQuote business-level service calls the service bus, which\ndefines the workflow that consists of calls to CreateCustomer and CalculateQuote,\neach of which also has calls to application services. The service bus acts as the inter\u2010\nmediary for all calls within this architecture, serving as both an integration hub and\norchestration engine.\nReuse\u2026and Coupling\nA major goal of this architecture is reuse at the service level\u2014the ability to gradually\nbuild business behavior that can be incrementally reused over time. Architects in this\narchitecture were instructed to find reuse opportunities as aggressively as possible.\nFor example, consider the situation illustrated in Figure 16-3.\nReuse\u2026and Coupling \n| \n239\n", "page": 259, "type": "text", "section": "Page 259"}
{"text": "Figure 16-3. Seeking reuse opportunities in service-oriented architecture\nIn Figure 16-3, an architect realizes that each of these divisions within an insurance\ncompany all contain a notion of Customer. Therefore, the proper strategy for service-\noriented architecture entails extracting the customer parts into a reusable service and\nallowing the original services to reference the canonical Customer service, shown in\nFigure 16-4.\nFigure 16-4. Building canonical representations in service-oriented architecture\n240 \n| \nChapter 16: Orchestration-Driven Service-Oriented Architecture\n", "page": 260, "type": "text", "section": "Page 260"}
{"text": "In Figure 16-4, the architect has isolated all customer behavior into a single Customer\nservice, achieving obvious reuse goals.\nHowever, architects only slowly realized the negative trade-offs of this design. First,\nwhen a team builds a system primarily around reuse, they also incur a huge amount\nof coupling between components. For example, in Figure 16-4, a change to the\nCustomer service ripples out to all the other services, making change risky. Thus, in\nservice-oriented architecture, architects struggled with making incremental change\u2014\neach change had a potential huge ripple effect. That in turn led to the need for coor\u2010\ndinated deployments, holistic testing, and other drags on engineering efficiency.\nAnother negative side effect of consolidating behavior into a single place: consider the\ncase of auto and disability insurance in Figure 16-4. To support a single Customer\nservice, it must include all the details the organization knows about customers. Auto\ninsurance requires a driver\u2019s license, which is a property of the person, not the vehi\u2010\ncle. Therefore, the Customer service will have to include details about driver\u2019s licenses\nthat the disability insurance division cares nothing about. Yet, the team that deals with\ndisability must deal with the extra complexity of a single customer definition.\nPerhaps the most damaging revelation from this architecture came with the realiza\u2010\ntion of the impractically of building an architecture so focused on technical partition\u2010\ning. While it makes sense from a separation and reuse philosophy standpoint, it was a\npractical nightmare. Domain concepts like CatalogCheckout were spread so thinly\nthroughout this architecture that they were virtually ground to dust. Developers com\u2010\nmonly work on tasks like \u201cadd a new address line to CatalogCheckout.\u201d In a service-\noriented architecture, that could entail dozens of services in several different tiers,\nplus changes to a single database schema. And, if the current enterprise services aren\u2019t\ndefined at the correct transactional granularity, the developers will either have to\nchange their design or build a new, near-identical service to change transactional\nbehavior. So much for reuse.\nArchitecture Characteristics Ratings\nMany of the modern criteria we use to evaluate architecture now were not priorities\nwhen this architecture was popular. In fact, the Agile software movement had just\nstarted and had not penetrated into the size of organizations likely to use this\narchitecture.\nA one-star rating in the characteristics ratings table in Figure 16-5 means the specific\narchitecture characteristic isn\u2019t well supported in the architecture, whereas a five-star\nrating means the architecture characteristic is one of the strongest features in the\narchitecture style. The definition for each characteristic identified in the scorecard\ncan be found in Chapter 4.\nArchitecture Characteristics Ratings \n| \n241\n", "page": 261, "type": "text", "section": "Page 261"}
{"text": "Service-oriented architecture is perhaps the most technically partitioned general-\npurpose architecture ever attempted! In fact, the backlash against the disadvantages\nof this structure lead to more modern architectures such as microservices. It has a\nsingle quantum even though it is a distributed architecture for two reasons. First, it\ngenerally uses a single database or just a few databases, creating coupling points\nwithin the architecture across many different concerns. Second, and more impor\u2010\ntantly, the orchestration engine acts as a giant coupling point\u2014no part of the archi\u2010\ntecture can have different architecture characteristics than the mediator that\norchestrates all behavior. Thus, this architecture manages to find the disadvantages of\nboth monolithic and distributed architectures.\nFigure 16-5. Ratings for service-oriented architecture\nModern engineering goals such as deployability and testability score disastrously in \nthis architecture, both because they were poorly supported and because those were\nnot important (or even aspirational) goals during that era.\n242 \n| \nChapter 16: Orchestration-Driven Service-Oriented Architecture\n", "page": 262, "type": "text", "section": "Page 262"}
{"text": "This architecture did support some goals such as elasticity and scalability, despite the\ndifficulties in implementing those behaviors, because tool vendors poured enormous\neffort into making these systems scalable by building session replication across appli\u2010\ncation servers and other techniques. However, being a distributed architecture, per\u2010\nformance was never a highlight of this architecture style and was extremely poor\nbecause each business request was split across so much of the architecture.\nBecause of all these factors, simplicity and cost have the inverse relationship most\narchitects would prefer. This architecture was an important milestone because it\ntaught architects how difficult distributed transactions can be in the real world and\nthe practical limits of technical partitioning.\nArchitecture Characteristics Ratings \n| \n243\n", "page": 263, "type": "text", "section": "Page 263"}
{"text": "CHAPTER 17\nMicroservices Architecture\nMicroservices is an extremely popular architecture style that has gained significant\nmomentum in recent years. In this chapter, we provide an overview of the important\ncharacteristics that set this architecture apart, both topologically and philosophically.\nHistory\nMost architecture styles are named after the fact by architects who notice a particular\npattern that keeps reappearing\u2014there is no secret group of architects who decide\nwhat the next big movement will be. Rather, it turns out that many architects end up\nmaking common decisions as the software development ecosystem shifts and\nchanges. The common best ways of dealing with and profiting from those shifts\nbecome architecture styles that others emulate.\nMicroservices differs in this regard\u2014it was named fairly early in its usage and popu\u2010\nlarized by a famous blog entry by Martin Fowler and James Lewis entitled \u201cMicroser\u2010\nvices,\u201d published in March 2014. They recognized many common characteristics in\nthis relatively new architectural style and delineated them. Their blog post helped\ndefine the architecture for curious architects and helped them understand the under\u2010\nlying philosophy.\nMicroservices is heavily inspired by the ideas in domain-driven design (DDD), a logi\u2010\ncal design process for software projects. One concept in particular from DDD, boun\u2010\nded context, decidedly inspired microservices. The concept of bounded context\nrepresents a decoupling style. When a developer defines a domain, that domain\nincludes many entities and behaviors, identified in artifacts such as code and database\nschemas. For example, an application might have a domain called CatalogCheckout,\nwhich includes notions such as catalog items, customers, and payment. In a tradi\u2010\ntional monolithic architecture, developers would share many of these concepts,\n245\n", "page": 265, "type": "text", "section": "Page 265"}
{"text": "building reusable classes and linked databases. Within a bounded context, the inter\u2010\nnal parts, such as code and data schemas, are coupled together to produce work; but\nthey are never coupled to anything outside the bounded context, such as a database\nor class definition from another bounded context. This allows each context to define\nonly what it needs rather than accommodating other constituents.\nWhile reuse is beneficial, remember the First Law of Software Architecture regarding\ntrade-offs. The negative trade-off of reuse is coupling. When an architect designs a\nsystem that favors reuse, they also favor coupling to achieve that reuse, either by\ninheritance or composition.\nHowever, if the architect\u2019s goal requires high degrees of decoupling, then they favor\nduplication over reuse. The primary goal of microservices is high decoupling, physi\u2010\ncally modeling the logical notion of bounded context.\nTopology\nThe topology of microservices is shown in Figure 17-1.\nFigure 17-1. The topology of the microservices architecture style\nAs illustrated in Figure 17-1, due to its single-purpose nature, the service size in\nmicroservices is much smaller than other distributed architectures, such as the\n246 \n| \nChapter 17: Microservices Architecture\n", "page": 266, "type": "text", "section": "Page 266"}
{"text": "orchestration-driven service-oriented architecture. Architects expect each service to\ninclude all necessary parts to operate independently, including databases and other\ndependent components. The different characteristics appear in the following sections.\nDistributed\nMicroservices form a distributed architecture: each service runs in its own process,\nwhich originally implied a physical computer but quickly evolved to virtual machines\nand containers. Decoupling the services to this degree allows for a simple solution to\na common problem in architectures that heavily feature multitenant infrastructure\nfor hosting applications. For example, when using an application server to manage\nmultiple running applications, it allows operational reuse of network bandwidth,\nmemory, disk space, and a host of other benefits. However, if all the supported appli\u2010\ncations continue to grow, eventually some resource becomes constrained on the\nshared infrastructure. Another problem concerns improper isolation between shared\napplications.\nSeparating each service into its own process solves all the problems brought on by\nsharing. Before the evolutionary development of freely available open source operat\u2010\ning systems, combined with automated machine provisioning, it was impractical for\neach domain to have its own infrastructure. Now, however, with cloud resources and\ncontainer technology, teams can reap the benefits of extreme decoupling, both at the\ndomain and operational level.\nPerformance is often the negative side effect of the distributed nature of microservi\u2010\nces. Network calls take much longer than method calls, and security verification at\nevery endpoint adds additional processing time, requiring architects to think care\u2010\nfully about the implications of granularity when designing the system.\nBecause microservices is a distributed architecture, experienced architects advise\nagainst the use of transactions across service boundaries, making determining the\ngranularity of services the key to success in this architecture.\nBounded Context\nThe driving philosophy of microservices is the notion of bounded context: each ser\u2010\nvice models a domain or workflow. Thus, each service includes everything necessary\nto operate within the application, including classes, other subcomponents, and data\u2010\nbase schemas. This philosophy drives many of the decisions architects make within\nthis architecture. For example, in a monolith, it is common for developers to share\ncommon classes, such as Address, between disparate parts of the application. How\u2010\never, microservices try to avoid coupling, and thus an architect building this architec\u2010\nture style prefers duplication to coupling.\nDistributed \n| \n247\n", "page": 267, "type": "text", "section": "Page 267"}
{"text": "Microservices take the concept of a domain-partitioned architecture to the extreme.\nEach service is meant to represent a domain or subdomain; in many ways, microser\u2010\nvices is the physical embodiment of the logical concepts in domain-driven design.\nGranularity\nArchitects struggle to find the correct granularity for services in microservices, and\noften make the mistake of making their services too small, which requires them to\nbuild communication links back between the services to do useful work.\nThe term \u201cmicroservice\u201d is a label, not a description.\n\u2014Martin Fowler\nIn other words, the originators of the term needed to call this new style something,\nand they chose \u201cmicroservices\u201d to contrast it with the dominant architecture style at\nthe time, service-oriented architecture, which could have been called \u201cgigantic serv\u2010\nices\u201d\n. However, many developers take the term \u201cmicroservices\u201d as a commandment,\nnot a description, and create services that are too fine-grained.\nThe purpose of service boundaries in microservices is to capture a domain or work\u2010\nflow. In some applications, those natural boundaries might be large for some parts of\nthe system\u2014some business processes are more coupled than others. Here are some\nguidelines architects can use to help find the appropriate boundaries:\nPurpose\nThe most obvious boundary relies on the inspiration for the architecture style, a\ndomain. Ideally, each microservice should be extremely functionally cohesive,\ncontributing one significant behavior on behalf of the overall application.\nTransactions\nBounded contexts are business workflows, and often the entities that need to\ncooperate in a transaction show architects a good service boundary. Because\ntransactions cause issues in distributed architectures, if architects can design\ntheir system to avoid them, they generate better designs.\nChoreography\nIf an architect builds a set of services that offer excellent domain isolation yet\nrequire extensive communication to function, the architect may consider bun\u2010\ndling these services back into a larger service to avoid the communication\noverhead.\nIteration is the only way to ensure good service design. Architects rarely discover the\nperfect granularity, data dependencies, and communication styles on their first pass.\nHowever, after iterating over the options, an architect has a good chance of refining\ntheir design.\n248 \n| \nChapter 17: Microservices Architecture\n", "page": 268, "type": "text", "section": "Page 268"}
{"text": "Data Isolation\nAnother requirement of microservices, driven by the bounded context concept, is\ndata isolation. Many other architecture styles use a single database for persistence.\nHowever, microservices tries to avoid all kinds of coupling, including shared schemas\nand databases used as integration points.\nData isolation is another factor an architect must consider when looking at service\ngranularity. Architects must be wary of the entity trap (discussed in \u201cEntity trap\u201d on\npage 110) and not simply model their services to resemble single entities in a\ndatabase.\nArchitects are accustomed to using relational databases to unify values within a sys\u2010\ntem, creating a single source of truth, which is no longer an option when distributing\ndata across the architecture. Thus, architects must decide how they want to handle\nthis problem: either identifying one domain as the source of truth for some fact and\ncoordinating with it to retrieve values or using database replication or caching to dis\u2010\ntribute information.\nWhile this level of data isolation creates headaches, it also provides opportunities.\nNow that teams aren\u2019t forced to unify around a single database, each service can\nchoose the most appropriate tool, based on price, type of storage, or a host of other\nfactors. Teams have the advantage in a highly decoupled system to change their mind\nand choose a more suitable database (or other dependency) without affecting other\nteams, which aren\u2019t allowed to couple to implementation details.\nAPI Layer\nMost pictures of microservices include an API layer sitting between the consumers of\nthe system (either user interfaces or calls from other systems), but it is optional. It is\ncommon because it offers a good location within the architecture to perform useful\ntasks, either via indirection as a proxy or a tie into operational facilities, such as a\nnaming service (covered in \u201cOperational Reuse\u201d on page 250).\nWhile an API layer may be used for variety of things, it should not be used as a medi\u2010\nator or orchestration tool if the architect wants to stay true to the underlying philoso\u2010\nphy of this architecture: all interesting logic in this architecture should occur inside a\nbounded context, and putting orchestration or other logic in a mediator violates that\nrule. This also illustrates the difference between technical and domain partitioning in\narchitecture: architects typically use mediators in technically partitioned architec\u2010\ntures, whereas microservices is firmly domain partitioned.\nAPI Layer \n| \n249\n", "page": 269, "type": "text", "section": "Page 269"}
{"text": "Operational Reuse\nGiven that microservices prefers duplication to coupling, how do architects handle\nthe parts of architecture that really do benefit from coupling, such as operational con\u2010\ncerns like monitoring, logging, and circuit breakers? One of the philosophies in the\ntraditional service-oriented architecture was to reuse as much functionality as possi\u2010\nble, domain and operational alike. In microservices, architects try to split these two\nconcerns.\nOnce a team has built several microservices, they realize that each has common ele\u2010\nments that benefit from similarity. For example, if an organization allows each service\nteam to implement monitoring themselves, how can they ensure that each team does\nso? And how do they handle concerns like upgrades? Does it become the responsibil\u2010\nity of each team to handle upgrading to the new version of the monitoring tool, and\nhow long will that take?\nThe sidecar pattern offers a solution to this problem, illustrated in Figure 17-2.\nFigure 17-2. The sidecar pattern in microservices\nIn Figure 17-2, the common operational concerns appear within each service as a\nseparate component, which can be owned by either individual teams or a shared\ninfrastructure team. The sidecar component handles all the operational concerns that\nteams benefit from coupling together. Thus, when it comes time to upgrade the mon\u2010\nitoring tool, the shared infrastructure team can update the sidecar, and each micro\u2010\nservices receives that new functionality.\n250 \n| \nChapter 17: Microservices Architecture\n", "page": 270, "type": "text", "section": "Page 270"}
{"text": "Once teams know that each service includes a common sidecar, they can build a ser\u2010\nvice mesh, allowing unified control across the architecture for concerns like logging\nand monitoring. The common sidecar components connect to form a consistent\noperational interface across all microservices, as shown in Figure 17-3.\nFigure 17-3. The service plane connects the sidecars in a service mesh\nIn Figure 17-3, each sidecar wires into the service plane, which forms the consistent\ninterface to each service.\nOperational Reuse \n| \n251\n", "page": 271, "type": "text", "section": "Page 271"}
{"text": "The service mesh itself forms a console that allows developers holistic access to serv\u2010\nices, which is shown in Figure 17-4.\nFigure 17-4. The service mesh forms a holistic view of the operational aspect of microser\u2010\nvices\nEach service forms a node in the overall mesh, as shown in Figure 17-4. The service\nmesh forms a console that allows teams to globally control operational coupling, such\nas monitoring levels, logging, and other cross-cutting operational concerns.\nArchitects use service discovery as a way to build elasticity into microservices archi\u2010\ntectures. Rather than invoke a single service, a request goes through a service discov\u2010\nery tool, which can monitor the number and frequency of requests, as well as spin up\nnew instances of services to handle scale or elasticity concerns. Architects often\ninclude service discovery in the service mesh, making it part of every microservice.\nThe API layer is often used to host service discovery, allowing a single place for user\ninterfaces or other calling systems to find and create services in an elastic, consistent\nway.\n252 \n| \nChapter 17: Microservices Architecture\n", "page": 272, "type": "text", "section": "Page 272"}
{"text": "Frontends\nMicroservices favors decoupling, which would ideally encompass the user interfaces\nas well as backend concerns. In fact, the original vision for microservices included the\nuser interface as part of the bounded context, faithful to the principle in DDD. How\u2010\never, practicalities of the partitioning required by web applications and other external\nconstraints make that goal difficult. Thus, two styles of user interfaces commonly\nappear for microservices architectures; the first appears in Figure 17-5.\nFigure 17-5. Microservices architecture with a monolithic user interface\nIn Figure 17-5, the monolithic frontend features a single user interface that calls\nthrough the API layer to satisfy user requests. The frontend could be a rich desktop,\nmobile, or web application. For example, many web applications now use a JavaScript\nweb framework to build a single user interface.\nFrontends \n| \n253\n", "page": 273, "type": "text", "section": "Page 273"}
{"text": "The second option for user interfaces uses microfrontends, shown in Figure 17-6.\nFigure 17-6. Microfrontend pattern in microservices\nIn Figure 17-6, this approach utilizes components at the user interface level to create a\nsynchronous level of granularity and isolation in the user interface as the backend\nservices. Each service emits the user interface for that service, which the frontend\ncoordinates with the other emitted user interface components. Using this pattern,\nteams can isolate service boundaries from the user interface to the backend services,\nunifying the entire domain within a single team.\nDevelopers can implement the microfrontend pattern in a variety of ways, either\nusing a component-based web framework such as React or using one of several open\nsource frameworks that support this pattern.\nCommunication\nIn microservices, architects and developers struggle with appropriate granularity,\nwhich affects both data isolation and communication. Finding the correct communi\u2010\ncation style helps teams keep services decoupled yet still coordinated in useful ways.\nFundamentally, architects must decide on synchronous or asynchronous communica\u2010\ntion. Synchronous communication requires the caller to wait for a response from the\ncallee. Microservices architectures typically utilize protocol-aware heterogeneous inter\u2010\noperability. We\u2019ll break down that term for you:\n254 \n| \nChapter 17: Microservices Architecture\n", "page": 274, "type": "text", "section": "Page 274"}
{"text": "Protocol-aware\nBecause microservices usually don\u2019t include a centralized integration hub to\navoid operational coupling, each service should know how to call other services.\nThus, architects commonly standardize on how particular services call each\nother: a certain level of REST, message queues, and so on. That means that serv\u2010\nices must know (or discover) which protocol to use to call other services.\nHeterogeneous\nBecause microservices is a distributed architecture, each service may be written\nin a different technology stack. Heterogeneous suggests that microservices fully\nsupports polyglot environments, where different services use different platforms.\nInteroperability\nDescribes services calling one another. While architects in microservices try to\ndiscourage transactional method calls, services commonly call other services via\nthe network to collaborate and send/receive information.\nEnforced Heterogeneity\nA well-known architect who was a pioneer in the microservices style was the chief\narchitecture at a personal information manager startup for mobile devices. Because\nthey had a fast-moving problem domain, the architect wanted to ensure that none of\nthe development teams accidentally created coupling points between each other, hin\u2010\ndering the teams\u2019 ability to move independently. It turned out that this architect had a\nwide mix of technical skills on the teams, thus mandating that each development\nteam use a different technology stack. If one team was using Java and the other was\nusing .NET, it was impossible to accidentally share classes!\nThis approach is the polar opposite of most enterprise governance policies, which\ninsist on standardizing on a single technology stack. The goal in the microservices\nworld isn\u2019t to create the most complex ecosystem possible, but rather to choose the\ncorrect scale technology for the narrow scope of the problem. Not every service needs\nan industrial-strength relational database, and forcing it on small teams slows them\nrather than benefitting them. This concept leverages the highly decoupled nature of\nmicroservices.\nFor asynchronous communication, architects often use events and messages, thus\ninternally utilizing an event-driven architecture, covered in Chapter 14; the broker\nand mediator patterns manifest in microservices as choreography and orchestration.\nCommunication \n| \n255\n", "page": 275, "type": "text", "section": "Page 275"}
{"text": "Choreography and Orchestration\nChoreography utilizes the same communication style as a broker event-driven archi\u2010\ntecture. In other words, no central coordinator exists in this architecture, respecting\nthe bounded context philosophy. Thus, architects find it natural to implement decou\u2010\npled events between services.\nDomain/architecture isomorphism is one key characteristic that architects should look\nfor when assessing how appropriate an architecture style is for a particular problem.\nThis term describes how the shape of an architecture maps to a particular architec\u2010\nture style. For example, in Figure 8-7, the Silicon Sandwiches\u2019 technically partitioned\narchitecture structurally supports customizability, and the microkernel architecture\nstyle offers the same general structure. Therefore, problems that require a high degree\nof customization become easier to implement in a microkernel.\nSimilarly, because the architect\u2019s goal in a microservices architecture favors decou\u2010\npling, the shape of microservices resembles the broker EDA, making these two pat\u2010\nterns symbiotic.\nIn choreography, each service calls other services as needed, without a central media\u2010\ntor. For example, consider the scenario shown in Figure 17-7.\nFigure 17-7. Using choreography in microservices to manage coordination\n256 \n| \nChapter 17: Microservices Architecture\n", "page": 276, "type": "text", "section": "Page 276"}
{"text": "In Figure 17-7, the user requests details about a user\u2019s wish list. Because the Customer\nWishList service doesn\u2019t contain all the necessary information, it makes a call to\nCustomerDemographics to retrieve the missing information, returning the result to\nthe user.\nBecause microservices architectures don\u2019t include a global mediator like other\nservice-oriented architectures, if an architect needs to coordinate across several serv\u2010\nices, they can create their own localized mediator, as shown in Figure 17-8.\nFigure 17-8. Using orchestration in microservices\nIn Figure 17-8, the developers create a service whose sole responsibility is coordinat\u2010\ning the call to get all information for a particular customer. The user calls the Report\nCustomerInformation mediator, which calls the necessary other services.\nCommunication \n| \n257\n", "page": 277, "type": "text", "section": "Page 277"}
{"text": "The First Law of Software Architecture suggests that neither of these solutions is per\u2010\nfect\u2014each has trade-offs. In choreography, the architect preserves the highly decou\u2010\npled philosophy of the architecture style, thus reaping maximum benefits touted by\nthe style. However, common problems like error handling and coordination become\nmore complex in choreographed environments.\nConsider an example with a more complex workflow, shown in Figure 17-9.\nFigure 17-9. Using choreography for a complex business process\nIn Figure 17-9, the first service called must coordinate across a wide variety of other\nservices, basically acting as a mediator in addition to its other domain responsibili\u2010\nties. This pattern is called the front controller pattern, where a nominally choreo\u2010\ngraphed service becomes a more complex mediator for some problem. The downside\nto this pattern is added complexity in the service.\n258 \n| \nChapter 17: Microservices Architecture\n", "page": 278, "type": "text", "section": "Page 278"}
{"text": "Alternatively, an architect may choose to use orchestration for complex business pro\u2010\ncesses, illustrated in Figure 17-10.\nFigure 17-10. Using orchestration for a complex business process\nIn Figure 17-10, the architect builds a mediator to handle the complexity and coordi\u2010\nnation required for the business workflow. While this creates coupling between these\nservices, it allows the architect to focus coordination into a single service, leaving the\nothers less affected. Often, domain workflows are inherently coupled\u2014the architect\u2019s\njob entails finding the best way to represent that coupling in ways that support both\nthe domain and architectural goals.\nCommunication \n| \n259\n", "page": 279, "type": "text", "section": "Page 279"}
{"text": "Transactions and Sagas\nArchitects aspire to extreme decoupling in microservices, but then often encounter\nthe problem of how to do transactional coordination across services. Because the\ndecoupling in the architecture encourages the same level for the databases, atomicity\nthat was trivial in monolithic applications becomes a problem in distributed ones.\nBuilding transactions across service boundaries violates the core decoupling principle\nof the microservices architecture (and also creates the worst kind of dynamic connas\u2010\ncence, connascence of value). The best advice for architects who want to do transac\u2010\ntions across services is: don\u2019t! Fix the granularity components instead. Often,\narchitects who build microservices architectures who then find a need to wire them\ntogether with transactions have gone too granular in their design. Transaction\nboundaries is one of the common indicators of service granularity.\nDon\u2019t do transactions in microservices\u2014fix granularity instead!\nExceptions always exist. For example, a situation may arise where two different serv\u2010\nices need vastly different architecture characteristics, requiring distinct service\nboundaries, yet still need transactional coordination. In those situations, patterns\nexist to handle transaction orchestration, with serious trade-offs.\n260 \n| \nChapter 17: Microservices Architecture\n", "page": 280, "type": "text", "section": "Page 280"}
{"text": "A popular distributed transactional pattern in microservices is the saga pattern, illus\u2010\ntrated in Figure 17-11.\nFigure 17-11. The saga pattern in microservices architecture\nIn Figure 17-11, a service acts a mediator across multiple service calls and coordi\u2010\nnates the transaction. The mediator calls each part of the transaction, records success\nor failure, and coordinates results. If everything goes as planned, all the values in the\nservices and their contained databases update synchronously.\nCommunication \n| \n261\n", "page": 281, "type": "text", "section": "Page 281"}
{"text": "In an error condition, the mediator must ensure that no part of the transaction suc\u2010\nceeds if one part fails. Consider the situation shown in Figure 17-12.\nFigure 17-12. Saga pattern compensating transactions for error conditions\nIn Figure 17-12, if the first part of the transaction succeeds, yet the second part fails,\nthe mediator must send a request to all the parts of the transaction that were success\u2010\nful and tell them to undo the previous request. This style of transactional coordina\u2010\ntion is called a compensating transaction framework. Developers implement this\npattern by usually having each request from the mediator enter a pending state until\nthe mediator indicates overall success. However, this design becomes complex if asyn\u2010\nchronous requests must be juggled, especially if new requests appear that are contin\u2010\ngent on pending transactional state. This also creates a lot of coordination traffic at\nthe network level.\n262 \n| \nChapter 17: Microservices Architecture\n", "page": 282, "type": "text", "section": "Page 282"}
{"text": "Another implementation of a compensating transaction framework has developers\nbuild do and undo for each potentially transactional operation. This allows less coor\u2010\ndination during transactions, but the undo operations tend to be significantly more\ncomplex than the do operations, more than doubling the design, implementation, and\ndebugging work.\nWhile it is possible for architects to build transactional behavior across services, it\ngoes against the reason for choosing the microservices pattern. Exceptions always\nexist, so the best advice for architects is to use the saga pattern sparingly.\nA few transactions across services is sometimes necessary; if it\u2019s the\ndominant feature of the architecture, mistakes were made!\nArchitecture Characteristics Ratings\nThe microservices architecture style offers several extremes on our standard ratings\nscale, shown in Figure 17-13. A one-star rating means the specific architecture char\u2010\nacteristic isn\u2019t well supported in the architecture, whereas a five-star rating means the\narchitecture characteristic is one of the strongest features in the architecture style.\nThe definition for each characteristic identified in the scorecard can be found in\nChapter 4.\nNotable is the high support for modern engineering practices such as automated\ndeployment, testability, and others not listed. Microservices couldn\u2019t exist without the\nDevOps revolution and the relentless march toward automating operational con\u2010\ncerns.\nAs microservices is a distributed architecture, it suffers from many of the deficiencies\ninherent in architectures made from pieces wired together at runtime. Thus, fault tol\u2010\nerance and reliability are impacted when too much interservice communication is\nused. However, these ratings only point to tendencies in the architecture; developers\nfix many of these problems by redundancy and scaling via service discovery. Under\nnormal circumstances, however, independent, single-purpose services generally lead\nto high fault tolerance, hence the high rating for this characteristic within a microser\u2010\nvices architecture.\nArchitecture Characteristics Ratings \n| \n263\n", "page": 283, "type": "text", "section": "Page 283"}
{"text": "Figure 17-13. Ratings for microservices\nThe high points of this architecture are scalability, elasticity, and evolutionary. Some\nof the most scalable systems yet written have utilized this style to great success. Simi\u2010\nlarly, because the architecture relies heavily on automation and intelligent integration\nwith operations, developers can also build elasticity support into the architecture.\nBecause the architecture favors high decoupling at an incremental level, it supports\nthe modern business practice of evolutionary change, even at the architecture level.\nModern business move fast, and software development has struggled to keep apace.\nBy building an architecture that has extremely small deployment units that are highly\ndecoupled, architects have a structure that can support a faster rate of change.\nPerformance is often an issue in microservices\u2014distributed architectures must make\nmany network calls to complete work, which has high performance overhead, and\nthey must invoke security checks to verify identity and access for each endpoint. \nMany patterns exist in the microservices world to increase performance, including\nintelligent data caching and replication to prevent an excess of network calls.\n264 \n| \nChapter 17: Microservices Architecture\n", "page": 284, "type": "text", "section": "Page 284"}
{"text": "Performance is another reason that microservices often use choreography rather than\norchestration, as less coupling allows for faster communication and fewer\nbottlenecks.\nMicroservices is decidedly a domain-centered architecture, where each service\nboundary should correspond to domains. It also has the most distinct quanta of any\nmodern architecture\u2014in many ways, it exemplifies what the quantum measure evalu\u2010\nates. The driving philosophy of extreme decoupling creates many headaches in this\narchitecture but yields tremendous benefits when done well. As in any architecture,\narchitects must understand the rules to break them intelligently.\nAdditional References\nWhile our goal in this chapter was to touch on some of the significant aspects of this\narchitecture style, many excellent resources exist to get further and more detailed\nabout this architecture style. Additional and more detailed information can be found\nabout microservices in the following references:\n\u2022 Building Microservices by Sam Newman (O\u2019Reilly)\n\u2022 Microservices vs. Service-Oriented Architecture by Mark Richards (O\u2019Reilly)\n\u2022 Microservices AntiPatterns and Pitfalls by Mark Richards (O\u2019Reilly)\nAdditional References \n| \n265\n", "page": 285, "type": "text", "section": "Page 285"}
{"text": "CHAPTER 18\nChoosing the Appropriate\nArchitecture Style\nIt depends! With all the choices available (and new ones arriving almost daily), we\nwould like to tell you which one to use\u2014but we cannot. Nothing is more contextual\nto a number of factors within an organization and what software it builds. Choosing\nan architecture style represents the culmination of analysis and thought about trade-\noffs for architecture characteristics, domain considerations, strategic goals, and a host\nof other things.\nHowever contextual the decision is, some general advice exists around choosing an\nappropriate architecture style.\nShifting \u201cFashion\u201d in Architecture\nPreferred architecture styles shift over time, driven by a number of factors:\nObservations from the past\nNew architecture styles generally arise from observations and pain points from\npast experiences. Architects have experience with systems in the past that influ\u2010\nence their thoughts about future systems. Architects must rely on their past expe\u2010\nrience\u2014it is that experience that allowed that person to become an architect in\nthe first place. Often, new architecture designs reflect specific deficiencies from\npast architecture styles. For example, architects seriously rethought the implica\u2010\ntions of code reuse after building architectures that featured it and then realizing\nthe negative trade-offs.\nChanges in the ecosystem\nConstant change is a reliable feature of the software development ecosystem\u2014\neverything changes all the time. The change in our ecosystem is particularly\n267\n", "page": 287, "type": "text", "section": "Page 287"}
{"text": "chaotic, making even the type of change impossible to predict. For example, a\nfew years ago, no one knew what Kubernetes was, and now there are multiple\nconferences around the world with thousands of developers. In a few more years,\nKubernetes may be replaced with some other tool that hasn\u2019t been written yet.\nNew capabilities\nWhen new capabilities arise, architecture may not merely replace one tool with\nanother but rather shift to an entirely new paradigm. For example, few architects\nor developers anticipated the tectonic shift caused in the software development\nworld by the advent of containers such as Docker. While it was an evolutionary\nstep, the impact it had on architects, tools, engineering practices, and a host of\nother factors astounded most in the industry. The constant change in the ecosys\u2010\ntem also delivers a new collection of tools and capabilities on a regular basis.\nArchitects must keep a keen eye open to not only new tools but new paradigms.\nSomething may just look like a new one-of-something-we-already-have, but it\nmay include nuances or other changes that make it a game changer. New capabil\u2010\nities don\u2019t even have to rock the entire development world\u2014the new features may\nbe a minor change that aligns exactly with an architect\u2019s goals.\nAcceleration\nNot only does the ecosystem constantly change, but the rate of change also con\u2010\ntinues to rise. New tools create new engineering practices, which lead to new\ndesign and capabilities. Architects live in a constant state of flux because change\nis both pervasive and constant.\nDomain changes\nThe domain that developers write software for constantly shifts and changes,\neither because the business continues to evolve or because of factors like mergers\nwith other companies.\nTechnology changes\nAs technology continues to evolve, organizations try to keep up with at least\nsome of these changes, especially those with obvious bottom-line benefits.\nExternal factors\nMany external factors only peripherally associated with software development\nmay drive change within an organizations. For example, architects and develop\u2010\ners might be perfectly happy with a particular tool, but the licensing cost has\nbecome prohibitive, forcing a migration to another option.\nRegardless of where an organization stands in terms of current architecture fashion,\nan architect should understand current industry trends to make intelligent decisions\nabout when to follow and when to make exceptions.\n268 \n| \nChapter 18: Choosing the Appropriate Architecture Style\n", "page": 288, "type": "text", "section": "Page 288"}
{"text": "Decision Criteria\nWhen choosing an architectural style, an architect must take into account all the vari\u2010\nous factors that contribute to the structure for the domain design. Fundamentally, an\narchitect designs two things: whatever domain has been specified, and all the other\nstructural elements required to make the system a success.\nArchitects should go into the design decision comfortable with the following things:\nThe domain\nArchitects should understand many important aspects of the domain, especially\nthose that affect operational architecture characteristics. Architects don\u2019t have to\nbe subject matter experts, but they must have at least a good general understand\u2010\ning of the major aspects of the domain under design.\nArchitecture characteristics that impact structure\nArchitects must discover and elucidate the architecture characteristics needed to\nsupport the domain and other external factors.\nData architecture\nArchitects and DBAs must collaborate on database, schema, and other data-\nrelated concerns. We don\u2019t cover much about data architecture in this book; it is\nits own specialization. However, architects must understand the impact that data\ndesign might have on their design, particularly if the new system must interact\nwith an older and/or in-use data architecture.\nOrganizational factors\nMany external factors may influence design. For example, the cost of a particular\ncloud vendor may prevent the ideal design. Or perhaps the company plans to\nengage in mergers and acquisitions, which encourages an architect to gravitate\ntoward open solutions and integration architectures.\nKnowledge of process, teams, and operational concerns\nMany specific project factors influence an architect\u2019s design, such as the software\ndevelopment process, interaction (or lack of) with operations, and the QA pro\u2010\ncess. For example, if an organization lacks maturity in Agile engineering practi\u2010\nces, architecture styles that rely on those practices for success will present\ndifficulties.\nDomain/architecture isomorphism\nSome problem domains match the topology of the architecture. For example, the\nmicrokernel architecture style is perfectly suited to a system that requires cus\u2010\ntomizability\u2014the architect can design customizations as plug-ins. Another\nexample might be genome analysis, which requires a large number of discrete\nDecision Criteria \n| \n269\n", "page": 289, "type": "text", "section": "Page 289"}
{"text": "operations, and space-based architecture, which offers a large number of discrete\nprocessors.\nSimilarly, some problem domains may be particularly ill-suited for some archi\u2010\ntecture styles. For example, highly scalable systems struggle with large monolithic\ndesigns because architects find it difficult to support a large number of concur\u2010\nrent users in a highly coupled code base. A problem domain that includes a huge\namount of semantic coupling matches poorly with a highly decoupled, dis\u2010\ntributed architecture. For instance, an insurance company application consisting\nof multipage forms, each of which is based on the context of previous pages,\nwould be difficult to model in microservices. This is a highly coupled problem\nthat will present architects with design challenges in a decoupled architecture; a\nless coupled architecture like service-based architecture would suit this problem\nbetter.\nTaking all these things into account, the architect must make several determinations:\nMonolith versus distributed\nUsing the quantum concepts discussed earlier, the architect must determine if a\nsingle set of architecture characteristics will suffice for the design, or do different\nparts of the system need differing architecture characteristics? A single set\nimplies that a monolith is suitable (although other factors may drive an architect\ntoward a distributed architecture), whereas different architecture characteristics\nimply a distributed architecture.\nWhere should data live?\nIf the architecture is monolithic, architects commonly assume a single relational\ndatabases or a few of them. In a distributed architecture, the architect must\ndecide which services should persist data, which also implies thinking about how\ndata must flow throughout the architecture to build workflows. Architects must\nconsider both structure and behavior when designing architecture and not be\nfearful of iterating on the design to find better combinations.\nWhat communication styles between services\u2014synchronous or asynchronous?\nOnce the architect has determined data partitioning, their next design considera\u2010\ntion is the communication between services\u2014synchronous or asynchronous?\nSynchronous communication is more convenient in most cases, but it can lead to\nscalability, reliability, and other undesirable characteristics. Asynchronous com\u2010\nmunication can provide unique benefits in terms of performance and scale but\ncan present a host of headaches: data synchronization, deadlocks, race condi\u2010\ntions, debugging, and so on.\n270 \n| \nChapter 18: Choosing the Appropriate Architecture Style\n", "page": 290, "type": "text", "section": "Page 290"}
{"text": "Because synchronous communication presents fewer design, implementation, and\ndebugging challenges, architects should default to synchronous when possible and\nuse asynchronous when necessary.\nUse synchronous by default, asynchronous when necessary.\nThe output of this design process is architecture topology, taking into account what\narchitecture style (and hybridizations) the architect chose, architecture decision\nrecords about the parts of the design which required the most effort by the architect,\nand architecture fitness functions to protect important principles and operational\narchitecture characteristics.\nMonolith Case Study: Silicon Sandwiches\nIn the Silicon Sandwiches architecture kata, after investigating the architecture char\u2010\nacteristics, we determined that a single quantum was sufficient to implement this sys\u2010\ntem. Plus, this is a simple application without a huge budget, so the simplicity of a\nmonolith appeals.\nHowever, we created two different component designs for Silicon Sandwiches: one\ndomain partitioned and another technically partitioned. Given the simplicity of the\nsolution, we\u2019ll create designs for each and cover trade-offs.\nModular Monolith\nA modular monolith builds domain-centric components with a single database,\ndeployed as a single quantum; the modular monolith design for Silicon Sandwiches\nappears in Figure 18-1.\nThis is a monolith with a single relational database, implemented with a single web-\nbased user interface (with careful design considerations for mobile devices) to keep\noverall cost down. Each of the domains the architect identified earlier appear as com\u2010\nponents. If time and resources are sufficient, the architect should consider creating\nthe same separation of tables and other database assets as the domain components,\nallowing for this architecture to migrate to a distributed architecture more easily if\nfuture requirements warrant it.\nMonolith Case Study: Silicon Sandwiches \n| \n271\n", "page": 291, "type": "text", "section": "Page 291"}
{"text": "Figure 18-1. A modular monolith implementation of Silicon Sandwiches\nBecause the architecture style itself doesn\u2019t inherently handle customization, the\narchitect must make sure that that feature becomes part of domain design. In this\ncase, the architect designs an Override endpoint where developers can upload indi\u2010\nvidual customizations. Correspondingly, the architect must ensure that each of the\ndomain components references the Override component for each customizable char\u2010\nacteristic\u2014this would make a perfect fitness function.\nMicrokernel\nOne of the architecture characteristics the architect identified in Silicon Sandwiches\nwas customizability. Looking at domain/architecture isomorphism, an architect may\nchoose to implement it using a microkernel, as illustrated in Figure 18-2.\n272 \n| \nChapter 18: Choosing the Appropriate Architecture Style\n", "page": 292, "type": "text", "section": "Page 292"}
{"text": "Figure 18-2. A microkernel implementation of Silicon Sandwiches\nIn Figure 18-2, the core system consists of the domain components and a single rela\u2010\ntional database. As in the previous design, careful synchronization between domains\nand data design will allow future migration of the core to a distributed architecture.\nEach customization appears in a plug-in, the common ones in a single set of plug-ins\n(with a corresponding database), and a series of local ones, each with their own data.\nBecause none of the plug-ins need to be coupled to the other plug-ins, they can each\nmaintain their data, leaving the plug-ins decoupled.\nThe other unique design element here utilizes the Backends for Frontends (BFF) pat\u2010\ntern, making the API layer a thin microkernel adaptor. It supplies general informa\u2010\ntion from the backend, and the BFF adaptors translate the generic information into\nthe suitable format for the frontend device. For example, the BFF for iOS will take the\ngeneric output from the backend and customize it for what the iOS native application\nexpects: the data format, pagination, latency, and other factors. Building each BFF\nMonolith Case Study: Silicon Sandwiches \n| \n273\n", "page": 293, "type": "text", "section": "Page 293"}
{"text": "adaptor allows for the richest user interfaces and the ability to expand to support\nother devices in the future\u2014one of the benefits of the microkernel style.\nCommunication within either Silicon Sandwich architecture can be synchronous\u2014\nthe architecture doesn\u2019t require extreme performance or elasticity requirements\u2014and\nnone of the operations will be lengthy.\nDistributed Case Study: Going, Going, Gone\nThe Going, Going, Gone (GGG) kata presents more interesting architecture chal\u2010\nlenges. Based on the component analysis in \u201cCase Study: Going, Going, Gone: Dis\u2010\ncovering Components\u201d on page 112, this architecture needs differing architecture\ncharacteristics for different parts of the architecture. For example, architecture char\u2010\nacteristics like availability and scalability will differ between roles like auctioneer and\nbidder.\nThe requirements for GGG also explicitly state certain ambitious levels of scale, elas\u2010\nticity, performance, and a host of other tricky operational architecture characteristics.\nThe architect needs to choose a pattern that allows for a high degree of customization\nat a fine-grained level within the architecture. Of the candidate distributed architec\u2010\ntures, either low-level event-driven or microservices match most of the architecture\ncharacteristics. Of the two, microservices better supports differing operational archi\u2010\ntecture characteristics\u2014purely event-driven architectures typically don\u2019t separate\npieces because of these operational architecture characteristics but are rather based\non communication style, orchestrated versus choreographed.\nAchieving the stated performance will provide a challenge in microservices, but\narchitects can often address any weak point of an architecture by designing to accom\u2010\nmodate it. For example, while microservices offers a high degrees of scalability\nnaturally, architects commonly have to address specific performance issues caused by\ntoo much orchestration, too aggressive data separation, and so on.\n274 \n| \nChapter 18: Choosing the Appropriate Architecture Style\n", "page": 294, "type": "text", "section": "Page 294"}
{"text": "An implementation of GGG using microservices is shown in Figure 18-3.\nFigure 18-3. A microservices implementation of Going, Going, Gone\nIn Figure 18-3, each identified component became services in the architecture,\nmatching component and service granularity. GGG has three distinct user interfaces:\nBidder\nThe numerous bidders for the online auction.\nAuctioneer\nOne per auction.\nStreamer\nService responsible for streaming video and bid stream to the bidders. Note that\nthis is a read-only stream, allowing optimizations not available if updates were\nnecessary.\nDistributed Case Study: Going, Going, Gone \n| \n275\n", "page": 295, "type": "text", "section": "Page 295"}
{"text": "The following services appear in this design of the GGG architecture:\nBidCapture\nCaptures online bidder entries and asynchronously sends them to Bid Tracker.\nThis service needs no persistence because it acts as a conduit for the online bids.\nBidStreamer\nStreams the bids back to online participants in a high performance, read-only\nstream.\nBidTracker\nTracks bids from both Auctioneer Capture and Bid Capture. This is the com\u2010\nponent that unifies the two different information streams, ordering the bids as\nclose to real time as possible. Note that both inbound connections to this service\nare asynchronous, allowing the developers to use message queues as buffers to\nhandle very different rates of message flow.\nAuctioneer Capture\nCaptures bids for the auctioneer. The result of quanta analysis in \u201cCase Study:\nGoing, Going, Gone: Discovering Components\u201d on page 112 led the architect to\nseparate Bid Capture and Auctioneer Capture because they have quite different\narchitecture characteristics.\nAuction Session\nThis manages the workflow of individual auctions.\nPayment\nThird-party payment provider that handles payment information after the\nAuction Session has completed the auction.\nVideo Capture\nCaptures the video stream of the live auction.\nVideo Streamer\nStreams the auction video to online bidders.\nThe architect was careful to identify both synchronous and asynchronous communi\u2010\ncation styles in this architecture. Their choice for asynchronous communication is\nprimarily driven by accommodating differing operational architecture characteristics\nbetween services. For example, if the Payment service can only process a new payment\nevery 500 ms and a large number of auctions end at the same time, synchronous\ncommunication between the services would cause time outs and other reliability\nheadaches. By using message queues, the architect can add reliability to a critical part\nof the architecture that exhibits fragility.\n276 \n| \nChapter 18: Choosing the Appropriate Architecture Style\n", "page": 296, "type": "text", "section": "Page 296"}
{"text": "In the final analysis, this design resolved to five quanta, identified in Figure 18-4.\nFigure 18-4. The quanta boundaries for GGG\nIn Figure 18-4, the design includes quanta for Payment, Auctioneer, Bidder, Bidder\nStreams, and Bid Tracker, roughly corresponding to the services. Multiple instances\nare indicated by stacks of containers in the diagram. Using quantum analysis at the\ncomponent design stage allowed the architect to more easily identify service, data,\nand communication boundaries.\nNote that this isn\u2019t the \u201ccorrect\u201d design for GGG, and it\u2019s certainly not the only one.\nWe don\u2019t even suggest that it\u2019s the best possible design, but it seems to have the least\nworst set of trade-offs. Choosing microservices, then intelligently using events and\nmessages, allows the architecture to leverage the most out of a generic architecture\npattern while still building a foundation for future development and expansion.\nDistributed Case Study: Going, Going, Gone \n| \n277\n", "page": 297, "type": "text", "section": "Page 297"}
{"text": "PART III\nTechniques and Soft Skills\nAn effective software architect must not only understand the technical aspects of soft\u2010\nware architecture, but also the primary techniques and soft skills necessary to think\nlike an architect, guide development teams, and effectively communicate the architec\u2010\nture to various stakeholders. This section of the book addresses the key techniques\nand soft skills necessary to become an effective software architect.\n", "page": 299, "type": "text", "section": "Page 299"}
{"text": "CHAPTER 19\nArchitecture Decisions\nOne of the core expectations of an architect is to make architecture decisions. Archi\u2010\ntecture decisions usually involve the structure of the application or system, but they\nmay involve technology decisions as well, particularly when those technology deci\u2010\nsions impact architecture characteristics. Whatever the context, a good architecture\ndecision is one that helps guide development teams in making the right technical\nchoices. Making architecture decisions involves gathering enough relevant informa\u2010\ntion, justifying the decision, documenting the decision, and effectively communicat\u2010\ning that decision to the right stakeholders.\nArchitecture Decision Anti-Patterns\nThere is an art to making architecture decisions. Not surprisingly, several architecture\nanti-patterns emerge when making decisions as an architect. The programmer\nAndrew Koenig defines an anti-pattern as something that seems like a good idea\nwhen you begin, but leads you into trouble. Another definition of an anti-pattern is a\nrepeatable process that produces negative results. The three major architecture anti-\npatterns that can (and usually do) emerge when making architecture decisions are the\nCovering Your Assets anti-pattern, the Groundhog Day anti-pattern, and the Email-\nDriven Architecture anti-pattern. These three anti-patterns usually follow a progres\u2010\nsive flow: overcoming the Covering Your Assets anti-pattern leads to the Groundhog\nDay anti-pattern, and overcoming this anti-pattern leads to the Email-Driven Archi\u2010\ntecture anti-pattern. Making effective and accurate architecture decisions requires an\narchitect to overcome all three of these anti-patterns.\n281\n", "page": 301, "type": "text", "section": "Page 301"}
{"text": "Covering Your Assets Anti-Pattern\nThe first anti-pattern to emerge when trying to make architecture decisions is the\nCovering Your Assets anti-pattern. This anti-pattern occurs when an architect avoids\nor defers making an architecture decision out of fear of making the wrong choice.\nThere are two ways to overcome this anti-pattern. The first is to wait until the last\nresponsible moment to make an important architecture decision. The last responsible\nmoment means waiting until you have enough information to justify and validate\nyour decision, but not waiting so long that you hold up development teams or fall\ninto the Analysis Paralysis anti-pattern. The second way to avoid this anti-pattern is to\ncontinually collaborate with development teams to ensure that the decision you made\ncan be implemented as expected. This is vitally important because it is not feasible as\nan architect to possibly know every single detail about a particular technology and all\nthe associated issues. By closely collaborating with development teams, the architect\ncan respond quickly to a change in the architecture decision if issues occur.\nTo illustrate this point, suppose an architect makes the decision that all product-\nrelated reference data (product description, weight, and dimensions) be cached in all\nservice instances needing that information using a read-only replicated cache, with\nthe primary replica owned by the catalog service. A replicated cache means that if\nthere are any changes to product information (or a new product is added), the catalog\nservice would update its cache, which would then be replicated to all other services\nrequiring that data through a replicated (in-memory) cache product. A good justifi\u2010\ncation for this decision is to reduce coupling between the services and to effectively\nshare data without having to make an interservice call. However, the development\nteams implementing this architecture decision find that due to certain scalability\nrequirements of some of the services, this decision would require more in-process\nmemory than is available. By closely collaborating with the development teams, the\narchitect can quickly become aware of the issue and adjust the architecture decision\nto accommodate these situations.\nGroundhog Day Anti-Pattern\nOnce an architect overcomes the Covering Your Assets anti-pattern and starts mak\u2010\ning decisions, a second anti-pattern emerges: the Groundhog Day anti-pattern. The\nGroundhog Day anti-pattern occurs when people don\u2019t know why a decision was\nmade, so it keeps getting discussed over and over and over. The Groundhog Day anti-\npattern gets it name from the Bill Murray movie Groundhog Day, where it was Febru\u2010\nary 2 over and over every day.\nThe Groundhog Day anti-pattern occurs because once an architect makes an archi\u2010\ntecture decision, they fail to provide a justification for the decision (or a complete jus\u2010\ntification). When justifying architecture decisions it is important to provide both\ntechnical and business justifications for your decision. For example, an architect may\n282 \n| \nChapter 19: Architecture Decisions\n", "page": 302, "type": "text", "section": "Page 302"}
{"text": "make the decision to break apart a monolithic application into separate services to\ndecouple the functional aspects of the application so that each part of the application\nuses fewer virtual machine resources and can be maintained and deployed separately.\nWhile this is a good example of a technical justification, what is missing is the busi\u2010\nness justification\u2014in other words, why should the business pay for this architectural\nrefactoring? A good business justification for this decision might be to deliver new\nbusiness functionality faster, therefore improving time to market. Another might be\nto reduce the costs associated with the development and release of new features.\nProviding the business value when justifying decisions is vitally important for any\narchitecture decision. It is also a good litmus test for determining whether the archi\u2010\ntecture decision should be made in the first place. If a particular architecture decision\ndoes not provide any business value, then perhaps it is not a good decision and\nshould be reconsidered.\nFour of the most common business justifications include cost, time to market, user\nsatisfaction, and strategic positioning. When focusing on these common business jus\u2010\ntifications, it is important to take into consideration what is important to the business\nstakeholders. Justifying a particular decision based on cost savings alone might not be\nthe right decision if the business stakeholders are less concerned about cost and more\nconcerned about time to market.\nEmail-Driven Architecture Anti-Pattern\nOnce an architect makes decisions and fully justifies those decisions, a third architec\u2010\nture anti-pattern emerges: Email-Driven Architecture. The Email-Driven Architecture\nanti-pattern is where people lose, forget, or don\u2019t even know an architecture decision\nhas been made and therefore cannot possibly implement that architecture decision.\nThis anti-pattern is all about effectively communicating your architecture decisions.\nEmail is a great tool for communication, but it makes a poor document repository\nsystem.\nThere are many ways to increase the effectiveness of communicating architecture\ndecisions, thereby avoiding the Email-Driven Architecture anti-pattern. The first rule\nof communicating architecture decisions is to not include the architecture decision in\nthe body of an email. Including the architecture decision in the body of the email cre\u2010\nates multiple systems of record for that decision. Many times important details\n(including the justification) are left out of the email, therefore creating the Ground\u2010\nhog Day anti-pattern all over again. Also, if that architecture decision is ever changed\nor superseded, how may people received the revised decision? A better approach is to\nmention only the nature and context of the decision in the body of the email and pro\u2010\nvide a link to the single system of record for the actual architecture decision and cor\u2010\nresponding details (whether it be a link to a wiki page or a document in a filesystem).\nArchitecture Decision Anti-Patterns \n| \n283\n", "page": 303, "type": "text", "section": "Page 303"}
{"text": "The second rule of effectively communicating architecture decisions is to only notify\nthose people who really care about the architecture decision. One effective technique\nis to write the body of the email as follows:\n\u201cHi Sandra, I\u2019ve made an important decision regarding communication between\nservices that directly impacts you. Please see the decision using the following link\u2026\u201d\nNotice the phrasing in the first sentence: \u201cimportant decision regarding communica\u2010\ntion between services.\u201d Here, the context of the decision is mentioned, but not the\nactual decision itself. The second part of the first sentence is even more important:\n\u201cthat directly impacts you.\u201d If an architectural decision doesn\u2019t directly impact the\nperson, then why bother that person with your architecture decision? This is a great\nlitmus test for determining which stakeholders (including developers) should be noti\u2010\nfied directly of an architecture decision. The second sentence provides a link to the\nlocation of the architecture decision so it is located in only one place, hence a single\nsystem of record for the decision.\nArchitecturally Significant\nMany architects believe that if the architecture decision involves any specific technol\u2010\nogy, then it\u2019s not an architecture decision, but rather a technical decision. This is not\nalways true. If an architect makes a decision to use a particular technology because it\ndirectly supports a particular architecture characteristic (such as performance or scal\u2010\nability), then it\u2019s an architecture decision.\nMichael Nygard, a well-known software architect and author of Release It! (Pragmatic\nBookshelf), addressed the problem of what decisions an architect should be responsi\u2010\nble for (and hence what is an architecture decision) by coining the term architectur\u2010\nally significant. According to Michael, architecturally significant decisions are those\ndecisions that affect the structure, nonfunctional characteristics, dependencies, inter\u2010\nfaces, or construction techniques.\nThe structure refers to decisions that impact the patterns or styles of architecture\nbeing used. An example of this is the decision to share data between a set of microser\u2010\nvices. This decision impacts the bounded context of the microservice, and as such\naffects the structure of the application.\nThe nonfunctional characteristics are the architecture characteristics (\u201c-ilities\u201d) that\nare important for the application or system being developed or maintained. If a\nchoice of technology impacts performance, and performance is an important aspect\nof the application, then it becomes an architecture decision.\nDependencies refer to coupling points between components and/or services within\nthe system, which in turn impact overall scalability, modularity, agility, testability,\nreliability, and so on.\n284 \n| \nChapter 19: Architecture Decisions\n", "page": 304, "type": "text", "section": "Page 304"}
{"text": "Interfaces refer to how services and components are accessed and orchestrated, usu\u2010\nally through a gateway, integration hub, service bus, or API proxy. Interfaces usually\ninvolve defining contracts, including the versioning and deprecation strategy of those\ncontracts. Interfaces impact others using the system and hence are architecturally\nsignificant.\nFinally, construction techniques refer to decisions about platforms, frameworks, tools,\nand even processes that, although technical in nature, might impact some aspect of\nthe architecture.\nArchitecture Decision Records\nOne of the most effective ways of documenting architecture decisions is through\nArchitecture Decision Records (ADRs). ADRs were first evangelized by Michael\nNygard in a blog post and later marked as \u201cadopt\u201d in the ThoughtWorks Technology\nRadar. An ADR consists of a short text file (usually one to two pages long) describing\na specific architecture decision. While ADRs can be written using plain text, they are\nusually written in some sort of text document format like AsciiDoc or Markdown.\nAlternatively, an ADR can also be written using a wiki page template.\nTooling is also available for managing ADRs. Nat Pryce, coauthor of Growing Object-\nOriented Software Guided by Tests (Addison-Wesley), has written an open source tool\nfor ADRs called ADR-tools. ADR-tools provides a command-line interface to manage\nADRs, including the numbering schemes, locations, and superseded logic. Micha\nKops, a software engineer from Germany, has written a blog post about using ADR-\ntools that provides some great examples on how they can be used to manage architec\u2010\nture decision records.\nBasic Structure\nThe basic structure of an ADR consists of five main sections: Title, Status, Context,\nDecision, and Consequences. We usually add two additional sections as part of the\nbasic structure: Compliance and Notes. This basic structure (as illustrated in\nFigure 19-1) can be extended to include any other section deemed needed, providing\nthe template is kept both consistent and concise. A good example of this might be to\nadd an Alternatives section if necessary to provide an analysis of all the other possible\nalternative solutions.\nArchitecture Decision Records \n| \n285\n", "page": 305, "type": "text", "section": "Page 305"}
{"text": "Figure 19-1. Basic ADR structure\nTitle\nThe title of an ADR is usually numbered sequentially and contains a short phrase\ndescribing the architecture decisions. For example, the decision to use asynchronous\nmessaging between the Order Service and the Payment Service might read: \u201c42. Use\nof Asynchronous Messaging Between Order and Payment Services.\u201d The title should\nbe descriptive enough to remove any ambiguity about the nature and context of the\ndecision but at the same time be short and concise.\nStatus\nThe status of an ADR can be marked as Proposed, Accepted, or Superseded. Proposed\nstatus means the decision must be approved by either a higher-level decision maker\nor some sort of architectural governance body (such as an architecture review board).\nAccepted status means the decision has been approved and is ready for implementa\u2010\ntion. A status of Superseded means the decision has been changed and superseded by\nanother ADR. Superseded status always assumes the prior ADR status was accepted;\nin other words, a proposed ADR would never be superseded by another ADR, but\nrather continued to be modified until accepted.\n286 \n| \nChapter 19: Architecture Decisions\n", "page": 306, "type": "text", "section": "Page 306"}
{"text": "The Superseded status is a powerful way of keeping a historical record of what deci\u2010\nsions were made, why they were made at that time, and what the new decision is and\nwhy it was changed. Usually, when an ADR has been superseded, it is marked with\nthe decision that superseded it. Similarly, the decision that supersedes another ADR is\nmarked with the ADR it superseded. For example, assume ADR 42 (\u201cUse of Asyn\u2010\nchronous Messaging Between Order and Payment Services\u201d) was previously\napproved, but due to later changes to the implementation and location of the Pay\u2010\nment Service, REST must now be used between the two services (ADR 68). The status\nwould look as follows:\nADR 42. Use of Asynchronous Messaging Between Order and Payment Services\nStatus: Superseded by 68\nADR 68. Use of REST Between Order and Payment Services\nStatus: Accepted, supersedes 42\nThe link and history trail between ADRs 42 and 68 avoid the inevitable \u201cwhat about\nusing messaging?\u201d question regarding ADR 68.\nADRs and Request for Comments (RFC)\nIf an architect wishes to send out a draft ADR for comments (which is sometimes a\ngood idea when the architect wants to validate various assumptions and assertions\nwith a larger audience of stakeholders), we recommend creating a new status named\nRequest for Comments (or RFC) and specify a deadline date when that review would\nbe complete. This practice avoids the inevitable Analysis Paralysis anti-pattern where\nthe decision is forever discussed but never actually made. Once that date is reached,\nthe architect can analyze all the comments made on the ADR, make any necessary\nadjustments to the decision, make the final decision, and set the status to Proposed\n(unless the architect is able to approve the decision themselves, in which case the sta\u2010\ntus would then be set to Accepted). An example of an RFC status for an ADR would\nlook as follows:\nSTATUS\nRequest For Comments, Deadline 09 JAN 2010\nAnother significant aspect of the Status section of an ADR is that it forces an architect\nto have necessary conversations with their boss or lead architect about the criteria\nwith which they can approve an architecture decision on their own, or whether it\nmust be approved through a higher-level architect, an architecture review board, or\nsome other architecture governing body.\nThree criteria that form a good start for these conversations are cost, cross-team\nimpact, and security. Cost can include software purchase or licensing fees, additional\nhardware costs, as well as the overall level of effort to implement the architecture\nArchitecture Decision Records \n| \n287\n", "page": 307, "type": "text", "section": "Page 307"}
{"text": "decision. Level of effort costs can be estimated by multiplying the estimated number\nof hours to implement the architecture decision by the company\u2019s standard Full-Time\nEquivalency (FTE) rate. The project owner or project manager usually has the FTE\namount. If the cost of the architecture decision exceeds a certain amount, then it\nmust be set to Proposed status and approved by someone else. If the architecture\ndecision impacts other teams or systems or has any sort of security implication, then\nit cannot be self-approved by the architect and must be approved by a higher-level\ngoverning body or lead architect.\nOnce the criteria and corresponding limits have been established and agreed upon\n(such as \u201ccosts exceeding \u20ac5,000 must be approved by the architecture review\nboard\u201d), this criteria should be well documented so that all architects creating ADRs\nknow when they can and cannot approve their own architecture decisions.\nContext\nThe context section of an ADR specifies the forces at play. In other words, \u201cwhat sit\u2010\nuation is forcing me to make this decision?\u201d This section of the ADR allows the archi\u2010\ntect to describe the specific situation or issue and concisely elaborate on the possible\nalternatives. If an architect is required to document the analysis of each alternative in\ndetail, then an additional Alternatives section can be added to the ADR rather than\nadding that analysis to the Context section.\nThe Context section also provides a way to document the architecture. By describing\nthe context, the architect is also describing the architecture. This is an effective way of\ndocumenting a specific area of the architecture in a clear and concise manner. Con\u2010\ntinuing with the example from the prior section, the context might read as follows:\n\u201cThe order service must pass information to the payment service to pay for an order\ncurrently being placed. This could be done using REST or asynchronous messaging.\u201d\nNotice that this concise statement not only specified the scenario, but also the\nalternatives.\nDecision\nThe Decision section of the ADR contains the architecture decision, along with a full\njustification for the decision. Michael Nygard introduced a great way of stating an\narchitecture decision by using a very affirmative, commanding voice rather than a\npassive one. For example, the decision to use asynchronous messaging between serv\u2010\nices would read \u201cwe will use asynchronous messaging between services.\u201d This is a\nmuch better way of stating a decision as opposed to \u201cI think asynchronous messaging\nbetween services would be the best choice.\u201d Notice here it is not clear what the deci\u2010\nsion is or even if a decision has even been made\u2014only the opinion of the architect is\nstated.\n288 \n| \nChapter 19: Architecture Decisions\n", "page": 308, "type": "text", "section": "Page 308"}
{"text": "Perhaps one of the most powerful aspects of the Decision section of ADRs is that it\nallows an architect to place more emphasis on the why rather than the how. Under\u2010\nstanding why a decision was made is far more important than understanding how\nsomething works. Most architects and developers can identify how things work by\nlooking at context diagrams, but not why a decision was made. Knowing why a deci\u2010\nsion was made and the corresponding justification for the decision helps people bet\u2010\nter understand the context of the problem and avoids possible mistakes through\nrefactoring to another solution that might produce issues.\nTo illustrate this point, consider an original architecture decision several years ago to\nuse Google\u2019s Remote Procedure Call (gRPC) as a means to communicate between two\nservices. Without understanding why that decision was made, another architect sev\u2010\neral years later makes the choice to override that decision and use messaging instead\nto better decouple the services. However, implementing this refactoring suddenly\ncauses a significant increase in latency, which in turn ultimately causes time outs to\noccur in upstream systems. Understanding that the original use of gRPC was to sig\u2010\nnificantly reduce latency (at the cost of tightly coupled services) would have preven\u2010\nted the refactoring from happening in the first place.\nConsequences\nThe Consequences section of an ADR is another very powerful section. This section\ndocuments the overall impact of an architecture decision. Every architecture decision\nan architect makes has some sort of impact, both good and bad. Having to specify the\nimpact of an architecture decision forces the architect to think about whether those\nimpacts outweigh the benefits of the decision.\nAnother good use of this section is to document the trade-off analysis associated with\nthe architecture decision. These trade-offs could be cost-based or trade-offs against\nother architecture characteristics (\u201c-ilities\u201d). For example, consider the decision to use\nasynchronous (fire-and-forget) messaging to post a review on a website. The justifi\u2010\ncation for this decision is to significantly increase the responsiveness of the post\nreview request from 3,100 milliseconds to 25 milliseconds because users would not\nneed to wait for the actual review to be posted (only for the message to be sent to a\nqueue). While this is a good justification, someone else might argue that this is a bad\nidea due to the complexity of the error handling associated with an asynchronous\nrequest (\u201cwhat happens if someone posts a review with some bad words?\u201d). Unknown\nto the person challenging this decision, that issue was already discussed with the busi\u2010\nness stakeholders and other architects, and it was decided from a trade-off perspec\u2010\ntive that it was more important to have the increase in responsiveness and deal with\nthe complex error handling rather than have the wait time to synchronously provide\nfeedback to the user that the review was successfully posted. By leveraging ADRs, that\ntrade-off analysis can be included in the Consequences section, providing a complete\nArchitecture Decision Records \n| \n289\n", "page": 309, "type": "text", "section": "Page 309"}
{"text": "picture of the context (and trade-offs) of the architecture decision and thus avoiding\nthese situations.\nCompliance\nThe compliance section of an ADR is not one of the standard sections in an ADR, but\nit\u2019s one we highly recommend adding. The Compliance section forces the architect to\nthink about how the architecture decision will be measured and governed from a\ncompliance perspective. The architect must decide whether the compliance check for\nthis decision must be manual or if it can be automated using a fitness function. If it\ncan be automated using a fitness function, the architect can then specify in this sec\u2010\ntion how that fitness function would be written and whether there are any other\nchanges to the code base are needed to measure this architecture decision for\ncompliance.\nFor example, consider the following architecture decision within a traditional n-\ntiered layered architecture as illustrated in Figure 19-2. All shared objects used by\nbusiness objects in the business layer will reside in the shared services layer to isolate\nand contain shared functionality.\nFigure 19-2. An example of an architecture decision\nThis architecture decision can be measured and governed automatically by using\neither ArchUnit in Java or NetArchTest in C#. For example, using ArchUnit in Java,\nthe automated fitness function test might look as follows:\n290 \n| \nChapter 19: Architecture Decisions\n", "page": 310, "type": "text", "section": "Page 310"}
{"text": "@Test\npublic void shared_services_should_reside_in_services_layer() {\n    classes().that().areAnnotatedWith(SharedService.class)\n        .should().resideInAPackage(\"..services..\")\n        .because(\"All shared services classes used by business \" +\n                 \"objects in the business layer should reside in the services \" +\n                 \"layer to isolate and contain shared logic\")\n        .check(myClasses);\n}\nNotice that this automated fitness function would require new stories to be written to\ncreate a new Java annotation (@SharedService) and to then add this annotation to all\nshared classes. This section also specifies what the test is, where the test can be found,\nand how the test will be executed and when.\nNotes\nAnother section that is not part of a standard ADR but that we highly recommend\nadding is the Notes section. This section includes various metadata about the ADR,\nsuch as the following:\n\u2022 Original author\n\u2022 Approval date\n\u2022 Approved by\n\u2022 Superseded date\n\u2022 Last modified date\n\u2022 Modified by\n\u2022 Last modification\nEven when storing ADRs in a version control system (such as Git), additional meta-\ninformation is useful beyond what the repository can support, so we recommend\nadding this section regardless of how and where ADRs are stored.\nStoring ADRs\nOnce an architect creates an ADR, it must be stored somewhere. Regardless of where\nADRs are stored, each architecture decision should have its own file or wiki page.\nSome architects like to keep ADRs in the Git repository with the source code. Keep\u2010\ning ADRs in a Git repository allows the ADR to be versioned and tracked as well.\nHowever, for larger organizations we caution against this practice for several reasons.\nFirst, everyone who needs to see the architecture decision may not have access to the\nGit repository. Second, this is not a good place to store ADRs that have a context out\u2010\nside of the application Git repository (such as integration architecture decisions,\nenterprise architecture decisions, or those decisions common to every application).\nArchitecture Decision Records \n| \n291\n", "page": 311, "type": "text", "section": "Page 311"}
{"text": "For these reasons we recommend storing ADRs either in a wiki (using a wiki tem\u2010\nplate) or in a shared directory on a shared file server that can be accessed easily by a\nwiki or other document rendering software. Figure 19-3 shows an example of what\nthis directory structure (or wiki page navigation structure) might look like.\nFigure 19-3. Example directory structure for storing ADRs\nThe application directory contains those architecture decisions that are specific to\nsome sort of application context. This directory is subdivided into further directories.\nThe common subdirectory is for architecture decisions that apply to all applications,\nsuch as \u201c\nAll framework-related classes will contain an annotation (@Framework in\nJava) or attribute ([Framework] in C#) identifying the class as belonging to the\nunderlying framework code.\u201d Subdirectories under the application directory corre\u2010\nspond to the specific application or system context and contain the architecture deci\u2010\nsions specific to that application or system (in this example, the ATP and PSTD\napplications). The integration directory contains those ADRs that involve the com\u2010\nmunication between application, systems, or services. Enterprise architecture ADRs\nare contained within the enterprise directory, indicating that these are global architec\u2010\nture decisions impacting all systems and applications. An example of an enterprise\narchitecture ADR would be \u201c\nAll access to a system database will only be from the\nowning system,\u201d thus preventing the sharing of databases across multiple systems.\nWhen storing ADRs in a wiki (our recommendation), the same structure previously\ndescribed applies, with each directory structure representing a navigational landing\npage. Each ADR would be represented as a single wiki page within each navigational\nlanding page (Application, Integration, or Enterprise).\n292 \n| \nChapter 19: Architecture Decisions\n", "page": 312, "type": "text", "section": "Page 312"}
{"text": "The directory or landing page names indicated in this section are only a recommen\u2010\ndation. Each company can choose whatever names fit their situation, as long as those\nnames are consistent across teams.\nADRs as Documentation\nDocumenting software architecture has always been a difficult topic. While some\nstandards are emerging for diagramming architecture (such as software architect\nSimon Brown\u2019s C4 Model or The Open Group ArchiMate standard), no such stan\u2010\ndard exists for documenting software architecture. That\u2019s where ADRs come in.\nArchitecture Decision Records can be used an an effective means to document a soft\u2010\nware architecture. The Context section of an ADR provides an excellent opportunity\nto describe the specific area of the system that requires an architecture decision to be\nmade. This section also provides an opportunity to describe the alternatives. Perhaps\nmore important is that the Decision section describes the reasons why a particular\ndecision is made, which is by far the best form of architecture documentation. The\nConsequences section adds the final piece to the architecture documentation by\ndescribing additional aspects of a particular decision, such as the trade-off analysis of\nchoosing performance over scalability.\nUsing ADRs for Standards\nVery few people like standards. Most times standards seem to be in place more for\ncontrolling people and the way they do things than anything useful. Using ADRs for\nstandards can change this bad practice. For example, the Context section of an ADR\ndescribes the situation that is forcing the particular standard. The Decision section of\nan ADR can be used to not only indicate what the standard is, but more importantly\nwhy the standard needs to exist. This is a wonderful way of being able to qualify\nwhether the particular standard should even exist in the first place. If an architect\ncannot justify the standard, then perhaps it is not a good standard to make and\nenforce. Furthermore, the more developers understand why a particular standard\nexists, the more likely they are to follow it (and correspondingly not challenge it).\nThe Consequences section of an ADR is another great place an architect can qualify\nwhether a standard is valid and should be made. In this section the architect must\nthink about and document what the implications and consequences are of a particu\u2010\nlar standard they are making. By analyzing the consequences, the architect might\ndecide that the standard should not be applied after all.\nArchitecture Decision Records \n| \n293\n", "page": 313, "type": "text", "section": "Page 313"}
{"text": "Example\nMany architecture decisions exist within our ongoing \u201cCase Study: Going, Going,\nGone\u201d on page 95. The use of event-driven microservices, the splitting up of the bid\u2010\nder and auctioneer user interfaces, the use of the Real-time Transport Protocol (RTP)\nfor video capture, the use of a single API layer, and the use of publish-and-subscribe\nmessaging are just a few of the dozens of architecture decisions that are made for this\nauction system. Every architecture decision made in a system, no matter how obvi\u2010\nous, should be documented and justified.\nFigure 19-4 illustrates one of the architecture decisions within the Going, Going,\nGone auction system, which is the use of publish-and-subscribe (pub/sub) messaging\nbetween the bid capture, bid streamer, and bid tracker services.\nFigure 19-4. Use of pub/sub between services\n294 \n| \nChapter 19: Architecture Decisions\n", "page": 314, "type": "text", "section": "Page 314"}
{"text": "The ADR for this architecture decision might look simliar to Figure 19-5:\nFigure 19-5. ADR 76. Asynchronous Pub/Sub Messaging Between Bidding Services\nArchitecture Decision Records \n| \n295\n", "page": 315, "type": "text", "section": "Page 315"}
{"text": "CHAPTER 20\nAnalyzing Architecture Risk\nEvery architecture has risk associated with it, whether it be risk involving availability,\nscalability, or data integrity. Analyzing architecture risk is one of the key activities of\narchitecture. By continually analyzing risk, the architect can address deficiencies\nwithin the architecture and take corrective action to mitigate the risk. In this chapter\nwe introduce some of the key techniques and practices for qualifying risk, creating\nrisk assessments, and identifying risk through an activity called risk storming.\nRisk Matrix\nThe first issue that arises when assessing architecture risk is determining whether the\nrisk should be classified as low, medium, or high. Too much subjectiveness usually\nenters into this classification, creating confusion about which parts of the architecture\nare really high risk versus medium risk. Fortunately, there is a risk matrix architects\ncan leverage to help reduce the level of subjectiveness and qualify the risk associated\nwith a particular area of the architecture.\nThe architecture risk matrix (illustrated in Figure 20-1) uses two dimensions to qual\u2010\nify risk: the overall impact of the risk and the likelihood of that risk occurring. Each\ndimensions has a low (1), medium (2), and high (3) rating. These numbers are multi\u2010\nplied together within each grid of the matrix, providing an objective numerical num\u2010\nber representing that risk. Numbers 1 and 2 are considered low risk (green), numbers\n3 and 4 are considered medium risk (yellow), and numbers 6 through 9 are consid\u2010\nered high risk (red).\n297\n", "page": 317, "type": "text", "section": "Page 317"}
{"text": "Figure 20-1. Matrix for determining architecture risk\nTo see how the risk matrix can be used, suppose there is a concern about availability\nwith regard to a primary central database used in the application. First, consider the\nimpact dimension\u2014what is the overall impact if the database goes down or becomes\nunavailable? Here, an architect might deem that high risk, making that risk either a 3\n(medium), 6 (high), or 9 (high). However, after applying the second dimension (like\u2010\nlihood of risk occurring), the architect realizes that the database is on highly available\nservers in a clustered configuration, so the likelihood is low that the database would\nbecome unavailable. Therefore, the intersection between the high impact and low\nlikelihood gives an overall risk rating of 3 (medium risk).\nWhen leveraging the risk matrix to qualify the risk, consider the\nimpact dimension first and the likelihood dimension second.\nRisk Assessments\nThe risk matrix described in the previous section can be used to build what is called a\nrisk assessment. A risk assessment is a summarized report of the overall risk of an\narchitecture with respect to some sort of contextual and meaningful assessment\ncriteria.\n298 \n| \nChapter 20: Analyzing Architecture Risk\n", "page": 318, "type": "text", "section": "Page 318"}
{"text": "Risk assessments can vary greatly, but in general they contain the risk (qualified from\nthe risk matrix) of some assessment criteria based on services or domain areas of an\napplication. This basic risk assessment report format is illustrated in Figure 20-2,\nwhere light gray (1-2) is low risk, medium gray (3-4) is medium risk, and dark gray\n(6-9) is high risk. Usually these are color-coded as green (low), yellow (medium), and\nred (high), but shading can be useful for black-and-white rendering and for color\nblindness.\nFigure 20-2. Example of a standard risk assessment\nThe quantified risk from the risk matrix can be accumulated by the risk criteria and\nalso by the service or domain area. For example, notice in Figure 20-2 that the accu\u2010\nmulated risk for data integrity is the highest risk area at a total of 17, whereas the\naccumulated risk for Availability is only 10 (the least amount of risk). The relative risk\nof each domain area can also be determined by the example risk assessment. Here,\ncustomer registration carries the highest area of risk, whereas order fulfillment carries\nthe lowest risk. These relative numbers can then be tracked to demonstrate either\nimprovements or degradation of risk within a particular risk category or domain\narea.\nAlthough the risk assessment example in Figure 20-2 contains all the risk analysis\nresults, rarely is it presented as such. Filtering is essential for visually indicating a par\u2010\nticular message within a given context. For example, suppose an architect is in a\nmeeting for the purpose of presenting areas of the system that are high risk. Rather\nthan presenting the risk assessment as illustrated in Figure 20-2, filtering can be used\nto only show the high risk areas (shown in Figure 20-3), improving the overall signal-\nto-noise ratio and presenting a clear picture of the state of the system (good or bad).\nRisk Assessments \n| \n299\n", "page": 319, "type": "text", "section": "Page 319"}
{"text": "Figure 20-3. Filtering the risk assessment to only high risk\nAnother issue with Figure 20-2 is that this assessment report only shows a snapshot\nin time; it does not show whether things are improving or getting worse. In other\nwords, Figure 20-2 does not show the direction of risk. Rendering the direction of\nrisk presents somewhat of an issue. If an up or down arrow were to be used to indi\u2010\ncate direction, what would an up arrow mean? Are things getting better or worse?\nWe\u2019ve spent years asking people if an up arrow meant things were getting better or\nworse, and almost 50% of people asked said that the up arrow meant things were pro\u2010\ngressively getting worse, whereas almost 50% said an up arrow indicated things were\ngetting better. The same is true for left and right arrows. For this reason, when using\narrows to indicate direction, a key must be used. However, we\u2019ve also found this\ndoesn\u2019t work either. Once the user scrolls beyond the key, confusion happens once\nagain.\nWe usually use the universal direction symbol of a plus (+) and minus (-) sign next to\nthe risk rating to indicate direction, as illustrated in Figure 20-4. Notice in\nFigure 20-4 that although performance for customer registration is medium (4), the\ndirection is a minus sign (red), indicating that it is progressively getting worse and\nheading toward high risk. On the other hand, notice that scalability of catalog check\u2010\nout is high (6) with a plus sign (green), showing that it is improving. Risk ratings\nwithout a plus or minus sign indicate that the risk is stable and neither getting better\nnor worse.\n300 \n| \nChapter 20: Analyzing Architecture Risk\n", "page": 320, "type": "text", "section": "Page 320"}
{"text": "Figure 20-4. Showing direction of risk with plus and minus signs\nOccasionally, even the plus and minus signs can be confusing to some people.\nAnother technique for indicating direction is to leverage an arrow along with the risk\nrating number it is trending toward. This technique, as illustrated in Figure 20-5,\ndoes not require a key because the direction is clear. Furthermore, the use of colors\n(red arrow for worse, green arrow for better) makes it even more clear where the risk\nis heading.\nFigure 20-5. Showing direction of risk with arrows and numbers\nRisk Assessments \n| \n301\n", "page": 321, "type": "text", "section": "Page 321"}
{"text": "The direction of risk can be determined by using continuous measurements through\nfitness functions described earlier in the book. By objectively analyzing each risk cri\u2010\nteria, trends can be observed, providing the direction of each risk criteria.\nRisk Storming\nNo architect can single-handedly determine the overall risk of a system. The reason\nfor this is two-fold. First, a single architect might miss or overlook a risk area, and\nvery few architects have full knowledge of every part of the system. This is where risk\nstorming can help.\nRisk storming is a collaborative exercise used to determine architectural risk within a\nspecific dimension. Common dimensions (areas of risk) include unproven technol\u2010\nogy, performance, scalability, availability (including transitive dependencies), data\nloss, single points of failure, and security. While most risk storming efforts involve\nmultiple architects, it is wise to include senior developers and tech leads as well. Not\nonly will they provide an implementation perspective to the architectural risk, but\ninvolving developers helps them gain a better understanding of the architecture.\nThe risk storming effort involves both an individual part and a collaborative part. In\nthe individual part, all participants individually (without collaboration) assign risk to\nareas of the architecture using the risk matrix described in the previous section. This\nnoncollaborative part of risk storming is essential so that participants don\u2019t influence\nor direct attention away from particular areas of the architecture. In the collaborative\npart of risk storming, all participants work together to gain consensus on risk areas,\ndiscuss risk, and form solutions for mitigating the risk.\nAn architecture diagram is used for both parts of the risk storming effort. For holistic\nrisk assessments, usually a comprehensive architecture diagram is used, whereas risk\nstorming within specific areas of the application would use a contextual architecture\ndiagram. It is the responsibility of the architect conducting the risk storming effort to\nmake sure these diagrams are up to date and available to all participants.\nFigure 20-6 shows an example architecture we\u2019ll use to illustrate the risk storming\nprocess. In this architecture, an Elastic Load Balancer fronts each EC2 instance con\u2010\ntaining the web servers (Nginx) and application services. The application services\nmake calls to a MySQL database, a Redis cache, and a MongoDB database for logging. \nThey also make calls to the Push Expansion Servers. The expansion servers, in turn,\nall interface with the MySQL database, Redis cache, and MongoDB logging facility.\n302 \n| \nChapter 20: Analyzing Architecture Risk\n", "page": 322, "type": "text", "section": "Page 322"}
{"text": "Figure 20-6. Architecture diagram for risk storming example\nRisk storming is broken down into three primary activities:\n1. Identification\n2. Consensus\n3. Mitigation\nIdentification is always an individual, noncollaborative activity, whereas consensus\nand mitigation are always collaborative and involve all participants working together\nin the same room (at least virtually). Each of these primary activities is discussed in\ndetail in the following sections.\nIdentification\nThe identification activity of risk storming involves each participant individually\nidentifying areas of risk within the architecture. The following steps describe the\nidentification part of the risk storming effort:\n1. The architect conducting the risk storming sends out an invitation to all partici\u2010\npants one to two days prior to the collaborative part of the effort. The invitation\ncontains the architecture diagram (or the location of where to find it), the risk\nRisk Storming \n| \n303\n", "page": 323, "type": "text", "section": "Page 323"}
{"text": "storming dimension (area of risk being analyzed for that particular risk storming\neffort), the date when the collaborative part of risk storming will take place, and\nthe location.\n2. Using the risk matrix described in the first section of this chapter, participants\nindividually analyze the architecture and classify the risk as low (1-2), medium\n(3-4), or high (6-9).\n3. Participants prepare small Post-it notes with corresponding colors (green, yellow,\nand red) and write down the corresponding risk number (found on the risk\nmatrix).\nMost risk storming efforts only involve analyzing one particular dimension (such as\nperformance), but there might be times, due to the availability of staff or timing\nissues, when multiple dimensions are analyzed within a single risk storming effort\n(such as performance, scalability, and data loss). When multiple dimensions are ana\u2010\nlyzed within a single risk storming effort, the participants write the dimension next to\nthe risk number on the Post-it notes so that everyone is aware of the specific dimen\u2010\nsion. For example, suppose three participants found risk within the central database.\nAll three identified the risk as high (6), but one participant found risk with respect to\navailability, whereas two participants found risk with respect to performance. These\ntwo dimensions would be discussed separately.\nWhenever possible, restrict risk storming efforts to a single dimen\u2010\nsion. This allows participants to focus their attention to that spe\u2010\ncific dimension and avoids confusion about multiple risk areas\nbeing identified for the same area of the architecture.\nConsensus\nThe consensus activity in the risk storming effort is highly collaborative with the goal\nof gaining consensus among all participants regarding the risk within the architec\u2010\nture. This activity is most effective when a large, printed version of the architecture\ndiagram is available and posted on the wall. In lieu of a large printed version, an elec\u2010\ntronic version can be displayed on a large screen.\nUpon arrival at the risk storming session, participants begin placing their Post-it\nnotes on the architecture diagram in the area where they individually found risk. If\nan electronic version is used, the architect conducting the risk storming session quer\u2010\nies every participant and electronically places the risk on the diagram in the area of\nthe architecture where the risk was identified (see Figure 20-7).\n304 \n| \nChapter 20: Analyzing Architecture Risk\n", "page": 324, "type": "text", "section": "Page 324"}
{"text": "Figure 20-7. Initial identification of risk areas\nOnce all of the Post-it notes are in place, the collaborative part of risk storming can\nbegin. The goal of this activity of risk storming is to analyze the risk areas as a team\nand gain consensus in terms of the risk qualification. Notice several areas of risk were\nidentified in the architecture, illustrated in Figure 20-7:\n1. Two participants individually identified the Elastic Load Balancer as medium risk\n(3), whereas one participant identified it as high risk (6).\n2. One participant individually identified the Push Expansion Servers as high risk\n(9).\n3. Three participants individually identified the MySQL database as medium risk\n(3).\n4. One participant individually identified the Redis cache as high risk (9).\n5. Three participants identified MongoDB logging as low risk (2).\n6. All other areas of the architecture were not deemed to carry any risk, hence there\nare no Post-it notes on any other areas of the architecture.\nRisk Storming \n| \n305\n", "page": 325, "type": "text", "section": "Page 325"}
{"text": "Items 3 and 5 in the prior list do not need further discussion in this activity since all\nparticipants agreed on the level and qualification of risk. However, notice there was a\ndifference of opinion in item 1 in the list, and items 2 and 4 only had a single partici\u2010\npant identifying the risk. These items need to be discussed during this activity.\nItem 1 in the list showed that two participants individually identified the Elastic Load\nBalancer as medium risk (3), whereas one participant identified it as high risk (6). In\nthis case the other two participants ask the third participant why they identified the\nrisk as high. Suppose the third participant says that they assigned the risk as high\nbecause if the Elastic Load Balancer goes down, the entire system cannot be accessed.\nWhile this is true and in fact does bring the overall impact rating to high, the other\ntwo participants convince the third participant that there is low risk of this happen\u2010\ning. After much discussion, the third participant agrees, bringing that risk level down\nto a medium (3). However, the first and second participants might not have seen a\nparticular aspect of risk in the Elastic Load Balancer that the third did, hence the need\nfor collaboration within this activity of risk storming.\nCase in point, consider item 2 in the prior list where one participant individually\nidentified the Push Expansion Servers as high risk (9), whereas no other participant\nidentified them as any risk at all. In this case, all other participants ask the participant\nwho identified the risk why they rated it as high. That participant then says that they\nhave had bad experiences with the Push Expansion Servers continually going down\nunder high load, something this particular architecture has. This example shows the\nvalue of risk storming\u2014without that participant\u2019s involvement, no one would have\nseen the high risk (until well into production of course!).\nItem 4 in the list is an interesting case. One participant identified the Redis cache as\nhigh risk (9), whereas no other participant saw that cache as any risk in the architec\u2010\nture. The other participants ask what the rationale is for the high risk in that area, and\nthe one participant responds with, \u201cWhat is a Redis cache?\u201d In this case, Redis was\nunknown to the participant, hence the high risk in that area.\nFor unproven or unknown technologies, always assign the highest\nrisk rating (9) since the risk matrix cannot be used for this\ndimension.\nThe example of item 4 in the list illustrates why it is wise (and important) to bring\ndevelopers into risk storming sessions. Not only can developers learn more about the\narchitecture, but the fact that one participant (who was in this case a developer on the\nteam) didn\u2019t know a given technology provides the architect with valuable informa\u2010\ntion regarding overall risk.\n306 \n| \nChapter 20: Analyzing Architecture Risk\n", "page": 326, "type": "text", "section": "Page 326"}
{"text": "This process continues until all participants agree on the risk areas identified. Once\nall the Post-it notes are consolidated, this activity ends, and the next one can begin.\nThe final outcome of this activity is shown in Figure 20-8.\nFigure 20-8. Consensus of risk areas\nMitigation\nOnce all participants agree on the qualification of the risk areas of the architecture,\nthe final and most important activity occurs\u2014risk mitigation. Mitigating risk within\nan architecture usually involves changes or enhancements to certain areas of the\narchitecture that otherwise might have been deemed perfect the way they were.\nThis activity, which is also usually collaborative, seeks ways to reduce or eliminate the\nrisk identified in the first activity. There may be cases where the original architecture\nneeds to be completely changed based on the identification of risk, whereas others\nmight be a straightforward architecture refactoring, such as adding a queue for back\npressure to reduce a throughput bottleneck issue.\nRegardless of the changes required in the architecture, this activity usually incurs\nadditional cost. For that reason, key stakeholders typically decide whether the cost\noutweighs the risk. For example, suppose that through a risk storming session the\ncentral database was identified as being medium risk (4) with regard to overall system\navailability. In this case, the participants agreed that clustering the database, com\u2010\nRisk Storming \n| \n307\n", "page": 327, "type": "text", "section": "Page 327"}
{"text": "bined with breaking the single database into separate physical databases, would miti\u2010\ngate that risk. However, while risk would be significantly reduced, this solution would\ncost $20,000. The architect would then conduct a meeting with the key business\nstakeholder to discuss this trade-off. During this negotiation, the business owner\ndecides that the price tag is too high and that the cost does not outweigh the risk.\nRather than giving up, the architect then suggests a different approach\u2014what about\nskipping the clustering and splitting the database into two parts? The cost in this case\nis reduced to $8,000 while still mitigating most of the risk. In this case, the stake\u2010\nholder agrees to the solution.\nThe previous scenario shows the impact risk storming can have not only on the over\u2010\nall architecture, but also with regard to negotiations between architects and business\nstakeholders. Risk storming, combined with the risk assessments described at the\nstart of this chapter, provide an excellent vehicle for identifying and tracking risk,\nimproving the architecture, and handling negotiations between key stakeholders.\nAgile Story Risk Analysis\nRisk storming can be used for other aspects of software development besides just\narchitecture. For example, we\u2019ve leveraged risk storming for determining overall risk\nof user story completion within a given Agile iteration (and consequently the overall\nrisk assessment of that iteration) during story grooming. Using the risk matrix, user\nstory risk can be identified by the first dimension (the overall impact if the story is\nnot completed within the iteration) and the second dimension (the likelihood that the\nstory will not be completed). By utilizing the same architecture risk matrix for stories,\nteams can identify stories of high risk, track those carefully, and prioritize them.\nRisk Storming Examples\nTo illustrate the power of risk storming and how it can improve the overall architec\u2010\nture of a system, consider the example of a call center system to support nurses advis\u2010\ning patients on various health conditions. The requirements for such a system are as\nfollows:\n\u2022 The system will use a third-party diagnostics engine that serves up questions and\nguides the nurses or patients regarding their medical issues.\n\u2022 Patients can either call in using the call center to speak to a nurse or choose to use\na self-service website that accesses the diagnostic engine directly, bypassing the\nnurses.\n\u2022 The system must support 250 concurrent nurses nationwide and up to hundreds\nof thousands of concurrent self-service patients nationwide.\n308 \n| \nChapter 20: Analyzing Architecture Risk\n", "page": 328, "type": "text", "section": "Page 328"}
{"text": "\u2022 Nurses can access patients\u2019 medical records through a medical records exchange,\nbut patients cannot access their own medical records.\n\u2022 The system must be HIPAA compliant with regard to the medical records. This\nmeans that it is essential that no one but nurses have access to medical records.\n\u2022 Outbreaks and high volume during cold and flu season need to be addressed in\nthe system.\n\u2022 Call routing to nurses is based on the nurse\u2019s profile (such as bilingual needs).\n\u2022 The third-party diagnostic engine can handle about 500 requests a second.\nThe architect of the system created the high-level architecture illustrated in\nFigure 20-9. In this architecture there are three separate web-based user interfaces:\none for self-service, one for nurses receiving calls, and one for administrative staff to\nadd and maintain the nursing profile and configuration settings. The call center por\u2010\ntion of the system consists of a call accepter which receives calls and the call router\nwhich routes calls to the next available nurse based on their profile (notice how the\ncall router accesses the central database to get nurse profile information). Central to\nthis architecture is a diagnostics system API gateway, which performs security checks\nand directs the request to the appropriate backend service.\nFigure 20-9. High-level architecture for nurse diagnostics system example\nThere are four main services in this system: a case management service, a nurse pro\u2010\nfile management service, an interface to the medical records exchange, and the exter\u2010\nnal third-party diagnostics engine. All communications are using REST with the\nexception of proprietary protocols to the external systems and call center services.\nRisk Storming Examples \n| \n309\n", "page": 329, "type": "text", "section": "Page 329"}
{"text": "The architect has reviewed this architecture numerous times and believes it is ready\nfor implementation. As a self-assessment, study the requirements and the architec\u2010\nture diagram in Figure 20-9 and try to determine the level of risk within this architec\u2010\nture in terms of availability, elasticity, and security. After determining the level of risk,\nthen determine what changes would be needed in the architecture to mitigate that\nrisk. The sections that follow contain scenarios that can be used as a comparison.\nAvailability\nDuring the first risk storming exercise, the architect chose to focus on availability first\nsince system availability is critical for the success of this system. After the risk storm\u2010\ning identification and collaboration activities, the participants came up with the fol\u2010\nlowing risk areas using the risk matrix (as illustrated in Figure 20-10):\n\u2022 The use of a central database was identified as high risk (6) due to high impact\n(3) and medium likelihood (2).\n\u2022 The diagnostics engine availability was identified as high risk (9) due to high\nimpact (3) and unknown likelihood (3).\n\u2022 The medical records exchange availability was identified as low risk (2) since it is\nnot a required component for the system to run.\n\u2022 Other parts of the system were not deemed as risk for availability due to multiple\ninstances of each service and clustering of the API gateway.\nFigure 20-10. Availability risk areas\nDuring the risk storming effort, all participants agreed that while nurses can man\u2010\nually write down case notes if the database went down, the call router could not func\u2010\n310 \n| \nChapter 20: Analyzing Architecture Risk\n", "page": 330, "type": "text", "section": "Page 330"}
{"text": "tion if the database were not available. To mitigate the database risk, participants\nchose to break apart the single physical database into two separate databases: one\nclustered database containing the nurse profile information, and one single instance\ndatabase for the case notes. Not only did this architecture change address the con\u2010\ncerns about availability of the database, but it also helped secure the case notes from\nadmin access. Another option to mitigate this risk would have been to cache the\nnurse profile information in the call router. However, because the implementation of\nthe call router was unknown and may be a third-party product, the participants went\nwith the database approach.\nMitigating the risk of availability of the external systems (diagnostics engine and\nmedical records exchange) is much harder to manage due to the lack of control of\nthese systems. One way to mitigate this sort of availability risk is to research if there is\na published service-level agreement (SLA) or service-level objective (SLO) for each of\nthese systems. An SLA is usually a contractual agreement and is legally binding,\nwhereas an SLO is usually not. Based on research, the architect found that the SLA\nfor the diagnostics engine is guaranteed to be 99.99% available (that\u2019s 52.60 minutes\nof downtime per year), and the medical records exchange is guaranteed at 99.9%\navailability (that\u2019s 8.77 hours of downtime per year). Based on the relative risk, this\ninformation was enough to remove the identified risk.\nThe corresponding changes to the architecture after this risk storming session are\nillustrated in Figure 20-11. Notice that two databases are now used, and also the SLAs\nare published on the architecture diagram.\nFigure 20-11. Architecture modifications to address availability risk\nRisk Storming Examples \n| \n311\n", "page": 331, "type": "text", "section": "Page 331"}
{"text": "Elasticity\nOn the second risk storming exercise, the architect chose to focus on elasticity\u2014\nspikes in user load (otherwise known as variable scalability). Although there are only\n250 nurses (which provides an automatic governor for most of the services), the self-\nservice portion of the system can access the diagnostics engine as well as nurses, sig\u2010\nnificantly increasing the number of requests to the diagnostics interface. Participants\nwere concerned about outbreaks and flu season, when anticipated load on the system\nwould significantly increase.\nDuring the risk storming session, the participants all identified the diagnostics engine\ninterface as high risk (9). With only 500 requests per second, the participants calcula\u2010\nted that there was no way the diagnostics engine interface could keep up with the\nanticipated throughput, particularly with the current architecture utilizing REST as\nthe interface protocol.\nOne way to mitigate this risk is to leverage asynchronous queues (messaging)\nbetween the API gateway and the diagnostics engine interface to provide a back-\npressure point if calls to the diagnostics engine get backed up. While this is a good\npractice, it still doesn\u2019t mitigate the risk, because nurses (as well as self-service\npatients) would be waiting too long for responses from the diagnostics engine, and\nthose requests would likely time out. Leveraging what is known as the Ambulance\nPattern would give nurses a higher priority over self-service. Therefore two message\nchannels would be needed. While this technique helps mitigate the risk, it still doesn\u2019t\naddress the wait times. The participants decided that in addition to the queuing tech\u2010\nnique to provide back-pressure, caching the particular diagnostics questions related\nto an outbreak would remove outbreak and flu calls from ever having to reach the\ndiagnostics engine interface.\nThe corresponding architecture changes are illustrated in Figure 20-12. Notice that in\naddition to two queue channels (one for the nurses and one for self-service patients),\nthere is a new service called the Diagnostics Outbreak Cache Server that handles all\nrequests related to a particular outbreak or flu-related question. With this architec\u2010\nture in place, the limiting factor was removed (calls to the diagnostics engine), allow\u2010\ning for tens of thousands of concurrent requests. Without a risk storming effort, this\nrisk might not have been identified until an outbreak or flu season happened.\n312 \n| \nChapter 20: Analyzing Architecture Risk\n", "page": 332, "type": "text", "section": "Page 332"}
{"text": "Figure 20-12. Architecture modifications to address elasticity risk\nSecurity\nEncouraged by the results and success of the first two risk storming efforts, the archi\u2010\ntect decides to hold a final risk storming session on another important architecture\ncharacteristic that must be supported in the system to ensure its success\u2014security.\nDue to HIPAA regulatory requirements, access to medical records via the medical\nrecord exchange interface must be secure, allowing only nurses to access medical\nrecords if needed. The architect believes this is not a problem due to security checks\nin the API gateway (authentication and authorization) but is curious whether the par\u2010\nticipants find any other elements of security risk.\nDuring the risk storming, the participants all identified the Diagnostics System API\ngateway as a high security risk (6). The rationale for this high rating was the high\nimpact of admin staff or self-service patients accessing medical records (3) combined\nwith medium likelihood (2). Likelihood of risk occurring was not rated high because\nof the security checks for each API call, but still rated medium because all calls (self-\nservice, admin, and nurses) are going through the same API gateway. The architect,\nwho only rated the risk as low (2), was convinced during the risk storming consensus\nactivity that the risk was in fact high and needed mitigation.\nRisk Storming Examples \n| \n313\n", "page": 333, "type": "text", "section": "Page 333"}
{"text": "The participants all agreed that having separate API gateways for each type of user\n(admin, self-service/diagnostics, and nurses) would prevent calls from either the\nadmin web user interface or the self-service web user interface from ever reaching the\nmedical records exchange interface. The architect agreed, creating the final architec\u2010\nture, as illustrated in Figure 20-13.\nFigure 20-13. Final architecture modifications to address security risk\nThe prior scenario illustrates the power of risk storming. By collaborating with other\narchitects, developers, and key stakeholders on dimensions of risk that are vital to the\nsuccess of the system, risk areas are identified that would otherwise have gone unno\u2010\nticed. Compare figures Figure 20-9 and Figure 20-13 and notice the significant differ\u2010\nence in the architecture prior to risk storming and then after risk storming. Those\nsignificant changes address availability concerns, elasticity concerns, and security\nconcerns within the architecture.\nRisk storming is not a one-time process. Rather, it is a continuous process through\nthe life of any system to catch and mitigate risk areas before they happen in produc\u2010\ntion. How often the risk storming effort happens depends on many factors, including\nfrequency of change, architecture refactoring efforts, and the incremental develop\u2010\nment of the architecture. It is typical to undergo a risk storming effort on some par\u2010\nticular dimension after a major feature is added or at the end of every iteration.\n314 \n| \nChapter 20: Analyzing Architecture Risk\n", "page": 334, "type": "text", "section": "Page 334"}
{"text": "CHAPTER 21\nDiagramming and Presenting Architecture\nNewly minted architects often comment on how surprised they are at how varied the\njob is outside of technical knowledge and experience, which enabled their move into\nthe architect role to begin with. In particular, effective communication becomes criti\u2010\ncal to an architect\u2019s success. No matter how brilliant an architect\u2019s technical ideas, if\nthey can\u2019t convince managers to fund them and developers to build them, their brilli\u2010\nance will never manifest.\nDiagramming and presenting architectures are two critical soft skills for architects.\nWhile entire books exist about each topic, we\u2019ll hit some particular highlights for\neach.\nThese two topics appear together because they have a few similar characteristics: each\nforms an important visual representation of an architecture vision, presented using\ndifferent media. However, representational consistency is a concept that ties both\ntogether.\nWhen visually describing an architecture, the creator often must show different views\nof the architecture. For example, the architect will likely show an overview of the\nentire architecture topology, then drill into individual parts to delve into design\ndetails. However, if the architect shows a portion without indicating where it lies\nwithin the overall architecture, it confuses viewers. Representational consistency is the\npractice of always showing the relationship between parts of an architecture, either in\ndiagrams or presentations, before changing views.\nFor example, if an architect wanted to describe the details of how the plug-ins relate\nto one another in the Silicon Sandwiches solution, the architecture would show the\nentire topology, then drill into the plug-in structure, showing the viewers the rela\u2010\ntionship between them; an example of this appears in Figure 21-1.\n315\n", "page": 335, "type": "text", "section": "Page 335"}
{"text": "Figure 21-1. Using representational consistency to indicate context in a larger diagram\nCareful use of representational consistency ensures that viewers understand the scope\nof items being presented, eliminating a common source of confusion.\nDiagramming\nThe topology of architecture is always of interest to architects and developers because\nit captures how the structure fits together and forms a valuable shared understanding\nacross the team. Therefore, architects should hone their diagramming skills to razor\nsharpness.\nTools\nThe current generation of diagramming tools for architects is extremely powerful,\nand an architect should learn their tool of choice deeply. However, before going to a\nnice tool, don\u2019t neglect low-fidelity artifacts, especially early in the design process.\nBuilding very ephemeral design artifacts early prevents architects from becoming\noverly attached to what they have created, an anti-pattern we named the Irrational\nArtifact Attachment anti-pattern.\n316 \n| \nChapter 21: Diagramming and Presenting Architecture\n", "page": 336, "type": "text", "section": "Page 336"}
{"text": "Irrational Artifact Attachment\n\u2026is the proportional relationship between a person\u2019s irrational attachment to some\nartifact and how long it took to produce. If an architect creates a beautiful diagram\nusing some tool like Visio that takes two hours, they have an irrational attachment to\nthat artifact that\u2019s roughly proportional to the amount of time invested, which also\nmeans they will be more attached to a four-hour diagram than a two-hour one.\nOne of the benefits to the low-ritual approach used in Agile software development\nrevolves around creating just-in-time artifacts, with as little ceremony as possible\n(this helps explain the dedication of lots of agilists to index cards and sticky notes).\nUsing low-tech tools lets team members throw away what\u2019s not right, freeing them to\nexperiment and allow the true nature of the artifact emerge through revision, collabo\u2010\nration, and discussion.\nAn architect\u2019s favorite variation on the cell phone photo of a whiteboard (along with\nthe inevitable \u201cDo Not Erase!\u201d imperative) uses a tablet attached to an overhead pro\u2010\njector rather than a whiteboard. This offers several advantages. First, the tablet has an\nunlimited canvas and can fit as many drawings that a team might need. Second, it\nallows copy/paste \u201cwhat if\u201d scenarios that obscure the original when done on a white\u2010\nboard. Third, images captured on a tablet are already digitized and don\u2019t have the\ninevitable glare associated with cell phone photos of whiteboards.\nEventually, an architect needs to create nice diagrams in a fancy tool, but make sure\nthe team has iterated on the design sufficiently to invest time in capturing something.\nPowerful tools exist to create diagrams on every platform. While we don\u2019t necessarily\nadvocate one over another (we quite happily used OmniGraffle for all the diagrams in\nthis book), architects should look for at least this baseline of features:\nLayers\nDrawing tools often support layers, which architects should learn well. A layer\nallows the drawer to link a group of items together logically to enable hiding/\nshowing individual layers. Using layers, an architect can build a comprehensive\ndiagram but hide overwhelming details when they aren\u2019t necessary. Using layers\nalso allows architects to incrementally build pictures for presentations later (see\n\u201cIncremental Builds\u201d on page 322).\nStencils/templates\nStencils allow an architect to build up a library of common visual components,\noften composites of other basic shapes. For example, throughout this book, read\u2010\ners have seen standard pictures of things like microservices, which exist as a\nsingle item in the authors\u2019 stencil. Building a stencil for common patterns and\nDiagramming \n| \n317\n", "page": 337, "type": "text", "section": "Page 337"}
{"text": "artifacts within an organization creates consistency within architecture diagrams\nand allows the architect to build new diagrams quickly.\nMagnets\nMany drawing tools offer assistance when drawing lines between shapes. Mag\u2010\nnets represent the places on those shapes where lines snap to connect automati\u2010\ncally, providing automatic alignment and other visual niceties. Some tools allow\nthe architect to add more magnets or create their own to customize how the con\u2010\nnections look within their diagrams.\nIn addition to these specific helpful features, the tool should, of course, support lines,\ncolors, and other visual artifacts, as well as the ability to export in a wide variety of\nformats.\nDiagramming Standards: UML, C4, and ArchiMate\nSeveral formal standards exist for technical diagrams in software.\nUML\nUnified Modeling Language (UML) was a standard that unified three competing\ndesign philosophies that coexisted in the 1980s. It was supposed to be the best of all\nworlds but, like many things designed by committee, failed to create much impact\noutside organizations that mandated its use.\nArchitects and developers still use UML class and sequence diagrams to communi\u2010\ncate structure and workflow, but most of the other UML diagram types have fallen\ninto disuse.\nC4\nC4 is a diagramming technique developed by Simon Brown to address deficiencies in\nUML and modernize its approach. The four C\u2019s in C4 are as follows:\nContext\nRepresents the entire context of the system, including the roles of users and\nexternal dependencies.\nContainer\nThe physical (and often logical) deployment boundaries and containers within\nthe architecture. This view forms a good meeting point for operations and\narchitects.\nComponent\nThe component view of the system; this most neatly aligns with an architect\u2019s\nview of the system.\n318 \n| \nChapter 21: Diagramming and Presenting Architecture\n", "page": 338, "type": "text", "section": "Page 338"}
{"text": "Class\nC4 uses the same style of class diagrams from UML, which are effective, so there\nis no need to replace them.\nIf a company seeks to standardize on a diagramming technique, C4 offers a good\nalternative. However, like all technical diagramming tools, it suffers from an inability\nto express every kind of design an architecture might undertake. C4 is best suited for\nmonolithic architectures where the container and component relationships may dif\u2010\nfer, and it\u2019s less suited to distributed architectures, such as microservices.\nArchiMate\nArchiMate (an amalgam of Arch*itecture-Ani*mate) is an open source enterprise\narchitecture modeling language to support the description, analysis, and visualization\nof architecture within and across business domains. ArchiMate is a technical stan\u2010\ndard from The Open Group, and it offers a lighter-weight modeling language for\nenterprise ecosystems. The goal of ArchiMate is to be \u201cas small as possible,\u201d not to\ncover every edge case scenario. As such, it has become a popular choice among many\narchitects.\nDiagram Guidelines\nRegardless of whether an architect uses their own modeling language or one of the\nformal ones, they should build their own style when creating diagrams and should\nfeel free to borrow from representations they think are particularly effective. Here are\nsome general guidelines to use when creating technical diagrams.\nTitles\nMake sure all the elements of the diagram have titles or are well known to the audi\u2010\nence. Use rotation and other effects to make titles \u201csticky\u201d to the thing they associate\nwith and to make efficient use of space.\nLines\nLines should be thick enough to see well. If lines indicate information flow, then use\narrows to indicate directional or two-way traffic. Different types of arrowheads might\nsuggest different semantics, but architects should be consistent.\nGenerally, one of the few standards that exists in architecture diagrams is that solid\nlines tend to indicate synchronous communication and dotted lines indicate asyn\u2010\nchronous communication.\nDiagramming \n| \n319\n", "page": 339, "type": "text", "section": "Page 339"}
{"text": "Shapes\nWhile the formal modeling languages described all have standard shapes, no perva\u2010\nsive standard shapes exist across the software development world. Thus, each archi\u2010\ntect tends to make their own standard set of shapes, sometimes spreading those\nacross an organization to create a standard language.\nWe tend to use three-dimensional boxes to indicate deployable artifacts and rectan\u2010\ngles to indicate containership, but we don\u2019t have any particular key beyond that.\nLabels\nArchitects should label each item in a diagram, especially if there is any chance of\nambiguity for the readers.\nColor\nArchitects often don\u2019t use color enough\u2014for many years, books were out of necessity\nprinted in black and white, so architects and developers became accustomed to mon\u2010\nochrome drawings. While we still favor monochrome, we use color when it helps dis\u2010\ntinguish one artifact from another. For example, when discussing microservices\ncommunication strategies in \u201cCommunication\u201d on page 254, we used color to indi\u2010\ncate that two difference microservices participate in the coordination, not two instan\u2010\nces of the same service, as reproduced in Figure 21-2.\nFigure 21-2. Reproduction of microservices communication example showing different\nservices in unique colors\n320 \n| \nChapter 21: Diagramming and Presenting Architecture\n", "page": 340, "type": "text", "section": "Page 340"}
{"text": "Keys\nIf shapes are ambiguous for any reason, include a key on the diagram clearly indicat\u2010\ning what each shape represents. Nothing is worse than a diagram that leads to misin\u2010\nterpretation, which is worse than no diagram.\nPresenting\nThe other soft skill required by modern architects is the ability to conduct effective\npresentations using tools like PowerPoint and Keynote. These tools are the lingua\nfranca of modern organizations, and people throughout the organization expect com\u2010\npetent use of these tools. Unfortunately, unlike word processors and spreadsheets, no\none seems to spend much time studying how to use these tools well.\nNeal, one of the coauthors of this book, wrote a book several years ago entitled Pre\u2010\nsentation Patterns (Addison-Wesley Professional), about taking the patterns/anti-\npatterns approach common in the software world and applying it to technical\npresentations.\nPresentation Patterns makes an important observation about the fundamental differ\u2010\nence between creating a document versus a presentation to make a case for some\u2010\nthing\u2014time. In a presentation, the presenter controls how quickly an idea is\nunfolding, whereas the reader of a document controls that. Thus, one of the most\nimportant skills an architect can learn in their presentation tool of choice is how to\nmanipulate time.\nManipulating Time\nPresentation tools offer two ways to manipulate time on slides: transitions and ani\u2010\nmations. Transitions move from slide to slide, and animations allow the designer to\ncreate movement within a slide. Typically, presentation tools allow just one transition\nper slide but a host of animations for each element: build in (appearance), build out\n(disappearance), and actions (such as movement, scale, and other dynamic behavior).\nWhile tools offer a variety of splashy effects like dropping anvils, architects use transi\u2010\ntion and animations to hide the boundaries between slides. One common anti-\npattern called out in Presentation Patterns named Cookie-Cutter states that ideas\ndon\u2019t have a predetermined word count, and accordingly, designers shouldn\u2019t artifi\u2010\ncially pad content to make it appear to fill a slide. Similarly, many ideas are bigger\nthan a single slide. Using subtle combinations of transitions and animations such as\ndissolve allows presenters to hide individual slide boundaries, stitching together a set\nof slides to tell a single story. To indicate the end of a thought, presenters should use a\ndistinctly different transition (such as door or cube) to provide a visual clue that they\nare moving to a different topic.\nPresenting \n| \n321\n", "page": 341, "type": "text", "section": "Page 341"}
{"text": "Incremental Builds\nThe Presentation Patterns book calls out the Bullet-Riddled Corpse as a common anti-\npattern of corporate presentations, where every slide is essentially the speaker\u2019s notes,\nprojected for all to see. Most readers have the excruciating experience of watching a\nslide full of text appear during a presentation, then reading the entire thing (because\nno one can resist reading it all as soon as it appears), only to sit for the next 10\nminutes while the presenter slowly reads the bullets to the audience. No wonder so\nmany corporate presentations are dull!\nWhen presenting, the speaker has two information channels: verbal and visual. By\nplacing too much text on the slides and then saying essentially the same words, the\npresenter is overloading one information channel and starving the other. The better\nsolution to this problem is to use incremental builds for slides, building up (hopefully\ngraphical) information as needed rather than all at once.\nFor example, say that an architect creates a presentation explaining the problems\nusing feature branching and wants to talk about the negative consequences of keeping\nbranches alive too long. Consider the graphical slide shown in Figure 21-3.\nFigure 21-3. Bad version of a slide showing a negative anti-pattern\nIn Figure 21-3, if the presenter shows the entire slide right away, the audience can see\nthat something bad happens toward the end, but they have to wait for the exposition\nto get to that point.\nInstead, the architect should use the same image but obscure parts of it when show\u2010\ning the slide (using a borderless white box) and expose a portion at a time (by per\u2010\nforming a build out on the covering box), as shown in Figure 21-4.\n322 \n| \nChapter 21: Diagramming and Presenting Architecture\n", "page": 342, "type": "text", "section": "Page 342"}
{"text": "Figure 21-4. A better, incremental version that maintains suspense\nIn Figure 21-4, the presenter still has a fighting chance of keeping some suspense\nalive, making the talk inherently more interesting.\nUsing animations and transitions in conjunction with incremental builds allows the\npresenter to make more compelling, entertaining presentations.\nPresenting \n| \n323\n", "page": 343, "type": "text", "section": "Page 343"}
{"text": "Infodecks Versus Presentations\nSome architects build slide decks in tools like PowerPoint and Keynote but never\nactually present them. Rather, they are emailed around like a magazine article, and\neach individual reads them at their own pace. Infodecks are slide decks that are not\nmeant to be projected but rather summarize information graphically, essentially using\na presentation tool as a desktop publishing package.\nThe difference between these two media is comprehensiveness of content and use of\ntransitions and animations. If someone is going to flip through the deck like a maga\u2010\nzine article, the author of the slides does not need to add any time elements. The\nother key difference between infodecks and presentations is the amount of material.\nBecause infodecks are meant to be standalone, they contain all the information the\ncreator wants to convey. When doing a presentation, the slides are (purposefully)\nmeant to be half of the presentation, the other half being the person standing there\ntalking!\nSlides Are Half of the Story\nA common mistake that presenters make is building the entire content of the presen\u2010\ntation into the slides. However, if the slides are comprehensive, the presenter should\nspare everyone the time of sitting through a presentation and just email it to everyone\nas a deck! Presenters make the mistake of adding too much material to slides when\nthey can make important points more powerfully. Remember, presenters have two\ninformation channels, so using them strategically can add more punch to the mes\u2010\nsage. A great example of that is the strategic use of invisibility.\nInvisibility\nInvisibility is a simple pattern where the presenter inserts a blank black slide within a\npresentation to refocus attention solely on the speaker. If someone has two informa\u2010\ntion channels (slides and speaker) and turns one of them off (the slides), it automati\u2010\ncally adds more emphasis to the speaker. Thus, if a presenter wants to make a point,\ninsert a blank slide\u2014everyone in the room will focus their attention back on the\nspeaker because they are now the only interesting thing in the room to look at.\nLearning the basics of a presentation tool and a few techniques to make presentations\nbetter is a great addition to the skill set of architects. If an architect has a great idea\nbut can\u2019t figure out a way to present it effectively, they will never get a chance to real\u2010\nize that vision. Architecture requires collaboration; to get collaborators, architects\nmust convince people to sign on to their vision. The modern corporate soapboxes are\npresentation tools, so it\u2019s worth learning to use them well.\n324 \n| \nChapter 21: Diagramming and Presenting Architecture\n", "page": 344, "type": "text", "section": "Page 344"}
{"text": "CHAPTER 22\nMaking Teams Effective\nIn addition to creating a technical architecture and making architecture decisions, a\nsoftware architect is also responsible for guiding the development team through the\nimplementation of the architecture. Software architects who do this well create effec\u2010\ntive development teams that work closely together to solve problems and create win\u2010\nning solutions. While this may sound obvious, too many times we\u2019ve seen architects\nignore development teams and work in siloed environments to create an architecture.\nThis architecture then gets handed it off to a development team which then struggles\nto implement the architecture correctly. Being able to make teams productive is one\nof the ways effective and successful software architects differentiate themselves from\nother software architects. In this chapter we introduce some basic techniques an\narchitect can leverage to make development teams effective.\nTeam Boundaries\nIt\u2019s been our experience that a software architect can significantly influence the suc\u2010\ncess or failure of a development team. Teams that feel left out of the loop or estranged\nfrom software architects (and also the architecture) often do not have the right level\nof guidance and right level of knowledge about various constraints on the system, and\nconsequently do not implement the architecture correctly.\nOne of the roles of a software architect is to create and communicate the constraints,\nor the box, in which developers can implement the architecture. Architects can create\nboundaries that are too tight, too loose, or just right. These boundaries are illustrated\nin Figure 22-1. The impact of having too tight or too loose of a boundary has a direct\nimpact on the teams\u2019 ability to successfully implement the architecture.\n325\n", "page": 345, "type": "text", "section": "Page 345"}
{"text": "Figure 22-1. Boundary types created by a software architect\nArchitects that create too many constraints form a tight box around the development\nteams, preventing access to many of the tools, libraries, and practices that are\nrequired to implement the system effectively. This causes frustration within the team,\nusually resulting in developers leaving the project for happier and healthier\nenvironments.\nThe opposite can also happen. A software architect can create constraints that are too\nloose (or no constraints at all), leaving all of the important architecture decisions to\nthe development team. In this scenario, which is just as bad as tight constraints, the\nteam essentially takes on the role of a software architect, performing proof of con\u2010\ncepts and battling over design decisions without the proper level of guidance, result\u2010\ning in unproductiveness, confusion, and frustration.\nAn effective software architect strives to provide the right level of guidance and con\u2010\nstraints so that the team has the correct tools and libraries in place to effectively\nimplement the architecture. The rest of this chapter is devoted to how to create these\neffective boundaries.\nArchitect Personalities\nThere are three basic types of architect personalities: a control freak architect\n(Figure 22-2), an armchair architect (Figure 22-3), and an effective architect\n(Figure 22-5). Each personality matches a particular boundary type discussed in the\nprior section on team boundaries: control freak architects produce tight boundaries,\narmchair architects produce loose boundaries, and effective architects produce just\nthe right kinds of boundaries.\n326 \n| \nChapter 22: Making Teams Effective\n", "page": 346, "type": "text", "section": "Page 346"}
{"text": "Control Freak\nFigure 22-2. Control freak architect (iStockPhoto)\nThe control freak architect tries to control every detailed aspect of the software devel\u2010\nopment process. Every decision a control freak architect makes is usually too fine-\ngrained and too low-level, resulting in too many constraints on the development\nteam.\nControl freak architects produce the tight boundaries discussed in the prior section.\nA control freak architect might restrict the development team from downloading any\nuseful open source or third-party libraries and instead insist that the teams write\neverything from scratch using the language API. Control freak architects might also\nplace tight restrictions on naming conventions, class design, method length, and so\non. They might even go so far as to write pseudocode for the development teams.\nEssentially, control freak architects steal the art of programming away from the devel\u2010\nopers, resulting in frustration and a lack of respect for the architect.\nIt is very easy to become a control freak architect, particularly when transitioning\nfrom developer to architect. An architect\u2019s role is to create the building blocks of the\napplication (the components) and determine the interactions between those compo\u2010\nnents. The developer\u2019s role in this effort is to then take those components and deter\u2010\nmine how they will be implemented using class diagrams and design patterns.\nHowever, in the transition from developer to architect, it is all too tempting to want\nto create the class diagrams and design patterns as well since that was the newly min\u2010\nted architect\u2019s prior role.\nArchitect Personalities \n| \n327\n", "page": 347, "type": "text", "section": "Page 347"}
{"text": "For example, suppose an architect creates a component (building block of the archi\u2010\ntecture) to manage reference data within the system. Reference data consists of static\nname-value pair data used on the website, as well as things like product codes and\nwarehouse codes (static data used throughout the system). The architect\u2019s role is to\nidentify the component (in this case, Reference Manager), determine the core set of\noperations for that component (for example, GetData, SetData, ReloadCache,\nNotifyOnUpdate, and so on), and which components need to interact with the\nReference Manager. The control freak architect might think that the best way to\nimplement this component is through a parallel loader pattern leveraging an internal\ncache, with a particular data structure for that cache. While this might be an effective\ndesign, it\u2019s not the only design. More importantly, it\u2019s no longer the architect\u2019s role to\ncome up with this internal design for the Reference Manager\u2014it\u2019s the role of the\ndeveloper.\nAs we\u2019ll talk about in \u201cHow Much Control?\u201d on page 331, sometimes an architect\nneeds to play the role of a control freak, depending on the complexity of the project\nand the skill level on the team. However, in most cases a control freak architect dis\u2010\nrupts the development team, doesn\u2019t provide the right level of guidance, gets in the\nway, and is ineffective at leading the team through the implementation of the\narchitecture.\nArmchair Architect\nFigure 22-3. Armchair architect (iStockPhoto)\nThe armchair architect is the type of architect who hasn\u2019t coded in a very long time (if\nat all) and doesn\u2019t take the implementation details into account when creating an\narchitecture. They are typically disconnected from the development teams, never\n328 \n| \nChapter 22: Making Teams Effective\n", "page": 348, "type": "text", "section": "Page 348"}
{"text": "around, or simply move from project to project once the initial architecture diagrams\nare completed.\nIn some cases the armchair architect is simply in way over their head in terms of the\ntechnology or business domain and therefore cannot possibly lead or guide teams\nfrom a technical or business problem standpoint. For example, what do developers\ndo? Why, they code, of course. Writing program code is really hard to fake; either a\ndeveloper writes software code, or they don\u2019t. However, what does an architect do?\nNo one knows! Most architects draw lots of lines and boxes\u2014but how detailed should\nan architect be in those diagrams? Here\u2019s a dirty little secret about architecture\u2014it\u2019s\nreally easy to fake it as an architect!\nSuppose an armchair architect is in way over their head or doesn\u2019t have the time to\narchitect an appropriate solution for a stock trading system. In that case the architec\u2010\nture diagram might look like the one illustrated in Figure 22-4. There\u2019s nothing wrong\nwith this architecture\u2014it\u2019s just too high level to be of any use to anyone.\nFigure 22-4. Trading system architecture created by an armchair architect\nArmchair architects create loose boundaries around development teams, as discussed\nin the prior section. In this scenario, development teams end up taking on the role of\narchitect, essentially doing the work an architect is supposed to be doing. Team veloc\u2010\nity and productivity suffer as a result, and teams get confused about how the system\nshould work.\nLike the control freak architect, it is all too easy to become an armchair architect. The\nbiggest indicator that an architect might be falling into the armchair architect person\u2010\nality is not having enough time to spend with the development teams implementing\nthe architecture (or choosing not to spend time with the development teams). Devel\u2010\nArchitect Personalities \n| \n329\n", "page": 349, "type": "text", "section": "Page 349"}
{"text": "opment teams need an architect\u2019s support and guidance, and they need the architect\navailable for answering technical or business-related questions when they arise. Other\nindicators of an armchair architect are following:\n\u2022 Not fully understanding the business domain, business problem, or technology\nused\n\u2022 Not enough hands-on experience developing software\n\u2022 Not considering the implications associated with the implementation of the\narchitecture solution\nIn some cases it is not the intention of an architect to become an armchair architect,\nbut rather it just \u201chappens\u201d by being spread too thin between projects or development\nteams and loosing touch with technology or the business domain. An architect can\navoid this personality by getting more involved in the technology being used on the\nproject and understanding the business problem and business domain.\nEffective Architect\nFigure 22-5. Effective software architect (iStockPhoto)\nAn effective software architect produces the appropriate constraints and boundaries\non the team, ensuring that the team members are working well together and have the\nright level of guidance on the team. The effective architect also ensures that the team\nhas the correct and appropriate tools and technologies in place. In addition, they\nremove any roadblocks that may be in the way of the development teams reaching\ntheir goals.\n330 \n| \nChapter 22: Making Teams Effective\n", "page": 350, "type": "text", "section": "Page 350"}
{"text": "While this sounds obvious and easy, it is not. There is an art to becoming an effective\nleader on the development team. Becoming an effective software architect requires\nworking closely and collaborating with the team, and gaining the respect of the team\nas well. We\u2019ll be looking at other ways of becoming an effective software architect in\nlater chapters in this part of the book. But for now, we\u2019ll introduce some guidelines\nfor knowing how much control an effective architect should exert on a development\nteam.\nHow Much Control?\nBecoming an effective software architect is knowing how much control to exert on a\ngiven development team. This concept is known as Elastic Leadership and is widely\nevangelized by author and consultant Roy Osherove. We\u2019re going to deviate a bit from\nthe work Osherove has done in this area and focus on specific factors for software\narchitecture.\nKnowing how much an effective software architect should be a control freak and how\nmuch they should be an armchair architect involves five main factors. These factors\nalso determine how many teams (or projects) a software architect can manage at\nonce:\nTeam familiarity\nHow well do the team members know each other? Have they worked together\nbefore on a project? Generally, the better team members know each other, the\nless control is needed because team members start to become self-organizing.\nConversely, the newer the team members, the more control needed to help facili\u2010\ntate collaboration among team members and reduce cliques within the team.\nTeam size\nHow big is the team? (We consider more than 12 developers on the same team to\nbe a big team, and 4 or fewer to be a small team.) The larger the team, the more\ncontrol is needed. The smaller the team, less control is needed. This is discussed\nin more detail in \u201cTeam Warning Signs\u201d on page 335.\nOverall experience\nHow many team members are senior? How many are junior? Is it a mixed team\nof junior and senior developers? How well do they know the technology and\nbusiness domain? Teams with lots of junior developers require more control and\nmentoring, whereas teams with more senior developers require less control. In\nthe latter cases, the architect moves from the role of a mentor to that of a\nfacilitator.\nProject complexity\nIs the project highly complex or just a simple website? Highly complex projects\nrequire the architect to be more available to the team and to assist with issues\nHow Much Control? \n| \n331\n", "page": 351, "type": "text", "section": "Page 351"}
{"text": "that arise, hence more control is needed on the team. Relatively simple projects\nare straightforward and hence do not require much control.\nProject duration\nIs the project short (two months), long (two years), or average duration (six\nmonths)? The shorter the duration, the less control is needed; conversely, the\nlonger the project, the more control is needed.\nWhile most of the factors make sense with regard to more or less control, the project\nduration factor may not appear to make sense. As indicated in the prior list, the\nshorter the project duration, the less control is needed; the longer the project dura\u2010\ntion, the more control is needed. Intuitively this might seem reversed, but that is not\nthe case. Consider a quick two-month project. Two months is not a lot of time to\nqualify requirements, experiment, develop code, test every scenario, and release into\nproduction. In this case the architect should act more as an armchair architect, as the\ndevelopment team already has a keen sense of urgency. A control freak architect\nwould just get in the way and likely delay the project. Conversely, think of a project\nduration of two years. In this scenario the developers are relaxed, not thinking in\nterms of urgency, and likely planning vacations and taking long lunches. More con\u2010\ntrol is needed by the architect to ensure the project moves along in a timely fashion\nand that complex tasks are accomplished first.\nIt is typical within most projects that these factors are utilized to determine the level\nof control at the start of a project; but as the system continues to evolve, the level of\ncontrol changes. Therefore, we advise that these factors continually be analyzed\nthroughout the life cycle of a project to determine how much control to exert on the\ndevelopment team.\nTo illustrate how each of these factors can be used to determine the level of control an\narchitect should have on a team, assume a fixed scale of 20 points for each factor.\nMinus values point more toward being an armchair architect (less control and\ninvolvement), whereas plus values point more toward being a control freak architect\n(more control and involvement). This scale is illustrated in Figure 22-6.\n332 \n| \nChapter 22: Making Teams Effective\n", "page": 352, "type": "text", "section": "Page 352"}
{"text": "Figure 22-6. Scale for the amount of control\nApplying this sort of scaling is not exact, of course, but it does help in determining\nthe relative control to exert on a team. For example, consider the project scenario\nshown in Table 22-1 and Figure 22-7. As shown in the table, the factors point to\neither a control freak (+20) or an armchair architect (-20). These factors add up and\nto an accumulated score of -60, indicating that the architect should play more of an\narmchair architect role and not get in the team\u2019s way.\nTable 22-1. Scenario 1 example for amount of control\nFactor\nValue\nRating\nPersonality\nTeam familiarity\nNew team members\n+20\nControl freak\nTeam size\nSmall (4 members)\n-20\nArmchair architect\nOverall experience\nAll experienced\n-20\nArmchair architect\nProject complexity\nRelatively simple\n-20\nArmchair architect\nProject duration\n2 months\n-20\nArmchair architect\nAccumulated score\n-60\nArmchair architect\nHow Much Control? \n| \n333\n", "page": 353, "type": "text", "section": "Page 353"}
{"text": "Figure 22-7. Amount of control for scenario 1\nIn scenario 1, these factors are all taken into account to demonstrate that an effective\nsoftware architect should initially play the role of facilitator and not get too involved\nin the day-to-day interactions with the team. The architect will be needed for answer\u2010\ning questions and to make sure the team is on track, but for the most part the archi\u2010\ntect should be largely hands-off and let the experienced team do what they know best\n\u2014develop software quickly.\nConsider another type of scenario described in Table 22-2 and illustrated in\nFigure 22-8, where the team members know each other well, but the team is large (12\nteam members) and consists mostly of junior (inexperienced) developers. The project\nis relatively complex with a duration of six months. In this case, the accumulated\nscore comes out to -20, indicating that the effective architect should be involved in\nthe day-to-day activities within the team and take on a mentoring and coaching role,\nbut not so much as to disrupt the team.\nTable 22-2. Scenario 2 example for amount of control\nFactor\nValue\nRating\nPersonality\nTeam familiarity\nKnow each other well\n-20\nArmchair architect\nTeam size\nLarge (12 members)\n+20\nControl freak\nOverall experience\nMostly junior\n+20\nControl freak\nProject complexity\nHigh complexity\n+20\nControl freak\nProject duration\n6 months\n-20\nArmchair architect\nAccumulated score\n-20\nControl freak\n334 \n| \nChapter 22: Making Teams Effective\n", "page": 354, "type": "text", "section": "Page 354"}
{"text": "Figure 22-8. Amount of control for scenario 2\nIt is difficult to objectify these factors, as some of them (such as the overall team\nexperience) might be more weighted than others. In these cases the metrics can easily\nbe weighted or modified to suit any particular scenario or condition. Regardless, the\nprimary message here is that the amount of control and involvement a software\narchitect has on the team varies by these five main factors and that by taking these\nfactors into account, an architect can gauge what sort of control to exert on the team\nand what the box in which development teams can work in should look like (tight\nboundaries and constraints or loose ones).\nTeam Warning Signs\nAs indicated in the prior section, team size is one of the factors that influence the\namount of control an architect should exert on a development team. The larger a\nteam, the more control needed; the smaller the team, the less control needed. Three\nfactors come into play when considering the most effective development team size:\n\u2022 Process loss\n\u2022 Pluralistic ignorance\n\u2022 Diffusion of responsibility\nProcess loss, otherwise known as Brook\u2019s law, was originally coined by Fred Brooks in\nhis book The Mythical Man Month (Addison-Wesley). The basic idea of process loss is\nthat the more people you add to a project, the more time the project will take. As\nillustrated in Figure 22-9, the group potential is defined by the collective efforts of\neveryone on the team. However, with any team, the actual productivity will always be\nless than the group potential, the difference being the process loss of the team.\nTeam Warning Signs \n| \n335\n", "page": 355, "type": "text", "section": "Page 355"}
{"text": "Figure 22-9. Team size impacts actual productivity (Brook\u2019s law)\nAn effective software architect will observe the development team and look for pro\u2010\ncess loss. Process loss is a good factor in determining the correct team size for a par\u2010\nticular project or effort. One indication of process loss is frequent merge conflicts\nwhen pushing code to a repository. This is an indication that team members are pos\u2010\nsibly stepping on each other\u2019s toes and working on the same code. Looking for areas\nof parallelism within the team and having team members working on separate serv\u2010\nices or areas of the application is one way to avoid process loss. Anytime a new team\nmember comes on board a project, if there aren\u2019t areas for creating parallel work\nstreams, an effective architect will question the reason why a new team member was\nadded to the team and demonstrate to the project manager the negative impact that\nadditional person will have on the team.\nPluralistic ignorance also occurs as the team size gets too big. Pluralistic ignorance is\nwhen everyone agrees to (but privately rejects) a norm because they think they are\nmissing something obvious. For example, suppose on a large team the majority agree\nthat using messaging between two remote services is the best solution. However, one\nperson on the team thinks this is a silly idea because of a secure firewall between the\ntwo services. However, rather than speak up, that person also agrees to the use of\nmessaging (but privately rejects the idea) because they are afraid that they are either\nmissing something obvious or afraid they might be seen as a fool if they were to speak\nup. In this case, the person rejecting the norm was correct\u2014messaging would not\nwork because of a secure firewall between the two remote services. Had they spoken\nup (and had the team size been smaller), the original solution would have been chal\u2010\nlenged and another protocol (such as REST) used instead, which would be a better\nsolution in this case.\nThe concept of pluralistic ignorance was made famous by the Danish children\u2019s story\n\u201cThe Emperor\u2019s New Clothes\u201d, by Hans Christian Andersen. In the story, the king is\nconvinced that his new clothes are invisible to anyone unworthy to actually see them.\nHe struts around totally nude, asking all of his subjects how they like his new clothes.\nAll the subjects, afraid of being considered stupid or unworthy, respond to the king\n336 \n| \nChapter 22: Making Teams Effective\n", "page": 356, "type": "text", "section": "Page 356"}
{"text": "that his new clothes are the best thing ever. This folly continues until a child finally\ncalls out to the king that he isn\u2019t wearing any clothes at all.\nAn effective software architect should continually observe facial expressions and\nbody language during any sort of collaborative meeting or discussion and act as a\nfacilitator if they sense an occurrence of pluralistic ignorance. In this case, the effec\u2010\ntive architect might interrupt and ask the person what they think about the proposed\nsolution and be on their side and support them when they speak up.\nThe third factor that indicates appropriate team size is called diffusion of responsibil\u2010\nity. Diffusion of responsibility is based on the fact that as team size increases, it has a\nnegative impact on communication. Confusion about who is responsible for what on\nthe team and things getting dropped are good signs of a team that is too large.\nLook at the picture in Figure 22-10. What do you observe?\nFigure 22-10. Diffusion of responsibility\nThis picture shows someone standing next to a broken-down car on the side of a\nsmall country road. In this scenario, how many people might stop and ask the moto\u2010\nrist if everything is OK? Because it\u2019s a small road in a small community, probably\neveryone who passes by. However, how many times have motorists been stuck on the\nside of a busy highway in the middle of a large city and had thousands of cars simply\ndrive by without anyone stopping and asking if everything is OK? All the time. This\nis a good example of the diffusion of responsibility. As cities get busier and more\ncrowded, people assume the motorist has already called or help is on the way due to\nthe large number of people witnessing the event. However, in most of these cases help\nis not on the way, and the motorist is stuck with a dead or forgotten cell phone,\nunable to call for help.\nTeam Warning Signs \n| \n337\n", "page": 357, "type": "text", "section": "Page 357"}
{"text": "An effective architect not only helps guide the development team through the imple\u2010\nmentation of the architecture, but also ensures that the team is healthy, happy, and\nworking together to achieve a common goal. Looking for these three warning signs\nand consequently helping to correct them helps to ensure an effective development\nteam.\nLeveraging Checklists\nAirline pilots use checklists on every flight\u2014even the most experienced, seasoned\nveteran pilots. Pilots have checklists for takeoff, landing, and thousands of other sit\u2010\nuations, both common and unusual edge cases. They use checklists because one\nmissed aircraft setting (such as setting the flaps to 10 degrees) or procedure (such as\ngaining clearance into a terminal control area) can mean the difference between a\nsafe flight and a disastrous one.\nDr. Atul Gawande wrote an excellent book called The Checklist Manifesto (Picador), in\nwhich he describes the power of checklists for surgical procedures. Alarmed at the\nhigh rate of staph infections in hospitals, Dr. Gawande created surgical checklists to\nattempt to reduce this rate. In the book he demonstrates that staph infection rates in\nhospitals using the checklists went down to near zero, while staph infection rates in\ncontrol hospitals not using the checklists continued to rise.\nChecklists work. They provide an excellent vehicle for making sure everything is cov\u2010\nered and addressed. If checklists work so well, then why doesn\u2019t the software develop\u2010\nment industry leverage them? We firmly believe through personal experience that\nchecklists make a big difference in the effectiveness of development teams. However,\nthere are caveats to this claim. First, most software developers are not flying airliners\nor performing open heart surgery. In other words, software developers don\u2019t require\nchecklists for everything. The key to making teams effective is knowing when to lev\u2010\nerage checklists and when not to.\n338 \n| \nChapter 22: Making Teams Effective\n", "page": 358, "type": "text", "section": "Page 358"}
{"text": "Consider the checklist shown in Figure 22-11 for creating a new database table.\nFigure 22-11. Example of a bad checklist\nThis is not a checklist, but a set of procedural steps, and as such should not be in a\nchecklist. For example, the database table cannot be verified if the form has not yet\nbeen submitted! Any processes that have a procedural flow of dependent tasks should\nnot be in a checklist. Simple, well-known processes that are executed frequently\nwithout error also do not need a checklist.\nProcesses that are good candidates for checklists are those that don\u2019t have any proce\u2010\ndural order or dependent tasks, as well as those that tend to be error-prone or have\nsteps that are frequently missed or skipped. The key to making checklists effective is\nto not go overboard making everything a checklist. Architects find that checklists do,\nin fact, make development teams more effective, and as such start to make everything\na checklist, invoking what is known as the law of diminishing returns. The more\nchecklists an architect creates, the less chance developers will use them. Another key\nsuccess factor when creating checklists is to make them as small as possible while still\ncapturing all the necessary steps within a process. Developers generally will not fol\u2010\nlow checklists that are too big. Seek items that can be performed through automation\nand remove those from the checklist.\nDon\u2019t worry about stating the obvious in a checklist. It\u2019s the obvious\nstuff that\u2019s usually skipped or missed.\nThree key checklists that we\u2019ve found to be most effective are a developer code comple\u2010\ntion checklist, a unit and functional testing checklist, and a software release checklist.\nEach checklist is discussed in the following sections.\nLeveraging Checklists \n| \n339\n", "page": 359, "type": "text", "section": "Page 359"}
{"text": "The Hawthorne Effect\nOne of the issues associated with introducing checklists to a development team is\nmaking developers actually use them. It\u2019s all too common for some developers to run\nout of time and simply mark all the items in a particular checklist as completed\nwithout having actually performed the tasks.\nOne of the ways of addressing this issue is by talking with the team about the impor\u2010\ntance of using checklists and how checklists can make a difference in the team. Have\nteam members read The Checklist Manifesto by Atul Gawande to fully understand the\npower of a checklist, and make sure each team member understands the reasoning\nbehind each checklist and why it is being used. Having developers collaborate on\nwhat should and shouldn\u2019t be on a checklist also helps.\nWhen all else fails, architects can invoke what is known as the Hawthorne effect. The\nHawthorne effect essentially means that if people know they are being observed or\nmonitored, their behavior changes, and generally they will do the right thing. Exam\u2010\nples include highly visible cameras in and around buildings that actually don\u2019t work\nor aren\u2019t really recording anything (this is very common!) and website monitoring\nsoftware (how many of those reports are actually viewed?).\nThe Hawthorne effect can be used to govern the use of checklists as well. An architect\ncan let the team know that the use of checklists is critical to the team\u2019s effectiveness,\nand as a result, all checklists will be verified to make sure the task was actually per\u2010\nformed, when in fact the architect is only occasionally spot-checking the checklists\nfor correctness. By leveraging the Hawthorne effect, developers will be much less\nlikely to skip items or mark them as completed when in fact the task was not done.\nDeveloper Code Completion Checklist\nThe developer code completion checklist is an effective tool to use, particularly when\na software developer states that they are \u201cdone\u201d with the code. It also is useful for\ndefining what is known as the \u201cdefinition of done.\u201d If everything in the checklist is\ncompleted, then the developer can claim they are actually done with the code.\nHere are some of the things to include in a developer code completion checklist:\n\u2022 Coding and formatting standards not included in automated tools\n\u2022 Frequently overlooked items (such as absorbed exceptions)\n\u2022 Project-specific standards\n\u2022 Special team instructions or procedures\n340 \n| \nChapter 22: Making Teams Effective\n", "page": 360, "type": "text", "section": "Page 360"}
{"text": "Figure 22-12 illustrates an example of a developer code completion checklist.\nFigure 22-12. Example of a developer code completion checklist\nNotice the obvious tasks \u201cRun code cleanup and code formatting\u201d and \u201cMake sure\nthere are no absorbed exceptions\u201d in the checklist. How may times has a developer\nbeen in a hurry either at the end of the day or at the end of an iteration and forgotten\nto run code cleanup and formatting from the IDE? Plenty of times. In The Checklist\nManifesto, Gawande found this same phenomenon with respect to surgical proce\u2010\ndures\u2014the obvious ones were often the ones that were usually missed.\nNotice also the project-specific tasks in items 2, 3, 6, and 7. While these are good\nitems to have in a checklist, an architect should always review the checklist to see if\nany items can be automated or written as plug-in for a code validation checker. For\nexample, while \u201cInclude @ServiceEntrypoint on service API class\u201d might not be able\nto have an automated check, the \u201cVerify that only public methods are calling setFai\u2010\nlure()\u201d certainly can (this is a straightforward automated check with any sort of code\ncrawling tool). Checking for areas of automation helps reduce both the size and the\nnoise within a checklist, making it more effective.\nUnit and Functional Testing Checklist\nPerhaps one of the most effective checklists is a unit and functional testing checklist.\nThis checklist contains some of the more unusual and edge-case tests that software\ndevelopers tend to forget to test. Whenever someone from QA finds an issue with the\ncode based on a particular test case, that test case should be added to this checklist.\nThis particular checklist is usually one of the largest ones due to all the types of tests\nthat can be run against code. The purpose of this checklist is to ensure the most com\u2010\nplete coding possible so that when the developer is done with the checklist, the code\nis essentially production ready.\nLeveraging Checklists \n| \n341\n", "page": 361, "type": "text", "section": "Page 361"}
{"text": "Here are some of the items found in a typical unit and functional testing checklist:\n\u2022 Special characters in text and numeric fields\n\u2022 Minimum and maximum value ranges\n\u2022 Unusual and extreme test cases\n\u2022 Missing fields\nLike the developer code completion checklist, any items that can be written as auto\u2010\nmated tests should be removed from the checklist. For example, suppose there is an\nitem in the checklist for a stock trading application to test for negative shares (such as\na BUY for \u20131,000 shares of Apple [AAPL]). If this check is automated through a unit\nor functional test within the test suite, then the item should be removed from the\nchecklist.\nDevelopers sometimes don\u2019t know where to start when writing unit tests or how\nmany unit tests to write. This checklist provides a way of making sure general or spe\u2010\ncific test scenarios are included in the process of developing the software. This check\u2010\nlist is also effective in bridging the gap between developers and testers in\nenvironments that have these activities performed by separate teams. The more\ndevelopment teams perform complete testing, the easier the job of the testing teams,\nallowing the testing teams to focus on certain business scenarios not covered in the\nchecklists.\nSoftware Release Checklist\nReleasing software into production is perhaps one of the most error-prone aspects of\nthe software development life cycle, and as such makes for a great checklist. This\nchecklist helps avoid failed builds and failed deployments, and it significantly reduces\nthe amount of risk associated with releasing software.\nThe software release checklist is usually the most volatile of the checklists in that it\ncontinually changes to address new errors and circumstances each time a deployment\nfails or has issues.\nHere are some of the items typically included within the software release checklist:\n\u2022 Configuration changes in servers or external configuration servers\n\u2022 Third-party libraries added to the project (JAR, DLL, etc.)\n\u2022 Database updates and corresponding database migration scripts\n342 \n| \nChapter 22: Making Teams Effective\n", "page": 362, "type": "text", "section": "Page 362"}
{"text": "Anytime a build or deployment fails, the architect should analyze the root cause of\nthe failure and add a corresponding entry to the software release checklist. This way\nthe item will be verified on the next build or deployment, preventing that issue from\nhappening again.\nProviding Guidance\nA software architect can also make teams effective by providing guidance through the\nuse of design principles. This also helps form the box (constraints), as described in\nthe first section of this chapter, that developers can work in to implement the archi\u2010\ntecture. Effectively communicating these design principles is one of the keys to creat\u2010\ning a successful team.\nTo illustrate this point, consider providing guidance to a development team regarding\nthe use of what is typically called the layered stack\u2014the collection of third-party libra\u2010\nries (such as JAR files, and DLLs) that make up the application. Development teams\nusually have lots of questions regarding the layered stack, including whether they can\nmake their own decisions about various libraries, which ones are OK, and which ones\nare not.\nUsing this example, an effective software architect can provide guidance to the devel\u2010\nopment team by first having the developer answer the following questions:\n1. Are there any overlaps between the proposed library and existing functionality\nwithin the system?\n2. What is the justification for the proposed library?\nThe first question guides developers to looking at the existing libraries to see if the\nfunctionality provided by the new library can be satisfied through an existing library\nor existing functionality. It has been our experience that developers sometimes ignore\nthis activity, creating lots of duplicate functionality, particularly in large projects with\nlarge teams.\nThe second question prompts the developer into questioning why the new library or\nfunctionality is truly needed. Here, an effective software architect will ask for both a\ntechnical justification as well as a business justification as to why the additional\nlibrary is needed. This can be a powerful technique to create awareness within the\ndevelopment team of the need for business justifications.\nProviding Guidance \n| \n343\n", "page": 363, "type": "text", "section": "Page 363"}
{"text": "The Impact of Business Justifications\nOne of your authors (Mark) was the lead architect on a particularly complex Java-\nbased project with a large development team. One of the team members was particu\u2010\nlarly obsessed with the Scala programming language and desperately wanted to use it\non the project. This desire for the use of Scala ended up becoming so disruptive that\nseveral key team members informed Mark that they were planning on leaving the\nproject and moving on to other, \u201cless toxic,\u201d environments. Mark convinced the two\nkey team members to hold off on their decision for a bit and had a discussion with\nthe Scala enthusiast. Mark told the Scala enthusiast that he would support the use of\nScala within the project, but the Scala enthusiast would have to provide a business\njustification for the use of Scala because of the training costs and rewriting effort\ninvolved. The Scala enthusiast was ecstatic and said he would get right on it, and he\nleft the meeting yelling, \u201cThank you\u2014you\u2019re the best!\u201d\nThe next day the Scala enthusiast came into the office completely transformed. He\nimmediately approached Mark and asked to speak with him. They both went into the\nconference room, and the Scala enthusiast immediately (and humbly) said, \u201cThank\nyou.\u201d The Scala enthusiast explained to Mark that he could come up with all the tech\u2010\nnical reasons in the world to use Scala, but none of those technical advantages had\nany sort of business value in terms of the architecture characteristics needed\n(\u201c-ilities\u201d): cost, budget, and timeline. In fact, the Scala enthusiast realized that the\nincrease in cost, budget, and timeline would provide no benefit whatsoever.\nRealizing what a disruption he was, the Scala enthusiast quickly transformed himself\ninto one of the best and most helpful members on the team, all because of being asked\nto provide a business justification for something he wanted on the project. This\nincreased awareness of justifications not only made him a better software developer,\nbut also made for a stronger and healthier team.\nAs a postscript, the two key developers stayed on the project until the very end.\nContinuing with the example of governing the layered stack, another effective techni\u2010\nque of communicating design principles is through graphical explanations about\nwhat the development team can make decisions on and what they can\u2019t. The illustra\u2010\ntion in Figure 22-13 is an example of what this graphic (as well as the guidance)\nmight look like for controlling the layered stack.\n344 \n| \nChapter 22: Making Teams Effective\n", "page": 364, "type": "text", "section": "Page 364"}
{"text": "Figure 22-13. Providing guidance for the layered stack\nIn Figure 22-13, an architect would provide examples of what each category of the\nthird-party library would contain and then what the guidance is (the design princi\u2010\nple) in terms of what the developers can and can\u2019t do (the box described in the first\nsection of the chapter). For example, here are the three categories defined for any\nthird-party library:\nSpecial purpose\nThese are specific libraries used for things like PDF rendering, bar code scan\u2010\nning, and circumstances that do not warrant writing custom software.\nGeneral purpose\nThese libraries are wrappers on top of the language API, and they include things\nlike Apache Commons, and Guava for Java.\nFramework\nThese libraries are used for things like persistence (such as Hibernate) and inver\u2010\nsion of control (such as Spring). In other words, these libraries make up an entire\nlayer or structure of the application and are highly invasive.\nOnce categorized (the preceding categories are only an example\u2014there can be many\nmore defined), the architect then creates the box around this design principle. Notice\nin the example illustrated in Figure 22-13 that for this particular application or\nproject, the architect has specified that for special-purpose libraries, the developer\nProviding Guidance \n| \n345\n", "page": 365, "type": "text", "section": "Page 365"}
{"text": "can make the decision and does not need to consult the architect for that library.\nHowever, notice that for general purpose, the architect has indicated that the devel\u2010\noper can undergo overlap analysis and justification to make the recommendation, but\nthat category of library requires architect approval. Finally, for framework libraries,\nthat is an architect decision\u2014in other words, the development teams shouldn\u2019t even\nundergo analysis for these types of libraries; the architect has decided to take on that\nresponsibility for those types of libraries.\nSummary\nMaking development teams effective is hard work. It requires lots of experience and\npractice, as well as strong people skills (which we will discuss in subsequent chapters\nin this book). That said, the simple techniques described in this chapter about elastic\nleadership, leveraging checklists, and providing guidance through effectively commu\u2010\nnicating design principles do, in fact, work, and have proven effective in making\ndevelopment teams work smarter and more effectively.\nOne might question the role of an architect for such activities, instead assigning the\neffort of making teams effective to the development manager or project manager. We\nstrongly disagree with this premise. A software architect not only provides technical\nguidance to the team, but also leads the team through the implementation of the\narchitecture. The close collaborative relationship between a software architect and a\ndevelopment team allows the architect to observe the team dynamics and hence facil\u2010\nitate changes to make the team more effective. This is exactly what differentiates a\ntechnical architect from an effective software architect.\n346 \n| \nChapter 22: Making Teams Effective\n", "page": 366, "type": "text", "section": "Page 366"}
{"text": "CHAPTER 23\nNegotiation and Leadership Skills\nNegotiation and leadership skills are hard skills to obtain. It takes many years of\nlearning, practice, and \u201clessons learned\u201d experiences to gain the necessary skills to\nbecome an effective software architect. Knowing that this book cannot make an\narchitect an expert in negotiation and leadership overnight, the techniques intro\u2010\nduced in this chapter provide a good starting point for gaining these important skills.\nNegotiation and Facilitation\nIn the beginning of this book, we listed the core expectations of an architect, the last\nbeing the expectation that a software architect must understand the political climate\nof the enterprise and be able to navigate the politics. The reason for this key expecta\u2010\ntion is that almost every decision a software architect makes will be challenged. Deci\u2010\nsions will be challenged by developers who think they know more than the architect\nand hence have a better approach. Decisions will be challenged by other architects\nwithin the organization who think they have a better idea or way of approaching the\nproblem. Finally, decisions will be challenged by stakeholders who will argue that the\ndecision is too expensive or will take too much time.\nConsider the decision of an architect to use database clustering and federation (using\nseparate physical domain-scoped database instances) to mitigate risk with regard to\noverall availability within a system. While this is a sound solution to the issue of data\u2010\nbase availability, it is also a costly decision. In this example, the architect must negoti\u2010\nate with key business stakeholders (those paying for the system) to come to an\nagreement about the trade-off between availability and cost.\nNegotiation is one of the most important skills a software architect can have. Effective\nsoftware architects understand the politics of the organization, have strong\n347\n", "page": 367, "type": "text", "section": "Page 367"}
{"text": "negotiation and facilitation skills, and can overcome disagreements when they occur\nto create solutions that all stakeholders agree on.\nNegotiating with Business Stakeholders\nConsider the following real-world scenario (scenario 1) involving a key business\nstakeholder and lead architect:\nScenario 1\nThe senior vice president project sponsor is insistent that the new trading system\nmust support five nines of availability (99.999%). However, the lead architect is\nconvinced, based on research, calculations, and knowledge of the business\ndomain and technology, that three nines of availability (99.9%) would be suffi\u2010\ncient. The problem is, the project sponsor does not like to be wrong or corrected\nand really hates people who are condescending. The sponsor isn\u2019t overly techni\u2010\ncal (but thinks they are) and as a result tends to get involved in the nonfunctional\naspects of projects. The architect must convince the project sponsor through\nnegotiation that three nines (99.9%) of availability would be enough.\nIn this sort of negotiation, the software architect must be careful to not be too egotis\u2010\ntical and forceful in their analysis, but also make sure they are not missing anything\nthat might prove them wrong during the negotiation. There are several key negotia\u2010\ntion techniques an architect can use to help with this sort of stakeholder negotiation.\nLeverage the use of grammar and buzzwords to better understand\nthe situation.\nPhrases such as \u201cwe must have zero downtime\u201d and \u201cI needed those features yester\u2010\nday\u201d are generally meaningless but nevertheless provide valuable information to the\narchitect about to enter into a negotiation. For example, when the project sponsor is\nasked when a particular feature is needed and responds, \u201cI needed it yesterday,\u201d that is\nan indication to the software architect that time to market is important to that stake\u2010\nholder. Similarly, the phrase \u201cthis system must be lightning fast\u201d means performance\nis a big concern. The phase \u201czero downtime\u201d means that availability is critical in the\napplication. An effective software architect will leverage this sort of nonsense gram\u2010\nmar to better understand the real concerns and consequently leverage that use of\ngrammar during a negotiation.\nConsider scenario 1 described previously. Here, the key project sponsor wants five\nnines of availability. Leveraging this technique tells the architect that availability is\nvery important. This leads to a second negotiation technique:\n348 \n| \nChapter 23: Negotiation and Leadership Skills\n", "page": 368, "type": "text", "section": "Page 368"}
{"text": "Gather as much information as possible before entering into a\nnegotiation.\nThe phrase \u201cfive nines\u201d is grammar that indicates high availability. However, what\nexactly is five nines of availability? Researching this ahead of time and gathering\nknowledge prior to the negotiation yields the information shown in Table 23-1.\nTable 23-1. Nines of availability\nPercentage uptime\nDowntime per year (per\nday)\n90.0% (one nine)\n36 days 12 hrs (2.4 hrs)\n99.0% (two nines)\n87 hrs 46 min (14 min)\n99.9% (three nines)\n8 hrs 46 min (86 sec)\n99.99% (four nines)\n52 min 33 sec (7 sec)\n99.999% (five nines)\n5 min 35 sec (1 sec)\n99.9999% (six nines)\n31.5 sec (86 ms)\n\u201cFive nines\u201d of availability is 5 minutes and 35 seconds of downtime per year, or 1\nsecond a day of unplanned downtime. Quite ambitious, but also quite costly and\nunnecessary for the prior example. Putting things in hours and minutes (or in this\ncase, seconds) is a much better way to have the conversation than sticking with the\nnines vernacular.\nNegotiating scenario 1 would include validating the stakeholder\u2019s concerns (\u201cI under\u2010\nstand that availability is very important for this system\u201d) and then bringing the nego\u2010\ntiation from the nines vernacular to one of reasonable hours and minutes of\nunplanned downtime. Three nines (which the architect deemed good enough) aver\u2010\nages 86 seconds of unplanned downtime per day\u2014certainly a reasonable number\ngiven the context of the global trading system described in the scenario. The architect\ncan always resort to this tip:\nWhen all else fails, state things in terms of cost and time.\nWe recommend saving this negotiation tactic for last. We\u2019ve seen too many negotia\u2010\ntions start off on the wrong foot due to opening statements such as, \u201cThat\u2019s going to\ncost a lot of money\u201d or \u201cWe don\u2019t have time for that.\u201d Money and time (effort\nNegotiation and Facilitation \n| \n349\n", "page": 369, "type": "text", "section": "Page 369"}
{"text": "involved) are certainly key factors in any negotiation but should be used as a last\nresort so that other justifications and rationalizations that matter more be tried first.\nOnce an agreement is reached, then cost and time can be considered if they are\nimportant attributes to the negotiation.\nAnother important negotiation technique to always remember is the following, par\u2010\nticularly in situations as described in scenario 1:\nLeverage the \u201cdivide and conquer\u201d rule to qualify demands or\nrequirements.\nThe ancient Chinese warrior Sun Tzu wrote in The Art of War, \u201cIf his forces are uni\u2010\nted, separate them.\u201d This same divide-and-conquer tactic can be applied by an archi\u2010\ntect during negotiations as well. Consider scenario 1 previously described. In this\ncase, the project sponsor is insisting on five nines (99.999%) of availability for the\nnew trading system. However, does the entire system need five nines of availability?\nQualifying the requirement to the specific area of the system actually requiring five\nnines of availability reduces the scope of difficult (and costly) requirements and the\nscope of the negotiation as well.\nNegotiating with Other Architects\nConsider the following actual scenario (scenario 2) between a lead architect and\nanother architect on the same project:\nScenario 2\nThe lead architect on a project believes that asynchronous messaging would be\nthe right approach for communication between a group of services to increase\nboth performance and scalability. However, the other architect on the project\nonce again strongly disagrees and insists that REST would be a better choice,\nbecause REST is always faster than messaging and can scale just as well (\u201csee for\nyourself by Googling it!\u201d). This is not the first heated debate between the two\narchitects, nor will it be the last. The lead architect must convince the other\narchitect that messaging is the right solution.\nIn this scenario, the lead architect can certainly tell the other architect that their opin\u2010\nion doesn\u2019t matter and ignore it based on the lead architect\u2019s seniority on the project.\nHowever, this will only lead to further animosity between the two architects and cre\u2010\nate an unhealthy and noncollaborative relationship, and consequently will end up\nhaving a negative impact on the development team. The following technique will help\nin these types of situations:\n350 \n| \nChapter 23: Negotiation and Leadership Skills\n", "page": 370, "type": "text", "section": "Page 370"}
{"text": "Always remember that demonstration defeats discussion.\nRather than arguing with another architect over the use of REST versus messaging,\nthe lead architect should demonstrate to the other architect how messaging would be\na better choice in their specific environment. Every environment is different, which is\nwhy simply Googling it will never yield the correct answer. By running a comparison\nbetween the two options in a production-like environment and showing the other\narchitect the results, the argument would likely be avoided.\nAnother key negotiation technique that works in these situations is as follows:\nAvoid being too argumentative or letting things get too personal in\na negotiation\u2014calm leadership combined with clear and concise\nreasoning will always win a negotiation.\nThis technique is a very powerful tool when dealing with adversarial relationships\nlike the one described in scenario 2. Once things get too personal or argumentative,\nthe best thing to do is stop the negotiation and reengage at a later time when both\nparties have calmed down. Arguments will happen between architects; however,\napproaching these situations with calm leadership will usually force the other person\nto back down when things get too heated.\nNegotiating with Developers\nEffective software architects don\u2019t leverage their title as architect to tell developers\nwhat to do. Rather, they work with development teams to gain respect so that when a\nrequest is made of the development team, it doesn\u2019t end up in an argument or resent\u2010\nment. Working with development teams can be difficult at times. In many cases\ndevelopment teams feel disconnected from the architecture (and also the architect),\nand as a result feel left out of the loop with regard to decisions the architect makes.\nThis is a classic example of the Ivory Tower architecture anti-pattern. Ivory tower\narchitects are ones who simply dictate from on high, telling development teams what\nto do without regard to their opinion or concerns. This usually leads to a loss of\nrespect for the architect and an eventual breakdown of the team dynamics. One nego\u2010\ntiation technique that can help address this situation is to always provide a\njustification:\nNegotiation and Facilitation \n| \n351\n", "page": 371, "type": "text", "section": "Page 371"}
{"text": "When convincing developers to adopt an architecture decision or\nto do a specific task, provide a justification rather than \u201cdictating\nfrom on high.\u201d\nBy providing a reason why something needs to be done, developers will more likely\nagree with the request. For example, consider the following conversation between an\narchitect and a developer with regard to making a simple query within a traditional\nn-tiered layered architecture:\nArchitect: \u201cYou must go through the business layer to make that call.\u201d\nDeveloper: \u201cNo. It\u2019s much faster just to call the database directly.\u201d\nThere are several things wrong with this conversation. First, notice the use of the\nwords \u201cyou must.\u201d This type of commanding voice is not only demeaning, but is one\nof the worst ways to begin a negotiation or conversation. Also notice that the devel\u2010\noper responded to the architect\u2019s demand with a reason to counter the demand\n(going through the business layer will be slower and take more time). Now consider\nan alternative approach to this demand:\nArchitect: \u201cSince change control is most important to us, we have formed a closed-\nlayered architecture. This means all calls to the database need to come from the busi\u2010\nness layer.\u201d\nDeveloper: \u201cOK, I get it, but in that case, how am I going to deal with the performance\nissues for simple queries?\u201d\nNotice here the architect is providing the justification for the demand that all requests\nneed to go through the business layer of the application. Providing the justification or\nreason first is always a good approach. Most of the time, once a person hears some\u2010\nthing they disagree with, they stop listening. By stating the reason first, the architect\nis sure that the justification will be heard. Also notice the architect removed the per\u2010\nsonal nature of this demand. By not saying \u201cyou must\u201d or \u201cyou need to,\u201d the architect\neffectively turned the demand into a simple statement of fact (\u201cthis means\u2026\u201d). Now\ntake a look at the developer\u2019s response. Notice the conversation shifted from disagree\u2010\ning with the layered architecture restrictions to a question about increasing perfor\u2010\nmance for simple calls. Now the architect and developer can engage in a collaborative\nconversation to find ways to make simple queries faster while still preserving the\nclosed layers in the architecture.\nAnother effective negotiation tactic when negotiating with a developer or trying to\nconvince them to accept a particular design or architecture decision they disagree\nwith is to have the developer arrive at the solution on their own. This creates a win-\nwin situation where the architect cannot lose. For example, suppose an architect is\nchoosing between two frameworks, Framework X and Framework Y. The architect\nsees that Framework Y doesn\u2019t satisfy the security requirements for the system and so\nnaturally chooses Framework X. A developer on the team strongly disagrees and\n352 \n| \nChapter 23: Negotiation and Leadership Skills\n", "page": 372, "type": "text", "section": "Page 372"}
{"text": "insists that Framework Y would still be the better choice. Rather than argue the mat\u2010\nter, the architect tells the developer that the team will use Framework Y if the devel\u2010\noper can show how to address the security requirements if Framework Y is used. One\nof two things will happen:\n1. The developer will fail trying to demonstrate that Framework Y will satisfy the\nsecurity requirements and will understand firsthand that the framework cannot\nbe used. By having the developer arrive at the solution on their own, the architect\nautomatically gets buy-in and agreement for the decision to use Framework X by\nessentially making it the developer\u2019s decision. This is a win.\n2. The developer finds a way to address the security requirements with Framework\nY and demonstrates this to the architect. This is a win as well. In this case the\narchitect missed something in Framework Y, and it also ended up being a better\nframework over the other one.\nIf a developer disagrees with a decision, have them arrive at the sol\u2010\nution on their own.\nIt\u2019s really through collaboration with the development team that the architect is able\nto gain the respect of the team and form better solutions. The more developers\nrespect an architect, the easier it will be for the architect to negotiate with those\ndevelopers.\nThe Software Architect as a Leader\nA software architect is also a leader, one who can guide a development team through\nthe implementation of the architecture. We maintain that about 50% of being an\neffective software architect is having good people skills, facilitation skills, and leader\u2010\nship skills. In this section we discuss several key leadership techniques that an effec\u2010\ntive software architect can leverage to lead development teams.\nThe 4 C\u2019s of Architecture\nEach day things seem to be getting more and more complex, whether it be increased\ncomplexity in business processes or increased complexity of systems and even archi\u2010\ntecture. Complexity exists within architecture as well as software development, and\nalways will. Some architectures are very complex, such as ones supporting six nines\nof availability (99.9999%)\u2014that\u2019s equivalent to unplanned downtime of about 86\nThe Software Architect as a Leader \n| \n353\n", "page": 373, "type": "text", "section": "Page 373"}
{"text": "milliseconds a day, or 31.5 seconds of downtime per year. This sort of complexity is\nknown as essential complexity\u2014in other words, \u201cwe have a hard problem.\u201d\nOne of the traps many architects fall into is adding unnecessary complexity to solu\u2010\ntions, diagrams, and documentation. Architects (as well as developers) seem to love\ncomplexity. To quote Neal:\nDevelopers are drawn to complexity like moths to a flame\u2014frequently with the same\nresult.\nConsider the diagram in Figure 23-1 illustrating the major information flows for the\nbackend processing systems at a very large global bank. Is this necessarily complex?\nNo one knows the answer to this question because the architect has made it complex. \nThis sort of complexity is called accidental complexity\u2014in other words, \u201cwe have\nmade a problem hard.\u201d Architects sometimes do this to prove their worth when\nthings seem too simple or to guarantee that they are always kept in the loop on dis\u2010\ncussions and decisions that are made regarding the business or architecture. Other\narchitects do this to maintain job security. Whatever the reason, introducing acciden\u2010\ntal complexity into something that is not complex is one of the best ways to become\nan ineffective leader as an architect.\nFigure 23-1. Introducing accidental complexity into a problem\n354 \n| \nChapter 23: Negotiation and Leadership Skills\n", "page": 374, "type": "text", "section": "Page 374"}
{"text": "An effective way of avoiding accidental complexity is what we call the 4 C\u2019s of archi\u2010\ntecture: communication, collaboration, clarity, and conciseness. These factors (illustra\u2010\nted in Figure 23-2) all work together to create an effective communicator and\ncollaborator on the team.\nFigure 23-2. The 4 C\u2019s of architecture\nAs a leader, facilitator, and negotiator, is it vital that a software architect be able to\neffectively communicate in a clear and concise manner. It is equally important that an\narchitect also be able to collaborate with developers, business stakeholders, and other\narchitects to discuss and form solutions together. Focusing on the 4 C\u2019s of architec\u2010\nture helps an architect gain the respect of the team and become the go-to person on\nthe project that everyone comes to not only for questions, but also for advice, men\u2010\ntoring, coaching, and leadership.\nBe Pragmatic, Yet Visionary\nAn effective software architect must be pragmatic, yet visionary. Doing this is not as\neasy as it sounds and takes a fairly high level of maturity and significant practice to\naccomplish. To better understand this statement, consider the definition of a\nvisionary:\nVisionary\nThinking about or planning the future with imagination or wisdom.\nBeing a visionary means applying strategic thinking to a problem, which is exactly\nwhat an architect is supposed to do. Architecture is about planning for the future and\nmaking sure the architectural vitality (how valid an architecture is) remains that way\nfor a long time. However, too many times, architects become too theoretical in their\nplanning and designs, creating solutions that become too difficult to understand or\neven implement. Now consider the definition of being pragmatic:\nPragmatic\nDealing with things sensibly and realistically in a way that is based on practical\nrather than theoretical considerations.\nThe Software Architect as a Leader \n| \n355\n", "page": 375, "type": "text", "section": "Page 375"}
{"text": "While architects need to be visionaries, they also need to apply practical and realistic\nsolutions. Being pragmatic is taking all of the following factors and constraints into\naccount when creating an architectural solution:\n\u2022 Budget constraints and other cost-based factors\n\u2022 Time constraints and other time-based factors\n\u2022 Skill set and skill level of the development team\n\u2022 Trade-offs and implications associated with an architecture decision\n\u2022 Technical limitations of a proposed architectural design or solution\nA good software architect is one that strives to find an appropriate balance between\nbeing pragmatic while still applying imagination and wisdom to solving problems\n(see Figure 23-3). For example, consider the situation where an architect is faced with\na difficult problem dealing with elasticity (unknown sudden and significant increases\nin concurrent user load). A visionary might come up with an elaborate way to deal\nwith this through the use of a complex data mesh, which is a collection of distributed,\ndomain-based databases. In theory this might be a good approach, but being prag\u2010\nmatic means applying reason and practicality to the solution. For example, has the\ncompany ever used a data mesh before? What are the trade-offs of using a data mesh?\nWould this really solve the problem?\nFigure 23-3. Good architects find the balance between being pragmatic, yet visionary\nMaintaining a good balance between being pragmatic, yet visionary, is an excellent\nway of gaining respect as an architect. Business stakeholders will appreciate visionary\nsolutions that fit within a set of constraints, and developers will appreciate having a\npractical (rather then theoretical) solution to implement.\nA pragmatic architect would first look at what the limiting factor is when needing\nhigh levels of elasticity. Is it the database that\u2019s the bottleneck? Maybe it\u2019s a bottleneck\nwith respect to some of the services invoked or other external sources needed. Find\u2010\ning and isolating the bottleneck would be a first practical approach to the problem. In\n356 \n| \nChapter 23: Negotiation and Leadership Skills\n", "page": 376, "type": "text", "section": "Page 376"}
{"text": "fact, even if it is the database, could some of the data needed be cached so that the\ndatabase need not be accessed at all?\nLeading Teams by Example\nBad software architects leverage their title to get people to do what they want them to\ndo. Effective software architects get people to do things by not leveraging their title as\narchitect, but rather by leading through example, not by title. This is all about gaining\nthe respect of development teams, business stakeholders, and other people through\u2010\nout the organization (such as the head of operations, development managers, and\nproduct owners).\nThe classic \u201clead by example, not by title\u201d story involves a captain and a sergeant dur\u2010\ning a military battle. The high-ranking captain, who is largely removed from the\ntroops, commands all of the troops to move forward during the battle to take a par\u2010\nticularly difficult hill. However, rather than listen to the high-ranking captain, the sol\u2010\ndiers, full of doubt, look over to the lower-ranking sergeant for whether they should\ntake the hill or not. The sergeant looks at the situation, nods his head slightly, and the\nsoldiers immediately move forward with confidence to take the hill.\nThe moral of this story is that rank and title mean very little when it comes to leading\npeople. The computer scientist Gerald Weinberg is famous for saying, \u201cNo matter\nwhat the problem is, it\u2019s a people problem.\u201d Most people think that solving technical\nissues has nothing to do with people skills\u2014it has to do with technical knowledge. \nWhile having technical knowledge is certainly necessary for solving a problem, it\u2019s\nonly a part of the overall equation for solving any problem. Suppose, for example, an\narchitect is holding a meeting with a team of developers to solve an issue that\u2019s come\nup in production. One of the developers makes a suggestion, and the architect\nresponds with, \u201cWell, that\u2019s a dumb idea.\u201d Not only will that developer not make any\nmore suggestions, but none of the other developers will dare say anything. The archi\u2010\ntect in this case has effectively shut down the entire team from collaborating on the\nsolution.\nGaining respect and leading teams is about basic people skills. Consider the following\ndialogue between an architect and a customer, client, or development team with\nregard to a performance issue in the application:\nDeveloper: \u201cSo how are we going to solve this performance problem?\u201d\nArchitect: \u201cWhat you need to do is use a cache. That would fix the problem.\u201d\nDeveloper: \u201cDon\u2019t tell me what to do.\u201d\nArchitect: \u201cWhat I\u2019m telling you is that it would fix the problem.\u201d\nBy using the words \u201cwhat you need to do is\u2026\u201d or \u201cyou must,\u201d the architect is forcing\ntheir opinion onto the developer and essentially shutting down collaboration. This is\na good example of using communication, not collaboration. Now consider the revised\ndialogue:\nThe Software Architect as a Leader \n| \n357\n", "page": 377, "type": "text", "section": "Page 377"}
{"text": "Developer: \u201cSo how are we going to solve this performance problem?\u201d\nArchitect: \u201cHave you considered using a cache? That might fix the problem.\u201d\nDeveloper: \u201cHmmm, no we didn\u2019t think about that. What are your thoughts?\u201d\nArchitect: \u201cWell, if we put a cache here\u2026\u201d\nNotice the use of the words \u201chave you considered\u2026\u201d or \u201cwhat about\u2026\u201d in the dia\u2010\nlogue. By asking the question, it puts control back on the developer or client, creating\na collaborative conversation where both the architect and developer are working\ntogether to form a solution. The use of grammar is vitally important when trying to\nbuild a collaborative environment. Being a leader as an architect is not only being\nable to collaborate with others to create an architecture, but also to help promote col\u2010\nlaboration among the team by acting as a facilitator. As an architect, try to observe\nteam dynamics and notice when situations like the first dialogue occurs. By taking\nteam members aside and coaching them on the use of grammar as a means of collab\u2010\noration, not only will this create better team dynamics, but it will also help create\nrespect among the team members.\nAnother basic people skills technique that can help build respect and healthy relation\u2010\nships between an architect and the development team is to always try to use the per\u2010\nson\u2019s name during a conversation or negotiation. Not only do people like hearing\ntheir name during a conversation, it also helps breed familiarity. Practice remember\u2010\ning people\u2019s names, and use them frequently. Given that names are sometimes hard to\npronounce, make sure to get the pronunciation correct, then practice that pronuncia\u2010\ntion until it is perfect. Whenever we ask someone\u2019s name, we repeat it to the person\nand ask if that\u2019s the correct way to pronounce it. If it\u2019s not correct, we repeat this pro\u2010\ncess until we get it right.\nIf an architect meets someone for the first time or only occasionally, always shake the\nperson\u2019s hand and make eye contact. A handshake is an important people skill that\ngoes back to medieval times. The physical bond that occurs during a simple hand\u2010\nshake lets both people know they are friends, not foes, and forms a bond between\nthem. However, it is sometimes hard to get a simple handshake right.\nWhen shaking someone\u2019s hand, give a firm (but not overpowering) handshake while\nlooking the person in the eye. Looking away while shaking someone\u2019s hand is a sign\nof disrespect, and most people will notice that. Also, don\u2019t hold on to the handshake\ntoo long. A simple two- to three-second, firm handshake is all that is needed to start\noff a conversation or to greet someone. There is also the issue of going overboard\nwith the handshake technique and making the other person uncomfortable enough\nto not want to communicate or collaborate with you. For example, imagine a software\narchitect who comes in every morning and starts shaking everyone\u2019s hand. Not only\nis this a little weird, it creates an uncomfortable situation. However, imagine a soft\u2010\nware architect who must meet with the head of operations monthly. This is the per\u2010\nfect opportunity to stand up, say \u201cHello Ruth, nice seeing you again,\u201d and give a\n358 \n| \nChapter 23: Negotiation and Leadership Skills\n", "page": 378, "type": "text", "section": "Page 378"}
{"text": "quick, firm handshake. Knowing when to do a handshake and when not to is part of\nthe complex art of people skills.\nA software architect as a leader, facilitator, and negotiator should be careful to pre\u2010\nserve the boundaries that exist between people at all levels. The handshake, as\ndescribed previously, is an effective and professional technique of forming a physical\nbond with the person you are communicating or collaborating with. However, while a\nhandshake is good, a hug in a professional setting, regardless of the environment, is\nnot. An architect might think that it exemplifies more physical connection and bond\u2010\ning, but all it does is sometimes make the other person at work more uncomfortable\nand, more importantly, can lead to potential harassment issues within the workplace.\nSkip the hugs all together, regardless of the professional environment, and stick with\nthe handshake instead (unless of course everyone in the company hugs each other,\nwhich would just be\u2026weird).\nSometimes it\u2019s best to turn a request into a favor as a way of getting someone to do\nsomething they otherwise might not want to do. In general, people do not like to be\ntold what to do, but for the most part, people want to help others. This is basic\nhuman nature. Consider the following conversation between an architect and devel\u2010\noper regarding an architecture refactoring effort during a busy iteration:\nArchitect: \u201cI\u2019m going to need you to split the payment service into five different serv\u2010\nices, with each service containing the functionality for each type of payment we accept,\nsuch as store credit, credit card, PayPal, gift card, and reward points, to provide better\nfault tolerance and scalability in the website. It shouldn\u2019t take too long.\u201d\nDeveloper: \u201cNo way, man. Way too busy this iteration for that. Sorry, can\u2019t do it.\u201d\nArchitect: \u201cListen, this is important and needs to be done this iteration.\u201d\nDeveloper: \u201cSorry, no can do. Maybe one of the other developers can do it. I\u2019m just too\nbusy.\u201d\nNotice the developer\u2019s response. It is an immediate rejection of the task, even though\nthe architect justified it through better fault tolerance and scalability. In this case,\nnotice that the architect is telling the developer to do something they are simply too\nbusy to do. Also notice the demand doesn\u2019t even include the person\u2019s name! Now con\u2010\nsider the technique of turning the request into a favor:\nArchitect: \u201cHi, Sridhar. Listen, I\u2019m in a real bind. I really need to have the payment\nservice split into separate services for each payment type to get better fault tolerance\nand scalability, and I waited too long to do it. Is there any way you can squeeze this into\nthis iteration? It would really help me out.\u201d\nDeveloper: \u201c(Pause)\u2026I\u2019m really busy this iteration, but I guess so. I\u2019ll see what I can\ndo.\u201d\nArchitect: \u201cThanks, Sridhar, I really appreciate the help. I owe you one.\u201d\nDeveloper: \u201cNo worries, I\u2019ll see that it gets done this iteration.\u201d\nFirst, notice the use of the person\u2019s name repeatedly throughout the conversation.\nUsing the person\u2019s name makes the conversation more of a personal, familiar nature\nThe Software Architect as a Leader \n| \n359\n", "page": 379, "type": "text", "section": "Page 379"}
{"text": "rather than an impersonal professional demand. Second, notice the architect admits\nthey are in a \u201creal bind\u201d and that splitting the services would really \u201chelp them out a\nlot.\u201d This technique does not always work, but playing off of basic human nature of\nhelping each other has a better probability of success over the first conversation. Try\nthis technique the next time you face this sort of situation and see the results. In most\ncases, the results will be much more positive than telling someone what to do.\nTo lead a team and become an effective leader, a software architect should try to\nbecome the go-to person on the team\u2014the person developers go to for their ques\u2010\ntions and problems. An effective software architect will seize the opportunity and\ntake the initiative to lead the team, regardless of their title or role on the team. When\na software architect observes someone struggling with a technical issue, they should\nstep in and offer help or guidance. The same is true for nontechnical situations as\nwell. Suppose an architect observes a team member that comes into work looking sort\nof depressed and bothered\u2014clearly something is up. In this circumstance, an effec\u2010\ntive software architect would notice the situation and offer to talk\u2014something like,\n\u201cHey, Antonio, I\u2019m heading over to get some coffee. Why don\u2019t we head over\ntogether?\u201d and then during the walk ask if everything is OK. This at least provides an\nopening for more of a personal discussion; and at it\u2019s best, a chance to mentor and\ncoach at a more personal level. However, an effective leader will also recognize times\nto not be too pushy and will back off by reading various verbal signs and facial\nexpressions.\nAnother technique to start gaining respect as a leader and become the go-to person\non the team is to host periodic brown-bag lunches to talk about a specific technique\nor technology. Everyone reading this book has a particular skill or knowledge that\nothers don\u2019t have. By hosting a periodic brown-bag lunch session, the architect not\nonly is able to exhibit their technical prowess, but also practice speaking skills and\nmentoring skills. For example, host a lunch session on a review of design patterns or\nthe latest features of the programming language release. Not only does this provide\nvaluable information to developers, but it also starts identifying you as a leader and\nmentor on the team.\nIntegrating with the Development Team\nAn architect\u2019s calendar is usually filled with meetings, with most of those meetings\noverlapping with other meetings, such as the calendar shown in Figure 23-4. If this is\nwhat a software architect\u2019s calendar looks like, then when does the architect have the\ntime to integrate with the development team, help guide and mentor them, and be\navailable for questions or concerns when they come up? Unfortunately, meetings are\na necessary evil within the information technology world. They happen frequently,\nand will always happen.\n360 \n| \nChapter 23: Negotiation and Leadership Skills\n", "page": 380, "type": "text", "section": "Page 380"}
{"text": "Figure 23-4. A typical calendar of a software architect\nThe key to being an effective software architect is making more time for the develop\u2010\nment team, and this means controlling meetings. There are two types of meetings an\narchitect can be involved in: those imposed upon (the architect is invited to a meet\u2010\ning), and those imposed by (the architect is calling the meeting). These meeting types\nare illustrated in Figure 23-5.\nFigure 23-5. Meeting types\nIntegrating with the Development Team \n| \n361\n", "page": 381, "type": "text", "section": "Page 381"}
{"text": "Imposed upon meetings are the hardest to control. Due to the number of stakeholders\na software architect must communicate and collaborate with, architects are invited to\nalmost every meeting that gets scheduled. When invited to a meeting, an effective\nsoftware architect should always ask the meeting organizer why they are needed in\nthat meeting. Many times architects get invited to meetings simply to keep them in\nthe loop on the information being discussed. That\u2019s what meeting notes are for. By\nasking why, an architect can start to qualify which meetings they should attend and\nwhich ones they can skip. Another related technique to help reduce the number of\nmeetings an architect is involved in is to ask for the meeting agenda before accepting\na meeting invite. The meeting organizer may feel that the architect is necessary, but\nby looking at the agenda, the architect can qualify whether they really need to be in\nthe meeting or not. Also, many times it is not necessary to attend the entire meeting.\nBy reviewing the agenda, an architect can optimize their time by either showing up\nwhen relevant information is being discussed or leaving after the relevant discussion\nis over. Don\u2019t waste time in a meeting if you can be spending that time working with\nthe development team.\nAsk for the meeting agenda ahead of time to help qualify if you are\nreally needed at the meeting or not.\nAnother effective technique to keep a development team on track and to gain their\nrespect is to take one for the team when developers are invited to a meeting as well.\nRather than having the tech lead attend the meeting, go in their place, particularly if\nboth the tech lead and architect are invited to a meeting. This keeps a development\nteam focused on the task at hand rather than continually attending meetings as well.\nWhile deflecting meetings away from useful team members increases the time an\narchitect is in meetings, it does increase the development team\u2019s productivity.\nMeetings that an architect imposes upon others (the architect calls the meeting) are\nalso a necessity at times but should be kept to an absolute minimum. These are the\nkinds of meetings an architect has control over. An effective software architect will\nalways ask whether the meeting they are calling is more important than the work they\nare pulling their team members away from. Many times an email is all that is required\nto communicate some important information, which saves everyone tons of wasted\ntime. When calling a meeting as an architect, always set an agenda and stick to it. Too\noften, meetings an architect calls get derailed due to some other issue, and that other\nissue may not be relevant to everyone else in the meeting. Also, as an architect, pay\nclose attention to developer flow and be sure not to disrupt it by calling a meeting.\nFlow is a state of mind developers frequently get into where the brain gets 100%\nengaged in a particular problem, allowing full attention and maximum creativity. For\n362 \n| \nChapter 23: Negotiation and Leadership Skills\n", "page": 382, "type": "text", "section": "Page 382"}
{"text": "example, a developer might be working on a particularly difficult algorithm or piece\nof code, and literally hours go by while it seems only minutes have passed. When call\u2010\ning a meeting, an architect should always try to schedule meetings either first thing in\nthe morning, right after lunch, or toward the end of the day, but not during the day\nwhen most developers experience flow state.\nAside from managing meetings, another thing an effective software architect can do\nto integrate better with the development team is to sit with that team. Sitting in a\ncubicle away from the team sends the message that the architect is special, and those\nphysical walls surrounding the cubicle are a distinct message that the architect is not\nto be bothered or disturbed. Sitting alongside a development team sends the message\nthat the architect is an integral part of the team and is available for questions or con\u2010\ncerns as they arise. By physically showing that they are part of the development team,\nthe architect gains more respect and is better able to help guide and mentor the team.\nSometimes it is not possible for an architect to sit with a development team. In these\ncases the best thing an architect can do is continually walk around and be seen.\nArchitects that are stuck on a different floor or always in their offices or cubicles and\nnever seen cannot possibly help guide the development team through the\nimplementation of the architecture. Block off time in the morning, after lunch, or late\nin the day and make the time to converse with the development team, help with\nissues, answer questions, and do basic coaching and mentoring. Development teams\nappreciate this type of communication and will respect you for making time for them\nduring the day. The same holds true for other stakeholders. Stopping in to say hi to\nthe head of operations while on the way to get more coffee is an excellent way of\nkeeping communication open and available with business and other key stakeholders.\nSummary\nThe negotiation and leadership tips presented and discussed in this chapter are meant\nto help the software architect form a better collaborative relationship with the devel\u2010\nopment team and other stakeholders. These are necessary skills an architect must\nhave in order to become an effective software architect. While the tips we presented\nin this chapter are good tips for starting the journey into becoming more of an effec\u2010\ntive leader, perhaps the best tip of all is from a quote from Theodore Roosevelt, the\n26th US president:\nThe most important single ingredient in the formula of success is knowing how to get\nalong with people.\n\u2014Theodore Roosevelt\nSummary \n| \n363\n", "page": 383, "type": "text", "section": "Page 383"}
{"text": "CHAPTER 24\nDeveloping a Career Path\nBecoming an architect takes time and effort, but based on the many reasons we\u2019ve\noutlined throughout this book, managing a career path after becoming an architect is\nequally tricky. While we can\u2019t chart a specific career path for you, we can point you to\nsome practices that we have seen work well.\nAn architect must continue to learn throughout their career. The technology world\nchanges at a dizzying pace. One of Neal\u2019s former coworkers was a world-renowned\nexpert in Clipper. He lamented that he couldn\u2019t take the enormous body of (now use\u2010\nless) Clipper knowledge and replace it with something else. He also speculated (and\nthis is still an open question): has any group in history learned and thrown away so\nmuch detailed knowledge within their lifetimes as software developers?\nEach architect should keep an eye out for relevant resources, both technology and\nbusiness, and add them to their personal stockpile. Unfortunately, resources come\nand go all too quickly, which is why we don\u2019t list any in this book. Talking to collea\u2010\ngues or experts about what resources they use to keep current is one good way of\nseeking out the latest newsfeeds, websites, and groups that are active in a particular\narea of interest. Architects should also build into their day some time to maintain\nbreadth utilizing those resources.\nThe 20-Minute Rule\nAs illustrated in Figure 2-6, technology breadth is more important to architects than\ndepth. However, maintaining breadth takes time and effort, something architects\nshould build into their day. But how in the world does anyone have the time to\nactually go to various websites to read articles, watch presentations, and listen to pod\u2010\ncasts? The answer is\u2026not many do. Developers and architects alike struggle with the\nbalance of working a regular job, spending time with the family, being available for\n365\n", "page": 385, "type": "text", "section": "Page 385"}
{"text": "our children, carving out personal time for interests and hobbies, and trying to\ndevelop careers, while at the same time trying to keep up with the latest trends and\nbuzzwords.\nOne technique we use to maintain this balance is something we call the 20-minute\nrule. The idea of this technique, as illustrated in Figure 24-1, is to devote at least 20\nminutes a day to your career as an architect by learning something new or diving\ndeeper into a specific topic. Figure 24-1 illustrates examples of some of the types of\nresources to spend 20 minutes a day on, such as InfoQ, DZone Refcardz, and the\nThoughtWorks Technology Radar. Spend that minimum of 20 minutes to Google\nsome unfamiliar buzzwords (\u201cthe things you don\u2019t know you don\u2019t know\u201d from Chap\u2010\nter 2) to learn a little about them, promoting that knowledge into the \u201cthings you\nknow you don\u2019t know.\u201d Or maybe spend the 20 minutes going deeper into a particular\ntopic to gain a little more knowledge about it. The point of this technique is to be able\nto carve out some time for developing a career as an architect and continuously gain\u2010\ning technical breadth.\nFigure 24-1. The 20-minute rule\nMany architects embrace this concept and plan to spend 20 minutes at lunch or in the\nevening after work to do this. What we have experienced is that this rarely works.\nLunchtime gets shorter and shorter, becoming more of a catch-up time at work rather\nthan a time to take a break and eat. Evenings are even worse\u2014situations change,\nplans get made, family time becomes more important, and the 20-minute rule never\nhappens.\nWe strongly recommend leveraging the 20-minute rule first thing in the morning, as\nthe day is starting. However, there is a caveat to this advice as well. For example, what\nis the first thing an architect does after getting to work in the morning? Well, the very\n366 \n| \nChapter 24: Developing a Career Path\n", "page": 386, "type": "text", "section": "Page 386"}
{"text": "first thing the architect does is to get that wonderful cup of coffee or tea. OK, in that\ncase, what is the second thing every architect does after getting that necessary coffee\nor tea\u2014check email. Once an architect checks email, diversion happens, email\nresponses are written, and the day is over. Therefore, our strong recommendation is\nto invoke the 20-minute rule first thing in the morning, right after grabbing that cup\nof coffee or tea and before checking email. Go in to work a little early. Doing this will\nincrease an architect\u2019s technical breadth and help develop the knowledge required to\nbecome an effective software architect.\nDeveloping a Personal Radar\nFor most of the \u201990s and the beginning of the \u201900s, Neal was the CTO of a small train\u2010\ning and consulting company. When he started there, the primary platform was Clip\u2010\nper, which was a rapid-application development tool for building DOS applications\natop dBASE files. Until one day it vanished. The company had noticed the rise of\nWindows, but the business market was still DOS\u2026until it abruptly wasn\u2019t. That les\u2010\nson left a lasting impression: ignore the march of technology at your peril.\nIt also taught an important lesson about technology bubbles. When heavily invested\nin a technology, a developer lives in a memetic bubble, which also serves as an echo\nchamber. Bubbles created by vendors are particularly dangerous, because developers\nnever hear honest appraisals from within the bubble. But the biggest danger of Bub\u2010\nble Living comes when it starts collapsing, which developers never notice from the\ninside until it\u2019s too late.\nWhat they lacked was a technology radar: a living document to assess the risks and\nrewards of existing and nascent technologies. The radar concept comes from\nThoughtWorks; first, we\u2019ll describe how this concept came to be and then how to use\nit to create a personal radar.\nThe ThoughtWorks Technology Radar\nThe ThoughtWorks Technology Advisory Board (TAB) is a group of senior technol\u2010\nogy leaders within ThoughtWorks, created to assist the CTO, Dr. Rebecca Parsons, in\ndeciding technology directions and strategies for the company and its clients. This\ngroup meets face-to-face twice a year. One of the outcomes of the face to face meeting\nwas the Technology Radar. Over time, it gradually grew into the biannual Technology\nRadar.\nThe TAB gradually settled into a twice-a-year rhythm of Radar production. Then, as\noften happens, unexpected side effects occurred. At some of the conferences Neal\nspoke at, attendees sought him out and thanked him for helping produce the Radar\nand said that their company had started producing their own version of it.\nDeveloping a Personal Radar \n| \n367\n", "page": 387, "type": "text", "section": "Page 387"}
{"text": "Neal also realized that this was the answer to a pervasive question at conference\nspeaker panels everywhere: \u201cHow do you (the speakers) keep up with technology?\nHow do you figure out what things to pursue next?\u201d The answer, of course, is that\nthey all have some form of internal radar.\nParts\nThe ThoughtWorks Radar consists of four quadrants that attempt to cover most of\nthe software development landscape:\nTools\nTools in the software development space, everything from developers tools like\nIDEs to enterprise-grade integration tools\nLanguages and frameworks\nComputer languages, libraries, and frameworks, typically open source\nTechniques\nAny practice that assists software development overall; this may include software\ndevelopment processes, engineering practices, and advice\nPlatforms\nTechnology platforms, including databases, cloud vendors, and operating\nsystems\nRings\nThe Radar has four rings, listed here from outer to inner:\nHold\nThe original intent of the hold ring was \u201chold off for now,\u201d to represent technolo\u2010\ngies that were too new to reasonably assess yet\u2014technologies that were getting\nlots of buzz but weren\u2019t yet proven. The hold ring has evolved into indicating\n\u201cdon\u2019t start anything new with this technology.\u201d There\u2019s no harm in using it on\nexisting projects, but developers should think twice about using it for new\ndevelopment.\nAssess\nThe assess ring indicates that a technology is worth exploring with the goal of\nunderstanding how it will affect an organization. Architects should invest some\neffort (such as development spikes, research projects, and conference sessions) to\nsee if it will have an impact on the organization. For example, many large compa\u2010\nnies visibly went through this phase when formulating a mobile strategy.\n368 \n| \nChapter 24: Developing a Career Path\n", "page": 388, "type": "text", "section": "Page 388"}
{"text": "Trial\nThe trial ring is for technologies worth pursuing; it is important to understand\nhow to build up this capability. Now is the time to pilot a low-risk project so that\narchitects and developers can really understand the technology.\nAdopt\nFor technologies in the adopt ring, ThoughtWorks feels strongly that the industry\nshould adopt those items.\nAn example view of the Radar appears in Figure 24-2.\nFigure 24-2. A sample ThoughtWorks Technology Radar\nIn Figure 24-2, each blip represents a different technology or technique, with associ\u2010\nated short write-ups. While ThoughtWorks uses the radar to broadcast their opinions\nabout the software world, many developers and architects also use it as a way of struc\u2010\nturing their technology assessment process. Architects can use the tool described in\n\u201cOpen Source Visualization Bits\u201d on page 371 to build the same visuals used by\nThoughtWorks as a way to organize their thinking about what to invest time in.\nDeveloping a Personal Radar \n| \n369\n", "page": 389, "type": "text", "section": "Page 389"}
{"text": "When using the radar for personal use, we suggest altering the meanings of the quad\u2010\nrants to the following:\nHold\nAn architect can include not only technologies and techniques to avoid, but also\nhabits they are trying to break. For example, an architect from the .NET world\nmay be accustomed to reading the latest news/gossip on forums about team\ninternals. While entertaining, it may be a low-value information stream. Placing\nthat in hold forms a reminder for an architect to avoid problematic things.\nAssess\nArchitects should use assess for promising technologies that they have heard\ngood things about but haven\u2019t had time to assess for themselves yet\u2014see \u201cUsing\nSocial Media\u201d on page 371. This ring forms a staging area for more serious\nresearch at some time in the future.\nTrial\nThe trial ring indicates active research and development, such as an architect\nperforming spike experiments within a larger code base. This ring represents\ntechnologies worth spending time on to understand more deeply so that an\narchitect can perform an effective trade-off analysis.\nAdopt\nThe adopt ring represents the new things an architect is most excited about and\nbest practices for solving particular problems.\nIt is dangerous to adopt a laissez-faire attitude toward a technology portfolio. Most\ntechnologists pick technologies on a more or less ad hoc basis, based on what\u2019s cool or\nwhat your employer is driving. Creating a technology radar helps an architect formal\u2010\nize their thinking about technology and balance opposing decision criteria (such as\nthe \u201cmore cool\u201d technology factor and being less likely to get a new job versus a huge\njob market but with less interesting work). Architects should treat their technology\nportfolio like a financial portfolio: in many ways, they are the same thing. What does\na financial planner tell people about their portfolio? Diversify!\nArchitects should choose some technologies and/or skills that are widely in demand\nand track that demand. But they might also want to try some technology gambits, like\nopen source or mobile development. Anecdotes abound about developers who freed\nthemselves from cubicle-dwelling servitude by working late at night on open source\nprojects that became popular, purchasable, and eventually, career destinations. This is\nyet another reason to focus on breadth rather than depth.\nArchitects should set aside time to broaden their technology portfolio, and building a\nradar provides a good scaffolding. However, the exercise is more important than the\noutcome. Creating the visualization provides an excuse to think about these things,\n370 \n| \nChapter 24: Developing a Career Path\n", "page": 390, "type": "text", "section": "Page 390"}
{"text": "and, for busy architects, finding an excuse to carve out time in a busy schedule is the\nonly way this kind of thinking can occur.\nOpen Source Visualization Bits\nBy popular demand, ThoughtWorks released a tool in November 2016 to assist tech\u2010\nnologists in building their own radar visualization. When ThoughtWorks does this\nexercise for companies, they capture the output of the meeting in a spreadsheet, with\na page for each quadrant. The ThoughtWorks Build Your Own Radar tool uses a\nGoogle spreadsheet as input and generates the radar visualization using an HTML 5\ncanvas. Thus, while the important part of the exercise is the conversations it gener\u2010\nates, it also generates useful visualizations.\nUsing Social Media\nWhere can an architect find new technologies and techniques to put in the assess ring\nof their radar? In Andrew McAfee\u2019s book Enterprise 2.0 (Harvard Business Review\nPress), he makes an interesting observation about social media and social networks in\ngeneral. When thinking about a person\u2019s network of contact between people, three\ncategories exist, as illustrated in Figure 24-3.\nFigure 24-3. Social circles of a person\u2019s relationships\nIn Figure 24-3, strong links represent family members, coworkers, and other people\nwhom a person regularly contacts. One litmus test for how close these connections\nare: they can tell you what a person in their strong links had for lunch at least one day\nlast week. Weak links are casual acquaintances, distant relatives, and other people seen\nUsing Social Media \n| \n371\n", "page": 391, "type": "text", "section": "Page 391"}
{"text": "only a few times a year. Before social media, it was difficult to keep up with this circle\nof people. Finally, potential links represent people you haven\u2019t met yet.\nMcAfee\u2019s most interesting observation about these connections was that someone\u2019s\nnext job is more likely to come from a weak link than a strong one. Strongly linked\npeople know everything within the strongly linked group\u2014these are people who see\neach other all the time. Weak links, on the other hand, offer advice from outside\nsomeone\u2019s normal experience, including new job offers.\nUsing the characteristics of social networks, architects can utilize social media to\nenhance their technical breadth. Using social media like Twitter professionally, archi\u2010\ntects should find technologists whose advice they respect and follow them on social\nmedia. This allows an architect to build a network on new, interesting technologies to\nassess and keep up with the rapid changes in the technology world.\nParting Words of Advice\nHow do we get great designers? Great designers design, of course.\n\u2014Fred Brooks\nSo how are we supposed to get great architects, if they only get the chance to architect\nfewer than a half-dozen times in their career?\n\u2014Ted Neward\nPractice is the proven way to build skills and become better at anything in life\u2026\nincluding architecture. We encourage new and existing architects to keep honing\ntheir skills, both for individual technology breadth but also for the craft of designing\narchitecture. To that end, check out the architecture katas on the companion website\nfor the book. Modeled after the katas used as examples here, we encourage architects\nto use these to practice building skills in architecture.\nA common question we get about katas: is there an answer guide somewhere?\nUnfortunately such an answer key does not exist. To quote your author, Neal:\nThere are not right or wrong answers in architecture\u2014only trade-offs.\nWhen we started using the architecture katas exercise during live training classes, we\ninitially kept the drawings the students produced with the goal of creating an answer\nrepository. We quickly gave up, though, because we realized that we had incomplete\nartifacts. In other words, the teams had captured the topology and explained their\ndecisions in class but didn\u2019t have the time to create architecture decision records.\nWhile how they implemented their solutions was interesting, the why was much\nmore interesting because it contains the trade-offs they considered in making that\ndecision. Keeping just the how was only half of the story. So, our last parting words of\nadvice: always learn, always practice, and go do some architecture!\n372 \n| \nChapter 24: Developing a Career Path\n", "page": 392, "type": "text", "section": "Page 392"}
{"text": "APPENDIX\nSelf-Assessment Questions\nChapter 1: Introduction\n1. What are the four dimensions that define software architecture?\n2. What is the difference between an architecture decision and a design principle?\n3. List the eight core expectations of a software architect.\n4. What is the First Law of Software Architecture?\nChapter 2: Architectural Thinking\n1. Describe the traditional approach of architecture versus development and\nexplain why that approach no longer works.\n2. List the three levels of knowledge in the knowledge triangle and provide an\nexample of each.\n3. Why is it more important for an architect to focus on technical breadth rather\nthan technical depth?\n4. What are some of the ways of maintaining your technical depth and remaining\nhands-on as an architect?\n373\n", "page": 393, "type": "text", "section": "Page 393"}
{"text": "Chapter 3: Modularity\n1. What is meant by the term connascence?\n2. What is the difference between static and dynamic connascence?\n3. What does connascence of type mean? Is it static or dynamic connascence?\n4. What is the strongest form of connascence?\n5. What is the weakest form of connascence?\n6. Which is preferred within a code base\u2014static or dynamic connascence?\nChapter 4: Architecture Characteristics Defined\n1. What three criteria must an attribute meet to be considered an architecture char\u2010\nacteristic?\n2. What is the difference between an implicit characteristic and an explicit one?\nProvide an example of each.\n3. Provide an example of an operational characteristic.\n4. Provide an example of a structural characteristic.\n5. Provide an example of a cross-cutting characteristic.\n6. Which architecture characteristic is more important to strive for\u2014availability or\nperformance?\nChapter 5: Identifying Architecture Characteristics\n1. Give a reason why it is a good practice to limit the number of characteristics (\u201c-\nilities\u201d) an architecture should support.\n2. True or false: most architecture characteristics come from business requirements\nand user stories.\n3. If a business stakeholder states that time-to-market (i.e., getting new features and\nbug fixes pushed out to users as fast as possible) is the most important business\nconcern, which architecture characteristics would the architecture need to sup\u2010\nport?\n4. What is the difference between scalability and elasticity?\n5. You find out that your company is about to undergo several major acquisitions to\nsignificantly increase its customer base. Which architectural characteristics\nshould you be worried about?\n374 \n| \nAppendix: Self-Assessment Questions\n", "page": 394, "type": "text", "section": "Page 394"}
{"text": "Chapter 6: Measuring and Governing Architecture\nCharacteristics\n1. Why is cyclomatic complexity such an important metric to analyze for architec\u2010\nture?\n2. What is an architecture fitness function? How can they be used to analyze an\narchitecture?\n3. Provide an example of an architecture fitness function to measure the scalability\nof an architecture.\n4. What is the most important criteria for an architecture characteristic to allow\narchitects and developers to create fitness functions?\nChapter 7: Scope of Architecture Characteristics\n1. What is an architectural quantum, and why is it important to architecture?\n2. Assume a system consisting of a single user interface with four independently\ndeployed services, each containing its own separate database. Would this system\nhave a single quantum or four quanta? Why?\n3. Assume a system with an administration portion managing static reference data\n(such as the product catalog, and warehouse information) and a customer-facing\nportion managing the placement of orders. How many quanta should this system\nbe and why? If you envision multiple quanta, could the admin quantum and\ncustomer-facing quantum share a database? If so, in which quantum would the\ndatabase need to reside?\nChapter 8: Component-Based Thinking\n1. We define the term component as a building block of an application\u2014something\nthe application does. A component usually consist of a group of classes or source\nfiles. How are components typically manifested within an application or service?\n2. What is the difference between technical partitioning and domain partitioning?\nProvide an example of each.\n3. What is the advantage of domain partitioning?\n4. Under what circumstances would technical partitioning be a better choice over\ndomain partitioning?\n5. What is the entity trap? Why is it not a good approach for component\nidentification?\nSelf-Assessment Questions \n| \n375\n", "page": 395, "type": "text", "section": "Page 395"}
{"text": "6. When might you choose the workflow approach over the Actor/Actions\napproach when identifying core components?\nChapter 9: Architecture Styles\n1. List the eight fallacies of distributed computing.\n2. Name three challenges that distributed architectures have that monolithic archi\u2010\ntectures don\u2019t.\n3. What is stamp coupling?\n4. What are some ways of addressing stamp coupling?\nChapter 10: Layered Architecture Style\n1. What is the difference between an open layer and a closed layer?\n2. Describe the layers of isolation concept and what the benefits are of this concept.\n3. What is the architecture sinkhole anti-pattern?\n4. What are some of the main architecture characteristics that would drive you to\nuse a layered architecture?\n5. Why isn\u2019t testability well supported in the layered architecture style?\n6. Why isn\u2019t agility well supported in the layered architecture style?\nChapter 11: Pipeline Architecture\n1. Can pipes be bidirectional in a pipeline architecture?\n2. Name the four types of filters and their purpose.\n3. Can a filter send data out through multiple pipes?\n4. Is the pipeline architecture style technically partitioned or domain partitioned?\n5. In what way does the pipeline architecture support modularity?\n6. Provide two examples of the pipeline architecture style.\n376 \n| \nAppendix: Self-Assessment Questions\n", "page": 396, "type": "text", "section": "Page 396"}
{"text": "Chapter 12: Microkernel Architecture\n1. What is another name for the microkernel architecture style?\n2. Under what situations is it OK for plug-in components to be dependent on other\nplug-in components?\n3. What are some of the tools and frameworks that can be used to manage plug-ins?\n4. What would you do if you had a third-party plug-in that didn\u2019t conform to the\nstandard plug-in contract in the core system?\n5. Provide two examples of the microkernel architecture style.\n6. Is the microkernel architecture style technically partitioned or domain\npartitioned?\n7. Why is the microkernel architecture always a single architecture quantum?\n8. What is domain/architecture isomorphism?\nChapter 13: Service-Based Architecture\n1. How many services are there in a typical service-based architecture?\n2. Do you have to break apart a database in service-based architecture?\n3. Under what circumstances might you want to break apart a database?\n4. What technique can you use to manage database changes within a service-based\narchitecture?\n5. Do domain services require a container (such as Docker) to run?\n6. Which architecture characteristics are well supported by the service-based archi\u2010\ntecture style?\n7. Why isn\u2019t elasticity well supported in a service-based architecture?\n8. How can you increase the number of architecture quanta in a service-based\narchitecture?\nChapter 14: Event-Driven Architecture Style\n1. What are the primary differences between the broker and mediator topologies?\n2. For better workflow control, would you use the mediator or broker topology?\n3. Does the broker topology usually leverage a publish-and-subscribe model with\ntopics or a point-to-point model with queues?\n4. Name two primary advantage of asynchronous communications.\n5. Give an example of a typical request within the request-based model.\nSelf-Assessment Questions \n| \n377\n", "page": 397, "type": "text", "section": "Page 397"}
{"text": "6. Give an example of a typical request in an event-based model.\n7. What is the difference between an initiating event and a processing event in\nevent-driven architecture?\n8. What are some of the techniques for preventing data loss when sending and\nreceiving messages from a queue?\n9. What are three main driving architecture characteristics for using event-driven\narchitecture?\n10. What are some of the architecture characteristics that are not well supported in\nevent-driven architecture?\nChapter 15: Space-Based Architecture\n1. Where does space-based architecture get its name from?\n2. What is a primary aspect of space-based architecture that differentiates it from\nother architecture styles?\n3. Name the four components that make up the virtualized middleware within a\nspace-based architecture.\n4. What is the role of the messaging grid?\n5. What is the role of a data writer in space-based architecture?\n6. Under what conditions would a service need to access data through the data\nreader?\n7. Does a small cache size increase or decrease the chances for a data collision?\n8. What is the difference between a replicated cache and a distributed cache? Which\none is typically used in space-based architecture?\n9. List three of the most strongly supported architecture characteristics in space-\nbased architecture.\n10. Why does testability rate so low for space-based architecture?\n378 \n| \nAppendix: Self-Assessment Questions\n", "page": 398, "type": "text", "section": "Page 398"}
{"text": "Chapter 16: Orchestration-Driven Service-Oriented\nArchitecture\n1. What was the main driving force behind service-oriented architecture?\n2. What are the four primary service types within a service-oriented architecture?\n3. List some of the factors that led to the downfall of service-oriented architecture.\n4. Is service-oriented architecture technically partitioned or domain partitioned?\n5. How is domain reuse addressed in SOA? How is operational reuse addressed?\nChapter 17: Microservices Architecture\n1. Why is the bounded context concept so critical for microservices architecture?\n2. What are three ways of determining if you have the right level of granularity in a\nmicroservice?\n3. What functionality might be contained within a sidecar?\n4. What is the difference between orchestration and choreography? Which does\nmicroservices support? Is one communication style easier in microservices?\n5. What is a saga in microservices?\n6. Why are agility, testability, and deployability so well supported in microservices?\n7. What are two reasons performance is usually an issue in microservices?\n8. Is microservices a domain-partitioned architecture or a technically partitioned\none?\n9. Describe a topology where a microservices ecosystem might be only a single\nquantum.\n10. How was domain reuse addressed in microservices? How was operational reuse\naddressed?\nChapter 18: Choosing the Appropriate Architecture Style\n1. In what way does the data architecture (structure of the logical and physical data\nmodels) influence the choice of architecture style?\n2. How does it influence your choice of architecture style to use?\n3. Delineate the steps an architect uses to determine style of architecture, data parti\u2010\ntioning, and communication styles.\n4. What factor leads an architect toward a distributed architecture?\nSelf-Assessment Questions \n| \n379\n", "page": 399, "type": "text", "section": "Page 399"}
{"text": "Chapter 19: Architecture Decisions\n1. What is the covering your assets anti-pattern?\n2. What are some techniques for avoiding the email-driven architecture anti-\npattern?\n3. What are the five factors Michael Nygard defines for identifying something as\narchitecturally significant?\n4. What are the five basic sections of an architecture decision record?\n5. In which section of an ADR do you typically add the justification for an architec\u2010\nture decision?\n6. Assuming you don\u2019t need a separate Alternatives section, in which section of an\nADR would you list the alternatives to your proposed solution?\n7. What are three basic criteria in which you would mark the status of an ADR as\nProposed?\nChapter 20: Analyzing Architecture Risk\n1. What are the two dimensions of the risk assessment matrix?\n2. What are some ways to show direction of particular risk within a risk assess\u2010\nment? Can you think of other ways to indicate whether risk is getting better or\nworse?\n3. Why is it necessary for risk storming to be a collaborative exercise?\n4. Why is it necessary for the identification activity within risk storming to be an\nindividual activity and not a collaborative one?\n5. What would you do if three participants identified risk as high (6) for a particular\narea of the architecture, but another participant identified it as only medium (3)?\n6. What risk rating (1-9) would you assign to unproven or unknown technologies?\nChapter 21: Diagramming and Presenting Architecture\n1. What is irrational artifact attachment, and why is it significant with respect to\ndocumenting and diagramming architecture?\n2. What do the 4 C\u2019s refer to in the C4 modeling technique?\n3. When diagramming architecture, what do dotted lines between components\nmean?\n4. What is the bullet-riddled corpse anti-pattern? How can you avoid this anti-\npattern when creating presentations?\n380 \n| \nAppendix: Self-Assessment Questions\n", "page": 400, "type": "text", "section": "Page 400"}
{"text": "5. What are the two primary information channels a presenter has when giving a\npresentation?\nChapter 22: Making Teams Effective\n1. What are three types of architecture personalities? What type of boundary does\neach personality create?\n2. What are the five factors that go into determining the level of control you should\nexhibit on the team?\n3. What are three warning signs you can look at to determine if your team is getting\ntoo big?\n4. List three basic checklists that would be good for a development team.\nChapter 23: Negotiation and Leadership Skills\n1. Why is negotiation so important as an architect?\n2. Name some negotiation techniques when a business stakeholder insists on five\nnines of availability, but only three nines are really needed.\n3. What can you derive from a business stakeholder telling you \u201cI needed it\nyesterday\u201d?\n4. Why is it important to save a discussion about time and cost for last in a\nnegotiation?\n5. What is the divide-and-conquer rule? How can it be applied when negotiating\narchitecture characteristics with a business stakeholder? Provide an example.\n6. List the 4 C\u2019s of architecture.\n7. Explain why it is important for an architect to be both pragmatic and visionary.\n8. What are some techniques for managing and reducing the number of meetings\nyou are invited to?\nChapter 24: Developing a Career Path\n1. What is the 20-minute rule, and when is it best to apply it?\n2. What are the four rings in the ThoughtWorks technology radar, and what do\nthey mean? How can they be applied to your radar?\n3. Describe the difference between depth and breadth of knowledge as it applies to\nsoftware architects. Which should architects aspire to maximize?\nSelf-Assessment Questions \n| \n381\n", "page": 401, "type": "text", "section": "Page 401"}
{"text": "Index\nA\nacceleration of rate of change in software devel\u2010\nopment ecosystem, 268\naccessibility, 59\naccidental architecture anti-pattern, 133\naccidental complexity, 354\naccountability, 61\nachievability, 60\nACID transactions, 132\nin service-based architecture, 177\nin services of service-based architecture, 168\nactions provided by presention tools, 321\nactor/actions approach to designing compo\u2010\nnents, 111\nin Going, Going, Gone case study, 112\nactual productivity (of development teams),\n335\nadaptability, 62\nadministrators (network), 129\nADR-tools, 285\nADRs (architecture decision records), 285-295\nas documentation, 293\nauction system example, 294\nbasic structure of, 285\ncompliance section, 290\ncontext section, 288\ndecision section, 288\ndraft ADR, request for comments on, 287\nnotes section, 291\nstatus, 286\nstoring, 291\ntitle, 286\nusing for standards, 293\nAgile development\nAgile Story risk analysis, 308\ncreation of just-in-time artifacts, 317\nextreme programming and, 15\nsoftware architecture and, 18, 101\nagility\nprocess measures of, 81\nrating in service-based architecture, 176\nversus time to market, 67\nAmbulance pattern, 312\nanalyzability, 62\nanimations provided by presentation tools, 321\nanti-patterns\nBig Ball of Mud, 85, 120\nBullet-Riddled Corpse in corporate presen\u2010\ntations, 322\nCookie-Cutter, 321\nCovering Your Assets, 282\nEmail-Driven Architecture, 283\nEntity Trap, 110\nFrozen Caveman, 30\nGeneric Architecture, 65\nGroundhog Day, 282\nIrrational Artifact Attachment, 316\nIvory Tower Architect, 74, 351\nanvils dropping effects, 321\nApache Camel, 186\nApache Ignite, 213\nApache Kafka, 146\nApache ODE, 186\nApache Zookeeper, 157\nAPI layer\nin microservices architecture, 249\nin service-based architecture, 167\n383\n", "page": 403, "type": "text", "section": "Page 403"}
{"text": "security risks of Diagnostics System API\ngateway, 313\napplication logic in processing units, 213\napplication servers\nscaling, problems with, 211\nvendors battling with database server ven\u2010\ndors, 235\napplication services, 237\nArchiMate, 319\narchitects (see software architects)\narchitectural extensibility, 32\nin broker topology of event-driven architec\u2010\nture, 182\narchitectural fitness functions, 17\narchitectural thinking, 23-36\nanalyzing trade-offs, 30\narchitecture versus design, 23-25\nbalancing architecture and hands-on cod\u2010\ning, 34\nself-assessment questions, 373\nunderstanding business drivers, 34\narchitecturally significant, 284\narchitecture by implication anti-pattern, 133\narchitecture characteristics, 55-64\nabout, 55-58\nanalyzing for components, 109\ncross-cutting, 59\ndefined, self-assessment questions, 374\ndefinitions of terms from the ISO, 61\nin distributed architecture Going, Going,\nGone case study, 274\nfitness functions testing\ncyclic dependencies example, 84-86\ndistance from main sequence example,\n86-88\ngovernance of, 82\nidentifying, 65-75\ndesign versus architecture and trade-\noffs, 74\nextracting from domain concerns, 65-67\nextracting from requirements, 67-69\nself-assessment questions, 374\nSilicon Sandwiches case study, 69-74\nincorporating into Going, Going, Gone\ncomponent design, 114\nmeasuring, 77-82\noperational measures, 78\nprocess measures, 81\nstructural measures, 79-81\nmeasuring and governing, self-assessment\nquestions, 375\noperational, 58\npartial listing of, 58\nratings in event-driven architecture,\n207-209\nratings in layered architecture, 139\nratings in microkernel architecture, 160\nratings in microservices architecture,\n263-265\nratings in orchestration-driven service-\noriented architecture, 241\nratings in pipeline architecture, 146\nratings in service-based architecture, 174\nratings in space-based architecture, 233\nscope of, 91-98\narchitectural quanta and granularity,\n92-98\ncoupling and connascence, 92\nself-assessment questions, 375\nstructural, 59\nin synchronous vs. asynchronous communi\u2010\ncations between services, 270\ntrade-offs and least worst architecture, 63\narchitecture decision records (see ADRs)\narchitecture decisions, 6, 281-295\nanti-patterns, 281-284\nCovering Your Assets, 282\nEmail-Driven Architecture, 283\nGroundhog Day, 282\narchitecturally significant, 284\narchitecture decision records (ADRs),\n285-295\nself-assessment questions, 380\narchitecture fitness function, 83\narchitecture katas\norigin of, 68\nreference on, 372\nSilicon Sandwiches case study, 69-74\narchitecture partitioning, 102\narchitecture quantum, 91\narchitectural quanta and granularity, 92-98\nGoing, Going, Gone case study, 95-98\narchitectural quanta in microservices, 265\narchitecture quanta in event-driven archi\u2010\ntecture, 208\narchitecture quanta in space-based architec\u2010\nture, 234\n384 \n| \nIndex\n", "page": 404, "type": "text", "section": "Page 404"}
{"text": "choosing between monolithic and dis\u2010\ntributed architectures in Going, Going,\nGone component design, 115-116\nin orchestration-driven service-oriented\narchitecture, 242\nquanta boundaries for distributed architec\u2010\nture Going, Going, Gone case study, 276\nseparate quanta in service-based architec\u2010\nture, 175\narchitecture risk, analyzing, 297-314\nAgile story risk analysis, 308\nrisk assessments, 298\nrisk matrix for, 297\nrisk storming, 302-308\nconsensus, 304\nidentifying areas of risk, 303\nmitigation of risk, 307\nrisk storming examples, 308-314\navailability of nurse diagnostics system,\n310\nelasticity of nurse diagnostics system,\n312\nnurse diagnostics system, 308\nsecurity in nurse diagnostics system, 313\nself-assessment questions, 380\nArchitecture Sinkhole anti-pattern, 138\narchitecture sinkhole anti-pattern\nmicrokernel architecture and, 161\narchitecture styles, 119-132\nchoosing the appropriate style, 267-277\ndecision criteria, 269-271\ndistributed architecture in Going, Going,\nGone case study, 274-277\nmonolithic architectures in Silicon Sand\u2010\nwiches case study, 271-274\nself-assessment questions, 379\nshifting fashion in architecture, 267-268\ndefined, 119\nfundamental patterns, 119-123\nmonolithic versus distributed architectures,\n123-132\nself-assessment questions, 376\narchitecture vitality, 9\narchivability, 59\nArchUnit (Java), 36, 87\nfitness function to govern layers, 87\nargumentativeness or getting personal, avoid\u2010\ning, 351\narmchair architects, 328\narrows indicating direction of risk, 301\nThe Art of War (Sun Tzu), 350\nasynchronous communication, 254, 270\nin event-driven architecture, 196-197\nin microservices implementation of Going,\nGoing, Gone, 276\nasynchronous connascence, 92, 94\nauditability\nin Going, Going, Gone case study, 96\nperformance and, 67\nauthentication/authorization, 59\nauthenticity, 61\nauto acknowledge mode, 202\nautomation\nleveraging, 35\non software projects, drive toward, 82\navailability, 57\nbasic availability in BASE transactions, 132\nin Going, Going, Gone case study, 97\nimplicit architecture characteristic, 73\nin Going, Going, Gone: discovering comm\u2010\nponents case study, 114\nin nurse diagnostics system risk storming\nexample, 310\nItaly-ility and, 60\nin layered architecture, 141\nnegotiating with business stakeholders\nabout, 349\nnines of, 349\nperformance and, 67\nin pipeline architecture, 148\nrating in service-based architecture, 176\nreliability versus, 60\nB\nBackends for Frontends (BFF) pattern, 273\nbandwidth is infinite fallacy, 126\nBASE transactions, 132\nin service-based architecture, 177\nbasic availability, soft state, eventual consis\u2010\ntency (see BASE transactions)\nBig Ball of Mud anti-pattern, 85, 120\nbottleneck trap, 34\nbounded context, 93, 94\nfor services in microservices\ndata isolation with, 249\nmicroservices and, 245\nin microservices architecture, 247\ngranularity for services, 248\nIndex \n| \n385\n", "page": 405, "type": "text", "section": "Page 405"}
{"text": "user interface as part of, 253\nbroadcast capabilities in event-driven architec\u2010\nture, 203\nbroker topology (event-driven architecture),\n180-185\nbenefits and disadvantages of, 185\nexample, 182\nBrooks' law, 335\nBrooks, Fred, 68, 335, 372\nBrown, Simon, 102, 318\nbug fixes, working on, 35\nbuild in animations, 321\nbuild out animations, 321\nBuilding Evolutionary Architectures (Ford et\nal.), 16, 82, 91\nBullet-Riddled Corpse anti-pattern, 322\nbusiness and technical justifications for archi\u2010\ntecture decisions, 282, 343\nbusiness delegate pattern, 136\nbusiness domains\nknowledge of, 11\nin layered architecture, 135\nbusiness drivers, understanding, 34\nbusiness layer\nin layered architectures, 133\nshared objects in, 136\nBusiness Process Execution Language (BPEL),\n187\nbusiness process management (BPM) engines,\n187\nbusiness rules layer, 104\nbusiness stakeholders, negotiating with, 348\nC\nC's of architecture, 353\nC4 diagramming standard, 318\ncaching\ndata collisions and caches in space-based\narchitecture, 224\ndata pumps in caches in space-based archi\u2010\ntecture, 220\nnamed caches and data readers, 222\nnamed caches in space-based architecture,\n216\nnear-cache considerations in space-based\narchitecture, 230\nreplicated vs. distributed in space-based\narchitecture, 227-230\ncapabilities, new, and shifting fashion in archi\u2010\ntecture, 268\ncapacity, 61\ncareer path, developing, 365-372\ndeveloping a personal radar, 367-371\nparting advice, 372\nself-assessment questions, 381\ntwenty-minute rule, 365-367\nusing social media, 371\nchaos engineering, 88\nChaos Gorilla, 88\nChaos Monkey, 88\nThe Checklist Manifesto (Gawande), 89, 338\nchecklists, leveraging, 338-343\ndeveloper code completion checklist, 340\nsoftware release checklist, 342\nunit and functional testing checklist, 341\nchoreography\nof bounded context services in microservi\u2010\nces, 248\nin microservices' communication, 256\ncircuit breakers, 124\nclarity, 355\nclasses, representation in C4 diagrams, 319\nclasspath (Java), 40\nclient acknowledge mode, 202\nclient/server architectures, 121\nbrowser and web server, 122\ndesktop and database server, 122\nthree-tier, 122\nclosed versus open layers, 135\ncloud, space-based architecture implementa\u2010\ntions on, 226\ncode reviews by architects, 36\ncoding, balancing with architecture, 34\ncoexistence, 61\ncohesion, 93\nfunctional, 92\ncollaboration, 355\nof architects with other teams, 74\ncolor in diagrams, 320\nCommon Object Request Broker Architecture\n(CORBA), 122\ncommunication, 355\ncommunicating architecture decisions effec\u2010\ntively, 283\ncommunication between services, 270\nin microservices architecture, 254-263\n386 \n| \nIndex\n", "page": 406, "type": "text", "section": "Page 406"}
{"text": "in microservices implementation of Going,\nGoing, Gone, 276\ncommunication connascence, 93\ncompatibility\ndefined, 61\ninteroperability versus, 60\ncompensating transaction framework, 262\ncompeting consumers, 209\ncompetitive advantage, translation to architec\u2010\nture characteristics, 67\ncomplexity in architecture, 353\ncomponent-based thinking, 99-116\nchoosing between monolithic and dis\u2010\ntributed architectures in Going, Going,\nGone component design, 115-116\ncomponent design, 110-112\ncomponent identification flow, 108-109\ncomponent scope, 99-100\ndevelopers' role, 108\ngranularity of components, 110\nself-assessment questions, 375\nsoftware architect's role, 101-107\ncomponents\ndefined, 99, 101\nrepresentation in C4 diagrams, 318\nconcert ticketing system example (space-based\narchitecture), 231\nconciseness, 355\nconfidentiality, 61\nconfigurability, 59\nConformity Monkey, 88\nconnascence\nabout, 92\nasynchronous, 94\nsynchronous, in high functional cohesion,\n93\nconnected components, 80\nconsistency, eventual, 132\nconstraints, communication by architect to\ndevelopment team, 325\nconstruction techniques, architecurally signifi\u2010\ncant decisions impacting, 285\nConsul, 157\nconsumer filters, 144\ncontainers in C4 diagramming, 318\ncontext\narchitecture katas and, 68\nbounded context and, 245\nbounded context in domain-driven design,\n94\ncontext section of ADRs, 288\nindicating in larger diagram using represen\u2010\ntational consistency, 315\nrepresentation in C4 diagrams, 318\ncontinuity, 58\ncontinuous delivery, 14\ncontracts\ndata pumps in space-based architecture, 220\nmaintenance and versioning, 132\nin microkernel architecture, 158\nin stamp coupling resolution, 126\ncontrol freak architects, 327\nConway's law, 103, 133\norchestration engine and, 238\nCookie-Cutter anti-pattern, 321\ncore system in microkernel architecture,\n150-153\ncorrelation ID, 204\ncost\njustification for architecture decisions, 283\nin orchestration-driven service-oriented\narchitecture, 243\noverall cost in layered architectures, 140\noverall cost in microkernel architecture, 160\noverall cost in pipeline architecture, 147\noverall cost in service-based architecture,\n176\nfor risk mitigation, 307\nin space-based architecture, 234\ntransport cost in distributed computing, 130\ncoupling\nand connascence, 92\ndecoupling of services in microservices, 247\nnegative trade-off of reuse, 246\nreuse and, in orchestration-driven service-\noriented architecture, 241\nCovering Your Assets anti-pattern, 282\nCrap4J tool, 81\ncritical or important to success (architecture\ncharacteristics), 75\ncross-cutting architecture characteristics, 59\ncube or door transitions, 321\ncustomizability, architecture characteristics\nand, 72\ncyclic dependencies between components,\n84-86\ncyclomatic complexity\nIndex \n| \n387\n", "page": 407, "type": "text", "section": "Page 407"}
{"text": "calculating, 79\ngood value for, 81\nremoval from core system of microkernel\narchitecture, 150\nD\ndata\ndeciding where it should live, 270\npreventing data loss in event-driven archi\u2010\ntecture, 201-203\nsoftware architecture and, 19\ndata abstraction layer, 223\ndata access layer, 223\ndata collisions, 224-226\ncache size and, 226\nformula to calculate probable number of,\n224\nnumber of processing unit instances and,\n226\ndata grid, 215\ndata isolation in microservices, 249\ndata meshes, 356\n\u201cData Monolith to Data Mesh\u201d article (Fowler),\n356\ndata pumps, 213, 219\ndata reader with reverse data pump, 223\nin domain-based data writers, 221\ndata readers, 213, 222\ndata writers, 213, 221\ndatabase entities, user interface frontend built\non, 111\nDatabase Output transformer filter, 146\ndatabase server, desktop and, 122\ndatabases\nACID transactions in services of service-\nbased architecture, 168\ncomponent-relational mapping of frame\u2010\nwork to, 111\ndata pump sending data to in space-based\narchitecture, 220\nlicensing of database servers, problems with,\n235\nin microkernel architecture core system,\n151\nin microkernel architecture plug-ins, 156\nin orchestration-driven service-oriented\narchitecture, 242\npartitioning in service-based architecture,\n169-171\nremoving as synchronous constraint in\nspace-based architecture, 212\nscaling database server, problems with, 211\nin service-based architecture, 164\ntransactions in service-based architecture,\n177\nvariants in service-based architecture, 166\nDDD (see domain-driven design)\ndemonstration defeats discussion, 350\ndependencies\narchitecturally significant decisions impact\u2010\ning, 284\ncyclic, modularity and, 84-86\ntiming, modules and, 41\ndeployability\nlow rating in layered architecture, 140\nprocess measures of, 81\nrating in microkernel architecture, 161\nrating in orchestration-driven service-\noriented architecture, 242\nrating in pipeline architecture, 147\nrating in service-based architecture, 176\ndeployment\nautomated deployment in microservices\narchitecture, 263\ndeployment manager in space-based archi\u2010\ntecture, 219\nphysical topology variants in layered archi\u2010\ntecture, 134\ndesign\narchitecture versus, 23\nversus architecture and trade-offs, 74\nunderstanding long-term implication of\ndecisions on, 123\ndesign principles in software architecture, 7\ndeveloper code completion checklist, 340\ndeveloper flow, 362\ndevelopers\ndrawn to complexity, 354\nnegotiating with, 351\nrole in components, 108\nroles in layered architecture, 133\ndevelopment process, separation from software\narchitecture, 14, 101\ndevelopment teams, making effective, 325-346\namount of control exerted by sotware archi\u2010\ntect, 331-335\nleveraging checklists, 338-343\ndeveloper code completion checklist, 340\n388 \n| \nIndex\n", "page": 408, "type": "text", "section": "Page 408"}
{"text": "software release checklist, 342\nunit and functional testing checklist, 341\nself-assessment questions, 381\nsoftware architect personality types and,\n326-331\nsoftware architect providing guidance,\n343-346\nteam boundaries, 325\nteam warning signs, 335-338\nDevOps, 3\nadoption of extreme programming practi\u2010\nces, 15\nintersection with software architecture, 17\ndiagramming and presenting architecture,\n315-324\ndiagramming, 316-321\nguidelines for diagrams, 319\nstandards, UML, C4, and ArchiMate,\n318\ntools for, 316\npresenting, 321-324\nincremental builds of presentations, 322\ninfodecks vs. presentations, 324\ninvisibility, 324\nmanipulating time with presentation\ntools, 321\nslides are half of the story, 324\nrepresentational consistency, 315\nself-assessment questions, 380\ndiffusion of responsibility, 337\ndirection of risk, 300\ndirectory structure for storing ADRs, 292\ndissolve transitions and animations, 321\ndistance from the main sequence metric, 86-88\ndistributed architectures\ndomain partitioning and, 107\nin Going, Going, Gone case study, 274-277\nmicrokernel architecture with remote access\nplug-ins, 156\nmicroservices, 247\nmonolithic architectures versus, 123-132,\n270\nfallacies of distributed computing,\n124-131\nin Going, Going, Gone case study,\n115-116\nother distributed computing considera\u2010\ntions, 131\norchestration and choreography of services\nin, 177\nin service-based architecture style, 175\nstamp coupling in, 126\nthree-tier architecture and network-level\nprotocols, 122\nDistributed Component Object Model\n(DCOM), 122\ndistributed systems, 121\ndistributed transactions, 132\ndistributed vs. replicated caching in space-\nbased architecture, 227-230\ndivide and conquer rule, 350\ndo and undo operations in transactions, 263\ndocumentation, ADRs as, 293\ndomain partitioning (components)\ndefined, 104\nin microkernel architecture, 161\nin service-based architecture style, 174\nin space-based architecture, 234\nin Silicon Sandwiches monolithic architec\u2010\ntures case study, 271\nin Silicon Sandwiches partitioning case\nstudy, 107\ntechnical partitioning versus, 249\ndomain-driven design (DDD), 94\ncomponent partitioning and, 104\nevent storming, 112\ninfluence on microservices, 245\nuser interface as part of bounded context,\n253\ndomain/architecture isomorphism, 256\ndomains\ndevelopers defining, 245\ndomain areas of applications, risk assess\u2010\nment on, 299\ndomain changes and architecture styles, 268\ndomain concerns, translating to architecture\ncharacteristics, 65-67\ndomain services in service-based architec\u2010\nture, 163, 168\ndomain-based data readers, 223\ndomain-based data writers, 221\ndomain-centered architecture in microser\u2010\nvices, 265\ninspiration for microservices service bound\u2010\naries, 248\nin technical and domain-partitioned archi\u2010\ntectures, 104\nIndex \n| \n389\n", "page": 409, "type": "text", "section": "Page 409"}
{"text": "door or cube transitions, 321\ndriving characteristics, focus on, 65\nduplication, favoring over reuse, 246\nDuration Calculator transformer filter, 146\nDuration filter, 146\ndynamic connascence, 92\nDZone Refcardz, 366\nE\nEclipse IDE, 150, 158\neffective architects, 330\neffective teams (see development teams, mak\u2010\ning effective)\neffects offered by presentation tools, 321\nelastic scale, 13\nelasticity, 70, 97\nbeing pragmatic, yet visionary about, 356\nin Going, Going, Gone case study, 96\nlow rating in layered architecture, 141\nlow rating in pipeline architecture, 148\nrating in microservices architecture, 264\nrating in orchestration-driven service-\noriented architecture, 243\nrating in service-based architecture, 176\nrating in space-based architecture, 233\nrisks in nurse diagnostics system example,\n312\nelectronic devices recycling example (service-\nbased architecture), 172-173\nEmail-Driven Architecture anti-pattern, 283\nengineering practices, software architecture\nand, 14\nEnterprise 2.0 (McAfee), 371\nentity objects, shared library in service-based\narchitecture, 170\nentity trap, 110, 249\nerror handling in event-driven architecture,\n197-200\nerrors (user), protection against, 61\nessential complexity, 354\nEvans, Eric, 94\nevent broker, 181\nevent mediators, 185\ndelegating events to, 187\nevent processor, 181, 186\nevent queue, 186\nevent storming in component discovery, 112\nevent-driven architecture, 179-209\narchitecture characteristics ratings, 207-209\nasynchronous capabilities, 196-197\nbroadcast capabilities, 203\nchoosing between request-based and event-\nbased model, 206\nerror handling, 197-200\npreventing data loss, 201-203\nrequest-reply messaging, 204\nself-assessment questions, 377\ntopology, 180\nbroker topology, 180-185\nmediator topology, 185-195\nevents\ncommands versus in event-driven architec\u2010\nture, 195\nuse for asynchronous communication in\nmicroservices, 255\neventual consistency, 132\neviction policy in front cache, 230\nevolutionary architectures, 83\nevent-driven architecture, 209\nmicroservices, 264\nexpectations of an architect, 8-13\nexplicit versus implicit architecture characteris\u2010\ntics, 57\nextensibility, 59\nrating in microkenel architecture, 161\nextreme programming (XP), 14, 82\nF\nfallacies of distributed computing, 124-131\nbandwidth is infinite, 126\nlatency is zero, 125\nthe network is reliable, 124\nthe network is secure, 127\nthe network is homogeneous, 131\nthe topology never changes, 128\nthere is only one administrator, 129\ntransport cost is zero, 130\nfast-lane reader pattern, 136\nfault tolerance\nlayered architecture and, 141\nmicrokernel architecture and, 160\npipeline architecture and, 148\nrating in event-driven architecture, 209\nrating in microservices arhitecture, 263\nrating in service-based architecture, 176\nreliability and, 61\nfeasibility, 72\nfederated event broker components, 181\n390 \n| \nIndex\n", "page": 410, "type": "text", "section": "Page 410"}
{"text": "filters\nin pipeline architecture, 143\ntypes of, 144\nin pipeline architecture example, 146\nFirst Law of Software Architecture, 19\nfitness functions, 17, 36, 83-89\nflame effects, 321\nflow, state of, 362\nFoote, Brian, 120\nFord, Neal, 30, 321, 354, 372\nFowler, Martin, 1, 245, 248, 356\nfront cache, 230\nfront controller pattern, 258\nfrontends\nBackends for Frontends (BFF) pattern, 273\nin microservices architecture, 253-254\nFrozen Caveman anti-pattern, 30\nfull backing cache, 230\nfunctional aspects of software, 62\nfunctional cohesion, 92\nhigh, 93\nfunctions or methods, formula for calculating\ncyclomatic complexity, 79\nG\nGawande, Atul, 89, 338\nGeneric Architecture (anti-pattern), 65\nGoing, Going, Gone case study, 95-98\nusing distributed architecture, 274-277\nGoing, Going, Gone: discovering components\ncase study, 112-115\ngovernance for architecture characteristics, 82\ngranularity\narchitectural quanta and, 92-98\nfor services in microservices, 248\nGroundhog Day anti-pattern, 282\ngroup potential, 335\nH\nHawthorne effect, 340\nHazelcast, 213\ncreating internal replicated data grid with,\n216\nlogging statements generated with, 217\nheterogeneity\nenforced, in microservices architecture, 255\nheterogeneous interoperability in microser\u2010\nvices, 255\nHickey, Rich, 32\nhigh functional cohesion, 93\nI\n\"-ilities\", 4\nimplicit architecture characteristics\nexplicit characteristics versus, 57\nmodularity and, 38\nin Silicon Sandwiches case study, 73\nincremental builds for presentations, 322\ninfodecks versus presentations, 324\nInfoQ website, 366\ninfrastructure services, 237\ninitial components, identifying, 108\ninitiating event, 181, 186\nlack of control over workflow associated\nwith, 185\ninstallability, 59\nportability and, 62\nintegrity, 61\nIntelliJ IDEA IDE, 158\ninterfaces, architecturally significant decisions\nimpacting, 285\nInternational Organization for Standards (ISO)\ndefinitions of software architecture terms,\n61\nfunctional aspects of software, 62\ninternationalization (i18n), architecture charac\u2010\nteristics and, 73\ninteroperability, 61, 97\ncompatibility versus, 60\nservices calling each other in microservices,\n255\ninterpersonal skills for architects, 12\nInverse Conway Maneuver, 104, 107\ninvisibility in presentations, 324\nIrrational Artifact Attachment anti-pattern, 316\nIsis framework, 111\nItaly-ility, 60\nIvory Tower Architect anti-pattern, 74, 351\nJ\nJanitor Monkey, 88\nJava\nIsis framework, 111\nno name conflicts in Java 1.0, 39\nthree-tier architecture and, 123\nJDepend tool, 86\nJenkins, 158\nJira, 158\nIndex \n| \n391\n", "page": 411, "type": "text", "section": "Page 411"}
{"text": "K\nK-weight budgets for page downloads, 78\nKafka, processing data streamed to in pipeline\narchitecture, 146\nkatas, 68\n(see also architecture katas)\nkeys for diagrams, 321\nKnuth, Donald, 144\nKops, Micha, 285\nkubernan (to steer), 82\nkubernetes, 268\nL\nlabels in diagrams, 320\nlast participant support (LPS), 202\nlatency\nfallacy of zero latency in distributed com\u2010\nputing, 125\nvarying replication latency in space-based\narchitecture, 225\nLatency Monkey, 88\nlayered architecture, 87, 133-141\nadding layers, 136\narchitecture characteristics ratings, 139\nArchUnit fitness function to govern layers,\n87\nlayers of isolation, 135\nNetArchTest for layer dependencies, 87\nother considerations, 138\nself-assessment questions, 376\ntechnical partitioning in Silicon Sandwiches\ncase study, 107\ntechnical partitioning of components, 107\ntopology, 133-135\nuse cases for, 139\nlayered monoliths, 102, 119\nlayered stack\ndefined, 343\nproviding guidance for, 344\nlayers, drawing tools supporting, 317\nleadership skills (see negotiation and leadership\nskills; software architects)\nlearnability, 60\nusability and, 61\nlearning something new, 366\nleast worst architecture, 63, 75\nlegal requirements, 59\nLeroy, Jonny, 104\nleverageability, 59\nLewis, James, 245\nlibraries, 99\nshared library for entity objects in service-\nbased architecture, 170\nshared library plug-in implementation in\nmicrokernel architecture, 154\nthird-party, in layered stack, 343\nlines in diagrams, 319\nlocalization, 59\nloggability in Going, Going, Gone case study,\n96\nlogging\ndistributed, 131\nstatements generated with Hazelcast in\nspace-based architecture, 217\nlogical partitioning, database in service-based\narchitecture, 170\nM\nmagnets in drawing tools, 318\nmaintainability, 59\ndefined, 62\nmaking teams effective (see development\nteams, making effective)\nmanaging architecture decision records with\nADR-tools blog post, 285\nmaturity, 61\nMcAfee, Andrew, 371\nMcCabe, Thomas, Sr., 79\nMcCullough, Matthew, 321\nMcIlroy, Doug, 144\nmean-time-to-recovery (MTTR)\nhigh MTTR in layered architecture, 141\nhigh MTTR in pipeline architecture, 148\nmediator topology (event-driven architecture),\n180, 185-195\ntrade-offs, 195\nmeetings, controlling, 361-363\nmember list of processing units, 217\nmergers and acquisitions, translation to archi\u2010\ntecture characteristics, 67\nmessage queues, 122\nmessages, use for asynchronous communica\u2010\ntion in microservices, 255\nmessaging\ndata pumps implemented as, 220\nfor item auction system, 31\nmessage flow in orchestration-driven\nservice-oriented architecture, 238\n392 \n| \nIndex\n", "page": 412, "type": "text", "section": "Page 412"}
{"text": "messaging grid, 214\nMetaobject protocol, 38\nmicrofrontends, 253\nmicrokernel architecture, 149-161\narchitecture characteristics ratings, 160\ncontracts between plug-ins and core system,\n158\ncore system, 150-153\nexamples and use cases, 158\nplug-in components, 153-157\nregistry, 157\nself-assessment questions, 377\nin Silicon Sandwiches monolithic architec\u2010\ntures case study, 272\ntopology, 149\nmicroservices, 3\nbounded context in, 93\ncomponents and, 100\ndomain partitioning in Silicon Sandwiches\ncase study, 107\nimplementation of Going, Going, Gone\nusing, 275\nliaison between operations and architecture,\n18\nservice-based architecture style and, 163\n\"Microservices\" blog entry, 245\nmicroservices architecture, 245-265\nAPI layer, 249\narchitecture characteristics ratings, 263-265\nbounded context in, 247\ngranularity for services, 248\ncommunication in, 254-263\nchoreography and orchestration,\n256-259\ntransactions and sagas, 260-263\ndistributed architecture, 247\nfrontends, 253-254\nhistory of, 245\noperational reuse in, 250\nreferences on, 265\nself-assessment questions, 379\ntopology, 246\nmitigation of architecture risk, 307\navailability risk in nurse diagnostics system\nexample, 311\nelasticity of nurse diagnostics system exam\u2010\nple, 312\nsecurity risks in nurse diagnostics system\nexample, 314\nmodifiability, 62\nmodular monoliths, 102\ndomain partitioning in Silicon Sandwiches\ncase study, 107\nusing in Silicon Sandwich case study, 271\nmodular programming languages, 38\nmodularity, 37-53\nabout, 38-40\nfitness functions testing, 84-89\ncyclic dependencies example, 84-86\ndistance from main sequence example,\n86-88\nimportant, but not urgent in software\nprojects, 82\nmaintainability and, 62\nmeasuring, 40-53\nin pipeline architecture, 147\nrating in microkernel architecture, 161\nself-assessment questions, 374\nin service-based architecture, 177\nMongoDB\ndatabase for logging in risk storming exam\u2010\nple, 302, 305\npersisting data to in pipeline architecture,\n146\nmonolithic architecture\nC4 diagramming for, 319\ndistributed architecture versus, 123-132, 270\nin Going, Going, Gone case study,\n115-116\nSilicon Sandwiches case study, 271-274\n\"More Shell, Less Egg\" blog post, 144\nmost frequently used (MFU) cache, 230\nmost recently used (MRU) cache, 230\nMule ESB, 186\nMyers, Glenford J., 37\nThe Mythical Man Month (Brooks), 335\nN\nn-tiered architecture (see layered architecture)\nNaked Objects framework, 111\nname conflicts in programming platforms, 39\nnamespaces, 39\nseparate, for plug-in components of micro\u2010\nkernel architecture, 154\nnear-cache, considerations in space-based\narchitecture, 230\nnegotiation and leadership skills, 347-363\nnegotiation and facilitation, 347-353\nIndex \n| \n393\n", "page": 413, "type": "text", "section": "Page 413"}
{"text": "negotiating with business stakeholders,\n348\nnegotiating with developers, 351\nnegotiating with other architects, 350\nself-assessment questions, 381\nsoftware architect as leader, 353-360\nbeing pragmatic, yet visionary, 355\nC's of architecture, 353\nleading teams by example, 357-360\n.NET\nNaked Objects framework, 111\nNetArchTest tool, 87\nNetflix, Chaos Monkey and Simian Army, 88\nnetworks\nfallacies in distributed computing\nthe network is homogeneous, 131\nthe network is reliable, 124\nthe network is secure, 127\nthe topology never changes, 128\nthere is only one administrator, 129\ntransport cost is zero, 130\nnetwork-level protocols, three-tier architec\u2010\nture and, 122\nNeward, Ted, 68, 372\nnonfunctional requirements, architecturally\nsignificant decisions impacting, 284\nnonrepudiation, 61\nNygard, Michael, 284\nO\nOmniGraffle, 317\non-premises implementations of space-based\narchitecture, 226\nonline auction system example (space-based\narchitecture), 232\nopen versus closed layers, 136\noperating systems, 247\nbefore open source, expensive licensing of,\n235\nin technology platforms, 368\noperational measures of architecture character\u2010\nistics, 78\noperations\nintersection with software architecture, 17\noperational architecture characteristics, 58\nsoftware architecture and, 13\nOracle BPEL Process Manager, 187\nOracle Coherence, 213\norchestration and choreography\nerror handling and orchestration in event\nmediators, 186\nin microservices' communication, 256\norchestration in space-based architecture,\n234\nservices in service-based architecture, 177\norchestration engines, 238\nacting as giant coupling points, 242\norchestration-driven service-oriented architec\u2010\nture, 235-243\narchitecture characteristics ratings, 241\nhistory and philosophy of, 235\nreuse and coupling in, 239-241\nself-assessment questions, 379\ntaxonomy, 236-239\napplication services, 237\ninfrastructure services, 237\nmessage flow, 238\norchestration engine, 238\ntopology, 236\nover-specifying architecture characteristics, 73\noverall costs, 140\n(see also cost)\nin microkernel architecture, 160\nin pipeline architecture, 147\nin service-based architecture, 176\nP\npackages, 38\nplug-in components of microkernel archi\u2010\ntecture implemented as, 154\nPage-Jones, Meilir, 92\npartitioning of components\nin microkernel architecture, 161\nin microservices architecture, 249\nin orchestration-driven service-oriented\narchitecture, 242\nin space-based architecture, 234\nSilicon Sandwiches case study, domain and\ntechnical partitioning, 271\npeople skills, 357-360\nperformance\nas an architecture characteristic, 58, 73\ndomain concerns translated to architecture\ncharacteristics, 67\nin Going, Going, Gone case study, 96\nmultiple, nuanced definitions of, 78\noperational measures of, 78\nperformance efficiency, defined, 61\n394 \n| \nIndex\n", "page": 414, "type": "text", "section": "Page 414"}
{"text": "rating in event-driven architecture, 209\nrating in layered architecture, 141\nrating in microkernel architecture, 161\nrating in microservices arhitecture, 264\nrating in orchestration-driven service-\noriented architecture, 243\nrating in service-based architecture, 233\ntrade-offs with security, 63\npersistence\nin component-based thinking, 103\npersistence layer, 104\nperson's network of contact between people,\n371\nphysical topology variants in layered architec\u2010\nture, 134\npipeline architecture, 143-148\narchitecture characteristics ratings, 146\nexample, 145-146\nself-assessment questions, 376\ntopology, 143\npipes and filters architecture (see pipeline\narchitecture)\npipes in pipeline architecture, 143\nplug-in components, microkernel architecture,\n153-157\nin Silicon Sandwiches case study, 273\nplus (+) and minus (\u2212) sign indicating risk\ndirection, 300\nPMD, 158\npoint-to-point plug-in components in micro\u2010\nkernel architecture, 154\npolitics, understanding and navigating, 12\nportability\nas structural architecture characteristic, 59\ndefined, 62\npragmatic, being, 355\npresentation layer in core system of microker\u2010\nnel architecture, 152\nPresentation Patterns (Ford et al.), 321\npresentations versus infodecks, 324\npresenting architecture, 315\n(see also diagramming and presenting\narchitecture)\nprivacy, 59\nprocess loss, 335\nprocess measures for architectural characteris\u2010\ntics, 81\nprocessing event, 181, 186\nprocessing grid, 218\nprocessing units, 213\ncontaining same named cache, data colli\u2010\nsions and, 226\ndata readers and, 223\ndata replication within, 217\ndata writers and, 221\nflexibility of, 234\nloss of, 218\nproducer filters, 144\nproof-of-concepts (POCs), 35\nprotocol-aware heterogeneous interoperability,\n254\nPryce, Nat, 285\npseudosynchronous communications, 204\npublish/subscribe messaging model in broker\ntoplogy of event-driven architecture, 181\nQ\nquantum, 92\n(see also architecture quantum)\nqueues and topics, trade-offs between, 33\nR\nradar for personal use, developing, 367-371\nopen source visualization bits, 371\nThoughtWorks Technology Radar, 368\nrandom replacement eviction policy in front\ncache, 230\nReact framework, 254\nrecoverability, 58\nItaly-ility and, 60\nperformance and, 67\nreliability and, 61\nregistry for plug-ins in microkernel architec\u2010\nture, 157\nreliability, 57, 58\navailability versus, 60\ndefined, 61\nin Going, Going, Gone case study, 97\nin Going, Going, Gone: discovering comm\u2010\nponents case study, 114\nimplicit architecture characteristic, 73\nin service-based architecture, 176\nin layered architecture, 141\nperformance and, 67\nrating in microkernel architecture, 161\nrating in microservices architecture, 263\nrating in pipeline architecture, 148\nremote access\nIndex \n| \n395\n", "page": 415, "type": "text", "section": "Page 415"}
{"text": "plug-ins in microkernel architecture, 155\nservices in service-based architecture, 164\nreplaceability, 62\nreplication\nreplicated vs. distributed caching in space-\nbased architecture, 227-230\nvarying latency in space-based architecture,\n225\nreplication unit in processing unit, 213\nrepresentational consistency, 315\nrequest orchestrator, 179\nrequest processors, 179\nrequest-based model (applications), 179\nchoosing between event-based and, 206\nscaling to meet increased loads in web\napplications, 211\nrequest-reply messaging in event-driven archi\u2010\ntecture, 204\nrequirements\nassigning to components, 109\nextracting architecture concerns from,\n67-69\nresilience, 60\nresource utilization, 61\nresponsibility, diffusion of, 337\nREST\naccess to services in service-based architec\u2010\nture via, 164\nremote plug-in access via, 155\nrestructuring of components, 109\nreusability, 62\nreuse and coupling, 246\noperational reuse in microservices architec\u2010\nture, 250\nin orchestration-driven service-oriented\narchitecture, 239-241\nRichards, Mark, 74\nrisk (architecture), analyzing (see architecture\nrisk, analyzing)\nrisk assessments (for architecture risk), 298\nrisk matrix (for architecture risk), 297\nrisk storming, 302-308\nconsensus activity, 304\nexamples, 308-314\navailability of nurse diagnostics system,\n310\nelasticity of nurse diagnostics system,\n312\nnurse diagnostics system, 308\nidentifying areas of risk, 303\nmitigation of risk, 307\nprimary activities in, 303\nrobustness, 58\nroles and responsibilities, analyzing for compo\u2010\nnents, 109\nRoosevelt, Theodore, 363\nRuby on Rails, mappings from website to data\u2010\nbase, 111\nS\nsagas (transactional), 132\nsaga pattern in microservices, 261\nscalability, 58\nelasticity versus, 70\nin Going, Going, Gone case study, 96\nlimits for web-based topologies, 211\nlow rating in layered architecture, 141\nlow rating in microkenel architecture, 160\nlow rating in pipeline architecture, 148\nperformance and, 67\nrating in event-driven architecture, 209\nrating in microservices arhitecture, 264\nrating in orchestration-driven service-\noriented architecture, 243\nrating in service-based architecture, 176\nrating in space-based architecture, 233\nsolving issues with space-based architecture,\n212\nscale, 13\nelastic, 14\nSchutta, Nathaniel, 321\nSecond Law of Software Architecture, 19\nsecurity, 57\nconsideration as architecture characteristic,\n73\nin cross-cutting architectural characteristics,\n59\ndefined, 61\nin Going, Going, Gone case study, 96\nrisks in nurse diagnostics system example,\n313\ntrade-offs with performance, 63\nSecurity Monkey, 88\nself-assessment questions, 373-381\nseparation of concerns, 135\nseparation of technical concerns, 104\nserialization in Java, 123\nservice discovery, 252\n396 \n| \nIndex\n", "page": 416, "type": "text", "section": "Page 416"}
{"text": "Service Info Capture filter, 146\nservice locator pattern, 164\nservice meshes, 251\nservice plane in microservices, 251\nservice-based architecture, 163-177\narchitecture characteristics ratings, 174\nexample, 172-173\nself-assessment questions, 377\nservice design and granularity, 167-169\ntopology, 163\ntopology variants, 165-167\nuse cases, 177\nservices, 100\nadding new services layer to architecture,\n137\ndecoupling in microservices architecture,\n247\ngranularity for, in microservices, 248\nin microkernel architecture core system,\n151\nin microservices implementation of Going,\nGoing, Gone, 276\nrisk assessment based on, 299\nin service-based architecture style, 163\nservice instances using named cache in\nspace-based architecture, 217\ndata collisions and, 225\nservice layer, 104\nshapes in diagrams, 320\nshells, use with pipeline architecture, 144\nsidecar pattern, 250\nSilicon Sandwiches case study, 69-74\nimplicit architecture characteristics, 73\nmonolithic architectures, 271-274\nSilicon Sandwiches partitioning case study,\n105-107\ndomain partitioning, 107\nSimian Army, 88\norigin of, 88\nsimplicity\nin event-driven architecture, 209\nin layered architecture, 140\nin microkernel architecture, 160\nin orchestration-driven service-oriented\narchitecture, 243\nin pipeline architecture, 147\nin service-based architecture, 176\nin space-based architecture, 234\nslides in presentations, 324\nsocial media, using, 371\nsoftware architects, 1\nboundary types created for development\nteams, 325\ndeveloping a career path, 365-372\ndeveloping a personal radar, 367-371\nparting advice, 372\ntwenty-minute rule, 365-367\nusing social media, 371\nexpectations of, 8-13\nintegration with development team, 360-363\nleadership skills, 353-360\nbeing pragmatic, yet visionary, 355\nC's of architecture, 353\nleading teams by example, 357-360\nlevel of control on development teams,\n331-335\nleveraging checklists for development\nteams, 338-343\nmaking development teams effective, sum\u2010\nmary of important points, 346\nnegotiation and facilitation skills, 347-353\nnegotiating with business stakeholders,\n348\nnegotiating with developers, 351\nnegotiating with other architects, 350\nobserving development team warning signs,\n335-338\npersonality types, 326-331\narmchair architects, 328\ncontrol freak, 327\neffective architects, 330\nproviding guidance to development teams,\n343-346\nrole in components, 101-107\nsoftware architecture\nabout, 3-7\ndynamic nature of, 2\nemerging standards for diagramming, 293\nintersection with other departments, 13\ndata, 19\nengineering practices, 14\noperations/DevOps, 17\nsoftware development process, 18\nintroduction to, self-assessment questions,\n373\nlack of clear definitions in, 63\nlaws of, 19\nsoftware development\nIndex \n| \n397\n", "page": 417, "type": "text", "section": "Page 417"}
{"text": "changes in the ecosystem, 267\ndevelopment process and software architec\u2010\nture, 18\nsoftware release checklist, 342\nspace-based architecture, 211-234\nadvantages of, 212\narchitecture characteristics ratings, 233\ncloud vs. on-premises implementations, 226\ndata collisions, 224-226\ngeneral topology, 212\ndata pumps, 219\ndata readers, 222\ndata writers, 221\nprocessing unit, 213\nvirtualized middleware, 214-219\nimplementation examples, 231-232\nconcert ticketing system, 231\nonline auction system, 232\nnear-cache, considerations with, 230\nreplicated vs. distributed caching in,\n227-230\nself-assessment questions, 378\nSpring Integration, 186\nstamp coupling, 126\nstandards, using ADRS for, 293\nstatic connascence, 92\nstatus of an ADR, 286\nstencils/templates, drawing tools supporting,\n317\nstrangler pattern, 18\nstrategic positioning, justification for architec\u2010\nture decisions, 283\nstrategy pattern, 12\nstructural architecture characteristics, 59\nstructural measures of architectural characteris\u2010\ntics, 79, 81\nstructure of the system, 5\nstructure, architecturally significant decisions\nimpacting, 284\nstructured programming languages, 38\nSun Tzu, 350\nsupportability, 59, 60\nSwedish warship (Vasa) case study, 66\nsynchronous comunication, 254, 270\nin microservices implementation of Going,\nGoing, Gone, 276\nsynchronous send in event-driven architec\u2010\nture, 201\nsynchronous connascence, 92, 93\nsystem level, architecture characteristics at, 91\nT\nteams, making effective (see development\nteams, making effective)\ntechnical and business justifications for archi\u2010\ntecture decisions, 282, 343\ntechnical breadth, 25-30\ntechnical debt, tackling, 35\ntechnical decisions versus architecture deci\u2010\nsions, 284\ntechnical knowledge, solving technical issues\nand, 357\ntechnical partitioning (components)\ndomain partitioning versus, 249\nin event-driven architecture, 208\nin microkernel architecture, 161\nin orchestration-driven service-oriented\narchitecture, 241\nin pipeline architecture, 146\nin layered architecture, 135\nin Silicon Sandwiches monolithic architec\u2010\ntures case study, 271\nin Silicon Sandwiches patitioning case\nstudy, 107\ntechnical top-level partitioning, 103\ntechnology bubbles, 367\ntechnology changes, impact on architecture\nstyles, 268\nTechnology Radar (see ThoughtWorks Tech\u2010\nnology Radar)\nTemplate Method design pattern, 74\ntemporary queues, 205\ntest-driven development (TDD), resulting in\nless complex code, 81\ntestability\nlow rating in layered architecture, 140\nprocess measures of, 81\nrating in event-driven architecture, 209\nrating in microkernel architecture, 161, 263\nrating in orchestration-driven service-\noriented architecture, 242\nrating in pipeline architecture, 147\nrating in service-based architecture, 176\nrating in space-based architecture, 234\ntester filters, 144\ntesting\nrating in space-based architecture, 234\nunit and functional testing checklist, 341\n398 \n| \nIndex\n", "page": 418, "type": "text", "section": "Page 418"}
{"text": "ThoughtWorks Build Your Own Radar tool,\n371\nThoughtWorks Technology Radar, 366,\n367-371\nthree-tier architecture, 122\nlanguage design and long-term implica\u2010\ntions, 123\ntime and budget, translation to architecture\ncharacteristics, 67\ntime behavior, 61\ntime to market\nagility versus, 67\njustification for architecture decisions, 283\ntranslation to architecture characteristics, 67\ntimeouts, 124\ntitles in diagrams, 319\ntop-level partitioning in an architecture, 102\ndomain partitioning, 104\ntopics and queues, trade-offs between, 33\ntopology (network), changes in, 128\ntrade-offs in software architecture, 19, 372\nanalyzing, 30\narchitecture characteristics and least worst\narchitecture, 63\ndesign versus, 74\nreuse and coupling, 246\ntransactional sagas, 132\ntransactions\nACID or BASE, 168\nacross boundaries in microservices, not rec\u2010\nommended, 247\nand bounded contexts in microservices, 248\ndifficulty of distributed transactions, 243\ndistributed, 132\nin orchestration-driven service-oriented\narchitecture, 238\nin service-based architecture, 177\nlack of ability to restart in broker toplogy of\nevent-driven architecture, 185\nand sagas in microservices' communication,\n260-263\ntransfomer filters, 144\ntransitions from presentation tools, 321\ntransport cost in distributed computing, 130\ntraveling salesperson problem, 83\ntuple space, 212\ntwenty-minute rule, 365-367\ntwo-tier architecture, 121\nU\nubiquitous language, use of, 63\nUnified Modeling Language (UML), 318\nunitary architecture, 121\nunknown unknowns in software systems, 15\nunplanned downtime, 349\nupgradeability, 59\nUptime Calculator transformer filter, 146\nUptime filter (tester filter), 146\nusability\narchitecture characteristics and, 73\ndefined, 61\nusability/achievability, 60\nuser error protection, 61\nuser interfaces (UIs)\naccess to services in service-based architec\u2010\nture via, 164\nas part of bounded context in DDD, 253\nin distributed architecture Going, Going,\nGone case study, 275\nmicroservices with monolithic UI, 253\nseparate UI in microkernel architecture, 152\nvariants in service-based architecture, 165\nuser satisfaction\njustification for architecture decisions, 283\ntranslation to arcitecture characteristics, 67\nV\nvalue-driven messages, 220\nvariance, 7\nVasa case study, 66\nvirtualized middleware, 213, 214-219\ndata grid, 215\ndeployment manager, 219\nmessaging grid, 214\nprocessing grid, 218\nvisionary, being, 355\nW\nweb applications, scaling to meet increased\nloads, 211\nweb browsers, using microkernel architecture,\n158\nweb servers\nand browser architecture, 122\nscaling, problems with, 211\nWeinberg, Gerald, 357\nIndex \n| \n399\n", "page": 419, "type": "text", "section": "Page 419"}
{"text": "What Every Programmer Should Know About\nObject Oriented Design (Page-Jones), 92\nWhy is more important than How, 19\nWildfly application server, 161\nworkflows\ndatabase relationships incorrectly identified\nas, 111\nin technical and domain-partitioned archi\u2010\ntecture, 104\nworkflow approach to designing compo\u2010\nnents, 112\nworkflow event pattern, 197-200\nworkflow delegate, 197\nworkflow processor, 198\nY\nYoder, Joseph, 120\n400 \n| \nIndex\n", "page": 420, "type": "text", "section": "Page 420"}
{"text": "About the Authors\nMark Richards is an experienced hands-on software architect involved in the archi\u2010\ntecture, design, and implementation of microservices and other distributed architec\u2010\ntures. He is the founder of DeveloperToArchitect.com, a website devoted to assisting\ndevelopers in the journey from developer to a software architect.\nNeal Ford is director, software architect, and meme wrangler at ThoughtWorks, a\nglobal IT consultancy with an exclusive focus on end-to-end software development\nand delivery. Before joining ThoughtWorks, Neal was the chief technology officer at\nThe DSW Group, Ltd., a nationally recognized training and development firm.\nColophon\nThe animal on the cover of Fundamentals of Software Engineering is the red-fan par\u2010\nrot (Deroptyus accipitrinus), a native to South America where it is known by several\nnames such as loro cacique in Spanish, or anac\u00e3, papagaio-de-coleira, and vanaqui\u00e1 in\nPortugese. This New World bird makes its home up in the canopies and tree holes of\nthe Amazon rainforest, where it feeds on the fruits of the Cecropia tree, aptly known\nas \u201csnake fingers,\u201d as well as the hard fruits of various palm trees.\nAs the only member of the genus Deroptyus, the red-fan parrot is distinguished by\nthe deep red feathers that cover its nape. Its name comes from the fact that those\nfeathers will \u201cfan\u201d out when it feels excited or threatened and reveal the brilliant blue\nthat highlights each tip. The head is topped by a white crown and yellow eyes, with\nbrown cheeks that are streaked in white. The parrot\u2019s breast and belly are covered in\nthe same red feathers dipped in blue, in contrast with the layered bright green feath\u2010\ners on its back.\nBetween December and January, the red-fan parrot will find its lifelong mate and\nthen begin laying 2-4 eggs a year. During the 28 days in which the female is incubat\u2010\ning the eggs, the male will provide her with care and support. After about 10 weeks,\nthe young are ready to start fledging in the wild and begin their 40-year life span in\nthe world\u2019s largest tropical rainforest.\nWhile the red-fan parrot\u2019s current conservation status is designated as of Least Con\u2010\ncern, many of the animals on O\u2019Reilly covers are endangered; all of them are impor\u2010\ntant to the world.\nThe cover illustration is by Karen Montgomery, based on a black and white engraving\nfrom Lydekker\u2019s Royal Natural History. The cover fonts are Gilroy Semibold and\nGuardian Sans. The text font is Adobe Minion Pro; the heading font is Adobe Myriad\nCondensed; and the code font is Dalton Maag\u2019s Ubuntu Mono.\n", "page": 421, "type": "text", "section": "Page 421"}
{"text": "There\u2019s much more  \nwhere this came from.\nExperience books, videos, live online  \ntraining courses, and more from O\u2019Reilly  \nand our 200+ partners\u2014all in one place.\nLearn more at oreilly.com/online-learning\n\u00a92019 O\u2019Reilly Media, Inc. O\u2019Reilly is a registered trademark of O\u2019Reilly Media, Inc. | 175\n", "page": 422, "type": "text", "section": "Page 422"}
