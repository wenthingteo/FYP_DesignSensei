{"text": "www.EBooksWorld.ir\n", "page": 1, "type": "text", "section": "Page 1"}
{"text": "Praise for Implementing Domain-Driven Design\n\u201cWith Implementing Domain-Driven Design, Vaughn has made an important con-\ntribution not only to the literature of the Domain-Driven Design community, but also \nto the literature of the broader enterprise application architecture field. In key chap-\nters on Architecture and Repositories, for example, Vaughn shows how DDD fits with \nthe expanding array of architecture styles and persistence technologies for enterprise \napplications\u2014including SOA and REST, NoSQL and data grids\u2014that has emerged in \nthe decade since Eric Evans\u2019 seminal book was first published. And, fittingly, Vaughn \nilluminates the blocking and tackling of DDD\u2014the implementation of entities, value \nobjects, aggregates, services, events, factories, and repositories\u2014with plentiful exam-\nples and valuable insights drawn from decades of practical experience. In a word, I \nwould describe this book as thorough. For software developers of all experience levels \nlooking to improve their results, and design and implement domain-driven enterprise \napplications consistently with the best current state of professional practice, Imple-\nmenting Domain-Driven Design will impart a treasure trove of knowledge hard won \nwithin the DDD and enterprise application architecture communities over the last cou-\nple decades.\u201d\n\u2014Randy Stafford, Architect At-Large, Oracle Coherence Product Development\n\u201cDomain-Driven Design is a powerful set of thinking tools that can have a profound \nimpact on how effective a team can be at building software-intensive systems. The \nthing is that many developers got lost at times when applying these thinking tools and \nreally needed more concrete guidance. In this book, Vaughn provides the missing links \nbetween theory and practice. In addition to shedding light on many of the misunder-\nstood elements of DDD, Vaughn also connects new concepts like Command/Query \nResponsibility Segregation and Event Sourcing that many advanced DDD practitioners \nhave used with great success. This book is a must-read for anybody looking to put \nDDD into practice.\u201d\n\u2014Udi Dahan, Founder of NServiceBus\n\u201cFor years, developers struggling to practice Domain-Driven Design have been wishing \nfor more practical help in actually implementing DDD. Vaughn did an excellent job in \nclosing the gap between theory and practice with a complete implementation reference. \nHe paints a vivid picture of what it is like to do DDD in a contemporary project, and \nprovides plenty of practical advice on how to approach and solve typical challenges \noccurring in a project life cycle.\u201d\n\u2014Alberto Brandolini, DDD Instructor, Certified by Eric Evans and \nDomain Language, Inc.\n\u201cImplementing Domain-Driven Design does a remarkable thing: it takes a sophisti-\ncated and substantial topic area in DDD and presents it clearly, with nuance, fun and \nfinesse. This book is written in an engaging and friendly style, like a trusted advisor \ngiving you expert counsel on how to accomplish what is most important. By the time \nyou finish the book you will be able to begin applying all the important concepts of \nwww.EBooksWorld.ir\n", "page": 2, "type": "text", "section": "Page 2"}
{"text": "DDD, and then some. As I read, I found myself highlighting many sections . . . I will be \nreferring back to it, and recommending it, often.\u201d\n\u2014Paul Rayner, Principal Consultant & Owner, Virtual Genius, LLC., DDD Instruc-\ntor, Certified by Eric Evans and Domain Language, Inc., DDD Denver Founder and \nCo-leader\n\u201cOne important part of the DDD classes I teach is discussing how to put all the ideas \nand pieces together into a full blown working implementation. With this book, the \nDDD community now has a comprehensive reference that addresses this in detail. \nImplementing Domain-Driven Design deals with all aspects of building a system using \nDDD, from getting the small details right to keeping track of the big picture. This is a \ngreat reference and an excellent companion to Eric Evans seminal DDD book.\u201d\n\u2014Patrik Fredriksson, DDD Instructor, Certified by Eric Evans and \nDomain Language, Inc.\n\u201cIf you care about software craftsmanship\u2014and you should\u2014then Domain-Driven \nDesign is a crucial skill set to master and Implementing Domain-Driven Design is the \nfast path to success. IDDD offers a highly readable yet rigorous discussion of DDD\u2019s \nstrategic and tactical patterns that enables developers to move immediately from under-\nstanding to action. Tomorrow\u2019s business software will benefit from the clear guidance \nprovided by this book.\u201d\n\u2014Dave Muirhead, Principal Consultant, Blue River Systems Group\n\u201cThere\u2019s theory and practice around DDD that every developer needs to know, and this \nis the missing piece of the puzzle that puts it all together. Highly recommended!\u201d\n\u2014Rickard \u00d6berg, Java Champion and Developer at Neo Technology\n\u201cIn IDDD, Vaughn takes a top-down approach to DDD, bringing strategic patterns \nsuch as bounded context and context maps to the fore, with the building block patterns \nof entities, values and services tackled later. His book uses a case study throughout, \nand to get the most out of it you\u2019ll need to spend time grokking that case study. But if \nyou do you\u2019ll be able to see the value of applying DDD to a complex domain; the fre-\nquent sidenotes, diagrams, tables, and code all help illustrate the main points. So if you \nwant to build a solid DDD system employing the architectural styles most commonly in \nuse today, Vaughn\u2019s book comes recommended.\u201d\n\u2014Dan Haywood, author of Domain-Driven Design with Naked Objects\n\u201cThis book employs a top-down approach to understanding DDD in a way that fluently \nconnects strategic patterns to lower level tactical constraints. Theory is coupled with \nguided approaches to implementation within modern architectural styles. Throughout \nthe book, Vaughn highlights the importance and value of focusing on the business \ndomain all while balancing technical considerations. As a result, the role of DDD, as \nwell as what it does and perhaps more importantly doesn\u2019t imply, become ostensibly \nclear. Many a time, my team and I would be at odds with the friction encountered in \napplying DDD. With Implementing Domain-Driven Design as our luminous guide we \nwere able to overcome those challenges and translate our efforts into immediate busi-\nness value.\u201d\n\u2014Lev Gorodinski, Principal Architect, DrillSpot.com\nwww.EBooksWorld.ir\n", "page": 3, "type": "text", "section": "Page 3"}
{"text": "Implementing \nDomain-Driven Design\nwww.EBooksWorld.ir\n", "page": 4, "type": "text", "section": "Page 4"}
{"text": "This page intentionally left blank \nwww.EBooksWorld.ir\n", "page": 5, "type": "text", "section": "Page 5"}
{"text": "Implementing \nDomain-Driven \nDesign\nVaughn Vernon\nUpper Saddle River, NJ \u2022 Boston \u2022 Indianapolis \u2022 San Francisco\nNew York \u2022 Toronto \u2022 Montreal \u2022 London \u2022 Munich \u2022 Paris \u2022 Madrid\nCapetown \u2022 Sydney \u2022 Tokyo \u2022 Singapore \u2022 Mexico City\nwww.EBooksWorld.ir\n", "page": 6, "type": "text", "section": "Page 6"}
{"text": "Many of the designations used by manufacturers and sellers to distinguish their products are \nclaimed as trademarks. Where those designations appear in this book, and the publisher was \naware of a trademark claim, the designations have been printed with initial capital letters or in \nall capitals.\nThe author and publisher have taken care in the preparation of this book, but make no expressed \nor implied warranty of any kind and assume no responsibility for errors or omissions. No liabil-\nity is assumed for incidental or consequential damages in connection with or arising out of the \nuse of the information or programs contained herein.\nThe publisher offers excellent discounts on this book when ordered in quantity for bulk pur-\nchases or special sales, which may include electronic versions and/or custom covers and content \nparticular to your business, training goals, marketing focus, and branding interests. For more \ninformation, please contact:\nU.S. Corporate and Government Sales\n(800) 382-3419\ncorpsales@pearsontechgroup.com\nFor sales outside the United States, please contact:\nInternational Sales\ninternational@pearsoned.com\nVisit us on the Web: informit.com/aw\nLibrary of Congress Control Number: 2012954071\nCopyright \u00a9 2013 Pearson Education, Inc.\nAll rights reserved. Printed in the United States of America. This publication is protected by \ncopyright, and permission must be obtained from the publisher prior to any prohibited repro-\nduction, storage in a retrieval system, or transmission in any form or by any means, electronic, \nmechanical, photocopying, recording, or likewise. To obtain permission to use material from \nthis work, please submit a written request to Pearson Education, Inc., Permissions Department, \nOne Lake Street, Upper Saddle River, New Jersey 07458, or you may fax your request to (201) \n236-3290.\nISBN-13: 978-0-321-83457-7\nISBN-10: \n0-321-83457-7\nText printed in the United States on recycled paper at Courier in Westford, Massachusetts.\nSecond printing, July 2013\nwww.EBooksWorld.ir\n", "page": 7, "type": "text", "section": "Page 7"}
{"text": "This book is dedicated to my dearest Nicole and Tristan. \nThanks for your love, your support, and your patience. \nwww.EBooksWorld.ir\n", "page": 8, "type": "text", "section": "Page 8"}
{"text": "This page intentionally left blank \nwww.EBooksWorld.ir\n", "page": 9, "type": "text", "section": "Page 9"}
{"text": "ix\nContents\nForeword .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  xvii\nPreface   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   xix\nAcknowledgments.  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . xxix\nAbout the Author .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  xxxiii\nGuide to This Book .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . xxxv\nChapter 1 Getting Started with DDD   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   1\nCan I DDD? \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   2\nWhy You Should Do DDD .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   6\nHow to Do DDD .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  20\nThe Business Value of Using DDD .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  25\n1. The Organization Gains a Useful Model of Its Domain   .  .  .  26\n2. A Refined, Precise Definition and Understanding of the \nBusiness Is Developed  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  27\n3. Domain Experts Contribute to Software Design  .  .  .  .  .  .  .  27\n4. A Better User Experience Is Gained  .  .  .  .  .  .  .  .  .  .  .  .  .  27\n5. Clean Boundaries Are Placed around Pure Models .  .  .  .  .  .  28\n6. Enterprise Architecture Is Better Organized \n  .  .  .  .  .  .  .  .  .  28\n7. Agile, Iterative, Continuous Modeling Is Used \n  .  .  .  .  .  .  .  .  28\n8. New Tools, Both Strategic and Tactical, Are Employed  .  .  .  28\nThe Challenges of Applying DDD \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  29\nFiction, with Bucketfuls of Reality .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  38\nWrap-Up .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  41\nwww.EBooksWorld.ir\n", "page": 10, "type": "text", "section": "Page 10"}
{"text": "CONTENTS\nx\nChapter 2 Domains, Subdomains, and Bounded Contexts  .  .  .  .  .  .  .  .  43\nBig Picture  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  43\nSubdomains and Bounded Contexts at Work  .  .  .  .  .  .  .  .  .  . 44\nFocus on the Core Domain \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  50\nWhy Strategic Design Is So Incredibly Essential \n  .  .  .  .  .  .  .  .  .  .  53\nReal-World Domains and Subdomains .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  56\nMaking Sense of Bounded Contexts  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  62\nRoom for More than the Model .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  66\nSize of Bounded Contexts .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  68\nAligning with Technical Components  \n  .  .  .  .  .  .  .  .  .  .  .  .  .  71\nSample Contexts  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  72\nCollaboration Context.  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  73\nIdentity and Access Context .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  80\nAgile Project Management Context .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  82\nWrap-Up .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  84\nChapter 3 Context Maps  \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  87\nWhy Context Maps Are So Essential  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  87\nDrawing Context Maps .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  89\nProjects and Organizational Relationships   .  .  .  .  .  .  .  .  .  .  .  91\nMapping the Three Contexts \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  95\nWrap-Up .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  111\nChapter 4 Architecture .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  113\nInterviewing the Successful CIO .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  114\nLayers   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  119\nDependency Inversion Principle .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  123\nHexagonal or Ports and Adapters   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  125\nService-Oriented  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  130\nRepresentational State Transfer\u2014REST  .  .  .  .  .  .  .  .  .  .  .  .  .  133\nREST as an Architectural Style  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  133\nKey Aspects of a RESTful HTTP Server  .  .  .  .  .  .  .  .  .  .  .  135\nKey Aspects of a RESTful HTTP Client  .  .  .  .  .  .  .  .  .  .  .  136\nREST and DDD .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  136\nWhy REST? .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  138\nwww.EBooksWorld.ir\n", "page": 11, "type": "text", "section": "Page 11"}
{"text": " \nCONTENTS\nxi\nCommand-Query Responsibility Segregation, or CQRS .  .  .  .  .  138\nExamining Areas of CQRS \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  140\nDealing with an Eventually Consistent Query Model .  .  .  .  .  146\nEvent-Driven Architecture  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  147\nPipes and Filters .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  149\nLong-Running Processes, aka Sagas    .  .  .  .  .  .  .  .  .  .  .  .  .  153\nEvent Sourcing  \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  160\nData Fabric and Grid-Based Distributed Computing    .  .  .  .  .  .  163\nData Replication  \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  164\nEvent-Driven Fabrics and Domain Events .  .  .  .  .  .  .  .  .  .  .  165\nContinuous Queries .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  166\nDistributed Processing  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  167\nWrap-Up .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  168\nChapter 5 Entities   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 171\nWhy We Use Entities .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  171\nUnique Identity .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  173\nUser Provides Identity .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  174\nApplication Generates Identity   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  175\nPersistence Mechanism Generates Identity   .  .  .  .  .  .  .  .  .  .  179\nAnother Bounded Context Assigns Identity .  .  .  .  .  .  .  .  .  .  182\nWhen the Timing of Identity Generation Matters .  .  .  .  .  .  .  184\nSurrogate Identity .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  186\nIdentity Stability .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  188\nDiscovering Entities and Their Intrinsic Characteristics  .  .  .  .  .  191\nUncovering Entities and Properties \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  192\nDigging for Essential Behavior   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  196\nRoles and Responsibilities    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  200\nConstruction   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  205\nValidation .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  208\nChange Tracking   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  216\nWrap-Up .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  217\nChapter 6 Value Objects  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 219\nValue Characteristics .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  221\nMeasures, Quantifies, or Describes  .  .  .  .  .  .  .  .  .  .  .  .  .  .  221\nImmutable .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  221\nwww.EBooksWorld.ir\n", "page": 12, "type": "text", "section": "Page 12"}
{"text": "CONTENTS\nxii\nConceptual Whole  \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  223\nReplaceability .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  226\nValue Equality .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   227\nSide-Effect-Free Behavior \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  228\nIntegrate with Minimalism .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   232\nStandard Types Expressed as Values .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  234\nTesting Value Objects   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   239\nImplementation.  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   243\nPersisting Value Objects \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   248\nReject Undue Influence of Data Model Leakage.  .  .  .  .  .  .  .   249\nORM and Single Value Objects .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   251\nORM and Many Values Serialized into a Single Column  .  .  .   253\nORM and Many Values Backed by a Database Entity.  .  .  .  .   255\nORM and Many Values Backed by a Join Table.  .  .  .  .  .  .  .   260\nORM and Enum-as-State Objects .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   261\nWrap-Up .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   263\nChapter 7 Services  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   265\nWhat a Domain Service Is (but First, What It Is Not) \n  .  .  .  .  .  .   267\nMake Sure You Need a Service .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   268\nModeling a Service in the Domain .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   272\nIs Separated Interface a Necessity?   .  .  .  .  .  .  .  .  .  .  .  .  .  .   275\nA Calculation Process .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   277\nTransformation Services .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   280\nUsing a Mini-Layer of Domain Services    .  .  .  .  .  .  .  .  .  .  .   281\nTesting Services.  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   281\nWrap-Up .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   284\nChapter 8 Domain Events   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   285\nThe When and Why of Domain Events  \n  .  .  .  .  .  .  .  .  .  .  .  .  .   285\nModeling Events  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   288\nWith Aggregate Characteristics  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   294\nIdentity   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   295\nPublishing Events from the Domain Model   .  .  .  .  .  .  .  .  .  .  .   296\nPublisher  \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .   297\nSubscribers   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  300\nwww.EBooksWorld.ir\n", "page": 13, "type": "text", "section": "Page 13"}
{"text": " \nCONTENTS\nxiii\nSpreading the News to Remote Bounded Contexts  .  .  .  .  .  .  .  303\nMessaging Infrastructure Consistency  .  .  .  .  .  .  .  .  .  .  .  .  303\nAutonomous Services and Systems  .  .  .  .  .  .  .  .  .  .  .  .  .  .  305\nLatency Tolerances   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  306\nEvent Store .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  307\nArchitectural Styles for Forwarding Stored Events .  .  .  .  .  .  .  .  312\nPublishing Notifications as RESTful Resources .  .  .  .  .  .  .  .  312\nPublishing Notifications through Messaging Middleware  \n  .  .  317\nImplementation  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  318\nPublishing the NotificationLog  .  .  .  .  .  .  .  .  .  .  .  .  .  .  319\nPublishing Message-Based Notifications   .  .  .  .  .  .  .  .  .  .  .  324\nWrap-Up .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  331\nChapter 9 Modules    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  333\nDesigning with Modules .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  333\nBasic Module Naming Conventions \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  336\nModule Naming Conventions for the Model .  .  .  .  .  .  .  .  .  .  .  337\nModules of the Agile Project Management Context  .  .  .  .  .  .  .  340\nModules in Other Layers    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  343\nModule before Bounded Context  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  344\nWrap-Up .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  345\nChapter 10 Aggregates .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  347\nUsing Aggregates in the Scrum Core Domain \n  .  .  .  .  .  .  .  .  .  .  348\nFirst Attempt: Large-Cluster Aggregate .  .  .  .  .  .  .  .  .  .  .  .  349\nSecond Attempt: Multiple Aggregates .  .  .  .  .  .  .  .  .  .  .  .  .  351\nRule: Model True Invariants in Consistency Boundaries .  .  .  .  .  353\nRule: Design Small Aggregates .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  355\nDon\u2019t Trust Every Use Case  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  358\nRule: Reference Other Aggregates by Identity \n  .  .  .  .  .  .  .  .  .  .  359\nMaking Aggregates Work Together through Identity \nReferences   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  361\nModel Navigation .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  362\nScalability and Distribution .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  363\nRule: Use Eventual Consistency Outside the Boundary   .  .  .  .  .  364\nAsk Whose Job It Is .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  366\nwww.EBooksWorld.ir\n", "page": 14, "type": "text", "section": "Page 14"}
{"text": "CONTENTS\nxiv\nReasons to Break the Rules  \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  367\nReason One: User Interface Convenience  .  .  .  .  .  .  .  .  .  .  .  367\nReason Two: Lack of Technical Mechanisms  .  .  .  .  .  .  .  .  .  368\nReason Three: Global Transactions .  .  .  .  .  .  .  .  .  .  .  .  .  .  369\nReason Four: Query Performance .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  369\nAdhering to the Rules .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  370\nGaining Insight through Discovery.  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  370\nRethinking the Design, Again .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  370\nEstimating Aggregate Cost   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  372\nCommon Usage Scenarios    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  373\nMemory Consumption   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  374\nExploring Another Alternative Design  \n  .  .  .  .  .  .  .  .  .  .  .  .  375\nImplementing Eventual Consistency .  .  .  .  .  .  .  .  .  .  .  .  .  .  376\nIs It the Team Member\u2019s Job?  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  378\nTime for Decisions  \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  379\nImplementation  \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  380\nCreate a Root Entity with Unique Identity   .  .  .  .  .  .  .  .  .  .  380\nFavor Value Object Parts   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  382\nUsing Law of Demeter and Tell, Don\u2019t Ask  .  .  .  .  .  .  .  .  .  .  382\nOptimistic Concurrency .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  385\nAvoid Dependency Injection .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  387\nWrap-Up .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  388\nChapter 11 Factories .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  389\nFactories in the Domain Model  \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  389\nFactory Method on Aggregate Root \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  391\nCreating CalendarEntry Instances .  .  .  .  .  .  .  .  .  .  .  .  .  392\nCreating Discussion Instances \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  395\nFactory on Service \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  397\nWrap-Up .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  400\nChapter 12 Repositories \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  401\nCollection-Oriented Repositories  \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  402\nHibernate Implementation  \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  407\nConsiderations for a TopLink Implementation   .  .  .  .  .  .  .  .  416\nwww.EBooksWorld.ir\n", "page": 15, "type": "text", "section": "Page 15"}
{"text": " \nCONTENTS\nxv\nPersistence-Oriented Repositories   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  418\nCoherence Implementation   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  420\nMongoDB Implementation   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  425\nAdditional Behavior \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  430\nManaging Transactions   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  432\nA Warning  \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  437\nType Hierarchies .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  437\nRepository versus Data Access Object  .  .  .  .  .  .  .  .  .  .  .  .  .  .  440\nTesting Repositories \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  441\nTesting with In-Memory Implementations  \n  .  .  .  .  .  .  .  .  .  .  445\nWrap-Up .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  448\nChapter 13 Integrating Bounded Contexts .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  449\nIntegration Basics  \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  450\nDistributed Systems Are Fundamentally Different  \n  .  .  .  .  .  .  451\nExchanging Information across System Boundaries .  .  .  .  .  .  452\nIntegration Using RESTful Resources \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  458\nImplementing the RESTful Resource \n  .  .  .  .  .  .  .  .  .  .  .  .  .  459\nImplementing the REST Client Using an Anticorruption \nLayer  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  463\nIntegration Using Messaging .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  469\nStaying Informed about Product Owners and Team \nMembers  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  469\nCan You Handle the Responsibility?   .  .  .  .  .  .  .  .  .  .  .  .  .  476\nLong-Running Processes, and Avoiding Responsibility  .  .  .  .  481\nProcess State Machines and Time-out Trackers .  .  .  .  .  .  .  .  493\nDesigning a More Sophisticated Process  \n  .  .  .  .  .  .  .  .  .  .  .  503\nWhen Messaging or Your System Is Unavailable   .  .  .  .  .  .  .  507\nWrap-Up .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  508\nChapter 14 Application.  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  509\nUser Interface  \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  512\nRendering Domain Objects  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  512\nRender Data Transfer Object from Aggregate Instances  \n  .  .  .  513\nUse a Mediator to Publish Aggregate Internal State .  .  .  .  .  .  514\nRender Aggregate Instances from a Domain Payload Object \n515\nwww.EBooksWorld.ir\n", "page": 16, "type": "text", "section": "Page 16"}
{"text": "CONTENTS\nxvi\nState Representations of Aggregate Instances .  .  .  .  .  .  .  .  .  516\nUse Case Optimal Repository Queries.  .  .  .  .  .  .  .  .  .  .  .  .  517\nDealing with Multiple, Disparate Clients  .  .  .  .  .  .  .  .  .  .  .  517\nRendition Adapters and Handling User Edits .  .  .  .  .  .  .  .  .  518\nApplication Services \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  521\nSample Application Service \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  522\nDecoupled Service Output    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  528\nComposing Multiple Bounded Contexts  .  .  .  .  .  .  .  .  .  .  .  .  .  531\nInfrastructure   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  532\nEnterprise Component Containers .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  534\nWrap-Up .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  537\nAppendix A Aggregates and Event Sourcing: A+ES   .  .  .  .  .  .  .  .  .  .  .  539\nInside an Application Service    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  541\nCommand Handlers  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  549\nLambda Syntax  \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  553\nConcurrency Control.  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  554\nStructural Freedom with A+ES .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  558\nPerformance \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  558\nImplementing an Event Store .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  561\nRelational Persistence  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  565\nBLOB Persistence    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  568\nFocused Aggregates   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  569\nRead Model Projections   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  570\nUse with Aggregate Design    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  573\nEvents Enrichment  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  573\nSupporting Tools and Patterns .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  576\nEvent Serializers .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  576\nEvent Immutability   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  577\nValue Objects \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  577\nContract Generation  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  580\nUnit Testing and Specifications    .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  582\nEvent Sourcing in Functional Languages .  .  .  .  .  .  .  .  .  .  .  .  .  583\nBibliography   .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  585\nIndex \n  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  589\nwww.EBooksWorld.ir\n", "page": 17, "type": "text", "section": "Page 17"}
{"text": "xvii\nForeword \nIn this new book, Vaughn Vernon presents the whole of Domain-Driven \nDesign (DDD) in a distinctive way, with new explanations of the concepts, \nnew examples, and an original organization of topics. I believe this fresh, alter-\nnative approach will help people grasp the subtleties of DDD, particularly the \nmore abstract ones such as Aggregates and Bounded Contexts. Not only do \ndifferent people prefer different styles\u2014subtle abstractions are hard to absorb \nwithout multiple explanations.\nAlso, the book conveys some of the insights of the past nine years that have \nbeen described in papers and presentations but have not appeared in a book \nbefore now. It places Domain Events alongside Entities and Value Objects as \nthe building blocks of a model. It discusses the Big Ball of Mud and places \nit into the Context Map. It explains the hexagonal architecture, which has \nemerged as a better description of what we do than the layered architecture.\nMy first exposure to the material in this book came almost two years ago \n(although Vaughn had been working on his book for some time by then). At \nthe first DDD Summit, several of us committed to writing about certain topics \nabout which we felt there were fresh things to say or there was a particular \nneed in the community for more specific advice. Vaughn took up the challenge \nof writing about Aggregates, and he followed through with a series of excellent \narticles about Aggregates (which became a chapter in this book). \nThere was also a consensus at the summit that many practitioners would \nbenefit from a more prescriptive treatment of some of the DDD patterns. \nThe honest answer to almost any question in software development is, \u201cIt \ndepends.\u201d That is not very useful to people who want to learn to apply a tech-\nnique, however. A person who is assimilating a new subject needs concrete \nguidance. Rules of thumb don\u2019t have to be right in all cases. They are what \nusually works well or the thing to try first. Through their decisiveness, they \nconvey the philosophy of the approach to solving the problem. Vaughn\u2019s book \nhas a good mix of straightforward advice balanced with a discussion of trade-\noffs that keep it from being simplistic.\nwww.EBooksWorld.ir\n", "page": 18, "type": "text", "section": "Page 18"}
{"text": "FOREWORD\nxviii\nNot only have additional patterns, such as Domain Events, become a main-\nstream part of DDD\u2014people in the field have progressed in learning how to \napply those patterns, not to mention adapting them to newer architectures and \ntechnologies. Nine years after my book, Domain-Driven Design: Tackling \nComplexity in the Heart of Software, was published, there\u2019s actually a lot to \nsay about DDD that is new, and there are new ways to talk about the funda-\nmentals. Vaughn\u2019s book is the most complete explanation yet of those new \ninsights into practicing DDD.\n\u2014Eric Evans\nDomain Language, Inc.\nwww.EBooksWorld.ir\n", "page": 19, "type": "text", "section": "Page 19"}
{"text": "xix\nPreface\n All the calculations show it can\u2019t work. There\u2019s only one thing to do: \nmake it work.\n\u2014Pierre-Georges Lat\u00e9co\u00e8re,\nearly French aviation entrepreneur\nAnd make it work we shall. The Domain-Driven Design approach to software \ndevelopment is far too important to leave any capable developer without clear \ndirections for how to implement it successfully.\nGetting Grounded, Getting Airborne\nWhen I was a kid, my father learned to pilot small airplanes. Often the whole \nfamily would go up flying. Sometimes we flew to another airport for lunch, \nthen returned. When Dad had less time but longed to be in the air, we\u2019d go out, \njust the two of us, and circle the airport doing \u201ctouch-and-goes.\u201d\nWe also took some long trips. For those, we always had a map of the route \nthat Dad had earlier charted. Our job as kids was to help navigate by looking \nout for landmarks below so we could be certain to stay on course. This was \ngreat fun for us because it was a challenge to spot objects so far below that \nexhibited little in the way of identifying details. Actually, I\u2019m sure that Dad \nalways knew where we were. He had all the instruments on the dashboard, \nand he was licensed for instrument flight.\nThe view from the air really changed my perspective. Now and then Dad \nand I would fly over our house in the countryside. At a few hundred feet up, \nthis gave me a context for home that I didn\u2019t have before. As Dad would cruise \nover our house, Mom and my sisters would run out into the yard to wave at \nus. I knew it was them, although I couldn\u2019t look into their eyes. We couldn\u2019t \nwww.EBooksWorld.ir\n", "page": 20, "type": "text", "section": "Page 20"}
{"text": "PREFACE\nxx\nconverse. If I had shouted out the airplane window, they would never have \nheard me. I could see the split-rail fence in the front dividing our property from \nthe road. When on the ground I\u2019d walk across it as if on a balance beam. From \nthe air, it looked like carefully woven twigs. And there was the huge yard that \nI circled row by row on our riding lawn mower every summer. From the air, I \nsaw only a sea of green, not the blades of grass.\nI loved those moments in the air. They are etched in my memory as if Dad \nand I were just taxiing in after landing to tie down for the evening. As much \nas I loved those flights, they sure were no substitute for being on the ground. \nAnd as cool as they were, the touch-and-goes were just too brief to make me \nfeel grounded.\nLanding with Domain-Driven Design\nGetting in touch with Domain-Driven Design (DDD) can be like flight to a \nkid. The view from the air is stunning, but sometimes things look unfamiliar \nenough to prevent us from knowing exactly where we are. Getting from point \nA to point B appears far from realistic. The DDD grownups always seem to \nknow where they are. They\u2019ve long ago plotted a course, and they are com-\npletely in tune with their navigational instruments. A great number of oth-\ners don\u2019t feel grounded. What is needed is the ability to \u201cland and tie down.\u201d \nNext, a map is needed to guide the way from where we are to where we need \nto be.\nIn the book Domain-Driven Design: Tackling Complexity in the Heart of \nSoftware [Evans], Eric Evans brought about what is a timeless work. It is my \nfirm belief that Eric\u2019s work will guide developers in practical ways for decades \nto come. Like other pattern works, it establishes flight far enough above the \nsurface to give a broad vision. Yet, there may be a bit more of a challenge when \nwe need to understand the groundwork involved in implementing DDD, and \nwe usually desire more detailed examples. If only we could land and stay on \nthe surface a bit longer, and even drive home or to some other familiar place.\nPart of my goal is to take you in for a soft landing, secure the aircraft, and \nhelp you get home by way of a well-known surface route. That will help you \nmake sense of implementing DDD, giving you examples that use familiar tools \nand technologies. And since none of us can stay home all the time, I will also \nhelp you venture out onto other paths to explore new terrain, taking you to \nplaces that perhaps you\u2019ve never been before. Sometimes the path will be steep, \nbut given the right tactics, a challenging yet safe ascent is possible. On this \ntrip you\u2019ll learn about alternative architectures and patterns for integrating \nwww.EBooksWorld.ir\n", "page": 21, "type": "text", "section": "Page 21"}
{"text": " \nMAPPING THE TERRAIN AND CHARTING FOR FLIGHT\nxxi\nmultiple domain models. This may expose you to some previously unexplored \nterritory. You will find detailed coverage of strategic modeling with multiple \nintegrations, and you\u2019ll even learn how to develop autonomous services.\nMy goal is to provide a map to help you take both short jaunts and long, \ncomplicated treks, enjoying the surrounding detail, without getting lost or \ninjured along the way.\nMapping the Terrain and Charting for Flight\nIt seems that in software development we are always mapping from one thing \nto another. We map our objects to databases. We map our objects to the user \ninterface and then back again. We map our objects to and from various appli-\ncation representations, including those that can be consumed by other systems \nand applications. With all this mapping, it\u2019s natural to want a map from the \nhigher-level patterns of Evans to implementation.\nEven if you have already landed a few times with DDD, there is probably \nmore to benefit from. Sometimes DDD is first embraced as a technical tool set. \nSome refer to this approach to DDD as DDD-Lite. We may have homed in on \nEntities, Services, possibly made a brave attempt at designing Aggregates, and \ntried to manage their persistence using Repositories. Those patterns felt a bit \nlike familiar ground, so we put them to use. We may even have found some use \nfor Value Objects along the way. All of these fall within the catalog of tacti-\ncal design patterns, which are more technical. They help us take on a serious \nsoftware problem with the skill of a surgeon with a scalpel. Still, there is much \nto learn about these and other places to go with tactical design as well. I map \nthem to implementation.\nHave you traveled beyond tactical modeling? Have you visited and even lin-\ngered with what some call the \u201cother half\u201d of DDD, the strategic design pat-\nterns? If you\u2019ve left out the use of Bounded Context and Context Maps, you \nhave probably also missed out on the use of the Ubiquitous Language.\nIf there is a single \u201cinvention\u201d Evans delivers to the software development \ncommunity, it is the Ubiquitous Language. At a minimum he brought the Ubiq-\nuitous Language out of the dusty archives of design wisdom. It is a team pat-\ntern used to capture the concepts and terms of a specific core business domain \nin the software model itself. The software model incorporates the nouns, adjec-\ntives, verbs, and richer expressions formally spoken by the development team, \na team that includes one or more business domain experts. It would be a mis-\ntake, however, to conclude that the Language is limited to mere words. Just as \nany human language reflects the minds of those who speak it, the Ubiquitous \nwww.EBooksWorld.ir\n", "page": 22, "type": "text", "section": "Page 22"}
{"text": "PREFACE\nxxii\nLanguage reflects the mental model of the experts of the business domain you \nare working in. Thus, the software and the tests that verify the model\u2019s adher-\nence to the tenets of the domain both capture and adhere to this Language, the \nsame conceived and spoken by the team. The Language is equally as valuable \nas the various strategic and tactical modeling patterns and in some cases has a \nmore enduring quality.\nSimply stated, practicing DDD-Lite leads to the construction of inferior \ndomain models. That\u2019s because the Ubiquitous Language, Bounded Context, \nand Context Mapping have so much to offer. You get more than a team lingo. \nThe Language of a team in an explicit Bounded Context expressed as a domain \nmodel adds true business value and gives us certainty that we are implement-\ning the correct software. Even from a technical standpoint, it helps us create \nbetter models, ones with more potent behaviors, that are pure and less error \nprone. Thus, I map the strategic design patterns to understandable example \nimplementations.\nThis book maps the terrain of DDD in a way that allows you to experience \nthe benefits of both strategic and tactical design. It puts you in touch with its \nbusiness value and technical strengths by peering closely at the details.\nIt would be a disappointment if all we ever did with DDD is stay on the \nground. Getting stuck in the details, we\u2019d forget that the view from flight \nteaches us a lot, too. Don\u2019t limit yourself to rugged ground travel. Brave the \nchallenge of getting in the pilot\u2019s seat and see from a height that is telling. With \ntraining flights on strategic design, with its Bounded Contexts and Context \nMaps, you will be prepared to gain a grander perspective on its full realization. \nWhen you reward yourself with DDD flight, I will have reached my goal.\nSummary of Chapters\nThe following highlights the chapters of this book and how you can benefit \nfrom each one.\nChapter 1: Getting Started with DDD\nThis chapter introduces you to the benefits of using DDD and how to achieve \nthe most from it. You will learn what DDD can do for your projects and your \nteams as you grapple with complexity. You\u2019ll find out how to score your proj-\nect to see if it deserves the DDD investment. You will consider the common \nalternatives to DDD and why they often lead to problems. The chapter lays the \nfoundations of DDD as you learn how to take the first steps on your project, \nwww.EBooksWorld.ir\n", "page": 23, "type": "text", "section": "Page 23"}
{"text": " \nSUMMARY OF CHAPTERS\nxxiii\nand it even gives you some ways to sell DDD to your management, domain \nexperts, and technical team members. That will enable you to face the chal-\nlenges of using DDD armed with the knowledge of how to succeed.\nYou are introduced to a project case study that involves a fictitious company \nand team, yet one with real-world DDD challenges. The company, with the \ncharter to create innovative SaaS-based products in a multitenant environment, \nexperiences many of the mistakes common to DDD adoption but makes vital \ndiscoveries that help the teams solve their issues and keep the project on track. \nThe project is one that most developers can relate to, as it involves developing \na Scrum-based project management application. This case study introduction \nsets the stage for subsequent chapters. Each strategic and tactical pattern is \ntaught through the eyes of the team, both as they err and as they make strides \ntoward maturity in implementing DDD successfully.\nChapter 2: Domains, Subdomains, and Bounded Contexts\nWhat is a Domain, a Subdomain, and a Core Domain? What are Bounded Con-\ntexts, and why and how should you use them? These questions are answered \nin the light of mistakes made by the project team in our case study. Early on \nin their first DDD project they failed to understand the Subdomain they were \nworking within, its Bounded Context, and a concise Ubiquitous Language. In \nfact, they were completely unfamiliar with strategic design, only leveraging the \ntactical patterns for their technical benefits. This led to problems in their ini-\ntial domain model design. Fortunately, they recognized what had happened \nbefore it became a hopeless morass.\nA vital message is conveyed, that of applying Bounded Contexts to distin-\nguish and segregate models properly. Addressed are common misapplications \nof the pattern along with effective implementation advice. The text then leads \nyou through the corrective steps the team took and how that resulted in the \ncreation of two distinct Bounded Contexts. This led to the proper separation \nof modeling concepts in their third Bounded Context, the new Core Domain, \nand the main sample used in the book.\nThis chapter will strongly resonate with readers who have felt the pain of \napplying DDD only in a technical way. If you are uninitiated in strategic design, \nyou are pointed in the right direction to start out on a successful journey.\nChapter 3: Context Maps\nContext Maps are a powerful tool to help a team understand their business \ndomain, the boundaries between distinct models, and how they are currently, \nor can be, integrated. This technique is not limited to drawing a diagram of \nwww.EBooksWorld.ir\n", "page": 24, "type": "text", "section": "Page 24"}
{"text": "PREFACE\nxxiv\nyour system architecture. It\u2019s about understanding the relationships between \nthe various Bounded Contexts in an enterprise and the patterns used to map \nobjects cleanly from one model to another. Use of this tool is important to suc-\nceeding with Bounded Contexts in a complex business enterprise. This chapter \ntakes you through the process used by the project team as they applied Context \nMapping to understand the problems they created with their first Bounded \nContext (Chapter 2). It then shows how the two resulting clean Bounded Con-\ntexts were leveraged by the team responsible for designing and implementing \nthe new Core Domain.\nChapter 4: Architecture\nJust about everyone knows the Layers Architecture. Are Layers the only way to \nhouse a DDD application, or can other diverse architectures be used? Here we \nconsider how to use DDD within such architectures as Hexagonal (Ports and \nAdapters), Service-Oriented, REST, CQRS, Event-Driven (Pipes and Filters, \nLong-Running Processes or Sagas, Event Sourcing), and Data Fabric/Grid-\nBased. Several of these architectural styles were put to use by the project team.\nChapter 5: Entities\nThe first of the DDD tactical patterns treated is Entities. The project team \nfirst leaned too heavily on these, overlooking the importance of designing with \nValue Objects when appropriate. This led to a discussion of how to avoid wide-\nspread overuse of Entities because of the undue influence of databases and per-\nsistence frameworks.\nOnce you are familiar with ways to distinguish their proper use, you see \nlots of examples of how to design Entities well. How do we express the Ubiq-\nuitous Language with an Entity? How are Entities tested, implemented, and \npersisted? You are stepped through how-to guidance for each of these.\nChapter 6: Value Objects\nEarly on the project team missed out on important modeling opportunities \nwith Value Objects. They focused too intensely on the individual attributes \nof Entities when they should have been giving careful consideration to how \nmultiple related attributes are properly gathered as an immutable whole. This \nchapter looks at Value Object design from several angles, discussing how to \nidentify the special characteristics in the model as a means to determine when \nto use a Value rather than an Entity. Other important topics are covered, such \nas the role of Values in integration and modeling Standard Types. The chapter \nthen shows how to design domain-centric tests, how to implement Value types, \nwww.EBooksWorld.ir\n", "page": 25, "type": "text", "section": "Page 25"}
{"text": " \nSUMMARY OF CHAPTERS\nxxv\nand how to avoid the bad influence persistence mechanisms can have on our \nneed to store them as part of an Aggregate.\nChapter 7: Services\nThis chapter shows how to determine when to model a concept as a fine-\ngrained, stateless Service that lives in the domain model. You are shown when \nyou should design a Service instead of an Entity or Value Object, and how \nDomain Services can be implemented to handle business domain logic as well \nas for technical integration purposes. The decisions of the project team are \nused to exemplify when to use Services and how they are designed.\nChapter 8: Domain Events\nDomain Events were not formally introduced by Eric Evans as part of DDD \nuntil after his book was published. You\u2019ll learn why Domain Events published \nby the model are so powerful, and the diverse ways that they can be used, \neven in supporting integration and autonomous business services. Although \nvarious kinds of technical events are sent and processed by applications, the \ndistinguishing characteristics of Domain Events are spotlighted. Design and \nimplementation guidance is provided, instructing you on available options and \ntrade-offs. The chapter then teaches how to create a Publish-Subscribe mech-\nanism, how Domain Events are published to integrated subscribers across the \nenterprise, ways to create and manage an Event Store, and how to properly \ndeal with common messaging challenges faced. Each of these areas is discussed \nin light of the project team\u2019s efforts to use them correctly and to their best \nadvantage.\nChapter 9: Modules\nHow do we organize model objects into right-sized containers with limited \ncoupling to objects that are in different containers? How do we name these \ncontainers so they reflect the Ubiquitous Language? Beyond packages and \nnamespaces, how can we use the more modern modularization facilities, such \nas OSGi and Jigsaw, provided by languages and frameworks? Here you will see \nhow Modules were put to use by the project team across a few of their projects.\nChapter 10: Aggregates\nAggregates are probably the least well understood among DDD\u2019s tactical \ntools. Yet, if we apply some rules of thumb, Aggregates can be made simpler \nand quicker to implement. You will learn how to cut through the complexity \nwww.EBooksWorld.ir\n", "page": 26, "type": "text", "section": "Page 26"}
{"text": "PREFACE\nxxvi\nbarrier to use Aggregates that create consistency boundaries around small \nobject clusters. Because of putting too much emphasis on the less important \naspects of Aggregates, the project team in our case study stumbled in a few \ndifferent ways. We step through the team\u2019s iterations with a few modeling chal-\nlenges and analyze what went wrong and what they did about it. The result \nof their efforts led to a deeper understanding of their Core Domain. We look \nin on how the team corrected their mistakes through the proper application \nof transactional and eventual consistency, and how that led them to design \na more scalable and high-performing model within a distributed processing \nenvironment.\nChapter 11: Factories\n[Gamma et al.] has plenty to say about Factories, so why bother with treating \nthem in this book? This is a simple chapter that does not attempt to reinvent \nthe wheel. Rather, its focus is on understanding where Factories should exist. \nThere are, of course, a few good tips to share about designing a worthy Fac-\ntory in a DDD setting. See how the project team created Factories in their Core \nDomain as a way to simplify the client interface and protect the model\u2019s con-\nsumers from introducing disastrous bugs into their multitenant environment.\nChapter 12: Repositories\nIsn\u2019t a Repository just a simple Data Access Object (DAO)? If not, what\u2019s the \ndifference? Why should we consider designing Repositories to mimic collec-\ntions rather than databases? Learn how to design a Repository that is used \nwith an ORM, one that supports the Coherence grid-based distributed cache, \nand one that uses a NoSQL key-value store. Each of these optional persistence \nmechanisms was at the disposal of the project team because of the power and \nversatility behind the Repository building block pattern.\nChapter 13: Integrating Bounded Contexts\nNow that you understand the higher-level techniques of Context Mapping and \nhave the tactical patterns on your side, what is involved in actually implement-\ning the integrations between models? What integration options are afforded \nby DDD? This chapter uncovers a few different ways to implement model inte-\ngrations using Context Mapping. Instruction is given based on how the project \nteam integrated the Core Domain with other supporting Bounded Contexts \nintroduced in early chapters.\nwww.EBooksWorld.ir\n", "page": 27, "type": "text", "section": "Page 27"}
{"text": " \nJAVA AND DEVELOPMENT TOOLS\nxxvii\nChapter 14: Application\nYou have designed a model per your Core Domain\u2019s Ubiquitous Language. \nYou\u2019ve developed ample tests around its usage and correctness, and it works. \nBut how do other members of your team design the areas of the application \nthat surround the model? Should they use DTOs to transfer data between the \nmodel and the user interface? Or are there other options for conveying model \nstate up to the presentation components? How do the Application Services \nand infrastructure work? This chapter addresses those concerns using the now \nfamiliar project to convey available options.\nAppendix A: Aggregates and Event Sourcing: A+ES\nEvent Sourcing is an important technical approach to persisting Aggregates \nthat also provides the basis for developing an Event-Driven Architecture. \nEvent Sourcing can be used to represent the entire state of an Aggregate as a \nsequence of Events that have occurred since it was created. The Events are used \nto rebuild the state of the Aggregate by replaying them in the same order in \nwhich they occurred. The premise is that this approach simplifies persistence \nand allows capturing concepts with complex behavioral properties, besides the \nfar-reaching influence the Events themselves can have on your own and exter-\nnal systems.\nJava and Development Tools\nThe majority of the examples in this book use the Java Programming Lan-\nguage. I could have provided the examples in C#, but I made a conscious deci-\nsion to use Java instead.\nFirst of all, and sad to say, I think there has been a general abandonment \nof good design and development practices in the Java community. These days \nit may be difficult to find a clean, explicit domain model in most Java-based \nprojects. It seems to me that Scrum and other agile techniques are being used \nas substitutes for careful modeling, where a product backlog is thrust at devel-\nopers as if it serves as a set of designs. Most agile practitioners will leave their \ndaily stand-up without giving a second thought to how their backlog tasks will \naffect the underlying model of the business. Although I assume this is needless \nto say, I must assert that Scrum, for example, was never meant to stand in \nplace of design. No matter how many project and product managers would \nlike to keep you marching on a relentless path of continuous delivery, Scrum \nwww.EBooksWorld.ir\n", "page": 28, "type": "text", "section": "Page 28"}
{"text": "PREFACE\nxxviii\nwas not meant only as a means to keep Gantt chart enthusiasts happy. Yet, it \nhas become that in so many cases.\nI consider this a big problem, and a major theme I have is to inspire the Java \ncommunity to return to domain modeling by giving a reasonable amount of \nthought to how sound, yet agile and rapid, design techniques can benefit their \nwork.\nFurther, there are already some good resources for using DDD in a .NET \nenvironment, one being Applying Domain-Driven Design and Patterns: With \nExamples in C# and .NET by Jimmy Nilsson [Nilsson]. Due to Jimmy\u2019s good \nwork and that of others promoting the Alt.NET mindset, there is a high tide of \ngood design and development practices going on in the .NET community. Java \ndevelopers need to take notice.\nSecond, I am well aware that the C#.NET community will have no problem \nwhatsoever understanding Java code. Due to the fact that much of the DDD \ncommunity uses C#.NET, most of my early book reviewers are C# developers, \nand I never once received a complaint about their having to read Java code. So, \nI have no concern that my use of Java in any way alienates C# developers.\nI need to add that at the time of this writing there was a significant shift \ntoward interest in using document-based and key-value storage over rela-\ntional databases. This is for good reason, for even Martin Fowler has aptly \nnicknamed these \u201caggregate-oriented storage.\u201d It\u2019s a fitting name and well \ndescribes the advantages of using NoSQL storage in a DDD setting.\nYet, in my consulting work I find that many are still quite married to \nrelational databases and object-relational mapping. Therefore, I think that \nin practical terms there has been no disservice to the community of NoSQL \nenthusiasts by my including guidance on using object-relational mapping tech-\nniques for domain models. I do acknowledge, however, that this may earn me \nsome scorn from those who think that the object-relational impedance mis-\nmatch makes it unworthy of consideration. That\u2019s fine, and I accept the flames, \nbecause there is a vast majority who must still live with the drudgeries of this \nimpedance mismatch on a day-to-day basis, however unenlightened they may \nseem to the minority.\nOf course, I also provide guidance in Chapter 12, \u201cRepositories,\u201d on the use \nof document-based, key-value, and Data Fabric/Grid-Based stores. As well, in \nseveral places I discuss where the use of a NoSQL store would tend to influence \nan alternative design of Aggregates and their contained parts. It\u2019s quite likely \nthat the trend toward NoSQL stores will continue to spur growth in that sec-\ntor, so in this case object-relational developers need to take notice. As you can \nsee, I understand both sides of the argument, and I agree with both. It\u2019s all part \nof the ongoing friction created by technology trends, and the friction needs to \nhappen in order for positive change to happen.\nwww.EBooksWorld.ir\n", "page": 29, "type": "text", "section": "Page 29"}
{"text": "xxix\nAcknowledgments\nI am grateful to the fine staff at Addison-Wesley for giving me the opportu-\nnity to publish under their highly respected label. As I have stated before in \nmy classes and presentations, I see Addison-Wesley as a publisher that under-\nstands the value of DDD. Both Christopher Guzikowski and Chris Zahn \n(Dr. Z) have supported my efforts throughout the editorial process. I will not \nforget the day that Christopher Guzikowski called to share the news that he \nwanted to sign me as one of his authors. I will remember how he encouraged \nme to persevere through the doubts that most authors must experience, until \npublication was in sight. Of course, it was Dr. Z who made sure the text was \nput into a publishable state. Thanks to my production editor, Elizabeth Ryan, \nfor coordinating the book\u2019s publication details. And thanks to my intrepid \ncopyeditor, Barbara Wood. \nGoing back a ways, it was Eric Evans who devoted a major portion of five \nyears of his career to write the first definitive work on DDD. Without his \nefforts, the wisdom that grew out of the Smalltalk and patterns communities, \nand that Eric himself refined, many more developers would just be hacking \ntheir way to delivering bad software. Sadly, this problem is more common than \nit should be. As Eric says, the poor quality of software development, and the \nuncreative joylessness of the teams that produce the software, nearly drove him \nto exit the software industry for good. We owe Eric hearty thanks for concen-\ntrating his energy into educating rather than into a career change.\nAt the end of the first DDD Summit in 2011, which Eric invited me to \nattend, it was determined that the leadership should produce a set of guidelines \nby which more developers could succeed with DDD. I was already far along \nwith this book and was in a good position to understand what developers were \nmissing. I offered to write an essay to provide the \u201crules of thumb\u201d for Aggre-\ngates. I determined that this three-part series entitled \u201cEffective Aggregate \nDesign\u201d would form the foundation for Chapter 10 of this book. Once released \non dddcommunity.org, it became quite clear how such sound guidance was \nwww.EBooksWorld.ir\n", "page": 30, "type": "text", "section": "Page 30"}
{"text": "ACKNOWLEDGMENTS\nxxx\ngreatly needed. Thanks to others among the DDD leadership who reviewed \nthat essay and thus provided valuable feedback for this book. Eric Evans and \nPaul Rayner did several detailed reviews of the essay. I also received feedback \nfrom Udi Dahan, Greg Young, Jimmy Nilsson, Niclas Hedhman, and Rickard \n\u00d6berg.\nSpecial thanks go to Randy Stafford, a longtime member of the DDD com-\nmunity. After attending a DDD talk I gave several years ago in Denver, Randy \nurged me to become more involved in the larger DDD community. Sometime \nlater, Randy introduced me to Eric Evans so I could pitch my ideas about draw-\ning the DDD community together. While my ideas were a bit grander and \npossibly less achievable, Eric convinced us that forming a smaller contingent \ncomposed of clear DDD leadership would have more near-term value. From \nthese discussions the DDD Summit 2011 was formed. Needless to say, without \nRandy\u2019s coaxing me to push forward with my views of DDD, this book would \nnot exist, and perhaps not even a DDD Summit. Although Randy was too busy \nwith Oracle Coherence work to contribute to this book, perhaps we will get \nthe chance to write something in the future in a combined effort.\nA huge thank-you goes to Rinat Abdullin, Stefan Tilkov, and Wes Williams \nfor contributing sections about specialized topics to the text. It\u2019s nearly impossi-\nble to know everything about everything related to DDD, and absolutely impos-\nsible to be an expert in all areas of software development. That\u2019s why I turned \nto experts in specific areas to write a few sections of Chapter 4 and Appendix A. \nThanks go to Stefan Tilkov for his uncommon knowledge of REST, to Wes Wil-\nliams for his GemFire experience, and to Rinat Abdullin for sharing his contin-\nually expanding experience with Event Sourcing for Aggregate implementation.\nOne of my earliest reviewers was Leo Gorodinsk, and he stuck with the \nproject. I first met Leo at our DDD Denver meetup. He provided a lot of great \nfeedback on this book based on his own struggles while implementing DDD \nwith his team in Boulder, Colorado. I hope my book helped Leo as much as his \ncritical reviews helped me. I see Leo as part of DDD\u2019s future.\nMany others provided feedback on at least one chapter of my book, and \nsome on several chapters. Some of the more critical feedback was provided \nby Gojko Adzic, Alberto Brandolini, Udi Dahan, Dan Haywood, Dave Muir-\nhead, and Stefan Tilkov. Specifically, Dan Haywood and Gojko Adzic deliv-\nered much of the early feedback, which was based on the most-painful-to-read \ncontent I produced. I am glad they endured and corrected me. Alberto Bran-\ndolini\u2019s insights into strategic design in general, and Context Mapping specif-\nically, helped me focus on the essence of that vital material. Dave Muirhead, \nwith an abundance of experience in object-oriented design, domain modeling, \nas well as object persistence and in-memory data grids\u2014including GemFire \nwww.EBooksWorld.ir\n", "page": 31, "type": "text", "section": "Page 31"}
{"text": " \nACKNOWLEDGMENTS\nxxxi\nand Coherence\u2014influenced my text regarding some of the history and finer \ndetails of object persistence. Besides his REST contribution, Stefan Tilkov sup-\nplied additional insights into architecture in general, and SOA and Pipes and \nFilters specifically. Finally, Udi Dahan validated and helped me clarify some \nof the concepts of CQRS, Long-Running Processes (aka Sagas), and messag-\ning with NServiceBus. Other reviewers who provided valuable feedback were \nRinat Abdullin, Svein Arne Ackenhausen, Javier Ruiz Aranguren, William \nDoman, Chuck Durfee, Craig Hoff, Aeden Jameson, Jiwei Wu, Josh Maletz, \nTom Marrs, Michael McCarthy, Rob Meidal, Jon Slenk, Aaron Stockton, Tom \nStockton, Chris Sutton, and Wes Williams. \nScorpio Steele produced the fantastic illustrations for the book. Scorpio \nmade everyone on the IDDD team the superheroes that they truly are. At the \nother end of the spectrum was the nontechnical editorial review by my good \nfriend Kerry Gilbert. While everyone else made sure I was technically correct, \nKerry put me \u201cunder the grammar hammer.\u201d\nMy father and mother have provided great inspiration and support through-\nout my life. My father\u2014AJ in the \u201cCowboy Logic\u201d humor throughout this \nbook\u2014is not just a cowboy. Don\u2019t get me wrong. Being a great cowboy would \nbe enough. Besides loving flight and piloting airplanes, my father was an \naccomplished civil engineer and land surveyor, and a talented negotiator. He \nstill loves math and studying the galaxies. Among many other things he taught \nme, my Dad imparted to me how to solve a right triangle when I was around \nten years old. Thanks, Dad, for giving me a technical bent at a young age. \nThanks also go to my mom, one of the nicest people you could ever know. \nShe has always encouraged and supported me through my personal challenges. \nBesides, what stamina I have comes from her. I could go on, but I could never \nsay enough good things about her.\nAlthough this book is dedicated to my loving wife, Nicole, and our marvel-\nous son, Tristan, my thanks would not be complete without a special mention \nhere. They are the ones who allowed me to work on and complete the book. \nWithout their support and encouragement my task would not have been possi-\nble. Thanks so much, my dearest loved ones.\nwww.EBooksWorld.ir\n", "page": 32, "type": "text", "section": "Page 32"}
{"text": "This page intentionally left blank \nwww.EBooksWorld.ir\n", "page": 33, "type": "text", "section": "Page 33"}
{"text": "xxxiii\nAbout the Author\nVaughn Vernon is a veteran software craftsman with more than twenty-five years \nof experience in software design, development, and architecture. He is a thought \nleader in simplifying software design and implementation using innovative meth-\nods. He has been programming with object-oriented languages since the 1980s \nand applying the tenets of Domain-Driven Design since his Smalltalk domain \nmodeling days in the early 1990s. His experience spans a wide range of business \ndomains, including aerospace, environmental, geospatial, insurance, medical and \nhealth care, and telecommunications. He has also succeeded in technical endeav-\nors, creating reusable frameworks, libraries, and implementation acceleration \ntools. He consults and speaks internationally and has taught his Implementing \nDomain-Driven Design classes on multiple continents. You can read more about \nhis latest efforts at www.VaughnVernon.co and follow him on Twitter here: \n@VaughnVernon.\nwww.EBooksWorld.ir\n", "page": 34, "type": "text", "section": "Page 34"}
{"text": "This page intentionally left blank \nwww.EBooksWorld.ir\n", "page": 35, "type": "text", "section": "Page 35"}
{"text": "xxxv\nGuide to This Book\nThe book Domain-Driven Design by Eric Evans presents what is essentially \na large pattern language. A pattern language is a set of software patterns that \nare intertwined because they are dependent on each other. Any one pattern \nreferences one or more other patterns that it depends on, or that depend on it. \nWhat does this mean for you?\nIt means that as you read any given chapter of this book, you could run into \na DDD pattern that isn\u2019t discussed in that chapter and that you don\u2019t already \nknow. Don\u2019t panic, and please don\u2019t stop reading out of frustration. The refer-\nenced pattern is very likely explained in detail in another chapter of the book.\nIn order to help unravel the pattern language, I used the syntax found in \nTable G.1 in the text.\nTable G.1 The Syntax Used in This Book\nWhen You See This . . .\nIt Means This . . .\nPattern Name (#)\n1.  \nIt is the first time the pattern is referenced in the \nchapter that you are reading, or\n2.  \nIt is an important additional reference to a pattern \nthat was already mentioned in the chapter, but it\u2019s \nessential to know where to locate more information \nabout it at that point in the text.\nBounded Context (2)\nThe chapter you are reading is referencing Chapter \n2 for you to find out deep details about Bounded \nContexts.\nBounded Context\nIt is the way I reference a pattern already mentioned \nin the same chapter. I don\u2019t want to irritate you by \nmaking every reference to a given pattern bold, with a \nchapter number.\n[REFERENCE]\nIt is a bibliographic reference to another work.\ncontinues\nwww.EBooksWorld.ir\n", "page": 36, "type": "text", "section": "Page 36"}
{"text": "GUIDE TO THIS BOOK\nxxxvi\nIf you start reading in the middle of a chapter and you see a reference such \nas Bounded Context, remember that you\u2019ll probably find a chapter in this book \nthat covers the pattern. Just glance at the index for a richer set of references.\nIf you have already read [Evans] and you know its patterns to some degree, \nyou\u2019ll probably tend to use this book as a way to clarify your understanding \nof DDD and to get ideas for how to improve your existing model designs. In \nthat case you may not need a big-picture view right now. But if you are rela-\ntively new to DDD, the following section will help you see how the patterns fit \ntogether, and how this book can be used to get you up and running quickly. \nSo, read on.\nBig-Picture View of DDD\nEarly on I take you through one of the pillars of DDD, the Ubiquitous Lan-\nguage (1). A Ubiquitous Language is applicable within a single Bounded Con-\ntext (2). Straightaway, you need to familiarize yourself with that critical domain \nmodeling mindset. Just remember that whichever way your software models \nare designed tactically, strategically you\u2019ll want them to reflect the following: a \nclean Ubiquitous Language modeled in an explicitly Bounded Context.\nTable G.1 The Syntax Used in This Book (Continued \n)\nWhen You See This . . .\nIt Means This . . .\n[Evans] or [Evans, Ref]\nI don\u2019t cover the specific referenced DDD pattern \nextensively, and if you want to know more, you need \nto read these works by Eric Evans. (They\u2019re always \nrecommended reading!)\n[Evans] means his classic book, Domain-Driven \nDesign.\n[Evans, Ref] means a second publication that is a \nseparate, condensed reference to the patterns in [Evans] \nthat have been updated and extended.\n[Gamma et al.] and \n[Fowler, P of EAA]\n[Gamma et al.] means the classic book Design \nPatterns.\n[Fowler, P of EAA] means Martin Fowler\u2019s Patterns of \nEnterprise Application Architecture.\nI reference these works frequently. Although I reference \nseveral other works as well, you will tend to see these \na bit more than others. Examine the full bibliography \nfor details.\nwww.EBooksWorld.ir\n", "page": 37, "type": "text", "section": "Page 37"}
{"text": " \nGUIDE TO THIS BOOK\nxxxvii\nStrategic Modeling\nA Bounded Context is a conceptual boundary where a domain model is applica-\nble. It provides a context for the Ubiquitous Language that is spoken by the team \nand expressed in its carefully designed software model, as shown in Figure G.1.\nUbiquitous Language (1)\nmodeled inside\nEquities domain model with a \nsingle, clean Ubiquitous Language\nBounded Context (2)\nExplicit boundary around model\nEquities Context\nFigure G.1 A diagram illustrating a Bounded Context and relevant \nUbiquitous Language\nAs you practice strategic design, you\u2019ll find that the Context Mapping (3)\npatterns seen in Figure G.2 work in harmony. Your team will use Context \nMaps to understand their project terrain.\nWe\u2019ve just considered the big picture of DDD\u2019s strategic design. Understand-\ning it is imperative.\nContext Mappings (3) with integration\nrelationships:\nOpen Host Service, Published Language,\nAnticorruption Layer, Customer-Supplier,\nPartnership, Conformist, Shared Kernel\nD\nU\nEquities Domain Model\nBounded Context (2)\nEquities Context\nAccounts Domain Model\nAccounts Context\n?\n?\nFigure G.2 Context Maps show the relationships among Bounded Contexts.\nwww.EBooksWorld.ir\n", "page": 38, "type": "text", "section": "Page 38"}
{"text": "GUIDE TO THIS BOOK\nxxxviii\nArchitecture\nSometimes a new Bounded Context or existing ones that interact through Con-\ntext Mapping will need to take on a new style of Architecture (4). It\u2019s important \nto keep in mind that your strategically and tactically designed domain models \nshould be architecturally neutral. Still, there will need to be some architecture \naround and between each model. A powerful architectural style for hosting a \nBounded Context is Hexagonal, which can be used to facilitate other styles \nsuch as Service-Oriented, REST and Event-Driven, and others. Figure G.3 \ndepicts a Hexagonal Architecture, and while it may look a little busy, it\u2019s a \nfairly simplistic style to employ.\nSometimes we may be tempted to place too much emphasis on architecture \nrather than focusing on the importance of carefully crafting a DDD-based \nmodel. Architecture is important, but architectural influences come and go. \nRemember to prioritize correctly, placing more emphasis on the domain model, \nwhich has greater business value and will be more enduring.\nDomain Model\nApplication\nAdapter\nAdapter\nAdapter\nAdapter\nAdapter\nAdapter\nAdapter\nAdapter\nArchitecture (4) such as\nthe Hexagonal style\nTactical domain model at the\nheart of the Bounded Context\nFigure G.3 The Hexagonal Architecture with the domain model at the heart \nof the software\nwww.EBooksWorld.ir\n", "page": 39, "type": "text", "section": "Page 39"}
{"text": " \nGUIDE TO THIS BOOK\nxxxix\nTactical Modeling\nWe model tactically inside a Bounded Context using DDD\u2019s building block \npatterns. One of the most important patterns of tactical design is Aggregate \n(10), as illustrated in Figure G.4.\nAn Aggregate is composed of either a single Entity (5) or a cluster of Entities \nand Value Objects (6) that must remain transactionally consistent throughout \nthe Aggregate\u2019s lifetime. Understanding how to effectively model Aggregates is \nquite important and one of the least well understood techniques among DDD\u2019s \nbuilding blocks. If they are so important, you may be wondering why Aggre-\ngates are placed later in the book. First of all, the placement of tactical pat-\nterns in this book follows the same order as is found in [Evans]. Also, since \nAggregates are based on other tactical patterns, we cover the basic building \nblocks\u2014such as Entities and Value Objects\u2014before the more complex Aggre-\ngate pattern.\nAn instance of an Aggregate is persisted using its Repository (12) and later \nsearched for within and retrieved from it. You can see an indication of that in \nFigure G.4.\nUse stateless Services (7), such as seen in Figure G.5, inside the domain \nmodel to perform business operations that don\u2019t fit naturally as an operation \non an Entity or a Value Object.\n<<aggregate root>>\nRoot Entity 1\n<<value object>>\n0..*\nValue Type 1\nAggregate Type 1\n<<repository>>\nRepository 1\n<<repository>>\nRepository 2\n<<value object>>\nValue Type 2\n<<value object>>\nValue Type 3\n<<aggregate root>>\nState inside reflecting true business rules\nmust remain completely consistent\nUse a Repository (12) to persist\na specific Aggregate type\nAggregate (10) with transactional\nconsistency boundary\nRoot Entity 2\nAggregate Type 2\n<<value object>>\nValue Type 4\n0..*\n<<entity>>\nEntity Type 3\nFigure G.4 Two Aggregate types with their own transactional consistency boundaries\nwww.EBooksWorld.ir\n", "page": 40, "type": "text", "section": "Page 40"}
{"text": "GUIDE TO THIS BOOK\nxl\nUse Domain Events (8) to indicate the occurrence of significant happenings \nin the domain. Domain Events can be modeled a few different ways. When \nthey capture occurrences that are a result of some Aggregate command opera-\ntion, the Aggregate itself publishes the Event as depicted in Figure G.6.\nAlthough often given little thought, it\u2019s really important to design Modules \n(9) correctly. In its simplest form, think of a Module as a package in Java or \na namespace in C#. Remember that if you design your Modules mechanically \nrather than according to the Ubiquitous Language, they will probably do more \nharm than good. Figure G.7 illustrates how Modules should contain a limited \nset of cohesive domain objects.\nOf course, there\u2019s much more to implementing DDD, and I won\u2019t try to \ncover it all here. There\u2019s a whole book ahead of you that does just that. I think \nthis Guide gets you off on the right foot for your journey through implement-\ning DDD. So, enjoy the journey!\n<<service>>\nUse a Service (7) to perform an operation\nthat cuts across Aggregates, for example\nQuery\noperation\nCommand\noperation\nDomain Service 1\n<<aggregate root>>\nRoot Entity 1\n<<aggregate root>>\nRoot Entity 2\nFigure G.5 Domain Services carry out domain-specific operations, which may \ninvolve multiple domain objects.\ncreate\npublish\nhandle\nEvent\nEvent Publisher\nSubscriber\nSubscriber\nSubscriber\nEvent\nAggregate\nFigure G.6 Domain Events can be published by Aggregates.\nwww.EBooksWorld.ir\n", "page": 41, "type": "text", "section": "Page 41"}
{"text": " \nGUIDE TO THIS BOOK\nxli\nOh, and just to get you familiarized with Cowboy Logic, here\u2019s one for the \ntrail:\nCowboy Logic \nAJ:  \n\u201cDon\u2019t worry about bitin\u2019 off more than you can chew. \nYour mouth is probably a whole lot bigger than you \nthink.\u201d ;-)\nLB:  \n\u201cYou meant to say \u2018mind,\u2019 J. Your mind is bigger than \nyou think!\u201d\ncom.companyname.context.domain.model.concept\n<<value object>>\nValue Type\n<<entity>>\nEntity 2\n<<aggregate root>>\nEntity 1\n<<value object>>\nIdentity\nFigure G.7 A Module contains and organizes cohesive domain objects.\nwww.EBooksWorld.ir\n", "page": 42, "type": "text", "section": "Page 42"}
{"text": "This page intentionally left blank \nwww.EBooksWorld.ir\n", "page": 43, "type": "text", "section": "Page 43"}
{"text": "1\nChapter 1\nGetting Started with DDD\nDesign is not just what it looks like and feels like. \nDesign is how it works.\n\u2014Steve Jobs\nWe strive to produce quality in the software we develop. We achieve some qual-\nity by using tests to help us avoid delivering software with a fatal number of \nbugs. Yet, even if we could produce completely bug-free software, that in itself \ndoes not necessarily mean that a quality software model is designed. The soft-\nware model\u2014the way the software expresses the solution to the business goal \nbeing sought\u2014could still suffer greatly. Delivering software with few defects is \nobviously good. Still, we can reach higher for a well-designed software model \nthat explicitly reflects the intended business objective, and our work may even \nreach the level of great.\nThe software development approach called Domain-Driven Design, or \nDDD, exists to help us more readily succeed at achieving high-quality software \nmodel designs. When implemented correctly, DDD helps us reach the point \nwhere our design is exactly how the software works. This book is about help-\ning you correctly implement DDD.\nYou may be completely new to DDD, you may have tried it and struggled, \nor you may have already succeeded with it before. Regardless, you no doubt \nare reading this book because you want to improve your ability to implement \nDDD, and you can. The chapter road map helps you target your specific needs.\nRoad Map to This Chapter\n\u2022 Discover what DDD can do for your projects and your teams as you grapple \nwith complexity.\n\u2022 Find out how to score your project to see if it deserves the DDD investment.\n\u2022 Consider the common alternatives to DDD and why they often lead to \nproblems.\n\u2022 Grasp the foundations of DDD as you learn how to take the first steps on your \nproject. \n\u2022 Learn how to sell DDD to your management, domain experts, and technical \nteam members.\ncontinues\nwww.EBooksWorld.ir\n", "page": 44, "type": "text", "section": "Page 44"}
{"text": "Chapter 1 GETTING STARTED WITH DDD\n2\n\u2022 Face the challenges of using DDD armed with knowledge of how to succeed.\n\u2022 Look in on a team that is learning how to implement DDD.\nWhat should you expect from DDD? Not a heavy, dense, ceremonial process \nthat blocks your way to progress. Rather, expect to use the agile development \ntechniques you probably already have come to trust. Beyond agile, anticipate \nthe acquisition of methods that help you gain deep insight into your business \ndomain, with the prospect of producing testable, malleable, organized, care-\nfully crafted, high-quality software models.\nDDD gives you both the strategic and tactical modeling tools necessary to \ndesign high-quality software that meets core business objectives.\nCan I DDD?\nYou can implement DDD if you have\n\u2022 A passion for creating excellent software every day, and the tenacity to \nachieve that goal\n\u2022 The eagerness to learn and improve, and the fortitude to admit you need to\n\u2022 The aptitude to understand software patterns and how to properly apply \nthem\n\u2022 The skill and patience to explore design alternatives using proven agile \nmethods\n\u2022 The courage to challenge the status quo\n\u2022 The desire and ability to pay attention to details, to experiment and \ndiscover \n\u2022 A drive to seek ways to code smarter and better\nI\u2019m not going to tell you that there isn\u2019t a learning curve. To put it bluntly, \nthe learning curve can be steep. Yet, this book has been put together to help \nflatten the curve as much as possible. My goal is to help you and your team \nimplement DDD with the greatest potential for success.\nDDD isn\u2019t first and foremost about technology. In its most central principles, \nDDD is about discussion, listening, understanding, discovery, and business \nwww.EBooksWorld.ir\n", "page": 45, "type": "text", "section": "Page 45"}
{"text": " \nCAN I DDD?\n3\nvalue, all in an effort to centralize knowledge. If you are capable of under-\nstanding the business in which your company works, you can at a minimum \nparticipate in the software model discovery process to produce a Ubiquitous \nLanguage. Sure, you\u2019re going to have to learn more about the business, lots \nmore. Still, you are on your way to succeeding with DDD already because you \ncan comprehend the concepts of your business, you revel in developing great \nsoftware, and that gives you the proper footing to take DDD all the way.\nWon\u2019t having years, even a decade or two, of software development expe-\nrience help? It might. Nevertheless, software development experience doesn\u2019t \ngive you the ability to listen and learn from domain experts, the people who \nknow the most about some high-priority area of the business. You are at a \ngreater advantage if you can engage with those who seldom, if ever, express \nthemselves using technical lingo. You\u2019re going to have to listen and listen care-\nfully. You\u2019re going to have to respect their viewpoint and trust that they know \na lot more than you do.\nThere Are Big Advantages to Engaging with Domain Experts\nYou are at a greater advantage if you can engage with those who seldom, if ever, \nexpress themselves using technical lingo. Just as you are going to learn from them, \nthere is a high probability that they are also going to learn from you.\nWhat you may like best about DDD is that the domain experts are also \ngoing to have to listen to you. You are on the team just as they are. As strange \nas it may seem, the domain experts don\u2019t know everything about their business, \nand they are also going to learn more about it. Just as you are going to learn \nfrom them, there is a high probability that they are also going to learn from \nyou. Your questions about what they know will most likely also uncover what \nthey don\u2019t know. You\u2019ll be directly involved in helping everyone on the team \ndiscover a deeper understanding of the business, even shaping the business.\nIt\u2019s great when a team learns and grows together. If you give it a chance, \nDDD makes that possible.\nBut We Don\u2019t Have Domain Experts\nA domain expert is not one by job title. These are the people who know the line of \nbusiness you are working in really well. They probably have a lot of background in \nthe business domain, and they might be product designers or even your salespeople.\nLook past the job title. The people you are looking for know more about what \nyou are working on than anyone else, and for sure way more than you know. Find \nthem. Listen. Learn. Design in code.\nSo far we\u2019re off to a pretty reassuring start. Still, I am also not going to tell \nyou that technical ability isn\u2019t important, that somehow you can get by without \nwww.EBooksWorld.ir\n", "page": 46, "type": "text", "section": "Page 46"}
{"text": "Chapter 1 GETTING STARTED WITH DDD\n4\nit. You will have to grasp some advanced software domain modeling concepts. \nEven so, it doesn\u2019t necessarily mean you are going to be in over your head. \nIf you have abilities somewhere between grasping Head First Design Patterns\n[Freeman et al.] and grokking the original Design Patterns [Gamma et al.] text, \nor even more advanced patterns, you stand a really good chance of succeeding \nwith DDD. You can bank on this: I\u2019m going to do everything I can to make that \nhappen by lowering the bar, no matter what your level of experience.\nWhat\u2019s a Domain Model?\nIt\u2019s a software model of the very specific business domain you are working in. Often \nit\u2019s implemented as an object model, where those objects have both data and behav-\nior with literal and accurate business meaning.\nCreating a unique, carefully crafted domain model at the heart of a core, strate-\ngic application or subsystem is essential to practicing DDD. With DDD your domain \nmodels will tend to be smallish, very focused. Using DDD, you never try to model \nthe whole business enterprise with a single, large domain model. Phew, that\u2019s good!\nConsider the following perspectives of the people who can benefit from \nDDD. I know you fit in here somewhere:\n\u2022 Newbie, junior developer: \u201cI\u2019m young, with fresh ideas, I\u2019ve got pent-up \nenergy to code, and I\u2019m going to have an impact. What\u2019s got me miffed is \none of the projects I sprint on. I didn\u2019t expect that my first gig off campus \nwould mean shoveling data back and forth using lots of almost identical \nyet redundant \u2018objects.\u2019 Why is this architecture so complex if that\u2019s all \nthat\u2019s happening? What\u2019s up with that? The code breaks a lot when I try \nto change it. Does anyone actually understand what it\u2019s supposed to do? \nNow there are some complex new features I have to add. I regularly slap \nan adapter around legacy classes to shield me from the goo. No joy. I\u2019m \nsure there\u2019s something I can do besides code and debug all day and night \njust to finish iterations. Whatever that is, I\u2019m going to track it down and \nown it. I heard some of the others talking about DDD. It sounds like \nGang of Four, but tuned for the domain model. Nice.\u201d\nGotcha covered.\n\u2022 Midlevel developer: \u201cOver the past few months I\u2019ve been included on \nthe new system. It\u2019s my turn to make a difference. I get it, but what I\u2019m \nmissing are profound insights when I\u2019m meeting with the senior develop-\ners. Sometimes things seem whacked, but I\u2019m not sure why. I\u2019m going to \nhelp change the way things are done around here. I know that throwing \ntechnology at a problem only takes you so far, and that\u2019s basically not far \nenough. What I need is a sound software development technique that\u2019s \nwww.EBooksWorld.ir\n", "page": 47, "type": "text", "section": "Page 47"}
{"text": " \nCAN I DDD?\n5\ngoing to help me become a wise and experienced software practitioner. \nOne of the senior architects, the new guy, made a pitch for something \ncalled DDD. I\u2019m listening.\u201d\nYou\u2019re sounding senior already. Read on. Your forward-thinking attitude \nwill be rewarded.\n\u2022 Senior developer, architect: \u201cI\u2019ve used DDD on a few projects, but not \nsince landing this new position. I like the power of the tactical patterns,\nbut there\u2019s a lot more I could apply, with strategic design being one. What \nI found most insightful when reading [Evans] was the Ubiquitous Lan-\nguage. That\u2019s powerful stuff. I\u2019ve had discussions with a number of my \nteammates and management, trying to influence DDD\u2019s adoption here. \nOne of the new kids and a few of the midlevel and senior members are \njazzed about the prospects. Management isn\u2019t so excited. I recently joined \nthis company, and although I was brought in to lead, it seems that the \norganization is less interested in disruptive advancements than I thought. \nWhatever. I\u2019m not giving up. With other developers psyched about it, I\nknow we can make it happen. The payoffs are going to be much greater \nthan anticipated. We\u2019ll draw the pure business people\u2014the domain \nexperts\u2014closer to our technical teams, and we\u2019ll actually invest in our \nsolutions, not just grunt them out iteration after iteration.\u201d\nNow that\u2019s what a leader does. This book has lots of guidance that shows \nhow to succeed with strategic design.\n\u2022 Domain expert: \u201cI\u2019ve been involved in specifying the IT solutions to our \nbusiness challenges for a long time now. Maybe it\u2019s too much to expect, \nbut I wish the developers understood better what we do here. They\u2019re \nalways talking down to us like we\u2019re stupid. What they don\u2019t understand \nis, if it wasn\u2019t for us there wouldn\u2019t be jobs here for them to mess around \nwith computers. The developers always have some strange way of talking \nabout what our software does. If we talk about A, they say it\u2019s really \ncalled B. It\u2019s like we have to have some sort of dictionary and road map \non hand every time we try to communicate what we need. If we don\u2019t let \nthem have their way by calling B what we know is A, they don\u2019t coop-\nerate. We waste so much time in this mode. Why can\u2019t the software just \nwork the way the real experts think about the business?\u201d\nYou\u2019ve got that right. One of the biggest problems is the false need for \ntranslation between business people and techies. This chapter is for you. \nAs you\u2019re going to see, DDD puts you and developers on level ground.\nwww.EBooksWorld.ir\n", "page": 48, "type": "text", "section": "Page 48"}
{"text": "Chapter 1 GETTING STARTED WITH DDD\n6\nAnd, surprise! You\u2019ve got some developers already leaning your way. Help \nthem here.\n\u2022 Manager: \u201cWe are shipping software. It\u2019s not always with the greatest \nresult, and changes seem to take longer than they should. The developers \nkeep talking about some domain something-or-another. I\u2019m not sure we \nneed to get high centered on yet another technique or methodology, like \nit\u2019s some kind of silver bullet. I\u2019ve heard all that a thousand times before. \nWe try, the fad dies, and we are right back to the same-old same-old. I \nkeep saying that we need to stay the course and stop dreaming, but the \nteam keeps hounding me. They\u2019ve worked hard, so I owe them a listen. \nThey are smart people and they all deserve a chance to improve things\nbefore they get torqued and move on. I could allow them some time to \nlearn and adjust if I can get backing from upper management. I think I \ncould get that approval if I can convince my boss of the team\u2019s claims of \nachieving critical software investment and a centralization of business \nknowledge. Truth is, it will make my job easier if I can do something to \ninspire trust and cooperation between my teams and business experts.\nAnyway, that\u2019s what I am hearing I can do.\u201d\nGood manager!\nWhoever you are, here\u2019s an important heads-up. To succeed with DDD you \nare going to have to learn something, and actually a lot of somethings. That \nshouldn\u2019t be a big deal, though. You are smart and you have to learn all the \ntime. Yet we all face this challenge:\nPersonally I\u2019m always ready to learn, although I do not always like being taught.\n\u2014Sir Winston Churchill\nThat\u2019s where this book comes in. I\u2019ve tried to make the teaching as pleas-\nant as possible while delivering the vital understanding you need to implement \nDDD with success.\nYour question, though, is: \u201cWhy should I do DDD?\u201d That\u2019s fair.\nWhy You Should Do DDD\nActually, I\u2019ve already given you some pretty good reasons why DDD makes so \nmuch practical sense. At the risk of breaking the DRY principle (\u201cDon\u2019t repeat \nyourself\u201d), I reiterate them here and also add to the earlier reasons. Does any-\none hear an echo?\nwww.EBooksWorld.ir\n", "page": 49, "type": "text", "section": "Page 49"}
{"text": " \nWHY YOU SHOULD DO DDD\n7\n\u2022 Put domain experts and developers on a level playing field, which pro-\nduces software that makes perfect sense to the business, not just the cod-\ners. This doesn\u2019t mean merely tolerating the opposite group. It means \nbecoming one cohesive, tight-knit team.\n\u2022 That \u201cmakes sense to the business\u201d thing means investing in the business \nby making software that is as close as possible to what the business lead-\ners and experts would create if they were the coders.\n\u2022 You can actually teach the business more about itself. No domain expert, \nno C-level manager, no one, ever knows every single thing about the busi-\nness. It\u2019s a constant discovery process that becomes more insightful over \ntime. With DDD, everybody learns because everybody contributes to dis-\ncovery discussions.\n\u2022 Centralizing knowledge is key, because with that the business is capable of \nensuring that understanding the software is not locked in \u201ctribal knowl-\nedge,\u201d available only to a select few, who are usually only the developers.\n\u2022 There are zero translations between the domain experts, the software \ndevelopers, and the software. That doesn\u2019t mean maybe some few transla-\ntions. It means zero translations because your team develops a common, \nshared language that everyone on the team speaks.\n\u2022 The design is the code, and the code is the design. The design is how it \nworks. Knowing the best code design comes through quick experimental \nmodels using an agile discovery process.\n\u2022 DDD provides sound software development techniques that address both \nstrategic and tactical design. Strategic design helps us understand what \nare the most important software investments to make, what existing soft-\nware assets to leverage in order to get there fastest and safest, and who \nmust be involved. Tactical design helps us craft the single elegant model of \na solution using time-tested, proven software building blocks.\nLike any good, high-yielding investment, DDD has some up-front cost of \ntime and effort for the team. Considering the typical challenges encountered by \nevery software development effort will reinforce the need to invest in a sound \nsoftware development approach.\nDelivering Business Value Can Be Elusive\nDeveloping software that delivers true business value is not the same thing as \ndeveloping ordinary business software. Software that delivers true business \nvalue aligns with the business strategic initiatives and bears solutions with \nwww.EBooksWorld.ir\n", "page": 50, "type": "text", "section": "Page 50"}
{"text": "Chapter 1 GETTING STARTED WITH DDD\n8\nclearly identifiable competitive advantage\u2014software that is not about technol-\nogy, but about the business.\nBusiness knowledge is never centralized. Development teams have to bal-\nance and prioritize among the needs and requests of multiple stakeholders and \nengage with many people having diverse skill sets, all with the goal of uncov-\nering software functional and nonfunctional requirements. After gathering all \nthat information, how can teams be certain that any given requirement delivers \ntrue business value? In fact, what are the business values being sought, and \nhow do you uncover them, prioritize them, and realize them?\nOne of the worst disconnects of a business software development effort is \nseen in the gap between domain experts and software developers. Generally \nspeaking, true domain experts are focused on delivering business value. On \nthe other hand, software developers are typically drawn to technology and \ntechnical solutions to business problems. It\u2019s not that software developers have \nwrong motivations; it\u2019s just what tends to grab their attention. Even when soft-\nware developers engage with domain experts, the collaboration is largely at \na surface level, and the software that gets developed often results in a trans-\nlation/mapping between how the business thinks and operates and how the \nsoftware developer interprets that. The resulting software generally does not \nreflect a recognizable realization of the mental model of the domain experts, \nor perhaps it does so only partially. Over time this disconnect becomes costly. \nThe translation of domain knowledge into software is lost as developers transi-\ntion to other projects or leave the company.\nA different, yet related problem is when one or more domain experts do \nnot agree with each other. This tends to happen because each expert has more \nor less experience in the specific domain being modeled, or they are simply \nexperts in related but different areas. It\u2019s also common for multiple \u201cdomain \nexperts\u201d to have no expertise in a given domain, where they are more of a busi-\nness analyst, yet they are expected to bring insightful direction to discussions. \nWhen this situation goes unchecked, it results in blurred rather than crisp men-\ntal models, which lead to conflicting software models.\nWorse still is when the technical approach to software development actually \nwrongly changes the way the business functions. While a different scenario, \nit is well known that enterprise resource planning (ERP) software will often \nchange the overall business operations of an organization to fit the way the \nERP functions. The total cost of owning the ERP cannot be fully calculated \nin terms of license and maintenance fees. The reorganization and disruption \nto the business can be far more costly than either of those two tangible fac-\ntors. A similar dynamic is at play as your software development teams inter-\npret what the business needs into what the newly developed software actually \ndoes. This can be both costly and disruptive to the business, its customers, and \nwww.EBooksWorld.ir\n", "page": 51, "type": "text", "section": "Page 51"}
{"text": " \nWHY YOU SHOULD DO DDD\n9\nits partners. Furthermore, this technical interpretation is both unnecessary and \navoidable with the use of proven software development techniques. The solu-\ntion is a key investment.\nHow DDD Helps\nDDD is an approach to developing software that focuses on these three pri-\nmary aspects:\n 1. DDD brings domain experts and software developers together in order to \ndevelop software that reflects the mental model of the business experts. \nThis does not mean that effort is spent on modeling the \u201creal world.\u201d \nRather, DDD delivers a model that is the most useful to the business. \nSometimes useful and realistic models happen to intersect, but to the \ndegree that they diverge, DDD chooses useful. \nWith this aspect the efforts of domain experts and software developers \nare devoted to jointly developing a Ubiquitous Language of the areas of \nthe business that they are focused on modeling. The Ubiquitous Language \nis developed with full team agreement, is spoken, and is directly captured \nin the model of the software. It is worth reiterating that the team is com-\nposed of both domain experts and software developers. It\u2019s never \u201cus and \nthem.\u201d It\u2019s always us. This is a key business value that allows business \nknow-how to outlive the relatively short initial development efforts that \ndeliver the first few versions of the software, and the teams that produce \nit. It\u2019s the point where the cost of developing software is a justifiable busi-\nness investment, not just a cost center.\nThis entire effort unifies domain experts who initially disagree with \neach other, or who simply lack core knowledge of the domain. Further, \nit strengthens the close-knit team by spreading deep domain insight \namong all team members, including software developers. Consider this \nthe hands-on training that every company should invest in its knowledge \nworkers.\n 2. DDD addresses the strategic initiatives of the business. While this stra-\ntegic design approach naturally includes technical analysis, it is more \nconcerned with the strategic direction of the business. It helps define the \nbest inter-team organizational relationships and provides early-warning \nsystems for recognizing when a given relationship could cause software \nand even project failure. The technical aspects of strategic design have \nthe goal of cleanly bounding systems and business concerns, which pro-\ntects each business-level service. This provides meaningful motivations \nwww.EBooksWorld.ir\n", "page": 52, "type": "text", "section": "Page 52"}
{"text": "Chapter 1 GETTING STARTED WITH DDD\n10\nfor how an overall service-oriented architecture or business-driven archi-\ntecture is achieved.\n 3. DDD meets the real technical demands of the software by using tacti-\ncal design modeling tools to analyze and develop the executable software \ndeliverables. These tactical design tools allow developers to produce soft-\nware that is a correct codification of the domain experts\u2019 mental model, \nis highly testable, is less error prone (a provable statement), performs \nto  \nservice-level agreements (SLAs), is scalable, and allows for distrib-\nuted computing. DDD best practices generally address a dozen or more \nhigher-level architectural and lower-level software design concerns, with \na focus on recognizing true business rules and data invariants, and pro-\ntecting the rules from error situations.\nUsing this approach to software development, you and your team can succeed \nin delivering true business value.\nGrappling with the Complexity of Your Domain\nWe primarily want to use DDD in the areas that are most important to the \nbusiness. You don\u2019t invest in what can be easily replaced. You invest in the \nnontrivial, the more complex stuff, the most valuable and important stuff that \npromises to return the greatest dividends. That\u2019s why we call such a model a \nCore Domain (2). It is these, and in second priority the significant Supporting \nSubdomains (2), that deserve and get the biggest investment. Rightly, then, we \nneed to grasp what complex means.\nUse DDD to Simplify, Not to Complicate\nUse DDD to model a complex domain in the simplest possible way. Never use DDD \nto make your solution more complex.\nWhat qualifies as complex will differ from business to business. Different \ncompanies have different challenges, different levels of maturity, and different \nsoftware development capabilities. So rather than determining what is com-\nplex, it may be easier to determine what is nontrivial. Thus, your team and \nmanagement will have to determine if a system you are planning to work on \ndeserves the cost of making a DDD investment.\nDDD Scorecard: Use Table 1.1 to determine whether your project qualifies \nfor an investment in DDD. If a row on the scorecard describes your project, \nplace the corresponding number of points in the right-hand column. Tally all \nthe points for your project. If it\u2019s 7 or higher, seriously consider using DDD.\nwww.EBooksWorld.ir\n", "page": 53, "type": "text", "section": "Page 53"}
{"text": "11\nTable 1.1 The DDD Scorecard\nDoes Your Project Score a Total of 7 Points or Higher?\nIf Your Project . . .\nPoints\nSupporting Thoughts\nYour \nScore\nIf your application is completely data-centric and truly qualifies \nfor a pure CRUD solution, where every operation is basically a \nsimple database query to Create, Read, Update, or Delete, you \ndon\u2019t need DDD. Your team just needs to put a pretty face on \na database table editor. In other words, if you can trust your \nusers to insert data directly into a table, update it, and some-\ntimes delete it, you wouldn\u2019t even need a user interface. That\u2019s \nnot realistic, but it\u2019s conceptually relevant. If you could even \nuse a simple database development tool to create a solution, \ndon\u2019t waste your company\u2019s time and money on DDD.\n0\nThis seems like a no-brainer, but it\u2019s not usually that \neasy to determine simple versus complex. It\u2019s not as if \nevery application that isn\u2019t pure CRUD deserves the \ntime and effort of using DDD. So maybe we could \ncome up with other metrics to help us draw a line \nbetween what is complex and what is not . . .\nIf your system requires just 30 or fewer business operations, it\u2019s \nprobably pretty simple. This would mean that your applica-\ntion would have no more than 30 total user stories or use case \nflows, with each of those flows having only minimal business \nlogic. If you could quickly and easily develop such an applica-\ntion using Ruby on Rails or Groovy and Grails and not feel the \npain of lacking power and control over complexity and change, \nyour system probably doesn\u2019t need to use DDD.\n1\nTo be clear, I am talking about 25 to 30 single busi-\nness methods, not 25 to 30 whole service interfaces, \neach with multiple methods. The latter might be \ncomplex.\nSo let\u2019s say that somewhere in the range of 30 to 40 user stories \nor use case flows could be creeping toward complexity. Your \nsystem might be getting into DDD territory.\n2\nCaveat emptor: Very often complexity is not rec-\nognized soon enough. We software developers are \nreally, really good at underestimating complexity and \nlevel of effort. Just because we might want to code up \na Rails or Grails application doesn\u2019t mean we should. \nIn the long run those could hurt more than help.\ncontinues\nwww.EBooksWorld.ir\n", "page": 54, "type": "text", "section": "Page 54"}
{"text": "12\nDoes Your Project Score a Total of 7 Points or Higher?\nIf Your Project . . .\nPoints\nSupporting Thoughts\nYour \nScore\nEven if the application is not going to be complex now, will it \ngrow in complexity? You may not know this for sure until real \nusers start working with it, but there is a step in the \u201cSup-\nporting Thoughts\u201d column that may help uncover the true \nsituation.\nBe careful here. If there is any hint at all that the application \nhas even moderate complexity\u2014here\u2019s a good time to be para-\nnoid\u2014that may be sufficient indication that it will actually be \nmore than moderately complex. Lean toward DDD.\n3\nHere it pays off to walk through the more complex \nusage scenarios with domain experts and see where it \nleads. Are domain experts . . .\n1. . . . already asking for more complex features? \nIf so, it\u2019s likely an indication that the application is \nalready or will soon become too complex to use a \nCRUD approach.\n2. . . . so bored with the features that they can hardly \nbear discussing them? It\u2019s probably not complex.\nThe application\u2019s features are going to change often over a \nnumber of years, and you can\u2019t anticipate that the kinds of \nchanges will be simple.\n4\nDDD can help you manage the complexity of refac-\ntoring your model over time.\nYou don\u2019t understand the Domain (2) because it\u2019s new. As \nfar as you and your team know, nobody has done this before. \nThat most likely means it\u2019s complex, or at least deserves due \ndiligence with analytical scrutiny to determine the level of \ncomplexity.\n5\nYou are going to need to work with domain experts \nand experiment with models to get it right. You \ncertainly also scored on one or more of the previous \ncriteria, so use DDD.\nTable 1.1 The DDD Scorecard (Continued \n)\nwww.EBooksWorld.ir\n", "page": 55, "type": "text", "section": "Page 55"}
{"text": " \nWHY YOU SHOULD DO DDD\n13\nThis scoring exercise may have led your team to these conclusions:\nIt\u2019s too bad that we can\u2019t shift gears quickly and easily when we discover we are \non the wrong side of complexity, no matter if the wrong side is more or less com-\nplex than we thought.\nSure, but that just means that we need to become much better at determining \nsimplicity versus complexity early on in our project planning. That would save us \na lot of time, expense, and trouble.\nOnce we make a major architectural decision and get several use cases deep in \ndevelopment, we are usually stuck with it. We had better choose wisely.\nIf any of these observations resonates with your team, you are making good \nuse of critical thought.\nAnemia and Memory Loss\nAnemia can be a serious health ailment with dangerous side effects. When \nthe name Anemic Domain Model [Fowler, Anemic] was first coined, it wasn\u2019t \nmeant to be a complimentary term, as if to say that a domain model that is \nweak, without the power of inherent behavioral qualities, could possibly be a \ngood thing. Strangely enough, Anemic Domain Models have popped up left \nand right in our industry. The trouble is that most developers seem to think \nthis is quite normal and would not even acknowledge that a serious condition \nexists when employed in their systems. It\u2019s a real problem.\nAre you wondering if your model is feeling tired, listless, forgetful, clumsy, \nneeding a good shot in the arm? If you\u2019re suddenly experiencing technical \nhypochondria, here\u2019s a good way to perform a self-examination. You\u2019ll either \nput yourself at ease or confirm your worst fears. Use the steps in Table 1.2 to \nperform your checkup.\nTable 1.2 Determine Your Domain Model Health History \nYes / No\nDoes the software you call a \u201cdomain model\u201d have mostly public getters and setters, \nand no business logic or almost none at all\u2014you know, objects that are mostly attri-\nbute value holders?\nAre the software components that frequently use your \u201cdomain model\u201d the ones \nthat house most of the business logic of your system, and do those heavily invoke the \npublic getters and setters on the \u201cdomain model\u201d? You probably call this particular \nclient layer of the \u201cdomain model\u201d a Service Layer or Application Layer (4, 14). If \ninstead this describes your user interface, answer \u201cYes\u201d to this question and write a \nthousand times on a whiteboard that you\u2019ll never, ever do that again.\nHint: The correct answers are either \u201cYes\u201d to both questions or \u201cNo\u201d to both questions.\nwww.EBooksWorld.ir\n", "page": 56, "type": "text", "section": "Page 56"}
{"text": "Chapter 1 GETTING STARTED WITH DDD\n14\nHow did you do?\nIf you answered \u201cNo\u201d to both questions, your domain is doing well.\nIf you answered \u201cYes\u201d to both questions, your \u201cdomain model\u201d is very, very \nill. It\u2019s anemic. The good news is that you can get help for it by reading on.\nIf you answered \u201cYes\u201d to one question and \u201cNo\u201d to the other question, you \nare either in denial or suffering from delusions or another neurological issue \nthat could be caused by anemia. What should you do if you have conflicting \nanswers? Go straight back to the first question and run the self-examination \nonce again. Take your time, but remember that your answer to both ques-\ntions must be an emphatic \u201cYes!\u201d\nAs [Fowler, Anemic] says, an Anemic Domain Model is a bad thing because \nyou pay most of the high cost of developing a domain model, but you get little \nor none of the benefit. For example, because of the object-relational impedance \nmismatch, developers of such a \u201cdomain model\u201d spend a lot of time and effort \nmapping objects to and from the persistence store. That\u2019s a high price to pay \nwhile getting little or no benefit in return. I\u2019ll add that what you have is not a \ndomain model at all, but just a data model projected from a relational model \n(or other database) into objects. It\u2019s an impostor that may actually be closer to \nthe definition of Active Record [Fowler, P of EAA]. You can probably simplify \nyour architecture by not being pretentious and just admit that you are really \nusing a form of Transaction Script [Fowler, P of EAA].\nReasons Why Anemia Happens\nSo if an Anemic Domain Model is the sickly outcome of a poorly executed \ndesign effort, why do so many use it while thinking that their model is experi-\nencing fine health? Certainly it does reflect a procedural programming mental-\nity, but I don\u2019t think that\u2019s the primary reason. A good portion of our industry \nis made up of sample code followers, which isn\u2019t bad as long as the samples \nare quality ones. Often, however, sample code is purposely focused on demon-\nstrating some concept or application programming interface (API) feature in \nthe simplest possible way, without concern for good design principles. Yet \noversimplified sample code, which usually demonstrates with a lot of getters \nand setters, is copied every day without a second thought about design.\nThere is another, older influence. The ancient history of Microsoft\u2019s Visual \nBasic had much to do with where we are today. I\u2019m not saying that Visual Basic \nwas a bad language and integrated development environment (IDE), because \nit\u2019s always been a highly productive environment and in some ways influenced \nthe industry for the good. Of course, some may have avoided its direct influ-\nence altogether, but Visual Basic indirectly caught up with just about every \nsoftware developer eventually. Just note the timeline shown in Table 1.3.\nwww.EBooksWorld.ir\n", "page": 57, "type": "text", "section": "Page 57"}
{"text": " \nWHY YOU SHOULD DO DDD\n15\nWhat I am talking about is the influence of properties and property sheets, \nboth backed by property getters and setters that were made so popular by the \noriginal Visual Basic forms designer. All you had to do was place a few custom \ncontrol instances on a form, fill out their property sheets, and voil\u00e0! You had \na fully functioning Windows application. It took just a few minutes to do that \ncompared to the few days required to program a similar application directly \nagainst the Windows API using C.\nSo what does all that have to do with Anemic Domain Models? The Java-\nBean standard was originally specified to assist in the creation of visual pro-\ngramming tools for Java. Its motivation was to bring the Microsoft ActiveX \ncapabilities to the Java platform. It offered the hope of creating a market full \nof third-party custom controls of various kinds, just like Visual Basic\u2019s. Soon \nalmost every framework and library jumped on the JavaBean bandwagon. This \nincluded much of the Java SDK/JDK as well as libraries such as the popular \nHibernate. Specific to our DDD concerns, Hibernate was introduced to persist \ndomain models. The trend continued as the .NET platform reached us.\nInterestingly, any domain model that was persisted using Hibernate in the \nearly days had to expose public getters and setters for every persistent sim-\nple attribute and complex association in every domain object. This meant that \neven if you wanted to design your POJO (Plain Old Java Object) with a behav-\nior-rich interface, you had to expose your internals publicly so that Hibernate \ncould persist and reconstitute your domain objects. Sure, you could do things \nto hide the public JavaBean interface, but by and large most developers didn\u2019t \nbother or even understand why they should have.\nShould I Be Concerned about Using Object-Relational Mappers with DDD?\nThe preceding critique of Hibernate is from a historical perspective. For quite a \nwhile now Hibernate has supported the use of hidden getters and setters, and even \ndirect field access. I demonstrate in later chapters how to avoid anemia in your mod-\nels when using Hibernate and other persistence mechanisms. So, don\u2019t sweat it.\nTable 1.3 The Timeline from Behavior Rich to Infamous Anemia\n1980s\n1991\n1992\u20131995\n1996\n1997\n1998\u2013\nObjects make \nan impact due \nto Smalltalk \nand C++\nVisual Basic \nproperties and \nproperty sheets\nVisual tools and \nIDEs become \nprolific\nJava JDK \n1.0 released\nJavaBean \nspecification\nExplosion of \nreflection-based \ntools for Java \nand .NET plat-\nforms based on \nproperties\nwww.EBooksWorld.ir\n", "page": 58, "type": "text", "section": "Page 58"}
{"text": "Chapter 1 GETTING STARTED WITH DDD\n16\nMost, if not all, of the Web frameworks also function solely on the JavaBean \nstandard. If you want your Java objects to be able to populate your Web pages, \nthe Java objects had better support the JavaBean specification. If you want \nyour HTML forms to populate a Java object when submitted to the server side, \nyour Java form object had better support the JavaBean specification. \nJust about every framework on the market today requires, and therefore \npromotes, the use of public properties on simple objects. Most developers can\u2019t \nhelp but be influenced by all the anemic classes all over their enterprises. Admit \nit. You\u2019ve been bitten by it, haven\u2019t you? As a result, we have a situation that \nmight be best labeled anemia everywhere.\nLook at What Anemia Does to Your Model\nAll right, so let\u2019s say we can agree that this is both true and vexing to us. What \ndoes anemia everywhere have to do with memory loss? When you are reading \nthrough the client code of an Anemic Domain Model (for example, the impos-\ntor Application Service (4, 14), \u00e0 la Transaction Script), what do we usually \nsee? Here\u2019s a rudimentary example:\n@Transactional\npublic void saveCustomer(\n    String customerId,\n    String customerFirstName, String customerLastName,\n    String streetAddress1, String streetAddress2,\n    String city, String stateOrProvince,\n    String postalCode, String country,\n    String homePhone, String mobilePhone,\n    String primaryEmailAddress, String secondaryEmailAddress) {\n    Customer customer = customerDao.readCustomer(customerId);\n    if (customer == null) {\n        customer = new Customer();\n        customer.setCustomerId(customerId);\n    }\n    customer.setCustomerFirstName(customerFirstName);\n    customer.setCustomerLastName(customerLastName);\n    customer.setStreetAddress1(streetAddress1);\n    customer.setStreetAddress2(streetAddress2);\n    customer.setCity(city);\n    customer.setStateOrProvince(stateOrProvince);\n    customer.setPostalCode(postalCode);\n    customer.setCountry(country);\n    customer.setHomePhone(homePhone);\n    customer.setMobilePhone(mobilePhone);\nwww.EBooksWorld.ir\n", "page": 59, "type": "text", "section": "Page 59"}
{"text": " \nWHY YOU SHOULD DO DDD\n17\n    customer.setPrimaryEmailAddress(primaryEmailAddress);\n    customer.setSecondaryEmailAddress (secondaryEmailAddress);\n    customerDao.saveCustomer(customer);\n}\nExample Purposely Kept Simple\nAdmittedly, this example is not from a very interesting domain, but it does help us \nexamine a less-than-ideal design and determine how we can refactor it to a much \nbetter one. Let\u2019s be clear that this exercise is not leading us to a cooler way to save \ndata. It\u2019s about crafting a software model that adds value to your business, even \nthough this example may not seem valuable.\nWhat did this code just do? Actually it\u2019s pretty versatile code. It saves a \nCustomer no matter whether it is new or preexisting. It saves a Customer\nno matter whether the last name changed or the person moved to a new home. \nIt saves a Customer no matter whether the person got a new home phone \nnumber or discontinued home phone service, or whether he or she got a mobile \nphone for the first time, or both. It even saves a Customer who switched from \nusing Juno to using Gmail instead, or who changed jobs and now has a new \nwork e-mail address. Wow, this is an awesome method!\nOr is it? Actually, we have no idea under what business situations this \nsaveCustomer() method is used\u2014not exactly, anyway. Why was this \nmethod created in the first place? Does anyone remember its original intent, \nand all the motivations for changing it to support a wide variety of business \ngoals? Those memories were quite likely lost only a few weeks or months after \nthe method was created and then modified. And it gets even worse. You don\u2019t \nbelieve me? Look at the next version of this same method:\n@Transactional\npublic void saveCustomer(\n    String customerId,\n    String customerFirstName, String customerLastName,\n    String streetAddress1, String streetAddress2,\n    String city, String stateOrProvince,\n    String postalCode, String country,\n    String homePhone, String mobilePhone,\n    String primaryEmailAddress, String secondaryEmailAddress) {\n    Customer customer = customerDao.readCustomer(customerId);\n    if (customer == null) {\n        customer = new Customer();\n        customer.setCustomerId(customerId);\n    }\nwww.EBooksWorld.ir\n", "page": 60, "type": "text", "section": "Page 60"}
{"text": "Chapter 1 GETTING STARTED WITH DDD\n18\n    if (customerFirstName != null) {\n        customer.setCustomerFirstName(customerFirstName);\n    }\n    if (customerLastName != null) {\n        customer.setCustomerLastName(customerLastName);\n    }\n    if (streetAddress1 != null) {\n        customer.setStreetAddress1(streetAddress1);\n    }\n    if (streetAddress2 != null) {\n        customer.setStreetAddress2(streetAddress2);\n    }\n    if (city != null) {\n        customer.setCity(city);\n    }\n    if (stateOrProvince != null) {\n        customer.setStateOrProvince(stateOrProvince);\n    }\n    if (postalCode != null) {\n        customer.setPostalCode(postalCode);\n    }\n    if (country != null) {\n        customer.setCountry(country);\n    }\n    if (homePhone != null) {\n        customer.setHomePhone(homePhone);\n    }\n    if (mobilePhone != null) {\n        customer.setMobilePhone(mobilePhone);\n    }\n    if (primaryEmailAddress != null) {\n        customer.setPrimaryEmailAddress(primaryEmailAddress);\n    }\n    if (secondaryEmailAddress != null) {\n        customer.setSecondaryEmailAddress (secondaryEmailAddress);\n    }\n    customerDao.saveCustomer(customer);\n}\nI have to note here that this example isn\u2019t as bad as it gets. Many times the \ndata-mapping code becomes quite complex, and a lot of business logic gets \ntucked away in it. I\u2019m sparing you the worst in this example, but you\u2019ve proba-\nbly seen it for yourself.\nNow each of the parameters other than the customerId is optional. We \ncan now use this method to save a Customer under at least a dozen business \nsituations, and more! But is that really a good thing? How could we actually \nwww.EBooksWorld.ir\n", "page": 61, "type": "text", "section": "Page 61"}
{"text": " \nWHY YOU SHOULD DO DDD\n19\ntest this method to ensure that it doesn\u2019t save a Customer under the wrong \nsituations?\nWithout going into extensive detail, this method could function incorrectly \nin more ways than it could correctly. Perhaps there are database constraints \nthat prevent a completely invalid state from being persisted, but now you have \nto look at the database to be sure. Almost certainly it will take you some time \nto mentally map between Java attributes and column names. Once you\u2019ve \nfigured out that part, you find that the database constraints are missing or \nincomplete.\nYou could look at the possibly many clients (not counting those added after \nthe user interface was completed to manage automatic remote clients) and com-\npare source revisions to gain some insight into why it is implemented the way \nit is right now. As you search for answers, you learn that nobody can explain \nwhy this one method works the way it does, or how many correct uses there \nare. It could take several hours or days to understand it on your own.\nCowboy Logic \nAJ:  \n\u201cThat fella\u2019s so confused, he doesn\u2019t know if he\u2019s \nsackin\u2019 potatoes or rollerskatin\u2019 in a buffalo herd.\u201d\nDomain experts can\u2019t help here because they would have to be programmers \nto understand the code. Even if a domain expert or two knew enough about \nprogramming or could at least read the code, they would probably be at least \nequally at a loss as a developer regarding all that code is meant to support. \nWith all these concerns in mind, do we dare change this code in any way, and \nif so, how?\nThere are at least three big problems here:\n 1. There is little intention revealed by the saveCustomer() interface.\n 2. The implementation of saveCustomer() itself adds hidden complexity.\n 3. The Customer \u201cdomain object\u201d isn\u2019t really an object at all. It\u2019s really just \na dumb data holder.\nLet\u2019s call this unenviable situation anemia-induced memory loss. It happens \nall the time on projects that produce this kind of implicit, completely subjective \ncode \u201cdesign.\u201d\nwww.EBooksWorld.ir\n", "page": 62, "type": "text", "section": "Page 62"}
{"text": "Chapter 1 GETTING STARTED WITH DDD\n20\nHold On a Minute!\nAt this point some of you may be thinking, \u201cOur designs never really leave the \nwhiteboard. We just draw some structure, and once agreement on that is reached, \nwe are set free to implement. Scary.\u201d\nIf so, try not to distinguish design from implementation. Remember that when \npracticing DDD, the design is the code and the code is the design. In other words, \nwhiteboard diagrams aren\u2019t the design, just a way to discuss the challenges of the \nmodel.\nStay tuned, as you\u2019ll learn how to take ideas off the whiteboard and make them \nwork for you.\nBy now you should be worried about this kind of code and how you can \ncreate a better design. The good news is that you can succeed in producing an \nexplicit, carefully crafted design in your code.\nHow to Do DDD\nLet\u2019s back away from heavy implementation discussions for a moment to con-\nsider one of the most empowering features of DDD, the Ubiquitous Language. \nIt\u2019s one of the two primary pillars of DDD\u2019s strengths, the second being the \nBounded Context (2), and one cannot properly stand without the other.\nTerms in a Context\nFor now think of a Bounded Context as a conceptual boundary around a whole \napplication or finite system. The reason for this boundary is to highlight that every \nuse of a given domain term, phrase, or sentence\u2014the Ubiquitous Language\u2014inside \nthe boundary has a specific contextual meaning. Any use of the term outside that \nboundary could, and probably does, mean something different. Chapter 2 explains \nBounded Context in depth.\nUbiquitous Language\nThe Ubiquitous Language is a shared team language. It\u2019s shared by domain \nexperts and developers alike. In fact, it\u2019s shared by everyone on the project \nteam. No matter your role on the team, since you are on the team you use the \nUbiquitous Language of the project.\nSo, You Think You Know What a Ubiquitous Language Is\nObviously it\u2019s the language of the business.\nWell, no.\nSurely it must be adopting industry standard terminology.\nNo, not really.\nwww.EBooksWorld.ir\n", "page": 63, "type": "text", "section": "Page 63"}
{"text": " \nHOW TO DO DDD\n21\nClearly it\u2019s the lingo used by the domain experts.\nSorry, but no.\nThe Ubiquitous Language is a shared language developed by the team\u2014a team \ncomposed of both domain experts and software developers.\nThat\u2019s it. Now you\u2019ve got it!\nNaturally, the domain experts have a heavy influence on the Language because \nthey know that part of the business best and may be influenced by industry stan-\ndards. However, the Language is more centered on how the business itself thinks \nand operates. Also, many times two or more domain experts disagree on concepts \nand terms, and they are actually wrong about some because they haven\u2019t thought of \nevery case before. So, as the experts and developers work together to craft a model \nof the domain, they use discussion with both consensus and compromise to achieve \nthe very best Language for the project. The team never compromises on the quality \nof the Language, just on the best concepts, terms, and meanings. Initial consensus is \nnot the end, however. The Language grows and changes over time as tiny and large \nbreakthroughs are achieved, much like any other living language.\nThis is no gimmick to get developers to be on the same page as domain \nexperts. It\u2019s not just a bunch of business jargon being forced on developers. It\u2019s \na real language that is created by the whole team\u2014domain experts, developers, \nbusiness analysts, everyone involved in producing the system. The Language \nmay start out with terms that are the natural lingo of the domain experts, but \nit isn\u2019t limited to that because the Language must grow over time. Suffice it to \nsay that when multiple domain experts are involved in creating the Language, \nthey often disagree ever so slightly on the terms and meanings of what they \nthought were already ubiquitous.\nIn Table 1.4, we not only model the administration of flu vaccines in code, \nbut the team must also speak the Language openly. When the team discusses \nthis aspect of the model, they literally speak phrases such as \u201cNurses adminis-\nter flu vaccines to patients in standard doses.\u201d\nThere will be some haggling and wrangling over the Language that exists \nin the minds of experts and what evolves from there. It\u2019s all part of the nat-\nural progression of developing the best Language that will matter a lot for a \nlong time. This happens through open discussion, looking at existing docu-\nments, business tribal knowledge that finally surfaces, as well as referencing \nstandards, dictionaries, and thesauruses. There\u2019s also a point reached where \nwe come to terms with the fact that some words and phrases just don\u2019t aptly fit \nthe business context as well as we once thought, and we realize that others fit \nit much better.\nwww.EBooksWorld.ir\n", "page": 64, "type": "text", "section": "Page 64"}
{"text": "Chapter 1 GETTING STARTED WITH DDD\n22\nSo how do you capture this all-important Ubiquitous Language? Here are \nsome ways that work as experimentation leads to advancement:\n\u2022 Draw pictures of the physical and conceptual domain and label them with \nnames and actions. These drawings are mostly informal but may contain \nsome aspects of formal software modeling. Even if your team does some \nformal modeling with Unified Modeling Language (UML), you want to \navoid any kind of ceremony that will bog down discussions and stifle the \ncreativity of the ultimate Language being sought.\n\u2022 Create a glossary of terms with simple definitions. List alternative terms, \nincluding the ones that show promise and the ones that didn\u2019t work, and \nwhy. As you include definitions, you cannot help but develop reusable \nphrases for the Language because you are forced to write in the Language \nof the domain.\n\u2022 If you don\u2019t like the idea of a glossary, still capture some kind of doc-\numentation that includes the informal drawings of important software \nconcepts. Again, the goal here is to force additional Language terms and \nphrases to surface.\n\u2022 Since only one or a few team members may capture the glossary or other \nwritten documents, circle back with the rest of the team to review the \nTable 1.4 Analyzing the Best Model for the Business\nWhich is better for the business?\nThough the second and third statements are similar, how should the code be designed?\nPossible Viewpoints\nResulting Code\n\u201cWho cares? Just code it up.\u201d\nUm, not even close.\npatient.setShotType(ShotTypes.TYPE_FLU);\npatient.setDose(dose);\npatient.setNurse(nurse);\n\u201cWe give flu shots to patients.\u201d\nBetter, but misses some \nimportant concepts.\npatient.giveFluShot();\n\u201cNurses administer flu  \nvaccines \nto patients in  \nstandard doses.\u201d\nThis seems like what we\u2019d like \nto run with at this time, at least \nuntil we learn more.\nVaccine vaccine = vaccines.standardAdultFluDose();\nnurse.administerFluVaccine(patient, vaccine);\nwww.EBooksWorld.ir\n", "page": 65, "type": "text", "section": "Page 65"}
{"text": " \nHOW TO DO DDD\n23\nresulting phrases. You won\u2019t always, if ever, agree on all the captured lin-\nguistics, so be agile and ready to edit heavily.\nThose are some ideal first steps to coining a Ubiquitous Language that fits \nyour specific domain. However, this is absolutely not the model that you are \ndeveloping. It\u2019s only the genesis of the Ubiquitous Language that will very soon \nbe expressed in your system\u2019s source code. We are talking Java, or C#, or Scala, \nor some other programming language of choice. These drawings and docu-\nments also don\u2019t address that the Ubiquitous Language will continue to expand \nand morph over time. The artifacts that originally led us down an inspiring \npath to developing a useful Ubiquitous Language that was just right for our \nspecialized domain will very likely be rendered obsolete over time. That\u2019s why \nin the end it is team speech and the model in the code that are the most endur-\ning and the only guaranteed current denotations of the Ubiquitous Language.\nSince team speech and the code will be the lasting expression of the Ubiq-\nuitous Language, be prepared to abandon the drawings, glossary, and other \ndocumentation that will be difficult to keep up-to-date with the spoken Ubiq-\nuitous Language and source code as they are rapidly enhanced. This is not a \nrequirement of using DDD, but it is pragmatic because it becomes impractical \nto keep all the documentation in sync with the system.\nWith this knowledge we can redesign the saveCustomer() example. What \nif we chose to make Customer reflect each of the possible business goals that \nit must support?\npublic interface Customer {\n    public void changePersonalName(\n        String firstName, String lastName);\n    public void postalAddress(PostalAddress postalAddress);\n    public void relocateTo(PostalAddress changedPostalAddress);\n    public void changeHomeTelephone(Telephone telephone);\n    public void disconnectHomeTelephone();\n    public void changeMobileTelephone(Telephone telephone);\n    public void disconnectMobileTelephone();\n    public void primaryEmailAddress(EmailAddress emailAddress);\n    public void secondaryEmailAddress(EmailAddress emailAddress);\n}\nWe can argue that this is not the best model for a Customer, but when \nimplementing DDD, questioning the design is expected. As a team we are free \nto haggle over what is the best model and settle only after we\u2019ve discovered the \nUbiquitous Language that is agreed upon. Still, the preceding interface does \nexplicitly reflect the various business goals that a Customer must support, \neven if the Language could be improved by refinements again and again.\nwww.EBooksWorld.ir\n", "page": 66, "type": "text", "section": "Page 66"}
{"text": "Chapter 1 GETTING STARTED WITH DDD\n24\nIt\u2019s important to understand too that the Application Service would also be \nrefactored to reflect the explicit intentions of the business goals at hand. Each \nApplication Service method would be modified to deal with a single use case \nflow or user story:\n@Transactional\npublic void changeCustomerPersonalName(\n    String customerId,\n    String customerFirstName,\n    String customerLastName) {\n    Customer customer = customerRepository.customerOfId(customerId);\n    if (customer == null) {\n        throw new IllegalStateException(\"Customer does not exist.\");\n    }\n    customer.changePersonalName(customerFirstName, customerLastName);\n}\nThis is different from the original example because in that code a single \nmethod was used to deal with many different use case flows or user stories. In \nthe new example we have limited a single Application Service method to deal \nwith changing the personal name of the Customer, and nothing more. Thus, \nwhen using DDD, it is our job to refine Application Services accordingly. This \nimplies that the user interface likewise reflects a narrower user goal, which \nmay have previously been true. Now, however, this specific Application Service \nmethod doesn\u2019t require its client to pass ten nulls following the first- and last-\nname parameters.\nDoesn\u2019t this new design put your mind at ease? You can read the code and \neasily comprehend it. You can also test it and confirm that it does exactly what \nit is meant to do, and that it doesn\u2019t do anything that it shouldn\u2019t.\nThus, the Ubiquitous Language is a team pattern used to capture the con-\ncepts and terms of a specific core business domain in the software model itself. \nThe software model incorporates the nouns, adjectives, verbs, and richer \nexpressions formally formulated and spoken by the close-knit team. Both the \nsoftware and the tests that verify the model\u2019s adherence to the tenets of the \ndomain capture and adhere to this Language, the same one spoken by the \nteam.\nUbiquitous, but Not Universal\nSome further clarification about the reach of a Ubiquitous Language is in \norder. There are a few basic concepts that we need to keep carefully in mind:\nwww.EBooksWorld.ir\n", "page": 67, "type": "text", "section": "Page 67"}
{"text": " \nTHE BUSINESS VALUE OF USING DDD\n25\n\u2022 Ubiquitous means \u201cpervasive,\u201d or \u201cfound everywhere,\u201d as spoken \namong the team and expressed by the single domain model that the team \ndevelops.\n\u2022 The use of the word ubiquitous is not an attempt to describe some kind \nof enterprise-wide, company-wide, or worldwide, universal domain \nlanguage.\n\u2022 There is one Ubiquitous Language per Bounded Context.\n\u2022 Bounded Contexts are relatively small, smaller than we might at first \nimagine. A Bounded Context is large enough only to capture the complete \nUbiquitous Language of the isolated business domain, and no larger.\n\u2022 The Language is ubiquitous only within the team that is working on the \nproject that develops in an isolated Bounded Context.\n\u2022 On a single project that develops a single Bounded Context, there are \nalways one or more additional isolated Bounded Contexts with which it \nintegrates using Context Maps (3). Each of the multiple Bounded Con-\ntexts that integrate has its own Ubiquitous Language, even though some \nterms of each may overlap.\n\u2022 If you try to apply a single Ubiquitous Language to an entire enterprise, \nor worse, universally among many enterprises, you will fail.\nWhen you begin a new project in which you are properly using DDD, iden-\ntify the isolated Bounded Context that is being developed. This places an \nexplicit boundary around your domain model. Discuss, research, conceptual-\nize, develop, and speak the Ubiquitous Language of the isolated domain model \nwithin the explicit Bounded Context. Reject all concepts that are not part of \nthe agreed-upon Ubiquitous Language of your isolated Context.\nThe Business Value of Using DDD\nIf your experience is anything like mine, you know that software developers \ncan no longer pursue technologies and techniques just because they sound \ncool or intriguing. We must justify everything that we do. I think that has not \nalways been true, but it is a good thing it is true now. I think the best justifica-\ntion for using any technology or technique is to provide value to the business. \nIf we can establish real, tangible business value, why would the business ever \nrefuse to use what we recommend?\nwww.EBooksWorld.ir\n", "page": 68, "type": "text", "section": "Page 68"}
{"text": "Chapter 1 GETTING STARTED WITH DDD\n26\nThe business case is strengthened especially if we can demonstrate that the \nbusiness values are higher with our recommended approach than with other \noptions.\nIsn\u2019t Business Value Most Important?\nSure, and perhaps I should have put this subheading \u201cThe Business Value of Using \nDDD\u201d earlier in the book. But it\u2019s done, now. This subheading could actually be \n\u201cHow You Can Sell DDD to Your Boss.\u201d Until you are mostly convinced that there \nis a real chance that you can actually implement DDD in your company, this book \nis just hypothetical. And I don\u2019t want you to read this book as just a theoretical \nexercise. Read it as a concrete reality for your company. Then you can become more \nexcited about how your company can really benefit. So read on.\nLet\u2019s consider the very realistic business value of employing DDD. Be sure to \nshare this openly with your management, domain experts, and technical team \nmembers. The value and benefits are summarized here, then I will elaborate. I \nstart off with the less technical benefits.\n 1. The organization gains a useful model of its domain.\n 2. A refined, precise definition and understanding of the business is \ndeveloped.\n 3. Domain experts contribute to software design.\n 4. A better user experience is gained.\n 5. Clean boundaries are placed around pure models.\n 6. Enterprise architecture is better organized.\n \n7. Agile, iterative, continuous modeling is used.\n 8. New tools, both strategic and tactical, are employed.\n1. The Organization Gains a Useful Model of Its Domain\nThe emphasis of DDD is to invest our efforts in what matters most to the busi-\nness. We don\u2019t over-model. We focus on the Core Domain. Other models exist \nto support the Core Domain and are important, too. Yet the supporting mod-\nels may not be given the priority and effort of the Core Domain.\nWhen our focus is on what distinguishes our business from all others, our \nmission is well understood and we have the parameters we need to keep on \ntrack. We will deliver exactly what is needed to achieve competitive advantage.\nwww.EBooksWorld.ir\n", "page": 69, "type": "text", "section": "Page 69"}
{"text": " \nTHE BUSINESS VALUE OF USING DDD\n27\n2.  \nA Refined, Precise Definition and Understanding of the \nBusiness Is Developed\nThe business may actually come to understand itself and its mission better than \nbefore. I have heard others state that the Ubiquitous Language developed for \nthe business\u2019s Core Domain has found its way into marketing materials. Cer-\ntainly it should be incorporated in vision documents and mission statements.\nAs the model is refined over time, the business develops a deep understand-\ning that can serve as an analysis tool. Details surface out of the minds of your \ndomain experts as you are challenged by one another and shaped by technical \nteam partners. These details can help your business analyze the value of the \ncurrent and future direction, both strategic and tactical.\n3. Domain Experts Contribute to Software Design\nThere is business value when the organization grows a deeper understanding \nof the core business. Domain experts don\u2019t always agree on concepts and ter-\nminology. Sometimes the differences are fostered by different experiences from \noutside before joining the organization. Sometimes it happens because of the \ndivergent paths taken by each expert within the same organization. Yet when \nbrought together to a DDD effort, the domain experts gain consensus among \nthemselves. This fortifies the effort and the organization as a whole.\nDevelopers now share a common Language as a unified team along with \ndomain experts. They benefit further from the knowledge transfer from the \ndomain experts they work with. As developers inevitably move on, either to a \nnew Core Domain or out of the organization, training and handoffs are eas-\nier. The chances of developing \u201ctribal knowledge,\u201d where only a select few \nunderstand the model, are reduced. The experts, remaining developers, and \nnew ones continue to share a common knowledge that is available to anyone in \nthe organization who requires it. This advantage exists because there remains \nan express goal to adhere to the Language of the domain.\n4. A Better User Experience Is Gained\nOften the end user experience can be tuned to better reflect the model of the \ndomain. Domain-Driven is formally \u201cbaked in,\u201d influencing human use of the \nsoftware.\nWhen software leaves too much to the understanding of its users, users must \nbe trained to make a great number of decisions. In essence the users are only \ntransferring the understanding in their minds into data that they enter into \nforms. The data is then saved to a data store. If users don\u2019t understand exactly \nwww.EBooksWorld.ir\n", "page": 70, "type": "text", "section": "Page 70"}
{"text": "Chapter 1 GETTING STARTED WITH DDD\n28\nwhat is needed, the results are incorrect. Often this leads to guesswork with \nrelated lowered productivity until users can figure out the software.\nWhen the user experience is designed to follow the contours of the under-\nlying expert model, users are led to correct conclusions. The software actually \ntrains the users, which reduces the training overhead to the business. Quicker \nto productivity with less training\u2014that\u2019s business value.\nWe next move into more technically driven benefits to the business.\n5. Clean Boundaries Are Placed around Pure Models\nThe technical team is discouraged from doing what might appeal more to their \nprogramming and algorithmic interests by aligning expectations with business \nadvantage. Purity in direction allows for focus on the potency of the solution, \nwith efforts directed to where they matter the most. Achieving this is very \nclosely connected to understanding the Bounded Context of the project.\n6. Enterprise Architecture Is Better Organized\nWhen Bounded Contexts are well understood and carefully partitioned, all \nteams in the enterprise develop an acute understanding of where and why \nintegrations are necessary. The boundaries are explicit, and the relationships \nbetween them are as well. The teams that have models that intersect by usage \ndependency employ Context Maps to establish formal relationships and ways \nto integrate. This can actually lead to a very thorough understanding of the \nentire enterprise architecture.\n7. Agile, Iterative, Continuous Modeling Is Used\nThe word design can evoke negative thoughts in the minds of business manage-\nment. However, DDD is not a heavyweight, high-ceremony design and devel-\nopment process. DDD is not about drawing diagrams. It is about carefully \nrefining the mental model of domain experts into a useful model for the busi-\nness. It is not about creating a real-world model, as in trying to mimic reality.\nThe team\u2019s efforts follow an agile approach, which is iterative and incremen-\ntal. Any agile process that the team feels comfortable with can be used success-\nfully in a DDD project. The model that is produced is the working software. It \nis refined continuously until it is no longer needed by the business.\n8. New Tools, Both Strategic and Tactical, Are Employed \nA Bounded Context gives the team a modeling boundary in which to create \na solution to a specific business problem domain. Inside a single Bounded \nwww.EBooksWorld.ir\n", "page": 71, "type": "text", "section": "Page 71"}
{"text": " \nTHE CHALLENGES OF APPLYING DDD\n29\nContext is a Ubiquitous Language formulated by the team. It is spoken among \nthe team and in the software model. Disparate teams, sometimes each respon-\nsible for a given Bounded Context, use Context Maps to strategically segregate \nBounded Contexts and understand their integrations. Within a single modeling \nboundary the team may employ any number of useful tactical modeling tools: \nAggregates (10), Entities (5), Value Objects (6), Services (7), Domain Events (8),\nand others.\nThe Challenges of Applying DDD\nAs you implement DDD, you will encounter challenges. So has everyone else \nwho has succeeded at it. What are the common challenges and how do we jus-\ntify using DDD as we face them? I will discuss the more common ones:\n\u2022 Allowing for the time and effort required to create a Ubiquitous Language\n\u2022 Involving domain experts at the outset and continuously with the project\n\u2022 Changing the way developers think about solutions in their domain\nOne of the greatest challenges in using DDD can be the time and effort \nrequired to think about the business domain, research concepts and termi-\nnology, and converse with domain experts in order to discover, capture, and \nenhance the Ubiquitous Language rather than coding in techno-babble. If you \nwant to apply DDD completely, with the greatest value to the business, it\u2019s \ngoing to require more thought and effort, and it\u2019s going to take more time. \nThat\u2019s the way it is, period.\nIt can also be a challenge to solicit the necessary involvement from domain \nexperts. No matter how difficult it is, make sure you do. If you don\u2019t get \ncommitment from at least one real expert, you are not going to uncover deep \nknowledge of the domain. When you do get the domain experts\u2019 involvement, \nthe onus falls back on the developers. Developers must converse with and listen \ncarefully to the true experts, molding their spoken language into software that \nreflects their mental model of the domain.\nIf the domain you are working in is truly distinguishing to your business, \ndomain experts have the edge-knowledge locked up in their heads, and you \nneed to draw it out. I\u2019ve been on projects where the real domain experts are \nhardly around. Sometimes they travel a lot and it can be weeks between one-\nhour meetings with them. In a small business it can be the CEO or one of the \nvice presidents, and they have lots of other things to do that may seem more \nimportant.\nwww.EBooksWorld.ir\n", "page": 72, "type": "text", "section": "Page 72"}
{"text": "Chapter 1 GETTING STARTED WITH DDD\n30\nCowboy Logic \nAJ:  \n\u201cIf you can\u2019t rope the big steer, you\u2019re gonna go \nhungry.\u201d\nGetting domain expert involvement may require creativity . . . \nHow to Involve Domain Experts in Your Project\nCoffee. Use that Ubiquitous Language: \n\u201cHi, Sally, I got you a tall half-skinny half-one-per-\ncent extra-hot split-quad-shot latte with whip. Do \nyou have a few minutes to talk about . . . ?\u201d\nLearn to use the Ubiquitous Language of C-Level \nmanagement: \u201c. . . profits . . . revenues . . . com-\npetitive edge . . . market domination.\u201d Seriously.\nHockey tickets.\nMost developers have had to change the way they think in order to properly \napply DDD. We developers are technical thinkers. Technical solutions come \neasy for us. It\u2019s not that thinking technically is bad. It\u2019s just that there are \ntimes when thinking less technically is better. If it\u2019s been our habit to practice \nsoftware development only in technical ways for years, perhaps now would \nbe a good time to consider a new way of thinking. Developing the Ubiquitous \nLanguage of your domain is the best place to start.\nCowboy Logic \nLB:  \n\u201cThat fella\u2019s boots are too small. If he don\u2019t find him-\nself another pair, his toes are gonna hurt.\u201d\nAJ:  \n\u201cYep. If you don\u2019t listen, you\u2019re gonna have to feel.\u201d\nThere\u2019s another level of thought that is required with DDD that goes beyond \nconcept naming. When we model a domain through software, we are required \nwww.EBooksWorld.ir\n", "page": 73, "type": "text", "section": "Page 73"}
{"text": " \nTHE CHALLENGES OF APPLYING DDD\n31\nto give careful thought to which model objects do what. It\u2019s about designing \nthe behaviors of objects. Yes, we want the behaviors to be named properly to \nconvey the essence of the Ubiquitous Language. But what an object does by \nmeans of a specific behavior must be considered. This is a level of effort that \ngoes beyond creating attributes on a class and exposing getters and setters pub-\nlicly to clients of the model.\nLet\u2019s now look at a more interesting domain, one that is more challenging \nthan the rudimentary one previously considered. I purposely repeat my previ-\nous guidance here to reinforce the ideas.\nAgain, what happens if we simply provide data accessors to our model? To \nreemphasize, if we only expose the data accessors for our model objects, the \nresults will look much like a data model. Consider the following two exam-\nples and decide for yourself which of the two requires more thorough design \nthought, and which produces the greater benefit to its clients. The requirement \nis in a Scrum model, where we need to commit a backlog item to a sprint. You \nprobably do this all the time, so it\u2019s most likely a familiar domain.\nThe first example, as is commonly done today, uses attribute accessors:\npublic class BacklogItem extends Entity {\n    private SprintId sprintId;\n    private BacklogItemStatusType status;\n    ...\n    public void setSprintId(SprintId sprintId) {\n        this.sprintId = sprintId;\n    }\n    public void setStatus(BacklogItemStatusType status) {\n        this.status = status;\n    }\n    ...\n}\nAs for the client of this model:\n// client commits the backlog item to a sprint\n// by setting its sprintId and status\nbacklogItem.setSprintId(sprintId);\nbacklogItem.setStatus(BacklogItemStatusType.COMMITTED);\nThe second example uses a domain object behavior that expresses the Ubiq-\nuitous Language of the domain:\nwww.EBooksWorld.ir\n", "page": 74, "type": "text", "section": "Page 74"}
{"text": "Chapter 1 GETTING STARTED WITH DDD\n32\npublic class BacklogItem extends Entity {\n    private SprintId sprintId;\n    private BacklogItemStatusType status;\n    ...\n    public void commitTo(Sprint aSprint) {\n        if (!this.isScheduledForRelease()) {\n            throw new IllegalStateException(\n                \"Must be scheduled for release to commit to sprint.\");\n        }\n        if (this.isCommittedToSprint()) {\n            if (!aSprint.sprintId().equals(this.sprintId())) {\n                this.uncommitFromSprint();\n            }\n        }\n        this.elevateStatusWith(BacklogItemStatus.COMMITTED);\n        this.setSprintId(aSprint.sprintId());\n        DomainEventPublisher\n            .instance()\n            .publish(new BacklogItemCommitted(\n                    this.tenant(),\n                    this.backlogItemId(),\n                    this.sprintId()));\n    }\n    ...\n}\nThe client of this explicit model seems to operate on safer ground:\n// client commits the backlog item to a sprint\n// by using a domain-specific behavior\nbacklogItem.commitTo(sprint);\nThe first example uses a very data-centric approach. The onus is entirely on \nthe client to know how to correctly commit the backlog item to a sprint. The \nmodel, which is not really a domain model, doesn\u2019t help at all. What if the cli-\nent mistakenly changes only the sprintId but not the status, or the oppo-\nsite? Or what if in the future another attribute must be set? The client code \nmust be analyzed for correct mapping of data values to the proper attributes \non the BacklogItem.\nThis approach also exposes the shape of the BacklogItem object and \nclearly focuses attention on its data attributes and not on its behaviors. Even \nwww.EBooksWorld.ir\n", "page": 75, "type": "text", "section": "Page 75"}
{"text": " \nTHE CHALLENGES OF APPLYING DDD\n33\nif you argue that setSprintId() and setStatus() are behaviors, the case \nin point is that these \u201cbehaviors\u201d have no real business domain value. These \n\u201cbehaviors\u201d do not explicitly indicate the intentions of the scenarios that the \ndomain software is supposed to model, that of committing a backlog item to \na sprint. They do cause cognitive overload when the client developer tries to \nmentally select from among the BacklogItem attributes needed to commit \na backlog item to a sprint. There could be many because it\u2019s a data-centric \nmodel.\nNow consider the second example. Instead of exposing the data attributes \nto clients, it exposes a behavior that explicitly and clearly indicates that a client \nmay commit a backlog item to a sprint. Experts in this particular domain dis-\ncuss the following requirement of the model:\nAllow each backlog item to be committed to a sprint. It may be committed only \nif it is already scheduled for release. If it is already committed to a different \nsprint, it must be uncommitted first. When the commit completes, notify inter-\nested parties.\nThus, the method in the second example captures the Ubiquitous Language of \nthe model in context, that is, the Bounded Context in which the  \nBacklogItem\ntype is isolated. And as we analyze this scenario, we discover that the first solu-\ntion is incomplete and contains bugs.\nWith the second implementation clients don\u2019t need to know what is required \nto perform the commit, whether simple or complex. The implementation of this \nmethod has as much or as little logic as necessary. We easily added a guard to \nprotect against committing a backlog item that is not yet scheduled for release. \nTrue, you can also place guards inside the setters of the first implementation, \nbut the setter now becomes responsible for understanding the full context of \nthe object\u2019s state rather than just the requirements for sprintId and status.\nThere\u2019s another subtle difference here, too. Note that if the backlog item is \nalready committed to another sprint, it will first be uncommitted from the cur-\nrent sprint. This is an important detail, because when a backlog item is uncom-\nmitted from a sprint, a Domain Event is to be published to clients:\nAllow each backlog item to be uncommitted from a sprint. When the backlog \nitem is uncommitted, notify interested parties.\nThe publication of the uncommitted notification is obtained for free just by \nusing the domain behavior uncommitFrom(). Method commitTo() doesn\u2019t \neven need to know that it notifies. All it needs to know is that it must uncom-\nmit from any current sprint before committing to a new sprint. Additionally, \nthe commitTo() domain behavior also notifies interested parties with an \nEvent as its final step. Without placing this rich behavior in BacklogItem\nwww.EBooksWorld.ir\n", "page": 76, "type": "text", "section": "Page 76"}
{"text": "Chapter 1 GETTING STARTED WITH DDD\n34\nwe would have to publish Events from the client. That would certainly leak \ndomain logic from the model. Bad.\nClearly, more thought is needed to create the BacklogItem of the second \nexample than that of the first. Yet the thought needed is not so much greater, \nand the benefits are so much higher. The more we learn to design in this way, \nthe easier it becomes. In the end, there is certainly more required thought, more \neffort, more collaboration and orchestration of team efforts, but not so much \nthat DDD becomes heavy. New thought is well worth the effort.\nWhiteboard Time\n\u2022 Using the specific domain you currently work in, think of the common \nterms and actions of the model.\n\u2022 Write the terms on the board.\n\u2022 Next, write phrases that should be used by your team when you talk \nabout the project.\n\u2022 Discuss them with a real domain expert to see how they could be refined \n(remember to bring the coffee).\nJustification for Domain Modeling\nTactical modeling is generally more complex than strategic modeling. Thus, if \nyou intend to develop a domain model using the DDD tactical patterns (Aggre-\ngates, Services, Value Objects, Events, and so forth), doing so will require more \ncareful thought and greater investment. Since this is so, how does an organiza-\ntion justify tactical domain modeling? What criteria can be used to qualify a \ngiven project for the extra investment needed to properly apply DDD from top \nto bottom?\nPicture yourself leading an expedition through unfamiliar territory. You \nwould want to understand the surrounding landmasses and borders. Your \nteam would study maps, maybe even draw their own, and determine their stra-\ntegic approach. You would consider aspects of the terrain and how it could be \nused to your advantage. No matter how much planning is done, some facets of \nsuch an endeavor are going to be really difficult.\nIf your strategy indicated that you\u2019d have to scale a vertical rock face, you\u2019d \nneed some fitting tactical tools and maneuvers for that ascent. Standing at the \nbottom and looking up, you might see some indication of specific challenges \nand perilous areas. Yet, you wouldn\u2019t see every detail until you were on the \nwww.EBooksWorld.ir\n", "page": 77, "type": "text", "section": "Page 77"}
{"text": " \nTHE CHALLENGES OF APPLYING DDD\n35\nrock face. You might need to drive pitons into slick rock, but you could use var-\nious-size cams to wedge into natural cracks. To latch on to these climbing pro-\ntections, you\u2019d bring along your carabiners. You would try to take as straight \na path as possible but would have to make specific determinations point by \npoint. Sometimes you might even have to backtrack and reroute depending on \nwhat the rock dictated. Many people think of climbing as a dangerous thrill \nsport, but those who actually climb will tell you it\u2019s safer than driving a car or \nflying an airplane. Clearly, for that to be true, climbers need to understand the \ntools and techniques and how to judge the rock.\nIf developing a given Subdomain (2) requires such a difficult, even precari-\nous, ascent, we\u2019d bring the DDD tactical patterns along for the climb. A busi-\nness initiative that matches the criteria of the Core Domain should not quickly \ndismiss the use of the tactical patterns. The Core Domain is an unknown and \ncomplex area. The team is best protected against a disastrous mid-asset fall if \nusing the right tactics.\nHere\u2019s some practical guidance. I begin with the high-level ones and prog-\nress to more details:\n\u2022 If a Bounded Context is being developed as the Core Domain, it is stra-\ntegically vital to the success of the business. The core model is not well \nunderstood and will require lots of experimentation and refactoring. It \nlikely deserves commitment to longevity with continuous enhancement. \nIt may not always be your Core Domain. Nonetheless, if the Bounded \nContext is complex, innovative, and needs to endure for a long time as it \nundergoes change, strongly consider the use of the tactical patterns as an \ninvestment in the future of your business. This assumes that your Core \nDomain deserves the best developer resources with a high skill level.\n\u2022 A domain that may become a Generic Subdomain (2) or Supporting Sub-\ndomain to its consumers may actually be a Core Domain to your busi-\nness. You don\u2019t always judge a domain from the viewpoint of its ultimate \nconsumers. If you are developing a Bounded Context as your chief busi-\nness initiative, it is your Core Domain regardless of how it is viewed by \ncustomers outside your business. Strongly consider the use of the tactical \npatterns.\n\u2022 If you are developing a Supporting Subdomain that, for various reasons, \ncannot be acquired as a third-party Generic Subdomain, it is possible that \nthe tactical patterns would benefit your efforts. In this case consider the \nskill level of the team and whether or not the model is new and inno-\nvative. It is innovative if it adds specific business value, captures special \nknowledge, and is not just technically intriguing. If the team is capable of \nwww.EBooksWorld.ir\n", "page": 78, "type": "text", "section": "Page 78"}
{"text": "Chapter 1 GETTING STARTED WITH DDD\n36\nproperly applying tactical design, and the Supporting Subdomain is inno-\nvative and must endure for years in the future, this is a good opportunity \nto invest in your software using tactical design. However, this does not \nmake this model the Core Domain since in the eyes of the business it is \nmerely Supporting.\nThese guidelines may be somewhat confining if your business employs a \ngood number of developers with vast experience in and a very high comfort \nlevel with domain modeling. Where experience is very high, and the engineers \nthemselves believe the tactical patterns would be the best choice, it makes sense \nto trust their opinion. Honest developers, no matter how experienced, will \nindicate in a specific case that developing a domain model is, or is not, the best \nchoice.\nThe type of business domain itself is not automatically the determining fac-\ntor for choosing a development approach. Your team should consider import-\nant questions to help you make the final determination. Consider the following \nshort list of more detailed decision parameters, which is more or less aligned \nwith and expands on the preceding higher-level guidelines:\n\u2022 Are domain experts available and are you committed to forming a team \naround them?\n\u2022 Although the specific business domain is somewhat simple now, will it \ngrow in complexity over time? There is risk in using Transaction Script1\nfor complex applications. If you use Transaction Script now, will the \npotential for refactoring to a behavioral domain model later on be practi-\ncal if/when the Context becomes complex?\n\u2022 Will the use of the DDD tactical patterns make it easier and more prac-\ntical to integrate with other Bounded Contexts, whether third-party or \ncustom developed?\n\u2022 Will development really be simpler and require less code if you use Trans-\naction Script? (Experience with both approaches proves that many times \nTransaction Script requires as much or more code. This is probably \nbecause the complexity of the domain and the innovation of the model \nwere not well understood during project planning. Underestimating \ndomain complexity and the innovation involved happens often.)\n\u2022 Do the critical path and timeline allow for any overhead required for tac-\ntical investment?\n 1. Here I am generalizing terms. In this list I use Transaction Script to represent sev-\neral non-domain-model approaches.\nwww.EBooksWorld.ir\n", "page": 79, "type": "text", "section": "Page 79"}
{"text": " \nTHE CHALLENGES OF APPLYING DDD\n37\n\u2022 Will the tactical investment in a Core Domain protect the system from \nchanging architectural influences? Transaction Script may leave it exposed. \n(Domain models are often enduring while architectural influences tend to \nbe more disruptive to other layers.)\n\u2022 Will clients/customers benefit from a cleaner, enduring design and devel-\nopment approach, or could their application be replaced by an off-the-\nshelf solution tomorrow? In other words, why would we ever develop this \nas a custom application/service in the first place?\n\u2022 Will developing an application/service using tactical DDD be more diffi-\ncult than using other approaches such as Transaction Script? (Skill level \nand availability of domain experts is vital to answering this question.)\n\u2022 If the team\u2019s toolkit was complete with DDD enablers, would we consci-\nentiously choose to use another approach instead? (Some enablers make \nmodel persistence practical, such as using object-relational mapping, full \nAggregate serialization and persistence, an Event Store, or a framework \nthat supports tactical DDD. There may be other enablers, too.)\nThis list is not prioritized for your domain, and you can probably assemble \nadditional criteria. You understand the compelling reasons for using the best \nand most empowering methods possible to your advantage. You also know \nyour business and technology landscape. In the end it is the business customer, \nnot the object practitioners and technologists, who must be pleased. Choose \nwisely.\nDDD Is Not Heavy\nIn no way do I want to imply that properly practicing DDD leads to a heavy-\nweight process with lots of ceremony and all the crufty documentation arti-\nfacts that must be supported. That\u2019s not what DDD is about. It is meant to fit \nwell into any agile project framework, such as Scrum, that the team desires to \nuse. Its design tenets lean toward rather rapid test-first refinements of a real \nsoftware model. If you were in need of developing a new domain object, such \nas an Entity or a Value Object, the test-first approach works like this:\n 1. Write a test that demonstrates how the new domain object should be used \nby a client of the domain model.\n 2. Create the new domain object with enough code to make the test compile.\n 3. Refactor both until the test properly represents the way a client would use \nthe domain object, and the domain object has proper behavioral method \nsignatures.\nwww.EBooksWorld.ir\n", "page": 80, "type": "text", "section": "Page 80"}
{"text": "Chapter 1 GETTING STARTED WITH DDD\n38\n 4. Implement each domain object behavior until the test passes, refactoring \nthe domain object until no inappropriate code duplications exist.\n 5. Demonstrate the code to team members, including domain experts, to \nensure that the test is using the domain object according to the current \nmeaning of the Ubiquitous Language.\nYou may conclude that this is not any different from the test-first approach \nyou already practice. Well, it might be a little different, but the point is that it\u2019s \nbasically the same. This test stage is not attempting to prove with absolute cer-\ntainty that the model is bulletproof. Later we will add tests to do that. First we \nwant to focus on how the model will be used by clients, and these tests drive \nthe model\u2019s design. The good news is that it really is an agile approach. DDD \npromotes lightweight development, not ceremonious, heavy, up-front design. \nFrom that standpoint it really isn\u2019t different from common agile development. \nSo, while the preceding steps may not enlighten you about agile, I think they \nclarify the position of DDD, that it is meant to be used in an agile way.\nLater you also add tests that verify the correctness of the new domain object \nfrom every possible (and practical) angle. At this point you are interested in the \ncorrectness of the expression of a domain concept that is embodied in the new \ndomain object. Reading the demonstrative clientlike test code must reveal the \nproper expressiveness using the Ubiquitous Language. Domain experts who \nare nontechnical should be able, with the help of a developer, to read the code \nwell enough to get a clear impression that the model has achieved the goal of \nthe team. This implies that test data must be realistic and support and enhance \nthe desired expressiveness. Otherwise, domain experts cannot make a com-\nplete judgment about the implementation.\nThis test-first agile methodology repeats until you have a model that is \nworking according to the tasks outlined for the current iteration. The steps \noutlined previously are agile and represent what Extreme Programming orig-\ninally promoted. Using agile does not eliminate any essential DDD patterns \nand practices. They go together quite well. Of course, you can choose to use \nfull DDD without doing test-first development. You can always develop tests \nagainst existing model objects. However, designing from the model client\u2019s \nperspective adds a very desirable dimension.\nFiction, with Bucketfuls of Reality\nAs I contemplated how to best present implementation guidance for contempo-\nrary use of DDD, I wanted to provide justification for everything I say should \nwww.EBooksWorld.ir\n", "page": 81, "type": "text", "section": "Page 81"}
{"text": " \nFICTION, WITH BUCKETFULS OF REALITY\n39\nbe done. That meant supplying not just the how, but the why. It occurred to \nme that looking at a few projects as case studies would appropriately illustrate \nwhy I made a certain suggestion and demonstrate how proper use of DDD will \nsolve the challenges commonly faced.\nSometimes it\u2019s easier to look at the problems faced by other project teams \nand learn from their misuse of DDD than it is to look inward. Certainly, once \nyou recognize the flaws of others\u2019 work, you\u2019ll be able to judge whether or \nnot you are leaning in the same precarious direction, or even standing in the \nthick of the same morass. Then, knowing where you are headed or where you \nalready are, you can make the precise adjustments to correct problems and \navoid the same in the future.\nRather than present a series of actual projects that I have worked on\u2014ones \nthat I could not discuss openly anyway\u2014I decided to use a bit of fiction based \non real-world situations that I and others have experienced. That way I could \ncreate the perfect state of affairs to demonstrate the reasons a specific imple-\nmentation approach works best, or at least better, when dealing with chal-\nlenges in DDD.\nSo it is not just fiction on which I am interested in building case studies. It is \na fictitious company with a real-world business charter, fictitious teams within \nthe company with real-world software to build and deploy, and real-world \nDDD challenges and resulting problems with real-world solutions to them. It\u2019s \nwhat I call \u201cfiction with bucketfuls of reality.\u201d I have found it quite effective to \nwrite in this style. I hope you benefit from it.\nWhen presenting any set of examples, we must limit the scope to make it \npractical. Otherwise, the volume will drown efforts to teach and learn. Exam-\nples cannot be overly simplistic either, or vital lessons would be lost. To balance \nthis effort, the business situation I have chosen is largely based on greenfield \ndevelopment.\nAs we peer into the projects at various points in time, we\u2019ll see different \nproblems and successes that the teams experience. The Core Domain that \nis the focus of the examples is sufficiently complex to examine DDD from \nvarious perspectives. Our Bounded Contexts use one or more others, which \nenables us to investigate integration with DDD. Still, the three sample models \ncannot possibly demonstrate every aspect of strategic design, such as occurs in \na \u201cbrownfield\u201d environment common where many legacy systems exist. I don\u2019t \ncompletely dodge those less attractive regions, as if they are irrelevant. When-\never advisable we will diverge from the main samples and study areas where \nDDD guidance can be used in additional advantageous ways.\nNow allow me to introduce you to the company and tell you a little bit \nabout its teams and the projects they are working on.\nwww.EBooksWorld.ir\n", "page": 82, "type": "text", "section": "Page 82"}
{"text": "Chapter 1 GETTING STARTED WITH DDD\n40\nSaaSOvation, Its Products, and Its Use of DDD\nThe company is SaaSOvation. As its name implies, \nSaaSOvation\u2019s charter is to develop a series of software \nas a service, or SaaS, products. The SaaS products are \nhosted by SaaSOvation and accessed and used by sub-\nscribing organizations. The company\u2019s business plan \nincludes two planned products, one to precede the other.\nThe flagship product is named CollabOvation. It is \na corporate collaboration suite, which sports the fea-\ntures of leading social networks. These include forums, \nshared calendars, blogs, instant messaging, wiki, mes-\nsage boards, document management, announcements and alerts, activity tracking, \nand RSS feeds. All of the collaboration tools are focused on the needs of corporate \nbusinesses, helping them spike productivity in smaller projects, in larger programs, \nand across business units. Business collaboration is important for creating and facil-\nitating a synergistic atmosphere in today\u2019s changing and sometimes uncertain, yet \nfast-paced economy. Anything that can help propel productivity forward, transfer \nknowledge, promote idea sharing, and associatively manage the creative process \nso results will not be misplaced will be a boon to the corporate success equation. \nCollabOvation provides a high-value proposition to customers, and the challenge will \nalso please its developers.\nThe second product, named ProjectOvation, is the Core Domain of primary focus. \nThe tool focuses on the management of agile projects, using Scrum as the itera-\ntive and incremental project management framework. ProjectOvation follows the tra-\nditional Scrum project management model, complete with product, product owner, \nteam, backlog items, planned releases, and sprints. Backlog item estimation is pro-\nvided through business value calculators that use cost-benefit analysis. If you think of \nScrum at its richest, that\u2019s where ProjectOvation is headed. But SaaSOvation plans \nto get more bang for its buck.\nCollabOvation and ProjectOvation would not go down entirely separate paths. \nSaaSOvation and its board of advisers envisioned innovation around weaving col-\nlaboration tools in with agile software development. Thus, CollabOvation features will \nbe offered as an optional add-on to ProjectOvation. Without a doubt, supplying col-\nlaboration tools for project planning, feature and story discussions, team and inter-\nteam group discussion, and support will be a popular option. SaaSOvation forecasts \nthat more than 60 percent of ProjectOvation subscribers will add on CollabOvation \nfeatures. And this kind of add-on sales often ends up leading to new full sales of the \nadd-on product itself. Once a sales channel is established and software development \nteams see the power of collaboration in their project management suite, their enthu-\nsiasm will influence full corporate adoption of the complete collaboration suite. Due to \nthis viral sales approach, SaaSOvation further forecasts that at a minimum 35 percent \nof all ProjectOvation sales will lead to full corporate adoption of CollabOvation. They \nconsider this a conservative estimate, but one that will make it extremely successful.\nThe CollabOvation product development team is staffed first. There are a few \nseasoned veterans on the team, but a greater number of midlevel developers. Early \nwww.EBooksWorld.ir\n", "page": 83, "type": "text", "section": "Page 83"}
{"text": " \nWRAP-UP\n41\nmeetings pointed to Domain-Driven Design as the favored design and development \napproach. One of the two senior developers had used a minimal set of DDD patterns \non a previous project at his former employer. As he described his experience to the \nteam, it would have been clear to a more experienced DDD practitioner that this was \nnot full use of DDD. What he had done is sometimes referred to as DDD-Lite.\nDDD-Lite is a means of picking and choosing a subset of the DDD tactical pat-\nterns, but without giving full attention to discovering, capturing, and enhancing the \nUbiquitous Language. As well, this technique generally bypasses the use of Bounded \nContexts and Context Mapping. Its focus is much more technical, with a desire to \nsolve technical problems. It can have benefits, but generally not with as high a reward \nas including strategic modeling along with it. SaaSOvation bought into this. In its case \ndoing so soon led to problems because the team didn\u2019t understand Subdomains and \nthe power and safety of explicit Bounded Contexts.\nThings could have been worse. SaaSOvation actually avoided some major pit-\nfalls of using DDD-Lite, just because its two core products formed a natural set of \nBounded Contexts. This tended to keep the CollabOvation model and the Project-\nOvation model formally segregated. But that was just by chance. It didn\u2019t mean the \nteam understood Bounded Context, which is why the problems they did experience \nhappened in the first place. Well, you either learn or you fail.\nIt\u2019s good that we can benefit from examining SaaSOvation\u2019s incomplete use \nof DDD. The team eventually learned from their mistakes by acquiring a better \ngrasp of strategic design. You will also learn from the adjustments the Col-\nlabOvation team made, as the eventual ProjectOvation team benefited from \nretrospectives of the early conditions of its sister and partner project. See Sub-\ndomains (2) and Bounded Contexts (2), as well as Context Maps (3), for the \nfull story.\nWrap-Up\nWell, that\u2019s a pretty encouraging start with DDD. I think by now you probably \nhave gotten a good feeling that you and your team can actually succeed with \nan advanced software development technique. I agree.\nOf course, we aren\u2019t going to oversimplify things. Implementing DDD takes \nreal concerted effort. If it were easy, everybody would be writing great code, \nwww.EBooksWorld.ir\n", "page": 84, "type": "text", "section": "Page 84"}
{"text": "Chapter 1 GETTING STARTED WITH DDD\n42\nand we know that just doesn\u2019t happen. So get ready. It will be worth it, because \nyour design will be exactly how your software works.\nHere\u2019s what you\u2019ve learned so far:\n\u2022 You\u2019ve discovered what DDD can do for your projects and your teams to \nhelp you grapple with domain complexity.\n\u2022 You found out how to score your project to see if it deserves the DDD \ninvestment.\n\u2022 You considered the common alternatives to DDD and why using those \napproaches often leads to problems.\n\u2022 You\u2019ve grasped the foundations of DDD and are prepared to take the first \nsteps on your project.\n\u2022 You\u2019ve found out how to sell DDD to your management, domain experts, \nand technical team members.\n\u2022 You are now armed with knowledge of how to succeed while facing the \nchallenges of DDD.\nHere\u2019s where we\u2019re going next. The next two chapters are on the all-im-\nportant strategic design, followed by a chapter on software architectures with \nDDD. This is really important stuff to get a handle on before you move to the \nsubsequent chapters on tactical modeling.\nwww.EBooksWorld.ir\n", "page": 85, "type": "text", "section": "Page 85"}
{"text": "43\nChapter 2\nDomains, Subdomains, and \nBounded Contexts\nThere are just as many notes as I required, \nneither more nor less.\n\u2014Mozart in the film Amadeus\n(Orion Pictures, Warner Brothers, 1984)\nThere are three things you are going to have to understand very clearly:\n\u2022 What your Domain is\n\u2022 What your Subdomains are\n\u2022 What your Bounded Contexts are\nJust because all these concepts were discussed in detail in the second half of \n[Evans] does not mean that they are of secondary importance. To succeed in \nimplementing DDD, you have to get these right.\nRoad Map to This Chapter\n\u2022 Grasp the big picture of DDD by understanding Domains, Subdomains, and \nBounded Contexts.\n\u2022 Learn why strategic design is so essential, and why designing without it hurts.\n\u2022 Consider a practical real-world Domain with multiple Subdomains.\n\u2022 Make sense of Bounded Contexts, both conceptually and technically.\n\u2022 See SaaSOvation\u2019s \u201caha!\u201d moments as they discover strategic design.\nBig Picture\nA Domain, in the broad sense, is what an organization does and the world it \ndoes it in. Businesses identify a market and sell products and services. Each \nkind of organization has its own unique realm of know-how and way of doing \nwww.EBooksWorld.ir\n", "page": 86, "type": "text", "section": "Page 86"}
{"text": "Chapter 2 DOMAINS, SUBDOMAINS, AND BOUNDED CONTEXTS\n44\nthings. That realm of understanding and its methods for carrying out its oper-\nations is its Domain. When you develop software for an organization, you are \nworking in its Domain. It should be pretty obvious to you what your Domain \nis. You work in it.\nOne thing to be aware of is that the term Domain may be a bit overloaded. \nDomain can refer to both the entire domain of the business, as well as just one \ncore or supporting area of it. I will do my best to distinguish each use of the \nterm. When referring to just one area of the business, I will generally qualify it \nwith the use of Core Domain, Subdomain, and the like.\nBecause the term domain model includes the word domain, we might get \nthe idea that we should create a single, cohesive, all-inclusive model of an orga-\nnization\u2019s entire business domain\u2014you know, like an enterprise model. How-\never, when using DDD, that is not our goal. DDD places emphasis on just the \nopposite. The whole Domain of the organization is composed of Subdomains. \nUsing DDD, models are developed in Bounded Contexts. In fact, developing \na Domain Model is actually one way that we focus on only one specific area \nof the whole business domain. Any attempt to define the business of even a \nmoderately complex organization in a single, all-encompassing model will be \nat best extremely difficult and will usually fail. As is made clear in this chapter, \nvigorously separating distinct areas of the whole business domain will help us \nsucceed.\nSo, if a domain model shouldn\u2019t be all-inclusive of what the organization \ndoes and how it does it, what should it be, exactly?\nAlmost every software Domain has multiple Subdomains. It really doesn\u2019t \nmatter whether the organization is huge and extremely complex or consists of \njust a few people and the software they use. There are different functions that \nmake any business successful, so it\u2019s advantageous to think about each of those \nbusiness functions separately.\nSubdomains and Bounded Contexts at Work\nHere\u2019s a fairly simple example to introduce how Subdomains can be used. \nThink of a retail company that sells products online. The products it sells \ncould be just about anything, so we won\u2019t think too carefully about them. To \ndo business in this Domain, the company must present a catalog of products \nto shoppers, it must allow orders to be placed, it must collect payment for the \nproducts sold, and it must ship the products to buyers. This online retailer\u2019s \nDomain seems to be composed of these four primary Subdomains: Product \nCatalog, Orders, Invoicing, and Shipping. The upper part of Figure 2.1 shows \nthe e-Commerce System.\nwww.EBooksWorld.ir\n", "page": 87, "type": "text", "section": "Page 87"}
{"text": " \nBIG PICTURE\n45\nThis all seems quite straightforward, and to some degree it is. However, if \nwe introduce just one additional detail, we will make our example more com-\nplex. Consider for a moment how difficult it can be to deal with Inventory,\nan additional system and Subdomain seen in Figure 2.1. We\u2019ll get back to the \nincreased complexity in a moment. First let\u2019s peer into the physical subsystems \nand logical Subdomains in the diagram.\nNotice that at this time just three physical systems exist to realize this \nretailer\u2019s Domain, only two of which are hosted internally. Those two inter-\nnal systems represent what we might think of as two Bounded Contexts. \nSince, unfortunately, most systems today are not created by employing a DDD \napproach, this ends up being a fairly typical situation, with fewer subsystems \nresponsible for many business functions.\nInside the e-Commerce Bounded Context there are really multiple implicit \ndomain models at play, even though they are not cleanly separated as such. \nThese otherwise separate domain models are actually fused into one software \nOrders Subdomain\nStraight lines between Subdomains and Bounded\nContexts indicate integration relationships\nThe outer boundary is the\nwhole business Domain\nThis is a\nSubdomain\nThis is a\nSubdomain\nDashed lines separate\nSubdomains\nSolid lines mark off\nBounded Contexts\nInvoicing\nSubdomain\nDomain\ne-Commerce\nSystem\nInventory\nSystem\nInventory\nSubdomain\nShipping\nSubdomain\nProduct Catalog\nSubdomain\nExternal Forecasting\nSystem\nFigure 2.1 A Domain with Subdomains and Bounded Contexts\nwww.EBooksWorld.ir\n", "page": 88, "type": "text", "section": "Page 88"}
{"text": "Chapter 2 DOMAINS, SUBDOMAINS, AND BOUNDED CONTEXTS\n46\nmodel, and that\u2019s very unfortunate. It might be less of a problem for the retailer \nif it had purchased this Bounded Context from a third party rather than build-\ning it, but whoever maintains this system has experienced the negative conse-\nquences of the increasing complexity that results from blending the Product \nCatalog, the Orders, the Invoicing, and the Shipping models into one large \ne-commerce model. As the various logical models need to grow to facilitate \nnew features, each of the conflicting concerns will impede the progress of each \nof the others. This would be especially so if another logical model\u2014a major \nnew feature set\u2014must be added. It\u2019s just what happens when software con-\ncerns are not cleanly separated.\nThis is particularly unfortunate because a lot of software developers think \nit\u2019s clever to bake everything possible into one system. It\u2019s your basic all- \nknowing, all-doing e-commerce system, and thus it will certainly satisfy every-\none\u2019s needs. This is deceiving, however, because no matter how many concerns \ncan be piled into one subsystem, it will never address the needs of every poten-\ntial consumer. Never. Add to this the fact that not separating otherwise dis-\ntinct software domain models by Subdomain will make ongoing changes much \nmore burdensome, since everything will tend to be connected to and depend on \neverything else.\nYet, using one of the DDD strategic design tools, we can to some degree cut \nthrough the complexity by externally dissecting these intertwined models into \nlogically separated Subdomains according to their actual functionality. The \nlogical Subdomain separations are indicated by the dashed lines in Figure 2.1. \nIt\u2019s not that we have somehow refactored the third-party models into cleanly \nseparated ones. We\u2019ve just indicated what separate models should exist, at least \nas they apply to our specific retailer\u2019s business operations. We\u2019ve also drawn \nsome connections between logical Subdomains and even physical Bounded \nContexts to show integrations.\nNow let\u2019s shift from technical complexities and focus on the business com-\nplexities faced by our small company. It has limited funds and it has limited \nwarehouse space. There\u2019s a constant juggling act going on. The company must \nnot overspend on products that aren\u2019t selling well, and some products sell bet-\nter at certain times than they do at other times. Obviously, if some products \ndon\u2019t sell according to plans, the company\u2019s funds are tied up with products \nthat its customers don\u2019t want, not right now anyway. The money is frozen. As \na result, the company has limited room to stock products that are selling well \nat any given time.\nThat\u2019s not all. There ends up being another problem. If some products \nsell more quickly than anticipated, the company will not be able to inven-\ntory enough of them to fulfill customer demand. This insufficient inventory \nwww.EBooksWorld.ir\n", "page": 89, "type": "text", "section": "Page 89"}
{"text": " \nBIG PICTURE\n47\nchallenge could cause customers to obtain the same urgently needed products \nelsewhere. Sure, some product wholesalers are willing to drop-ship on behalf \nof the retailer, but that option costs more and introduces other undesirable \nconsequences. There are also cost-saving strategies to stock some products \nnearby for local consumption and drop-ship others that sell well in distant \nregions. Thus, drop-shipping should be leveraged to the retailer\u2019s advantage, \nnot as a last-minute tactic employed to rescue a sale gone bad. After all, it\u2019s not \nthat the products that are selling the best are scarce. It\u2019s just that they are \nnot readily available from the small retail company because it didn\u2019t optimally \ninventory them. If customers experience delays on a continuing basis, it will \nlikely cost the online sales company at least a significant part of any competi-\ntive advantage it had previously earned. This example is inspired by customer \nproblems commonly solved by Lokad.1\nTo be clear, we haven\u2019t investigated the limits of the challenges faced with \ninventories, and these undesirable situations are not limited to small retailers. \nRetailers everywhere desire to purchase and inventory precisely according to \ntheir exact needs, minimizing cost and optimizing sales fulfillment according \nto demand. Yet the small retailer tends to suffer the penalties of suboptimal \nperformance more quickly than large retailers.\nWhat would help any online retailer tremendously is a way to base future \ninventory and sales demands on past trends. If the retailer could use a forecast-\ning engine, providing it with data about inventory and sales history, it could \nobtain demand forecasts with specific numbers for optimizing its inventory\u2014\nwhen to reorder and how much of each product to obtain.\nFor the small retailer to add such forecasting capabilities would probably \nconstitute a new Core Domain, because it is a nontrivial problem to solve, \nand succeeding would help the company establish a new competitive advan-\ntage. In fact, the third physical Bounded Context in Figure 2.1 is an External \nForecasting System. The Orders Subdomain and the Inventory Bounded Con-\ntext integrate with Forecasting to supply historical product sales and returns \ninformation. Additionally, we should also have the Catalog Subdomain pro-\nvide globally recognized product bar codes, which would allow Forecasting \nto compare the small retailer\u2019s product lines to related and similar sales trends \nworldwide, resulting in a broader perspective. This leads to the Forecasting\nengine possessing the means to calculate the most accurate numbers needed by \nthe small retailer to correctly stock products.\nIf this new solution were actually a Core Domain, and it most likely is, the \nteam developing it would benefit greatly from understanding the surrounding \n 1. www.lokad.com/.\nwww.EBooksWorld.ir\n", "page": 90, "type": "text", "section": "Page 90"}
{"text": "Chapter 2 DOMAINS, SUBDOMAINS, AND BOUNDED CONTEXTS\n48\nbusiness terrain composed of logical Subdomains and the integrations needed. \nThus, highlighting the preexisting integrations indicated on the diagram in \nFigure 2.1 is key to grasping the project situation at the time the project begins.\nIt\u2019s not always the case that Subdomains feature such distinct models of \nsignificant size and functionality. Sometimes a Subdomain can be as simple as \na set of algorithms that, while essential to the business solution, are not part of \nthe distinguished Core Domain. Applying good DDD techniques, such simple \nSubdomains can be separated from the Core using Modules (9) and need not \nbe housed in a heavy, architecturally significant subsystem component.\nWhen we employ DDD, we strive for each Bounded Context to mark off \nwhere the meaning of every term used by the domain model is well under-\nstood, or at least should be if we\u2019ve done a good job of modeling the software. \nIt\u2019s chiefly a linguistic boundary. These contextual boundaries are a key to \nimplementing DDD. \nCowboy Logic\nLB:  \n\u201cWe get along just fine with the neighbors, until their \nfences break down.\u201d\nAJ:  \n\u201cThat\u2019s right. Keep your fences horse-high.\u201d\nNote that a single Bounded Context does not necessarily fall within only \na single Subdomain, but it may. In Figure 2.1, only one Bounded Context, \nInventory, falls within just one Subdomain.2 That makes it rather apparent \nthat proper DDD was not in use when the e-Commerce System was devel-\noped. In that system we\u2019ve identified four Subdomains, and there are probably \nmore. On the other hand, the Inventory System does seem to be aligned as one \nSubdomain per Bounded Context by limiting its domain model to inventory-\ning products. The Inventory System\u2019s apparently clean model may be due to \nemploying DDD, or it may be merely coincidental. We\u2019d have to look under the \nhood to know for sure. Regardless, we can still make practical use of Inven-\ntory to develop the new Core Domain.\nLinguistically, which of the Bounded Contexts in Figure 2.1 has a better \ndesign? In other words, which has an unambiguous set of domain-specific terms? \nWhen we consider that there are at least four Subdomains in the e-Commerce \n 2. True, the Shipping Subdomain uses Inventory, but that doesn\u2019t make Inventory\npart of the e-Commerce System where Shipping has context.\nwww.EBooksWorld.ir\n", "page": 91, "type": "text", "section": "Page 91"}
{"text": " \nBIG PICTURE\n49\nSystem, it\u2019s almost certain that terms and meanings collide there. For example, \nthe term Customer must have multiple meanings. When a user is browsing the \nCatalog, Customer means one thing, but when a user is placing an Order, it \nmeans something else. Here\u2019s why. When browsing the Catalog, Customer is \nbeing used in the context of previous purchases, loyalty, available products, dis-\ncounts, and shipping options. On the Order itself, however, Customer has a lim-\nited meaning. Among the few details there is a name with a ship-to address, a \nbill-to address, a total due, and payment terms. Just by this basic reasoning we \nsee that in the e-Commerce System there is no one clean meaning for Customer. \nGiven this situation, as we look around that system we would expect to find sev-\neral other terms that have multiple meanings. It\u2019s not a clean Bounded Context \nwith an explicit meaning for each term naming a domain concept.\nYet, there\u2019s also no guarantee that the Inventory System has a completely \nclean model, possessing wholly unambiguous domain linguistics. Even in this \napparently focused Context we could face differences in meanings among the \nthings that are being controlled in inventory. This is because there are different \nways that inventoried Items are used. Is there a clean distinction between an \nItem being ordered, one being received, one in stock, and one moving out of \nstock? An Item on order that is not yet available for sale is called Back-Ordered \nItem. An Item being received is often called Goods Received. An item in stock \nmay be called a Stock Item. An Item being consumed is often referred to as an \nItem Leaving Inventory. An inventoried Item that becomes spoiled or broken is \noften called a Wasted Inventory Item.\nBy looking at Figure 2.1, we don\u2019t know how well the range of inventory \nconcepts and their accompanying linguistics are modeled. When using DDD, \nwe\u2019d leave none of it to guesswork. We would be certain that each of those con-\ncepts is well understood, spoken of explicitly, and modeled as such. The way \ndomain experts describe each of these concepts could lead to separating some \nin different Bounded Contexts.\nFrom outward appearances we would conclude that the Inventory System\nhas better DDD health than the e-Commerce System. Perhaps the team that \nworked out its model didn\u2019t attempt to make one Item represent all invento-\nried item situations. Although uncertain, it\u2019s possible that the model of the \nInventory System will be easier to integrate with than that of the e-Commerce \nSystem.\nSpeaking of integration, Figure 2.1 further shows that Bounded Contexts \nin an enterprise rarely if ever completely stand alone. Even when the third-\nparty e-Commerce System attempts to provide a large, all-encompassing \nmodel, it can\u2019t do everything the retailer needs. The solid straight lines running \nbetween and connecting the various Subdomains in the e-Commerce System,\nwww.EBooksWorld.ir\n", "page": 92, "type": "text", "section": "Page 92"}
{"text": "Chapter 2 DOMAINS, SUBDOMAINS, AND BOUNDED CONTEXTS\n50\nthe Inventory System, and the External Forecasting System show the neces-\nsary integration relationships, which proves that different models must work \ntogether. There are always specific kinds of relationships involved in integra-\ntion, and you\u2019ll learn more about the possible integration options in Contexts \nMaps (3).\nThat\u2019s the high-level summary of one view of a simple business domain. \nWe\u2019ve briefly encountered a Core Domain and gotten the notion that it is an \nimportant part of DDD. Now we need to understand it better.\nFocus on the Core Domain\nWith an understanding of Subdomains and Bounded Contexts, consider an \nabstract view of a different Domain found in Figure 2.2. This could repre-\nsent any domain, perhaps even the one you work in. I\u2019ve removed the explicit \nnames so you can mentally fill in the blanks. Naturally, our business goals are \non a path of continuous refinement and expansion reflected by ever-changing \nSupporting\nSubdomain (B)\nGeneric\nSubdomain\nCore\nDomain\nSupporting\nSubdomain (A)\nDomain\nBounded\nContext\nBounded Context\nBounded Context\nBounded Context\nBounded\nContext\n(External)\nFigure 2.2 An abstract business Domain that includes Subdomains \nand Bounded Contexts\nwww.EBooksWorld.ir\n", "page": 93, "type": "text", "section": "Page 93"}
{"text": " \nBIG PICTURE\n51\nSubdomains and the models within. This diagram only captures the whole \nbusiness Domain at a moment in time with a specific perspective, and one that \ncould be somewhat short-lived.\nWhiteboard Time\n\u2022 In one column make a list of all the Subdomains that you are aware of \nin your daily work. In another column list the Bounded Contexts. Do \nSubdomains intersect with multiple Bounded Contexts? If so, it\u2019s not nec-\nessarily a bad thing, just a fact of enterprise software.\n\u2022 Now, using the template in Figure 2.2, write in some of the names of the \nsoftware running in your enterprise with the Subdomains, Bounded Con-\ntexts, and the integration relationships between them.\nWas that difficult? Probably, because the template in Figure 2.2 likely doesn\u2019t \nclosely reflect the existing boundaries in your Domain.\n\u2022 Start over. This time you should draw a diagram that aligns with your\nDomain, Subdomains, and Bounded Contexts. Use the techniques dis-\nplayed in Figure 2.2, but go ahead and fit them to your world.\nOf course, you may not know about every Subdomain and Bounded Context in \nyour entire enterprise, especially if your Domain is really large and complex. But \nyou may be able to figure out the ones you deal with on a day-to-day basis. Anyway, \ngive it a go. Don\u2019t be afraid of being wrong. You\u2019ll get some good practice at Con-\ntext Mapping, which will be refined in the next chapter. If you want to jump to that \nchapter briefly for more advice, that\u2019s fine. Still, don\u2019t worry about being perfect just \nnow. Grasp the basic ideas first.\nNow look at the top of the Domain boundary in Figure 2.2 and you\u2019ll \nsee the Subdomain labeled Core Domain. Introduced earlier, this is another \naspect of DDD of major importance. A Core Domain is a part of the busi-\nness Domain that is of primary importance to the success of the organization. \nStrategically speaking, the business must excel with its Core Domain. It is of \nutmost importance to the ongoing success of the business. That project gets \nthe highest priority, one or more domain experts with deep knowledge of that \nSubdomain, the best developers, and as much leeway and leverage as possible \nto give the close-knit team an unobstructed success path. Most of your DDD \nproject efforts will be focused on the Core Domain.\nwww.EBooksWorld.ir\n", "page": 94, "type": "text", "section": "Page 94"}
{"text": "Chapter 2 DOMAINS, SUBDOMAINS, AND BOUNDED CONTEXTS\n52\nTwo other kinds of Subdomains are found in Figure 2.2, Supporting Sub-\ndomain and Generic Subdomain. Sometimes a Bounded Context is created or \nacquired to support the business. If it models some aspect of the business that \nis essential, yet not Core, it is a Supporting Subdomain. The business creates \na Supporting Subdomain because it is somewhat specialized. Otherwise, if it \ncaptures nothing special to the business, yet is required for the overall business \nsolution, it is a Generic Subdomain. Being Supporting or Generic doesn\u2019t mean \nunimportant. These kinds of Subdomains are important to the success of the \nbusiness, yet there is no need for the business to excel in these areas. It\u2019s the \nCore Domain that requires excellence in implementation, since it will provide \ndistinct advantages to the business.\nWhiteboard Time\n\u2022 To make sure you grasp the significance of the Core Domain concepts, \nwhat you should do next is go back to your fresh whiteboard drawing and \nsee if you can identify where a Core Domain is being developed in your \norganization.\n\u2022 Next, see if you can identify the Supporting Subdomains and Generic \nSubdomains in your Domain.\nRemember: Ask the Domain Experts! \nEven if you don\u2019t get it just right the first time, this exer-\ncise will help you to think carefully about what software \nmost distinguishes your business, what supports the \ndistinguishing software, and what doesn\u2019t distinguish \nyour business\u2019s success at all. Keep working at it so you \nbecome more comfortable with the thought processes \nand techniques.\nDiscuss each Subdomain and Bounded Context in your drawing with a few \ndomain experts who specialize in the different areas.\nNot only will you learn a lot from them, but you\u2019ll gain valuable experience in \nlistening to the experts. That\u2019s a hallmark of implementing DDD well.\nWhat you\u2019ve just learned is the big-picture foundation of strategic design.\nwww.EBooksWorld.ir\n", "page": 95, "type": "text", "section": "Page 95"}
{"text": " \nWHY STRATEGIC DESIGN IS SO INCREDIBLY ESSENTIAL\n53\nWhy Strategic Design Is So Incredibly Essential\nOK, you\u2019ve learned some DDD terminology and the meaning behind it, but \nnot much has been said about why this is so important. I\u2019ve really just asserted \nthat it is very important and hoped that you\u2019d believe me. But like most state-\nments of \u201cfact,\u201d I\u2019d better back my assertion now. Let\u2019s jump in on our run-\nning example, that of the projects going on at SaaSOvation. They\u2019ve managed \nto get themselves into a real jam.\nEarly on in their first effort with DDD, the \ncollaboration project team began to veer \noff the path to developing a clean model. \nThis happened because they didn\u2019t under-\nstand strategic design, not even at its most \nbasic level. As is true of most developers, \ntheir focus was on the details of Entities \n(5) and Value Objects (6), which obscured their vision of the bigger picture. They blended \ntheir core concepts with generic ones, causing the creation of two models in one. Before \nlong they started to feel the pain of the design reflected in Figure 2.3. The bottom line? \nThey had not fully achieved the goal of implementing DDD.\nA few on the SaaSOvation team asserted, \u201cSo what if collaboration concepts are \ntightly coupled to Users and Permissions? We must track who did what!\u201d The senior \ndeveloper pointed out that it\u2019s actually not the coupling alone that the team should \nCalendar Entry\nUser\nForum\nPost\nDiscussion\nPermission\nCalendar\nFigure 2.3 The team didn\u2019t understand basic strategic design, which led to \nmismatched concepts in the collaboration model. The dashes encircle the \nproblem elements.\nwww.EBooksWorld.ir\n", "page": 96, "type": "text", "section": "Page 96"}
{"text": "Chapter 2 DOMAINS, SUBDOMAINS, AND BOUNDED CONTEXTS\n54\nbe concerned with. \u201cIn the end, a Forum, a Post, a Discussion, a Calendar, and a \nCalendar Entry will all be coupled to some kind of human collaborator objects. And\nthat\u2019s just it. The linguistics are wrong here.\u201d As he elaborated, he showed that Forum, \nPost, Discussion, and the like were all coupled to the wrong linguistic concepts. Users \nand Permissions have nothing to do with collaboration and don\u2019t harmonize in the \ntrue Ubiquitous Language of Collaboration. Users and Permissions are identity and \naccess concepts\u2014security concerns. Every concept modeled in the Collaboration \nContext\u2014as in the Bounded Context surrounding the collaboration domain model\u2014\nshould have a linguistic association to collaboration, and right now they don\u2019t. \u201cWhat \nwe should be focused on are collaboration concepts, such as Author and Moderator. \nThose are the correct concepts and linguistic terms in a collaboration setting.\u201d\nNaming a Bounded Context\nDid you notice the name Collaboration Context used here? This is the way we name \na Bounded Context, which is in the form Name-of-Model Context. In this case we \nuse Collaboration Context because it is the Bounded Context that contains the \ndomain model of the Collaboration project. We also have Identity and Access Con-\ntext for the Bounded Context that contains the model of the Identity and Access \nproject, and Agile Project Management (PM) Context for the Bounded Context that \nholds the model of the Agile Project Management project.\nTo reiterate, at a fundamental level, the SaaSOvation developers didn\u2019t at first \nunderstand that Users and Permissions had nothing to do with collaboration tools. \nWell, sure, they did have users of their software, and those users had to be distin-\nguished one from another to determine the tasks each could perform. But collabora-\ntion tools should be interested in the roles of users, rather than who they specifically \nare and each little action they are permitted to perform. However, the collaboration \nmodel now had user and permission details completely intertwined. If something \nchanged about the way users and/or permissions worked, a lot or all of the model \nwould suffer from the ripple. In fact, this problem was right at the threshold. The team \nwanted to switch from a permissions approach and use role-based access manage-\nment instead. When they decided to make this switch, it made them more aware of \nthe strategic modeling problem at hand.\nThey now realized that a Forum should not be concerned with who can post a \nsubject, or under what conditions that is permitted. A Forum just needs to know that \nan Author is doing that right now, or had done that previously. The team was now \ngrasping that determining who can do something is the concern of a completely sep-\narate model, and the core collaboration model only needed to know that any question \nregarding who can do what had already been answered. The Forum just needed to be \ngiven an Author who wants to Post to a Discussion. The Forum and Author are clearly \nconcepts of the Ubiquitous Language of the collaboration model, a Bounded Context \nnamed Collaboration Context. User and Permission, or some similar concepts such \nas Role, belonged someplace completely different. Those needed to be isolated from \nthe Collaboration Context.\nIt would be easy for the team to conclude that they only needed to factor out the \ntight coupling to User and Permission. After all, there would not be anything wrong \nwww.EBooksWorld.ir\n", "page": 97, "type": "text", "section": "Page 97"}
{"text": " \nWHY STRATEGIC DESIGN IS SO INCREDIBLY ESSENTIAL\n55\nwith separating User and Permission/Role into a separate Module. That could help \nthem place these concepts in a separate logical Security Subdomain within the same \nBounded Context. However, what made the best modeling choice stand out even \nmore boldly was the realization that the team\u2019s next Core Domain project would \nhave very similar role-based access needs and would lean on the use of domain- \nspecific role characteristics. Clearly, Users and Roles were truly part of a Supporting \nor Generic Subdomain that had an enterprise-wide, and even customer-facing, part \nto play in the future.\nTaking a more vigorous approach to clean modeling would help them avoid a more \ninsidious problem. They were probably leaning toward working their way into a Big \nBall of Mud (3). It wasn\u2019t just that their User and Permission concepts were not prop-\nerly modularized. While modularization is an essential DDD modeling tool, it doesn\u2019t \nfix linguistic misalignment.\nThe senior developer was very concerned that, if left unchecked, this situation \ncould easily lead to an undisciplined mindset that would allow more tangle to even-\ntually creep in subtly. In time, as the team faced modeling another set of noncollab-\noration concepts, the Core Domain would become even less clear. They could end \nup with only an implicit model with source code that wouldn\u2019t reflect an expressive \nUbiquitous Language of Collaboration. What the team really needed to understand \nwas their business Domain, its Subdomains, as well as the Bounded Contexts they \nwere developing. Doing so would prevent the entry of the dastardly foe of strategic \ndesign, the muck of the Big Ball of Mud. Thus, the team needed to gain a strategic \nmodeling mindset.\nOh, No! There\u2019s That Word Design Again!\nIf you think that design is a dirty word when agile is in practice, it\u2019s not with DDD. \nUsing DDD with agile is completely natural. Always keep design in check with agile. \nDesign need not be heavy.\nYeah, that was an important lesson to learn. They did manage to work their \nway through it with a lot of research and finally got a handle on their Domain \nand Subdomains. How they did that will be presented soon.\nAlignment with the DDD Community\nThe running examples in this book are provided as three Bounded Contexts. \nThese Bounded Contexts are likely different from those you work with. The \nexamples present fairly typical modeling situations. However, not everyone \nwould agree that Users and Permissions should be separated out of a given \nCore Domain. Perhaps in some cases it might make sense to intertwine \nthem with your Core model. As always, that is the choice of a specific team. \nIn my experience, however, this is one of the basic problems encountered by \nthose new to DDD, and one that misleads their implementation efforts into \nwww.EBooksWorld.ir\n", "page": 98, "type": "text", "section": "Page 98"}
{"text": "Chapter 2 DOMAINS, SUBDOMAINS, AND BOUNDED CONTEXTS\n56\nan unnecessarily messy result. Another common misstep would be to meld \nthe collaboration and agile project management models into one. These are \nonly a few common problems. Other common modeling errors are discussed \nin each chapter.\nAt a minimum, the problems posed here, and those that follow, are repre-\nsentative of the kinds of modeling mistakes that are made when teams fail \nto understand the importance of linguistic drivers and Bounded Contexts. \nThus, even if you disagree with the specific example problems, both the \nproblems and solutions are still applicable in a general way to all DDD proj-\nects, because they all focus on the linguistics of a given Bounded Context.\nMy goal is to teach the principles of implementing DDD using the simplest, \nyet nontrivial, examples possible. I can\u2019t afford to allow the examples to get \nin the way of my teaching and your learning. If I demonstrate that identity and \naccess management, collaboration, and agile project management all have \nseparate linguistics, readers are well served by what the examples empha-\nsize. Since it is each team\u2019s choice to discover the linguistic drivers that \nthey find important, and that help them achieve the vision of their domain \nexperts, assume that there is no mistake in the \u201cultimate correct\u201d conclu-\nsions reached by the SaaSOvation developers and the modeling choices \nthey made in their DDD implementation journey.\nAll of my guidance regarding Subdomains and Bounded Contexts is closely \naligned with that of the broader DDD community, as it reflects my own expe-\nrience. Other DDD leaders may have a slightly different focus. However, \nmy explanations definitely provide a firm foundation for any team to move \nforward without ambiguity. Clearing the murky areas of DDD is the most \nimportant service to the community, and it is my primary goal. It should be \nyour goal to put these guidelines to use in the most practical way to benefit \nyour project.\nReal-World Domains and Subdomains\nI have something more to tell you about domains. They have both a problem \nspace and a solution space. The problem space enables us to think of a stra-\ntegic business challenge to be solved, while the solution space focuses on how \nwe will implement the software to solve the problem of the business challenge. \nHere\u2019s how that fits into what you\u2019ve already learned:\n\u2022 The problem space is the parts of the Domain that need to be developed to \ndeliver a new Core Domain. Assessing the problem space involves exam-\nining Subdomains that already exist and those that are needed. Thus, \nwww.EBooksWorld.ir\n", "page": 99, "type": "text", "section": "Page 99"}
{"text": " \nREAL-WORLD DOMAINS AND SUBDOMAINS\n57\nyour problem space is the combination of the Core Domain and the Sub-\ndomains it must use. The Subdomains in the problem space are usually \ndifferent from project to project since they are used to explore a current \nstrategic business problem. This makes Subdomains a very useful tool in \nassessing the problem space. Subdomains allow us to rapidly view differ-\nent parts of the Domain that are necessary to solve a specific problem.\n\u2022 The solution space is one or more Bounded Contexts, a set of specific \nsoftware models. That\u2019s because the Bounded Context is a specific solu-\ntion, a realization view, once developed. The Bounded Context is used to \nrealize a solution as software.\nIt is a desirable goal to align Subdomains one-to-one with Bounded Con-\ntexts. Doing so expressly segregates domain models into well-defined areas of \nbusiness by objective, melding the problem space with the solution space. In \npractice this is not always possible, but it can work in a greenfield effort. Con-\nsidering a legacy system, and probably a Big Ball of Mud, however, Subdomains \noften intersect Bounded Contexts, similar to what we discussed regarding Fig-\nure 2.1. In a large and complex enterprise we can employ an assessment view\nto understand our problem space, which can save us from making costly mis-\ntakes. We can conceptually divide a single, large Bounded Context using two \nor more Subdomains, or multiple Bounded Contexts as part of a single Subdo-\nmain. Consider an example to help clarify the difference between the problem \nspace and the solution space.\nImagine a large, monolithic system, classified as an ERP application. Strictly \nspeaking, an ERP may be thought of as a single Bounded Context. However, \nsince ERP systems provide many modular business services, there\u2019s a benefit to \nthinking of distinct modules as different Subdomains. For example, we could \ndivide the inventory module and purchasing module into separate, logical Sub-\ndomains. True, these modules aren\u2019t available through completely different \nsystems. Both are part of the same ERP. Still, each provides a very different set \nof services to the business domain. For analytical discussions let\u2019s name these \nas separate Subdomains, the Inventory Subdomain and the Purchasing Subdo-\nmain. Continuing with the example, we\u2019ll see why doing so is useful.\nAs a core business initiative, the organization whose Domain is represented \nin Figure 2.4 (a concrete example using the template from Figure 2.2) starts \nplanning the design and development of a specialized domain model to reduce \nthe cost of doing business. The model will provide decision-making tools to be \nused by purchasing agents. Algorithms discovered over years of manual, human \nprocess must now be automated by software to ensure that they are always used \nby all purchasing agents without error. This new Core Domain will make the \nwww.EBooksWorld.ir\n", "page": 100, "type": "text", "section": "Page 100"}
{"text": "Chapter 2 DOMAINS, SUBDOMAINS, AND BOUNDED CONTEXTS\n58\norganization more competitive by identifying better deals more quickly, and \nthen ensuring that the needed inventories are met. To accurately stock inven-\ntory, use of the previously examined Forecasting System of Figure 2.1 would \nhelp here as well.\nBefore we can execute a specific solution, we need to make an assessment of \nthe problem space and the solution space. Here are some questions that should \nbe answered in order to steer your project in the right direction:\n\u2022 What is the name of and vision for the strategic Core Domain?\n\u2022 What concepts should be considered part of the strategic Core Domain?\n\u2022 What are the necessary Supporting Subdomains and the Generic Subdomains?\n\u2022 Who should do the work in each area of the domain?\n\u2022 Can the right teams be assembled?\nInventory\n(Supporting)\nResource\nPlanning\n(Generic)\nOptimal Acquisition (Core)\nPurchasing (Supporting)\nDomain\nERP\nInventory Context\nOptimal Acquisition\nContext\nPurchasing\nContext\nMapping\nContext\n(External)\nFigure 2.4 The Core Domain and other Subdomains involved in purchasing and \ninventory. This view is limited to select Subdomains used for specific problem space \nanalysis, not the entire Domain.\nwww.EBooksWorld.ir\n", "page": 101, "type": "text", "section": "Page 101"}
{"text": " \nREAL-WORLD DOMAINS AND SUBDOMAINS\n59\nIf we don\u2019t understand the vision and goals of the Core Domain and the \nareas of the Domain that are needed to support it, we won\u2019t be able to strategi-\ncally take advantage of them and avoid associated pitfalls. Keep problem space \nassessment high-level, but make it thorough. Be sure that all stakeholders are \naligned with and committed to successfully delivering on the vision.\nWhiteboard Time\nTake a moment to look at your whiteboard work and consider: What is your \nproblem space? Recall that it is the combination of the strategic Core Domain \nand the Subdomains supporting it.\nWhen you have a good understanding of the problem space, you then turn \nto the solution space. The first assessment will contribute knowledge to the \nsecond. The solution space will be strongly influenced by the existing systems \nand technologies, and those that are to be newly created. Here we really need \nto think in terms of cleanly separated Bounded Contexts because we are look-\ning at the Ubiquitous Language of each. Consider these crucial questions:\n\u2022 What software assets already exist, and can they be reused?\n\u2022 What assets need to be acquired or created?\n\u2022 How are all of these connected to each other, or integrated?\n\u2022 What additional integration will be needed?\n\u2022 Given the existing assets and those that need to be created, what is the \nrequired effort?\n\u2022 Do the strategic initiative and all supporting projects have a high proba-\nbility of success, or will any one of them cause the overall program to be \ndelayed or even fail?\n\u2022 Where are the terms of the Ubiquitous Languages involved completely \ndifferent?\n\u2022 Where is there overlap and sharing of concepts and data between Bounded \nContexts?\n\u2022 How are shared terms and/or overlapping concepts mapped and trans-\nlated between the Bounded Contexts?\nwww.EBooksWorld.ir\n", "page": 102, "type": "text", "section": "Page 102"}
{"text": "Chapter 2 DOMAINS, SUBDOMAINS, AND BOUNDED CONTEXTS\n60\n\u2022 Which Bounded Context contains the concepts that address the Core \nDomain and which of the [Evans] tactical patterns will be used to model it?\nRemember, the efforts in developing the solutions in the Core Domain are a \nkey business investment!\nThe specialized purchasing model described previously and pictured in \nFigure 2.4\u2014the one that captures decision-making tools and algorithms\u2014\nrepresents the solution for the Core Domain. The domain model will be imple-\nmented in an explicit Bounded Context: the Optimal Acquisitions Context.\nThis Bounded Context aligns one-to-one with the Subdomain, the Optimal \nAcquisitions Core Domain. Being aligned with just one Subdomain, and its \ncarefully crafted domain model, will make it one of the best Bounded Contexts \nin this business domain.\nYet another Bounded Context, the Purchasing Context, will be developed in \norder to refine some technical aspects of the purchasing process as a helper to \nthe Optimal Acquisitions Context. These refinements don\u2019t reveal any special \nknowledge about an optimal approach to purchasing. They just make it easier \nfor the Optimal Acquisitions Context to interact with the ERP at an arm\u2019s \nlength. It\u2019s just a convenient model that operates against the ERP published \ninterface. The new Purchasing Context and the preexisting ERP purchasing \nmodule fall within the Purchasing (Supporting) Subdomain.\nThe ERP purchasing module is as a whole a Generic Subdomain. That\u2019s \nbecause you could replace this Subdomain with any off-the-shelf purchasing \nsystem as long as it fulfills your basic business needs. However, being used \nalong with the new Purchasing Context in the Purchasing Subdomain makes it \nwork in a Supporting fashion.\nYou Can\u2019t Change the World of Bad Software Design\nIn a typical brownfield enterprise you are going to have undesirable situations like \nthose illustrated in Figures 2.1 and 2.4. This means that Subdomains in poorly \ndesigned software will not align in an ideal way, one-to-one, with Bounded Con-\ntexts. You can\u2019t change the world of bad software design. You can only hope to \nimplement proper DDD in projects you work on. In the end you will have to inte-\ngrate with and even work in brownfield domains, so be prepared to exercise the \ntechniques taught in the first one-third of this chapter as you analyze the multiple \nimplicit models found in a single, brown Bounded Context.\nSticking with Figure 2.4, the Optimal Acquisition Context must also inter-\nact with the Inventory Context. Inventory manages warehousing items. It uses \nthe ERP inventory module, which falls within the Inventory (Supporting) Sub-\ndomain. As a convenience to delivery contractors, the Inventory Context can \nprovide maps and directions to each of its warehouses from an origin loca-\ntion by using an external geographical mapping service. From the Inventory \nwww.EBooksWorld.ir\n", "page": 103, "type": "text", "section": "Page 103"}
{"text": " \nREAL-WORLD DOMAINS AND SUBDOMAINS\n61\nContext point of view, there is nothing special about mapping. There are sev-\neral geographical mapping services to choose from, and there may be advan-\ntages to changing the chosen mapping system over time. The mapping service \nis itself a Generic Subdomain, but it is consumed by a Supporting Subdomain.\nNote these key points as viewed from the perspective of the company devel-\noping the Optimal Acquisition Context. In the solution space the geographical \nmapping service is not part of the Inventory Context, although in the prob-\nlem space it is considered part of the Inventory Subdomain. In the solution \nspace, even if the mapping services are provided by a simple component-based \nAPI, it is in a different Bounded Context. The Ubiquitous Languages of Inven-\ntory and of Mapping are mutually exclusive, which means they are in differ-\nent Bounded Contexts. When the Inventory Context uses something from the \nexternal Mapping Context, the data may go through at least some minimal \ntranslation to be properly consumed.\nOn the other hand, from the point of view of the external business organi-\nzation that develops and offers the mapping service for subscription, mapping \nis a Core Domain. That external organization has its own domain, or realm of \nbusiness operations. It must remain competitive, constantly refining its domain \nmodel in order to retain subscribers and attract new ones. If you were the CEO \nof the mapping organization, you\u2019d make sure to give customers, including the \none subscriber under discussion, every reason to stick with your services rather \nthan move on to the competition. However, that doesn\u2019t change the perspec-\ntive of the subscriber that is developing its inventory system. To the inventory \nsystem it is still a Generic Subdomain. It could, if it was to its advantage, sub-\nscribe to a different mapping service.\nWhiteboard Time\nWhat are the Bounded Contexts in your solution space? At this point you \nshould be able to refer back to your whiteboard diagram for a good idea. Still, \nyou may be a bit surprised as we dig deeper into how to properly use Bounded \nContexts. So be ready for possible refinements. We are doing agile develop-\nment, after all.\nSo, for the balance of this chapter we are going to shift gears and consider \nthe importance of Bounded Contexts as an essential solution space modeling \ntool for DDD. In Context Maps (3) the discussion primarily stresses how to \ndeal with mapping different, but related, Ubiquitous Languages, by integrating \ntheir Bounded Contexts.\nwww.EBooksWorld.ir\n", "page": 104, "type": "text", "section": "Page 104"}
{"text": "Chapter 2 DOMAINS, SUBDOMAINS, AND BOUNDED CONTEXTS\n62\nMaking Sense of Bounded Contexts\nDon\u2019t forget, a Bounded Context is an explicit boundary within which a \ndomain model exists. The domain model expresses a Ubiquitous Language as a \nsoftware model. The boundary is created because each of the model\u2019s concepts \ninside, with its properties and operations, has a special meaning. If you are a \nmember of such a modeling team, you\u2019d know exactly the meaning of each of \nthe concepts in your Context.\nBounded Context Is Explicit and Linguistic\nA Bounded Context is an explicit boundary within which a domain model exists. \nInside the boundary all terms and phrases of the Ubiquitous Language have specific \nmeaning, and the model reflects the Language with exactness.\nIt is often the case that in two explicitly different models, objects with the \nsame or similar names have different meanings. When an explicit boundary \nis placed around each of the two models individually, the meaning of each \nconcept in each Context is certain. Thus, a Bounded Context is principally a \nlinguistic boundary. You should use these points of reasoning as a touchstone \nto determine if you are correctly using Bounded Contexts.\nSome projects fall into the trap of attempting to create an all-inclusive \nmodel, one where the goal is to get the entire organization to agree on concepts \nwith names that have only one global meaning. Approaching a modeling effort \nin this way is a pitfall. First, it will be nearly impossible to establish agreement \namong all stakeholders that all concepts have a single, pure, and distinct global \nmeaning. Some organizations are so large and complex that you\u2019d never be able \nto get all stakeholders together, let alone establish total meaningful agreement \namong them. Even if you are working in a smaller company with relatively few \nstakeholders, establishing an enduring definition of a single global concept is \nstill unlikely. Thus, the best position to take is to embrace the fact that dif-\nferences always exist and apply Bounded Context to separately delineate each \ndomain model where differences are explicit and well understood.\nA Bounded Context does not dictate the creation of a single kind of project \nartifact. It\u2019s not an individual component, document, or diagram.3 So it\u2019s not a \nJAR or DLL, but these can be used to deploy a Bounded Context as described \nlater in the chapter.\nConsider this sharp contrast between an Account in a Banking Context and \nan Account in a Literary Context as presented in Table 2.1.\n 3. You can draw a diagram of one or more Bounded Contexts as seen here and in \nContext Maps. However, the diagram is not the Bounded Context.\nwww.EBooksWorld.ir\n", "page": 105, "type": "text", "section": "Page 105"}
{"text": " \nMAKING SENSE OF BOUNDED CONTEXTS\n63\nTable 2.1 The Diversity of Meanings That the Term Account Can Have\nContext\nMeaning\nExample\nBanking Context\nAn Account maintains a record \nof debit and credit transactions \nindicating a customer\u2019s current \nfinancial state with the bank.\nChecking Account and Sav-\nings Account\nLiterary Context\nAn Account is a set of literary \nexpres \nsions about one or more \nrelated events over a time span.\nAmazon.com sells the book \nInto Thin Air: A Personal \nAccount of the Mt. Everest \nDisaster.\nLooking at Figure 2.5, there is nothing characteristic of the Account types \nby name that distinguishes them. It is only by looking at the name of each con-\nceptual container\u2014its Bounded Context\u2014that you understand the differences \nbetween the two.\nThese two Bounded Contexts are probably not in the same Domain. The \npoint is to demonstrate that context is king.\nContext Is King\nContext is king, especially when implementing DDD.\nIn the financial world the word security is often used. The Securities and \nExchange Commission (SEC) restricts the term security to use with equities. Now \nconsider this: Futures contracts are commodities and not under the jurisdiction of \nthe SEC. However, some financial firms call Futures by the name security as a refer-\nence but mark them with the Standard Type (6) Futures.\nIs that the best Language for a Future? It depends on the Domain it\u2019s used in. \nSome would obviously say it is, while others would insist that it isn\u2019t. Context is also \ncultural. Inside a given firm that trades Futures, it may align best with the culture to \nuse the term Security in a specific Ubiquitous Language.\nBanking Context\nAccount\nLiterary Context\nAccount\nFigure 2.5 Account objects in two different Bounded Contexts have completely \ndifferent meanings, but you know that only by considering the name of each \nBounded Context.\nwww.EBooksWorld.ir\n", "page": 106, "type": "text", "section": "Page 106"}
{"text": "Chapter 2 DOMAINS, SUBDOMAINS, AND BOUNDED CONTEXTS\n64\nIt is often the subtly different meanings that are most commonly faced in \nyour enterprise. Here\u2019s why. The name chosen by each team in each Context \nis always made with the Ubiquitous Language in mind. You never name a con-\ncept arbitrarily, such as to purposely distinguish it from a term in a different \nContext. Consider two banking Contexts, one for checking accounts and one \nfor savings accounts.4 We don\u2019t need to give the name Checking Account to \nthe object in the Checking Context or the name Savings Account to the object \nin the Savings Context. Both concepts may safely be named Account because \neach Bounded Context distinguishes subtle meanings. Of course, there is no \nrule that says that more meaning cannot be added to these names. That\u2019s the \ndecision of your team.\nWhen integrations are needed, mapping must be done between Bounded \nContexts. This can be a complex aspect of DDD and calls for a corresponding \namount of care. We don\u2019t usually use an object instance outside its bound-\nary, but related objects in multiple contexts may share some subset of common \nstate. \nHere\u2019s another example with a common name used in multiple Bounded \nContexts, but this time within the same Domain. Consider the modeling chal-\nlenges of a publishing organization that must deal with the various stages of \nthe life cycle of books. Roughly speaking, publishers deal with similar stages \nas a book progresses through these different Contexts:\n\u2022 Conceptualizing and proposing a book\n\u2022 Contracting with authors\n\u2022 Managing the book\u2019s authorship and editorial process\n\u2022 Designing the book layout, including illustrations\n\u2022 Translating the book into other languages\n\u2022 Producing the physical print and/or electronic editions\n\u2022 Marketing the book\n\u2022 Selling the book to resellers and/or directly to consumers\n\u2022 Shipping a physical book to resellers and consumers\nThroughout each of these stages, is there one single way to properly model \na Book? Absolutely not. At each of these stages the Book has different defini-\ntions. It is not until contract that the Book has a tentative title, which might \n 4. This assumes a Domain where separate Bounded Contexts are used for checking \nand savings accounts.\nwww.EBooksWorld.ir\n", "page": 107, "type": "text", "section": "Page 107"}
{"text": " \nMAKING SENSE OF BOUNDED CONTEXTS\n65\nchange during editing. During the authorship and editorial phases, the Book \nhas a collection of drafts with comments and corrections, along with a final \ndraft. Graphic designers create page layouts. Production uses the layouts and \nto create press images, \u201cblue lines,\u201d and finally plates. Marketing doesn\u2019t need \nmost of the editorial or production artifacts, perhaps just cover art and high-\nlevel descriptions. For shipping, the Book might carry only an identity, inven-\ntory location, availability count, a size, and a weight.\nWhat would happen if you tried to design a central model for Books that \nfacilitated all the stages in its life cycle? There would be a high degree of con-\nfusion, disagreement, and contention, and little deliverable software. Even if \na correct common model could be delivered from time to time, it would likely \nmeet the needs of all clients only occasionally and far too briefly.\nTo counter that kind of undesirable churn and burn, such a publisher mod-\neling with DDD would use separate Bounded Contexts for each of the life cycle \nstages. In every one of the multiple Bounded Contexts, there is a type of Book. \nThe various Book objects would share an identity across all or most of the \nContexts, perhaps first established at the conceptualization stage. However, \nthe model of a Book in each Context would be different from all others. That\u2019s \nfine, and in fact the way it should be. When the team of a given Bounded \nContext speaks about a Book, it means exactly what they require for their \nContext. The organization embraces the natural need for differences. This is \nnot to say that such positive outcomes are trivial to achieve. Nonetheless, using \nexplicit Bounded Contexts, software gets delivered regularly with incremental \nimprovements that address the specific needs of the business.\nAt this point let\u2019s take a quick look at the solution used by the SaaSOvation \ncollaboration team to solve the modeling challenge as shown in Figure 2.3.\nAs indicated previously, in a Collaboration Context domain experts don\u2019t \ndescribe the people who employ the collaboration facilities as Users with Per-\nmissions. Rather, they talk about these collaborators in terms of the roles they \nplay in the Context, as Authors, Owners, Participants, and Moderators. Some \ncontact information may exist there, but probably not all of it. On the other \nhand, it\u2019s in an Identity and Access Context that we talk about Users. In that \nContext User objects have usernames and detailed information about the indi-\nvidual person, including detailed ways to contact the person.\nYet, we don\u2019t create an Author object out of thin air. Every collaborator \nmust be prequalified. We confirm the existence of a User playing the appropri-\nate Role within the Identity and Access Context. The attributes of an authenti-\ncation descriptor are passed with requests to the Identity and Access Context.\nTo create a new collaborator object, such as a Moderator, we use a subset of \nUser attributes and a Role name. The exact details of how we obtain object \nstate from a separate Bounded Context is not important (although later on \nwww.EBooksWorld.ir\n", "page": 108, "type": "text", "section": "Page 108"}
{"text": "Chapter 2 DOMAINS, SUBDOMAINS, AND BOUNDED CONTEXTS\n66\nit\u2019s explained extensively). What\u2019s important now is that these two different \nconcepts are similar and different at the same time, and that the differences \nare determined by the Bounded Context. Figure 2.6 exemplifies User and Role \nin their own Context being used to create a Moderator in a different Context.\nWhiteboard Time\n\u2022 See if you can identify some subtly different concepts that exist in multi-\nple Bounded Contexts in your Domain.\n\u2022 Determine whether the concepts are properly separated, or if developers \nsimply copied code into both.\nGenerally you can determine a proper separation because the similar objects have \ndifferent properties and operations. In that case the boundary has separated the con-\ncepts appropriately. However, if you see the exact same objects in multiple contexts, \nit probably means there is some modeling error, unless the two Bounded Contexts \nare using a Shared Kernel (3).\nRoom for More than the Model\nA Bounded Context does not necessarily encompass only the domain model. \nTrue, the model is the primary occupant of the conceptual container. How-\never, a Bounded Context is not limited to the model only. It often marks off a \nsystem, an application, or a business service.5 Sometimes a Bounded Context \n 5. Admittedly the meanings of system, application, and business service are not \nalways agreed upon. However, in a general sense I intend these to mean a complex \nset of components that interact to realize a set of significant business use cases.\nCollaboration Context\nModerator\nIdentity and Access\nContext\nUser\nRole\nFigure 2.6 The Moderator object in its Context is based on User and Role in a \ndifferent context.\nwww.EBooksWorld.ir\n", "page": 109, "type": "text", "section": "Page 109"}
{"text": " \nMAKING SENSE OF BOUNDED CONTEXTS\n67\nhouses less than this if, for example, a Generic Subdomain can be produced \nwithout much more than a domain model. Consider portions of a system that \nare typically part of a Bounded Context.\nWhen the model drives the creation of a persistence database schema, the \ndatabase schema will live inside the boundary. This is the case because the \nschema is designed, developed, and maintained by the modeling team. It means \nthat the database table names and column names, for example, will directly \nreflect names used in the model, rather than names translated to another style. \nFor example, say our model has a class named BacklogItem and that class has \nValue Object properties named backlogItemId and businessPriority:\npublic class BacklogItem extends Entity  {\n    ...\n    private BacklogItemId backlogItemId;\n    private BusinessPriority businessPriority;\n    ...\n}\nWe would expect to see those mapped to the database in like manner:\nCREATE TABLE `tbl_backlog_item` (\n     ...\n    `backlog_item_id_id` varchar(36) NOT NULL,\n    `business_priority_ratings_benefit` int NOT NULL,\n    `business_priority_ratings_cost` int NOT NULL,\n    `business_priority_ratings_penalty` int NOT NULL,\n    `business_priority_ratings_risk` int NOT NULL,\n    ...\n) ENGINE=InnoDB;\nOn the other hand, if a database schema is preexisting or if a separate team of \ndata modelers forces contradicting designs on the database schema, the schema \ndoes not live within the Bounded Context occupied by the domain model.\nWhen there are User Interface (14) views that render the model and drive \nexecution of its behavior, these are also inside the Bounded Context. However, \nthis does not mean that we model the Domain in the user interface, causing \ndomain model anemia. We want to reject the Smart UI Anti-Pattern [Evans] \nand any temptation to drag domain concepts that belong in the model into \nother areas of the system.\nUsers of the system/application are not always limited to humans and \nmay include other computer systems. Components such as Web services may \nexist. We might use RESTful resources to provide interaction with the model \nas an Open Host Service (3, 13). Or perhaps we deploy Simple Object Access \nwww.EBooksWorld.ir\n", "page": 110, "type": "text", "section": "Page 110"}
{"text": "Chapter 2 DOMAINS, SUBDOMAINS, AND BOUNDED CONTEXTS\n68\nProtocol (SOAP) or messaging service endpoints instead. In all such cases, the \nservice-oriented components are inside the boundary.\nBoth user interface components and service-oriented endpoints delegate to \nApplication Services (14). These are different kinds of services, generally pro-\nviding security and transaction management, and acting as Facade [Gamma et \nal.] to the model. They are task managers, transforming use case flow requests \ninto the execution of domain logic. Application Services are also inside the \nboundary.\nMore on Architectural and Application Concerns\nIf you want to consider how DDD fits with various architectural styles, see Archi-\ntecture (4). Also, Application Services are treated specially in Application (14). There \nare helpful diagrams and code snippets in both chapters.\nThe Bounded Context primarily encapsulates the Ubiquitous Language \nand its domain model, but it includes what exists to provide interaction with \nand support of the domain model. Pay attention to keeping the aspects of each \nArchitectural concern in their proper place.\nWhiteboard Time\n\u2022 Look at each of the Bounded Contexts you identified in your whiteboard \ndiagram. When you think of those, do you imagine components other \nthan the domain model as being within the boundary?\n\u2022 If there is a user interface and a set of Application Services, make sure \nthey are inside the boundary. (You have flexibility in how you represent \nthese. See Figures 2.8, 2.9, and 2.10 for some ideas for representing vari-\nous components.)\n\u2022 If your database schema or other persistence store was developed for your \nmodel, make sure it is also inside the boundary. (Figures 2.8, 2.9, and \n2.10 provide one way to represent a database schema.)\nSize of Bounded Contexts\nHow many Modules (9), Aggregates (10), Events (8), and Services (7)\u2014the \nprimary building blocks of a domain model created using DDD\u2014should a \nBounded Context contain? That\u2019s a bit like asking, \u201cHow long is a piece of \nstring?\u201d A Bounded Context should be as big as it needs to be in order to fully \nexpress its complete Ubiquitous Language.\nwww.EBooksWorld.ir\n", "page": 111, "type": "text", "section": "Page 111"}
{"text": " \nMAKING SENSE OF BOUNDED CONTEXTS\n69\nExtraneous concepts that are not truly part of the Core Domain should be \nfactored out. If a concept is not in your Ubiquitous Language, it should not \nbe introduced in your model in the first place. Still, if one or more extraneous \nconcepts creep in, get rid of them. They probably belong in a separate Support-\ning or Generic Subdomain, or in no model at all.\nBe careful not to mistakenly factor out concepts that do truly belong in the \nCore Domain. Your model must completely exhibit the richness of the Ubiq-\nuitous Language in context, leaving out nothing essential. Clearly, good judg-\nment is needed. Tools such as Context Maps (3) can help shape your team\u2019s \ngood judgment.\nIn the film Amadeus6 there is a scene where the Austrian emperor Joseph \nII communicates to Mozart that the musical work Mozart had just performed \nwas a quality piece, but one that contained \u201csimply too many notes.\u201d Mozart \naptly replies to the emperor, \u201cThere are just as many notes as I required, nei-\nther more nor less.\u201d This reply well illustrates an essential mentality to take \ninto stepping off contextual boundaries around our models. There is a very \nappropriate number of domain concepts to model in a given Bounded Context, \nneither more nor less.\nOf course this is rarely as easy for each of us to achieve as when Mozart \nwould compose a symphony with the ease of writing a letter to a friend. At any \ngiven time we may have missed an opportunity to refine the domain model to \nsome degree. During each iteration we challenge our assumptions about the \nmodel, which forces us to add or remove a concept or change the way con-\ncepts behave and collaborate. But the point is that we face that challenge time \nand again, and using DDD principles we give serious consideration to what \nbelongs and what does not. We use Bounded Context and tools such as Con-\ntext Maps to help analyze what is truly part of a Core Domain. We don\u2019t resort \nto applying arbitrary segregation rules based on non-DDD principles.\nThe Beautiful Sound of Domain Models\nIf our models were music, they would have the unmistakable sound of completeness, \npurity, power, and possibly even elegance and beauty.\nIf we constrain a given Bounded Context too stringently, gaping holes \nresult from vital but missing contextual concepts. And if we keep piling con-\ncepts onto the model that don\u2019t express the core of the business problem being \nsolved, we will muddy the waters so much that we will fail to observe and \nunderstand what is essential. Our goal? If our models were music, they would \nhave the unmistakable sound of completeness, purity, power, and possibly even \n 6. Orion Pictures, Warner Brothers, 1984.\nwww.EBooksWorld.ir\n", "page": 112, "type": "text", "section": "Page 112"}
{"text": "Chapter 2 DOMAINS, SUBDOMAINS, AND BOUNDED CONTEXTS\n70\nelegance and beauty. The number of notes\u2014the Modules, Aggregates, Events, \nand Services inside\u2014would be neither more nor less than what the correct \ndesign requires. Those \u201clistening\u201d in on the model would never have to ask \nwhat that strange \u201csound\u201d is in the middle of an otherwise harmonious sym-\nphony. Nor would they be distracted by moments of complete silence caused by \na missing page or two of musical notes.\nWhat could lead us into creating a wrong-sized Bounded Context? We \nmight mistakenly allow architectural influences, rather than the Ubiquitous \nLanguage, to guide us. Perhaps the way a platform, framework, or some infra-\nstructure is typically used to package and deploy components could unduly \ninfluence the way we think about Bounded Contexts, treating them as techni-\ncal rather than linguistic boundaries.\nAnother trap would be to divide Bounded Contexts in order to distribute \ntasks to available developer resources. Technical leads and project managers \nmight think it is easier for developers to manage smaller tasks. While that \nmight be the case, enforcing boundaries for the sake of task distribution plays \nfalse to the linguistic motivations of contextual modeling. In fact, there is no \nneed to impose fake boundaries in order to manage technical resources.\nThe important question is, What does the Language of the domain experts \nindicate about the real contextual boundaries?\nWhen a fake Context is formulated in order to address an architectural com-\nponent or developer resources, the Language becomes fragmented and lacks \nexpressiveness. Hence, focus on the Core Domain with the concepts that nat-\nurally fit together into a single Bounded Context, according to the Language \nspoken by domain experts. After you do so, you can identify the components \nthat naturally fit in a single, cohesive model. Keep all such components in the \nBounded Context.\nSometimes the problem of creating miniature Bounded Contexts can be \navoided with careful application of Modules. Given an analysis of a set of ser-\nvices that are spread across multiple \u201cBounded Contexts,\u201d you will find that \njudicious use of Modules could reduce the total number of actual Bounded \nContexts to just one. Modules can also be used as a means to divide developer \nresponsibilities, hence managing task distribution using a more appropriate \ntactical approach.\nWhiteboard Time\n\u2022 Draw a Bounded Context of your current model as a big, irregularly \nshaped ellipse.\nwww.EBooksWorld.ir\n", "page": 113, "type": "text", "section": "Page 113"}
{"text": " \nMAKING SENSE OF BOUNDED CONTEXTS\n71\nEven if you don\u2019t yet have an explicit model, still think of the Language within.\n\u2022 Inside the ellipse, write the names of the primary concepts that you are \nsure your code implements. See if you can spot concepts that should be \nthere but are missing, and those that are there but shouldn\u2019t be. What \nshould you do about each of those problems?\nBe Careful to Practice DDD Using Linguistic Drivers\nThe bottom line: If you are not following the Language drivers, you are not working \nwith and listening to domain experts to create the Bounded Context. Think care-\nfully about the size of your Bounded Contexts. Don\u2019t be too quick to miniaturize \nthem.\nAligning with Technical Components\nIt doesn\u2019t hurt to think about a Bounded Context in terms of the technical \ncomponents that house it. Just keep in mind that technical components don\u2019t \ndefine the Context. Let\u2019s consider some common ways that they are composed \nand deployed.\nWhen using an IDE such as Eclipse or IntelliJ IDEA, a Bounded Context is \noften housed in a single project. When using Visual Studio and .NET, you may \nfavor dividing your user interface, Application Services, and domain model \ninto separate projects within the same solution, or you may decide on another \ndivision. The source tree of the project may be limited to the domain model \nitself, or it may contain surrounding Layers (4) or Hexagonal (4) areas. There \nis a lot of flexibility here. Using Java, the top-level package generally defines \nthe highest-level Module name for the Bounded Context. Using one of the pre-\nceding examples, that could be done something like this:\n    com.mycompany.optimalpurchasing\nThe source tree of this Bounded Context would be further divided accord-\ning to Architectural responsibilities. Here\u2019s a view of the project\u2019s possible sec-\nond-level package names:\n    com.mycompany.optimalpurchasing.presentation\n    com.mycompany.optimalpurchasing.application\n    com.mycompany.optimalpurchasing.domain.model\n    com.mycompany.optimalpurchasing.infrastructure\nEven with these modular divisions, only a single team should work in a single \nBounded Context. \nwww.EBooksWorld.ir\n", "page": 114, "type": "text", "section": "Page 114"}
{"text": "Chapter 2 DOMAINS, SUBDOMAINS, AND BOUNDED CONTEXTS\n72\nA Single Team for a Single Bounded Context\nAssigning a single team to work on a single Bounded Context is not an attempt to \nlimit flexibility to team organization. It\u2019s not as if teams can\u2019t be arranged as needed, \nor that individual members of one team cannot be used on one or more other proj-\nects. A company should use people in the way that best fits its needs. This is simply \nstating that it is best for one well-defined, cohesive team of domain experts and \ndevelopers to focus on one Ubiquitous Language modeled in an explicit Bounded \nContext. If you assign two or more distinct teams to one Bounded Context, each \nteam will contribute to a divergent and ill-defined Ubiquitous Language.\nThere is also the possibility that two teams will cooperate in the design of \na Shared Kernel, which is actually not a typical Bounded Context. This Context \nMapping pattern forms an intimate relationship between two teams, which requires \nongoing consultation when model changes are deemed necessary. This modeling \napproach is less common and is generally avoided if possible.\nWhen using Java, we may technically house a Bounded Context in one or \nmore JAR files, including WAR or EAR files. The desire for modularization \nmay have an influence here. Loosely coupled parts of the domain model could \nbe housed in separate JAR files, enabling them to be deployed independently \nby version. This would be especially useful with large models. Creating mul-\ntiple JAR files of a single model would provide the advantage of managing \nversions of its elements using OSGi bundles or using Java 8 Jigsaw modules. \nThus, various high-level modules, their versions, and their dependencies could \nbe managed as bundles/modules. There are at least four such bundles/modules \nrepresented by the preceding DDD-based, second-level Modules, and possibly \nmore.\nFor a native Windows Bounded Context, such as for the .NET platform, \ndeployment would be done using separate assemblies in DLL files. Think of \na DLL as having similar deployment motivations to those of JAR described \npreviously. The model could be partitioned for deployment in similar ways. All \ncommon language runtime (CLR) modularization is managed through assem-\nblies. The specific version of an assembly and the versions of dependent assem-\nblies are recorded in the assembly\u2019s manifest. See [MSDN Assemblies].\nSample Contexts\nBecause the samples represent a greenfield development environment, the three \nchosen Bounded Contexts eventually align in the most desirable way, one-to-\none, with their respective Subdomains. The team wasn\u2019t successful in aligning \nthem one-to-one from the start, which teaches a crucial lesson. The ultimate \noutcome is shown in Figure 2.7.\nwww.EBooksWorld.ir\n", "page": 115, "type": "text", "section": "Page 115"}
{"text": " \nSAMPLE CONTEXTS\n73\nThe following material demonstrates how the three models form a realistic, \nmodern enterprise solution. There are always multiple Bounded Contexts in \nany project in the real world. Integration among them is an important scenario \nin today\u2019s enterprise. In addition to Bounded Context and Subdomains, we \nmust also grasp Context Mapping with Integration (13).\nLet\u2019s look at the three Bounded Contexts provided as sample DDD imple-\nmentations.7 They are the Collaboration Context, the Identity and Access \nContext, and the Agile Project Management Context.\nCollaboration Context\nBusiness collaboration tools are one of the most important areas for creating \nand facilitating a synergistic workplace in the fast-paced economy. Anything \n 7. Note that Context Maps provides more detail about the actual three sample \nBounded Contexts, how they are related to each other, and how they are \nintegrated. Still, more depth is concentrated on the Core Domain.\nIdentity and Access\n(Generic)\nAgile PM (Core)\nCollaboration (Supporting)\nDomain\nIdentity and Access\nContext\nAgile PM Context\nCollaboration\nContext\nFigure 2.7 The assessment view of the sample Bounded Contexts in fully \naligned Subdomains\nwww.EBooksWorld.ir\n", "page": 116, "type": "text", "section": "Page 116"}
{"text": "Chapter 2 DOMAINS, SUBDOMAINS, AND BOUNDED CONTEXTS\n74\nthat can help increase productivity, transfer knowledge, promote idea sharing, \nand associatively manage the creative process so results will not be misplaced \nis a boon to the corporate success equation. Whether the software tools offer \nfeatures for broad communities or for narrow audiences targeted to daily activ-\nities and projects, corporations are flocking to the best-of-breed online tools, \nand SaaSOvation wants a share of that market.\nThe core team tasked to design and implement the Collaboration Context\nwas given a first-release mandate to support the following minimum suite \nof tools: forums, shared calendars, blogs, instant messaging, wiki, message \nboards, document management, announcements and alerts, activity tracking, \nand RSS feeds. While supporting a broad array of features, each of the indi-\nvidual collaboration tools in the suite can also support targeted, narrow team \nenvironments, yet they remain in the same Bounded Context because they are \nall part of collaboration. Unfortunately this book cannot provide the entire \ncollaboration suite. However, we do explore parts of the domain model for the \ntools represented in Figure 2.8, namely, Forums and Shared Calendars.\nNow, to the team experience . . .\nCollaboration Context\n<<aggregate root>>\nForum\n<<domain event>>\nForumClosed\n<<domain event>>\nForumReopened\n<<domain event>>\nForumDescriptionChanged\n<<domain event>>\nForumSubjectChanged\n<<domain event>>\nPostedToDiscussion\n<<domain event>>\nDiscussionStarted\n<<aggregate root>>\nDiscussion\n<<value object>>\nOwner\n<<value object>>\nAuthor\n<<aggregate root>>\nCalendar\n<<aggregate root>>\nPost\n<<value object>>\nParticipant\n<<domain event>>\nCalendarEntryScheduled\n<<aggregate root>>\nCalendarEntry\n<<value object>>\nModerator\nInvitee\nRepetition\nTime Span\nCollaboration Schema\n<<value object>>\nCreator\nFigure 2.8 The Collaboration Context. Its Ubiquitous Language determines what belongs \ninside the boundary. For readability, some model elements are not shown. The same goes for \nuser interface (UI) and Application Service components.\nwww.EBooksWorld.ir\n", "page": 117, "type": "text", "section": "Page 117"}
{"text": " \nSAMPLE CONTEXTS\n75\nTactical DDD was used from the inception of product develop-\nment, but the team was still learning some of DDD\u2019s finer points. \nIn fact, they were really using what amounted to DDD-Lite, \nemploying the tactical patterns mostly for a technical payoff. \nSure, they were attempting to capture the Ubiquitous Language \nof collaboration, but they didn\u2019t understand that the model had \nclear limits that couldn\u2019t be stretched too far. As a result, they \nmade a mistake by baking security and permissions into the \ncollaboration model. The team realized well into the project that designing security and \npermissions as part of their model was not as desirable as they once thought.\nEarly on they were not overly concerned about or fully aware of the danger of \nconstructing an application silo. Yet, without using a central security provider, that\u2019s \njust what would happen. It constituted mixing two models in one. Soon enough they \nlearned that the confusing entanglement that resulted from blending security con-\ncerns into their Core Domain had backfired. Right in the middle of core business \nlogic, in behavioral methods, developers would check for client permissions to carry \nout the request:\npublic class Forum extends Entity {\n    ...\n    public Discussion startDiscussion(\n            String aUsername, String aSubject) {\n        if (this.isClosed()) {\n            throw new IllegalStateException(\"Forum is closed.\");\n        }\n        User user = userRepository.userFor(this.tenantId(), aUsername);\n        if (!user.hasPermissionTo(Permission.Forum.StartDiscussion)) {\n            throw new IllegalStateException(\n                    \"User may not start forum discussion.\");\n        }\n        String authorUser = user.username();\n        String authorName = user.person().name().asFormattedName();\n        String authorEmailAddress = user.person().emailAddress();\n        Discussion discussion = new Discussion(\n                this.tenant(), this.forumId(),\n                DomainRegistry.discussionRepository().nextIdentity(),\n                authorUser, authorName, authorEmailAddress,\n                aSubject);\n        return discussion;\n    }\n    ...\n}\nwww.EBooksWorld.ir\n", "page": 118, "type": "text", "section": "Page 118"}
{"text": "Chapter 2 DOMAINS, SUBDOMAINS, AND BOUNDED CONTEXTS\n76\nDid I Just See a Train Wreck?\nSome developers consider the chaining of multiple expressions in a row, such as \nuser.person().name().asFormattedName(), a \u201ctrain wreck.\u201d Others consider \nit expressiveness in code. I am not addressing either of those viewpoints. Rather, I \nam focused on the muddled model. The \u201ctrain wreck\u201d is another topic entirely.\nThis was really bad design. Developers should not have been able to reference \nUser here, let alone query a Repository (12) for one. Even Permission should \nhave been out of reach. It was possible because these were wrongly designed as part \nof the collaboration model. What is more, this distortion caused them to overlook a \nconcept that they should have modeled, namely, Author. Instead of gathering three \nrelated attributes into an explicit Value Object, the developers seemed to be satisfied \nto deal with the data elements separately. Security was on their minds rather than \ncollaboration.\nThis was not an isolated case. Every collaboration object had similar issues. As \nthe risk of creating a Big Ball of Mud was becoming imminent, the team decided the \ncode had to change. Besides, the team also wanted to switch from a permissions \napproach to security and use role-based access management instead. What would \nthey do?\nBeing users of agile development methodologies and eventual builders of agile \nproject management tools, they were not afraid to employ refactoring efforts just in \ntime. So iteratively refactor they would. Still the question remained: What were the \nbest DDD patterns to get them out of their bad situation, a deep bog of ill-placed \ncode?\nAs a few on the team spent extra hours poring over the [Evans] tactical building \nblock patterns, they realized that these were not the answer. They had followed the \nguidance in those patterns to create Aggregates by composing Entities and Value \nObjects in a technical way. They used Repositories and Domain Services (7) as \nwell. Nonetheless, they were missing something important, and possibly this pointed \nto the need to pay closer attention to the second half of [Evans].\nFinally doing so, they noted some empowering techniques. As they pored over \n\u201cPart III: Refactoring toward Deeper Insight\u201d [Evans], it was obvious that DDD \noffered far more than they once thought. With the techniques gleaned from that part \nof [Evans], they now knew how they could improve their current model by paying \ncloser attention to the Ubiquitous Language. By spending more quality time with their \ndomain experts, they could produce a model that more closely resembled their men-\ntal model. But that still didn\u2019t address the security morass that distorted their vision of \na pure collaboration domain model.\nFurther into the book there was \u201cPart IV: Strategic Design\u201d [Evans]. One of the \nteam members found what proved to be crucial guidance that would eventually lead \nthem to the realization of a Core Domain. One of the first new tools employed was \nContext Maps, which led to a better understanding of their current project situation. \nAlthough a simple exercise, drawing the first Context Map and formulating discus-\nsions about their predicament was a big step forward. It led to productive analysis \ntoward a resolution, which eventually unblocked the team.\nwww.EBooksWorld.ir\n", "page": 119, "type": "text", "section": "Page 119"}
{"text": " \nSAMPLE CONTEXTS\n77\nThey now had a few options to make interim refinements, enabling them to stabi-\nlize their increasingly brittle model:\n \n1. They could possibly refactor the model into Responsibility Layers [Evans], \ndividing the security and permissions features by pushing them down into \na lower logical layer of the existing model. But that didn\u2019t seem like the best \napproach. The use of Responsibility Layers is intended to address large-scale \nmodels, or to plan for those that will eventually grow to a large scale. Each layer \nis meant to remain in the model because it is part of the Core Domain, even \nthough the layers should be carefully divided. On the other hand, what the team \nwas dealing with were misappropriated concepts\u2014ones that didn\u2019t belong in the \nCore Domain.\n \n2. Alternatively they could work toward a Segregated Core [Evans]. This could \nbe accomplished by an exhaustive search for all security and permissions con-\ncerns in the Collaboration Context, followed by the refactoring of the identity \nand access components into completely separate packages in the same model. \nIt would not produce the ultimate outcome of creating a completely separate \nBounded Context, but it would move the team closer to it. This seemed to be \nprecisely what was needed, for the pattern itself states: \u201cThe time to chop out \na Segregated Core is when you have a large Bounded Context that is critical \nto the system, but where the essential part of the model is being obscured by \na great deal of supporting capability.\u201d The supporting capability was definitely \nsecurity and permissions. The team eventually realized that a separate Identity \nand Access Context would emerge out of these efforts and serve as a Generic \nSubdomain to their Collaboration Context.\nThe initiative to create a Segregated Core would not be simple. It could require a \nfew weeks of unplanned work. But if they didn\u2019t take corrective action and refactor \nsoon, they\u2019d be paying for their lack of corrective action with bugs, coupled with a \nfragile code base that would not respond well to change. Business leadership helped \nconfirm the wisdom of this direction when they determined that a successful separa-\ntion into a new business service could someday lead to a new SaaS product.\nImportantly, the team now understood the value of Bounded Contexts and of fight-\ning hard to maintain a cohesive Core Domain. Using additional patterns of strategic \ndesign, they could segregate reusable models in separate Bounded Contexts and \nintegrate as appropriate.\nLikely the future Identity and Access Bounded Context would look different from \nthe embedded security and permissions design. Designing for reuse would force the \nteam to focus on a more general-purpose model, one that could be exploited by many \napplications as necessary. That dedicated team\u2014different from our Collaboration \nContext team, but formed using a few members from it\u2014could also introduce various \nimplementation strategies. The strategies could include use of third-party products \nand customer-specific integrations, which had become far out of reach due to the \nembedded security tangle.\nSince the development of the Segregated Core became an interim step, we don\u2019t \nfocus on those results here. Briefly, it amounted to moving all security and permissions \nwww.EBooksWorld.ir\n", "page": 120, "type": "text", "section": "Page 120"}
{"text": "Chapter 2 DOMAINS, SUBDOMAINS, AND BOUNDED CONTEXTS\n78\nclasses to segregated Modules and requiring Application Services clients to check \nsecurity and permissions using those objects prior to calling into the Core Domain. \nThat freed the Core to implement only collaboration model object compositions and \nbehaviors. The Application Service took care of security and object translation:\npublic class ForumApplicationService ... {\n    ...\n    @Transactional\n    public Discussion startDiscussion(\n            String aTenantId, String aUsername,\n            String aForumId, String aSubject) {\n        Tenant tenant = new Tenant(aTenantId);\n        ForumId forumId = new ForumId(aForumId);\n        Forum forum = this.forum(tenant, forumId);\n        if (forum == null) {\n            throw new IllegalStateException(\"Forum does not exist.\");\n        }\n        Author author =\n                this.collaboratorService.authorFrom(\n                        tenant,\n                        anAuthorId);\n        Discussion newDiscussion =\n                forum.startDiscussion(\n                        this.forumNavigationService(),\n                        author,\n                        aSubject);\n        this.discussionRepository.add(newDiscussion);\n        return newDiscussion;\n    }\n    ...\n}\nThe result to the Forum looked like this:\npublic class Forum extends Entity {\n    ...\n    public Discussion startDiscussionFor(\n        ForumNavigationService aForumNavigationService,\n        Author anAuthor,\n        String aSubject) {\n        if (this.isClosed()) {\n            throw new IllegalStateException(\"Forum is closed.\");\n        }\nwww.EBooksWorld.ir\n", "page": 121, "type": "text", "section": "Page 121"}
{"text": " \nSAMPLE CONTEXTS\n79\n        Discussion discussion = new Discussion(\n                this.tenant(),\n                this.forumId(),\n                aForumNavigationService.nextDiscussionId(),\n                anAuthor,\n                aSubject);\n        DomainEventPublisher\n            .instance()\n            .publish(new DiscussionStarted(\n                    discussion.tenant(),\n                    discussion.forumId(),\n                    discussion.discussionId(),\n                    discussion.subject()));\n        return discussion;\n    }\n    ...\n}\nThis removed the User and Permission tangle and focused the model strictly \non collaboration. Again, it was not a picture-perfect outcome, but it prepared the team \nfor the future refactorings to separate and integrate Bounded Contexts. The Collab-\noration Context team would finally remove all the security and permissions Modules \nand types from their Bounded Context and gladly employ the new Identity and Access \nContext. Their ultimate goal to make security central and reusable was now within \nreach.\nGranted, the team could have started out going in the other direction. They could \nhave miniaturized Bounded Contexts by creating a number of separate ones, ending \nup with ten or more total\u2014one for each collaboration facility (for example, Forum \nand Calendar as separate models). What could have led them in that direction? \nSince most of the collaboration facilities were not coupled to the others, each could \nbe deployed as an autonomous component. By placing each facility in a separate \nBounded Context, the team could create ten or so natural deployment units. True, but \nproducing ten different domain models was unnecessary to achieve those deploy-\nment objectives and would probably only serve to work against the modeling princi-\nples of the Ubiquitous Language.\nInstead, the team kept the model as one but chose to create a separate JAR file for \neach collaboration facility. Using Jigsaw modularization, they created a version-based \ndeployment unit for each. Besides JAR files for the natural collaboration divisions, \nthey also needed one for shared model objects, such as Tenant, Moderator,\nAuthor, Participant, and others. Going this route supported the development of \na unified Ubiquitous Language, while meeting the deployment objectives that had \narchitectural and application management advantages.\nWith this understanding we can examine how the Identity and Access Con-\ntext came about.\nwww.EBooksWorld.ir\n", "page": 122, "type": "text", "section": "Page 122"}
{"text": "Chapter 2 DOMAINS, SUBDOMAINS, AND BOUNDED CONTEXTS\n80\nIdentity and Access Context\nMost enterprise applications today need to have some form of security and \npermissions components in place to ensure that people who try to use the sys-\ntem are authentic users and are authorized to do what they attempt to do. As \nwe just analyzed, a naive approach to application security builds users and \npermissions in with each discrete system, which creates a silo effect in every \napplication.\nCowboy Logic \nLB:  \n\u201cYou have no locks on your barns and silos, but \nnobody steals your corn?\u201d\nAJ:  \n\u201cMy dog Tumbleweed cares for access manage-\nment. It\u2019s my own silo effect.\u201d\nLB:  \n\u201cI don\u2019t think you really understand the book.\u201d\nThe users of one system cannot be easily associated with the users of any \nother systems, even though many of the people using them are the same. To \nprevent silos from popping up all over the business landscape, architects need \nto centralize security and permissions. This is done by purchasing or develop-\ning an identity and access management system. The route chosen will depend \nmuch on the level of sophistication needed, the time available, and the total \ncost of ownership.\nCorrecting the identity and access tangle in CollabOvation \nwould be a multistep process. First the team refactored using \nSegregated Core [Evans]; see the \u201cCollaboration Context\u201d \nsection. This step served the intended purpose at the time to \nensure that CollabOvation was cleansed of security and per-\nmissions concerns. However, they figured that identity and \naccess management should eventually occupy a context \nboundary of its own. That would require an even greater effort.\nThis constitutes a new Bounded Context\u2014the Identity and Access Con-\ntext\u2014and will be used by other Bounded Contexts through standard DDD \nintegration techniques. To the consuming contexts the Identity and Access \nContext is a Generic Subdomain. The product will be named IdOvation.\nAs Figure 2.9 shows, the Identity and Access Context provides support for \nmultitenant subscribers. When developing an SaaS product, this goes without \nwww.EBooksWorld.ir\n", "page": 123, "type": "text", "section": "Page 123"}
{"text": " \nSAMPLE CONTEXTS\n81\nsaying. Each tenant and every object asset owned by a given tenant would have \na completely unique identity, logically isolating each tenant from all others. \nUsers of the systems are registered via self-service by invitation only. Secured \naccess is handled by means of an authentication service, and passwords are \nalways highly encrypted. Groups of users and nested groups enable sophis-\nticated identity management across the entire organization and down to the \nsmallest of teams. Access to system resources is managed through simple, ele-\ngant, yet powerful role-based permissions.\nAs a more advanced step, throughout the model Domain Events (8) are \npublished when model behaviors cause state transformations of special inter-\nest to observers of such occurrences. These Events are generally modeled as \nnouns combined with verbs in the past tense, such as TenantProvisioned,\nUserPasswordChanged, PersonNameChanged, and others as well.\nThe next chapter, \u201cContext Maps,\u201d shows how the Identity and Access \nContext is used by the other two sample Contexts using DDD integration \npatterns.\nIdentity and Access Context\n<<aggregate root>>\nTenant\n<<aggregate root>>\nGroup\n<<aggregate root>>\nRole\n<<aggregate root>>\nUser\n<<domain event>>\nUserPasswordChanged\n<<domain event>>\nUserRegistered\n<<domain event>>\nTenantProvisioned\n<<domain event>>\nTenantActivated\n<<domain event>>\nTenantDeactivated\n<<domain event>>\nPersonNameChanged\n<<domain event>>\nPersonContactInformationChanged\n<<value object>>\nContactInformation\n<<value object>>\nEnablement\n<<value object>>\nGroupMember\n<<entity>>\nPerson\n<<entity>>\nRegistrationInvitation\nIdentity and Access Schema\nFigure 2.9 The Identity and Access Context. Everything inside the boundary is in \ncontext per the Ubiquitous Language. There are other components in this Bounded \nContext, some in the model and some in other layers, but they are not shown here for \nthe sake of readability. The same goes for UI and Application Service components.\nwww.EBooksWorld.ir\n", "page": 124, "type": "text", "section": "Page 124"}
{"text": "Chapter 2 DOMAINS, SUBDOMAINS, AND BOUNDED CONTEXTS\n82\nAgile Project Management Context\nThe lightweight methods of agile development have propelled it to popularity, \nespecially following the creation of the Agile Manifesto in 2001. In its vision \nstatement, SaaSOvation has as its second primary and strategic initiative to \ndevelop an agile project management application. Here\u2019s how things went . . .\nAfter three quarters of successful Collab-\nOvation subscription sales, planned upgrades \nwith incremental improvements per customer \nfeedback, and better-than-expected reve-\nnues, the company\u2019s plans for ProjectOvation \nwere launched. It\u2019s their new Core Domain, \nand top developers from CollabOvation will \nbe pulled in to leverage their SaaS multi-\ntenancy and newfound DDD experience.\nThe tool focuses on management of agile projects, using Scrum as the iterative \nand incremental project management framework. ProjectOvation follows the tra-\nditional Scrum project management model, complete with product, product owner, \nteam, backlog items, planned releases, and sprints. Backlog item estimation is pro-\nvided through business value calculators that use cost-benefit analysis.\nThe business plan began with a two-headed vision. CollabOvation and Project-\nOvation would not go down entirely separate paths. SaaSOvation and its board of \ndirectors envisioned innovation around weaving collaboration tools in with agile \nsoftware development. Thus, CollabOvation features will be offered as an optional \nadd-on to ProjectOvation. Because it provides add-on features, CollabOvation is a \nSupporting Subdomain to ProjectOvation. Product owners and team members will \ninteract in product discussions, release and sprint planning, and backlog item dis-\ncussions, and they will share calendars, and more. There is a future plan to include \ncorporate resource planning with ProjectOvation, but initial agile product goals must \nfirst be met.\nThe technical stakeholders originally planned to develop the ProjectOvation fea-\ntures as an extension of the CollabOvation model by using a revision control sys-\ntem source branch. That actually would have been a huge mistake, although typical \nof those not focusing proper attention on Subdomains in their problem space and \nBounded Contexts in their solution space.\nFortunately the technical staff learned from early problems with the muddled Col-\nlaboration Context. The lesson they learned from that experience convinced them \nthat even starting down the path of combining the agile project management model \nwith the collaboration model would be a major mistake. Now the teams were starting \nto think with a strong leaning toward DDD strategic design.\nFigure 2.10 shows that as a result of adopting a strategic design mentality, the \nProject \nOvation team now appropriately thinks of their consumers as Product Owners \nwww.EBooksWorld.ir\n", "page": 125, "type": "text", "section": "Page 125"}
{"text": " \nSAMPLE CONTEXTS\n83\nand Team Members. After all, those are the project member roles played by Scrum \npractitioners. The users and roles are managed inside the separate Identity and \nAccess Context. By using that Bounded Context, self-service enables subscribers \nto manage their own personal identity. Administrative controls enable managers, \nsuch as product owners, to specify their product team members. With the roles prop-\nerly managed, the Product Owners and Team Members can be created where they \nbelong, inside the Agile Project Management Context. The remainder of the project\u2019s \ndesign will benefit as the team focuses on capturing the Ubiquitous Language of agile \nproject management into a carefully crafted domain model.\nOne requirement calls for ProjectOvation to operate as a set of autonomous appli-\ncation services. The team desires to limit the dependency of ProjectOvation on other \nBounded Contexts to a reasonable periodicity, or at least as much as is practical. \nGenerally speaking, ProjectOvation will be capable of operating on its own, and if \nIdOvation or CollabOvation were to go offline for any number of reasons, Project-\nOvation would continue to function autonomously. Of course, in that case some \nthings might get out of sync for a while, and probably a very short while at that, but the \nsystem would continue to function.\nAgile Project Management Context\n<<domain event>>\nProductSprintScheduled\n<<domain event>>\nProductBacklogItemPlanned\n<<domain event>>\nTaskStatusChanged\n<<domain event>>\nBacklogItemStatusChanged\n<<domain event>>\nBacklogItemCommitted\n<<domain event>>\nBacklogItemScheduled\n<<domain event>>\nProductCreated\n<<domain event>>\nProductReleaseScheduled\n<<value object>>\nBusinessPriority\n<<value object>>\nBusinessPriorityRatings\n<<value object>>\nEstimationLogEntry\n<<entity>>\nTask\nAgile PM Schema\n<<aggregate root>>\nTeam\n<<aggregate root>>\nTeamMember\n<<aggregate root>>\nProduct\n<<aggregate root>>\nProductOwner\n<<aggregate root>>\nBacklogItem\n<<aggregate root>>\nRelease\n<<aggregate root>>\nSprint\nFigure 2.10 The Agile Project Management Context. The Ubiquitous Language of this Bounded \nContext is concerned with Scrum-based agile products, iterations, and releases. For readability, \nsome components, including those from the UI and Application Services, are not shown here.\nwww.EBooksWorld.ir\n", "page": 126, "type": "text", "section": "Page 126"}
{"text": "Chapter 2 DOMAINS, SUBDOMAINS, AND BOUNDED CONTEXTS\n84\nThe Context Gives Each Term a Very Specific Meaning\nA Scrum-based Product has any number of BacklogItem instances that describe the \nsoftware being constructed. This is far different from the products on an e-commerce \nsite that you put in a shopping cart to purchase. How do we know? Because of the Con-\ntext. We understand what our Product means because it is in the Agile PM Context.\nIn an Online Store Context, Product means something very different. The team didn\u2019t \nneed to name the product ScrumProduct in order to communicate the difference.\nThe Core Domain of Product, Backlog Items, Tasks, Sprints, and Releases \nis already off to a better start given the SaaSOvation experience gains. Still, \nwe are interested in looking in on the big lessons they learned along the steep \nlearning curve of carefully modeling Aggregates (10).\nWrap-Up\nThat was a seriously intense discussion of the importance of DDD strategic \ndesign!\n\u2022 You\u2019ve looked into Domains, Subdomains, and Bounded Contexts.\n\u2022 You\u2019ve discovered how to strategically assess the current lay of the enter-\nprise landscape using both problem space and solution space assessments.\n\u2022 You peered extensively into the details of how to use Bounded Contexts \nto explicitly segregate models linguistically.\n\u2022 You\u2019ve learned what is included in Bounded Contexts, how to right-size \nthem, and how they can be built for deployment.\n\u2022 You felt the pain the SaaSOvation team experienced early on in the design \nof the Collaboration Context and how the team worked their way out of \nthat bad situation.\n\u2022 You saw the formation of the current Core Domain, the Agile Project \nManagement Context, which is the focus of the design and implementa-\ntion examples.\nwww.EBooksWorld.ir\n", "page": 127, "type": "text", "section": "Page 127"}
{"text": " \nWRAP-UP\n85\nAs promised, the next chapter takes a deep dive into Context Mapping. It \nis an essential strategic modeling tool to use in designs. You may have figured \nout that we\u2019ve done a bit of Context Mapping already in this chapter. It was \nunavoidable as we assessed different domains. Still, we will go into much more \ndetail next.\nwww.EBooksWorld.ir\n", "page": 128, "type": "text", "section": "Page 128"}
{"text": "This page intentionally left blank \nwww.EBooksWorld.ir\n", "page": 129, "type": "text", "section": "Page 129"}
{"text": "87\nChapter 3\nContext Maps\nWhatever course you decide upon, there is always someone to tell you \nthat you are wrong. There are always difficulties arising which tempt \nyou to believe that your critics are right. To map out a course of action \nand follow it to an end requires courage.\n\u2014Ralph Waldo Emerson\nThe Context Map of a project can be expressed in two ways. The easier way is \nto draw a simple diagram that shows the mappings between two or more exist-\ning Bounded Contexts (2). Understand, however, that you are just drawing a \nsimple diagram of what already exists. The drawing illustrates how the actual \nsoftware Bounded Contexts in the solution space are related to one another \nthrough integration. This means that the more detailed way to express Context \nMaps is as the source code implementations of the integrations. We\u2019ll look at \nboth ways in this chapter, but for most of the implementation details see Inte-\ngrating Bounded Contexts (13).\nAt a high level, keep in mind that this chapter focuses on the solution space \nassessment, whereas the previous chapter dealt quite a bit with the problem \nspace assessment.\nRoad Map to This Chapter\n\u2022 Learn why drawing a Context Map is essential for the success of your project.\n\u2022 See how easy it can be to draw a meaningful Context Map.\n\u2022 Consider the common organizational and system relationships and how they \naffect your projects.\n\u2022 Learn from the SaaSOvation teams as they produce Maps to get control of \ntheir projects.\nWhy Context Maps Are So Essential\nWhen you start out on a DDD effort, first draw a visual Context Map of your \ncurrent project situation. Produce a Context Map of the current Bounded \nwww.EBooksWorld.ir\n", "page": 130, "type": "text", "section": "Page 130"}
{"text": "Chapter 3 CONTEXT MAPS\n88\nContexts involved in your project and the integration relationships between \nthem. Figure 3.1 shows an abstract Context Map. We\u2019ll be filling in the details \nas we progress.\nThis simple drawing is your team\u2019s Map. Other project teams can refer to \nit, but they should also create their own Maps if they are implementing DDD. \nYour Map is drawn primarily to give your team the solution space perspective \nit needs to succeed. Other teams may not be using DDD and/or they may not \ncare about your perspective.\nOh, No! There\u2019s New Terminology!\nWe are introducing Big Ball of Mud, Customer-Supplier, and Conformist here. Be \npatient; these and other DDD team and integration relationships noted here are dis-\ncussed in detail later in this chapter.\nFor example, when you are integrating Bounded Contexts in a large enter-\nprise, you may need to interface with a Big Ball of Mud. The team maintaining \nthe muddy monolith may not care what direction your project takes as long \nas you adhere to their API. So, they aren\u2019t going to gain any insight from your \nMap or what you do with their API. Still, your Map needs to reflect the kind of \nrelationship you have with them, because it will give your team needed insight \nand indicate areas where inter-team communication is imperative. Having \nthat understanding can do much to help your team succeed.\nCommunications Facility\nBesides giving you an inventory of systems you must interact with, a Context Map \nserves as a catalyst for inter-team communication.\nName-C Context\nName-A Context\nName-B Context\nD\nD\nD\nU\nU\nU\nFigure 3.1 A Context Map of an abstract Domain. Three Bounded Contexts \nand their relationships are drawn. The U stands for Upstream and D stands for \nDownstream.\nwww.EBooksWorld.ir\n", "page": 131, "type": "text", "section": "Page 131"}
{"text": " \nWHY CONTEXT MAPS ARE SO ESSENTIAL\n89\nImagine what would happen if your team assumes that the team maintain-\ning the muddy monolith will provide new APIs that you are depending on, but \nthey don\u2019t intend to provide them, or they don\u2019t even know what you are think-\ning. Your team is counting on a Customer-Supplier relationship with the mud. \nThe legacy team, however, by providing only what they currently have, forces \nyour team into an unexpected Conformist relationship. Depending on how late \nin the project you got the bad news, this unseen yet actual relationship could \ndelay your delivery or even cause your project\u2019s failure. By drawing a Context \nMap early, you will be forced to think carefully about your relationships with \nall other projects you depend on.\nIdentify each model in play on the project and define its BOUNDED CON-\nTEXT. . . . Name each BOUNDED CONTEXT, and make the names part of the \nUBIQUITOUS LANGUAGE. Describe the points of contact between the models, \noutlining explicit translation for any communication and highlighting any shar-\ning. [Evans, p. 345]\nWhen the CollabOvation team first \nstarted developing its greenfield model, \nthey should have used a Context Map. \nEven though they were nearly starting \nfrom scratch, stating their assumptions \nabout the project in the form of a Map \nwould have prompted them to think \nabout separate Bounded Contexts. They still could have listed significant modeling \nelements on a whiteboard, and then gathered them into groups of related linguistic \nterms. That would have forced recognition of linguistic boundaries and resulted in a \nsimple Context Map. However, they actually didn\u2019t understand strategic modeling in \nthe least. They first needed to attain a strategic modeling breakthrough. Later on they \ndid make the crucial discovery of this project-saving tool, applying it to their eventual \nbenefit. When the subsequent Core Domain project got under way, it again paid off \nsubstantially.\nLet\u2019s see how you can quickly produce a useful Context Map.\nDrawing Context Maps\nA Context Map captures the existing terrain. First, you should map the pres-\nent, not the imagined future. If the landscape will change as your current proj-\nect progresses, you can update the Map at that time. First focus on the current \nsituation so you can form an understanding of where you are and determine \nwhere to go next.\nwww.EBooksWorld.ir\n", "page": 132, "type": "text", "section": "Page 132"}
{"text": "Chapter 3 CONTEXT MAPS\n90\nCreating a graphical Context Map need not be complicated. Your first \noption is always hand-drawn diagrams where whiteboards and dry-erase \nmarkers rule. The style used here is easily adapted as shown by [Brandolini]. \nIf you decide to use a tool to capture the drawing, be sure to keep it informal.\nReferring back to Figure 3.1, the Bounded Context names are just place-\nholders, as are the integration relationships. They would all be actual names in \na tangible Map. The upstream and downstream relationships are shown, the \nmeanings of which are explained later in the chapter.\nWhiteboard Time\nDraw a simple diagram of your current project situation that communicates at \na high level where the boundaries are, the relationships between them and their \nteams, what kinds of integrations are involved, and the necessary translations \nbetween them.\nRemember that software implements what\u2019s in the drawing. If you need more infor-\nmation about what you should draw, consider the systems that your Bounded Con-\ntext integrates with.\nSometimes we\u2019ll want to zoom in and add more detail to a given part of a \nContext Map. It\u2019s just a different perspective on the same Context(s). Besides \nboundaries, relationships, and translations, we may want to include other items \nsuch as Modules (9), significant Aggregates (10), perhaps how teams are allo-\ncated, and any other information relevant to the Contexts. These techniques \nare demonstrated later in the chapter.\nAll of the drawings and any prose can be placed into a single reference doc-\nument if it has value to the team. With any such effort we should avoid cer-\nemony and remain both simple and agile. The more ceremony you add, the \nfewer people will want to use the Map. Putting too much detail in diagrams \nwon\u2019t really help the team. Open communication is the key. As conversations \nunveil strategic insight, add it to the Context Map.\nNo, It\u2019s Not Enterprisy\nA Context Map is not an Enterprise Architecture or system topology diagram.\nA Context Map is not an Enterprise Architecture or system topology dia-\ngram. The information is conveyed relative to interacting models and DDD \norganizational patterns. Still, Context Maps may be used in high-level \nwww.EBooksWorld.ir\n", "page": 133, "type": "text", "section": "Page 133"}
{"text": " \nWHY CONTEXT MAPS ARE SO ESSENTIAL\n91\narchitectural investigations, providing views of the enterprise not otherwise \navailable. They may highlight architectural deficiencies such as integration \nbottlenecks. Because they exhibit an organizational dynamic, Context Maps \nmay even help us identify sticky governance issues that could block progress, \nand other team and management challenges that are more difficult to uncover \nusing other methods.\nCowboy Logic\nAJ:  \n\u201cThe missus said, \u2018I was out in the pasture with the \ncows; didn\u2019t you notice me?\u2019 I said, \u2018Nope.\u2019 She \ndidn\u2019t talk to me for a week.\u201d\nThe diagrams deserve to be posted prominently on a wall in a team area. If \nthe team frequents a wiki, the diagrams might also be uploaded there. If a wiki \nwill be largely ignored, don\u2019t bother. It\u2019s been said that a wiki can be a place \nwhere information goes to die. No matter where they are displayed, Context \nMaps will be hidden in plain sight unless the team pays regular attention to \nthem through meaningful discussion.\nProjects and Organizational Relationships\nTo briefly reiterate, SaaSOvation is on a path to develop and refine three \nproducts:\n 1. A social collaboration suite product, CollabOvation, enables registered users \nto publish content of business value using popular Web-based tools such as \nforums, shared calendars, blogs, wikis, and the like. This is the SaaSOvation \nflagship product and was the company\u2019s first Core Domain (2) (although the \nteam didn\u2019t know the DDD terminology at the time). It is the Context from \nwhich IdOvation\u2019s (point 2) model was eventually extracted. CollabOvation \nnow uses IdOvation as a Generic Subdomain (2). CollabOvation will itself \nbe consumed as a Supporting Subdomain (2), being an optional add-on to \nProjectOvation (point 3).\n 2. A reusable identity and access management model, IdOvation provides \nsecure role-based access management for registered users. These features \nwere first combined with CollabOvation (point 1), but that implementation \nwas limited and not reusable. SaaSOvation has refactored Collab \nOvation, \nintroducing a new, clean Bounded Context. A key product feature is the \nwww.EBooksWorld.ir\n", "page": 134, "type": "text", "section": "Page 134"}
{"text": "Chapter 3 CONTEXT MAPS\n92\nsupport of multiple tenants, which is vital to an SaaS application.  \nIdOvation \nserves as a Generic Subdomain to its consuming models.\n 3. An agile project management product, ProjectOvation, is at this point in \ntime the new Core Domain. Users of this SaaS product can create project \nmanagement assets, as well as analysis and design artifacts, and track prog-\nress using a Scrum-based execution framework. As with CollabOvation, \nProjectOvation uses IdOvation as a Generic Subdomain. One of the inno-\nvative features adds team collaboration (point 1) to agile project manage-\nment, enabling discussions around Scrum products, releases, sprints, and \nindividual backlog items.\nFinally, the Definitions!\nThe organizational and integration patterns mentioned previously are defined . . .\nWhat are the relationships between these Bounded Contexts and their indi-\nvidual project teams? There are several DDD organizational and integration \npatterns, one of which commonly exists between any two Bounded Contexts. \nEach of the following definitions is largely quoted from [Evans, Ref]:\n\u2022 Partnership: When teams in two Contexts will succeed or fail together, \na cooperative relationship needs to emerge. The teams institute a process \nfor coordinated planning of development and joint management of inte-\ngration. The teams must cooperate on the evolution of their interfaces to \naccommodate the development needs of both systems. Interdependent fea-\ntures should be scheduled so that they are completed for the same release.\n\u2022 Shared Kernel: Sharing part of the model and associated code forms a \nvery intimate interdependency, which can leverage design work or under-\nmine it. Designate with an explicit boundary some subset of the domain \nmodel that the teams agree to share. Keep the kernel small. This explicit \nshared stuff has special status and shouldn\u2019t be changed without consul-\ntation with the other team. Define a continuous integration process that \nwill keep the kernel model tight and align the Ubiquitous Language (1) of \nthe teams.\n\u2022 Customer-Supplier Development: When two teams are in an upstream-\ndownstream relationship, where the upstream team may succeed inter-\ndependently of the fate of the downstream team, the needs of the down-\nstream team come to be addressed in a variety of ways with a wide range \nof consequences. Downstream priorities factor into upstream planning. \nNegotiate and budget tasks for downstream requirements so that every-\none understands the commitment and schedule.\nwww.EBooksWorld.ir\n", "page": 135, "type": "text", "section": "Page 135"}
{"text": " \nWHY CONTEXT MAPS ARE SO ESSENTIAL\n93\n\u2022 Conformist: When two development teams have an upstream/ \ndownstream \nrelationship in which the upstream team has no motivation to provide for \nthe downstream team\u2019s needs, the downstream team is helpless. Altru-\nism may motivate upstream developers to make promises, but they are \nunlikely to be fulfilled. The downstream team eliminates the complex-\nity of translation between bounded contexts by slavishly adhering to the \nmodel of the upstream team.\n\u2022 Anticorruption Layer: Translation layers can be simple, even elegant, \nwhen bridging well-designed Bounded Contexts with cooperative teams. \nBut when control or communication is not adequate to pull off a shared \nkernel, partner, or customer-supplier relationship, translation becomes \nmore complex. The translation layer takes on a more defensive tone. As a \ndownstream client, create an isolating layer to provide your system with \nfunctionality of the upstream system in terms of your own domain model. \nThis layer talks to the other system through its existing interface, requir-\ning little or no modification to the other system. Internally, the layer \ntranslates in one or both directions as necessary between the two models.\n\u2022 Open Host Service: Define a protocol that gives access to your subsystem \nas a set of services. Open the protocol so that all who need to integrate \nwith you can use it. Enhance and expand the protocol to handle new inte-\ngration requirements, except when a single team has idiosyncratic needs. \nThen, use a one-off translator to augment the protocol for that special \ncase so that the shared protocol can stay simple and coherent.\n\u2022 Published Language: The translation between the models of two Bounded \nContexts requires a common language. Use a well-documented shared \nlanguage that can express the necessary domain information as a com-\nmon medium of communication, translating as necessary into and out of \nthat language. Published Language is often combined with Open Host \nService.\n\u2022 Separate Ways: We must be ruthless when it comes to defining require-\nments. If two sets of functionality have no significant relationship, they \ncan be completely cut loose from each other. Integration is always expen-\nsive, and sometimes the benefit is small. Declare a bounded context to \nhave no connection to the others at all, enabling developers to find simple, \nspecialized solutions within this small scope.\n\u2022 Big Ball of Mud: As we survey existing systems, we find that, in fact, \nthere are parts of systems, often large ones, where models are mixed and \nboundaries are inconsistent. Draw a boundary around the entire mess and \nwww.EBooksWorld.ir\n", "page": 136, "type": "text", "section": "Page 136"}
{"text": "Chapter 3 CONTEXT MAPS\n94\ndesignate it a Big Ball of Mud. Do not try to apply sophisticated modeling \nwithin this Context. Be alert to the tendency for such systems to sprawl \ninto other Contexts.\nBy integrating with the Identity and Access Context, both the Collabora-\ntion Context and the Agile Project Management Context avoid going their \nSeparate Ways with respect to security and permissions. True, Separate Ways \nmay be applied Context-wide for a specific system, but it can also be employed \non a case-by-case basis. For example, one team could refuse to use a central-\nized security system but may still choose to integrate with some other corpo-\nrate standard facilities.\nThe teams will cooperate with Customer-Supplier roles. There\u2019s no way that \nSaaSOvation\u2019s management will allow one team to force others to be Con-\nformists. It\u2019s not that a Conformist relationship is always negative. Rather, \nCustomer-Supplier requires commitment on the part of the Supplier to provide \nsupport for the Customer, which fosters the kind of inter-team relationships \nSaaSOvation thinks it needs to achieve complete success. Of course, Customers \naren\u2019t always right, and so some give-and-take must exist. Overall it is the pos-\nitive organizational relationship that the teams need to maintain.\nThe teams\u2019 integrations will make use of Open Host Service and Published \nLanguage. Perhaps surprisingly they will also employ Anticorruption Layer. \nThis is not a contradiction, even though they are establishing open standards \nbetween their Bounded Contexts. They can still realize the benefits of isolated \ntranslation by using its fundamental principles in the downstream Contexts, \nbut with less complexity than needed when consuming a Big Ball of Mud. The \ntranslation layers will be simple and elegant.\nThe Context Map drawings that follow use these abbreviations to indicate \nthe patterns employed at each end of a relationship:\n\u2022 ACL for Anticorruption Layer\n\u2022 OHS for Open Host Service\n\u2022 PL for Published Language\nAs you review the following sample Context Maps and supporting text, \nit may be helpful to glance back at Chapter 2, \u201cDomains, Subdomains, and \nBounded Contexts.\u201d The diagrams of each of the three sample Bounded Con-\ntexts are also useful here. Since they remain fairly high-level, those diagrams \ncould be included as part of the Maps for each Context, although they are not \nrepeated here.\nwww.EBooksWorld.ir\n", "page": 137, "type": "text", "section": "Page 137"}
{"text": " \nWHY CONTEXT MAPS ARE SO ESSENTIAL\n95\nMapping the Three Contexts\nNow let\u2019s jump into the team experience so we can learn from what they \ndid . . .\nWhen the CollabOvation team realized the tangle they had \ncreated, they dug into [Evans] to help find their way out of it. \nAmong other discoveries of enormous value within the strate-\ngic design patterns, they found a practical tool named Context \nMaps. They also found a helpful article online by [Brandolini] \nexpanding on this technique. Since the tool\u2019s guidance indi-\ncated that they should map the existing terrain, that\u2019s the first \nstep they took. Figure 3.2 shows the results.\nThe first Map produced by the team highlights their early recognition of the exis-\ntence of a Bounded Context that they named Collaboration Context. By the odd shape \nof the existing boundary they appropriately conveyed the likely existence of a second \nContext, but one without a clean and clear separation from the Core Domain.\nA narrow passage near the top allows foreign concepts to migrate back \nand forth almost without censure, as the caution sign indicates. It\u2019s not that \nContext boundaries need to be completely impenetrable. As with any bound-\nary, the team wants the Collaboration Context to control with full knowl-\nedge what crosses its borders and for what purpose. Otherwise the territory \nbecomes overrun with unknown and possibly unwelcome visitors. In the case \nof a model, the unwelcome visitors generally cause confusion and bugs. Mod-\nelers should be cordial and even welcoming, but under conditions that favor \norder and harmony. Any foreign concepts entering the boundaries need to \ndemonstrate the right to be there, even taking on characteristics compatible \nwith the territory within.\nCollaboration Context\nUsers-Permissions\n!\nFigure 3.2 The tangle within the Collaboration Context caused by unwelcome \nconcepts is exposed by this Map. The caution sign points out the area of impurity.\nwww.EBooksWorld.ir\n", "page": 138, "type": "text", "section": "Page 138"}
{"text": "Chapter 3 CONTEXT MAPS\n96\nThis analysis led to a better understanding \nnot only of the current condition of the model, \nbut in what direction the project needed to \ngo. Once the project team realized that con-\ncepts such as security, users, and permis-\nsions did not belong inside the Collaboration \nContext, they responded accordingly. The \nteam had to segregate these from the Core \nDomain and allow them to enter only under \nagreeable terms. \nThis is a vital DDD project commitment. The Language of each Bounded \nContext must be honored in order for all models to remain pure. Linguistic \nsegregation and a strict adherence to it help each team involved in the project \nto focus on their own Bounded Context and keep their vision correctly focused \non their own work.\nApplying Subdomain analysis, or problem space assessment, led the team to the \ndiagram shown in Figure 3.3. Two Subdomains were carved out of a single Bounded \nContext. Since it is a good goal to align Subdomains one-to-one with Bounded Con-\ntexts, this analysis showed the need to separate the single Bounded Context into two.\nCollaboration (Core) Subdomain\nSecurity (Generic) Subdomain\nCollaboration Context\nUsers-Permissions\n!\nFigure 3.3 The team\u2019s Subdomain analysis led to the discovery of two, a \nCollaboration Core Domain and a Security Generic Subdomain.\nwww.EBooksWorld.ir\n", "page": 139, "type": "text", "section": "Page 139"}
{"text": " \nWHY CONTEXT MAPS ARE SO ESSENTIAL\n97\nThe Subdomain and boundary analysis led to decisions. When human users of Col-\nlabOvation interact with the available features, they do so as Participants, Authors, \nModerators, and so forth. A variety of other contextual separations are discussed \nlater, but this gives a good idea of the necessary divisions that were created. With \nthat knowledge, the clean and crisp boundaries indicated on the high-level Context \nMap shown in Figure 3.4 came about. The team used Segregated Core [Evans] to \nrefactor to reach this point of clarity. The recognizable shapes of the boundaries act \nas icons or visual cues for each Context. Keeping the same relative shapes across \ndiagrams can help with cognition.\nThe Context Maps usually don\u2019t appear all at once as the various sketches \nmay lead you to believe, although when finally understood, they are not dif-\nficult to produce. Thought and discussion help to refine a Map through rapid \niterations. Some of the refinements might come in the way of integration \npoints, which describe the relationships between Contexts.\nThe first two Maps indicate the gains made after applying strategic design. After the \noriginal CollabOvation project was well under way, the team had factored out iden-\ntity and access concerns. As they progressed, they produced the Context Map in \nFigure 3.4. The team sketched only the Core Domain, Collaboration Context, along \nCollaboration Context\nIdentity and Access\nContext\nU\nD\nOHS / PL\nACL\nFigure 3.4 The original Core Domain is marked with a bold boundary and \nintegration points. Here IdOvation serves as a Generic Subdomain for the \ndownstream CollabOvation.\nwww.EBooksWorld.ir\n", "page": 140, "type": "text", "section": "Page 140"}
{"text": "Chapter 3 CONTEXT MAPS\n98\nwith the new Generic Subdomain, Identity and Access Context. They didn\u2019t depict \nany future models, such as the Agile Project Management Context. It wouldn\u2019t help \nthe team to jump ahead too far. They only needed to correct flaws with what existed. \nTransformations supporting forthcoming systems would be needed soon enough, and \nthat Map belonged to the future team to produce.\nWhiteboard Time\n\u2022 Thinking of your own Bounded Context, can you identify concepts that \ndon\u2019t belong? If so, draw a new Context Map that shows the desired Con-\ntexts and relationships between them.\n\u2022 Which of the nine DDD organizational and integration relationships \nwould you choose, and why?\nWhen the next project involving Project-\nOvation was starting up, it was time to \naugment the existing Map with the new \nCore Domain, the Agile Project Manage-\nment Context. The results of that map-\nping are seen in Figure 3.5. It was not \npremature to capture what was in plan-\nning, even though it was not yet in code. The details inside the new Context weren\u2019t \nfully understood, but that would come with discussion. Applying high-level strategic \ndesign at this early stage would help all teams understand where their responsibil-\nities lay. Since the third of the three high-level Maps is just an augmentation of the \nprevious, we\u2019ll be focusing on it. That\u2019s where SaaSOvation is headed. The company \nhas assigned experienced lead developers to the new project. Being the richest of \nthe three Contexts and the current direction, the new Core Domain is where the best \ndevelopers should be working.\nSome essential segregations are already well understood. Similar to the Collabo-\nration Context, when users of ProjectOvation create products, plan releases, sched-\nule sprints, and work on the tasks of backlog items, they do so as Product Owners \nand Team Members. The Identity and Access Context is segregated out of the Core \nDomain. The same goes for their use of the Collaboration Context. It is now a Sup-\nporting Subdomain. Any consumption by the new model will be protected by bound-\naries and translations into Core Domain concepts.\nConsider the finer details of these diagrams. They are not system architec-\nture diagrams. If they were, given that Agile Project Management Context is \nwww.EBooksWorld.ir\n", "page": 141, "type": "text", "section": "Page 141"}
{"text": " \nWHY CONTEXT MAPS ARE SO ESSENTIAL\n99\nour new Core Domain, we would expect it to reside at the top or center of the \ndiagram. Here, however, it is at the bottom. This possibly curious characteris-\ntic indicates visually that the core model is downstream of the others.\nThis nuance serves as another visual cue. Upstream models have influences \non downstream models, as activities on a river that occur upstream tend to \nhave impacts on populations downstream, whether positive or negative. Con-\nsider pollutants dumped into a river by a large city. Those pollutants may have \nlittle impact on that city, but downstream cities may face severe consequences. \nThe vertical proximity of models on the diagram helps identify the upstream \ninfluences on downstream models. The labels U and D explicitly call this out \nbetween each associated model. These labels make vertical positioning of each \nContext less important, yet it is still visually appealing to employ them.\nCowboy Logic \nLB:  \n\u201cWhen you get yourself a powerful thirst, always \ndrink upstream from the herd.\u201d\nCollaboration Context\nIdentity and Access\nContext\nU\nU\nU\nD\nD\nD\nOHS / PL\nOHS / PL\nACL\nAgile Project Management\nContext\nACL\nACL\nFigure 3.5 The current Core Domain is marked with a bold boundary and \nintegration points. The CollabOvation Supporting Subdomain and IdOvation Generic \nSubdomain are upstream.\nwww.EBooksWorld.ir\n", "page": 142, "type": "text", "section": "Page 142"}
{"text": "Chapter 3 CONTEXT MAPS\n100\nThe Identity and Access Context is furthest upstream. It has an impact on \nboth the Collaboration Context and the Agile Project Management Context.\nOur Collaboration Context is also upstream to the Agile Project Management \nContext because the agile model depends on the collaboration model and ser-\nvices. As noted in Bounded Contexts (2), ProjectOvation will operate as auton-\nomously as is practical. Operation must continue largely independent of the \navailability of surrounding systems. This does not mean that autonomous ser-\nvices can operate entirely independently of upstream models. We must design \nin ways to drastically limit direct real-time dependencies. Though autonomous, \nour Agile Project Management Context is still downstream of the others.\nOutfitting an application with autonomous services does not mean that \ndatabases from upstream Contexts are simply replicated into the dependent \nContext. Replication would force the local system to take on many undesir-\nable responsibilities. That would require the creation of a Shared Kernel, which \ndoesn\u2019t really achieve autonomy.\nOn the latest Map, note the connector boxes on the upstream side of each \nconnection. Both of the connectors are labeled OHS/PL, an abbreviation iden-\ntifying Open Host Service and Published Language. All three downstream \nconnector boxes are labeled ACL, shorthand for Anticorruption Layer. The \ntechnical implementations are covered under Integrating Bounded Contexts (13).\nBriefly, these integration patterns have these technical characteristics:\n\u2022 Open Host Service: This pattern can be implemented as REST-based \nresources that client Bounded Contexts interact with. We generally think \nof Open Host Service as a remote procedure call (RPC) API, but it can be \nimplemented using message exchange.\n\u2022 Published Language: This can be implemented in a few different ways but \nis many times done as an XML schema. When expressed with REST-based \nservices, the Published Language is rendered as representations of domain \nconcepts. Representations may include both XML and JSON, for exam-\nple. It is also possible to render representations as Google Protocol Buffers. \nIf you are publishing Web user interfaces, it might also include HTML rep-\nresentations. One advantage to using REST is that each client can specify \nits preferred Published Language, and the resources render representations \nin the requested content type. REST also has the advantage of producing \nhypermedia representations, which facilitates HATEOAS. Hypermedia \nmakes a Published Language very dynamic and interactive, enabling cli-\nents to navigate to sets of linked resources. The Language may be pub-\nlished using standard and/or custom media types. A Published Language \nis also used in an Event-Driven Architecture (4), where Domain Events (8)\nare delivered as messages to subscribing interested parties.\nwww.EBooksWorld.ir\n", "page": 143, "type": "text", "section": "Page 143"}
{"text": " \nWHY CONTEXT MAPS ARE SO ESSENTIAL\n101\n\u2022 Anticorruption Layer: A Domain Service (7) can be defined in the down-\nstream Context for each type of Anticorruption Layer. You may also \nput an Anticorruption Layer behind a Repository (12) interface. If using \nREST, a client Domain Service implementation accesses a remote Open \nHost Service. Server responses produce representations as a Published \nLanguage. The downstream Anticorruption Layer translates representa-\ntions into domain objects of its local Context. This is where, for example, \nthe Collaboration Context asks the Identity and Access Context for a \nUser-in-Moderator-role resource. It might receive the requested resource \nas XML or JSON, and then translates to a Moderator, which is a Value \nObject. The new Moderator instance reflects a concept in terms of the \ndownstream model, not the upstream model.\nThe chosen patterns are common ones. Constraining the choices helps keep \nthe scope of integration discussed in this book manageable. We\u2019ll see, even among \nthese select few patterns, that there is diversity in how they can be applied.\nThe question remains: Is that all there is to creating a Context Map? Pos-\nsibly. The high-level view provides a good amount of knowledge about the \nproject as a whole. Still, we may be curious about what goes on inside the \nconnections and the named relationships on each Context. Curiosity among \nteam members influences us to produce a bit more detail. When we zoom in, \nthe somewhat blurred picture of the three integration patterns becomes clearer.\nLet\u2019s take a minor step back in time. Since the Collaboration Context was \nthe first Core Domain, let\u2019s peer inside it. First we introduce the zooming tech-\nnique with the simpler integrations, then progress to the more advanced ones.\nCollaboration Context\nNow, back to the experience of the Collaboration team . . .\nThe Collaboration Context was the first model and system\u2014the \nfirst Core Domain\u2014and its workings are now well understood. \nThe integrations employed here are easier yet less robust in \nterms of reliability and autonomy. Creating a zoomed Context \nMap is done with relative ease.\nAs a client of the REST-based services published by the Identity and Access \nContext, the Collaboration Context takes a traditional RPC-like approach to \nreaching resources. This Context doesn\u2019t permanently record any data from \nwww.EBooksWorld.ir\n", "page": 144, "type": "text", "section": "Page 144"}
{"text": "Chapter 3 CONTEXT MAPS\n102\nthe Identity and Access Context that it can subsequently reference for local \nreuse. Rather, it reaches out to the remote system to request information every \nsingle time it needs it. This Context is obviously highly dependent on remote \nservices, not autonomous. This is a fact that SaaSOvation is willing to live with \nfor now. Integration with a Generic Subdomain was completely unexpected. \nTo meet their demanding delivery schedule the team couldn\u2019t invest time in \na more elaborate autonomous design. At the time the up-front ease-of-design \nperk could not be passed up. After the rollout of ProjectOvation and the expe-\nrience with autonomy gained there, similar techniques may be employed for \nCollabOvation.\nThe boundary objects in the zoomed Map captured in Figure 3.6 request a \nresource synchronously. When the remote model\u2019s representation is received, \nthe boundary objects grab the content of interest out of the representation and \ntranslate it, creating the appropriate Value Object instance. A Translation Map \nto turn the representation into a Value Object is shown in Figure 3.7. Here a \nUser in the Role of Moderator in the Identity and Access Context is trans-\nlated as a Moderator Value Object in the Collaboration Context.\nCollaboration Context\nIdentity and Access\nContext\nHTTPClient (Facade)\nCollaboratorService\nCollaboratorTranslator\nUserResource\n/tenants/(tenantId)/users/(username)/inRole/(role)\nUserRoleAdapter\nFigure 3.6 A zoom in on the Anticorruption Layer and Open Host Service of the \nintegration between the Collaboration Context and the Identity and Access Context\nwww.EBooksWorld.ir\n", "page": 145, "type": "text", "section": "Page 145"}
{"text": " \nWHY CONTEXT MAPS ARE SO ESSENTIAL\n103\nWhiteboard Time\nCreate a Translation Map of one of the interesting aspects of integration found \nin your project\u2019s Bounded Context.\nWhat if you find the translations overly complex, requiring a lot of data copying and \nsynchronization, making your translated object look a lot like the one from the other \nmodel? Perhaps you are using too much from the foreign Bounded Context, adopting \ntoo much from that model, and thus causing confusing conflict in your own model.\nUnfortunately, if the synchronous request fails because the remote system is \nunavailable, the entire local execution must fail. The user will be informed of \nthe problem and asked to try again later.\nSystems integrations commonly rely on RPC. At a high level RPC appears \nto be very much like a regular programming procedure call. Libraries and tools \nmake it attractive and easy to use. Unlike calling a procedure that resides in \nyour own process space, however, a remote call has a higher potential for per-\nformance-degrading latency or outright failure. Network and remote system \nload can delay RPC completion. When the RPC target system is unavailable, a \nuser\u2019s request to your system will not complete successfully.\nWhile REST-based resource usage isn\u2019t really RPC, it still has similar char-\nacteristics. Although complete system failure is relatively rare, this is a poten-\ntially annoying limitation. The team looks forward to improving on this \nsituation as soon as possible.\nModerator\nemailAddress\nidentity\nname\nHTTP/1.1 200 OK\nContent-Type: application/wnd.saadovation.idovation+xml\n. . .\n<userInRole>\n  <tenantId>CCA701C2-6409-41B9-B4DA-DB785107C8C8</tenantId>\n  <usermane>jdoe</usermane>\n  <firstname>John</firstname>\n  <lastname>Doe</lastname>\n  <emailAddress>John.Doe@domainmethod.org</emailAddress>\n  <role>Moderator</role>\n</userInRole>\nFigure 3.7 A logical Translation Map that shows how a representational state (XML \nin this case) is mapped to a Value Object in the local model.\nwww.EBooksWorld.ir\n", "page": 146, "type": "text", "section": "Page 146"}
{"text": "Chapter 3 CONTEXT MAPS\n104\nAgile Project Management Context\nSince the Agile Project Management Context is the new Core Domain, let\u2019s \npay particularly close attention to it. Let\u2019s zoom in on it and its connections to \nother models.\nTo achieve a greater degree of autonomy than RPC affords, the Agile Proj-\nect Management Context team will need to carefully constrain its use. Out-of-\nband, or asynchronous, event processing is therefore strategically favored.\nA greater degree of autonomy can be achieved when dependent state is \nalready in place in our local system. Some may think of this as a cache of whole \ndependent objects, but that\u2019s not usually the case when using DDD. Instead \nwe create local domain objects translated from the foreign model, maintaining \nonly the minimal amount of state needed by the local model. To get the state in \nthe first place we may need to make limited, well-placed RPC calls, or similar \nrequests for REST-based resources. But any necessary synchronization with \nremote model changes can often best be achieved through message-oriented \nnotifications published by remote systems. The notifications might be sent on a \nservice bus or a message queue, or be published via REST.\nThink Minimalistic\nThe synchronized state is the limited, minimal attributes of the remote models that \nare needed by the local model. It\u2019s not only to limit our need to synchronize data, it\u2019s \nalso a matter of modeling concepts properly.\nIt pays to limit our use of remote state, even when considering the design \nof the local modeling elements themselves. We don\u2019t want, for example, a \nProductOwner and a TeamMember to in reality reflect a UserOwner and \na UserMember because they take on so many characteristics of the remote \nUser object that a hybridization happens unwittingly.\nIntegration with the Identity and Access Context\nLooking at the zoomed Map in Figure 3.8, we see that the resource URIs pro-\nvide notifications about significant Domain Events that have occurred in the \nIdentity and Access Context. These are made available through the Notifi-\ncationResource provider, which publishes a RESTful resource. Notification \nresources are groups of published Domain Events. Every Event ever published \nis always available for consumption in order of occurrence, but each client is \nresponsible for preventing duplicate consumption.\nA custom media type indicates that two resources can be requested:\napplication/vnd.saasovation.idovation+json\n//iam/notifications\n//iam/notifications/{notificationId}\nwww.EBooksWorld.ir\n", "page": 147, "type": "text", "section": "Page 147"}
{"text": " \nWHY CONTEXT MAPS ARE SO ESSENTIAL\n105\nThe first resource URI enables clients to get (literally HTTP GET) the current \nnotification log (a fixed set of individual notifications). Per the documented \ncustom media type,\napplication/vnd.saasovation.idovation+json\nthe URI is considered minted and stable because it never changes. No matter \nwhat the current notification log consists of, this URI provides it. The current \nlog is a set of the most recent events that have occurred in the Identity and \nAccess model. The second resource URI enables clients to get and navigate a \nchain of all previous event-based notifications that have been archived. Why \ndo we need a current log and any number of distinct archived notification logs? \nSee Domain Events (8) and Integrating Bounded Contexts (13) for details on \nhow feed-based notifications work.\nActually at this point the ProjectOvation team is not committed to using \nREST in all cases. For example, they are currently negotiating with the Col-\nlabOvation team over whether to use a messaging infrastructure instead. \nAgile Project Management\nContext\nIdentity and Access\nContext\nHTTPClient (Facade)\nMemberTranslator\nNotificationResource\nIdentityAccessNotificationsAdapter\n/tenants/notifications\n/tenants/notifications/(notificationId)\nMemberService\nmaintainMembers()\nFigure 3.8 A zoom in on the Anticorruption Layer and Open Host Service of the \nintegration between the Agile Project Management Context and the Identity and \nAccess Context\nwww.EBooksWorld.ir\n", "page": 148, "type": "text", "section": "Page 148"}
{"text": "Chapter 3 CONTEXT MAPS\n106\nUnder consideration is the use of RabbitMQ. Nonetheless, at this time their \nintegrations with the Identity and Access Context will be REST-based.\nFor now let\u2019s leave most of the technology details out of the picture and \nconsider the role of each of the objects interacting in the zoomed Map. Here\u2019s \nan explanation of the integration steps visually demonstrated in the sequence \ndiagram found in Figure 3.9:\n\u2022 MemberService is a Domain Service that is responsible for providing \nProductOwner and TeamMember objects to its local model. It is the \ninterface of the basic Anticorruption Layer. Specifically, maintain-\nMembers() is used periodically to check for new notifications from the \nIdentity and Access Context. This method is not invoked by normal clients \nof the model. When a recurring timer interval fires, the notified component \nuses the MemberService by invoking method maintain \nMembers().\nFigure 3.9 shows the timer recipient as  \nMemberSynchronizer, which \ndelegates to MemberService.\n\u2022 The MemberService delegates to IdentityAccessNotification-\nAdapter, which plays the role of the Adapter between the Domain Service \nand the remote system\u2019s Open Host Service. The Adapter acts as a client \nto the remote system. The interaction with the remote Notification-\nResource is not shown.\n\u2022 Once the Adapter has received the response from the remote Open Host \nService, it delegates to the MemberTranslator to translate the Published \nLanguage media into concepts of the local system. If the local  \nMember\ninstance already exists, the translation updates the existing domain \nobject. This is indicated by the MemberService self-delegation to its \ninternal updateMember(). The Member subclasses are  \nProductOwner\nand TeamMember, which reflect the local contextual concepts.\nMemberSynchronizer\nmaintainMembers()\nsynchronizeMembers()\nupdateMember()\ntoMember()\nGET\nMemberTranslator\nHTTPClient\nMemberService\nIdentityAccessNotificationAdapter\nFigure 3.9 A view of the inner workings of the Agile Project Management Context and \nIdentity and Access Anticorruption Layer\nwww.EBooksWorld.ir\n", "page": 149, "type": "text", "section": "Page 149"}
{"text": " \nWHY CONTEXT MAPS ARE SO ESSENTIAL\n107\nWe should not focus on the technologies or integration products involved. \nRather, by cleanly separating Bounded Contexts, we are able to keep each \nContext pure, while applying data from other Contexts to express concepts in \nour own.\nThe diagrams and supporting text exemplify how we might create Context \nMap documents. It need not be extensive but should provide enough back-\nground and explanation to bring a new project member up to speed. However, \ncreate a document only if it is helpful to the team.\nIntegration with the Collaboration Context\nNext, let\u2019s consider how the \nAgile Project Management Context interacts with the Collaboration Context.\nHere, too, we strive for autonomy, but this raises the bar, posing some interest-\ning challenges to accomplish the goal of system independence.\nProjectOvation has add-on features that are supplied by CollabOvation. \nSome include project-based forum discussions and shared calendar scheduling. \nUsers won\u2019t directly interact with CollabOvation. ProjectOvation must deter-\nmine whether the options are available to a given tenant and, if so, on its own \nfacilitate resource creation in CollabOvation.\nConsider a section of this Create a Product use case:\nPrecondition: The collaboration feature is enabled (option was purchased).\n \n 1. The user provides Product descriptive information.\n \n 2. The user indicates a desire for a team discussion.\n \n 3. The user requests that the defined Product be created.\n \n 4. The system creates the Product with a Forum and Discussion.\nA Forum and a Discussion must be created in the Collaboration Context\non behalf of the Product. In contrast, this is unlike the Identity and Access \nContext where a tenant has already been provisioned and users, groups, and \nroles have been defined, and notifications about those events are available. In \nthat case the objects are preexisting. In this case the Agile Project Manage-\nment Context needs objects that don\u2019t exist yet and won\u2019t exist until it requests \nthem. That\u2019s a potential obstacle to autonomy because we depend on the avail-\nability of the Collaboration Context in order to create resources remotely. \nWith desired autonomy, this raises an interesting challenge.\nWhy Is Discussion Used in Both Contexts?\nThis is an interesting situation because it\u2019s one where the name of the concept, Dis-\ncussion, is the same in both Bounded Contexts, but they are different types, differ-\nent objects, and thus have different state and different behavior.\nwww.EBooksWorld.ir\n", "page": 150, "type": "text", "section": "Page 150"}
{"text": "Chapter 3 CONTEXT MAPS\n108\nIn the Collaboration Context a Discussion is an Aggregate and it manages a set \nof Posts\u2014implicit children that are themselves Aggregates. In the Agile PM Context\nthe Discussion is a Value Object and only holds a reference to the actual Discussion \nwith Posts in the foreign Context. Note, however, that in Chapter 13 when the team \nimplements the integrations, they discover that they should strongly type the differ-\nent kinds of Discussions in the Agile PM Context.\nWe need to leverage eventual consistency using Domain Events (8) and \nan Event-Driven Architecture (4). There\u2019s nothing that says that only remote \nsystems can consume notifications produced by our local system. When a \nProductInitiated Domain Event is published by our model, it is handled \nby our own system. The local handler requests the Forum and Discussion to \nbe created remotely. This could be done via RPC or messaging, depending on \nwhat CollabOvation supports. If using RPC and the remote collaboration sys-\ntem were not available at that time, the local handler would simply keep trying \non a periodic basis until it finally met with success. If messaging is supported \ninstead of RPC, the local handler would send a message to the collaboration \nsystem. In turn, collaboration would respond with its own message when \nresource creation completes. When the Event handler back in ProjectOvation \nreceived this notification, it would update the Product with an identity refer-\nence to its newly created discussion.\nWhat happens if the product owner or team members try to use the discus-\nsion prior to its existence? Is the unavailable discussion considered a bug in the \nmodel? Will it cause the system to exhibit an unreliable condition? Consider \nthe fact that any given subscriber may not have paid to use the collaboration \nadd-on in the first place. That\u2019s a nontechnical reason to design in resource \nunavailability. Working around eventual consistency is in no way a kludge. It\u2019s \njust another valid state that should be modeled.\nAn elegant way to handle all of the possible unavailability scenarios is \nto make them explicit. Consider this Standard Type implemented as a State\n[Gamma et al.], as described in Value Objects (6):\npublic enum DiscussionAvailability {\n    ADD_ON_NOT_ENABLED, NOT_REQUESTED, REQUESTED, READY;\n}\npublic final class Discussion implements Serializable {\n    private DiscussionAvailability availability;\n    private DiscussionDescriptor descriptor;\n    ...\n}\npublic class Product extends Entity {\n    ...\nwww.EBooksWorld.ir\n", "page": 151, "type": "text", "section": "Page 151"}
{"text": " \nWHY CONTEXT MAPS ARE SO ESSENTIAL\n109\n     private Discussion discussion;\n    ...\n}\nUsing this design, a Discussion Value Object is protected from misuse \nbecause the State defined by DiscussionAvailability protects it. When \nsomeone attempts to participate in a discussion about the Product, it can \nsafely hand off its discussion State. If not READY, the participant will be \nshown one of three messages:\nTo use team collaboration you need to purchase the add-on option.\nThe product owner didn\u2019t request the creation of a product discussion.\nThe discussion setup has not yet completed; check back soon.\nIf the Discussion availability is READY, we allow full team member \nparticipation.\nInterestingly, as implied by the first of the unavailable state messages, the \npossibility exists that the business chooses to make collaboration options \nselectable even though they have not yet been purchased. Leaving collabora-\ntion UI options enabled could be an effective marketing tickler to encourage \nfollow-on purchase. Who better to nag management to purchase an add-on \noption than those who are daily reminded that they could be using it, but can-\nnot? Clearly, technical benefits are not the only ones realized by the use of the \navailability State.\nAt this time the team isn\u2019t certain what its actual integration with collabo-\nration will be. For the sake of Customer-Supplier discussions, they\u2019ve produced \nthe diagram in Figure 3.10. The Agile Project Management Context may use \na second Anticorruption Layer to manage integration between itself and the \nCollaboration Context. It would be like the one it uses for the Identity and \nAccess Context. The diagram shows the primary boundary objects, which are \nsimilar to their counterparts used for identity and access management integra-\ntion. Actually there is not one single CollaborationAdapter. It is just a \nplaceholder for the several needed, but unknown at this time.\nShown inside the local Context are DiscussionService and Schedul-\ningService. These represent the Domain Services that could be used to man-\nage discussions and calendar entries in the collaboration system. The actual \nmechanisms will be determined by Customer-Supplier negotiations between \nthe teams, which are implemented in Integrating Bounded Contexts (13).\nThe team can understand part of their model now. What happens, for \nexample, when a discussion has been created and the result is communicated \nwww.EBooksWorld.ir\n", "page": 152, "type": "text", "section": "Page 152"}
{"text": "Chapter 3 CONTEXT MAPS\n110\nCollaboration Context\nHTTPClient (Facade)\nForumResource\nCalendarResource\nDiscussionTranslator\nDiscussionService\nSchedulingTranslator\nSchedulingService\nCollaborationAdapter\nAgile Project Management\nContext\nFigure 3.10 A zoom in on an Anticorruption Layer and Open Host Service of the \npossible integration components between Agile Project Management Context and \nCollaboration Context\nto the local Context? The asynchronous component\u2014either RPC client or \nmessage handler\u2014tells the Product to attachDiscussion(), passing it a \nnew  \nDiscussion Value instance. All local Aggregates with pending remote \nresource interests will be cared for in this fashion.\nThis examination has gone into some useful detail on Context Maps. We \nneed to exercise restraint, however, as we can quickly reach the point of dimin-\nishing returns. Perhaps we could have included Modules (9), but those have \nbeen placed in their own dedicated chapter. Include any relevant, high-level \nelements that will lead to vital team communication. On the other hand, push \nback when detail seems ceremonious.\nProduce Context Maps that you can post on the wall. You can upload them \nto a team wiki as long as it\u2019s not just the project\u2019s attic where nobody ever goes. \nKeep discussions about the project flowing back to your Map to stimulate use-\nful refinements.\nwww.EBooksWorld.ir\n", "page": 153, "type": "text", "section": "Page 153"}
{"text": " \nWRAP-UP\n111\nWrap-Up\nThat was definitely a productive session with Context Mapping.\n\u2022 We\u2019ve discussed what Context Maps are, what help they provide to your \nteam, and how you can create them with ease.\n\u2022 You took a detailed look into SaaSOvation\u2019s three Bounded Contexts and \ntheir supporting Context Maps.\n\u2022 Using mapping, you zoomed in on the integrations between each of the \nContexts.\n\u2022 You examined the boundary objects supporting Anticorruption Layer and \ntheir interactions.\n\u2022 You saw how to produce a Translation Map showing the local mapping \nbetween REST-based resources and the corresponding object in the con-\nsuming domain model.\nNot every project will need the level of detail demonstrated here. Others \nmay require more. The trick is to balance the need to understand with practi-\ncality and not pile too much detail into this level. Remember that we are likely \nnot going to keep a very detailed graphical Map up-to-date far into the project. \nWe\u2019ll benefit most from what can be posted on a wall, enabling team mem-\nbers to point at them during discussions. If we reject ceremony and embrace \nsimplicity and agility, we\u2019ll produce useful Context Maps that help us move \nforward rather than bog down the project.\nwww.EBooksWorld.ir\n", "page": 154, "type": "text", "section": "Page 154"}
{"text": "This page intentionally left blank \nwww.EBooksWorld.ir\n", "page": 155, "type": "text", "section": "Page 155"}
{"text": "113\nChapter 4\nArchitecture\nArchitecture should speak of its time and place, \nbut yearn for timelessness.\n\u2014Frank Gehry\nOne of the big advantages of DDD is that it doesn\u2019t require the use of any spe-\ncific architecture. Since our carefully crafted Core Domain (2) resides at the \nheart of a Bounded Context (2), it enables one or more architectural influences \nto play a role in the entire application or system.1 Some architectural influ-\nences surround the domain model and have a broad overall effect, while others \naddress specific demands. The goal is to use just the right choices and combi-\nnations of architecture and architecture patterns.\nThe real demands for specific software qualities should drive the use of \narchitectural styles and patterns. The ones chosen must be proven to meet \nor exceed required qualities. Avoiding architectural style and pattern over-\nuse is just as important as using the right ones. Allowing real, genuine qual-\nity demands to drive what we do with architecture is a beneficial risk-driven \napproach [Fairbanks]. That way we use architecture only to mitigate the risk \nof failure, not to increase our risk of failure by using an architectural style or \npattern that cannot be justified. Thus, we must be able to justify every archi-\ntectural influence in use, or we eliminate it from our system.\nOur ability to justify the selection of any architectural styles and patterns \nis limited to the available functional requirements, such as use cases or user \nstories, and even scenarios specific to the domain model. In other words, you \ncannot determine the necessary software qualities without functional require-\nments. Lacking these kinds of inputs, we actually cannot make sound archi-\ntectural choices, which implies that employing a use-case-driven architecture \napproach to software development is still applicable today.\n 1. This chapter is about architectural styles, application architectures, and architec-\nture patterns. A style describes how to implement a specific architecture, while an \narchitecture pattern explains how to address a specific concern within an archi-\ntecture but is broader than a design pattern. I suggest you not get too hung up on \nthe differences, but just understand that DDD can reside at the heart of a lot of \nsurrounding architectural influences.\nwww.EBooksWorld.ir\n", "page": 156, "type": "text", "section": "Page 156"}
{"text": "Chapter 4 ARCHITECTURE\n114\nRoad Map to This Chapter\n\u2022 Listen in on a retrospective interview with SaaSOvation\u2019s CIO.\n\u2022 Learn how the trusty Layers Architecture has been improved on by DIP and \nHexagonal.\n\u2022 See how Hexagonal can support Service-Oriented and REST.\n\u2022 Gain perspective on Data Fabric or Grid-Based Distributed Cache and \nEvent-Driven styles.\n\u2022 Consider how a newer architecture pattern called CQRS helps with DDD.\n\u2022 Learn from the architectures employed by the SaaSOvation teams.\nArchitecture Isn\u2019t a Coolness Factor\nThe following architectural styles and patterns are not a grab bag of cool tools we \nshould apply everywhere possible. Instead, use them only where applicable, where \nthey mitigate a specific risk that would otherwise increase the potential for project \nor system failure.\n[Evans] focused on the Layers Architec-\nture. That being so, SaaSOvation first \nconcluded that DDD could only be effec-\ntive using that well-known pattern. It took \nthe teams some time to understand that \nDDD is considerably more adaptable \nthan that, even though Layers was most \npopular at the time [Evans] was written.\nThe principles of a Layers Architecture can still be used to govern good \ndecision making. We don\u2019t need to stop there, however, as we\u2019ll consider some \nof the more modern architectures and patterns that can be leveraged where \nneeded. This will prove the versatility and broad applicability of DDD.\nFor sure, SaaSOvation did not need every architectural influence all at once, \nbut its teams needed to choose wisely from the options available to them.\nInterviewing the Successful CIO\nTo give a bit of a perspective on why each of the architectural influences dis-\ncussed in the chapter might be used, we\u2019re going to leap a decade into the \nfuture and talk to SaaSOvation\u2019s CIO. While the company\u2019s beginnings were \nwww.EBooksWorld.ir\n", "page": 157, "type": "text", "section": "Page 157"}
{"text": " \nINTERVIEWING THE SUCCESSFUL CIO\n115\nhumble, architectural decision helped it succeed each step of the way. Let\u2019s \ntune in to the program TechMoney, with Anchor Maria Finance-Ilmundo . . .\nMaria: Tonight, my exclusive interview is with Mitchell Williams, CIO of \nthe enormously successful SaaSOvation. We\u2019re continuing our \u201cKnow Your \nArchitectural $tyles\u201d series. Tonight\u2019s focus is on how selecting the right \narchitecture can bring enduring success. Welcome to the show, Mitchell, \nand thanks for joining us.\nMitchell: I\u2019m glad to be here again, Maria. It\u2019s always a pleasure.\nMaria: Can you take us through some of the early architectural decisions \nyou went with, and why?\nMitchell: Of course. Believe it or not, we actually started off planning our \nprojects around desktop deployment. Our team designed for the desktop \napplication to persist to a central database. They chose the Layers Architec-\nture for this approach.\nMaria: Did that make sense?\nMitchell: Well, we believe it did, especially since we were only dealing with \na single application tier plus the central database. It would have served us \nwell for a simple client-server style.\nMaria: But the tables soon turned, didn\u2019t they?\nMitchell: They certainly did. We actually joined forces with a business \npartner and decided to move forward with an SaaS subscription model. \nWe sought some significant funding to support our efforts and landed it. \nWe determined that our agile project management application would go \non the back burner for a while until we first developed a suite of collabo-\nration tools. This had a twofold benefit. First, we\u2019d enter the accelerating \ncollaboration market, but then we\u2019d also have a natural feature add-on for \nthe project management application. You know, collaborating on software \ndevelopment project deliverables.\nMaria: Interesting. It all sounds quite grassroots. Where did these decisions \nlead you?\nMitchell: As the software complexity increased, we needed to manage qual-\nity by introducing unit and feature testing tools. To do that, we kind of \nturned Layers on its ear by introducing the Dependency Inversion Principle, \nor DIP. It was important since the team could easily test by stubbing out the \nUI and Infrastructure Layers and concentrate on testing the Application and \nwww.EBooksWorld.ir\n", "page": 158, "type": "text", "section": "Page 158"}
{"text": "Chapter 4 ARCHITECTURE\n116\nDomain. In fact, we could develop the UI in isolation and delay decisions on \npersistence technology for some time. And it actually wasn\u2019t a big leap away \nfrom Layers. The team had a high comfort level.\nMaria: Wow, swapping out the UI and persistence! That seems risky. How \ntough was it?\nMitchell: Well, actually not so much. As it turns out, the fact that we were \nusing the Domain-Driven Design tactical patterns didn\u2019t hurt us at all. Since \nwe used the Aggregate pattern and Repositories, we could develop against \nin-memory persistence behind the Repository interfaces and swap in a per-\nsistence mechanism after we had time to consider our options.\nMaria: Dude.\nMitchell: Totally.\nMaria: And?\nMitchell: Bang. Things were off and running. We delivered CollabOvation \nand ProjectOvation, with successive profitable quarters.\nMaria: Ka-ching.\nMitchell: Got that right. We then decided that we wanted to support mobile \ndevices in addition to desktop browsers since mobile exploded and it got \nall over us. For that we\u2019d use REST. Subscribers started asking for things \nlike federated identity and security, as well as sophisticated project and time \nresource management tools. And then new investors wanted to see reports \non their preferred business intelligence dash.\nMaria: Amazing. So mobile wasn\u2019t the only thing exploding. Let me get \nyour take on dealing with all that.\nMitchell: The team decided that migrating to a Hexagonal Architecture \nwas an appropriate choice to handle all these additions. They found that \nthe Ports and Adapters approach gave them the ability to add new kinds of \nclients almost ad hoc. The same went for new output Port types, like inno-\nvative new persistence mechanisms, such as NoSQL, and messaging capa-\nbilities. And that all spelled c-l-o-u-d.\nMaria: So you had confidence in those modifications?\nMitchell: Absolutely.\nMaria: Huge. If you don\u2019t buckle under all that, it probably means you made \ngreat choices that leveraged your ability to go even further.\nwww.EBooksWorld.ir\n", "page": 159, "type": "text", "section": "Page 159"}
{"text": " \nINTERVIEWING THE SUCCESSFUL CIO\n117\nMitchell: Exactly. By now we were adding new tenants by many hundreds \nevery month. We actually added a service to migrate existing data from leg-\nacy corporate collaboration tools into our cloud. The team decided that an \nSOA focus allowed them to aggregate this data nicely using Mule\u2019s Collec-\ntion Aggregator. It could sit on the service boundary while still using the \nHexagonal Architecture.\nMaria: Ah, so you didn\u2019t introduce SOA because it sounded cool. You used \nit when it made sense. Perfect. We haven\u2019t seen good decision making like \nthat throughout the industry.\nMitchell: Yes, Maria, and that\u2019s really the approach we took all along. It \nwas our blueprint for success. For example, in time we added TrackOvation, \nour defect tracking software, which integrated with ProjectOvation. And as \nProjectOvation features grew, the UI became more and more sophisticated. \nThe Product Owner\u2019s dashboard of all Scrum products and defects in their \nsystems updated with each application command and corresponding event. \nSince Product Owners across subscribing tenants had different preferred \nviews, it made the dashboards even more complex. And, naturally, we also \nhad to support the mobile devices. The team considered the merits of includ-\ning a CQRS architecture pattern.\nMaria: CQRS? Come on, Mitch, that\u2019s pretty heady. Was that one of those \nuncertainties that we don\u2019t know how it plays out? What about walking off \nthe plank there?\nMitchell: No, not really. Once the team had a valid reason to use CQRS \nto ease the friction between the command and query universes, it was full \nsteam ahead, and they never looked back.\nMaria: Exactly. Wasn\u2019t that about the time that your subscribers starting \nasking for features that required distributed processing?\nMitchell: Yes; if we didn\u2019t get this one right we\u2019d soon be drowning in \ncomplexity. Some features required running through a series of distributed \nprocesses before delivering an answer. The ProjectOvation team would not \nmake the user wait for these potentially long-running tasks and risk time-\nouts. They introduced a fully Event-Driven Architecture, employing a clas-\nsic Pipes and Filters pattern to manage these.\nMaria: But that wasn\u2019t the end of your journey down Complexity Lane, was \nit? How tough was that?\nMitchell: LOL. No, no. Never would that happen, it seemed. However, \nwhen you have a smart team, it makes Complexity Lane like a stroll in the \nwww.EBooksWorld.ir\n", "page": 160, "type": "text", "section": "Page 160"}
{"text": "Chapter 4 ARCHITECTURE\n118\npark. In actuality, the Event-Driven Architecture simplified many areas of \nthe expanding suite of systems.\nMaria: True, that. Go on. That was an obvious opportunity. We\u2019re getting \nto my favorite part of the story. You know . . . [eyes twinkle $$$]\nMitchell: Our architecture allowed us to scale so rapidly and manage change \nso well that RoaringCloud acquired SaaSOvation for, well . . . that\u2019s all a \nmatter of public record.\nMaria: I\u2019d say, and very public. At $50 per common share that was around \n$3 billion worth of public record.\nMitchell: Good memory for financial facts! And that was serious incentive \nto get the integration right. They brought a vast number of new subscribers, \nand the user base actually started to stress the ProjectOvation infrastruc-\nture. It was now time to distribute and parallelize the Pipes and Filters. That \ncalled for adding in long-running processes, sometimes called Sagas.\nMaria: Nice. Can you categorically say that that was fun?\nMitchell: Fun indeed, but necessary even more so.\nMaria: And it seems that the fun would never end. Probably one of the least \nexpected and even shocking chapters in your long success story came next.\nMitchell: You know it. Now that RoaringCloud had a monopoly in the \nmarketplace due to the plethora of subscription applications and millions of \nusers, the government took notice and began regulating the industry. A new \nlaw was passed to require RoaringCloud to track every change to a project. \nActually, the best way to handle this compliance situation as a natural part \nof the domain model was to use Event Sourcing.\nMaria: Man, you were poised. That\u2019s crazy. I mean, really, really crazy.\nMitchell: That\u2019s a crazy good problem to have, really.\nMaria: What\u2019s so amazing to me is that through all these years, the core of \nyour applications was based on DDD software models. Yet, obviously DDD \ndidn\u2019t hurt you. You seemed to not experience hardships because of it.\nMitchell: In fact it was quite the opposite. We firmly believe that it was \nbecause we chose DDD early, and took the time to understand it thoroughly, \nthat the business situations we could not escape\u2014and didn\u2019t want to\u2014were \nhandled in stride.\nwww.EBooksWorld.ir\n", "page": 161, "type": "text", "section": "Page 161"}
{"text": " \nLAYERS\n119\nMaria: Well, as I like to say, \u201cKa-ching!\u201d Thanks again, Mitchell. We\u2019ve \nlearned how selecting the right architecture can bring enduring success, \nright here on \u201cKnow Your Architectural $tyles.\u201d\nMitchell: My pleasure, Maria. Thanks for inviting me.\nThat was a bit quirky, but helpful. It demonstrates how the architectural \ninfluences discussed in the following sections can be used with DDD, and how \nto introduce each at just the right time.\nLayers\nThe Layers Architecture [Buschmann et al.] pattern is considered by many to \nbe the granddaddy of all. It supports N-tier systems and is, thus, commonly \nused in Web, enterprise, and desktop applications. Here we rigorously separate \nthe various concerns of our application or system into well-defined layers.\nIsolate the expression of the domain model and the business logic, and eliminate \nany dependency on infrastructure, user interface, or even application logic that \nis not business logic. Partition a complex program into layers. Develop a design \nwithin each layer that is cohesive and that depends only on the layers below. \n[Evans, Ref, p. 16]\nFigure 4.1 shows the layers common to a DDD application that uses a tradi-\ntional Layers Architecture. Here the isolated Core Domain resides in one layer \nUser Interface Layer\nApplication Layer\nDomain Layer\nInfrastructure Layer\nFigure 4.1 The traditional Layers Architecture in which DDD is applied\nwww.EBooksWorld.ir\n", "page": 162, "type": "text", "section": "Page 162"}
{"text": "Chapter 4 ARCHITECTURE\n120\nin the architecture. Above it are the User Interface and Application Layers.\nBelow it is the Infrastructure Layer.\nAn essential rule of this architecture is that each layer may couple only to \nitself and below. There are distinctions within the style. A Strict Layers Archi-\ntecture is one that allows coupling only to the layer directly below. A Relaxed \nLayers Architecture, however, allows any higher-level layer to couple to any \nlayer below it. Since both the User Interface and the Application Services often \nneed to employ infrastructure, many, if not most, systems are based on Relaxed \nLayers.\nLower layers may actually loosely couple to higher layers, but this is only by \nmeans of a mechanism such as Observer or Mediator [Gamma et al.]; there is \nnever a direct reference from lower to higher. Using Mediator, for example, the \nhigher layer would implement an interface defined by the lower layer, then pass \nthe implementing object as an argument to the lower layer. The lower layer uses \nthe implementing object with no knowledge of where it resides architecturally.\nThe User Interface is to contain only code that addresses user view and \nrequest concerns. It must not contain domain/business logic. Some may con-\nclude that since validation is required by the User Interface, it must contain \nbusiness logic. The kinds of validation found in the User Interface are not the \nkinds that belong in the domain model (only). As discussed in Entities (5), we \nstill want to limit coarse-grained validations that express deep business knowl-\nedge only to the model.\nIf the User Interface components use objects from the domain model, it is \ngenerally limited to rendering its data on the glass. If using this approach, a \nPresentation Model (14) can be used to prevent the view itself from knowing \nabout domain objects.\nSince a user may be either a human or other systems, sometimes this layer \nwill provide the means to remotely invoke the services of an API in the form of \nan Open Host Service (13).\nComponents in the User Interface are direct clients of the Application Layer.\nApplication Services (14) reside in the Application Layer. These are dif-\nferent from Domain Services (7) and are thus devoid of domain logic. They \nmay control persistence transactions and security. They may also be in charge \nof sending Event-based notifications to other systems and/or for composing \ne-mail messages to be sent to users. The Application Services in this layer are \nthe direct clients of the domain model, though themselves possessing no busi-\nness logic. They remain very lightweight, coordinating operations performed \nagainst domain objects, such as Aggregates (10). They are the primary means \nof expressing use cases or user stories on the model. Hence, a common func-\ntion of an Application Service is to accept parameters from the User Interface, \nwww.EBooksWorld.ir\n", "page": 163, "type": "text", "section": "Page 163"}
{"text": " \nLAYERS\n121\nuse a Repository (12) to obtain an Aggregate instance, and then execute some \ncommand operation on it:\n@Transactional\npublic void commitBacklogItemToSprint(\n    String aTenantId, String aBacklogItemId, String aSprintId) {\n    TenantId tenantId = new TenantId(aTenantId);\n    BacklogItem backlogItem =\n        backlogItemRepository.backlogItemOfId(\n                tenantId, new BacklogItemId(aBacklogItemId));\n    Sprint sprint = sprintRepository.sprintOfId(\n                tenantId, new SprintId(aSprintId));\n    backlogItem.commitTo(sprint);\n}\nIf our Application Services become much more complex than this, it is prob-\nably an indication that domain logic is leaking into the Application Services, \nand that the model is becoming anemic. So it\u2019s a best practice to keep these \nmodel clients very thin. When a new Aggregate must be created, an Applica-\ntion Service would use a Factory (11) or the Aggregate\u2019s constructor to instan-\ntiate it and then use the corresponding Repository to persist it. An Application \nService may also use a Domain Service to fulfill some domain-specific task \ndesigned as a stateless operation.\nWhen the domain model is designed to publish Domain Events (8), the \nApplication Layer may register subscribers to any number of Events. Doing so \nenables the Events to be stored, forwarded, and otherwise dealt with as one \nof the application\u2019s duties. This frees the domain model to be aware of only \nits own core concerns and enables the Domain Event Publisher (8) to remain \nlightweight and liberated from messaging infrastructure dependencies.\nSince the domain model possessing all business logic is discussed at great \nlength in the other chapters, it is not repeated here. Nonetheless, there are \nsome challenges associated with the domain and the use of traditional Lay-\ners. Using Layers may require the Domain Layer to make some limited use of \nInfrastructure. I\u2019m not saying that core domain objects would do this, as we \nshould absolutely avoid that altogether. However, adhering to the definition of \nLayers may require implementations of some interfaces in the Domain Layer \nthat depend on technologies provided by Infrastructure.\nFor example, Repository interfaces require implementations that use com-\nponents, such as persistence mechanisms, housed in Infrastructure. What if we \nwww.EBooksWorld.ir\n", "page": 164, "type": "text", "section": "Page 164"}
{"text": "Chapter 4 ARCHITECTURE\n122\njust implemented the Repository interfaces in Infrastructure? Since the Infra-\nstructure Layer is below the Domain Layer, the references from Infrastruc-\nture upward to Domain would violate the rules of Layers Architecture. Still, \navoiding that does not mean that the primary domain objects would couple to \nInfrastructure. To avoid that we might use implementation Modules (9) to hide \ntechnical classes:\ncom.saasovation.agilepm.domain.model.product.impl\nAs indicated in Modules (9), MongoProductRepository could be housed \nin that package. This is not the only way to address this challenge, however. \nWe might decide instead to implement such interfaces in the Application Layer, \nwhich would uphold the rules of Layers. Figure 4.2 provides a glimpse of this \napproach. But doing that may seem a bit distasteful.\nThere is a better way, as discussed in the section entitled \u201cDependency \nInversion Principle.\u201d\nIn a traditional Layers Architecture the Infrastructure is at the bottom. \nThings like persistence and messaging mechanisms reside there. Messages may \ninclude those sent by enterprise messaging middleware systems or more basic \ne-mails (SMTP) or text messages (SMS). Think of all the technical components \nand frameworks that provide low-level services for the application. Those are \nusually considered to be part of Infrastructure. The higher-level Layers couple \nto the lower-level components to reuse the technical facilities provided. That \nbeing the case, again we want to reject any notion of coupling core domain \nmodel objects to Infrastructure.\nUser Interface Layer\nApplication Layer\nImplements Domain Layer\ninterfaces\nDomain Layer\nFigure 4.2 The Application Layer could house some technical implementations of \ninterfaces defined by the Domain Layer.\nwww.EBooksWorld.ir\n", "page": 165, "type": "text", "section": "Page 165"}
{"text": " \nLAYERS\n123\nThe SaaSOvation teams noted that having the Infrastructure \nLayer at the bottom posed some disadvantages. For one it \nmade implementing technical aspects required by the Domain \nLayer kind of bitter-tasting since the rules of Layers had to be \nviolated. And actually their code was difficult to test. How could \nthey overcome this disadvantage?\nCould we whip up something a bit sweeter if we adjusted the order of \nLayers?\nDependency Inversion Principle\nThere is a way to improve on the traditional Layers Architecture by adjusting \nthe way dependencies work. The Dependency Inversion Principle (DIP) was \npostulated by Robert C. Martin and described in [Martin, DIP]. The formal \ndefinition states:\nHigh-level modules should not depend on low-level modules. Both should depend \non abstractions.\nAbstractions should not depend upon details. Details should depend upon \nabstractions.\nThe essence of this definition is communicating that a component that \nprovides low-level services (Infrastructure, for this discussion) should depend \non interfaces defined by high-level components (for this discussion, User \nInterface, Application, and Domain). While there are several ways to express \nan architecture that uses DIP, we could boil it down to the structure shown \nin Figure 4.3.\nDoes DIP Really Support All Those Layers?\nSome would conclude that DIP has only two layers, one at the top and one at the \nbottom. The one at the top would implement interface abstractions defined in the \nlayer at the bottom. Adjusting Figure 4.3 to fit this, the Infrastructure Layer would \nbe the one at the top, and the User Interface Layer, Application Layer, and Domain \nLayer would constitute one at the bottom. You may or may not prefer this view of \na DIP architecture. Don\u2019t worry; the Hexagonal [Cockburn] or Ports and Adapters \nArchitecture is where this is all headed.\nwww.EBooksWorld.ir\n", "page": 166, "type": "text", "section": "Page 166"}
{"text": "Chapter 4 ARCHITECTURE\n124\nFrom the architecture of Figure 4.3, we would have a Repository imple-\nmented in Infrastructure for an interface defined in Domain:\npackage com.saasovation.agilepm.infrastructure.persistence;\nimport com.saasovation.agilepm.domain.model.product.*;\npublic class HibernateBacklogItemRepository\n    implements BacklogItemRepository  {\n    ...\n    @Override\n    @SuppressWarnings(\"unchecked\")\n    public Collection<BacklogItem> allBacklogItemsComittedTo(\n        Tenant aTenant, SprintId aSprintId) {\n        Query query =\n            this.session().createQuery(\n                \"from -BacklogItem as _obj_ \"\n                + \"where _obj_.tenant = ? and _obj_.sprintId = ?\");\n        query.setParameter(0, aTenant);\n        query.setParameter(1, aSprintId);\n        return (Collection<BacklogItem>) query.list();\n    }\n    ...\n}\nUser Interface Layer\nApplication Layer\nDomain Layer\nInfrastructure Layer\nFigure 4.3 The possible Layers when the Dependency Inversion Principle is used. We \nmove the Infrastructure Layer above all others, enabling it to implement interfaces for \nall Layers below.\nwww.EBooksWorld.ir\n", "page": 167, "type": "text", "section": "Page 167"}
{"text": " \nHEXAGONAL OR PORTS AND ADAPTERS\n125\nFocusing on the Domain Layer, using DIP enables both the Domain and \nInfrastructure to depend on abstractions (interfaces) defined by the domain \nmodel. Since the Application Layer is the direct client of the Domain, it \ndepends on Domain interfaces and indirectly accesses Repository and any \ntechnical Domain Service implementation classes provided by Infrastructure. \nIt may use any one of a few ways to acquire the implementations, including \nDependency Injection, Service Factory, and Plug In [Fowler, P of EAA]. The \nexamples throughout the book use Dependency Injection provided by Spring \nFramework and sometimes the Service Factory via class DomainRegistry.\nIn fact, DomainRegistry uses Spring to look up references to beans that \nimplement interfaces defined by the domain model, including Repositories and \nDomain Services.\nInterestingly enough, when we think about the influence that DIP has on \nthis architecture, we might conclude that there are actually no longer any \nlayers at all. Both high-level and low-level concerns are dependent only on \nabstractions, which seems to topple the stack. What if we actually thought of \nturning this architecture on its ear and adding a bit more symmetry? Let\u2019s next \nsee how that would work.\nHexagonal or Ports and Adapters\nWith the Hexagonal Architecture2 Alistair Cockburn codified a style to pro-\nduce symmetry [Cockburn]. It advances this goal by allowing many disparate \nclients to interact with the system on equal footing. Need a new client? Not a \nproblem. Just add an Adapter to transform any given client\u2019s input into that \nunderstood by the internal application\u2019s API. At the same time, output mech-\nanisms employed by the system, such as graphics, persistence, and messaging, \nmay also be diverse and swappable. That\u2019s possible because an Adapter is cre-\nated to transform application results into a form accepted by a specific output \nmechanism.\nAs we discuss it, you may agree that this architecture has potential for \ntimelessness.\n 2. We refer to this architecture by the name Hexagonal, even though its name seems \nto have changed to Ports and Adapters. Despite its changed name, the community \nstill refers to it as Hexagonal. The Onion Architecture has also surfaced. How-\never, it appears to many that Onion is just an (unfortunate) alternate name for \nHexagonal. We can safely assume that they are the same and stick with the [Cock-\nburn] definition.\nwww.EBooksWorld.ir\n", "page": 168, "type": "text", "section": "Page 168"}
{"text": "Chapter 4 ARCHITECTURE\n126\nThese days many teams that say they are using a Layers Architecture are \nactually using Hexagonal instead. This is due, in part, to the number of proj-\nects that now use some form of Dependency Injection. It\u2019s not that Dependency \nInjection is automatically Hexagonal. It\u2019s just that it encourages a way of pro-\nducing an architecture that leans naturally toward the development of a Ports \nand Adapters style. In any case, a more thorough understanding will clarify \nthis point.\nWe usually think of the place where clients interact with the system as its \n\u201cfront end.\u201d Likewise, we consider the place where the application retrieves \npersisted data, stores new persistent data, or sends output as its \u201cback end.\u201d \nBut Hexagonal promotes a different way of looking at the areas of a system, \nas indicated by Figure 4.4. There are two primary areas, the outside and the \ninside. The outside enables disparate clients to submit input and also provides \nmechanisms to retrieve persisted data, store the application\u2019s output (for exam-\nple, a database), or send it elsewhere along its way (for example, messaging).\nDomain Model\nApplication\nAdapter A\nAdapter B\nAdapter C\nAdapter D\nAdapter E\nAdapter F\nAdapter G\nMem\nC\nC\nC\nC\nAdapter H\nFigure 4.4 The Hexagonal Architecture is also known as Ports and Adapters. There \nare Adapters for each of the outside types. The outside reaches the inside through the \napplication\u2019s API.\nwww.EBooksWorld.ir\n", "page": 169, "type": "text", "section": "Page 169"}
{"text": " \nHEXAGONAL OR PORTS AND ADAPTERS\n127\nCowboy Logic \nAJ:  \n\u201cMy horses sure do like their new hexagonal corral. \nIt gives \u2019em more corners to run to when I\u2019m carryin\u2019 \na saddle.\u201d\nIn Figure 4.4 each client type has its own Adapter [Gamma et al.], which \ntransforms input protocols into input that is compatible with the application\u2019s \nAPI\u2014the inside. Each of the hexagon\u2019s sides represents a different kind of Port, \nfor either input or output. Three of the clients\u2019 requests arrive via the same \nkind of input Port (Adapters A, B, and C), and one uses a different kind of Port \n(Adapter D). Perhaps the three use HTTP (browser, REST, SOAP, and so on) \nand the one uses AMQP (for example, RabbitMQ). There is not a strict defini-\ntion of what a Port means, making it a flexible concept. In whatever way Ports \nare partitioned, client requests arrive and the respective Adapter transforms \ntheir input. It then invokes an operation on the application or sends the appli-\ncation an event. Control is thus transferred to the inside.\nWe Probably Are Not Implementing the Ports Ourselves\nWe actually normally don\u2019t implement the Ports ourselves. Think of a Port as HTTP \nand the Adapter as a Java Servlet or JAX-RS annotated class that receives method \ninvocations from a container (JEE) or framework (RESTEasy or Jersey). Or we \nmight create a message listener for NServiceBus or RabbitMQ. In that case the Port \nis more or less the messaging mechanism, and the Adapter is the message listener, \nbecause it is the responsibility of the message listener to grab data from the message \nand translate it into parameters suitable to pass into the Application\u2019s API (the client \nof the domain model).\nDesign the Application Inside per Functional Requirements\nWhen using Hexagonal, we design the application with our use cases in mind, not the \nnumber of supported clients. Any number and type of clients may request through \nvarious Ports, but each Adapter delegates to the application using the same API. \nThe application receives requests by way of its public API. The application \nboundary, or inner hexagon, is also the use case (or user story) boundary. \nIn other words, we should create use cases based on application functional \nrequirements, not on the number of diverse clients or output mechanisms. \nWhen the application receives a request via its API, it uses the domain model to \nfulfill all requests involving the execution of business logic. Thus, the applica-\ntion\u2019s API is published as a set of Application Services. Here again, Application \nServices are the direct client of the domain model, just as when using Layers.\nwww.EBooksWorld.ir\n", "page": 170, "type": "text", "section": "Page 170"}
{"text": "Chapter 4 ARCHITECTURE\n128\nThe following represents a RESTful resource published using JAX-RS. \nA request arrives through the HTTP input Port, and the handler acts as an \nAdapter, delegating to an Application Service:\n@Path(\"/tenants/{tenantId}/products\")\npublic class ProductResource extends Resource {\n    private ProductService productService;\n    ...\n    @GET\n    @Path(\"{productId}\")\n    @Produces({ \"application/vnd.saasovation.projectovation+xml\" })\n    public Product getProduct(\n            @PathParam(\"tenantId\") String aTenantId,\n            @PathParam(\"productId\") String aProductId,\n            @Context Request aRequest) {\n        Product product = productService.product(aTenantId, aProductId);\n        if (product == null) {\n            throw new WebApplicationException(\n                    Response.Status.NOT_FOUND);\n        }\n        return product; // serialized to XML using MessageBodyWriter\n    }\n    ...\n}\nThe various JAX-RS annotations provide a significant part of the Adapter, \nparsing the resource path and turning its parameters into String instances. \nThe ProductService instance is injected and used by this request to dele-\ngate to the application inside. The Product is serialized to XML and placed \nin a Response, which is then sent through the HTTP output Port.\nJAX-RS Isn\u2019t the Focus Here\nThis is just one way to use the application and domain model inside. In essence, \nJAX-RS is not important. We could instead use Restfulie, or create a Node.js server \nrunning the restify module. Further still, Adapters designed to handle input from \nother Ports would delegate to the same API, as you will see.\nWhat about the other side of the application, to the right? Consider Repos-\nitory implementations as persistence Adapters, providing access to previously \nstored Aggregate instances and storage for new ones. As depicted in the dia-\ngram (Adapters E, F, and G), we might have Repository implementations \nfor relational databases, document stores, distributed cache, and in-memory \nwww.EBooksWorld.ir\n", "page": 171, "type": "text", "section": "Page 171"}
{"text": " \nHEXAGONAL OR PORTS AND ADAPTERS\n129\nstores. If the application sends Domain Event messages to the outside, it would \nuse a different Adapter (H) for messaging. The output messaging Adapter is \nthe opposite of the input Adapter that supports AMQP and thus goes out a \ndifferent Port from the one used for persistence.\nA big advantage with Hexagonal is that Adapters are easily developed for \ntest purposes. The entire application and domain model can be designed and \ntested before clients and storage mechanisms exist. Tests could be created to \nexercise ProductService well before any decision is made to support HTTP/\nREST, SOAP, or messaging Ports. Any number of test clients can be developed \nbefore the user interface wireframes have been completed. Long before a per-\nsistence mechanism is selected for the project, in-memory Repositories can be \nemployed to mimic persistence for the sake of testing. See Repositories (12) for \ndetails on developing in-memory implementations. Significant progress can be \nmade on the core without the need for supplementary technical components.\nIf using true Layers, consider the advantages of toppling the structure and \ndeveloping based on Ports and Adapters instead. When designed properly, the \nhexagon inside\u2014the application and domain model\u2014will not leak to the out-\nside parts. This promotes a clean application boundary inside in which use \ncases are implemented. Outside any number of client Adapters can support \nnumerous automated tests and real-world clients, as well as storage, messag-\ning, and other output mechanisms.\nWhen the SaaSOvation teams considered the advan-\ntages of using the Hexagonal Architecture, they decided \nto make the switch from Layers. It wasn\u2019t difficult, actu-\nally. It just required adopting a slightly different mindset in \nusing the familiar Spring Framework.\nBecause the Hexagonal Architecture is versatile, it could well be the foun-\ndation that supports other architectures required by the system. For instance, \nwe might factor in Service-Oriented, REST, or an Event-Driven Architecture; \nemploy CQRS; use a Data Fabric or Grid-Based Distributed Cache; or tack \non Map-Reduce distributed and parallel processing, most of which are dis-\ncussed later in this chapter. The Hexagonal style forms the strong foundation \nwww.EBooksWorld.ir\n", "page": 172, "type": "text", "section": "Page 172"}
{"text": "Chapter 4 ARCHITECTURE\n130\nfor supporting any and all of those additional architectural options. There \nare other ways, but for the remainder of this chapter assume that Ports and \nAdapters is used to assist with developing around each of the remaining topics \ndiscussed.\nService-Oriented\nThe Service-Oriented Architecture, or SOA, has different meanings to differ-\nent people. This can make discussions about it somewhat challenging. It\u2019s best \nto try to find some common ground, or at least define the ground for this \ndiscussion. Consider some principles of SOA as defined by Thomas Erl [Erl]. \nBesides the fact that services are always interoperable, they also possess the \neight design principles presented in Table 4.1.\nTable 4.1  Design Principles of Services\nService Design Principle\nDescription\n1. Service Contract\nServices express their purpose and capabilities by \nmeans of a contract in one or more description \ndocuments.\n2. Service Loose Coupling\nServices minimize dependency and only have an \nawareness of each other.\n3. Service Abstraction\nServices publish only their contract and hide internal \nlogic from clients.\n4. Service Reusability\nServices can be reused by others in order to build \nmore coarse-grained services.\n5. Service Autonomy\nServices control their underlying environment and \nresources to remain independent, which allows them \nto remain consistent and reliable.\n6. Service Statelessness\nServices place the responsibility of state management \non consumers, where this does not conflict with \nwhat is controlled for Service Autonomy.\n7. Service Discoverability\nServices are described with metadata to allow dis-\ncovery and to make their Service Contract under-\nstood, allowing them to be (re)usable assets.\n8. Service Composability\nServices may be composed within more coarse-\ngrained services no matter the size and complexity of \nthe composition they fall within.\nwww.EBooksWorld.ir\n", "page": 173, "type": "text", "section": "Page 173"}
{"text": " \nSERVICE-ORIENTED\n131\nWe can combine these principles with a Hexagonal Architecture, with the \nservice boundary at the far left and the domain model at the heart. The basic \narchitecture is presented in Figure 4.5, where consumers reach services using \nREST, SOAP, and messaging. Note that one Hexagonal-based system supports \nmultiple technical service endpoints. This has a bearing on how DDD is used \nwithin an SOA.\nSince opinions vary widely on what SOA is and what value it provides, \nit wouldn\u2019t be surprising if you disagree with what\u2019s presented here. Mar-\ntin Fowler labels this situation \u201cservice-oriented ambiguity\u201d [Fowler, SOA]. \nTherefore, I won\u2019t make a valiant attempt to disambiguate SOA here. I will, \nhowever, provide a perspective on one way DDD fits into the set of priorities\ndeclared in the SOA Manifesto.3\n 3. The SOA Manifesto itself has received considerable negative criticism, but we may \nstill glean some value from it.\nDomain Model\nApplication\nREST\nAdapter\nSOAP\nAdapter\nMessaging\nAdapter\nMessaging\nAdapter\nAdapter E\nT-Services\nT-Services\nServices Registry\nT-Services\nAdapter F\nAdapter G\nMem\nC\nC\nC\nFigure 4.5 A Hexagonal Architecture supporting SOA, with REST, SOAP, and \nmessaging services\nwww.EBooksWorld.ir\n", "page": 174, "type": "text", "section": "Page 174"}
{"text": "Chapter 4 ARCHITECTURE\n132\nFirst, considering the pragmatic viewpoints expressed by one of the Mani-\nfesto contributors [Tilkov, Manifesto] gives an important context. Comment-\ning on the Manifesto, he brings us at least a step or two closer to understanding \nwhat SOA services can be:\n[The Manifesto] gives me the option to view a service as either a set of SOAP/\nWSDL interfaces or a collection of RESTful resources. . . . This is not [an] \nattempt at a definition\u2014it\u2019s an attempt to find out what values and principles we \ncould find that we all can agree on.\nStefan\u2019s comments are noteworthy. Finding agreement always helps, and we \ncan probably agree that a business service can be provided by any number of \ntechnical services.\nThe technical services could be RESTful resources, SOAP interfaces, or mes-\nsage types. The business service emphasizes business strategy, a way to bring \nbusiness and technology together. However, defining a single business service \ndoes not equate to defining a single Subdomain (2) or Bounded Context. No \ndoubt as we perform both problem space and solution space assessments, we \nwill find that a business service comprises a number of each. Thus, Figure 4.5 \nshows the architecture of only a single Bounded Context, one that may provide \na set of technical services realized through a number of RESTful resources, \nSOAP interfaces, or message types\u2014just a part of the overall business service. \nIn the SOA solutions space we would expect to see many Bounded Contexts, \nwhether any individual one uses a Hexagonal Architecture or another. Neither \nSOA nor DDD need specify how each set of technical services is designed and \ndeployed, there being a wide variety of options.\nStill, when using DDD our goal is to create a Bounded Context with a com-\nplete, linguistically well-defined domain model. As discussed in Bounded Con-\ntexts (2), we don\u2019t want architecture to influence the size of the domain model. \nThat could happen if one or a few of the technical service endpoints, such as \na single REST resource, a single SOAP interface, or a system message type, \nwere to be used to dictate the size of a Bounded Context. Doing so would \nforce many, very small Bounded Contexts and domain models, perhaps each \nconsisting of only one Entity acting as the Root of a single, small Aggregate. \nThis could result in hundreds of such miniature Bounded Contexts in a single \nenterprise.\nWhile that approach may be viewed as having technical advantages, it does \nnot necessarily realize the goals of strategic DDD. It works against a clean, \nwell-modeled domain based on a complete and comprehensive Ubiquitous \nLanguage (1), actually fragmenting the Language. And, according to the SOA \nManifesto, unnaturally fragmenting Bounded Contexts is not necessarily the \nspirit of SOA:\nwww.EBooksWorld.ir\n", "page": 175, "type": "text", "section": "Page 175"}
{"text": " \nREPRESENTATIONAL STATE TRANSFER\u2014REST\n133\n 1. Business value over technical strategy\n 2. Strategic goals over project-specific benefits \nAssuming we can accept these as worthy values, they align very well with stra-\ntegic DDD. As explained in Bounded Contexts (2), the technical component \narchitecture drivers are less important when partitioning models.\nThe SaaSOvation teams had to learn a \ndifficult and important lesson, that listen-\ning to the linguistic drivers aligns better \nwith DDD. Each of their three Bounded \nContexts reflects the goals of SOA\u2014\nboth for the business and in the techni-\ncal services.\nThe three sample models discussed in Bounded Contexts (2), Context Maps \n(3), and Integrating Bounded Contexts (13) individually represent the single lin-\nguistically well-defined domain model. Each domain model is surrounded by a \nset of open services that implement an SOA that meets the business objectives.\nRepresentational State Transfer\u2014REST\nContributed by Stefan Tilkov\nREST has become one of the most used, and abused, architecture buzzwords \nof the last few years. As usual, different people think about different things \nwhen they use the acronym. To some, REST means sending XML over HTTP \nconnections without using SOAP; some equate it with using HTTP and JSON; \nothers believe that to do REST you need to send method arguments as URI \nquery parameters. All of these interpretations are wrong, but luckily\u2014and \nvastly different from many other concepts such as \u201ccomponents\u201d or \u201cSOA\u201d\u2014\nthere is an authoritative source for what REST means: the dissertation by Roy \nT. Fielding, which coined the term and defines it very clearly.\nREST as an Architectural Style\nThe first thing to understand when trying to \u201cget\u201d REST is the concept of archi-\ntectural styles. An architectural style is to architecture what a design pattern is \nwww.EBooksWorld.ir\n", "page": 176, "type": "text", "section": "Page 176"}
{"text": "Chapter 4 ARCHITECTURE\n134\nto a specific design. It is an abstraction of those aspects that are common to \ndifferent concrete implementations, enabling discussion of their relevant ben-\nefits without getting lost in technical detail. There are many different styles of \ndistributed systems architecture, including client-server and distributed objects. \nThe first few chapters of Fielding\u2019s thesis explain some of them, including the \nconstraints they mandate for an architecture that adheres to each of them. The \nconcept of architectural styles and constraints imposed by them might strike \nyou as somewhat theoretical, and you\u2019d be right. They form the theoretical \nfoundation of a (then) new architectural style that Fielding introduces. This is \nREST, which is the architectural style that the Web\u2019s architecture is supposed \nto adhere to.\nOf course the Web\u2014as embodied by its most important standards, URI, \nHTTP, and HTML\u2014predates Fielding\u2019s PhD work. But he had been one of \nthe main forces in standardization of HTTP 1.1, and a huge influence on many \ndesign decisions that led to the Web as we know it.4 Seen this way, REST is a \ntheoretical extrapolation, created after the fact, of the Web\u2019s architecture itself.\nSo why do we now equate \u201cREST\u201d with a specific way of building systems \nor, even more restricting, a way to build Web services? The reason for this is, \nas it turns out, that like any other technology, the Web protocols can be used in \nmany different ways. Some of them match the goals of the original designers; \nsome of them don\u2019t. One often-used analogy highlights this using the RDBMS \nworld familiar to many. You can use an RDBMS in line with its architectural \nconcepts\u2014that is, define tables with columns, foreign key relationships, views, \nconstraints, and so on\u2014or you can create a single table with two columns, \none called \u201ckey,\u201d one called \u201cvalue,\u201d and simply store serialized objects in the \nvalue column. Of course, you\u2019d still be using an RDBMS, but many of its ben-\nefits will not be available to you (meaningful queries, joins, sorting and group-\ning, and so forth). \nIn a very similar fashion, the Web protocols can be used in line with the \noriginal ideas that made them what they are\u2014with an architecture that con-\nforms to the REST architectural style\u2014or be used in a way that fails to follow \nit. And similar to our RDBMS example, we ignore the underlying architec-\ntural style to our peril. Thus, a different kind of distributed systems architec-\nture might be appropriate if we don\u2019t end up exploiting any of the benefits of \nusing HTTP in a \u201cRESTful\u201d way, just as a NoSQL/key-value store is the better \nchoice for storing whole values that are associated with a single unique key.\n 4. He also happens to be the author of the very first widely used HTTP library, one \nof the original developers of the Apache HTTP server, and founder of the Apache \nSoftware Foundation.\nwww.EBooksWorld.ir\n", "page": 177, "type": "text", "section": "Page 177"}
{"text": " \nREPRESENTATIONAL STATE TRANSFER\u2014REST\n135\nKey Aspects of a RESTful HTTP Server\nSo what are the key aspects of a distribution architecture that uses \u201c \nRESTful \nHTTP\u201d? Let\u2019s look at the server side first. Note that it\u2019s entirely irrelevant \nwhether we are talking about a server that\u2019s used by a human using a Web \nbrowser (a \u201cWeb application\u201d) or used by some other agent, such as a client \nwritten in your programming language of choice (a \u201cWeb service\u201d).\nFirst of all, as the name implies, resources are a key concept. How so? As a \nsystem designer, you decide what are the meaningful \u201cthings\u201d that you want to \nexpose as accessible from the outside, and you assign each a distinct identity. \nIn general, each resource has one URI, and more importantly, each URI should \npoint to one resource\u2014the \u201cthings\u201d you expose to the outside need to be indi-\nvidually addressable. For example, you might decide that each customer, each \nproduct, each product listing, each search result, and maybe each change to \nthe product catalog should be resources in their own right. Resources have \nrepresentations, renditions of their state, in one or more formats. It\u2019s through \nrepresentations\u2014an XML or JSON document, an HTML form\u2019s post data, or \nsome binary format\u2014that clients interact with resources.\nThe next key aspect is the idea of stateless communication, using self- \ndescriptive messages. Such is an HTTP request that carries all the information \nthe server needs to handle it. Of course, the server can (and usually will) use its \nown persistent state to help, but it\u2019s important that the client and server don\u2019t \nrely on individual requests to set up an implicit context (a session). This enables \naccess to each resource independently of other requests, an aspect that helps in \nachieving massive scalability.\nIf you view resources as objects\u2014and it\u2019s not at all unreasonable to do so\u2014\nit\u2019s valid to ask what kind of interface they should have. The answer is another \nvery important aspect that differentiates REST from any other architectural \nstyle for distributed systems. The set of methods that you can invoke is fixed. \nEvery object supports the same interface. In RESTful HTTP, the methods are \nthe HTTP verbs\u2014most importantly, GET, PUT, POST, DELETE\u2014that can be \napplied to resources.\nEven though it might appear so at first sight, these methods do not trans-\nlate to CRUD operations. It is very common to create resources that do not \nrepresent any persistent entity but instead encapsulate behavior that is invoked \nonce an appropriate verb is used on them. Each of the HTTP methods has a \nvery clear definition in the HTTP specification. For example, the GET method \nis to be used only for \u201csafe\u201d operations: (1) it can perform actions that reflect \nan effect a client might not have requested; (2) it always reads data; (3) it can \npotentially be cached (if the server indicates that this is the case by means of \nappropriate response headers).\nwww.EBooksWorld.ir\n", "page": 178, "type": "text", "section": "Page 178"}
{"text": "Chapter 4 ARCHITECTURE\n136\nHTTP\u2019s GET method has been called \u201cthe most optimized piece of distrib-\nuted systems plumbing in the world\u201d by none other than Don Box, one of the \nmain figures behind SOAP-style Web services. His words highlight that a lot of \nthe Web\u2019s performance and scalability that we take for granted is due to HTTP \noptimizations for this particular, very common case.\nSome HTTP methods are idempotent, meaning that they can be safely \ncalled again without problems in case of an error or unclear outcome. This is \ntrue for GET, PUT, and DELETE.\nFinally, a RESTful server enables a client to discover a path through the appli-\ncation\u2019s possible state transitions by means of hypermedia. This is called Hyper-\nmedia as the Engine of Application State (HATEOAS) in Fielding\u2019s dissertation. \nPut more simply, the individual resources don\u2019t stand on their own. They are \nconnected, linked to each other. This should not come as a surprise. After all, \nthis is where the Web got its name. For the server, this means that it will embed \nlinks in its answers, enabling the client to interact with connected resources.\nKey Aspects of a RESTful HTTP Client\nA RESTful HTTP client moves from one resource to the next either by fol-\nlowing links contained in resource representations or by being redirected to \nresources as a result of sending data for processing to the server. Server and cli-\nent cooperate to influence the client\u2019s distribution behavior dynamically. As a \nURI contains all information necessary for dereferencing an address\u2014includ-\ning host name and port\u2014a client following the hypermedia principle might \nend up talking to a resource hosted by a different application, a different host, \nor even a different company. \nIn an ideal REST setup, a client will start with a single well-known URI \nand continue following hypermedia controls from then on. This is exactly the \nmodel used by the browser when rendering and displaying HTML, including \nlinks and forms, to the user. Then, it uses the user\u2019s input to interact with a \nmultitude of Web applications, without up-front knowledge about their inter-\nface or implementations.\nGranted, a browser is not a self-sufficient agent. It requires a human to make \nthe actual decisions. But a programmatic client can adopt many of the same \nprinciples, even when some logic is hard-coded. It will follow links instead of \nassuming specific URI structures, or even colocation of resources in one server, \nand it will make use of its knowledge of one or more media types.\nREST and DDD\nTempting though it may be, it is not advisable to directly expose a domain \nmodel via RESTful HTTP. This approach often leads to system interfaces that \nwww.EBooksWorld.ir\n", "page": 179, "type": "text", "section": "Page 179"}
{"text": " \nREPRESENTATIONAL STATE TRANSFER\u2014REST\n137\nare more brittle than they need to be, as each change in the domain model is \ndirectly reflected in the system interface. There are two alternative approaches \nfor combining DDD and RESTful HTTP.\nThe first approach is to create a separate Bounded Context for the system\u2019s \ninterface layer and use appropriate strategies to access the actual Core Domain \nfrom the system\u2019s interface model. This can be deemed a classic approach, as \nit views the system\u2019s interface as a cohesive whole that is simply exposed using \nresource abstractions instead of services or remote interfaces.\nConsider a concrete example of this approach. We build a system that man-\nages a workgroup, including its tasks, schedules/appointments, subgroups, and \nall of the processes needed to handle these. We would design a pure domain \nmodel, untainted by the infrastructure details, that captures the Ubiquitous \nLanguage and implements the necessary business logic. To publish an interface \nto this carefully crafted domain model, we provide a remote interface as a set \nof RESTful resources. These resources reflect the use cases the client needs, \nwhich is very likely different from the pure domain model. Yet each resource \nis built from, for example, one or more Aggregates belonging to the Core \nDomain.\nOf course, we could simply use the domain objects as parameters to JAX-RS \nresource methods\u2014let\u2019s say /\n:user/\n:task would map to a method get-\nTask() that returns a Task object. That\u2019s seemingly simple, but it comes with \none major problem. Any change to the Task object structure is immediately \nreflected in the remote interface, possibly breaking many clients, even though \nwe might only have changed something that\u2019s entirely irrelevant to the outside \nworld. Not good.\nSo the first approach is preferred, that of decoupling the Core Domain from \nthe system\u2019s interface model. Doing so enables us to make changes to the Core \nDomain and then decide in each individual case whether that change must be \nreflected in the system\u2019s interface model and, if so, the best mapping to use. \nNote that with this approach, the classes designed for the system\u2019s interface \nmodel are usually driven by those of the Core Domain, but are certainly driven \nby the use cases. Note: Even in this case we could define a custom media type.\nAnother approach is appropriate when more emphasis is placed on standard \nmedia types. If specific media types are developed to support not only a single \nsystem interface but a category of similar client-server interactions, a domain \nmodel can be created to represent each standard media type. Such a domain \nmodel might even be reused across clients and servers, although some REST \nand SOA proponents view this as an anti-pattern. Note: Such an approach is \nessentially a Shared Kernel (3) or Published Language (3) in DDD terms.\nThis reflects more of an outside-in, crosscutting approach. In the workgroup \nand task management domain mentioned previously, there are many common \nwww.EBooksWorld.ir\n", "page": 180, "type": "text", "section": "Page 180"}
{"text": "Chapter 4 ARCHITECTURE\n138\nformats. Let\u2019s consider the ical format as an example. This is a generic format \nthat can be used by many different applications. In this case we would start \nby selecting a media type (ical) and then creating a domain model for this for-\nmat. This model could then be used by any system that needs to understand \nthis format\u2014our server application, for example, but also others (such as an \nAndroid client). Naturally, with this approach a server might need to deal with \nmany different media types, and the same media type might be used by multi-\nple servers.\nWhich of these two approaches is chosen depends to a large degree on the \ngoals of the system designer in terms of reusability. The more specialized the \nsolution, the more useful the first approach turns out to be. The more generally \nuseful the solution is, with the extreme end of the spectrum being standard-\nization by an official standards body, the more sense it makes to go with the \nsecond, media-type-centric approach.\nWhy REST?\nIn my experience, a system designed conforming to REST principles fulfills the \npromise of loose coupling. In general, it\u2019s very easy to add new resources and \nlinks to them in existing resource representations. It\u2019s also easy to add support \nfor new formats where needed, leading to a much less brittle set of system con-\nnections. A REST-based system is much easier to understand, as it\u2019s split into \nsmaller chunks\u2014the resources\u2014each of which exposes a separately testable, \ndebuggable, and usable entry point. The design of HTTP and the maturity of \nthe tooling with support for features such as URI rewriting and caching make \nRESTful HTTP a great choice for architectures that need to be both loosely \ncoupled and highly scalable.\nCommand-Query Responsibility Segregation, or CQRS\nIt can be difficult to query from Repositories all the data users need to view. \nThis is especially so when user experience design creates views of data that \ncuts across a number of Aggregate types and instances. The more sophisticated \nyour domain, the more this situation tends to occur.\nUsing only Repositories to solve this can be less than desirable. We could \nrequire clients to use multiple Repositories to get all the necessary Aggregate \ninstances, then assemble just what\u2019s needed into a Data Transfer Object (DTO) \n[Fowler, P of EAA]. Or we could design specialized finders on various Reposi-\ntories to gather the disjointed data using a single query. If these solutions seem \nwww.EBooksWorld.ir\n", "page": 181, "type": "text", "section": "Page 181"}
{"text": " \nCOMMAND-QUERY RESPONSIBILITY SEGREGATION, OR CQRS\n139\nunsuitable, perhaps we should instead compromise on user experience design, \nmaking views rigidly adhere to the model\u2019s Aggregate boundaries. Most would \nagree that in the long run a mechanical and spartan user interface won\u2019t suffice.\nIs there an altogether different way to map domain data to views? The \nanswer lies in the oddly named architecture pattern CQRS [Dahan, CQRS; \nNijof, CQRS]. It is the result of pushing a stringent object (or component) \ndesign principle, command-query separation (CQS), up to an architecture \npattern.\nThis principle, devised by Bertrand Meyer, asserts the following:\nEvery method should be either a command that performs an action, or a query \nthat returns data to the caller, but not both. In other words, asking a question \nshould not change the answer. More formally, methods should return a value \nonly if they are referentially transparent and hence possess no side effects. [Wiki-\npedia, CQS]\nAt an object level this means:\n 1. If a method modifies the state of the object, it is a command, and its \nmethod must not return a value. In Java and C# the method must be \ndeclared void.\n 2. If a method returns some value, it is a query, and it must not directly or \nindirectly cause the modification of the state of the object. In Java and C# \nthe method must be declared with the type of the value it returns.\nThat\u2019s pretty straightforward guidance, and there is a practical and theoretical \nbasis for adhering to it. Yet, as an architecture pattern when using DDD, why \nand how is it applied?\nVisualize a domain model, such as one of those discussed under Bounded \nContexts (2). We\u2019d normally see Aggregates with both command and query \nmethods. We\u2019d also see Repositories that have a number of finder methods that \nfilter on certain properties. With CQRS we are going to disregard these \u201cnor-\nmalities\u201d and design a different way to query display data.\nNow think of segregating all of the pure query responsibilities traditionally \nfound in a model from all responsibilities that execute pure commands on the \nsame model. Aggregates would have no query methods (getters), only com-\nmand methods. Repositories would be stripped down to an add() or save()\nmethod (supporting both creation and updating saves) and only a single query \nmethod, such as fromId(). The single query method takes the unique iden-\ntity of an Aggregate and returns it. A Repository could not be used to find an \nAggregate by any other means, such as by filtering on some additional prop-\nerties. With all of that removed from the traditional model, we designate it \nwww.EBooksWorld.ir\n", "page": 182, "type": "text", "section": "Page 182"}
{"text": "Chapter 4 ARCHITECTURE\n140\na command model. We still need a way to display data to the user. For that \nwe create a second model, one that is tuned for optimized queries. That\u2019s our \nquery model.\nIsn\u2019t This Accidental Complexity?\nYour impression may be that this proposed style is a lot of work and that we are \nmerely replacing one set of problems with another set of problems, and adding a lot \nmore code to do it.\nDon\u2019t be too quick to dismiss this style, however. Under some circumstances the \nadded complexity is justifiable. Remember, CQRS is meant to solve a specific view \nsophistication problem, not to tack on as a cool new style that will strengthen your \nr\u00e9sum\u00e9.\nKnown by Other Names\nNote that some areas/components of CQRS may be known by other names. What \nI call the query model is also known as the read model, and the command model is \nalso called the write model.\nAs a result, the traditional domain model would be split in two. The com-\nmand model is persisted in one store and the query model in another. We end \nup with a set of components like the one in Figure 4.6. Some more details will \nclarify this pattern.\nExamining Areas of CQRS\nLet\u2019s step through each of the major areas of this pattern. We can start with \nthe client and query support and move through to the command model and \nhow updates to the query model are done.\nQuery\nProcessor\nEvent (all)\nSubscriber\nCommand\nModel\nCommand\nModel\nStore\nCommand\nProcessors\n(Application\nServices)\nQuery\nModel\nFigure 4.6 With CQRS, commands from clients travel one way to the command \nmodel. Queries are run against a separate data source optimized for presentation and \ndelivered as user interface or reports.\nwww.EBooksWorld.ir\n", "page": 183, "type": "text", "section": "Page 183"}
{"text": " \nCOMMAND-QUERY RESPONSIBILITY SEGREGATION, OR CQRS\n141\nClient and Query Processor\nThe client (at the far left in the diagram) may be a Web browser or a custom \ndesktop user interface. It uses a set of query processors running on a server. \nThe diagram doesn\u2019t show architecturally significant divisions between tiers \non the server(s). Whatever tiers exist, the query processor represents a simple \ncomponent that only knows how to execute basic queries on a database, such \nas a SQL store.\nThere are no complex layers here. At most this component runs a query \nagainst the query store database and maybe serializes the query result into \nsome format for transport (maybe a DTO, but maybe not), if that\u2019s necessary. \nIf the client runs Java or C#, it could query the database directly. However, that \nmight require a large number of database client licenses, one per connection. \nEmploying a query processor that uses pooled connections is the best choice.\nIf the client can consume a database result set (for example, JDBC vari-\nety), serialization is unnecessary but may be desirable anyway. There are two \nschools of thought here. One asserts that ultimate simplicity requires that the \nresult set, or a very basic wire-compatible serialization of it (XML or JSON), \nmust be consumed by the client. Others assert that DTOs should be built and \nconsumed by the client. This may be a matter of taste, but we might agree that \nanytime we add DTOs and DTO Assemblers [Fowler, P of EAA] there is added \ncomplexity, and if not truly needed, these would be accidental complexity.\nEach team determines which approach works best for their project.\nQuery Model (or Read Model)\nThe query model is a denormalized data model. It is not meant to deliver \ndomain behavior, only data for display (and possibly reporting). If this data \nmodel is a SQL database, each table would hold the data for a single kind \nof client view (display). The table can have many columns, even a superset of \nthose needed by any given user interface display view. Table views can be cre-\nated from tables, each of which is used as a logical subset of the whole.\nCreate Support for as Many Views as Needed\nIt\u2019s worth noting that CQRS-based views can be both cheap and disposable (for \ndevelopment and in maintenance). This is especially so if you use a simple form of \nEvent Sourcing (see the section \u201cEvent Sourcing\u201d later in the chapter and Appendix \nA) and save all Events into a persistent store, which can be republished at any time to \ncreate new persistent view data. Doing so, any single view could be rewritten from \nscratch in isolation or the entire query model be switched to completely different \npersistence technology. This makes it easy to create and maintain views that contin-\nuously address ongoing UI needs. This can lead to more intuitive user experiences \nthat avoid the table paradigm but are instead much richer.\nwww.EBooksWorld.ir\n", "page": 184, "type": "text", "section": "Page 184"}
{"text": "Chapter 4 ARCHITECTURE\n142\nFor example, a table could be designed with enough data to display user \ninterfaces for normal users, managers, and administrators. If a correspond-\ning database table view was created for each of those user types, the data for \neach security role would be divided appropriately. This builds security into the \nviewable data per user type. A normal user view component would select all \ncolumns from the normal user table view. A manager\u2019s view component would \nselect all columns from the manager\u2019s table view. That way normal users would \nnot be able to see what managers can see.\nPreferably, a select statement requires only a primary key for the view being \nused. Here the query processor selects all columns from the normal user table \nview of a product:\nSELECT * FROM vw_usr_product WHERE id = ?\nAs a side note, the table view naming convention seen here is not necessar-\nily recommended. It just makes obvious what the sample select is doing. The \nprimary key corresponds to the unique identity of some Aggregate type or a \ncombined set of Aggregate types merged into a single table. In this example the \nid primary key column is the unique identity of a Product in the command \nmodel. The data model design should follow, as much as possible, the pattern \nof one table per user interface view type, with as many table views as necessary \nto reflect application security roles. But, be practical.\nBe Practical\nIf there are 25 traders at a high-frequency trading desk and each one is trading secu-\nrities that most of the others cannot view due to SEC compliance, would we need 25 \ntable views? Using a trader filter would be more appropriate. Otherwise, there may \nbe too many views to maintain to be truly practical.\nIn practice this may be difficult to achieve, and queries may have to join \nmultiple tables or table views as necessarily for practical use. Joins across \nviews/tables may be necessary or at least more practical to achieve necessary \nfiltering. This may tend to be the case, especially when there are many user \nroles at play in your domain.\nDon\u2019t Database Table Views Cause Overhead?\nA basic database table view has no overhead when performing updates on the back-\ning table. The view just corresponds to a query, which in this case does not even \nrequire a join. Only materialized views incur update overhead since the view\u2019s data \nmust be copied into one place so it is ready for selects. Use care when designing \ntables and views so that query model updates perform optimally.\nwww.EBooksWorld.ir\n", "page": 185, "type": "text", "section": "Page 185"}
{"text": " \nCOMMAND-QUERY RESPONSIBILITY SEGREGATION, OR CQRS\n143\nClient Drives Command Processing\nUser interface clients submit commands to the server (or indirectly execute an \nApplication Service method) as the means of executing behavior on Aggregates, \nwhich are in the command model. The submitted command contains the name \nof the behavior to execute and the parameters necessary to carry it out. The \ncommand packet is a serialized method invocation. Since the command model \nhas carefully designed contracts and behaviors, matching the commands to the \ncontracts is a straightforward mapping.\nTo accomplish this the user interface must collect the data necessary to \ncorrectly parameterize the command. This implies that much thought must \nbe given to user experience design. It must lead users toward the proper goal \nof submitting an explicit command. An inductive, task-driven user interface \ndesign works best [Inductive UI]. It filters out all inapplicable options, focusing \non precision command execution. That said, it is possible to design a deductive \nuser interface that generates an explicit command.\nCommand Processors\nA command submission is received by a Command Handler/processor, which \ncan have a few different styles. We consider those styles here, along with some \nadvantages and disadvantages.\nWe can use a categorized style with several Command Handlers in one \nApplication Service. This style creates an Application Service interface and \nimplementation for a category of commands. Each Application Service could \nhave multiple methods, one method declared for each type of command with \nparameters that fits the category. The primary advantage here is simplicity. \nThis kind of handler is well understood, easy to create, and easy to maintain.\nWe can create a dedicated style handler. Each one would be a single class \nwith one method. The method contract facilitates a specific command with \nparameters. This has clear advantages: There is a single responsibility per \nhandler/processor; each handler may be redeployed independently of others; \nhandler types can be scaled out to manage high volumes of certain kinds of \ncommands.\nThis leads to the messaging style of Command Handler. Each command \nis sent as an asynchronous message and delivered to a handler designed with \nthe dedicated style. This not only enables each command processor component \nto receive specifically typed messages, but processors of a given type can be \nadded to deal with command processing load. This approach should not be \nused by default, as it has a more complex design. Instead, start off with either \nof the other two styles as synchronous command processors. Switch to asyn-\nchronous only if scalability demands require it. That said, some will conclude \nwww.EBooksWorld.ir\n", "page": 186, "type": "text", "section": "Page 186"}
{"text": "Chapter 4 ARCHITECTURE\n144\nthat an asynchronous approach providing temporal decoupling leads to more \nresilient systems. That viewpoint will often lead to a bias toward implementing \nthe messaging style of Command Handlers.\nWhatever kind of handler is used, decouple each one from all others. Do not \nallow any one handler to depend on (make use of) any others. This will allow \nany type of handler to be redeployed independently without impacting others.\nCommand Handlers generally do only a few things. If one has a creation \naspect, it instantiates a new Aggregate instance and adds the new instance to \nits Repository. Most often it gets an Aggregate instance from its Repository \nand executes a command method behavior on it:\n@Transactional\npublic void commitBacklogItemToSprint(\n    String aTenantId, String aBacklogItemId, String aSprintId) {\n    TenantId tenantId = new TenantId(aTenantId);\n    BacklogItem backlogItem =\n        backlogItemRepository.backlogItemOfId(\n            tenantId, new BacklogItemId(aBacklogItemId));\n    Sprint sprint = sprintRepository.sprintOfId(\n            tenantId, new SprintId(aSprintId));\n    backlogItem.commitTo(sprint);\n}\nWhen the Command Handler completes, a single Aggregate instance has \nbeen updated and a Domain Event has been published by the command model. \nThis is essential to ensuring that the query model is updated. Note too that, \nas discussed in Domain Events (8) and Aggregates (10), the published Event \nmay also be used to cause the synchronization of other Aggregate instances \neffected by this one command, but the modification of the additional Aggre-\ngate instances would be eventually consistent with the one committed by this \ntransaction.\nCommand Model (or Write Model) Executes Behavior\nAs each command method on the command model is executed, it completes \nby publishing an Event as described in Domain Events (8). Using the running \nexample, the BacklogItem would complete its command method as follows:\npublic class BacklogItem extends ConcurrencySafeEntity  {\n    ...\n    public void commitTo(Sprint aSprint) {\n        ...\nwww.EBooksWorld.ir\n", "page": 187, "type": "text", "section": "Page 187"}
{"text": " \nCOMMAND-QUERY RESPONSIBILITY SEGREGATION, OR CQRS\n145\n        DomainEventPublisher\n            .instance()\n            .publish(new BacklogItemCommitted(\n                    this.tenant(),\n                    this.backlogItemId(),\n                    this.sprintId()));\n    }\n    ...\n}\nWhat\u2019s Behind the Publisher Component?\nThis particular DomainEventPublisher is a lightweight component based on the \nObserver pattern [Gamma et al.]. See Domain Events (8) for details on how Events \nget published broadly.\nThis is the linchpin for updating the query model with the most recent \nchanges to the command model. If using Event Sourcing, the Events are also \nnecessary for persisting the state of the Aggregate that has just been modified \n(BacklogItem in this example). However, it is not a necessity to use Event \nSourcing with CQRS. Unless Event logging is a requirement specified by the \nbusiness, the command model can be persisted using an object- \nrelational map-\nper (ORM) to a relational database or some other approach. Either way, a \nDomain Event must still be published to ensure that the query model is updated.\nWhen Commands Don\u2019t Result in Event Publishing\nThere are circumstances when command dispatching does not lead to Events being \npublished. For example, if a command was delivered by \u201cat-least-once\u201d messag-\ning and the application ensures idempotent operations, the redelivered message is \nsilently dropped.\nAlso consider the case where the application validates incoming commands. All \nauthorized clients know about validation rules and will always pass them. However, \nall unauthorized clients\u2014such as those of attackers\u2014submitting invalid commands \nwill fail and can be silently dropped without endangering authorized users.\nEvent Subscriber Updates the Query Model\nA special subscriber registers to receive all Domain Events published by the \ncommand model. The subscriber uses each Domain Event to update the query \nmodel to reflect the most recent changes to the command model. This implies \nthat each Event must be rich enough to supply all the data necessary to produce \nthe correct state in the query model.\nShould the updates be performed synchronously or asynchronously? It \ndepends on the normal load on the system, and possibly also on where the \nquery model database is stored. Data consistency constraints and performance \nrequirements will influence the decision.\nwww.EBooksWorld.ir\n", "page": 188, "type": "text", "section": "Page 188"}
{"text": "Chapter 4 ARCHITECTURE\n146\nTo update synchronously, the query model and command model would nor-\nmally share the same database (or schema), and we would update the two mod-\nels in the same transaction. That keeps both models completely consistent. Yet, \nthis will require more processing time for the multiple table updates, which \nmay not meet the service-level agreement (SLA). If the system is normally \nunder heavy load and the query model update process is lengthy, use asyn-\nchronous updates instead. This may lead to challenges of eventual consistency, \nwhere the user interface will not immediately reflect the most recent changes \nin the command model. The lag time is unpredictable, but it is a trade-off that \nmay be necessary to meet other SLAs.\nWhat happens when a new user interface view is created but its data must \nbe created? Design the table and any table views as described previously. Pop-\nulate the new table with current state using one of a few techniques. If the \ncommand model is persisted using Event Sourcing, or if there is a full historical \nEvent Store, replay the historical Events to produce the updates. This is possi-\nble only if the right kinds of Events already exist in the store. If they don\u2019t, the \ntable may have to be populated as future commands enter the system. There \nmay be another option.\nIf the command model is persisted using an ORM, use the backing com-\nmand model store to populate the new query model table. This may employ \na common data warehousing (or report database) generation technique, such \nas extract, transform, load (ETL). Extract the data from the command model \nstore, transform it as needed by the user interface, and load it into the query \nmodel store.\nDealing with an Eventually Consistent Query Model\nIf the query model is designed to be eventually consistent\u2014query model \nupdates are performed asynchronously following writes to the command model \nstore\u2014there will be resulting idiosyncrasies in the user interface to deal with. \nFor example, after a user submits a command, will the next user interface view \nhave the fully updated and consistent data reflected from the query model? It \nmay depend on system load and other factors. But we had better assume not \nand design for the worst case, where the user interface is never consistent.\nOne option is to design the user interface to temporarily display the data \nthat was successfully submitted as parameters of the command just executed. \nThis is a bit of a trick, but it enables the user to immediately see what will \neventually be reflected in the query model. It may be the only way to ensure \nthat the user interface does not display completely stale data just after a com-\nmand is successfully executed.\nwww.EBooksWorld.ir\n", "page": 189, "type": "text", "section": "Page 189"}
{"text": " \nEVENT-DRIVEN ARCHITECTURE\n147\nWhat if that is not practical for a given user interface? Even if it is, there are \nalso times when any one user executes a command and all other users viewing \nrelated data will absolutely see stale data. How can this challenge be met?\nOne technique suggested by [Dahan, CQRS] always explicitly displays on \nthe user interface the date and time of the data from the query model that \na user is currently viewing. To do so, each record in the query model needs \nto maintain the date and time of the latest update. This is a trivial step, gen-\nerally supported by a database trigger. With the date and time of the latest \nupdate, the user interface can now inform the user how old the data is. If the \nuser determines that the data is too stale to use, he or she can at that time \nrequest fresher data. Admittedly this approach is lauded by some as an effec-\ntive pattern and heavily criticized by others as a hack or artifice. Certainly \nthese opposing viewpoints indicate the need to perform user acceptance tests \nbefore this approach is employed in our own systems.\nYet, it\u2019s possible that the delayed view data synchronization is not a crit-\nical problem at all. It may also be overcome by other means, such as Comet\n(aka Ajax Push), or another form of latent update, such as some variation of \nObserver [Gamma et al.] or Distributed Cache/Grid (for example, Coherence \nor GemFire) event subscriptions. Addressing delays may even be as easy as \ninforming users that their request has been accepted and a result will require \nsome processing time. Carefully determine whether the eventual consistency \nlag time poses a problem. If so, you\u2019ll have to find the best way to address it in \na given environment.\nAs with every pattern, CQRS introduces a number of competing forces. We \nmust exercise a great deal of care and choose wisely. Certainly if a user inter-\nface is not overly complex or regularly cut across several different Aggregates \nin a single view, employing CQRS would serve to introduce accidental com-\nplexity rather than necessary complexity. CQRS is the right choice when it \nremoves a risk that has a high probability of causing failure if ignored.\nEvent-Driven Architecture\nEvent-driven architecture (EDA) is a software architecture promoting the pro-\nduction, detection, consumption of, and reaction to events. [Wikipedia, EDA]\nThe Hexagonal Architecture shown in Figure 4.4 can represent the notion of \none system participating in an EDA by means of incoming and outgoing mes-\nsages. An EDA doesn\u2019t have to use Hexagonal, but it\u2019s a decent way to present \nthe concepts here. On a greenfield project it would be well worth it to consider \nusing Hexagonal as the overarching style.\nwww.EBooksWorld.ir\n", "page": 190, "type": "text", "section": "Page 190"}
{"text": "Chapter 4 ARCHITECTURE\n148\nExamining Figure 4.4, say that the triangular client and the corresponding \ntriangular output mechanism represent the messaging mechanism used by the \nBounded Context. Input events enter on a Port separate from the one used by \nthe other three clients. Output events likewise travel via a different Port. As pro-\nposed previously, the separate Ports could represent the message transport over \nAMQP, as used by RabbitMQ, rather than the more common HTTP that the \nother clients use. Whichever actual messaging mechanism may be in use, we will \nassume that events enter and exit the system by means of the symbolic triangles.\nThere may be a number of different kinds of events that enter and exit a \nhexagon. We are interested specifically in Domain Events. The application may \nalso subscribe to system, enterprise, or other types of events as well. Perhaps \nthose deal with system health and monitoring, logging, dynamic provisioning, \nand the like. Yet, it is the Domain Events that convey the happenings requiring \nour modeling attention.\nWe can replicate the system in the Hexagonal Architecture view as many \ntimes as necessary to represent the complement of systems in the enterprise \nthat support the Event-Driven way. That\u2019s been done in Figure 4.7. Again, it\u2019s \nnot that every system will be based on Hexagonal. The diagram just demon-\nstrates how Event-Driven could be supported if multiple systems were Hex-\nagonal at their foundation. Otherwise, feel free to replace the hexagons with \nLayers, or another style.\nThe Domain Events published by one such system through the output Port \nwould be delivered to subscribers represented in the others through their input \nPort. The various Domain Events received have a specific meaning in each receiving \nIncoming events\nIncoming events\nOutgoing events\nHexagonal Architecture\nFigure 4.7 Three systems using an Event-Driven Architecture with an overarching \nHexagonal style. The EDA style decouples all but the systems\u2019 dependency on the \nmessaging mechanism itself and the Event types they subscribe to.\nwww.EBooksWorld.ir\n", "page": 191, "type": "text", "section": "Page 191"}
{"text": " \nEVENT-DRIVEN ARCHITECTURE\n149\nBounded Context, or possibly no meaning at all.5 If the Event type is of interest in \na specific Context, its properties are adapted to the application\u2019s API and used to \nexecute an operation there. The command operation executed on the application\u2019s \nAPI is then reflected into the domain model according to its protocol.\nIt\u2019s possible that a specific Domain Event received represents only one part \nof a multitask process. Until all anticipated Domain Events arrive, the mul-\ntitask process is not considered completed. But how does the process begin? \nHow is it distributed across the enterprise? And how do we handle tack prog-\nress through to process completion? The answers are discussed subsequently in \nthe section on long-running processes. But first some initial groundwork is in \norder. Message-based systems often reflect a Pipes and Filters style.\nPipes and Filters\nIn one of its simplest forms, Pipes and Filters are available using a shell/console \ncommand line:\n$ cat phone_numbers.txt | grep 303 | wc -l\n3\n$\nHere a Linux command line is used to find how many contacts are in the fancy \npersonal information manager, phone_numbers.txt, who have  \nColorado-\nbased phone numbers. Admittedly this is not a very reliable way to implement \nthat use case, but it does demonstrate how Pipes and Filters work:\n 1. The cat utility outputs the contents of phone_numbers.txt to what is \ncalled the standard output stream. Normally this stream is connected to \nthe console. But when the | symbol is used, the output is piped to the input \nof the next utility.\n 2. Next, grep reads its input from the standard input stream, which was \nthe result of cat. The argument to grep tells it to match lines that con-\ntain the text 303. Each line that it finds is output to its standard output \nstream. As with cat, grep\u2019s output stream is now piped to the input of \nthe next utility.\n 3. Finally, wc reads its standard input stream, which was piped from grep\u2019s \nstandard output. The command-line argument to wc is -l, telling it to \ncount the number of lines it reads. It outputs the result, which in this case \n 5. If using message filters or routing keys, subscribers can avoid receiving Events that \nare meaningless to them.\nwww.EBooksWorld.ir\n", "page": 192, "type": "text", "section": "Page 192"}
{"text": "Chapter 4 ARCHITECTURE\n150\nis 3, because three lines were output by grep. Note that now the stan-\ndard output is displayed to the console since this time there is no Pipe to \nan additional command.\nThis can be approximated using a Windows console, but with less piping:\nC:\\fancy_pim> type phone_numbers.txt | find /c \"303\"\n3\nC:\\fancy_pim>\nConsider what happens with each of the utilities. Each receives a dataset, \nprocesses it, and outputs a different dataset. The dataset that is output changes \nfrom the input because each utility acts as a Filter. By the end of the filtering \nprocess the output is completely different from the input. The input started out \nas a text file with individual lines of contact information and ended up being \nthe text digit representing the number 3.\nUsing the basic principles from this example, how might we apply them to \nan Event-Driven Architecture? In fact, we can find some useful overlap. The \nfollowing discussion is based on the Pipes and Filters messaging pattern found \nin [Hohpe, Woolf]. Understand, however, that a messaging Pipes and Filters \napproach is not exactly like the command-line version, and it is not intended \nto be. For example, an EDA Filter doesn\u2019t need to actually filter anything. A \nFilter in an EDA may be used to perform some processing while leaving the mes-\nsage data intact. Yet Pipes and Filters in an EDA is similar enough to the com-\nmand-line type that the previous example helped lay some groundwork for what \nfollows. If you are a more advanced reader, feel free to \u201cfilter\u201d what follows.\nTable 4.2 presents some of the basic characteristics of a message-based Pipes \nand Filters process.\nTable 4.2 Basic Characteristics of a Message-Based Pipes and Filters Process\nCharacteristic\nDescription\nPipes are message \nchannels\nFilters receive messages on an inbound Pipe and send mes-\nsages on an outbound Pipe. The Pipe is actually a message \nchannel.\nPorts connect Filters \nto Pipes\nFilters connect to inbound and outbound Pipes through a \nPort. Ports make Hexagonal (Ports and Adapters) a fitting \noverarching style.\nFilters are processors\nFilters may process messages without actually filtering.\nSeparate processors\nEach Filter processor is a separate component, and proper \ncomponent granularity is achieved by careful design.\nwww.EBooksWorld.ir\n", "page": 193, "type": "text", "section": "Page 193"}
{"text": " \nEVENT-DRIVEN ARCHITECTURE\n151\nNow, what if we were to think of each of the utilities cat, grep, and wc (or \ntype and find) as components in an Event-Driven Architecture? What if we \neven implemented components to act as message senders and receivers to pro-\ncess telephone numbers in a similar way? (Again, I am not trying to illustrate a \none-to-one command-line replacement, just a simple messaging example with \nthe same basic goals.)\nHere\u2019s how a messaging Pipes and Filters approach could work, with steps \nillustrated in Figure 4.8:\n 1. We could start off with a component named PhoneNumbersPublisher\nthat reads all the lines in phone_numbers.txt and then creates and \nsends an Event message that includes all of the text lines. The Event is \nnamed AllPhoneNumbersListed. Once it is sent, the pipeline begins.\n 2. A message handler component named PhoneNumberFinder is config-\nured to subscribe to AllPhoneNumbersListed and receives it. This \nmessage handler is the first Filter in the pipeline. The Filter is configured \nto search for the text 303. This component processes the Event by search-\ning each line for the 303 text sequence. It then creates a new Event named \nPhoneNumbersMatched, placing the full lines of matching results in \nthe Event. The Event message is sent, continuing the pipeline.\n 3. A message handler component named MatchedPhoneNumberCounter\nis configured to subscribe to PhoneNumbersMatched and receives it. This \nmessage handler is the second Filter in the pipeline. Its sole responsibility \nCharacteristic\nDescription\nLoosely coupled\nEach Filter processor is composed into the process inde-\npendent of all others. Filter processor composition may be \ndefined by configuration.\nInterchangeable\nThe order in which a processor receives messages may be \nrearranged per use case requirements, again using config-\nured composition.\nFilters may \nmulti-Pipe\nWhile the command-line Filters read from and write to \nonly one Pipe, messaging Filters may read from and/or \nwrite to multiple Pipes, which implies parallel or concur-\nrent processing.\nUse same-type Filters \nin parallel\nThe busiest and possibly slowest Filters may be deployed in \nmultiples to increase throughput.\n Table 4.2 Basic Characteristics of a Message-Based Pipes and Filters Process \n(Continued \n)\nwww.EBooksWorld.ir\n", "page": 194, "type": "text", "section": "Page 194"}
{"text": "Chapter 4 ARCHITECTURE\n152\nis to count the phone numbers in the Event and then forward the results \nin a new Event. In this case it counts three total lines containing phone \nnumbers. The Filter completes by creating the MatchedPhoneNumbers-\nCounted Event, setting the count property to 3. The Event message is \nsent, continuing the pipeline.\n 4. Finally, a message handler component subscribed to MatchedPhone-\nNumbersCounted receives it. This component is named PhoneNumber-\nExecutive. Its single responsibility is to log the result, including the \ncount Event property and the date and time it was received, to a file. In \nthis case it writes\n3 phone numbers matched on July 15, 2012 at 11:15 PM\nThe pipeline for this specific process is now completed.6\n 6. For simplicity I don\u2019t discuss Ports, Adapters, and the application API of the \nHexagonal Architecture.\n<<event>>\nsends\nreads\nlogs\nreceived by\nsends\nreceived by\nsends\nreceived by\nAllPhoneNumbersListed\n<<event>>\nPhoneNumbersMatched\n<<event>>\nMatchedPhoneNumbersCounted\nPhoneNumbersPublisher\nPhoneNumberFinder\nMatchedPhoneNumberCounter\nPhoneNumberExecutive\nFigure 4.8 A pipeline is formed by sending Events that the Filters process.\nwww.EBooksWorld.ir\n", "page": 195, "type": "text", "section": "Page 195"}
{"text": " \nEVENT-DRIVEN ARCHITECTURE\n153\nThis kind of pipeline is somewhat flexible. If we wanted to add any new Fil-\nters to the pipeline, we\u2019d create new Events that each existing Filter subscribes \nto and publishes. Basically we\u2019d have to carefully change the sequential order \nof the pipeline via configuration. Of course, it\u2019s not as easy to change this pro-\ncess as with the command-line approach. Typically, however, we won\u2019t change \nDomain Event pipelines all that frequently. While this particular distributed \nprocess is not very useful in itself, it does demonstrate how Pipes and Filters \nmight work in a messaging, Event-Driven Architecture.\nSo, would we actually expect that we\u2019d see Pipes and Filters exploited to \nsolve a problem like this? Well, ideally not. (In fact, if you find this example \nannoying, it\u2019s probably because you already know better. That\u2019s fine, but there \nare plenty of others who are helped by it.) This is meant only as a synthetic \nexample, one that highlights the concepts. In a real enterprise we would use \nthis pattern to break down a large problem into smaller steps that would make \ndistributed processing easier to understand and manage. It would also allow \nmultiple systems to care only for what they do well.\nIn an actual DDD scenario, Domain Events reflect names meaningful to \nthe business. Step 1 could publish a Domain Event based on the behavioral \noutcome of an Aggregate in one Bounded Context. Steps 2 through 4 could \noccur in one or more different Bounded Contexts that receive the initial Event \nand then publish one of the subsequent ones. Those three steps could create or \nmodify Aggregates in their respective Contexts. It does depend on the domain, \nbut those are common outcomes of handling Domain Events in a Pipes and \nFilters Architecture.\nAs explained in Domain Events (8), these are not just paper-thin technical \nnotifications. They explicitly model business process activity occurrences that \nare useful for domain-wide subscribers to know about, and they pack unique \nidentity and as many knowledge-conveying properties as necessary to clearly \nget their point across. Yet this synchronous, step-by-step style can be extended \nto accomplish more than one thing at the same time.\nLong-Running Processes, aka Sagas\nThe synthetic Pipes and Filters example can be extended to demonstrate another \nEvent-Driven, distributed, parallel processing pattern, namely, Long-Running \nProcesses. A Long-Running Process is sometimes called a Saga, but depending \non your background that name may collide with a preexisting pattern. An early \ndescription of Sagas is presented in [Garcia-Molina & Salem]. In an attempt to \navoid confusion and ambiguity, I have chosen to use the name Long-Running \nProcess, and sometimes I use the name Process for brevity.\nwww.EBooksWorld.ir\n", "page": 196, "type": "text", "section": "Page 196"}
{"text": "Chapter 4 ARCHITECTURE\n154\nCowboy Logic \nLB:  \n\u201cDallas and Dynasty, now those are what I call \nsagas!\u201d\nAJ:  \n\u201cFor all you German readers, y\u2019all know Dynasty as \nDer Denver Clan.\u201d\nExtending the previous example, we could create parallel pipelines by adding \njust one new Filter, TotalPhoneNumbersCounter, as an additional sub-\nscriber to AllPhoneNumbersListed. It receives the Event AllPhone-\nNumbersListed virtually in parallel with the  \nPhoneNumberFinder. The \nnew Filter has a very simple goal, counting all existing contacts. This time, \nhowever, PhoneNumberExecutive both starts the Long-Running Process \nand tracks it through completion. The executive may or may not reuse the \nPhoneNumbersPublisher, but the important thing is what\u2019s new about it. \nThe executive, implemented as an Application Service or Command Handler, \ntracks the progress of the Long- \nRunning Process and understands when it is \ncompleted and what to do when that happens. Refer to Figure 4.9 as we step \nthrough the sample Long-Running Process.\n<<event>>\nsends\nreads\nlogs\nreceived by\nsends\nsends\nreceived by\nreceived by\nsends\nreceived by\nreceived by\nAllPhoneNumbersListed\n<<event>>\nPhoneNumbersMatched\n<<event>>\nMatchedPhoneNumbersCounted\n<<event>>\nAllPhoneNumbersCounted\nTotalPhoneNumbersCounter\nPhoneNumberFinder\nMatchedPhoneNumberCounter\nPhoneNumberExecutive\nFigure 4.9 The single Long-Running Process executive initiates the parallel processing and tracks \nit to completion. The wider arrows indicate where the parallelism begins when two Filters receive \nthe same Event.\nwww.EBooksWorld.ir\n", "page": 197, "type": "text", "section": "Page 197"}
{"text": " \nEVENT-DRIVEN ARCHITECTURE\n155\nDifferent Ways to Design a Long-Running Process\nHere are three approaches to designing a Long-Running Process, although \nthere may be more:\n\u2022 Design the process as a composite task, which is tracked by an exec-\nutive component that records the steps and completeness of the task \nusing a persistent object. This is the approach discussed most thor-\noughly here.\n\u2022 Design the process as a set of partner Aggregates that collaborate in a \nset of activities. One or more Aggregate instances act as the executive \nand maintain the overall state of the process. This is the approach pro-\nmoted by Amazon\u2019s Pat Helland [Helland].\n\u2022 Design a stateless process in that each message handler component \nthat receives an Event-carrying message must enrich the received \nEvent with more task progress information as it sends the next mes-\nsage. The state of the overall process is maintained only in the body of \neach message sent from collaborator to collaborator.\nSince the initial Event is now subscribed to by two components, both Filters \nreceive the same Event virtually simultaneously. The original Filter goes about \nas it always has, matching the specific 303 text pattern. The new Filter only \ncounts all lines, and when it has completed, it sends the Event AllPhone-\nNumbersCounted. The Event includes the count of total contacts. If there \nare, for example, 15 total phone numbers, the Event count property is set \nto 15.\nNow it is the responsibility of PhoneNumberExecutive to subscribe \nto two Events, both MatchedPhoneNumbersCounted and AllPhone-\nNumbersCounted. The parallel processing is not considered completed until \nboth of these Domain Events are received. When completion is reached, the \nresults of the parallel processing are merged into a single result. The executive \nnow logs\n    3 of 15 phone numbers matched on July 15, 2012 at 11:27 PM\nThe log output is enhanced with the total count of phone numbers in addi-\ntion to the previous matching, date, and time information. Although the tasks \nperformed to yield results were really simple, they were performed in parallel. \nAnd if at least some of the subscriber components were deployed to different \ncomputing nodes, the parallel processing was also distributed.\nThere is a problem with this Long-Running Process, however. The \nPhoneNumberExecutive currently has no way of knowing that it has \nwww.EBooksWorld.ir\n", "page": 198, "type": "text", "section": "Page 198"}
{"text": "Chapter 4 ARCHITECTURE\n156\nreceived the two completion Domain Events associated with the specific, cor-\nresponding parallel processes. If many such processes were started in parallel, \nand completion Events for each were received out of order, how would the \nexecutive know which parallel process was ending? For our synthetic example, \nlogging with mismatched events is hardly tragic. But when dealing with corpo-\nrate business domains, an improperly aligned Long-Running Process could be \ndisastrous.\nThe first step in the solution to this troublesome situation is to assign a \nunique Process identity that is carried by each of the associated Domain Events. \nThis could be the same identity assigned to the originating Domain Event that \ncauses the Long-Running Process to begin (for example, AllPhoneNumbers-\nListed). We could use a universally unique identifier (UUID) allocated spe-\ncifically to the Process. See Entities (5) and Domain Events (8) for a discussion \nof providing unique identity. The PhoneNumberExecutive would now write \noutput to the log only upon receiving completion Events with equal identities. \nHowever, we can\u2019t expect the executive to wait around until all the completion \nEvents are received. It, too, is an Event subscriber that comes and goes with the \nreceipt and handling of each delivery.\nExecutive and Tracker?\nSome find that merging the concepts of executive and tracker into a single \nobject\u2014an Aggregate\u2014to be the simplest approach. Implementing such an \nAggregate as a part of the domain model that naturally tracks just a part of \nthe overall Process can be a liberating technique. For one, we avoid devel-\noping a separate tracker as state machine, in addition to the Aggregates that \nmust also exist. In fact, the most basic Long-Running Processes are best \nimplemented just that way.\nIn a Hexagonal Architecture, a Port-Adapter message handler would sim-\nply dispatch to an Application Service (or Command Handler), which would \nload the target Aggregate and delegate to its appropriate command method. \nSince the Aggregate would in turn fire a Domain Event, the Event would be \npublished in part as an indication that the Aggregate has completed its role \nin the Process.\nThis approach closely follows that promoted by Pat Helland, which he refers \nto as partner activities [Helland], and is the second approach described in \nthe sidebar \u201cDifferent Ways to Design a Long-Running Process.\u201d Ideally, \nhowever, discussing a separate executive and tracker is a more effective \nway to teach the overall technique, and a more intuitive way to learn it.\nwww.EBooksWorld.ir\n", "page": 199, "type": "text", "section": "Page 199"}
{"text": " \nEVENT-DRIVEN ARCHITECTURE\n157\nIn an actual domain each instance of a Process executive creates a new \nAggregate-like state object for tracking its eventual completion. The state \nobject is created when the Process begins, associating the same unique identity \nthat each related Domain Event must carry. It may also be useful for it to hold \na timestamp of when the Process began (the reasons are discussed later in the \nchapter). The Process state tracker object is illustrated in Figure 4.10.\nAs each pipeline in the parallel processing completes, the executive receives \na corresponding completion Event. The executive retrieves the state tracking \ninstance by matching the unique Process identity carried by the received Event \nand sets a property that represents the step just completed.\nThe Process state instance usually has a method such as isCompleted().\nAs each step is completed and recorded on this state tracker, the executive \nchecks isCompleted(). This method checks for the recorded completion of \nall required parallel processes. When the method answers true, the executive \nhas the option to publish a final Domain Event if required by the business. \nThis Event could be required if the completing Process is just a branch in a \nlarger parallel process, for example.\nA given messaging mechanism may lack features that guarantee single deliv-\nery of each Event.7 If it is possible for the messaging mechanism to deliver a \nDomain Event message two or more times, we can use the Process state object \nto de-duplicate. Does this require special features to be provided by the mes-\nsaging mechanism? Consider how it can be handled without them.\n 7. This does not mean guaranteed delivery, but guaranteed single delivery, or once \nand only once.\nchecks and\nupdates\nreads\nlogs\nreceived by\nreceived by\n<<event>>\nMatchedPhoneNumbersCounted\n<<event>>\nAllPhoneNumbersCounted\n<<saga state>>\nPhoneNumberStateTracker\n+hasTimedOut()\n+isCompleted()\n+totalMatchedPhoneNumbers()\n+totalPhoneNumberCount()\nPhoneNumberExecutive\nFigure 4.10 A PhoneNumberStateTracker serves as a Long-Running Process state object \nto track progress. The tracker is implemented as an Aggregate.\nwww.EBooksWorld.ir\n", "page": 200, "type": "text", "section": "Page 200"}
{"text": "Chapter 4 ARCHITECTURE\n158\nWhen each completion Event is received, the executive checks the state \nobject for an existing record of completion for that specific Event. If the \ncompletion indicator is already set, the Event is considered a duplicate and is \nignored, yet acknowledged.8 Another option is to design the state object to be \nidempotent. That way, if duplicate messages are received by the executive, the \nstate object absorbs the duplicate occurrence recordings equally. While only \nthe second option designs the state tracker itself as idempotent, both of these \napproaches support idempotent messaging. See Domain Events (8) for further \ndiscussion of Event de-duplication.\nSome Process completion tracking may be time-sensitive. We can deal with \nProcess time-outs passively or actively. Recall that the Process state tracker \ncan hold a timestamp of its inception. Add to this a total allowable time con-\nstant (or configuration) value and the executive can manage time-sensitive \nLong-Running Processes.\nA passive time-out check is performed each time a parallel processing com-\npletion Event is received by the executive. The executive retrieves the state \ntracker and asks it if a time-out has occurred. A method such as hasTimed-\nOut() can serve that purpose. If the passive time-out check indicates that the \nallowable time threshold has been exceeded, the Process state tracker can be \nmarked as abandoned. It\u2019s also possible to publish a corresponding failure \nDomain Event. Note that a disadvantage of the passive time-out check is that \nthe Process could remain active well past its threshold if one or more com-\npletion Events are for some reason never received by the executive. This may \nbe unacceptable if a larger parallel process is dependent on certain success or \nfailure of this Process.\nAn active Process time-out check can be managed using an external timer. \nFor example, a JMX TimerMBean instance is one way to get a Java-managed \ntimer. The timer is set for the maximum time-out threshold just as the Process \nbegins. When the timer fires, the listener accesses the Process state tracker. If \nthe state is not already completed (always checked in case the timer fires just as \nan asynchronous Event completes the Process), it is then marked as abandoned, \nand a corresponding failure Event is published. If the state tracker is marked as \ncompleted prior to the timer firing, the timer can then be terminated. One dis-\nadvantage of the active time-out check is that it requires more system resources, \nwhich may burden a high-traffic environment. Also, a race condition between \nthe timer and the arriving completion Event could incorrectly cause failure.\n 8. When the messaging mechanism finally receives acknowledgment of receipt, the \nmessage will not be delivered again.\nwww.EBooksWorld.ir\n", "page": 201, "type": "text", "section": "Page 201"}
{"text": " \nEVENT-DRIVEN ARCHITECTURE\n159\nLong-Running Processes are often associated with distributed parallel pro-\ncessing but have nothing to do with distributed transactions. They require a \nmindset that embraces eventual consistency. We must enter any effort to design \na Long-Running Process soberly, with the expectation that when infrastruc-\nture or the tasks themselves fail, well-designed error recovery is essential. Every \nsystem participating in a single instance of a Long-Running Process must be \nconsidered inconsistent with all other participants until the executive receives \nthe final completion notification. True, some Long-Running Processes may be \ncapable of succeeding with only partial completion, or they may delay for even \na number of days before full completion. But if the Process runs aground and \nthe participating systems are left in inconsistent states, compensation may be \nnecessary. If compensation is mandatory, it could surpass the complexity of \ndesigning the success path. Perhaps business procedures could allow for fail-\nures and offer workflow solutions instead.\nThe SaaSOvation teams employ an Event-Driven Architec-\nture across Bounded Contexts, and the ProjectOvation team \nwill use the simplest form of a Long-Running Process to \nmanage the creation of Discussions assigned to Product\ninstances. The overarching style is Hexagonal to manage the \noutside messaging and publishing of Domain Events around \nthe enterprise.\nNot to be overlooked is that the Long-Running Process executive can pub-\nlish one, two, or more Events to initiate the parallel processing. There may \nalso be not only two, but three or more subscribers to any initiating Event \nor Events. In other words, a Long-Running Process may lead to many sepa-\nrate business process activities executing simultaneously. Thus, our synthetic \nexample is limited in complexity only for the sake of communicating the basic \nconcepts of a Long-Running Process.\nLong-Running Processes are often useful when integration with legacy sys-\ntems can have high latency. Even if latency and legacy are not the chief con-\ncerns, we still benefit from the distribution and parallelism with elegance, \nwhich can lead to highly scalable, highly available business systems.\nSome messaging mechanisms have built-in support for Long-Running Pro-\ncesses, which can greatly expedite adoption. One such is [NServiceBus], which \nspecifically calls them Sagas. Another Saga implementation is provided with \n[MassTransit].\nwww.EBooksWorld.ir\n", "page": 202, "type": "text", "section": "Page 202"}
{"text": "Chapter 4 ARCHITECTURE\n160\nEvent Sourcing\nSometimes the business cares about tracking changes that occur to the objects \nin a domain model. There are varying levels of change tracking interest, and \nways to support each level. Typically businesses have chosen to track only when \nsome entity is created and last modified, and by whom. It\u2019s a relatively simple \nand straightforward approach to change tracking. This, however, doesn\u2019t pro-\nvide any information about the individual changes in the model.\nWith an increased desire for even more change tracking, the business \ndemands more metadata. It begins to care also about the individual operations \nthat were executed over time. Maybe it even wants to understand how long \ncertain operations took to execute. Those desires lead to the need to main-\ntain an audit log or journal of the finer-grained use case metrics. But an audit \nlog or journal has its limitations. It can convey some information about what \nhas happened in the system, perhaps even allowing for some debugging. But it \ndoesn\u2019t allow us to examine the state of individual domain objects before and \nafter specific kinds of changes. What if we could stretch more out of change \ntracking?\nAs developers we have all experienced finer-grained change tracking in one \nform or another. The most common example is with the use of a source code \nrepository, such as CVS, Subversion, Git, or Mercurial. What all of these vari-\nations of source revision management systems have in common is that they all \nknow how to track changes that occur on a source file. The change tracking \nprovided by this genre of tool enables us to go all the way back in time, to view \na source code artifact from its very first revision, and then to proceed revision \nby revision, all the way to the very latest. When committing all source files to \nrevision control, it can track changes of the whole development life cycle.\nNow, if we think about applying this concept to a single Entity, then to \nan Aggregate, then to every Aggregate in the model, we can understand the \npower of change tracking objects and the value it can produce in our systems. \nWith that in mind, we want to develop a means to know what occurred in the \nmodel to cause the creation of any given Aggregate instance, and also what \nhas happened to that given Aggregate instance throughout time, operation by \noperation. Given the history of everything that\u2019s happened, we could even sup-\nport temporal models. This level of change tracking is at the heart of a pattern \nnamed Event Sourcing.9 Figure 4.11 shows a high-level view of this pattern.\nThere are varying definitions of Event Sourcing, so some clarification is fit-\nting. We are discussing the use where every operational command executed \n 9. A discussion of Event Sourcing generally requires an understanding of CQRS, \nwhich is treated in the earlier section on that topic.\nwww.EBooksWorld.ir\n", "page": 203, "type": "text", "section": "Page 203"}
{"text": " \nEVENT-DRIVEN ARCHITECTURE\n161\non any given Aggregate instance in the domain model will publish at least one \nDomain Event that describes the execution outcome. Each of the events is saved \nto an Event Store (8) in the order in which it occurred. When each Aggregate \nis retrieved from its Repository, the instance is reconstituted by playing back \nthe Events in the order in which they previously occurred.10 In other words, \nfirst the very earliest Event is played back, and the Aggregate applies the Event \nto itself, modifying its state. Next, the second-oldest Event is played back in \nthe same manner. This continues until all Events, from the oldest to the most \nrecent, are completely played back and applied. At that point the Aggregate \nexists in the state it had upon the most recent execution of some command \nbehavior.\nA Moving Target?\nThe definition of Event Sourcing has undergone some scrutiny and refinement, and \nat the time of writing it is still not completely settled. As with most leading-edge \ntechniques, refinement is necessary. What is described here captures the essence of \nthe pattern as applied using DDD and probably to a large degree reflects how in gen-\neral it will be used moving forward.\nOver a long period of changes to any and all Aggregate instances, doesn\u2019t \nthe playback of hundreds, thousands, or even millions of Events cause serious \nlatency and overhead in processing the model? At least for some of the higher-\ntraffic models that would most certainly be the case.\nTo avoid this bottleneck we can apply an optimization that uses Aggre-\ngate state snapshots. A process is developed to produce, in the background, a \n10. The Aggregate state is a conflation of previous Events, but only by applying them \nin the same order in which they occurred.\nfinds aggregate instance using\nread by\napplied to\nexecutes\ncommand on\nreceived by\npublishes\nstores\nClient\nEvent\nEvent\nEvent\nEvent Store\nAggregate\nRepository\nEventsPersisterSubscriber\nFigure 4.11 A high-level view of Event Sourcing, where Aggregates publish Events \nthat are stored and used to track the model\u2019s state changes. The Repository reads \nEvents from the Store and applies them to reconstitute the Aggregate\u2019s state.\nwww.EBooksWorld.ir\n", "page": 204, "type": "text", "section": "Page 204"}
{"text": "Chapter 4 ARCHITECTURE\n162\nsnapshot of the Aggregate\u2019s in-memory state at a specific point in Event Store \nhistory. To do this, the Aggregate is loaded into memory using all previous \nEvents to the current point in time. The Aggregate state is then serialized, and \nthe serialized snapshot image is then saved to the Event Store. From that point \nforward the Aggregate is first instantiated using the most recent snapshot, and \nthen all Events newer than that snapshot are played back on the Aggregate as \ndescribed previously.\nSnapshots are not created randomly. Rather, they can be created at points \nwhere a predefined number of newer Events have occurred. The team would \ndetermine a number based on domain heuristics or other observations. For \nexample, we might find that Aggregate retrieval performs optimally when hav-\ning no more than 50 or 100 or so Events between snapshots.\nEvent Sourcing leans heavily in the direction of technical solution. We can \nproduce domain models that publish Domain Events without the need to sup-\nport Event Sourcing. As a persistence mechanism, Event Sourcing replaces and \nis far different from using an ORM tool. Because Events are often persisted \nin an Event Store as binary representations, they cannot (optimally) be used \nfor queries. In fact, Repositories designed for an Event Sourcing model require \nonly a single get/find operation, and that method takes as a parameter only the \nAggregate unique identity. Further, by design Aggregates don\u2019t have any query \nmethods (getters). As a result, we need another way to query, which gener-\nally leads to employing CQRS (discussed previously) hand-in-glove with Event \nSourcing.11\nSince Event Sourcing leads us down the path of thinking differently about \nthe way domain models are designed, we need to justify our use. At its most \nbasic, Event history can reveal solutions to bugs in the system. Debugging with \nthe use of explicit history of everything that has ever happened to the model \nhas a big advantage. Event Sourcing can lead to high-throughput domain mod-\nels, scaling to extremely large numbers of transactions per second. Appending \nto a single database table, for example, is extremely fast. Further, it enables \nthe CQRS query model to be scaled out, because updates to that data source \nare performed in the background after the Event Store is updated with new \nEvents. This can additionally allow for replicating the query model to more \ndata source instances in support of growing numbers of clients.\nBut technical advantages don\u2019t always sell techniques to the business. Thus, \nconsider just a few of the business advantages of using Event Sourcing that are \nafforded due to the technical implementation:\n \n11. Although we can use CQRS without using Event Sourcing, the opposite is not usu-\nally practical.\nwww.EBooksWorld.ir\n", "page": 205, "type": "text", "section": "Page 205"}
{"text": " \nDATA FABRIC AND GRID-BASED DISTRIBUTED COMPUTING\n163\n\u2022 Patch the Event Store with new or modified Events that fix problems. This \nmay have business implications, but if it is legal in a given situation, the \npatch can save the system from serious issues that occurred because of \nbugs in the model. Since the patches have a built-in audit trail, the use of \npatches may decrease any legal implications by making them explicit and \ntraceable.\n\u2022 Besides patching, we can also undo and redo changes in the model by \nreplaying varying sets of Events. This may have technical implications \nand business implications and may not be possible to support in all cases.\n\u2022 With an accurate history of everything that has occurred in the domain \nmodel, the business can consider \u201cwhat if?\u201d questions. That is, by playing \nback stored Events on a set of Aggregates that have experimental enhance-\nments, the business can get accurate answers to hypothetical questions. \nWould the business benefit if it could simulate conceptual scenarios using \nreal historical data? Very likely, yes. It\u2019s an alternative way to approach \nbusiness intelligence.\nWould the business benefit from one or more of these technical and nontechni-\ncal advantages?\nAppendix A provides rich details on implementing Aggregates with Event \nSourcing and discusses how views may be projected for CQRS. For further \ndetails see [Dahan, CQRS] and [Nijof, CQRS].\nData Fabric and Grid-Based Distributed Computing\nContributed by Wes Williams\nAs software systems become more and more complex and sophisticated, with \nexpanding user bases and requirements centered around \u201cbig data,\u201d traditional \ndatabase solutions can become performance bottlenecks. Organizations that \nface the realities of information systems of colossal size have no alternative \nbut to seek solutions that are equal to the computing challenges. Data Fab-\nrics\u2014also sometimes called Grid Computing12\u2014offer performance and elastic \nscalability capabilities that such business situations demand.\n12. This is not to say that Fabrics and Grids are identical concepts, but for those look-\ning at this architecture in a general way these labels often mean the same thing. \nCertainly marketing and sales often limit them to the same meaning. In any case, \nthis section uses the term Data Fabric since it generally represents a richer set of \ncapabilities than Grid Computing.\nwww.EBooksWorld.ir\n", "page": 206, "type": "text", "section": "Page 206"}
{"text": "Chapter 4 ARCHITECTURE\n164\nCowboy Logic \nAJ:  \n\u201cWould you like some information in exchange for a \ndrink?\u201d\nLB:  \n\u201cSorry, J. We only accept cache here.\u201d\nOne good thing about Data Fabrics is that they support domain models in a \nnatural way, nearly eliminating any impedance mismatch. In fact, their distrib-\nuted caches easily accommodate the persistence of domain objects in general \nand act as Aggregate Stores specifically.13 Simply stated, an Aggregate stored \nin a Fabric\u2019s map-based cache14 is the value part of a key-value pair. The key is \nformed from the globally unique identity of the Aggregate, and the Aggregate \nstate itself is serialized to some binary or textual representation serving as the \nvalue:\nString key = product.productId().id();\nbyte[] value = Serializer.serialize(product);\n// region (GemFire) or cache (Coherence)\nregion.put(key, value);\nThus, a positive consequence of using a Data Fabric with features closely \naligned with the technical aspects of a domain model is the possibility of short-\nened development cycles.15\nThe examples provided in this section demonstrate how a Data Fabric can \nhost a domain model in cache and enable system functionalities at distributed \nscale. In doing so, we\u2019ll explore ways to support the CQRS architecture pat-\ntern and Event-Driven Architecture using Long-Running Processes.\nData Replication\nThinking of an in-memory data cache, we may immediately consider the real \npossibility of losing all or part of our system\u2019s state if the cache fails in some \n13. Martin Fowler has recently promoted the term Aggregate Store, although the con-\ncept has existed for some time.\n \n14. In GemFire this is called a region, but it\u2019s the same concept that Coherence calls a \ncache. I use cache for consistency.\n15. Some NoSQL stores likewise act as natural \u201cAggregate Stores,\u201d simplifying tech-\nnical aspects of implementing DDD.\nwww.EBooksWorld.ir\n", "page": 207, "type": "text", "section": "Page 207"}
{"text": " \nDATA FABRIC AND GRID-BASED DISTRIBUTED COMPUTING\n165\nway. It\u2019s a real concern, but far from troublesome when redundancy is built \ninto the Fabric.\nConsider the memory cache provided by a Fabric when using a cache-per- \nAggregate strategy. In that case the Repository of a given Aggregate type is \nbacked by a dedicated cache. A cache supporting only a single node would be \nquite vulnerable to failures at a single point. However, a Fabric providing mul-\ntinode caches with replication would be quite reliable. You can choose the level \nof redundancy based on the probability of the number of nodes that may fail at \nany given time, which becomes very narrow as more nodes are included. You \nalso have the latitude to trade redundancy for performance since, of course, \nperformance can be impacted by the number of node replications required for \nan Aggregate to be fully committed.\nHere\u2019s an example of how cache (or region, again depending on the concrete \nFabric) redundancy may work. One node acts as the primary cache/region, and \nany number of others are secondary. If a primary store fails, a fail-over occurs \nand one of the secondaries becomes the new primary. When the former pri-\nmary recovers, all data stored on the new primary gets replicated to the recov-\nered node and it becomes a secondary.\nAn additional advantage of fail-over nodes is that they ensure guaranteed \ndelivery of events published from the Fabric. Thus, updates to Aggregates and \nany Fabric events published as a result are never lost. Obviously, cache redun-\ndancy and replication are essential features for storing business-critical domain \nmodel objects.\nEvent-Driven Fabrics and Domain Events\nA primary feature of a Fabric is the support of an Event-Driven style, with \nguaranteed delivery. Most Fabrics have built-in eventing of a technical nature, \nthat is, the automatic notification of events that inform about cache-level and \nentry-level occurrences. Those should not be confused with Domain Events. \nFor example, a cache-level event informs of happenings such as cache reini-\ntialization, and an entry-level event informs about occurrences such as entry \ncreation and updates.\nStill, with a Fabric supporting an open architecture there should be a way to sup-\nport publishing Domain Events directly out of Aggregates. Your Domain Events \nmay have to subclass a specific framework event type, such as  \nEntryEvent (for \nexample, GemFire), but that\u2019s a small price to pay for the power they afford.\nHow might you actually use Domain Events in a Fabric? As discussed in \nDomain Events (8), your Aggregates would use a simple DomainEvent-\nPublisher component. In the cache of a Fabric this publisher may simply put \nwww.EBooksWorld.ir\n", "page": 208, "type": "text", "section": "Page 208"}
{"text": "Chapter 4 ARCHITECTURE\n166\nthe published Events into a specific cache/region. Cached Events would then be \ndelivered to subscribers (listeners), either synchronously or asynchronously. So \nas not to waste precious memory in this dedicated Event cache/region, as each \nEvent is fully acknowledged by all subscribers, its entry would be removed \nfrom the map. Of course, each Event is only fully acknowledged once it has \nbeen published by one or more subscribers to a message queue or bus and/or \nused to freshen a CQRS query model.\nSince Domain Event subscribers may also use the Events to carry out the \nsynchronization of other dependent Aggregates, eventual consistency is guar-\nanteed by means of the architecture.\nContinuous Queries\nSome Fabrics support a kind of event notification known as Continuous Query. \nThis enables a client to register a query with the Fabric that will ensure that the \nclient receives notification of changes in the cache that satisfy the query. One \nuse of the Continuous Query is by user interface components, which enables \nthese to listen for changes that could impact the current view.\nDo you see what\u2019s coming? CQRS has a strong fit with the Continuous \nQuery feature, assuming that the query model is maintained in the Fabric. \nRather than requiring the view to chase after view table updates, the notifi-\ncations delivered as registered Continuous Queries are resolved, allowing the \nviews to update just in time. Here\u2019s an example of a client registering for Gem-\nFire Continuous Query events:\nCqAttributesFactory factory = new CqAttributesFactory();\nCqListener listener = new BacklogItemWatchListener();\nfactory.addCqListener(listener);\nString continuousQueryName = \"BacklogItemWatcher\";\nString query = \"select * from /queryModelBacklogItem qmbli \"\n        + \"where qmbli.status = 'Committed'\";\nCqQuery backlogItemWatcher = queryService.newCq(\n        continuousQueryName, query, factory.create());\nThe Data Fabric will now deliver CQRS query model updates based on Aggre-\ngate modifications to the client callback object provided by the CqListener,\nalong with metadata that was added, updated, or destroyed when the matching \ncriteria are met.\nwww.EBooksWorld.ir\n", "page": 209, "type": "text", "section": "Page 209"}
{"text": " \nDATA FABRIC AND GRID-BASED DISTRIBUTED COMPUTING\n167\nDistributed Processing\nA powerful use of a Data Fabric is to distribute processing across the Fabric\u2019s \nreplicated caches and return the aggregated results to the client. This enables \nthe Fabric to fulfill Event-Driven, distributed parallel processing, perhaps using \nLong-Running Processes.\nTo illustrate this feature, we\u2019ll have to mention some concrete approaches \nin GemFire and Coherence. Your Process executive could be implemented as \na GemFire Function or a Coherence Entry Processor. Both can serve as Com-\nmand [Gamma et al.] handlers that execute in parallel across distributed, rep-\nlicated cache. (You might instead choose to think of this concept as a Domain \nService, but what it does may not be domain-centric.) For consistency let\u2019s call \nthis feature a Function. A Function can optionally accept a filter to constrain \nthe execution against matching Aggregate instances.\nLet\u2019s look at a sample Function that implements a Long-Running Process \nfor the previously presented Phone Number Count Process. This Process will \nbe executed in parallel across the replicated cache using a GemFire Function:\npublic class PhoneNumberCountSaga extends FunctionAdapter {\n    @Override\n    public void execute(FunctionContext context) {\n        Cache cache = CacheFactory.getAnyInstance();\n        QueryService queryService = cache.getQueryService();\n        String phoneNumberFilterQuery = (String) context.getArguments();\n        ...\n        // Pseudo code\n        // - Execute Function to obtain MatchedPhoneNumbersCounted.\n        //   - Send answer to the aggregator by invoking the\n        //     aggregator.sendResult(MatchedPhoneNumbersCounted).\n        // - Execute Function to obtain AllPhoneNumbersCounted.\n        //   - Send answer to the aggregator by invoking the\n        //     aggregator.sendResult(AllPhoneNumbersCounted).\n        // - The aggregator automatically accumulates the answers\n        //   from each distributed Function call and returns the\n        //   single aggregated answer to the client.\n    }\n}\nHere is sample code for a client that will execute a Long-Running Process in \nparallel against distributed replicated cache:\nPhoneNumberCountProcess phoneNumberCountProcess =\n         new PhoneNumberCountProcess();\nwww.EBooksWorld.ir\n", "page": 210, "type": "text", "section": "Page 210"}
{"text": "Chapter 4 ARCHITECTURE\n168\nString phoneNumberFilterQuery = \n        \"select phoneNumber from /phoneNumberRegion pnr \"\n        + \"where pnr.areaCode = '303'\";\nExecution execution =\n        FunctionService.onRegion(phoneNumberRegion)\n                .withFilter(0)\n                .withArgs(phoneNumberFilterQuery)\n                .withCollector(new PhoneNumberCountResultCollector());\nPhoneNumberCountResultCollector resultCollector =\n         execution.execute(phoneNumberCountProcess);\nList allPhoneNumberCountResults = (List) resultsCollector.getResult();\nOf course, the process could be much more complex or far simpler than this \none. This also demonstrates that a Process is not of necessity an Event-Driven \nconcept, but one that can work with other concurrent, distributed processing \napproaches. For a full discussion of Fabric-based distributed and parallel pro-\ncessing, see [GemFire Functions].\nWrap-Up\nWe\u2019ve reviewed several architectural styles and architecture patterns that can \nbe used with DDD. This is not an exhaustive list because there are just too \nmany possibilities, which emphasizes the versatility of DDD. For example, we \nhaven\u2019t considered how to apply DDD when Map-Reduce is at play. That\u2019s a \ntopic for a future discussion.\n\u2022 We\u2019ve discussed the traditional Layers Architecture and how it can be \nimproved on by using the Dependency Inversion Principle.\n\u2022 You\u2019ve learned about the strengths of the possibly timeless Hexago-\nnal Architecture, which provides an overarching style for application \narchitectures.\n\u2022 We\u2019ve emphasized how DDD should be used in an SOA environment, \nwith REST, and using a Data Fabric or a Grid-Based Distributed Cache.\nwww.EBooksWorld.ir\n", "page": 211, "type": "text", "section": "Page 211"}
{"text": " \nWRAP-UP\n169\n\u2022 You got an overview of CQRS and how it can simplify some aspects of \nthe application.\n\u2022 We\u2019ve taken a look at the various aspects of how Event-Driven works, \nincluding Pipes and Filters, Long-Running Processes, and even a glimpse \nat Event Sourcing.\nWe next move on to a series of chapters on DDD tactical modeling. Those \nchapters will help you see the finer-grained modeling options at your disposal, \nand how to best put them to work.\nwww.EBooksWorld.ir\n", "page": 212, "type": "text", "section": "Page 212"}
{"text": "This page intentionally left blank \nwww.EBooksWorld.ir\n", "page": 213, "type": "text", "section": "Page 213"}
{"text": "171\nChapter 5\nEntities\nI\u2019m Chevy Chase . . . and you\u2019re not.\n\u2014Chevy Chase\nThere is a tendency for developers to focus on data rather than the domain. \nThis can happen with those new to DDD, because of the prevailing approaches \nto software development that place importance on the database. Instead of \ndesigning domain concepts with rich behaviors, we might think primarily about \nthe attributes (columns) and associations (foreign keys) of the data. Doing so \nreflects the data model into object counterparts, which leads to almost every \nconcept in our \u201cdomain model\u201d being coded as an Entity abounding with get-\nter and setter methods. It\u2019s easy to find tools that will generate all that for us. \nAlthough there may be nothing wrong with property accessors, that\u2019s not the \nonly behavior DDD Entities should have.\nIt\u2019s a trap that was sprung on SaaSOvation developers. Learn from their \nlessons in Entity design.\nRoad Map to This Chapter\n\u2022 Consider why Entities have their proper place when we need to model unique \nthings.\n\u2022 See how unique identities may be generated for Entities.\n\u2022 Look in on a design session as a team captures its Ubiquitous Language \n(1) in Entity design.\n\u2022 Learn how you can express Entity roles and responsibilities.\n\u2022 See examples of how Entities can be validated and how to persist them to \nstorage.\nWhy We Use Entities\nWe design a domain concept as an Entity when we care about its individu-\nality, when distinguishing it from all other objects in a system is a manda-\ntory constraint. An Entity is a unique thing and is capable of being changed \nwww.EBooksWorld.ir\n", "page": 214, "type": "text", "section": "Page 214"}
{"text": "Chapter 5 ENTITIES\n172\ncontinuously over a long period of time. Changes may be so extensive that the \nobject might seem much different from what it once was. Yet, it is the same \nobject by identity.\nAs the object changes, we may be interested in tracking when, how, and \nby whom changes were made. Or we might be satisfied that its current form \nimplies enough about its previous state transitions that explicit change tracking \nis unnecessary. Even if we don\u2019t decide to track every detail of its change his-\ntory, we could still reason on and discuss the sequences of valid changes that \ncould occur to these objects over their entire lifetime. It is the unique identity \nand mutability characteristics that set Entities apart from Value Objects (6).\nThere are times when an Entity is not the appropriate modeling tool to \nreach for. Misappropriated use happens far more often than many are aware. \nOften a concept should be modeled as a Value. If this is a disagreeable notion, \nit might be that DDD doesn\u2019t fit your business needs. It is quite possible that \na CRUD-based system would be more fitting. If so, that decision should save \nyour project both time and money. The problem is that pursuing CRUD-based \nalternatives doesn\u2019t always save those precious resources.\nBusinesses regularly put too much effort into developing glorified database \ntable editors. Without the correct tool selection, CRUD-based solutions treated \nelaborately are too expensive. When CRUD makes sense, languages and frame-\nworks such as Groovy and Grails, Ruby on Rails, and the like make the most \nsense. If the choice is correct, it should save time and money.\nCowboy Logic \nAJ:  \n\u201cWhat kinda CRUD did I just land in?\u201d\nLB:  \n\u201cThat\u2019s a cow pie, J!\u201d\nAJ:  \n\u201cI know what pie is. You got your apple pie and your \ncherry pie. This ain\u2019t no pie.\u201d\nLB:  \n\u201cLike they say, \u2018Never kick a cow pie on a hot day.\u2019 \nIt\u2019s a good thing you didn\u2019t kick it.\u201d\nOn the other hand, if we apply CRUD to the wrong systems\u2014more complex \nones that deserve the precision of DDD\u2014we may regret it. When complex-\nity grows, we experience the limitation of poor tool selection. CRUD systems \ncan\u2019t produce a refined business model by only capturing data.\nIf DDD is a justifiable investment in the business\u2019s bottom line, we use Enti-\nties as intended.\nWhen an object is distinguished by its identity, rather than its attributes, make \nthis primary to its definition in the model. Keep the class definition simple and \nwww.EBooksWorld.ir\n", "page": 215, "type": "text", "section": "Page 215"}
{"text": " \nUNIQUE IDENTITY\n173\nfocused on life cycle continuity and identity. Define a means of distinguishing \neach object regardless of its form or history. . . . The model must define what it \nmeans to be the same thing. [Evans, p. 92]\nThis chapter teaches how to place the proper emphasis on Entities and \nshows you various Entity design techniques.\nUnique Identity\nIn the early stages of designing an Entity, we purposely focus only on those \nprimary attributes and behaviors that are central to its unique identity, as well \nas those useful for querying it, and we purposely ignore all other attributes and \nbehaviors until we settle on the primary ones.\nRather than focusing on the attributes or even the behavior, strip the Entity \nobject\u2019s definition down to the most intrinsic characteristics, particularly those \nthat identify it or are commonly used to find or match it. Add only behavior \nthat is essential to the concept and attributes that are required by that behavior.  \n[Evans,  p. 93]\nSo that\u2019s what we\u2019ll do first. Having a range of available options for imple-\nmenting identity is really important, as are those for ensuring that the unique-\nness is preserved throughout time.\nAn Entity\u2019s unique identity may or may not also be practical for finding \nor matching. Using the unique identity for matching usually depends on how \nhuman-readable it is. For example, if the application makes searching for a \nperson\u2019s name available to users, it is very unlikely that the name is used as the \nPerson Entity unique identity. People very frequently have nonunique names. \nOn the other hand, if the application makes searching for a company\u2019s tax ID \npossible, the tax ID may well be the primary unique identifier for the  \nCompany\nEntity. Governments issue unique tax identities.\nValue Objects can serve as holders of unique identity. They are immutable, \nwhich ensures identity stability, and any behavior specific to the kind of iden-\ntity is centralized. Having a focal point for identity behavior, however sim-\nple, keeps the know-how from leaking into other parts of the model and into \nclients.\nConsider some common identity creation strategies, from the apparently \nsimplest and most basic to those with increasing complexity:\n\u2022 The user provides one or more original unique values as input to the \napplication. The application must ensure that they are unique.\nwww.EBooksWorld.ir\n", "page": 216, "type": "text", "section": "Page 216"}
{"text": "Chapter 5 ENTITIES\n174\n\u2022 The application internally generates an identity using an algorithm that \nensures uniqueness. We can get a library or framework to do this for us, \nbut it can be done by the application.\n\u2022 The application relies on a persistence store, such as a database, to gener-\nate a unique identity.\n\u2022 Another Bounded Context (2) (system or application) has already deter-\nmined the unique identity. It is input or selected by the user from a set of \nchoices.\nLet\u2019s consider the individual strategies, along with particular challenges \nrelated to each. There are almost always side effects when considering the \nrange of technical solutions. One such side effect occurs when we use rela-\ntional databases for object persistence, which leak into our domain models. \nWe round out identity creation concerns by addressing the impact of the timing \nof identity generation, the relational database\u2019s referential identity on domain \nobjects, and how object-relational mapping (ORM) plays into this situation. \nWe\u2019ll also consider some practical guidance on keeping unique identities stable.\nUser Provides Identity\nIt appears to be a straightforward approach to have a user manually enter the \ndetails of unique identity. The user types a recognizable value or symbol into \nan input field or selects from a set of available characteristics, and the Entity is \ncreated. True, it is a simple enough approach. But there can be complications.\nOne complication is relying on users to produce quality identities. The iden-\ntity may be unique but incorrect. Most times identities must be immutable, \nso users shouldn\u2019t change them. This is not always the case, and there may be \nadvantages to enabling users to correct identity values. Here\u2019s an example. If \nwe use the titles of Forum and Discussion as unique identities, what would \nhappen if the user spelled the title incorrectly, or later decided that the title \nwas not as fitting as it could have been, as shown in Figure 5.1? What\u2019s the \ncost of change? Although user-provided identity may seem like a well-budgeted \napproach, it may not be. Can users be relied upon to produce both unique and \ncorrect, long-lasting identities?\nPreventing this problem starts with design discussions. Teams need to con-\nsider fail-proof approaches to enable users to define unique identity. Work-\nflow-based identity approval is not conducive to high-throughput domains but \nworks best when human-readable identity is a must. If it takes extra time and \neffort to create and approve an identity that will be used pervasively throughout \nwww.EBooksWorld.ir\n", "page": 217, "type": "text", "section": "Page 217"}
{"text": " \nUNIQUE IDENTITY\n175\nthe business for years to come, and supporting a workflow is possible, adding a \nfew extra cycles to ensure the quality of the identity is a good investment.\nWe always have the option to include user-entered values as Entity prop-\nerties available for matching, but not to use them for unique identity. Simple \nproperties are more easily modified as part of the normal operational state \nof the Entity that changes over time. In that case we will need to use another \nmeans to obtain unique identity.\nApplication Generates Identity\nThere are highly reliable ways to autogenerate unique identities, although care \nmust be taken when the application is clustered or otherwise distributed across \nmultiple computing nodes. There are identity creation patterns that can, to a \nmuch greater degree of certainty, produce a completely unique identity. The \nuniversally unique identifier (UUID), or globally unique identifier (GUID), is \none such approach. A common variation follows, where the result of each step \nis concatenated into a single textual representation:\n 1. Time in milliseconds on the computing node\n 2. IP address of the computing code\n 3. Object identity of the factory object instance within the virtual machine \n(Java)\n 4. Random number generated by the same generator within the virtual \nmachine (Java)\nThis produces a 128-bit unique value. It is most often expressed as a 32-byte \nor 36-byte hexadecimal encoded text string. The text format is 36 bytes when \nyou use the common hyphen segment separators in the format f36ab21c-\n67dc-5274-c642-1de2f4d5e72a. Without the hyphens it is 32 bytes. Either \nway, the identity is big and is not considered human-readable.\nNew Forum\nForum Title:\nOK\nCancel\nUneck Identity & User Inpt\nx\nNew Discussion\nDiscussion Title:\nOK\nCancel\nids and stuff\nx\nFigure 5.1 The forum title is misspelled and the discussion title is less than desirable.\nwww.EBooksWorld.ir\n", "page": 218, "type": "text", "section": "Page 218"}
{"text": "Chapter 5 ENTITIES\n176\nIn the Java world, this formula has been replaced by a standard UUID gen-\nerator available since Java 1.5. It\u2019s provided by class java.util.UUID. This \nimplementation supports four different generator algorithms based on the \nLeach-Salz variant. Using the Java standard API, we can easily generate a pseu-\ndo-random unique identity:\nString rawId = java.util.UUID.randomUUID().toString();\nIt uses type 4, employing a cryptographically strong pseudo-random-number \ngenerator, which is based on the java.security\n.SecureRandom generator. \nType 3 employs a name encryption approach, which uses java.security\n.MessageDigest. We can get a name-based UUID like this:\nString rawId = java.util.UUID.nameUUIDFromBytes(\n        \"Some text\".getBytes()).toString();\nWe can also blend the pseudo-random-number generation with encryption:\nSecureRandom randomGenerator = new SecureRandom();\nint randomNumber = randomGenerator.nextInt();\nString randomDigits = new Integer(randomNumber).toString();\nMessageDigest encryptor = MessageDigest.getInstance(\"SHA-1\");\nbyte[] rawIdBytes = encryptor.digest(randomDigits.getBytes());\nNow we are left only with the task of converting the rawIdBytes array to \na hexadecimal text representation. We could get that conversion for free. After \ngenerating the random number and converting it to a String, we pass that \ntext to the UUID nameUUIDFromBytes() Factory [Gamma et al.] method.\nThere are other identity generation facilities, such as java.rmi.server\n.UID and java.rmi.dgc.VMID, but these seem inferior to java.util.UUID\nand are not discussed here.\nUUID is a relatively fast identity to generate, requiring no interaction with \nthe outside, such as a persistence mechanism. Even if a specific kind of Entity is \ncreated many times per second, the UUID generator can keep up the pace. For \nhigher-performance domains we can cache any number of UUID instances, \nrefilling the cache in the background. If cached UUID instances are lost due \nto server restart, there are no gaps in identities because they are all based on \nrandom, manufactured values. Refilling the cache on server restart has no neg-\native consequences of abandoned values.\nwww.EBooksWorld.ir\n", "page": 219, "type": "text", "section": "Page 219"}
{"text": " \nUNIQUE IDENTITY\n177\nWith such a large identity, its use could in rare cases be rendered imprac-\ntical because of the memory overhead. In such cases an 8-byte long identity \ngenerated by the persistence mechanism would improve matters. A smaller, \n4-byte integer, with two billion or so unique values, may even suffice. These \napproaches are discussed next.\nConsidering the following, understandably we don\u2019t normally want to dis-\nplay a UUID on our user interface views:\nf36ab21c-67dc-5274-c642-1de2f4d5e72a\nA full UUID is usually appropriate when it can be hidden from users and \nhuman-readable reference techniques can be used. For example, we can design \nhypermedia resources with URIs that can be e-mailed or sent around using \nother user-to-user messaging. The text relationship part of the link can be used \nto disguise the mysterious-looking UUID, just as the text in <a>text</a>\ndisguises technical links in HTML.\nDepending on the level of trust you have in the uniqueness of individual seg-\nments of the hexadecimal text UUID, you may decide to use just one or a few \nsegments of the whole. The shortened identities are more trustworthy when \nused only as the local identity of Entities within the Aggregate (10) bound-\nary. Local identity means that Entities held inside an Aggregate need only have \nuniqueness among other Entities held inside the same Aggregate. On the other \nhand, the Entity serving as an Aggregate Root requires global unique identity.\nOur own identity generator could use one or more specific UUID segments. \nConsider a contrived example: APM-P-08-\n14-2012-F36AB21C. This 25-character \nidentity represents a Product (P) from the Agile Project Management Context\n(APM) that was created on August 14, 2012. The extra text F36AB21C is the first \nsegment of a generated UUID, which uniquely sets it apart from other Product\nEntities created on the same day. It has the benefit of human readability with \na high probability for global uniqueness. Users aren\u2019t the only ones to benefit. \nWhen identities such as this one are passed between Bounded Contexts, devel-\nopers immediately know where they originated. For SaaSOvation this approach \ncould be practical since Aggregates are further segregated by tenancy.\nMaintaining this kind of identity in a String would probably not be a \ngood choice. A custom identity Value Object would work better:\nString rawId = \"APM-P-08-14-2012-F36AB21C\"; // would be generated\nProductId productId = new ProductId(rawId);\n...\nDate productCreationDate =  productId.creationDate();\nwww.EBooksWorld.ir\n", "page": 220, "type": "text", "section": "Page 220"}
{"text": "Chapter 5 ENTITIES\n178\nA client can ask for identity details, such as the date the product was cre-\nated, and it\u2019s conveniently provided. Clients need not understand the raw iden-\ntity format. Now the Product Aggregate Root can expose its creation date \nwithout indicating to clients how it is obtained:\npublic class Product extends Entity {\n    private ProductId productId;\n    ...\n    public Date creationDate() {\n        return this.productId().creationDate();\n    }\n    ...\n}\nYou may find identity generation in third-party libraries and frameworks. \nThe Apache Commons project has a Commons Id (sandbox) component, \nwhich supplies five different identity generators.\nSome persistence stores, such as NoSQL Riak and MongoDB, can generate \nidentities for you. Normally to save a value in Riak, you use HTTP PUT, which \ntakes a key:\nPUT /riak/bucket/key\n[object serialization]\nYou may instead use POST without providing a key, forcing Riak to generate a \nunique identity. Still, we do need to think about early versus late identity gener-\nation, as discussed later in this chapter.\nWhat will serve as a Factory for your application-generated identities? For \nAggregate Root identity generation, I like to use its Repository (12):\npublic class HibernateProductRepository\n        implements ProductRepository  {\n    ...\n    public ProductId nextIdentity() {\n        return new ProductId(\n                java.util.UUID.randomUUID().toString().toUpperCase());\n    }\n    ...\n}\nThis seems like a natural location for identity generation.\nwww.EBooksWorld.ir\n", "page": 221, "type": "text", "section": "Page 221"}
{"text": " \nUNIQUE IDENTITY\n179\nPersistence Mechanism Generates Identity\nDelegating the generation of unique identity to a persistence mechanism has \nsome unique advantages. If we call on the database for a sequence or incre-\nmenting value, it will always be unique.\nDepending on the range needed, the database can generate a unique \n2-byte, 4-byte, or 8-byte value. In Java, a 2-byte short integer would allow \nfor up to 32,767 unique identities; a 4-byte normal integer would afford \n2,147,483,647 unique values; and an 8-byte long integer would provide up to \n9,223,372,036,854,775,807 distinct identities. Even zero-filled text represen-\ntations of these ranges are narrow, at five, ten, and 19 characters respectively. \nThese can also be employed to create composite identities.\nOne possible downside is performance. It can take significantly longer to go \nto the database to get each value than to generate identities in the application. \nMuch depends on database load and application demand. One way around this \nis to cache sequence/increment values in the application, such as in a Repos-\nitory. This can work well, but we generally count on losing a good number \nof unused values when server nodes must be restarted. If the gaps caused by \nlost cache are unacceptable, or if you have planned for only a relatively small \nnumber of values (2-byte short integer), caching preallocated values may not be \na practical or necessary option. It may be possible to harvest and recover lost \nidentities, but that may be more trouble than it is worth.\nPreallocation and caching are not an issue if the model can suffice with late \nidentity generation. Here\u2019s how it\u2019s done with Hibernate and an Oracle sequence:\n<id name=\"id\" type=\"long\" column=\"product_id\">\n    <generator class=\"sequence\">\n        <param name=\"sequence\">product_seq</param>\n    </generator>\n</id>\nHere\u2019s an example of the same approach, but using a MySQL auto-incre-\nment column:\n<id name=\"id\" type=\"long\" column=\"product_id\">\n    <generator class=\"native\"/>\n</id>\nThis does perform well, and it is quite easy to configure in a Hibernate map-\nping definition. The problem could be the timing of generation, which is dis-\ncussed a bit later. The remainder of this subsection covers the early identity \ngeneration requirement.\nwww.EBooksWorld.ir\n", "page": 222, "type": "text", "section": "Page 222"}
{"text": "Chapter 5 ENTITIES\n180\nOrder May Matter\nSometimes it matters when the identity generation and assignment occur for an \nEntity.\nEarly identity generation and assignment happen before the Entity is persisted.\nLate identity generation and assignment happen when the Entity is persisted.\nHere a Repository supports early generation, serving the next available Ora-\ncle sequence using a query:\npublic ProductId nextIdentity() {\n    Long rawProductId = (Long)\n        this.session()\n            .createSQLQuery(\n                \"select product_seq.nextval as product_id from dual\")\n            .addScalar(\"product_id\", Hibernate.LONG)\n            .uniqueResult();\n    return new ProductId(rawProductId);\n}\nSince Oracle returns sequence values that Hibernate maps as BigDecimal\ninstances, we must inform Hibernate that we want the product_id result \nconverted to a Long.\nWhat do we do about databases, such as MySQL, that don\u2019t support \nsequences? MySQL supports auto-incrementing columns. Normally the \nauto-increment does not occur until a row is newly inserted. Still, there is a \nway to make a MySQL auto-increment work like an Oracle sequence:\nmysql> CREATE TABLE product_seq (nextval INT NOT NULL);\nQuery OK, 0 rows affected (0.14 sec)\nmysql> INSERT INTO product_seq VALUES (0);\nQuery OK, 1 row affected (0.03 sec)\nmysql> UPDATE product_seq SET nextval=LAST_INSERT_ID(nextval + 1);\nQuery OK, 1 row affected (0.03 sec)\nRows matched: 1  Changed: 1  Warnings: 0\nmysql> SELECT LAST_INSERT_ID();\n+------------------+\n| LAST_INSERT_ID() |\n+------------------+\n|                1 |\n+------------------+\n1 row in set (0.06 sec)\nwww.EBooksWorld.ir\n", "page": 223, "type": "text", "section": "Page 223"}
{"text": " \nUNIQUE IDENTITY\n181\nmysql> SELECT * FROM product_seq;\n+---------+\n| nextval |\n+---------+\n|       1 |\n+---------+\n1 row in set (0.00 sec)\nWe\u2019ve created a table in a MySQL database named product_seq. Next, \nwe insert a single row into the table, initializing its one and only column, \nnextval, to 0. Those first two steps establish the sequence emulator for the \nProduct Entity. The next two statements demonstrate a single sequence value \ngeneration. We update the one and only row by incrementing the nextval\ncolumn by 1. The update statement uses a MySQL function, LAST_INSERT_\nID(), to increment the column\u2019s INT value. The expression parameter is first \nexecuted, then the result is assigned to the nextval column. The result of the \nexpression parameter nextval + 1 remains stable in the LAST_INSERT_\nID() function, such that when the subsequence SELECT LAST_INSERT_ID()\nstatement is evaluated, the value of nextval that results from that exact exe-\ncution is returned in the result set. Last, as a test, we can SELECT * FROM \nproduct_seq to prove that the current value of nextval is the same \nreturned with the function result.\nHibernate 3.2.3 uses org.hibernate.id.enhanced.SequenceStyle-\nGenerator to facilitate portable sequences, but that supports only late identity \ngeneration (when the Entity is inserted). To support early sequence generation \nin a Repository we will have to create a custom Hibernate or JDBC query. \nHere is a reimplementation of the ProductRepository method next-\nIdentity() for MySQL:\npublic ProductId nextIdentity() {\n    long rawId = -1L;\n    try {\n        PreparedStatement ps =\n            this.connection().prepareStatement(\n                \"update product_seq \"\n                + \"set next_val=LAST_INSERT_ID(next_val + 1)\");\n        ResultSet rs = ps.executeQuery();\n        try {\n            rs.next();\n            rawId = rs.getLong(1);\n        } finally {\n            try {\n                rs.close();\nwww.EBooksWorld.ir\n", "page": 224, "type": "text", "section": "Page 224"}
{"text": "Chapter 5 ENTITIES\n182\n            } catch(Throwable t) {\n                // ignore\n            }\n        }\n    } catch (Throwable t) {\n        throw new IllegalStateException(\n                \"Cannot generate next identity\", t);\n    }\n    return new ProductId(rawId);\n}\nUsing JDBC, there is no need to execute a second query on the database to \nget the results of function LAST_INSERT_ID(). The update query does it all. \nWe get the long value from the ResultSet, using it to create the ProductId.\nThe last trick is to get a JDBC connection from Hibernate. This can be a bit \nof a pain, but it\u2019s possible:\nprivate Connection connection() {\n    SessionFactoryImplementor sfi =\n           (SessionFactoryImplementor)sessionFactory;\n    ConnectionProvider cp = sfi.getConnectionProvider();\n    return cp.getConnection();\n}\nWithout a Connection object we can\u2019t get a ResultSet by executing \na PreparedStatement. Without that it\u2019s not possible to use a portable \nsequence.\nUsing portable sequences from Oracle, MySQL, and other databases, we \nhave the means to generate more compact, guaranteed unique identities that \nsupport pre-insert creation.\nAnother Bounded Context Assigns Identity\nWhen another Bounded Context assigns identity, we need to integrate to find, \nmatch, and assign each identity. DDD integrations are explained in Context \nMaps (3) and Integrating Bounded Contexts (13).\nMaking an exact match is the most desirable. Users need to provide one \nor more attributes, such as an account number, username, e-mail address, or \nother unique symbol, to pinpoint the intended result.\nOften, matching involves fuzzy input, resulting in multiple search results, \nalong with some human user selection. Figure 5.2 illustrates this. The user \nenters the \u201clike search\u201d (wildcard) criterion for the sought-after Entity. We \nwww.EBooksWorld.ir\n", "page": 225, "type": "text", "section": "Page 225"}
{"text": " \nUNIQUE IDENTITY\n183\naccess the API of the external Bounded Context, which resolves the search to \nzero, one, or multiple similarly described objects. The user then selects the spe-\ncific result from among the multiple options. The identity of the selected choice \nis used as the local identity. Some additional state (properties) from the foreign \nEntity may also be copied into the local Entity.\nThis has synchronization implications. What happens if externally refer-\nenced objects transition in ways that affect local Entities? How will we know \nthat the associated object changed? This problem can be solved using an Event-\nDriven Architecture (4) with Domain Events (8). Our local Bounded Context \nsubscribes to Domain Events published by external systems. When a relevant \nnotification is received, our local system transitions its own Aggregate Entities \nto reflect the state of those in external systems. Sometimes synchronization \nmust be initiated by the local Bounded Context with changes being pushed to \nthe originating external system.\nThis is rarely easy to do, but it leads to more autonomous systems. When \nautonomy is achieved, it can actually narrow searches to local objects. This is \nnot a matter of caching foreign objects locally. Rather, it involves translating \nforeign concepts into those of the local Bounded Context, as explained in Con-\ntext Mapping (3).\nThis is the most complex of identity creation strategies. The maintenance of \nthe local Entity is dependent not only on transitions caused by local domain \nbehaviors but possibly also on those that occur in one or more external sys-\ntems. Use this approach as conservatively as possible.\nFind Product\nProduct Name:\nOK\nCancel\nBright Day*\nBright Day Sunscreen SPF 50 \n22350\nBright Day Sunscreen SPF 30 \n22330\nBright Day Sunglasses \n22399\nx\nFigure 5.2 The search results from matching an external system to find an identity. \nThe selection user interface may or may not display the identity. This example does \ndisplay it.\nwww.EBooksWorld.ir\n", "page": 226, "type": "text", "section": "Page 226"}
{"text": "Chapter 5 ENTITIES\n184\nWhen the Timing of Identity Generation Matters\nIdentity generation can occur either early, as part of the object\u2019s construction, \nor late, as part of its persistence. Sometimes it\u2019s important to time identity gen-\neration early, and other times not. If it matters, we need to understand what\u2019s \ninvolved.\nConsider possibly the simplest case, that we can tolerate the late allocation \nof identity when a new Entity is persisted, that is, a new row is inserted in the \ndatabase. This is demonstrated in the diagram in Figure 5.3. The client just \ninstantiates a new Product and adds it to the ProductRepository. When \nthe Product instance is newly created, the client doesn\u2019t need its identity. And \nit\u2019s a good thing, too, because the identity won\u2019t exist then. It\u2019s only after the \ninstance is persisted that the identity is available.\nWhy might timing matter? Consider a scenario where the client subscribes \nto outgoing Domain Events. An Event occurs when a new Product instan-\ntiation completes. The client saves the published Event to an Event Store (8).\nEventually those stored Events are published as notifications that reach sub-\nscribers outside the Bounded Context. Using the approach of Figure 5.3, the \nDomain Event is received before the client has the opportunity to add the new \nProduct to the ProductRepository. Thus, the Domain Event would not \ncontain the valid identity of the new Product. For the Domain Event to be \ncorrectly initialized, the identity generation must be completed early. Figure 5.4 \ndemonstrates that approach. The client queries for the next identity from the \nProductRepository, passing it to the Product constructor.\nClient\nnew\nadd(aProduct)\nINSERT\nDatabase\nProduct\nProductRepository\nsetProductId()\nFigure 5.3 The simplest way to allocate a unique identity is to have the data store \ngenerate it the first time the object is persisted.\nwww.EBooksWorld.ir\n", "page": 227, "type": "text", "section": "Page 227"}
{"text": " \nUNIQUE IDENTITY\n185\nThere is another problem that can occur when identity generation is delayed \nuntil the Entity is persisted. It occurs when two or more new Entities must \nbe added to a java.util.Set, but their identity has not yet been assigned, \nmaking them equal to the other new ones (for example, null, or 0, or -1). If \nthe Entity\u2019s equals() method compares identities, those newly added to the \nSet will appear to be the same object. Only the first object added will be con-\ntained, and all others will be excluded. This causes a dubious bug whose root \ncause is at first difficult to understand and fix.\nTo avoid this bug we must do one of two things. Either we change the design \nto allocate and assign identity early, or we refactor the equals() method to \ncompare attributes other than the domain identity. If choosing the equals()\nmethod approach, it must be implemented as if the Entity is a Value Object. \nIn that case, the same object\u2019s hashCode() method must harmonize with the \nequals() method:\npublic class User extends Entity  {\n    ...\n    @Override\n    public boolean equals(Object anObject) {\n        boolean equalObjects = false;\n        if (anObject != null &&\n               this.getClass() == anObject.getClass()) {\n            User typedObject = (User) anObject;\n            equalObjects =\n                this.tenantId().equals(typedObject.tenantId()) &&\nClient\nnew\nadd(aProduct)\nINSERT\nDatabase\nProduct\nProductRepository\nnextIdentity()\nFigure 5.4 Here unique identity is queried from the Repository and assigned \nduring instantiation. The complexities of identity generation are hidden behind the \nRepository implementation.\nwww.EBooksWorld.ir\n", "page": 228, "type": "text", "section": "Page 228"}
{"text": "Chapter 5 ENTITIES\n186\n                this.username().equals(typedObject.username()));\n        }\n        return equalObjects;\n    }\n    @Override\n    public int hashCode() {\n        int hashCode =\n            + (151513 * 229)\n            + this.tenantId().hashCode()\n            + this.username().hashCode();\n        return hashCode;\n    }\n    ...\n}\nIn the case of a multitenancy environment, the TenantId instance is also \nconsidered part of unique identity. No two User objects under different \nTenant subscribers must be considered equal.\nMore to the point, when faced with this add-to-Set situation, I prefer early \nallocation and assignment to the Value equality test approach. It is more desir-\nable for Entities to have equals() and hashCode() methods that are based \non the object\u2019s unique identity rather than other attributes.\nSurrogate Identity\nSome ORM tools, such as Hibernate, want to deal with object identity on their \nown terms. Hibernate prefers the database\u2019s native type, such as a numeric \nsequence, as the primary identity of each Entity. If the domain requires another \nkind of identity, it causes an undesirable conflict for Hibernate. To cure this, \nwe need to use two identities. One of the identities is designed for the domain \nmodel and adheres to the requirements of the domain. The other is for Hiber-\nnate and is known as a surrogate identity.\nCreating a surrogate identity is straightforward. Create an attribute on the \nEntity to hold the type of the surrogate. Generally a long or int does it. Also \ncreate a column in the database entity table to hold the unique identity, and \nplace a primary key constraint on it. Then include in the Entity\u2019s Hibernate \nmapping definition an <id> element. Remember, in this case it has nothing to \ndo with the domain-specific identity. It is being created only for the sake of the \nORM, Hibernate.\nIt\u2019s best to hide the surrogate attribute from the outside world. Because the \nsurrogate is not part of the domain model, visibility constitutes persistence \nwww.EBooksWorld.ir\n", "page": 229, "type": "text", "section": "Page 229"}
{"text": " \nUNIQUE IDENTITY\n187\nleakage. Although some leakage may be unavoidable, we can take some steps \nto tuck it away from model developers and clients.\nOne safeguard employs a Layer Supertype [Fowler, P of EAA]:\npublic abstract class IdentifiedDomainObject\n        implements Serializable  {\n    private long id = -1;\n    public IdentifiedDomainObject() {\n        super();\n    }\n    protected long id() {\n        return this.id;\n    }\n    protected void setId(long anId) {\n        this.id = anId;\n    }\n}\nThis Layer Supertype is IdentifiedDomainObject, an abstract base \nclass that hides the surrogate primary key from the view of clients using \nprotected accessor methods. Clients will never have to wonder if the meth-\nods are for their use since they are not visible outside the Module (9) of the \nEntity that extends the base class. We could even declare private scope. \nHibernate has no problems using method or field reflection with any level of \nvisibility, public to private. Additional Layer Supertypes may add value, \nsuch as for supporting optimistic concurrency, as seen in Aggregates (10).\nWe need to map the surrogate id attribute to the database column through \nthe Hibernate definition. Here class User has its id attribute mapped to the \ndatabase table column named id:\n<hibernate-mapping default-cascade=\"all\">\n    <class\n     name=\"com.saasovation.identityaccess.domain.model.identity.User\" \n     table=\"tbl_user\" lazy=\"true\">\n        <id\n            name=\"id\"\n            type=\"long\"\n            column=\"id\"\n            unsaved-value=\"-1\">\nwww.EBooksWorld.ir\n", "page": 230, "type": "text", "section": "Page 230"}
{"text": "Chapter 5 ENTITIES\n188\n            <generator class=\"native\"/>\n        </id>\n        ...\n    </class>\n</hibernate-mapping>\nHere is the MySQL table definition to store the User objects:\nCREATE TABLE `tbl_user` (\n    `id` int(11) NOT NULL auto_increment,\n    `enablement_enabled` tinyint(1) NOT NULL,\n    `enablement_end_date` datetime,\n    `enablement_start_date` datetime,\n    `password` varchar(32) NOT NULL,\n    `tenant_id_id` varchar(36) NOT NULL,\n    `username` varchar(25) NOT NULL,\n    KEY `k_tenant_id_id` (`tenant_id_id`),\n    UNIQUE KEY `k_tenant_id_username` (`tenant_id_id`,`username`),\n    PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\nThe first column, id, is the surrogate identity. The last column statement \nin the definition declares id as the table\u2019s primary key. We can distinguish the \nsurrogate and the domain\u2019s identity. There are two columns, tenant_id_id\nand username, that provide unique identity for the domain. They are com-\nbined to form one unique key named k_tenant_id_username.\nThere is no need for the domain identity to play the role of database pri-\nmary key. We allow the surrogate id to serve as the database primary key, \nwhich keeps Hibernate happy.\nSurrogate database primary keys can be used throughout the data model \nas foreign keys in other tables, providing referential integrity. This may be a \nrequirement for data management in your enterprise (for example, for audits) \nor for tools support. The referential integrity is important for Hibernate, too, \nwhen wiring tables together to implement the various any-to-any (such as 1:M) \nmappings. They also support table joins to optimize queries when reading \nAggregates out of the database.\nIdentity Stability\nIn most cases unique identity must be protected from modification, remaining \nstable throughout the lifetime of the Entity to which it is assigned.\nTrivial measures may be taken to prevent identity modification. We can hide \nidentity setters from clients. We might also create guards in setters to prevent \nwww.EBooksWorld.ir\n", "page": 231, "type": "text", "section": "Page 231"}
{"text": " \nUNIQUE IDENTITY\n189\neven the Entity itself from changing the state of the identity if it already exists. \nGuards are coded as assertions in Entity setters. Here\u2019s an example of an iden-\ntity setter:\npublic class User extends Entity  {\n    ...\n    protected void setUsername(String aUsername) {\n        if (this.username != null) {\n            throw new IllegalStateException(\n                    \"The username may not be changed.\");\n        }\n        if (aUsername == null) {\n            throw new IllegalArgumentException(\n                    \"The username may not be set to null.\");\n        }\n        this.username = aUsername;\n    }\n    ...\n}\nIn this example, the username attribute, being the domain identity of the \nUser Entity, is mutable only once, and only internally. The setter, method \nsetUsername(), provides self-encapsulation that is hidden from clients. When \nan Entity public behavior self-delegates to the setter, the method checks the \nusername attribute to see if it is already non-null. If it is already non-null,\nindicating an unchangeable invariant state, the IllegalStateException\nis thrown. The exception indicates that username must be maintained as a \nmodify-once state.\nWhiteboard Time\n\u2022 Consider some true Entities from your current domain and write their \nnames.\nWhat are their unique identities, both domain and surrogate? Would any of the iden-\ntities have been better served by a different kind of identity generation, or the timing \nof the identity assignment?\n\u2022 Indicate next to each Entity whether you should have used a different \nidentity assignment approach\u2014user, application, persistence, or other \nBounded Context\u2014and why (even if you can\u2019t change it now).\nwww.EBooksWorld.ir\n", "page": 232, "type": "text", "section": "Page 232"}
{"text": "Chapter 5 ENTITIES\n190\n\u2022 Note next to each Entity whether it needs early identity generation or can \nsuffice with late identity generation, and explain why.\nConsider the stability of each identity, which is one area you can improve on if \nnecessary.\nThis setter does not get in the way of Hibernate when it needs to recon-\nstitute object state from persistence. Since the object is first constructed with \nits default, zero-argument constructor, the username attribute is initially \nnull. This enables re-initialization to occur cleanly, and the setter will enable \nthe one-time Hibernate-initiated assignment to take place. This is completely \nbypassed when instructing Hibernate to use field (attribute) access for per-\nsistence and rehydration purposes, rather than accessors.\nA test affirms that the modify-once guard properly protects the state of \nUser identity:\npublic class UserTest extends IdentityTest {\n    ...\n    public void testUsernameImmutable() throws Exception {\n        try {\n            User user = this.userFixture();\n            user.setUsername(\"testusername\");\n            fail(\"The username must be immutable after\u03a6\ninitialization.\");\n        } catch (IllegalStateException e) {\n            // expected, fall through\n        }\n    }\n    ...\n}\nThis exemplary test demonstrates how the model works. Upon successful \ncompletion it proves that method setUsername() guards existing, non-null\nidentity from being altered. (We discuss guards and Entity tests more thor-\noughly as part of validation.)\nwww.EBooksWorld.ir\n", "page": 233, "type": "text", "section": "Page 233"}
{"text": " \nDISCOVERING ENTITIES AND THEIR INTRINSIC CHARACTERISTICS\n191\nDiscovering Entities and Their Intrinsic Characteristics\nNow let\u2019s look at some lessons learned by the SaaSOvation teams . . .\nAt first the CollabOvation team got caught \nin the trap of doing a lot of entity-relation-\nship (ER) modeling in Java code. They put \ntoo much focus on database, tables, and \ncolumns, and how those were reflected \nin objects. That led to a largely Anemic \nDomain Model [Fowler, Anemic] composed \nof a lot of getters and setters. They should \nhave been thinking more about DDD. By the \ntime they needed to factor out the security tangle, as described in Bounded Con-\ntexts (2), they had learned to focus more on modeling the Ubiquitous Language. \nThat led to good results. In this section we will see how the newer Identity and Access \nContext team gained from the lessons learned.\nThe Ubiquitous Language in a cleanly separated Bounded Context gives us \nthe concepts and terms we need to design our domain model. The Language \ndoesn\u2019t suddenly appear. It must be developed through careful discussion with \ndomain experts and by mining requirements. Some terminology uncovered \nwill be nouns that name things, adjectives that describe them, and verbs that \nindicate what the things do. It would be a mistake to think that the objects \ndistill to only a set of nouns that name classes and verbs that name prominent \noperations, that we can capture deep insight by considering nothing else. Lim-\niting ourselves in that way could stifle the fluency and richness that the model \ndeserves. Investing in liberal amounts of discussion and reviews of specifica-\ntions will help develop a Language that reflects considerable thought, effort, \nagreement, and compromise. In the end the team speaks the Language in com-\nplete sentences, and the model clearly reflects the spoken Language.\nIf it is important for these special domain scenarios to outlive team discus-\nsions, capture them in a lightweight document. In an early form, your Ubiq-\nuitous Language can take the shape of a glossary and a set of simple usage \nscenarios. Yet, it would be a further mistake to think of the Language as the \nglossary and scenarios only. In the end the Language is modeled by your code, \nand it may be difficult or impossible to keep documentation in sync.\nwww.EBooksWorld.ir\n", "page": 234, "type": "text", "section": "Page 234"}
{"text": "Chapter 5 ENTITIES\n192\nUncovering Entities and Properties\nLet\u2019s take up a very basic example. In the Identity and Access Context the \nSaaSOvation team knows that it needs to model a User. True, this modeling \nexample is not taken from the Core Domain (2), but we do transition to that \nexample later. At this time I want to clear away added complexity inherent \nwith the Core Domain and just focus on a more basic Entity. It has enough \nmodeling challenge to serve as an effective teaching tool.\nHere\u2019s what the team knew about a User in terse soft-\nware requirements (not use cases or user stories) that \nroughly reflected statements from the Ubiquitous Lan-\nguage. They did need refinement:\n\u2022 Users exist in association with and under the control \nof a tenancy.\n\u2022 Users of a system must be authenticated.\n\u2022 Users possess personal information, including a \nname and contact information.\n\u2022 User personal information may be changed by the users themselves or by a \nmanager.\n\u2022 User security credentials (passwords) may be changed.\nThe team had to read and listen carefully. As soon as they saw/heard different \nforms of the word change used, they were pretty sure that they were dealing with at \nleast one Entity. True enough, \u201cchange\u201d could also mean \u201creplace the Value\u201d instead \nof \u201cchange the Entity.\u201d Was there anything else that sealed the team\u2019s choice of which \nbuilding block to use? There was. The key term was authenticated, which was a \nstrong indication to the team that some kind of search resolution needed to be pro-\nvided. If you have a bunch of things, and one of the things needs to be found out of \nmany, you need unique identity to distinguish the one from all others. A search will \nneed to resolve from many users in association with a tenant down to a single one.\nBut what about the statement regarding tenancy controlling users? Doesn\u2019t \nthat imply that the real Entity here is Tenant, not User? This opens up a \ndiscussion about Aggregates (10), which we save for that chapter. In short, the \nanswer is \u201cyes and no.\u201d Yes, there is a Tenant Entity, and no, this doesn\u2019t \nmean there is not a User Entity. They are both Entities. To understand why \nTenant and User are the Roots (10) of two different Aggregates, see that \nchapter. And yes, both User and Tenant are ultimately types of Aggregates, \nbut the team avoids those concerns at first.\nwww.EBooksWorld.ir\n", "page": 235, "type": "text", "section": "Page 235"}
{"text": " \nDISCOVERING ENTITIES AND THEIR INTRINSIC CHARACTERISTICS\n193\nThe justification here is that each User must be uniquely identified, clearly \ndistinguished from all others. A User must also support change over time, so \nit is clearly an Entity. At this time, it doesn\u2019t matter how we model the personal \ninformation inside the User.\nThe team needed to give some attention to clarifying the meaning of the first \nrequirement:\n\u2022 Users exist in association with and under the control of a tenancy.\nAt first the team could just add a note or change the wording of the statement in \nsome way that would show that tenants own users, but they don\u2019t collect and contain \nthem. The team needed to be careful because they didn\u2019t want to get down into the \ntechnical and tactical modeling weeds. The statements needed to make sense to the \nwhole team. They settled on this:\n\u2022 Tenants allow for the registration of many users by invitation.\n\u2022 Tenants may be active or be deactivated.\n\u2022 Users of a system must be authenticated but can be authenticated only if the \ntenant is active.\n\u2022 . . . \nWell, that was a surprise! Following further discussion, the team cut cleanly \nthrough the issues of word craft and at the same time gave the requirements much \nmore meaning. They found that the original statement about users under tenancy \ncontrol was incomplete. The fact is that users are registered within a tenancy, and by \ninvitation only. It was also important to state that tenants may be active or inactive, \nand that users can be authenticated only when their tenancy is active. This complete \nrestating of one requirement, the addition of another, and the clarification of a third \nrevealed a far more accurate definition of what actually happens.\nThe effort did away with any possible implications about what manages the life \ncycle of users but made it clear that whatever owns users, some users may be \nunavailable under specific circumstances. Those were the important scenarios to \ncapture at that time.\nIt seemed at this point that they had the beginnings of a glossary of the terms of a \nUbiquitous Language. Still, they didn\u2019t have enough information to flesh out the defini-\ntions. The team will wait a while longer to make entries in the glossary.\nThey had a couple of known Entities, as shown in Figure 5.5. It was important \nto know next how they would be uniquely identified, and what additional properties \nmight be needed to find them among many possible objects of the same type.\n<<entity>>\nTenant\n<<entity>>\nUser\nFigure 5.5 Two Entities, Tenant and User, following early discovery\nwww.EBooksWorld.ir\n", "page": 236, "type": "text", "section": "Page 236"}
{"text": "Chapter 5 ENTITIES\n194\nThe team decided that they would use a full UUID to identify each Tenant\nuniquely, a case where the application generates the identity. The large text value \nwas easily justified, not only for guaranteed uniqueness, but also because it added \na good measure of security to each subscriber. It would be difficult for anyone to \nrandomly reproduce a UUID as first-level access to proprietary data. They also saw \nthe need to explicitly segregate the Entities that belonged under each Tenant from \nthose that belonged to every other. A requirement like this is stated to address addi-\ntional security issues that tenant subscribers\u2014competitive businesses\u2014have with \nhosted applications and services. Thus, every Entity in all systems would be \u201cstriped\u201d \nwith this unique identity, and every query would require the unique identity to find any \nEntity, no matter what.\nThe unique tenant identity is not an Entity. It is a Value of some kind. The question \nis, Should this identity have a specialized type, or can it remain a simple String?\nThere seemed to be no need to model Side-Effect-Free Functions (6) on the \nidentity. It\u2019s just a hexadecimal text representation of a large number. But the identity \nwould be used broadly. It would be set on all other Entities in every Context. In this \ncase strong typing could be advantageous. By defining a TenantId Value Object, \nthe team could more confidently ensure that all subscriber-owned Entities were \nstriped with the correct identity. Figure 5.6 shows how this is modeled, with both the \nTenant and the User Entities.\nThe Tenant must be named. The name can be a simple String attribute \nbecause it has no special behavior. The name helps resolve queries. A help desk \nworker would need to find the Tenant by name before he or she could provide assis-\ntance. It\u2019s a necessary attribute and an \u201cintrinsic characteristic.\u201d The name may also \nbe constrained as unique among all other subscribers, but that\u2019s not important now.\nOther attributes may be associated with each subscriber, such as a support con-\ntract and call activation PIN, billing and payment information, and maybe a business \nlocation along with customer contacts. But those are business concerns, not part of \n<<entity>>\nUser\nusername: String\npassword: String\n<<entity>>\nTenant\nname: String\n<<value object>>\nTenantId\npassword encrypted\nFigure 5.6 After an Entity is discovered and named, uncover the attributes/\nproperties that uniquely identify it and enable it to be found.\nwww.EBooksWorld.ir\n", "page": 237, "type": "text", "section": "Page 237"}
{"text": " \nDISCOVERING ENTITIES AND THEIR INTRINSIC CHARACTERISTICS\n195\nsecurity. Attempting to stretch the Identity and Access Context too far would be a \ndefeating effort.\nSupport will be managed by a different Context. After finding the tenant by name, \nthe software can use its unique TenantId. It would then be used to access the Sup-\nport Context, for example, or the Billing Context, or the Customer Relationship Man-\nagement Context. Support contracts, business location, and customer contacts have \nlittle to nothing to do with security. Still, associating the name of the subscriber with \nthe Tenant will help support personnel quickly provide needed support. The name\nbelongs.\nHaving completed what appears to be the essence of Tenant, the team turned \ntheir attention to the User Entity for a while. What would serve as its unique identity? \nMost identity systems support a unique username. It doesn\u2019t matter much what com-\nprises the username, as long as it is unique within the tenant. (Usernames need not \nbe unique across tenant lines.) It will be left to the discretion of users to determine \ntheir own usernames. If the subscribing business has certain policy criteria for user-\nnames, or if the names will be determined by a federated security integration, it will be \nleft to the registering user to comply. The team simply declared a username attribute \non class User.\nOne requirement states that a security credential exists. It indicates that this is a \npassword. The team picked up on the terminology and declared a password attri-\nbute on class User. They concluded that the password would never be stored as \nclear text. A note was made that the password must be encrypted. Since they will \nneed a way to encrypt each password before it is associated with the User, it seemed \nas if this called for some kind of Domain Service (7). The team created a place-\nholder in the glossary of the Ubiquitous Language, which could now be started. The \nglossary would be limited, but useful:\n\u2022 Tenant: A named organizational subscriber of identity and access services, as \nwell as other online services. Facilitates user registration through invitation.\n\u2022 User: A registered security principal within a tenancy, complete with per-\nsonal name and contact information. The User has a unique username and an \nencrypted password.\n\u2022 Encryption Service: Provides a means to encrypt passwords and other data \nthat cannot be stored and used as clear text.\nOne question remained: Should the password be considered a part of the unique \nidentity of a User? After all, it is used to find a User. If so, we\u2019d probably want to \ncombine the two attributes into a Whole Value, naming it something like Security-\nPrincipal. That would make this concept much more explicit. It is an interesting \nidea, but it overlooks an important requirement: Passwords can be changed. There \nmay also be times when services will need to find a User without being provided with \na password. This is not for authentication. (Consider the scenario where we need to \ncheck to see if a User is playing a security Role. We can\u2019t require a password to find \na User every time we need to check for access permissions.) It\u2019s not identity. We can \nstill include both the username and the password in a single authentication query. \nwww.EBooksWorld.ir\n", "page": 238, "type": "text", "section": "Page 238"}
{"text": "Chapter 5 ENTITIES\n196\nThe idea of creating a SecurityPrincipal Value type produced a desirable \nmodeling proposition. It was noted for later consideration. There were also some \nother concepts that went unexplored, such as how registration invitations would be \nprovided, and the details on personal name and contact information. The team would \ncatch those in the next quick iteration.\nDigging for Essential Behavior\nAfter essential attributes were identified, the team could look into indispens-\nable behavior . . .\nAfter looking back at the basic requirements the team was given, they now sought the \nbehavior of Tenant and User:\n\u2022 Tenants may be active or be deactivated.\nWhen we think of activating and deactivating a Tenant, we probably visu-\nalize a Boolean toggle. As true as that may be, how it is implemented is unim-\nportant here. If we were to place active in the attributes compartment of \nTenant in the class diagram, would that necessarily tell the reader anything \nuseful? In Tenant.\njava, would the following attribute declaration reveal \nintentions?\npublic class Tenant extends Entity {\n    ...\n    private boolean active;\n    ...\nProbably not entirely. And at first we want to focus only on attributes/prop-\nerties that provide identity and enable matching on queries. We add support \ndetails like that later.\nThe team could have decided in favor of \ndeclaring method setActive(boolean),\nthough that wouldn\u2019t really address the \nterminology of the requirement. It\u2019s not \nthat public setter methods are never \nappropriate, but they should be used \nonly when the Language allows for them \nwww.EBooksWorld.ir\n", "page": 239, "type": "text", "section": "Page 239"}
{"text": " \nDISCOVERING ENTITIES AND THEIR INTRINSIC CHARACTERISTICS\n197\nand usually only when you won\u2019t have to use multiple setters to fulfill a single request. \nThe multiple setters make the intention ambiguous. They also complicate publishing \na single, meaningful Domain Event as an outcome to what should actually be a single \nlogical command.\nTo address the Language, the team noted that domain experts talk about activat-\ning and deactivating. To incorporate that terminology they\u2019d assign operations such \nas activate() and deactivate() instead.\nThe following source is an Intention Revealing Interface [Evans] and complies \nwith the team\u2019s growing Ubiquitous Language:\npublic class Tenant extends Entity {\n    ...\n    public void activate() {\n         // TODO: implement\n    }\n    public void deactivate() {\n        // TODO: implement\n    }\n    ...\nTo animate their ideas, the team first developed a test to see how it feels to use the \nnew behaviors:\npublic class TenantTest ... {\n    public void testActivateDeactivate() throws Exception {\n        Tenant tenant = this.tenantFixture();\n        assertTrue(tenant.isActive());\n        tenant.deactivate();\n        assertFalse(tenant.isActive());\n        tenant.activate();\n        assertTrue(tenant.isActive());\n    }\n}\nAfter this test the team felt confident in the quality of the interface. Writing the test \nmade them realize that another method, isActive(), was needed. They settled on \nthese three new methods, as seen in Figure 5.7. The Ubiquitous Language glossary \ngrew as well:\n\u2022 Activate tenant: Facilitate the activation of a tenant using this operation, and \nthe current state may be confirmed.\n\u2022 Deactivate tenant: Facilitate the deactivation of a tenant using this operation. \nUsers may not be authenticated when the tenant is deactivated.\nwww.EBooksWorld.ir\n", "page": 240, "type": "text", "section": "Page 240"}
{"text": "Chapter 5 ENTITIES\n198\n\u2022 Authentication Service: Coordinates the authentication of users, first ensuring \nthat their owning tenant is active.\nThe last glossary entry added here indicates the discovery of another Domain \nService. Before attempting to match the User instance, something must first check \nTenant for isActive(). That understanding was gained when also considering this \nrequirement:\n\u2022 Users of a system must be authenticated but can be authenticated only if the \ntenant is active.\nSince there is more to authentication than merely finding a User that matches \na specific username and password, a higher-level coordinator is needed. Domain \nServices are good at that. Details can be added later. For now it\u2019s important that the \nteam captured the AuthenticationService by name and added it to the Ubiqui-\ntous Language. The test-first approach sure paid off.\nThe team also considered the following requirement:\n\u2022 Tenants allow for the registration of many users by invitation.\nWhen they started analyzing this carefully, they understood it to be a bit more \ncomplex than they wanted to deal with in the first, rapid iteration. There seemed to \nbe some kind of Invitation object involved. But the requirement didn\u2019t tell them \nenough to be understood clearly. The behavior to manage invitations wasn\u2019t clear \neither. So the team postponed modeling this until they could solicit more input from \nearly domain experts and early customers. They did define the registerUser()\nmethod, however. It is essential to the creation of User instances (see \u201cConstruction\u201d \nlater in the chapter).\nWith that they ventured back into class User:\n\u2022 Users possess personal information, including a name and contact information.\n\u2022 User personal information may be changed by the users themselves or by a \nmanager.\n\u2022 User security credentials (passwords) may be changed.\n<<entity>>\nTenant\nname: String\nactivate()\ndeactivate()\nisActive()\nregisterUser()\n<<value object>>\nTenantId\nFigure 5.7 Indispensable behavior is assigned to Tenant during the first rapid \niteration. Some behaviors are omitted due to complexity but can be added soon.\nwww.EBooksWorld.ir\n", "page": 241, "type": "text", "section": "Page 241"}
{"text": " \nDISCOVERING ENTITIES AND THEIR INTRINSIC CHARACTERISTICS\n199\nUser along with Fundamental Identity, two commonly combined security pat-\nterns, were applied.1 From the use of the term personal, it is clear that a personal \nconcept accompanies the User. The team worked out the composition and behavior \nbased on the preceding statements.\nPerson is modeled as a separate class to avoid placing too much responsibil-\nity on the User. The word personal led the team to add Person to the Ubiquitous \nLanguage:\n\u2022 Person: Contains and manages personal data about a User, including name \nand contact information.\nIs the Person an Entity or a Value Object? Again here the word change is key. It \nseems unnecessary to replace the entire Person object just because the individual\u2019s \nwork telephone number may change. The team made it an Entity, as indicated in Fig-\nure 5.8, which holds two Values, the ContactInformation and Name. These were \ncurrently fuzzy concepts and would stand to be refactored in time.\nManaging changes to the personal name and contact information of a user \nresulted in some further deliberation. Should clients be given access to the Person\nobject inside the User? One developer questioned whether a User would always be \na person. What if it were an external system? This was not the current situation and \nmight be rushing ahead on unknown future requirements, but the concern had merit. \nIf clients were given access to the shape of User, with navigation into the Person in \norder to execute behavior, that could require client refactoring later.\nIf, instead, they modeled the personal behavior on User, making it more general-\nized for a security principal, they would probably avoid some of the ripple later. After \nthey wrote some exemplary tests to explore the notion, it seemed like the right thing \nto do. They modeled User as shown in Figure 5.8.\n 1. See my published patterns: http://vaughnvernon.co/.\n<<entity>>\nUser\nusername: String\npassword: String\nchangePassword()\nchangePersonalName()\nchangePersonalContactInformation()\n<<entity>>\nPerson\n<<value object>>\nContactInformation\n<<value object>>\nName\n<<value object>>\nTenantId\npassword encrypted\nFigure 5.8 The foundational behavior of User drives out more associations. Without \nbeing overly specific, the team modeled a few more objects along with the operations.\nwww.EBooksWorld.ir\n", "page": 242, "type": "text", "section": "Page 242"}
{"text": "Chapter 5 ENTITIES\n200\nThere were other considerations. Should the team expose Person at all, or hide \nit from all clients? For now they decided to leave Person exposed for the purpose of \nquerying information. The accessor could later be redesigned to serve a Principal\ninterface, and Person and System would each be a specialized Principal. The \nteam would be able to refactor this as they gained deeper understanding.\nMaintaining their cadence, the team quickly recognized the Ubiquitous Language \nhighlighted by the final requirement currently under consideration:\n\u2022 User security credentials (passwords) may be changed.\nThe User has a changePassword() behavior. This reflects the term used in \nrequirements and satisfies domain experts. Access to even the encrypted password \nis never granted to clients. Once the password is set on User, it is never exposed \nbeyond the Aggregate boundary. Anything seeking authentication has but one \napproach, using the AuthenticationService.\nThe team also decided that all behaviors that could cause modification, when suc-\ncessful, were to publish a specific Domain Event outcome. This, too, was more detail \nthan the team wanted to address early on. But they did recognize the need for Events. \nEvents would accomplish at least two things. First, they would enable change track-\ning through the life cycle of all objects (discussed later). Second, they would enable \noutside subscribers to synchronize with the changes, giving outsiders the potential \nfor autonomy.\nThose topics are discussed in Events (8) and Integrating Bounded Contexts (13).\nRoles and Responsibilities\nAn aspect of modeling is to discover the roles and responsibilities of objects. \nRole and responsibility analysis is applicable to domain objects in general. \nHere we look specifically at the roles and responsibilities of Entities.\nWe need some context for the term role. One use, when discussing the Iden-\ntity and Access Context, is that a Role is an Entity and Aggregate Root that \naddresses a broad system security concern. Clients can ask if a user is in, or \nplays, a security role. That\u2019s completely different from what I am now dis-\ncussing. What I am discussing in this section is how roles can be played by the \nobjects in your model.\nDomain Objects Playing Multiple Roles\nIn object-oriented programming, generally interfaces determine the roles of \nan implementing class. When designed correctly, a class has one role for each \ninterface that it implements. If the class has no explicitly declared roles\u2014it \ndoesn\u2019t implement any explicit interfaces\u2014by default it has the role of its class. \nThat is, the class has the implicit interface of its public methods. Class User in \nwww.EBooksWorld.ir\n", "page": 243, "type": "text", "section": "Page 243"}
{"text": " \nDISCOVERING ENTITIES AND THEIR INTRINSIC CHARACTERISTICS\n201\nthe preceding examples implements no explicit interfaces, yet it plays one role, \na User.\nWe could make one object play the role of both User and Person. Not that \nthis is being suggested, but for now assume that we consider this a good idea. \nIf we did, there would be no reason to aggregate a separate Person object as \na referenced association of the User object. Instead, there would be just one \nobject, one that plays two roles.\nWhy might we do this? Usually it\u2019s because we see both similarities and \ndifferences in two or more objects. The overlapping characteristics can be \naddressed by blending multiple interfaces on a single object. For example, we \ncould have one object be both a User and a Person, naming the implementa-\ntion class HumanUser:\npublic interface User {\n    ...\n}\npublic interface Person {\n    ...\n}\npublic class HumanUser implements User, Person {\n    ...\n}\nDoes this make sense? Possibly, but it may also complicate things. If both \ninterfaces are complex, it could be difficult to implement both in one object. \nAlso, a User may be a system, which would increase the necessary interfaces \nto three. Designing the single object to play the roles of User, Person, and \nSystem would be even harder. Maybe we could simplify this by creating a \ngeneral-purpose Principal:\npublic interface User {\n    ...\n}\npublic interface Principal {\n    ...\n}\npublic class UserPrincipal implements User, Principal {\n    ...\n}\nwww.EBooksWorld.ir\n", "page": 244, "type": "text", "section": "Page 244"}
{"text": "Chapter 5 ENTITIES\n202\nWith this design we are attempting to determine the actual principal type at \nruntime (late binding). A person principal and a system principal have different \nimplementations. Systems don\u2019t need the same kind of contact information as \na person has. Still, we might try anyway, designing a forwarding delegation \nimplementation. To do that we\u2019d check for the existence of one type or the \nother at runtime and delegate to the existing object:\npublic interface User {\n    ...\n}\npublic interface Principal {\n    public Name principalName();\n    ...\n}\npublic class PersonPrincipal implements Principal {\n    ...\n}\npublic class SystemPrincipal implements Principal {\n    ...\n}\npublic class UserPrincipal implements User, Principal {\n    private Principal personPrincipal;\n    private Principal systemPrincipal;\n    ...\n    public Name principalName() {\n        if (personPrincipal != null) {\n            return personPrincipal.principalName();\n        } else if (systemPrincipal != null) {\n            return systemPrincipal.principalName();\n        } else {\n            throw new IllegalStateException(\n                    \"The principal is unknown.\");\n        }\n    }\n    ...\n}\nThis design produces various problems. For one, it suffers from what is \ncalled object schizophrenia.2 Behavior is delegated by a technique known \n 2. It describes an object with multiple personalities, which is not medically the defi-\nnition of schizophrenia. The actual problem behind the confusing name is object \nidentity confusion.\nwww.EBooksWorld.ir\n", "page": 245, "type": "text", "section": "Page 245"}
{"text": " \nDISCOVERING ENTITIES AND THEIR INTRINSIC CHARACTERISTICS\n203\nas forwarding or dispatching. Neither personPrincipal nor system-\nPrincipal carries the identity of Entity UserPrincipal, on which the \nbehavior was originally executed. Object schizophrenia describes the situa-\ntion where the objects delegated to don\u2019t know the identity of their originating \nobject. There is confusion inside the delegates as to who they really are. It\u2019s not \nthat every delegate method in the two concrete classes would be required to \ntake on the base object\u2019s identity, but some could need it. We could pass in a \nreference to the UserPrincipal. But that complicates the design and actually \nrequires the Principal interface to change. That\u2019s not good. As [Gamma et \nal.] states, \u201cDelegation is a good design choice only when it simplifies more \nthan it complicates.\u201d\nWe won\u2019t try to solve this modeling challenge here. It\u2019s used only to illus-\ntrate the challenges sometimes encountered when using object roles and to \nemphasize that it\u2019s a modeling style we need to be careful with. With the right \ntools, such as Qi4j [\u00d6berg], we could improve things.\nIt might help the situation to make role interfaces finer grained, as Udi \nDahan [Dahan, Roles] promotes. Here are two requirements that enable us to \ncreate fine-grained interfaces:\n\u2022 Add new orders to a customer.\n\u2022 Make a customer preferred (the condition for meeting this level is not \nstated).\nClass Customer implements two fine-grained role interfaces: IAddOrders-\nToCustomer and IMakeCustomerPreferred. Each defines only a single \noperation, as seen in Figure 5.9. We might even implement other interfaces, \nsuch as Ivalidator.\nAs discussed in Aggregates (10), we wouldn\u2019t normally collect a large num-\nber of objects, such as all its orders, on a Customer. So let\u2019s view this as a \n<<role>>\nIAddOrdersToCustomer\nAddOrder(anOrder:Order)\n<<role>>\nIMakeCustomerPreferred\nMakePreferred()\n<<entity>>\nCustomer\nFigure 5.9 Using C#.NET naming conventions, the Customer Entity implements \ntwo object roles, IAddOrdersToCustomer and IMakeCustomerPreferred.\nwww.EBooksWorld.ir\n", "page": 246, "type": "text", "section": "Page 246"}
{"text": "Chapter 5 ENTITIES\n204\nsynthetic example, used solely as a means to illustrate how object roles are \nused.\nThe I interface name prefix is a style widely used in .NET programming. \nBesides following the .NET approach in general, some think it enhances read-\nability: \u201cI add orders to customer\u201d and \u201cI make customer preferred.\u201d Without \nthe I prefix, the resulting verb-based names may be less desirable: AddOrders-\nToCustomer and MakeCustomerPreferred. We may be more used to \nnaming interfaces as nouns or adjectives, and that standard could certainly be \napplied here instead.\nConsider some advantages this style promotes. The role of an Entity can \nchange from use case to use case. When a client needs to add a new Order\ninstance to a Customer, the role is different from when they want to make the \nCustomer preferred. There\u2019s also a technical advantage. Different use cases \nmay require specialized fetching strategies:\nIMakeCustomerPreferred customer =\n    session.Get<IMakeCustomerPreferred>(customerId);\ncustomer.MakePreferred();\n...\nIAddOrdersToCustomer customer =\n    session.Get<IAddOrdersToCustomer>(customerId);\ncustomer.AddOrder(order);\nThe persistence mechanism interrogates the parameterization type name T\nof the Get<T>() method. It uses the type to look up an associated fetching \nstrategy that is registered with the infrastructure. If the interface happens to \nhave no special fetching strategy, the default is used. By executing the fetching \nstrategy, the identified Customer object is loaded in the shape needed by the \nspecific use case.\nWe may see technical merit as role marker interfaces lend a hand to enabling \nbehind-the-scenes hooks. Other use-case-specific behavior can be associated \nwith any given role, such as validation, enabling the execution of a specific \nvalidator as the Entity modifications are being persisted.\nFine-grained interfaces make it easier for the implementing class, such as \nCustomer, to implement the behavior on itself. There is no need to delegate the \nimplementation to separate classes, which helps prevent object schizophrenia.\nIt\u2019s fair to ask whether there is a distinct domain modeling advantage to \nseparating Customer behaviors by role. Compare the previous Customer to \nthe one in Figure 5.10; is one better than the other? Would it be easier for \nwww.EBooksWorld.ir\n", "page": 247, "type": "text", "section": "Page 247"}
{"text": " \nDISCOVERING ENTITIES AND THEIR INTRINSIC CHARACTERISTICS\n205\na client to mistakenly invoke the AddOrder() method when it should actu-\nally invoke MakePreferred()? Probably not. But we should not judge the \napproach on this alone.\nPerhaps the most practical use of role interfaces is also the simplest. We can \nleverage interfaces to hide implementation details that we don\u2019t want leaking \nout of the model to clients. Design an interface to expose exactly what we \nwant to allow clients to use, and nothing more. The implementation class can \nbe far more complex than the interface. It might have all kinds of supporting \nproperties with getters and setters, and implementation behavior that clients \nwill never get a glimpse of. For example, perhaps a tool or framework forces \nthe creation of public methods that we don\u2019t want clients to use. Even so, the \ndomain model interface is not influenced by necessarily nasty technical imple-\nmentation details. This has a definite domain modeling advantage.\nAlong with any design choice, ensure that the Ubiquitous Language holds \nsway over any technical preferences. With DDD, it\u2019s a model of the business \ndomain that matters most.\nConstruction\nWhen we newly instantiate an Entity, we want to use a constructor that cap-\ntures enough state to fully identify it and enable clients to find it. When early \nidentity generation is used, a correctly designed constructor takes as a param-\neter at least the unique identity. If the Entity is queried by other means, such \nas with a name or description, we would also include all such as constructor \nparameters.\nSometimes an Entity maintains one or more invariants. An invariant is a \nstate that must stay transactionally consistent throughout the Entity life cycle. \nInvariants are a concern of Aggregates, but since the Aggregate Root is always \nan Entity, it is mentioned here. If an Entity has an invariant that is satisfied by \nthe non-null state of a contained object, or calculated using some other state, \nthat state must be provided by one or more constructor parameters.\n<<entity>>\nCustomer\nAddOrder(anOrder:Order)\nMakePreferred()\nFigure 5.10 Here Customer is modeled with the operations that were previously on \ndifferent interfaces now collapsed onto the single interface of the Entity class.\nwww.EBooksWorld.ir\n", "page": 248, "type": "text", "section": "Page 248"}
{"text": "Chapter 5 ENTITIES\n206\nEvery User object must contain a tenantId, username, password, and \nperson. In other words, following successful construction, references to these \ndeclared instance variables may never be null. The User constructor and its \ninstance variable setters ensure this:\npublic class User extends Entity {\n    ...\n    protected User(TenantId aTenantId, String aUsername,\n            String aPassword, Person aPerson) {\n        this();\n        this.setPassword(aPassword);\n        this.setPerson(aPerson);\n        this.setTenantId(aTenantId);\n        this.setUsername(aUsername);\n        this.initialize();\n    }\n    ...\n    protected void setPassword(String aPassword) {\n        if (aPassword == null) {\n            throw new IllegalArgumentException(\n                   \"The password may not be set to null.\");\n        }\n        this.password = aPassword;\n    }\n    protected void setPerson(Person aPerson) {\n        if (aPerson == null) {\n            throw new IllegalArgumentException(\n                    \"The person may not be set to null.\");\n        }\n        this.person = aPerson;\n    }\n    protected void setTenantId(TenantId aTenantId) {\n        if (aTenantId == null) {\n            throw new IllegalArgumentException(\n                    \"The tenantId may not be set to null.\");\n        }\n        this.tenantId = aTenantId;\n    }\n    protected void setUsername(String aUsername) {\n        if (this.username != null) {\n            throw new IllegalStateException(\n                    \"The username may not be changed.\");\n        }\n        if (aUsername == null) {\n            throw new IllegalArgumentException(\n                    \"The username may not be set to null.\");\n        }\nwww.EBooksWorld.ir\n", "page": 249, "type": "text", "section": "Page 249"}
{"text": " \nDISCOVERING ENTITIES AND THEIR INTRINSIC CHARACTERISTICS\n207\n        this.username = aUsername;\n    }\n    ...\n}\nThe design of class User demonstrates the power of self-encapsulation. The \nconstructor delegates instance variable assignment to its own internal attri-\nbute/property setters, which provide self-encapsulation for the variables. The \nself-encapsulation enables each setter to determine the appropriate contractual \nconditions for setting a portion of state. Each of the setters individually asserts \na non-null constraint on behalf of the Entity, which enforces the instance \ncontract. The assertions are called guards (see \u201cValidation\u201d). As indicated \nearlier in the \u201cIdentity Stability\u201d section, the self-encapsulation techniques of \nthese setter methods can be more complex as needed.\nUse a Factory for complex Entity instantiations. This is covered in more \ndetail in Factories (11). In the preceding example, did you notice that the User\nconstructor has protected visibility? The Tenant Entity serves as a Factory for \nUser instances, and only classes in the same Module can see the User con-\nstructor. That way no object other than a Tenant may create User instances:\npublic class Tenant extends Entity  {\n    ...\n    public User registerUser(\n            String aUsername,\n            String aPassword,\n            Person aPerson) {\n        aPerson.setTenantId(this.tenantId());\n        User user = \n                new User(\n                        this.tenantId(),\n                        aUsername,\n                        aPassword,\n                        aPerson);\n        return user;\n    }\n    ...\n}\nHere method registerUser() is the Factory. The Factory simplifies con-\nstruction of the User default state and ensures that the TenantId for both \nthe User and Person Entities is always correct. This all happens under the \ncontrol of a Factory method that addresses the Ubiquitous Language.\nwww.EBooksWorld.ir\n", "page": 250, "type": "text", "section": "Page 250"}
{"text": "Chapter 5 ENTITIES\n208\nValidation\nThe primary reasons to use validation in the model are to check the correctness \nof any one attribute/property, any whole object, or any composition of objects. \nWe look at three levels of validation in the model. Although there are lots of \nways to perform validation, including specialized frameworks/libraries, those \nare not examined here. Instead, general-purpose approaches are presented, but \nthese can lead to more elaborate approaches.\nValidation accomplishes different things. Just because all of the attributes/\nproperties of a domain object are individually valid, that does not mean that \nthe object as a whole is valid. Maybe the combination of two correct attributes \ninvalidates the whole object. Just because a single object as a whole is valid, \nthat does not mean that a composition of objects is valid. Perhaps the combina-\ntion of two Entities, each of which has individual valid states, actually makes \nthe composition invalid. Therefore, we may need to use one or more levels of \nvalidation to address all possible issues.\nValidating Attributes/Properties\nHow can we protect a single attribute or property\u2014see Value Objects (6)\nfor the difference between the two\u2014from being set to an invalid value? As \ndiscussed elsewhere in this chapter and book, I highly recommend the use of \nself-encapsulation. Self-encapsulation facilitates the first solution.\nTo quote Martin Fowler, \u201cSelf encapsulation is designing your classes so \nthat all access to data, even from within the same class, goes through accessor \nmethods\u201d [Fowler, Self Encap]. Using this technique provides several advan-\ntages. It allows for the abstraction of an object\u2019s instance (and class/static) vari-\nables. It provides a way to easily derive attributes/properties from any number \nof others the object holds. And not least for this specific discussion, it lends \nsupport for a simple form of validation.\nActually, I don\u2019t necessarily like calling the use of self-encapsulation to \nprotect correct object state by the name validation. That name puts off some \ndevelopers, because validation is a separate concern and should be the respon-\nsibility of a validation class, not a domain object. I agree. Still, I am talking \nabout something a bit different. What I\u2019m discussing is assertions that follow a \ndesign-by-contract approach.\nBy definition, design by contract enables us to specify the preconditions, \npostconditions, and invariants of the components we design. This is advocated \nby Bertrand Meyer and was thoroughly expressed in his Eiffel programming \nlanguage. There is some support for the Java and C# languages and a book on \nthe subject, Design Patterns and Contracts [Jezequel et al.]. Here we look only \nat preconditions, by applying guards, as a form of validation:\nwww.EBooksWorld.ir\n", "page": 251, "type": "text", "section": "Page 251"}
{"text": " \nDISCOVERING ENTITIES AND THEIR INTRINSIC CHARACTERISTICS\n209\npublic final class EmailAddress {\n    private String address;\n    public EmailAddress(String anAddress) {\n        super();\n        this.setAddress(anAddress);\n    }\n    ...\n    private void setAddress(String anAddress) {\n        if (anAddress == null) {\n            throw new IllegalArgumentException(\n                    \"The address may not be set to null.\");\n        }\n        if (anAddress.length() == 0) {\n            throw new IllegalArgumentException(\n                    \"The email address is required.\");\n        }\n        if (anAddress.length() > 100) {\n            throw new IllegalArgumentException(\n                    \"Email address must be 100 characters or less.\");\n        }\n        if (!java.util.regex.Pattern.matches(\n            \"\\\\w+([-+.']\\\\w+)*@\\\\w+([-.]\\\\w+)*\\\\.\\\\w+([-.]\\\\w+)*\",\n                anAddress)) {\n            throw new IllegalArgumentException(\n                    \"Email address and/or its format is invalid.\");\n        }\n        this.address = anAddress;\n    }\n    ...\n}\nThere are four preconditions to the method contract of setAddress(). All \nof the precondition guards assert a condition of the argument anAddress:\n\u2022 The parameter may not be null.\n\u2022 The parameter must not be an empty string.\n\u2022 The parameter must be 100 characters in length or less (but not zero \ncharacters).\n\u2022 The parameter must match the basic format of an e-mail address.\nIf all of these preconditions pass, the address property is set to the value of \nanAddress. If one is not met, an IllegalArgumentException is thrown.\nClass EmailAddress is not an Entity. It is a Value Object. We use it here \nfor a few reasons. First, it is a good example of implementing various degrees of \nwww.EBooksWorld.ir\n", "page": 252, "type": "text", "section": "Page 252"}
{"text": "Chapter 5 ENTITIES\n210\nprecondition guards, from null checks down to value formatting (more on this \nnext). Second, this Value is held by the Person Entity as one of its properties, \nindirectly through the ContactInformation Value. So, actually, this is part \nof an Entity in the same way that a simple attribute declared on an Entity class \nis also part of it. We use the exact same kinds of precondition guards when \nimplementing setters for simple attributes. When a Whole Value is assigned to \nan Entity property, there is no way to guard against setting insane state unless \nthe smaller attributes within the Value are guarded.\nCowboy Logic\nLB:  \n\u201cI thought I had a valid argument with the missus, \nbut then she suddenly threw an illegal argument \nexception at me.\u201d\nSome developers refer to these kinds of precondition checks as defensive pro-\ngramming. It certainly is defensive programming to guard against completely \ninvalid values entering your model. Some may not agree with the increasing \ndegree of specificity that such guards have. Some defensive programmers agree \nwith checking for nulls, and maybe even checking for empty strings, but may \nshy away from checking for conditions such as string lengths, numeric ranges, \nvalue formats, and the like. Some think, for example, that leaving value size \nchecks to the database is best. They consider things like maximum string \nlengths to be a concern of something other than model objects. Yet, these pre-\nconditions may be viewed as justifiable sanity checks.\nThere may be occasions when it is unnecessary to check for string lengths. It \ncould make sense when using a database whose maximum NVARCHAR column \nsize can never be reached. The text columns of Microsoft SQL Server can be \ndeclared using the max keyword:\nCREATE TABLE PERSON (\n    ...\n    CONTACT_INFORMATION_EMAIL_ADDRESS_ADDRESS\n            NVARCHAR(max) NOT NULL,\n    ...\n) ON PRIMARY\nGO\nIt\u2019s not that we\u2019d ever want an e-mail address to be 1,073,741,822 characters \nwide. It\u2019s just that we want to declare a column width that we will never need \nto worry about exceeding. \nwww.EBooksWorld.ir\n", "page": 253, "type": "text", "section": "Page 253"}
{"text": " \nDISCOVERING ENTITIES AND THEIR INTRINSIC CHARACTERISTICS\n211\nThis may not be possible with some databases. With MySQL, there is a \nmaximum row width of 65,535 bytes. Again, that\u2019s row width, not column \nwidth. If we declare even one column with the maximum VARCHAR column \ntype width of 65,535, there is no space left for one additional column in the \ntable. Depending on the number of VARCHAR columns in a given table, we \nwill need to restrict each column width to some practical limit that will allow \nfor all of the columns to fit. In cases like this we could declare character col-\numns as TEXT, since TEXT and BLOB columns are stored in separate segments. \nHence, depending on the database, there may be ways to work around column \nwidth limits and reduce the need for string length checks in the model.\nIf there is a potential to overflow a column, a simple string length check in \nthe model is warranted. How impractical would it be to translate the following \ninto a meaningful domain error?\nORA-01401: inserted value too large for column \nWe couldn\u2019t even determine which column was overflowed. It may be best to \navoid this problem altogether by checking text widths in setter preconditions. \nBesides, the length check need not be only about a database column constraint. \nIn the end, it is the domain itself that may constrain a text length for very justi-\nfiable reasons, such as constraints on legacy systems we integrate with.\nWe may also have to consider guarding high-low range checks, and pos-\nsibly others. Even a simple formatting check, like the e-mail address format, \nmakes sense if we want to prevent a completely insane value from being asso-\nciated with an Entity. Certainly if basic values of a single Entity are sane, it \nwill be easier to perform coarse-grained validation on whole objects and object \ncompositions.\nValidating Whole Objects\nEven though we may have an Entity with completely valid attributes/proper-\nties, it does not necessarily mean the entire Entity is valid. To validate a whole \nEntity, we need to have access to the state of the entire object\u2014all of its attri-\nbutes/properties. We also need a Specification [Evans & Fowler, Spec] or Strat-\negy [Gamma et al.] for the validation.\nIn his Checks pattern language, Ward Cunningham [Cunningham, Checks] \naddresses several approaches to validation. A useful one for whole objects is \nDeferred Validation. Ward says that this is \u201ca class of checking that should \nbe deferred until the last possible moment.\u201d It is deferred because it is a kind \nof very detailed validation, one that we would run over at least one complex \nobject, or even a composition of objects. For that reason we discuss Deferred \nValidation later also as a means to address larger compositions of objects. In \nwww.EBooksWorld.ir\n", "page": 254, "type": "text", "section": "Page 254"}
{"text": "Chapter 5 ENTITIES\n212\nthis subsection I limit validations to what Ward calls \u201cthe checks of simpler \nactivities.\u201d\nBecause the entire state of the Entity must be available to the validation, \nsome may see this as a good time to embed validation processing logic right \nin the Entity. Be cautious here. Many times the validation of a domain object \nchanges more often than the domain object itself. Embedding validation inside \nan Entity also gives it too many responsibilities. It already has the responsibil-\nity to address domain behavior as it maintains its state.\nA validation component has the responsibility to determine whether or not \nthe Entity state is valid. When designing a separate validation class with Java, \nplace it in the same Module (package) as the Entity. Assuming the use of Java, \ndeclare attribute/property read accessors with at least protected/package scope, \nand public is fine. Private scope will not allow the validation class to read the \nnecessary state. If the validation class is not placed in the same Module as the \nEntity, all attribute/property accessors must be public, which is undesirable in \nmany cases.\nThe validation class can implement the Specification pattern or the Strategy \npattern. If it detects an invalid state, it informs the client or otherwise makes \na record of the results that can be reviewed later (for example, after batch pro-\ncessing). It is important for the validation process to collect a full set of results \nrather than throw an exception at the first sign of trouble. Consider this reus-\nable, abstract validator and concrete subclass:\npublic abstract class Validator {\n    private ValidationNotificationHandler notificationHandler;\n    ...\n    public Validator(ValidationNotificationHandler aHandler) {\n        super();\n        this.setNotificationHandler(aHandler);\n    }\n    public abstract void validate();\n    protected ValidationNotificationHandler notificationHandler() {\n        return this.notificationHandler;\n    }\n    private void setNotificationHandler(\n            ValidationNotificationHandler aHandler) {\n        this.notificationHandler = aHandler;\n    }\n}\nwww.EBooksWorld.ir\n", "page": 255, "type": "text", "section": "Page 255"}
{"text": " \nDISCOVERING ENTITIES AND THEIR INTRINSIC CHARACTERISTICS\n213\npublic class WarbleValidator extends Validator {\n    private Warble warble;\n    public Validator(\n            Warble aWarble,\n            ValidationNotificationHandler aHandler) {\n        super(aHandler);\n        this.setWarble(aWarble);\n    }\n    ...\n    public void validate() {\n        if (this.hasWarpedWarbleCondition(this.warble())) {\n            this.notificationHandler().handleError(\n                    \"The warble is warped.\");\n        }\n        if (this.hasWackyWarbleState(this.warble())) {\n            this.notificationHandler().handleError(\n                    \"The warble has a wacky state.\");\n        }\n        ...\n    }\n}\nThe WarbleValidator is instantiated with a ValidationNotifi-\ncationHandler. Whenever an invalid condition is encountered, the Val-\nidationNotificationHandler is asked to handle the condition. The \nValidationNotificationHandler is a general-purpose implementa-\ntion with a handleError() method that takes a String notification mes-\nsage. We may instead create specialized implementations that have a different \nmethod for each kind of invalid condition:\nclass WarbleValidator extends Validator {\n    ...\n    public void validate() {\n        if (this.hasWarpedWarbleCondition(this.warble())) {\n            this.notificationHandler().handleWarpedWarble();\n        }\n        if (this.hasWackyWarbleState(this.warble())) {\n            this.notificationHandler().handleWackyWarbleState();\n        }\n    }\n    ...\n}\nwww.EBooksWorld.ir\n", "page": 256, "type": "text", "section": "Page 256"}
{"text": "Chapter 5 ENTITIES\n214\nThis has the advantage of not coupling error messages, or message property \nkeys, or anything specific to notification, to the validation process. Even bet-\nter, place the notification handling inside the check method:\nclass WarbleValidator extends Validator {\n    ...\n    public Validator(\n            Warble aWarble,\n            ValidationNotificationHandler aHandler) {\n        super(aHandler);\n        this.setWarble(aWarble);\n    }\n    ...\n    public void validate() {\n        this.checkForWarpedWarbleCondition();\n        this.checkForWackyWarbleState();\n        ...\n    }\n    ...\n    protected checkForWarpedWarbleCondition() {\n        if (this.warble()...) {\n            this.warbleNotificationHandler().handleWarpedWarble();\n        }\n    }\n    ...\n    protected WarbleValidationNotificationHandler\n            warbleNotificationHandler() {\n        return (WarbleValidationNotificationHandler)\n                this.notificationHandler();\n    }\n}\nIn this example we use a Warble-specific ValidationNotificationHan-\ndler. It comes in as a standard type but is cast to the specific type when used \ninternally. It is up to the model to work out the contract between itself and \nclients to supply the correct type.\nHow do clients ensure that Entity validation occurs? And where does vali-\ndation processing begin?\nOne way places a validate() method on all Entities that require valida-\ntion and may do so using a Layer Supertype:\npublic abstract class Entity\n        extends IdentifiedDomainObject  {\n    public Entity() {\n        super();\n    }\nwww.EBooksWorld.ir\n", "page": 257, "type": "text", "section": "Page 257"}
{"text": " \nDISCOVERING ENTITIES AND THEIR INTRINSIC CHARACTERISTICS\n215\n    public void validate(\n            ValidationNotificationHandler aHandler) {\n    }\n}\nAny Entity subclass can safely have its validate() method invoked. If \nthe concrete Entity supports specialized validation, it is executed. If not sup-\nported, the behavior is a no-op. If only some Entities validate, it may be best to \ndeclare validate() only on those that need it.\nHowever, should Entities actually validate themselves? Having its own \nvalidate() method doesn\u2019t mean the Entity itself performs validation. Yet, it \ndoes allow the Entity to determine what validates it, relieving clients from that \nconcern:\npublic class Warble extends Entity {\n    ...\n    @Override\n    public void validate(ValidationNotificationHandler aHandler) {\n        (new  WarbleValidator(this, aHandler)).validate();\n    }\n    ...\n}\nEach specialized Validator subclass performs any number of fine-grained \nvalidations, as needed. The Entity needs to know nothing about how it is val-\nidated, only that it can be validated. The separate Validator subclass also \nallows the validation process to change at a different pace from the Entity and \nenables complex validations to be thoroughly tested.\nValidating Object Compositions\nWe can use Deferred Validation for what Ward Cunningham says are the \u201cmore \ncomplex actions requiring all of the checks of simpler activities and then some.\u201d \nHere we determine not only that an individual Entity is valid, but that a cluster \nor composition of Entities are all valid together, including one or more Aggre-\ngate instances. To do so we could instantiate the concrete Validator subclass \nwith the appropriate number of instances. But it may be best to manage that \nkind of validation using a Domain Service. The Domain Service can use Repos-\nitories to read the Aggregate instances it needs to validate. It can then run each \ninstance through its paces, separately or in combination with others.\nDecide whether validation is appropriate at all times. On occasion an Aggre-\ngate or a set of Aggregates is in a temporary, intermediate state. Perhaps we \nwww.EBooksWorld.ir\n", "page": 258, "type": "text", "section": "Page 258"}
{"text": "Chapter 5 ENTITIES\n216\ncould model a status on an Aggregate to indicate this, preventing validation \nat inappropriate times. When the conditions are ripe for validation, the model \ncould inform clients by publishing a Domain Event:\npublic class SomeApplicationService ... {\n    ...\n    public void doWarbleUseCaseTask(...) {\n        Warble warble =\n            this.warbleRepository.warbleOfId(aWarbleId);\n        DomainEventPublisher\n            .instance()\n            .subscribe(new DomainEventSubscriber<WarbleTransitioned>(){\n                public void handleEvent(DomainEvent aDomainEvent) {\n                     ValidationNotificationHandler handler = ...;\n                     warble.validate(handler);\n                     ...\n                }\n                public Class<WarbleTransitioned>\n                        subscribedToEventType() {\n                    return WarbleTransitioned.class;\n                }\n            });\n        warble.performSomeMajorTransitioningBehavior();\n    }\n}\nWhen received by the client, WarbleTransitioned indicates that valida-\ntion is now appropriate. Until that time the client refrains from validating.\nChange Tracking\nBy the definition of Entity, it is not necessary to track the changes that occur \non state over its lifetime. We have to support only its continuously changing \nstate. However, sometimes domain experts care about important occurrences \nin the model as time passes. When that\u2019s the case, tracking specific changes to \nEntities can help.\nThe most practical way to achieve accurate and useful change tracking is \nwith Domain Events and an Event Store. We create a unique Event type for \nevery important state-altering command executed against every Aggregate that \ndomain experts care about. The combination of the Event name and its proper-\nties makes the record of change explicit. The Events are published as the com-\nmand methods complete. A subscriber registers to receive every Event produced \nby the model. When received, the subscriber saves the Event to the Event Store.\nwww.EBooksWorld.ir\n", "page": 259, "type": "text", "section": "Page 259"}
{"text": " \nWRAP-UP\n217\nDomain experts may not care about every change to a model, but the tech-\nnical team may care anyway. This is usually for technical reasons, using a pat-\ntern named Event Sourcing (4).\nWrap-Up\nWe\u2019ve run the gamut of Entity-related topics. Here\u2019s a recap of what you\u2019ve \nlearned:\n\u2022 You\u2019ve covered four primary ways to generate Entity unique identities.\n\u2022 You understand the importance of the timing of generation, and how to \nuse surrogate identity.\n\u2022 You now know how to ensure the stability of identities.\n\u2022 We discussed how to discover the intrinsic characteristics of Entities by \nuncovering the Ubiquitous Language in Context. You saw how both \nproperties and behavior are discovered.\n\u2022 Along with core behavior, you looked into the strengths and weaknesses \nof modeling Entities using multiple roles.\n\u2022 Finally, you examined the details of how to construct Entities, how to val-\nidate them, and how to track their changes when necessary.\nNext, we\u2019ll be looking at a very important building block among the tacti-\ncal modeling tools, Value Objects.\nwww.EBooksWorld.ir\n", "page": 260, "type": "text", "section": "Page 260"}
{"text": "This page intentionally left blank \nwww.EBooksWorld.ir\n", "page": 261, "type": "text", "section": "Page 261"}
{"text": "219\nChapter 6\nValue Objects\nPrice is what you pay. Value is what you get.\n\u2014Warren Buffett\nAlthough often overshadowed by entity-think, Value Objects are a vital build-\ning block of DDD. Examples of objects that are commonly modeled as Values \nare numbers, such as 3, 10, and 293.51; text strings, such as \u201chello, world!\u201d \nand \u201cDomain-Driven Design\u201d; dates; times; more detailed objects such as a \nperson\u2019s full name composed of first, middle, last name, and title attributes; \nand others such as currency, colors, phone numbers, and postal addresses. And \nthere are more complex kinds. I\u2019ll be discussing Values that model concepts \nof your domain using your Ubiquitous Language (1), addressing the goals of \nDomain-Driven Design.\nKnow the Value Advantages\nValue types that measure, quantify, or describe things are easier to create, test, use, \noptimize, and maintain.\nIt may surprise you to learn that we should strive to model using Value \nObjects instead of Entities wherever possible. Even when a domain concept \nmust be modeled as an Entity, the Entity\u2019s design should be biased toward serv-\ning as a Value container rather than a child Entity container. That advice is \nnot based on an arbitrary preference. Value types that measure, quantify, or \ndescribe things are easier to create, test, use, optimize, and maintain.\nRoad Map to This Chapter\n\u2022 Learn how to understand the characteristics of a domain concept to model \nas a Value.\n\u2022 See how to leverage Value Objects to minimize integration complexity.\n\u2022 Examine the use of domain Standard Types expressed as Values.\n\u2022 Consider how SaaSOvation learned the importance of Values.\n\u2022 Learn how the SaaSOvation teams tested, implemented, and persisted their \nValue types.\nwww.EBooksWorld.ir\n", "page": 262, "type": "text", "section": "Page 262"}
{"text": "Chapter 6 VALUE OBJECTS\n220\nAt first the SaaSOvation teams went over-\nboard with their use of Entities. This actu-\nally started to happen well before the User \nand Permission concepts got intertwined \nwith collaboration. From project inception \nthey followed the popular mode of thinking \nthat every element of their domain model \nneeded to map to its own database table, \nand that all their attributes should be easily \nset and retrieved through public accessor methods. Since every object had a data-\nbase primary key, the model was tightly stitched together into a large, complex graph. \nThat idea primarily came from the data modeling perspective that most developers \nhave when unduly influenced by relational databases, where everything is normalized \nand referenced using foreign keys. As they later learned, getting caught in the tide of \nentity-think was not only unnecessary, it was also more costly in development time \nand effort.\nWhen designed correctly, a Value instance can be created, handed off, and \nforgotten about. We don\u2019t have to worry that the consumer has somehow mod-\nified it incorrectly, or even modified it at all. A Value can have a brief or long \nexistence. It\u2019s just an unharmed and harmless Value that comes and goes as \nneeded.\nThis is a huge load off of our mind, similar to transitioning from a program-\nming language without managed memory facilities to one with garbage collec-\ntion. With the ease of use that Values afford, we should want as much of their \nkind as we can possibly justify.\nSo how do we determine if a domain concept should be modeled as a Value? \nWe have to pay close attention to its characteristics.\nWhen you care only about the attributes of an element of the model, classify it as \na VALUE OBJECT. Make it express the meaning of the attributes it conveys and \ngive it related functionality. Treat the VALUE OBJECT as immutable. Don\u2019t give \nit any identity and avoid the design complexities necessary to maintain ENTI-\nTIES. [Evans, p. 99]\nAs easy as it may be to create a Value type, sometimes those inexperienced \nwith DDD face confusion when trying to choose whether to model an Entity \nor a Value in a specific instance. The truth is that even experienced designers \nstruggle with this from time to time. Along with showing you how to imple-\nment a Value, I hope to clear up some of the mystery around the sometimes \nconfusing decision-making process.\nwww.EBooksWorld.ir\n", "page": 263, "type": "text", "section": "Page 263"}
{"text": " \nVALUE CHARACTERISTICS\n221\nValue Characteristics\nAs a first order of business, make certain when modeling a domain concept \nas a Value Object that you are addressing the Ubiquitous Language. Consider \nthis to be an overarching principle and a characteristic that must be achieved. I \nimply this principle throughout the chapter.\nWhen you are trying to decide whether a concept is a Value, you should \ndetermine whether it possesses most of these characteristics:\n\u2022 It measures, quantifies, or describes a thing in the domain.\n\u2022 It can be maintained as immutable.\n\u2022 It models a conceptual whole by composing related attributes as an inte-\ngral unit.\n\u2022 It is completely replaceable when the measurement or description changes.\n\u2022 It can be compared with others using Value equality.\n\u2022 It supplies its collaborators with Side-Effect-Free Behavior [Evans].\nIt will help to understand each of these characteristics in more detail. By \nemploying this approach to analyzing design elements in the model, you may \nfind that you should use Value Objects far more often than you may have before.\nMeasures, Quantifies, or Describes\nWhen you have a true Value Object in your model, whether you realize it or \nnot, it is not a thing in your domain. Instead, it is actually a concept that mea-\nsures, quantifies, or otherwise describes a thing in the domain. A person has \nan age. The age is not really a thing but measures or quantifies the number \nof years the person (thing) has lived. A person has a name. The name is not a \nthing but describes what the person (thing) is called.\nThis is closely related to the Conceptual Whole characteristic.\nImmutable\nAn object that is a Value is unchangeable after it has been created.1 When \nprogramming in Java or C#, for example, you use one of the Value class\u2019s \n 1. There are times when a Value Object can be designed as mutable, but the need is \nusually rare. I don\u2019t dwell on mutable Values here. If you are interested in when to \nuse a mutable Value type, please see the sidebar on page 101 of [Evans].\nwww.EBooksWorld.ir\n", "page": 264, "type": "text", "section": "Page 264"}
{"text": "Chapter 6 VALUE OBJECTS\n222\nconstructors to create an instance, passing in as parameters all objects on \nwhich its state will be based. The parameters may be the objects that will \ndirectly serve as the attributes of the Value, or they may be objects that will be \nused to derive one or more newly constituted attributes during construction. \nHere\u2019s an example of a Value Object type that holds a reference to another \nValue Object:\npackage com.saasovation.agilepm.domain.model.product;\npublic final class BusinessPriority implements Serializable  {\n    private BusinessPriorityRatings ratings;\n    public BusinessPriority(BusinessPriorityRatings aRatings) {\n        super();\n        this.setRatings(aRatings);\n        this.initialize();\n    }\n    ...\n}\nInstantiation alone does not guarantee that an object is immutable. After \nthe object has been instantiated and initialized by means of construction, none \nof its methods, whether public or hidden, will from that time forward cause its \nstate to change. In this example only the setRatings() and initialize()\nmethods may mutate state because they are used only in the scope of construc-\ntion. Method setRatings() is private/hidden and cannot be invoked from \noutside the instance.2 Further, class BusinessPriority must be implemented \nsuch that none of its methods other than constructors, public or hidden, may \ninvoke the setter. Later I will discuss how to test Value Objects for immutability.\nDepending on your taste, you can at times design Value Objects that hold \nreferences to Entities. But some caution may be warranted. When the refer-\nenced Entities change state\u2014by the Entity\u2019s behavior\u2014the Value changes, too, \nwhich violates the quality of immutability. Thus, it may be best to employ the \nmindset that Entity references held by Value types are used for the sake of com-\npositional immutability, expressiveness, and convenience. Otherwise, if Enti-\nties are held with the express purpose of mutating their state through the Value \nObject\u2019s interface, that\u2019s probably the wrong reason to compose them. Weigh \nthe competing forces while considering the Side-Effect-Free Behavior charac-\nteristic discussed later in the chapter.\n 2. In some cases, frameworks such as object-relational mappers or serialization \nlibraries (for XML, JSON, and so on) may need to use setters to reconstitute Value \nstate from its serialized form.\nwww.EBooksWorld.ir\n", "page": 265, "type": "text", "section": "Page 265"}
{"text": " \nVALUE CHARACTERISTICS\n223\nChallenge Your Assumptions\nIf you think that the object you are designing must be mutated by its behavior, ask \nyourself why that is necessary. Would it be possible instead to use replacement when \nthe Value must change? Using this approach where possible is designing toward \nsimplification.\nSometimes it makes no sense for an object to be immutable. That\u2019s perfectly fine, \nand it indicates that the object should be modeled as an Entity. If your analysis leads \nyou to that conclusion, refer to Entities (5).\nConceptual Whole\nA Value Object may possess just one, a few, or a number of individual attri-\nbutes, each of which is related to the others. Each attribute contributes an \nimportant part to a whole that collectively the attributes describe. Taken apart \nfrom the others, each of the attributes fails to provide a cohesive meaning. \nOnly together do all the attributes form the complete intended measure or \ndescription. This is different from merely grouping a set of attributes together \nin an object. The grouping itself accomplishes little if the whole fails to ade-\nquately describe another thing in the model.\nAs Ward Cunningham illustrates in his Whole Value pattern3 [Cunning-\nham, Whole Value aka Value Object], the Value {50,000,000 dollars} has two \nattributes: the attribute 50,000,000 and the attribute dollars. Separately these \nattributes describe something else or nothing special. This is especially true \nof the number 50,000,000, but certainly also of dollars. Together these attri-\nbutes are a conceptual whole that describes a monetary measure. So we would \nnot expect the thing that is said to be worth 50,000,000 dollars to have two \nseparate attributes to describe its worth, one of amount that is 50,000,000 \nand one of currency that is dollars. Because the thing\u2019s worth is not just \n50,000,000, and not just dollars. Here\u2019s the inexplicit way to model it:\n// incorrectly modeled thing of worth\npublic class ThingOfWorth {\n    private String name;         // attribute\n    private BigDecimal amount;   // attribute\n    private String currency;     // attribute\n    // ...\n}\nIn this example the model and its clients have to know when and how to use \namount and currency together because they don\u2019t form a conceptual whole. \nThis begs for a better approach.\n 3. Also called Meaningful Whole.\nwww.EBooksWorld.ir\n", "page": 266, "type": "text", "section": "Page 266"}
{"text": "Chapter 6 VALUE OBJECTS\n224\nTo properly describe a thing\u2019s worth it must be treated not as two separate \nattributes, but as a whole value: {50,000,000 dollars}. Here it is modeled as a \nWhole Value:\npublic final class MonetaryValue implements Serializable  {\n    private BigDecimal amount;\n    private String currency;\n    public MonetaryValue(BigDecimal anAmount, String aCurrency) {\n        this.setAmount(anAmount);\n        this.setCurrency(aCurrency);\n    }\n    ...\n}\nThis is not to say that MonetaryValue is perfect and could not be \nimproved. For sure, the use of an additional Value type such as Currency\nwould help here. We\u2019d replace the String type of the currency attribute \nwith the much more descriptive Currency type. There may also be a good \nargument to have a Factory and possibly a Builder [Gamma et al.] to take care \nof that. But those topics would detract from the simple example that is meant \nto focus on the concept of Whole Value.\nBecause the wholeness of a concept in the domain is so important, the par-\nent reference to a Value Object is not just an attribute. Rather, it is a prop-\nerty of the containing parent object/thing in the model that holds a reference \nto it. Granted, the type of the Value Object has one or more attributes (two \nin the case of MonetaryValue). But to the thing that holds the reference to \nthe Value Object instance, it is a property. Therefore, the thing that is worth \n50,000,000 dollars\u2014let\u2019s call it ThingOfWorth\u2014would have a property\u2014\npossibly named worth\u2014that holds a reference to an instance of a Value Object \nthat has two attributes that collectively describe the measure {50,000,000 dol-\nlars}. Remember, though, that the property name\u2014possibly worth\u2014and the \nValue type name\u2014possibly MonetaryValue\u2014can be determined only after \nestablishing our Bounded Context (2) and its Ubiquitous Language. Here\u2019s an \nimproved implementation:\n// correctly modeled thing of worth\npublic class ThingOfWorth {\n    private ThingName name;      // property\n    private MonetaryValue worth; // property\n    // ...\n}\nwww.EBooksWorld.ir\n", "page": 267, "type": "text", "section": "Page 267"}
{"text": " \nVALUE CHARACTERISTICS\n225\nAs expected, I changed ThingOfWorth to possess a property of type \nMonetaryValue that is named worth. It sure cleans up the otherwise disor-\nganized attributes. But more importantly, there is now a Value that expresses \na whole.\nI want to draw attention to a second change, perhaps one that you were not \nexpecting. The name of the ThingOfWorth may be just as important to aptly \ndescribe as is its worth. So I also replaced the String type of name with the \nThingName type. The use of a String attribute for name could seem thor-\nough enough at first. But, in later iterations, you learn that the use of a plain \nString causes problems. It has allowed domain logic central to the name of a \nThingOfWorth to leak out of the model. It has leaked into other parts of the \nmodel and into client code:\n// clients deal with naming issues\nString name = thingOfWorth.name();\nString capitalizedName =\n        name.substring(0, 1).toUpperCase()\n        + name.substring(1).toLowerCase();\nHere the client makes a feeble attempt to fix possible capitalization issues \nwith the name. By defining a ThingName type instead, we can centralize all \nconcerns dealing with the name of a ThingOfWorth. Based on this example, \nthe ThingName may fully format the text name upon instantiation, relieving \nclients of that burden. This emphasizes the need to proliferate Values through-\nout the model as opposed to minimizing their significance and use. Now, \nrather than containing three less meaningful attributes, ThingOfWorth con-\ntains two properly typed and named property Values.\nThe constructors of a Value class play into the effectiveness of a conceptual \nwhole. Along with immutability, we require a Value class\u2019s constructors to be \nthe means to ensure that the Whole Value is created in one operation. You must \nnot allow the attributes of a Value instance to be populated after construction, \nas if to build up the Whole Value piece by piece. Instead, the final state must \nbe guaranteed to initialize all at once, atomically. The previously expressed \nBusinessPriority and MonetaryValue constructors demonstrate this.\nHere\u2019s another angle on basic value type (for example, String, Integer, or \nDouble) overuse. There are programming languages (such as Ruby) that allow \nyou to effectively patch a class with new, specialized behavior. With such capa-\nbilities, you may consider using, for example, a double floating-point value to \nrepresent currency. If you need to calculate exchange rates between currencies, \nyou could just patch class Double with a  \nconvertToCurrency(Currency \naCurrency) behavior. This might seem like programming coolness, but is \nwww.EBooksWorld.ir\n", "page": 268, "type": "text", "section": "Page 268"}
{"text": "Chapter 6 VALUE OBJECTS\n226\nit really a good idea to use a language feature in this case? For one thing, \nthis currency-specific behavior is probably lost in a sea of general-purpose \nfloating-point responsibilities. Strike one. Likewise, there is no built-in under-\nstanding of currencies in class Double. So you\u2019d have to build up the language \ndefault type to understand more about currencies. After all, you have to pass \nin a Currency to know the one to convert to. Strike two. Most importantly, \nclass Double says nothing explicit about your domain. You lose track of your \ndomain concerns by not applying the Ubiquitous Language. Big swing and a \nmiss. Strike three.\nChallenge Your Assumptions\nIf you are tempted to place multiple attributes on an Entity that as a result manifests \na weakened relationship to all other attributes, the attributes should very likely be \ngathered into a single Value type, or multiple Value types. Each should form a con-\nceptual whole that reflects cohesiveness, appropriately named from your Ubiquitous \nLanguage. If even one attribute is associated with a descriptive concept, it is very \npossible that centralizing all concerns of this concept will improve the power of the \nmodel. If one or more of the attributes must change over time, consider Whole Value \nreplacement over maintaining an Entity through a long life cycle.\nReplaceability\nIn your model an immutable Value should be held as a reference by an Entity \nas long as its constant state describes the currently correct Whole Value. If that \nis no longer true, the entire Value is completely replaced with a new Value that \ndoes represent the currently correct whole.\nThe concept of replaceability is readily understood in the context of num-\nbers. Say that you have the concept of a total that is an integer in your \ndomain. If the total is currently set to the value 3 but must now be the value \n4, you don\u2019t, of course, modify the integer 3 itself to become the number 4. \nInstead you simply set the total to the integer 4:\nint total = 3;\n// later...\ntotal = 4;\nThis is obvious, but it helps make a point. In this example we have just replaced\nthe total value 3 with the value 4. This is not an oversimplification. It is \nexactly what replacement does even when a given Value Object type is more \ncomplex than an integer. Consider a more complex Value type:\nwww.EBooksWorld.ir\n", "page": 269, "type": "text", "section": "Page 269"}
{"text": " \nVALUE CHARACTERISTICS\n227\nFullName name = new FullName(\"Vaughn\", \"Vernon\");\n// later...\nname = new FullName(\"Vaughn\", \"L\", \"Vernon\");\nThe name starts out as the descriptive value of my first name and my last \nname. Later that Whole Value is replaced with the Whole Value of my first \nname, the first initial of my middle name, and my last name. I did not use a \nmethod on FullName to change the state of the value of name to contain the \nfirst initial of my middle name. That would violate the immutability quality \nof the FullName Value type. Rather we simply use Whole Value replacement, \nassigning the name object reference an entirely new instance of FullName.\n(True, this example was not an expressive way to handle replacement, and a \nbetter way is just ahead.)\nChallenge Your Assumptions\nIf you are leaning toward the creation of an Entity because the attributes of the \nobject must change, challenge your assumptions that it\u2019s the correct model. Would \nobject replacement work instead? Considering the preceding replacement example, \nyou may think that creating a new instance is impractical and lacks expressiveness. \nEven if the object you are dealing with is complex and changes somewhat frequently, \nreplacement need not be an impractical, or even ugly, proposition. A later example \ndemonstrates Side-Effect-Free Behavior for a simple and expressive way to deal with \nWhole Value replacement.\nValue Equality\nWhen a Value Object instance is compared to another instance, a test of object \nequality is employed. Throughout the system there may be many, many Value \ninstances that are equal, and yet not the same objects. Equality is determined \nby comparing the types of both objects and then their attributes. If both the \ntypes and their attributes are equal, the Values are considered equal. Further, \nif any two or more Value instances are equal, you could assign (using replace-\nment) any one of the equal Value instances to an Entity\u2019s property of that type \nand the assignment would not change the value of the property.\nHere\u2019s an example of class FullName implementing a test for Value \nequality:\npublic boolean equals(Object anObject) {\n    boolean equalObjects = false;\n    if (anObject != null &&\n            this.getClass() == anObject.getClass()) {\n        FullName typedObject = (FullName) anObject;\nwww.EBooksWorld.ir\n", "page": 270, "type": "text", "section": "Page 270"}
{"text": "Chapter 6 VALUE OBJECTS\n228\n        equalObjects =\n            this.firstName().equals(typedObject.firstName()) &&\n            this.lastName().equals(typedObject.lastName());\n    }\n    return equalObjects;\n}\nEach of the attributes of two FullName instances is compared to the oth-\ners (assuming this version has only first and last names, not a middle name). \nIf all of the attributes in both objects are equal, the two FullName instances \nare considered equal. This particular Value prevents null firstName and \nlastName upon construction. Thus, there is no need to protect against null\nin equals() comparisons of each of the corresponding properties. Further, I \nfavor the use of self-encapsulation, so I access attributes through their query \nmethods. This allows for derived attributes rather than requiring each attri-\nbute to exist as explicit state. Also implied is the need for a corresponding \nhashCode() implementation (demonstrated later).\nConsider the combination of Value characteristics necessary to support \nAggregate (10) unique identity. We need the Value equality capability, for \nexample, when we query for a specific Aggregate instance by identity. Immu-\ntability is also crucial. The unique identity must never change, and this can in \npart be ensured through the Value immutability characteristic. We also benefit \nfrom the conceptual whole characteristic, because the identity is named per \nthe Ubiquitous Language and holds all uniqueness-identifying attributes in one \ninstance. However, in this specific case we don\u2019t need the replacement charac-\nteristic of a Value Object because the unique identity of an Aggregate Root will \nnever be replaced. Yet, lacking the need for replacement characteristics does \nnot disqualify the use of a Value here. Further, if the identity requires some \nSide-Effect-Free Behavior, it is implemented on the Value type.\nChallenge Your Assumptions\nAsk yourself if the concept you are designing must be an Entity identified uniquely \nfrom all other objects or if it is sufficiently supported using Value equality. If the \nconcept itself doesn\u2019t require unique identity, model it as a Value Object.\nSide-Effect-Free Behavior\nA method of an object can be designed as a Side-Effect-Free Function [Evans]. \nA function is an operation of an object that produces output but without mod-\nifying its own state. Since no modification occurs when executing a specific \noperation, that operation is said to be side-effect free. The methods of an \nimmutable Value Object must all be Side-Effect-Free Functions because they \nmust not violate its immutability quality. You may consider this characteristic \nwww.EBooksWorld.ir\n", "page": 271, "type": "text", "section": "Page 271"}
{"text": " \nVALUE CHARACTERISTICS\n229\nas part and parcel with immutability. It is closely tied. However, I prefer to \nbreak it out as a distinct characteristic because doing so emphasizes a huge \nbenefit of Value Objects. Otherwise, we might see Values only as attribute con-\ntainers, overlooking one of the most powerful aspects of the pattern.\nThe Functional Way\nFunctional programming languages generally enforce this characteristic. In fact, \npure functional languages allow nothing but Side-Effect-Free Behavior, requiring all \nclosures to receive and produce only immutable Value Objects.\nBertrand Meyer described Side-Effect-Free Functions as the Query methods \nof his Command-Query Separation principle, or CQS, as discussed by Martin \nFowler in [Fowler, CQS]. A query method is one that asks an object a question. \nBy definition, asking an object a question must not change the answer.\nHere is an example of the FullName type\u2019s use of Side-Effect-Free Behavior \nto produce a new replacement value of itself:\nFullName name = new FullName(\"Vaughn\", \"Vernon\");\n// later...\nname =  name.withMiddleInitial(\"L\");\nThis produces the same outcome as the example discussed under \u201cReplace-\nability,\u201d but in a more expressive way. This Side-Effect-Free Function is imple-\nmented as follows:\npublic FullName withMiddleInitial(String aMiddleNameOrInitial) {\n    if (aMiddleNameOrInitial == null) {\n        throw new IllegalArgumentException(\n                \"Must provide a middle name or initial.\");\n    }\n    String middle = aMiddleNameOrInitial.trim();\n    if (middle.isEmpty()) {\n        throw new IllegalArgumentException(\n                \"Must provide a middle name or initial.\");\n    }\n    return new FullName(\n            this.firstName(),\n            middle.substring(0, 1).toUpperCase(),\n            this.lastName());\n}\nwww.EBooksWorld.ir\n", "page": 272, "type": "text", "section": "Page 272"}
{"text": "Chapter 6 VALUE OBJECTS\n230\nIn this example the method withMiddleInitial() does not modify the \nstate of its own Value and is, therefore, side-effect free. Instead it instantiates \na new Value composed from some of its own parts and a given middle initial. \nThis method captures important domain business logic in the model rather \nthan allowing it to leak out into client code, which could happen in the earlier \nexample.\nWhen a Value References an Entity\nShould a Value Object method be permitted to cause the modification of an Entity \nthat is passed as a parameter? Without stating a rule, if such a method does cause \nthe modification of an Entity, is it really side-effect free? Would it be easy to test that \nmethod? I say not easy or less easy. Thus, when a Value\u2019s method takes an Entity as \nparameter, it may be best for it to answer a result that the Entity could use to modify \nitself on its own terms.\nNonetheless, there are problems with such a design. Consider an example. \nHere a Scrum Product, an Entity, is used in some way by  \nBusinessPriority,\na Value Object, to calculate a priority:\nfloat priority = businessPriority.priorityOf(product);\nDo you see flaws in this? You have probably concluded that at least some prob-\nlems exist:\n\u2022 What I draw attention to is that we are forcing the Value to not only \ndepend on a Product, but also to understand the shape of this Entity. \nWhere possible, limit a Value to depend on and understand only its own \ntype and the types of its attributes. That is not always possible, but it\u2019s a \ngood goal.\n\u2022 Someone reading the code will not know what parts of the Product\nwill be used. The expression is not explicit, which weakens the clarity of \nthe model. It would be much better if some actual or derived property of \nProduct were passed.\n\u2022 More important for this discussion, any Value method that takes an \nEntity as parameter cannot easily prove that it doesn\u2019t cause the Entity\u2019s \nmodification, making the operation more difficult to test. So, even though \na Value promises not to cause modification, no one can easily prove that \nit doesn\u2019t.\nGiven this analysis, we haven\u2019t really improved anything here. To change \nthat and make the Value robust, you\u2019d pass only Values as parameters to Value \nwww.EBooksWorld.ir\n", "page": 273, "type": "text", "section": "Page 273"}
{"text": " \nVALUE CHARACTERISTICS\n231\nmethods. This way you reach the greatest level of Side-Effect-Free Behavior. It \nis not difficult to accomplish:\nfloat priority =\n        businessPriority.priority(\n               product.businessPriorityTotals());\nHere we simply ask the Product to provide an instance of Value Business-\nPriorityTotals. You may conclude that priority() should return a type \nother than float. That would be especially true if expressing a priority should \nbe a more formal part of the Ubiquitous Language, in which case a custom \nvalue type would be in order. Decisions like these come as a result of continu-\nally refining the model. Indeed, after some analysis the SaaSOvation team finds \nthat the Product Entity should not itself calculate business priority totals at \nall. That would eventually be performed by a Domain Service (7), and you will \nsee the better solution in that chapter.\nIf you decide against designing a specialized Value Object in favor of using \na basic language Value type instead (primitive or wrapper), you might be \nshortchanging your model. You won\u2019t have the opportunity to assign domain- \nspecific Side-Effect-Free Functions to the basic language Value type. Any spe-\ncialty behavior will be separate from the Value. And even if your programming \nlanguage allows you to patch the basic type with new behavior, is that really \ngoing to enable you to capture deep domain insight?\nChallenge Your Assumptions\nIf you think that a specific method cannot be side-effect free and must mutate the \nstate of its own instance, challenge your assumptions. Is there a way to employ \nreplacement rather than mutation? The preceding example provides a very simple \napproach to creating a new Value by reusing parts of the existing one and replacing \nonly the specifically changed parts. Rarely would every object in the system be a \nValue. Some objects will almost certainly be Entities. Carefully compare the Value \ncharacteristic qualifiers against those of Entities. A reasonable amount of team \nthought and discussion should lead to the correct conclusions.\nOnce the SaaSOvation teams read the [Evans] guidance about Side-Effect-Free \nFunctions, and other Whole Value material, they realized that they should be using \nValue Objects far more frequently. The teams have since come to realize that under-\nstanding the preceding Value characteristics really helped them discover more natu-\nral Value types in their domain.\nwww.EBooksWorld.ir\n", "page": 274, "type": "text", "section": "Page 274"}
{"text": "Chapter 6 VALUE OBJECTS\n232\nIs Everything a Value Object?\nBy now you may have begun to think that everything looks like a Value Object. \nThat\u2019s better than thinking that everything looks like an Entity. Where you might \nuse a little caution is when there are truly simple attributes that really don\u2019t need \nany special treatment. Perhaps those are Booleans or any numeric value that is really \nself-contained, needing no additional functional support, and is related to no other \nattributes in the same Entity. On their own the simple attributes are a Meaningful \nWhole. Still, you could certainly make the \u201cmistake\u201d of unnecessarily wrapping a \nsingle attribute in a Value type with no special functionality and be better off than \nthose who never give Value design a nod. If you find that you\u2019ve overdone it a bit, \nyou can always refactor a little.\nIntegrate with Minimalism\nThere are always multiple Bounded Contexts in every DDD initiative, which \nmeans we must find appropriate ways to integrate them. Where possible use \nValue Objects to model concepts in the downstream Context when objects from \nthe upstream Context flow in. By doing so you can integrate with a priority \non minimalism, that is, minimizing the number of properties that you assume \nresponsibility for managing in your downstream model. Using immutable Val-\nues results in assuming less responsibility.\nWhy Be So Responsible?\nUsing immutable Values results in assuming less responsibility.\nReusing an example from Bounded Contexts (2), recall that two Aggregates \nin the upstream Identity and Access Context have an impact on the down-\nstream Collaboration Context, as illustrated in Figure 6.1. In the Identity and \nAccess Context the two Aggregates are User and Role. The Collaboration \nContext is interested in whether a specific User plays a specific Role, namely, \nCollaboration Context\nModerator\nIdentity and Access\nContext\nUser\nRole\nFigure 6.1 The Moderator object in its Context is based on the state of a User and \nRole in a different Context. User and Role are Aggregates, but Moderator is a \nValue Object.\nwww.EBooksWorld.ir\n", "page": 275, "type": "text", "section": "Page 275"}
{"text": " \nINTEGRATE WITH MINIMALISM\n233\nModerator. The Collaboration Context uses its Anticorruption Layer (3) to \nquery the Open Host Service (3) of the Identity and Access Context. If the \nintegration-based query indicates that the Moderator role is being played by \nthe specific user, the Collaboration Context creates a representative object, \nnamely, a Moderator.\nModerator, among the Collaborator subclasses shown in Figure 6.2, is \nmodeled as a Value Object. Instances are statically created and associated with \na Forum Aggregate, the important point being the minimized impact that mul-\ntiple Aggregates in the upstream Identity and Access Context, possessing many \nattributes, have on the Collaboration Context. With just a few attributes of its \nown, a Moderator models an essential concept of the Ubiquitous Language \nspoken in the Collaboration Context. Furthermore, class  \nModerator contains \nno single attribute from the Role Aggregate. Rather, the class name itself cap-\ntures the Moderator role played by a user. By choice, the Moderator is a stat-\nically created Value instance, and there is no goal to keep it synchronized with \nthe remote Context of origin. This carefully chosen quality-of- \nservice contract \nlifts a potentially heavy burden off the consuming Context.\nOf course, there are times when an object in a downstream Context must \nbe eventually consistent with the partial state of one or more Aggregates in a \nremote Context. In that case we\u2019d design an Aggregate in the downstream con-\nsuming Context, because Entities are used to maintain a thread of continuity \nof change. But we should strive to avoid this modeling choice where possi-\nble. When you can, choose Value Objects to model integrations. This advice is \napplicable in many cases when consuming remote Standard Types.\n<<value object>>\nCollaborator\nemailAddress\nidentity\nname\n<<value object>>\nAuthor\n<<value object>>\nCreator\n<<value object>>\nModerator\n<<value object>>\nOwner\n<<value object>>\nParticipant\nFigure 6.2 The Collaborator class hierarchy of Value Objects. Only a few User\nattributes are retained from the upstream Context, with class names making roles \nexplicit.\nwww.EBooksWorld.ir\n", "page": 276, "type": "text", "section": "Page 276"}
{"text": "Chapter 6 VALUE OBJECTS\n234\nStandard Types Expressed as Values\nIn many systems and applications there is a need for what I call Standard \nTypes. Standard Types are descriptive objects that indicate the types of things. \nThere is the thing (Entity) or description (Value) itself, and there are also the \nStandard Types to distinguish them from other types of the same thing. I am \nunaware of an industry standard name for this concept, but I have also heard \nit called a type code and a lookup. The name type code doesn\u2019t say much. And \na lookup is a lookup of what? I prefer the name Standard Types because it is \nmore descriptive. To make this concept clearer, consider a few uses. In some \ncases these are modeled as Power Types.\nYour Ubiquitous Language defines a PhoneNumber (Value), which also \nrequires you to describe the type of each one. \u201cIs the phone number a home, \nmobile, work, or other type of number?\u201d asks your domain expert. Should dif-\nferent types of phone numbers be modeled as a class hierarchy? Having a sepa-\nrate class for each type makes it more difficult for clients to distinguish among \nthem. Here you\u2019d likely desire to use a Standard Type to describe the type of \nphone, either Home, Mobile, Work, or Other. These descriptions represent \nthe Standard Types of phones.\nAs I previously discussed, in a financial domain there is the possibility \nof having a Currency (Value) type to constrain a MonetaryValue to an \namount within a specific world currency. In this case the Standard Type would \nprovide a Value for each of the world\u2019s currencies: AUD, CAD, CNY, EUR, \nGBP, JPY, USD, and so on. Using a Standard Type here helps you avoid bogus \ncurrencies. Although the incorrect currency could be assigned to the Mone-\ntaryValue, a nonexistent currency could not be. If using a string attribute, \nyou could place the model into an invalid state. Consider the misspelled dool-\nars and the problems it would cause.\nYou might be working in the pharmaceutical field and designing for medi-\ncations that have various kinds of administration routes. A specific medication \n(Entity) has a long life cycle and change is managed over time\u2014it is concep-\ntualized, researched, developed, tested, manufactured, improved, and finally \ndiscontinued. You may or may not decide to manage the life cycle stages using \nStandard Types. These life cycle shifts may justifiably be managed in a few dif-\nferent Bounded Contexts. On the other hand, the directed patient administra-\ntion route of each medication can be classified by Standard Type descriptions, \nsuch as IV, Oral, or Topical.\nDepending on the level of standardization, these types may be maintained \nat the application level only, or be escalated in importance to shared corporate \ndatabases, or be available through national or international standards bodies. \nwww.EBooksWorld.ir\n", "page": 277, "type": "text", "section": "Page 277"}
{"text": " \nSTANDARD TYPES EXPRESSED AS VALUES\n235\nThe level of standardization can sometimes influence the way Standard Types \nare retrieved and used inside a model.\nWe may think of these as Entities because they have a life of their own in \na dedicated, native Bounded Context. Regardless of how they are created and \nmaintained by any kind of standards body, if possible we should strive to treat \nthem as Values in our consuming Context. This works well because they mea-\nsure and describe the types of things, and measures and descriptions are best \nmodeled as Values. Further, one instance of {IV}, for example, is just the same \nas any other instance of {IV}. They are clearly interchangeable, which also \nmeans that they are replaceable and can employ Value equality. Thus, if there \nis no need to maintain a continuity of change over the life cycle of descriptive \ntypes in your Bounded Context, model them as Values.\nFor the sake of maintenance it is common for Standard Types to natively \nreside in a separate Context from the models that consume them. There they \nare Entities and have a persistent life cycle with attributes such as identity,\nname, and description. There may be other attributes as well, but the ones \nmentioned are the most common to use in a consuming Context. We often use \njust one. This is in adherence to the goal to integrate with minimalism.\nAs a very simple example, consider a Standard Type that models a member \nof a group for which two types exist. There may be members that are users \nand members that are themselves groups (nested groups). This Java enum rep-\nresents one way to support a Standard Type:\npackage com.saasovation.identityaccess.domain.model.identity;\npublic enum GroupMemberType {\n    GROUP {\n        public boolean isGroup() {\n            return true;\n        }\n    },\n    USER {\n        public boolean isUser() {\n            return true;\n        }\n    };\n    public boolean isGroup() {\n        return false;\n    }\n    public boolean isUser() {\n        return false;\n    }\n}\nwww.EBooksWorld.ir\n", "page": 278, "type": "text", "section": "Page 278"}
{"text": "Chapter 6 VALUE OBJECTS\n236\nA GroupMember Value instance is instantiated with a specific Group-\nMemberType. To demonstrate, when a User or a Group is assigned to a \nGroup, the assigned Aggregate is asked to render a GroupMember corre-\nsponding to itself. Here is the toGroupMember() method implementation of \nclass User:\nprotected GroupMember toGroupMember() {\n    GroupMember groupMember =\n        new GroupMember(\n                this.tenantId(),\n                this.username(),\n                GroupMemberType.USER); // enum standard type\n    return groupMember;\n}\nUse of a Java enum is a very simple way to support a Standard Type. The \nenum provides a well-defined finite number of Values (in this case two), it is very \nlightweight, and it has by convention Side-Effect-Free Behavior. But where is the \nValue\u2019s textual description? There are two possible answers. Often there is no \nneed to provide a description of the type, just its name. Why? Textual descrip-\ntions are generally valid only in the User Interface Layer (14) and can be supplied \nby matching the type name to a view-centric property. Many times the view- \ncentric property must be localized (as in multilanguage computing), making this \ninappropriate to support in the model. Often the name of the Standard Type \nalone is the best attribute to use in the model. The second answer is that there \nare limited descriptions built right into the enum state names GROUP and USER.\nYou may render the descriptive names using the toString() behavior of each \ntype. But if necessary, descriptive text of each type may be modeled as well.\nThis sample Java enum Standard Type is also, in essence, an elegant and \nclutter-free State [Gamma et al.] object. At the bottom of the enum declara-\ntion there are two methods that implement the default behavior for all States, \nisGroup() and isUser(). By default, both of these methods answer false,\nwhich is the proper basic behavior. In each of the State definitions, however, the \nmethods are overridden to answer true as applicable for their specific State. \nWhen the state of the Standard Type is the GROUP, the isGroup() method is \noverridden to produce a true outcome. When the state of the Standard Type \nis the USER, the isUser() method is overridden to produce a true outcome. \nThe state changes by replacing the current enum value with a different one.\nThis enum demonstrates some very basic behavior. The State pattern imple-\nmentation can be more sophisticated as needed by the domain, adding more \nwww.EBooksWorld.ir\n", "page": 279, "type": "text", "section": "Page 279"}
{"text": " \nSTANDARD TYPES EXPRESSED AS VALUES\n237\nstandard behaviors that are overridden and specialized by each State. As it is, \nthis is an example of a Value type whose states are constrained to a well-de-\nfined set of constants. An important one is the BacklogItemStatusType,\nwhich provides PLANNED, SCHEDULED, COMMITTED, DONE, and REMOVED\nstates. I use this Standard Type approach throughout the three sample Bounded \nContexts. I think it keeps them as simple as possible.\nState Pattern Considered Harmful?\nSome consider the State pattern to be less than desirable. A common complaint is the \nneed to create an abstract implementation of each of the behaviors supported by the \ntype (the two methods at the bottom of GroupMemberType) and then to override \nthose behaviors when the given State must provide a specialized implementation. In \nJava this typically requires a separate class (usually in a separate file) for the abstract \ntype and also for each State. Like it or not, that is the way of the State pattern.\nI agree that when separate State classes must be developed\u2014one for each unique \nstate plus an abstract type\u2014it can become an unwieldy mess. The distinct behaviors \nin each class, perhaps mixed with some default behavior from the abstract class, \ncan lead to tight coupling of subclasses and lack of readability between types. This \nburden is especially taxing if you have a large number of States. However, I think \nthat the use of a Java enum is a very simple and possibly the more optimal way to \nuse the State pattern to produce a set of Standard Types. I think you get the best of \nboth approaches. You get a very simple Standard Type and a way to interrogate the \nstandard for its current State. This keeps behavior cohesive to the type. Limiting the \nState behavior makes for practical use.\nBut it\u2019s still possible that you don\u2019t like even this simple implementation of State, \nand to each his or her own.\nIf you decide that you dislike the use of Java enums to support Standard \nTypes, you can always use a unique Value instance for each type. However, if \nyour concern is primarily that you don\u2019t like the idea of using the State pattern, \nyou can easily use an enum for elegant Standard Type support without think-\ning of it as the State pattern. After all, I may be the first person to have put the \nenum-as-State thought into your mind. That being said, there are alternatives \nto implementing Standard Types other than the enum and Value approaches.\nAs one alternative, you can use an Aggregate as a Standard Type with one \ninstance of the Aggregate per type. Think twice before you run with this. Stan-\ndard types should generally not be maintained inside the Bounded Context \nthat consumes them. Widely used Standard Types should normally be main-\ntained in a separate Context with very carefully planned updates to consumers. \nInstead, you could choose to expose Standard Type Aggregates as immutable \nin consumer Contexts. But ask yourself if an immutable Entity is by definition \nreally an Entity. If you think not, you should consider modeling it as a shared \nimmutable Value Object instead.\nwww.EBooksWorld.ir\n", "page": 280, "type": "text", "section": "Page 280"}
{"text": "Chapter 6 VALUE OBJECTS\n238\nA shared immutable Value Object can be obtained from a hidden persistence \nstore. This is a viable choice if obtained from a Standard Type Service (7) or \nFactory (11). If employed, you should probably have one Service or Factory \nprovider for each set of Standard Types (one for phone number types, another \nfor postal address types, one for currency types), as depicted in Figure 6.3. In \nboth cases the concrete implementations of a Service or Factory would access \nthe persistence store to obtain the shared Values as needed, but clients would \nnever know that the Values are stored in a standards database. Using either a \nService or a Factory to provide the types also enables you to put a number of \nviable caching strategies to work easily and safely because the Values are read-\nonly from the store and immutable in the system.\nIn the end, I think it is best to be biased toward enum for Standard Types \nwhether or not you actually think of it as a State. If you have many possible \nStandard Type instances in a single category, consider code generation to pro-\nduce the enum. A code generation approach could read through all existing \nStandard Types in their respective persistence store (system of record) and cre-\nate a unique type/state per row, for example.\nIf you decide to use classical Value Objects as Standard Types, you may \nfind it useful to introduce a Service or Factory to statically create instances \nas needed. This would have similar motivations as discussed previously but \nwould be different in its implementation from those producing shared Values. \nIn this case your Service or Factory would provide statically created immutable \nValue instances of each individual Standard Type. Any changes to the under-\nlying Standard Type database entities in the system of record would not be \nTBL_CURRENCY_TYPE\n*ID \nNUMBER\n*NAME \nVARCHAR(50)\n*SYMBOL \nVARCHAR(4)\n<<value object>>\nCurrencyType\n<<domain service>>\n<<instantiates>>\nCurrencyService\nFigure 6.3 A Domain Service can be used to provide Standard Types. In this case the \nService goes out to the database to read the state of a requested CurrencyType.\nwww.EBooksWorld.ir\n", "page": 281, "type": "text", "section": "Page 281"}
{"text": " \nTESTING VALUE OBJECTS\n239\nautomatically reflected in the preexisting statically created representation \ninstances. If you desired to keep such statically created Value instances syn-\nchronized with the system of record, you\u2019d need to provide a custom solution to \nsearch for and update their state in your model. This could negate the potential \nusefulness of this approach.4 Thus, you might from design inception determine \nthat all such statically created Standard Type Values will never be updated in \nthe consuming Bounded Context. All competing forces must be weighed.\nTesting Value Objects\nTo emphasize test-first, I first present sample tests before I provide the Value \nObject implementation. These tests drive the domain model\u2019s design by provid-\ning examples of how a client will use each object.\nEmploying this style, we are not as interested in addressing the various \naspects of unit testing, thoroughly proving that the model is completely bul-\nletproof in every way. Rather, at this point in time there is more interest in \ndemonstrating how various objects in the domain model will be used by cli-\nents and what those clients can expect when they use them. It is essential to \nassume the client\u2019s perspective when designing the model in order to capture \nthe essential concepts. Otherwise, we could be modeling from our own per-\nspective instead of from the business\u2019s.\nBest Sample Code\nHere\u2019s one way of thinking about this style of test: If we were writing a user\u2019s man-\nual for the model, we would provide these tests as the most appropriate code sam-\nples for how clients should use this specific domain object.\nThis is not to say that unit tests should not be developed. All additional tests \nthat address team standards should and must be written. However, there are \ndifferent motivations for each type of test. Unit tests and behavioral tests have \ntheir place, as do the following modeling tests.\nThe Value Object selected is a good all-around representation taken from \nthe latest Core Domain (2), the Agile Project Management Context.\n 4. This would be a good time to model an Aggregate in an upstream Context also \nas an Aggregate in the downstream Context. They wouldn\u2019t be the same class or \nnecessarily contain all the same attributes, but modeling the downstream concept \nas an Aggregate would allow for eventual consistency and single point updates.\nwww.EBooksWorld.ir\n", "page": 282, "type": "text", "section": "Page 282"}
{"text": "Chapter 6 VALUE OBJECTS\n240\nIn this Bounded Context business domain experts speak \nof the \u201cbusiness priority of backlog items.\u201d To fulfill this \npart of the Ubiquitous Language we model the concept \nas a BusinessPriority. It provides calculated output \nsuitable for supporting the business analysis of the value \nof developing each product backlog item [Wiegers]. The \noutputs are cost percentage, or the cost of developing a \nspecific backlog item as compared to the cost of develop-\ning all others; total value, which is the total value gained \nby developing a specific backlog item; and value percent-\nage, as in the value of developing a specific backlog item compared to the value of \ndeveloping any other; and priority, which is the calculated priority the business should \nconsider giving this backlog item when compared against all others.\nThese tests actually emerged over multiple brief refactoring iterations of stepwise \nrefinements, although they are presented here as a finished set:\npackage com.saasovation.agilepm.domain.model.product;\nimport com.saasovation.agilepm.domain.model.DomainTest;\nimport java.text.NumberFormat;\npublic class BusinessPriorityTest extends DomainTest {\n    public BusinessPriorityTest() {\n        super();\n    }\n    ...\n    private NumberFormat oneDecimal() {\n        return this.decimal(1);\n    }\n    private NumberFormat twoDecimals() {\n        return this.decimal(2);\n    }\n    private NumberFormat decimal(int aNumberOfDecimals) {\n        NumberFormat fmt = NumberFormat.getInstance();\n        fmt.setMinimumFractionDigits(aNumberOfDecimals);\n        fmt.setMaximumFractionDigits(aNumberOfDecimals);\n        return fmt;\n    }\n}\nThe class has some fixture helpers. Since the team needed to test the accuracy \nof various calculations, they coded methods to provide NumberFormat instances for \nwww.EBooksWorld.ir\n", "page": 283, "type": "text", "section": "Page 283"}
{"text": " \nTESTING VALUE OBJECTS\n241\nfractional values that had either one or two places to the right of the decimal point. \nYou\u2019ll see next why these are useful:\n    public void testCostPercentageCalculation() throws Exception {\n        BusinessPriority businessPriority =\n            new BusinessPriority(\n                    new BusinessPriorityRatings(2, 4, 1, 1));\n        BusinessPriority businessPriorityCopy =\n            new BusinessPriority(businessPriority);\n        assertEquals(businessPriority, businessPriorityCopy);\n        BusinessPriorityTotals totals =\n            new BusinessPriorityTotals(53, 49, 53 + 49, 37, 33);\n        float cost = businessPriority.costPercentage(totals);\n        assertEquals(this.oneDecimal().format(cost), \"2.7\");\n        assertEquals(businessPriority, businessPriorityCopy);\n    }\nThe team came up with a good idea to test for immutability. Each test first created \nan instance of BusinessPriority and then made an equivalent copy of it using \nthe copy constructor. The first assertion in the test ensured that the copy constructor \nproduced a copy equal to the original.\nNext, they designed the test to create BusinessPriorityTotals and assigned \nit to the totals method variable. With totals they were able to use the cost-\nPercentage() \nquery method and assign the results to cost. They then asserted \nthat the value returned was 2.\n7, which was the manually calculated correct out-\ncome. Finally, they asserted that the behavior of method costPercentage() \nwas \ntruly side-effect free, which would be the case if businessPriority still had Value \nequality with businessPriorityCopy. From this test they gained a good idea of \nhow to calculate cost percentages and what their outcome would be like.\nNext, they needed to test the priority, the total value, and the value percentage \ncalculations, using the same basic plan of attack:\n    public void testPriorityCalculation() throws Exception {\n        BusinessPriority businessPriority =\n            new BusinessPriority(\n                    new BusinessPriorityRatings(2, 4, 1, 1));\n        BusinessPriority businessPriorityCopy =\n            new BusinessPriority(businessPriority);\nwww.EBooksWorld.ir\n", "page": 284, "type": "text", "section": "Page 284"}
{"text": "Chapter 6 VALUE OBJECTS\n242\n        assertEquals(businessPriorityCopy, businessPriority);\n        BusinessPriorityTotals totals =\n            new BusinessPriorityTotals(53, 49, 53 + 49, 37, 33);\n        float calculatedPriority = businessPriority.priority(totals);\n        assertEquals(\"1.03\",\n                     this.twoDecimals().format(calculatedPriority));\n        assertEquals(businessPriority, businessPriorityCopy);\n    }\n    public void testTotalValueCalculation() throws Exception {\n        BusinessPriority businessPriority =\n            new BusinessPriority(\n                    new BusinessPriorityRatings(2, 4, 1, 1));\n        BusinessPriority businessPriorityCopy =\n            new BusinessPriority(businessPriority);\n        assertEquals(businessPriority, businessPriorityCopy);\n        float totalValue = businessPriority.totalValue();\n        assertEquals(\"6.0\", this.oneDecimal().format(totalValue));\n        assertEquals(businessPriority, businessPriorityCopy);\n    }\n    public void testValuePercentageCalculation() throws Exception {\n        BusinessPriority businessPriority =\n            new BusinessPriority(\n                    new BusinessPriorityRatings(2, 4, 1, 1));\n        BusinessPriority businessPriorityCopy =\n            new BusinessPriority(businessPriority);\n        assertEquals(businessPriority, businessPriorityCopy);\n        BusinessPriorityTotals totals =\n            new BusinessPriorityTotals(53, 49, 53 + 49, 37, 33);\n        float valuePercentage =\n               businessPriority.valuePercentage(totals);\n        assertEquals(\"5.9\", this.oneDecimal().format(valuePercentage));\n        assertEquals(businessPriorityCopy, businessPriority);\n    }\nwww.EBooksWorld.ir\n", "page": 285, "type": "text", "section": "Page 285"}
{"text": " \nIMPLEMENTATION\n243\nTests Should Have Domain Meaning\nYour model tests should have meaning to your domain experts.\nNontechnical domain experts\u2014given a bit of help\u2014reading these example-based \ntests were able to understand just how BusinessPriority was used, the kinds of \noutcomes it produced, that its behavior was guaranteed to be side-effect free, and \nthat it adhered to the concepts and intent of the Ubiquitous Language.\nImportantly, the state of the Value Object was guaranteed immutable for every \nusage. Clients could produce results from the priority calculations of any number of \nproduct backlog items, sort them, compare them, and adjust the BusinessPriori-\ntyRatings of each item as needed.\nImplementation\nI like this BusinessPriority example because it demonstrates all of the \nValue characteristics and more. Besides showing how to design for immutabil-\nity, conceptual wholeness, replaceability, Value equality, and Side-Effect-Free \nBehavior, it also demonstrates how you can use a Value type as a Strategy\n[Gamma et al.] (aka Policy).\nAs each test method was developed, the team understood \nmore about how a client would use a BusinessPriority,\nenabling them to implement it to behave as the tests asserted \nit should. Here is the basic class definition along with construc-\ntors that the team coded:\npublic final class BusinessPriority implements Serializable  {\n    private static final long serialVersionUID = 1L;\n    private BusinessPriorityRatings ratings;\n    public BusinessPriority(BusinessPriorityRatings aRatings) {\n        super();\n        this.setRatings(aRatings);\n    }\n    public BusinessPriority(BusinessPriority aBusinessPriority) {\n        this(aBusinessPriority.ratings());\n    }\nwww.EBooksWorld.ir\n", "page": 286, "type": "text", "section": "Page 286"}
{"text": "Chapter 6 VALUE OBJECTS\n244\nThe team decided to declare their Value types Serializable. There are times \nwhen a Value instance needs to be serialized, such as when it is communicated to a \nremote system, and may be useful for some persistence strategies.\nThis BusinessPriority itself was designed to hold a Value property named \nratings of type BusinessPriorityRatings (not shown here). The ratings\nproperty described the business value and expense trade-off of either implement-\ning, or not implementing, a given product backlog item. The BusinessPriority-\nRatings type provided the BusinessPriority with benefit, cost, penalty,\nand risk ratings, which enabled a range of calculations to be performed.\nUsually I support at least two constructors for each of my Value Objects. \nThe first constructor takes the full complement of parameters necessary to \nderive and/or set state attributes. This primary constructor first initializes its \ndefault state. The basic attribute initialization is performed first by invoking \nprivate setters. I recommend the use of self-delegation and demonstrate its use \nhere with private setters.\nKeeping Values Immutable\nOnly the primary constructor(s) use self-delegation to set properties/attributes. No \nother methods shall self-delegate to setter methods. Since all setter methods in a \nValue Object are always private scope, there is no opportunity for attributes to be \nexposed to mutation by consumers. These are two important factors in maintaining \nthe immutability of Values.\nThe second constructor is used to copy an existing Value to create a new \none, or what is called a copy constructor. This constructor performs what\u2019s \nknown as a shallow copy as it self-delegates to its primary constructor, passing \nas parameters each of the corresponding attributes of the Value being copied. \nWe could perform a deep copy or clone where all contained attributes and \nproperties are themselves copied to produce a completely unique object, but \nstill equal to the value of the one copied. However, this many times proves to \nbe both complex and unnecessary when dealing with Values. If a deep copy is \never needed, it can be added. But when dealing with immutable Values, it is \nnever a problem to share attributes/properties between instances.\nThis second constructor, the copy constructor, is important for unit \ntests. When we test a Value Object, we want to include verification that it is \nimmutable. As demonstrated earlier, when the unit test begins, create the new \ntest Value Object instance and a copy of it using the copy constructor, and \nassert that the two instances are equal. Next, test the Value instance Side- \nEffect-Free Behavior. If all test goal assertions pass, the final assertion is that \nthe tested and the copied instances are still equal.\nwww.EBooksWorld.ir\n", "page": 287, "type": "text", "section": "Page 287"}
{"text": " \nIMPLEMENTATION\n245\nNext, we implement the Strategy/Policy part of the Value type:\n    public float costPercentage(BusinessPriorityTotals aTotals) {\n        return (float) 100 * this.ratings().cost() /\n            aTotals.totalCost();\n    }\n    public float priority(BusinessPriorityTotals aTotals) {\n        return\n            this.valuePercentage(aTotals) /\n                (this.costPercentage(aTotals) +\n                    this.riskPercentage(aTotals));\n    }\n    public float riskPercentage(BusinessPriorityTotals aTotals) {\n        return (float) 100 * this.ratings().risk() /\n            aTotals.totalRisk();\n    }\n    public float totalValue() {\n        return this.ratings().benefit() + this.ratings().penalty();\n    }\n    public float valuePercentage(BusinessPriorityTotals aTotals) {\n        return (float) 100 * this.totalValue() / aTotals.totalValue();\n    }\n    public BusinessPriorityRatings ratings() {\n        return this.ratings;\n    }\nSome of the calculation behavior requires a parameter of type Business-\nPriorityTotals. This Value provides a description of the cost-risk totals \nacross all product backlog items. Totals are necessary when calculating per-\ncentages and the overall business priority compared to all other backlog items. \nNone of these behaviors modifies its own instance state. We assert this exter-\nnally in tests by comparing the copied state with the current state following the \nexecution of each behavior.\nThere currently is no Separated Interface [Fowler, P of EAA] for the Strategy \nbecause there is at present only one implementation. No doubt in time that will \nchange, and customers of the Agile PM SaaS product will be given other busi-\nness priority calculation options, each with its own Strategy implementation.\nThe method names of the Side-Effect-Free Functions are important. \nAlthough these methods all return Values (because they are CQS query meth-\nods), they purposely avoid the use of the get-prefix JavaBean naming conven-\ntion. This simple but effective approach to object design keeps the Value Object \nwww.EBooksWorld.ir\n", "page": 288, "type": "text", "section": "Page 288"}
{"text": "Chapter 6 VALUE OBJECTS\n246\nfaithful to the Ubiquitous Language. The use of  \ngetValuePercentage()\nis a technical computer statement, but valuePercentage() is a fluent \nhuman-readable language expression.\nWhere Did My Fluent Java Go?\nI think that the JavaBean specification has had a negative impact on object \ndesign, one that doesn\u2019t promote the principles of Domain-Driven Design \nor good object design in general. Consider the Java API that existed prior \nto the JavaBean specification. Take java.lang.String, for one example. \nThere are but a few query methods on the class String that are prefixed by \nget. Most of the query methods are named more fluently, such as charAt(),\ncompareTo(), concat(), contains(), endsWith(), indexOf(), length(),\nreplace(), startsWith(), substring(), and the like. There\u2019s no Java-\nBean code smell there! Of course, this example alone doesn\u2019t prove my \npoint. Nonetheless, it is true that Java APIs since the JavaBean specifica-\ntion have been greatly influenced and lack fluency in expression. A fluent, \nhuman- \nreadable language expression is a very worthwhile style to embrace.\nIf you are concerned about tooling that depends on the JavaBean specifica-\ntion, there are solutions. For example, Hibernate provides support for field-\nlevel access (object attributes). Thus, as far as Hibernate is concerned, your \nmethods can be named as desired without a negative impact on persistence.\nWith other tools there could be a downside to designing with expressive \ninterfaces, however. If you desire to use the standard Java EL or OGNL, for \ninstance, you won\u2019t be able to render such types directly. You would have to \nuse another means, such as a Data Transfer Object [Fowler, P of EAA] with \ngetters, to transfer Value Object properties to the user interface. Since DTO \nis a commonly used pattern, albeit often technically unnecessary, some may \nfind this of little consequence. If DTO is not an option for you, there are oth-\ners. Consider the Presentation Model as discussed in Application (14).\nSince your Presentation Model can serve as an Adapter [Gamma et al.], it \ncan surface getters for use by views that use EL, for example. Yet, if all else \nfails, you may need to grudgingly design your domain objects with getters.\nIf you reach that conclusion, you should still not design Value Objects \nwith full JavaBean capabilities that would allow their state to be initialized \nthrough public setters. That would violate their essential Value immutability \ncharacteristic.\nThe next set of methods includes the standard object overrides equals(),\nhashCode(), and toString():\nwww.EBooksWorld.ir\n", "page": 289, "type": "text", "section": "Page 289"}
{"text": " \nIMPLEMENTATION\n247\n    @Override\n    public boolean equals(Object anObject) {\n        boolean equalObjects = false;\n        if (anObject != null &&\n                this.getClass() == anObject.getClass()) {\n            BusinessPriority typedObject = (BusinessPriority) anObject;\n            equalObjects =\n                this.ratings().equals(typedObject.ratings());\n        }\n        return equalObjects;\n    }\n    @Override\n    public int hashCode() {\n        int hashCodeValue =\n            + (169065 * 179)\n            + this.ratings().hashCode();\n        return hashCodeValue;\n    }\n    @Override\n    public String toString() {\n        return\n            \"BusinessPriority\"\n            + \" ratings = \" + this.ratings();\n    }\nThe equals() \nmethod fulfills the Value Object requirement to check for Value \nequality, one of the five Value characteristics. Here we always eliminate null\nparameters from equality. The class of the parameter must be the same as the \nclass of the Value. If they are the same, each of the properties/attributes is \ncompared in both Values. If each one is affirmed as equal to its corresponding \nproperty/attribute, the Whole Values are considered equal.\nPer Java standards, hashCode() \nhas the same contract as equals() \nin that \nall Values that are equal also produce equal hash code values.\nThere is nothing special about toString(). It creates a human-readable \nrepresentation of the Value instance state. You may design the representation \nformat as needed.\nThere are a few remaining methods to review:\n    protected BusinessPriority() {\n        super();\n    }\n    private void setRatings(BusinessPriorityRatings aRatings) {\n        if (aRatings == null) {\nwww.EBooksWorld.ir\n", "page": 290, "type": "text", "section": "Page 290"}
{"text": "Chapter 6 VALUE OBJECTS\n248\n            throw new IllegalArgumentException(\n                    \"The ratings are required.\");\n        }\n        this.ratings = aRatings;\n    }\n}\nThe zero-argument constructor is provided for the sake of framework tools \nthat require it, such as Hibernate. Since the zero-argument constructor is \nalways hidden, there is no danger of model clients creating invalid instances. \nHibernate functions perfectly well with hidden constructors and accessors. This \nconstructor enables Hibernate and other tools to create instances of the type as \nthey are being reconstituted from, for example, the persistence store. Tools use \nthe zero-argument constructor to create an initially hollow instance and then \ncall each property/attribute setter to hydrate the object. Optionally you can tell \nHibernate to bypass setter methods and directly set attributes, as is the case \nwith this model since it doesn\u2019t provide a complete JavaBean interface. Just to \nreiterate, model clients use the public constructors, never the hidden one.\nFinally, the class definition ends with the property setter for ratings. One \nof the strengths of self-encapsulation/delegation is seen in this method. An \naccessor method\u2014getter or setter\u2014need not be limited to setting an instance \nfield. It can also perform important Assertions [Evans], a key element to suc-\ncessful software development in general and DDD models specifically.\nThe Assertion for valid parameters is called a guard, because it guards the \nmethod from being subjected to obviously invalid data. Guards can and should \nbe used in any method when wrong parameters would cause more serious \nproblems later if correctness were otherwise taken for granted. Here the setter \nasserts that the parameter aRatings is not null, and if it happens to be, it \nthrows an IllegalArgumentException. True, the setter is logically used \nonly once in the Value\u2019s lifetime. Still, the Assertion is a well-placed guard. You \nwill see the advantages of self-delegation demonstrated elsewhere, too. Specif-\nically, Entities (5) explains the technique thoroughly as part of a discussion of \nvalidation.\nPersisting Value Objects\nThere are a variety of ways to persist Value Object instances to a persistent \nstore. In a general sense it involves serializing the object to some text or \nbinary format and saving it to disk. However, since we are not concerned \nwith persisting individual Value instances on their own, I won\u2019t be focusing \nwww.EBooksWorld.ir\n", "page": 291, "type": "text", "section": "Page 291"}
{"text": " \nPERSISTING VALUE OBJECTS\n249\non general-purpose persistence. Rather, we are more interested in persisting \nValues along with the state of the Aggregate instances that contain them. The \nfollowing approaches assume that a parent Entity ultimately holds references \nto the Value instances that get persisted. All of the following examples are \nbased on the assumption that an Aggregate is being added to or read from \nits Repository (12), and its contained Values are persisted and reconstituted \nbehind the scenes along with the Entity\u2014such as the Aggregate Root\u2014that \ncontains them.\nObject-relational mapping (ORM, such as Hibernate) persistence is popu-\nlar and widely used. However, using an ORM to map every class to a table \nand every attribute to a column adds complexity, which may be unwarranted. \nRising in popularity is the use of NoSQL databases and key-value stores \nbecause of their ability to provide high-performance, scalable, fault-tolerant, \nand highly available enterprise storage. To boot, key-value stores can greatly \nsimplify Aggregate persistence. In this chapter I stick with ORM-based per-\nsistence. Because NoSQL, key-value stores persist Aggregates exceptionally \nwell, I give attention to that style in Repositories (12).\nBut before we jump into Value ORM persistence examples, there\u2019s a vital \nmodeling commitment that must be well understood and diligently followed. \nSo to start off, let\u2019s tackle what can happen when data modeling (as opposed to \ndomain modeling) has an inappropriate influence on your domain model, and \nwhat can be done to reject this wrong and harmful influence.\nReject Undue Influence of Data Model Leakage\nProbably most times that a Value Object is persisted to a data store (for exam-\nple, using an ORM tool along with a relational database) it is stored in a denor-\nmalized fashion; that is, its attributes are stored in the same database table row \nas its parent Entity object. This makes the storage and retrieval of Values clean \nand optimized and prevents any persistence store leakage into the model. It\u2019s \nboth a pleasure and a relief when Values can be persisted this way.\nThere are times, however, when a Value Object in the model will of neces-\nsity be stored as an Entity with respect to a relational persistence store. In \nother words, when persisted, an instance of a specific Value Object type will \noccupy its own row in a relational database table that exists specifically for its \ntype, and it will have its own database primary key column. This happens, for \nexample, when supporting a collection of Value Object instances with ORM. \nIn such cases the Value type persistent data is modeled as a database entity.\nIs this an indication that the domain model object should reflect the design \nof the data model and be an Entity rather than a Value? No. When you face \nthe consequences of this impedance mismatch, it is important to maintain a \nwww.EBooksWorld.ir\n", "page": 292, "type": "text", "section": "Page 292"}
{"text": "Chapter 6 VALUE OBJECTS\n250\ndomain model perspective rather than a persistence perspective. To keep your \nperspective on the domain model you can ask yourself these questions:\n 1. Is the concept I am modeling a thing in the domain or does it measure, \nquantify, or describe a thing as one of its properties?\n 2. If modeled correctly to describe an element of the domain, must this \nmodel concept possess all or most of the value characteristics outlined \npreviously?\n 3. Am I considering the use of an Entity in the model only because the \nunderlying data model must store the domain model object as an entity?\n 4. Am I using an Entity because the domain model requires unique iden-\ntity, I care about individual instances, and I must manage a continuity of \nchange over the object\u2019s life cycle?\nIf your answers are \u201cDescribes, Yes, Yes, and No,\u201d you should use a Value \nObject. Model the persistence store in the way necessary to deal with the stor-\nage of the object, but don\u2019t let that influence the way your team conceptualizes \nthe Value property in the domain model.\nThe Data Model Should Be Subordinate\nDesign your data model for the sake of your domain model, not your domain model \nfor the sake of your data model.\nIf at all possible, always design your data model for the sake of your domain \nmodel, not your domain model for the sake of your data model. If you do the \nformer, you will maintain a domain model perspective. If you do the latter, you \nwill maintain a persistence perspective and your domain model will tend to \nserve merely as a projection of your data model. As you discipline your mind \nto think in terms of the domain model\u2014DDD-think\u2014rather than the data \nmodel, you will avoid the negative consequences of data model leakage. See \nEntities (5) for more discussion of DDD-think.\nOf course, there are times when database referential integrity matters (such \nas for foreign keys). Absolutely, you want key columns to be properly indexed. \nSure, there certainly is the need to support business intelligence reporting \ntools that operate against your business data. You can enable all these facets \nin appropriate and necessary places. Most conclude that reporting and busi-\nness intelligence should not operate against your production data and should \ninstead have a dedicated, specially designed data model. Following this more \nstrategic mentality frees you to design your domain model\u2019s backing data \nmodel to best support your DDD efforts.\nwww.EBooksWorld.ir\n", "page": 293, "type": "text", "section": "Page 293"}
{"text": " \nPERSISTING VALUE OBJECTS\n251\nWhatever technical facets your data model uses, its entities, primary keys, \nreferential integrity, and indexes simply must not drive the way you model \ndomain objects. DDD is not about structuring data in a normalized fashion. It \nis about modeling the Ubiquitous Language in a consistent Bounded Context. \nI encourage you to adhere to DDD, not to data structure. As you do so, you \nshould wisely take every possible step to hide all vestiges of data model leakage \n(which will occur to at least a minimal degree when using an ORM) from your \ndomain model and its clients. This is something I discuss in the next section.\nORM and Single Value Objects\nPersisting a single Value Object instance to a database is usually very straight-\nforward. Here my focus is on the use of Hibernate with the MySQL relational \ndatabase. The basic idea is to store each of the attributes of the Value in sep-\narate columns of the row where its parent Entity is stored. Said another way, \na single Value Object is denormalized into its parent Entity\u2019s row. There are \nadvantages to employing convention for column naming to clearly identify and \nstandardize the way serialized objects are named. I present a persisted Value \nObject naming convention here.\nWhen using Hibernate to persist a single instance of a Value Object, use the \ncomponent mapping element. The component element is employed because \nit enables the Value to be mapped directly into the parent Entity table row \nin a denormalized fashion. This is an optimal serialization technique that \nstill enables Values to be included in SQL queries. Here is the section of the \nHibernate mapping document that describes the mapping of the Business-\nPriority Value Object held by its parent Entity, class BacklogItem:\n<component name=\"businessPriority\"\n    class=\"com.saasovation.agilepm.domain.model.product.\u03a6\n        BusinessPriority\">\n    <component name=\"ratings\"\n           class=\"com.saasovation.agilepm.domain.model.product.\u03a6\n               BusinessPriorityRatings\">\n        <property\n            name=\"benefit\"\n            column=\"business_priority_ratings_benefit\"\n            type=\"int\"\n            update=\"true\"\n            insert=\"true\"\n            lazy=\"false\"\n            />\n        <property\n            name=\"cost\"\n            column=\"business_priority_ratings_cost\"\nwww.EBooksWorld.ir\n", "page": 294, "type": "text", "section": "Page 294"}
{"text": "Chapter 6 VALUE OBJECTS\n252\n            type=\"int\"\n            update=\"true\"\n            insert=\"true\"\n            lazy=\"false\"\n            />\n        <property\n            name=\"penalty\"\n            column=\"business_priority_ratings_penalty\"\n            type=\"int\"\n            update=\"true\"\n            insert=\"true\"\n            lazy=\"false\"\n            />\n        <property\n            name=\"risk\"\n            column=\"business_priority_ratings_risk\"\n            type=\"int\"\n            update=\"true\"\n            insert=\"true\"\n            lazy=\"false\"\n            />\n    </component>\n</component>\nThis is a good example because it demonstrates a simple Value Object \nmapping, but one that contains a child Value Object instance. Recall that \nBusinessPriority has a single ratings Value property and no additional \nattributes. Thus, in the mapping description the outer component element \nhas a nested component element. This is used to denormalize the single con-\ntained ratings Value property of type BusinessPriorityRatings. Since \nthe BusinessPriority has no attributes of its own, there are none mapped \nin the outer component. Instead we immediately nest the mapping of its \nratings Value property. In the end, we actually store only the four integer \nattributes of the BusinessPriorityRatings instance into four separate \ncolumns of table tbl_backlog_item. So we map two component element \nValue Objects, one that has no attributes of its own and an inner Value that \nhas four attributes.\nNote the use of standard column naming of each of the Hibernate prop-\nerty elements. The naming convention is based on the navigation path from \nthe ultimate parent Value down to the individual attributes. For example, con-\nsider the navigation path from the BusinessPriority down to the benefit\nattribute of the ValueCostRiskRatings instance. Logically it is\nbusinessPriority.ratings.benefit\nTo represent this navigation path as a single relational column name I use the \nfollowing:\nwww.EBooksWorld.ir\n", "page": 295, "type": "text", "section": "Page 295"}
{"text": " \nPERSISTING VALUE OBJECTS\n253\nbusiness_priority_ratings_benefit\nOf course, you can use another representative name if you like. Perhaps you \nprefer one that mixes camel case with underscores:\nbusinessPriority_ratings_benefit\nTo your mind this sample notation may better express the navigation. I have \nstandardized on all underscores since it leans more toward traditional SQL \ncolumn names rather than object names. The corresponding MySQL database \ntable definition includes the following columns:\nCREATE TABLE `tbl_backlog_item` (\n    ...\n    `business_priority_ratings_benefit` int NOT NULL,\n    `business_priority_ratings_cost` int NOT NULL,\n    `business_priority_ratings_penalty` int NOT NULL,\n    `business_priority_ratings_risk` int NOT NULL,\n    ...\n) ENGINE=InnoDB;\nTogether, the Hibernate mapping and relational database table definition \nprovide both an optimal and queryable persistent object. Because Value attri-\nbutes are denormalized into their parent Entity\u2019s table row, there is no need for \nthe database to use joins to retrieve even a deeply nested Value instance. When \nyou specify an HQL query, Hibernate is able to easily map from the object \nexpression of an object attribute into an optimal SQL query expression using a \ncolumn, where\n    businessPriority.ratings.benefit\nbecomes\n    business_priority_ratings_benefit\nHence, although there is a clear impedance mismatch between objects and \nrelational databases, we have realized one of the more functional and optimal \nmappings possible.\nORM and Many Values Serialized into a Single Column\nThere are unique challenges associated with mapping a collection of many \nValue Objects into a relational database using an ORM. To be clear, by col-\nlection I mean a List or Set that is held by an Entity and contains zero, \none, or more Value instances. The challenges are not insurmountable, but the \nobject-relational impedance mismatch becomes glaringly obvious here.\nwww.EBooksWorld.ir\n", "page": 296, "type": "text", "section": "Page 296"}
{"text": "Chapter 6 VALUE OBJECTS\n254\nOne option available with Hibernate object-relational mapping is to seri-\nalize the entire collection of objects into a textual representation and persist \nthe representation into a single column. This approach has some drawbacks. \nHowever, in some cases the drawbacks are unobtrusive and may be summarily \nignored in favor of leveraging this option\u2019s advantages. In such cases you may \ndecide to use this Value collection persistence option. Here are the potential \ndrawbacks to consider:\n\u2022 Column width. Sometimes you cannot determine the maximum number \nof Value elements in the collection, or the maximum size of each serial-\nized Value. For example, some object collections could have any number \nof elements\u2014an unknown upper limit. Also, each of the Value elements \nin the collection could have an indeterminate serialized representation \ncharacter width. This can happen when one or more of the attributes of \nthe Value type are of type String and the length in characters is many \nor open-ended. In either or both of these situations, it is possible that \nthe serialized form or the entire collection would overflow the maximum \navailable width of a character column. This may be further compounded \nby character columns that have a relatively narrow maximum width, or \nby the total maximum number of bytes available to store an entire row \nof data. While the MySQL InnoDB engine, for example, has a maxi-\nmum VARCHAR width of 65,535 characters, it also has a limit of 65,535 \ntotal bytes of storage for a single row. You must allow room for enough \ncolumns to store an entire Entity. Oracle Database has a maximum \nVARCHAR2/NVARCHAR2 width of 4,000. If you cannot predetermine the \nmaximum width required to store a serialized representation of a Value \ncollection and/or your maximum column width could be overflowed, you \nshould avoid this option.\n\u2022 Must query. Since with this style Value collections are serialized into a \nflat text representation, the attributes of individual Value elements cannot \nbe used in SQL query expressions. If any of the Value attributes must be \nqueryable, you cannot use this option. It\u2019s possible that this is a less likely \nreason to avoid this option since the need to query one or more attributes \nout of objects in a contained collection could be rare.\n\u2022 Requires custom user type. To use this approach you must develop a \nHibernate custom user type that manages serialization and deserialization \nof each collection. Personally, I think this is less obtrusive than the other \nconcerns because a single, well-thought-out, custom user type implemen-\ntation can support collections of every Value Object type (one size fits all).\nwww.EBooksWorld.ir\n", "page": 297, "type": "text", "section": "Page 297"}
{"text": " \nPERSISTING VALUE OBJECTS\n255\nI don\u2019t provide a Hibernate custom user type here to manage collection seri-\nalization to a single column, but the Hibernate community provides plenty of \nguidance for you to implement your own.\nORM and Many Values Backed by a Database Entity\nA very straightforward approach to persisting a collection of Value instances \nusing Hibernate (or other ORM) and a relational database is to treat the Value \ntype as an entity in the data model. To reiterate what I asserted in the section \n\u201cReject Undue Influence of Data Model Leakage,\u201d this approach must not lead \nto wrongly modeling a concept as an Entity in the domain model just because \nit is best represented as a database entity for the sake of persistence. It is the \nobject-relation impedance mismatch that in some cases requires this approach, \nnot a DDD principle. If there were a perfectly matched persistence style avail-\nable to you, you\u2019d model the concept as a Value type and never give database \nentity characteristics a second thought. It helps our domain modeling mind to \nthink that way.\nTo accomplish this we can employ a Layer Supertype [Fowler, P of EAA]. \nPersonally it makes me feel better to tuck away the necessary surrogate iden-\ntity (primary key). However, since every Object in Java (and other languages) \nalready has an internal unique identity that is used only by the virtual machine, \nyou may feel justified in adding a specialized identity directly to the Value. I \nthink whatever approach we prefer, when working around the object-relational \nimpedance mismatch we need to formulate a convincing justification in our \nminds for why we make a technical choice. My preferences are addressed next.\nHere\u2019s an example of my preferred approach to surrogate keys, which uses \ntwo Layer Supertype classes:\npublic abstract class IdentifiedDomainObject\n        implements Serializable  {\n    private long id = -1;\n    public IdentifiedDomainObject() {\n        super();\n    }\n    protected long id() {\n        return this.id;\n    }\n    protected void setId(long anId) {\n        this.id = anId;\n    }\n}\nwww.EBooksWorld.ir\n", "page": 298, "type": "text", "section": "Page 298"}
{"text": "Chapter 6 VALUE OBJECTS\n256\nThe first Layer Supertype involved is IdentifiedDomainObject. This \nabstract base class provides a basic surrogate primary key that is hidden from \nthe view of clients. Because the accessor methods are declared protected,\nclients will never have to wonder if the methods are for their use. Of course, \nyou can further avoid any knowledge of these methods by declaring their scope \nprivate. Hibernate has no problems using method or field reflection on any \nscope other than public.\nNext, I provide one more Layer Supertype that is specific to Value Objects:\npublic abstract class IdentifiedValueObject\n        extends IdentifiedDomainObject  {\n    public IdentifiedValueObject() {\n        super();\n    }\n}\nYou may consider class IdentifiedValueObject as merely a marker class, \na behaviorless subclass of IdentifiedDomainObject. I see it as having a \nsource code documentation benefit because it makes the modeling challenge it \naddresses more explicit. Along those lines, class IdentifiedDomain \nObject\nhas a second direct abstract subclass named Entity, which is discussed in \nEntities (5). I like this approach. You may prefer to eliminate these extra classes.\nNow that there is a convenient and suitably hidden means to give any Value \ntype a surrogate identity, here\u2019s a sample class that puts it to use:\npublic final class GroupMember extends IdentifiedValueObject  {\n    private String name;\n    private TenantId tenantId;\n    private GroupMemberType type;\n    public GroupMember(\n            TenantId aTenantId,\n            String aName,\n            GroupMemberType aType) {\n        this();\n        this.setName(aName);\n        this.setTenantId(aTenantId);\n        this.setType(aType);\n        this.initialize();\n    }\n    ...\n}\nwww.EBooksWorld.ir\n", "page": 299, "type": "text", "section": "Page 299"}
{"text": " \nPERSISTING VALUE OBJECTS\n257\nClass GroupMember is a Value type that is collected by the Root Entity of \nthe Aggregate class Group. The Root Entity contains any number of Group-\nMember instances. Now with each GroupMember instance being uniquely \nidentified to the data model using its surrogate primary key, we are free to \nmap its persistence as a database entity while keeping it a Value in the domain \nmodel. Here\u2019s the relevant portion of class Group:\npublic class Group extends Entity  {\n    private String description;\n    private Set<GroupMember> groupMembers;\n    private String name;\n    private TenantId tenantId;\n    public Group(\n            TenantId aTenantId,\n            String aName,\n            String aDescription) {\n        this();\n        this.setDescription(aDescription);\n        this.setName(aName);\n        this.setTenantId(aTenantId);\n        this.initialize();\n    }\n    ...\n    protected Group() {\n        super();\n        this.setGroupMembers(new HashSet<GroupMember>(0));\n    }\n    ...\n}\nClass Group will gradually build up any number of GroupMember\ninstances in its Set of groupMembers. Keep in mind that if you will ever per-\nform whole collection replacement, always use the Collection\u2019s clear()\nmethod prior to replacement. Doing so ensures that the backing Hibernate \nCollection implementation will delete obsolete elements from the data store. \nThe following is not an actual Group method, but an example provided to \ndemonstrate how, in general, to avoid orphaned Value elements when perform-\ning whole collection replacement:\npublic void replaceMembers(Set<GroupMember> aReplacementMembers) {\n    this.groupMembers().clear();\n    this.setGroupMembers(aReplacementMembers);\n}\nwww.EBooksWorld.ir\n", "page": 300, "type": "text", "section": "Page 300"}
{"text": "Chapter 6 VALUE OBJECTS\n258\nI think this ORM leakage into the model is unobtrusive because it uses a \ncommon Collection facility, and besides, the client doesn\u2019t see it. Synchro-\nnizing collection contents with the database doesn\u2019t always require careful \nthought. A single Value data store deletion is automatically covered by the use \nof Collection\u2019s remove() \nmethod, so in that case there\u2019s no ORM leakage \nat all.\nNext, we are interested in the section of Group\u2019s mapping description that \nmaps the collection:\n<hibernate-mapping>\n    <class name=\"com.saasovation.identityaccess.domain.model.\u21b5\n        identity.Group\"\n     table=\"tbl_group\" lazy=\"true\">\n        ...\n        <set name=\"groupMembers\" cascade=\"all,delete-orphan\"\n          inverse=\"false\" lazy=\"true\">\n            <key column=\"group_id\" not-null=\"true\" />\n            <one-to-many class=\"com.saasovation.\u21b5\n              identityaccess.domain.model.identity.GroupMember\" />\n        </set>\n        ...\n    </class>\n</hibernate-mapping>\nThe Set of groupMembers is mapped exactly as a database entity. Addition-\nally we see the full GroupMember mapping description:\n<hibernate-mapping>\n    <class name=\"com.saasovation.identityaccess.domain.model.\u21b5\n           identity.GroupMember\"\n           table=\"tbl_group_member\" lazy=\"true\">\n        <id\n            name=\"id\"\n            type=\"long\"\n            column=\"id\"\n            unsaved-value=\"-1\">\n            \n            <generator class=\"native\"/>\n        </id>\n        <property\n            name=\"name\"\n            column=\"name\"\n            type=\"java.lang.String\"\n            update=\"true\"\n            insert=\"true\"\n            lazy=\"false\"\n        />\n", "page": 301, "type": "text", "section": "Page 301"}
{"text": " \nPERSISTING VALUE OBJECTS\n259\n        <component name=\"tenantId\"\n            class=\"com.saasovation.identityaccess.domain.model.\u03a6\n                identity.TenantId\">\n            <property\n                name=\"id\"\n                column=\"tenant_id_id\"\n                type=\"java.lang.String\"\n                update=\"true\"\n                insert=\"true\"\n                lazy=\"false\"\n            />\n        </component>\n        <property\n            name=\"type\"\n            column=\"type\"\n            type=\"com.saasovation.identityaccess.infrastructure.\u03a6\n                persistence.GroupMemberTypeUserType\"\n            update=\"true\"\n            insert=\"true\"\n            not-null=\"true\"\n        />\n    </class>\n</hibernate-mapping>\nNote the <id> element that defines the persistence surrogate primary key. And \nfinally, here is the corresponding MySQL tbl_group_member description:\nCREATE TABLE `tbl_group_member` (\n    `id` int(11) NOT NULL auto_increment,\n    `name` varchar(100) NOT NULL,\n    `tenant_id_id` varchar(36) NOT NULL,\n    `type` varchar(5) NOT NULL,\n    `group_id` int(11) NOT NULL,\n    KEY `k_group_id` (`group_id`),\n    KEY `k_tenant_id_id` (`tenant_id_id`),\n    CONSTRAINT `fk_1_tbl_group_member_tbl_group` \n        FOREIGN KEY (`group_id`) REFERENCES `tbl_group` (`id`),\n    PRIMARY KEY (`id`)\n) ENGINE=InnoDB;\nWhen we look at the GroupMember mapping and database table descrip-\ntion, we get the strong impression that we are dealing with an entity. There\u2019s \nthe primary key named id. There\u2019s the separate table that must be joined with \ntbl_group. There\u2019s the foreign key back to tbl_group. By any other name \nwe are dealing with an entity, but only from the data model perspective. In \nthe domain model GroupMember is clearly a Value Object. Appropriate steps \nwww.EBooksWorld.ir\n", "page": 302, "type": "text", "section": "Page 302"}
{"text": "Chapter 6 VALUE OBJECTS\n260\nhave been taken in the domain model to carefully hide any persistence con-\ncerns. I give no clue to clients of the domain model that any persistence leakage \nhas occurred. And what is more, even developers in the model must look hard \nto detect any notion of persistence leakage.\nORM and Many Values Backed by a Join Table\nHibernate provides a means to persist multivalued collections in a join table \nwithout requiring the Value type itself to have any data model entity charac-\nteristics. This mapping type simply persists the collection Value elements to a \ndedicated table with the parent Entity domain object\u2019s database identity as a \nforeign key. Thus, all collection Value elements can be queried by their parent\u2019s \nforeign key identity and reconstituted into the model\u2019s Value collection. The \nstrength of this mapping approach is that the Value type doesn\u2019t need to have a \nhidden surrogate identity in order to achieve a join. To use this Value collection \nmapping option you employ Hibernate\u2019s <composite-element> tag.\nThis seems like a big win, and it may be for your needs. However, there are \nweaknesses to this approach that you should be aware of. One downside is that \na join is necessary even if your Value type requires no surrogate key because \nit involves normalization of two tables. True, the \u201cORM and Many Values \nBacked by a Database Entity\u201d approach also requires a join. But that approach \nis not limited by the second weakness of this one, which is . . .\nIf your collection is a Set, none of your Value type\u2019s attributes may be null.\nThis is the case because in order to delete (garbage collection in the data model) \na given Set element, all attributes that make the element a unique Value must \nbe used as a sort of composite key to find and delete it. A null cannot be used \nas a part of the required composite key. Of course, if you know that a given \nValue type will never have null attributes, this is a viable approach\u2014that is, \nas long as you have no additional conflicting needs.\nThe third downside of using this mapping approach is that the Value type \nbeing mapped may itself not contain a collection. There is no provision for map-\nping with <composite-element> if the elements themselves contain collec-\ntions. If your Value type does not hold a collection of any kind and otherwise \nmeets the requirements for this mapping style, it is available for your use.\nIn the end, I find this mapping approach to be limiting enough that it \ndeserves general avoidance. To me it is simply easier to put a well-hidden surro-\ngate identity on the Value type that is collected into a one-to-many association \nand not worry about any of the <composite-element> constraints. You \nmay feel differently, and it certainly can be leveraged to your benefit if all the \nmodeling cards fall into place for you.\nwww.EBooksWorld.ir\n", "page": 303, "type": "text", "section": "Page 303"}
{"text": " \nPERSISTING VALUE OBJECTS\n261\nORM and Enum-as-State Objects\nIf you find enums an effective modeling choice for Standard Types and/or State \nobjects, you will need the means to persist them. With Hibernate, Java enums \nrequire a specialized persistence technique. Unfortunately to date, the Hiber-\nnate development community does not support enums as an out-of-the-box \nproperty type. Therefore, to persist enums in our model we have to create a \nHibernate custom user type.\nRecall that each GroupMember has a GroupMemberType:\npublic final class GroupMember extends IdentifiedValueObject  {\n    private String name;\n    private TenantId tenantId;\n    private GroupMemberType type;\n    public GroupMember(\n            TenantId aTenantId,\n            String aName,\n            GroupMemberType aType) {\n        this();\n        this.setName(aName);\n        this.setTenantId(aTenantId);\n        this.setType(aType);\n        this.initialize();\n    }\n    ...\n}\nThe GroupMemberType enum Standard Types include GROUP and USER.\nHere again is the definition:\npackage com.saasovation.identityaccess.domain.model.identity;\npublic enum GroupMemberType {\n    GROUP {\n        public boolean isGroup() {\n            return true;\n        }\n    },\n    USER {\n        public boolean isUser() {\n            return true;\n        }\n    };\n    public boolean isGroup() {\n        return false;\n    }\nwww.EBooksWorld.ir\n", "page": 304, "type": "text", "section": "Page 304"}
{"text": "Chapter 6 VALUE OBJECTS\n262\n    public boolean isUser() {\n        return false;\n    }\n}\nThe simple answer to persisting a Java enum Value is to store its text repre-\nsentation. However, the simple answer leads to the unfolding of a slightly more \ncomplex technique of creating a Hibernate customer user type. Rather than \ninclude here the various approaches to class EnumUserType provided by the \nHibernate community, I provide the wiki article resource link: http://commu-\nnity.jboss.org/wiki/Java5EnumUserType.\nAt the time of writing, this wiki article provided a variety of approaches. \nThere were samples for implementing a custom user type class for each enum \ntype; a way to use Hibernate 3 parameterized types to avoid implementing a \ncustom user for each enum type (very desirable); one that supports not only text \nstring but numeric representations of the enum value; and even an enhanced \nimplementation by Gavin King. Gavin King\u2019s enhanced implementation allows \nthe enum to be used as a type discriminator or as a data table identity (id).\nGiven the selection of one choice from these options, here\u2019s an example of \nhow the enum GroupMemberType is mapped:\n<hibernate-mapping>\n    <class name=\"com.saasovation.identityaccess.domain.model.\u03a6\n            identity.GroupMember\" table=\"tbl_group_member\" lazy=\"true\">\n        ...\n        <property\n            name=\"type\"\n            column=\"type\"\n            type=\"com.saasovation.identityaccess.infrastructure.\u03a6\n                persistence.GroupMemberTypeUserType\"\n            update=\"true\"\n            insert=\"true\"\n            not-null=\"true\"\n        />\n    </class>\n</hibernate-mapping>\nNote that the <property> element\u2019s type attribute is set to class Group-\nMemberTypeUserType\u2019s full classpath. This is just one choice, and you \nshould choose whatever one you prefer. Recall that the MySQL table descrip-\ntion contains the column to hold the enum:\nwww.EBooksWorld.ir\n", "page": 305, "type": "text", "section": "Page 305"}
{"text": " \nWRAP-UP\n263\nCREATE TABLE `tbl_group_member` (\n    ...\n    `type` varchar(5) NOT NULL,\n    ...\n) ENGINE=InnoDB;\nThe type column is a VARCHAR type with a maximum size of five characters, \nenough to hold the widest type text representation: GROUP or USER.\nWrap-Up\nIn this chapter you\u2019ve seen the importance of favoring the use of Value \nObjects whenever possible, because they are simply easier to develop, test, and \nmaintain.\n\u2022 You\u2019ve learned the characteristics of Value Objects and how to use them.\n\u2022 You\u2019ve seen how to leverage Value Objects to minimize integration \ncomplexity.\n\u2022 You examined the use of domain Standard Types expressed as Values and \nhave a few strategies for implementing them.\n\u2022 You saw why SaaSOvation now favors modeling with Values whenever \npossible.\n\u2022 You gained experience in how to test, implement, and persist Value types \nthrough the SaaSOvation projects.\nNext, we\u2019ll be looking at Domain Services, stateless operations that are \nactually part of the model.\nwww.EBooksWorld.ir\n", "page": 306, "type": "text", "section": "Page 306"}
{"text": "This page intentionally left blank \nwww.EBooksWorld.ir\n", "page": 307, "type": "text", "section": "Page 307"}
{"text": "265\nChapter 7\nServices\nSometimes, it just isn\u2019t a thing.\n\u2014Eric Evans\nA Service in the domain is a stateless operation that fulfills a domain-specific \ntask. Often the best indication that you should create a Service in the domain \nmodel is when the operation you need to perform feels out of place as a method \non an Aggregate (10) or a Value Object (6). To alleviate that uncomfortable \nfeeling, our natural tendency might be to create a static method on the class of \nan Aggregate Root. However, when using DDD, that tactic is a code smell that \nlikely indicates you need a Service instead.\nRoad Map to This Chapter\n\u2022 See how domain model refinements can lead to the realization that you need \na Service.\n\u2022 Learn what a Service in the domain is, and what it isn\u2019t.\n\u2022 Consider a necessary caution when deciding whether or not to create a \nService.\n\u2022 Discover how to model Services in a domain through two examples from \nSaaSOvation\u2019s projects.\nSmelly code? That\u2019s exactly what SaaSOvation\u2019s developers experienced \nbecause of refactoring an Aggregate. Let\u2019s consider their tactical correction. \nHere\u2019s what happened . . .\nEarly on in their project the team had modeled the collection \nof BacklogItem instances as a composed Aggregate part of \nProduct. That modeling situation allowed calculating the total \nbusiness priority value of all product backlog items to be a sim-\nple instance method on class Product:\nwww.EBooksWorld.ir\n", "page": 308, "type": "text", "section": "Page 308"}
{"text": "Chapter 7 SERVICES\n266\npublic class Product extends ConcurrencySafeEntity {\n    ...\n    private Set<BacklogItem> backlogItems;\n    ...\n    public BusinessPriorityTotals businessPriorityTotals() {\n        ...\n    }\n    ...\n}\nAt that time the design made perfect sense because method business-\nPriorityTotals() would just iterate over the composed BacklogItem instances \nand come up with the queried total business priority. The design properly answered \nthe query with a Value Object, namely, BusinessPriorityTotals.\nHowever, it wouldn\u2019t stay that way. As the analysis found in Aggregates (10)\nshowed, the large cluster Product needed to be broken up, and BacklogItem\nwould be redesigned to stand on its own as an Aggregate. Thus, the previous design \nthat used an instance method no longer worked.\nSince Product no longer contained the BacklogItem collection, the team\u2019s first \nreaction was to refactor the existing instance method to use the new BacklogItem-\nRepository to get all the BacklogItem instances the calculation needed. Does \nthat sound right?\nActually, the senior team mentor persuaded the team not to do that. As a rule of \nthumb, we should try to avoid the use of Repositories (12) from inside Aggregates, \nif at all possible. What about just making the same method static on class Product\nand passing in the collection of BacklogItem instances that static method would \nneed for the calculation? That way the method would remain almost intact, except for \nthe new parameter:\npublic class Product extends ConcurrencySafeEntity {\n    ...\n    public static BusinessPriorityTotals businessPriorityTotals(\n            Set<BacklogItem> aBacklogItems) {\n        ...\n    }\n    ...\n}\nWas Product really the best place to create the static method? It seemed diffi-\ncult to determine where it really belonged. Since the operation actually only used the \nbusiness priority values of each BacklogItem, maybe the static method belonged \nthere. Still, the business priority being sought was that of a product, not a backlog \nitem. Quandaries.\nAt that point the mentoring senior developer spoke up. He noted that the team\u2019s \nentire source of discomfort could be dismissed with a single modeling tool, the \nDomain Service. How would that work?\nwww.EBooksWorld.ir\n", "page": 309, "type": "text", "section": "Page 309"}
{"text": " \nWHAT A DOMAIN SERVICE IS (BUT FIRST, WHAT IT IS NOT)\n267\nLet\u2019s first establish some background. Then we\u2019ll revisit this modeling situa-\ntion and see what the team decided to do.\nWhat a Domain Service Is (but First, What It Is Not)\nWhen we hear the term service in a software context, we might naturally \nenvision a coarse-grained component that enables a remote client to interact \nwith a complex business system. That basically describes a service in a Service- \nOriented Architecture (4). There are different technologies and approaches \nfor developing SOA services. In the end these kinds of services emphasize \nsystem-level remote procedure calls (RPCs) or message-oriented middleware\n(MoM), where other systems across the data center, or across the globe, are \nable to interact with the service to carry out business transactions.\nNone of those is a Domain Service.\nFurther, don\u2019t confuse a Domain Service with an Application Service. We \ndon\u2019t want to house business logic in an Application Service, but we do want \nbusiness logic housed in a Domain Service. If you are confused about the differ-\nence, compare with Application (14). Briefly, to differentiate the two, an Appli-\ncation Service, being the natural client of the domain model, would normally be \nthe client of a Domain Service. You\u2019ll see that demonstrated later in the chapter.\nJust because a Domain Service has the word service in its name does not \nmean that it is required to be a coarse-grained, remote-capable, heavyweight \ntransactional operation.1\nCowboy Logic \nLB:  \n\u201cAlways take a good look at what you are about to \neat. It\u2019s not so important to know what it is, but it\u2019s \ncritical to know what it was.\u201d\nServices that specifically belong to the business domain are a perfect mod-\neling tool to use when your needs intersect with their sweet spot. So, now that \nwe know what a Domain Service isn\u2019t, let\u2019s consider what it is.\n 1. There are times when a Domain Service is concerned with remote invocations on \na foreign Bounded Context (2). Yet, the focus here is different in that the Domain \nService is not itself providing a remote procedure call interface but is rather the \nclient of the RPC.\nwww.EBooksWorld.ir\n", "page": 310, "type": "text", "section": "Page 310"}
{"text": "Chapter 7 SERVICES\n268\nSometimes, it just isn\u2019t a thing. . . . When a significant process or transformation \nin the domain is not a natural responsibility of an ENTITY or VALUE OBJECT, \nadd an operation to the model as a standalone interface declared as a SERVICE. \nDefine the interface in terms of the language of the model and make sure the \noperation name is part of the UBIQUITOUS LANGUAGE. Make the SERVICE \nstateless. [Evans, pp. 104, 106]\nSince the domain model generally deals with finer-grained behaviors that \nare focused on some specific aspect of the business at hand, a Service in the \ndomain would tend to adhere to similar tenets. Since it may be dealing with \nmultiple domain objects in a single, atomic operation, it would have the lati-\ntude to scale up a bit in complexity.\nUnder what conditions would an operation not belong on an existing Entity \n(5) or Value Object? It is difficult to give an exhaustive list of reasons, but I\u2019ve \nlisted a few here. You can use a Domain Service to\n\u2022 Perform a significant business process \n\u2022 Transform a domain object from one composition to another \n\u2022 Calculate a Value requiring input from more than one domain object\nThe last one\u2014a calculation\u2014probably falls under the \u201csignificant process\u201d \ncategory, but I call it out to be clear. It\u2019s a very common one, and that kind of \noperation can require two, and possibly many, different Aggregates or their \ncomposed parts as input. And when it is just plain clumsy to place the method \non any one Entity or Value, it works out best to define a Service. Make sure the \nService is stateless and has an interface that clearly expresses the Ubiquitous \nLanguage (1) in its Bounded Context.\nMake Sure You Need a Service\nDon\u2019t lean too heavily toward modeling a domain concept as a Service. Do \nso only if the circumstances fit. If we aren\u2019t careful, we might start to treat \nServices as our modeling \u201csilver bullet.\u201d Using Services overzealously will usu-\nally result in the negative consequences of creating an Anemic Domain Model\n[Fowler, Anemic], where all the domain logic resides in Services rather than \nmostly spread across Entities and Value Objects. The following analysis shows \nthe importance of thinking carefully about the tactics you should employ for \neach modeling situation. Following this guidance should help you make good \ndecisions about whether or not to model a Service.\nLet\u2019s investigate an example of recognizing the need to model a Service. \nThink of trying to authenticate a User in our Identity and Access Context.\nwww.EBooksWorld.ir\n", "page": 311, "type": "text", "section": "Page 311"}
{"text": " \nMAKE SURE YOU NEED A SERVICE\n269\nRecall that in Entities (5) we ran into this domain scenario that the team \nwanted to push off until later. Well, later is now:\n\u2022 Users of a system must be authenticated but can be authenticated only if \nthe tenant is active.\nLet\u2019s consider why a Service is necessary. Could we simply place this behav-\nior on an Entity? From a client\u2019s perspective, maybe we could model authenti-\ncation like this:\n// client finds User and asks it to authenticate itself\nboolean authentic = false;\nUser user =\n    DomainRegistry\n        .userRepository()\n        .userWithUsername(aTenantId, aUsername);\nif (user != null) {\n    authentic = user.isAuthentic(aPassword);\n}\nreturn authentic;\nI think there are at least a few problems with this design. We require clients \nto understand what it means to authenticate. They have to find the User and \nthen ask the User if a given password matches the one the User holds. Also, \nthe Ubiquitous Language is not explicitly modeled. Here we asked the User\nif it \u201cis authentic\u201d rather than ask the model to \u201cauthenticate.\u201d If possible it \nwould be best to model in terms of the natural expressions spoken by the team, \nrather than force the team to adjust their view away from what comes natu-\nrally because we failed to better model the concept. But there are worse prob-\nlems than these.\nThis does not properly model what that team discovered about authenticat-\ning a user. A glaring omission is that there is no check to determine whether or \nnot the tenant is active. Per the requirement, if the tenant under which the user \nresides is not active, the user is not authenticated. Perhaps we could solve the \nproblem like this:\n// maybe this way is better ...\nboolean authentic = false;\nwww.EBooksWorld.ir\n", "page": 312, "type": "text", "section": "Page 312"}
{"text": "Chapter 7 SERVICES\n270\nTenant tenant =\n    DomainRegistry\n        .tenantRepository()\n        .tenantOfId(aTenantId);\nif (tenant != null && tenant.isActive()) {\n    User user =\n        DomainRegistry\n            .userRepository()\n            .userWithUsername(aTenantId, aUsername);\n    if (user != null) {\n        authentic = tenant.authenticate(user, aPassword)\n    }\n}\nreturn authentic;\nThis test does properly determine that the Tenant is active before car-\nrying on with authentication. We were also able to rid User of method \nisAuthentic() by placing authenticate() on Tenant.\nBut there are problems with this. Look at the additional burden that we\u2019ve \nheaped on the client. It now needs to understand much more about authentica-\ntion than it should. We could alleviate this a bit by checking whether Tenant\nisActive() inside method authenticate(), but I\u2019d argue that that is not \nan explicit model. It also produces another problem. Now Tenant might need \nto understand what to do with a password. Recall that another requirement \nwas realized, though not specifically called out in the authentication scenario:\n\u2022 Passwords must be stored encrypted, not as clear text.\nWith our proposed solutions, we seem to keep producing more friction in \nthe model. With the latest proposal we have to choose one of four undesirable \napproaches:\n 1. Handle encryption in Tenant and pass the encrypted password to User.\nThis violates Tenant\u2019s Single Responsibility [Martin, SRP] to deal with \nmodeling only a tenant.\n2. \nUser may already need to know a little bit about encryption since it must \nguarantee that any stored password is encrypted. If so, create a method \non User that knows how to authenticate given a clear-text password. \nBut in this case authentication becomes a facade on Tenant that is fully \nimplemented only on User. Further still, User must have a protected \nauthentication interface to prevent clients outside the model from directly \nusing it.\nwww.EBooksWorld.ir\n", "page": 313, "type": "text", "section": "Page 313"}
{"text": " \nMAKE SURE YOU NEED A SERVICE\n271\n3. Tenant asks User to encrypt the clear-text password, then it compares \nit with the one User is holding. This seems to have extra steps with an \nuntidy set of collaborations. Tenant is still required to understand the \ndetails of authentication even though it doesn\u2019t quite carry it out.\n 4. Have the client encrypt the password and pass it in to the Tenant. This \nadds further to the responsibility that the client has, when in fact the cli-\nent should need to know nothing of the need to encrypt passwords.\nNone of these proposals help much, and the client is still too complex. Respon-\nsibility that we\u2019ve dumped on the client should instead be elegantly tucked \naway in the model. Knowledge that is purely domain specific should never be \nleaked out into clients. Even if the client is an Application Service, that compo-\nnent is not responsible for the domain of identity and access management.\nCowboy Logic \nAJ:  \n\u201cWhen you find yourself in a hole, the first thing to do \nis stop digging.\u201d\nReally, the only business responsibility that the client should have is to \ncoordinate the use of a single domain-specific operation that handles all other \ndetails of the business problem:\n// inside an Application Service client with\n// only task coordination responsibility\nUserDescriptor userDescriptor =\n    DomainRegistry\n        .authenticationService()\n        .authenticate(aTenantId, aUsername, aPassword);\nIn this simple and elegant solution, the client need only obtain a reference \nto a stateless instance of AuthenticationService and then ask it to \nauthenticate(). This pushes all details of authentication out of the Applica-\ntion Service client and into the Domain Service. Any number of domain objects \nmay be used by the Service, as needed. This includes ensuring that password \nencryption is performed as appropriate. The client doesn\u2019t need to understand \nany of those details. The Ubiquitous Language in the Context is satisfied \nwww.EBooksWorld.ir\n", "page": 314, "type": "text", "section": "Page 314"}
{"text": "Chapter 7 SERVICES\n272\nbecause the proper terms are expressed by the software that models the iden-\ntity management domain, rather than partly by the model and partly by the \nclient.\nA Value Object, UserDescriptor, is returned from the Service method. \nThis object is small and secure. Unlike a full User, it includes only a few attri-\nbutes essential to referencing a User:\npublic class UserDescriptor implements Serializable  {\n    private String emailAddress;\n    private TenantId tenantId;\n    private String username;\n    public UserDescriptor(\n            TenantId aTenantId,\n            String aUsername,\n            String anEmailAddress) {\n        ...\n    }\n    ...\n}\nIt is suitable for storing in a per-user Web session. The client Application Service \nmay itself return this object to its invoker or create one more suitable for it.\nModeling a Service in the Domain\nDepending on the purpose of a Domain Service, it can be quite simple to \nmodel. You\u2019ll have to decide whether or not your Service should have a Sepa-\nrated Interface [Fowler, P of EAA]. If so, this might be the interface definition:\npackage com.saasovation.identityaccess.domain.model.identity;\npublic interface AuthenticationService {\n    public UserDescriptor authenticate(\n            TenantId aTenantId,\n            String aUsername,\n            String aPassword);\n}\nThe interface is declared in the same Module (9) as the identity-spe-\ncific Aggregates, such as Tenant, User, and Group. That is done because \nwww.EBooksWorld.ir\n", "page": 315, "type": "text", "section": "Page 315"}
{"text": " \nMODELING A SERVICE IN THE DOMAIN\n273\nAuthenticationService is an identity concept, and we currently place all \nidentity-related concepts in the identity Module. The interface definition \nitself is quite simple. Only one operation, authenticate(), is necessary.\nA choice we have is where to place the implementation class. If you are using \nthe Dependency Inversion Principle (4) or Hexagonal (4), you may decide to \nplace this somewhat technical implementation class in a location outside the \ndomain model. Technical implementations may be housed in a Module in the \nInfrastructure Layer, for example.\nHere is the class:\npackage com.saasovation.identityaccess.infrastructure.services;\nimport com.saasovation.identityaccess.domain.model.DomainRegistry;\nimport com.saasovation.identityaccess.domain.model.identity.\u03a6\nAuthenticationService;\nimport com.saasovation.identityaccess.domain.model.identity.Tenant;\nimport com.saasovation.identityaccess.domain.model.identity.TenantId;\nimport com.saasovation.identityaccess.domain.model.\u03a6\nidentity.User;\nimport com.saasovation.identityaccess.domain.model.\u03a6\nidentity.UserDescriptor;\npublic class DefaultEncryptionAuthenticationService\n        implements AuthenticationService  {\n    public DefaultEncryptionAuthenticationService() {\n        super();\n    }\n    @Override\n    public UserDescriptor authenticate(\n            TenantId aTenantId,\n            String aUsername,\n            String aPassword) {\n        if (aTenantId == null) {\n            throw new IllegalArgumentException(\n                    \"TenantId must not be null.\");\n        }\n        if (aUsername == null) {\n            throw new IllegalArgumentException(\n                    \"Username must not be null.\");\n        }\n        if (aPassword == null) {\n            throw new IllegalArgumentException(\n                    \"Password must not be null.\");\n        }\n        UserDescriptor userDescriptor = null;\nwww.EBooksWorld.ir\n", "page": 316, "type": "text", "section": "Page 316"}
{"text": "Chapter 7 SERVICES\n274\n        Tenant tenant =\n            DomainRegistry\n                .tenantRepository()\n                .tenantOfId(aTenantId);\n        if (tenant != null && tenant.isActive()) {\n            String encryptedPassword =\n                DomainRegistry\n                    .encryptionService()\n                    .encryptedValue(aPassword);\n            User user =\n                DomainRegistry\n                    .userRepository()\n                    .userFromAuthenticCredentials(\n                            aTenantId,\n                            aUsername,\n                            encryptedPassword);\n            if (user != null && user.isEnabled()) {\n                userDescriptor = user.userDescriptor();\n            }\n        }\n        return userDescriptor;\n    }\n}\nThe method guards against null parameters. Otherwise, if the authentication \nprocess fails under normal conditions, the returned UserDescriptor will be \nnull.\nTo authenticate we begin by attempting to retrieve the Tenant from its \nRepository using its identity. If the Tenant both exists and is active, we next \nencrypt the clear-text password. We do that now because we will use the \nencrypted password to retrieve the User. Rather than request the User only \nfrom a TenantId and matching username, we also match on the encrypted \npassword. (The result of encryption is always the same for two equal clear-text \npasswords.) The Repository is designed to filter on all three.\nIf the human user has submitted the correct tenant identity, username, and \nclear-text password, it will result in retrieving the matching User instance. \nStill, this does not completely prove the user\u2019s authenticity. There is one final \nrequirement not yet handled:\n\u2022 Users can be authenticated only if they are enabled.\nEven if the Repository finds the filtered User instance, it may have been dis-\nabled. Providing the possibility of disabling a User allows the tenant to control \nwww.EBooksWorld.ir\n", "page": 317, "type": "text", "section": "Page 317"}
{"text": " \nMODELING A SERVICE IN THE DOMAIN\n275\nuser authentication at a different level. Thus, as a final step the User instance \nmust be both non-null and enabled, which will result in a UserDescriptor\nbeing derived from the User.\nIs Separated Interface a Necessity?\nSince this AuthenticationService does not have a technical implementa-\ntion, is it really necessary to create a Separated Interface and implementation \nclass, and in separate Layers and Modules? No, it is not, in fact, an absolute \nnecessity. We could have created this particular Service with only a single \nimplementation class with the name of the Service:\npackage com.saasovation.identityaccess.domain.model.identity;\npublic class AuthenticationService {\n    public AuthenticationService() {\n        super();\n    }\n    public UserDescriptor authenticate(\n            TenantId aTenantId,\n            String aUsername,\n            String aPassword) {\n        ...\n    }\n}\nThere would be nothing wrong with this. You might even consider this a more \nfitting approach since this particular Service may never need to have multiple \nimplementations. However, given that different tenants might eventually desire \nspecialized security standards, it\u2019s possible that there could be multiple imple-\nmentations. At this point in time, however, the team has decided to drop the \nuse of a Separated Interface and go with the class as shown here.\nNaming Your Implementation Class\nIn the Java world it\u2019s become quite common to name the implementation \nclass with its interface\u2019s name as a prefix and Impl as a postfix. In our \nexample using this approach would render the name Authentication-\nServiceImpl. Further, the interface and implementing class are often \nhoused in the same package. Is this a good thing?\nwww.EBooksWorld.ir\n", "page": 318, "type": "text", "section": "Page 318"}
{"text": "Chapter 7 SERVICES\n276\nActually, if your implementation class is named this way, it\u2019s probably a very \ngood indication that you don\u2019t need a Separated Interface, or that you need \nto think more carefully about the name of the implementing class. So, no, \nthe AuthenticationServiceImpl name isn\u2019t a really good one. But then \nagain, DefaultEncryptionAuthenticationService is not particularly \nuseful either. For that reason the SaaSOvation team decided to eliminate the \nSeparated Interface for now and go with AuthenticationService as a \nsimple class instead.\nIf your implementation class has specific decoupling goals because you are \nproviding multiple specific implementations, name the class according to its \nspecialty. The need to name each specialized implementation carefully is \nproof that specialties exist in your domain.\nSome will conclude that having the interface and implementation class simi-\nlarly named makes large packages of these pairs easier to browse and nav-\nigate. However, others would conclude that such large packages are poorly \ndesigned according to the goals of Modules. Further still, those with focused \nmodularity goals will also favor placing the interface and various implemen-\ntation classes in separate packages, as we do with Dependency Inversion \nPrinciple (4). For example, the EncryptionService interface is in the \ndomain model, while MD5EncryptionService resides in infrastructure.\nEliminating the Separated Interface for nontechnical Domain Services will \nnot weaken testability since any interfaces that the Service depends on can \nbe injected or resolved by a test-configured Service Factory, or you could \npass in as parameters instances of inbound and outbound dependencies as \nneeded. Remember, too, that nontechnical, domain-specific Services, such \nas calculations, must be tested for correctness.\nUnderstandably this is a controversial topic, and I am aware that there is a \nlarge camp that regularly names interface realizations using Impl. Just be \naware that there is a well-informed polar opposite to that camp that has very \nsound reasons for avoiding that approach. As always, the choice is yours to \nmake.\nUsing Separated Interface may be more a matter of style in cases where \nthe Service is always domain specific and will never have a technical imple-\nmentation or multiple implementations. As Fowler [Fowler, P of EAA] states, \nSeparated Interface is useful if you have certain decoupling goals: \u201cA client \nthat needs the dependency to the interface can be completely unaware of the \nimplementation.\u201d However, if you are using Dependency Injection or a Factory\n[Gamma et al.] of Services, even when the Service interface and class are com-\nbined, you can still prevent the client from being aware of the implementation. \nwww.EBooksWorld.ir\n", "page": 319, "type": "text", "section": "Page 319"}
{"text": " \nMODELING A SERVICE IN THE DOMAIN\n277\nIn other words, the following use of the DomainRegistry as Service Factory \nwill decouple the client from implementation:\n// the registry decouples client from implementation knowledge\nUserDescriptor userDescriptor =\n    DomainRegistry\n        .authenticationService()\n        .authenticate(aTenantId, aUsername, aPassword);\nOr if you are using Dependency Injection, you can get similar benefits:\npublic class SomeApplicationService ... {\n    @Autowired\n    private AuthenticationService authenticationService;\n    ...\n}\nThe inversion-of-control container (such as Spring) injects the Service instance. \nSince the client never instantiates the Service, it isn\u2019t aware that the interface \nand implementation are either combined or separated.\nClearly, some have utter disdain for both the Service Factory and Depen-\ndency Injection and prefer to set up inbound dependencies by way of a con-\nstructor or pass them in as method parameters. In the end that is the most \nexplicit way to wire dependencies and make code testable, and it could even \nbe considered easier than Dependency Injection. Some may find it beneficial \nto use a combination of all three depending on the situation, while preferring \nconstructor-based dependency setup overall. Several of the samples in this \nchapter use DomainRegistry for clarity, though not necessarily indicating \na preference. Much of the source code actually distributed online in support of \nthis book leans toward dependency set up by way of constructors, or by pass-\ning dependencies directly to methods as parameters.\nA Calculation Process\nHere\u2019s another example, this time from the current Core Domain (2), the Agile \nProject Management Context. This Service calculates a result from Values on \nany number of Aggregates of a specific type. Here I think there is no good \nreason to use a Separated Interface, at least not at present. The calculations are \nalways performed the same way. Unless that situation changes, we shouldn\u2019t \nbother separating the interface from the implementation.\nwww.EBooksWorld.ir\n", "page": 320, "type": "text", "section": "Page 320"}
{"text": "Chapter 7 SERVICES\n278\nCowboy Logic \nLB:  \n\u201cMy stallion brings $5,000 per service, and I\u2019ve got \nthe mares lined up.\u201d\nAJ:  \n\u201cNow that horse is in his domain.\u201d\nRecall that the SaaSOvation developers originally created fine-grained static \nmethods on Product to perform the desired calculations. Here\u2019s what hap-\npened next . . .\nThe team\u2019s mentor also pointed to the desirability of using a \nDomain Service instead of a static method. The idea behind \nthis Service would be very similar to the current design, to \ncalculate and return a BusinessPriorityTotals Value \ninstance. But the Service would have to do a bit more work. \nThis would include finding all outstanding backlog items of a \ngiven Scrum product and then totaling each of their individual \nBusinessPriority Values. Here\u2019s the implementation:\npackage com.saasovation.agilepm.domain.model.product;\nimport com.saasovation.agilepm.domain.model.DomainRegistry;\nimport com.saasovation.agilepm.domain.model.tenant.Tenant;\npublic class BusinessPriorityCalculator {\n    public BusinessPriorityCalculator() {\n        super();\n    }\n    public BusinessPriorityTotals businessPriorityTotals(\n            Tenant aTenant,\n            ProductId aProductId) {\n        int totalBenefit = 0;\n        int totalPenalty = 0;\n        int totalCost = 0;\n        int totalRisk = 0;\n        java.util.Collection<BacklogItem> outstandingBacklogItems =\n            DomainRegistry\n                .backlogItemRepository()\n                .allOutstandingProductBacklogItems(\n                        aTenant,\n                        aProductId);\nwww.EBooksWorld.ir\n", "page": 321, "type": "text", "section": "Page 321"}
{"text": " \nMODELING A SERVICE IN THE DOMAIN\n279\n        for (BacklogItem backlogItem : outstandingBacklogItems) {\n            if (backlogItem.hasBusinessPriority()) {\n                BusinessPriorityRatings ratings =\n                    backlogItem.businessPriority().ratings();\n                totalBenefit += ratings.benefit();\n                totalPenalty += ratings.penalty();\n                totalCost += ratings.cost();\n                totalRisk += ratings.risk();\n            }\n        }\n        BusinessPriorityTotals businessPriorityTotals =\n            new BusinessPriorityTotals(\n                    totalBenefit,\n                    totalPenalty,\n                    totalBenefit + totalPenalty,\n                    totalCost,\n                    totalRisk);\n        return businessPriorityTotals;\n    }\n}\nThe BacklogItemRepository is used to get all outstanding Backlog-\nItem instances. An outstanding BacklogItem is one with a status type of \nPlanned, Scheduled, or Committed, not either Done or Removed. A Service in \nthe domain is welcome to use Repositories as needed, but accessing Reposito-\nries from an Aggregate instance is not a recommended practice.\nWith all outstanding items for a given product, we iterate over them and \ntotal each of the ratings of their BusinessPriority. The totals that result \nfrom iteratively calculating are used to instantiate a new BusinessPrior-\nityTotals, which is returned to the client. There is no need for a Service \ncalculation process to be complex, though it could be a necessity. This one \nhappens to be rather simple.\nNote from this example that you would absolutely not want this logic to \nreside in an Application Service. Even if you consider the summing calculation \nin the for loop to be trivial, it is still business logic. But there\u2019s another reason:\n        BusinessPriorityTotals businessPriorityTotals =\n            new BusinessPriorityTotals(\n                    totalBenefit,\n                    totalPenalty,\nwww.EBooksWorld.ir\n", "page": 322, "type": "text", "section": "Page 322"}
{"text": "Chapter 7 SERVICES\n280\n                    totalBenefit + totalPenalty,\n                    totalCost,\n                    totalRisk);\nAs the BusinessPriorityTotals is instantiated, its totalValue attri-\nbute is derived from summing the totalBenefit and totalPenalty. This \nlogic is domain specific and must not leak into the Application Layer. We could \nargue that the BusinessPriorityTotals constructor should itself arrange \nfor this to be derived from the two passed-in parameters. While that might be \na way to improve the model, doing so wouldn\u2019t be a justification for moving \nthe remaining calculations into an Application Service.\nAlthough we don\u2019t house this business logic in an Application Service, an \nApplication Service does serve as the client to the Domain Service:\npublic class ProductService ... {\n    ...\n    private BusinessPriorityTotals productBusinessPriority(\n            String aTenantId,\n            String aProductId) {\n        BusinessPriorityTotals productBusinessPriority =\n                DomainRegistry\n                    .businessPriorityCalculator()\n                    .businessPriorityTotals(\n                            new TenantId(aTenantId),\n                            new ProductId(aProductId));\n        return productBusinessPriority;\n    }\n}\nIn this case a private method in the Application Service is responsible for \nrequesting the total business priority for the product. Here the method may be \nsupplying just one part of the payload returned to the client of ProductSer-\nvice, such as the user interface.\nTransformation Services\nThe more technical Domain Service implementations that definitely live in \nInfrastructure are often those used for integration. For that reason I have dele-\ngated such examples to Integrating Bounded Contexts (13). There you\u2019ll see the \nService interfaces, implementation classes, and also Adapters [Gamma et al.] \nand translators used by the implementations.\nwww.EBooksWorld.ir\n", "page": 323, "type": "text", "section": "Page 323"}
{"text": " \nTESTING SERVICES\n281\nUsing a Mini-Layer of Domain Services\nSometimes it may be desirable to create a \u201cmini-layer\u201d of Domain Services \nabove the rest of your domain model Entities and Value Objects. As I pre-\nviously indicated, this will often lead down the precarious path of Anemic \nDomain Model, which should be considered an anti-pattern. \nYet, there are some systems where designing in the mini-layer of Domain \nServices makes more sense than in others and will not lead to Anemic Domain \nModel. It depends on the characteristics of the domain model, and in the case \nof the Identity and Access Context this is actually quite helpful.\nIf you were to experience working in such a domain and you did decide \nto produce a mini-layer of Domain Services, remember that such are always \ndifferent from Application Services in the Application Layer. Address trans-\nactions and security as application concerns in Application Services, not in \nDomain Services.\nTesting Services\nWe want to test our Services to make sure we gain a client perspective on how \nwe should model. We want our domain-focused tests to reflect the way the \nmodel should be used, while at this point ignoring some of the finer software \ncorrectness focus.\nIsn\u2019t It a Bit Late to Test?\nI have normally introduced tests before implementations. I did show some test-first \ncode snippets earlier when analyzing the need for a Service. It\u2019s just that I found it \nmore natural to discuss the implementation a bit earlier in this chapter, that\u2019s all. \nHowever, this does show that test-first isn\u2019t an absolute necessity, although it may \nlimit a proper modeling focus.\nThese tests demonstrate how to properly use AuthenticationService,\nand we first test against the successful authentication scenario:\npublic class AuthenticationServiceTest\n        extends IdentityTest {\n    public void testAuthenticationSuccess() throws Exception {\n        User user = this.getUserFixture();\n        DomainRegistry\n            .userRepository()\n            .add(user);\nwww.EBooksWorld.ir\n", "page": 324, "type": "text", "section": "Page 324"}
{"text": "Chapter 7 SERVICES\n282\n        UserDescriptor userDescriptor =\n            DomainRegistry\n                .authenticationService()\n                .authenticate(\n                        user.tenantId(),\n                        user.username(),\n                        FIXTURE_PASSWORD);\n        assertNotNull(userDescriptor);\n        assertEquals(user.tenantId(), userDescriptor.tenantId());\n        assertEquals(user.username(), userDescriptor.username());\n        assertEquals(user.person().emailAddress(),\n                     userDescriptor.emailAddress());\n    }\n    ...\nThis example shows how the AuthenticationService would be used by \nan Application Service client. It\u2019s a happy path where that client would success-\nfully authenticate a user by passing expected parameters.\nNote that the Repository could be the full implementation, an in-memory \nvariety, or mocked. It works fine to test with the full implementation if it is fast \nenough, as long as the test ends with a rollback of the transaction, preventing \nthe buildup of extraneous instances across tests. The kind of Repository imple-\nmentation used for testing is your choice.\nNext, we demonstrate a scenario under which authentication fails:\n    public void testAuthenticationTenantFailure() throws Exception {\n        User user = this.getUserFixture();\n        DomainRegistry\n            .userRepository()\n            .add(user);\n        TenantId bogusTenantId =\n            DomainRegistry.tenantRepository().nextIdentity();\n        UserDescriptor userDescriptor =\n            DomainRegistry\n                .authenticationService()\n                .authenticate(\n                        bogusTenantId, // bogus\n                        user.username(),\n                        FIXTURE_PASSWORD);\n        assertNull(userDescriptor);\n    }\nwww.EBooksWorld.ir\n", "page": 325, "type": "text", "section": "Page 325"}
{"text": " \nTESTING SERVICES\n283\nThis authentication test fails because we purposely pass in a TenantId that is \ndifferent from the one in which the User was created. Then there is the invalid \nusername condition to demonstrate:\n    public void testAuthenticationUsernameFailure() throws Exception {\n        User user = this.getUserFixture();\n        DomainRegistry\n            .userRepository()\n            .add(user);\n        UserDescriptor userDescriptor =\n            DomainRegistry\n                .authenticationService()\n                .authenticate(\n                        user.tenantId(),\n                        \"bogususername\",\n                        user.password());\n        assertNull(userDescriptor);\n    }\nThis authentication test scenario fails because we pass in a wrong username. \nThere\u2019s one last failure scenario demonstrated in these tests:\n    public void testAuthenticationPasswordFailure() throws Exception {\n        User user = this.getUserFixture();\n        DomainRegistry\n            .userRepository()\n            .add(user);\n        UserDescriptor userDescriptor =\n            DomainRegistry\n                .authenticationService()\n                .authenticate(\n                        user.tenantId(),\n                        user.username(),\n                        \"passw0rd\");\n        assertNull(userDescriptor);\n    }\n}\nwww.EBooksWorld.ir\n", "page": 326, "type": "text", "section": "Page 326"}
{"text": "Chapter 7 SERVICES\n284\nThis test provides the wrong password, which causes it to fail. In all cases \nwhen demonstrating failure scenarios the UserDescriptor is returned as \nnull. This is a detail that clients should take note of, as it indicates what they \nshould expect when the user is not authenticated. It also indicates that fail-\ning authentication is not an exceptional error, just a normal possibility of this \ndomain. Otherwise, if failing authentication were considered exceptional, we\u2019d \nmake the Service throw an AuthenticationFailedException.\nThere are actually a few tests missing. I will leave it to you to test domain \nscenarios that include when a Tenant is not active and a User that is disabled. \nAfter that, you can create tests for the BusinessPriorityCalculator.\nWrap-Up\nIn this chapter we discussed what a Domain Service is and what it is not, and \nwe analyzed when we should use a Service rather than an operation on an \nEntity or Value Object. There was more:\n\u2022 You learned that recognizing a legitimate need for a Service is necessary \nto avoid overusing Services.\n\u2022 You were reminded that overuse of Domain Services leads to Anemic \nDomain Model, an anti-pattern.\n\u2022 You saw the specific steps of general practice when implementing a \nService.\n\u2022 You considered the pluses and minuses of using a Separated Interface.\n\u2022 You reviewed a sample calculation process from the Agile Project Man-\nagement Context.\n\u2022 Finally, you considered how to provide exemplary tests to demonstrate \nhow to use the Services our models provide.\nNext, we are going to consider one of the newer DDD tactical modeling \ntools to appear on the scene. It\u2019s the powerful Domain Event building block \npattern.\nwww.EBooksWorld.ir\n", "page": 327, "type": "text", "section": "Page 327"}
{"text": "285\nChapter 8\nDomain Events\nHistory is the version of past events that people \nhave decided to agree upon.\n\u2014Napoleon Bonaparte\nUse a Domain Event to capture an occurrence of something that happened in \nthe domain. This is an extremely powerful modeling tool. Once you get the \nhang of using Domain Events, you will be addicted and wonder how you sur-\nvived without them until now. To get started with them, all you have to do is \nfind agreement on what your Events actually are.\nRoad Map to This Chapter\n\u2022 Discover what Domain Events are, and when and why you should consider \nusing them.\n\u2022 Learn how Events are modeled as objects, and when they must be uniquely \nidentified.\n\u2022 Examine a lightweight Publish-Subscribe [Gamma et al.] pattern and how it \nfits with notifying clients.\n\u2022 See which components publish Events and which ones are the subscribers.\n\u2022 Consider why you\u2019d want to develop an Event Store, how it can be done, and \nhow one is used.\n\u2022 Learn from SaaSOvation how Events are published to autonomous systems \nin different ways.\nThe When and Why of Domain Events\nReferencing [Evans], you will find no formal definition for Domain Events. \nThe pattern was introduced in detail sometime after the book was published. \nTo begin a discussion about implementing Events in the Domain (2), consider \nthe contemporary definition:\nSomething happened that domain experts care about. \nwww.EBooksWorld.ir\n", "page": 328, "type": "text", "section": "Page 328"}
{"text": "Chapter 8 DOMAIN EVENTS\n286\nModel information about activity in the domain as a series of discrete events. \nRepresent each event as a domain object. . . . A domain event is a full-fledged \npart of the domain model, a representation of something that happened in the \ndomain. [Evans, Ref, p. 20] \nHow can we determine if something that happens in the domain is impor-\ntant to the domain experts? As we have discussions with them, we must lis-\nten carefully for clues. Consider a few key phrases to listen for when domain \nexperts talk:\n\u2022 \u201cWhen . . .\u201d\n\u2022  \u201cIf that happens . . .\u201d\n\u2022  \u201cInform me if . . .\u201d and \u201cNotify me if . . .\u201d\n\u2022  \u201cAn occurrence of . . .\u201d\nOf course, with the \u201cInform me if . . .\u201d and \u201cNotify me if . . .\u201d expressions it\u2019s \nnot the notification that constitutes an Event. It\u2019s just a statement of the fact \nthat someone in the domain wants to be notified as a result of an important \noccurrence, and that likely means the need to model an explicit Event. In addi-\ntion, domain experts might say things such as \u201cIf that happens, it isn\u2019t impor-\ntant, but if this happens, it is important.\u201d (Replace that and this with something \nmeaningful in your domain.) Depending on your organizational culture, there \ncould be other triggering phrases. \nCowboy Logic \nAJ:  \n\u201cIn the event that I want my horse, I just yell, \u2018Here, \nTrigger!\u2019 and he comes runnin\u2019. Of course, it never \nhurts to let him know I\u2019m carryin\u2019 a cube of sugar.\u201d\nThere will probably be times when the spoken language of the experts \ndoesn\u2019t lead to a clear reason to model an Event, yet the business situation \nmay still call for it. Domain experts may or may not be aware of these kinds \nof requirements, and they could become known only as a result of cross-team \ndiscussions. This tends to happen when Events must be broadcast to external \nservices, where the systems in your enterprise have been decoupled and occur-\nrences throughout the domain must be communicated across Bounded Con-\ntexts (2). Events like this get published, and subscribers are notified. As such \nEvents are handled by subscribers, they may have far-reaching impact on local \nand remote Bounded Contexts.\nwww.EBooksWorld.ir\n", "page": 329, "type": "text", "section": "Page 329"}
{"text": " \nTHE WHEN AND WHY OF DOMAIN EVENTS\n287\nDomain Experts and Events\nAlthough domain experts may not initially be aware of the need for every kind of \nEvent, they should understand the reasons for them as they are included in discus-\nsions about specific Events. Once there is clear consensus, new Events become a \nformal part of the Ubiquitous Language (1).\nWhen Events are delivered to interested parties, in either local or foreign sys-\ntems, they are generally used to facilitate eventual consistency. This is purposeful \nand by design. It can eliminate the need for two-phase commits (global transac-\ntions) and support of the rules of Aggregates (10). One rule of Aggregates states \nthat only a single instance should be modified in a single transaction, and all \nother dependent changes must occur in separate transactions. So other Aggregate \ninstances in the local Bounded Context may be synchronized using this approach. \nWe also bring remote dependencies into a consistent state with latency. The \ndecoupling helps provide a highly scalable and peak-performing set of cooperat-\ning services. It also allows us to achieve loose coupling between systems.\nFigure 8.1 shows how Events may originate, how they can be stored and \nforwarded, and where they may be used. Events may be consumed by the local, \nand foreign, Bounded Contexts.\ncreate\npublish\nhandle\nEvent\nstore\nData store is same used\nby domain model (simple\nsingle transaction)\nLightweight Subscribers\nLightweight Subscriber\nstoring all events\nMessaging\nInfrastructure\n(MoM)\nXA/2PC\nrequired\nhere\nLightweight Publisher\nEvent Publisher\nSimple\nSubscriber\nImmediate\nForwarding\nSubscriber\nRemote\nSubscriber\nMessage\nQueue\nForwarder\nEvent\nStoring\nSubscriber\nEvent\nAggregate\nFigure 8.1 Aggregates create Events and publish them. Subscribers may store Events and then \nforward them to remote subscribers, or just forward them without storing. Immediate forwarding \nrequires XA (two-phase commit) unless messaging middleware shares the model\u2019s data store.\nwww.EBooksWorld.ir\n", "page": 330, "type": "text", "section": "Page 330"}
{"text": "Chapter 8 DOMAIN EVENTS\n288\nAlso, think of times when your systems normally perform batch process-\ning. Perhaps during off-peak hours (possibly nighttime) your systems process \ndaily maintenance of some kind, deleting obsolete objects, creating ones that \nare needed to support newly formed business situations, bringing some objects \ninto agreement with others, and even notifying certain users that important \nthings have happened. Often performing such batch processes requires you to \nexecute some complex queries in order to determine the business situations \nthat require attention. The calculations and procedures to address them are \ncostly, and synchronizing all the changes requires large transactions. What if \nthose pesky batch processes could be made redundant?\nNow think of the actual occurrences that took place throughout the pre-\nvious day that led to the need to play catch-up later. If each of those discrete \noccurrences were captured by a single Event, and published to listeners in your \nown system, would that simplify things? Indeed, it would eliminate the com-\nplex queries because you would know exactly what occurred and when, pro-\nviding the context of what needs to happen as a result. You would just do it \nas you receive notification of each Event. The processing currently dealt with \nin I/O and processor-intensive batches would be spread out into short spurts \nthroughout the day, and your business situations would be in harmony much \nmore quickly, ready for users to take the next steps.\nDoes every Aggregate command result in an Event? Just as important as rec-\nognizing the need for an Event is knowing when to disregard extraneous hap-\npenings in the domain that experts or the business as a whole don\u2019t care about. \nStill, depending on the technical implementation aspects of the model or the \ngoals of collaborating systems, it is possible that Events will be more prolific \nthan domain experts directly require. Such is the case when using Event Sourc-\ning (4, Appendix A).\nI leave some of this to Integrating Bounded Contexts (13), but we\u2019ll consider \nthe essential modeling tools here.\nModeling Events\nLet\u2019s take a requirement from the Agile Project Management Context. The \ndomain experts indicated the need for an Event in this way (italics added for \nemphasis):\nwww.EBooksWorld.ir\n", "page": 331, "type": "text", "section": "Page 331"}
{"text": " \nMODELING EVENTS\n289\nAllow each backlog item to be committed to a sprint. It \nmay be committed only if it is already scheduled for \nrelease. If it is already committed to a different sprint, \nit must be uncommitted first. When the backlog item is \ncommitted, notify the sprint and other interested parties.\nWhen modeling Events, name them and their properties according to the \nUbiquitous Language in the Bounded Context where they originate. If an \nEvent is the result of executing a command operation on an Aggregate, the \nname is usually derived from the command that was executed. The command \nis the cause of the Event, and hence the Event\u2019s name is rightly stated in terms \nof the command having occurred in the past. Per the example scenario, when \nwe commit a backlog item to a sprint, we publish an Event that explicitly mod-\nels what happened in the domain:\nCommand operation:   BacklogItem#commitTo(Sprint aSprint)\nEvent outcome: \n  BacklogItemCommitted\nThe Event name states what occurred (past tense) in the Aggregate after the \nrequested operation succeeded: \u201cThe backlog item was committed.\u201d The team \ncould have modeled the name a bit more verbosely, such as BacklogItem-\nCommittedToSprint, and that would work. However, in the Ubiquitous \nLanguage of Scrum, a backlog item is never committed to anything besides a \nsprint. In other words, backlog items are scheduled for release, not committed \nto a release. There would be no doubt that this Event was published as a result \nof using the commitTo() operation. Thus, the Event is sufficiently named as \nit is, and the more compact name is easier to read. If your team likes a more \nverbose name in a specific case, however, use it.\nWhen publishing Events from Aggregates, it is important that the Event \nname reflect the past nature of the occurrence. It is not occurring now. It \noccurred previously. The best name to choose is the one that reflects that fact.\nAfter the right name is found, what properties should it have? For one, we \nneed a timestamp that indicates when the Event occurred. In Java we could \nrepresent it as a java.util.Date:\nwww.EBooksWorld.ir\n", "page": 332, "type": "text", "section": "Page 332"}
{"text": "Chapter 8 DOMAIN EVENTS\n290\npackage com.saasovation.agilepm.domain.model.product;\npublic class BacklogItemCommitted implements DomainEvent {\n    private Date occurredOn;\n    ...\n}\nThe minimal interface DomainEvent, implemented by all Events, ensures \nsupport of an occurredOn() accessor. It enforces a basic contract for all \nEvents:\npackage com.saasovation.agilepm.domain.model;\nimport java.util.Date;\npublic interface DomainEvent {\n    public Date occurredOn();\n}\nBesides this, the team determines what other properties are necessary to \nrepresent a meaningful occurrence of what happened. Consider including \nwhatever would be necessary to trigger the Event again. This normally includes \nthe identity of the Aggregate instance on which it took place, or any Aggre-\ngate instances involved. Using this guidance, we might create properties of any \nparameters that caused the Event, if discussion proves they are useful. It\u2019s also \npossible that some resulting Aggregate state transition values could be helpful \nto subscribers.\nHere\u2019s what analysis of BacklogItemCommitted led to:\npackage com.saasovation.agilepm.domain.model.product;\npublic class BacklogItemCommitted implements DomainEvent {\n    private Date occurredOn;\n    private BacklogItemId backlogItemId;\n    private SprintId committedToSprintId;\n    private TenantId tenantId;\n    ...\n}\nwww.EBooksWorld.ir\n", "page": 333, "type": "text", "section": "Page 333"}
{"text": " \nMODELING EVENTS\n291\nThe team decided that the identity of the BacklogItem and \nthat of the Sprint were essential. It was the BacklogItem\nthat the Event occurred on, and the Sprint that it occurred \nwith. But more was involved in this decision. The requirement \nthat drove out the need for this Event indicated specifically \nthat the Sprint must be notified that a certain BacklogItem\nwas committed to it. Thus, an Event subscriber in the same \nBounded Context must eventually inform the Sprint, and it \ncan do so only if BacklogItemCommitted has the SprintId.\nAdditionally, in the multitenancy environment, recording the TenantId is always \nnecessary, even though it was not passed as a command parameter. It is needed \nfor both the local and foreign Bounded Contexts. Locally the team would need the \nTenantId to query the BacklogItem and the Sprint from their respective Repos-\nitories (12). Likewise, any foreign, remote systems that listen for a broadcast of this \nEvent would need to know which TenantId it applies to.\nHow do we model the behavioral operations supplied by Events? These are \ngenerally very simple because an Event is usually designed as immutable. First \nand foremost, the Event\u2019s interface has the express purpose to convey the prop-\nerties that reflect its cause. Most Events will have a constructor that permits \nonly full state initialization, along with a complement of read accessors for \neach of its properties.\nBased on that, here\u2019s what the ProjectOvation team did:\npackage com.saasovation.agilepm.domain.model.product;\npublic class BacklogItemCommitted implements DomainEvent {\n    ...\n    public BacklogItemCommitted(\n            TenantId aTenantId,\n            BacklogItemId aBacklogItemId,\n            SprintId aCommittedToSprintId) {\n        super();\n        this.setOccurredOn(new Date());\n        this.setBacklogItemId(aBacklogItemId);\n        this.setCommittedToSprintId(aCommittedToSprintId);\n        this.setTenantId(aTenantId);\n    }\n    @Override\n    public Date occurredOn() {\n        return this.occurredOn;\nwww.EBooksWorld.ir\n", "page": 334, "type": "text", "section": "Page 334"}
{"text": "Chapter 8 DOMAIN EVENTS\n292\n    }\n    public BacklogItemId backlogItemId() {\n        return this.backlogItemId;\n    }\n    public SprintId committedToSprintId() {\n        return this.committedToSprintId;\n    }\n    public TenantId tenantId() {\n        return this.tenant;\n    }\n    ...\n}\nWith this Event published, a subscriber in the local Bounded Context can use it to \nnotify the Sprint that a certain BacklogItem was recently committed to it:\nMessageConsumer.instance(messageSource, false)\n    .receiveOnly(\n            new String[] { \"BacklogItemCommitted\" },\n            new MessageListener(Type.TEXT) {\n        @Override\n        public void handleMessage(\n            String aType,\n            String aMessageId,\n            Date aTimestamp,\n            String aTextMessage,\n            long aDeliveryTag,\n            boolean isRedelivery)\n        throws Exception {\n            // first de-duplicate message by aMessageId\n            ...\n            // get tenantId, sprintId, and backlogItemId from JSON\n            ...\n            Sprint sprint =\n                    sprintRepository.sprintOfId(tenantId, sprintId);\n            BacklogItem backlogItem =\n                    backlogItemRepository.backlogItemOfId(\n                        tenantId,\n                        backlogItemId);\n            sprint.commit(backlogItem);\n        }\n    });\nwww.EBooksWorld.ir\n", "page": 335, "type": "text", "section": "Page 335"}
{"text": " \nMODELING EVENTS\n293\nPer the system requirements, after handling the specific \"BacklogItem-\nCommitted\" message, the Sprint is consistent with the BacklogItem that \nwas recently committed to it. How the subscriber receives this Event is dis-\ncussed later in this chapter.\nThe team realized that there might \nbe a bit of a problem here. How is the \nSprint updating transaction managed? \nWe could have the message handler \ndo that, but either way the code found \nin the handler needs some refactoring. \nIt would be best for it to delegate to an \nApplication Service (14) to harmonize with the Hexagonal Architecture (4). Doing \nso would allow the Application Service to manage the transaction, which is a natural \napplication concern. In that case the handler would now look like this:\nMessageConsumer.instance(messageSource, false)\n    .receiveOnly(\n            new String[] { \"BacklogItemCommitted\" },\n            new MessageListener(Type.TEXT) {\n        @Override\n        public void handleMessage(\n            String aType,\n            String aMessageId,\n            Date aTimestamp,\n            String aTextMessage,\n            long aDeliveryTag,\n            boolean isRedelivery)\n        throws Exception {\n            // get tenantId, sprintId, and backlogItemId from JSON\n            String tenantId = ...\n            String sprintId = ...\n            String  backlogItemId = ...\n            ApplicationServiceRegistry\n                    .sprintService()\n                    .commitBacklogItem(\n                            tenantId, sprintId, backlogItemId);\n        }\n    });\nIn this example Event de-duplication is unnecessary because committing \na BacklogItem to a Sprint is an idempotent operation. If the specific \nwww.EBooksWorld.ir\n", "page": 336, "type": "text", "section": "Page 336"}
{"text": "Chapter 8 DOMAIN EVENTS\n294\nBacklogItem is already committed to the Sprint, the current request to \ncommit it again is ignored.\nIt may be necessary to provide additional state and behavior if subscribers \nrequire more than the indication of the Event\u2019s cause. This could be conveyed \nby enriched state (more properties) or operations that derive richer state. Sub-\nscribers thus avoid querying back on the Aggregate from which the Event was \npublished, which could be needlessly difficult or expensive. Event enrichment \nmay be more common when using Event Sourcing because an Event used for \npersistence may need additional state when also published out of the Bounded \nContext. Examples of Event enrichment are provided in Appendix A.\nWhiteboard Time\n\u2022 List the kinds of Events that already occur in your domain but that aren\u2019t \nbeing captured.\n\u2022 Make note of how making them an explicit part of your model would \nimprove your design.\nIt might be easiest to identify Aggregates that have dependencies on the state of \nother Aggregates, where eventual consistency is necessary.\nTo derive richer state using operations, make sure that any additional Event \nbehaviors are Side-Effect Free, as discussed in Value Objects (6), protecting the \nobject\u2019s immutability.\nWith Aggregate Characteristics\nSometimes Events are designed to be created by direct request from clients. \nThis is done in response to some occurrence that is not the direct result of exe-\ncuting behavior on an instance of an Aggregate in the model. Possibly a user \nof the system initiates some action that is considered an Event in its own right. \nWhen that happens, the Event can be modeled as an Aggregate and retained \nin its own Repository. Since it represents some past occurrence, its Repository \nwould not permit its removal.\nWhen Events are modeled in this way, like Aggregates they become part of \nthe model\u2019s structure. Thus, they are not just a record of some past occurrence, \nalthough they are that also.\nThe Event is still designed as immutable, but it may be assigned a generated \nunique identity. It is possible, however, that the identity can be supported by a \nwww.EBooksWorld.ir\n", "page": 337, "type": "text", "section": "Page 337"}
{"text": " \nMODELING EVENTS\n295\nnumber of the Event\u2019s properties. Even if unique identity could be determined \nby a set of properties, it may be best to assign a generated unique identity as \ndiscussed in Entities (5). This would allow the Event to undergo various design \nchanges over time without risking its uniqueness among all others.\nWhen an Event is modeled in this fashion, it can be published via messaging \ninfrastructure at the same time as it is added to its Repository. The client could \ncall on a Domain Service (7) to create the Event, add it to its Repository, and \nthen publish it over a messaging infrastructure. With this approach, both the \nRepository and the messaging infrastructure must be backed by the same per-\nsistence instance (data source), or a global transaction (aka XA and two-phase \ncommit) would be necessary to guarantee that both commit successfully.\nAfter the messaging infrastructure successfully saves the new Event message \nto its persistence store, it would then asynchronously send it on to any queue \nlistener, topic/exchange subscribers, or actor if using the Actor Model.1 If the \nmessaging infrastructure uses a persistence store that is separate from that \nused by the model, and if it does not support global transactions, your Domain \nService would have to see that it is first saved in the Event Store, which in this \ncase would also act as a queue for out-of-band publishing. Each Event in the \nStore would be processed by a forwarding component that would send it out \nover the messaging infrastructure. This technique is discussed in detail later in \nthis chapter.\nIdentity\nLet\u2019s clarify the reasons for assigning unique identity. At times it may be nec-\nessary to distinguish Events one from another, but the need may be rare. In the \nBounded Context where the Event is caused, created, and published, there will \ntend to be little reason to compare one Event to another, if ever. But what if, \nfor some reason, Events must be compared? And what if an Event is designed \nas an Aggregate?\nIt may be enough to allow Event identity to be represented by its properties, \nas is the case with Value Objects. The Event\u2019s name/type along with the iden-\ntities of the Aggregate(s) involved in the cause, as well as a timestamp of when \nthe Event occurred, may be enough to distinguish it from others.\nIn cases where an Event is modeled as an Aggregate, or in other cases when \nEvents must be compared and their combined properties do not distinguish \nthem, we may assign an Event a formal unique identity. But there may be other \nreasons to assign unique identity.\n 1. See Erlang\u2019s and Scala\u2019s Actor Model of concurrency. In particular, Akka is worth \nconsidering if using Scala or Java.\nwww.EBooksWorld.ir\n", "page": 338, "type": "text", "section": "Page 338"}
{"text": "Chapter 8 DOMAIN EVENTS\n296\nUnique identity may be necessary when Events are published outside the \nlocal Bounded Context where they occur, when messaging infrastructure for-\nwards them along. In some situations individual messages can be delivered \nmore than once. This would happen if the message sender crashes before the \nmessaging infrastructure confirms that the message was sent.\nWhatever may cause a message\u2019s redelivery, the solution is to get the remote \nsubscribers to detect duplicate message delivery and ignore messages already \nreceived. To help with this, some messaging infrastructures provide a unique \nmessage identity as part of the header/envelope around its body, making \nit unnecessary for the model to generate one. Even if the messaging system \ndoesn\u2019t itself automatically provide a unique identity for all messages, publish-\ners can assign one either to the Event itself or to the message. In either case, \nremote subscribers can use the unique identity to manage de-duplication when \nmessages are delivered more than once.\nIs there a need for equals() and hashCode() implementations? These \nwould most often be necessary only if the local Bounded Context used them. \nEvents sent via messaging infrastructure are sometimes not reconstituted as \ntheir native typed objects when received by subscribers but are consumed as, \nfor example, XML, JSON, or key-value maps. On the other hand, when an \nEvent is designed as an Aggregate and saved to its own Repository, the Event \ntype should provide both of these standard methods.\nPublishing Events from the Domain Model\nAvoid exposing the domain model to any kind of middleware messaging infra-\nstructure. Those kinds of components live only in the infrastructure. And while \nthe domain model might at times use such infrastructure indirectly, it would \nnever explicitly couple to it. We\u2019ll use an approach that completely avoids the \nuse of infrastructure.\nOne of the simplest and most effective ways to publish Domain Events with-\nout coupling to components outside the domain model is to create a lightweight \nObserver [Gamma et al.]. For the sake of naming I use Publish- \nSubscribe, \nwhich is acknowledged by [Gamma et al.] as another name for the same pat-\ntern. The examples in that pattern and my use of it are lightweight because \nthere is no network involved in subscribing to Events and publishing them. All \nregistered subscribers execute in the same process space with the publisher and \nrun on the same thread. When an Event is published, each subscriber is noti-\nfied synchronously, one by one. This also implies that all subscribers are run-\nning within the same transaction, perhaps controlled by an Application Service \nthat is the direct client of the domain model.\nwww.EBooksWorld.ir\n", "page": 339, "type": "text", "section": "Page 339"}
{"text": " \nPUBLISHING EVENTS FROM THE DOMAIN MODEL\n297\nConsidering the two halves of Publish-Subscribe separately helps to explain \nthem in a DDD context.\nPublisher\nPerhaps the most common use of Domain Events is when an Aggregate cre-\nates an Event and publishes it. The publisher resides in a Module (9) of the \nmodel, but it doesn\u2019t model some aspect of the domain. Rather, it provides a \nsimple service to Aggregates that need to notify subscribers of Events. The fol-\nlowing is a DomainEventPublisher, which adheres to this definition. An \nabstract view of how the DomainEventPublisher is used can be found in \nFigure 8.2.\npackage com.saasovation.agilepm.domain.model;\nimport java.util.ArrayList;\nimport java.util.List;\npublic class DomainEventPublisher {\n    @SuppressWarnings(\"unchecked\")\n    private static final ThreadLocal<List> subscribers =\n            new ThreadLocal<List>();\n    private static final ThreadLocal<Boolean> publishing =\n            new ThreadLocal<Boolean>() {\n        protected Boolean initialValue() {\n            return Boolean.FALSE;\n        }\n    };\n    public static DomainEventPublisher instance() {\n        return new DomainEventPublisher();\n    }\n    public DomainEventPublisher() {\n        super();\n    }\n    @SuppressWarnings(\"unchecked\")\n    public <T> void publish(final T aDomainEvent) {\n        if (publishing.get()) {\n            return;\n        }\n        try {\n            publishing.set(Boolean.TRUE);\n            List<DomainEventSubscriber<T>> registeredSubscribers =\n                    subscribers.get();\nwww.EBooksWorld.ir\n", "page": 340, "type": "text", "section": "Page 340"}
{"text": "Chapter 8 DOMAIN EVENTS\n298\n            if (registeredSubscribers != null) {\n                Class<?> eventType = aDomainEvent.getClass();\n                for (DomainEventSubscriber<T> subscriber :\n                     registeredSubscribers) {\n                    Class<?> subscribedTo =\n                            subscriber.subscribedToEventType();\n                    if (subscribedTo == eventType ||\n                        subscribedTo == DomainEvent.class) {\n                        subscriber.handleEvent(aDomainEvent);\n                    }\n                }\n            }\n        } finally {\n            publishing.set(Boolean.FALSE);\n        }\n    }\n    public DomainEventPublisher reset() {\n        if (!publishing.get()) {\n            subscribers.set(null);\n        }\n        return this;\n    }\n    @SuppressWarnings(\"unchecked\")\n    public <T> void subscribe(DomainEventSubscriber<T> aSubscriber) {\n        if (publishing.get()) {\n            return;\n        }\n        List<DomainEventSubscriber<T>> registeredSubscribers =\n                subscribers.get();\n        if (registeredSubscribers == null) {\n            registeredSubscribers =\n                    new ArrayList<DomainEventSubscriber<T>>();\n            subscribers.set(registeredSubscribers);\n        }\n        registeredSubscribers.add(aSubscriber);\n    }\n}\nSince every incoming request from users of the system is handled on a sep-\narate dedicated thread, we divide subscribers by thread. So the two Thread-\nLocal variables, subscribers and publishing, are allocated per thread. \nWhen interested parties use the subscribe() operation to register them-\nselves, the subscriber object reference is added to the thread-bound List. Any \nnumber of subscribers may be registered per thread.\nDepending on the application server, threads may be pooled and reused \nrequest by request. We don\u2019t want subscribers registered on the thread for \nwww.EBooksWorld.ir\n", "page": 341, "type": "text", "section": "Page 341"}
{"text": " \nPUBLISHING EVENTS FROM THE DOMAIN MODEL\n299\na previous request to remain registered for the next request that reuses the \nthread. When a new user request is received by the system, it should use the \nreset() operation to clear any previous subscribers. This ensures that sub-\nscribers will be limited only to those registered from that point forward. On \nthe presentation tier (\u201cUser Interface\u201d in Figure 8.2), for example, we might \nintercept each request using a filter. The intercepting component would in \nsome way cause a reset():\n// in a Web filter component when user request is received\nDomainEventPublisher.instance().reset();\n...\n// later in an Application Service during same request\nDomainEventPublisher.instance().subscribe(subscriber);\nFollowing the execution of this code\u2014by two separate components, as seen in \nFigure 8.2\u2014there will be just one registered subscriber for the thread. From \nthe implementation of method subscribe() \nyou can see that subscribers may \nbe registered only when the publisher is not in the process of publishing. This \nprevents problems such as concurrent modification exceptions on the List.\nUser Interface\nreset()\nsubscribe()\ndoCommand()\nnew\nnew\nDomainEventPublisher\nApplicationService\nEvent\nDomainEventSubscriber\ncommand()\nsubscribedToEventType()\nhandleEvent()\npublish()\nAggregate\nFigure 8.2 An abstract view of the sequence interactions between the lightweight Observer, User \nInterface (14), Application Services, and the Domain Model (1)\nwww.EBooksWorld.ir\n", "page": 342, "type": "text", "section": "Page 342"}
{"text": "Chapter 8 DOMAIN EVENTS\n300\nThis problem is manifest if subscribers call back on the publisher to add new \nsubscribers in response to a handled Event.\nNext, note how an Aggregate publishes an Event. Continuing with the \nrunning example, when BacklogItem\u2019s commitTo() executes successfully, \nBacklogItemCommitted is published:\npublic class BacklogItem extends ConcurrencySafeEntity {\n    ...\n    public void commitTo(Sprint aSprint) {\n        ...\n        DomainEventPublisher\n            .instance()\n            .publish(new BacklogItemCommitted(\n                    this.tenantId(),\n                    this.backlogItemId(),\n                    this.sprintId()));\n    }\n    ...\n}\nWhen publish() is executed on DomainEventPublisher, it iterates \nthrough all registered subscribers. Invoking subscribedToEventType()\non each subscriber allows it to filter out all subscribers not subscribed to the \nspecific Event type. Subscribers answering DomainEvent.class to this filter \nquery will receive all Events. All qualified subscribers are sent the published \nEvent by way of their handleEvent() method. After all subscribers have \nbeen either filtered or notified, the publisher completes.\nAs with subscribe(), publish() does not allow nested requests to pub-\nlish Events. The thread-bound Boolean named publishing is checked and \nmust be false for publish() to iterate and dispatch.\nHow is Event publishing extended to reach remote Bounded Contexts, sup-\nporting autonomous services? We\u2019ll get to that soon, but let\u2019s look closer at \nlocal subscribers.\nSubscribers\nWhat components register subscribers to Domain Events? Generally speak-\ning, Application Services (14), and sometimes Domain Services, will. The \nsubscriber may be any component that is running on the same thread as the \nAggregate that publishes the Event, and that can subscribe prior to the Event \nbeing published. This means that the subscriber is registered in the method \nexecution path that uses the domain model.\nwww.EBooksWorld.ir\n", "page": 343, "type": "text", "section": "Page 343"}
{"text": " \nPUBLISHING EVENTS FROM THE DOMAIN MODEL\n301\nCowboy Logic \nLB:  \n\u201cI want a subscription to the The Fence Post so I can \nfind even more corny things to say in this book.\u201d\nSince Application Services are the direct client of the domain model when \nusing Hexagonal Architecture, they are in an ideal position to register a sub-\nscriber with the publisher before they execute Event-generating behavior on \nAggregates. Here\u2019s one example of an Application Service that subscribes:\npublic class BacklogItemApplicationService ... {\n   public void commitBacklogItem(\n           Tenant aTenant,\n           BacklogItemId aBacklogItemId,\n           SprintId aSprintId) {\n       DomainEventSubscriber subscriber =\n               new DomainEventSubscriber<BacklogItemCommitted>() {\n           @Override\n           public void handleEvent(BacklogItemCommitted aDomainEvent) {\n               // handle event here ...\n           }\n           @Override\n           public Class<BacklogItemCommitted> subscribedToEventType() {\n               return BacklogItemCommitted.class;\n           }\n       }\n       DomainEventPublisher.instance().subscribe(subscriber);\n       BacklogItem backlogItem =\n               backlogItemRepository\n                       .backlogItemOfId(aTenant, aBacklogItemId);\n       Sprint sprint = sprintRepository.sprintOfId(aTenant, aSprintId);\n       backlogItem.commitTo(sprint);\n   }\n}\nIn this (contrived) example, BacklogItemApplicationService is \nan Application Service, with a service method commitBacklogItem().\nThe method instantiates an instance of an anonymous DomainEvent-\nSubscriber. The Application Service task coordinator then registers the \nwww.EBooksWorld.ir\n", "page": 344, "type": "text", "section": "Page 344"}
{"text": "Chapter 8 DOMAIN EVENTS\n302\nsubscriber with the DomainEventPublisher. Finally, the service method \nuses Repositories to get instances of BacklogItem and Sprint and exe-\ncutes the backlog item\u2019s commitTo() behavior. When completed, method \ncommitTo() publishes an Event of type BacklogItemCommitted.\nWhat the subscriber does with the Event is not shown in this example. It \ncould send an e-mail about the fact that a BacklogItemCommitted, if that \nmade any sense. It might store the Event in an Event Store. It could forward the \nEvent via a messaging infrastructure. Usually in these last two cases\u2014saving to \nan Event Store and forwarding using messaging infrastructure\u2014we wouldn\u2019t \nmake a use-case-specific Application Service to handle the Event in this way. \nInstead we\u2019d design a single subscriber component to do that. An example of \na single-responsibility component that saves to an Event Store is found in the \nsection \u201cEvent Store.\u201d\nBe Careful about What the Event Handler Does\nRemember, the Application Service controls the transaction. Don\u2019t use the Event \nnotification to modify a second Aggregate instance. That breaks a rule of thumb to \nmodify one Aggregate instance per transaction.\nOne thing the subscriber should not do is get another Aggregate instance \nand execute modifying command behavior on it. This would violate the modi-\nfy-single-aggregate-instance-in-single-transaction rule of thumb, as discussed \nin Aggregates (10). As [Evans] indicates, the consistency of all Aggregate \ninstances other than the one used in the single transaction must be enforced by \nasynchronous means.\nForwarding the Event via a messaging infrastructure would allow asynchro-\nnous delivery to out-of-band subscribers. Each of those asynchronous subscrib-\ners could arrange to modify an additional Aggregate instance in one or more \nseparate transactions. The additional Aggregate instances could be in the same \nBounded Context or in others. Publishing the Event outward to any number \nBounded Contexts of other Subdomains (2) emphasizes the word Domain in \nthe term Domain Event. In other words, Events are a domain-wide concept, \nnot just a concept in a single Bounded Context. The contract of Event publish-\ning should have the potential to be at least as broad as the enterprise, or even \nbroader. Yet, wide broadcast does not forbid delivery of Events by consumers \nin the same Bounded Context. Refer back to Figure 8.1.\nSometimes it is necessary for Domain Services to register subscribers. The \nmotivation for doing so would be similar to the reasons that Application Ser-\nvices do, but in this case there would be domain-specific reasons to listen for \nEvents.\nwww.EBooksWorld.ir\n", "page": 345, "type": "text", "section": "Page 345"}
{"text": " \nSPREADING THE NEWS TO REMOTE BOUNDED CONTEXTS\n303\nSpreading the News to Remote Bounded Contexts\nThere are several possible ways for remote Bounded Contexts to become aware \nof Events that occur in your Bounded Context. The primary idea is that some \nform of messaging takes place, and an enterprise messaging mechanism is \nneeded. To be clear, the mechanism being spoken of here goes well beyond the \nsimple, lightweight Publish-Subscribe components just discussed. Here we are \ndiscussing what takes over where the lightweight mechanism leaves off.\nThere are numerous such messaging components available, and they are \ngenerally classed as middleware. From the open source ActiveMQ, RabbitMQ, \nAkka, NServiceBus, and MassTransit, to the various commercially licensed \nproducts, there are plenty of options. We might also home-grow a form of \nmessaging based on REST resources, where autonomous systems are the inter-\nested parties that reach out to the publishing system, requesting all Event noti-\nfications that they have not previously consumed. All of these fall under the \numbrella of Publish-Subscribe [Gamma et al.], with varying degrees of advan-\ntage or disadvantage. Much depends on the budget, taste, functional require-\nments, and nonfunctional qualities sought by the teams involved.\nThe use of any such messaging mechanism between Bounded Contexts \nrequires that we adopt a commitment to eventual consistency. It can\u2019t be \nfought. The changes in one model that influence changes in one or more other \nmodels will not be fully consistent for some elapsed period of time. What is \nmore, depending on the traffic to individual systems and the effects they have \non others, it may be that the systems as a whole may never be fully consistent \nat any one instant in time.\nMessaging Infrastructure Consistency\nWith all the chatter about eventual consistency, it might surprise you that at \nleast two mechanisms in a messaging solution must always be consistent with \neach other: the persistence store used by the domain model, and the persistence \nstore backing the messaging infrastructure used to forward the Events pub-\nlished by the model. This is required to ensure that when the model\u2019s changes \nare persisted, Event delivery is also guaranteed, and that if an Event is deliv-\nered through messaging, it indicates a true situation reflected by the model that \npublished it. If either of these is out of lockstep with the other, it will lead to \nincorrect states in one or more interdependent models.\nHow is model and Event persistence consistency accomplished? There are \nthree basic ways:\nwww.EBooksWorld.ir\n", "page": 346, "type": "text", "section": "Page 346"}
{"text": "Chapter 8 DOMAIN EVENTS\n304\n 1. Your domain model and messaging infrastructure share the same per-\nsistence store (for example, a data source). This will allow the changes to \nthe model and the insertion of the new message to commit under the same \nlocal transaction. It has the advantage of relatively good performance. It \nhas the possible disadvantage that the messaging system\u2019s storage areas \n(such as database tables) must reside in the same database (or schema) as \nyour model\u2019s, which may be a matter of taste. Of course, this is not a via-\nble option if your choice of model store and your messaging mechanism\u2019s \nstore cannot be shared.\n 2. Your domain model\u2019s persistence store and your messaging persistence \nstore are controlled under a global, XA transaction (two-phase com-\nmit). This has the advantage that you can keep model and messaging \nstorage separated from each other. It has the disadvantage that global \ntransactions require special support, which may not be available for all \npersistence stores or messaging systems. Global transactions tend to be \nexpensive and perform poorly. It is also possible that either the model\u2019s \nstore or the messaging mechanism\u2019s store, or both, isn\u2019t XA compatible.\n 3. You create a special storage area (for example, a database table) for \nEvents in the same persistence store that is used to store your domain \nmodel. This is an Event Store, as discussed later in this chapter. It is sim-\nilar to option 1; however, this storage area is not owned and controlled \nby your messaging mechanism but instead by your Bounded Context. An \nout-of-band component that you create uses the Event Store to publish \nall stored, unpublished Events through the messaging mechanism. This \nhas the advantage that your model and your Events are guaranteed to be \nconsistent within a single, local transaction. It has the further advantages \nthat are characteristic of an Event Store, including the ability to produce \nREST-based notification feeds. This approach allows the use of a mes-\nsaging infrastructure whose message store is completely private. Given \nthat a middleware messaging mechanism can be used after Event stor-\nage, this approach has the disadvantage that the Event forwarder must \nbe custom-developed in order to send through the messaging mechanism, \nand that clients must be designed to de-duplicate incoming messages (see \n\u201cEvent Store\u201d).\nIt is the third approach that I use in my examples. While there are disadvan-\ntages to this approach, there are also several advantages that are made clear \nunder \u201cEvent Store.\u201d My choice of this one approach in no way negates the \nvalue of selecting in favor of a different set of trade-offs. You and your team \nmust choose from among them.\nwww.EBooksWorld.ir\n", "page": 347, "type": "text", "section": "Page 347"}
{"text": " \nSPREADING THE NEWS TO REMOTE BOUNDED CONTEXTS\n305\nAutonomous Services and Systems\nUsing Domain Events allows any number of your enterprise systems to be \ndesigned as autonomous services and systems. I use the term autonomous ser-\nvice to represent any coarse-grained business service, possibly thought of as \na system or application, that operates largely independent of other such \u201cser-\nvices\u201d in the enterprise. The autonomous service may have a number of service \ninterface endpoints, meaning that it offers potentially many technical service \ninterfaces to remote clients. A high degree of independence from other systems \nis achieved by avoiding in-band remote procedure calls (RPCs), where a user \nrequest is satisfied only by successful completion of an API request to a remote \nsystem.\nSince there may be times when the remote system is either completely \nunavailable or under heavy load, RPC may affect the success of the dependent \nsystem. This risk multiples as the number of systems with RPC APIs that a \ngiven system depends on increases. Thus, avoiding in-band RPC greatly eases \ndependency and related instances of complete failure and/or unacceptable per-\nformance caused by unavailable or low-throughput remote systems.\nRather than calling out to other systems, use asynchronous messaging to \nachieve a greater degree of independence between systems\u2014autonomy. As \nmessages carrying Domain Events from Bounded Contexts around the enter-\nprise are received, execute behavior on your model that reflects the meaning \nof those Events within your Bounded Context. This does not mean that you \nsimply replicate data or make exact copies of objects from other business ser-\nvices into your business service. True, some data may be copied between sys-\ntems. At a minimum, copied data will include some unique identities of foreign \nAggregates. But the objects in one system will seldom if ever be exact copies \nof objects from surrounding ones. If that probable modeling error exists, see \nBounded Contexts (2) and Context Maps (3) for reasons why it is problematic \nand for ways to avoid it. In fact, if Domain Events are correctly designed, they \nwill rarely if ever carry entire objects as part of their state.\nThe Event will hold some limited amount of command parameters and/or \nAggregate state that will convey enough meaning to allow subscribing Bounded \nContexts to react correctly. Certainly if any given Event does not hold enough \ninformation for any given subscriber, the domain-wide contract of the Event \nmust be altered in order to supply what is needed. This probably spells design-\ning an explicitly new version of the Event or a completely different one.\nIt is also true that in some cases the use of RPC cannot be easily avoided. \nSome legacy systems may be capable of providing only RPC. Also, when trans-\nlating a concept or set of concepts from a foreign Bounded Context to your \nwww.EBooksWorld.ir\n", "page": 348, "type": "text", "section": "Page 348"}
{"text": "Chapter 8 DOMAIN EVENTS\n306\nlocal Bounded Context is very difficult to do, extrapolating sufficient meaning \nfrom multiple Events may tend to increase complexity. If you must nearly rep-\nlicate the concepts, objects, and their associations from the foreign model in \nyour own model, you may need to consider sticking with RPC. This must be \nconsidered on a case-by-case basis, and I suggest not giving in to RPC too eas-\nily. If it can\u2019t be avoided, either surrender to RPC or try to influence the team \nthat owns the foreign model to find a way to simplify their design. Admittedly \nthe latter may be very difficult, if not impossible.\nLatency Tolerances\nWon\u2019t the potentially long latency periods before a message is received\u2014where \neventual consistency represents delays of more than a few milliseconds\u2014cause \nproblems? Certainly this is a matter to consider carefully, given that out-of-\nsync data could influence wrong and even damaging actions. We must ask how \nlong between consistent states is acceptable, and how much delay is too great. \nDomain experts will likely be very much in tune with what constitutes accept-\nable and unacceptable delays. It may surprise developers to learn that most \ntimes, several seconds, minutes, hours, or even days between consistent states \nis completely tolerable. This is not to say that it is always true. But we must \nnot assume that in any given domain, near-consistent time frames are always \nimperative.\nSometimes the following question will lead to an informative answer: How \ndid the business work prior to computers, or how would it work without them \nnow? Perhaps not even the very simplest of paper-based systems is ever imme-\ndiately consistent. It would only make sense, then, that automated computer \nsystems could also tolerate and even thrive in an eventually consistent manner. \nWe might conclude that eventual consistency makes better business sense.\nImagine a Subdomain used to plan future team activities. As any of the indi-\nvidual activities becomes approved, a Domain Event is published that reflects \nthe approval: TeamActivityApproved. This one follows any number of \nother Events that have already been published about the genesis and defini-\ntion of all now-approved activities. Another Bounded Context reacts to the \napproval by scheduling the latest readied activity to start sometime in relation \nto all other approved activities.\nWe know that any given activity is specified and approved at least weeks \nbefore it begins. That being so, would it matter if the Event necessary to cause \nplacement of the approved activity in the schedule were to be received min-\nutes, hours, or possibly even days following approval? Maybe days wouldn\u2019t be \nacceptable. However, if the outage of a system caused the Event to be delayed \nwww.EBooksWorld.ir\n", "page": 349, "type": "text", "section": "Page 349"}
{"text": " \nEVENT STORE\n307\nfor a number of hours\u2014probably an unlikely situation\u2014would hours with-\nout having the activity on the schedule be a completely intolerable delay? No, \nbecause it is a rare system outage that must be worked around, and the activity \nis still weeks off anyway. Since that is so, certainly a typical delay of perhaps as \nmuch as a few seconds\u2014at the outer limits\u2014for the same Event to arrive under \ncompletely normal circumstances would be not only tolerable, but acceptable. \nIn fact any actual delays may not even be perceptible.\nCowboy Logic \nAJ:  \n\u201cIs that a Kentucky \u2018shortly\u2019?\u201d\nLB:  \n\u201cIt might be a New York \u2018minute.\u2019\u201d\nJust as much as this example may prove true, other business services will \ndemand higher throughput. Maximum latency tolerances should be well \nunderstood and systems should have the architectural qualities to meet them \nand possibly even out-perform them. High availability and scalability must be \ndesigned into autonomous services and their supporting messaging infrastruc-\nture in order to dutifully fulfill stringent enterprise nonfunctional requirements.\nEvent Store\nMaintaining a store of all Domain Events for a single Bounded Context has \nseveral potential benefits. Consider what you could do if you were to store a \ndiscrete Event for every model command behavior that is ever executed. You \ncould\n 1. Use the Event Store as a queue for publishing all Domain Events through \na messaging infrastructure. This is one of the primary uses in this book. It \nallows integrations between Bounded Contexts, where remote subscribers \nreact to the Events in terms of their own contextual needs. (See the previ-\nous section, \u201cSpreading the News to Remote Bounded Contexts.\u201d)\n 2. You may use the same Event Store to feed REST-based Event notifications \nto polling clients. (This is logically the same as point 1, but different in \nactual use.)\nwww.EBooksWorld.ir\n", "page": 350, "type": "text", "section": "Page 350"}
{"text": "Chapter 8 DOMAIN EVENTS\n308\n 3. Examine a historical record of the result of every command that has ever \nbeen executed on the model. This could help trace bugs, not only in the \nmodel but also in clients. It\u2019s important to grasp that an Event Store is not \njust an audit log. Audit logs may helpful for debugging, but they rarely \ncarry the complete results of each Aggregate command outcome.\n 4. Use the data in trending, forecasting, and for other business analytics. \nMany times businesses have no idea how such historical data can be used \nuntil they later realize that they need it. Unless an Event Store is main-\ntained from the start, the historical data will be unavailable as needs arise.\n 5. Use the Events to reconstitute each Aggregate instance when it is retrieved \nfrom its Repository. This is a required part of what is known as Event \nSourcing. It is done by applying to an Aggregate instance all previously \nstored Events in chronological order. You may produce snapshots of any \nnumber of stored Events (for example, groups of 100) to optimize instance \nreconstitution.\n 6. Given an application of the preceding point, undo blocks of changes to an \nAggregate. This is possible by preventing (perhaps by removal or marking \nas obsolete) certain Events from being used to reconstitute a given Aggre-\ngate instance. You may also patch Events or insert additional Events to \ncorrect bugs in the Event stream.\nDepending on your reasons to create an Event Store, it will have certain \ncharacteristics. Since the examples presented here are primarily motivated by \nbenefits 1 and 2, our Event Store is basically concerned with holding serial-\nized Events in the order in which they occurred. This does not mean that we \ncouldn\u2019t use the Events to realize all of the first four benefits, because the sec-\nond two are possible based on the fact that we are making a record of all sig-\nnificant Events in the domain. Achieving benefits 3 and 4 is, therefore, further \napplication of what\u2019s accomplished by the first two. However, we will not be \nattempting to leverage the Event Store for points 5 and 6 in this chapter.\nSeveral steps are necessary to realize benefits 1 and 2. The steps are sum-\nmarized in Figure 8.3. Let\u2019s first discuss the steps covered in that sequence \ndiagram and the components involved. We\u2019ll do so through the project experi-\nences of SaaSOvation.\nFor whatever reasons we use an Event Store, one of the first things we need \nto do is create a subscriber that will receive every Event that is published out of \nthe model. The team decided to do that using an aspect-oriented hook that can \ninsert itself in the execution path of every Application Service in the system.\nwww.EBooksWorld.ir\n", "page": 351, "type": "text", "section": "Page 351"}
{"text": " \nEVENT STORE\n309\nHere\u2019s what the SaaSOvation team did for the Identity and \nAccess Context. The following component has the single \nresponsibility to see to it that all Domain Events get stored:\n@Aspect\npublic class IdentityAccessEventProcessor {\n    ...\n    @Before(\n    \"execution(* com.saasovation.identityaccess.application.*.*(..))\")\n    public void listen() {\n        DomainEventPublisher\n            .instance()\n            .subscribe(new DomainEventSubscriber<DomainEvent>() {\n                public void handleEvent(DomainEvent aDomainEvent) {\n                    store(aDomainEvent);\n                }\nsubscribe()\nnew\nnew\nEventStore\nIdentityAccessEventProcessor\nDomainEventSubscriber\nappend()\nserialize()\nsave()\nhandleEvent()\nDomainEventPublisher\nObjectSerializer\nSession\nStoredEvent\nAggregate command\npublishes Event . . .\nFigure 8.3 The IdentityAccessEventProcessor anonymously subscribes to all Events of the \nmodel. It delegates to EventStore, which serializes each to a StoredEvent and saves it.\nwww.EBooksWorld.ir\n", "page": 352, "type": "text", "section": "Page 352"}
{"text": "Chapter 8 DOMAIN EVENTS\n310\n                public Class<DomainEvent> subscribedToEventType() {\n                    return DomainEvent.class; // all domain events\n                }\n            });\n    }\n    private void store(DomainEvent aDomainEvent) {\n        EventStore.instance().append(aDomainEvent);\n    }\n}\nIt\u2019s a simple Event processor, and a similar one could be used by any other \nBounded Context with the same mission. It\u2019s designed as an aspect (using Spring\u2019s \nAOP) that intercepts all Application Service method invocations. When an Application \nService method is executed, this processor arranges to listen for all Domain Events \nthat get published due to the Application Service\u2019s interaction with the model. The \nprocessor registers a subscriber with the thread-bound instance of DomainEvent-\nPublisher. This subscriber\u2019s filter is wide open, which is indicated by its answer-\ning DomainEvent.class from subscribedToEventType(). Returning that class \nindicates that the subscriber wants to receive all Events. When its handleEvent()\nis invoked, it delegates to store(), which in turn delegates to class EventStore to \nappend the Event to the end of the actual Event Store.\nHere\u2019s a look at the EventStore component\u2019s append() method:\npackage com.saasovation.identityaccess.application.eventStore;\n...\npublic class EventStore ... {\n    ...\n    public void append(DomainEvent aDomainEvent) {\n        String eventSerialization =\n            EventStore.objectSerializer().serialize(aDomainEvent);\n        StoredEvent storedEvent =\n                new StoredEvent(\n                        aDomainEvent.getClass().getName(),\n                        aDomainEvent.occurredOn(),\n                        eventSerialization);\n        this.session().save(storedEvent);\n        this.setStoredEvent(storedEvent);\n    }\n}\nwww.EBooksWorld.ir\n", "page": 353, "type": "text", "section": "Page 353"}
{"text": " \nEVENT STORE\n311\nMethod store() serializes the DomainEvent instance, places that into \na new StoredEvent instance, and then writes that new object to the Event \nStore. Here is a portion of class StoredEvent that holds the serialized \nDomainEvent:\npackage com.saasovation.identityaccess.application.eventStore;\n...\npublic class StoredEvent {\n    private String eventBody;\n    private long eventId;\n    private Date occurredOn;\n    private String typeName;\n    public StoredEvent(\n            String aTypeName,\n            Date anOccurredOn,\n            String anEventBody) {\n        this();\n        this.setEventBody(anEventBody);\n        this.setOccurredOn(anOccurredOn);\n        this.setTypeName(aTypeName);\n    }\n    ...\n}\nEach StoredEvent instance gets a unique sequence value autogenerated \nby the database and set as its eventId. Its eventBody contains the serial-\nization of the DomainEvent. The serialization used here is JSON using the \n[Gson] library, but we could use another form. The typeName holds the name \nof the concrete class of the corresponding DomainEvent, and occurredOn\nis a copy of the same occurredOn in the DomainEvent.\nAll StoredEvent objects are persisted into a MySQL table. Plenty of room \nis reserved for Event serializations, although 65,000 characters is no doubt far \nmore storage than will ever be needed by a single instance:\nCREATE TABLE `tbl_stored_event` (\n    `event_id` int(11) NOT NULL auto_increment,\n    `event_body` varchar(65000) NOT NULL,\n    `occurred_on` datetime NOT NULL,\n    `type_name` varchar(100) NOT NULL,\n    PRIMARY KEY (`event_id`)\n) ENGINE=InnoDB;\nThat takes us through the high-level review of a few components necessary \nto build up the Event Store with all Event instances published by Aggregates \nwww.EBooksWorld.ir\n", "page": 354, "type": "text", "section": "Page 354"}
{"text": "Chapter 8 DOMAIN EVENTS\n312\nin the domain model. We\u2019ll look at more detail later. Let\u2019s next see how these \nstored records of happenings in our model can be consumed by other systems.\nArchitectural Styles for Forwarding Stored Events\nOnce the Event Store is populated, it is available to provide Events to be for-\nwarded as notifications to interested parties. We\u2019ll look at two styles of making \nthese Events available. One style is through RESTful resources that are queried \nby clients, and the second style is by sending messages over a topic/exchange of \na middleware messaging product.\nGranted, the REST-based approach is not truly a forwarding technique. Yet, \nit is used to produce the same results as a Publish-Subscribe style, much as an \ne-mail client is a \u201csubscriber\u201d to e-mail messages \u201cpublished\u201d by an e-mail \nserver.\nPublishing Notifications as RESTful Resources\nThe REST style of Event notification works best when used in an environment \nthat follows the basic premises of Publish-Subscribe. That is, many consumers \nare interested in the same events that are available from a single producer. On \nthe other hand, if you attempt to use the REST-based style as a Queue, the \napproach tends to break down. Here is a summary of the good and the bad of \nthe RESTful approach:\n\u2022 If potentially many clients can go to a single well-known URI to request \nthe same set of notifications, the RESTful approach works well. Essen-\ntially notifications are fanned out to any number of polling consumers. \nThis follows the basic Publish-Subscribe pattern, even though it uses the \npull model instead of the push model.2\n\u2022 If one or a few consumers are required to pull from multiple producers \nfor resources in order to get a single set of tasks to be performed in a spe-\ncific sequence, you will probably quickly feel the pain of using a REST-\nful approach. This describes a Queue, where potentially many producers \nneed to feed notifications to one or a few consumers, and the order of \nreceipt may matter. A polling model is typically not a good choice for \nimplementing Queues.\n 2. See http://c2.com/cgi/wiki?ObserverPattern for a discussion of push versus pull \nmodel in conjunction with the Observer pattern.\nwww.EBooksWorld.ir\n", "page": 355, "type": "text", "section": "Page 355"}
{"text": " \nARCHITECTURAL STYLES FOR FORWARDING STORED EVENTS\n313\nThe RESTful approach to publishing Event notifications is quite the oppo-\nsite of those published using a typical messaging infrastructure. The \u201cpub-\nlisher\u201d does not maintain a set of registered \u201csubscribers\u201d because nothing gets \npushed to interested parties. Instead this approach requires REST clients to \npull for notifications using a well-known URI.\nConsider the RESTful approach from a high level. If you are familiar with \nthe way Atom feeds are consumed on the Web, this approach will look very \nfamiliar. It\u2019s actually based on Atom concepts.\nClients use the HTTP GET method to request what is known as the current \nlog. The current log contains the very latest notifications that have been pub-\nlished. The client receives the current log with a number of notifications not \nto exceed a standard limit. Our examples use 20 as the maximum number of \nnotifications for each log. The client navigates through each of the Events in the \ncurrent log to find all that have not yet been consumed by its Bounded Context.\nHow does a client consume Event notifications locally? It interprets the seri-\nalized Event by type, translating any pertinent data as appropriate to the local \nBounded Context. This likely includes finding related Aggregate instances in \nits own model and executing commands based on the interpretation of appli-\ncable Events. Of course, Events must be applied in chronological order, since \nthe oldest Events represent operations that took place earlier than newer ones. \nUnless the oldest Events are applied first in the order in which they occurred, \nthe changes that are affected on the local model could well cause bugs.\nIn our implementation, the current log will have at most 19 notifications. It \ncould have somewhat fewer than 19, even as few as zero. When the current log \nreaches 20 total notifications, it is automatically archived. If there are no new \nnotifications available at the time the previous current log is archived, the new \ncurrent log will be empty of notifications.\nWhat\u2019s an Archived Log All About?\nThere\u2019s nothing mysterious about an archived log. It just means that the specific log \ncan no longer be altered by any action in the owning system, and clients are guar-\nanteed that no matter how many times they ask for a particular archived log, it will \nalways be the same.\nOn the other hand, the current log will change up to the point where it becomes \nfull and is finally archived. However, the only changes that can occur to the current \nlog would be to add new notifications until it is full.\nEvents previously added to any log must never change. This is so because clients \nmust have the guarantee that once they have applied a specific Event locally, it has \nbeen applied once and for all times.\nThus, the current log may not always hold the newest or oldest notification \nthat has yet to be applied locally. The oldest such Event may reside in the log \nwww.EBooksWorld.ir\n", "page": 356, "type": "text", "section": "Page 356"}
{"text": "Chapter 8 DOMAIN EVENTS\n314\nprevious to the current, or even the others before it. It\u2019s all a matter of timing \nbased on how frequently Events fill up a given finite log (in this case with just \n20 entries) and how often clients pull for the logs. Figure 8.4 shows how notifi-\ncation logs chain together to provide a virtual array of individual notifications.\nAssuming the log state depicted by Figure 8.4, let\u2019s say that notifications 1 \nthrough 58 have already been applied locally. That means that notifications 59 \nthrough 65 have not yet been applied. If the client pulls the following URI, it \nwill receive the current log:\n//iam/notifications\nThe client reads from its own database a tracking record of the identity of the \nmost recently applied notification, which in our example is 58. The onus is \non the client, not the server, to track the next notification to apply. The client \nnavigates from the top to the bottom through the current log in search of the \nnotification with identity 58. It doesn\u2019t find it there, so it continues to navigate \nback to the previous log, which is an archived log. The previous log is reached \nby use of a hypermedia link in the current log. One style is to allow hyperme-\ndia navigation to leverage a header:\nHTTP/1.1 200 OK\nContent-Type: application/vnd.saasovation.idovation+json\n...\nLink: <http://iam/notifications/61,80>; rel=self\nLink: <http://iam/notifications/41,60>; rel=previous\n...\nCURRENT\nNotification Log\n[61\u201365]\nnext\nARCHIVED\nNotification Log\n[41\u201360]\nARCHIVED\nNotification Log\n[21\u201340]\nARCHIVED\nNotification Log\n[1\u201320]\nprevious\nnext\nprevious\nnext\nprevious\nFigure 8.4 The current log and any number of linked archived logs form a \nvirtual array of all Events from the most recent Event back to the very first Event. \nHere notifications 1 through 65 are depicted. Each of the archived logs contains \nthe full 20-notification limit. The current log has not yet filled up and contains \njust five total notifications.\nwww.EBooksWorld.ir\n", "page": 357, "type": "text", "section": "Page 357"}
{"text": " \nARCHITECTURAL STYLES FOR FORWARDING STORED EVENTS\n315\nWhy Doesn\u2019t the URI Reflect What\u2019s Actually in the Current Log?\nNote that although the current log presently has only notifications with identities \n61 through 65, its URI is composed of the full identity range, 61 through 80, for \nexample:\nLink: <http://iam/notifications/61,80>; rel=self\nThat\u2019s because the resource must remain stable over its entire lifetime. This \nallows for consistent access and for caching to work correctly.\nFrom the Link containing rel=previous, the URI is used for a GET,\nwhich retrieves the log previous to the current one:\n//iam/notifications/41,60\nUsing this archived log, the client now finds the sought-after notification, the \none with identity 58, after three probes on individual notifications (60, 59, \nthen 58). Since this client has already applied that notification (identity 58), \nit does not apply notification 58 again. Instead, it now navigates in the other \ndirection in search of all newer notifications. In this archived log it finds iden-\ntity 59 and applies it. Then it finds 60 and applies it. It has now reached the \ntop of this archived log, so it navigates to the rel=next resource, which is the \ncurrent log:\nHTTP/1.1 200 OK\nContent-Type: application/vnd.saasovation.idovation+json\n...\nLink: <http://iam/notifications/61,80>; rel=next\nLink: <http://iam/notifications/41,60>; rel=self\nLink: <http://iam/notifications/21,40>; rel=previous\n...\nIt finds in that log notifications with identities 61, 62, 63, 64, and 65, applying \neach in chronological order. It reaches the end of the current log and stops pro-\ncessing for now, because the current log never has a link header of rel=next.\nSometime later the process repeats. The current log is requested by URI. \nPerhaps by now the activity in the source Bounded Context has caused the \ngeneration of significantly different logs by producing a number of new noti-\nfications. When the current log is now requested, it may have any number of \nnew notifications. The client may have to navigate back one, two, or even more \narchived logs to find the most recently applied notification, which is presently \nthe one with identity 65. As before, when the client finds notification 65, it will \napply all newer ones in chronological order.\nAny number of different client Bounded Contexts may request the notifica-\ntion logs. In fact, any Bounded Context that needs to know what Events have \nwww.EBooksWorld.ir\n", "page": 358, "type": "text", "section": "Page 358"}
{"text": "Chapter 8 DOMAIN EVENTS\n316\nbeen produced by any other Bounded Context providing this kind of notifica-\ntion publisher may reach out to get the notifications as far back as the \u201cbegin-\nning of time.\u201d Of course, each client Bounded Context may actually be a client \nonly if it has proper access to the source system (for example, security rights).\nBut won\u2019t client polling of notification resources cause enormous amounts \nof unwanted traffic against your Web server? Not if your RESTful resources \nmake effective use of caching. For example, the current log might be cached by \nthe client itself for approximately one minute:\nHTTP/1.1 200 OK\nContent-Type: application/vnd.saasovation.idovation+json\n...\nCache-Control: max-age=60\n...\nEvery time the client polling precedes the one-minute caching, the client cache \nitself provides the previously retrieved current log. When the cache times out, \nthe latest current log will be retrieved from the server resource. Archived logs \nmay be cached longer since their contents never change, as demonstrated by \nthis one-hour max-age:\nHTTP/1.1 200 OK\nContent-Type: application/vnd.saasovation.idovation+json\n...\nCache-Control: max-age=3600\n...\nThe client may use the current log max-age value as a timer/sleep thresh-\nold since it is unnecessary to perform GET requests continuously on cached \nresources. Sleep-induced decreased polling can benefit processing load on the \nclient Bounded Context and on the source server. The resource provider will \nnever receive the requests as long as the cache max-age has not expired. So \nan ill-behaved client can never hurt performance or availability of the notifi-\ncation producer, assuming the proper use of client caching. This highlights the \nbenefits of using the Web and its built-in infrastructure to achieve tremendous \nperformance and scalability benefits.\nThe server may also provide its own cache. Server caching of notification \nlogs works really well because the contents of archived logs never change. \nAny client that requests a given archived notification log not only receives \nthe resource, it also warms the cache for all other clients in need of the same \nwww.EBooksWorld.ir\n", "page": 359, "type": "text", "section": "Page 359"}
{"text": " \nARCHITECTURAL STYLES FOR FORWARDING STORED EVENTS\n317\nresource. There is no need for the cache to refresh an archived log because the \nlog is guaranteed immutable.\nWow! That was quite a bit of detail, and still more remains under Inte-\ngrating Bounded Contexts (13). I suggest that you reference [Parastatidis et \nal., RiP] for various strategies on designing efficient RESTful Event notifica-\ntion systems. There you will find discussions on the advantages and disadvan-\ntages of the standard media type Atom-based notification logs, as well as a \nfew reference implementations. Also, Jim Webber provides further insight on \nthis approach in his presentation [Webber, REST & DDD]. One of the ear-\nliest references to this approach comes from Stefan Tilkov\u2019s article on InfoQ \n[Tilkov, RESTful Doubts]. You can also watch my own presentation using this \napproach [Vernon, RESTful DDD].\nPublishing Notifications through Messaging Middleware\nNot surprisingly, a messaging middleware product such as RabbitMQ manages \ndetails for you that the REST style forces you to deal with on your own. The \nmessaging system also allows you to fairly easily support both Publish-Sub-\nscribe and Queues, whichever better fits your needs. In both cases the mes-\nsaging system uses a push model to send messages of Event notifications to \nregistered subscribers or listeners.\nConsider the requirements for publishing Events from our Event Store via a \nmessaging middleware product. We are going to stick with Publish-Subscribe, \nusing what RabbitMQ calls a fanout exchange. We will need a set of compo-\nnents that together do the following in order:\n 1. Query all Domain Event objects from the Event Store that have not yet \nbeen published to the specific exchange. Order the queried objects in \nascending order by their sequenced unique identity.\n 2. Iterate over the queried objects in ascending order, sending each to the \nexchange.\n 3. When the messaging system indicates that the message was successfully \npublished, track that Domain Event as having been published through \nthat exchange.\nWe do not wait to see if subscribers confirm receipt. Subscriber systems may \nnot even be running when the publisher sends messages through the exchange. \nEach subscriber is responsible for handling messages in its own time frame, \nensuring that it properly carries out any necessary domain behavior on its own \nmodel. We simply allow the messaging mechanism to guarantee delivery.\nwww.EBooksWorld.ir\n", "page": 360, "type": "text", "section": "Page 360"}
{"text": "Chapter 8 DOMAIN EVENTS\n318\nWhiteboard Time\n\u2022 Draw a Context Map of the Bounded Context you work on and the oth-\ners you integrate with. Make sure you show connections between the \nContexts that interact.\n\u2022 Make notations of the kinds of relationships between them, such as Anti-\ncorruption Layer (3).\n\u2022 Now indicate how you would integrate these Contexts. Would you use \nRPC, RESTful notifications, or a messaging infrastructure? Draw those in.\nRemember, you might not have much choice when integrating with a legacy \nsystem.\nImplementation\nHaving decided on the architectural styles used for publishing Events, the \nSaaSOvation team is now focused on the implementation of components to \naccomplish that . . .\nThe core of notification publishing behavior is placed \nbehind an Application Service, the NotificationSer-\nvice. That allowed the team to manage the transac-\ntional scope of changes in their own data source. It also \nemphasized that notification is an application concern, \nnot a domain concern, even though the Events being \npublished as notifications originated in the model.\nThere was no need for the NotificationService\nto have a Separated Interface [Fowler, P of EAA]. At \nthis time there would be just one implementation of the \nApplication Service, so the team would keep things simple. Still, every simple class \nhas a public interface, so here it is presented as stubbed-out methods:\npackage com.saasovation.identityaccess.application;\n...\npublic class NotificationService {\n    ...\n    @Transactional(readOnly=true)\n    public NotificationLog currentNotificationLog() {\n        ...\n    }\nwww.EBooksWorld.ir\n", "page": 361, "type": "text", "section": "Page 361"}
{"text": " \nIMPLEMENTATION\n319\n    @Transactional(readOnly=true)\n    public NotificationLog notificationLog(String aNotificationLogId) {\n        ...\n    }\n    @Transactional\n    public void publishNotifications() {\n        ...\n    }\n    ...\n}\nThe first two methods will be used for querying NotificationLog instances that \nare provided to clients as RESTful resources, and the third will be used to publish \nindividual Notification instances over a messaging mechanism. The team will first \ntackle the query methods for getting NotificationLog instances, then turn their \nattention to the one that interacts with the messaging infrastructure.\nThere are some interesting implementations ahead.\nPublishing the NotificationLog\nRecall that there are two kinds of notification logs, a current log and an \narchived log. Thus, the NotificationService interface provides a query \nmethod for each type:\npublic class NotificationService {\n    @Transactional(readOnly=true)\n    public NotificationLog currentNotificationLog() {\n        EventStore eventStore = EventStore.instance();\n        return this.findNotificationLog(\n                this.calculateCurrentNotificationLogId(eventStore),\n                eventStore);\n    }\n    @Transactional(readOnly=true)\n    public NotificationLog notificationLog(String aNotificationLogId) {\n        EventStore eventStore = EventStore.instance();\n        return this.findNotificationLog(\n                new NotificationLogId(aNotificationLogId),\n                eventStore);\n    }\n    ...\n}\nwww.EBooksWorld.ir\n", "page": 362, "type": "text", "section": "Page 362"}
{"text": "Chapter 8 DOMAIN EVENTS\n320\nUltimately both of these methods must \u201cfind\u201d a NotificationLog.\nWhat that really means is finding a section of DomainEvent instances \nthat have been serialized in the Event Store, encapsulating each one with a \nNotification, and collecting all those into a NotificationLog. Once a \nNotificationLog instance is created, it can be represented as a RESTful \nresource and provided to a requesting client.\nSince the current log may be a constantly moving target, its identity must be \ncalculated every time it is requested. Here\u2019s the calculation:\npublic class NotificationService {\n    ...\n    protected NotificationLogId calculateCurrentNotificationLogId(\n            EventStore anEventStore) {\n        long count = anEventStore.countStoredEvents();\n        long remainder = count % LOG_NOTIFICATION_COUNT;\n        if (remainder == 0) {\n            remainder = LOG_NOTIFICATION_COUNT;\n        }\n        long low = count - remainder + 1;\n        // ensures a minted id value even though there may\n        // not be a full set of notifications at present\n        long high = low + LOG_NOTIFICATION_COUNT - 1;\n        return new NotificationLogId(low, high);\n    }\n    ...\n}\nOtherwise, for an archived log all that is needed is a NotificationLogId\nto encapsulate the low and high range of the identifier. Remember that the iden-\ntifier is encoded as a textual representation of a range between low and high val-\nues, such as 21\u201340. Thus, the constructor for an encoded identity looks like this:\npublic class NotificationLogId {\n    ...\n    public NotificationLogId(String aNotificationLogId) {\n        super();\n        String[] textIds = aNotificationLogId.split(\",\");\n        this.setLow(Long.parseLong(textIds[0]));\n        this.setHigh(Long.parseLong(textIds[1]));\n    }\n    ...\n}\nwww.EBooksWorld.ir\n", "page": 363, "type": "text", "section": "Page 363"}
{"text": " \nIMPLEMENTATION\n321\nWhether querying for the current log or an archived log, we now have a \nNotificationLogId that describes what method findNotification-\nLog() will query for:\npublic class NotificationService {\n    ...\n    protected NotificationLog findNotificationLog(\n            NotificationLogId aNotificationLogId,\n            EventStore anEventStore) {\n        List<StoredEvent> storedEvents =\n            anEventStore.allStoredEventsBetween(\n                    aNotificationLogId.low(),\n                    aNotificationLogId.high());\n        long count = anEventStore.countStoredEvents();\n        boolean archivedIndicator = aNotificationLogId.high() < count;\n        NotificationLog notificationLog =\n            new NotificationLog(\n                    aNotificationLogId.encoded(),\n                    NotificationLogId.encoded(\n                            aNotificationLogId.next(\n                                    LOG_NOTIFICATION_COUNT)),\n                    NotificationLogId.encoded(\n                            aNotificationLogId.previous(\n                                    LOG_NOTIFICATION_COUNT)),\n                    this.notificationsFrom(storedEvents),\n                    archivedIndicator);\n        return notificationLog;\n    }\n    ...\n    protected List<Notification> notificationsFrom(\n            List<StoredEvent> aStoredEvents) {\n        List<Notification> notifications =\n            new ArrayList<Notification>(aStoredEvents.size());\n        for (StoredEvent storedEvent : aStoredEvents) {\n            DomainEvent domainEvent =\n                    EventStore.toDomainEvent(storedEvent);\n            Notification notification =\n                new Notification(\n                        domainEvent.getClass().getSimpleName(),\n                        storedEvent.eventId(),\n                        domainEvent.occurredOn(),\n                        domainEvent);\n            notifications.add(notification);\n        }\nwww.EBooksWorld.ir\n", "page": 364, "type": "text", "section": "Page 364"}
{"text": "Chapter 8 DOMAIN EVENTS\n322\n        return notifications;\n    }\n    ...\n}\nIt\u2019s quite interesting that there is no need to actually persist any  \nNotification\ninstances or whole logs. We can just manufacture them each time they are \nneeded. Obviously, for that reason, it helps with performance and scalability to \ncache NotificationLog resources at the points of request.\nMethod findNotificationLog() uses the EventStore component to \nquery the StoredEvent instances it needs for a given log. Here\u2019s how the \nEventStore finds them:\npackage com.saasovation.identityaccess.application.eventStore;\n...\npublic class EventStore ... {\n    ...\n    public List<StoredEvent> allStoredEventsBetween(\n            long aLowStoredEventId,\n            long aHighStoredEventId) {\n        Query query =\n            this.session().createQuery(\n                    \"from StoredEvent as _obj_ \"\n                    + \"where _obj_.eventId between ? and ? \"\n                    + \"order by _obj_.eventId\");\n        query.setParameter(0, aLowStoredEventId);\n        query.setParameter(1, aHighStoredEventId);\n        List<StoredEvent> storedEvents = query.list();\n        return storedEvents;\n    }\n    ...\n}\nFinally, at the Web tier we publish the current log and archived logs:\n@Path(\"/notifications\")\npublic class NotificationResource {\n    ...\n    @GET\n    @Produces({ OvationsMediaType.NAME })\n    public Response getCurrentNotificationLog(\n            @Context UriInfo aUriInfo) {\nwww.EBooksWorld.ir\n", "page": 365, "type": "text", "section": "Page 365"}
{"text": " \nIMPLEMENTATION\n323\n        NotificationLog currentNotificationLog =\n            this.notificationService()\n                .currentNotificationLog();\n        if (currentNotificationLog == null) {\n            throw new WebApplicationException(\n                    Response.Status.NOT_FOUND);\n        }\n        Response response =\n            this.currentNotificationLogResponse(\n                    currentNotificationLog,\n                    aUriInfo);\n        return response;\n    }\n    @GET\n    @Path(\"{notificationId}\")\n    @Produces({ OvationsMediaType.ID_OVATION_NAME })\n    public Response getNotificationLog(\n            @PathParam(\"notificationId\") String aNotificationId,\n            @Context UriInfo aUriInfo) {\n        NotificationLog notificationLog =\n            this.notificationService()\n                .notificationLog(aNotificationId);\n        if (notificationLog == null) {\n            throw new WebApplicationException(\n                    Response.Status.NOT_FOUND);\n        }\n        Response response =\n            this.notificationLogResponse(\n                    notificationLog,\n                    aUriInfo);\n        return response;\n    }\n    ...\n}\nThe team could have used a MessageBodyWriter to generate the response, \nbut there are some necessary minor complexities that are managed in response \nbuilder methods.\nThat covers the important bits used to publish both current and archived \nnotification logs to RESTful clients.\nwww.EBooksWorld.ir\n", "page": 366, "type": "text", "section": "Page 366"}
{"text": "Chapter 8 DOMAIN EVENTS\n324\nPublishing Message-Based Notifications\nThe NotificationService provides a single method for publishing \nDomainEvent instances over a messaging infrastructure. Here is the service \nmethod:\npublic class NotificationService {\n    ...\n    @Transactional\n    public void publishNotifications() {\n        PublishedMessageTracker publishedMessageTracker =\n            this.publishedMessageTracker();\n        List<Notification> notifications =\n            this.listUnpublishedNotifications(\n                    publishedMessageTracker\n                            .mostRecentPublishedMessageId());\n        MessageProducer messageProducer = this.messageProducer();\n        try {\n            for (Notification notification : notifications) {\n                this.publish(notification, messageProducer);\n            }\n            this.trackMostRecentPublishedMessage(\n                    publishedMessageTracker,\n                    notifications);\n        } finally {\n            messageProducer.close();\n        }\n    }\n    ...\n}\nMethod publishNotifications() first gets its PublishedMessage-\nTracker. This is the object that persists the record of which Events have \nalready been published:\npackage com.saasovation.identityaccess.application.notifications;\n...\npublic class PublishedMessageTracker {\n    private long mostRecentPublishedMessageId;\n    private long trackerId;\n    private String type;\n    ...\n}\nwww.EBooksWorld.ir\n", "page": 367, "type": "text", "section": "Page 367"}
{"text": " \nIMPLEMENTATION\n325\nNote that this class is not part of the domain model but rather belongs to \nthe application. The trackerId is just this object\u2019s unique identity (essentially \nan Entity). The type attribute holds the String description of the type of \ntopic/channel that the Events were published on. The attribute mostRecent-\nPublishedMessageId corresponds to the unique identity of the individual \nDomainEvent that was serialized and persisted as a StoreEvent. Thus, it \nholds the value of the StoredEvent eventId of the most recently published \ninstance. After all new Notification messages have been sent, the service \nmethod ensures that the PublishedMessageTracker is saved with the \nidentity of the now most recently published Event.\nThe Event identity along with the type attribute allows us to publish the \nsame notifications at different times to any number of topics/channels. We just \ncreate a new instance of the PublishedMessageTracker with the name of \nthe topic/channel as its type and start again with the first StoredEvent. In \nfact, here\u2019s how method publishedMessageTracker() does it:\npublic class NotificationService {\n    private static final String EXCHANGE_NAME =\n            \"saasovation.identity_access\";\n    ...\n    private PublishedMessageTracker publishedMessageTracker() {\n        Query query =\n            this.session().createQuery(\n                    \"from PublishedMessageTracker as _obj_ \"\n                    + \"where _obj_.type = ?\");\n        query.setParameter(0, EXCHANGE_NAME);\n        PublishedMessageTracker publishedMessageTracker =\n            (PublishedMessageTracker) query.uniqueResult();\n        if (publishedMessageTracker == null) {\n            publishedMessageTracker =\n                new PublishedMessageTracker(EXCHANGE_NAME);\n        }\n        return publishedMessageTracker;\n    }\n    ...\n}\nMultichannel publishing is not yet supported, but it could be added easily \nwith a little refactoring.\nNext, method listUnpublishedNotifications() is responsible for \nquerying a sorted list of all unpublished Notification instances:\nwww.EBooksWorld.ir\n", "page": 368, "type": "text", "section": "Page 368"}
{"text": "Chapter 8 DOMAIN EVENTS\n326\npublic class NotificationService {\n    ...\n    protected List<Notification> listUnpublishedNotifications(\n            long aMostRecentPublishedMessageId) {\n        EventStore eventStore = EventStore.instance();\n        List<StoredEvent> storedEvents =\n                eventStore.allStoredEventsSince(\n                        aMostRecentPublishedMessageId);\n        List<Notification> notifications =\n            this.notificationsFrom(storedEvents);\n        return notifications;\n    }\n    ...\n}\nIn reality it\u2019s querying the EventStore for StoredEvent instances with \neventId values greater than the one held by parameter aMostRecent-\nPublishedMessageId. Those returned from the EventStore are used to \ncreate a new collection of Notification instances.\nNow, back to the main service method publishNotifications(). With \nthe collection of DomainEvent wrapper Notification instances, it iterates \nand dispatches to method publish():\n...\nfor (Notification notification : notifications) {\n    this.publish(notification, messageProducer);\n}\nThis method that publishes individual Notification instances does so \nthrough RabbitMQ, but using a very simple object library to make its interface \nseem more object-oriented:\npublic class NotificationService {\n    ...\n    protected void publish(\n            Notification aNotification,\n            MessageProducer aMessageProducer) {\n        MessageParameters messageParameters =\n            MessageParameters.durableTextParameters(\n                    aNotification.type(),\n                    Long.toString(aNotification.notificationId()),\n                    aNotification.occurredOn());\nwww.EBooksWorld.ir\n", "page": 369, "type": "text", "section": "Page 369"}
{"text": " \nIMPLEMENTATION\n327\n        String notification =\n            NotificationService\n                .objectSerializer()\n                .serialize(aNotification);\n        aMessageProducer.send(notification, messageParameters);\n    }\n    ...\n}\nThis publish() \nmethod creates MessageParameters and then sends \nthe JSON serialized DomainEvent by way of a MessageProducer.3 The \nMessageParameters include select properties to send along with the mes-\nsage body. Among these special parameters are the Event type string, the \nnotification identity used as a unique message ID, and the occurredOn time-\nstamp of the Event. These parameters allow subscribers to determine impor-\ntant facts about each message without the need to parse the JSON message \nbody, which is the serialized Event. And the unique message ID (notification \nidentity) supports message de-duplication, which is explained later.\nConsider one more method used to fully implement publishing:\npublic class NotificationService {\n    ...\n    private MessageProducer messageProducer() {\n        // create my exchange if nonexistent\n        Exchange exchange =\n            Exchange.fanOutInstance(\n                    ConnectionSettings.instance(),\n                    EXCHANGE_NAME,\n                    true);\n        // create a message producer used to forward Events\n        MessageProducer messageProducer =\n            MessageProducer.instance(exchange);\n        return messageProducer;\n    }\n    ...\n}\n 3. Classes Exchange, ConnectionSettings, MessageProducer, Message-\nParameters, and others are part of a library that serves as an abstraction layer \naround RabbitMQ. I provide this library, which makes using RabbitMQ much \nmore object friendly, along with the other sample code for the book.\nwww.EBooksWorld.ir\n", "page": 370, "type": "text", "section": "Page 370"}
{"text": "Chapter 8 DOMAIN EVENTS\n328\nMethod publishNotifications() uses messageProducer() to ensure \nthat the exchange exists and then gets the instance of MessageProducer\nused to publish. RabbitMQ supports exchange idempotence, so the first \ntime you ask for the exchange it is created, and all subsequent times you are \ngiven the preexisting one. We don\u2019t retain an open instance of the Message-\nProducer in case a problem with the backing broker channel somehow devel-\nops. Reestablishing the connection each time publish is executed helps prevent \na completely inoperable publisher. We may need to look out for possible per-\nformance issues if constant reconnection becomes a bottleneck. But for now \nwe will count on the configured pauses between publish operations to alleviate \nreconnection overhead.\nSpeaking of pauses between publish operations, none of the preceding code \nindicates how Events are published to the exchange on a regular, recurring \nbasis. That can be accomplished in a few different ways and may depend on \nyour operational environment. For one, a JMX TimerMBean can be used to \nmanage recurring time intervals.\nBefore presenting the following timer solution, it\u2019s important to note an \nimportant context. The Java MBean standard also uses the term notification,\nbut this is not the same used by our own publishing process. In this case, a \nlistener receives notification of each occurrence of the timer firing. Just be pre-\npared to sort that out in your mind.\nWhatever suitable interval is determined and configured for a given timer, \na NotificationListener is registered so the MBeanServer can notify on \neach occasion when an interval is reached:\nmbeanServer.addNotificationListener(\n        timer.getObjectName(), \n        new NotificationListener() {\n            public void handleNotification(\n                    Notification aTimerNotification,\n                    Object aHandback) {\n                ApplicationServiceRegistry\n                        .notificationService()\n                        .publishNotifications();\n            }\n        },\n        null,\n        null);\nIn this example, when method handleNotification() is invoked due \nto the timer firing, it requests the NotificationService to perform its \npublishNotifications() operation. That\u2019s all that\u2019s necessary. For as long \nas the TimerMBean continues to fire at regular, recurring intervals, Domain \nwww.EBooksWorld.ir\n", "page": 371, "type": "text", "section": "Page 371"}
{"text": " \nIMPLEMENTATION\n329\nEvents will continue to be published through the exchange and consumed by \nsubscribers across the enterprise.\nUsing an application-server-managed timer has the added advantage that you \ndon\u2019t have to create a component to monitor the life cycle of your publishing \nprocess. If, for example, the publishNotifications() should for some rea-\nson on any given execution encounter problems and terminate with an excep-\ntion, the TimerMBean would continue to run and fire on subsequent intervals. \nAdministrators may need to address infrastructure errors, perhaps with Rab-\nbitMQ, but once problems are out of the way, messages would continue to be \npublished. That said, there are other timer facilities available, such as [Quartz].\nBut we are still left with questions about message de-duplication. What is \nmessage de-duplication? And why is it necessary for messaging subscribers to \nsupport it?\nEvent De-duplication De-duplication is a necessity in environments where \na single message published through a messaging system could possibly be deliv-\nered to subscribers more than once. There are various causes of duplicate mes-\nsages. One way this can happen is the following:\n 1. RabbitMQ delivers the newly sent messages to one or more subscribers.\n 2. The subscribers process the messages.\n 3. Before subscribers can acknowledge that the messages were received and \nprocessed, they fail.\n 4. RabbitMQ delivers the unacknowledged messages again.\nThe possibility also exists when publishing out of an Event Store, and the \nmessaging system doesn\u2019t share the Event Store\u2019s persistence mechanism, and \nglobal, XA transactions are not controlling atomic commits of Event Store and \nmessaging persistence changes. As discussed earlier under \u201cPublishing Notifi-\ncations through Messaging Middleware,\u201d that is exactly our situation. Con-\nsider a scenario that highlights how a message could be sent more than once:\n 1. The NotificationService queries and publishes three unpub-\nlished Notification instances. It updates the record of this with \nPublishedMessageTracker.\n 2. The RabbitMQ broker receives all three messages and prepares to send \nthem to all subscribers.\n 3. However, due to some exceptional condition on the application server, \nthere is a failure of the NotificationService. The modification to the \nPublishedMessageTracker is not committed.\nwww.EBooksWorld.ir\n", "page": 372, "type": "text", "section": "Page 372"}
{"text": "Chapter 8 DOMAIN EVENTS\n330\n 4. RabbitMQ delivers the newly sent messages to subscribers.\n 5. The exceptional condition on the application server is corrected. The \nprocess of publishing begins again and the NotificationService\nsuccessfully sends messages for all unpublished Events. This includes \nsending (again!) messages for all Events that were previously published \nbut unknown to the PublishedMessageTracker.\n 6. RabbitMQ delivers the newly sent messages to subscribers, at least three \nof which are duplicate deliveries.\nIn this scenario I arbitrarily use three Events. I could have used one, two, \nfour, or many more. The number is not significant, only the fact that prob-\nlems like these could cause redelivery. When you face this and other reasons \nfor message duplication, de-duplication is necessary. See Idempotent Receiver\n[Hohpe & Woolf] for more elaborate treatment.\nAn Idempotent Operation\nAn idempotent operation is one that can be executed two or more times in succes-\nsion with results identical to those of executing the same operation only once.\nOne way to deal with the possibility of duplicate message delivery is for \nsubscriber model operation to be idempotent. The subscriber\u2019s response to all \nmessages could be idempotent operations against its own domain model. The \nproblem is that designing a domain object, or any object for that matter, to be \nidempotent can be difficult, impractical, or even impossible. And if we attempt \nto design the Event itself to carry information that reflects an idempotent \naction to be taken, that can also be troublesome. For one, the sender must fully \nunderstand the current business situation of all receivers relative to the Event \nstate they will send. Further, receipt of Events that are out of sequence due to \nlatency, retries, and so on could cause errors.\nWhen domain object idempotence is not a viable option, you can instead \ndesign the subscriber/receiver itself to be idempotent. The receiver can be \ndesigned to refuse to execute an operation in response to a duplicate message. \nFirst, you should check to see if your messaging product supports this as a fea-\nture. If not, your receiver will need to track which messages have already been \nhandled. One way to accomplish that is to allocate an area in the subscriber\u2019s \npersistence mechanism to save the name of the topic/exchange along with the \nunique message ID of all handled messages\u2014yes, similar to a Published-\nMessageTracker. Then you can query for duplicates before handling each \nmessage. If the query finds that a message was already handled, the subscriber \nsimply ignores it. The handled message tracking is not part of the domain \nwww.EBooksWorld.ir\n", "page": 373, "type": "text", "section": "Page 373"}
{"text": " \nWRAP-UP\n331\nmodel. It should be viewed only as a technical work-around for common mes-\nsaging idiosyncrasies.\nWhen using a typical messaging middleware product, it is not enough to \nsave only a record of the latest handled message because messages can be \nreceived out of order. Thus, a de-duplication query that checks for message IDs \nless than the most recent one would cause you to ignore some messages that \nwere received out of order. Also to be considered is that sometimes you will \nwant to discard all handled message tracking entries that are obsolete, as in \ndatabase garbage collection.\nWhen using the REST-based notification approach, de-duplication is not \nreally a factor. Client receivers need to save only the most recently applied noti-\nfication identity since they will always be applying only the notifications of \nevents that occurred after it. Each notification log will always be in reverse \nchronological order (descending) by notification identity.\nIn both cases\u2014messaging middleware subscribers and REST-based notifi-\ncation clients\u2014it is important that the tracking of handled message identity \nbe committed along with any changes to the local domain model state. Other-\nwise, you will be unable to maintain tracking consistency in conjunction with \nthe modifications made in response to Events.\nWrap-Up\nIn this chapter we looked at the definition of Domain Events and how they \ndetermine when modeling an Event would be to your advantage.\n\u2022 You\u2019ve learned what Domain Events are, and when and why to use them.\n\u2022 You looked into how Events are modeled as objects, and when they must \nbe uniquely identified.\n\u2022 You considered when an Event should have Aggregate characteristics, and \nwhen a simple Value-based Event works best.\n\u2022 You saw how lightweight Publish-Subscribe components are used in the \nmodel.\nwww.EBooksWorld.ir\n", "page": 374, "type": "text", "section": "Page 374"}
{"text": "Chapter 8 DOMAIN EVENTS\n332\n\u2022 You discovered which components publish Events and which ones sub-\nscribe to them.\n\u2022 You grasped why you\u2019d want to develop an Event Store, how it can be \ndone, and how one is used.\n\u2022 You learned about two approaches to Event publishing outside the \nBounded Context: REST-based notifications and the use of messaging \nmiddleware.\n\u2022 You learned some ways to de-duplicate messages in subscribing systems.\nNext, we are going to change directions quite a bit and look into how \ndomain model objects can be well organized by using Modules.\nwww.EBooksWorld.ir\n", "page": 375, "type": "text", "section": "Page 375"}
{"text": "333\nChapter 9\nModules\nThe secret of all victory lies in the organization of the non-obvious.\n\u2014Marcus Aurelius\nIf you are using Java or C#, you are already familiar with Modules, though \nyou know them by another name. Java calls them packages. C# calls them \nnamespaces. Actually in Ruby you can use the module language construct to \neffect namespaces for classes. In Ruby\u2019s case the DDD pattern name matches \nthe name of the language construct. For the sake of our DDD context I will \ncontinue to call them Modules in most cases. It will be easy for you to map \nthat name to the programming language term you regularly use. I won\u2019t spend \nmuch time trying to explain technically what Modules do, because you proba-\nbly figured that out long ago.\nRoad Map to This Chapter\n\u2022 Learn the difference between traditional Modules and the newer deployment \nmodularity approach.\n\u2022 Consider the importance of naming Modules per the Ubiquitous Language (1).\n\u2022 See how designing Modules mechanically actually stifles modeling creativity.\n\u2022 Learn the design choices and trade-offs made by the SaaSOvation teams.\n\u2022 Find out the role Modules play outside the domain model, and when to favor \nnew Modules over new Bounded Contexts.\nDesigning with Modules\nIn a DDD context, Modules in your model serve as named containers for \ndomain object classes that are highly cohesive with one another. The goal \nshould be low coupling between the classes that are in different Modules. Since \nModules as used in DDD are not bland or generic storage compartments, it is \nalso important to properly name the Modules. Their names are an important \nfacet of the Ubiquitous Language.\nwww.EBooksWorld.ir\n", "page": 376, "type": "text", "section": "Page 376"}
{"text": "Chapter 9 MODULES\n334\nChoose Modules that tell the story of the system and contain a cohesive set of \nconcepts. This often yields low coupling among Modules, but if it doesn\u2019t, look \nfor a way to change the model to disentangle the concepts. . . . Give Modules \nnames that become part of the Ubiquitous Language. Modules and their names \nshould reflect insight into the domain. [Evans, pp. 110, 111]\nThere are a few simple rules to keep in mind when designing Modules, as \nnoted in Table 9.1.\nTable 9.1  Simple Rules for Module Design\nModule Do\u2019s and Don\u2019ts\nWhy?\nDo design Modules to fit \nmodeling concepts.\nTypically you\u2019ll have one Module for one or a few Aggregates \n(10) that are cohesive, if only by reference.\nDo name Modules per the \nUbiquitous Language.\nThis is a basic goal of DDD, but it will also tend to come natu-\nrally if you think about the concepts being modeled.\nDon\u2019t create Modules \nmechanically according to \na general component type \nor pattern being used in the \nmodel.\nOur model won\u2019t benefit at all if we segregate all Aggregates \ninto one Module, all Services (7) into another Module, all Fac-\ntories (11) into yet another, for example. That misses the point \nof DDD Modules and will also tend to limit your creativity \ntoward rich modeling. Instead of thinking openly about the \ndomain, you\u2019d tend to think only about the kinds of compo-\nnents or patterns you use to solve current problems.\nDo design loosely coupled \nModules.\nEnsuring that Modules are largely independent of others has \nthe same benefits as loosely coupled classes. This will make it \neasier to maintain and refactor your modeling concepts and to \nuse larger-grained modularization facilities, such as OSGi and \nJigsaw.\nDo strive for acyclic depen-\ndencies on peer Modules \nwhere coupling is necessary. \n(Peer Modules are those at the \nsame \u201clevel,\u201d or those with \nsimilar weight or bearing on \nthe design.)\nIt\u2019s rarely possible or even practical for Modules to be com-\npletely independent of each other. After all, a domain model \nimplies some coupling. Yet, you will reduce the coupling of \ncomponents if you think in terms of making the dependency \nbetween two peer Modules only unidirectional (for exam-\nple, product depends on team, but team does not depend on \nproduct).\nDo relax the rules a bit \nbetween child and parent \nModules. (A parent Mod-\nule is one at a higher level \nand a child is just a level \nlower\u2014parent.child, for \nexample.)\nIt\u2019s really difficult to prevent dependency between parent and \nchild Modules. If at all possible, still strive for acyclic depen-\ndencies between parents and children, but allow for circular \ndependencies if there\u2019s no way to avoid it (for example, a parent \ncreates a child, and the child must reference its parent, if only \nby identity).\nwww.EBooksWorld.ir\n", "page": 377, "type": "text", "section": "Page 377"}
{"text": " \nDESIGNING WITH MODULES\n335\nView Modules as first-class citizens of the model, and strive to create \nones with as much meaning and naming consideration as is given to Entities \n(5), Value Objects (6), Services, and Events (8). This means being aggressive \nenough to rename existing Modules with the same boldness as when creating \nnew ones. Always assertively place fresh and freshened domain concepts into \nthe Modules that contemporary insight calls for.\nNone of us would feel good about opening a drawer in our home kitchen \nand finding a disorganized assortment of forks, knives, spoons, wrenches, \nscrewdrivers, sockets, and hammers. We would probably at least refuse to eat \nwith the silverware, even if we could gather a full place setting. We might avoid \ndigging through the disorganized drawer to look for a particular screwdriver \nout of fear of being sliced by an undetected butcher\u2019s knife.\nContrast this with a kitchen drawer that has silverware neatly organized \ninto sets of forks, knives, and spoons, and a toolbox in your garage where each \ntype of tool has its own well-arranged drawer. We would have no problem \nfinding what we need to use for a specific purpose, or hesitate to put it to its \nintended use. Everything is well organized, uncluttered. With all this modu-\nlar organization in place, no one would expect to find cups and saucers in \nthe drawer with silverware, even though both belong in the kitchen. The neat \nstacks of tableware would likely lead us to believe that cups and saucers have \na proper place of their own. A few quick glances into nearby obvious-looking \ncabinets, and there they would be. We would likewise expect to find sharp \ncutlery in a location that promised to protect their edges and protect those \nintending to use them.\nOn the other hand, we would probably not organize our kitchen\u2019s contents \nusing a mechanical approach, such as placing all sturdy things in one drawer \nand all things that might break in a high cabinet. We wouldn\u2019t want to have \nto remember that our flower vases are kept with our fine teacups just because \nboth are somewhat fragile. Neither would we want to remember that we keep \nour stainless steel meat tenderizer with the fine cutlery just because both kinds \nof devices are in little danger of damage by the other sturdy ones.\nTable 9.1  Simple Rules for Module Design (Continued \n)\nModule Do\u2019s and Don\u2019ts\nWhy?\nDon\u2019t make Modules a static \nconcept of the model, but \nallow them to be molded \nalong with the objects that \nthey organize.\nIf the model\u2019s concepts are malleable and take on different \nshapes, behaviors, and names over time, it\u2019s very likely that the \nModules that organize those same concepts should be created, \nrenamed, and deleted in kind. It\u2019s not a necessity, but if you can \nsee mismatched names, refactor. Yes, it can be a pain, but the \npain is probably less than that experienced with poorly named \nModules.\nwww.EBooksWorld.ir\n", "page": 378, "type": "text", "section": "Page 378"}
{"text": "Chapter 9 MODULES\n336\nIf we were modeling a kitchen, it would be perfectly natural to see a Mod-\nule named placesettings, and in it we would see objects such as Fork,\nSpoon, and Knife. Possibly we might even decide to place Serviette there \nas well, proving that it\u2019s not only being made of metal that qualifies an object \nto be a part of the placesettings Module. On the other hand, it would \nbe less helpful to modeling place settings if we had separate Modules named \npronged, scooping, and blunt.\nNote that more recent advances in the modularization of software have led \nto a different level of software modularity. This approach has to do with the \npackaging of loosely coupled yet logically cohesive segments of software into a \ndeployment unit by version. In a Java ecosystem we still think in terms of JAR \nfiles, but with those now assembled by version using, for example, OSGi bun-\ndles or Java 8 Jigsaw modules. Thus, various high-level modules, their versions, \nand their dependencies could be managed as bundles/modules. These kinds of \nmodules/bundles are a bit different from DDD Modules, but they can comple-\nment each other. Certainly it makes sense to bundle loosely coupled parts of a \ndomain model into the larger-grained modules according to their DDD Mod-\nules. After all, it\u2019s the loosely coupled design of your DDD Modules that will \ncontribute to your ability to bundle with OSGi or modularize to Jigsaw.\nCowboy Logic\nLB:  \n\u201cYou gotta wonder how this gas station keeps their \nrestrooms so neat and clean.\u201d\nAJ:  \n\u201cNow, LB, a tornado could hit that restroom and do \n$10,000 in improvements.\u201d\nWe\u2019ll focus on how DDD Modules are used. Thinking of the purposes of \nspecific Entities, Value Objects, Services, and Events of your model benefits \nModule design. Let\u2019s look at examples of thoughtful Module design.\nBasic Module Naming Conventions\nIn both Java and C#, the names of Modules reflect a hierarchical form.1\nEach level in the hierarchy is separated by a dot/period. The name hierarchy \n 1. There will be some differences between Java packages and C# namespaces. If you\u2019re \ndeveloping with C#, for example, you can still use this as guidance, but you\u2019ll want \nto adapt it to make sense for your specific programming language and platform.\nwww.EBooksWorld.ir\n", "page": 379, "type": "text", "section": "Page 379"}
{"text": " \nMODULE NAMING CONVENTIONS FOR THE MODEL\n337\ngenerally begins with the name of the organization that produced it, composed \nwith its Internet domain name. When the Internet domain name is used, it typ-\nically starts with the top-level domain, followed by the organizational domain \nname:\n    com.saasovation // Java\n    SaaSOvation // C#\nUsing unique top-level names prevents namespace collision with third-party \nModules that are employed on your projects, or those caused when yours are \nconsumed by others. If you have questions about the most basic conventions, \nyou can consult the standard.2\nVery likely your organization has already settled on a top-level Module \nnaming convention. It\u2019s best to be consistent.\nModule Naming Conventions for the Model\nThe next segment of the Module name identifies the Bounded Context. Basing \nthis segment on the name of the Bounded Context is a good choice.\nHere is how the SaaSOvation teams named these Modules:\n    com.saasovation.identityaccess\n    com.saasovation.collaboration\n    com.saasovation.agilepm\nThey considered using the following, but it added little if any value compared to the \nprevious Module names. Even though they exactly name the Context, they probably \nproduce unnecessary noise:\n    com.saasovation.identityandaccess\n    com.saasovation.agileprojectmanagement\nInterestingly, too, they did not use their commercial product names (brands) in \nthe Module names. Brand names can change, and sometimes product names have \n 2. http://java.sun.com/docs/books/jls/second_edition/html/packages.doc.html#26639.\nwww.EBooksWorld.ir\n", "page": 380, "type": "text", "section": "Page 380"}
{"text": "Chapter 9 MODULES\n338\nlittle or no direct correlation to the underlying Bounded Contexts. It is more important \nto identify the Context by name since that\u2019s what the team discusses. The goal is \nto reflect the Ubiquitous Language. If the team were to use the following names, it \nwouldn\u2019t help them realize that goal:\n    com.saasovation.idovation\n    com.saasovation.collabovation\n    com.saasovation.projectovation\nThe first Module name, com.saasovation.idovation, has almost no correla-\ntion to its Bounded Context. The second one is fairly close. The third name is almost \nas deficient as the first, but slightly better. At least it has the word project in it. None-\ntheless, the team decided that these names didn\u2019t have an intuitively obvious mental \nmapping to the Bounded Contexts represented. Even more, if marketing decided that \nany of the product names had to change\u2014possibly for trademark infringement or \ncultural incompatibilities\u2014these Module names would be completely obsolete. So the \nteam decided to stick with the first set.\nNext, they tacked on an important qualifier. It identifies that the specific Module is \nin the domain:\n    com.saasovation.identityaccess.domain\n    com.saasovation.collaboration.domain\n    com.saasovation.agilepm.domain\nThis convention is compatible with a traditional Layers Architecture (4) and \na Hexagonal Architecture (4). These days a system that uses Layers will gen-\nerally manage them using a Hexagonal, injection style. With Hexagonal you \nhave an \u201cinside\u201d part of the application, which includes the domain part. This \nwill be similar with other architectural styles.\nThe domain compartment may be devoid of interfaces/classes and serve \nonly as a container for lower-level Modules. Here\u2019s the next level down:\n    com.saasovation.identityaccess.domain.model\n    com.saasovation.collaboration.domain.model\n    com.saasovation.agilepm.domain.model\nThis is where model classes start to be defined. This package level can con-\ntain reusable interfaces and abstract classes.\nwww.EBooksWorld.ir\n", "page": 381, "type": "text", "section": "Page 381"}
{"text": " \nMODULE NAMING CONVENTIONS FOR THE MODEL\n339\nSaaSOvation liked to place in this Module common interfaces, such as those that were \nused for Event publishing, and abstract base classes for Entities and Value Objects:\n    ConcurrencySafeEntity\n    DomainEvent\n    DomainEventPublisher\n    DomainEventSubscriber\n    DomainRegistry\n    Entity\n    IdentifiedDomainObject\n    IdentifiedValueObject\nIf you favor the style of placing Domain Services outside the domain.\nmodel Module, you can create a peer to it:\n    com.saasovation.identityaccess.domain.service\n    com.saasovation.collaboration.domain.service\n    com.saasovation.agilepm.domain.service\nIt is not a requirement to place Domain Services here. It is available if you \nconsider them to be a kind of medium-grained service mini-layer above the \nmodel, or a ring surrounding it [Evans, p. 108, \u201cGranularity\u201d]. However, be \naware that this approach can quickly lead to Anemic Domain Model, which is \ndiscussed in Services (7).\nIn the case where you do not divide model and services into two packages, \nit is possible to drop the model Module and just place all model Modules \ndirectly under domain:\n    com.saasovation.identityaccess.domain.conceptname\nIt does eliminate one level that may seem redundant. Yet, what happens if \nlater you do decide to place a few Domain Services into a domain.service\nsub-Module? At that point you\u2019d probably be pretty disappointed that you \nfailed to create a domain.model sub-Module.\nBut there\u2019s an even more important naming influence to consider. Remember \nthat we do not develop a domain. The Domain (2) is some realm of know-how \nof the business we are working in. What we design and implement is a model \nof a domain. So when naming the ultimate Module of the model, domain.\nmodel seems most appropriate. Still, that\u2019s the choice of your team.\nwww.EBooksWorld.ir\n", "page": 382, "type": "text", "section": "Page 382"}
{"text": "Chapter 9 MODULES\n340\nModules of the Agile Project Management Context\nSaaSOvation\u2019s current Core Domain (2) is the Agile Project Management Con-\ntext, so it makes sense to see how its Modules are designed.\nThe ProjectOvation team chose three top-level Modules: tenant, team,\nand product. Here\u2019s the first:\n    com.saasovation.agilepm.domain.model.tenant\n        <<value object>> TenantId\nIts contents are a simple Value Object, TenantId, that holds the unique iden-\ntity of a specific tenant, which originates in the Identity and Access Context.\nIn the case of this Module, just about all others in the model will depend on \nit. It\u2019s essential for segregating one tenant\u2019s objects from another\u2019s. Yet, the \ndependency is acyclic. The tenant Module does not depend on the others.\nThe team Module holds Aggregates and a Domain Service that is used to \nmanage product teams:\n    com.saasovation.agilepm.domain.model.team\n         <<service>> MemberService\n         <<aggregate root>> ProductOwner\n         <<aggregate root>> Team\n         <<aggregate root>> TeamMember\nThere are three Aggregates and one Domain Service interface. Class Team\nholds one ProductOwner instance and any number of TeamMember\ninstances in a collection. The ProductOwner and TeamMember instances \nare created by the MemberService. All three of the Aggregate Root Entities \nreference the TenantId of the tenant Module:\npackage com.saasovation.agilepm.domain.model.team;\nimport com.saasovation.agilepm.domain.model.tenant.TenantId;\npublic class Team extends ConcurrencySafeEntity {\n    private TenantId tenantId;\n    ...\n}\nThe MemberService is a front end for an Anticorruption Layer (3) that \nsynchronizes product team members with identities and roles of the Identity \nand Access Context. The synchronization happens in the background, out of \nband with regular user requests. This Service is proactive, creating members as \nwww.EBooksWorld.ir\n", "page": 383, "type": "text", "section": "Page 383"}
{"text": " \nMODULES OF THE AGILE PROJECT MANAGEMENT CONTEXT\n341\nthey are registered in the remote Context. The synchronization is eventually \nconsistent with the remote system but lags only a short period of time from \nactual changes that occur remotely. It also updates member details, such as \nnames and e-mail addresses, as needed.\nThe Agile Project Management Context has a parent Module named \nproduct and three children:\n    com.saasovation.agilepm.domain.model.product\n        <<aggregate root>> Product\n        ...\n        com.saasovation.agilepm.domain.model.product.backlogitem\n            <<aggregate root>> BacklogItem\n            ...\n        com.saasovation.agilepm.domain.model.product.release\n            <<aggregate root>> Release\n            ...\n        com.saasovation.agilepm.domain.model.product.sprint\n            <<aggregate root>> Sprint\n            ...\nThis is where the modeling of Scrum\u2019s core lives. Here you will find \nProduct, BacklogItem, Release, and Sprint Aggregates. You\u2019ll see in \nAggregates (10) why the concepts are modeled as separate Aggregates.\nThe team liked how the Modules read naturally per the \nUbiquitous Language: \u201cproduct,\u201d \u201cproduct backlog item,\u201d \n\u201cproduct release,\u201d and \u201cproduct sprint.\u201d\nWith so few closely related Aggregates\u2014only four\u2014\nwhy didn\u2019t the team place all four in the product Mod-\nule? Not shown here are all the other Aggregate parts, \nsuch as the ProductBacklogItem Entity contained \nby Product, the Task Entity contained by Backlog-\nItem, the ScheduledBacklogItem contained by \nRelease, and the CommittedBacklogItem contained \nby Sprint. There are other Entities and Value Objects held by each Aggregate type. \nToo, there are a number of Domain Events published by some Aggregates. All in all, \nplacing nearly 60 classes and interfaces in a single Module would make it quite busy, \ngiving a definite impression of disorganization. The team opted for organization over \ncross-Module coupling concerns.\nLike ProductOwner, Team, and TeamMember, all of the Product, Backlog-\nItem, Release, and Sprint Aggregate types reference TenantId. And there are \nadditional dependencies. Consider Product:\nwww.EBooksWorld.ir\n", "page": 384, "type": "text", "section": "Page 384"}
{"text": "Chapter 9 MODULES\n342\npackage com.saasovation.agilepm.domain.model.product;\nimport com.saasovation.agilepm.domain.model.tenant.TenantId;\npublic class Product extends ConcurrencySafeEntity {\n    private ProductId productId;\n    private TeamId teamId;\n    private TenantId tenantId;\n    ...\n}\nAlso, look at BacklogItem:\npackage com.saasovation.agilepm.domain.model.product.backlogitem;\nimport com.saasovation.agilepm.domain.model.tenant.TenantId;\npublic class BacklogItem extends ConcurrencySafeEntity {\n    private BacklogItemId backlogItemId;\n    private ProductId productId;\n    private TeamId teamId;\n    private TenantId tenantId;\n    ...\n}\nThe references to TenantId and TeamId are acyclic dependencies; they go in \na single direction. Yet, while the BacklogItem reference to ProductId seems to \nform an acyclic dependency from the backlogItem Module to product, it is actu-\nally bidirectional. Each Product serves as a Factory for creating BacklogItem (and \nRelease, and Sprint) instances. Thus, the dependencies go in both directions. \nStill, the three sub-Modules are children of product, and we can relax the rules \nof dependencies a bit. Here the trade-off is organizational strengths over coupling. \nAgain, BacklogItem, Release, and Sprint are all natural and expected child con-\ncepts of Product, so there is little sense in trying to break up these concepts beyond \nAggregate boundaries.\nHowever, couldn\u2019t the team have achieved loose coupling among these elements \nby the use of a generic identity type, where BacklogItem, Release, and Sprint\nwould all refer to their Product in a nonbinding manner?\npublic class BacklogItem extends ConcurrencySafeEntity {\n    private Identity backlogItemId;\n    private Identity productId;\n    private Identity teamId;\n    private Identity tenantId;\n    ...\n}\nwww.EBooksWorld.ir\n", "page": 385, "type": "text", "section": "Page 385"}
{"text": " \nMODULES IN OTHER LAYERS\n343\nTrue, the team could have achieved looser coupling. However, it would also have \nopened up the potential for bugs in code where each Identity type could not be \ndistinguished from the others.\nThe Agile Project Management Context will continue to evolve. SaaSOvation \nplans to support other agile approaches and tools. Doing so will impact the current \nModules, at least in driving the creation of new ones, but probably also influencing \nchanges to existing ones. The team, having an agile mentality, was committed to \nrefactoring Modules with due diligence.\nNext, let\u2019s consider how Modules are used in other locations through the \nsystem\u2019s source code.\nModules in Other Layers\nRegardless of the Architecture (4) you choose, you will always have to cre-\nate and name the Modules of the non-model components of your architecture. \nHere we discuss some options for a conventional Layered Architecture (4), but \nones that can be applied with other architectural styles.\nIn a typical Layered Architecture used for an application that sports a domain \nmodel, you\u2019d stack the layers as follows: User Interface, Application, Domain, \nInfrastructure. Depending on the kinds of components in each layer, as deter-\nmined by your application\u2019s needs, the Modules within each layer will vary.\nTo start, consider the User Interface Layer (14) and the effect of supporting \nRESTful resources. It is possible that your resources will be used to service a \nGUI and system clients, producing representational state in XML, JSON, and \nHTML. However, in the case of supporting a GUI, RESTful resources will \nnot/should not create representations that include presentation layout. They \nwill instead produce only bland representations in a variety of markup (XML, \nHTML) and serialization formats (XML, JSON, Protocol Buffers). All of the \ngraphical layouts that any of the representational state might be subjected to \non the client will come from a different channel. Thus, in the User Interface \nLayer that supports REST you may choose to have at least two Modules that \ncould be named like this:\n    com.saasovation.agilepm.resources\n    com.saasovation.agilepm.resources.view\nRESTful resources are maintained in the resources package. Pure pres-\nentation concerns are provided by components in the view sub-package (or \nwww.EBooksWorld.ir\n", "page": 386, "type": "text", "section": "Page 386"}
{"text": "Chapter 9 MODULES\n344\npresentation, if you prefer). Depending on the number of REST-based \nresources your system requires, you may have a number of sub-Modules under \neach primary Module. Keeping in mind that one resource provider class can \nsupport several URIs, you may have few enough resource provider classes to \nkeep them all in the primary Module. Whether or not to further modular-\nize them is an easy decision to make once you determine your actual resource \nrequirements.\nThe Application Layer may have other Modules, which could consist of one \nper service type:\n    com.saasovation.agilepm.application.team\n    com.saasovation.agilepm.application.product\n    ...\n    com.saasovation.agilepm.application.tenant\nSimilar to the design principles of RESTful service resources, the services in the \nApplication Layer are divided into sub-Modules only if it helps. In the Identity \nand Access Context, for example, there are only a few Application Services, \nand the team chose to leave them in the main Module:\n    com.saasovation.identityaccess.application\nYou could decide in favor of the more modularized design. That would also be \nfine. When you have more than a few services, perhaps half a dozen or so, it \nwould probably help to modularize them more carefully.\nModule before Bounded Context\nWe have to give careful consideration to the perceived need to divide cohesive \ndomain model objects into separate models, or to keep them together. Some-\ntimes the linguistics of the true, actual domain will jump out at you, and some-\ntimes the terminology will be fuzzy. In cases where terminology is fuzzy and it \nis not clear if contextual boundaries should be created, first consider the pos-\nsibility of keeping them together. This approach will use the thinner boundary \nof Module to separate, rather than the thicker one of Bounded Context.\nThis does not mean that we rarely use multiple Bounded Contexts. Boundar-\nies between models are clearly justified, as the linguistics demand. You should \ntake away that Bounded Contexts are not meant to be used as a substitute for \nModules. Use Modules to modularize cohesive domain objects, and to separate \nthose that are not cohesive or less cohesive.\nwww.EBooksWorld.ir\n", "page": 387, "type": "text", "section": "Page 387"}
{"text": " \nWRAP-UP\n345\nWrap-Up\nWe\u2019ve just considered domain model modularization, why it is important, and \nhow it is done.\n\u2022 You noted the difference between traditional Modules and the newer \ndeployment modularity approach.\n\u2022 You learned about the importance of naming Modules per the Ubiquitous \nLanguage.\n\u2022 You saw how designing Modules incorrectly, even mechanically, actually \nstifles modeling creativity.\n\u2022 You considered how the Modules of the Agile PM Context were designed, \nand why certain choices were made.\n\u2022 You received some helpful guidance on Modules in areas of the system \noutside the model.\n\u2022 Finally, you got a few reminders about considering the use of Modules \nrather than creating new Bounded Contexts, unless the linguistics dictate \nthe coarser-grained division.\nNext, we will take a seriously deep dive into one of the least understood \nmodeling tools of DDD, Aggregates.\nwww.EBooksWorld.ir\n", "page": 388, "type": "text", "section": "Page 388"}
{"text": "This page intentionally left blank \nwww.EBooksWorld.ir\n", "page": 389, "type": "text", "section": "Page 389"}
{"text": "347\nChapter 10\nAggregates\nThe universe is built up into an aggregate of permanent objects \nconnected by causal relations that are independent of the subject and \nare placed in objective space and time.\n\u2014Jean Piaget\nClustering Entities (5) and Value Objects (6) into an Aggregate with a carefully \ncrafted consistency boundary may at first seem like quick work, but among all \nDDD tactical guidance, this pattern is one of the least well understood.\nRoad Map to This Chapter\n\u2022 Along with SaaSOvation, experience the negative consequences of improp-\nerly modeling Aggregates.\n\u2022 Learn to design by the Aggregate Rules of Thumb as a set of best-practice \nguidelines.\n\u2022 Grasp how to model true invariants in consistency boundaries according to \nreal business rules.\n\u2022 Consider the advantages of designing small Aggregates.\n\u2022 See why you should design Aggregates to reference other Aggregates by \nidentity.\n\u2022 Discover the importance of using eventual consistency outside the Aggregate \nboundary.\n\u2022 Learn Aggregate implementation techniques, including Tell, Don\u2019t Ask and \nLaw of Demeter.\nTo start off, it might help to consider some common questions. Is an Aggre-\ngate just a way to cluster a graph of closely related objects under a common \nparent? If so, is there some practical limit to the number of objects that should \nbe allowed to reside in the graph? Since one Aggregate instance can reference \nother Aggregate instances, can the associations be navigated deeply, modify-\ning various objects along the way? And what is this concept of invariants and \na consistency boundary all about? It is the answer to this last question that \ngreatly influences the answers to the others.\nwww.EBooksWorld.ir\n", "page": 390, "type": "text", "section": "Page 390"}
{"text": "Chapter 10 AGGREGATES\n348\nThere are various ways to model Aggregates incorrectly. We could fall into \nthe trap of designing for compositional convenience and make them too large. \nAt the other end of the spectrum we could strip all Aggregates bare and as a \nresult fail to protect true invariants. As we\u2019ll see, it\u2019s imperative that we avoid \nboth extremes and instead pay attention to the business rules.\nUsing Aggregates in the Scrum Core Domain\nWe\u2019ll take a close look at how Aggregates are used by SaaSOvation, and spe-\ncifically within the Agile Project Management Context the application named \nProjectOvation. It follows the traditional Scrum project management model, \ncomplete with product, product owner, team, backlog items, planned releases, \nand sprints. If you think of Scrum at its richest, that\u2019s where ProjectOvation \nis headed; this is a familiar domain to most of us. The Scrum terminology \nforms the starting point of the Ubiquitous Language (1). Since it is a subscrip-\ntion-based application hosted using the software as a service (SaaS) model, \neach subscribing organization is registered as a tenant, another term of our \nUbiquitous Language.\nThe company has assembled a group of \ntalented Scrum experts and developers. \nHowever, since their experience with \nDDD is somewhat limited, the team will \nmake some mistakes with DDD as they \nclimb a difficult learning curve. They will \ngrow by learning from their experiences \nwith Aggregates, and so can we. Their struggles may help us recognize and change \nsimilar unfavorable situations we\u2019ve created in our own software.\nThe concepts of this domain, along with its performance and scalability require-\nments, are more complex than any that the team has previously faced in the initial \nCore Domain (2), the Collaboration Context. To address these issues, one of the \nDDD tactical tools that they will employ is Aggregates.\nHow should the team choose the best object clusters? The Aggregate pattern dis-\ncusses composition and alludes to information hiding, which they understand how to \nachieve. It also discusses consistency boundaries and transactions, but they haven\u2019t \nbeen overly concerned with that. Their chosen persistence mechanism will help man-\nage atomic commits of their data. However, that was a crucial misunderstanding of \nthe pattern\u2019s guidance that caused them to regress. Here\u2019s what happened. The team \nconsidered the following statements in the Ubiquitous Language:\n\u2022 Products have backlog items, releases, and sprints.\n\u2022 New product backlog items are planned.\nwww.EBooksWorld.ir\n", "page": 391, "type": "text", "section": "Page 391"}
{"text": " \nUSING AGGREGATES IN THE SCRUM CORE DOMAIN\n349\n\u2022 New product releases are scheduled.\n\u2022 New product sprints are scheduled.\n\u2022 A planned backlog item may be scheduled for release.\n\u2022 A scheduled backlog item may be committed to a sprint.\nFrom these they envisioned a model and made their first attempt at a design. \nLet\u2019s see how it went.\nFirst Attempt: Large-Cluster Aggregate\nThe team put a lot of weight on the words Products have in the first statement, \nwhich influenced their initial attempt to design Aggregates for this domain.\nIt sounded to some like composition, that objects needed to be interconnected like \nan object graph. Maintaining these object life cycles together was considered very \nimportant. As a result the developers added the following consistency rules to the \nspecification:\n\u2022 If a backlog item is committed to a sprint, we must not allow it to be removed \nfrom the system.\n\u2022 If a sprint has committed backlog items, we must not allow it to be removed from \nthe system.\n\u2022 If a release has scheduled backlog items, we must not allow it to be removed \nfrom the system.\n\u2022 If a backlog item is scheduled for release, we must not allow it to be removed \nfrom the system.\nAs a result, Product was first modeled as a very large Aggregate. The Root \nobject, Product, held all BacklogItem, all Release, and all Sprint instances \nassociated with it. The interface design protected all parts from inadvertent client \nremoval.\nThis design is shown in the following code, and as a UML diagram in Fig-\nure 10.1:\npublic class Product extends ConcurrencySafeEntity  {\n    private Set<BacklogItem> backlogItems;\n    private String description;\n    private String name;\n    private ProductId productId;\n    private Set<Release> releases;\nwww.EBooksWorld.ir\n", "page": 392, "type": "text", "section": "Page 392"}
{"text": "Chapter 10 AGGREGATES\n350\n    private Set<Sprint> sprints;\n    private TenantId tenantId;\n    ...\n}\nThe big Aggregate looked attractive, but it wasn\u2019t truly practical. Once the \napplication was running in its intended multi-user environment, it began to \nregularly experience transactional failures. Let\u2019s look more closely at a few cli-\nent usage patterns and how they interact with our technical solution model. \nOur Aggregate instances employ optimistic concurrency to protect persistent \nobjects from simultaneous overlapping modifications by different clients, thus \navoiding the use of database locks. As discussed in Entities (5), objects carry \na version number that is incremented when changes are made and checked \nbefore they are saved to the database. If the version on the persisted object is \ngreater than the version on the client\u2019s copy, the client\u2019s is considered stale and \nupdates are rejected.\nConsider a common simultaneous, multiclient usage scenario:\n\u2022 Two users, Bill and Joe, view the same Product marked as version 1 and \nbegin to work on it.\n\u2022 Bill plans a new BacklogItem and commits. The Product version is \nincremented to 2.\n\u2022 Joe schedules a new Release and tries to save, but his commit fails \nbecause it was based on Product version 1.\nPersistence mechanisms are used in this general way to deal with concur-\nrency.1 If you argue that the default concurrency configurations can be \nchanged, reserve your verdict for a while longer. This approach is actually \nimportant to protecting Aggregate invariants from concurrent changes.\n 1. For example, Hibernate provides optimistic concurrency in this way. The same \ncould be true of a key-value store because the entire Aggregate is often serialized \nas one value, unless designed to save composed parts separately.\n<<aggregate root>>\nProduct\n<<entity>>\nBacklogItem\n<<entity>>\nRelease\n1\n0..*\n0..*\n0..*\n<<entity>>\nSprint\nFigure 10.1\nProduct modeled as a very large Aggregate\nwww.EBooksWorld.ir\n", "page": 393, "type": "text", "section": "Page 393"}
{"text": " \nUSING AGGREGATES IN THE SCRUM CORE DOMAIN\n351\nThese consistency problems came up with just two users. Add more users, \nand you have a really big problem. With Scrum, multiple users often make \nthese kinds of overlapping modifications during the sprint planning meeting \nand in sprint execution. Failing all but one of their requests on an ongoing \nbasis is completely unacceptable.\nNothing about planning a new backlog item should logically interfere with \nscheduling a new release! Why did Joe\u2019s commit fail? At the heart of the issue, \nthe large-cluster Aggregate was designed with false invariants in mind, not \nreal business rules. These false invariants are artificial constraints imposed by \ndevelopers. There are other ways for the team to prevent inappropriate removal \nwithout being arbitrarily restrictive. Besides causing transactional issues, the \ndesign also has performance and scalability drawbacks.\nSecond Attempt: Multiple Aggregates\nNow consider an alternative model as shown in Figure 10.2, in which there are \nfour distinct Aggregates. Each of the dependencies is associated by inference \nusing a common ProductId, which is the identity of Product considered the \nparent of the other three.\nBreaking the single large Aggregate into four will change some method con-\ntracts on Product. With the large-cluster Aggregate design the method signa-\ntures looked like this:\npublic class Product ... {\n    ...\n    public void planBacklogItem(\n        String aSummary, String aCategory,\n        BacklogItemType aType, StoryPoints aStoryPoints) {\n            ...\n    }\n    ...\n    public void scheduleRelease(\n        String aName, String aDescription,\n<<aggregate root>>\nProduct\n<<value object>>\nProductId\n<<aggregate root>>\nBacklogItem\n<<aggregate root>>\nRelease\n<<aggregate root>>\nSprint\nFigure 10.2\nProduct and related concepts are modeled as separate Aggregate types.\nwww.EBooksWorld.ir\n", "page": 394, "type": "text", "section": "Page 394"}
{"text": "Chapter 10 AGGREGATES\n352\n        Date aBegins, Date anEnds) {\n        ...\n    }\n    public void scheduleSprint(\n        String aName, String aGoals,\n        Date aBegins, Date anEnds) {\n        ...\n    }\n    ...\n}\nAll of these methods are CQS commands [Fowler, CQS]; that is, they mod-\nify the state of the Product by adding the new element to a collection, so they \nhave a void return type. But with the multiple-Aggregate design, we have\npublic class Product ... {\n    ...\n    public BacklogItem planBacklogItem(\n        String aSummary, String aCategory,\n        BacklogItemType aType, StoryPoints aStoryPoints) {\n        ...\n    }\n    public Release scheduleRelease(\n        String aName, String aDescription,\n        Date aBegins, Date anEnds) {\n        ...\n    }\n    public Sprint scheduleSprint(\n        String aName, String aGoals,\n        Date aBegins, Date anEnds) {\n        ...\n    }\n    ...\n}\nThese redesigned methods have a CQS query contract and act as Factories \n(11); that is, each creates a new Aggregate instance and returns a reference to \nit. Now when a client wants to plan a backlog item, the transactional Applica-\ntion Service (14) must do the following:\npublic class ProductBacklogItemService ... {\n    ...\n    @Transactional\n    public void planProductBacklogItem(\nwww.EBooksWorld.ir\n", "page": 395, "type": "text", "section": "Page 395"}
{"text": " \nRULE: MODEL TRUE INVARIANTS IN CONSISTENCY BOUNDARIES\n353\n        String aTenantId, String aProductId,\n        String aSummary, String aCategory,\n        String aBacklogItemType, String aStoryPoints) {\n        Product product =\n            productRepository.productOfId(\n                    new TenantId(aTenantId),\n                    new ProductId(aProductId));\n        BacklogItem plannedBacklogItem =\n            product.planBacklogItem(\n                    aSummary,\n                    aCategory,\n                    BacklogItemType.valueOf(aBacklogItemType),\n                    StoryPoints.valueOf(aStoryPoints));\n        backlogItemRepository.add(plannedBacklogItem);\n    }\n    ...\n}\nSo we\u2019ve solved the transaction failure issue by modeling it away. Any num-\nber of BacklogItem, Release, and Sprint instances can now be safely cre-\nated by simultaneous user requests. That\u2019s pretty simple.\nHowever, even with clear transactional advantages, the four smaller Aggre-\ngates are less convenient from the perspective of client consumption. Perhaps \ninstead we could tune the large Aggregate to eliminate the concurrency issues. \nBy setting our Hibernate mapping optimistic-lock option to false, we \nmake the transaction failure domino effect go away. There is no invariant on \nthe total number of created BacklogItem, Release, or Sprint instances, so \nwhy not just allow the collections to grow unbounded and ignore these specific \nmodifications on Product? What additional cost would there be for keeping \nthe large-cluster Aggregate? The problem is that it could actually grow out of \ncontrol. Before thoroughly examining why, let\u2019s consider the most important \nmodeling tip the SaaSOvation team needed.\nRule: Model True Invariants in Consistency Boundaries\nWhen trying to discover the Aggregates in a Bounded Context (2), we must \nunderstand the model\u2019s true invariants. Only with that knowledge can we \ndetermine which objects should be clustered into a given Aggregate.\nAn invariant is a business rule that must always be consistent. There are \ndifferent kinds of consistency. One is transactional consistency, which is \nwww.EBooksWorld.ir\n", "page": 396, "type": "text", "section": "Page 396"}
{"text": "Chapter 10 AGGREGATES\n354\nconsidered immediate and atomic. There is also eventual consistency. When \ndiscussing invariants, we are referring to transactional consistency. We might \nhave the invariant\n    c = a + b\nTherefore, when a is 2 and b is 3, c must be 5. According to that rule and con-\nditions, if c is anything but 5, a system invariant is violated. To ensure that c is \nconsistent, we design a boundary around these specific attributes of the model:\n    AggregateType1 {\n        int a;\n        int b;\n        int c;\n        operations ...\n    }\nThe consistency boundary logically asserts that everything inside adheres to \na specific set of business invariant rules no matter what operations are per-\nformed. The consistency of everything outside this boundary is irrelevant to \nthe Aggregate. Thus, Aggregate is synonymous with transactional consistency \nboundary. (In this limited example, AggregateType1 has three attributes of \ntype int, but any given Aggregate could hold attributes of various types.)\nWhen employing a typical persistence mechanism, we use a single trans-\naction2 to manage consistency. When the transaction commits, everything \ninside one boundary must be consistent. A properly designed Aggregate is one \nthat can be modified in any way required by the business with its invariants \ncompletely consistent within a single transaction. And a properly designed \nBounded Context modifies only one Aggregate instance per transaction in all \ncases. What is more, we cannot correctly reason on Aggregate design without \napplying transactional analysis.\nLimiting modification to one Aggregate instance per transaction may sound \noverly strict. However, it is a rule of thumb and should be the goal in most \ncases. It addresses the very reason to use Aggregates.\n 2. The transaction may be handled by a Unit of Work [Fowler, P of EAA].\nwww.EBooksWorld.ir\n", "page": 397, "type": "text", "section": "Page 397"}
{"text": " \nRULE: DESIGN SMALL AGGREGATES\n355\nWhiteboard Time\n\u2022 List on your whiteboard all large-cluster Aggregates in your system.\n\u2022 Make a note next to each of those Aggregates why it is a large cluster and \nany potential problems caused by its size.\n\u2022 Next to that list, name any Aggregates that are modified in the same \ntransaction with others.\n\u2022 Make a note next to each of those Aggregates whether true or false invari-\nants caused the formation of poorly designed Aggregate boundaries.\nThe fact that Aggregates must be designed with a consistency focus implies \nthat the user interface should concentrate each request to execute a single com-\nmand on just one Aggregate instance. If user requests try to accomplish too \nmuch, the application will be forced to modify multiple instances at once.\nTherefore, Aggregates are chiefly about consistency boundaries and not \ndriven by a desire to design object graphs. Some real-world invariants will be \nmore complex than this. Even so, typically invariants will be less demanding \non our modeling efforts, making it possible to design small Aggregates.\nRule: Design Small Aggregates\nWe can now thoroughly address this question: What additional cost would \nthere be for keeping the large-cluster Aggregate? Even if we guarantee that \nevery transaction would succeed, a large cluster still limits performance and \nscalability. As SaaSOvation develops its market, it\u2019s going to bring in lots of \ntenants. As each tenant makes a deep commitment to ProjectOvation, SaaS-\nOvation will host more and more projects and the management artifacts to go \nalong with them. That will result in vast numbers of products, backlog items, \nreleases, sprints, and others. Performance and scalability are nonfunctional \nrequirements that cannot be ignored.\nKeeping performance and scalability in mind, what happens when one user \nof one tenant wants to add a single backlog item to a product, one that is years \nold and already has thousands of backlog items? Assume a persistence mech-\nanism capable of lazy loading (Hibernate). We almost never load all backlog \nitems, releases, and sprints at once. Still, thousands of backlog items would be \nwww.EBooksWorld.ir\n", "page": 398, "type": "text", "section": "Page 398"}
{"text": "Chapter 10 AGGREGATES\n356\nloaded into memory just to add one new element to the already large collection. \nIt\u2019s worse if a persistence mechanism does not support lazy loading. Even being \nmemory conscious, sometimes we would have to load multiple collections, such \nas when scheduling a backlog item for release or committing one to a sprint; all \nbacklog items, and either all releases or all sprints, would be loaded.\nTo see this clearly, look at the diagram in Figure 10.3 containing the \nzoomed composition. Don\u2019t let the 0..* fool you; the number of associations \nwill almost never be zero and will keep growing over time. We would likely \nneed to load thousands and thousands of objects into memory all at once, just \nto carry out what should be a relatively basic operation. That\u2019s just for a single \nteam member of a single tenant on a single product. We have to keep in mind \nthat this could happen all at once with hundreds or thousands of tenants, each \nwith multiple teams and many products. And over time the situation will only \nbecome worse.\nThis large-cluster Aggregate will never perform or scale well. It is more \nlikely to become a nightmare leading only to failure. It was deficient from the \nstart because the false invariants and a desire for compositional convenience \ndrove the design, to the detriment of transactional success, performance, and \nscalability.\nIf we are going to design small Aggregates, what does \u201csmall\u201d mean? The \nextreme would be an Aggregate with only its globally unique identity and one \n<<aggregate root>>\nProduct\n<<entity>>\nBacklogItem\n<<entity>>\nScheduledBacklogItem\norderOfPriority\n<<entity>>\nRelease\n0..*\n0..*\n0..*\n<<entity>>\nSprint\n0..*\n<<entity>>\nTask\n0..*\n<<value object>>\nEstimationLogEntry\n0..*\n<<entity>>\nCommittedBacklogItem\norderOfPriority\n0..*\nFigure 10.3 With this Product model, multiple large collections load during many \nbasic operations.\nwww.EBooksWorld.ir\n", "page": 399, "type": "text", "section": "Page 399"}
{"text": " \nRULE: DESIGN SMALL AGGREGATES\n357\nadditional attribute, which is not what\u2019s being recommended (unless that is \ntruly what one specific Aggregate requires). Rather, limit the Aggregate to just \nthe Root Entity and a minimal number of attributes and/or Value-typed prop-\nerties.3 The correct minimum is however many are necessary, and no more.\nWhich ones are necessary? The simple answer is: those that must be con-\nsistent with others, even if domain experts don\u2019t specify them as rules. For \nexample, Product has name and description attributes. We can\u2019t imagine \nname and description being inconsistent, modeled in separate Aggregates. \nWhen you change the name, you probably also change the description. If \nyou change one and not the other, it\u2019s probably because you are fixing a spell-\ning error or making the description more fitting to the name. Even though \ndomain experts will probably not think of this as an explicit business rule, it is \nan implicit one.\nWhat if you think you should model a contained part as an Entity? First \nask whether that part must itself change over time, or whether it can be com-\npletely replaced when change is necessary. Cases where instances can be com-\npletely replaced point to the use of a Value Object rather than an Entity. At \ntimes Entity parts are necessary. Yet, if we run through this design exercise \non a case-by-case basis, many concepts modeled as Entities can be refactored \nto Value Objects. Favoring Value types as Aggregate parts doesn\u2019t mean the \nAggregate is immutable since the Root Entity itself mutates when one of its \nValue-typed properties is replaced.\nThere are important advantages to limiting internal parts to Values. \nDepending on your persistence mechanism, Values can be serialized with the \nRoot Entity, whereas Entities can require separately tracked storage. Overhead \nis higher with Entity parts, as, for example, when SQL joins are necessary to \nread them using Hibernate. Reading a single database table row is much faster. \nValue objects are smaller and safer to use (fewer bugs). Due to immutability \nit is easier for unit tests to prove their correctness. These advantages are dis-\ncussed in Value Objects (6).\nOn one project for the financial derivatives sector using Qi4j [\u00d6berg], Niclas \nHedhman4 reported that his team was able to design approximately 70 percent \nof all Aggregates with just a Root Entity containing some Value-typed proper-\nties. The remaining 30 percent had just two to three total Entities. This doesn\u2019t \nindicate that all domain models will have a 70/30 split. It does indicate that a \nhigh percentage of Aggregates can be limited to a single Entity, the Root.\n 3. A Value-typed property is an attribute that holds a reference to a Value Object. I \ndistinguish this from a simple attribute such as a string or numeric type, as does \nWard Cunningham when describing Whole Value [Cunningham, Whole Value].\n 4. See also www.jroller.com/niclas/\nwww.EBooksWorld.ir\n", "page": 400, "type": "text", "section": "Page 400"}
{"text": "Chapter 10 AGGREGATES\n358\nThe [Evans] discussion of Aggregates gives an example where having mul-\ntiple Entities makes sense. A purchase order is assigned a maximum allow-\nable total, and the sum of all line items must not surpass the total. The rule \nbecomes tricky to enforce when multiple users simultaneously add line items. \nAny one addition is not permitted to exceed the limit, but concurrent additions \nby multiple users could collectively do so. I won\u2019t repeat the solution here, but \nI want to emphasize that most of the time the invariants of business models \nare simpler to manage than that example. Recognizing this helps us to model \nAggregates with as few properties as possible.\nSmaller Aggregates not only perform and scale better, they are also biased \ntoward transactional success, meaning that conflicts preventing a commit are \nrare. This makes a system more usable. Your domain will not often have true \ninvariant constraints that force you into large-composition design situations. \nTherefore, it is just plain smart to limit Aggregate size. When you occasionally \nencounter a true consistency rule, add another few Entities, or possibly a col-\nlection, as necessary, but continue to push yourself to keep the overall size as \nsmall as possible.\nDon\u2019t Trust Every Use Case\nBusiness analysts play an important role in delivering use case specifications. \nMuch work goes into a large and detailed specification, and it will affect many \nof our design decisions. Yet, we mustn\u2019t forget that use cases derived in this \nway don\u2019t carry the perspective of the domain experts and developers of our \nclose-knit modeling team. We still must reconcile each use case with our cur-\nrent model and design, including our decisions about Aggregates. A common \nissue that arises is a particular use case that calls for the modification of mul-\ntiple Aggregate instances. In such a case we must determine whether the spec-\nified large user goal is spread across multiple persistence transactions, or if it \noccurs within just one. If it is the latter, it pays to be skeptical. No matter how \nwell it is written, such a use case may not accurately reflect the true Aggregates \nof our model.\nAssuming your Aggregate boundaries are aligned with real business con-\nstraints, it\u2019s going to cause problems if business analysts specify what you see \nin Figure 10.4. Thinking through the various commit order permutations, \nyou\u2019ll see that there are cases where two of the three requests will fail.5 What \n 5. This doesn\u2019t address the fact that some use cases describe modifications to mul-\ntiple Aggregates that span transactions, which would be fine. A user goal should \nnot be viewed as synonymous with a transaction. We are concerned only with use \ncases that actually indicate the modification of multiple Aggregate instances in \none transaction.\nwww.EBooksWorld.ir\n", "page": 401, "type": "text", "section": "Page 401"}
{"text": " \nRULE: REFERENCE OTHER AGGREGATES BY IDENTITY\n359\ndoes attempting this indicate about your design? The answer to that question \nmay lead to a deeper understanding of the domain. Trying to keep multiple \nAggregate instances consistent may be telling you that your team has missed \nan invariant. You may end up folding the multiple Aggregates into one new \nconcept with a new name in order to address the newly recognized business \nrule. (And, of course, it might be only parts of the old Aggregates that get \nrolled into the new one.)\nSo a new use case may lead to insights that push us to remodel the Aggre-\ngate, but be skeptical here, too. Forming one Aggregate from multiple ones \nmay drive out a completely new concept with a new name, yet if modeling \nthis new concept leads you toward designing a large-cluster Aggregate, that \ncan end up with all the problems common to that approach. What different \napproach may help?\nJust because you are given a use case that calls for maintaining consistency \nin a single transaction doesn\u2019t mean you should do that. Often, in such cases, \nthe business goal can be achieved with eventual consistency between Aggre-\ngates. The team should critically examine the use cases and challenge their \nassumptions, especially when following them as written would lead to unwieldy \ndesigns. The team may have to rewrite the use case (or at least re-imagine it if \nthey face an uncooperative business analyst). The new use case would specify \neventual consistency and the acceptable update delay. This is one of the issues \ntaken up later in this chapter.\nRule: Reference Other Aggregates by Identity\nWhen designing Aggregates, we may desire a compositional structure that \nallows for traversal through deep object graphs, but that is not the motiva-\ntion of the pattern. [Evans] states that one Aggregate may hold references to \n<<aggregate root>>\nrequest\nrequest\nrequest\nProduct\nUser 1\nUser 2\nUser 3\n<<aggregate root>>\nBacklogItem\nFigure 10.4 Concurrency contention exists among three users who are all trying to \naccess the same two Aggregate instances, leading to a high number of transactional \nfailures.\nwww.EBooksWorld.ir\n", "page": 402, "type": "text", "section": "Page 402"}
{"text": "Chapter 10 AGGREGATES\n360\nthe Root of other Aggregates. However, we must keep in mind that this does \nnot place the referenced Aggregate inside the consistency boundary of the one \nreferencing it. The reference does not cause the formation of just one whole \nAggregate. There are still two (or more), as shown in Figure 10.5. \nIn Java the association would be modeled like this:\npublic class BacklogItem extends ConcurrencySafeEntity  {\n    ...\n    private Product product;\n    ...\n}\nThat is, the BacklogItem holds a direct object association to Product.\nIn combination with what\u2019s already been discussed and what\u2019s next, this has \na few implications:\n 1. Both the referencing Aggregate (BacklogItem) and the referenced Aggre-\ngate (Product) must not be modified in the same transaction. Only one \nor the other may be modified in a single transaction.\n 2. If you are modifying multiple instances in a single transaction, it may be \na strong indication that your consistency boundaries are wrong. If so, it \nis possibly a missed modeling opportunity; a concept of your Ubiquitous \nLanguage has not yet been discovered although it is waving its hands and \nshouting at you (see earlier in this chapter).\n<<aggregate root>>\nBacklogItem\nInside\nOutside\n<<aggregate root>>\nProduct\n<<entity>>\nTask\ndescription\nhoursRemaining\nname\nvolunteer\n0..*\n<<value object>>\nEstimationLogEntry\ndescription\nhoursRemaining\nname\nvolunteer\n0..*\nFigure 10.5 There are two Aggregates, not one.\nwww.EBooksWorld.ir\n", "page": 403, "type": "text", "section": "Page 403"}
{"text": " \nRULE: REFERENCE OTHER AGGREGATES BY IDENTITY\n361\n 3. If you are attempting to apply point 2, and doing so influences a large-\ncluster Aggregate with all the previously stated caveats, it may be an indi-\ncation that you need to use eventual consistency (see later in this chapter) \ninstead of atomic consistency.\nIf you don\u2019t hold any reference, you can\u2019t modify another Aggregate. So the \ntemptation to modify multiple Aggregates in the same transaction could be \nsquelched by avoiding the situation in the first place. But that is overly limiting \nsince domain models always require some associative connections. What might \nwe do to facilitate necessary associations, protect from transaction misuse or \ninordinate failure, and allow the model to perform and scale?\nMaking Aggregates Work Together through Identity References\nPrefer references to external Aggregates only by their globally unique identity, \nnot by holding a direct object reference (or \u201cpointer\u201d). This is exemplified in \nFigure 10.6. \n<<aggregate root>>\nBacklogItem\n<<value object>>\nSprintId\n<<value object>>\nReleaseId\n<<value object>>\nProductId\n<<entity>>\nTask\ndescription\nhoursRemaining\nname\nvolunteer\nstatus\nstory\nstoryPoints\nsummary\ntype\n0..*\n<<value object>>\nEstimationLogEntry\ndescription\nhoursRemaining\nname\nvolunteer\n0..*\nFigure 10.6 The BacklogItem Aggregate, inferring associations outside its \nboundary with identities\nwww.EBooksWorld.ir\n", "page": 404, "type": "text", "section": "Page 404"}
{"text": "Chapter 10 AGGREGATES\n362\nWe would refactor the source to\npublic class BacklogItem extends ConcurrencySafeEntity  {\n    ...\n    private ProductId productId;\n    ...\n}\nAggregates with inferred object references are thus automatically smaller \nbecause references are never eagerly loaded. The model can perform better \nbecause instances require less time to load and take less memory. Using less \nmemory has positive implications for both memory allocation overhead and \ngarbage collection.\nModel Navigation\nReference by identity doesn\u2019t completely prevent navigation through the model. \nSome will use a Repository (12) from inside an Aggregate for lookup. This \ntechnique is called Disconnected Domain Model, and it\u2019s actually a form \nof lazy loading. There\u2019s a different recommended approach, however: Use \na Repository or Domain Service (7) to look up dependent objects ahead of \ninvoking the Aggregate behavior. A client Application Service may control this, \nthen dispatch to the Aggregate:\npublic class ProductBacklogItemService ... {\n    ...\n    @Transactional\n    public void assignTeamMemberToTask(\n        String aTenantId,\n        String aBacklogItemId,\n        String aTaskId,\n        String aTeamMemberId) {\n        BacklogItem backlogItem =\n            backlogItemRepository.backlogItemOfId(\n                new TenantId(aTenantId),\n                new BacklogItemId(aBacklogItemId));\n        Team ofTeam =\n            teamRepository.teamOfId(\n                backlogItem.tenantId(),\n                backlogItem.teamId());\n        backlogItem.assignTeamMemberToTask(\n                new TeamMemberId(aTeamMemberId),\nwww.EBooksWorld.ir\n", "page": 405, "type": "text", "section": "Page 405"}
{"text": " \nRULE: REFERENCE OTHER AGGREGATES BY IDENTITY\n363\n                ofTeam,\n                new TaskId(aTaskId));\n    }\n    ...\n}\nHaving an Application Service resolve dependencies frees the Aggregate \nfrom relying on either a Repository or a Domain Service. However, for very \ncomplex and domain-specific dependency resolutions, passing a Domain Ser-\nvice into an Aggregate command method can be the best way to go. The Aggre-\ngate can then double-dispatch to the Domain Service to resolve references. \nAgain, in whatever way one Aggregate gains access to others, referencing mul-\ntiple Aggregates in one request does not give license to cause modification on \ntwo or more of them.\nCowboy Logic\nLB:  \n\u201cI\u2019ve got two points of reference when I\u2019m navigating \nat night. If it smells like beef on the hoof, I\u2019m head-\ning to the herd. If it smells like beef on the grill, I\u2019m \nheading home.\u201d\nLimiting a model to using only reference by identity could make it more dif-\nficult to serve clients that assemble and render User Interface (14) views. You \nmay have to use multiple Repositories in a single use case to populate views. \nIf query overhead causes performance issues, it may be worth considering the \nuse of theta joins or CQRS. Hibernate, for example, supports theta joins as a \nmeans to assemble a number of referentially associated Aggregate instances in \na single join query, which can provide the necessary viewable parts. If CQRS \nand theta joins are not an option, you may need to strike a balance between \ninferred and direct object reference.\nIf all this advice seems to lead to a less convenient model, consider the addi-\ntional benefits it affords. Making Aggregates smaller leads to better-perform-\ning models, plus we can add scalability and distribution.\nScalability and Distribution\nSince Aggregates don\u2019t use direct references to other Aggregates but reference \nby identity, their persistent state can be moved around to reach large scale. \nAlmost-infinite scalability is achieved by allowing for continuous repartition-\ning of Aggregate data storage, as explained by Amazon.com\u2019s Pat Helland in \nwww.EBooksWorld.ir\n", "page": 406, "type": "text", "section": "Page 406"}
{"text": "Chapter 10 AGGREGATES\n364\nhis position paper \u201cLife beyond Distributed Transactions: An Apostate\u2019s Opin-\nion\u201d [Helland]. What we call Aggregate, he calls entity. But what he describes \nis still an Aggregate by any other name: a unit of composition that has trans-\nactional consistency. Some NoSQL persistence mechanisms support the Ama-\nzon-inspired distributed storage. These provide much of what [Helland] refers \nto as the lower, scale-aware layer. When employing a distributed store, or even \nwhen using a SQL database with similar motivations, reference by identity \nplays an important role.\nDistribution extends beyond storage. Since there are always multiple Bounded \nContexts at play in a given Core Domain initiative, reference by identity allows \ndistributed domain models to have associations from afar. When an Event-\nDriven approach is in use, message-based Domain Events (8) containing Aggre-\ngate identities are sent around the enterprise. Message subscribers in foreign \nBounded Contexts use the identities to carry out operations in their own domain \nmodels. Reference by identity forms remote associations or partners. Distributed \noperations are managed by what [Helland] calls two-party activities, but in Pub-\nlish-Subscribe [Buschmann et al.] or Observer [Gamma et al.] terms it\u2019s multi-\nparty (two or more). Transactions across distributed systems are not atomic. The \nvarious systems bring multiple Aggregates into a consistent state eventually.\nRule: Use Eventual Consistency Outside the Boundary\nThere is a frequently overlooked statement found in the [Evans] Aggregate pat-\ntern definition. It bears heavily on what we must do to achieve model consis-\ntency when multiple Aggregates must be affected by a single client request:\nAny rule that spans AGGREGATES will not be expected to be up-to-date at all \ntimes. Through event processing, batch processing, or other update mechanisms, \nother dependencies can be resolved within some specific time. [Evans, p. 128]\nThus, if executing a command on one Aggregate instance requires that addi-\ntional business rules execute on one or more other Aggregates, use eventual \nconsistency. Accepting that all Aggregate instances in a large-scale, high-traf-\nfic enterprise are never completely consistent helps us accept that eventual con-\nsistency also makes sense in the smaller scale where just a few instances are \ninvolved.\nAsk the domain experts if they could tolerate some time delay between the \nmodification of one instance and the others involved. Domain experts are \nsometimes far more comfortable with the idea of delayed consistency than are \ndevelopers. They are aware of realistic delays that occur all the time in their \nbusiness, whereas developers are usually indoctrinated with an atomic change \nwww.EBooksWorld.ir\n", "page": 407, "type": "text", "section": "Page 407"}
{"text": " \nRULE: USE EVENTUAL CONSISTENCY OUTSIDE THE BOUNDARY\n365\nmentality. Domain experts often remember the days prior to computer auto-\nmation of their business operations, when various kinds of delays occurred all \nthe time and consistency was never immediate. Thus, domain experts are often \nwilling to allow for reasonable delays\u2014a generous number of seconds, min-\nutes, hours, or even days\u2014before consistency occurs.\nThere is a practical way to support eventual consistency in a DDD model. \nAn Aggregate command method publishes a Domain Event that is in time \ndelivered to one or more asynchronous subscribers:\npublic class BacklogItem extends ConcurrencySafeEntity  {\n    ...\n    public void commitTo(Sprint aSprint) {\n        ...\n        DomainEventPublisher\n            .instance()\n            .publish(new BacklogItemCommitted(\n                    this.tenantId(),\n                    this.backlogItemId(),\n                    this.sprintId()));\n    }\n    ...\n}\nEach of these subscribers then retrieves a different yet corresponding Aggre-\ngate instance and executes its behavior based on it. Each of the subscribers \nexecutes in a separate transaction, obeying the rule of Aggregates to modify \njust one instance per transaction.\nWhat happens if the subscriber experiences concurrency contention with \nanother client, causing its modification to fail? The modification can be retried \nif the subscriber does not acknowledge success to the messaging mechanism. \nThe message will be redelivered, a new transaction started, a new attempt \nmade to execute the necessary command, and a corresponding commit made. \nThis retry process can continue until consistency is achieved, or until a retry \nlimit is reached.6 If complete failure occurs, it may be necessary to compensate, \nor at a minimum to report the failure for pending intervention.\nWhat is accomplished by publishing the BacklogItemCommitted Domain \nEvent in this specific example? Recalling that BacklogItem already holds \nthe identity of the Sprint it is committed to, we are in no way interested in \n 6. Consider attempting retries using Capped Exponential Back-off. Rather than \ndefaulting to a retry every N fixed number of seconds, exponentially back off on \nretries while capping waits with an upper limit. For example, start at one second \nand back off exponentially, doubling until success or until reaching a 32-second \nwait-and-retry cap.\nwww.EBooksWorld.ir\n", "page": 408, "type": "text", "section": "Page 408"}
{"text": "Chapter 10 AGGREGATES\n366\nmaintaining a meaningless bidirectional association. Rather, the Event allows \nfor the eventual creation of a CommittedBacklogItem so the Sprint can \nmake a record of work commitment. Since each CommittedBacklogItem\nhas an ordering attribute, it allows the Sprint to give each BacklogItem\nan ordering different from those of Product and Release, and that is not \ntied to the BacklogItem instance\u2019s own recorded estimation of Business-\nPriority. Thus, Product and Release hold similar associations, namely, \nProductBacklogItem and ScheduledBacklogItem, respectively.\nWhiteboard Time\n\u2022 Return to your list of large-cluster Aggregates and the two or more modi-\nfied in a single transaction.\n\u2022 Describe and diagram how you will break up the large clusters. Circle and \nnote each of the true invariants inside each of the new small Aggregates.\n\u2022 Describe and diagram how you will keep separate Aggregates eventually \nconsistent.\nThis example demonstrates how to use eventual consistency in a single \nBounded Context, but the same technique can also be applied in a distributed \nfashion as previously described.\nAsk Whose Job It Is\nSome domain scenarios can make it very challenging to determine whether \ntransactional or eventual consistency should be used. Those who use DDD \nin a classic/traditional way may lean toward transactional consistency. Those \nwho use CQRS may tend toward eventual consistency. But which is correct? \nFrankly, neither of those tendencies provides a domain-specific answer, only a \ntechnical preference. Is there a better way to break the tie?\nCowboy Logic\nLB:  \n\u201cMy son told me that he found on the Internet how to \nmake my cows more fertile. I told him that\u2019s the bull\u2019s \njob.\u201d\nwww.EBooksWorld.ir\n", "page": 409, "type": "text", "section": "Page 409"}
{"text": " \nREASONS TO BREAK THE RULES\n367\nDiscussing this with Eric Evans revealed a very simple and sound guideline. \nWhen examining the use case (or story), ask whether it\u2019s the job of the user \nexecuting the use case to make the data consistent. If it is, try to make it trans-\nactionally consistent, but only by adhering to the other rules of Aggregates. If \nit is another user\u2019s job, or the job of the system, allow it to be eventually con-\nsistent. That bit of wisdom not only provides a convenient tie breaker, but it \nhelps us gain a deeper understanding of our domain. It exposes the real system \ninvariants: the ones that must be kept transactionally consistent. That under-\nstanding is much more valuable than defaulting to a technical leaning.\nThis is a great tip to add to the Aggregate Rules of Thumb. Since there are \nother forces to consider, it may not always lead to the final choice between \ntransactional and eventual consistency but will usually provide deeper insight \ninto the model. This guideline is used later in the chapter when the team revis-\nits their Aggregate boundaries.\nReasons to Break the Rules\nAn experienced DDD practitioner may at times decide to persist changes to \nmultiple Aggregate instances in a single transaction, but only with good rea-\nson. What might some reasons be? I discuss four reasons here. You may expe-\nrience these and others.\nReason One: User Interface Convenience\nSometimes user interfaces, as a convenience, allow users to define the common \ncharacteristics of many things at once in order to create batches of them. Per-\nhaps it happens frequently that team members want to create several backlog \nitems as a batch. The user interface allows them to fill out all the common \nproperties in one section, and then one by one the few distinguishing proper-\nties of each, eliminating repeated gestures. All of the new backlog items are \nthen planned (created) at once:\npublic class ProductBacklogItemService ... {\n    ...\n    @Transactional\n    public void planBatchOfProductBacklogItems(\n        String aTenantId, String productId,\n        BacklogItemDescription[] aDescriptions) {\n        Product product =\n            productRepository.productOfId(\n                    new TenantId(aTenantId),\n                    new ProductId(productId));\nwww.EBooksWorld.ir\n", "page": 410, "type": "text", "section": "Page 410"}
{"text": "Chapter 10 AGGREGATES\n368\n        for (BacklogItemDescription desc : aDescriptions) {\n            BacklogItem plannedBacklogItem =\n                product.planBacklogItem(\n                    desc.summary(),\n                    desc.category(),\n                    BacklogItemType.valueOf(\n                            desc.backlogItemType()),\n                    StoryPoints.valueOf(\n                            desc.storyPoints()));\n            backlogItemRepository.add(plannedBacklogItem);\n        }\n    }\n    ...\n}\nDoes this cause a problem with managing invariants? In this case, no, since \nit would not matter whether these were created one at a time or in batch. The \nobjects being instantiated are full Aggregates, which maintain their own invari-\nants. Thus, if creating a batch of Aggregate instances all at once is semantically \nno different from creating one at a time repeatedly, it represents one reason to \nbreak the rule of thumb with impunity.\nReason Two: Lack of Technical Mechanisms\nEventual consistency requires the use of some kind of out-of-band process-\ning capability, such as messaging, timers, or background threads. What if the \nproject you are working on has no provision for any such mechanism? While \nmost of us would consider that strange, I have faced that very limitation. With \nno messaging mechanism, no background timers, and no other home-grown \nthreading capabilities, what could be done?\nIf we aren\u2019t careful, this situation could lead us back toward designing \nlarge-cluster Aggregates. While that might make us feel as if we are adhering \nto the single transaction rule, as previously discussed it would also degrade \nperformance and limit scalability. To avoid that, perhaps we could instead \nchange the system\u2019s Aggregates altogether, forcing the model to solve our chal-\nlenges. We\u2019ve already considered the possibility that project specifications may \nbe jealously guarded, leaving us little room for negotiating previously unimag-\nined domain concepts. That\u2019s not really the DDD way, but sometimes it does \nhappen. The conditions may allow for no reasonable way to alter the modeling \ncircumstances in our favor. In such cases project dynamics may force us to \nmodify two or more Aggregate instances in one transaction. However obvious \nthis might seem, such a decision should not be made too hastily.\nwww.EBooksWorld.ir\n", "page": 411, "type": "text", "section": "Page 411"}
{"text": " \nREASONS TO BREAK THE RULES\n369\nCowboy Logic\nAJ:  \n\u201cIf you think that rules are made to be broken, you\u2019d \nbetter know a good repairman.\u201d\nConsider an additional factor that could further support diverging from the \nrule: user-aggregate affinity. Are the business workflows such that only one \nuser would be focused on one set of Aggregate instances at any given time? \nEnsuring user-aggregate affinity makes the decision to alter multiple Aggregate \ninstances in a single transaction more sound since it tends to prevent the viola-\ntion of invariants and transactional collisions. Even with user-aggregate affin-\nity, in rare situations users may face concurrency conflicts. Yet each Aggregate \nwould still be protected from that by using optimistic concurrency. Anyway, \nconcurrency conflicts can happen in any system, and even more frequently \nwhen user-aggregate affinity is not our ally. Besides, recovering from concur-\nrency conflicts is straightforward when encountered at rare times. Thus, when \nour design is forced to, sometimes it works out well to modify multiple Aggre-\ngate instances in one transaction.\nReason Three: Global Transactions\nAnother influence considered is the effects of legacy technologies and enter-\nprise policies. One such might be the need to strictly adhere to the use of \nglobal, two-phase commit transactions. This is one of those situations that \nmay be impossible to push back on, at least in the short term.\nEven if you must use a global transaction, you don\u2019t necessarily have to \nmodify multiple Aggregate instances at once in your local Bounded Context. \nIf you can avoid doing so, at least you can prevent transactional contention in \nyour Core Domain and actually obey the rules of Aggregates as far as you are \nable. The downside to global transactions is that your system will probably \nnever scale as it could if you were able to avoid two-phase commits and the \nimmediate consistency that goes along with them.\nReason Four: Query Performance\nThere may be times when it\u2019s best to hold direct object references to other \nAggregates. This could be used to ease Repository query performance issues. \nThese must be weighed carefully in the light of potential size and overall \nwww.EBooksWorld.ir\n", "page": 412, "type": "text", "section": "Page 412"}
{"text": "Chapter 10 AGGREGATES\n370\nperformance trade-off implications. One example of breaking the rule of refer-\nence by identity is given later in the chapter.\nAdhering to the Rules\nYou may experience user interface design decisions, technical limitations, stiff \npolicies, or other factors in your enterprise environment that require you to \nmake some compromises. Certainly we don\u2019t go in search of excuses to break \nthe Aggregate Rules of Thumb. In the long run, adhering to the rules will ben-\nefit our projects. We\u2019ll have consistency where necessary, and support for opti-\nmally performing and highly scalable systems.\nGaining Insight through Discovery\nWith the rules of Aggregates in use, we\u2019ll see how adhering to them affects \nthe design of the SaaSOvation Scrum model. We\u2019ll see how the project team \nrethinks their design again, applying newfound techniques. That effort leads to \nthe discovery of new insights into the model. Their various ideas are tried and \nthen superseded.\nRethinking the Design, Again\nAfter the refactoring iteration that broke up the large-cluster Product, the \nBacklogItem now stands alone as its own Aggregate. It reflects the model \npresented in Figure 10.7. The team composed a collection of Task instances \ninside the BacklogItem Aggregate. Each BacklogItem has a globally \nunique identity, its BacklogItemId. All associations to other Aggregates are \ninferred through identities. That means its parent Product, the Release it is \nscheduled within, and the Sprint to which it is committed are referenced by \nidentities. It seems fairly small.\nWith the team now jazzed about designing small Aggregates, could they \npossibly overdo it in that direction?\nDespite the good feeling coming out of that previous iteration, \nthere was still some concern. For example, the story attribute \nallowed for a good deal of text. Teams developing agile stories \nwon\u2019t write lengthy prose. Even so, there is an optional edi-\ntor component that supports writing rich use case definitions. \nThose could be many thousands of bytes. It was worth consid-\nering the possible overhead.\nwww.EBooksWorld.ir\n", "page": 413, "type": "text", "section": "Page 413"}
{"text": " \nGAINING INSIGHT THROUGH DISCOVERY\n371\nGiven this potential overhead and the errors already made in designing the \nlarge-cluster Product of Figures 10.1 and 10.3, the team was now on a mission to \nreduce the size of every Aggregate in the Bounded Context. Crucial questions arose. \nWas there a true invariant between BacklogItem and Task that this relationship \nmust maintain? Or was this yet another case where the association could be further \nbroken apart, with two separate Aggregates being safely formed? What would be the \ntotal cost of keeping the design as is?\nA key to their making a proper determination lay in the Ubiquitous Language. Here \nis where an invariant was stated:\n\u2022 When progress is made on a backlog item task, the team member will estimate \ntask hours remaining.\n\u2022 When a team member estimates that zero hours are remaining on a specific \ntask, the backlog item checks all tasks for any remaining hours. If no hours \nremain on any tasks, the backlog item status is automatically changed to done.\n\u2022 When a team member estimates that one or more hours are remaining on a \nspecific task and the backlog item\u2019s status is already done, the status is auto-\nmatically regressed.\nThis sure seemed like a true invariant. The backlog item\u2019s correct status is auto-\nmatically adjusted and is completely dependent on the total number of hours remain-\ning on all its tasks. If the total number of task hours and the backlog item status are \nto remain consistent, it seems as if Figure 10.7 does stipulate the correct Aggregate \n<<aggregate root>>\nBacklogItem\n<<value object>>\nSprintId\n<<value object>>\nBacklogItemId\n<<value object>>\nTaskId\n<<value object>>\nReleaseId\n<<value object>>\nProductId\n<<entity>>\nTask\ndescription\nhoursRemaining\nname\nvolunteer\nstatus\nstory\nstoryPoints\nsummary\ntype\n0..*\n<<value object>>\nEstimationLogEntry\ndescription\nhoursRemaining\nname\nvolunteer\n0..*\nFigure 10.7 The fully composed BacklogItem Aggregate\nwww.EBooksWorld.ir\n", "page": 414, "type": "text", "section": "Page 414"}
{"text": "Chapter 10 AGGREGATES\n372\nconsistency boundary. However, the team should still determine what the current \ncluster could cost in terms of performance and scalability. That would be weighed \nagainst what they might save if the backlog item status could be eventually consistent \nwith the total task hours remaining.\nSome will see this as a classic opportunity to use eventual consistency, but \nwe won\u2019t jump to that conclusion just yet. Let\u2019s analyze a transactional consis-\ntency approach, then investigate what could be accomplished using eventual \nconsistency. We can then draw our own conclusion as to which approach is \npreferred.\nEstimating Aggregate Cost\nAs Figure 10.7 shows, each Task holds a collection of  \nEstimationLogEntry\ninstances. These logs model the specific occasions when a team member enters \na new estimate of hours remaining. In practical terms, how many Task ele-\nments will each BacklogItem hold, and how many EstimationLogEntry\nelements will a given Task hold? It\u2019s hard to say exactly. It\u2019s largely a measure \nof how complex any one task is and how long a sprint lasts. But some back-of-\nthe-envelope (BOTE) calculations might help [Bentley].\nTask hours are usually reestimated each day after a team member works on \na given task. Let\u2019s say that most sprints are either two or three weeks in length. \nThere will be longer sprints, but a two- to three-week time span is common \nenough. So let\u2019s select a number of days somewhere between ten and 15. With-\nout being too precise, 12 days works well since there may actually be more \ntwo-week than three-week sprints.\nNext, consider the number of hours assigned to each task. Remembering \nthat tasks must be broken down into manageable units, we generally use a \nnumber of hours between four and 16. Normally if a task exceeds a 12-hour \nestimate, Scrum experts suggest breaking it down further. But using 12 hours \nas a first test makes it easier to simulate work evenly. We can say that tasks are \nworked on for one hour on each of the 12 days of the sprint. Doing so favors \nmore complex tasks. So we\u2019ll figure 12 reestimations per task, assuming that \neach task starts out with 12 hours allocated to it.\nThe question remains: How many tasks would be required per backlog item? \nThat too is a difficult question to answer. What if we thought in terms of there \nbeing two or three tasks required per Layer (4) or Hexagonal Port-Adapter (4)\nfor a given feature slice? For example, we might count three for the User Inter-\nface Layer (14), two for the Application Layer (14), three for the Domain Layer, \nand three for the Infrastructure Layer (14). That would bring us to 11 total \nwww.EBooksWorld.ir\n", "page": 415, "type": "text", "section": "Page 415"}
{"text": " \nGAINING INSIGHT THROUGH DISCOVERY\n373\ntasks. It might be just right or a bit slim, but we\u2019ve already erred on the side of \nnumerous task estimations. Let\u2019s bump it up to 12 tasks per backlog item to be \nmore liberal. With that we are allowing for 12 tasks, each with 12 estimation \nlogs, or 144 total collected objects per backlog item. While this may be more \nthan the norm, it gives us a chunky BOTE calculation to work with.\nThere is another variable to be considered. If Scrum expert advice to define \nsmaller tasks is commonly followed, it would change things somewhat. Dou-\nbling the number of tasks (24) and halving the number of estimation log entries \n(6) would still produce 144 total objects. However, it would cause more tasks \nto be loaded (24 rather than 12) during all estimation requests, consuming \nmore memory on each. The team will try various combinations to see if there is \nany significant impact on their performance tests. But to start they will use 12 \ntasks of 12 hours each.\nCommon Usage Scenarios\nNow it\u2019s important to consider common usage scenarios. How often will one \nuser request need to load all 144 objects into memory at once? Would that ever \nhappen? It seems not, but the team needs to check. If not, what\u2019s the likely \nhigh-end count of objects? Also, will there typically be multiclient usage that \ncauses concurrency contention on backlog items? Let\u2019s see.\nThe following scenarios are based on the use of Hibernate for persistence. \nAlso, each Entity type has its own optimistic concurrency version attribute. \nThis is workable because the changing status invariant is managed on the \nBacklogItem Root Entity. When the status is automatically altered (to done \nor back to committed), the Root\u2019s version is bumped. Thus, changes to tasks \ncan happen independently of each other and without impacting the Root each \ntime one is modified, unless the result is a status change. (The following anal-\nysis could need to be revisited if using, for example, document-based storage, \nsince the Root is effectively modified every time a collected part is modified.)\nWhen a backlog item is first created, there are zero contained tasks. Nor-\nmally it is not until sprint planning that tasks are defined. During that meeting \ntasks are identified by the team. As each one is called out, a team member adds \nit to the corresponding backlog item. There is no need for two team mem-\nbers to contend with each other for the Aggregate, as if racing to see who can \nenter new tasks more quickly. That would cause collision, and one of the two \nrequests would fail (for the same reason simultaneously adding various parts to \nProduct previously failed). However, the two team members would probably \nsoon figure out how counterproductive their redundant work is.\nIf the developers learned that multiple users do indeed regularly want to add \ntasks together, it would change the analysis significantly. That understanding \nwww.EBooksWorld.ir\n", "page": 416, "type": "text", "section": "Page 416"}
{"text": "Chapter 10 AGGREGATES\n374\ncould immediately tip the scales in favor of breaking BacklogItem and Task\ninto two separate Aggregates. On the other hand, this could also be a perfect \ntime to tune the Hibernate mapping by setting the optimistic-lock option \nto false. Allowing tasks to grow simultaneously could make sense in this \ncase, especially if they don\u2019t pose performance and scalability issues.\nIf tasks are at first estimated at zero hours and later updated to an accurate \nestimate, we still don\u2019t tend to experience concurrency contention, although \nthis would add one additional estimation log entry, pushing our BOTE total \nto 13. Simultaneous use here does not change the backlog item status. Again, \nit advances to done only by going from greater than zero to zero hours, or \nregresses to committed if already done and hours are changed from zero to one \nor more\u2014two uncommon events.\nWill daily estimations cause problems? On day one of the sprint there are \nusually zero estimation logs on a given task of a backlog item. At the end of \nday one, each volunteer team member working on a task reduces the estimated \nhours by one. This adds a new estimation log to each task, but the backlog \nitem\u2019s status remains unaffected. There is never contention on a task because \njust one team member adjusts its hours. It\u2019s not until day 12 that we reach the \npoint of status transition. Still, as each of any 11 tasks is reduced to zero hours, \nthe backlog item\u2019s status is not altered. It\u2019s only the very last estimation, the \n144th on the 12th task, that causes automatic status transition to the done state.\nThis analysis led the team to an important realization. Even if they altered the usage \nscenarios, accelerating task completion by double (six days) or even mixing it up \ncompletely, it wouldn\u2019t change anything. It\u2019s always the final estimate that transitions \nthe status, which modifies the Root. This seemed like a safe design, although mem-\nory overhead was still in question.\nMemory Consumption\nNow to address the memory consumption. Important here is that estimates \nare logged by date as Value Objects. If a team member reestimates any number \nof times on a single day, only the most recent estimate is retained. The latest \nValue of the same date replaces the previous one in the collection. At this point \nthere\u2019s no requirement to track task estimation mistakes. There is the assump-\ntion that a task will never have more estimation log entries than the number of \ndays the sprint is in progress. That assumption changes if tasks were defined \none or more days before the sprint planning meeting, and hours were reesti-\nmated on any of those earlier days. There would be one extra log for each day \nthat occurred.\nwww.EBooksWorld.ir\n", "page": 417, "type": "text", "section": "Page 417"}
{"text": " \nGAINING INSIGHT THROUGH DISCOVERY\n375\nWhat about the total number of tasks and estimates in memory for each \nreestimation? When using lazy loading for the tasks and estimation logs, we \nwould have as many as 12 plus 12 collected objects in memory at one time per \nrequest. This is because all 12 tasks would be loaded when accessing that col-\nlection. To add the latest estimation log entry to one of those tasks, we\u2019d have \nto load the collection of estimation log entries. That would be up to another 12 \nobjects. In the end the Aggregate design requires one backlog item, 12 tasks, \nand 12 log entries, or 25 objects maximum total. That\u2019s not very many; it\u2019s a \nsmall Aggregate. Another factor is that the higher end of objects (for example, \n25) is not reached until the last day of the sprint. During much of the sprint the \nAggregate is even smaller.\nWill this design cause performance problems because of lazy loads? Possi-\nbly, because it actually requires two lazy loads, one for the tasks and one for \nthe estimation log entries for one of the tasks. The team will have to test to \ninvestigate the possible overhead of the multiple fetches.\nThere\u2019s another factor. Scrum enables teams to experiment in order to iden-\ntify the right planning model for their practices. As explained by [Sutherland], \nexperienced teams with a well-known velocity can estimate using story points \nrather than task hours. As they define each task, they can assign just one hour \nto each task. During the sprint they will reestimate only once per task, chang-\ning one hour to zero when the task is completed. As it pertains to Aggregate \ndesign, using story points reduces the total number of estimation logs per task \nto just one and almost eliminates memory overhead.\nLater on, ProjectOvation developers will be able to ana-\nlytically determine (on average) how many actual tasks \nand estimation log entries exist per backlog item by \nexamining real production data.\nThe foregoing analysis was enough to motivate the \nteam to test against their BOTE calculations. After incon-\nclusive results, however, they decided that there were \nstill too many variables for them to be confident that this \ndesign dealt well with their concerns. There were enough \nunknowns to consider an alternative design.\nExploring Another Alternative Design\nIs there another design that could contribute to Aggregate boundaries more \nfitting to the usage scenarios?\nwww.EBooksWorld.ir\n", "page": 418, "type": "text", "section": "Page 418"}
{"text": "Chapter 10 AGGREGATES\n376\nTo be thorough, the team wanted to think through what they would have to do to make \nTask an independent Aggregate, and if that would actually work to their benefit. What \nthey envisioned is seen in Figure 10.8. Doing this would reduce part composition \noverhead by 12 objects and reduce lazy load overhead. In fact, this design gave them \nthe option to eagerly load estimation log entries in all cases if that would perform best.\nThe developers agreed not to modify separate Aggregates, both the Task and \nthe BacklogItem, in the same transaction. They had to determine if they could per-\nform a necessary automatic status change within an acceptable time frame. They\u2019d \nbe weakening the invariant\u2019s consistency since the status couldn\u2019t be consistent by \ntransaction. Would that be acceptable? They discussed the matter with the domain \nexperts and learned that some delay between the final zero-hour estimate and the \nstatus being set to done, and vice versa, would be acceptable.\nImplementing Eventual Consistency\nIt looks as if there could be a legitimate use of eventual consistency between \nseparate Aggregates. Here is how it could work.\nWhen a Task processes an estimateHoursRemaining() command, it publishes \na corresponding Domain Event. It does that already, but the team would now leverage \nthe Event to achieve eventual consistency. The Event is modeled with the following \nproperties:\n<<aggregate root>>\nBacklogItem\n<<value object>>\nSprintId\n<<value object>>\nBacklogItemId\n<<value object>>\nTaskId\n<<value object>>\nReleaseId\n<<aggregate root>>\nTask\ndescription\nhoursRemaining\nname\nvolunteer\nstatus\nstory\nstoryPoints\nsummary\ntype\n0..*\n<<value object>>\nEstimationLogEntry\ndescription\nhoursRemaining\nname\nvolunteer\n<<value object>>\nProductId\nFigure 10.8\nBacklogItem and Task modeled as separate Aggregates\nwww.EBooksWorld.ir\n", "page": 419, "type": "text", "section": "Page 419"}
{"text": " \nGAINING INSIGHT THROUGH DISCOVERY\n377\npublic class TaskHoursRemainingEstimated implements DomainEvent {\n    private Date occurredOn;\n    private TenantId tenantId;\n    private BacklogItemId backlogItemId;\n    private TaskId taskId;\n    private int hoursRemaining;\n    ...\n}\nA specialized subscriber would now listen for these and delegate to a Domain Ser-\nvice to coordinate the consistency processing. The Service would\n\u2022 Use the BacklogItemRepository to retrieve the identified BacklogItem.\n\u2022 Use the TaskRepository to retrieve all Task instances associated with the \nidentified BacklogItem.\n\u2022 Execute the BacklogItem command named estimateTaskHours \nRemaining(),\npassing the Domain Event\u2019s hoursRemaining and the retrieved Task instances. \nThe BacklogItem may transition its status depending on parameters.\nThe team should find a way to optimize this. The three-step design requires all \nTask instances to be loaded every time a reestimation occurs. When using our BOTE \nestimate and advancing continuously toward done, 143 out of 144 times that\u2019s unnec-\nessary. This could be optimized pretty easily. Instead of using the Repository to get \nall Task instances, they could simply ask it for the sum of all Task hours as calcu-\nlated by the database:\npublic class HibernateTaskRepository implements TaskRepository {\n    ...\n    public int totalBacklogItemTaskHoursRemaining(\n            TenantId aTenantId,\n            BacklogItemId aBacklogItemId) {\n        Query query = session.createQuery(\n            \"select sum(task.hoursRemaining) from Task task \"\n            + \"where task.tenantId = ? and \"\n            + \"task.backlogItemId = ?\");\n        ...\n    }\n}\nEventual consistency complicates the user interface a bit. Unless the sta-\ntus transition can be achieved within a few hundred milliseconds, how would \nthe user interface display the new state? Should they place business logic in \nwww.EBooksWorld.ir\n", "page": 420, "type": "text", "section": "Page 420"}
{"text": "Chapter 10 AGGREGATES\n378\nthe view to determine the current status? That would constitute a smart UI \nanti-pattern. Perhaps the view would just display the stale status and allow \nusers to deal with the visual inconsistency. That could easily be perceived as a \nbug, or at least be very annoying.\nThe view could use a background Ajax polling request, but that could be quite ineffi-\ncient. Since the view component could not easily determine exactly when checking \nfor a status update is necessary, most Ajax pings would be unnecessary. Using our \nBOTE numbers, 143 of 144 reestimations would not cause the status update, which is \na lot of redundant requests on the Web tier. With the right server-side support the cli-\nents could instead depend on Comet (aka Ajax Push). Although a nice challenge, that \nwould introduce a completely new technology that the team had no experience using.\nOn the other hand, perhaps the best solution is the simplest. They could opt to \nplace a visual cue on the screen that informs the user that the current status is uncer-\ntain. The view could suggest a time frame for checking back or refreshing. Alterna-\ntively, the changed status will probably show on the next rendered view. That\u2019s safe. \nThe team would need to run some user acceptance tests, but it looked hopeful.\nIs It the Team Member\u2019s Job?\nOne important question has thus far been completely overlooked: Whose job \nis it to bring a backlog item\u2019s status into consistency with all remaining task \nhours? Do team members using Scrum care if the parent backlog item\u2019s sta-\ntus transitions to done just as they set the last task\u2019s hours to zero? Will they \nalways know they are working with the last task that has remaining hours? \nPerhaps they will and perhaps it is the responsibility of each team member to \nbring each backlog item to official completion.\nOn the other hand, what if there is another project stakeholder involved? \nFor example, the product owner or some other person may desire to check the \ncandidate backlog item for satisfactory completion. Maybe someone wants to \nuse the feature on a continuous integration server first. If others are happy \nwith the developers\u2019 claim of completion, they will manually mark the status \nas done. This certainly changes the game, indicating that neither transactional \nnor eventual consistency is necessary. Tasks could be split off from their parent \nbacklog item because this new use case allows it. However, if it is really the \nteam members who should cause the automatic transition to done, it would \nmean that tasks should probably be composed within the backlog item to allow \nfor transactional consistency. Interestingly, there is no clear answer here either, \nwhich probably indicates that it should be an optional application preference. \nwww.EBooksWorld.ir\n", "page": 421, "type": "text", "section": "Page 421"}
{"text": " \nGAINING INSIGHT THROUGH DISCOVERY\n379\nLeaving tasks within their backlog item solves the consistency problem, and \nit\u2019s a modeling choice that can support both automatic and manual status \ntransitions.\nThis valuable exercise uncovered a com-\npletely new aspect of the domain. It seems \nas if teams should be able to configure a \nworkflow preference. They won\u2019t implement \nsuch a feature now, but they will promote it \nfor further discussion. Asking \u201cwhose job is \nit?\u201d led them to a few vital perceptions about \ntheir domain.\nNext, one of the developers made a \nvery practical suggestion as an alternative to this whole analysis. If they were chiefly \nconcerned with the possible overhead of the story attribute, why not do something \nabout that specifically? They could reduce the total storage capacity for the story\nand in addition create a new useCaseDefinition property. They could design it to \nlazy load, since much of the time it would never be used. Or they could even design \nit as a separate Aggregate, loading it only when needed. With that idea they realized \nthis could be a good time to break the rule to reference external Aggregates only by \nidentity. It seemed like a suitable modeling choice to use a direct object reference and \ndeclare its object-relational mapping so as to lazily load it. Perhaps that made sense.\nTime for Decisions\nThis level of analysis can\u2019t continue all day. There needs to be a decision. It\u2019s \nnot as if going in one direction now would negate the possibility of going \nanother route later. Open-mindedness is now blocking pragmatism.\nBased on all this analysis, currently the team was shying away from splitting Task\nfrom BacklogItem. They couldn\u2019t be certain that splitting it now was worth the extra \neffort, the risk of leaving the true invariant unprotected, or allowing users to experi-\nence a possible stale status in the view. The current Aggregate, as they understood it, \nwas fairly small. Even if their common worst case loaded 50 objects rather than 25, it \nwould still be a reasonably sized cluster. For now they planned around the specialized \nuse case definition holder. Doing that was a quick win with lots of benefits. It added \nlittle risk, because it will work now, and it will also work in the future if they decide to \nsplit Task from BacklogItem.\nThe option to split it in two remained in their hip pocket just in case. After further \nexperimentation with the current design, running it through performance and load \nwww.EBooksWorld.ir\n", "page": 422, "type": "text", "section": "Page 422"}
{"text": "Chapter 10 AGGREGATES\n380\ntests, as well investigating user acceptance with an eventually consistent status, it \nwill become clearer which approach is better. The BOTE numbers could prove to be \nwrong if in production the Aggregate is larger than imagined. If so, the team will no \ndoubt split it into two.\nIf you were a member of the ProjectOvation team, which modeling option \nwould you have chosen? Don\u2019t shy away from discovery sessions as demon-\nstrated in the case study. That entire effort would require 30 minutes, and per-\nhaps as much as 60 minutes at worst. It\u2019s well worth the time to gain deeper \ninsight into your Core Domain.\nImplementation\nThe more prominent factors summarized and highlighted here can make \nimplementations more robust but should be investigated more thoroughly in \nEntities (5), Value Objects (6), Domain Events (8), Modules (9), Factories (11),\nand Repositories (12). Use this amalgamation as a point of reference.\nCreate a Root Entity with Unique Identity\nModel one Entity as the Aggregate Root. Examples of Root Entities in the \npreceding modeling efforts are Product, BacklogItem, Release, and \nSprint. Depending on the decision made to split Task from BacklogItem,\nTask may also be a Root.\nThe refined Product model finally led to the declaration of the following \nRoot Entity:\npublic class Product extends ConcurrencySafeEntity  {\n    private Set<ProductBacklogItem> backlogItems;\n    private String description;\n    private String name;\n    private ProductDiscussion productDiscussion;\n    private ProductId productId;\n    private TenantId tenantId;\n    ...\n}\nClass ConcurrencySafeEntity is a Layer Supertype [Fowler, P of EAA] \nused to manage surrogate identity and optimistic concurrency versioning, as \nexplained in Entities (5).\nwww.EBooksWorld.ir\n", "page": 423, "type": "text", "section": "Page 423"}
{"text": " \nIMPLEMENTATION\n381\nA Set of ProductBacklogItem instances not previously discussed has \nbeen, perhaps mysteriously, added to the Root. This is for a special purpose. \nIt\u2019s not the same as the BacklogItem collection that was formerly composed \nhere. It is for the purpose of maintaining a separate ordering of backlog items.\nEach Root must be designed with a globally unique identity. The Prod-\nuct has been modeled with a Value type named ProductId. That type is the \ndomain-specific identity, and it is different from the surrogate identity provided \nby ConcurrencySafeEntity. How a model-based identity is designed, allo-\ncated, and maintained is further explained in Entities (5). The implementation of \nProductRepository has nextIdentity() generate ProductId as a UUID:\npublic class HibernateProductRepository implements ProductRepository  {\n    ...\n    public ProductId nextIdentity() {\n        return new ProductId(java.util.UUID.randomUUID()\u03a6\n.toString().toUpperCase());\n    }\n    ...\n}\nUsing nextIdentity(), a client Application Service can instantiate a \nProduct with its globally unique identity:\npublic class ProductService ... {\n   ...\n   @Transactional\n   public String newProduct(\n        String aTenantId, aProductName, aProductDescription) {\n        Product product =\n            new Product(\n                new TenantId(aTenantId),\n                this.productRepository.nextIdentity(),\n                \"My Product\",\n                \"This is the description of my product.\",\n                new ProductDiscussion(\n                        new DiscussionDescriptor(\n                            DiscussionDescriptor.UNDEFINED_ID),\n                        DiscussionAvailability.NOT_REQUESTED));\n        this.productRepository.add(product);\n        return product.productId().id();\n    }\n    ...\n}\nwww.EBooksWorld.ir\n", "page": 424, "type": "text", "section": "Page 424"}
{"text": "Chapter 10 AGGREGATES\n382\nThe Application Service uses ProductRepository to both generate \nan identity and then persist the new Product instance. It returns the plain \nString representation of the new ProductId.\nFavor Value Object Parts\nChoose to model a contained Aggregate part as a Value Object rather than an \nEntity whenever possible. A contained part that can be completely replaced, if \nits replacement does not cause significant overhead in the model or infrastruc-\nture, is the best candidate.\nOur current Product model is designed with two simple attributes and \nthree Value-typed properties. Both description and name are String\nattributes that can be completely replaced. The productId and tenantId\nValues are maintained as stable identities; that is, they are never changed after \nconstruction. They support reference by identity rather than direct to object. In \nfact, the referenced Tenant Aggregate is not even in the same Bounded Con-\ntext and thus should be referenced only by identity. The product \nDiscussion\nis an eventually consistent Value-typed property. When the Product is first \ninstantiated, the discussion may be requested but will not exist until sometime \nlater. It must be created in the Collaboration Context. Once the creation has \nbeen completed in the other Bounded Context, the identity and status are set \non the Product.\nThere are good reasons why ProductBacklogItem is modeled as an \nEntity rather than a Value. As discussed in Value Objects (6), since the backing \ndatabase is used via Hibernate, it must model collections of Values as database \nentities. Reordering any one of the elements could cause a significant number, \neven all, of the ProductBacklogItem instances to be deleted and replaced. \nThat would tend to cause significant overhead in the infrastructure. As an \nEntity, it allows the ordering attribute to be changed across any and all col-\nlection elements as often as a product owner requires. However, if we were to \nswitch from using Hibernate with MySQL to a key-value store, we could easily \nchange ProductBacklogItem to be a Value type instead. When using a key-\nvalue or document store, Aggregate instances are typically serialized as one \nvalue representation for storage.\nUsing Law of Demeter and Tell, Don\u2019t Ask\nBoth Law of Demeter [Appleton, LoD] and Tell, Don\u2019t Ask [PragProg, TDA] \nare design principles that can be used when implementing Aggregates, both of \nwhich stress information hiding. Consider the high-level guiding principles to \nsee how we can benefit:\nwww.EBooksWorld.ir\n", "page": 425, "type": "text", "section": "Page 425"}
{"text": " \nIMPLEMENTATION\n383\n\u2022 Law of Demeter: This guideline emphasizes the principle of least knowl-\nedge. Think of a client object and another object the client object uses \nto execute some system behavior; refer to the second object as a server.\nWhen the client object uses the server object, it should know as little as \npossible about the server\u2019s structure. The server\u2019s attributes and proper-\nties\u2014its shape\u2014should remain completely unknown to the client. The \nclient can ask the server to perform a command that is declared on its \nsurface interface. However, the client must not reach into the server, ask \nthe server for some inner part, and then execute a command on the part. \nIf the client needs a service that is rendered by the server\u2019s inner parts, the \nclient must not be given access to the inner parts to request that behav-\nior. The server should instead provide only a surface interface and, when \ninvoked, delegate to the appropriate inner parts to fulfill its interface.\nHere\u2019s a basic summary of the Law of Demeter: Any given method on \nany object may invoke methods only on the following: (1) itself, (2) any \nparameters passed to it, (3) any object it instantiates, (4) self-contained \npart objects that it can directly access.\n\u2022 Tell, Don\u2019t Ask: This guideline simply asserts that objects should be told \nwhat to do. The \u201cDon\u2019t Ask\u201d part of the guideline applies to the client as \nfollows: A client object should not ask a server object for its contained \nparts, then make a decision based on the state it got, and then make the \nserver object do something. Instead, the client should \u201cTell\u201d a server what \nto do, using a command on the server\u2019s public interface. This guideline \nhas very similar motivations as Law of Demeter, but Tell, Don\u2019t Ask may \nbe easier to apply broadly.\nGiven these guidelines, let\u2019s see how we apply the two design principles to \nProduct:\npublic class Product extends ConcurrencySafeEntity  {\n    ...\n    public void reorderFrom(BacklogItemId anId, int anOrdering) {\n        for (ProductBacklogItem pbi : this.backlogItems()) {\n            pbi.reorderFrom(anId, anOrdering);\n        }\n    }\n    public Set<ProductBacklogItem> backlogItems() {\n        return this.backlogItems;\n    }\n    ...\n}\nwww.EBooksWorld.ir\n", "page": 426, "type": "text", "section": "Page 426"}
{"text": "Chapter 10 AGGREGATES\n384\nThe Product requires clients to use its method reorderFrom() to exe-\ncute a state-modifying command in its contained backlogItems. That is \na good application of the guidelines. Yet, method backlogItems() is also \npublic. Does this break the principles we are trying to follow by exposing \nProductBacklogItem instances to clients? It does expose the collection, but \nclients may use those instances only to query information from them. Because \nof the limited public interface of ProductBacklogItem, clients cannot deter-\nmine the shape of Product by deep navigation. Clients are given least knowl-\nedge. As far as clients are concerned, the returned collection instances may \nhave been created only for the single operation and may represent no definite \nstate of Product. Clients may never execute state-altering commands on the \ninstances of ProductBacklogItem, as its implementation indicates:\npublic class ProductBacklogItem extends ConcurrencySafeEntity  {\n    ...\n    protected void reorderFrom(BacklogItemId anId, int anOrdering) {\n        if (this.backlogItemId().equals(anId)) {\n            this.setOrdering(anOrdering);\n        } else if (this.ordering() >= anOrdering) {\n            this.setOrdering(this.ordering() + 1);\n        }\n    }\n    ...\n}\nIts only state-modifying behavior is declared as a hidden, protected method. \nThus, clients can\u2019t see or reach this command. For all practical purposes, \nonly Product can see it and execute the command. Clients may use only the \nProduct public reorderFrom() command method. When invoked, the \nProduct delegates to all its internal ProductBacklogItem instances to per-\nform the inner modifications.\nThe implementation of Product limits knowledge about itself, is more eas-\nily tested, and is more maintainable, due to the application of these simple \ndesign principles.\nYou will need to weigh the competing forces between use of Law of Deme-\nter and Tell, Don\u2019t Ask. Certainly the Law of Demeter approach is much more \nrestrictive, disallowing all navigation into Aggregate parts beyond the Root. \nOn the other hand, the use of Tell, Don\u2019t Ask allows for navigation beyond \nthe Root but does stipulate that modification of the Aggregate state belongs to \nthe Aggregate, not the client. You may thus find Tell, Don\u2019t Ask to be a more \nbroadly applicable approach to Aggregate implementation.\nwww.EBooksWorld.ir\n", "page": 427, "type": "text", "section": "Page 427"}
{"text": " \nIMPLEMENTATION\n385\nOptimistic Concurrency\nNext, we need to consider where to place the optimistic concurrency version\nattribute. When we contemplate the definition of Aggregate, it could seem saf-\nest to version only the Root Entity. The Root\u2019s version would be incremented \nevery time a state-altering command is executed anywhere inside the Aggre-\ngate boundary, no matter how deep. Using the running example, Product\nwould have a version attribute, and when any of its describeAs(), ini-\ntiateDiscussion(), rename(), or reorderFrom() command methods \nare executed, the version would always be incremented. This would prevent \nany other client from simultaneously modifying any attributes or properties \nanywhere inside the same Product. Depending on the given Aggregate design, \nthis may be difficult to manage, and even unnecessary.\nAssuming we are using Hibernate, when the Product\nname or \ndescription is modified, or its productDiscussion is attached, the \nversion is automatically incremented. That\u2019s a given, because those elements \nare directly held by the Root Entity. However, how do we see to it that the \nProduct version is incremented when any of its backlogItems are reor-\ndered? Actually, we can\u2019t, or at least not automatically. Hibernate will not \nconsider a modification to a ProductBacklogItem part instance as a modi-\nfication to the Product itself. To solve this, perhaps we could just change the \nProduct method reorderFrom(), dirtying some flag or just incrementing \nthe version on our own:\npublic class Product extends ConcurrencySafeEntity  {\n    ...\n    public void reorderFrom(BacklogItemId anId, int anOrdering) {\n        for (ProductBacklogItem pbi : this.backlogItems()) {\n            pbi.reorderFrom(anId, anOrdering);\n        }\n        this.version(this.version() + 1);\n    }\n    ...\n}\nOne problem is that this code always dirties the Product, even when a \nreordering command actually has no effect. Further, this code leaks infra-\nstructural concerns into the model, which is a less desirable domain modeling \nchoice if it can be avoided. What else can be done?\nwww.EBooksWorld.ir\n", "page": 428, "type": "text", "section": "Page 428"}
{"text": "Chapter 10 AGGREGATES\n386\nCowboy Logic\nAJ:  \n\u201cI\u2019m thinkin\u2019 that marriage is a sort of optimistic con-\ncurrency. When a man gets married, he is optimistic \nthat the gal will never change. And at the same time, \nshe\u2019s optimistic that he will.\u201d\nActually in the case of the Product and its ProductBacklogItem\ninstances, it\u2019s possible that we don\u2019t need to modify the Root\u2019s version when \nany backlogItems are modified. Since the collected instances are themselves \nEntities, they can carry their own optimistic concurrency version. If two cli-\nents reorder any of the same ProductBacklogItem instances, the last client \nto commit changes will fail. Admittedly, overlapping reordering would rarely \nif ever happen, because it\u2019s usually only the product owner who reorders the \nproduct backlog items.\nVersioning all Entity parts doesn\u2019t work in every case. Sometimes the only \nway to protect an invariant is to modify the Root version. This can be accom-\nplished more easily if we can modify a legitimate property on the Root. In this \ncase, the Root\u2019s property would always be modified in response to a deeper \npart modification, which in turn causes Hibernate to increment the Root\u2019s \nversion. Recall that this approach was described previously to model the sta-\ntus change on BacklogItem when all of its Task instances have been transi-\ntioned to zero hours remaining.\nHowever, that approach may not be possible in all cases. If not, we may be \ntempted to resort to using hooks provided by the persistence mechanism to \nmanually dirty the Root when Hibernate indicates a part has been modified. \nThis becomes problematic. It can usually be made to work only by maintain-\ning bidirectional associations between child parts and the parent Root. The \nbidirectional associations allow navigation from a child back to the Root when \nHibernate sends a life cycle event to a specialized listener. Not to be forgotten, \nthough, is that [Evans] generally discourages bidirectional associations in most \ncases. This is especially so if they must be maintained only to deal with opti-\nmistic concurrency, which is an infrastructural concern.\nAlthough we don\u2019t want infrastructural concerns to drive modeling deci-\nsions, we may be motivated to travel a less painful route. When modifying the \nRoot becomes very difficult and costly, it could be a strong indication that we \nneed to break down our Aggregates to just a Root Entity, containing only sim-\nple attributes and Value-typed properties. When our Aggregates consist of only \na Root Entity, the Root is always modified when any part is modified.\nwww.EBooksWorld.ir\n", "page": 429, "type": "text", "section": "Page 429"}
{"text": " \nIMPLEMENTATION\n387\nFinally, it must be acknowledged that the preceding scenarios are not a \nproblem when an entire Aggregate is persisted as one value and the value itself \nprevents concurrency conflict. This approach can be leveraged when using \nMongoDB, Riak, Oracle\u2019s Coherence distributed grid, or VMware\u2019s GemFire. \nFor example, when an Aggregate Root implements the Coherence Version-\nable interface and its Repository uses the VersionedPut entry processor, \nthe Root will always be the single object used for concurrency conflict detec-\ntion. Other key-value stores may provide similar conveniences.\nAvoid Dependency Injection\nDependency injection of a Repository or Domain Service into an Aggregate \nshould generally be viewed as harmful. The motivation may be to look up a \ndependent object instance from inside the Aggregate. The dependent object \ncould be another Aggregate, or a number of them. As stated earlier under \n\u201cRule: Reference Other Aggregates by Identity,\u201d preferably dependent objects \nare looked up before an Aggregate command method is invoked, and passed \nin to it. The use of Disconnected Domain Model is generally a less favorable \napproach.\nAdditionally, in a very high-traffic, high-volume, high-performance domain, \nwith heavily taxed memory and garbage collection cycles, think of the poten-\ntial overhead of injecting Repositories and Domain Service instances into \nAggregates. How many extra object references would that require? Some may \ncontend that it\u2019s not enough to tax their operational environment, but theirs \nis probably not the kind of domain being described here. Still, take great care \nnot to add unnecessary overhead that could be easily avoided by using other \ndesign principles, such as looking up dependencies before an Aggregate com-\nmand method is invoked, and passing them in to it.\nThis is only meant to warn against injecting Repositories and Domain Ser-\nvices into Aggregate instances. Of course, dependency injection is quite suit-\nable for many other design situations. For example, it could be quite useful to \ninject Repository and Domain Service references into Application Services.\nwww.EBooksWorld.ir\n", "page": 430, "type": "text", "section": "Page 430"}
{"text": "Chapter 10 AGGREGATES\n388\nWrap-Up\nWe\u2019ve examined how crucial it is to follow the Aggregate Rules of Thumb \nwhen designing Aggregates.\n\u2022 You experienced the negative consequences of modeling large-cluster \nAggregates.\n\u2022 You learned to model true invariants in consistency boundaries.\n\u2022 You considered the advantages of designing small Aggregates.\n\u2022 You now know why you should favor referencing other Aggregates by \nidentity.\n\u2022 You discovered the importance of using eventual consistency outside the \nAggregate boundary.\n\u2022 You saw various implementation techniques, including how you might \nuse Tell, Don\u2019t Ask and Law of Demeter.\nIf we adhere to the rules, we\u2019ll have consistency where necessary and sup-\nport optimally performing and highly scalable systems, all while capturing the \nUbiquitous Language of our business domain in a carefully crafted model.\nwww.EBooksWorld.ir\n", "page": 431, "type": "text", "section": "Page 431"}
{"text": "389\nChapter 11\nFactories\nI can\u2019t abide ugliness in factories! In we go, then! \nBut do be careful, my dear children! \nDon\u2019t lose your heads! Don\u2019t get overexcited! \nKeep very calm!\n\u2014Willy Wonka\nOf all the patterns used in DDD, Factory is probably one of the better known. \nHighly publicized in Design Patterns [Gamma et al.] are Abstract Factory,\nFactory Method, and Builder. I won\u2019t in any way attempt to overshadow the \nadvice given there, or that provided by [Evans]. The focus here is to provide \nexamples of how you can use Factories in the domain model.\nRoad Map to This Chapter\n\u2022 Learn why the use of Factories can produce expressive models that adhere \nto the Ubiquitous Language (1).\n\u2022 See how SaaSOvation uses Factory Methods as Aggregate (10) behaviors.\n\u2022 Consider how to use Factory Methods to create Aggregate instances of other \ntypes.\n\u2022 Learn how Domain Services can be designed as Factories while interact-\ning with other Bounded Contexts (2) and translating foreign objects to local \ntypes.\nFactories in the Domain Model\nConsider the primary motivations for using Factories:\nShift the responsibility for creating instances of complex objects and AGGRE-\nGATES to a separate object, which may itself have no responsibility in the \ndomain model but is still part of the domain design. Provide an interface that \nencapsulates all complex assembly and does not require the client to reference the \nconcrete classes of the objects being instantiated. Create entire AGGREGATES \nas a piece, enforcing their invariants. [Evans, p. 138]\nwww.EBooksWorld.ir\n", "page": 432, "type": "text", "section": "Page 432"}
{"text": "Chapter 11 FACTORIES\n390\nA Factory may or may not have additional responsibilities in the domain model \nother than object creation. An object that has the purpose only of instantiating \na specific Aggregate type will have no other responsibilities and will not even be \nconsidered a first-class citizen of the model. It is only a Factory. An Aggregate \nRoot that provides a Factory Method for producing instances of another Aggre-\ngate type (or inner parts) will have the primary responsibility of providing its \nmain Aggregate behavior, the Factory Method being just one of those.\nThe latter is what tends to occur more frequently in my examples. The \nAggregates I demonstrate have mostly non-complex construction. Yet, some \nimportant details of Aggregate construction must be protected against the pro-\nduction of wrong state. Consider the demands of a multitenancy environment. \nIf an Aggregate instance were created under the wrong tenant, giving it the \nwrong TenantId, it could be disastrous. There is a high degree of account-\nability to keep all data of each tenant segregated and secure from all others. \nPlacing a carefully designed Factory Method on specific Aggregate Roots can \nensure that tenancy and other association identities are created correctly. It \nsimplifies clients, requiring them to pass only basic parameters, often Value \nObjects (6) only, by hiding the construction details from them.\nFurther, Factory Methods on Aggregates allow you to express the Ubiq-\nuitous Language in ways not possible through constructors alone. When the \nbehavioral method name is expressive with respect to the Ubiquitous Lan-\nguage, you\u2019ve made an additional powerful case for using a Factory Method.\nCowboy Logic\nLB:  \n\u201cI used to work in a fire hydrant factory. You couldn\u2019t \npark anywhere near the place.\u201d\nThe sample Bounded Contexts do in some cases require complex construc-\ntion. These situations occur when Integrating Bounded Contexts (13). At those \ntimes Services (7) function as Factories producing Aggregates or Value Objects \nof various types.\nOne case where you would find an Abstract Factory of great benefit is when \ncreating objects of different types in a class hierarchy, which is a classic use. \nThe client is required to pass in only some basic parameters from which the \nFactory can determine the concrete type that must be created. I don\u2019t have any \nwww.EBooksWorld.ir\n", "page": 433, "type": "text", "section": "Page 433"}
{"text": " \nFACTORY METHOD ON AGGREGATE ROOT\n391\ndomain-specific class hierarchies among my examples, so I won\u2019t be demon-\nstrating this usage here. If you see class hierarchies in your future domain \nmodeling efforts, I suggest that you look at the related discussion under Repos-\nitories (12). It will help you enter such an effort with eyes wide open. If you \ndecide to use class hierarchies in your design, be prepared for the potential for \npain that could result.\nFactory Method on Aggregate Root\nThroughout the three sample Bounded Contexts there are Factory sites on \nAggregate Root Entities, of which Table 11.1 provides a summary.\nI discuss the Product Factory Methods under Aggregates (10). For exam-\nple, its method planBacklogItem() creates a new BacklogItem, which is \nan Aggregate that is subsequently returned to the client.\nTo demonstrate the design of Factory Methods, let\u2019s look at the three in the \nCollaboration Context.\nTable 11.1 Sites of Factory Methods on Aggregates\nBounded Context\nAggregate\nFactory Method\nIdentity and Access \nContext\nTenant\nofferRegistrationInvitation()\nprovisionGroup()\nprovisionRole()\nregisterUser()\nCollaboration \nContext\nCalendar\nscheduleCalendarEntry()\nForum\nstartDiscussion()\nDiscussion\npost()\nAgile PM Context\nProduct\nplanBacklogItem()\nscheduleRelease()\nscheduleSprint()\nwww.EBooksWorld.ir\n", "page": 434, "type": "text", "section": "Page 434"}
{"text": "Chapter 11 FACTORIES\n392\nCreating CalendarEntry Instances\nLet\u2019s look at the design. The Factory we are considering now has its site on \nCalendar and is used to create CalendarEntry instances. The Collab-\nOvation team takes us through the implementation.\nHere\u2019s a test developed to demonstrate how the Calendar\nFactory Method should be used:\npublic class CalendarTest extends DomainTest {\n    private CalendarEntry calendarEntry;\n    private CalendarEntryId calendarEntryId;\n    ...\n    public void testCreateCalendarEntry() throws Exception {\n        Calendar calendar = this.calendarFixture();\n        DomainRegistry.calendarRepository().add(calendar);\n        DomainEventPublisher\n            .instance()\n            .subscribe(\n                new DomainEventSubscriber<CalendarEntryScheduled>() {\n                public void handleEvent(\n                        CalendarEntryScheduled aDomainEvent) {\n                    calendarEntryId = aDomainEvent.calendarEntryId();\n                }\n                public Class<CalendarEntryScheduled>\n                        subscribedToEventType() {\n                    return CalendarEntryScheduled.class;\n                }\n            });\n        calendarEntry =\n            calendar.scheduleCalendarEntry(\n                    DomainRegistry\n                        .calendarEntryRepository()\n                        .nextIdentity()\nwww.EBooksWorld.ir\n", "page": 435, "type": "text", "section": "Page 435"}
{"text": " \nFACTORY METHOD ON AGGREGATE ROOT\n393\n                    new Owner(\n                        \"jdoe\",\n                        \"John Doe\",\n                        \"jdoe@lastnamedoe.org\"),\n                    \"Sprint Planning\",\n                    \"Plan sprint for first half of April 2012.\",\n                    this.tomorrowOneHourTimeSpanFixture(),\n                    this.oneHourBeforeAlarmFixture(),\n                    this.weeklyRepetitionFixture(),\n                    \"Team Room\",\n                    new TreeSet<Invitee>(0));\n        DomainRegistry.calendarEntryRepository().add(calendarEntry);\n        assertNotNull(calendarEntryId);\n        assertNotNull(calendarEntry);\n        ...\n    }\n}\nNine parameters are passed in to scheduleCalendarEntry(). Yet, as seen \nlater, the CalendarEntry constructor requires a total of 11 parameters. We\u2019ll con-\nsider the benefits of this in a moment. After a new CalendarEntry is successfully \ncreated, the client must add it to its Repository. Failing to do so will release the new \ninstance to be swept by the garbage collector.\nThe first assertion demonstrates that the CalendarEntryId published with the \nEvent must be non-null, confirming that the Event was successfully published. It\u2019s \nnot that the direct client of Calendar will actually subscribe to that Event, but the test \ndemonstrates that the Event CalendarEntryScheduled is in fact published.\nThe new CalendarEntry instance must also be non-null. We could make addi-\ntional assertions, but the two just shown are most important to documenting the Fac-\ntory Method design and the client\u2019s use of it.\nNow let\u2019s take a look at the implementation of the Factory Method:\npackage com.saasovation.collaboration.domain.model.calendar;\npublic class Calendar extends Entity  {\n    ...\n    public CalendarEntry scheduleCalendarEntry(\n            CalendarEntryId aCalendarEntryId,\n            Owner anOwner,\n            String aSubject,\n            String aDescription,\n            TimeSpan aTimeSpan,\n            Alarm anAlarm,\n            Repetition aRepetition,\n            String aLocation,\n            Set<Invitee> anInvitees) {\nwww.EBooksWorld.ir\n", "page": 436, "type": "text", "section": "Page 436"}
{"text": "Chapter 11 FACTORIES\n394\n        CalendarEntry calendarEntry =\n            new CalendarEntry(\n                    this.tenant(),\n                    this.calendarId(),\n                    aCalendarEntryId,\n                    anOwner,\n                    aSubject,\n                    aDescription,\n                    aTimeSpan,\n                    anAlarm,\n                    aRepetition,\n                    aLocation,\n                    anInvitees);\n        DomainEventPublisher\n            .instance()\n            .publish(new CalendarEntryScheduled(...));\n        return calendarEntry;\n    }\n    ...\n}\nThe Calendar instantiates a new Aggregate, namely, CalendarEntry.\nThe new instance is returned to the client following the Event CalendarEn-\ntryScheduled being published. (The details of the Event published are not \nsignificant to this discussion.) You may note the lack of guards at the top of \nthis method. It is unnecessary to guard the Factory Method itself since the con-\nstructors of each of the Value parameters and the CalendarEntry construc-\ntor, as well as the setter methods that the constructor self-delegates to, provide \nall the needed guards. (See Entities (5) for more details on self-delegation and \nguards.) If you\u2019d like to be doubly cautious, you could add guards here as well.\nThe team designed the method name to adhere to the \nUbiquitous Language. Domain experts, along with the \nrest of the team, discussed the following scenario:\n       Calendars schedule calendar entries.\nIf our design were to support only a public constructor \non CalendarEntry, it would reduce the expressiveness \nof the model and we would not be able to explicitly model \nthat part of the Language of the domain. Using this design \nrequires the full Aggregate constructor to be hidden from \nwww.EBooksWorld.ir\n", "page": 437, "type": "text", "section": "Page 437"}
{"text": " \nFACTORY METHOD ON AGGREGATE ROOT\n395\nclients. We declare the constructor with protected scope, which forces clients to make \nuse of the scheduleCalendarEntry() Factory Method on Calendar:\npublic class CalendarEntry extends Entity  {\n    ...\n    protected CalendarEntry(\n        Tenant aTenant, CalendarId aCalendarId,\n        CalendarEntryId aCalendarEntryId, Owner anOwner,\n        String aSubject, String aDescription, TimeSpan aTimeSpan,\n        Alarm anAlarm, Repetition aRepetition, String aLocation,\n        Set<Invitee> anInvitees) {\n        ...\n    }\n    ...\n}\nWhile having the upside of careful construction, the lowered usage burden on cli-\nents, and an expressive model, using the Calendar Factory Method does have the \ndownside of a bit more performance overhead. As is the case with any such Aggre-\ngate Factory Method, the Calendar will have to be acquired from its persistence \nstore before it can be used to create the CalendarEntry. This extra hit may be well \nworth it, but as the traffic in this Bounded Context increases, the team will have to \nweigh the consequences carefully.\nGermane to the benefits of using Factories is that two of the CalendarEntry\nconstructor parameters are not passed in by clients. Given that there are 11 required \nconstructor parameters, this design unburdens clients, requiring them to supply only \nnine. Most of the nine required parameters are fairly easily created by clients. (Admit-\ntedly the Set of Invitee instances is more involved, but that\u2019s not the fault of the \nFactory Method. The team should think in terms of designing a facility to more con-\nveniently provide this Set, which may be pointing toward the creation of a dedicated \nFactory.)\nStill, the Tenant and associated CalendarId are strictly provided only by the \nFactory Method. This is where we guarantee that CalendarEntry instances are \ncreated only for the correct Tenant and in association with the correct Calendar.\nLet\u2019s now consider one more example from the Collaboration Context.\nCreating Discussion Instances\nLook at the Factory Method on Forum. It has the same motivation and very \nsimilar implementation as the one on Calendar, so there is no need to dive \ninto great detail on it. Yet, there is an additional advantage of using the Fac-\ntory Method here, as the team demonstrates.\nwww.EBooksWorld.ir\n", "page": 438, "type": "text", "section": "Page 438"}
{"text": "Chapter 11 FACTORIES\n396\nConsider the Language-specific startDiscussion() Factory Method on Forum:\npackage com.saasovation.collaboration.domain.model.forum;\npublic class Forum extends Entity  {\n    ...\n    public Discussion startDiscussion(\n            DiscussionId aDiscussionId,\n            Author anAuthor,\n            String aSubject) {\n        if (this.isClosed()) {\n            throw new IllegalStateException(\"Forum is closed.\");\n        }\n        Discussion discussion = new Discussion(\n                this.tenant(),\n                this.forumId(),\n                aDiscussionId,\n                anAuthor,\n                aSubject);\n        DomainEventPublisher\n            .instance()\n            .publish(new DiscussionStarted(...));\n        return discussion;\n    }\n    ...\n}\nBesides creating a Discussion, this Factory Method also guards against cre-\nating one if the Forum is closed. The Forum supplies the Tenant and associ-\nated  \nForumId. Thus, only three of five parameters required to instantiate a new \nDiscussion must be supplied by the client.\nThis Factory Method also expresses the Ubiquitous Language of the Collaboration \nContext. The team used Forum\u2019s startDiscussion() to design in just what the \ndomain experts said it should do:\n        Authors start discussions on forums.\nThis allows the client to be just this simple:\nDiscussion discussion = agilePmForum.startDiscussion(\n    this.discussionRepository.nextIdentity(),\n    new Author(\"jdoe\", \"John Doe\", \"jdoe@saasovation.com\"),\n    \"Dealing with Aggregate Concurrency Issues\");\nwww.EBooksWorld.ir\n", "page": 439, "type": "text", "section": "Page 439"}
{"text": " \nFACTORY ON SERVICE\n397\nassertNotNull(discussion);\n...\nthis.discussionRepository.add(discussion);\nSimple, indeed, which is always a goal of a domain modeler.\nThis Factory Method pattern can repeat as often as necessary. I think it has \nbeen duly demonstrated how effectively Factory Methods on Aggregates can \nbe used to express the Language in Context, reduce the burden on clients when \ncreating new Aggregate instances, and ensure instantiations with correct state.\nFactory on Service\nSince much of how I use Services as Factories is related to Integrating Bounded \nContexts (13), I leave the bulk of the discussion to that chapter. In that chap-\nter my focus is more on integrating with Anti-Corruption Layer (3), Published \nLanguage (3), and Open Host Service (3). Here I want to emphasize the Fac-\ntory itself and how a Service can be designed as one.\nThe team now provides another example from the Collabora-\ntion Context. It\u2019s a Factory in the form of CollaboratorSer-\nvice, producing Collaborator instances from tenant and \nuser identity:\npackage com.saasovation.collaboration.domain.model.collaborator;\nimport com.saasovation.collaboration.domain.model.tenant.Tenant;\npublic interface CollaboratorService  {\n    public Author authorFrom(Tenant aTenant, String anIdentity);\n    public Creator creatorFrom(Tenant aTenant, String anIdentity);\n    public Moderator moderatorFrom(Tenant aTenant, String anIdentity);\n    public Owner ownerFrom(Tenant aTenant, String anIdentity);\nwww.EBooksWorld.ir\n", "page": 440, "type": "text", "section": "Page 440"}
{"text": "Chapter 11 FACTORIES\n398\n    public Participant participantFrom(\n            Tenant aTenant,\n            String anIdentity);\n}\nThis Service provides object translation from the Identity and Access Context to \nthe Collaboration Context. As shown in Bounded Contexts (2), the CollabOvation \nteam doesn\u2019t speak of users when discussing collaboration. It is more to the point \nthat humans in the collaborative media domain are authors, creators, moderators, \nowners, and participants. To accomplish this, the team will need to interact with the \nIdentity and Access Context behind a Service and transform user and role objects \nfrom that model into corresponding collaborator objects of their own model\u2019s Context.\nSince new objects that are derived from the abstract base Collaborator are \ncreated by the Service, it actually functions as a Factory. Taking a look at one of the \ninterface method implementations reveals some of the detail involved:\npackage com.saasovation.collaboration.infrastructure.services;\npublic class UserRoleToCollaboratorService\n        implements CollaboratorService {\n    public UserRoleToCollaboratorService() {\n        super();\n    }\n    @Override\n    public Author authorFrom(Tenant aTenant, String anIdentity) {\n        return\n            (Author)\n                UserInRoleAdapter\n                    .newInstance()\n                    .toCollaborator(\n                            aTenant,\n                            anIdentity,\n                            \"Author\",\n                            Author.class);\n    }\n    ...\n}\nBecause it is a technical implementation, the class is housed in a Module (9) in \nthe Infrastructure Layer.\nThe implementation hitches to the UserInRoleAdapter to morph a Tenant and \nan identity\u2014the user\u2019s username\u2014into an instance of class Author. This Adapter\n[Gamma et al.] interacts with the Open Host Service of the Identity and Access Con-\ntext to confirm that the given user is in the role named Author. If that is true, the \nAdapter delegates to class CollaboratorTranslator to translate the Published \nwww.EBooksWorld.ir\n", "page": 441, "type": "text", "section": "Page 441"}
{"text": " \nFACTORY ON SERVICE\n399\nLanguage integration response to an instance of class Author in the local model. \nThe Author, as well as the other Collaborator subclasses, is a simple Value \nObject:\npackage com.saasovation.collaboration.domain.model.collaborator;\npublic class Author extends Collaborator  {\n    ...\n}\nOther than constructors, equals(), hashCode(), and toString(), each of the \nsubclasses receives all state and behavior from Collaborator:\npackage com.saasovation.collaboration.domain.model.collaborator;\npublic abstract class Collaborator implements Serializable  {\n    private String emailAddress;\n    private String identity;\n    private String name;\n    public Collaborator(\n            String anIdentity,\n            String aName,\n            String anEmailAddress) {\n        super();\n        this.setEmailAddress(anEmailAddress);\n        this.setIdentity(anIdentity);\n        this.setName(aName);\n    }\n    ...\n}\nThe Collaboration Context uses the username as the Collaborator\nidentity attribute. The emailAddress and name are simple String\ninstances. In this model the team has chosen to keep each of these concepts \nas simple as possible. The user\u2019s name, for example, is kept as the full name in \ntext. We\u2019ve managed to separate the life cycles and conceptual terminologies \nfrom the two Bounded Contexts by means of a Service-Based Factory.\nThere is a measure of complexity in UserInRoleAdapter and  \nCollaborator \n-\nTranslator. In a nutshell the UserInRoleAdapter is responsible only for \ncommunicating with the foreign Context. The Collaborator \nTranslator\nis responsible only for translation that results in creation. See Integrating \nBounded Contexts (13) for details.\nwww.EBooksWorld.ir\n", "page": 442, "type": "text", "section": "Page 442"}
{"text": "Chapter 11 FACTORIES\n400\nWrap-Up\nWe examined the reasons for using Factories in DDD and how they often fit \ninto the model.\n\u2022 You now understand why the use of Factories can produce expressive \nmodels that more closely adhere to the Ubiquitous Language in context.\n\u2022 You\u2019ve seen two different Factory Methods implemented as Aggregate \nbehaviors.\n\u2022 This helped you learn how to use Factory Methods to create Aggregate \ninstances of other types, all while ensuring the correct production and use \nof sensitive data.\n\u2022 You also learned how Domain Services can be designed as Factories, even \ninteracting with other Bounded Contexts and translating foreign objects \nto local types.\nNext, we\u2019ll take a look at how Repositories can be designed for two pri-\nmary styles of persistence, along with other implementation choices that must \nbe considered.\nwww.EBooksWorld.ir\n", "page": 443, "type": "text", "section": "Page 443"}
{"text": "401\nChapter 12\nRepositories\nYour eyes are the same color as my storage unit.\n\u2014Overheard at a redneck bar\nA repository commonly refers to a storage location, usually considered a place \nof safety or preservation of the items stored in it. When you store something \nin a repository and later return to retrieve it, you expect that it will be in the \nsame state as it was in when you put it there. At some point you may choose to \nremove the stored item from the repository.\nThis basic set of principles applies to a DDD Repository. Placing an Aggre-\ngate (10) instance in its corresponding Repository, and later using that Repos-\nitory to retrieve the same instance, yields the expected whole object. If you \nalter a preexisting Aggregate instance that you retrieve from the Repository, its \nchanges will be persisted. If you remove the instance from the Repository, you \nwill be unable to retrieve it from that point forward.\nFor each type of object that needs global access, create an object that can provide \nthe illusion of an in-memory collection of all objects of that type. Set up access \nthrough a well-known global interface. Provide methods to add and remove \nobjects. . . . Provide methods that select objects based on some criteria and return \nfully instantiated objects or collections of objects whose attribute values meet the \ncriteria. . . . Provide repositories only for aggregates. . . . [Evans, p. 151]\nThese collection-like objects are all about persistence. Every persistent \nAggregate type will have a Repository. Generally speaking, there is a one-to-\none relationship between an Aggregate type and a Repository. However, some-\ntimes when two or more Aggregate types share an object hierarchy, the types \nmay share a single Repository. Both of these approaches are discussed in this \nchapter.\nRoad Map to This Chapter\n\u2022 Learn about the two different kinds of Repositories and why to use one or the \nother.\n\u2022 See how to implement Repositories for Hibernate, TopLink, Coherence, and \nMongoDB.\ncontinues\nwww.EBooksWorld.ir\n", "page": 444, "type": "text", "section": "Page 444"}
{"text": "Chapter 12 REPOSITORIES\n402\n\u2022 Understand why you might need additional behavior on a Repository\u2019s inter-\nface. Consider how transactions play into the use of Repositories.\n\u2022 Become familiar with the challenges of designing Repositories for type \nhierarchies.\n\u2022 Look at some fundamental differences between Repositories and Data \nAccess Objects [Crupi et al.]. \n\u2022 Consider some ways to test Repositories and how to test using Repositories.\nStrictly speaking, only Aggregates have Repositories. If you are not using \nAggregates in a given Bounded Context (2), the Repository pattern may be less \nuseful. If you are retrieving and using Entities (5) directly in an ad hoc fash-\nion rather than crafting Aggregate transactional boundaries, you may prefer \nto avoid Repositories. However, those less concerned with the tenets of DDD, \nonly using some of its patterns in a technical way, may prefer Repositories \nover Data Access Objects. Still others will think that direct use of a persistence \nmechanism\u2019s Session or Unit of Work [P of EAA] makes more sense. This is not \nto suggest that you should avoid the use of Aggregates. In fact, the opposite is \ntrue. Still, it is an option that some will employ.\nIn my estimation there are two kinds of Repository designs, a collection- \noriented design and a persistence-oriented design. There are circumstances \nunder which a collection-oriented design will work for you, and circumstances \nwhen it is best to use a persistence-oriented design. I first discuss when to use \nand how to create a collection-oriented Repository and follow that with a \ntreatment of persistence-oriented ones.\nCollection-Oriented Repositories\nWe can consider a collection-oriented design a traditional approach because it \nadheres to the basic ideas presented in the original DDD pattern. These very \nclosely mimic a collection, simulating at least some of its standard interface. \nHere you design a Repository interface that does not hint in any way that there \nis an underlying persistence mechanism, avoiding any notion of saving or per-\nsisting data to a store.\nBecause this design approach requires some specific capabilities of the \nunderlying persistence mechanism, it\u2019s possible that it won\u2019t work for you. If \nyour persistence mechanism prevents or hampers your ability to design with a \ncollection perspective, see the following subsection. I address the conditions \nunder which I think collection-oriented design works best. To do so I need to \nestablish some foundational background.\nwww.EBooksWorld.ir\n", "page": 445, "type": "text", "section": "Page 445"}
{"text": " \nCOLLECTION-ORIENTED REPOSITORIES\n403\nConsider how a standard collection works. In Java, C#, or most any other \nobject-oriented language, objects are added to a collection, and they remain in \nthe collection until they are removed. There is no need to do anything special \nto get the collection to recognize changes to the objects that it contains, other \nthan to ask the collection to hand you a reference to a specific object and then \nask that object to do something to itself, which modifies its own state. The \nsame object is still held by the collection, and now the state of that contained \nobject is different from what it was prior to the modification.\nLet\u2019s look at this a bit closer by stepping through a few examples. Using \njava.util.Collection as an example, here, in part, is the standard \ninterface:\npackage java.util;\npublic interface Collection ... {\n    public boolean add(Object o);\n    public boolean addAll(Collection c);\n    public boolean remove(Object o);\n    public boolean removeAll(Collection c);\n    ...\n}\nIf we want to add an object to a collection, we use add(). If we want to \nremove the same object, we pass its reference to remove(). The following \ntest assumes a newly instantiated collection of some kind that can contain \nCalendar instances:\nassertTrue(calendarCollection.add(calendar));\nassertEquals(1, calendarCollection.size());\nassertTrue(calendarCollection.remove(calendar));\nassertEquals(0, calendarCollection.size());\nSimple enough. One special kind of collection, java.util.Set, and its \nimplementing java.util.HashSet, provides the kind of collection that a \nRepository mimics. Every object added to a Set must be unique. If you attempt \nto add an object already contained by the Set, it will not be added because it \nis already contained. Thus, you never need to add the same object twice, as if \nadding it again somehow saves changes that you have asked the object to make \nto itself. The following test assertions prove that adding the same object more \nthan once has no effect, positive or negative:\nwww.EBooksWorld.ir\n", "page": 446, "type": "text", "section": "Page 446"}
{"text": "Chapter 12 REPOSITORIES\n404\nSet<Calendar> calendarSet = new HashSet<Calendar>();\nassertTrue(calendarSet.add(calendar));\nassertEquals(1, calendarSet.size());\nassertFalse(calendarSet.add(calendar));\nassertEquals(1, calendarSet.size());\nAll of these assertions succeed because, although the same Calendar\ninstance is added twice, the second attempt to add the object does not change \nthe state of the Set. The same goes for a Repository designed using a collection \norientation. If we add the Aggregate instance calendar to a CalendarRe-\npository designed with a collection orientation, adding calendar a second \ntime is benign. Each Aggregate has a globally unique identity that is associated \nwith the Root Entity (5, 10). It is this unique identity that allows the Set-like \nRepository to prevent adding the same Aggregate instances more than once.\nIt is important to understand the kind of collection\u2014a Set\u2014that a Repos-\nitory should mimic. Whatever the backing implementation with a specific per-\nsistence mechanism, you must not allow instances of the same object to be \nadded twice.\nAnother key takeaway is that you don\u2019t need to \u201cre-save\u201d modified objects \nalready held by the Repository. Consider again how you\u2019d go about modifying \nan object that is held by a collection. It\u2019s really simple, actually. You\u2019d just \nretrieve from the collection the reference to the object you desire to modify, \nand then ask the object to execute some state-transitioning behavior by invok-\ning a command method.\nTake-aways for Collection-Oriented Repositories\nA Repository should mimic a Set collection. Whatever the backing implementation \nwith a specific persistence mechanism, you must not allow instances of the same \nobject to be added twice. Also, when retrieving objects from a Repository and mod-\nifying them, you don\u2019t need to \u201cre-save\u201d them to the Repository.\nTo illustrate, say we extend (subclass) a standard java.util.HashSet\nand create a method on the new type that allows us to find a specific object \ninstance by unique identity. We\u2019ll give the extending class a name that identi-\nfies it as a Repository, but it\u2019s just an in-memory HashSet:\npublic class CalendarRepository extends HashSet {\n    private Set<CalendarId, Calendar> calendars;\nwww.EBooksWorld.ir\n", "page": 447, "type": "text", "section": "Page 447"}
{"text": " \nCOLLECTION-ORIENTED REPOSITORIES\n405\n    public CalendarRepository() {\n        this.calendars = new HashSet<CalendarId, Calendar>();\n    }\n    public void add(Calendar aCalendar) {\n        this.calendars.add(aCalendar.calendarId(), aCalendar);\n    }\n    public Calendar findCalendar(CalendarId aCalendarId) {\n        return this.calendars.get(aCalendarId);\n    }\n}\nWe don\u2019t normally subclass HashSet in order to create a typical Reposi-\ntory. Here we do so just for the sake of example. So, back to the example. Now \nwe can add a Calendar instance to the specialized Set and later find the \ninstance and ask it to modify itself:\nCalendarId calendarId = new CalendarId(...);\nCalendar calendar =\n    new Calendar(calendarId, \"Project Calendar\", ...);\nCalendarRepository calendarRepository = new CalendarRepository();\ncalendarRepository.add(calendar);\n// later ...\nCalendar calendarToRename =\n    calendarRepository.findCalendar(calendarId);\ncalendarToRename.rename(\"CollabOvation Project Calendar\");\n// even later still ...\nCalendar calendarThatWasRenamed =\n    calendarRepository.findCalendar(calendarId);\nassertEquals(\"CollabOvation Project Calendar\",\n    calendarThatWasRenamed.name());\nNote that the instance of Calendar, referenced by calendarTo \nRename,\nis modified by asking it to rename itself. Much later, after the rename is per-\nformed, the name is still what it was changed to. This was accomplished without \nasking the HashSet subclass CalendarRepository to save changes to the \nCalendar instance, which wouldn\u2019t make any sense.  \nCalendarRepository\ndoesn\u2019t have a save() method because there is no need for one. There is no \nreason to save changes to the Calendar instance that calendarToRename\nwww.EBooksWorld.ir\n", "page": 448, "type": "text", "section": "Page 448"}
{"text": "Chapter 12 REPOSITORIES\n406\nreferences, because the collection still holds a reference to the object being \nmodified, and the modifications are made directly on that object.\nThe bottom line, then, is that a traditional collection-oriented Repository \ntruly mimics a collection in that no parts of the persistence mechanisms are \nsurfaced to the client by its public interface. Therefore, it is our goal to design \nand implement such a collection-oriented Repository with the characteristics \ndemonstrated by a HashSet, but with a persistent data store instead.\nAs you can imagine, this requires some specific capabilities of the backing \npersistence mechanism. The persistence mechanism must in some way support \nthe ability to implicitly track changes made to each persistent object that it \nmanages. This may be accomplished in various ways, including the following \ntwo:\n 1. Implicit Copy-on-Read [Keith & Stafford]: The persistence mechanism \nimplicitly copies each persistent object on read when it is reconstituted from \nthe data store and compares its private copy to the client\u2019s copy on commit. \nStepping through this, when you ask the persistence mechanism to read an \nobject from the data store, it does so and immediately makes a copy of the \nentire object (minus any lazy-loaded parts, which also may be loaded and \ncopied later). When a transaction created through the persistence mecha-\nnism is committed, the persistence mechanism checks for modifications on \nthe copied objects it has loaded (or reattached to) by comparing them. All \nobjects with detected changes are flushed to the data store.\n 2. Implicit Copy-on-Write [Keith & Stafford]: The persistence mechanism \nmanages all loaded persistent objects through a proxy. As each object \nis loaded from the data store, a thin proxy is created and handed to the \nclient. Clients unknowingly invoke behavior on the proxy object, which \nreflects the behavior onto the real object. When the proxy first receives \na method invocation, it makes a copy of the managed object. The proxy \ntracks changes made to the state of the managed object and marks it dirty. \nWhen a transaction created through the persistence mechanism is commit-\nted, it checks for dirty objects and all such are flushed to the data store.\nThe advantages and differences between these approaches may vary, and if \nyour system stands to suffer the negative consequences of choosing one over \nthe other, you should measure them carefully. Of course, you can decide to go \nwith your favorite rather than doing your homework, but that may not be the \nsafest decision.\nStill, the overall advantage to either of these approaches is that persistent \nobject changes are tracked implicitly, requiring no explicit client knowledge \nor intervention to make changes known to the persistence mechanism. The \nwww.EBooksWorld.ir\n", "page": 449, "type": "text", "section": "Page 449"}
{"text": " \nCOLLECTION-ORIENTED REPOSITORIES\n407\nbottom line here is that using a persistence mechanism like this, such as Hiber-\nnate, allows you to employ a traditional, collection-oriented Repository.\nThat said, it is possible even if you have the latitude to use such an implic-\nit-copying change-tracking persistence mechanism, such as Hibernate, that it \nmay be undesirable or inappropriate to use. If your requirements demand a \nvery high-performance domain with many, many objects in memory at any \ngiven time, this sort of mechanism is going to add gratuitous overhead, in both \nmemory and execution. You will have to consider and decide carefully whether \nor not this works for you. Certainly there are many domains in which Hiber-\nnate does work. So don\u2019t take my call to attention as an attempt to declare a \ntaboo. The use of any tool should be with full awareness of trade-offs.\nCowboy Logic\nLB:  \n\u201cWhen my dog got a case of worms, the veterinarian \nprescribed some repositories.\u201d\nThis could lead you to consider the use of a more optimally performing \nobject-relational mapping tool that can support a collection-oriented Reposi-\ntory. One such tool is Oracle\u2019s TopLink, and its nearest relative, EclipseLink. \nTopLink provides a Unit of Work, which is not entirely unlike Hibernate\u2019s \nSession. However, TopLink\u2019s Unit of Work does not make an implicit copy-\non-read. Instead, it makes an Explicit Copy-before-Write [Keith & Stafford]. \nHere the term explicit means that the client must inform the Unit of Work that \nchanges are about to take place. This gives the Unit of Work the opportunity \nto clone the given domain object in preparation for modifications (what it calls \nedits, discussed later in this chapter). The key point is that TopLink consumes \nmemory only when it must.\nHibernate Implementation\nThere are two primary steps to creating either orientation of a Repository. You \nneed to define a public interface and at least one implementation.\nSpecifically in the case of a collection-oriented design, in the first step you \ndefine an interface that mimics a collection. The second step provides an imple-\nmentation that addresses the use of the backing primary storage mechanism, \nsuch as Hibernate. The interface, like a collection, will often have common \nmethods such as are found in the following example:\nwww.EBooksWorld.ir\n", "page": 450, "type": "text", "section": "Page 450"}
{"text": "Chapter 12 REPOSITORIES\n408\npackage com.saasovation.collaboration.domain.model.calendar;\npublic interface CalendarEntryRepository  {\n    public void add(CalendarEntry aCalendarEntry);\n    public void addAll(\n            Collection<CalendarEntry> aCalendarEntryCollection);\n    public void remove(CalendarEntry aCalendarEntry);\n    public void removeAll(\n            Collection<CalendarEntry> aCalendarEntryCollection);\n    ...\n}\nPlace the interface definition in the same Module (9) as the Aggregate type \nthat it stores. In this case interface CalendarEntryRepository is placed \nin the same Module (Java package) as CalendarEntry. The implementation \nclass goes in a separate package, as discussed later.\nInterface CalendarEntryRepository has methods that are very much \nlike those provided by collections, such as the standard java.util.Collection.\nOne new CalendarEntry may be added to this Repository using add().\nMultiple new instances may be added using addAll(). Once the instances \nhave been added, they will be persisted to some sort of data store and be \nretrievable by unique identity from that point forward. The antithesis of those \nmethods is remove() and removeAll(), allowing for the removal of one or \nmultiple instances from the collection.\nI personally don\u2019t like these methods to answer Boolean results as do full-\nfledged collections. That\u2019s because in some cases answering true to an add-\ntype operation does not guarantee success. The true results may still be \nsubject to a transaction commit on the data store. Thus, void may be the more \naccurate return type in the case of a Repository.\nThere may be cases where adding and/or removing multiple Aggregate \ninstances in one transaction isn\u2019t appropriate. When that is true of a given case \nin your domain, don\u2019t include methods addAll() and removeAll(). How-\never, these methods are provided only for convenience. A client can always use \na loop to invoke add() or remove() multiple times when iterating over a col-\nlection on its own. So eliminating the addAll() and removeAll() methods \nis only symbolic of a policy that can\u2019t actually be enforced by design, unless \nyou also build in a means to detect adding and removing multiple objects in \na single transaction. Doing so would likely require such a Repository to be \ninstantiated for every transaction, which is a potentially costly proposal. I \nwon\u2019t discuss this further.\nIt is possible that instances of some Aggregate types must never be removed \nthrough normal application use cases. It may be necessary to retrain the \nwww.EBooksWorld.ir\n", "page": 451, "type": "text", "section": "Page 451"}
{"text": " \nCOLLECTION-ORIENTED REPOSITORIES\n409\ninstance long after it is no longer usable in the application, possibly for refer-\nential and/or historical purposes. Referentially it may actually be very difficult \nor impossible to remove some objects. From a business perspective it may be \nunwise, ill advised, or even illegal to remove some objects. In those cases you \nmay decide to simply mark the Aggregate instance disabled, unusable, or, in \nsome other domain-specific way, logically removed. If so, you may determine \nnot to include any removal methods on the Repository public interface, or you \nmay decide to implement the removal methods to set the unusable state of the \nAggregate instance. You may instead prevent full object removal through code \nreviews, where clients are carefully inspected to ensure that no such uses of \nremoval behavior exist. It\u2019s a decision to ponder, but you may find it easier to \ndisallow removal altogether. After all, any methods on public interfaces are \ngenerally considered available for use. If removal is publicly available when \nlogically disallowed, you probably want to consider implementing logical \nrather than physical removal.\nAnother important part of the Repository interface is the definition of finder \nmethods:\npublic interface CalendarEntryRepository  {\n    ...\n    public CalendarEntry calendarEntryOfId(\n            Tenant aTenant,\n            CalendarEntryId aCalendarEntryId);\n    public Collection<CalendarEntry> calendarEntriesOfCalendar(\n            Tenant aTenant,\n            CalendarId aCalendarId);\n    public Collection<CalendarEntry> overlappingCalendarEntries(\n            Tenant aTenant,\n            CalendarId aCalendarId,\n            TimeSpan aTimeSpan);\n}\nThe first method definition, calendarEntryOfId(), allows you to retrieve \na specific instance of the CalendarEntry Aggregate by unique identity. This \ntype uses an explicit identity type, namely, CalendarEntryId. The second \nmethod definition, calendarEntriesOfCalendar(), allows you to retrieve \na collection of all CalendarEntry instances for a specific  \nCalendar by its \nunique identity. Finally, the third finder method definition, overlapping-\nCalendarEntries(), provides a collection of all CalendarEntry instances \nfor a specific Calendar over a specific TimeSpan. In particular, this method \nsupports retrieving what is scheduled over a particular contiguous period of \ndates and times.\nwww.EBooksWorld.ir\n", "page": 452, "type": "text", "section": "Page 452"}
{"text": "Chapter 12 REPOSITORIES\n410\nFinally, you may be wondering how a CalendarEntry is assigned its glob-\nally unique identity. This also can be conveniently provided by the Repository:\npublic interface CalendarEntryRepository  {\n    public CalendarEntryId nextIdentity();\n    ...\n}\nAny code responsible for instantiating new CalendarEntry instances uses \nnextIdentity() to get a new instance of CalendarEntryId:\nCalendarEntry calendarEntry =\n    new CalendarEntry(tenant, calendarId,\n            calendarEntryRepository.nextIdentity(),\n            owner, subject, description, timeSpan, alarm,\n            repetition, location, invitees);\nSee Entities (5) for an exhaustive discussion of identity creation techniques, \nthe use of domain-specific and surrogate identities, and the importance of \nproperly timing the assignment of identity.\nLet\u2019s now look at the implementation class for this traditional Repository. \nThere are a few options for selecting the Module in which to place the class. \nSome like to use a Module (Java package) directly under the Aggregate and \nRepository Module. In this case that would mean\npackage com.saasovation.collaboration.domain.model.calendar.impl;\npublic class HibernateCalendarEntryRepository\n        implements CalendarEntryRepository  {\n    ...\n}\nPlacing the class here allows you to manage the implementation in the Domain \nLayer, but in a special package for implementations. That way you keep the \ndomain concepts cleanly separated from those that directly deal with per-\nsistence. This style of declaring interfaces in a richly named package, and their \nimplementations in a sub-package named impl directly under it, is widely \npracticed in Java projects. However, in the case of the Collaboration Context\nthe team has chosen to locate all technical implementation classes in the Infra-\nstructure Layer:\nwww.EBooksWorld.ir\n", "page": 453, "type": "text", "section": "Page 453"}
{"text": " \nCOLLECTION-ORIENTED REPOSITORIES\n411\npackage com.saasovation.collaboration.infrastructure.persistence;\npublic class HibernateCalendarEntryRepository\n        implements CalendarEntryRepository  {\n    ...\n}\nThis uses the Dependency Inversion Principle (4), or DIP, for layering infra-\nstructure concerns. The Infrastructure Layer is logically above all others, mak-\ning references unidirectional and downward to the Domain Layer.\nClass HibernateCalendarEntryRepository is a registered Spring \nbean. It has a zero-argument constructor and has another infrastructure bean \nobject dependency injected:\nimport com.saasovation.collaboration.infrastructure\n        .persistence.SpringHibernateSessionProvider;\npublic class HibernateCalendarEntryRepository\n        implements CalendarEntryRepository  {\n    public HibernateCalendarEntryRepository() {\n        super();\n    }\n    ...\n    private SpringHibernateSessionProvider sessionProvider;\n    public void setSessionProvider(\n            SpringHibernateSessionProvider aSessionProvider) {\n        this.sessionProvider = aSessionProvider;\n    }\n    private org.hibernate.Session session() {\n        return this.sessionProvider.session();\n    }\n}\nClass SpringHibernateSessionProvider is also housed in the Infra-\nstructure Layer in the com.saasovation.collaboration.infrastruc-\nture.persistence Module and is injected into each Hibernate-based \nRepository. Each method that uses Hibernate\u2019s Session object self-invokes \nmethod  \nsession() to get it. Method session() uses the dependency-in-\njected  \nsessionProvider instance to get the thread-bound Session instance \n(seen later in this chapter).\nwww.EBooksWorld.ir\n", "page": 454, "type": "text", "section": "Page 454"}
{"text": "Chapter 12 REPOSITORIES\n412\nMethods add(), addAll(), remove(), and removeAll() are imple-\nmented as follows:\npackage com.saasovation.collaboration.infrastructure.persistence;\npublic class HibernateCalendarEntryRepository\n        implements CalendarEntryRepository  {\n    ...\n    @Override\n    public void add(CalendarEntry aCalendarEntry) {\n        try {\n            this.session().saveOrUpdate(aCalendarEntry);\n        } catch (ConstraintViolationException e) {\n            throw new IllegalStateException(\n                    \"CalendarEntry is not unique.\", e);\n        }\n    }\n    @Override\n    public void addAll(\n            Collection<CalendarEntry> aCalendarEntryCollection) {\n        try {\n            for (CalendarEntry instance : aCalendarEntryCollection) {\n                this.session().saveOrUpdate(instance);\n            }\n        } catch (ConstraintViolationException e) {\n            throw new IllegalStateException(\n                    \"CalendarEntry is not unique.\", e);\n        }\n    }\n    @Override\n    public void remove(CalendarEntry aCalendarEntry) {\n        this.session().delete(aCalendarEntry);\n    }\n    @Override\n    public void removeAll(\n            Collection<CalendarEntry> aCalendarEntryCollection) {\n        for (CalendarEntry instance : aCalendarEntryCollection) {\n            this.session().delete(instance);\n        }\n    }\n    ...\n}\nThese methods have rather simplistic implementations. Each method self- \ninvokes session() to get its Hibernate Session instance (as just previously \nexplained).\nwww.EBooksWorld.ir\n", "page": 455, "type": "text", "section": "Page 455"}
{"text": " \nCOLLECTION-ORIENTED REPOSITORIES\n413\nPerhaps curiously, methods add() and addAll() use the Session\u2019s \nmethod saveOrUpdate(). This is further support for Set-like adds. If a cli-\nent happens to add the same CalendarEntry more than once, the saveOr-\nUpdate() behavior makes it appear as a benign no-op. In fact, since Hibernate \nversion 3 any form of update is a no-op since, as previously noted, updates are \ntracked implicitly by object state modifications. Therefore, unless the objects \nadded by these two methods are entirely new, the behavior does nothing.\nAdding can cause a ConstraintViolationException. Rather than \nallowing Hibernate exceptions to trickle out to clients, those exceptions are \ncaught and wrapped by the more client-friendly IllegalStateException.\nWe could also declare domain-specific exceptions and throw those. That is a \nchoice for each project team. The main point is that since we are going to the \ntrouble of abstracting away the implementation details of the underlying per-\nsistence framework, we want to insulate clients from all such details, including \nexceptions.\nMethods remove() and removeAll() are quite simple. They only need \nto use the Session delete() to facilitate removal from the underlying data \nstore. There is one additional detail regarding the removal of Aggregates that \nuse one-to-one mappings, which is true in one case in the Identity and Access \nContext. Because you cannot cascade changes on such relationships, you will \nneed to explicitly delete objects on both sides of the association:\npackage com.saasovation.identityaccess.infrastructure.persistence;\npublic class HibernateUserRepository implements UserRepository  {\n    ...\n    @Override\n    public void remove(User aUser) {\n        this.session().delete(aUser.person());\n        this.session().delete(aUser);\n    }\n    @Override\n    public void removeAll(Collection<User> aUserCollection) {\n        for (User instance : aUserCollection) {\n            this.session().delete(instance.person());\n            this.session().delete(instance);\n        }\n    }\n    ...\n}\nThe inner Person object must first be deleted, and then the User Aggre-\ngate Root. If you do not delete the inner Person object, it will be orphaned \nwww.EBooksWorld.ir\n", "page": 456, "type": "text", "section": "Page 456"}
{"text": "Chapter 12 REPOSITORIES\n414\nin its corresponding database table. In general this is a good reason to avoid \none-to-one associations and instead use a constrained singular many-to-one \nunidirectional association. However, I chose to implement the one-to-one bidi-\nrectional association purposely in order to demonstrate what working with the \nmore troublesome mappings involves.\nNote that there are different preferred approaches for dealing with such sit-\nuations. Some may choose to depend on ORM life cycle events to cause part \nobject cascading deletes. I have purposely avoided such approaches because I \nam a strong opponent of Aggregate-managed persistence, and I strongly advo-\ncate Repository-only persistence. The arguments are passionate and never-end-\ning, ad nauseam. You should make an informed choice, but understand that \nDDD experts avoid Aggregate-managed persistence as a rule of thumb.\nNow back to HibernateCalendarEntryRepository and its finder \nmethod implementations:\npublic class HibernateCalendarEntryRepository\n        implements CalendarEntryRepository {\n    ...\n    @Override\n    @SuppressWarnings(\"unchecked\")\n    public Collection<CalendarEntry> overlappingCalendarEntries(\n        Tenant aTenant, CalendarId aCalendarId, TimeSpan aTimeSpan) {\n        Query query =\n            this.session().createQuery(\n                \"from CalendarEntry as _obj_ \" +\n                \"where _obj_.tenant = :tenant and \" +\n                  \"_obj_.calendarId = :calendarId and \" +\n                  \"((_obj_.repetition.timeSpan.begins between \" +\n                      \":tsb and :tse) or \" +\n                  \" (_obj_.repetition.timeSpan.ends between \" +\n                      \":tsb and :tse))\");\n        query.setParameter(\"tenant\", aTenant);\n        query.setParameter(\"calendarId\", aCalendarId);\n        query.setParameter(\"tsb\", aTimeSpan.begins(), Hibernate.DATE);\n        query.setParameter(\"tse\", aTimeSpan.ends(), Hibernate.DATE);\n        return (Collection<CalendarEntry>) query.list();\n    }\n    @Override\n    public CalendarEntry calendarEntryOfId(\n            Tenant aTenant,\n            CalendarEntryId aCalendarEntryId) {\n        Query query =\n            this.session().createQuery(\n               \"from CalendarEntry as _obj_ \" +\n               \"where _obj_.tenant = ? and _obj_.calendarEntryId = ?\");\nwww.EBooksWorld.ir\n", "page": 457, "type": "text", "section": "Page 457"}
{"text": " \nCOLLECTION-ORIENTED REPOSITORIES\n415\n        query.setParameter(0, aTenant);\n        query.setParameter(1, aCalendarEntryId);\n        return (CalendarEntry) query.uniqueResult();\n    }\n    @Override\n    @SuppressWarnings(\"unchecked\")\n    public Collection<CalendarEntry> calendarEntriesOfCalendar(\n        Tenant aTenant, CalendarId aCalendarId) {\n        Query query =\n            this.session().createQuery(\n                \"from CalendarEntry as _obj_ \" +\n                \"where _obj_.tenant = ? and _obj_.calendarId = ?\");\n        query.setParameter(0, aTenant);\n        query.setParameter(1, aCalendarId);\n        return (Collection<CalendarEntry>) query.list();\n    }\n    ...\n}\nEach of the three finders creates a Query through its Session. As is com-\nmon with Hibernate queries, the team uses HQL to describe the criteria and \nthen loads up the parameter objects. The query is then run, asking for either \na singular, unique result or a list collection of objects. The more sophisticated \nof the thread queries is that of overlappingCalendarEntries(), in which \ncase we must find all CalendarEntry instances that overlap a specific date \nand time range, or TimeSpan.\nLast we look at the implementation of method nextIdentity():\npublic class HibernateCalendarEntryRepository\n        implements CalendarEntryRepository  {\n    ...\n    public CalendarEntryId nextIdentity() {\n        return new CalendarEntryId(\n                UUID.randomUUID().toString().toUpperCase());\n    }\n    ...\n}\nThis particular implementation does not use the persistence mechanism or \ndata store to generate a unique identity. Rather, the relatively fast and very \nreliable UUID generator is used.\nwww.EBooksWorld.ir\n", "page": 458, "type": "text", "section": "Page 458"}
{"text": "Chapter 12 REPOSITORIES\n416\nConsiderations for a TopLink Implementation\nTopLink has both a Session and a Unit of Work. This differs somewhat from \nHibernate in that Hibernate\u2019s Session is also a Unit of Work.1 Let\u2019s look at a \nperspective on the use of Unit of Work as separate from Session, and then ease \ninto how to use them in a Repository implementation.\nWithout the benefit of a Repository abstraction, you\u2019d use TopLink in this way:\nCalendar calendar = session.readObject(...);\nUnitOfWork unitOfWork = session.acquireUnitOfWork();\nCalendar calendarToRename = unitOfWork.registerObject(calendar);\ncalendarToRename.rename(\"CollabOvation Project Calendar\");\nunitOfWork.commit();\nThe UnitOfWork provides a much more efficient use of memory and pro-\ncessing power since you must explicitly inform the UnitOfWork that you \nintend to modify the object. It is not until that time that a clone, or editing \ncopy, of your Aggregate is made. As shown previously, method register-\nObject() answers a clone of the original Calendar instance. It is this clone \nobject, referenced by calendarToRename, that must be edited/modified. As \nyou cause modifications on the object, TopLink is able to track the changes \nthat occur. When method commit() on UnitOfWork is invoked, all modified \nobjects are committed to the database.2\nAdding new objects to a TopLink Repository can be facilitated easily \nenough:\n    ...\n    public void add(Calendar aCalendar) {\n        this.unitOfWork().registerNewObject(aCalendar);\n    }\n    ...\n 1. I am not measuring TopLink\u2019s value in terms of Hibernate. In fact, TopLink has a \nvery long history of success, which was established long before Oracle picked up \nthe product as a result of the WebGain debacle and subsequent \u201cfire sale.\u201d Top is \nan acronym for \u201cThe Object People,\u201d which was the original company behind the \ntool that is approaching two decades of proven success. Here I am merely contrast-\ning the way the two tools work.\n 2. This assumes that the Unit of Work is not nested inside a parent. If it is nested \ninside a parent Unit of Work, changes from the committed Unit of Work are \nmerged with its parent. Ultimately the outermost is committed to the database.\nwww.EBooksWorld.ir\n", "page": 459, "type": "text", "section": "Page 459"}
{"text": " \nCOLLECTION-ORIENTED REPOSITORIES\n417\nThe use of registerNewObject() \nstipulates that aCalendar is a new \ninstance. This would enforce failure if add() was invoked with aCalendar\nthat is actually preexisting. We could also use the vanilla registerObject()\nhere, which would be similar to using Hibernate\u2019s saveOrUpdate() method \n(discussed earlier). Either way we satisfy the need for a workable collection- \noriented interface.\nBut we still need a way to acquire a clone when we have to modify a pre-\nexisting Aggregate. The trick is to find a convenient way to register such an \nAggregate instance with a UnitOfWork. So far our discussion hasn\u2019t provided \na Repository interface to do that because we\u2019ve been trying to mimic a Set\nand avoid any inference to persistence in the interface. Still, we could accom-\nplish this in a way that doesn\u2019t necessarily influence a persistence frame of \nmind. Consider using one of two approaches:\npublic Calendar editingCopy(Calendar aCalendar);\n// or\npublic void useEditingMode();\nWith the first approach editingCopy() would acquire a UnitOfWork, reg-\nister the given Calendar instance, get its clone, and answer it:\n    ...\n    public Calendar editingCopy(Calendar aCalendar) {\n        return (Calendar) this.unitOfWork().registerObject(aCalendar);\n    }\n    ...\nThis reflects the underlying registerObject() way of doing things. Under-\nstandably this may not be desirable, but it is a clean approach and doesn\u2019t \nreflect a persistence frame of mind.\nThe second approach is to place the Repository into editing mode with \nuseEditingMode(). After this is done, all subsequent finder methods will \nautomatically register all objects they query with a backing UnitOfWork\nand answer the clones. It does more or less lock the Repository into use for \nAggregate modifications. That is, nonetheless, how Repositories tend to be \nused, either read-only or read for modification. It also reflects the use of a \nRepository for Aggregates that have well-crafted boundaries that reflect a bias \ntoward transactional success.\nThere may be other ways to design a collection-oriented repository for \nTopLink, but this provides a few options worth considering.\nwww.EBooksWorld.ir\n", "page": 460, "type": "text", "section": "Page 460"}
{"text": "Chapter 12 REPOSITORIES\n418\nPersistence-Oriented Repositories\nFor times when a collection-oriented style doesn\u2019t work, you will need to \nemploy a persistence-oriented, save-based Repository. This will be the case \nwhen your persistence mechanism doesn\u2019t implicitly or explicitly detect and \ntrack object changes. This happens to be the case when using an in-memory \nData Fabric (4), or by any other name a NoSQL key-value data store. Every \ntime you create a new Aggregate instance or change a preexisting one, you will \nhave to put it into the data store by using save() or a save-like Repository \nmethod.\nThere is another consideration for choosing a persistence-oriented approach, \neven if you are using an object-relational mapper that supports a collection-ori-\nented approach. What would happen if you designed collection-oriented Repos-\nitories and then decided to swap out your relational database with a key-value \nstore? You\u2019d have a lot of ripple through your Application Layer as it would \nhave to be changed to use save() in all places where Aggregate updates occur. \nYou\u2019d also want to rid your Repositories of add() and addAll(), because \nthose would no longer pertain. In cases where it is a very realistic possibility \nthat your persistence mechanism will shift in the future, it might be best to \ndesign with the more flexible interface in mind. The downside is that your \ncurrent object-relational mapper may cause you to leave out necessary uses of \nsave() that you may catch only later when there is no longer a backing Unit \nof Work.3 The upside is that the Repository pattern will allow you to com-\npletely replace your persistence mechanism with potentially little impact on \nyour application.\nTake-aways for Persistence-Oriented Repositories\nWe must explicitly put() both new and changed objects into the store, effectively \nreplacing any value previously associated with the given key. Using these kinds of \ndata stores greatly simplifies the basic writes and reads of Aggregates. For this rea-\nson they are sometimes called Aggregate Stores or Aggregate-Oriented Databases.\nWhen using an in-memory Data Fabric, such as GemFire or Oracle Coher-\nence, the storage is an in-memory Map implementation mimicking java.util\n.HashMap, where each mapped element is considered an entry. Similarly, when \nusing a NoSQL store such as MongoDB or Riak, object persistence gives the \nillusion of something like a collection, instead of tables, rows, and columns. \n 3. You could create Application Service (14) tests that account for updating saves as \nnecessary. An in-memory Repository implementation (see the main text later in \nthe chapter) could be designed to audit the thoroughness of saves.\nwww.EBooksWorld.ir\n", "page": 461, "type": "text", "section": "Page 461"}
{"text": " \nPERSISTENCE-ORIENTED REPOSITORIES\n419\nThese store key-value pairs. This is effectively a Map-like store, but it uses disk \nrather than memory as its primary persistence medium.\nAlthough both of these styles of persistence mechanisms roughly mimic a \nMap collection, we must unfortunately explicitly put() both new and changed \nobjects into the store, effectively replacing the value previously associated with \nthe given key. That\u2019s true even when a changed object is logically the same \nobject that is already stored, because these typically don\u2019t provide a Unit of \nWork to track changes or support transaction demarcation to control atomic \nwrites. Rather, each put() and putAll() represents a separate logical \ntransaction.\nUsing either of these kinds of data stores greatly simplifies the basic writes \nand reads of Aggregates. For example, consider the simplicity of adding this \nProduct (Agile Project Management Context) to a Coherence data grid, and \nthen reading it back again:\ncache.put(product.productId(), product);\n// later ...\nproduct = cache.get(productId);\nHere the Product instance is automatically serialized to the Map using stan-\ndard Java serialization. This simplistic interface can be a bit deceptive, how-\never. If you want really high-performing domains, there is a bit more to do. \nCoherence supports standard Java serialization when a custom serialization \nprovider is not registered. Using the standard Java serialization is not generally \nthe best option. It requires a premium of bytes to represent each object, and it \nperforms relatively poorly.4 You don\u2019t want to purchase a high-performance \nData Fabric and then hamstring it by reducing the number of objects it can \ncache and reduce the overall throughput using slow serialization. So keep in \nmind that when using a Data Fabric, for example, distribution is introduced \ninto your system. That will often bring a new force into domain model design, \nnamely, custom or at least specialized serialization. That can cause you to \nmake different decisions, at least at an implementation level.\nSo when using the GemFire or Coherence caches, the MongoDB or Riak \nkey-value stores, or some other kind of NoSQL persistence, you will probably \nwant to use a fast and compact means to convert Aggregates to their serialized/\n 4. It also limits your Coherence clients to Java only, when .NET and C++ clients \ncould also use the grid data if you were to provide Portable Object Format (POF) \nserialization.\nwww.EBooksWorld.ir\n", "page": 462, "type": "text", "section": "Page 462"}
{"text": "Chapter 12 REPOSITORIES\n420\ndocument form and then back again to their object form. Granted, attacking \nthese challenges isn\u2019t that difficult. For instance, creating an optimal serializa-\ntion for an Aggregate persisted by GemFire or Coherence is no more challeng-\ning than creating mapping descriptions for an object-relational mapper. But it\u2019s \nnot as easy as just using put() \nand get() \non a Map.\nNext, I demonstrate how a persistence-oriented Repository can be created \nfor Coherence, and following that I highlight some techniques for doing the \nsame for MongoDB.\nCoherence Implementation\nAs we did with the collection-oriented Repository, we first define an inter-\nface and then its implementation. Here\u2019s a persistence-oriented interface that \ndefines save-based methods that are used for the Oracle Coherence data grid:\npackage com.saasovation.agilepm.domain.model.product;\nimport java.util.Collection;\nimport com.saasovation.agilepm.domain.model.tenant.Tenant;\npublic interface ProductRepository  {\n    public ProductId nextIdentity();\n    public Collection<Product> allProductsOfTenant(Tenant aTenant);\n    public Product productOfId(Tenant aTenant, ProductId aProductId);\n    public void remove(Product aProduct);\n    public void removeAll(Collection<Product> aProductCollection);\n    public void save(Product aProduct);\n    public void saveAll(Collection<Product> aProductCollection);\n}\nThis ProductRepository is not entirely unlike the CalendarEntryRe-\npository from the previous section. It differs only in the way it allows Aggre-\ngate instances to be included in the mimicked collection. In this case we have \nsave() and saveAll() methods rather than add() and addAll() methods. \nBoth method styles logically do similar things. The main difference is how the \nclient uses the methods. To reiterate, when using a collection-oriented style, \nAggregate instances are added only when they are created. When using a per-\nsistence-oriented style, Aggregate instances must be saved both when they are \ncreated and when they are modified:\nProduct product = new Product(...);\nproductRepository.save(product);\nwww.EBooksWorld.ir\n", "page": 463, "type": "text", "section": "Page 463"}
{"text": " \nPERSISTENCE-ORIENTED REPOSITORIES\n421\n// later ...\nProduct product =\n    productRepository.productOfId(tenantId, productId);\nproduct.reprioritizeFrom(backlogItemId, orderOfPriority);\nproductRepository.save(product);\nOther than that, the details are in the implementation. So let\u2019s dive right \ninto that. First take a look at the Coherence infrastructure we need to make \nthe leap to the data grid cache:\npackage com.saasovation.agilepm.infrastructure.persistence;\nimport com.tangosol.net.CacheFactory;\nimport com.tangosol.net.NamedCache;\npublic class CoherenceProductRepository\n        implements ProductRepository {\n    private Map<Tenant,NamedCache> caches;\n    public CoherenceProductRepository() {\n        super();\n        this.caches = new HashMap<Tenant,NamedCache>();\n    }\n    ...\n    private synchronized NamedCache cache(TenantId aTenantId) {\n        NamedCache cache = this.caches.get(aTenantId);\n        if (cache == null) {\n            cache = CacheFactory.getCache(\n                    \"agilepm.Product.\" + aTenantId.id(),\n                    Product.class.getClassLoader());\n            this.caches.put(aTenantId, cache);\n        }\n        return cache;\n    }\n    ...\n}\nIn the case of the Agile Project Management Context, the team has chosen \nto place Repository technical implementations in the Infrastructure Layer.\nAlong with a simple zero-argument constructor, there is the Coherence \nlinchpin, the NamedCache. Among other imports, note those that are specific \nto creating or attaching to and using a cache, CacheFactory and Named-\nCache. Both of these classes are in package com.tangosol.net.\nwww.EBooksWorld.ir\n", "page": 464, "type": "text", "section": "Page 464"}
{"text": "Chapter 12 REPOSITORIES\n422\nThe private method cache() is the means by which a NamedCache is \nobtained. The method lazily gets the cache on the Repository\u2019s first attempt to \nuse it. This is primarily because each cache is named for the specific Tenant\nand the Repository must wait for a public method to be invoked before it has \naccess to a TenantId. There are various Coherence named cache strategies \nthat could be designed. In this case the team has chosen to cache using the fol-\nlowing namespace:\n 1. First level by the Bounded Context short name: agilepm\n 2. Second level by the Aggregate simple name: Product\n 3. Third level by the unique identity of each tenant: TenantId\nThis has a few benefits. First, the model of each Bounded Context, Aggre-\ngate, and tenant that is managed by Coherence can be tuned and scaled sep-\narately. Also, each tenant is completely segregated from all others, so there \nis no way that queries for one tenant can accidentally include the objects of \nother tenants. This is the same motivation used when \u201cstriping\u201d each entity \ntable with the tenant identity in a MySQL persistence solution, yet it is even \ncleaner in this case. Further, anytime a finder method is required to answer all \nAggregate instances for a given tenant, there is actually no query required. The \nfinder method just asks Coherence for all entries in the cache. You\u2019ll see this \noptimization later with the implementation of allProductsOfTenant().\nAs each NamedCache is created or attached to, it is placed into the Map\nassociated with the caches instance variable. This allows each cache to be \nlooked up quickly by TenantId on all uses subsequent to the first.\nThere are far too many Coherence configuration and tuning considerations \nto address here. It\u2019s an entire discussion on its own, and the literature already \ngoes into this. I\u2019ll leave it to Aleks Seovi\u00fe to cover this topic [Seovi\u00fe]. Now on \nwith the implementation:\npublic class CoherenceProductRepository\n        implements ProductRepository {\n    ...\n    @Override\n    public ProductId nextIdentity() {\n        return new ProductId(\n                java.util.UUID.randomUUID()\n                    .toString()\n                    .toUpperCase());\n    }\n    ...\n}\nwww.EBooksWorld.ir\n", "page": 465, "type": "text", "section": "Page 465"}
{"text": " \nPERSISTENCE-ORIENTED REPOSITORIES\n423\nThe nextIdentity() method of the ProductRepository is imple-\nmented in the same fashion as that of the CalendarEntryRepository. It \ngrabs a UUID and uses it to instantiate a ProductId, which it then answers:\npublic class CoherenceProductRepository\n        implements ProductRepository {\n    ...\n    @Override\n    public void save(Product aProduct) {\n        this.cache(aProduct.tenantId())\n                .put(this.idOf(aProduct), aProduct);\n    }\n    @Override\n    public void saveAll(Collection<Product> aProductCollection) {\n        if (!aProductCollection.isEmpty()) {\n            TenantId tenantId = null;\n            Map<String,Product> productsMap =\n                new HashMap<String,Product>(aProductCollection.size());\n            for (Product product : aProductCollection) {\n                if (tenantId == null) {\n                    tenantId = product.tenantId();\n                }\n                productsMap.put(this.idOf(product), product);\n            }\n            this.cache(tenantId).putAll(productsMap);\n        }\n    }\n    ...\n    private String idOf(Product aProduct) {\n        return this.idOf(aProduct.productId());\n    }\n    private String idOf(ProductId aProductId) {\n        return aProductId.id();\n    }\n}\nTo persist a single new or modified Product instance to the data grid, use \nsave(). The save() method uses cache() to get the NamedCache instance \nfor the TenantId of the Product. It then puts the Product instance into the \nNamedCache. Note the use of method idOf(), which has two editions, one \nfor a Product and the other for a ProductId. In both cases these methods \nanswer the String form of the Product\u2019s unique identity, or ProductId. So \nwww.EBooksWorld.ir\n", "page": 466, "type": "text", "section": "Page 466"}
{"text": "Chapter 12 REPOSITORIES\n424\nthe put() method of the NamedCache, which implements java.util.Map,\nis given a String-based key and the Product instance as the value.\nMethod saveAll() may be a bit more complex than you expected. Why \nnot just iterate over aProductCollection, invoking save() for each ele-\nment? We could do so. However, depending on the specific Coherence cache in \nuse, each invocation of put() requires a network request. Therefore, it\u2019s best \nto batch up all Product instances to be persisted in a simple local HashMap\nand submit them with putAll() instead. This reduces the network latency to \nthe lowest possible delay by using a single request, which is the most optimal.\npublic class CoherenceProductRepository\n        implements ProductRepository {\n    ...\n    @Override\n    public void remove(Product aProduct) {\n        this.cache(aProduct.tenant()).remove(this.idOf(aProduct));\n    }\n    @Override\n    public void removeAll(Collection<Product> aProductCollection) {\n        for (Product product : aProductCollection) {\n            this.remove(product);\n        }\n    }\n    ...\n}\nThe implementation of remove() works exactly as expected. However, \ngiven the implementation of saveAll(), removeAll() may be as big a sur-\nprise. After all, isn\u2019t there a way to remove a batch of entries? Well, no, the \nstandard java.util.Map interface doesn\u2019t provide that, and thus neither does \nCoherence. So in this case we do just iterate over aProductCollection and \nuse remove() for each element. Considering the possible consequences of \nremoving only some of the given collection due to Coherence failure, this may \nseem dangerous. Of course, you will have to weigh the forces of providing a \nremoveAll(), but remember that a major strength of Data Fabrics such as \nGemFire and Coherence is redundancy and high availability.\nFinally, we arrive at interface method implementations that provide a few \nways of finding Product instances:\npublic class CoherenceProductRepository\n        implements ProductRepository {\n    ...\nwww.EBooksWorld.ir\n", "page": 467, "type": "text", "section": "Page 467"}
{"text": " \nPERSISTENCE-ORIENTED REPOSITORIES\n425\n    @SuppressWarnings(\"unchecked\")\n    @Override\n    public Collection<Product> allProductsOfTenant(Tenant aTenant) {\n        Set<Map.Entry<String, Product>> entries =\n            this.cache(aTenant).entrySet();\n        Collection<Product> products =\n            new HashSet<Product>(entries.size());\n        for (Map.Entry<String, Product> entry : entries) {\n            products.add(entry.getValue());\n        }\n        return products;\n    }\n    @Override\n    public Product productOfId(Tenant aTenant, ProductId aProductId) {\n       return (Product) this.cache(aTenant).get(this.idOf(aProductId));\n    }\n    ...\n}\nMethod productOfId() only has to do a basic get() on the Named-\nCache, providing the identity of the Product instance being requested.\nMethod allProductsOfTenant() is the one I previously referred to. \nRather than having to employ a more sophisticated Coherence filter entry pro-\ncess, all it needs to do is ask the data grid for all Product instances in the spe-\ncific NamedCache. Because each cache is segregated down to the individual \ntenant, every Aggregate instance in the cache satisfies the query.\nThat wraps up class CoherenceProductRepository. This implementa-\ntion shows how an abstract interface is fulfilled using Coherence as a client \nto persist data on the grid cache and then find it later. It doesn\u2019t show every-\nthing involved in configuring and tuning Coherence, or what it takes to create \nindexes for each cache, or design a compacting, high-performance serializer \nfor each domain object. That\u2019s not the Repository\u2019s responsibility. See [Seovi\u00fe]\nfor extensive coverage of those topics.\nMongoDB Implementation\nAs with the other Repository implementations, there are some basic implemen-\ntation considerations. The MongoDB implementation is actually similar to the \nCoherence version. Here is the high-level overview of what we need:\n 1. A means to serialize Aggregate instances to the MongoDB format, and \nthen deserialize from that format and reconstitute the Aggregate instance. \nwww.EBooksWorld.ir\n", "page": 468, "type": "text", "section": "Page 468"}
{"text": "Chapter 12 REPOSITORIES\n426\nMongoDB uses a special form of JSON called BSON, which is a binary \nJSON format.\n 2. A unique identity generated by MongoDB and assigned to the Aggregate.\n 3. A reference to the MongoDB node/cluster.\n 4. A unique collection in which to store each Aggregate type. All instances \nof each Aggregate type must be stored as a set of serialized documents \n(key-value pairs) in their own collection.\nLet\u2019s take this step by step as we look through a Repository implementation. \nSince we\u2019ll use the ProductRepository again, you can compare the imple-\nmentation to that for Coherence (previous section).\npublic class MongoProductRepository\n        extends MongoRepository<Product>\n        implements ProductRepository {\n    public MongoProductRepository() {\n        super();\n        this.serializer(new BSONSerializer<Product>(Product.class));\n    }\n    ...\n}\nThis implementation holds an instance of a BSONSerializer, which is used \nto serialize and deserialize all Product instances (actually held by superclass \nMongoRepository). I won\u2019t go into deep detail about  \nBSONSerializer. It\u2019s \na custom-developed solution for producing MongoDB DBObject instances \nfrom Product instances (and any other Aggregate types) and back to \nProduct instances. This class is provided along with other sample code.\nThere are a few notable things you can do with a BSONSerializer. Basic \nserialization and deserialization are handled using direct field access. This \nfrees your domain objects from having to implement JavaBean getters and set-\nters, which tends to steer you away from an Anemic Domain Model [Fowler, \nAnemic]. Since you won\u2019t use methods to access fields, you will at some point \nneed to migrate from one version of an Aggregate type to another version. To \ndo so you can specify override mappings for each field on deserialization:\npublic class MongoProductRepository\n        extends MongoRepository<Product>\n        implements ProductRepository {\nwww.EBooksWorld.ir\n", "page": 469, "type": "text", "section": "Page 469"}
{"text": " \nPERSISTENCE-ORIENTED REPOSITORIES\n427\n    public MongoProductRepository() {\n        super();\n        this.serializer(new BSONSerializer<Product>(Product.class));\n        Map<String, String> overrides = new HashMap<String, String>();\n        overrides.put(\"description\", \"summary\");\n        this.serializer().registerOverrideMappings(overrides);\n    }\n    ...\n}\nIn this example we\u2019ll assume that a previous version of class Product had \na field named description. In a subsequent version this field was renamed \nsummary. To solve this problem we could run a migration script across all \nMongoDB collections used to store Product instances for each tenant. How-\never, that could be a difficult and very lengthy set of operations, rendering it an \nimpractical approach. As an alternative, we\u2019ll simply ask the  \nBSONSerializer\nto map any BSON field on Product named  \ndescription to the field \nnamed summary. Then, when the migrated Product is serialized back to a \nDBObject and saved in the MongoDB collection, the new serialization will \ncontain a field named summary rather than description. Of course, it also \nmeans that any Product instances never read and saved back to the store will \nremain with the obsolete description field names. You\u2019ll have to weigh the \ntrade-offs of this lazy migration approach.\nNext, we need a way for MongoDB to generate a unique identity for each \nAggregate instance to use:\npublic class MongoProductRepository\n        extends MongoRepository<Product>\n        implements ProductRepository {\n    ...\n    public ProductId nextIdentity() {\n        return new ProductId(new ObjectId().toString());\n    }\n    ...\n}\nWe still use method nextIdentity(), but in this implementation we ini-\ntialize the ProductId with the String value of a new ObjectId. The main \nreason for this is that we want MongoDB to use the same unique identity that \nwe hold in the Aggregate instance itself. Thus, when we serialize a Product\n(or another type in a different Repository implementation), we can ask the \nBSONSerializer to map that identity to the special MongoDB _id key:\nwww.EBooksWorld.ir\n", "page": 470, "type": "text", "section": "Page 470"}
{"text": "Chapter 12 REPOSITORIES\n428\npublic class BSONSerializer<T> {\n    ...\n    public DBObject serialize(T anObject) {\n        DBObject serialization = this.toDBObject(anObject);\n        return serialization;\n    }\n    public DBObject serialize(String aKey, T anObject) {\n        DBObject serialization = this.serialize(anObject);\n        serialization.put(\"_id\", new ObjectId(aKey));\n        return serialization;\n    }\n    ...\n}\nThe first serialize() method supports no such _id mapping, giving cli-\nents the option to retain the matching identities, or not. Next, look at how the \nsave() method is implemented:\npublic class MongoProductRepository\n        extends MongoRepository<Product>\n        implements ProductRepository {\n    ...\n    @Override\n    public void save(Product aProduct) {\n        this.databaseCollection(\n                this.collectionName(aProduct.tenantId()))\n            .save(this.serialize(aProduct));\n    }\n    ...\n}\nSimilar to the Coherence implementation of the same Repository interface, \nwe get a tenant-specific collection in which to store the Product instances for \na given TenantId. This yields a Mongo DBCollection from a DB. To get \nthe DBCollection object we have the following in the MongoRepository\nabstract base class:\npublic abstract class MongoRepository<T> {\n    ...\n    protected DBCollection databaseCollection(\n            String aDatabaseName,\n            String aCollectionName) {\nwww.EBooksWorld.ir\n", "page": 471, "type": "text", "section": "Page 471"}
{"text": " \nPERSISTENCE-ORIENTED REPOSITORIES\n429\n        return MongoDatabaseProvider\n                .database(aDatabaseName)\n                .getCollection(aCollectionName);\n    }\n    ...\n}\nWe use a MongoDatabaseProvider to get a connection to the database \ninstance, which answers with a DB object. From the returned DB object we ask \nfor a DBCollection. As seen in the concrete Repository implementation, the \ncollection is named by the combination of the text \"product\" and the full \nidentity of the tenant. The Agile PM Context uses a dedicated database named \nagilepm, much like the way the Coherence implementation names its cache:\npublic class MongoProductRepository\n        extends MongoRepository<Product>\n        implements ProductRepository {\n    ...\n    protected String collectionName(TenantId aTenantId) {\n        return \"product\" + aTenantId.id();\n    }\n    protected String databaseName() {\n        return \"agilepm\";\n    }\n    ...\n}\nSimilar to the SpringHibernateSessionProvider presented previ-\nously, the MongoDatabaseProvider is the means to retrieve an applica-\ntion-wide instance of DB.\nThe same DBCollection is used for save() and for finding instances of \nProduct:\npublic class MongoProductRepository\n        extends MongoRepository<Product>\n        implements ProductRepository {\n    ...\n    @Override\n    public Collection<Product> allProductsOfTenant(\n            TenantId aTenantId) {\n        Collection<Product> products = new ArrayList<Product>();\n        DBCursor cursor =\n            this.databaseCollection(\n                    this.databaseName(),\n                    this.collectionName(aTenantId)).find();\nwww.EBooksWorld.ir\n", "page": 472, "type": "text", "section": "Page 472"}
{"text": "Chapter 12 REPOSITORIES\n430\n        while (cursor.hasNext()) {\n            DBObject dbObject = cursor.next();\n            Product product = this.deserialize(dbObject);\n            products.add(product);\n        }\n        return products;\n    }\n    @Override\n    public Product productOfId(\n            TenantId aTenantId, ProductId aProductId) {\n        Product product = null;\n        BasicDBObject query = new BasicDBObject();\n        query.put(\"productId\",\n                new BasicDBObject(\"id\", aProductId.id()));\n        DBCursor cursor =\n            this.databaseCollection(\n                    this.databaseName(),\n                    this.collectionName(aTenantId)).find(query);\n        if (cursor.hasNext()) {\n            product = this.deserialize(cursor.next());\n        }\n        return product;\n    }\n    ...\n}\nThe implementation of allProductsOfTenant() is, again, very similar to \nthat for Coherence. We simply ask the tenant-based  \nDBCollection to find()\nall instances. As for productOfId(), this time we give the  \nDBCollection\nmethod find() a DBObject describing the specific Product instance to \nretrieve. In both finder methods we use the returned DBCursor to get all, and \nget only the first instance, respectively.\nAdditional Behavior\nSometimes it is beneficial to provide additional behavior on a Repository inter-\nface, besides the typical kinds presented in the previous sections. One behavior \nthat comes in handy is to answer the count of all instances in the collection of \nwww.EBooksWorld.ir\n", "page": 473, "type": "text", "section": "Page 473"}
{"text": " \nADDITIONAL BEHAVIOR\n431\nAggregates. You might think of this behavior as having the name count. How-\never, since a Repository should mimic a collection as closely as possible, you \nmight consider instead using the following method:\npublic interface CalendarEntryRepository {\n    ...\n    public int size();\n}\nMethod size() is exactly what a standard java.util.Collection sup-\nplies. When using Hibernate, the implementation would work like this:\npublic class HibernateCalendarEntryRepository\n        implements CalendarEntryRepository  {\n    ...\n    public int size() {\n        Query query =\n            this.session().createQuery(\n                \"select count(*) from CalendarEntry\");\n        int size = ((Integer) query.uniqueResult()).intValue();\n        return size;\n    }\n}\nThere may be other calculations that must be performed in the data store \n(database or grid included) in order to meet some stringent nonfunctional \nrequirement. This can be the case if moving the data from its store to where the \nbusiness logic executes is too slow. Instead you may have to move the code to \nthe data. This can be accomplished using database stored procedures or data \ngrid entry processors, such as are available with Coherence. However, such \nimplementations are often best placed under the control of Domain Services \n(7), since those are used to house stateless, domain-specific operations.\nIt may at times be advantageous to query Aggregate parts out of the Reposi-\ntory without directly accessing the Root itself. This might be so if an Aggregate \nholds a large collection of some Entity type, and you need to get access only to \nthe instances that match a certain criterion. Of course, this might make sense \nonly if the Aggregate allows for such access by navigation through the Root. \nYou wouldn\u2019t design a Repository to provide access to parts that the Aggre-\ngate Root would not otherwise allow access to by way of navigation. Doing \nso would violate the Aggregate contract. I suggest that you would also not \ndesign the Repository to provide this kind of access as a mere shortcut for cli-\nent convenience. I think this should be used primarily to address performance \nwww.EBooksWorld.ir\n", "page": 474, "type": "text", "section": "Page 474"}
{"text": "Chapter 12 REPOSITORIES\n432\nconcerns under conditions where navigation through the Root would cause an \nunacceptable bottleneck. The methods that address such optimal access would \nhave the same basic characteristics as other finders (see earlier in this chapter) \nbut would answer instances of the contained parts rather than Root Entities. \nAgain, use with caution.\nAnother reason might influence you to design in special finder methods. \nCertain use cases of your system may not follow the exact contours of a single \nAggregate type when rendering views of domain data. They may instead cut \nacross types, possibly composing just certain parts of one or more Aggregates. \nIn situations like this you might choose not to, in a single transaction, find \nwhole Aggregate instances of various types and then programmatically com-\npose them into a single container, and supply that payload container to a client. \nYou might instead use what is called a use case optimal query. This is where \nyou specify a complex query against the persistence mechanism, dynamically \nplacing the results into a Value Object (6) specifically designed to address the \nneeds of the use case.\nIt should not seem strange for a Repository to in some cases answer a Value \nObject rather than an Aggregate instance. A Repository that provides a size()\nmethod answers a very simple Value in the form of an integer count of the total \nAggregate instances it holds. A use case optimal query is just extending this \nnotion a bit to provide a somewhat more complex Value, one that addresses \nmore complex client demands.\nIf you find that you must create many finder methods supporting use case opti-\nmal queries on multiple Repositories, it\u2019s probably a code smell. First of all, this \nsituation could be an indication that you\u2019ve misjudged Aggregate boundaries and \noverlooked the opportunity to design one or more Aggregates of different types. \nThe code smell here might be called Repository masks Aggregate mis-design.\nHowever, what if you encounter this situation and your analysis indicates \nthat your Aggregate boundaries are well designed? This could point to the \nneed to consider using CQRS (4).\nManaging Transactions\nThe domain model and its encompassing Domain Layer is never the correct \nplace to manage transactions.5 The operations associated with a model are \n 5. Note that for some persistence mechanisms transaction management is either non-\nexistent or works differently from ACID transactions common with relational \ndatabases. Both Coherence and many NoSQL stores differ in that way, and this \nmaterial is generally not applicable to such data storage mechanisms.\nwww.EBooksWorld.ir\n", "page": 475, "type": "text", "section": "Page 475"}
{"text": " \nMANAGING TRANSACTIONS\n433\nusually too fine grained to themselves manage transactions and shouldn\u2019t be \naware that transactions play a part in their life cycle. If you are to avoid plac-\ning transactional concerns in the model, just where do they belong?\nA common architectural approach to facilitating transactions on behalf of \npersistence aspects of the domain model is to manage them in the Application \nLayer (14).6 Generally, we create one Facade [Gamma et al.] there for each \nmajor use case grouping addressed by the application/system. The Facade is \ndesigned with coarse-grained business methods, usually one for each use case \nflow (which may be limited to one for a given use case). Each such business \nmethod coordinates a task as required by the use case. When a Facade\u2019s busi-\nness method is invoked by the User Interface Layer (14), whether on behalf \nof a human or another system, the business method begins a transaction and \nthen acts as a client to the domain model. After all necessary interaction with \nthe domain model is successfully completed, the Facade\u2019s business method \ncommits the transaction it started. If an error/exception occurs that prevents \ncompletion of the use case task, the transaction is rolled back by the same \nmanaging business method.\nThe transaction may be managed declaratively or explicitly by developer \ncode. Whether or not your transactions are declarative or user managed, what \nI have described here logically works as follows:\npublic class SomeApplicationServiceFacade {\n    ...\n    public void doSomeUseCaseTask()  {\n        Transaction transaction = null;\n        try {\n            transaction = this.session().beginTransaction();\n            // use the domain model ...\n            transaction.commit();\n        } catch (Exception e) {\n            if (transaction != null) {\n                transaction.rollback();\n            }\n        }\n    }\n}\n 6. There are other concerns managed by the Application Layer, such as security, but I \ndon\u2019t discuss those here.\nwww.EBooksWorld.ir\n", "page": 476, "type": "text", "section": "Page 476"}
{"text": "Chapter 12 REPOSITORIES\n434\nTo enlist changes to the domain model in a transaction, ensure that Repos-\nitory implementations have access to the same Session or Unit of Work for \nthe transaction that the Application Layer started. That way the modifications \nmade in the Domain Layer will be properly committed to the underlying data-\nbase or rolled back.\nThere is such a variety in how this can be accomplished that I cannot \naddress all possibilities. What I will do is note that enterprise Java containers \nand inversion-of-control containers, such as Spring, provide the means to do \nwhat I have described, and it is generally well understood. The emphasis here \nis to use what is appropriate for your environment. As an example, here\u2019s how \nyou might do so using Spring:\n<tx:annotation-driven transaction-manager=\"transactionManager\"/>\n<bean\n    id=\"sessionFactory\"\n    class=\"org.springframework.orm.hibernate3.LocalSessionFactoryBean\">\n    <property name=\"configLocation\">\n        <value>classpath:hibernate.cfg.xml</value>\n    </property>\n</bean>\n<bean\n    id=\"sessionProvider\"\n    class=\"com.saasovation.identityaccess.infrastructure\n           .persistence.SpringHibernateSessionProvider\"\n    autowire=\"byName\">\n</bean>\n<bean\n    id=\"transactionManager\"\n    class=\"org.springframework.orm.hibernate3\n           .HibernateTransactionManager\">\n    <property name=\"sessionFactory\">\n        <ref bean=\"sessionFactory\"/>\n    </property>\n</bean>\n<bean\n    id=\"abstractTransactionalServiceProxy\"\n    abstract=\"true\"\n    class=\"org.springframework.transaction.interceptor\n           .TransactionProxyFactoryBean\">\n    <property name=\"transactionManager\">\n        <ref bean=\"transactionManager\"/>\n    </property>\n    <property name=\"transactionAttributes\">\nwww.EBooksWorld.ir\n", "page": 477, "type": "text", "section": "Page 477"}
{"text": " \nMANAGING TRANSACTIONS\n435\n        <props>\n            <prop key=\"*\">PROPAGATION_REQUIRED</prop>\n        </props>\n    </property>\n</bean>\nThe configured sessionFactory bean provides the means to obtain a \nHibernate Session. The bean named sessionProvider is used to associate \na Session obtained from the sessionFactory with the current Thread\nof execution. The sessionProvider bean can be used by Hibernate-based \nRepositories when they need to get the Session instance for the Thread\nthey are running under. The transactionManager uses the session-\nFactory to get and manage Hibernate transactions. The one remaining bean, \nabstractTransactionalServiceProxy, is used optionally as a proxy for \ndeclaring transactional beans using Spring configuration. The topmost decla-\nration allows transactions to be declared via Java annotations, which may be \nmore convenient than using configuration:\n    <tx:annotation-driven transaction-manager=\"transactionManager\"/>\nWith this wired you can now declare a given Facade business method transac-\ntional using a simple annotation:\npublic class SomeApplicationServiceFacade {\n    ...\n    @Transactional\n    public void doSomeUseCaseTask()  {\n        // use the domain model ...\n    }\n}\nCompared to the previous example of managing a transaction, this certainly \ncuts down on clutter in the business method and allows you to focus on the task \ncoordination itself. By means of this annotation, when the business method is \ninvoked, Spring automatically starts a transaction, and when the method com-\npletes, the transaction is either committed or rolled back as appropriate.\nHere is a look at the source code of the sessionProvider bean as it is \nimplemented for the Identity and Access Context:\npackage com.saasovation.identityaccess.infrastructure.persistence;\nimport org.hibernate.Session;\nimport org.hibernate.SessionFactory;\nwww.EBooksWorld.ir\n", "page": 478, "type": "text", "section": "Page 478"}
{"text": "Chapter 12 REPOSITORIES\n436\npublic class SpringHibernateSessionProvider {\n    private static final ThreadLocal<Session> sessionHolder =\n            new ThreadLocal<Session>();\n    private SessionFactory sessionFactory;\n    public SpringHibernateSessionProvider() {\n        super();\n    }\n    public Session session() {\n        Session threadBoundsession = sessionHolder.get();\n        if (threadBoundsession == null) {\n            threadBoundsession = sessionFactory.openSession();\n            sessionHolder.set(threadBoundsession);\n        }\n        return threadBoundsession;\n    }\n    public void setSessionFactory(SessionFactory aSessionFactory) {\n        this.sessionFactory = aSessionFactory;\n    }\n}\nSince the sessionProvider is a Spring bean that is declared with \nautowire=\"byName\", when the bean is instantiated as a singleton its set-\nSessionFactory() method is invoked to inject the sessionFactory bean \ninstance. To save you looking back through the chapter in search of how a \nHibernate-based Repository uses this, here\u2019s a brief reminder:\npackage com.saasovation.identityaccess.infrastructure.persistence;\npublic class HibernateUserRepository\n        implements UserRepository  {\n    @Override\n    public void add(User aUser) {\n        try {\n            this.session().saveOrUpdate(aUser);\n        } catch (ConstraintViolationException e) {\n            throw new IllegalStateException(\"User is not unique.\", e);\n        }\n    }\n    ...\n    private SpringHibernateSessionProvider sessionProvider;\n    public void setSessionProvider(\n            SpringHibernateSessionProvider aSessionProvider) {\n        this.sessionProvider = aSessionProvider;\n    }\nwww.EBooksWorld.ir\n", "page": 479, "type": "text", "section": "Page 479"}
{"text": " \nTYPE HIERARCHIES\n437\n    private org.hibernate.Session session() {\n        return this.sessionProvider.session();\n    }\n}\nThis snippet is from the HibernateUserRepository of the Identity and \nAccess Context. This class, too, is a Spring bean that is autowired by name, \nwhich means its method setSessionProvider() is automatically invoked \nupon creation so that it gets a reference to the sessionProvider bean, which \nis an instance of SpringHibernateSessionProvider. When the add()\nmethod (or any other method that provides persistence) is invoked, it asks for \na Session through its session() method. In turn, session() uses the \ninjected sessionProvider to obtain the thread-bound Session instance.\nWhile I have demonstrated how transactions are managed only when using \nHibernate, all of these principles carry over to TopLink, JPA, and other per-\nsistence mechanisms. With any such persistence mechanism you must find a \nway to provide access to the same Session, Unit of Work, and transaction that \nthe Application Layer is managing. Dependency injection works well for this \nif it is available. If it isn\u2019t available, there are other creative ways to facilitate \nthe necessary wiring, even going as far as manually binding such objects to the \ncurrent thread.\nA Warning\nI feel obligated to provide a parting warning about overuse of transactions in \nconjunction with the domain model. Aggregates must be designed carefully in \norder to ensure correct consistency boundaries. Be careful not to overuse the \nability to commit modifications to multiple Aggregates in a single transaction \njust because it works in a unit test environment. If you aren\u2019t careful, what \nworks well in development and test can fail severely in production because of \nconcurrency issues. If need be, revisit Aggregates (10) for vital reminders to pre-\ncisely define consistency boundaries in order to ensure transactional success.\nType Hierarchies\nWhen using an object-oriented language to develop a domain model, it can be \ntempting to leverage inheritance to create type hierarchies. We might think of \nthis as an opportunity to place default state and behavior in a base class and \nthen extend that using subclasses. And why not? It seems like a perfect way to \navoid repeating yourself.\nwww.EBooksWorld.ir\n", "page": 480, "type": "text", "section": "Page 480"}
{"text": "Chapter 12 REPOSITORIES\n438\nCreating Aggregates that have a common ancestry and yet stand apart from \ntheir relatives with a separate Repository is a different use of inheritance from \ncreating Aggregates with the same ancestry that share a single Repository. So \nthis section does not discuss the situation where all Aggregate types in a sin-\ngle domain model extend a Layer Supertype [Fowler, P of EAA] to provide \ndomain-wide common state and/or behavior.7\nRather, here I am referring to creating a relatively small number of Aggregate \ntypes that extend a common domain-specific superclass. These are designed in \norder to form a hierarchy of closely related types that have interchangeable, \npolymorphic characteristics. These kinds of hierarchies use a single Repository \nto store and retrieve instances of the separate types, because the client should \nuse the instances interchangeably, and clients rarely if ever have to be aware of \nthe specific subclass that they are dealing with at any given time, which reflects \nthe Liskov Substitution Principle (LSP) [Liskov].\nHere\u2019s what I mean. Say your business uses external businesses to provide \nvarious kinds of services, and you need to model the relationships. You decide \nto have a common abstract base class ServiceProvider, but for some good \nreason you need to divide various concrete types of these because the services \neach provides are both common and yet distinctly different. You might have a \nWarbleServiceProvider and a WonkleServiceProvider. You design \nthese types such that you can schedule a service request in a generic way:\n// client of domain model\nserviceProviderRepository.providerOf(id)\n        .scheduleService(date, description);\nWith this context, it is clear that the creation of domain-specific Aggregate \ntype hierarchies will probably have limited usefulness in many domains. Here\u2019s \nwhy. As demonstrated previously, most times the common Repository will be \ndesigned with finder methods that retrieve instances of any of the subclasses. \nThat means that the method will answer instances of the common superclass, \nin this case a ServiceProvider, not instances of the specific subclasses, \nWarbleServiceProvider and WonkleServiceProvider. Think of what \nwould happen if finders were designed to return specific types. Clients would \nhave to know which identities or other descriptive attributes of the Aggregates \nwould lead to specific typed instances. Otherwise it could lead to an unmatched \nfind or a ClassCastException when a matched instance of the wrong type \n 7. I discuss the benefits of using a Layer Supertype in the design of Entities (5) and \nValue Objects (6). See the respective chapters.\nwww.EBooksWorld.ir\n", "page": 481, "type": "text", "section": "Page 481"}
{"text": " \nTYPE HIERARCHIES\n439\nis returned. Even if you could design in a good way to find instances of the \ncorrect types, clients would also have to know which subclasses could per-\nform specifically different operations, given that the Aggregates could not be \nentirely designed for LSP.\nTo solve the first problem of segregating types by identity, you might con-\nclude that you could safely detect instances by encoding Aggregate type infor-\nmation as a discriminator in the class of the unique identity. You could do \nso. But that also leads to two additional problems. The client must take on \nthe responsibility of resolving and mapping identities to types. The other new \nproblem is coupling clients to the distinct operations by type. It leads to this \nkind of client type dependencies:\n// client of domain model\nif (id.identifiesWarble()) {\n    serviceProviderRepository.warbleOf(id)\n            .scheduleWarbleService(date, warbleDescription);\n} else if (id.identifiesWonkle()) {\n    serviceProviderRepository.wonkleOf(id)\n            .scheduleWonkleService(date, wonkleDescription);\n} ...\nIf this kind of interaction becomes the norm rather than the exception, it \nindicates a code smell. Granted, if the benefits gained from creating a hierar-\nchy are so great, a rare one-off usage like this may be a worthwhile trade-off. \nHowever, in this contrived example a more discerning design of the implied \nServiceDescription type and the internal implementation of schedule-\nService() would probably suffice. Otherwise, I think we\u2019d have to ask if we \ncould gain some benefits from using inheritance while assigning each type a \nseparate Repository. In the case where only two or a few such concrete sub-\nclasses are necessary, it may be best to create separate Repositories. When the \nnumber of concrete subclasses grows to several or many, most of which can \nbe used completely interchangeably (LSP), it is worthwhile for them to share a \ncommon Repository.\nMost of the time, this kind of situation can be completely avoided by design-\ning type descriptive information as a property of the Aggregate (not in the \nidentity). See the discussion about Standard Types under Value Objects (6).\nThis way a single Aggregate type could internally implement different behav-\nior based on an explicitly determined Standard Type. Using an explicit Stan-\ndard Type, we could have a single concrete ServiceProvider Aggregate \nand design its scheduleService() to dispatch based on its type. To shield \nclients from the decisions based on the type we ensure that such is not leaked \nwww.EBooksWorld.ir\n", "page": 482, "type": "text", "section": "Page 482"}
{"text": "Chapter 12 REPOSITORIES\n440\nout to them. Instead, scheduleService() and other ServiceProvider\nmethods properly enclose such domain-specific decisions, as can be seen here:\npublic class ServiceProvider {\n    private ServiceType type;\n    ...\n    public void scheduleService(\n            Date aDate,\n            ServiceDescription aDescription) {\n        if (type.isWarble()) {\n            this.scheduleWarbleService(aDate, aDescription);\n        } else if (type.isWonkle()) {\n            this.scheduleWonkleService(aDate, aDescription);\n        } else {\n            this.scheduleCommonService(aDate, aDescription);\n        }\n    }\n    ...\n}\nIf the internal dispatching becomes messy, we can always design another \nsmaller hierarchy to deal with that. In fact, the Standard Type itself could be \ndesigned as a State [Gamma et al.], assuming you like that approach. In that \ncase the various types would implement specialized behavior. This, of course, \nalso means that we\u2019d have a single ServiceProviderRepository, which \naddresses the desire to store different types in one Repository and use them \nwith common behavior.\nThe situation could also be sidestepped with the use of role-based interfaces. \nHere we might have decided to design a SchedulableService interface that \nmultiple Aggregate types would implement. See the discussion about roles and \nresponsibilities under Entities (5). Even if inheritance is used, Aggregate poly-\nmorphic behavior can most often be carefully designed such that no special \ncases are surfaced to clients.\nRepository versus Data Access Object\nSometimes the idea of a Repository is considered synonymous with Data \nAccess Object, or DAO. Both provide an abstraction over a persistence mecha-\nnism. This is true. However, an object-relational mapping tool also provides an \nabstraction over a persistence mechanism, but it is neither a Repository nor a \nDAO. Thus, we wouldn\u2019t call just any persistence abstraction a DAO. We must \nrather determine if the DAO pattern is being implemented.\nwww.EBooksWorld.ir\n", "page": 483, "type": "text", "section": "Page 483"}
{"text": " \nTESTING REPOSITORIES\n441\nI think there are generally differences between Repositories and DAOs. \nBasically, a DAO is expressed in terms of database tables, providing CRUD \ninterfaces to them. Martin Fowler in [Fowler, P of EAA] separates the uses of \nDAO-like facilities from those that are used with a domain model. He identi-\nfies Table Module, Table Data Gateway, and Active Record as patterns that \nwould typically be used in a Transaction Script application. That\u2019s because \nDAO and related patterns tend to serve as wrappers around database tables. \nOn the other hand, Repository and Data Mapper, having object affinity, are \ntypically the patterns that would be used with a domain model.\nSince you can use DAO and related patterns to perform fine-grained CRUD \noperations on data that would otherwise be considered parts of an Aggregate, \nthis would be a pattern to avoid with a domain model. Under normal con-\nditions you want the Aggregate itself to manage its business logic and other \ninternals and keep everyone else out.\nI did indicate previously that at times a stored procedure or a data grid entry \nprocessor is essential to meet some demanding nonfunctional requirement. \nDepending on your domain, this may be more the rule than the exception. If a \nsystem nonfunctional requirement is not driving this, however, I suggest that \nyou should avoid it. Housing and executing business logic in the data store \nmany times runs orthogonal to DDD. I would conclude that the use of a Data \nFabric Function/Entry Processor is not really disruptive to the goals of domain \nmodeling. The Function/Entry Processor implementation would be written in \nJava, for example, and would adhere to the Ubiquitous Language (1) and goals \nof the domain. The only difference from the core model is where the Function/\nEntry Processor is executed, which is not disruptive. On the other hand, pro-\nlific use of stored procedures is potentially very disruptive to DDD because the \nprogramming language is generally not well understood by the modeling team \nand implementations are generally \u201csafely\u201d tucked away from their view. If so, \nthat is exactly the opposite of what DDD is trying to accomplish.\nYou may choose to think of a Repository as a DAO in a general sense. The \nprimary thing to keep in mind is that as much as possible you should try to \ndesign your Repositories with a collection orientation rather than a data access \norientation. That will help keep you focused on the domain as a model rather \nthan on data and any CRUD operations that may be used behind the scenes to \nmanage its persistence.\nTesting Repositories\nThere are two ways to look at testing Repositories. You have to test the Repos-\nitories themselves in order to prove that they work correctly. You also must \nwww.EBooksWorld.ir\n", "page": 484, "type": "text", "section": "Page 484"}
{"text": "Chapter 12 REPOSITORIES\n442\ntest code that uses Repositories to store the Aggregates that they create and to \nfind preexisting ones. For the first kind of test you must use the full produc-\ntion-quality implementations. Otherwise you won\u2019t know if your production \ncode will work. For the second kind of test, either you can use your production \nimplementations, or you can use in-memory implementations instead. I discuss \nthe production implementation tests now and defer the in-memory tests to just \na bit later.\nLet\u2019s take a look at the tests for the Coherence implementation of the Prod-\nuctRepository presented previously:\npublic class CoherenceProductRepositoryTest extends DomainTest {\n    private ProductRepository productRepository;\n    private TenantId tenantId;\n    public CoherenceProductRepositoryTest() {\n        super();\n    }\n    ...\n    @Override\n    protected void setUp() throws Exception {\n        this.setProductRepository(new CoherenceProductRepository());\n        this.tenantId = new TenantId(\"01234567\");\n        super.setUp();\n    }\n    @Override\n    protected void tearDown() throws Exception {\n        Collection<Product> products =\n            this.productRepository()\n                    .allProductsOfTenant(tenantId);\n        this.productRepository().removeAll(products);\n    }\n    protected ProductRepository productRepository() {\n        return this.productRepository;\n    }\n    protected void setProductRepository(\n            ProductRepository aProductRepository) {\n        this.productRepository = aProductRepository;\n    }\n}\nThere are some general setup and tear-down operations to prepare for and \nclean up after each test. To set up we create an instance of class Coherence-\nProductRepository and then create a fake instance of TenantId.\nwww.EBooksWorld.ir\n", "page": 485, "type": "text", "section": "Page 485"}
{"text": " \nTESTING REPOSITORIES\n443\nTo tear down we remove all Product instances that may have been added \nto the backing cache by each test. For Coherence this is an important cleanup \nstep. If you don\u2019t remove all cached instances, they will remain during subse-\nquent tests, which may cause failure for certain assertions such as persisted \ninstance counts.\nNext, we test the Repository behavior:\npublic class CoherenceProductRepositoryTest extends DomainTest {\n    ...\n    public void testSaveAndFindOneProduct() throws Exception {\n        Product product =\n            new Product(\n                    tenantId,\n                    this.productRepository().nextIdentity(),\n                    \"My Product\",\n                    \"This is the description of my product.\");\n        this.productRepository().save(product);\n        Product readProduct =\n            this.productRepository()\n                .productOfId(tenantId, product.productId());\n        assertNotNull(readProduct);\n        assertEquals(readProduct.tenantId(), tenantId);\n        assertEquals(readProduct.productId(), product.productId());\n        assertEquals(readProduct.name(), product.name());\n        assertEquals(readProduct.description(), product.description());\n    }\n    ...\n}\nAs the test method name states, here we save a single Product and attempt \nto find it. The first task is to instantiate a Product and then save it to the \nRepository. If no exception is thrown by the infrastructure, we may think that \nthe Product was correctly saved. However, there is only one way to know for \ncertain. We have to find the instance and compare it to the original. To find \nthe instance we pass its globally unique identity to method productOfId(). If \nthe instance was found, we can successfully assert that it is not null, that its \ntenantId is the same, its productId is the same, its name is the same, and \nits description is the same as the one that was stored.\nNext, we test saving and finding multiple instances:\npublic class CoherenceProductRepositoryTest extends DomainTest {\n    ...\n    public void testSaveAndFindMultipleProducts() throws Exception {\nwww.EBooksWorld.ir\n", "page": 486, "type": "text", "section": "Page 486"}
{"text": "Chapter 12 REPOSITORIES\n444\n        Product product1 =\n            new Product(\n                    tenantId,\n                    this.productRepository().nextIdentity(),\n                    \"My Product 1\",\n                    \"This is the description of my first product.\");\n        Product product2 =\n            new Product(\n                    tenantId,\n                    this.productRepository().nextIdentity(),\n                    \"My Product 2\",\n                    \"This is the description of my second product.\");\n        Product product3 =\n            new Product(\n                    tenantId,\n                    this.productRepository().nextIdentity(),\n                    \"My Product 3\",\n                    \"This is the description of my third product.\");\n        this.productRepository()\n            .saveAll(Arrays.asList(product1, product2, product3));\n        assertNotNull(this.productRepository()\n            .productOfId(tenant, product1.productId()));\n        assertNotNull(this.productRepository()\n            .productOfId(tenant, product2.productId()));\n        assertNotNull(this.productRepository()\n            .productOfId(tenant, product3.productId()));\n        Collection<Product> allProducts =\n            this.productRepository().allProductsOfTenant(tenant);\n        assertEquals(allProducts.size(), 3);\n    }\n    ...\n}\nFirst we instantiate three Product instances and then save them at once \nusing saveAll(). Next, we again use productOfId() to find individual \ninstances. If all three instances are not null, we are convinced that all three \ninstances were correctly persisted.\nCowboy Logic\nAJ:  \n\u201cMy sister told me her husband asked her to sell all \nthe stuff in his storage unit when he dies. My sister \nasked him why. He said he didn\u2019t want some jerk to \nhave his stuff when she remarries. She told him not to \nworry since she wasn\u2019t going to marry another jerk.\u201d\nwww.EBooksWorld.ir\n", "page": 487, "type": "text", "section": "Page 487"}
{"text": " \nTESTING REPOSITORIES\n445\nThere is one Repository method, allProductsOfTenant(), that has not yet \nbeen tested. Given that the Repository cache was completely empty when the test \nstarted, we should be able to successfully read three Product instances from it. So \nwe attempt to find all of them. The returned Collection should never be null,\neven if you don\u2019t find what you expected. So the last step in the test is to assert that \nthe full number of expected Product instances, or three, was in fact found.\nNow that we have a test that demonstrates how clients can use the Repos-\nitory and proves its correctness, we can look at how you can more optimally \ntest clients that use Repositories.\nTesting with In-Memory Implementations\nIf it is very difficult to set up the full persistent implementation of a Repository \nfor test, or too slow to use it, you can leverage another approach. You may also \nface undesirable conditions early on during domain modeling, perhaps when \nyour persistence mechanisms, including the database schema, are not yet avail-\nable. When you face any of these situations, it works best to implement an \nin-memory edition of Repositories.\nCreating in-memory editions can be quite simple, but it may also pose some \nchallenges. The simple part is creating a HashMap to back your interface. It \nis straightforward to put() entries to and remove() them from the Map. We \njust use the globally unique identity of each Aggregate instance as the key. The \nAggregate instance itself serves as the value. The add() or save() methods \nand the remove() methods are quite trivial. In fact, in the case of the Prod-\nuctRepository the entire implementation is fairly simple:\npackage com.saasovation.agilepm.domain.model.product.impl;\npublic class InMemoryProductRepository implements ProductRepository {\n    private Map<ProductId,Product> store;\n    public InMemoryProductRepository() {\n        super();\n        this.store = new HashMap<ProductId,Product>();\n    }\n    @Override\n    public Collection<Product> allProductsOfTenant(Tenant aTenant) {\n        Set<Product> entries = new HashSet<Product>();\n        for (Product product : this.store.values()) {\n            if (product.tenant().equals(aTenant)) {\n                entries.add(product);\n            }\n        }\nwww.EBooksWorld.ir\n", "page": 488, "type": "text", "section": "Page 488"}
{"text": "Chapter 12 REPOSITORIES\n446\n        return entries;\n    }\n    @Override\n    public ProductId nextIdentity() {\n        return new ProductId(java.util.UUID.randomUUID()\n                .toString().toUpperCase());\n    }\n    @Override\n    public Product productOfId(Tenant aTenant, ProductId aProductId) {\n        Product product = this.store.get(aProductId);\n        if (product != null) {\n            if (!product.tenant().equals(aTenant)) {\n                product = null;\n            }\n        }\n        return product;\n    }\n    @Override\n    public void remove(Product aProduct) {\n        this.store.remove(aProduct.productId());\n    }\n    @Override\n    public void removeAll(Collection<Product> aProductCollection) {\n        for (Product product : aProductCollection) {\n            this.remove(product);\n        }\n    }\n    @Override\n    public void save(Product aProduct) {\n        this.store.put(aProduct.productId(), aProduct);\n    }\n    @Override\n    public void saveAll(Collection<Product> aProductCollection) {\n        for (Product product : aProductCollection) {\n            this.save(product);\n        }\n    }\n}\nThere is actually only a single special case for productOfId(). To cor-\nrectly implement this finder, after getting a matching Product by the given \nProductId, we must also check that the TenantId of the Product matches \nthe Tenant parameter. If it doesn\u2019t, we set the Product instance to null.\nwww.EBooksWorld.ir\n", "page": 489, "type": "text", "section": "Page 489"}
{"text": " \nTESTING REPOSITORIES\n447\nWe can actually make a near-identical copy of CoherenceProduct-\nRepositoryTest named InMemoryProductRepositoryTest to test this \nin-memory implementation. The only change that needs to be made is in setUp():\npublic class InMemoryProductRepositoryTest extends TestCase {\n    ...\n    @Override\n    protected void setUp() throws Exception {\n        this.setProductRepository(new InMemoryProductRepository());\n        this.tenantId = new TenantId(\"01234567\");\n        super.setUp();\n    }\n    ...\n}\nJust instantiate InMemoryProductRepository rather than the Coher-\nence implementation. Other than that the test methods themselves are identical.\nThe possible difficult challenges are generally related to implementing more \nadvanced finders, where parameter criteria are complex to resolve. If the crite-\nria and resolution logic becomes too complex, you may have to find a way to \nwork around the situation. It might mean prepopulating the Repository with \ninstances that will resolve the search while making the finder method itself \nreturn only the instance or instances that are prepopulated. You can prepopu-\nlate using the test\u2019s setUp() method.\nAnother advantage to implementing in-memory editions of your Repositories \nis when you need to test for proper uses of save() with a persistence- \noriented \ninterface. You can implement the save() methods to count invocations. After \neach test is run, you can assert that the invocation count matches the num-\nber required by the client of the specific Repository. Generally, you could use \nthis approach when testing Application Services that must explicitly save()\nchanges to an Aggregate.\nwww.EBooksWorld.ir\n", "page": 490, "type": "text", "section": "Page 490"}
{"text": "Chapter 12 REPOSITORIES\n448\nWrap-Up\nIn this chapter we looked in depth at implementing Repositories.\n\u2022 You learned about collection-oriented and persistence-oriented  \nRepositories, \nand why to use one or the other.\n\u2022 You saw how to implement Repositories for Hibernate, TopLink, Coher-\nence, and MongoDB.\n\u2022 You investigated why you might need additional behavior on a Repository\u2019s \ninterface.\n\u2022 You considered how transactions play into the use of Repositories.\n\u2022 You are now familiar with the challenges of designing Repositories for \ntype hierarchies.\n\u2022 You looked at some fundamental differences between Repositories and \nData Access Objects.\n\u2022 You saw how to test Repositories and different ways to test using \nRepositories.\nNext, we\u2019ll shift gears and take a careful look at integrating Bounded \nContexts.\nwww.EBooksWorld.ir\n", "page": 491, "type": "text", "section": "Page 491"}
{"text": "449\nChapter 13\nIntegrating Bounded Contexts\nMaking mental connections is our most crucial learning tool, \nthe essence of human intelligence; to forge links; to go beyond the given; \nto see patterns, relationships, context.\n\u2014Marilyn Ferguson\nThere are always multiple Bounded Contexts (2) in any project of significance, \nand two or more of those Bounded Contexts will need to integrate. Using Con-\ntext Maps (3), we discussed the relationships that commonly exist between \nBounded Contexts, and we examined some ways that those relationships can \nbe managed correctly according to the principles of DDD. If you don\u2019t have a \nfairly strong grasp of Domains (2), Subdomains (2), and Bounded Contexts, \nor of Context Maps, you should obtain that before continuing. The material \npresented here builds on those fundamental concepts.\nAs previously discussed, Context Maps have two primary forms. One form \nis a simple drawing that is used to illustrate the kinds of relationships that exist \nbetween any two or more Bounded Contexts. The second and far more con-\ncrete form is the code that actually implements those relationships. That\u2019s what \nwe are considering now.\nRoad Map to This Chapter\n\u2022 Review some of the basics of integration, and develop the proper mindset \nnecessary to succeed in integrating systems in a distributed computing \nenvironment.\n\u2022 See how you can approach integration using RESTful resources, and con-\nsider some of its advantages and disadvantages.\n\u2022 Learn how to integrate when using messaging.\n\u2022 Understand the challenges you will face when you decide to duplicate infor-\nmation across Bounded Contexts.\n\u2022 Study examples that provide increasing maturity in design approaches.\nwww.EBooksWorld.ir\n", "page": 492, "type": "text", "section": "Page 492"}
{"text": "Chapter 13 INTEGRATING BOUNDED CONTEXTS\n450\nIntegration Basics\nWhen two Bounded Contexts need to integrate, there are a few reasonably \nstraightforward ways this can be done in code.\nOne such straightforward approach is for a Bounded Context to expose an \napplication programming interface (API), and another Bounded Context to use \nthat API via remote procedure calls (RPCs). The API could be made avail-\nable using SOAP or simply support sending XML requests and responses over \nHTTP (not the same as REST). Actually, there are several ways to create a \nremotely accessible API. This is one of the more popular ways to integrate, and \nsince it supports a procedure call style, it is easily understood by programmers \nused to calling procedures or methods. That\u2019s pretty much all of us.\nA second straightforward way to integrate Bounded Contexts is through the \nuse of a messaging mechanism. Each of the systems that need to interact do so \nthrough the use of a message queue or a Publish-Subscribe [Gamma et al.] mech-\nanism. Of course, these messaging gateways can well be thought of as an API, \nbut we may find broader acceptance if we simply refer to them as service inter-\nfaces instead. There are a large number of integration techniques that may be \nemployed when using messaging, many of them discussed in [Hohpe & Woolf].\nA third way to integrate Bounded Contexts is by using RESTful HTTP. Some \nthink of this as a kind of RPC approach, but it really is not. It has some simi-\nlar properties in that one system makes a request of another system, but these \nrequests are not made using procedures that take parameters. As discussed in \nArchitecture (4), REST is a means of exchanging and modifying resources that \nare uniquely identified using a distinct URI. Various operations can be per-\nformed on each resource. RESTful HTTP provides methods, primarily GET,\nPUT, POST, and DELETE. Even though these may seem to support only CRUD \noperations, using a little imagination allows us to actually categorize operations \nwith explicit intent within one of the four method categories. For example, GET\ncan be used to categorize various kinds of query operations, and PUT can be \nused to encapsulate a command operation that executes on an Aggregate (10).\nOf course, this in no way means that there are only three ways to integrate \napplications. You can, for example, use file-based integration and shared- \ndatabase integration, but doing so could make you old before your time.\nCowboy Logic \nAJ:  \n\u201cYou better take a low seat in your saddle. That \nhorse is a tough one and it\u2019ll make you feel old \nbefore your time.\u201d\nwww.EBooksWorld.ir\n", "page": 493, "type": "text", "section": "Page 493"}
{"text": " \nINTEGRATION BASICS\n451\nAlthough I\u2019ve highlighted three common ways that are used to integrate \nBounded Contexts, we\u2019ll actually stick with just two of those in this chapter. \nWe will mostly focus on integrating with messaging mechanisms but will see \nhow to use RESTful HTTP as well. We\u2019ll avoid examples using RPC because \nyou can easily imagine creating procedural APIs that could be used to replace \nthe other two approaches. Also, RPC has less resilience when our goal is to \nsupport autonomous services (aka autonomous applications). A failed system \nthat would normally provide an RPC-based API will prevent dependent sys-\ntems from succeeding in their own operations.\nThis brings up a topic of vital importance, which requires the attention of \nevery integration developer.\nDistributed Systems Are Fundamentally Different\nProblems always arise with integration when developers who are unfamiliar \nwith the principles of distributed systems gloss over its inherent complexity. \nThis can be especially true when using RPC, because those inexperienced \nwith distribution commonly imagine that any one remote call is as good as \nan in-process call. Such assumptions can cause cascading failure across any \nnumber of systems when just one system or one of its components becomes \nunavailable, even temporarily so. Thus, all developers working within dis-\ntributed systems will succeed or fail by the following Principles of Distributed \nComputing:\n\u2022 The network is not reliable.\n\u2022 There is always some latency, and maybe a lot.\n\u2022 Bandwidth is not infinite.\n\u2022 Do not assume that the network is secure.\n\u2022 Network topology changes.\n\u2022 Knowledge and policies are spread across multiple administrators.\n\u2022 Network transport has cost.\n\u2022 The network is heterogeneous.\nThese are purposely stated differently from the \u201cFallacies of Distributed Com-\nputing\u201d [Deutsch]. I call them principles to emphasize the challenges that must \nbe worked around and complexities that must be planned for, rather than the \nmistakes commonly made by the naive.\nwww.EBooksWorld.ir\n", "page": 494, "type": "text", "section": "Page 494"}
{"text": "Chapter 13 INTEGRATING BOUNDED CONTEXTS\n452\nExchanging Information across System Boundaries\nMost of the time when we need a foreign system to provide a service for our \nown system, we need to pass informational data to the service. The services we \nuse sometimes need to provide responses. Thus, we need a reliable way to pass \ninformational data between systems. This data needs to be exchanged between \ndisparate systems in a structure that is easily consumed by all involved. Most \nof us would choose to use some standard way to do that.\nInformational data sent as parameters or messages constitutes just \nmachine-readable structures that can be generated in one of many formats. We \nmust also create some form of contract between the data-exchanging systems, \nand possibly even the mechanisms to parse or interpret those structures, so \nthey can be consumed.\nThere are several ways to generate the structures used to exchange infor-\nmation between systems. One technical implementation simply relies on the \nprogramming language facilities to serialize objects into a binary format and \ndeserialize them on the consumer\u2019s side. This works well as long as all systems \nsupport the same language facilities, and if the serialization is actually com-\npatible or interchangeable between disparate hardware architectures. It also \nrequires you to deploy all the interfaces and classes of objects that are used \nacross systems to each system that uses the specific object type.\nAnother approach to building exchangeable information structures is to use \nsome standard intermediate format. Some options are to use XML, JSON, or \na specialized format such as Protocol Buffers. Each of these approaches has \nadvantages and disadvantages, some of which include richness and compact-\nness factors, performance of type conversions, support for flexibility between \nobject versions, and ease of use. Some of these can have costly impacts when \nconsidering the Principles of Distributed Computing listed earlier (for example, \n\u201cNetwork transport has cost\u201d).\nUsing this intermediate format approach, you may still desire to deploy all \nthe interfaces and classes of objects that are used across systems, and use a tool \nto place the data of the intermediate format into your type-safe objects. This \nhas the advantage that you can use objects the same way in the consuming sys-\ntem as you would in the source system.\nOf course, deploying these interfaces and classes also has related complexity, \nand it typically means that the consuming system will need to be recompiled \nto maintain compatibility with the latest versions of interface and class defi-\nnitions. There is also the danger of using the foreign objects freely in the con-\nsuming system as if they were our very own, which would tend to violate the \nvery DDD strategic design principles we have been fighting so hard to follow. \nSome may think that by declaring this as a Shared Kernel (3), it indemnifies the \nwww.EBooksWorld.ir\n", "page": 495, "type": "text", "section": "Page 495"}
{"text": " \nINTEGRATION BASICS\n453\napproach. However, be aware that the convenience of objects that are shared \nbetween systems can lead you down a slippery slope. Yet, regardless of the \ncomplexity and potential danger of polluted models, many believe that any \nstrong typing afforded by this tactic is a suitable trade-off for the required \ncomplexity.\nStill, I encounter those who struggle with this for various reasons, and they \noften wish for an easier and safer approach, but one that doesn\u2019t entirely dis-\ncard type safety. Let\u2019s consider such an approach.\nWhat if we could define a contract between the systems that produce the \nexchangeable information structures and those that consume them in such a \nway that the consumers could confidently use the data without deserializing \nit into object instances of specific classes? We can define such a reliable con-\ntract using a standards-based approach, which actually forms a Published Lan-\nguage (3). One such standard approach is to define a custom media type, or the \nsemantic equivalent. Whether or not you have good reason to register such a \nmedia type using the guidelines from RFC 4288, it is the actual specification \nthat matters. The specification defines the binding contract between producers \nand consumers and offers a foolproof means to exchange such media without \nsharing the interface and class binaries.\nThis does require some trade-offs, as always. You will not be able to navi-\ngate using property accessors as you would if you had the interfaces/classes for \neach object, and with associated type safety. You would also lack some IDE \nsupport, such as the ability to use code completion. This isn\u2019t really a big disad-\nvantage. Further, you would have no operational function/method support that \nhaving the Event class could provide. However, I do not see the lack of Event \noperational functions/methods as a disadvantage, but rather as a protection. \nThe consuming Bounded Context should be interested only in the data proper-\nties and should never be tempted to use functionality that is part of a different \nmodel. The consumer\u2019s Port Adapters (4) should shield its domain model from \nany such dependencies and must instead pass needed Event data as appropriate \nparameters with types as defined only in its own Bounded Context. Any neces-\nsary calculations or processing should be performed by the producing Bounded \nContext and provided as enriching Event data attributes.\nConsider an example. SaaSOvation needs to exchange media between its \nvarious Bounded Contexts. It will do so using RESTful resources and by \nsending messages containing Events (8) between services. In fact, one kind of \nRESTful resource is a notification, and Event-based messages are also sent \nto subscribers as Notification objects. In other words, in both cases the \nNotification holds an Event, and the two are formatted into a single struc-\nture. The custom media type specification for notifications and Events could \nindicate a contract that includes\nwww.EBooksWorld.ir\n", "page": 496, "type": "text", "section": "Page 496"}
{"text": "Chapter 13 INTEGRATING BOUNDED CONTEXTS\n454\n\u2022 Type: Notification format: JSON\n\u2022 notificationId: long integer unique identity\n\u2022 typeName: text String type of notification, an example type name \nbeing com.saasovation.agilepm.domain.model.product.\n\u03a6\nbacklogItem.BacklogItemCommitted\n\u2022 version: integer version of the notification\n\u2022 occurredOn: date/time when the notification\u2019s contained Event happened\n\u2022 event: JSON payload details; see specific Event types\nUsing the fully qualified class name (package name included) for the \ntypeName allows subscribers to precisely differentiate various Notifica-\ntion types. The notification specification would be followed by the various \nEvent type specifications. For one example, consider a familiar Event named \nBacklogItemCommitted:\n\u2022 Event type: com.saasovation.agilepm.domain.model.product.\n\u03a6\nbacklogItem.BacklogItemCommitted\n\u2022 eventVersion: integer version of the Event, which is the same as the \nNotification version\n\u2022 occurredOn: date/time when the Event occurred, which is the same as \nNotification occurredOn\n\u2022 backlogItemId: BacklogItemId, which contains the id text string \nattribute\n\u2022 committedToSprintId: SprintId, which contains the id text string \nattribute\n\u2022 tenantId: TenantId, which contains the id text string attribute\n\u2022 Event details: see specific Event types\nWe would, of course, specify the Event details for every Event type. \nWith the Notification and all Event types specified, we can safely use a \nNotification \nReader as demonstrated by this test:\nDomainEvent domainEvent = new TestableDomainEvent(100, \"testing\");\nNotification notification = new Notification(1, domainEvent);\nNotificationSerializer serializer =\n     NotificationSerializer.instance();\nwww.EBooksWorld.ir\n", "page": 497, "type": "text", "section": "Page 497"}
{"text": " \nINTEGRATION BASICS\n455\nString serializedNotification = serializer.serialize(notification);\nNotificationReader reader = \n     new NotificationReader(serializedNotification);\nassertEquals(1L, reader.notificationId());\nassertEquals(\"1\", reader.notificationIdAsString());\nassertEquals(domainEvent.occurredOn(), reader.occurredOn());\nassertEquals(notification.typeName(), reader.typeName());\nassertEquals(notification.version(), reader.version());\nassertEquals(domainEvent.eventVersion(), reader.version());\nThe test shows how the NotificationReader can provide type-safe stan-\ndard parts for every serialized Notification object.\nThe next test shows how the special parts of each Event\u2019s details can also \nbe read out of a Notification payload. Event object navigation is provided \nusing XPath-like syntax, or dot-separated properties, or you may use attribute \nnames separated by commas (Java varargs). You can see that each attribute \ncan be read as a String value or as its actual primitive type (int, long,\nboolean, double, and so on) if the type is other than String:\nTestableNavigableDomainEvent domainEvent =\n    new TestableNavigableDomainEvent(100, \"testing\");\nNotification notification = new Notification(1, domainEvent);\nNotificationSerializer serializer = NotificationSerializer.instance();\nString serializedNotification = serializer.serialize(notification);\nNotificationReader reader =\n     new NotificationReader(serializedNotification);\nassertEquals(\"\" + domainEvent.eventVersion(),\n    reader.eventStringValue(\"eventVersion\"));\nassertEquals(\"\" + domainEvent.eventVersion(),\n    reader.eventStringValue(\"/eventVersion\"));\nassertEquals(domainEvent.eventVersion(),\n    reader.eventIntegerValue(\"eventVersion\").intValue());\nassertEquals(domainEvent.eventVersion(),\n    reader.eventIntegerValue(\"/eventVersion\").intValue());\nassertEquals(\"\" + domainEvent.nestedEvent().eventVersion(),\n    reader.eventStringValue(\"nestedEvent\", \"eventVersion\"));\nassertEquals(\"\" + domainEvent.nestedEvent().eventVersion(),\n    reader.eventStringValue(\"/nestedEvent/eventVersion\"));\nassertEquals(domainEvent.nestedEvent().eventVersion(),\n    reader.eventIntegerValue(\"nestedEvent\", \"eventVersion\").intValue());\nassertEquals(domainEvent.nestedEvent().eventVersion(),\n    reader.eventIntegerValue(\"/nestedEvent/eventVersion\").intValue());\nwww.EBooksWorld.ir\n", "page": 498, "type": "text", "section": "Page 498"}
{"text": "Chapter 13 INTEGRATING BOUNDED CONTEXTS\n456\nassertEquals(\"\" + domainEvent.nestedEvent().id(),\n    reader.eventStringValue(\"nestedEvent\", \"id\"));\nassertEquals(\"\" + domainEvent.nestedEvent().id(),\n    reader.eventStringValue(\"/nestedEvent/id\"));\nassertEquals(domainEvent.nestedEvent().id(),\n    reader.eventLongValue(\"nestedEvent\", \"id\").longValue());\nassertEquals(domainEvent.nestedEvent().id(),\n    reader.eventLongValue(\"/nestedEvent/id\").longValue());\nassertEquals(\"\" + domainEvent.nestedEvent().name(),\n    reader.eventStringValue(\"nestedEvent\", \"name\"));\nassertEquals(\"\" + domainEvent.nestedEvent().name(),\n    reader.eventStringValue(\"/nestedEvent/name\"));\nassertEquals(\"\" + domainEvent.nestedEvent().occurredOn().getTime(),\n    reader.eventStringValue(\"nestedEvent\", \"occurredOn\"));\nassertEquals(\"\" + domainEvent.nestedEvent().occurredOn().getTime(),\n    reader.eventStringValue(\"/nestedEvent/occurredOn\"));\nassertEquals(domainEvent.nestedEvent().occurredOn(),\n    reader.eventDateValue(\"nestedEvent\", \"occurredOn\"));\nassertEquals(domainEvent.nestedEvent().occurredOn(),\n    reader.eventDateValue(\"/nestedEvent/occurredOn\"));\nassertEquals(\"\" + domainEvent.occurredOn().getTime(),\n    reader.eventStringValue(\"occurredOn\"));\nassertEquals(\"\" + domainEvent.occurredOn().getTime(),\n    reader.eventStringValue(\"/occurredOn\"));\nassertEquals(domainEvent.occurredOn(),\n    reader.eventDateValue(\"occurredOn\"));\nassertEquals(domainEvent.occurredOn(),\n    reader.eventDateValue(\"/occurredOn\"));\nThe TestableNavigableDomainEvent holds a TestableDomain-\nEvent, which allows us to test navigation to deeper attributes. The various \nattributes are read using XPath-like syntax with varargs attribute navigation. \nWe also test reading each attribute value as various types.\nSince Notification and Event instances always have a version number, \nyou can key off of the version to read specialized attributes in a specific ver-\nsion. Consumers that specialize in a given version can pick out the special parts \nthat they need. However, it is also possible for consumers to receive any given \nEvent-containing Notification as if it were version 1.\nThus, if we carefully consider how each Event type is designed, we can pro-\ntect most consumers from incompatibility when all they need is version 1 of a \ngiven Event. Such consumers never have to change or be recompiled when an \nEvent changes. Still, you really have to think in terms of the version compat-\nibility and plan for smart modifications to new versions so you don\u2019t break \nmost consumers. Sometimes it\u2019s impossible to achieve, but in many cases it is \nentirely possible.\nwww.EBooksWorld.ir\n", "page": 499, "type": "text", "section": "Page 499"}
{"text": " \nINTEGRATION BASICS\n457\nThis approach has the added advantage that Events can hold more than \njust primitive attributes and strings. Events may also safely hold instances of \nmore sophisticated Value Objects (6), which is especially effective when their \nValue types tend to be stable. This is certainly the case with BacklogItemId,\nSprintId, and TenantId, as demonstrated by the following code, this time \nusing dot-separated property navigation:\nNotificationReader reader =\n     new NotificationReader(backlogItemCommittedNotification);\nString backlogItemId = reader.eventStringValue(\"backlogItemId.id\"));\nString sprintId = reader.eventStringValue(\"sprintId.id\"));\nString tenantId = reader.eventStringValue(\"tenantId.id\"));\nThe fact that any held Value instances are frozen in the structure allows \nEvents to be not only immutable, but also eternally fixed. New versions of \nValue Object types contained by Events do not impact your ability to read \nolder versions of those Values from preexisting Notification instances. Cer-\ntainly, Protocol Buffers can be far easier to use when Event versions change \nsignificantly and often, and dealing with those changes becomes unwieldy for \nconsumers that use the NotificationReader.\nUnderstand that this is simply an option for gracefully handling deserializa-\ntion without deploying Event types and dependencies everywhere. Some will \nfind this approach quite elegant and liberating, while others will find it risky, \ninept, or downright dangerous. The opposite approach of deploying interfaces \nand classes everywhere the serialized objects are consumed is well known. \nHere I provide some food for thought by pointing out a less traveled road.\nCowboy Logic \nLB:  \n\u201cYou know, J, when a cowboy\u2019s too old to set a bad \nexample, he hands out good advice.\u201d\nIt is possible that each approach\u2014deploying classes to exchange serializa-\ntions versus defining a media type contract\u2014has an advantage at different \nstages of a project. For example, depending on the number of teams, Bounded \nwww.EBooksWorld.ir\n", "page": 500, "type": "text", "section": "Page 500"}
{"text": "Chapter 13 INTEGRATING BOUNDED CONTEXTS\n458\nContexts, change ratio, and other factors, it might work out to share classes \nand interfaces when your project is starting, but it could be better to use a \nmore decoupled, custom media type contract in the production stage. In prac-\ntice this may or may not work for a particular team or set of teams. Sometimes \nwhat a team starts out with ends up being what they live with ongoing, and \nthey never take the time to make a 180-degree change.\nTo keep our running examples simple and understandable, in the remain-\nder of the chapter I use the NotificationReader throughout. Whether or \nnot to use a custom media type contract and NotificationReader in your \nBounded Contexts is your choice to make.\nIntegration Using RESTful Resources\nWhen a Bounded Context provides a rich set of RESTful resources through \nURIs, it is a kind of Open Host Service (3):\nDefine a protocol that gives access to your subsystem as a set of services. Open \nthe protocol so that all who need to integrate with you can use it. Enhance and \nexpand the protocol to handle new integration requirements. [Evans]\nWe can well think of the HTTP methods\u2014GET, PUT, POST, and DELETE\u2014\ncombined with resources on which they operate, as a set of open services. \nHTTP and REST certainly form an open protocol allowing all who need to \nintegrate with the subsystem to do so. The fact that a virtually unlimited num-\nber of resources\u2014each with a unique identity through a URI\u2014can be created \nallows the protocol to handle new integration requirements as needed. It is a \nvery versatile way to allow clients to integrate with your Bounded Context.\nEven so, since the RESTful service provider must be directly interacted with \nwhenever a resource is operated on, this style does not permit clients to be com-\npletely autonomous. If the REST-based Bounded Context becomes unavailable \nfor some reason, dependent client Bounded Contexts will be unable to carry \nout necessary integration operations during any downtime.\nStill, we can overcome this to some extent by making dependence on REST-\nful resources a lesser obstacle to consumer autonomy. Even when RESTful (or \nRPC for that matter) is your only means to integrate, you can create the illu-\nsion of temporal decoupling by using timers or messaging in your own system. \nThat way your system will reach out to any remote systems only when a timer \nelapses or when a message is received. If the remote system is unavailable, the \ntimer threshold can be backed off, or if using messaging the message can be \nnegatively acknowledged to the broker and redelivered. This naturally places \nwww.EBooksWorld.ir\n", "page": 501, "type": "text", "section": "Page 501"}
{"text": " \nINTEGRATION USING RESTFUL RESOURCES\n459\nmore of a burden on your team to make the systems loosely coupled, but that\u2019s \na price you may have to pay to achieve autonomy.\nWhen the SaaSOvation team devel-\noping the Identity and Access Context\nneeded to create a way for integrators to \nuse their Bounded Context, they deter-\nmined that RESTful HTTP would be one \nof the best ways to open their system for \nintegration without directly exposing the \nstructural and behavioral details of their domain model. For them this meant design-\ning a set of RESTful resources that would provide representations of identity and \naccess concepts on a tenant-by-tenant basis.\nMuch of their design would allow integrating Bounded Contexts to GET resources \nthat convey user and group identity, and also indicate role-based security permis-\nsions for those identity types. For example, if an integration client needs to know if a \nuser within a given tenant could play a specific access role, the client should GET a \nresource using this URI format:\n   /tenants/{tenantId}/users/{username}/inRole/{role}\nIf the tenant\u2019s user is in the role, the resource representation is included in the \nsuccessful 200 response. Otherwise, the response is a 204 No Content status code if \nthe user does not exist or does not play that named role. It\u2019s a simple RESTful HTTP \ndesign.\nLet\u2019s look at how the team exposed the access resources and how integration \nclients could consume them in terms of the Ubiquitous Language (1) of their own \nBounded Context.\nImplementing the RESTful Resource\nAs SaaSOvation started applying REST principles to one of their Bounded \nContexts, they learned some important lessons. Let\u2019s look in on their journey.\nAs the SaaSOvation team working in the Identity and Access Context considered how \nto provide an Open Host Service for integrators, they considered simply exposing \ntheir domain model as a set of RESTful linked resources. That would mean allowing \nHTTP clients to GET a unique tenant resource and navigate through its users, groups, \nand roles. Was that a good idea? It seemed natural at first. After all, that would afford \nclients with the greatest flexibility. Clients could know everything about the domain \nmodel and just make decisions in their own Bounded Context.\nwww.EBooksWorld.ir\n", "page": 502, "type": "text", "section": "Page 502"}
{"text": "Chapter 13 INTEGRATING BOUNDED CONTEXTS\n460\nWhich DDD Context Mapping pattern best describes this design approach? In \nreality that is not an Open Host Service, but depending on the size of the shared \nmodel it would instead be a Shared Kernel or a Conformist (3). Publishing a Shared \nKernel or accepting a Conformist relationship puts consumers into a tightly coupled \nintegration with the consumed domain model. Those kinds of relationships should be \navoided if at all possible since they tend to run counter to the most fundamental goals \nof DDD.\nIt was a good thing that along the way the team found some good advice to avoid \nexposing their model to clients in that way. They learned to think of the use cases (or \nuser stories) that integrators needed. That was in harmony with this part of the Open \nHost Service definition: \u201cEnhance and expand the protocol to handle new integration \nrequirements.\u201d That means that you provide only what integrators need at present, \nand you understand those needs only by considering a range of use case scenarios.\nWhen the team followed that advice, they realized that, for example, what \nintegrators are really interested in is whether or not a given user can play a \nspecific role. Shielding the integrators from the details of understanding the \ndomain model would ultimately increase their productivity and make their \ndependent Bounded Contexts more maintainable. In terms of design it meant \nthat their User RESTful resource could include the following design:\n@Path(\"/tenants/{tenantId}/users\")\npublic class UserResource {\n    ...\n    @GET\n    @Path(\"{username}/inRole/{role}\")\n    @Produces({ OvationsMediaType.ID_OVATION_TYPE })\n    public Response getUserInRole(\n            @PathParam(\"tenantId\") String aTenantId,\n            @PathParam(\"username\") String aUsername,\n            @PathParam(\"role\") String aRoleName) {\n        Response response = null;\n        User user = null;\n        try {\n            user = this.accessService().userInRole(\n                        aTenantId, aUsername, aRoleName);\n        } catch (Exception e) {\n            // fall through\n        }\n        if (user != null) {\n            response = this.userInRoleResponse(user, aRoleName);\n        } else {\n            response = Response.noContent().build();\n        }\nwww.EBooksWorld.ir\n", "page": 503, "type": "text", "section": "Page 503"}
{"text": " \nINTEGRATION USING RESTFUL RESOURCES\n461\n        return response;\n    }\n    ...\n}\nIn the Hexagonal (4) or Ports and Adapters architecture, class User-\nResource is an Adapter for the RESTful HTTP Port provided by the JAX-RS \nimplementation. A consumer makes a request in the form\n    GET /tenants/{tenantId}/users/{username}/inRole/{role}\nThe Adapter delegates to the AccessService, an Application Service (14)\nthat provides an API at the inner hexagon. Being a direct client of the domain \nmodel, the AccessService manages the use case task and transaction. The \ntask includes finding whether or not the User exists at all, and if so, whether \nor not it plays the named role:\npackage com.saasovation.identityaccess.application;\n...\npublic class AccessService ... {\n    ...\n    @Transactional(readOnly=true)\n    public User userInRole(\n            String aTenantId,\n            String aUsername,\n            String aRoleName) {\n        User userInRole = null;\n        TenantId tenantId = new TenantId(new TenantId(aTenantId));\n        User user =\n            DomainRegistry\n                .userRepository()\n                .userWithUsername(tenantId, aUsername);\n        if (user != null) {\n            Role role =\n                DomainRegistry\n                    .roleRepository()\n                    .roleNamed(tenantId, aRoleName);\n            if (role != null) {\n                GroupMemberService groupMemberService =\n                        DomainRegistry.groupMemberService();\n                if (role.isInRole(user, groupMemberService)) {\n                    userInRole = user;\n                }\n            }\n        }\nwww.EBooksWorld.ir\n", "page": 504, "type": "text", "section": "Page 504"}
{"text": "Chapter 13 INTEGRATING BOUNDED CONTEXTS\n462\n        return userInRole;\n    }\n    ...\n}\nThe Application Service finds both the User and the named Role Aggre-\ngate. When the Role query method isInRole() is called, a GroupMember-\nService is passed in. This is not an Application Service, but rather a Domain \nService (7) that helps the Role perform certain domain-specific checks and \nqueries that the Role itself should not be responsible for.\nThe Response from the UserResource is formed from the resolved User\nand the specific role name, using one of the custom media types:\npackage com.saasovation.common.media;\npublic class OvationsMediaType {\n    public static final String COLLAB_OVATION_TYPE =\n            \"application/vnd.saasovation.collabovation+json\";\n    public static final String ID_OVATION_TYPE =\n            \"application/vnd.saasovation.idovation+json\";\n    public static final String PROJECT_OVATION_TYPE =\n            \"application/vnd.saasovation.projectovation+json\";\n    ...\n}\nWhen the user is in the named role, the UserResource Adapter produces an \nHTTP response with a JSON representation like the following:\nHTTP/1.1 200 OK\nContent-Type: application/vnd.saasovation.idovation+json\n...\n{\n    \"role\":\"Author\",\"username\":\"zoe\",\n    \"tenantId\":\"A94A8298-43B8-4DA0-9917-13FFF9E116ED\",\n    \"firstName\":\"Zoe\",\"lastName\":\"Doe\",\n    \"emailAddress\":\"zoe@saasovation.com\"\n}\nAs you will see next, the integrating consumer of this RESTful resource \ncan translate it into the specific kind of domain object needed by its Bounded \nContext.\nwww.EBooksWorld.ir\n", "page": 505, "type": "text", "section": "Page 505"}
{"text": " \nINTEGRATION USING RESTFUL RESOURCES\n463\nImplementing the REST Client Using an Anticorruption Layer\nAlthough the JSON representation produced by the Identity and Access Con-\ntext is quite useful to the client integrators, when we are focused on the goals \nof DDD, the representation will not be consumed as is in the client Bounded \nContext. As discussed in previous chapters, if the consumer is the Collabo-\nration Context, the team is not interested in primitive users and their roles. \nInstead, the team developing in the collaboration model is interested in the \ndomain-specific roles. The fact that in some other model there is a set of User\nobjects that can be assigned to one or more roles as modeled by a Role object \nis really not in the collaboration sweet spot.\nSo, then, how do we make the user-in-role representation serve our specific \ncollaboration purposes? Let\u2019s take another look at a previously drawn Con-\ntext Map, this time found in Figure 13.1. The important parts of the User-\nResource Adapter were shown in the previous subsection. This leaves the \ninterfaces and classes to be developed specifically for the Collaboration Con-\ntext. These are the CollaboratorService, the UserInRoleAdapter, and \nCollaboration Context\nIdentity and Access\nContext\nHttpClient (Facade)\nCollaboratorService\nCollaboratorTranslator\nUserResource\n/tenants/(tenantId)/users/(username/inRole/(role)\nUserInRoleAdapter\nFigure 13.1 The Open Host Service of the Identity and Access Context and \nthe Anticorruption Layer of the Collaboration Context used for integration \nbetween the two\nwww.EBooksWorld.ir\n", "page": 506, "type": "text", "section": "Page 506"}
{"text": "Chapter 13 INTEGRATING BOUNDED CONTEXTS\n464\nthe CollaboratorTranslator. There is also the HttpClient, but that is \nprovided by the JAX-RS implementation through the classes ClientRequest\nand ClientResponse.\nThe trio of CollaboratorService, UserInRoleAdapter, and  \nCol- \nlaboratorTranslator is used to form an Anticorruption Layer (3), the \nmeans by which the Collaboration Context will interact with the Identity and \nAccess Context and translate the user-in-role representation into a Value \nObject for a specific kind of Collaborator.\nHere\u2019s interface CollaboratorService, which forms the simple opera-\ntions of the Anticorruption Layer:\npublic interface CollaboratorService  {\n    public Author authorFrom(Tenant aTenant, String anIdentity);\n    public Creator creatorFrom(Tenant aTenant, String anIdentity);\n    public Moderator moderatorFrom(Tenant aTenant, String anIdentity);\n    public Owner ownerFrom(Tenant aTenant, String anIdentity);\n    public Participant participantFrom(\n            Tenant aTenant, String anIdentity);\n}\nFrom the viewpoint of the clients of CollaboratorService, the interface \ncompletely abstracts away the complexity of the remote system access and sub-\nsequent translations from the Published Language to objects that adhere to \nthe local Ubiquitous Language. In this particular case we do use a Separated \nInterface [Fowler, P of EAA] and an implementation class because the imple-\nmentation is technical and should not reside in the Domain Layer.\nAll of these Factories (11) are very similar to each other. They all create \na subclass of the abstract Collaborator Value type, but only if the user \nwithin aTenant and having anIdentity plays the security role within one \nof the five types: Author, Creator, Moderator, Owner, and Participant.\nSince they are so similar, let\u2019s look at just one of the method implementations, \nauthorFrom():\npackage com.saasovation.collaboration.infrastructure.services;\nimport com.saasovation.collaboration.domain.model.collaborator.Author;\n...\npublic class TranslatingCollaboratorService\n       implements CollaboratorService  {\n    ...\n    @Override\n    public Author authorFrom(Tenant aTenant, String anIdentity) {\n        Author author =\nwww.EBooksWorld.ir\n", "page": 507, "type": "text", "section": "Page 507"}
{"text": " \nINTEGRATION USING RESTFUL RESOURCES\n465\n            this.userInRoleAdapter\n                .toCollaborator(\n                        aTenant,\n                        anIdentity,\n                        \"Author\",\n                        Author.class);\n        return author;\n    }\n    ...\n}\nFirst note that TranslatingCollaboratorService is in a Module (9)\nof the Infrastructure. We create the Separated Interface in the inner hexagon as \npart of the domain model. Yet, the implementation is technical and is housed \nat the outside of the Hexagonal architecture, where the Ports and Adapters \nreside.\nAs part of the technical implementation, generally an Anticorruption Layer \nwill have a specialized Adapter [Gamma et al.] and a translator. Looking again \nat Figure 13.1, you can see that our specific Adapter is UserInRoleAdapter,\nand the translator is the CollaboratorTranslator. The specialized User-\nInRoleAdapter of this Anticorruption Layer is responsible for reaching out \nto the remote system, requesting the necessary user-in-role resource:\npackage com.saasovation.collaboration.infrastructure.services;\nimport org.jboss.resteasy.client.ClientRequest;\nimport org.jboss.resteasy.client.ClientResponse;\n...\npublic class UserInRoleAdapter {\n    ...\n    public <T extends Collaborator> T toCollaborator(\n            Tenant aTenant,\n            String anIdentity,\n            String aRoleName,\n            Class<T> aCollaboratorClass) {\n        T collaborator = null;\n        try {\n            ClientRequest request =\n                    this.buildRequest(aTenant, anIdentity, aRoleName);\n            ClientResponse<String> response =\n                    request.get(String.class);\n            if (response.getStatus() == 200) {\n                collaborator =\n                    new CollaboratorTranslator()\nwww.EBooksWorld.ir\n", "page": 508, "type": "text", "section": "Page 508"}
{"text": "Chapter 13 INTEGRATING BOUNDED CONTEXTS\n466\n                        .toCollaboratorFromRepresentation(\n                            response.getEntity(),\n                            aCollaboratorClass);\n            } else if (response.getStatus() != 204) {\n                throw new IllegalStateException(\n                        \"There was a problem requesting the user: \"\n                        + anIdentity\n                        + \" in role: \"\n                        + aRoleName\n                        + \" with resulting status: \"\n                        + response.getStatus());\n            }\n        } catch (Throwable t) {\n            throw new IllegalStateException(\n                    \"Failed because: \" + t.getMessage(), t);\n        }\n        return collaborator;\n    }\n    ...\n}\nIf the response to the GET request is successful (status 200), it means that \nthe UserInRoleAdapter has received a user-in-role resource, which can now \nbe translated into our Collaborator subclass:\npackage com.saasovation.collaboration.infrastructure.services;\nimport java.lang.reflect.Constructor;\nimport com.saasovation.common.media.RepresentationReader;\n...\npublic class CollaboratorTranslator {\n    public CollaboratorTranslator() {\n        super();\n    }\n    public <T extends Collaborator> T toCollaboratorFromRepresentation(\n            String aUserInRoleRepresentation,\n            Class<T> aCollaboratorClass)\n    throws Exception {\n        RepresentationReader reader =\n                new RepresentationReader(aUserInRoleRepresentation);\n        String username = reader.stringValue(\"username\");\n        String firstName = reader.stringValue(\"firstName\");\n        String lastName = reader.stringValue(\"lastName\");\n        String emailAddress = reader.stringValue(\"emailAddress\");\nwww.EBooksWorld.ir\n", "page": 509, "type": "text", "section": "Page 509"}
{"text": " \nINTEGRATION USING RESTFUL RESOURCES\n467\n        T collaborator =\n            this.newCollaborator(\n                    username,\n                    firstName,\n                    lastName,\n                    emailAddress,\n                    aCollaboratorClass);\n        return collaborator;\n    }\n    private <T extends Collaborator> T newCollaborator(\n            String aUsername,\n            String aFirstName,\n            String aLastName,\n            String aEmailAddress,\n            Class<T> aCollaboratorClass)\n    throws Exception {\n        Constructor<T> ctor =\n            aCollaboratorClass.getConstructor(\n                    String.class, String.class, String.class);\n        T collaborator =\n            ctor.newInstance(\n                    aUsername,\n                    (aFirstName + \" \" + aLastName).trim(),\n                    aEmailAddress);\n        return collaborator;\n    }\n}\nThis translator takes a user-in-role representation text String and the \nClass to be used to create the Collaborator subclass instance. First the \nRepresentationReader\u2014quite similar to the NotificationReader\nintroduced previously\u2014is used to read four attributes out of the JSON rep-\nresentation. Again, we can confidently and reliably do this because the SaaS-\nOvation custom media type forms a binding contract between producers and \nconsumers. After the translator has the necessary String values, it uses them \nto instantiate the Collaborator Value Object and, in the case of this exam-\nple, an Author:\npackage com.saasovation.collaboration.domain.model.collaborator;\npublic final class Author \n       extends Collaborator  {\nwww.EBooksWorld.ir\n", "page": 510, "type": "text", "section": "Page 510"}
{"text": "Chapter 13 INTEGRATING BOUNDED CONTEXTS\n468\n    public Author(\n            String anIdentity,\n            String aName,\n            String anEmailAddress) {\n        super(anIdentity, aName, anEmailAddress);\n    }\n    ...\n}\nThere is no effort made to keep Collaborator Value instances synchro-\nnized with the Identity and Access Context. They are immutable and can \nonly be fully replaced, not modified. Here\u2019s how an Author is obtained by an \nApplication Service and then given to a Forum to start a new Discussion:\npackage com.saasovation.collaboration.application;\n...\npublic class ForumService ... {\n    ...\n    @Transactional\n    public Discussion startDiscussion(\n            String aTenantId,\n            String aForumId,\n            String anAuthorId,\n            String aSubject) {\n        Tenant tenant = new Tenant(aTenantId);\n        ForumId forumId = new ForumId(aForumId);\n        Forum forum = this.forum(tenant, forumId);\n        if (forum == null) {\n            throw new IllegalStateException(\"Forum does not exist.\");\n        }\n        Author author =\n                this.collaboratorService.authorFrom(\n                        tenant, anAuthorId);\n        Discussion newDiscussion =\n                forum.startDiscussion(\n                        this.forumNavigationService(),\n                        author,\n                        aSubject);\n        this.discussionRepository.add(newDiscussion);\n        return newDiscussion;\n    }\n    ...\n}\nwww.EBooksWorld.ir\n", "page": 511, "type": "text", "section": "Page 511"}
{"text": " \nINTEGRATION USING MESSAGING\n469\nIf a Collaborator name or e-mail address changes in the Identity and \nAccess Context, such changes won\u2019t be automatically updated in the Collab-\noration Context. Those kinds of changes rarely occur, so the team made the \ndecision to keep this particular design simple and not attempt to synchronize \nchanges in the remote Context with objects in their local Context. We will \nsee, however, that the Agile Project Management Context has different design \ngoals.\nThere are other ways to implement an Anticorruption Layer, such as by \nmeans of a Repository (12). However, since Repositories are typically used \nto persist and reconstitute Aggregates, creating Value Objects by that means \nseems misplaced. If our goal is to produce an Aggregate from an Anticorrup-\ntion Layer, a Repository may be a more natural source.\nIntegration Using Messaging\nA message-based approach to integration can allow any one system to achieve \na higher degree of autonomy from systems it depends on. As long as the mes-\nsaging infrastructure remains operational, messages can be sent and delivered \neven when any one system is unavailable.\nOne of the ways that DDD can be leveraged to make systems autonomous \nis through the use of Domain Events. When something of significance happens \nin one system, it produces an Event about it. There will tend to be several or \neven many such Events that occur in each system, and you will create a unique \nkind of Event as a means to record each. As Events occur, they are published \nto interested parties by means of a messaging mechanism. That\u2019s just a big-pic-\nture review. In case you bypassed the details of this topic in earlier chapters, \nyou may be better off getting some background from Architecture (4), Domain \nEvents (8), and Aggregates (10) before continuing here.\nStaying Informed about Product Owners and Team Members\nThe Agile Project Management Context needs to manage a pool of Scrum \nproduct owners and team members for each tenant that subscribes to the ser-\nvice. At any time a product owner can create a new product and then assign \nteam members to the team. How can the Scrum project management appli-\ncation know who plays each of these roles? The answer is that it won\u2019t go it \nalone.\nActually, the Agile Project Management Context is going to allow those \nroles to be managed by the Identity and Access Context, a natural and fitting \nwww.EBooksWorld.ir\n", "page": 512, "type": "text", "section": "Page 512"}
{"text": "Chapter 13 INTEGRATING BOUNDED CONTEXTS\n470\nchoice. In that system each tenant that subscribes to the Scrum service will \nhave two Role instances created: ScrumProductOwner and ScrumTeam-\nMember. Each User who needs to play one of those roles will be assigned to it. \nHere\u2019s the Application Service method in the Identity and Access Context that \nmanages the task of assigning a User to a Role:\npackage com.saasovation.identityaccess.application;\n...\npublic class AccessService ... {\n    ...\n    @Transactional\n    public void assignUserToRole(AssignUserToRoleCommand aCommand) {\n        TenantId tenantId =\n                new TenantId(aCommand.getTenantId());\n        User user =\n                this.userRepository\n                    .userWithUsername(\n                            tenantId,\n                            aCommand.getUsername());\n        if (user != null) {\n            Role role =\n                    this.roleRepository\n                        .roleNamed(\n                                tenantId,\n                                aCommand.getRoleName());\n            if (role != null) {\n                role.assignUser(user);\n            }\n        }\n    }\n    ...\n}\nGreat, but how does this help the Agile Project Management Context know \nwho is in the role of a ScrumTeamMember or ScrumProductOwner? Here\u2019s \nhow. When method assignUser() of the Role completes, its last responsibil-\nity is to publish an Event:\npackage com.saasovation.identityaccess.domain.model.access;\n...\npublic class Role extends Entity {\n    ...\n    public void assignUser(User aUser) {\nwww.EBooksWorld.ir\n", "page": 513, "type": "text", "section": "Page 513"}
{"text": " \nINTEGRATION USING MESSAGING\n471\n        if (aUser == null) {\n            throw new NullPointerException(\"User must not be null.\");\n        }\n        if (!this.tenantId().equals(aUser.tenantId())) {\n            throw new IllegalArgumentException(\n                    \"Wrong tenant for this user.\");\n        }\n        this.group().addUser(aUser);\n        DomainEventPublisher\n            .instance()\n            .publish(new UserAssignedToRole(\n                    this.tenantId(),\n                    this.name(),\n                    aUser.username(),\n                    aUser.person().name().firstName(),\n                    aUser.person().name().lastName(),\n                    aUser.person().emailAddress()));\n    }\n    ...\n}\nEvent UserAssignedToRole, enriched with User name and e-mail \naddress properties, is eventually delivered to all interested parties. When the \nAgile Project Management Context receives the Event, it will use it to ensure \nthat a new TeamMember or ProductOwner is established in its model. This \nis not a terribly difficult use case. Yet, there are more details to manage than \nmay at first meet the eye. Let\u2019s break these down.\nAs it turns out, there are some highly reusable aspects to listening for notifi-\ncations from RabbitMQ. We already have a simple object-oriented library that \nhelps make the RabbitMQ Java client easier to use. Now we\u2019re going to add \none more simple class to make becoming an exchange queue consumer really \nsimple:\npackage com.saasovation.common.port.adapter.messaging.rabbitmq;\n...\npublic abstract class ExchangeListener {\n    private MessageConsumer messageConsumer;\n    private Queue queue;\n    public ExchangeListener() {\n        super();\n        this.attachToQueue();\nwww.EBooksWorld.ir\n", "page": 514, "type": "text", "section": "Page 514"}
{"text": "Chapter 13 INTEGRATING BOUNDED CONTEXTS\n472\n        this.registerConsumer();\n    }\n    protected abstract String exchangeName();\n    protected abstract void filteredDispatch(\n            String aType, String aTextMessage);\n    protected abstract String[] listensToEvents();\n    protected String queueName() {\n        return this.getClass().getSimpleName();\n    }\n    private void attachToQueue() {\n        Exchange exchange =\n                Exchange.fanOutInstance(\n                        ConnectionSettings.instance(),\n                        this.exchangeName(),\n                        true);\n        this.queue =\n                Queue.individualExchangeSubscriberInstance(\n                        exchange,\n                        this.exchangeName() + \".\" + this.queueName());\n    }\n    private Queue queue() {\n        return this.queue;\n    }\n    private void registerConsumer() {\n        this.messageConsumer =\n                MessageConsumer.instance(this.queue(), false);\n        this.messageConsumer.receiveOnly(\n                this.listensToEvents(),\n                new MessageListener(MessageListener.Type.TEXT) {\n            @Override\n            public void handleMessage(\n                    String aType,\n                    String aMessageId,\n                    Date aTimestamp,\n                    String aTextMessage,\n                    long aDeliveryTag,\n                    boolean isRedelivery)\n            throws Exception {\n                filteredDispatch(aType, aTextMessage);\n            }\n        });\n    }\n}\nwww.EBooksWorld.ir\n", "page": 515, "type": "text", "section": "Page 515"}
{"text": " \nINTEGRATION USING MESSAGING\n473\nThe ExchangeListener is an abstract base class that concrete lis-\ntener subclasses reuse. A concrete subclass need add only a little bit of code \nin addition to extending the abstract base class. First, it just ensures that the \ndefault base class constructor is invoked, which always happens anyway. \nThen all that\u2019s left is to implement three abstract methods, two of which are \nvery simple to implement: exchangeName(), filteredDispatch(), and \nlistensToEvents().\nTo implement exchangeName() all that is needed is to return the String\nname of the exchange for which the concrete listener consumes notifications. \nTo implement the abstract method listensToEvents() you must answer a \nString[] of notification types that you want to receive. Many listeners will \nconsume only one type of notification and so would answer an array with \nonly one element. The one remaining method, filteredDispatch(), is the \nmost complex of the three because it is responsible for the heavy lifting of han-\ndling received messages. To see how it works, let\u2019s take a look at the listener of \nEvent-carrying notifications for UserAssignedToRole:\npackage com.saasovation.agilepm.infrastructure.messaging;\n...\npublic class TeamMemberEnablerListener extends ExchangeListener {\n    @Autowired\n    private TeamService teamService;\n    public TeamMemberEnablerListener() {\n        super();\n    }\n    @Override\n    protected String exchangeName() {\n        return Exchanges.IDENTITY_ACCESS_EXCHANGE_NAME;\n    }\n    @Override\n    protected void filteredDispatch(\n                String aType,\n                String aTextMessage) {\n        NotificationReader reader =\n                new NotificationReader(aTextMessage);\n        String roleName = reader.eventStringValue(\"roleName\");\n        if (!roleName.equals(\"ScrumProductOwner\") &&\n            !roleName.equals(\"ScrumTeamMember\")) {\n            return;\n        }\nwww.EBooksWorld.ir\n", "page": 516, "type": "text", "section": "Page 516"}
{"text": "Chapter 13 INTEGRATING BOUNDED CONTEXTS\n474\n        String emailAddress = reader.eventStringValue(\"emailAddress\");\n        String firstName = reader.eventStringValue(\"firstName\");\n        String lastName = reader.eventStringValue(\"lastName\");\n        String tenantId = reader.eventStringValue(\"tenantId.id\");\n        String username = reader.eventStringValue(\"username\");\n        Date occurredOn = reader.occurredOn();\n        if (roleName.equals(\"ScrumProductOwner\")) {\n            this.teamService.enableProductOwner(\n                    new EnableProductOwnerCommand(\n                        tenantId,\n                        username,\n                        firstName,\n                        lastName,\n                        emailAddress,\n                        occurredOn));\n        } else {\n            this.teamService.enableTeamMember(\n                    new EnableTeamMemberCommand(\n                        tenantId,\n                        username,\n                        firstName,\n                        lastName,\n                        emailAddress,\n                        occurredOn));\n        }\n    }\n    @Override\n    protected String[] listensToEvents() {\n        return new String[] {\n                \"com.saasovation.identityaccess.domain.model.\u03a6\naccess.UserAssignedToRole\"\n                };\n    }\n}\nThe ExchangeListener default constructor is properly invoked, \nexchangeName() answers the name of the exchange published to by the \nIdentity and Access Context, and method listensToEvents() answers \na one-element array with the fully qualified class name of Event User-\nAssignedToRole. Note that publishers and subscribers should consider the \nuse of fully qualified class names, which includes the Module name and the \nclass name. This removes all possible collision or ambiguity that could exist \nwith same or similarly named Events from different Bounded Contexts.\nAgain, it is filteredDispatch() that contains the bulk of the behavior. \nThe method is named as it is because it can further filter the notification before \nit dispatches to the Application Service API. In this case it does filter before \nwww.EBooksWorld.ir\n", "page": 517, "type": "text", "section": "Page 517"}
{"text": " \nINTEGRATION USING MESSAGING\n475\ndispatching, by ignoring all notifications of type UserAssignedToRole\nthat are not conveying Events about the roles named ScrumProduct \nOwner\nand ScrumTeamMember. On the other hand, if the roles are the ones we \nare interested in receiving Events about, we get the UserAssignedToRole\ndetails out of the notification and dispatch to the Application Service named \nTeamService. Each of the Service methods enableProductOwner() and \nenableTeamMember() takes a command object, either EnableProduct-\nOwnerCommand or EnableTeamMemberCommand, respectively.\nAt first it might seem that a member would just be created as a result of one \nof these Events. However, since it is possible that each User could be assigned \nto one of these Roles, and then later unassigned, and then reassigned, it\u2019s \npossible that the member represented by the User in the received notification \nalready exists. Here\u2019s how the TeamService deals with that situation:\npackage com.saasovation.agilepm.application;\n...\npublic class TeamService ... {\n    @Autowired\n    private ProductOwnerRepository productOwnerRepository;\n    @Autowired\n    private TeamMemberRepository teamMemberRepository;\n    ...\n    @Transactional\n    public void enableProductOwner(\n                EnableProductOwnerCommand aCommand) {\n        TenantId tenantId = new TenantId(aCommand.getTenantId());\n        ProductOwner productOwner =\n                this.productOwnerRepository.productOwnerOfIdentity(\n                        tenantId,\n                        aCommand.getUsername());\n        if (productOwner != null) {\n            productOwner.enable(aCommand.getOccurredOn());\n        } else {\n            productOwner =\n                    new ProductOwner(\n                            tenantId,\n                            aCommand.getUsername(),\n                            aCommand.getFirstName(),\n                            aCommand.getLastName(),\n                            aCommand.getEmailAddress(),\n                            aCommand.getOccurredOn());\nwww.EBooksWorld.ir\n", "page": 518, "type": "text", "section": "Page 518"}
{"text": "Chapter 13 INTEGRATING BOUNDED CONTEXTS\n476\n            this.productOwnerRepository.add(productOwner);\n        }\n    }\n}\nFor example, Service method enableProductOwner() deals with the \npossibility that the specific ProductOwner already exists. If it does exist, we \nassume that it may need to be enabled again, so we dispatch to the correspond-\ning command operation. If the ProductOwner does not yet exist, we instan-\ntiate a new Aggregate and add it to its Repository. Actually, we deal with the \nTeamMember in the same way, so enableTeamMember() is implemented in \nthe same way.\nCan You Handle the Responsibility?\nThis all seems fine and good. It appears simple enough. We have Product-\nOwner and TeamMember Aggregate types, and we\u2019ve designed them so \nthat each holds some information about the backing User from the foreign \nBounded Context. But did you realize how much responsibility we\u2019ve just \nassumed by designing these Aggregates that way?\nRecall that in the Collaboration Context the team decided to just create \nimmutable Value Objects that hold similar information (see \u201cImplementing \nthe REST Client Using an Anticorruption Layer\u201d). Because the Values are \nimmutable, the team will never have to worry about keeping the shared infor-\nmation up-to-date. Of course, the downside to that advantage is that if some \nof the shared information is updated, the Collaboration Context will never \nupdate the related objects that it created in the past. So the Agile Project Man-\nagement team went for the opposite trade-off.\nNow, however, there are a few challenges to keeping the Aggregates up-to-\ndate. Why? Can\u2019t we just listen for additional Event-carrying notifications that \nreflect changes to the User instances that correspond to our ProductOwner\nand TeamMember instances? Yes, indeed, we can and must do so. But the fact \nthat we are using a messaging infrastructure makes this just a bit more chal-\nlenging than might be obvious.\nFor example, what would happen if in the Identity and Access Context a \nmanager mistakenly unassigns Joe Johnson from the ScrumTeamMember\nrole? Well, we receive an Event-carrying notification that indicates that fact, \nso we use the TeamService to disable the TeamMember corresponding to \nJoe Johnson. Wait. Seconds later the manager realizes that she has unassigned \nthe wrong user from the ScrumTeamMember role, and that she should have \nunassigned Joe Jones instead. So she quickly assigns Joe Johnson back to the \nwww.EBooksWorld.ir\n", "page": 519, "type": "text", "section": "Page 519"}
{"text": " \nINTEGRATION USING MESSAGING\n477\nrole and unassigns Joe Jones. Next, the Agile Project Management Context\nreceives the corresponding notifications, and everyone is happy (except maybe \nJoe Jones). Or, is everything actually OK?\nWe could be making a bad assumption about this use case. We are assuming \nthat we receive the notifications in the order in which they actually occurred \nin the Identity and Access Context. Yet, things might not always work out so \nwell. What would happen if, for whatever reason, the notifications about Joe \nJohnson were received in this order, UserAssignedToRole and then User-\nUnassignedFromRole? What will happen is that the TeamMember corre-\nsponding to Joe Johnson will be stuck in a disabled state, and at best someone \nwill have to patch the data in the Agile PM database, or the manager will \nhave to play some tricks to get the right Joe reenabled. This can happen, and \nironically, it seems to always happen when we overlook the fact that it could \nhappen. So, how do we prevent this?\nLet\u2019s take a closer look at the command objects that we pass as parameters \nto the TeamService APIs. For example, consider the commands Enable-\nTeamMemberCommand and DisableTeamMemberCommand. Each of these \nrequires a Date object, namely, occurredOn, to be provided. In fact, all of \nour command objects are designed this way. We will use the occurredOn\nvalues to ensure that our ProductOwner and TeamMember Aggregates deal \nwith the command operations in a time-aware way. Thinking back to the use \ncase that could have caused us trouble before, let\u2019s see what would happen if we \ndealt with the possibility of the UserUnassignedFromRole arriving after \nUserAssignedToRole, even though they occurred in the opposite order:\npackage com.saasovation.agilepm.application;\n...\npublic class TeamService ... {\n    ...\n    @Transactional\n    public void disableTeamMember(DisableTeamMemberCommand aCommand) {\n        TenantId tenantId = new TenantId(aCommand.getTenantId());\n        TeamMember teamMember =\n                this.teamMemberRepository.teamMemberOfIdentity(\n                        tenantId,\n                        aCommand.getUsername());\n        if (teamMember != null) {\n            teamMember.disable(aCommand.getOccurredOn());\n        }\n    }\n}\nwww.EBooksWorld.ir\n", "page": 520, "type": "text", "section": "Page 520"}
{"text": "Chapter 13 INTEGRATING BOUNDED CONTEXTS\n478\nNote that when we dispatch to the TeamMember disable() command \nmethod, we are required to pass an occurredOn value from the command \nobject. The TeamMember will use this internally to make certain that dis-\nabling takes place only if it should:\npackage com.saasovation.agilepm.domain.model.team;\n...\npublic abstract class Member extends Entity  {\n    ...\n    private MemberChangeTracker changeTracker;\n    ...\n    public void disable(Date asOfDate) {\n        if (this.changeTracker().canToggleEnabling(asOfDate)) {\n            this.setEnabled(false);\n            this.setChangeTracker(\n                    this.changeTracker().enablingOn(asOfDate));\n        }\n    }\n    public void enable(Date asOfDate) {\n        if (this.changeTracker().canToggleEnabling(asOfDate)) {\n            this.setEnabled(true);\n            this.setChangeTracker(\n                    this.changeTracker().enablingOn(asOfDate));\n        }\n    }\n    ...\n}\nNote that this Aggregate behavior is provided by a common abstract base \nclass, Member. Both the disable() and the enable() methods are designed \nto query a changeTracker to determine whether the requested operation \ncan be carried out according to the asOfDate parameter (the command\u2019s \noccurredOn value). The MemberChangeTracker Value Object maintains \nthe occurrence of the most recent related operation and uses that to answer the \nquery:\npackage com.saasovation.agilepm.domain.model.team;\n...\npublic final class MemberChangeTracker implements Serializable  {\n    private Date emailAddressChangedOn;\n    private Date enablingOn;\n    private Date nameChangedOn;\n    ...\n    public boolean canToggleEnabling(Date asOfDate) {\n        return this.enablingOn().before(asOfDate);\n    }\n    ...\nwww.EBooksWorld.ir\n", "page": 521, "type": "text", "section": "Page 521"}
{"text": " \nINTEGRATION USING MESSAGING\n479\n    public MemberChangeTracker enablingOn(Date asOfDate) {\n        return new MemberChangeTracker(\n                asOfDate,\n                this.nameChangedOn(),\n                this.emailAddressChangedOn());\n    }\n    ...\n}\nIf the operation is permitted and carried out, a replacement MemberChange-\nTracker instance is obtained by using the corresponding enablingOn()\nmethod. Since we can expect PersonNameChanged and PersonContact-\nInformationChanged changes to possibly arrive out of order, the same \nkinds of facilities are available with emailAddressChangedOn and name-\nChangedOn. In fact, there is one additional check for the case of e-mail \naddress changes. It\u2019s possible that PersonContactInformationChanged\nEvents are indicating a change of telephone number or postal address rather \nthan a less common e-mail address change:\npackage com.saasovation.agilepm.domain.model.team;\n...\npublic abstract class Member extends Entity  {\n    ...\n    public void changeEmailAddress(\n        String anEmailAddress,\n        Date asOfDate) {\n        if (this.changeTracker().canChangeEmailAddress(asOfDate) &&\n            !this.emailAddress().equals(anEmailAddress)) {\n            this.setEmailAddress(anEmailAddress);\n            this.setChangeTracker(\n                this.changeTracker().emailAddressChangedOn(asOfDate));\n        }\n    }\n    ...\n}\nHere we check to see if in fact the e-mail address has changed. If it has not, \nwe don\u2019t want to track it as changed. If we did so, an out-of-order Event of the \nsame type that did in fact carry a changed e-mail address would be ignored.\nThe MemberChangeTracker also serves to make Member subclass com-\nmand operations idempotent, such that when the same notification is delivered \nmultiple times by the messaging infrastructure, redundant deliveries are ignored.\nWe might argue that introducing the MemberChangeTracker in the \nAggregate design is a mistake. We might conclude that this has nothing to do \nwww.EBooksWorld.ir\n", "page": 522, "type": "text", "section": "Page 522"}
{"text": "Chapter 13 INTEGRATING BOUNDED CONTEXTS\n480\nwith the Ubiquitous Language of Scrum-based teams. That is true. However, \nwe never expose the MemberChangeTracker outside the Aggregate bound-\nary. It is an implementation detail, and clients will never know it exists. The \nonly detail that clients are aware of is that they must supply the occurredOn\nvalue for when the corresponding fact of a modification took place. What is \nmore, this is exactly the kind of implementation detail that Pat Helland calls \nfor as he describes how partner relationships are managed in his treatment of \nscalable, distributed systems that are eventually consistent. In that paper [Hel-\nland], specifically see section 5, \u201cActivities: Coping with Messy Messages.\u201d\nNow, back to dealing with our new responsibilities . . .\nAlthough this is a very basic example of maintaining changes to duplicate \ninformation originating in a foreign Bounded Context, it is not a trivial respon-\nsibility to take on, at least not if you are using a messaging mechanism that \ncould deliver messages out of order and more than once.1 Further, when we \nrealize all of the possible operations in the Identity and Access Context that \ncould have some kind of impact on just the few attributes that we maintain in \nMember, it can be a wake-up call:\n\u2022 PersonContactInformationChanged\n\u2022 PersonNameChanged\n\u2022 UserAssignedToRole\n\u2022 UserUnassignedFromRole\nAnd then we realize that there are a few other Events that could be just as \nimportant to react to:\n\u2022 UserEnablementChanged\n\u2022 TenantActivated\n\u2022 TenantDeactivated\nThese facts emphasize that, if at all possible, it is best to minimize or even \ncompletely eliminate information duplication across Bounded Contexts. It may \nnot be possible to entirely avoid the duplication of information. SLAs may \nmake it impractical to retrieve remote data every time it is needed. That\u2019s one \n 1. This could be a case where using the RESTful approach to notification consump-\ntion could be a distinct advantage since the notifications are guaranteed to be \ndelivered in the same order in which they were appended to the Event Store (4, \nAppendix A). The notifications, from first to last, can be consumed over and over \nagain for different reasons with the same order guarantees each time.\nwww.EBooksWorld.ir\n", "page": 523, "type": "text", "section": "Page 523"}
{"text": " \nINTEGRATION USING MESSAGING\n481\nof the motivations the team had to hold the personal name of the User and the \nuser\u2019s e-mail address locally. However, having the goal to reduce the amount of \nforeign information we take responsibility for will make our jobs much easier. \nIt\u2019s integrating with a minimalist\u2019s mindset.\nOf course, there is no way to avoid duplication of tenant and user identity, \nand identity duplication across Bounded Contexts is necessary in general. That \nis one of the primary ways that Bounded Contexts can integrate at all. Besides, \nidentity is safe to share because it is immutable. We can even use Aggregate dis-\nabling and soft deletions to ensure that referenced objects never disappear, as \nwe do, for example, with Tenant, User, ProductOwner, and TeamMember.\nThis call to attention doesn\u2019t mean that Domain Events should not be \nenriched with information-conveying properties. Certainly, Events must pro-\nvide enough information to inform consumers of the kinds of steps that they \nmust take in response to past facts. Still, it is possible for Event data to be \nused to perform calculations and derive state in consuming foreign Bounded \nContexts while not actually holding on to and assuming the responsibility for \nkeeping it synchronized with its official state located in the system of record.\nLong-Running Processes, and Avoiding Responsibility\nIf we likened what we described in the previous section to being a responsi-\nble adult, we might compare this section to an attempt to return to our teen-\nage years. You know, adults have to assume all kinds of responsibility. Parents \nhave to buy cars, insure them, pay to put gasoline in the tank, and spend their \nmoney to repair them. As teens we just want to use our parents\u2019 car, but not \npay for any of its expenses. There\u2019s no way teenagers are going to make a car \npayment for their parents, fill the tank with gasoline, pay for a mechanic, or \ncover the cost of insurance. They just allow their parents to take care of that \nhorrible R-word stuff so they can have all the fun.\nWhat we are doing in this section is having fun with Long-Running Pro-\ncesses (4), but making sure we refuse to accept any of the painful responsibil-\nities required when we duplicate information from other Bounded Contexts. \nWe will just let the system of record deal with its own information after we\u2019ve \nhad all the fun making that foreign Bounded Context create and maintain data \nfor us.\nIn Context Maps (3) we were presented with the Create a Product use case:\nPrecondition: The collaboration feature is enabled (option was purchased).\n \n 1. The user provides Product descriptive information.\n \n 2. The user indicates a desire for a team discussion.\nwww.EBooksWorld.ir\n", "page": 524, "type": "text", "section": "Page 524"}
{"text": "Chapter 13 INTEGRATING BOUNDED CONTEXTS\n482\n \n 3. The user requests that the defined Product be created.\n \n 4. The system creates the Product with a Forum and Discussion.\nHere\u2019s where the fun begins, and where we kick responsibility across the \nnetwork.\nIn Context Maps (3) the team proposed using a RESTful approach to inte-\ngration between these two Bounded Contexts. However, the team finally set-\ntled on a message-based solution instead.\nAlso, one of the first things that you may notice is that the proposed concept \noriginally added to the Ubiquitous Language as Discussion (in Chapter 3) \nhas been refined. The Agile Project Management team saw the need to differ-\nentiate between the types of discussions, so there are now two different types: \nProductDiscussion and BacklogItemDiscussion. (In this section we \nare concerned only with ProductDiscussion.) Both Value Objects have \nthe same basic state and behavior, but the distinction adds type safety to help \ndevelopers avoid attaching the wrong discussions to Product and Backlog-\nItem. For all practical purposes, they are the same. Each of these two discus-\nsion types just holds its availability and, if a discussion was established, the \nidentity of the actual Discussion Aggregate instance in the Collaboration \nContext.\nIt is worth stating that the original proposal in the Agile Project Manage-\nment Context to name one Value Object the same as the Aggregate in the Col-\nlaboration Context was not an error in judgment. Thus, to be completely clear, \nthe Value Object\u2019s name was not changed from Discussion to Product-\nDiscussion in order to distinguish it from the Aggregate in the Collabora-\ntion Context. From the standpoint of Context Mapping it would have been \nperfectly fine to leave the Value Object\u2019s name as it was, because the Con-\ntext is what distinguished the two objects. The decision to create two distinct \nValue types in the Agile Project Management Context was made only from the \nrequirements of the isolated local model.\nTo dive in, let\u2019s first take a look at the Application Service (API) that is used \nto create a Product:\npackage com.saasovation.agilepm.application;\n...\npublic class ProductService ... {\n    @Autowired\n    private ProductRepository productRepository;\n    @Autowired\n    private ProductOwnerRepository productOwnerRepository;\n    ...\nwww.EBooksWorld.ir\n", "page": 525, "type": "text", "section": "Page 525"}
{"text": " \nINTEGRATION USING MESSAGING\n483\n    @Transactional\n    public String newProductWithDiscussion(\n                NewProductCommand aCommand) {\n        return this.newProductWith(\n                aCommand.getTenantId(),\n                aCommand.getProductOwnerId(),\n                aCommand.getName(),\n                aCommand.getDescription(),\n                this.requestDiscussionIfAvailable());\n    }\n    ...\n}\nThere are actually two ways to create a new Product. The first method, \nnot shown here, creates a Product without a Discussion, while the one \nseen here does attempt to cause a ProductDiscussion to eventually be cre-\nated and attached to the Product. The two internal methods, newProduct-\nWith() and requestDiscussionIfAvailable(), are not shown here. The \nlatter method is used to check whether or not the CollabOvation add-on is \nenabled. If it is, the availability state REQUESTED is returned; otherwise, the \nstate return value is ADD_ON_NOT_ENABLED. Method newProductWith()\ninvokes the Product constructor, so let\u2019s look at the constructor next:\npackage com.saasovation.agilepm.domain.model.product;\n...\npublic class Product extends ConcurrencySafeEntity  {\n    ...\n    public Product(\n            TenantId aTenantId,\n            ProductId aProductId,\n            ProductOwnerId aProductOwnerId,\n            String aName,\n            String aDescription,\n            DiscussionAvailability aDiscussionAvailability) {\n        this();\n        this.setTenantId(aTenantId);\n        this.setProductId(aProductId);\n        this.setProductOwnerId(aProductOwnerId);\n        this.setName(aName);\n        this.setDescription(aDescription);\n        this.setDiscussion(\n                ProductDiscussion.fromAvailability(\n                        aDiscussionAvailability));\nwww.EBooksWorld.ir\n", "page": 526, "type": "text", "section": "Page 526"}
{"text": "Chapter 13 INTEGRATING BOUNDED CONTEXTS\n484\n        DomainEventPublisher\n            .instance()\n            .publish(new ProductCreated(\n                this.tenantId(),\n                this.productId(),\n                this.productOwnerId(),\n                this.name(),\n                this.description(),\n                this.discussion().availability().isRequested()));\n    }\n    ...\n}\nThe client is required to pass a DiscussionAvailability, which \nmay convey one of the following states: ADD_ON_NOT_ENABLED, NOT_\nREQUESTED, or REQUESTED. The READY state is reserved as a completion \nstate. Either of the first two states results in the creation of a Product-\nDiscussion with that exact state, which means there won\u2019t be an associ-\nated discussion, at least not as a result of construction. Given a request with \nthe third state, REQUESTED, the ProductDiscussion will be created with \na PENDING_SETUP state. Here\u2019s the ProductDiscussion Factory Method \nused by the Product constructor:\npackage com.saasovation.agilepm.domain.model.product;\n...\npublic final class ProductDiscussion implements Serializable {\n    ...\n    public static ProductDiscussion fromAvailability(\n            DiscussionAvailability anAvailability) {\n        if (anAvailability.isReady()) {\n            throw new IllegalArgumentException(\n                    \"Cannot be created ready.\");\n        }\n        DiscussionDescriptor descriptor =\n                new DiscussionDescriptor(\n                        DiscussionDescriptor.UNDEFINED_ID);\n        return new ProductDiscussion(descriptor, anAvailability);\n    }\n    ...\n}\nAs long as the request is not for the READY state, which would be a prob-\nlem, we get a ProductDiscussion with one of the three other states and an \nundefined descriptor. If the state is REQUESTED, a Long-Running Process will \nwww.EBooksWorld.ir\n", "page": 527, "type": "text", "section": "Page 527"}
{"text": " \nINTEGRATION USING MESSAGING\n485\nmanage the creation of the collaborative discussion and its subsequent initi-\nation with the Product. How? Recall that the last thing the Product con-\nstructor does is publish the ProductCreated Event:\npackage com.saasovation.agilepm.domain.model.product;\n    ...\n    public Product(...) {\n        ...\n        DomainEventPublisher\n            .instance()\n            .publish(new ProductCreated(\n                this.tenantId(),\n                this.productId(),\n                this.productOwnerId(),\n                this.name(),\n                this.description(),\n                this.discussion().availability().isRequested()));\n    }\n    ...\n}\nIf the state of the discussion availability is REQUESTED, the last parameter \nto the Event constructor will be true, which is exactly what is needed to start \nthe Long-Running Process.\nThink back to Domain Events (8); every single Event instance, including \nthose of type ProductCreated, is appended to an Event Store for the specific \nBounded Context in which the Event occurred. All newly appended Events are \nthen forwarded from the Event Store to interested parties by means of a mes-\nsaging mechanism. In the case of SaaSOvation, the teams have decided to use \nRabbitMQ for that purpose. We need to create a simple Long-Running Process \nto manage the creation of the discussion and then attach it to the Product.\nBefore moving on to the details of the Long-Running Process, let\u2019s consider \none more possible way that a discussion is requested. What if when a given \nProduct instance is first created, either a discussion is not requested, or the \ncollaboration add-on is only enabled? Later on the product owner decides to \nadd a discussion, and the add-on is now available. The product owner can now \nuse this command method on the Product:\npackage com.saasovation.agilepm.domain.model.product;\n...\npublic class Product extends ConcurrencySafeEntity  {\n    ...\n    public void requestDiscussion(\n            DiscussionAvailability aDiscussionAvailability) {\nwww.EBooksWorld.ir\n", "page": 528, "type": "text", "section": "Page 528"}
{"text": "Chapter 13 INTEGRATING BOUNDED CONTEXTS\n486\n        if (!this.discussion().availability().isReady()) {\n            this.setDiscussion(\n                    ProductDiscussion.fromAvailability(\n                            aDiscussionAvailability));\n            DomainEventPublisher\n                .instance()\n                .publish(new ProductDiscussionRequested(\n                    this.tenantId(),\n                    this.productId(),\n                    this.productOwnerId(),\n                    this.name(),\n                    this.description(),\n                    this.discussion().availability().isRequested()));\n        }\n    }\n    ...\n}\nMethod requestDiscussion() takes the familiar Discussion-\nAvailability parameter, because the client must prove to the Product that \nthe collaboration add-on is enabled. Of course, the client could cheat here and \nalways pass REQUESTED, but that would just end up in a dead-end bug if the \nadd-on is actually not available. Here, too, if the state of the discussion avail-\nability is REQUESTED, the last parameter to the Event constructor will be true, \nwhich is exactly what is needed to start the Long-Running Process:\npackage com.saasovation.agilepm.domain.model.product;\n...\npublic class ProductDiscussionRequested implements DomainEvent {\n    ...\n    public ProductDiscussionRequested(\n            TenantId aTenantId,\n            ProductId aProductId,\n            ProductOwnerId aProductOwnerId,\n            String aName,\n            String aDescription,\n            boolean isRequestingDiscussion) {\n        ...\n    }\n    ...\n}\nThis Event has exactly the same properties as ProductCreated, which will \nallow both Event types to be handled by the same listener.\nWe might ask whether publishing this Event makes any sense if the avail-\nability state is not REQUESTED. It does make sense, because whether or not \nwww.EBooksWorld.ir\n", "page": 529, "type": "text", "section": "Page 529"}
{"text": " \nINTEGRATION USING MESSAGING\n487\nthe request can be fulfilled, the request was still made, unless it is currently in \nREADY state. It is the responsibility of listeners to determine whether or not to \nactually do something in response to the Event. Perhaps receiving this Event \nwith isRequestingDiscussion set to false indicates a problem, or setup \nof the add-on is in progress but still not done. Therefore, some intervention \nmay be necessary. The process may need to send an e-mail to the administrator \ngroup, for example.\nThe classes used to manage the Long-Running Process on the Agile Proj-\nect Management Context side are similar to those used to manage the cre-\nation and maintenance of the ProductOwner and TeamMember Aggregates \n(see the previous section). Each of the listeners presented here is wired using \nSpring such that it is instantiated as the Spring application context is created \nfor this Bounded Context. The first listener registers itself to receive two kinds \nof notifications on the AGILEPM_EXCHANGE_NAME, ProductCreated, and \nProductDiscussionRequested:\npackage com.saasovation.agilepm.infrastructure.messaging;\n...\npublic class ProductDiscussionRequestedListener\n       extends ExchangeListener {\n    ...\n    @Override\n    protected String exchangeName() {\n        return Exchanges.AGILEPM_EXCHANGE_NAME;\n    }\n    ...\n    @Override\n    protected String[] listensToEvents() {\n        return new String[] {\n                \"com.saasovation.agilepm.domain.model\u03a6\n.product.ProductCreated\",\n                \"com.saasovation.agilepm.domain.model\u03a6\n.product.ProductDiscussionRequested\"\n                };\n    }\n    ...\n}\nThe COLLABORATION_EXCHANGE_NAME is the interest of the second lis-\ntener, and specifically for notification DiscussionStarted:\npackage com.saasovation.agilepm.infrastructure.messaging;\n...\npublic class DiscussionStartedListener extends ExchangeListener {\n    ...\nwww.EBooksWorld.ir\n", "page": 530, "type": "text", "section": "Page 530"}
{"text": "Chapter 13 INTEGRATING BOUNDED CONTEXTS\n488\n    @Override\n    protected String exchangeName() {\n        return Exchanges.COLLABORATION_EXCHANGE_NAME;\n    }\n    ...\n    @Override\n    protected String[] listensToEvents() {\n        return new String[] {\n                \"com.saasovation.collaboration.domain.model.\u03a6\nforum.DiscussionStarted\"\n                };\n    }\n    ...\n}\nYou can probably see where this is going. If either ProductCreated or \nProductDiscussionRequested is received by the first listener, it will dis-\npatch a command to the Collaboration Context to have a new Forum and \nDiscussion created on behalf of the Product. When that request is fulfilled \nby the components in the Collaboration Context, the DiscussionStarted\nnotification is published and, once received, the corresponding discussion \nidentity will be initiated on the Product. That\u2019s the long and short of this \nLong-Running Process. Here is how the filteredDispatch() works in the \nfirst listener:\npackage com.saasovation.agilepm.infrastructure.messaging;\n...\npublic class ProductDiscussionRequestedListener\n        extends ExchangeListener {\n    private static final String COMMAND =\n           \"com.saasovation.collaboration.discussion.\u03a6\nCreateExclusiveDiscussion\";\n    ...\n    @Override\n    protected void filteredDispatch(\n                String aType,\n                String aTextMessage) {\n        NotificationReader reader =\n                new NotificationReader(aTextMessage);\n        if (!reader.eventBooleanValue(\"requestingDiscussion\")) {\n            return;\n        }\n        Properties parameters = this.parametersFrom(reader);\n        PropertiesSerializer serializer =\n                PropertiesSerializer.instance();\n        String serialization = serializer.serialize(parameters);\n        String commandId = this.commandIdFrom(parameters);\nwww.EBooksWorld.ir\n", "page": 531, "type": "text", "section": "Page 531"}
{"text": " \nINTEGRATION USING MESSAGING\n489\n        this.messageProducer()\n            .send(\n                serialization,\n                MessageParameters\n                    .durableTextParameters(\n                            COMMAND,\n                            commandId,\n                            new Date()))\n            .close();\n    }\n    ...\n}\nIn the case of either Event type, ProductCreated or Product-\nDiscussionRequested, if the requestingDiscussion attribute is \nfalse, we ignore the Event. Otherwise, we build up a CreateExclusive-\nDiscussion command from the Event\u2019s state and send the command to the \nmessage exchange of the Collaboration Context.\nThis is a good time to pause and reflect on how this process is designed. \nShould the Agile Project Management Context really set up a listener to an \nEvent published by a local Aggregate? Would it be better to create a listener for \nthe ProductCreated Event in the Collaboration Context instead? If we did \nso, we could simply have the listener in the Collaboration Context manage the \ncreation of the exclusive Forum and Discussion, and it would eliminate a bit \nof code from the Agile Project Management Context. To determine which is \nthe better approach requires the consideration of a few factors.\nDoes it make sense that an upstream Bounded Context listens for Events \npublished from a downstream Context? Or, in an Event-Driven Architecture \n(4), are systems really upstream and downstream to each other? Need they be \ncast in that mold? Possibly the more important factor to consider is whether it \nwould be correct for a ProductCreated Event to be interpreted in the Col-\nlaboration Context as indicating that an exclusive Forum and Discussion\nshould be created. In fact, does ProductCreated actually have any meaning \nat all to the Collaboration Context? How many other Contexts may eventually \ndesire similar automatic support for this very feature given their own unique \nEvent types? Is it best to place such a burden to support any number of for-\neign Events as creation commands on the Collaboration Context? Yet, there \nis another factor to consider, which requires us to more carefully manage the \nsuccess of Long-Running Processes. This topic, discussed just a bit later, may \nhelp to settle why we\u2019ve approached it in this particular way.\nNow, back to the example . . . Once received in the Collaboration Con-\ntext, the command is adapted to pass to the ForumService, which is an \nwww.EBooksWorld.ir\n", "page": 532, "type": "text", "section": "Page 532"}
{"text": "Chapter 13 INTEGRATING BOUNDED CONTEXTS\n490\nApplication Service. Note that this API has not yet been designed to use com-\nmand parameters but rather takes individual attribute parameters:\npackage com.saasovation.collaboration.infrastructure.messaging;\n...\npublic class ExclusiveDiscussionCreationListener\n        extends ExchangeListener {\n    @Autowired\n    private ForumService forumService;\n    ...\n    @Override\n    protected void filteredDispatch(\n                String aType,\n                String aTextMessage) {\n        NotificationReader reader =\n                new NotificationReader(aTextMessage);\n        String tenantId = reader.eventStringValue(\"tenantId\");\n        String exclusiveOwnerId =\n                reader.eventStringValue(\"exclusiveOwnerId\");\n        String forumSubject = reader.eventStringValue(\"forumTitle\");\n        String forumDescription =\n                reader.eventStringValue(\"forumDescription\");\n        String discussionSubject =\n                reader.eventStringValue(\"discussionSubject\");\n        String creatorId = reader.eventStringValue(\"creatorId\");\n        String moderatorId = reader.eventStringValue(\"moderatorId\");\n        forumService.startExclusiveForumWithDiscussion(\n            tenantId,\n            creatorId,\n            moderatorId,\n            forumSubject,\n            forumDescription,\n            discussionSubject,\n            exclusiveOwnerId);\n    }\n    ...\n}\nThat makes sense, but shouldn\u2019t this ExclusiveDiscussionCreation-\nListener send a response message back to the Agile Project Management \nContext? Well, not exactly. Both the Forum and Discussion Aggregates \npublish an Event in response to their respective creation: ForumStarted and \nDiscussionStarted. This Bounded Context publishes all its Domain Events \nthough its exchange, defined by COLLABORATION_EXCHANGE_NAME. That\u2019s \nwhy the DiscussionStartedListener in the Agile Project Management \nwww.EBooksWorld.ir\n", "page": 533, "type": "text", "section": "Page 533"}
{"text": " \nINTEGRATION USING MESSAGING\n491\nContext receives the DiscussionStarted Event. And here\u2019s what that lis-\ntener does when it receives the Event:\npackage com.saasovation.agilepm.infrastructure.messaging;\n...\npublic class DiscussionStartedListener extends ExchangeListener {\n    @Autowired\n    private ProductService productService;\n    ...\n    @Override\n    protected void filteredDispatch(\n                String aType,\n                String aTextMessage) {\n        NotificationReader reader =\n                new NotificationReader(aTextMessage);\n        String tenantId = reader.eventStringValue(\"tenant.id\");\n        String productId = reader.eventStringValue(\"exclusiveOwner\");\n        String discussionId =\n                reader.eventStringValue(\"discussionId.id\");\n        productService.initiateDiscussion(\n                new InitiateDiscussionCommand(\n                    tenantId,\n                    productId,\n                    discussionId));\n    }\n    ...\n}\nThis listener adapts the received notification\u2019s Event properties to pass as a \ncommand to the ProductService Application Service. This initiateDis-\ncussion() service method works like this:\npackage com.saasovation.agilepm.application;\n...\npublic class ProductService ... {\n    @Autowired\n    private ProductRepository productRepository;\n    ...\n    @Transactional\n    public void initiateDiscussion(\n                InitiateDiscussionCommand aCommand) {\n        Product product =\n                productRepository\n                    .productOfId(\n                            new TenantId(aCommand.getTenantId()),\n                            new ProductId(aCommand.getProductId()));\nwww.EBooksWorld.ir\n", "page": 534, "type": "text", "section": "Page 534"}
{"text": "Chapter 13 INTEGRATING BOUNDED CONTEXTS\n492\n        if (product == null) {\n            throw new IllegalStateException(\n                    \"Unknown product of tenant id: \"\n                    + aCommand.getTenantId()\n                    + \" and product id: \"\n                    + aCommand.getProductId());\n        }\n        product.initiateDiscussion(\n                new DiscussionDescriptor(\n                        aCommand.getDiscussionId()));\n    }\n    ...\n}\nUltimately the Product Aggregate\u2019s initiateDiscussion() behavior is \nexecuted:\npackage com.saasovation.agilepm.domain.model.product;\n...\npublic class Product extends ConcurrencySafeEntity  {\n    ...\n    public void initiateDiscussion(DiscussionDescriptor aDescriptor) {\n        if (aDescriptor == null) {\n            throw new IllegalArgumentException(\n                    \"The descriptor must not be null.\");\n        }\n        if (this.discussion().availability().isRequested()) {\n            this.setDiscussion(this.discussion()\n                          .nowReady(aDescriptor));\n            DomainEventPublisher\n                .instance()\n                .publish(new ProductDiscussionInitiated(\n                        this.tenantId(),\n                        this.productId(),\n                        this.discussion()));\n        }\n    }\n    ...\n}\nIf the Product discussion property is still in the REQUESTED state, it \nis transitioned to the READY state with the DiscussionDescriptor, which \nholds an identity reference to the exclusive Discussion in the Collaboration \nContext. The request for a Forum and Discussion to be created for and \nassociated with the Product has just become consistent, although it happened \neventually.\nwww.EBooksWorld.ir\n", "page": 535, "type": "text", "section": "Page 535"}
{"text": " \nINTEGRATION USING MESSAGING\n493\nHowever, if discussion is in the READY state at the time of this com-\nmand invocation, it is not further transitioned. Is this a bug? No. It is one \nway to ensure that initiateDiscussion() is an idempotent operation. The \nassumption must be made that if the state is currently READY, the Long-Run-\nning Process has already completed. Perhaps any subsequent command invoca-\ntion is due to a notification redelivery, since the team chose to use a messaging \nmechanism that delivers messages at least once. Whatever the case, we need \nnot be concerned because the idempotent operation allows for any number \nof infrastructure and architectural influences to be harmlessly ignored when \nthey should be. Further, in this specific case we didn\u2019t need to design with \na ProductChangeTracker as we did for the Member subclasses and their \nMemberChangeTracker. The simple fact that the discussion is READY\ntells us all we need to know.\nThere could be a problem with this overall approach, however. What hap-\npens if the Long-Running Process experiences some sort of problem due to the \nmessaging mechanism? How would we ensure that the process is run com-\npletely to its finish? Well, it\u2019s probably time for the teenager to grow up a little.\nProcess State Machines and Time-out Trackers\nWe can make this process more mature by adding a concept similar to that \ndescribed under Long-Running Processes (4). The SaaSOvation developers \ncreated a reusable concept that they named TimeConstrainedProcess-\nTracker. A tracker watches for processes whose allotted time for completion \nhas expired, and those that can be retried any number of times prior to expir-\ning. The tracker design allows for retries at fixed intervals if desired and can \neventually completely time-out after no retries at all, or after a determined \nnumber of retries.\nTo clarify, the tracker is not part of the Core Domain. It is rather part of a \ntechnical Subdomain that any SaaSOvation project can reuse. This means that \nin some cases we aren\u2019t overly concerned with the rules of Aggregates when \npersisting trackers and later causing their modification. Trackers are relatively \nisolated and won\u2019t tend to face concurrency conflicts since there is a one-to-one \nrelationship with the associated process. However, if there are conflicts, we \ncan count on messaging retries to help our cause. Any exception in the context \nof a notification delivery will cause the listener to NAK the message, which in \nturn causes RabbitMQ to redeliver. Still, we don\u2019t anticipate the necessity of a \ngreat number of retries.\nIt is the Product that holds the current state of the process, and in that con-\ntext a tracker will publish the following Event when a retry interval is reached, \nor when the observed process completely times out:\nwww.EBooksWorld.ir\n", "page": 536, "type": "text", "section": "Page 536"}
{"text": "Chapter 13 INTEGRATING BOUNDED CONTEXTS\n494\npackage com.saasovation.agilepm.domain.model.product;\nimport com.saasovation.common.domain.model.process.ProcessId;\nimport com.saasovation.common.domain.model.process.ProcessTimedOut;\npublic class ProductDiscussionRequestTimedOut extends ProcessTimedOut {\n    public ProductDiscussionRequestTimedOut(\n            String aTenantId,\n            ProcessId aProcessId,\n            int aTotalRetriesPermitted,\n            int aRetryCount) {\n        super(aTenantId, aProcessId,\n              aTotalRetriesPermitted, aRetryCount);\n    }\n}\nEvents that subclass ProcessTimedOut are used by the tracker when retry \nintervals or full time-outs have been reached. Event listeners can use Event \nmethod hasFullyTimedOut() to determine whether the Event signifies a full \ntime-out or is just a retry. If retries are permitted, assuming listeners have use of \nthe ProcessTimedOut class, they can ask the Event for indicators and values \nsuch as allowsRetries(), retryCount(), totalRetriesPermitted(),\nand totalRetriesReached().\nArmed with the ability to receive notifications about retries and time-\nouts, we can make the Product participate in a better process. First, \nwe need to start the process, and we can do that from our existing \nProductDiscussionRequestedListener:\npackage com.saasovation.agilepm.infrastructure.messaging;\n...\npublic class ProductDiscussionRequestedListener\n        extends ExchangeListener {\n    @Override\n    protected void filteredDispatch(\n                String aType,\n                String aTextMessage) {\n        NotificationReader reader =\n                new NotificationReader(aTextMessage);\n        if (!reader.eventBooleanValue(\"requestingDiscussion\")) {\n            return;\n        }\n        String tenantId = reader.eventStringValue(\"tenantId.id\");\n        String productId = reader.eventStringValue(\"product.id\");\nwww.EBooksWorld.ir\n", "page": 537, "type": "text", "section": "Page 537"}
{"text": " \nINTEGRATION USING MESSAGING\n495\n        productService.startDiscussionInitiation(\n                new StartDiscussionInitiationCommand(\n                        tenantId,\n                        productId));\n        // send command to Collaboration Context\n        ...\n    }\n    ...\n}\nThe ProductService creates the tracker and persists it, and it associates the \nprocess with the given Product:\npackage com.saasovation.agilepm.application;\n...\npublic class ProductService ... {\n    ...\n    @Transactional\n    public void startDiscussionInitiation(\n            StartDiscussionInitiationCommand aCommand) {\n        Product product =\n                productRepository\n                    .productOfId(\n                            new TenantId(aCommand.getTenantId()),\n                            new ProductId(aCommand.getProductId()));\n        if (product == null) {\n            throw new IllegalStateException(\n                    \"Unknown product of tenant id: \"\n                    + aCommand.getTenantId()\n                    + \" and product id: \"\n                    + aCommand.getProductId());\n        }\n        String timedOutEventName =\n                ProductDiscussionRequestTimedOut.class.getName();\n        TimeConstrainedProcessTracker tracker =\n                new TimeConstrainedProcessTracker(\n                        product.tenantId().id(),\n                        ProcessId.newProcessId(),\n                        \"Create discussion for product: \"\n                            + product.name(),\n                        new Date(),\n                        5L * 60L * 1000L, // retries every 5 minutes\n                        3, // 3 total retries\n                        timedOutEventName);\n        processTrackerRepository.add(tracker);\nwww.EBooksWorld.ir\n", "page": 538, "type": "text", "section": "Page 538"}
{"text": "Chapter 13 INTEGRATING BOUNDED CONTEXTS\n496\n        product.setDiscussionInitiationId(\n                tracker.processId().id());\n    }\n    ...\n}\nThe TimeConstrainedProcessTracker is instantiated to retry three \ntimes every five minutes, if necessary. True, we may not normally hard-code \nthese values, but doing so allows us to see clearly how the tracker is created.\nDid You Detect a Possible Problem Here?\nThe retry specification we are using could contribute to problems if we aren\u2019t care-\nful, but we\u2019ll leave the design as is for now and act as if we think it\u2019s all right.\nIt is this approach of creating a tracker on behalf of the Product that may \nbest address the reason we have handled the ProductCreated Event locally, \nrather than having it interpreted in the Collaboration Context. This gives our \nown system the opportunity to set up process management and decouple the \nProductCreated Event from the command in the Collaboration Context,\nnamely, CreateExclusiveDiscussion.\nA background timer will fire regularly to check on process elapsed times. \nThe timer will delegate to method checkForTimedOutProcesses() in the \nProcessService:\npackage com.saasovation.agilepm.application;\n...\npublic class ProcessService ... {\n    ...\n    @Transactional\n    public void checkForTimedOutProcesses() {\n        Collection<TimeConstrainedProcessTracker> trackers =\n            processTrackerRepository.allTimedOut();\n        for (TimeConstrainedProcessTracker tracker : trackers) {\n            tracker.informProcessTimedOut();\n        }\n    }\n    ...\n}\nIt\u2019s the tracker\u2019s method informProcessTimedOut() that confirms the \nneed to retry or time-out a process and, if confirmed, publishes the Process-\nTimedOut Event subclass.\nNext, we need to add a new listener to handle retries and  \ntime-outs. Up \nto three retries may occur every five minutes as needed. It\u2019s the Product-\nDiscussionRetryListener:\nwww.EBooksWorld.ir\n", "page": 539, "type": "text", "section": "Page 539"}
{"text": " \nINTEGRATION USING MESSAGING\n497\npackage com.saasovation.agilepm.infrastructure.messaging;\n...\npublic class ProductDiscussionRetryListener extends ExchangeListener {\n    @Autowired\n    private ProcessService processService;\n    ...\n    @Override\n    protected String exchangeName() {\n        return Exchanges.AGILEPM_EXCHANGE_NAME;\n    }\n    @Override\n    protected void filteredDispatch(\n                String aType,\n                String aTextMessage) {\n        Notification notification =\n            NotificationSerializer\n                .instance()\n                .deserialize(aTextMessage, Notification.class);\n        ProductDiscussionRequestTimedOut event =\n                notification.event();\n        if (event.hasFullyTimedOut()) {\n            productService.timeOutProductDiscussionRequest(\n                    new TimeOutProductDiscussionRequestCommand(\n                            event.tenantId(),\n                            event.processId().id(),\n                            event.occurredOn()));\n        } else {\n            productService.retryProductDiscussionRequest(\n                    new RetryProductDiscussionRequestCommand(\n                            event.tenantId(),\n                            event.processId().id()));\n        }\n    }\n    @Override\n    protected String[] listensToEvents() {\n        return new String[] {\n                \"com.saasovation.agilepm.process.\u03a6\nProductDiscussionRequestTimedOut\"\n                };\n    }\n}\nThis listener is interested only in ProductDiscussionRequestTimedOut\nEvents and is designed to work with any number of retry and time-out permu-\ntations. It\u2019s the process and tracker that determine how many times it could \nwww.EBooksWorld.ir\n", "page": 540, "type": "text", "section": "Page 540"}
{"text": "Chapter 13 INTEGRATING BOUNDED CONTEXTS\n498\npossibly be notified. Events will be sent under one of two possible conditions. \nThe process may have completely timed out, or it may be a notification to \nretry the operation. In both cases the listener dispatches to the new Product-\nService. If a complete time-out has occurred, the Application Service han-\ndles the situation:\npackage com.saasovation.agilepm.application;\n...\npublic class ProductService ... {\n    ...\n    @Transactional\n    public void timeOutProductDiscussionRequest(\n            TimeOutProductDiscussionRequestCommand aCommand) {\n        ProcessId processId =\n                ProcessId.existingProcessId(\n                        aCommand.getProcessId());\n        TenantId tenantId = new TenantId(aCommand.getTenantId());\n        Product product =\n                productRepository\n                    .productOfDiscussionInitiationId(\n                            tenantId,\n                            processId.id());\n        this.sendEmailForTimedOutProcess(product);\n        product.failDiscussionInitiation();\n    }\n    ...\n}\nFirst an e-mail is sent to the product owner indicating that the discussion \nsetup has failed, and then the Product is marked as failing discussion initiation. \nAs seen from the new Product method failDiscussionInitiation(), we \nneeded to declare an additional FAILED state as a  \nDiscussionAvailability.\nMethod failDiscussionInitiation() deals with the simple compensation \nnecessary to keep the Product in a sound state:\npackage com.saasovation.agilepm.domain.model.product;\n...\npublic class Product extends ConcurrencySafeEntity  {\n    ...\n    public void failDiscussionInitiation() {\n        if (!this.discussion().availability().isReady()) {\n            this.setDiscussionInitiationId(null);\nwww.EBooksWorld.ir\n", "page": 541, "type": "text", "section": "Page 541"}
{"text": " \nINTEGRATION USING MESSAGING\n499\n            this.setDiscussion(\n                    ProductDiscussion\n                        .fromAvailability(\n                                DiscussionAvailability.FAILED));\n        }\n    }\n    ...\n}\nWhat may be missing here is a new DiscussionRequestFailed Event \nbeing published by failDiscussionInitiation(). The team will have to \nconsider the possible advantages of doing that. In fact, it could be that the \ne-mails sent to product owners and other administrative resources would be \nbest handled as a result of just that Event. After all, what would happen if \nthe ProductService method timeOutProductDiscussionRequest()\nencountered problems sending the e-mail? Things could get tedious. (Aha!) \nThe team has made note of this and will return to address it later.\nOn the other hand, if the Event indicates that a retry should be attempted, \nthe listener delegates to the following operation in the ProductService:\npackage com.saasovation.agilepm.application;\n...\npublic class ProductService ... {\n    ...\n    @Transactional\n    public void retryProductDiscussionRequest(\n            RetryProductDiscussionRequestCommand aCommand) {\n        ProcessId processId =\n                ProcessId.existingProcessId(\n                        aCommand.getProcessId());\n        TenantId tenantId = new TenantId(aCommand.getTenantId());\n        Product product =\n                productRepository\n                    .productOfDiscussionInitiationId(\n                            tenantId,\n                            processId.id());\n        if (product == null) {\n            throw new IllegalStateException(\n                    \"Unknown product of tenant id: \"\n                    + aCommand.getTenantId()\n                    + \" and discussion initiation id: \"\n                    + processId.id());\n        }\nwww.EBooksWorld.ir\n", "page": 542, "type": "text", "section": "Page 542"}
{"text": "Chapter 13 INTEGRATING BOUNDED CONTEXTS\n500\n        this.requestProductDiscussion(\n                new RequestProductDiscussionCommand(\n                        aCommand.getTenantId(),\n                        product.productId().id()));\n    }\n    ...\n}\nThe Product is retrieved from its Repository by means of the  \nassociated \nProcessId, which is set on the Product attribute discussionInitia-\ntionId. After the Product is obtained, it is used by the ProductService\n(self-delegation) to request the discussion again.\nUltimately we get the desired outcome. When the discussion is started suc-\ncessfully, the Collaboration Context publishes the DiscussionStarted\nEvent. Shortly following this our DiscussionStartedListener in the \nAgile Project Management Context receives the notification and dispatches to \nthe ProductService as it did previously. This time, however, there\u2019s new \nbehavior:\npackage com.saasovation.agilepm.application;\n...\npublic class ProductService ... {\n    ...\n    @Transactional\n    public void initiateDiscussion(\n               InitiateDiscussionCommand aCommand) {\n        Product product =\n                productRepository\n                    .productOfId(\n                            new TenantId(aCommand.getTenantId()),\n                            new ProductId(aCommand.getProductId()));\n        if (product == null) {\n            throw new IllegalStateException(\n                    \"Unknown product of tenant id: \"\n                    + aCommand.getTenantId()\n                    + \" and product id: \"\n                    + aCommand.getProductId());\n        }\n        product.initiateDiscussion(\n                new DiscussionDescriptor(\n                        aCommand.getDiscussionId()));\n        TimeConstrainedProcessTracker tracker =\n                this.processTrackerRepository.trackerOfProcessId(\n                        ProcessId.existingProcessId(\n                                product.discussionInitiationId()));\nwww.EBooksWorld.ir\n", "page": 543, "type": "text", "section": "Page 543"}
{"text": " \nINTEGRATION USING MESSAGING\n501\n        tracker.completed();\n    }\n    ...\n}\nThe ProductService now provides the finishing behavior for the process, \ninforming the tracker that it is completed(). From this point forward the \ntracker will no longer be selected as a retry or time-out notifier. The process is \ndone.\nAlthough we\u2019re probably feeling good about the results, there could be a bit \nof a problem with this design. The way things stand, retrying requests to create \na Product discussion could lead to some issues if we were to leave the design \nof the Collaboration Context as it is. The basic problem is that the operations \nin the Collaboration Context are currently not idempotent. Here is a break-\ndown of the minor design flaw and what should be done about it:\n\u2022 Since guaranteed, at least once, delivery of messages is in use, as soon as a \nmessage is sent to the exchange, it is sure to reach its listener(s) in a matter \nof time. If there is some delay in creating the new collaboration objects \nand it causes even one retry, the retry will in turn cause multiple sends \nof the same CreateExclusiveDiscussion command. All such com-\nmands will eventually be delivered. Thus, any retries will make the Col-\nlaboration Context attempt to create the same Forum and Discussion\nmultiple times. We won\u2019t actually end up with duplicates since uniqueness \nconstraints are already imposed on Forum and Discussion properties. \nThus, the multiple creation attempt errors will end up being benign. Yet, \nfrom the perspective of error logs the failed attempts will appear to be \ncaused by bugs. The question is, While we still want to stipulate a com-\nplete process time-out, should the periodic retries be disabled?\n\u2022 While it might seem that the solution is to disable retries in the Agile Proj-\nect Management Context, the bottom line is that we need to make the \nCollaboration Context operations idempotent. Remember that  \nRabbitMQ \nguarantees delivery at least once and thus may deliver the same command \nmessage multiple times, even if it is sent only once. Making the collabo-\nration operations idempotent will prevent any attempt to create the same \nForum and Discussion multiple times and will stifle logging of benign \nfailures.\n\u2022 It is possible for the Agile Project Management Context to fail when \nattempting to send the CreateExclusiveDiscussion command. If \nthere is a problem with the message send, care must be taken to ensure \nwww.EBooksWorld.ir\n", "page": 544, "type": "text", "section": "Page 544"}
{"text": "Chapter 13 INTEGRATING BOUNDED CONTEXTS\n502\nthat a resend is attempted until it succeeds. Otherwise, a request for cre-\nation of the Forum and Discussion will never be made. We can ensure \ncommand resend attempts in a few ways. If the message send fails, we \ncan throw an exception from filteredDispatch(), which will cause a \nmessage NAK. As a result, RabbitMQ will consider it necessary to rede-\nliver the ProductCreated or ProductDiscussionRequested Event \nnotification, and our ProductDiscussionRequestedListener will \nreceive it again. The other way to handle this is to simply retry the send \nuntil it succeeds, perhaps using a Capped Exponential Back-off. In the \ncase of an offline RabbitMQ, retries could fail for quite a while. Thus, \nusing a combination of message NAKs and retries could be the best \napproach. Still, if our process retries three times every five minutes, it \ncould be all we need. After all, a complete process time-out results in an \ne-mail requesting human intervention.\nIn the end, if the Collaboration Context\u2019s ExclusiveDiscussionCre-\nationListener could delegate to an idempotent Application Service opera-\ntion, it would solve many of our problems:\npackage com.saasovation.collaboration.application;\n...\npublic class ForumService ... {\n    ...\n    @Transactional\n    public Discussion startExclusiveForumWithDiscussion(\n            String aTenantId,\n            String aCreatorId,\n            String aModeratorId,\n            String aForumSubject,\n            String aForumDescription,\n            String aDiscussionSubject,\n            String anExclusiveOwner) {\n        Tenant tenant = new Tenant(aTenantId);\n        Forum forum =\n                forumRepository\n                    .exclusiveForumOfOwner(\n                            tenant,\n                            anExclusiveOwner);\n        if (forum == null) {\n            forum = this.startForum(\n                    tenant,\n                    aCreatorId,\n                    aModeratorId,\n                    aForumSubject,\nwww.EBooksWorld.ir\n", "page": 545, "type": "text", "section": "Page 545"}
{"text": " \nINTEGRATION USING MESSAGING\n503\n                    aForumDescription,\n                    anExclusiveOwner);\n        }\n        Discussion discussion =\n                discussionRepository\n                    .exclusiveDiscussionOfOwner(\n                            tenant,\n                            anExclusiveOwner);\n        if (discussion == null) {\n            Author author =\n                    collaboratorService\n                        .authorFrom(\n                                tenant,\n                                aModeratorId);\n            discussion =\n                    forum.startDiscussion(\n                            forumNavigationService,\n                            author,\n                            aDiscussionSubject);\n            discussionRepository.add(discussion);\n        }\n        return discussion;\n    }\n    ...\n}\nBy trying to find the Forum and Discussion from their unique exclusive \nowner attribute, we prevent attempting to create two Aggregate instances that \nmay already exist. Wow, just a few lines of code make our Event-Driven pro-\ncessing so much better!\nDesigning a More Sophisticated Process\nStill, we may desire to design a more sophisticated process. In cases where \nmultiple completion steps are necessary, it works best to have a more elabo-\nrate state machine. To address such needs, here\u2019s the definition of a Process\ninterface:\npackage com.saasovation.common.domain.model.process;\nimport java.util.Date;\npublic interface Process {\nwww.EBooksWorld.ir\n", "page": 546, "type": "text", "section": "Page 546"}
{"text": "Chapter 13 INTEGRATING BOUNDED CONTEXTS\n504\n    public enum ProcessCompletionType {\n        NotCompleted,\n        CompletedNormally,\n        TimedOut\n    }\n    public long allowableDuration();\n    public boolean canTimeout();\n    public long currentDuration();\n    public String description();\n    public boolean didProcessingComplete();\n    public void informTimeout(Date aTimedOutDate);\n    public boolean isCompleted();\n    public boolean isTimedOut();\n    public boolean notCompleted();\n    public ProcessCompletionType processCompletionType();\n    public ProcessId processId();\n    public Date startTime();\n    public TimeConstrainedProcessTracker\n               timeConstrainedProcessTracker();\n    public Date timedOutDate();\n    public long totalAllowableDuration();\n    public int totalRetriesPermitted();\n}\nThe following are some of the more significant operations available with a \nProcess:\n\u2022 allowableDuration(): If the Process can time-out, answers either \nthe total duration or the duration between retries.\n\u2022 canTimeout(): If the Process can time-out, this method answers \ntrue.\n\u2022 timeConstrainedProcessTracker(): If the Process can time-out, \nanswers a new unique TimeConstrainedProcessTracker.\n\u2022 totalAllowableDuration(): Answers the total allowable duration \nof the Process. If retries are not permitted, the answer is allowable-\nDuration(). If retries are permitted, the answer is  \nallowableDuration()\nmultiplied by totalRetriesPermitted().\n\u2022 totalRetriesPermitted(): If the Process permits time-outs and \nretries, this method answers the total number of retries that may be \nattempted.\nImplementers of Process may be observed for time-out and retries under \nthe control of the now familiar TimeConstrainedProcessTracker. Once \nwww.EBooksWorld.ir\n", "page": 547, "type": "text", "section": "Page 547"}
{"text": " \nINTEGRATION USING MESSAGING\n505\nwe create our Process, we can ask it for a unique tracker. This test shows \nhow the two objects work together, which is much the same way that  \nProduct\nworked with its tracker:\nProcess process =\n     new TestableTimeConstrainedProcess(\n            TENANT_ID,\n            ProcessId.newProcessId(),\n            \"Testable Time Constrained Process\",\n            5000L);\nTimeConstrainedProcessTracker tracker =\n    process.timeConstrainedProcessTracker();\nprocess.confirm1();\nassertFalse(process.isCompleted());\nassertFalse(process.didProcessingComplete());\nassertEquals(process.processCompletionType(),\n        ProcessCompletionType.NotCompleted);\nprocess.confirm2();\nassertTrue(process.isCompleted());\nassertTrue(process.didProcessingComplete());\nassertEquals(process.processCompletionType(),\n        ProcessCompletionType.CompletedNormally);\nassertNull(process.timedOutDate());\ntracker.informProcessTimedOut();\nassertFalse(process.isTimedOut());\nThe Process created by this test must complete (without retries) within five \nseconds (5000L milliseconds), which it always will do. The Process will be \nmarked as completed, with fully completed processing, only after both con-\nfirm1() and confirm2() have been invoked. Internally the Process knows \nthat both states must be confirmed:\npublic class TestableTimeConstrainedProcess extends AbstractProcess {\n    ...\n    public void confirm1() {\n        this.confirm1 = true;\n        this.completeProcess(ProcessCompletionType.CompletedNormally);\n    }\n    public void confirm2() {\n        this.confirm2 = true;\nwww.EBooksWorld.ir\n", "page": 548, "type": "text", "section": "Page 548"}
{"text": "Chapter 13 INTEGRATING BOUNDED CONTEXTS\n506\n        this.completeProcess(ProcessCompletionType.CompletedNormally);\n    }\n    ...\n    protected boolean completenessVerified() {\n        return this.confirm1 && this.confirm2;\n    }\n    protected void completeProcess(\n            ProcessCompletionType aProcessCompletionType) {\n        if (!this.isCompleted() && this.completenessVerified()) {\n            this.setProcessCompletionType(aProcessCompletionType);\n        }\n    }\n    ...\n}\nEven when this Process self-invokes completeProcess(), the  \nProcess\ncannot be marked as completed until completeness \nVerified() answers \ntrue. That method will answer true only when both  \nconfirm1 and confirm2\nhave been set to true. In other words, both the  \nconfirm1() and confirm2()\noperations must have been executed. Thus, method completeness \nVerified()\nallows for multiple processing steps to be confirmed as completed before the \nentire Process is considered completed, and every specialized kind of Process\ncan have its own definition of completenessVerified().\nYet, what will happen when the final step of this test is run?\n...\ntracker.informProcessTimedOut();\nassertFalse(process.isTimedOut());\nFrom its internal state the tracker knows that the Process has actually not \ntimed out. Thus, the assertion in the next line of code will always be false. (Of \ncourse, it is assumed that the entire test will complete in less than five seconds, \nand it is strongly believed that it always will under normal test conditions.)\nAn AbstractProcess base class implements Process, serving as \nan Adapter, and provides a really easy way to develop a more sophisticated \nLong-Running Process. Since AbstractProcess extends the Entity base \nclass, it\u2019s easy to design an Aggregate as a Process. For example, we could \nmake Product subclass AbstractProcess, although it doesn\u2019t need that \nlevel of sophistication. Still, we can imagine leveraging this approach to \nwww.EBooksWorld.ir\n", "page": 549, "type": "text", "section": "Page 549"}
{"text": " \nINTEGRATION USING MESSAGING\n507\naccommodate a more complex process and require method completeness-\nVerified() to determine whether or not all required steps have completed.\nWhen Messaging or Your System Is Unavailable\nNo single approach to developing complex software systems is a panacea. \nThere are always issues and drawbacks with any approach, some of which we \nhave already discussed. One problem with a messaging system is that it can \nbecome unavailable for a period of time. This may be an infrequent situation, \nbut when it does happen, there are a few things to keep in mind.\nWhen a messaging mechanism is offline for some time, notification pub-\nlishers will be unable to send messages through it. Since this situation may be \ndetected by the publishing client, it would likely work best to back off attempts \nto send notifications until the messaging system is available once again. This \nwill be evident when any one send succeeds. But until that time, make sure that \nattempts to send occur less frequently than when everything is working well. \nIt could make sense to back off as much as 30 seconds or a minute between \nretries. Remember, if your system has an Event Store, your Events will con-\ntinue to be queued in your live system and can be sent as soon as messaging is \navailable again.\nCertainly listeners will not receive new Event-carrying notifications if the \nmessaging infrastructure goes away for a period of time. When the messaging \nmechanism becomes available again, will your client listeners be automatically \nreactivated, or will it be necessary to subscribe to your consumer-side client \nmechanism again? If automatic recovery of consumers is not supported, you \nwill need to be certain that your consumers are reregistered. Otherwise, you \nwill eventually make the unwanted discovery that your Bounded Context isn\u2019t \nreceiving the notifications that are necessary to keep it interacting with the \nBounded Contexts it depends on. That\u2019s one kind of eventual consistency that \nyou want to avoid.\nIt\u2019s not always the messaging mechanism that is the source of message-based \nproblems. Consider this situation. Your Bounded Context becomes unavailable \nfor some lengthy period of time. When it becomes available again, the durable \nmessage exchanges/queues that it subscribes to have collected a lot of unde-\nlivered messages. Once your Bounded Context starts up again and registers \nits consumers, it could require a considerable amount of time to receive and \nprocess all the available notifications. There may not be much that you can \ndo about this situation other than doggedly pursue limited downtime goals, \ndevelop a \u201clive\u201d deployment scheme, and design with redundant nodes (a clus-\nter) so that losing one node doesn\u2019t make your system unavailable. Still, there \nwww.EBooksWorld.ir\n", "page": 550, "type": "text", "section": "Page 550"}
{"text": "Chapter 13 INTEGRATING BOUNDED CONTEXTS\n508\nmay be times when you can\u2019t avoid some downtime. For example, if changes \nto your application\u2019s code require changes to the database and you can\u2019t patch \nin changes without causing problems, you will need some system downtime. \nIn such cases your message consumption processing may simply have to play \ncatch-up. Clearly it\u2019s a situation that we need to be aware of and plan to avoid \nor deal with if it could be a problem.\nWrap-Up\nIn this chapter we\u2019ve examined various ways to successfully integrate multiple \nBounded Contexts.\n\u2022 We reviewed the basic mindset necessary to succeed with integration in a \ndistributed computing environment.\n\u2022 We considered how we can integrate multiple Contexts by means of \nRESTful resources.\n\u2022 You got to see several examples of integration with messaging, includ-\ning how to develop and manage Long-Running Processes, from simple to \ncomplex.\n\u2022 You learned the challenges faced when you decide to duplicate informa-\ntion across Bounded Contexts, and how to manage it and also how to \navoid it.\n\u2022 You benefited from considering simple examples, and then progressed to \nthe more complex ones that employed increasing design maturity.\nNow that we\u2019ve seen how to integrate multiple Bounded Contexts, let\u2019s \nfocus back on the single Bounded Context and how to design the parts of the \napplication that surround the domain model. \nwww.EBooksWorld.ir\n", "page": 551, "type": "text", "section": "Page 551"}
{"text": "509\nChapter 14\nApplication\nAny program is only as good as it is useful.\n\u2014Linus Torvalds\nA domain model often lives at the heart of an application. The application may \nhave a user interface that presents concepts of the domain model and allows \nthe user to perform various actions on the model. The user interface will make \nuse of application-level services that coordinate use case tasks, manage transac-\ntions, and assert necessary security authorizations. Further, the user interface, \nApplication Services, and domain model will rely on enterprise platform-spe-\ncific infrastructural support. The infrastructure implementation details will \ngenerally include the facilities of a component container, application manage-\nment, messaging, and database.\nRoad Map to This Chapter\n\u2022 Learn several ways to provide domain model data for the user interface to \nrender.\n\u2022 See how Application Services are implemented, and the kinds of operations \nthey perform.\n\u2022 Study ways to decouple output from Application Services and disparate client \ntypes.\n\u2022 Consider why you might need to compose multiple models in the user inter-\nface, and how it\u2019s done.\n\u2022 Learn ways to use the infrastructure to provide the application\u2019s technical \nimplementations.\nSometimes we work on models that exist to support applications. This is \ntrue of the Identity and Access Context. SaaSOvation has seen the need to \nbreak off identity and access management concerns and form a supporting \nmodel that will also serve as a subscription-based product of its own. Even \nin the case of IdOvation, it will of necessity have its own administrative and \nself-service user interface. It\u2019s true that Generic and Supporting Subdomains \n(2) will sometimes lack all the extras associated with a full application, and \nthat\u2019s fine. When a model exists to support another model, the supporting \nwww.EBooksWorld.ir\n", "page": 552, "type": "text", "section": "Page 552"}
{"text": "Chapter 14 APPLICATION\n510\nmodel may be as simple as a set of classes in a separate Module (9) that address \na specialty concept and provide some algorithms.1 Other models will require \nat least some human user experience and application components. This chapter \nfocuses on the latter, more complex variety.\nWe are here using the term application somewhat interchangeably with sys-\ntem and business service. I won\u2019t attempt to formally analyze at what point \nan application becomes a system, but I\u2019d say when an application depends on \nother applications or services through integration, the whole solution could be \ncalled a system. Sometimes the terms application and system are used inter-\nchangeably to mean one and the same thing, where system really describes \nwhat we\u2019d normally call an application. And a single business service that pro-\nvides several or many technical service endpoints might also be called a system \nin a general sense. While I don\u2019t want to muddy the waters of what makes each \nof these three concepts distinct, I do want to use a single term that allows me \nto discuss concerns and responsibilities that are common to all three.\nWhat\u2019s an Application?\nTo boil it down, I am using the term application to mean the finest set of compo-\nnents that are assembled to interact with and support a Core Domain (2) model. \nThis generally means the domain model itself, a user interface, internally used \nApplication Services, and infrastructural components. What exactly fits into each \nof those compartments will vary from application to application and will depend on \nthe specific Architectures (4) in use.\nWhen an application opens up its services programmatically, the user inter-\nface is broader and includes a kind of application programming interface (API). \nThere are different ways to open its services, but the interface is not meant for \nhuman consumption. This kind of user interface is discussed in Integrating \nBounded Contexts (13). In this chapter I cover aspects of human user interfaces \nthat are typically of the graphical variety.\nFor this topic I try to avoid leaning toward any specific Architecture. I \nreflect that departure in the odd-looking diagram of Figure 14.1, which pur-\nposely adheres to no typical architecture. Dashed lines with clear arrowheads \ndepict implementation per UML, which is a reflection of Dependency Inver-\nsion Principle (4), or DIP. Solid lines with open arrowheads indicate operation \ndispatching. For example, the infrastructure implements interface abstractions \nfrom the user interface, Application Services, and the domain model. It also \ndispatches operations to Application Services, the domain model, and the data \nstore.\n 1. For an example Generic Subdomain that is a stand-alone model, see Eric Evans\u2019s \n\u201cTime and Money Code Library\u201d: http://timeandmoney.sourceforge.net/.\nwww.EBooksWorld.ir\n", "page": 553, "type": "text", "section": "Page 553"}
{"text": "511\n \nAPPLICATION \nAlthough it is inevitable that there will be some overlap with some architec-\ntural styles, our interest in this chapter is on what most any architecture would \nneed to do to sustain the goals of the application. Where a specific architecture \ndoes enter the picture, I provide an acknowledgment.\nIt is difficult not to use the term layer, as in Layers Architecture (4). It is a \nuseful term no matter what architectural style is being discussed. For example, \nconsider the place where Application Services live. Whether you think of the \nApplication Services as being in a ring around the domain model, in a hexa-\ngon encompassing the model, in a capsule hanging off a message bus, or in a \nlayer below the user interface and above the model, it should be acceptable to \nuse the term Application Layer to describe that conceptual place. While I try \nto refrain from overusing the term in this chapter, layer is helpful in labeling \nwhere components reside. This certainly does not imply that DDD is limited to \nexisting only in a Layers Architecture.2\nI start with the user interface, move on to Application Services, and then to \ninfrastructure. Through each of the subjects I cover where the model fits in, \nbut I don\u2019t delve into the model proper since that would be redundant with the \nremainder of the book.\n 2. See Chapter 4 for details.\nApplication Services\nUser Interface\nDomain Model\nInfrastructure\nFigure 14.1 The primary application areas of concern, but without ties to any one \narchitecture. These areas still emphasize the DIP with infrastructure dependent on \nabstractions of every other area.\nwww.EBooksWorld.ir\n", "page": 554, "type": "text", "section": "Page 554"}
{"text": "Chapter 14 APPLICATION\n512\nUser Interface\nOn the Java platform, the .NET platform, and others, there are so many \nhuman user interface frameworks that it seems neither interesting nor produc-\ntive to study their advantages here.\nWhat seems best is to understand the broader categories, which fall mainly \nunder those described in the following list. They are listed in order of \u201cheavi-\nness\u201d factors, not popularity. At the time of this writing it must almost cer-\ntainly be the case that the second category of Web-based rich user interface is \nthe direction of greatest choice and will soon be influenced by HTML5. Appli-\ncations of the first category, pure request-response Web user interfaces, may \nstill be more prolific as legacy applications than Web 2.0.\n\u2022 Pure request-response Web user interfaces, perhaps best known as Web 1.0. \nFrameworks such as Struts, Spring MVC and Web Flow, and ASP.NET \nsupport this category.\n\u2022 Web-based rich Internet application (RIA) user interfaces, including \nthose that use DHTML and Ajax, known as Web 2.0. Google\u2019s GWT, \nYahoo!\u2019s YUI, Ext JS, Adobe\u2019s Flex, and Microsoft\u2019s Silverlight fall into \nthis category.\n\u2022 Native client GUIs (for example, Windows, Mac, and Linux desktop \nuser interfaces) that may include the use of abstraction libraries (such as \nEclipse SWT, Java Swing, or WinForms and WPF on Windows). This \ndoes not necessarily imply a heavy desktop application, but it is possible \nthat it does. The native client GUI may access services over HTTP, for \nexample, making the user interface the only client installed component.\nWith any of these user interface categories, a few priority questions must be \nanswered: How do we render domain objects onto the glass? And how do we \ncommunicate user gestures back to the model?\nRendering Domain Objects\nThere is a fair amount of controversy and disagreement on how best to ren-\nder objects of the domain model onto the user interface. The user interface \nregularly benefits from views of data richer than is required to accomplish the \ndirect task. The display of extra data is necessary because it provides support-\ning information that users need in order to make intelligent decisions to carry \nout their immediate task. The extra data may also include selection options. \nThus, the user interface will often need to render properties of multiple Aggre-\ngate (10) instances. This is despite the fact that in most cases a user should be \nwww.EBooksWorld.ir\n", "page": 555, "type": "text", "section": "Page 555"}
{"text": " \nUSER INTERFACE\n513\nperforming a state-mutating task that is to be applied to just one instance of a \nsingle type of Aggregate. This situation is illustrated in Figure 14.2.\nRender Data Transfer Object from Aggregate Instances\nA popular way to tackle the problem of rendering multiple Aggregate instances \nto a single view is to use Data Transfer Objects [Fowler, P of EAA], or DTOs. \nThe DTO is designed to hold the entire number of attributes that need to be \ndisplayed in a view. The Application Service (see \u201cApplication Services\u201d) will \nuse Repositories (12) to read the necessary Aggregate instances and then del-\negate to a DTO Assembler [Fowler, P of EAA] to map the attributes of the \nDTO. The DTO thus carries the full complement of information that needs to \nbe rendered. The user interface component accesses each individual DTO attri-\nbute and renders it onto the view.\nWith this approach both reads and writes are performed through Reposito-\nries. It has the advantage of resolving any lazy-loaded collections because the \nDTO Assembler will directly access every part of the Aggregates that it needs \nto build the DTO. It also solves the specific problem where the presentation \ntier is physically separated from the business tier and you need to serialize data \nholders and transfer them over the network to another tier.\nAggregate\nUser\nAggregate\nAggregate\nAggregate\nFigure 14.2 The user interface may need to render properties of multiple Aggregate \ninstances but submit a request to modify only a single instance at a time.\nwww.EBooksWorld.ir\n", "page": 556, "type": "text", "section": "Page 556"}
{"text": "Chapter 14 APPLICATION\n514\nInterestingly, the DTO pattern was originally designed to deal with a remote \npresentation tier that consumes the DTO instances. The DTO is built on the \nbusiness tier, serialized, sent over the wire, and deserialized on the presenta-\ntion tier. If your presentation tier is not remote, this pattern many times leads \nto accidental complexity in the application\u2019s design, as in YAGNI (\u201cYou Ain\u2019t \nGonna Need It\u201d). This includes the disadvantage of requiring the creation of \nclasses that sometimes closely resemble the shape of domain objects but are \nnot quite the same. It also has the downside of instantiating additional poten-\ntially large objects that must be managed by the virtual machine (for example, \nJVM) when in fact they are mismatched for a single virtual machine applica-\ntion architecture.\nYour Aggregates will need to be designed so that DTO Assemblers can \nquery for necessary data. Think carefully about how to reveal state without \nrevealing too much about the internal shape or structure of the Aggregates. \nTry to eliminate a client\u2019s coupling to all internal parts of an Aggregate. Should \nyou allow clients\u2014the Assemblers in this case\u2014to navigate deeply into Aggre-\ngates? That can be a bad idea since it tightly couples each client to a specific \nAggregate implementation.\nUse a Mediator to Publish Aggregate Internal State\nTo work around the problem of tight coupling between the model and its cli-\nents, you may choose to design Mediator [Gamma et al.] (aka Double-Dispatch\nand Callback) interfaces to which the Aggregate publishes its internal state. \nClients would implement the Mediator interface, passing the implementer\u2019s \nobject reference to the Aggregate as a method argument. The Aggregate would \nthen double-dispatch to that Mediator to publish the requested state, all with-\nout revealing its shape or structure. The trick is to not wed the Mediator\u2019s \ninterface to any sort of view specification, but to keep it focused on rendering \nAggregate states of interest:\npublic class BacklogItem ... {\n    ...\n    public void provideBacklogItemInterest(\n             BacklogItemInterest anInterest) {\n         anInterest.informTenantId(this.tenantId().id());\n         anInterest.informProductId(this.productId().id());\n         anInterest.informBacklogItemId(this.backlogItemId().id());\n         anInterest.informStory(this.story());\n         anInterest.informSummary(this.summary());\n         anInterest.informType(this.type().toString());\n         ...\n    }\nwww.EBooksWorld.ir\n", "page": 557, "type": "text", "section": "Page 557"}
{"text": " \nUSER INTERFACE\n515\n    public void provideTasksInterest(TasksInterest anInterest) {\n         Set<Task> tasks = this.allTasks();\n         anInterest.informTaskCount(tasks.size());\n         for (Task task : tasks) {\n             ...\n         }\n    }\n    ...\n}\nThe various interest providers may be implemented by other classes, much the \nsame way that Entities (5) describe the way validation is delegated to separate \nvalidator classes.\nBe aware that some will consider this approach completely outside the \nresponsibility of an Aggregate. Others will consider it a completely natural \nextension of a well-designed domain model. As always, such trade-offs must be \ndiscussed by your technical team members.\nRender Aggregate Instances from a Domain Payload Object\nThere is an approach that provides a possible improvement when DTOs are \nunnecessary. This one gathers multiple whole Aggregate instances for view \nrendition into a single Domain Payload Object [Vernon, DPO]. DPO has moti-\nvations similar to DTO but takes advantage of the single virtual machine appli-\ncation architecture. It is designed to contain references to whole Aggregate \ninstances, not individual attributes. Clusters of Aggregate instances can be trans-\nferred between logical tiers or layers by a simple Payload container object. The \nApplication Service (see \u201cApplication Services\u201d) uses Repositories to retrieve the \nnecessary Aggregate instances and then instantiates the DPO to hold references \nto each. The presentation components ask the DPO object for the Aggregate \ninstance references, and then ask the Aggregates for viewable attributes.\nCowboy Logic\nLB:  \n\u201cIf you haven\u2019t fallen off a horse, you haven\u2019t been \nridin\u2019 long enough.\u201d\nThis approach has the advantage of simplifying the design of objects to \nmove clusters of data between logical tiers. The DPOs tend to be much easier \nto design and have a smaller memory footprint. Since the Aggregate instances \nmust be read into memory anyway, we leverage that they already exist.\nwww.EBooksWorld.ir\n", "page": 558, "type": "text", "section": "Page 558"}
{"text": "Chapter 14 APPLICATION\n516\nThere are a few potential negative consequences to consider. Because of the \nsimilarity to DTOs, this approach also requires Aggregates to provide a means \nto read their state. To avoid tightly coupling the user interface to the model, \nthe same Mediator, Double-Dispatch, or Aggregate Root query interface, sug-\ngested previously for use by DTO Assemblers, may be employed here as well.\nThere\u2019s still another situation to deal with. Since the DPO holds references \nto whole Aggregate instances, any lazy-loaded objects/collections are not yet \nresolved. There is no reason to access all needed Aggregate properties to create \nthe Domain Payload Object. Since even read-only transactions are generally \ncommitted when the Application Service method ends, any presentation com-\nponent that references unresolved lazy-loaded objects will cause an exception.3\nTo fix up necessary lazy loads we might choose an eager loading strategy, \nor we can use a Domain Dependency Resolver [Vernon, DDR]. This is a form \nof Strategy [Gamma et al.], usually employing one Strategy per use case flow. \nEach Strategy forces access of all Aggregate lazy-loaded properties consumed \nby the specific use case flow. The forced access occurs before the Application \nService commits the transaction and returns the Domain Payload Object to \nits client. The Strategy may be hard-coded to manually access the lazy-loaded \nproperties, or it may employ a simple expression language that describes how to \nintrospectively and reflectively navigate through the Aggregate instances. The \nreflection-based navigation crawler has the advantage that it can be made to \nwork on hidden attributes. Still, you may be happier customizing your queries \nto eagerly fetch objects that are normally lazy loaded, if the option is available.\nState Representations of Aggregate Instances\nIf your application provides REST-based resources as discussed in REST (4),\nthese will need to produce state representations of domain objects for clients. \nIt is very important to create representations that are based on use case, not on \nAggregate instances. This has very similar motivations as DTOs, which also \nare tuned for use cases. However, it may be more accurate to think of a set of \nRESTful resources as a separate model in their own right\u2014a View Model or \nPresentation Model [Fowler, PM]. Resist the temptation to produce representa-\ntions that are a one-to-one reflection of your domain model Aggregate states, \npossibly with links to navigate to deeper state. Otherwise your clients will have \nto understand your domain model as well as the Aggregates themselves. Clients \n 3. Some like to use Open Session In View (OSIV) to control transactions at the \nrequest-response level, high in the user interface. For various reason I consider \nOSIV harmful, but YMMV (\u201cYour Mileage May Vary\u201d).\nwww.EBooksWorld.ir\n", "page": 559, "type": "text", "section": "Page 559"}
{"text": " \nUSER INTERFACE\n517\nwill have to be fully aware of subtleties in behaviors and state transitions, and \nyou will lose all benefits of abstraction.\nUse Case Optimal Repository Queries\nRather than reading multiple whole Aggregate instances of various types and \nthen programmatically composing them into a single container (DTO or DPO), \nyou might instead use what is called a use case optimal query. This is where \nyou design your Repository with finder query methods that compose a custom \nobject as a superset of one or more Aggregate instances. The query dynami-\ncally places the results into a Value Object (6) specifically designed to address \nthe needs of the use case. You design a Value Object, not a DTO, because the \nquery is domain specific, not application specific (as are DTOs). The custom \nuse case optimal Value Object is then consumed directly by the view renderer.\nThe use case optimal query approach has motivations similar to CQRS \n(4). However, the use case optimal query uses a Repository against the uni-\nfied domain model persistence store rather than a raw database (such as SQL) \nquery against a separate query/read store. To understand the trade-offs of this \napproach versus CQRS, see the related discussion under Repositories (12).\nStill, once you start to go down this use case optimal query path, you are so \nclose to CQRS that it may be worth going that route instead.\nDealing with Multiple, Disparate Clients\nWhat will you do if your application must support multiple, disparate clients? \nThis may include an RIA, a graphical thick client, REST-based services, and \nmessaging too. You probably also consider various test drivers as being dif-\nferent client types. Discussed in more detail a bit later, you may design your \nApplication Services to accept Data Transformer, where each client specifies \nthe Data Transformer type. The Application Service would double-dispatch on \nthe Data Transformer parameter, which would produce the required data for-\nmat. Here\u2019s how the user interface side might look for a REST-based client:\n...\nCalendarWeekData calendarWeekData =\n    calendarAppService\n        .calendarWeek(date, new CalendarWeekXMLDataTransformer());\nResponse response =\n    Response.ok(calendarWeekData.value())\n        .cacheControl(this.cacheControlFor(30)).build();\nreturn response;\nwww.EBooksWorld.ir\n", "page": 560, "type": "text", "section": "Page 560"}
{"text": "Chapter 14 APPLICATION\n518\nMethod calendarWeek() of the CalendarApplicationService accepts \na Date within a given week and an implementation of interface Calendar-\nWeekDataTransformer. The chosen implementer is class Calendar-\nWeekXMLDataTransformer, which creates an XML document as a state \nrepresentation of the CalendarWeekData. Method value() on Calendar-\nWeekData answers the preferred type of the given data format, which in this \ncase is an XML document String.\nAdmittedly the example could benefit from having the Data Transformer \ninstance dependency injected. It\u2019s hard-coded here to make the example easier \nto understand.\nAmong the possible implementers of CalendarWeekDataTransformer\ncould be, for example:\n\u2022 CalendarWeekCSVDataTransformer\n\u2022 CalendarWeekDPODataTransformer\n\u2022 CalendarWeekDTODataTransformer\n\u2022 CalendarWeekJSONDataTransformer\n\u2022 CalendarWeekTextDataTransformer\n\u2022 CalendarWeekXMLDataTransformer\nThere is another possible approach to abstracting application output types \nto disparate clients that I discuss later under \u201cApplication Services.\u201d\nRendition Adapters and Handling User Edits\nWhen you get to the point where you have your domain data and it needs to \nbe viewed and edited by a user, there are patterns that can help you separate \nresponsibilities. Again, there are simply too many frameworks out there and \ntoo many ways to deal with them to recommend a surefire way to deal with all \nof them. With some user interface frameworks you must adhere to the specific \npatterns that are supported. Sometimes those are good, and sometimes not so \ngood. With others you have a bit more flexibility.\nIn whatever way your domain data is provided from Application Services\u2014\nthrough DTOs, DPOs, or state representations\u2014and whatever presentation \nframework you use, you may be able to benefit from Presentation Model.4 Its \ngoal is to separate responsibilities between presentation and view. While it \n 4. See also Model-View-Presenter [Dolphin], which [Fowler, PM] calls Supervising \nController and Passive View.\nwww.EBooksWorld.ir\n", "page": 561, "type": "text", "section": "Page 561"}
{"text": " \nUSER INTERFACE\n519\ncould be made to work with Web 1.0 applications, I think its strengths tend to \nbe in favor of Web 2.0 RIA, or those with desktop clients, as described in the \nsecond and third categories listed earlier.\nUsing this pattern, we want to make views passive in that they only manage \ndisplay of data and user interface controls and do little else. There are two pos-\nsible ways of view rendering:\n 1. Views render themselves based on the Presentation Model. I think this is \na more natural way and eliminates coupling from the Presentation Model \nto the view.\n 2. Views are rendered by the Presentation Model. This way has test advan-\ntages but requires the Presentation Model to couple to the view.\nThe Presentation Model acts as an Adapter [Gamma et al.]. It masks the \ndetails of the domain model by providing properties and behaviors that are \ndesigned in terms of the needs of the view. This means that there is more than \na thin veneer around attributes on domain objects or DTOs. It means that \ndecisions are made in the Adapter based on the state of the model as it applies \nto the view. For example, enabling a specific control on the view may not have \na direct relationship to any one property of the domain model but can still be \nderived from one or more such. Rather than requiring the domain model to \nspecifically support the necessary view properties, it is the responsibility of the \nPresentation Model to derive the view-specific indicators and properties from \nthe state of the domain model.\nA further, yet perhaps subtle, benefit of using a Presentation Model is that \nit can adapt Aggregates that don\u2019t support a JavaBean interface of getters to \nuser interface frameworks that require getters. Many, if not all, of the Java-\nbased Web frameworks require objects to provide public getters, such as \ngetSummary() and getStory(), while the domain model design favors flu-\nent, domain-specific expressions that closely reflect the Ubiquitous Language \n(1). The difference may be as simple as summary() and story() but produces \na user interface framework impedance mismatch. Yet, a Presentation Model \ncan be used to easily adapt summary() to getSummary() and story() to \ngetStory(), eliminating tension between model and view:\npublic class BacklogItemPresentationModel\n       extends AbstractPresentationModel {\n    private BacklogItem backlogItem;\n    public BacklogItemPresentationModel(BacklogItem aBacklogItem) {\n        super();\n        this.backlogItem = backlogItem;\n    }\nwww.EBooksWorld.ir\n", "page": 562, "type": "text", "section": "Page 562"}
{"text": "Chapter 14 APPLICATION\n520\n    public String getSummary() {\n        return this.backlogItem.summary();\n    }\n    public String getStory() {\n        return this.backlogItem.story();\n    }\n    ...\n}\nOf course, a Presentation Model can adapt between any number of the pre-\nviously discussed approaches, including the use of a DTO or DPO, or using a \nMediator through which Aggregate internal state is published.\nAdditionally, edits performed by the user are tracked by the Presentation \nModel. This is not a case of placing overloaded responsibilities on the Presen-\ntation Model, since it is meant to adapt in both directions, model to view and \nview to model.\nOne important point to keep in mind is that a Presentation Model is not a \nheavy-lifting Facade [Gamma et al.] around the Application Services or the \ndomain model. Granted, once users have completed a task with the user inter-\nface, they will usually invoke an \u201capply\u201d or \u201ccancel\u201d type of action, or prefer-\nably an explicit command. This will require the Presentation Model to reflect \nthe user\u2019s action to the application, which in essence represents a minimal \nFacade around an Application Service:\npublic class BacklogItemPresentationModel\n       extends AbstractPresentationModel {\n    private BacklogItem backlogItem;\n    private BacklogItemEditTracker editTracker;\n    // following is injected\n    private BacklogItemApplicationService backlogItemAppService;\n    public BacklogItemPresentationModel(BacklogItem aBacklogItem) {\n        super();\n        this.backlogItem = backlogItem;\n        this.editTracker = new BacklogItemEditTracker(aBacklogItem);\n    }\n    ...\n    public void changeSummaryWithType() {\n        this.backlogItemAppService\n            .changeSummaryWithType(\n                this.editTracker.summary(),\n                this.editTracker.type());\n    }\n    ...\n}\nwww.EBooksWorld.ir\n", "page": 563, "type": "text", "section": "Page 563"}
{"text": " \nAPPLICATION SERVICES\n521\nThe user clicks a command button on the view that causes change-\nSummaryWithType() to be invoked. It is the responsibility of Backlog-\nItemPresentationModel to interact with an Application Service to apply \nthe edits that occurred on editTracker. There is no other bystander wait-\ning to take the user\u2019s edits and do something with them. So we might say \nthat the Presentation Model is a minimal Facade to the Application Services \non behalf of the view, but just because changeSummaryWithType() is a \nhigher-level interface that makes BacklogItemApplicationService eas-\nier to use. However, we would not want to see several lines of code in the \nPresentation Model class manage detailed use of the Application Service, or \nworse yet, to itself act as the Application Service to the domain model. That \nwould go well beyond the responsibility of the Presentation Model. Instead, we \nwant to see a simple delegation to the more complex and heavy-lifting Facade, \nBacklogItemApplicationService.\nThis is a powerful approach to coordinating the domain model and UI. \nIt may even receive your vote for the most versatile UI management pattern. \nUsing any of the view management techniques, however, we still often interact \nwith an Application Services API.\nApplication Services\nIn some cases your user interface will aggregate multiple Bounded Contexts (2)\nusing independent Presentation Model components, all composed on a single \nview. Whether your user interface renders a single model or composes multiple \nmodels, it will likely interact with Application Services, so let\u2019s consider those \nnow.\nThe Application Services are the direct clients of the domain model. For \noptions on the logical location of Application Service, see Architecture (4).\nThese are responsible for task coordination of use case flows, one service \nmethod per flow. When using an ACID database, the Application Services \nalso control transactions, ensuring that model state transitions are atomically \npersisted. I discuss transaction control here briefly, but see Repositories (12)\nfor a broader perspective. Security is also commonly cared for by Application \nServices.\nIt is a mistake to consider Application Services to be the same as Domain \nServices (7). They are not. The contrast should be stark, which is clearly \ndemonstrated in the next section. We should strive to push all business domain \nlogic into the domain model, whether that be in Aggregates, Value Objects, or \nDomain Services. Keep Application Services thin, using them only to coordi-\nnate tasks on the model.\nwww.EBooksWorld.ir\n", "page": 564, "type": "text", "section": "Page 564"}
{"text": "Chapter 14 APPLICATION\n522\nSample Application Service\nLet\u2019s take a look at the partial sample interface and implementation class for \nan Application Service. This is the service that provides use case task manage-\nment for tenants of the Identity and Access Context. It is just a sample and not \nmeant to be taken as the final say. Trade-offs will be apparent.\nFirst consider the basic interface:\npackage com.saasovation.identityaccess.application;\npublic interface TenantIdentityService {\n    public void activateTenant(TenantId aTenantId);\n    public void deactivateTenant(TenantId aTenantId);\n    public String offerLimitedRegistrationInvitation(\n            TenantId aTenantId,\n            Date aStartsOnDate,\n            Date anUntilDate);\n    public String offerOpenEndedRegistrationInvitation(\n            TenantId aTenantId);\n    public Tenant provisionTenant(\n            String aTenantName,\n            String aTenantDescription,\n            boolean isActive,\n            FullName anAdministratorName,\n            EmailAddress anEmailAddress,\n            PostalAddress aPostalAddress,\n            Telephone aPrimaryTelephone,\n            Telephone aSecondaryTelephone,\n            String aTimeZone);\n    public Tenant tenant(TenantId aTenantId);\n    ...\n}\nThese six Application Service methods are used to create or provision a tenant, \nto activate and deactivate an existing one, to offer limited and open-ended reg-\nistration invitations to future users, and to query for a specific tenant.\nSome types from the domain model are used in these method signatures. \nThat will require the user interface to be aware of these types and depend on \nthem. Sometimes the Application Services are designed to completely shield \nthe user interface from all such domain knowledge. Doing so, the Applica-\ntion Service method signatures use only primitive types (int, long, double), \nwww.EBooksWorld.ir\n", "page": 565, "type": "text", "section": "Page 565"}
{"text": " \nAPPLICATION SERVICES\n523\nStrings, and possibly DTOs. As an alternative to these approaches, however, \na better approach may be to design Command [Gamma et al.] objects instead. \nThere is not necessarily a right or wrong way. It mostly depends on your tastes \nand goals. This book presents each of these styles in various examples.\nConsider the trade-offs. If you eliminate types from the model, you avoid \ndependency and coupling, but you lose out on strong type checking and basic \nvalidations (guards) that you get for free from Value Object types. If you don\u2019t \nexpose domain objects as return types, you will need to provide DTOs. If you \nprovide DTOs, there may be accidental complexity in your solution from the \nextra overhead of the additional types. Then there is also the aforementioned \nmemory overhead in high-traffic applications that is caused by the possibly \nunnecessary DTOs constantly being created and garbage collected.\nOf course, if you expose domain objects to disparate clients, each client \ntype will need to deal with them separately. Again, coupling is higher and with \nmore client types this becomes a bigger issue. Given that, at least a few of these \nmethods could be better designed to deal with return types. As discussed pre-\nviously, we might instead use Data Transformers:\npackage com.saasovation.identityaccess.application;\npublic interface TenantIdentityService {\n    ...\n    public TenantData provisionTenant(\n            String aTenantName,\n            String aTenantDescription,\n            boolean isActive,\n            FullName anAdministratorName,\n            EmailAddress anEmailAddress,\n            PostalAddress aPostalAddress,\n            Telephone aPrimaryTelephone,\n            Telephone aSecondaryTelephone,\n            String aTimeZone,\n            TenantDataTransformer aDataTransformer);\n    public TenantData tenant(\n            TenantId aTenantId,\n            TenantDataTransformer aDataTransformer);\n    ...\n}\nFor now I will stick with exposing domain objects to the client and assume \nthat we have only one user interface that is Web based. It will help to simplify \nthe examples. Later I\u2019ll go back to the Data Transformers approach.\nConsider how the Application Service interface is implemented. Taking a \nlook at a few of the more trivial methods to implement it helps highlight some \nwww.EBooksWorld.ir\n", "page": 566, "type": "text", "section": "Page 566"}
{"text": "Chapter 14 APPLICATION\n524\nbasic points. Note that there may be no advantage to having a Separated Inter-\nface [Fowler, P of EAA]. Here is an example where we will just define the inter-\nface with the implementation class:\npackage com.saasovation.identityaccess.application;\npublic class TenantIdentityService {\n    @Transactional\n    public void activateTenant(TenantId aTenantId) {\n        this.nonNullTenant(aTenantId).activate();\n    }\n    @Transactional\n    public void deactivateTenant(TenantId aTenantId) {\n        this.nonNullTenant(aTenantId).deactivate();\n    }\n    ...\n    @Transactional(readOnly=true)\n    public Tenant tenant(TenantId aTenantId) {\n        Tenant tenant =\n            this\n                .tenantRepository()\n                .tenantOfId(aTenantId);\n        return tenant;\n    }\n    private Tenant nonNullTenant(TenantId aTenantId) {\n        Tenant tenant = this.tenant(aTenantId);\n        if (tenant == null) {\n            throw new IllegalArgumentException(\n                    \"Tenant does not exist.\");\n        }\n        return tenant;\n    }\n}\nA client requests to deactivate an existing Tenant using deactivate-\nTenant(). To interact with the actual Tenant object we need to retrieve it \nfrom its Repository using its TenantId. Here we have created an internal \nhelper method named nonNullTenant(), which itself delegates to tenant().\nThe helper exists to guard against nonexistent Tenant instances and is used \nby all service methods that need to get an existing Tenant.\nwww.EBooksWorld.ir\n", "page": 567, "type": "text", "section": "Page 567"}
{"text": " \nAPPLICATION SERVICES\n525\nMethods activateTenant() and deactivateTenant() are marked \nwrite transactional by a Spring Transactional annotation. Method \ntenant() is marked read-only transactional. In all three cases, when a client \nobtains this bean through its Spring context and invokes a service method, \na transaction is started. When the method completes by normal return, the \ntransaction is committed. Depending on configuration, exceptions thrown \nwithin the scope of the method will cause the transaction to roll back.\nBut how would we prevent the misuse of these methods, say, by a malicious \nintruder? When we are talking about deactivating or reactivating a tenant, \nit\u2019s an operation that should actually be permitted only by an SaaS \nOvation \nemployee authorized user. The same goes for provisioning a new tenant \nsubscriber.\nWhat if we were to leverage something like Spring Security? We could use \nanother annotation, PreAuthorize:\npublic class TenantIdentityService {\n    @Transactional\n    @PreAuthorize(\"hasRole('SubscriberRepresentative')\")\n    public void activateTenant(TenantId aTenantId) {\n        this.nonNullTenant(aTenantId).activate();\n    }\n    @Transactional\n    @PreAuthorize(\"hasRole('SubscriberRepresentative')\")\n    public void deactivateTenant(TenantId aTenantId) {\n        this.nonNullTenant(aTenantId).deactivate();\n    }\n    ...\n    @Transactional\n    @PreAuthorize(\"hasRole('SubscriberRepresentative')\")\n    public Tenant provisionTenant(\n            String aTenantName,\n            String aTenantDescription,\n            boolean isActive,\n            FullName anAdministratorName,\n            EmailAddress anEmailAddress,\n            PostalAddress aPostalAddress,\n            Telephone aPrimaryTelephone,\n            Telephone aSecondaryTelephone,\n            String aTimeZone) {\n        return\n            this\n                .tenantProvisioningService\nwww.EBooksWorld.ir\n", "page": 568, "type": "text", "section": "Page 568"}
{"text": "Chapter 14 APPLICATION\n526\n                .provisionTenant(\n                        aTenantName,\n                        aTenantDescription,\n                        isActive,\n                        anAdministratorName,\n                        anEmailAddress,\n                        aPostalAddress,\n                        aPrimaryTelephone,\n                        aSecondaryTelephone,\n                        aTimeZone);\n    }\n    ...\n}\nThis is declarative method-level security and prevents unauthorized users \nfrom accessing Application Services. Of course, the user interface would be \ndesigned to hide any navigation access to such facilities if the user were not \nauthorized. That wouldn\u2019t stop a malicious attacker, however, but the security \ndeclaration will.\nThis declarative method security is different from what IdOvation is provid-\ning. SaaSOvation employees would log in to IdOvation differently from tenant \nusers. Particularly those with the special role SubscriberRepresentative\nwould be permitted to execute these sensitive methods, and no subscriber user \nwould ever be permitted to. This, of course, would require integration between \nIdOvation and Spring Security. \nNow, when we look at the implementation of provisionTenant(), we see \nthat it delegates to a Domain Service. This highlights the difference between \nthe two kinds of services, especially when we peek inside the domain Tenant-\nProvisioningService. There is significant domain logic inside this \nDomain Service, but very little in the Application Service. Consider what the \nDomain Service does (although I don\u2019t present the code here):\n 1. Instantiates a new Tenant Aggregate and adds it to its Repository.\n 2. Assigns a new administrator for the new Tenant. This includes provi-\nsioning the Administrator role for the new Tenant and publishing Event \nTenantAdministratorRegistered.\n 3. Publishes the Event TenantProvisioned.\nIf the Application Service were to do more than step 1, we would be seri-\nously leaking domain logic out of the model. Since there are two additional \nsteps that are not the responsibility of the Application Service, we instead place \nall three inside the Domain Service. Using the Domain Service, we place this \nwww.EBooksWorld.ir\n", "page": 569, "type": "text", "section": "Page 569"}
{"text": " \nAPPLICATION SERVICES\n527\n\u201csignificant process . . . in the domain\u201d [Evans].5 We also properly follow the \ndefinition of Application Service by managing the transaction, security, and \nthe task of delegating this significant tenant provisioning process to the model.\nBut consider for a moment the noise caused by the provisionTenant()\nparameter list. There is a total of nine parameters, and that\u2019s probably at least \na few too many. We can prevent this situation by designing simple Command\n[Gamma et al.] objects instead: \u201cEncapsulate a request as an object, thereby \nletting you parameterize clients with different requests, queue or log requests, \nand support undoable operations.\u201d In other words, we might think of a Com-\nmand object as a serialized method invocation, and in our case we are inter-\nested in everything a Command can help with except for undo operations. \nThis is how simple a Command class is to design:\npublic class ProvisionTenantCommand {\n    private String tenantName;\n    private String tenantDescription;\n    private boolean isActive;\n    private String administratorFirstName;\n    private String administratorLastName;\n    private String emailAddress;\n    private String primaryTelephone;\n    private String secondaryTelephone;\n    private String addressStreetAddress;\n    private String addressCity;\n    private String addressStateProvince;\n    private String addressPostalCode;\n    private String addressCountryCode;\n    private String timeZone;\n    public ProvisionTenantCommand(...) {\n        ...\n    }\n    public ProvisionTenantCommand() {\n        super();\n    }\n    public String getTenantName() {\n        return tenantName;\n    }\n    public void setTenantName(String tenantName) {\n        this.tenantName = tenantName;\n    }\n    ...\n}\n 5. See Chapter 7.\nwww.EBooksWorld.ir\n", "page": 570, "type": "text", "section": "Page 570"}
{"text": "Chapter 14 APPLICATION\n528\nThe ProvisionTenantCommand doesn\u2019t use model objects, just basic \ntypes. It has a multi-argument constructor and also a zero-argument construc-\ntor. Along with the zero-argument constructor, having public setters allows the \nCommand to be populated by UI form-field-to-object mappers (for example, \nassuming a JavaBean, or .NET CLR properties). You might think of the Com-\nmand as a DTO, but it is truly more than that. Since the Command object is \nnamed for the operation that is to be carried out, it is more explicit. The Com-\nmand instance may be passed to an Application Service method:\npublic class TenantIdentityService {\n    ...\n    @Transactional\n    public String provisionTenant(ProvisionTenantCommand aCommand) {\n        ...\n        return tenant.tenantId().id();\n    }\n    ...\n}\nBesides this approach of dispatching to an Application Service API method, \nas the pattern states we could instead or in addition to send Commands to a \nqueue to be dispatched to a Command Handler. Consider a Command Handler \nto be semantically equivalent to an Application Service method, but temporally \ndecoupled. As discussed in Appendix A, this enables greater throughput and \nscalability of Command handling.\nDecoupled Service Output\nA couple of times earlier I discussed the use of Data Transformers as a way to \naccommodate disparate client types with the specific data type they require. \nThat approach uses Transformers to produce the data in a specific type that \nimplements an abstract interface that all related types share. Again, from the \nclient\u2019s perspective it might look like this:\nTenantData tenantData =\n    tenantIdentityService.provisionTenant(\n            ..., myTenantDataTransformer);\nTenantPresentationModel tenantPresentationModel =\n    new TenantPresentationModel(tenantData.value());\nThe Application Services are designed as an API, with input and output. The \nreason for passing in a Data Transformer is to produce the specific output type \nneeded by the client.\nwww.EBooksWorld.ir\n", "page": 571, "type": "text", "section": "Page 571"}
{"text": " \nAPPLICATION SERVICES\n529\nWhat if we took an entirely different course and made the rule that Applica-\ntion Services are always declared void and, thus, never return data to clients? \nHow would that work? The answer lies in a mentality that the Hexagonal \nArchitecture (4) promotes, the use of the Ports and Adapters style. In this \ninstance we would use a single standard output Port with any number of adapt-\ners, one for each client type. Doing so would yield a provision \nTenant()\nApplication Service method like this one:\npublic class TenantIdentityService {\n    ...\n    @Transactional\n    @PreAuthorize(\"hasRole('SubscriberRepresentative')\")\n    public void provisionTenant(\n            String aTenantName,\n            String aTenantDescription,\n            boolean isActive,\n            FullName anAdministratorName,\n            EmailAddress anEmailAddress,\n            PostalAddress aPostalAddress,\n            Telephone aPrimaryTelephone,\n            Telephone aSecondaryTelephone,\n            String aTimeZone) {\n        Tenant tenant =\n            this\n                .tenantProvisioningService\n                .provisionTenant(\n                        aTenantName,\n                        aTenantDescription,\n                        isActive,\n                        anAdministratorName,\n                        anEmailAddress,\n                        aPostalAddress,\n                        aPrimaryTelephone,\n                        aSecondaryTelephone,\n                        aTimeZone);\n        this.tenantIdentityOutputPort().write(tenant);\n    }\n    ...\n}\nThe output Port here is a specific named Port at the edge of the application. \nUsing Spring, it would be a bean injected into the service. The only thing that \nprovisionTenant() needs to know is that it must write() to the Port the \nTenant instance it gets from the Domain Service. This Port would have any \nnumber of readers, which register themselves ahead of using the Application \nwww.EBooksWorld.ir\n", "page": 572, "type": "text", "section": "Page 572"}
{"text": "Chapter 14 APPLICATION\n530\nService. When a write() occurs, each of the registered readers is signaled to \nread the output as its input. At that point the readers may transform the output \nusing the established mechanism, such as a Data Transformer.\nThis isn\u2019t just a fancy artifice to add complexity to your architecture. The \nstrength is the same as with any Ports and Adapters architecture, whether \nfor a software system or a hardware device. Each component only needs to \nunderstand the input it reads, its own behavior, and the Port to which it writes \noutput.\nWriting to a Port is roughly the same thing that an Aggregate pure com-\nmand method does when it produces no return value, but it does publish a \nDomain Event (8). In the case of the Aggregate the Domain Event Publisher \n(8) is an Aggregate output Port. Further, if we solve querying the state of an \nAggregate by using a Double-Dispatch on a Mediator, it is similar to using \nPorts and Adapters.\nOne downside of the Ports and Adapters approach is that it may make it \nmore difficult to name Application Service methods that perform queries. Con-\nsider method tenant() from the sample service. That name now seems inap-\npropriate because it no longer answers the Tenant that it queries. The name \nprovisionTenant() still works for the provisioning API because it actually \nbecomes a pure command method, no longer returning a value. But we might \nwant to think of a better name for tenant(). The following may improve \nthings a bit:\n    ...\n    @Override\n    @Transactional(readOnly=true)\n    public void findTenant(TenantId aTenantId) {\n        Tenant tenant =\n            this\n                .tenantRepository\n                .tenantOfId(aTenantId);\n        this.tenantIdentityOutputPort().write(tenant);\n    }\n    ...\n}\nThe name findTenant() might work because finding doesn\u2019t necessarily \nimply the need to answer a result. Whatever name is chosen, the situation con-\nfirms that each architectural decision we make leads to positive and negative \nconsequences.\nwww.EBooksWorld.ir\n", "page": 573, "type": "text", "section": "Page 573"}
{"text": " \nCOMPOSING MULTIPLE BOUNDED CONTEXTS\n531\nComposing Multiple Bounded Contexts\nThe examples I have provided don\u2019t address the possibility that a single user \ninterface may need to compose two or more domain models. In my examples, \nconcepts from upstream models are integrated into downstream models by \ntranslating them into terms of the downstream model.\nThat\u2019s different from the need to compose multiple models into one unified \npresentation, as seen in Figure 14.3. The foreign models, in this example, are \nProducts Context, Discussions Context, and Reviews Context. The user inter-\nface should not be aware that it is composing multiple models. When a similar \nsituation occurs in your application, you should give thought to how Module \n(9) structure and naming support your needs, and how Application Services \ncan smooth out the probable disconnect between different models.\nOne solution uses multiple Application Layers, which is unlike that shown in \nFigure 14.3. With multiple Application Layers you would need to supply inde-\npendent user interface components with each, where the user interface compo-\nnents would have some affinity to a specific underlying domain model. This is \nbasically the portal-portlet style. Still, it could be more difficult to get the dis-\nparate Application Layers and independent user interface components to har-\nmonize along use case flows, which is what the user interface is concerned with.\nSince the Application Layer manages use cases, it may be easiest to create a \nsingle Application Layer as the actual source of model composition, which is \nthe approach shown in Figure 14.3. Services in that single layer are devoid of \nbusiness domain logic. It will only serve to aggregate objects from each model \ninto cohesive ones that the user interface needs. Likely in this case you would \nUser Interface Layer\nApplication Layer\nProducts: Domain Layer\nDiscussions: Domain Layer\nReviews: Domain Layer\nFigure 14.3 There are times when a UI must compose multiple models. Here three \nmodels are composed using a single Application Layer.\nwww.EBooksWorld.ir\n", "page": 574, "type": "text", "section": "Page 574"}
{"text": "Chapter 14 APPLICATION\n532\nname Modules in the User Interface and Application Layers according to the \npurpose of the composition, a named context:\n    com.consumerhive.productreviews.presentation\n    com.consumerhive.productreviews.application\nConsumer Hive provides consumer product reviews and discussions. It has \nseparated the Products Context from the Discussions Context and Reviews \nContext. Yet, the presentation and application Modules reflect the unification \nunder one user interface. Likely it gets its product catalog from one or more \nexternal sources, whereas the discussions and reviews are its Core Domain.\nAnd speaking of Core Domain . . . Strangely enough, what do you detect \nhere? Isn\u2019t this Application Layer really serving as a new domain model with a \nbuilt-in Anticorruption Layer (3)? Yes, it is basically a new bargain-basement \nBounded Context. Here the Application Services manage a merger of various \nDTOs, which mimic a sort of Anemic Domain Model (1). It is a bit of a Trans-\naction Script (1) approach that models the Core Domain.\nIf you were to decide that Consumer Hive\u2019s three-model composition is cry-\ning for a new Domain Model (1) that is a unified object model in a single \nBounded Context, you might name the Modules of the new model as follows:\n    com.consumerhive.productreviews.domain.model.product\n    com.consumerhive.productreviews.domain.model.discussion\n    com.consumerhive.productreviews.domain.model.review\nIn the end you will have to decide how to model this situation. Will you decide \nto use strategic design and even tactical design to create a new model? At a \nminimum, this situation begs the question: Where do we draw the line between \ncomposing multiple Bounded Contexts into a single user interface, and creating \na new, clean Bounded Context with a unified domain model? Each case must \nbe considered carefully. A less significant system would have other influences \nand priorities. Still, we must not treat such decisions arbitrarily. Consideration \nshould be given to the criteria provided in Bounded Contexts. In the end the \nbest approach is the one that benefits the business the most.\nInfrastructure\nThe job of the infrastructure is to provide technical capabilities for other parts \nof your application. While avoiding a discussion about Layers (4), it is still \nuseful to maintain a Dependency Inversion Principle mentality. So wherever \nwww.EBooksWorld.ir\n", "page": 575, "type": "text", "section": "Page 575"}
{"text": " \nINFRASTRUCTURE\n533\nyour infrastructure lives architecturally, it works out very well if its compo-\nnents depend on the interfaces from the user interface, Application Services, \nand domain model that require special technical capabilities. That way, when \nan Application Service looks up a Repository, it will be dependent only on the \ninterface from the domain model, but using the implementation from the infra-\nstructure. Figure 14.4 provides the UML static structure diagram to illustrate \nhow that works.\nThe lookup may be implicit through Dependency Injection [Fowler, DI] or \nusing a Service Factory. The final section of this chapter, \u201cEnterprise Compo-\nnent Containers,\u201d discusses these options. Repeating a portion of the Applica-\ntion Service used as a running example, you can see again here how the Service \nFactory is used to look up the Repository:\npackage com.saasovation.identityaccess.application;\npublic class TenantIdentityService {\n    ...\n    @Override\n    @Transactional(readOnly=true)\n    public Tenant tenant(TenantId aTenantId) {\n        Tenant tenant =\n            DomainRegistry\n                .tenantRepository()\n                .tenantOfId(aTenantId);\napplication\nTenantIdentityService\n+activateTenant()\n+deactivateTenant()\n+provisionTenant()\n+tenant()\ninfrastructure\nHibernateTenantRepository\ndomain model\nTenantRepository\n+tenantOfId()\nFigure 14.4 The Application Service depends on the Repository interface from the \ndomain model but uses the implementation class from infrastructure. The packages \nencapsulate broad responsibilities.\nwww.EBooksWorld.ir\n", "page": 576, "type": "text", "section": "Page 576"}
{"text": "Chapter 14 APPLICATION\n534\n        return tenant;\n    }\n    ...\n}\nThis Application Service could have instead injected the Repository, or we \ncould have set up the inbound dependencies by way of constructor parameters.\nImplementations of Repositories are kept in the infrastructure because they \ndeal with storage, which is not a responsibility that the model should take on. \nYou would use the infrastructure to implement interfaces that require use of \nmessaging, such as message queues and e-mail. If there are special user inter-\nface components that feature generated graphical charts, maps, and the like, \nthese would also be implemented in the infrastructure.\nEnterprise Component Containers\nThese days, enterprise application servers are a commodity. There seems to \nbe little innovation in the servers themselves and in the component contain-\ners that run inside them. We can use Enterprise JavaBeans (EJB) as Session \nFacades [Crupi et al.] or simple JavaBeans hosted by inversion-of-control con-\ntainers, such as Spring, to facilitate the use of Application Services. There are \narguments about which is better, but there has also been a lot of convergence \namong the frameworks. In fact, a peek inside some JEE servers reveals that \nsome are implemented using Spring.\nIs It WebLogic or Spring?\nIf you were to view a stack trace from the Oracle WebLogic Server, you\u2019d likely see \nreferences to classes from Spring Framework. They aren\u2019t part of your application\u2019s \ndeployment. In this case you are using only standard JEE with EJB Session Beans. \nThe Spring classes you are seeing are part of WebLogic\u2019s EJB container implementa-\ntion. Is this a case of \u201cif you can\u2019t beat them, join them\u201d?\nI have chosen to implement the three sample Bounded Contexts I have pro-\nvided using Spring Framework. Yet, these examples would easily carry over to \nother enterprise container platforms. So there\u2019s nothing lost if you don\u2019t use \nSpring on your projects, and you should still feel quite comfortable reading \nthrough the examples. There are minimal logical differences among the vari-\nous containers.\nIn Repositories (12) is seen the Spring configuration used to wire up trans-\nactional support for Application Services that is used for persisting domain \nwww.EBooksWorld.ir\n", "page": 577, "type": "text", "section": "Page 577"}
{"text": " \nENTERPRISE COMPONENT CONTAINERS\n535\nobjects. Here let\u2019s look at other parts of the Spring configuration. Two files of \ninterest are\n    config/spring/applicationContext-application.xml\n    config/spring/applicationContext-domain.xml\nAs the filenames indicate, Application Services and domain model compo-\nnents are wired in these. Consider a few from the application wiring:\n<beans ...>\n    <aop:aspectj-autoproxy/>\n    <tx:annotation-driven transaction-manager=\"transactionManager\"/>\n    ...\n    <bean\n        id=\"applicationServiceRegistry\"\n        class=\"com.saasovation.identityaccess.application\u03a6\n.ApplicationServiceRegistry\"\n        autowire=\"byName\">\n    </bean>\n    ...\n    <bean\n        id=\"tenantIdentityService\"\n        class=\"com.saasovation.identityaccess.application\u03a6\n.TenantIdentityService\"\n        autowire=\"byName\">\n    </bean>\n    ...\n</beans>\nThe bean tenantIdentityService is the one reviewed earlier. This bean \ncan be wired into other Spring beans, such as in the user interface. If you prefer \na Service Factory rather than injecting bean instances into others, we can use \nthe other bean in the configuration, applicationServiceRegistry. This \nbean provides lookup access to all Application Services. You\u2019d use it like this:\n...\nApplicationServiceRegistry\n    .tenantIdentityService()\n    .deactivateTenant(tenantId);\nWe can do so because it is itself injected with the Spring Application-\nContext when the bean is newly created.\nThe same kind of registry bean is provided for access to components of the \ndomain model, such as Repositories and Domain Services. Here is the Regis-\ntry, Repository, and Domain Service bean configuration for the domain model:\nwww.EBooksWorld.ir\n", "page": 578, "type": "text", "section": "Page 578"}
{"text": "Chapter 14 APPLICATION\n536\n<beans ...>\n    ...\n    <bean\n        id=\"authenticationService\"\n        class=\"com.saasovation.identityaccess.infrastructure\u03a6\n.services.DefaultEncryptionAuthenticationService\"\n        autowire=\"byName\">\n    </bean>\n    <bean\n        id=\"domainRegistry\"\n        class=\"com.saasovation.identityaccess.domain.model\u03a6\n.DomainRegistry\"\n        autowire=\"byName\">\n    </bean>\n    <bean\n        id=\"encryptionService\"\n        class=\"com.saasovation.identityaccess.infrastructure\u03a6\n.services.MessageDigestEncryptionService\"\n        autowire=\"byName\">\n    </bean>\n    <bean\n        id=\"groupRepository\"\n        class=\"com.saasovation.identityaccess.infrastructure\u03a6\n.persistence.HibernateGroupRepository\"\n        autowire=\"byName\">\n    </bean>\n    <bean\n        id=\"roleRepository\"\n        class=\"com.saasovation.identityaccess.infrastructure\u03a6\n.persistence.HibernateRoleRepository\"\n        autowire=\"byName\">\n    </bean>\n    <bean\n        id=\"tenantProvisioningService\"\n        class=\"com.saasovation.identityaccess.domain.model\u03a6\n.identity.TenantProvisioningService\"\n        autowire=\"byName\">\n    </bean>\n    <bean\n        id=\"tenantRepository\"\n        class=\"com.saasovation.identityaccess.infrastructure\u03a6\n.persistence.HibernateTenantRepository\"\n        autowire=\"byName\">\n    </bean>\nwww.EBooksWorld.ir\n", "page": 579, "type": "text", "section": "Page 579"}
{"text": " \nWRAP-UP\n537\n    <bean\n        id=\"userRepository\"\n        class=\"com.saasovation.identityaccess.infrastructure\u03a6\n.persistence.HibernateUserRepository\"\n        autowire=\"byName\">\n    </bean>\n</beans>\nUsing the DomainRegistry, we can access any of these Spring registered \nbeans. All of the beans are also available for dependency injection into other \nSpring beans. Thus, the Application Services could choose to use the Service \nFactory or Dependency Injection. See Services (7) for a more in-depth discus-\nsion of using these two approaches versus a constructor-based dependency \nsetup.\nWrap-Up\nIn this chapter we\u2019ve looked into how the application works outside the domain \nmodel.\n\u2022 You\u2019ve considered several techniques for rendering the model\u2019s data into \nuser interfaces.\n\u2022 You saw ways of accepting user input that is applied to the domain model.\n\u2022 You\u2019ve learned a variety of options for transferring model data, even \nwhen there are possibly many different kinds of user interface types.\n\u2022 You have looked into Application Services and what they are responsible \nfor.\n\u2022 You were introduced to an option for decoupling output from specific \nclient types.\n\u2022 You\u2019ve learned ways to use the infrastructure to keep technical implemen-\ntations out of the domain model.\nwww.EBooksWorld.ir\n", "page": 580, "type": "text", "section": "Page 580"}
{"text": "Chapter 14 APPLICATION\n538\n\u2022 You considered how, using DIP, to make clients of every aspect of the \napplication depend on abstractions rather than implementation details, \nwhich promotes loose coupling.\n\u2022 Finally, you saw how commodity application servers and enterprise com-\nponent containers can give legs to your applications.\nYou should now be on solid footing to implement DDD from the carefully \ncrafted domain model through to the components of the entire application.\nwww.EBooksWorld.ir\n", "page": 581, "type": "text", "section": "Page 581"}
{"text": "539\nAppendix A\nAggregates and Event \nSourcing: A+ES\nContributed by Rinat Abdullin\nThe concept of Event Sourcing has been used for decades but has more recently \nbeen popularized by Greg Young by applying it to DDD [Young, ES]. \nEvent Sourcing can be used to represent the entire state of an Aggregate (10)\nas a sequence of Events (8) that have occurred since it was created. The Events \nare used to rebuild the state of the Aggregate by replaying them in the same \norder in which they occurred. The premise is that this approach simplifies per-\nsistence and allows capturing concepts with complex behavioral properties.\nThe set of Events representing the state of each Aggregate is captured in \nan append-only Event Stream. This Aggregate state is further mutated by suc-\ncessive operations that append new Events to the end of the Event Stream, as \nillustrated in Figure A.1. (In this appendix Events are shown as light gray rect-\nangles to make them stand out from other concepts.)\nThe Event Stream of each Aggregate is usually persisted in Event Stores \n(8), where they are uniquely distinguished, usually by the identity of the root \nEntity (5). How to build an Event Store specifically for use with Event Sourcing \nis addressed in more detail later in the appendix.\nFrom here forward, let\u2019s refer to this approach of using Event Sourcing to \nmaintain the state of Aggregates and persist them as A+ES.\nSome of the primary benefits of A+ES are:\n\u2022 Event Sourcing guarantees that the reason for each change to an Aggre-\ngate instance will not be lost. When using the traditional approach of \nEvent\nStream\nEvent 1\nCustomer\nCreated\nEvent 2\nCustomer Charged\nfor Services\nEvent 3\nContact Phone\nProvided\nEvent 4\nService Charge\nCanceled\nEvent N\n. . .\nFigure A.1 An Event Stream with Domain Events in order of occurrence\nwww.EBooksWorld.ir\n", "page": 582, "type": "text", "section": "Page 582"}
{"text": "Appendix A AGGREGATES AND EVENT SOURCING: A+ES\n540\nserializing the current state of an Aggregate to a database, we are always \noverwriting the previous serialized state, never to be recovered. However, \nretaining the reason for every change from the creation of an Aggregate \ninstance through its entire lifetime can be invaluable for the business. As \ndiscussed in Architecture (4), the benefits can be far-reaching: reliability, \nnear- and far-term business intelligence, analytic discoveries, full audit \nlog, the ability to look back in time for debugging purposes.\n\u2022 The append-only nature of Event Streams performs outstandingly well and \nsupports an array of data replication options. Using similar approaches \nhas allowed companies such as LMAX to facilitate very low-latency equi-\nties trading systems.\n\u2022 The Event-centric approach to Aggregate design can allow developers to \nfocus more of their attention on behaviors expressed by the Ubiquitous \nLanguage (1) by avoiding the potential impedance mismatch of object- \nrelational mapping and can lead to systems that are more robust and tol-\nerant to change.\nThat said, make no mistake: A+ES is not a silver bullet. Consider a few real-\nistic drawbacks:\n\u2022 Defining Events for A+ES requires a deep understanding of the business \ndomain. As in any DDD project, this level of effort is usually justifiable \nonly for complex models from which the organization will derive compet-\nitive advantage.\n\u2022 At the time of writing, there is a lack of tooling and a consistent body of \nknowledge in this field. This increases costs and the risks of introducing \nthe approach to inexperienced teams. \n\u2022 The number of experienced developers is limited.\n\u2022 Implementing A+ES almost certainly requires some form of Com-\nmand-Query Responsibility Segregation, or CQRS (4), since Event \nStreams are hard to query. This increases developer cognitive load and \nlearning curve.\nFor those undaunted by these challenges, implementing with A+ES can provide \na lot of benefits. Let\u2019s examine some ways to implement using this powerful \napproach in the object-oriented world.\nwww.EBooksWorld.ir\n", "page": 583, "type": "text", "section": "Page 583"}
{"text": " \nINSIDE AN APPLICATION SERVICE\n541\nInside an Application Service\nLooking at A+ES inside an Application Service (4, 14) demonstrates the big \npicture. It\u2019s common for Aggregates to reside inside a domain model behind \nApplication Services, which serve as the direct clients of the domain model.\nWhen an Application Service receives control, it loads an Aggregate and \nretrieves any supporting Domain Services (7) needed by the Aggregate\u2019s busi-\nness operation. When the Application Service delegates to the Aggregate busi-\nness operation, the Aggregate\u2019s method produces Events as the outcome. Those \nEvents mutate the state of the Aggregate and are also published as notifications \nto all subscribers. The Aggregate\u2019s business method may require passing one \nor more Domain Services as parameters. The use of any such Domain Ser-\nvices could compute values used to cause side effects to the Aggregate\u2019s state. \nSome such Domain Service operations could include calling a payment gate-\nway, requesting a unique identity, or querying data from a remote system. Fig-\nure A.2 illustrates how this works.\nEvt1\nEvt2\nEvt3\nEvt5\nwww\nDesktop\nApplication Service\nDomain Services\nTransactional\nScope\n1. When client calls\nApplication Service\n3. Call Aggregate method passing\nparameters from Application Service,\nalong with Domain Services\nas needed\n4. Commit published Events as a Unit\nof Work to the Event Store to persist\nthe state of the Aggregate\n2. Load Aggregate state\nfrom Event Stream\n5. New Events are published from\nEvent Store to all subscribers\nA+ES\nEvent Store\nMobile\nEvt4\nEvt5\nEvt4\nFigure A.2 An Application Service controls access to and use of the Aggregate.\nwww.EBooksWorld.ir\n", "page": 584, "type": "text", "section": "Page 584"}
{"text": "Appendix A AGGREGATES AND EVENT SOURCING: A+ES\n542\nThe following Application Service implemented in C# shows how the steps \nof Figure A.2 might be supported:\npublic class CustomerApplicationService\n{\n  // event store for accessing event streams\n  IEventStore _eventStore;\n  // domain service that is neeeded by aggregate\n  IPricingService _pricingService;\n  // pass dependencies for this application service via constructor\n  public CustomerApplicationService(\n    IEventStore eventStore,\n    IPricingService pricing)\n  {\n    _eventStore = eventStore;\n    _pricingService = pricing;\n  }\n   \n// Step 1: LockForAccountOverdraft method of \n  // Customer Application Service is called\n  public void LockForAccountOverdraft(\n    CustomerId customerId, string comment)\n  {\n    // Step 2.1: Load event stream for Customer, given its id\n    var stream = _eventStore.LoadEventStream(customerId);\n    // Step 2.2: Build aggregate from event stream\n    var customer = new Customer(stream.Events);\n    // Step 3: Call aggregate method, passing it arguments and\n    // pricing domain service\n    customer.LockForAccountOverdraft(comment, _pricingService);\n    // Step 4: Commit changes to the event stream by id \n    _eventStore.AppendToStream(\n      customerId, stream.Version, customer.Changes);\n  }\n  public void LockCustomer(CustomerId customerId, string reason)\n  {\n    var stream = _eventStore.LoadEventStream(customerId);\n    var customer = new Customer(stream.Events);\n    customer.Lock(reason);\n    _eventStore.AppendToStream(\n      customerId, stream.Version, customer.Changes);\n  }\n  // other methods on this application service\n}\nThe CustomerApplicationService is initialized with two dependen-\ncies through the constructor, the IEventStore, and IPricingService.\nwww.EBooksWorld.ir\n", "page": 585, "type": "text", "section": "Page 585"}
{"text": " \nINSIDE AN APPLICATION SERVICE\n543\nConstructor-based initialization is a worthy means to fulfill the dependen-\ncies, but they could have been retrieved by means of a Service Factory or using \ndependency injection. Your team standards and practices reign.\nWhere Can I Find the Sample Code?\nAll source code for the A+ES examples is available for download here:\nhttp://lokad.github.com/lokad-iddd-sample/.\nOur IEventStore can have a simple interface definition, and our Event-\nStream follows suit:\npublic interface IEventStore\n{\n    EventStream LoadEventStream(IIdentity id);\n    EventStream LoadEventStream(\n        IIdentity id, int skipEvents, int maxCount);\n    void AppendToStream(\n        IIdentity id, int expectedVersion, ICollection<IEvent> events);\n}\npublic class EventStream\n{\n    // version of the event stream returned\n    public int Version;\n    // all events in the stream\n    public List<IEvent> Events;\n}\nThis Event Store can be implemented quite easily with a relational database \n(Microsoft SQL, Oracle, or MySQL) or with a NoSQL store that has strong \nconsistency guarantees (file system, MongoDB, RavenDB, or Azure Blob \nstorage).\nWe load Events from the Event Store using the unique identity of the Aggre-\ngate instance to be reconstituted. Let\u2019s see how this can be done for an Aggre-\ngate named Customer. Although the unique identity could have any type, for \nexpressiveness let\u2019s use an IIdentity interface implemented by CustomerId.\nWe need to load the Events belonging to the specific Customer, and the \nEvents are passed to the Customer\u2019s constructor to instantiate the Aggregate:\nvar eventStream = _eventStore.LoadEventStream(customerId);\nvar customer = new Customer(eventStream.Events);\nwww.EBooksWorld.ir\n", "page": 586, "type": "text", "section": "Page 586"}
{"text": "Appendix A AGGREGATES AND EVENT SOURCING: A+ES\n544\nAs seen in Figure A.3, the Aggregate applies Events by replaying them \nthrough method Mutate(). Here\u2019s how it works:\npublic partial class Customer\n{\n  public Customer(IEnumerable<IEvent> events)\n  {\n    // reinstate this aggregate to the latest version\n    foreach (var @event in events)\n    {\n      Mutate(@event);\n    }\n  }\n  public bool ConsumptionLocked { get; private set; }\n  public void Mutate(IEvent e)\n  { \n    // .NET magic to call one of 'When' handlers with\n    // matching signature \n    ((dynamic) this).When((dynamic)e);\n  }\n  public void When(CustomerLocked e)\n  {\n    ConsumptionLocked = true;\n  }\n  public void When(CustomerUnlocked e)\n  {\n    ConsumptionLocked = false;\n  }\n  // etc.\nEvent Store\nMutate(IEvent e)\nAggregate Boundary\n(state consistency)\nvoid When(EventA e)\nvoid When(EventB e)\nvoid When(EventC e)\nEvt3\nEvt2\nEvt1\nFigure A.3 The Aggregate state is reconstituted using Events applied in order \nof occurrence.\nwww.EBooksWorld.ir\n", "page": 587, "type": "text", "section": "Page 587"}
{"text": " \nINSIDE AN APPLICATION SERVICE\n545\nMutate() just locates (via .NET dynamics) the appropriate overloaded \nWhen() method by the specific Event parameter type, and then executes the \nmethod by passing in the Event. After Mutate() has completed, the  \nCustomer\ninstance has a completely reconstituted state.\nWe can make a reusable query operation for reconstituting an Aggregate \ninstance from the Event Store:\npublic Customer LoadCustomerById(CustomerId id)\n{\n    var eventStream = _eventStore.LoadEventStream(id);\n    var customer = new Customer(eventStream.Events);\n    return customer;\n}\nAfter considering how an Aggregate instance can be reconstituted from \na Stream of historic Events, it\u2019s easy to imagine other uses for the historical \nrecord. We can use them to look back in time just to view what happened, and \nwhen. The view capability becomes even more powerful when considering the \nneed to debug production deployments.\nHow are business operations performed? Once the Aggregate is reconsti-\ntuted from the Event Store, the Application Service delegates to a command \noperation on the Aggregate instance. It uses its current state and any Domain \nServices required by the contract to carry out the operation. As a behavior is \nexecuted, changes to the state are expressed as new Events. Each new Event is \npassed to the Aggregate\u2019s Apply() method, as pictured in Figure A.4.\nCustomer.Lock(args)\nAggregate Boundary\n(state consistency)\nState.Mutate(e)\nvoid Apply(IEvent e)\nChanges.Add(e)\nEvt5\nQuery state\nEvt4\nEvt5\nEvt4\nFigure A.4 Aggregate state is based on past Events, and outcome of behavior produces \nnew Events.\nwww.EBooksWorld.ir\n", "page": 588, "type": "text", "section": "Page 588"}
{"text": "Appendix A AGGREGATES AND EVENT SOURCING: A+ES\n546\nAs seen in the following code, new Events are accumulated in the Changes\ncollection and then used to mutate the current state of the Aggregate:\npublic partial class Customer \n{\n  ...\n  void Apply(IEvent event)\n  {\n     \n \n// append event to change list for further persistence    \n    Changes.Add(event);\n     \n \n// pass each event to modify current in-memory state\n    Mutate(event);\n  }\n  ...\n}\nAll Events added to the Changes collection will be persisted as newly \nappended. Since each Event is also used to immediately mutate the Aggregate\u2019s \nstate, if a behavior has multiple steps, each subsequent step has up-to-date \nstate to operate on.\nNext, take a look at some of the business behavior of the Customer\nAggregate:\npublic partial class Customer\n{\n  // Second part of aggregate class \n  public List<IEvent> Changes = new List<IEvent>();\n  public void LockForAccountOverdraft(\n    string comment, IPricingService pricing)\n  {\n    if (!ManualBilling)\n    {\n      var balance = pricing.GetOverdraftThreshold(Currency);\n      if (Balance < balance)\n      {\n        LockCustomer(\"Overdraft. \" + comment);\n      }\n    }\n  }\n  public void LockCustomer(string reason)\n  {\n    if (!ConsumptionLocked)\n    {\n      Apply(new CustomerLocked(_state.Id, reason));\n    }\n  }\nwww.EBooksWorld.ir\n", "page": 589, "type": "text", "section": "Page 589"}
{"text": " \nINSIDE AN APPLICATION SERVICE\n547\n  // Other business methods are not shown ...\n  void Apply(IEvent e)\n  {\n    Changes.Add(e);\n    Mutate(e);\n  }\n}\nConsider Using Two Implementation Classes\nTo make your code clearer, you can split the A+ES implementation into two dis-\ntinct classes, one for state and one for behavior, with the state object being held by \nthe behavioral. The two objects would collaborate exclusively through the Apply()\nmethod. This ensures that state is mutated only by means of Events.\nOnce the mutating behaviors have completed, we must commit the Changes\ncollection to the Event Store. We append all new changes, ensuring that there \nare no concurrency conflicts with other writing threads. This check is possi-\nble because we pass a concurrency version variable from the Load() to the \nAppend() methods.\nIn the simplest implementation, there will be a background processor that \ncatches up with newly appended Events and publishes them to a messaging \ninfrastructure (such as RabbitMQ, JMS, MSMQ, or cloud queues), delivering \nthem to all interested parties. See Figure A.5.\nThis simple implementation can be replaced by more elaborate ones. One \nsuch immediately or eventually replicates Events to one or more clones, increas-\ning fault tolerance. Figure A.6 shows immediate Event replication to one clone. \nAppender\nPublisher\nPublish to Subscribers\nAppend\nRead\nEvent Stream\nEvt5\nEvt4\nEvt1\nEvt2\nEvt3\nFigure A.5 Newly appended Aggregate behavioral outcome Events are published \nto subscribers.\nwww.EBooksWorld.ir\n", "page": 590, "type": "text", "section": "Page 590"}
{"text": "Appendix A AGGREGATES AND EVENT SOURCING: A+ES\n548\nIn this case, the Master Event Store considers its own Events to be saved only \nafter it has successfully replicated them to the Clone Event Store, which is a \nwrite-through strategy.\nAn alternative is to replicate Events to the Clone after changes are saved \nby the Master using a separate thread, which is a write-behind strategy. This \napproach is illustrated in Figure A.7. In this case the Clone could be inconsis-\ntent with the Master, which is especially true if a server crashes or if partition-\ning is impacted by network latency.\nTo summarize what has been discussed so far, let\u2019s walk through the execu-\ntion sequence that begins with the invocation of an operation on an Applica-\ntion Service:\n 1. A client invokes a method on an Application Service.\n 2. Obtain any Domain Services needed to carry out the business operation.\n 3. With the client-supplied Aggregate instance identity, retrieve its Event \nStream.\n1. Append Events\n4. Event Store completes Append() invocation\n2. Append Events to Clone\n3. Clone acknowledges to Master\nAggregate\nEvent Store\nMaster\nEvent Store\nClone\nFigure A.6 Write through: A Master Event Store immediately replicates all newly \nappended Events to a Clone Event Store.\n1. Append Events\n2. Event Store completes Append() invocation\n3. Append Events to Clone\nAggregate\nEvent Store\nMaster\nEvent Store\nClone\nFigure A.7 Write behind: A Master Event Store eventually replicates all newly \nappended Events to a Clone Event Store.\nwww.EBooksWorld.ir\n", "page": 591, "type": "text", "section": "Page 591"}
{"text": " \nCOMMAND HANDLERS\n549\n 4. Reconstitute the Aggregate instance by applying to it all Events from the \nStream.\n 5. Execute a business operation provided by the Aggregate, passing in all \nparameters required by the interface\u2019s contract.\n 6. The Aggregate may double-dispatch to any provided Domain Services, \ninstances of other Aggregates, and so on and will generate new Events as \nthe outcome of the operation.\n \n7. Assuming no failed business operations, append all newly generated \nEvents to the Stream using the Stream version to guard against concur-\nrency conflicts.\n 8. Publish newly appended Events from the Event Store to subscribers using \nyour choice of messaging infrastructure.\nWe could enhance our A+ES implementation using various options. For \nexample, we could use a Repository (12) to encapsulate access to the Event \nStore and the details of reconstitution of the Aggregate instances. Given the \npreceding code snippets, it would be easy for you to create a reusable Repos-\nitory base class. Let\u2019s focus on just two practical optional enhancements that \nhelp a lot with A+ES designs: Command Handlers and lambdas.\nCommand Handlers\nLet\u2019s consider the advantages of using Commands (4, 14) and Command Han-\ndlers to control the task management of our application. To start, first take \nanother look at our Application Service and its LockCustomer() method:\npublic class CustomerApplicationService\n{\n  ...\n  public void LockCustomer(CustomerId id, string reason)\n  {\n    var eventStream = _eventStore.LoadEventStream(id);\n    var customer = new Customer(stream.Events);\n    customer.LockCustomer(reason);\n    _store.AppendToStream(id, eventStream.Version, customer.Changes);\n  }\n  ...\n}\nwww.EBooksWorld.ir\n", "page": 592, "type": "text", "section": "Page 592"}
{"text": "Appendix A AGGREGATES AND EVENT SOURCING: A+ES\n550\nNow imagine creating a serialized representation of the method name and \nits parameters. How might that look? We could create a class named for the \napplication operation and create instance properties to match the parameters \nto the service method. This class forms a Command:\npublic sealed class LockCustomerCommand\n{\n  public CustomerId { get; set; }\n  public string Reason { get; set; }\n}\nCommand contracts follow the same semantics as Events and can be shared \nacross systems in a similar fashion. This Command could then be passed to a \nmethod on the Application Service:\npublic class CustomerApplicationService\n{\n  ...\n  public void When(LockCustomerCommand command)\n  {\n    var eventStream = _eventStore.LoadEventStream(command.CustomerId);\n    var customer = new Customer(stream.Events);\n    customer.LockCustomer(command.Reason);\n    _eventStore.AppendToStream(\n      command.CustomerId, eventStream.Version, customer.Changes);\n  }\n  ...\n}\nThis simple refactoring could have a few long-term benefits for the system. \nLet\u2019s see how.\nSince the Command objects can be serialized, we can send the textual or \nbinary representations as messages over a message queue. The object that the \nmessage is delivered to is a message handler and is to us a Command Handler. \nThe Command Handler effectively replaces the Application Service method, \nalthough it is roughly equivalent and may still be referred to as such. Anyway, \ndecoupling the client from the Service can enhance load balancing, enable \ncompeting consumers, and support system partitioning. Take load balanc-\ning for one. We can spread the load by starting the same Command Handler \n(semantically an Application Service) on any number of servers. As Commands \nare put on the message queue, the Command messages can be delivered to one \nof the several Command Handlers that are listening for them. This is depicted \nwww.EBooksWorld.ir\n", "page": 593, "type": "text", "section": "Page 593"}
{"text": " \nCOMMAND HANDLERS\n551\nin Figure A.8. (In this appendix Commands are shown as circular objects.) The \nactual distribution might be done using a simple round-robin style or some \nmore sophisticated delivery algorithm, any of which are provided by the mes-\nsaging infrastructure.\nThis approach creates temporal decoupling between clients and the Appli-\ncation Service, leading toward more robust systems. For one, the client will no \nlonger be blocked if the Application Service is unavailable for a short period \nof time (for example, for maintenance or upgrade). Instead, Commands will \nbe put into a persistent queue, which will be processed by the Command Han-\ndlers (Application Service) when its server comes back online, as indicated in \nFigure A.9.\nAnother advantage is the ability to chain additional aspects before Com-\nmand dispatching as needed. For example, we could easily patch in auditing, \nlogging, authorization, and validation. \nClient\nServer 1\nServer 2\nServer N\n. . .\nMessage Queue\nCmd\nCmd\nFigure A.8 Application Commands being distributed to any number \nof Command Handlers\nClient\nMessage Queue\nCmd\nCmd\nCmd\nCmd\nMessage Queue\nCmd\nApplication Service\nONLINE!\nCmd\nApplication Service\nOFFLINE!\n1. Client sends Command to Message Queue\nwhile Application Service is offline\n2. Application Service comes\nonline; receives Commands\nFigure A.9 The temporal decoupling characteristics of message-based Commands and \ntheir Command Handlers allow for flexible system availability options.\nwww.EBooksWorld.ir\n", "page": 594, "type": "text", "section": "Page 594"}
{"text": "Appendix A AGGREGATES AND EVENT SOURCING: A+ES\n552\nConsider how we might patch in logging. We first define a standard inter-\nface and implement the interface in an Application Service class:\npublic interface IApplicationService\n{\n    void Execute(ICommand cmd);\n}\npublic partial class CustomerApplicationService : IApplicationService\n{\n  public void Execute(ICommand command)\n  {\n    // pass command to a specific method When()\n    // that can handle the command\n    ((dynamic)this).When((dynamic)command);\n  }\n}\nExecute and Mutate Have Similar Implementations\nNote that the way this Execute() method is implemented has some characteristics \nsimilar to the Mutate() method described previously as part of an A+ES Aggre-\ngate\u2019s design.\nOnce we have a standard interface for all Command Handlers (Application \nServices), we can patch in any kind of standard pre- and post-execution fea-\ntures, such as generic logging:\npublic class LoggingWrapper : IApplicationService\n{\n  readonly IApplicationService _service;\n  public LoggingWrapper(IApplicationService service)\n  {\n    _service = service;\n  }\n  public void Execute(ICommand cmd)\n  {\n    Console.WriteLine(\"Command: \" + cmd);\n    try\n    {\n      var watch = Stopwatch.StartNew();\n      _service.Execute(cmd);\n      var ms = watch.ElapsedMilliseconds;\n      Console.WriteLine(\"  Completed in {0} ms\", ms);\n    }\nwww.EBooksWorld.ir\n", "page": 595, "type": "text", "section": "Page 595"}
{"text": " \nLAMBDA SYNTAX\n553\n    catch( Exception ex)\n    {\n      Console.WriteLine(\"Error: {0}\", ex);\n    }\n  } \n}\nBecause all Application Services have a standard interface, we can patch \nin any number of generic utilities that operate before and/or after the actual \nCommand Handler functions. Here\u2019s how the CustomerApplicationSer-\nvice is initialized with pre- and post-execution logging:\nvar customerService =\n  new CustomerApplicationService(eventStore, pricingService);\nvar customerServiceWithLogging = new LoggingWrapper(customerService); \nOf course, the fact that Commands are serialized objects dispatched to \nCommand Handlers enables us to deal with various failures and error condi-\ntions in a single location. Given a certain class of error, such as resource con-\ntention over concurrency issues, we could choose a standard recovery action, \nsuch as retrying the operation X number of times. The retries could be based \non a Capped Exponential Back-off strategy, making all retries uniform, reli-\nable, and maintained in a single class.\nLambda Syntax\nIf your language supports lambda expressions, it is possible to make other-\nwise repetitive code more compact by avoiding repetitive Event Stream man-\nagement. To demonstrate this fact, here we introduce a helper method within \nour Application Service:\npublic class CustomerApplicationService\n{\n  ...\n   \npublic void Update(CustomerId id, Action<Customer> execute)\n  {\n    EventStream eventStream = _eventStore.LoadEventStream(id);\n    Customer customer = new Customer(eventStream.Events);\n    execute(customer);\n    _eventStore.AppendToStream(\n      id, eventStream.Version, customer.Changes);\n  }\n  ...\n}\nwww.EBooksWorld.ir\n", "page": 596, "type": "text", "section": "Page 596"}
{"text": "Appendix A AGGREGATES AND EVENT SOURCING: A+ES\n554\nIn this method the parameter Action<Customer> execute references \nan anonymous function (C# delegate) that can operate on any Customer\ninstance. The conciseness of the lambda expression can be seen in the parame-\nter passed to Update():\npublic class CustomerApplicationService\n{\n  ...\n  public void When(LockCustomer c)\n  {\n    Update(c.Id, customer => customer.LockCustomer(c.Reason));\n  }\n  ...\n}\nIn actuality the C# compiler generates something similar to the following \ncode that fulfills the intent of the lambda expression:\n \npublic class AnonymousClass_X\n{\n    public string Reason;\n    public void Execute(Customer customer);\n    {\n       Customer.LockCustomer(Reason);\n    }\n}\npublic delegate void Action<T>(T argument);\npublic void When(LockCustomer c)\n{\n  var x = new AnonymousClass_X();\n  x.Reason = c.Reason\n  Update(c.Id, new Action<Customer>(customer => x.Execute(customer));\n}\nSince this generated function takes a Customer instance as an argument, it \ncan actually be used to capture the behavior in the code and execute it multiple \ntimes on different Customer instances. The power of using lambdas is high-\nlighted in the following section.\nConcurrency Control\nAggregate Event Streams can be accessed and read by multiple threads simul-\ntaneously. This opens up the real potential for concurrency conflicts that, if \nwww.EBooksWorld.ir\n", "page": 597, "type": "text", "section": "Page 597"}
{"text": " \nCONCURRENCY CONTROL\n555\nleft unchecked, could result in a random number of invalid Aggregate states. \nConsider a scenario when two threads attempt to modify the Event Stream at \nthe same time, as shown in Figure A.10.\nThe simplest resolution to this situation is to use EventStoreConcur-\nrencyException at step 4, allowing it to propagate all the way up to the \nultimate client:\npublic class EventStoreConcurrencyException : Exception\n{\n    public List<IEvent> StoreEvents { get; set; }\n    public long StoreVersion { get; set; }\n}\nUpon catching this exception in the ultimate client, the user would probably be \ninstructed to retry the operation manually.\nInstead of taking that approach first, you would probably agree that a \nstandardized retry approach might be best. So when our Event Store throws \nEventStoreConcurrencyException, we can immediately attempt recovery:\nvoid Update(CustomerId id, Action<Customer> execute)\n{\n  while(true)\n  {\nThread 1\nEvt4\nEvt5\nEvt1\nEvt2\nEvt3\n1. Events 1\u20133 are loaded\nby Thread 1\n3. Thread 1 executes behaviors and\nsuccessfully appends Events 4 and 5\nafter Event 3\nThread 2\nEvt4\nEvt5\n2. Events 1\u20133 are loaded\nby Thread 2\n4. Thread 2 executes behaviors and\nattempts to append Events 4 and 5\nafter Event 3, but fails\nFigure A.10 Two threads contending for the same instance of an Aggregate \ndesigned using A+ES\nwww.EBooksWorld.ir\n", "page": 598, "type": "text", "section": "Page 598"}
{"text": "Appendix A AGGREGATES AND EVENT SOURCING: A+ES\n556\n    EventStream eventStream = _eventStore.LoadEventStream(c.Id);\n    var customer = new Customer(eventStream.Events);\n    try\n    {\n      execute(customer);\n      _eventStore.AppendToStream(\n        c.Id, eventStream.Version, customer.Changes);\n      return;\n    }\n    catch (EventStoreConcurrencyException)\n    {\n      // fall through and retry, with optional brief delay\n    }\n  }\n}\nIn the case where a concurrency conflict occurs, we would add these addi-\ntional steps to overcome the problem:\n 1. Thread 2 catches the exception and falls through, with control going to \nthe beginning of the while loop. Now Events 1\u20135 are loaded into a new \nCustomer instance.\n 2. Thread 2 reexecutes the delegate on the reloaded Customer, which now \ncreates Events 6\u20137, which will be successfully appended after Event 5.\nIf the required Aggregate behavior reexecution is too expensive or for some \nreason not feasible (for example, requires costly third-party system integration \nto place an order or to charge a credit card), we might want to employ a differ-\nent strategy.\nAs is illustrated in Figure A.11, one such strategy is Event conflict resolu-\ntion, which is employed to reduce the number of actual concurrency excep-\ntions. Here\u2019s how a very simple use of conflict resolution can work:\nConflicts?\nNo\nEvent Store\nEvt1\nEvt2\nEvt3\nEvt4\nEvt5\nClient Changes\nEvt4\nEvt5\nEvent Store\nEvt1\nEvt2\nEvt3\nEvt4\nEvt5\nEvt6\nEvt7\nFigure A.11 Using Event conflict resolution on the Event Stream of an Aggregate\nwww.EBooksWorld.ir\n", "page": 599, "type": "text", "section": "Page 599"}
{"text": " \nCONCURRENCY CONTROL\n557\nvoid UpdateWithSimpleConflictResolution(\n  CustomerId id, Action<Customer> execute)\n{\n  while (true)\n  {\n    EventStream eventStream = _eventStore.LoadEventStream(id);\n    Customer customer = new Customer(eventStream.Events);\n    execute(customer);\n    try\n    {\n      _eventStore.AppendToStream(\n        id, eventStream.Version, customer.Changes);\n      return;\n    }\n    catch (EventStoreConcurrencyException ex)\n    {\n      foreach (var failedEvent in customer.Changes)\n      {\n        foreach (var succeededEvent in ex.ActualEvents)\n        {\n          if (ConflictsWith(failedEvent, succeededEvent))\n          {\n            var msg = string.Format(\"Conflict between {0} and {1}\", \n              failedEvent, succeededEvent);\n            throw new RealConcurrencyException(msg, ex);\n          }\n        }\n      }\n      // there are no conflicts and we can append\n      _eventStore.AppendToStream(\n        id, ex.ActualVersion, customer.Changes);\n    }\n  }\n}\nIn this case the conflict detection method ConflictsWith() is used to \ncompare each of the Aggregate Events for conflicts with Events that were con-\ncurrently appended to the Event Store (as reported in the exception). \nThis conflict resolution method is usually defined per Aggregate Root, \ndepending on the specific kinds of behaviors it supports. Yet, there is a \nConflictsWith() implementation that would work for the majority of \nAggregates:\n \nbool ConflictsWith(IEvent event1, IEvent event2)\n{\n  return event1.GetType() == event2.GetType();\n}\nwww.EBooksWorld.ir\n", "page": 600, "type": "text", "section": "Page 600"}
{"text": "Appendix A AGGREGATES AND EVENT SOURCING: A+ES\n558\nThis majority-case conflict resolution is based on a simple rule: Events of the \nsame type always conflict with each other, but Events of different types do not.\nStructural Freedom with A+ES\nOne of the biggest practical advantages of A+ES is the simplicity of persistence \nand the versatility it provides. No matter how complex the structure of a given \nAggregate is, it can always be represented with a sequence of serialized Events \nthat can be used to reconstitute it. Many domains influence changes to the \nmodel over time, with new behaviors or modeling subtleties that arise from \nchanging requirements of an evolving system. Even if we must restructure the \ninternal implementation of a given Aggregate in order to deal with significant \nchanges, A+ES can most times facilitate such changes with lower risks and lit-\ntle frustration to developers.\nThe sequence of Events associated with a specific identity is usually referred \nto as an Event Stream. In essence, it is just an append-only list of messages \nserialized into byte blocks with the serializer of your choice. As such, an Event \nStream can be persisted with equal success using relational databases, NoSQL \npersistence, plain file systems, or cloud storage, as long as any chosen store has \nstrong consistency guarantees.\nHere are three major advantages of A+ES persistence, which are especially \nimportant for Bounded Contexts (2) with a long life:\n\u2022 The ability to adapt the internal implementations of an Aggregate to any \npractical structural representation necessary to express new behaviors \nencountered by domain experts\n\u2022 The ability to move the entire infrastructure between various hosting \nsolutions, which enables us to deal with cloud outages and provide sound \nfail-over options\n\u2022 The ability of an Event Stream for any Aggregate instance to be down-\nloaded to a development machine and replayed to debug an error condition\nPerformance\nSometimes loading Aggregates from large Streams can cause performance prob-\nlems, especially when individual Streams go beyond hundreds of thousands of \nwww.EBooksWorld.ir\n", "page": 601, "type": "text", "section": "Page 601"}
{"text": " \nPERFORMANCE\n559\nEvents. There are a couple of simple patterns that could be applied in individ-\nual cases to solve this problem:\n\u2022 Cache Event Streams in server memory, leveraging the fact that Events \nare immutable once written to an Event Store. While querying the Event \nStore for any changes, we could supply a version of the last known Event \nand ask only for those that occurred since then, if any. This can improve \nperformance at the cost of memory consumption.\n\u2022 Avoid loading and replaying a large portion of an Event Stream by tak-\ning a snapshot of each Aggregate instance. This way, while loading any \nAggregate instance, you just need to find its latest snapshot and then \nreplay any Events that were appended to the Event Stream since it was \ntaken.\nAs seen in Figure A.12, snapshots are just serialized copies of an Aggregate\u2019s \nfull state, taken at certain moments in time, that reside in the Event Stream as \nspecific versions. They can be persisted in a Repository encapsulated behind a \nsimple interface like this:\npublic interface ISnapshotRepository\n{\n  bool TryGetSnapshotById<TAggregate>(\n    IIdentity id, out TAggregate snapshot, out int version);\n  void SaveSnapshot(IIdentity id, TAggregate snapshot, int version);\n}\nWe must record the Stream\u2019s version along with each snapshot. With the \nversion we can load the snapshot along with only the Events that have occurred \nsince the moment the snapshot was recorded. We first retrieve the snapshot as \nthe base state of the Aggregate instance, and then we load and replay all Events \nthat occurred since the snapshot was taken:\n// simple document storage interface\nISnapshotRepository _snapshots;\nLoad Aggregate State\nEvt1\nEvt2\nEvt3\nEvt4\nEvt5\nSnapshot\nFigure A.12 An Aggregate\u2019s Event Stream with a snapshot of its state followed by \ntwo Events that occurred after the snapshot was taken\nwww.EBooksWorld.ir\n", "page": 602, "type": "text", "section": "Page 602"}
{"text": "Appendix A AGGREGATES AND EVENT SOURCING: A+ES\n560\n// our event store\nIEventStore _store;\npublic Customer LoadCustomerAggregateById(CustomerId id)\n{\n  Customer customer;\n  long snapshotVersion = 0;\n  if (_snapshots.TryGetSnapshotById(\n        id, out customer, out snapshotVersion))\n  {\n    // load any events since snapshot was taken\n    EventStream stream = _store.LoadEventStreamAfterVersion(\n      id, snapshotVersion);\n    // replay these events to update snapshot\n    customer.ReplayEvents(stream.Events);\n    return customer;\n  }\n  else // we don't have any persisted snapshot\n  {\n    EventStream stream = _store.LoadEventStream(id);\n    return new Customer(stream.Events);\n  }\n}\nThe method ReplayEvents() must be used to bring the Aggregate \ninstance state up-to-date with the Events that occurred since the latest snap-\nshot. Remember that the Aggregate instance state is mutated from the point of \nthe latest snapshot forward. Thus, we will not be instantiating the Customer\n(in this example) using an Event Stream only. And we can\u2019t just use Apply()\nbecause it not only mutates the current state with the given Event, it also saves \neach Event it receives to the Changes collection. Saving Events to Changes\nthat are already in the Event Stream would cause serious bugs. Thus, we simply \nneed to implement the new method ReplayEvents():\npublic partial class Customer\n{\n  ...\n  public void ReplayEvents(IEnumerable<IEvent> events)\n  {\n    foreach (var event in events)\n    {\n      Mutate(event);\n    }\n  }\n  ...\n}\nwww.EBooksWorld.ir\n", "page": 603, "type": "text", "section": "Page 603"}
{"text": " \nIMPLEMENTING AN EVENT STORE\n561\nHere\u2019s some simple code for generating Customer snapshots:\npublic void GenerateSnapshotForCustomer(IIdentity id)\n{\n  // load all events from the start\n  EventStream stream = _store.LoadEventStream(id);\n  Customer customer = new Customer(stream.Events);\n  _snapshots.SaveSnapshot(id, customer, stream.Version);\n}\nSnapshot generation and persistence can be delegated to a background \nthread. New snapshots would be produced only after some set number of \nEvents have occurred since the latest snapshot. These steps are indicated in \nFigure A.13. Since the characteristics of each Aggregate type could be quite \ndifferent, the snapshot threshold for each type can be tuned for specific perfor-\nmance needs.\nOne additional way to address performance concerns with A+ES Aggregates \nis to partition Aggregates among multiple processes or machines by Aggregate \nidentity. This partitioning can be accomplished using identity hashing or other \nalgorithms and can be combined with both Aggregate instance memory cach-\ning and Aggregate snapshots.\nImplementing an Event Store\nLet\u2019s now actually implement a few different Event Stores that are suitable for \nuse with A+ES. The Stores here are simple and aren\u2019t designed for extremely \nhigh performance, yet they will be good enough for most domains.\nWhile the implementation for each of the various Event Stores is different, \nthe contracts are the same:\nEvent Stream\nEvt1\nEvt2\nEvt3\nEvt4\nEvt5\nSnapshot\nAppend\nLoad\nSnapshot\nProcess\nFigure A.13 An Aggregate\u2019s snapshot is generated after a specific number of new \nEvents have occurred.\nwww.EBooksWorld.ir\n", "page": 604, "type": "text", "section": "Page 604"}
{"text": "Appendix A AGGREGATES AND EVENT SOURCING: A+ES\n562\n \npublic interface IEventStore\n{\n  // loads all events for a stream\n  EventStream LoadEventStream(IIdentity id);\n  // loads subset of events for a stream\n  EventStream LoadEventStream(\n    IIdentity id, int skipEvents, int maxCount);\n  // appends events to a stream, throwing \n  // OptimisticConcurrencyException another appended\n  // new events since expectedversion\n  void AppendToStream(\n    IIdentity id, int expectedVersion, ICollection<IEvent> events);\n}\npublic class EventStream\n{\n    // version of the event stream returned\n    public int Version;\n    // all events in the stream\n    public IList<IEvent> Events = new List<IEvent>();\n}\nAs illustrated in Figure A.14, the class implementing IEventStore is a \nproject-specific wrapper around the more generic and reusable IAppend-\nOnlyStore. While the IEventStore implementation deals with serialization \nand strong typing, the IAppendOnlyStore implementations provide low-\nlevel access to various storage engines.\nMS SQL Server Store\nFile-based Store\nWindows Azure Blob Store\nImplementations of IAppendOnlyStore\nMySQL Store\nCurrency Detection\nEvent Serialization\nIAppendOnly Store\nEvent Store\nStrong Typing\nFigure A.14 The characteristics of the higher-level IEventStore and the \nlower-level IAppendOnlyStore\nwww.EBooksWorld.ir\n", "page": 605, "type": "text", "section": "Page 605"}
{"text": " \nIMPLEMENTING AN EVENT STORE\n563\nEvent Store Source Code\nFull source code for the range of Event Stores with multiple storage implementations \nis available for download as part of an A+ES sample project: http://lokad.github.\ncom/lokad-iddd-sample/.\nHere is the lower-level IAppendOnlyStore interface:\npublic interface IAppendOnlyStore : IDisposable\n{\n  void Append(string name, byte[] data, int expectedVersion = -1);\n  IEnumerable<DataWithVersion> ReadRecords(\n    string name, int afterVersion, int maxCount);\n  IEnumerable<DataWithName> ReadRecords(\n    int afterVersion, int maxCount);\n  void Close();\n}\npublic class DataWithVersion\n{\n  public int Version;\n  public byte[] Data;\n}\npublic sealed class DataWithName\n{\n  public string Name;\n  public byte[] Data;\n}\nAs you can see, IAppendOnlyStore deals with arrays of bytes instead of \nEvent collections, and string names instead of strongly typed identities. Class \nEventStore handles conversions between the two types of data.\nThe IAppendOnlyStore declares two distinct ReadRecords() meth-\nods. The first one listed is used to read Events within a single Stream by their \nnames, and the second one to read all Events in the Store. Both method imple-\nmentations must always read Events in the order in which they were persisted. \nAs you have probably deduced, the first overloaded method is required for \nrebuilding the state of a single Aggregate. The second ReadRecords() is used \nby the infrastructure to replicate Events, to publish them without the need for \ntwo-phase commit, and to rebuild persistent read models such as are needed \nfor CQRS-based user interfaces.\nA simple approach to serialization and deserialization\u2014conversion between \nbytes and strongly typed Event objects\u2014could use the .NET BinaryFormatter:\nwww.EBooksWorld.ir\n", "page": 606, "type": "text", "section": "Page 606"}
{"text": "Appendix A AGGREGATES AND EVENT SOURCING: A+ES\n564\npublic class EventStore : IEventStore\n{\n  readonly BinaryFormatter _formatter = new BinaryFormatter();\n  byte[] SerializeEvent(IEvent[] e)\n  {\n    using (var mem = new MemoryStream())\n    {\n      _formatter.Serialize(mem, e);\n      return mem.ToArray();\n    }\n  }\n  IEvent[] DeserializeEvent(byte[] data)\n  {\n    using (var mem = new MemoryStream(data))\n    {\n      return (IEvent[])_formatter.Deserialize(mem);\n    }\n  }\n}\nHere\u2019s how we can use serialization and deserialization to load an Event \nStream:\nreadonly IAppendOnlyStore _appendOnlyStore;\n...\npublic EventStream LoadEventStream(IIdentity id, int skip, int take)\n{\n  var name = IdentityToString(id);\n  var records = _appendOnlyStore.ReadRecords(name, skip, take).ToList();\n  var stream = new EventStream();\n  foreach (var tapeRecord in records)\n  {\n    stream.Events.AddRange(DeserializeEvent(tapeRecord.Data));\n    stream.Version = tapeRecord.Version;\n  }\n  return stream;\n} \nstring IdentityToString(IIdentity id)\n{\n  // in this project all identities produce proper name\n  return id.ToString();\n}\nwww.EBooksWorld.ir\n", "page": 607, "type": "text", "section": "Page 607"}
{"text": " \nRELATIONAL PERSISTENCE\n565\nHere we see how to append new Events to the Event Store by way of the \nIAppendOnlyStore:\npublic void AppendToStream(\n  IIdentity id, int originalVersion, ICollection<IEvent> events)\n{\n  if (events.Count == 0)\n    return;\n  var name = IdentityToString(id);\n  var data = SerializeEvent(events.ToArray());\n  try\n  {\n    _appendOnlyStore.Append(name, data, originalVersion);\n  }\n  catch(AppendOnlyStoreConcurrencyException e)\n  {\n    // load server events\n    var server = LoadEventStream(id, 0, int.MaxValue);\n    // throw a real problem\n    throw OptimisticConcurrencyException.Create(\n      server.Version, e.ExpectedVersion, id, server.Events);\n  }\n}\nRelational Persistence\nThe capabilities and strong consistency guarantees provided by relational \ndatabases make for the simplest approach to implementing append-only per-\nsistence. The fact that many enterprises have already standardized on one or \nmore relational database products means there is little to no cost or learning \ncurve to using them for Event Stores.\nSince the MySQL database is a popular open source relational database \nserver that is available on several platforms, we will use it to implement an \nEvent Store. The MySQLAppendOnlyStore implements IAppendOnly-\nStore, acting as an access layer. It will be used to save Events as binary data \ninto an ES_Events table, and to subsequently load those persisted Events. \nHere\u2019s the table definition, which manages an Event Stream for each Aggre-\ngate type in a Bounded Context:\nCREATE TABLE IF NOT EXISTS `ES_Events` (\n  `Id` int NOT NULL AUTO_INCREMENT,    -- unique id\n  `Name` nvarchar(50) NOT NULL,        -- name of the stream\nwww.EBooksWorld.ir\n", "page": 608, "type": "text", "section": "Page 608"}
{"text": "Appendix A AGGREGATES AND EVENT SOURCING: A+ES\n566\n  `Version` int NOT NULL,              -- incrementing stream version\n  `Data` LONGBLOB NOT NULL             -- data payload\n)\nTo append an Event to a specific Stream using a transaction, use the follow-\ning steps:\n 1. Begin a transaction.\n 2. Check if the Event Store changed from the expected version; if so, throw \nan exception.\n 3. If there are no concurrency conflicts, append the Events.\n 4. Commit the transaction.\nHere is the source code for method Append():\npublic void Append(string name, byte[] data, int expectedVersion)\n{\n  using (var conn = new MySqlConnection(_connectionString))\n  {\n    conn.Open();\n    using (var tx = conn.BeginTransaction())\n    {\n      const string sql =\n        @\"SELECT COALESCE(MAX(Version),0) \n          FROM `ES_Events` \n          WHERE Name=?name\";\n      int version;\n      using (var cmd = new MySqlCommand(sql, conn, tx))\n      {\n        cmd.Parameters.AddWithValue(\"?name\", name);\n        version = (int)cmd.ExecuteScalar();\n        if (expectedVersion != -1)\n        {\n          if (version != expectedVersion)\n          {\n            throw new AppendOnlyStoreConcurrencyException(\n              version, expectedVersion, name);\n          }\n        }\n      }\n      const string txt =\n           @\"INSERT INTO `ES_Events` (`Name`, `Version`, `Data`) \n            VALUES(?name, ?version, ?data)\";\n      using (var cmd = new MySqlCommand(txt, conn, tx))\n      {\n        cmd.Parameters.AddWithValue(\"?name\", name);\nwww.EBooksWorld.ir\n", "page": 609, "type": "text", "section": "Page 609"}
{"text": " \nRELATIONAL PERSISTENCE\n567\n        cmd.Parameters.AddWithValue(\"?version\", version+1);\n        cmd.Parameters.AddWithValue(\"?data\", data);\n        cmd.ExecuteNonQuery();\n      }\n      tx.Commit();\n    }\n  }\n}\nReading from the IAppendOnlyStore is quite simple, requiring only a \nbasic query. For example, this is how we get a list of records for an Aggregate\u2019s \nEvent Stream:\npublic IEnumerable<DataWithVersion> ReadRecords(\n  string name, int afterVersion, int maxCount)\n{\n  using (var conn = new MySqlConnection(_connectionString))\n  {\n    conn.Open();\n    const string sql =\n      @\"SELECT `Data`, `Version` FROM `ES_Events`\n        WHERE `Name` = ?name AND `Version`>?version\n        ORDER BY `Version`\n        LIMIT 0,?take\";\n    using (var cmd = new MySqlCommand(sql, conn))\n    {\n      cmd.Parameters.AddWithValue(\"?name\", name);\n      cmd.Parameters.AddWithValue(\"?version\", afterVersion);\n      cmd.Parameters.AddWithValue(\"?take\", maxCount);\n      using (var reader = cmd.ExecuteReader())\n      {\n        while (reader.Read())\n        {\n          var data = (byte[])reader[\"Data\"];\n          var version = (int)reader[\"Version\"];\n          yield return new DataWithVersion(version, data);\n        }\n      }\n    }\n  }\n}\nYou will find the full source code for this MySQL-based Event Store with \nthe rest of the sample code. A similar implementation is provided for Microsoft \nSQL Server.\nwww.EBooksWorld.ir\n", "page": 610, "type": "text", "section": "Page 610"}
{"text": "Appendix A AGGREGATES AND EVENT SOURCING: A+ES\n568\nBLOB Persistence\nLeveraging a database server (such as MySQL or MS SQL Server) will save you \na lot of work. It saves significant effort in dealing with concurrency manage-\nment, file fragmentation, caching, and data consistency. Obviously, then, not \nusing a database product would require us to handle many of those concerns \non our own.\nHowever, if we did choose to brave a rougher road to Event Stores, we do \nhave some help. For example, Windows Azure Blob storage and simple file \nsystem storage are at our disposal, and the sample project includes implemen-\ntations of both.\nLet\u2019s consider some design guidelines for building an Event Store without a \ndatabase, some of which are summarized by Figure A.15:\n 1. Our custom storage is composed of a set of one or more append-only \nbinary large object (BLOB) files or their equivalents. The component that \nwrites to the storage locks it exclusively as it appends but allows for con-\ncurrent reads.\n 2. Depending on your strategy, you could use just one BLOB store for all \nAggregate types and instances for a Bounded Context. Alternatively you \ncould create one BLOB store for each Aggregate type, where all instances \nof a given type would be stored. Or you could split up the BLOB stores \nfor each Aggregate type by instance, where the Event Stream for a single \ninstance would be stored on its own.\n 3. When the writer component appends, it opens the appropriate BLOB \nstore, writes to it, and maintains an index into the store.\nAppend-file-001.dat\nname\nversion\ndata\nsha1\nname\nversion\ndata\nsha1\nname\nversion\ndata\nsha1\nname\nversion\ndata\nWrite/Read direction\nsha1\nAppend-file-002.dat\nAppend-file-003.dat\nFigure A.15 File-based BLOB storage using a strategy of one file for each Aggregate \ninstance, containing one record for each Event\nwww.EBooksWorld.ir\n", "page": 611, "type": "text", "section": "Page 611"}
{"text": " \nFOCUSED AGGREGATES\n569\n 4. Regardless of the BLOB storage strategy in use, all new Events are \nappended to the end. Each record is composed of a name, version, and \nbinary data fields. This is similar to the way we store Event records to \na relational database. However, with a BLOB store we must prefix vari-\nable-length fields with the byte count length, and we also append a hash \ncode or cyclic redundancy check (CRC) to verify data integrity when the \nrecords are read.\n 5. BLOB-based append-only storage allows for enumeration of all Events \nacross all Event Streams simply by enumerating all files and their con-\ntents. In order to speed up disk seeks and reading Events for a specific \nStream, we would need to maintain a dedicated in-memory index and/\nor cache the Event Streams in memory. If memory caching is used, each \nappend would require the cache to be refreshed. Further, Aggregate state \nsnapshots and file defragmentation can also help to improve performance.\n 6. Of course, we can avoid many of the file system disk fragmentation issues \nby preallocating large regions of BLOB file space as each file-based Event \nStream is created.\nThis design is inspired by the Riak Bitcask model. You can read more details \nand explanations in the Riak Bitcask architecture paper: http://downloads.\nbasho.com/papers/bitcask-intro.pdf.\n \nFocused Aggregates\nWhile developing Aggregates with traditional persistence (for example, rela-\ntional database without the use of Event Sourcing), development friction from \nintroducing a new Entity into the system or enriching an existing one can be \nnoticeable. We need to create new tables and define new mapping schemata and \nRepository methods. If our tendency is to resist such development overhead, it \ncan cause us to grow Aggregates as we concentrate more state structure and \nbehaviors on each. It can be much easier to add onto an existing Aggregate \nrather than to create a new one.\nHowever, our bias can shift if Aggregates are more easily designed anew, \nand I assert that this is true when Event Sourcing is in use. In my experience, \nAggregates designed using A+ES tend to be smaller, which is one of the pri-\nmary Aggregate Rules of Thumb.\nFor example, for a company providing software as a service, a real-world \ncustomer might be represented with distinct Aggregates focusing on different \nbehavioral aspects:\nwww.EBooksWorld.ir\n", "page": 612, "type": "text", "section": "Page 612"}
{"text": "Appendix A AGGREGATES AND EVENT SOURCING: A+ES\n570\n\u2022 Customer:505 hosts behaviors for billing, invoicing, and general account \nmanagement.\n\u2022 Security-Account:505 maintains multiple users with access permis-\nsions for each.\n\u2022 Consumer:505 tracks actual service consumption.\nEach of these Aggregate types may be implemented in a different Bounded \nContext, each Bounded Context using different technologies and architectural \napproaches. For example, the Consumer aspect might need to provide high \nscalability and deal with consuming thousands of messages for customers each \nsecond. Assuming that is so, such an Event Stream should be hosted in auto-\nscaling cloud fabric. Other aspects might be less demanding, allowing them to \nbe hosted in a less demanding environment.\nOf course, Aggregates should never be designed to be arbitrarily small. \nWe always want to design Aggregates to protect true business invariants, and \ndoing so may cause any given Aggregate to be composed of multiple Entities \nand a number of Value Objects. Yet, the ease of using A+ES provides us with \ngreater opportunity to strive for simple and efficient designs. This is an advan-\ntage that should be embraced whenever possible.\nIn fact, sometimes it can be helpful to start domain modeling by defining \nthe core of your Ubiquitous Language by defining the primary incoming Com-\nmands and outgoing Events, as well as the behaviors that are performed. Only \nat a later stage would we actually group some concepts as Aggregates, based \non similarity, relevance, and business rules. Such an approach\u2014even if it is \njust a temporary development spike used as a part of a domain modeling exer-\ncise\u2014can lead to a deeper understanding of our core business concepts.\nRead Model Projections\nOne of the common concerns of the A+ES design approach is how to query \nthe Aggregates by their properties. Event Sourcing does not provide a simple \nway to answer a question such as \u201cWhat is the total amount of all customer \norders within the last month?\u201d We would actually need to load every Cus-\ntomer instance, enumerate all of the Order instances within the last month \nfor each one, and calculate their total, which would be extremely inefficient.\nThis is where Read Model Projections can help. Read Model Projections \ncan be realized through a simple set of Domain Event subscribers that are used \nto generate and update a persistent Read Model. In other words, they pro-\nject Events to a persistent Read Model. When Event subscribers receive new \nwww.EBooksWorld.ir\n", "page": 613, "type": "text", "section": "Page 613"}
{"text": " \nREAD MODEL PROJECTIONS\n571\nEvents, they calculate some query results and store them in the Read Model for \nlater consumption.\nIn a nutshell, a Projection is very similar to an Aggregate instance. As \nEvents are received and handled, we use the data from them to build the Pro-\njection\u2019s state. Read Model Projections are persisted after each update and can \nbe accessed by many readers, both inside and outside the Bounded Context.\nProjection Samples Are Available\nMore information about using Projections, including source code for various per-\nsistence scenarios and automatic rebuilding of Read Models, is available in the sam-\nple project: http://lokad.github.com/lokad-cqrs/.\nThis is how we could define a Projection to capture all transactions for each \nCustomer:\npublic class CustomerTransactionsProjection\n{\n  IDocumentWriter<CustomerId, CustomerTransactions> _store;\n  public CustomerTransactionsProjection(\n    IDocumentWriter<CustomerId, CustomerTransactions> store)\n  {\n    _store = store;\n  }\n  public void When(CustomerCreated e)\n  {\n    _store.Add(e.Id, new CustomerTransactions());\n  }\n  public void When(CustomerChargeAdded e)\n  {\n    _store.UpdateOrThrow(e.Id,\n      v => v.AddTx(e.ChargeName, -e.Charge, e.NewBalance, e.TimeUtc));\n  }\n  public void When(CustomerPaymentAdded e)\n  {\n    _store.UpdateOrThrow(e.Id,\n      v => v.AddTx(e.PaymentName, e.Payment, e.NewBalance, e.TimeUtc));\n  }\n}\nThis Projection class is similar to an Application Service designed for A+ES \nthat uses lambdas. However, our Projection reacts to Events rather than Com-\nmands and updates documents using IDocumentWriter, rather than updat-\ning Aggregate instances.\nwww.EBooksWorld.ir\n", "page": 614, "type": "text", "section": "Page 614"}
{"text": "Appendix A AGGREGATES AND EVENT SOURCING: A+ES\n572\nThe underlying Read Model is actually just a simple Data Transfer Object\n(DTO) [Fowler] that can be serialized and persisted to some underlying storage \nby means of an IDocumentWriter:\n[Serializable]\npublic class CustomerTransactions\n{\n  public IList<CustomerTransaction> Transactions =\n    new List<CustomerTransaction>();\n  public void AddTx(\n    string name, CurrencyAmount change,\n    CurrencyAmount balance, DateTime timeUtc)\n  {\n    Transactions.Add(new CustomerTransaction()\n    {\n        Name = name,\n        Balance = balance,\n        Change = change,\n        TimeUtc = timeUtc\n    });\n  }\n}\n[Serializable]\npublic class CustomerTransaction\n{\n  public CurrencyAmount Change;\n  public CurrencyAmount Balance;\n  public string Name;\n  public DateTime TimeUtc;\n}\nIt is common practice to persist Read Models in a document database, \nalthough other options can be used. We may cache Read Models in memory \n(for example, memcached instance), push them as documents into a content- \ndelivery network, or persist them in relational database tables.\nIn addition to scalability, one of the major advantages of Projections is that \nthey are completely disposable. They can be added, modified, or completely \nreplaced at any time during the application\u2019s lifetime. To replace the whole \nRead Model, discard all existing Read Model data and generate new data by \nrunning your entire Event Stream through your Projection classes. This pro-\ncess can be automated. It\u2019s even possible to prevent any downtime while effect-\ning full Read Model replacement.\nwww.EBooksWorld.ir\n", "page": 615, "type": "text", "section": "Page 615"}
{"text": " \nEVENTS ENRICHMENT\n573\nUse with Aggregate Design\nSuch Read Model Projections are frequently used to expose information to \nvarious clients (such as desktop and Web user interfaces), but they are also \nquite useful for sharing information between Bounded Contexts and their \nAggregates. Consider the scenario where an Invoice Aggregate needs some \nCustomer information (for example, name, billing address, and tax ID) in \norder to calculate and prepare a proper Invoice. We can capture this infor-\nmation in an easy-to-consume form via CustomerBillingProjection,\nwhich will create and maintain an exclusive instance of CustomerBilling-\nView. This Read Model is available to the Invoice Aggregate through the \nDomain Service named IProvideCustomerBillingInformation. Under \nthe covers this Domain Service just queries the document store for the appro-\npriate instance of the CustomerBillingView.\nProjections also enable us to share information between Aggregate instances \nin a loosely coupled and more maintainable way. If at any point in time we \nneed to change information returned by IProvideCustomerBillingView,\nwe can do so without modifying the Customer Aggregate. We only need to \nchange the Projection implementation and rebuild the Read Models by replay-\ning all Events.\nEvents Enrichment\nOne of the more common problems with A+ES designs comes from their dual \npurpose. Events are used both for Aggregate persistence and to communicate \ndomain-level happenings around the enterprise by means of Event publishing.\nFor example, consider the following: A project management system allows \ncustomers to create new projects and archive completed projects. Imagine that \nwe publish a ProjectArchived Event each time a user archives a project. \nThis Domain Event could have this design:\npublic class ProjectArchived {\n  public ProjectId Id { get; set; }\n  public UserId ChangeAuthorId { get; set; }\n  public DateTime ArchivedUtc { get; set; }\n  public string OptionalComment { get; set; }\n}\nwww.EBooksWorld.ir\n", "page": 616, "type": "text", "section": "Page 616"}
{"text": "Appendix A AGGREGATES AND EVENT SOURCING: A+ES\n574\nThis information is rich enough to be used to reconstitute an archived  \nProject\nusing A+ES. However, designed in this way, our Event could be rather prob-\nlematic for publishers to consume.\nWhy? Consider the Projection for the ArchivedProjectsPerCustomer\nview, as illustrated in Figure A.16. It subscribes to Events and maintains a list \nof archived projects per customer. In order to get the job done, this Projection \nwill need the latest information about things like\n\u2022 Project names\n\u2022 Names of customers\n\u2022 Assignments of projects to customers\n\u2022 Project archival Events\nWe can simplify this Projection significantly by enriching our Project-\nArchived Event with additional data members to push relevant information. \nThe additional data members would not be essential for reconstituting the \nstate of the corresponding Aggregate but would noticeably simplify our Event \nconsumers. Consider this alternative Event contract:\npublic class ProjectArchived {\n  public ProjectId Id { get; set; }\n  public string ProjectName { get; set; }\n  public UserId ChangeAuthorId { get; set; }\n  public DateTime ArchivedUtc { get; set; }\nProjection (Processing)\nPublished to . . .\nCreates/Updates\nProject\nUnassigned\nProject\nAssigned\nProject\nArchived\nProject\nRenamed\nProject\nCreated\nArchivedProjectsPerCustomerView\nFigure A.16 Multiple Domain Events are consumed by a Projection and used to \nbuild up a view of a Read Model.\nwww.EBooksWorld.ir\n", "page": 617, "type": "text", "section": "Page 617"}
{"text": " \nEVENTS ENRICHMENT\n575\n  public string OptionalComment { get; set; }\n  public CustomerId Customer { get; set; }\n  public string CustomerName { get; set; }\n}\nGiven this newly enriched Event, our ArchivedProjectsPerCustomer-\nView generated by the Projection can be simplified as seen in Figure A.17.\nA Domain Event rule of thumb says to design them with enough informa-\ntion to satisfy 80 percent of subscribers, even though doing so would require \nEvents to have more information than needed by a good number of subscrib-\ners. Remembering that we want to ensure that view Projection processors have \na rich set of Event data, we usually include\n\u2022 Entity identifiers, which are the Event owners/masters, such as  \nCustomerId\nis to Customer\n\u2022 Names and other properties that are generally used for display purposes, \nsuch as ProjectName, CustomerName, and the like\nThese are recommendations, not rules. They usually work well for enter-\nprises that have a lot of different Bounded Contexts. Monolithic Bounded \nContexts benefit less from these suggestions, since they tend to maintain sec-\nondary lookup tables and Entity maps. Of course, you are in the best position \nto know which properties should be included in your Events. Sometimes it\u2019s \nobvious just which properties belong in a given Event type, and for those refac-\ntoring is seldom required.\nProjection (Processing)\nPublished to . . .\nCreates/Updates\nProject\nArchived\nArchivedProjectsPerCustomerView\nFigure A.17 Domain Events such as ProjectArchived can be consumed by \nProjection processors that generate view- and report-specific Read Models.\nwww.EBooksWorld.ir\n", "page": 618, "type": "text", "section": "Page 618"}
{"text": "Appendix A AGGREGATES AND EVENT SOURCING: A+ES\n576\nSupporting Tools and Patterns\nDeveloping, building, deploying, and maintaining systems using A+ES require \na set of patterns that can differ somewhat from those of traditional systems. \nThis section presents some patterns, tools, and practices that have proven quite \nuseful when using A+ES.\nEvent Serializers\nIt\u2019s wise to choose a serializer that favors versioning and renaming Events. This \nis especially true early on in an A+ES project as the domain model tends to \nevolve rapidly. Consider this Event, which is declared using a .NET implemen-\ntation of Protocol Buffers1 annotations:\n[DataContract]\npublic class ProjectClosed {\n  [DataMember(Order=1)] public long ProjectId { get; set; }\n  [DataMember(Order=2)] public DateTime Closed { get; set; }\n}\nNow, if we were to serialize ProjectClosed using DataContract-\nSerializer or JsonSerializer rather than Protocol Buffers, any renamed \nmembers could easily break dependent consumers. For example, assume you \nrename the Closed property ClosedUtc. Unless you take special care to map \nthe renamed property in a consuming Bounded Context, you\u2019d produce a con-\nfusing error or produce buggy data: \n[DataContract]\npublic class ProjectClosed {\n  [DataMember] public long ProjectId { get; set; }\n  [DataMember(Name=\"Closed\"] public DateTime ClosedUtc { get; set; }\n}\nProtocol Buffers accommodates evolving serialization situations because it \ntracks contract members by integral tags, not names. As can be seen in the \nfollowing code, clients may successfully use either Close or CloseUtc as \nthe property name. It serializes objects extremely quickly and produces a very \ncompact binary representation. Using Protocol Buffers, we can rename Event \nproperties without worrying about backward compatibility, reducing develop-\nment friction in an evolving domain model.\n 1. Protocol Buffers was originated by Google. Others have created .NET implementations.\nwww.EBooksWorld.ir\n", "page": 619, "type": "text", "section": "Page 619"}
{"text": " \nSUPPORTING TOOLS AND PATTERNS\n577\n[DataContract]\npublic class ProjectClosed {\n  [DataMember(Order=1)] public long ProjectId { get; set; }\n  [DataMember(Order=2)] public DateTime ClosedUtc { get; set; }\n}\nSome additional cross-platform serialization tools include Apache Thrift, \nAvro, and MessagePack, giving a variety of worthy options.\nEvent Immutability\nEvent Streams are considered to be immutable by nature. In order to keep the \ndevelopment model consistent with this concept (and avoid undesirable side \neffects), Event contracts should be implemented as immutable. To do that with \nC# on .NET, we mark fields as read-only and set values only via the construc-\ntor. Given the previous ProjectClosed Event, we can make it an immutable \nimplementation:\n[DataContract]\npublic class ProjectClosed {\n  [DataMember(Order=1)] public long ProjectId { get; private set }\n  [DataMember(Order=2)] public DateTime ClosedUtc { get; private set; }\n  public ProjectClosed(long projectId, DateTime closedUtc) \n  {\n    ProjectId  = projectId;\n    ClosedUtc = closedUtc;\n  }\n}\nValue Objects\nAs discussed thoroughly in Value Objects (6), this is a pattern that can \ngreatly simplify development and the evolution of rich domain models. Using \nValue Objects, we compose cohesive primitive types into an explicitly named \nimmutable type. For instance, instead of declaring the identity of a project as a \nlong, we would model an explicit ProjectId:\npublic struct ProjectId\n{\n  public readonly long Id { get; private set; }\n  public ProjectId(long id)\n  {\n    Id = id\n  }\nwww.EBooksWorld.ir\n", "page": 620, "type": "text", "section": "Page 620"}
{"text": "Appendix A AGGREGATES AND EVENT SOURCING: A+ES\n578\n  public override ToString() {\n    return string.Format(\"Project-{0}\", Id);\n  }\n}\nWe still use a long type to hold the actual identity number, but we use the \nProjectId type to distinguish it from all others. Value types are certainly \nnot limited to unique identities. Other appropriate Value types include money \nobjects (especially in multicurrency systems), addresses, e-mails, measure-\nments, and so on. \nIn addition to enrichment and expressiveness of Event and Command con-\ntracts, domain Value Objects bring more practical benefits to A+ES imple-\nmentations, like static type checking and IDE support. Consider the following \nscenario, where a developer can accidentally misplace parameters of a simple \nEvent constructor by passing them in the wrong order:\nlong customerId = ...;\nlong projectId = ...;\nvar event = new ProjectAssignedToCustomer(customerId, projectId);\nThis is an error that would not be caught by the compiler but might be \nfound only through much debugging and frustration. However, if you use \nValue Objects as identifiers, the compiler (and thus the IDE editor) would catch \nthe error in passing the CustomerId first and the ProjectId second:\nCustomerId customerId = ...;\nProjectId projectId = ...;\nvar event = new ProjectAssignedToCustomer(customerId, projectId);\nBenefits become even more apparent when you have flat contract classes \nwith a large number of fields. For instance, consider this Event (simplified from \nthe actual production version):\npublic class CustomerInvoiceWritten {\n  public InvoiceId Id { get; private set; }\n  public DateTime CreatedUtc { get; private set; }\n  public CurrencyType Currency { get; private set; }\n  public InvoiceLine[] Lines { get; private set; }\n  public decimal SubTotal { get; private set; }\n  public CustomerId Customer { get; private set; }\n  public string CustomerName { get; private set; }\n  public string CustomerBillingAddress { get; private set; }\nwww.EBooksWorld.ir\n", "page": 621, "type": "text", "section": "Page 621"}
{"text": " \nSUPPORTING TOOLS AND PATTERNS\n579\n  public float OptionalVatRatio { get; private set; }\n  public string OptionalVatName { get; private set; }\n  public decimal VatTax { get; private set; }\n  public decimal Total { get; private set; }\n}\nAs you can imagine, dealing with a class having so many properties2 can \nbe a bit complicated. We can refactor this large Event to be more explicit and \nreadable by refining its model according to existing domain concepts:\npublic class CustomerInvoiceWritten {\n  public InvoiceId Id { get; private set; }\n  public InvoiceHeader Header { get; private set; }\n  public InvoiceLine[] Lines { get; private set; }\n  public InvoiceFooter Footer { get; private set; }\n}\nThe InvoiceHeader and InvoiceFooter constitute cohesive properties:\npublic class InvoiceHeader {\n  public DateTime CreatedUtc { get; private set; }\n  public CustomerId Customer { get; private set; }\n  public string CustomerName { get; private set; }\n  public string CustomerBillingAddress { get; private set; }\n}\npublic class InvoiceFooter {\n  public CurrencyAmount SubTotal { get; private set; }\n  public VatInformation OptionalVat { get; private set; }\n  public CurrencyAmount VarAmount { get; private set; }\n  public CurrencyAmount Total { get; private set; }\n}\nWe replaced the separate CurrencyType Currency and decimal Sub-\nTotal properties with a CurrencyAmount Value Object. An added benefit \nis that this class could be enhanced with sanity check logic that prevents oper-\nations between amounts expressed in different currencies and other inappro-\npriate operations. The same goes for joining VAT information into a separate \nValue Object that is then composed on the InvoiceFooter, along with the \nother invoice totals.\nWherever possible we should strive to employ Value Objects, whether for \nCommand objects, Events, or Aggregate parts.\n 2. Empirical data proves an appropriate rule of thumb: There should be no more \nthan five to seven property members per class.\nwww.EBooksWorld.ir\n", "page": 622, "type": "text", "section": "Page 622"}
{"text": "Appendix A AGGREGATES AND EVENT SOURCING: A+ES\n580\nObviously, using Value Objects in Commands and/or Events would require \ndeploying them together, or even creating a Shared Kernel (3). However, some \ndeeply complex domains might require designing some Value Objects with \nextremely involved business logic. In such cases, placing such Value Objects \nin a Shared Kernel merely for type-safe deserialization would likely result in a \nbrittle design. It could help to distinguish between simple shared classes used \nto deserialize Command and Event data in a type-safe way from the more com-\nplex ones required by the Core Domain (2). That would mean creating two sets \nof Value Object classes, those used exclusively by the Core Domain and those \nthat are deployed with Command and Event classes. The data held by the two \nis converted from one to the other as needed.\nDepending on your taste, duplicating classes may seem more complex than \nnecessary, leading you down the path of creating accidental complexity in \nyour systems. If that\u2019s your opinion, it may be worth considering a different \napproach. One alternative is to standardize serialized Events as a Published \nLanguage (3). As explained in Integrating Bounded Contexts (13), you may \nchoose to consume Event notifications using a dynamic typing approach. \nDoing so would eliminate the need for Event and Value Object types being \ndeployed to the consuming subscribers. As with all approaches, this one has \ntrade-offs that must be weighed.\nContract Generation\nMaintaining hundreds of Event (and Command) contracts manually is both \ntedious and error prone. It\u2019s usually more efficient to express their definitions \nin some compact domain-specific language (DSL) that can be used for simple \ncode generation, by building correct classes at build time. There are several \nways to formulate a DSL syntax, and we might consider the Protocol Buffer \n.proto format or a similar one to be the way to go. For example, you may \nfind this approach useful:\nCustomerInvoiceWritten!(InvoiceId Id, InvoiceHeader header,\n   InvoiceLine[] lines, InvoiceFooter footer)\nA simple code generator can use the parsed DSL to generate code for each \nsource line. Note one example here, where the CustomerInvoiceWritten is \ngenerated from the preceding DSL:\nwww.EBooksWorld.ir\n", "page": 623, "type": "text", "section": "Page 623"}
{"text": " \nCONTRACT GENERATION\n581\n[DataContract]\npublic sealed class CustomerInvoiceWritten : IDomainEvent {\n  [DataMember(Order=1) public InvoiceId Id\n    { get; private set; }\n  [DataMember(Order=2) public InvoiceHeader Header\n    { get; private set; }\n  [DataMember(Order=3) public InvoiceLine[] Lines\n    { get; private set; }\n  [DataMember(Order=4) public InvoiceFooter Footer\n    { get; private set; }\n  public CustomerInvoiceWriter(\n    InvoiceId id, InvoiceHeader header, InvoiceLine[] lines,\n    InvoiceFooter footer)\n  {\n    Id = id;\n    Header = header;\n    Lines = lines;\n    Footer = footer;\n  }\n  // required by serializer\n  ProjectClosed() {\n    Lines = new InvoiceLine[0];\n  }\n}\nThis has the following practical benefits:\n\u2022 It reduces development friction by enabling faster domain modeling \niterations.\n\u2022 It reduces the probability of human errors common with manual labor.\n\u2022 The compact representation allows us to keep all Event definitions on a \nsingle screen, providing a big-picture view for improved insight. This can \neven serve as a terse glossary to the Ubiquitous Language.\n\u2022 We can version and distribute Event contracts as compact definitions \ninstead of requiring source or binary code. This might even serve to \nenhance collaboration between various teams.\nThe same can be applied to Command contracts as well. The open source \nimplementation of a DSL-based code generation tool along with examples is \navailable within the sample project.\nwww.EBooksWorld.ir\n", "page": 624, "type": "text", "section": "Page 624"}
{"text": "Appendix A AGGREGATES AND EVENT SOURCING: A+ES\n582\nUnit Testing and Specifications\nConsider an added benefit of using Event Sourcing as we create unit tests. We \ncan easily specify our tests in the form Given-When-Expect, as follows:\n 1. Given Events in the past\n 2. When Aggregate method is called\n 3. Expect the following Events or an exception\nHere\u2019s how it works. Past Events are used to set up the state of an Aggre-\ngate at the beginning of the unit test. We then execute the Aggregate method \nbeing tested, supplying test arguments and mock implementations of Domain \nServices as needed. Finally, we assert the expected results by comparing Events \nproduced by an Aggregate with expected Events. \nThis approach allows us to capture and verify behaviors associated with \neach Aggregate. At the same time, we stay decoupled from the internals of the \nAggregate state. This helps to reduce test fragility because development teams \ncan change and optimize each Aggregate implementation in any way, as long \nas the behavioral contracts are fulfilled as confirmed by the unit tests.\nIt is possible to take this approach one step further by expressing the When\nclause directly using a Command, which is passed to the appropriate Appli-\ncation Service hosting the Aggregate under test. This allows us to express the \nunit test as a specification expressed completely in the terms of our Ubiquitous \nLanguage, either through code or by creating a DSL. \nWith just a little bit of code, such specifications can be automatically printed \nout as human-readable use cases that domain experts can comprehend. These \nuse case definitions can help project teams communicate better over domains \nwith complex behaviors, which enhances their modeling efforts.\nHere\u2019s a simple specification defined by a text document:\n[Passed] Use case 'Add Customer Payment - Unlock On Payment'.\nGiven:\n 1. Created customer 7 Eur 'Northwind' with key c67b30 ...\n 2. Customer locked\nWhen:\n  Add 'unlock' payment 10 EUR via unlock\nExpectations:\n  [ok] Tx 1: payment 10 EUR 'unlock' (none)\n  [ok] Customer unlocked\nwww.EBooksWorld.ir\n", "page": 625, "type": "text", "section": "Page 625"}
{"text": " \nEVENT SOURCING IN FUNCTIONAL LANGUAGES\n583\nIf this approach interests you, performing a Web search for \u201cEvent Sourcing \nSpecifications\u201d will result in detailed guidance.\nEvent Sourcing in Functional Languages\nThe implementation patterns outlined previously focused on an object-oriented \napproach, which is a good fit for programming languages such as Java and C#. \nHowever, Event Sourcing is inherently functional in nature. Thus, it can be \nsuccessfully implemented with functional languages such as F# and Clojure. \nDoing so could potentially lead to more concise code that performs optimally.\nHere are some peculiarities of switching from an object-oriented to a func-\ntional approach for Aggregate implementations:\n\u2022 We must switch from using a mutable object-oriented Aggregate state object \nto designing a simple immutable state record with a collection of mutat-\ning functions. The mutating functions simply take a state record and Event \narguments, returning a new state record as the result. This is quite like the \ndesign of an immutable Value Object, where its Side-Effect-Free Functions \nonly produce new Values based on its own state and function arguments. \nSuch functions take the form Func<State, Event, State>.\n\u2022 The current Aggregate state can be defined as a left fold of all past Events \nthat are passed to the mutating functions.\n\u2022 Aggregate methods can also be transformed into a collection of state-\nless functions, which take Command parameters, Domain Services, and \na state. Such functions return zero or more Events and take the form \nFunc<TArg1, TArg2.\n.\n.\n, State, Event[]>.\n\u2022 An Event Store can be perceived and communicated as a functional data-\nbase, because it persists the arguments to functions that mutate Aggregate \nstate. Supporting snapshots in a functional Event Store is familiar to func-\ntional programmers under the name memoization.\nA development spike that captures core business concepts by means of A+ES \nin a functional programming language can accelerate our domain modeling \nefforts. What is more, it forces us to shift our domain exploration focus away \nfrom Aggregate structure toward a strict reflection of our domain\u2019s Ubiq-\nuitous Language expressed by its behaviors. Anything that can help us give \nmore emphasis to the Core Domain and less to technology will likely drive \nout more value for the business and help it achieve an even greater competitive \nadvantage.\nwww.EBooksWorld.ir\n", "page": 626, "type": "text", "section": "Page 626"}
{"text": "This page intentionally left blank \nwww.EBooksWorld.ir\n", "page": 627, "type": "text", "section": "Page 627"}
{"text": "585\nBibliography\n[Appleton, LoD] Appleton, Brad. n.d. \u201cIntroducing Demeter and Its Laws.\u201d \nwww.bradapp.com/docs/demeter-intro.html.\n[Bentley] Bentley, Jon. 2000. Programming Pearls, Second Edition. Boston, \nMA: Addison-Wesley. \nhttp://cs.bell-labs.com/cm/cs/pearls/bote.html.\n[Brandolini] Brandolini, Alberto. 2009. \u201cStrategic Domain-Driven Design \nwith Context Mapping.\u201d \nwww.infoq.com/articles/ddd-contextmapping.\n[Buschmann et al.] Buschmann, Frank, et al. 1996. Pattern-Oriented Soft-\nware Architecture, Volume 1: A System of Patterns. New York: Wiley.\n[Cockburn] Cockburn, Alastair. 2012. \u201cHexagonal Architecture.\u201d \nhttp://alistair.cockburn.us/Hexagonal+architecture.\n[Crupi et al.] Crupi, John, et al. n.d. \u201cCore J2EE Patterns.\u201d \nhttp://corej2eepatterns.com/Patterns2ndEd/DataAccessObject.htm.\n[Cunningham, Checks] Cunningham, Ward. 1994. \u201cThe CHECKS Pattern \nLanguage of Information Integrity.\u201d \nhttp://c2.com/ppr/checks.html.\n[Cunningham, Whole Value] Cunningham, Ward. 1994. \u201c1. Whole Value.\u201d \nhttp://c2.com/ppr/checks.html#1.\n[Cunningham, Whole Value aka Value Object] Cunningham, Ward. 2005. \n\u201cWhole Value.\u201d \nhttp://fit.c2.com/wiki.cgi?WholeValue.\n[Dahan, CQRS] Dahan, Udi. 2009. \u201cClarified CQRS.\u201d \nwww.udidahan.com/2009/12/09/clarified-cqrs/.\n[Dahan, Roles] Dahan, Udi. 2009. \u201cMaking Roles Explicit.\u201d \nwww.infoq.com/presentations/Making-Roles-Explicit-Udi-Dahan. \n[Deutsch] Deutsch, Peter. 2012. \u201cFallacies of Distributed Computing.\u201d  \nhttp://en.wikipedia.org/wiki/Fallacies_of_Distributed_Computing.\n[Dolphin] Object Arts. 2000. \u201cDolphin Smalltalk; Twisting the Triad.\u201d \nwww.object-arts.com/downloads/papers/TwistingTheTriad.PDF.\n[Erl] Erl, Thomas. 2012. \u201cSOA Principles: An Introduction to the Service- \nOriented Paradigm.\u201d \nhttp://serviceorientation.com/index.php/serviceorientation/index.\nwww.EBooksWorld.ir\n", "page": 628, "type": "text", "section": "Page 628"}
{"text": "BIBLIOGRAPHY\n586\n[Evans] Evans, Eric. 2004. Domain-Driven Design: Tackling the Complexity \nin the Heart of Software. Boston, MA: Addison-Wesley.\n[Evans, Ref] Evans, Eric. 2012. \u201cDomain-Driven Design Reference.\u201d \nhttp://domainlanguage.com/ddd/patterns/DDD_Reference_2011-01-31.pdf.\n[Evans & Fowler, Spec] Evans, Eric, and Martin Fowler. 2012. \u201cSpecifications.\u201d \nhttp://martinfowler.com/apsupp/spec.pdf.\n[Fairbanks] Fairbanks, George. 2011. Just Enough Software Architecture.\nMarshall & Brainerd.\n[Fowler, Anemic] Fowler, Martin. 2003. \u201cAnemicDomainModel.\u201d \nhttp://martinfowler.com/bliki/AnemicDomainModel.html.\n[Fowler, CQS] Fowler, Martin. 2005. \u201cCommandQuerySeparation.\u201d \nhttp://martinfowler.com/bliki/CommandQuerySeparation.html.\n[Fowler, DI] Fowler, Martin. 2004. \u201cInversion of Control Containers and the \nDependency Injection Pattern.\u201d \nhttp://martinfowler.com/articles/injection.html.\n[Fowler, P of EAA] Fowler, Martin. 2003. Patterns of Enterprise Application \nArchitecture. Boston, MA: Addison-Wesley.\n[Fowler, PM] Fowler, Martin. 2004. \u201cPresentation Model.\u201d \nhttp://martinfowler.com/eaaDev/PresentationModel.html.\n[Fowler, Self Encap] Fowler, Martin. 2012. \u201cSelfEncapsulation.\u201d \nhttp://martinfowler.com/bliki/SelfEncapsulation.html.\n[Fowler, SOA] Fowler, Martin. 2005. \u201cServiceOrientedAmbiguity.\u201d \nhttp://martinfowler.com/bliki/ServiceOrientedAmbiguity.html.\n[Freeman et al.] Freeman, Eric, Elisabeth Robson, Bert Bates, and Kathy \nSierra. 2004. Head First Design Patterns. Sebastopol, CA: O\u2019Reilly Media.\n[Gamma et al.] Gamma, Erich, Richard Helm, Ralph Johnson, and John \nVlissides. 1994. Design Patterns. Reading, MA: Addison-Wesley.\n[Garcia-Molina & Salem] Garcia-Molina, Hector, and Kenneth Salem. 1987. \n\u201cSagas.\u201d ACM, Department of Computer Science, Princeton University, \nPrince \nton, NJ. \nwww.amundsen.com/downloads/sagas.pdf.\n[GemFire Functions] 2012. VMware vFabric 5 Documentation Center. \nhttp://pubs.vmware.com/vfabric5/index.jsp?topic=/com.vmware.vfabric\n.gemfire.6.6/developing/function_exec/chapter_overview.html.\n[Gson] 2012. A Java JSON library hosted on Google Code. \nhttp://code.google.com/p/google-gson/.\nwww.EBooksWorld.ir\n", "page": 629, "type": "text", "section": "Page 629"}
{"text": " \nBIBLIOGRAPHY\n587\n[Helland] Helland, Pat. 2007. \u201cLife beyond Distributed Transactions: An \nApostate\u2019s Opinion.\u201d Third Biennial Conference on Innovative DataSystems \nResearch (CIDR), January 7\u201310, Asilomar, CA. \nwww.ics.uci.edu/~cs223/papers/cidr07p15.pdf.\n[Hohpe & Woolf] Hohpe, Gregor, and Bobby Woolf. 2004. Enterprise Inte-\ngration Patterns: Designing, Building, and Deploying Messaging Systems.\nBoston, MA: Addison-Wesley.\n[Inductive UI] 2001. Microsoft Inductive User Interface Guidelines. \nhttp://msdn.microsoft.com/en-us/library/ms997506.aspx.\n[Jezequel et al.] Jezequel, Jean-Marc, Michael Train, and Christine Mingins. \n2000. Design Patterns and Contract. Reading, MA: Addison-Wesley.\n[Keith & Stafford] Keith, Michael, and Randy Stafford. 2008. \u201cExposing the \nORM Cache.\u201d ACM, May 1. \nhttp://queue.acm.org/detail.cfm?id=1394141.\n[Liskov] Liskov, Barbara. 1987. Conference Keynote: \u201cData Abstraction and \nHierarchy.\u201d http://en.wikipedia.org/wiki/Liskov_substitution_principle. \u201cThe \nLiskov Substitution Principle.\u201d \nwww.objectmentor.com/resources/articles/lsp.pdf. \n[Martin, DIP] Martin, Robert. 1996. \u201cThe Dependency Inversion Principle.\u201d \nwww.objectmentor.com/resources/articles/dip.pdf.\n[Martin, SRP] Martin, Robert. 2012. \u201cSRP: The Single Responsibility Principle.\u201d \nwww.objectmentor.com/resources/articles/srp.pdf.\n[MassTransit] Patterson, Chris. 2008. \u201cManaging Long-Lived Transactions \nwith MassTransit.Saga.\u201d \nhttp://lostechies.com/chrispatterson/2008/08/29/managing-long-lived-\ntransactions-with-masstransit-saga/.\n[MSDN Assemblies] 2012. \nhttp://msdn.microsoft.com/en-us/library/51ket42z%28v=vs.71%29.aspx.\n[Nilsson] Nilsson, Jimmy. 2006. Applying Domain-Driven Design and Pat-\nterns: With Examples in C# and .NET. Boston, MA: Addison-Wesley.\n[Nijof, CQRS] Nijof, Mark. 2009. \u201cCQRS \u00e0 la Greg Young.\u201d \nhttp://cre8ivethought.com/blog/2009/11/12/cqrs--la-greg-young.\n[NServiceBus] 2012. \nwww.nservicebus.com/.\n[\u00d6berg] \u00d6berg, Rickard. 2012. \u201cWhat Is Qi4j\u2122?\u201d \nhttp://qi4j.org/.\nwww.EBooksWorld.ir\n", "page": 630, "type": "text", "section": "Page 630"}
{"text": "BIBLIOGRAPHY\n588\n[Parastatidis et al., RiP] Webber, Jim, Savas Parastatidis, and Ian Robinson. \n2011. REST in Practice. Sebastopol, CA: O\u2019Reilly Media.\n[PragProg, TDA] The Pragmatic Programmer. \u201cTell, Don\u2019t Ask.\u201d \nhttp://pragprog.com/articles/tell-dont-ask.\n[Quartz] 2012. Terracotta Quartz Scheduler. \nhttp://terracotta.org/products/quartz-scheduler.\n[Seovi\u00fe] Seovi\u00fe, Aleksandar, Mark Falco, and Patrick Peralta. 2010. Ora-\ncle Coherence 3.5: Creating Internet-Scale Applications Using Oracle\u2019s \nHigh-Performance Data Grid. Birmingham, England: Packt Publishing.\n[SOA Manifesto] 2009. SOA Manifesto. \nwww.soa-manifesto.org/.\n[Sutherland] Sutherland, Jeff. 2010. \u201cStory Points: Why Are They Better than \nHours?\u201d \nhttp://scrum.jeffsutherland.com/2010/04/story-points-why-are-they-better-\nthan.html.\n[Tilkov, Manifesto] Tilkov, Stefan. 2009. \u201cComments on the SOA Manifesto.\u201d \nwww.innoq.com/blog/st/2009/10/comments_on_the_soa_manifesto.html.\n[Tilkov, RESTful Doubts] Tilkov, Stefan. 2012. \u201cAddressing Doubts about REST.\u201d \nwww.infoq.com/articles/tilkov-rest-doubts.\n[Vernon, DDR] Vernon, Vaughn. n.d. \u201cArchitecture and Domain-Driven Design.\u201d \nhttp://vaughnvernon.co/?page_id=38.\n[Vernon, DPO] Vernon, Vaughn. n.d. \u201cArchitecture and Domain-Driven Design.\u201d \nhttp://vaughnvernon.co/?page_id=40.\n[Vernon, RESTful DDD] Vernon, Vaughn. 2010. \u201cRESTful SOA or Domain-\nDriven Design\u2014A Compromise?\u201d QCon SF 2010. \nwww.infoq.com/presentations/RESTful-SOA-DDD.\n[Webber, REST & DDD] Webber, Jim. \u201cREST and DDD.\u201d \nhttp://skillsmatter.com/podcast/design-architecture/rest-and-ddd.\n[Wiegers] Wiegers, Karl E. 2012. \u201cFirst Things First: Prioritizing Require-\nments.\u201d \nwww.processimpact.com/articles/prioritizing.html.\n[Wikipedia, CQS] 2012. \u201cCommand-Query Separation.\u201d \nhttp://en.wikipedia.org/wiki/Command-query_separation.\n[Wikipedia, EDA] 2012. \u201cEvent-Driven Architecture.\u201d \nhttp://en.wikipedia.org/wiki/Event-driven_architecture.\n[Young, ES] Young, Greg. 2010. \u201cWhy Use Event Sourcing?\u201d  \nhttp://codebetter.com/gregyoung/2010/02/20/why-use-event-sourcing/.\nwww.EBooksWorld.ir\n", "page": 631, "type": "text", "section": "Page 631"}
{"text": "589\nIndex\nA\nAbstract classes, in modules, 338\nAbstract Factory pattern, 389\nAbstraction, Dependency Inversion Principle \nand, 123\nAccess management, identity and, 91\u201392\nACID databases, 521\nACL. See Anticorruption Layer (ACL)\nActive Record, in Transaction Scripts, 441\nActiveMQ, as messaging middleware, 303\nActor Model, 295\nAdapters. See also Hexagonal Architecture\nDomain Services use for integration, 280\nhandling client output types, 529\u2013530\nHexagonal Architecture and, 126\u2013127\nPresentation Model as, 519\nfor REST client implementation, 465\u2013466\nAggregate Root query interface, 516\nAggregate Stores\ndistributed caches of Data Fabrics as, 164\npersistence-oriented repositories and, 418\nAggregate-Oriented Databases, 418\nAggregates. See also A+ES (Aggregates and \nEvent Sourcing)\nApplication Services and, 120\u2013121\navoiding dependency Injection, 387\nbehavioral focus of, 569\u2013570\nContext Maps and, 90\ncost estimates of memory overhead, \n372\u2013373\ncreating and publishing Events, 287\ndecision process in designing, 379\u2013380\ndesigning, 573\ndesigning based on usage scenarios, \n375\u2013376\nDomain Events with Aggregate \ncharacteristics, 294\u2013295\nEvent Sourcing and, 160\u2013162, 539\neventual consistency, 364\u2013367, 376\u2013378\nexecutives and trackers merged in, 156\nfactories on Aggregate Root, 391\u2013392\nglobal transactions as reason to break \ndesign rules, 369\nimplementing, 380\ninformation hiding (Law of Demeter and \nTell, Don\u2019t Ask), 382\u2013384\ninvariant determination in creating \nclusters, 353\u2013355\nlack of technical mechanisms as reason to \nbreak design rules, 368\u2013369\nlocal identity of Entities and, 177\nmediators publishing internal state of, \n514\u2013515\nmemory consumption and, 374\u2013375\nmodel navigation and, 362\u2013363\nmotivations for Factory use, 389\nas object collections, 203\noptimistic concurrency, 385\u2013387\norganizing into large clusters, 349\u2013351\norganizing into smaller units, 351\u2013353\noverview of, 347\u2013348\nplacing in repository, 401\nquery performance as reason to break \ndesign rules, 369\u2013370\nquerying repositories and, 138\nreferences between, 359\u2013362\nremoving from repository, 409\nrendering Data Transfer Objects, 513\u2013514\nrendering Domain Payload Objects, \n515\u2013516\nrendering properties of multiple instances, \n512\u2013513\nrethinking design, 370\u2013372\nreview, 388\nRoot Entity and, 380\u2013382\nscalability and distribution of, 363\u2013364\nin Scrum Core Domain, 348\u2013349\nsingle-aggregate-instance-in-single-\ntransaction rule of thumb, 302\nsize of Bounded Contexts and, 68\nsmall Aggregate design, 355\u2013358\nsnapshots of, 559\u2013561\nas Standard Type, 237\nstate of, 516\u2013517\nstoring in Data Fabrics, 164\nsynchronizing instances in local Bounded \nContext, 287\nwww.EBooksWorld.ir\n", "page": 632, "type": "text", "section": "Page 632"}
{"text": "INDEX\n590\nAggregates (continued \n)\ntactical modeling tools, 29\nresults of asking whose job it is, 378\u2013379\nusage scenarios applied to designing, \n373\u2013374\nuse cases and, 358\u2013359\nuser interface convenience as reason to \nbreak design rules, 367\u2013368\nValue Objects preferred over Entities \nwhen possible, 382\nAggregates and Event Sourcing (A+ES)\nadvantages of, 539\u2013540\nAggregate design, 573\nBLOB persistence, 568\u2013569\nCommand Handlers, 549\u2013553\nconcurrency control, 554\u2013558\ncontract generation and maintenance, \n580\u2013581\ndrawbacks of, 540\nevent enrichment, 573\u2013575\nevent immutability, 577\nevent serializers, 576\u2013577\nevent sourcing in functional languages, \n583\nfocusing Aggregates on different \nbehavioral aspects, 569\u2013570\nimplementing event stores, 561\u2013565\ninside Application Services, 541\u2013549\nlambda syntax, 553\u2013554\noverview of, 539\nperformance issues, 558\u2013561\nRead Model Projections, 570\u2013572\nrelational persistence, 565\u2013567\nstructural freedom with, 558\ntools and patterns supporting, 576\nunit tests and specifications, 582\u2013583\nValue Objects and, 577\u2013580\nAgile Manifesto, 82\nAgile modeling\nbenefits of DDD, 28\ndesign and, 55\nAgile Project Management (APM), 177\nAgile Project Management Context\ncalculation process from, 277\nContext Maps and, 104\nas Core Domain, 98\nintegrating with Collaboration Context, \n107\u2013110\nintegrating with Identity and Access \nContext, 104\u2013107\nmodeling Domain Event from, 288\u2013289\nmodules, 340\u2013343\noverview of, 82\u201384\nProjectOvation as example of, 92\nValue Objects and, 239\nAjax Push (Comet), 147\nAkka, as messaging middleware, 303\nAnemia, 14\u201316\nAnemia-induced memory loss, 16\u201320\nAnemic Domain Model\navoiding, 426\ncauses of, 14\u201315\ndetermining health of Domain Model \nand, 13\nDTOs mimicking, 532\noveruse of services resulting in, 268\noverview of, 13\npresence of anemia everywhere, 15\u201316\nwhat anemia does to your model, 16\u201317\nAnticorruption Layer (ACL)\nBounded Context relationships, 93\u201394\nbuilt-in, 532\ndefined, 101\nimplementing, 469\nimplementing REST clients and, 463\u2013469\nsynchronizing team members with \nidentities and roles, 340\u2013341\nAPIs (application programming interfaces)\ncreating products, 482\u2013483\nintegration basics and, 450\u2013451\nopening services and, 510\nAPM (Agile Project Management), 177. \nSee also Agile Project Management \nContext\nApplication Layer\ncomposing multiple Bounded Contexts \nand, 531\u2013532\ncreating and naming modules of non-\nmodel components, 343\u2013344\nDIP (Dependency Inversion Principle) \nand, 124\nin Layers Architecture, 119\u2013121\nmanaging transactions in, 433\u2013434\nApplication programming interfaces. See\nAPIs (application programming \ninterfaces)\nApplication Services, 68\ncontrolling access and use of Aggregates, \n541\u2013549\ndecoupling service output, 528\u2013530\ndelegation of, 461\u2013462\nDomain Services compared with, 267\nenterprise component containers, \n534\u2013537\nexample, 522\u2013528\nHexagonal Architecture and, 126-128\nwww.EBooksWorld.ir\n", "page": 633, "type": "text", "section": "Page 633"}
{"text": " \nINDEX\n591\ninfrastructure and, 509, 532\u2013534\nin Layers Architecture, 120\u2013121\nmessage handler, 293\noverview of, 521\npassing commands to, 550\nperforming business operations, 545\nreasons for not wanting business logic in, \n279\u2013280\nregistering subscribers to Domain Events, \n300\u2013302\ntransactional service in multiple-\nAggregate design, 352\u2013353\nApplications\nBounded Contexts and, 66\u201368\ncomposing multiple Bounded Contexts, \n531\u2013532\ndealing with multiple, disparate clients, \n517\u2013518\ndefined, 510\nenterprise component containers, 534\u2013537\ngenerating identity of Entities, 175\u2013178\ninfrastructure and, 532\u2013534\nmediators, 514\u2013515\noverview of, 509\u2013511\nrendering Aggregates, 515\u2013516\nrendering domain objects, 512\u2013513\nrendering DTOs, 513\u2013514\nrendition adapters and user edit handling, \n518\u2013521\nrepresenting state of Aggregate instances, \n516\u2013517\nreview, 534\u2013537\ntask management for, 549\nuse case optimal repository queries, 517\nuser interface, 512\nArchitects, benefits of DDD to, 5\u20136\nArchitecture\nApplication Services and, 521\nbenefits of Aggregates, 540\nBounded Contexts and architectural \nissues, 68\nContext Maps for, 90\nCQRS. See CQRS (Command-Query \nResponsibility Segregation)\ncreating and naming modules of non-\nmodel components, 343\u2013344\ndata fabric and grid-based distributed \ncomputing. See Data fabrics\ndecision process (in fictitious interview), \n115\u2013119\nDIP (Dependency Inversion Principle) \nand, 123\u2013125\nevent driven. See EDA (event-driven \narchitecture)\nLayers Architecture pattern, 119\u2013123\noverview of, 113\u2013114\nPorts and Adapters. See Hexagonal \nArchitecture\nREST. See REST (Representational State \nTransfer)\nreview, 168\u2013169\nSOA (Service-Oriented Architecture), \n130\u2013133\nArchived logs\nfinding notification, 315\npublishing NotificationLog, 319\u2013323\nwhat they are, 313\nAssertions, design-by-contract approach and, \n208\nAssessment view, for understanding problem \nspace, 57\nAttributes, validating Entities, 208\u2013211\nAudit logs, 308\nAuthentication\ndeciding where to place technical \ncomponents, 272\u2013275\nexample of where to use a Domain \nService, 269\u2013271\ntesting authentication service, 281\u2013284\nof users, 198\nAutonomous services and systems, Domain \nEvents and, 305\u2013306\nB\nBehaviors\nessential Entity behaviors, 196\u2013200\nfocusing Aggregates on different \nbehavioral aspects, 569\u2013570\nmodeling Domain Events, 291\u2013293\nnaming object behaviors, 31\u201332\npatching classes with specialized \nbehaviors, 225\u2013226\nrepositories and, 430\u2013432\nBig Ball of Mud\nBounded Contexts, 93\u201394\ncollaboration issues and, 76\nfailure from not using strategic design, \n55\ninterfacing with, 88\u201389\nBinary JSON (BSON), 426\nBitcask model, Riak, 569\nBLOB (binary large object) persistence, \n568\u2013569\nBoundaries\nContext Maps and, 90\nexchanging information across system \nboundaries, 452\u2013458\nmodules and, 344\nwww.EBooksWorld.ir\n", "page": 634, "type": "text", "section": "Page 634"}
{"text": "INDEX\n592\nBounded Context. See also Integrating \nBounded Contexts\nabstract business domain with \nSubdomains and, 50\nAggregate discovery in, 353\u2013354\nAgile Project Management Context and, \n82\u201384\nalignment with Subdomains, 57, 60\nalignment with technical components, \n71\u201372\nassigning identity of Entities, 182\u2013183\nbank accounts example, 64\nbook publishing example, 64\u201365\nbusiness value and, 28\nCollaboration Context. See Collaboration \nContext\ncombining DDD and RESTful HTTP and, \n137\ncommunicating Domain Events across, \n286\ncommunicating to remote, 303\ncomposing multiple, 531\u2013532\ncontext is king, 63\nContext Maps. See Context Maps\ncontextual boundaries and, 344\nCore Domain and, 35\nencompassing more than Domain Model, \n66\u201368\nexamples, 72\u201373\nexplicit and linguistic nature of, 62\nIdentity and Access Context, 80\u201381\nintegrating with Subdomains, 46\nintegration between, 49\u201350, 450\u2013451\nlinguistic boundaries, 48\nmapping, 64\nmodule name identifying, 337\u2013339\nnaming, 54\noverview of, 20\npersistence of, 558\nrepositories and, 402\nSaaSOvation case study, 65\u201366\nsize of, 68\u201371\nSOA and, 132\u2013133\nsolution space and, 57\nUbiquitous Language and, 25\nwhiteboard illustration of Subdomain \nand, 51\nBSON (binary JSON), 426\nBuilder pattern, 389\nBundles, OSGi, 336\nBusiness analysts, benefits of Ubiquitous \nLanguage to, 21\nBusiness processes, uses of Domain Services, \n268\nBusiness services, 66\u201368. See also\nApplications\nBusiness strategies, 132\nBusiness value, of DDD\nclean boundaries around models, 28\ndomain experts contributing to software \ndesign, 27\nimproved organization of enterprise \narchitecture, 28\nimproved user experience, 27\u201328\noverview of, 25\u201326\nprecise and refined understanding of \nbusiness, 27\nsoftware development, 7\u201310\nstrategic and tactical tools, 28\u201329\nuseful Domain Models, 26\u201327\nBusiness-driven architecture, 10\nBusiness-level service, 9\u201310\nBusinessPriority\ntesting for, 242\nUbiquitous Language and, 240\nusing Value type as Strategy, 243\u2013244\nC\nC#\nApplication Service implemented in, 542\ncollections in, 403\nnamespaces, 333, 336\u2013337\nCache\nclient cache, 316\nData Fabrics providing, 164\u2013165\ndistributed, 147\nEvent Streams, 559\nnamed cache strategies in Coherence, \n422\u2013424\nCalculations\ncreating service for, 277\u2013280\nuses of Domain Services, 268\nCalendarEntry instances, Factory \nexamples, 392\u2013395\nCallback, 514\u2013515\nCapped Exponential Back-off, 365, 502, 553\nCategorized style, CQRS Command \nHandlers, 143\nChecks pattern language (Cunningham), 211\nClasses\nimplementation classes for repository, \n410\u2013411\nmodel in modules, 338\nroles and, 200\u2013201\nwww.EBooksWorld.ir\n", "page": 635, "type": "text", "section": "Page 635"}
{"text": " \nINDEX\n593\nClear-text passwords, 274\nClient and query processor, 141\nClients\ndealing with multiple, disparate clients, \n517\u2013518\njustification for domain modeling, 37\nproducing specific output types for, 528\nRESTful HTTP clients, 136, 463\u2013469\nClient-server style, using Layers Architecture \nfor, 115\nClojure, event sourcing in, 583\nClones, of Value Objects, 244\nCockburn, Alistair, 125\nCode smells\nAggregate mis-design and, 432\nindicating need of a service, 265\ntype hierarchies and, 439\nCoherence (Oracle)\nconcurrency and, 385\u2013386\ndistributed processing and, 167\nimplementing persistence-oriented \nrepository, 420\u2013425\npersistence-oriented repositories and, \n418\u2013420\ntesting persistence-oriented repository, \n442\u2013445\nCollaboration Context\ndesigning and implementing, 74\nfacilitating synergistic workspace, 73\nFactory Methods on Aggregates and, \n391\u2013392\nimplementing REST client, 463\u2013469\nintegrating with Agile Project \nManagement Context, 107\u2013110\nintegrating with Identity and Access \nContext, 101\u2013103\nlong-running processes (sagas) and, \n488\u2013490\nmapping three contexts, 95\u201396\nnaming Bounded Context and, 54\nresponsibilities and, 476\nServices as Factories and, 397\u2013399\nValue Objects preferred over Entities \nwhen possible, 382\nCollaboration model, example from failure to \nuse strategic design, 53\u201355\nCollection-oriented repositories\nbackground of collections and, 403\u2013404\nHibernate implementation of. See\nHibernate repository\nmimicking set collections, 404\u2013406\noverview of, 402\npersistent data store and, 406\u2013407\ntools for, 407\nColumns, serialization of many Values into, \n253\u2013255\nComet (Ajax Push), 147\nCommand (write) model, in CQRS\nclient driving command processing, 143\ncommand processors, 143\u2013144\ndefined, 140\noverview of, 144\u2013145\nCommand Handlers\ncontrolling task management for \napplications, 549\u2013553\nin CQRS, 143\u2013144\nCommand objects\ndesigning, 523\ndesigning Command class, 527\u2013528\nCommand-Query Responsibility Segregation. \nSee CQRS (Command-Query \nResponsibility Segregation)\nCommand-Query Separation. See CQS \n(Command-Query Separation)\nCommands\ncontract generation and maintenance, \n580\u2013581\ncontrolling task management for \napplications, 549\nCQRS, 139\npassing to Application Services methods, \n550\nCommunication\nContext Maps facilitating inter-team, \n88\u201389\nof Domain Events across Bounded \nContext, 286\nof Events to remote Bounded Contexts, \n303\nComplexity, Subdomains and, 46\nConceptual Wholeness characteristic, of \nValue Objects, 221, 223\u2013226\nConcurrency\nconcurrency control for Event Streams, \n554\u2013558\neventual consistency and, 365\npersistence mechanisms for dealing with, \n350\nConformist relationships\nbeing forced into, 89\nBounded Context, 93\nContext Maps and, 460\nConsistency\neventual. See Eventual consistency\ninvariants and, 359\nin modeling Aggregates, 349\u2013351, 355\ntransactional. See Transactional \nconsistency\nwww.EBooksWorld.ir\n", "page": 636, "type": "text", "section": "Page 636"}
{"text": "INDEX\n594\nConstructors\nof Entities, 205\u2013207\nof Events, 291\nfulfilling dependencies, 543\nof Value class, 225\nof Value Objects, 244\nContainers, for enterprise components, \n534\u2013537\nContext Maps\nAgile Project Management Context and, \n104\nBounded Context and, 25\nbusiness value from, 28\ndesign approaches, 460\ndrawing, 89\u201391\nforms of, 449\nintegrating Agile Project Management \nContext with Identity and Access \nContext, 104\u2013107\nintegrating Collaboration Context with \nAgile Project Management Context, \n107\u2013110\nintegrating Collaboration Context with \nIdentity and Access Context, 101\u2013103\nintegration options in, 50\nintegration with, 182\niterative refinement of, 97\u201398\nlinguistic boundaries, 96\nmessage-based approach to integration, \n482\nof organizational and integration \npatterns, 92\u201394\noverview of, 87\nin problem space assessment, 96\u201397\nproject and organizational relationships \nand, 91\u201392\nreview, 111\ntool for shaping team judgment, 69\nupstream/downstream relationships, \n99\u2013100\nwhy essential, 87\u201389\nContinuous Queries, Data Fabrics \nsupporting, 166\nContinuous modeling, benefits of DDD, 28\nContracts\ndesign-by-contract approach and, 208\nfor Domain Events, 290\ngenerating and maintaining, 580\u2013581\nCopy constructors, creating Value Objects, \n244\nCore Domain\naggregates in, 348\u2013349\nAgile Project Management Context as, \n98, 239\nin assessment of problem and solution \nspaces, 58\u201359\ndistinguishing between types of domains, \n44\neliminating extraneous concepts, 69\nfocus on, 50\u201351\ninvesting in what produces biggest \nbenefit, 10\njustification for domain modeling, 35, 37\nmodule of Agile Project Management \nContext, 340\nproblem space in development of, 56\u201357\nfor SaaS Ovation Domain Model, 91\nTransaction Script approach to modeling, \n532\nwhen to add, 47\u201348\nwhiteboard illustration of, 52\nCQRS (Command-Query Responsibility \nSegregation)\nclient and query processor in, 141\nclient driving command processing, 143\ncode smell suggesting use of, 432\ncommand (write) model, 144\u2013145\ncommand processors, 143\u2013144\ncontinuos queries, 166\ndealing with inconsistency in query \nmodel, 146\u2013147\nEvent Sourcing and, 160, 162\nevent subscriber updating query model, \n145\u2013146\neventual consistency and, 366\nexample of use of, 117\nimplementing Aggregates and Event \nSourcing (A+ES), 540\noverview of, 138\u2013140\nquery (read) model, 141\u2013142\nreferences by identity and, 363\nuse case optimal query compared with, 517\nCQS (Command-Query Separation)\ndefined, 139\nin multiple-Aggregate design, 352\nQuery methods, 229\nSide-Effect-Free Functions and, 245\nCRC (cyclic redundancy check), BLOB data \nstore and, 569\nCritical path, justification for Domain \nModeling, 36\nCRUD-based systems\nas alternative to Entities, 172\nDAOs (Data Access Objects) and, 441\nwww.EBooksWorld.ir\n", "page": 637, "type": "text", "section": "Page 637"}
{"text": " \nINDEX\n595\nCunningham, Ward, 211\u2013212, 215, 223, 357\nCurrent logs\nHTTP GET method and, 313\u2013315\npublishing NotificationLog, 319\u2013323\nCustomers, justification for Domain \nModeling, 37\nCustomer-Supplier Development, Bounded \nContext relationships, 92, 94\nCustomer-Supplier relationship, 89\nCyclic redundancy check (CRC), BLOB data \nstore and, 569\nD\nDahan, Udi, 203\nDAOs (Data Access Objects), 440\u2013441\nData Fabrics\ncontinuous queries, 166\ndata replication, 164\u2013165\ndistributed processing, 167\u2013168\ndomain modeling, 441\nevent-driven fabrics and Domain Events, \n165\u2013166\noverview of, 163\u2013164\npersistence-oriented repositories and, 418\nData Mapper, use within Domain Model, \n441\nData Model Leakage, 249\u2013251\nData replication, 164\u2013165\nData store\nBLOB data store and, 569\npersistence-oriented repositories and, \n418\u2013420\nData Transfer Objects. See DTOs (Data \nTransfer Objects)\nData Transformer\ndealing with multiple, disparate clients, \n517\u2013518\nfor producing specific output types for \nclients, 528\ntype complexity and, 523\nDatabases\nACID, 521\nfunctional, 583\nmany Values backed by database entity, \n255\u2013260\nMySQL. See MySQL\nNoSQL, 249, 418\nrelational, 543, 565\u2013567\nDDD (Domain-Driven Design), getting \nstarted\nanemia-induced memory loss and, 16\u201320\nbenefits of, 26\u201329\nbenefits to architects and domain experts, \n5\u20136\nbenefits to developers, 4\u20135\nbenefits to managers, 6\nbusiness value of, 25\u201326\ncase studies in presentation of, 38\u201339\nchallenges in applying, 29\u201334\ndelivering software with true business \nvalue, 7\u201310\ndetermining Domain Model health, 13\u201314\njustification for domain modeling, 34\u201337\nmodeling complex domains in simplest \nmanner, 10\noverview of, 1\nreasons for implementing, 6\u20137\nreasons for poor (anemic) domain health, \n14\u201316\nrequirements for implementing, 2\u20134\nreview, 41\u201342\nSaaSOvation case study, 40\u201341\nscorecard for determining if project \nqualifies, 10\u201313\ntest-first approach, 37\u201338, 239\u2013243\nUbiquitous Language and, 20\u201325\nDDR (Domain Dependency Resolver), 516\nDecision making\nAggregate design and, 379\u2013380\nfictitious interview and, 115\u2013119\nmodels providing tools for, 57\nDecoupling service output\nApplication Services and, 528\u2013530\ndecoupling service from client, 550\u2013551\ntemporal decoupling, 551\nDedicated style, CQRS Command Handlers, \n143\nDeep clones, creating Value Objects, 244\nDefensive programming, 210\nDeferred Validation\nof object compositions, 215\nof whole objects, 211\u2013212\nDelegation\nof Aggregate instances to DTO, 513\u2013514\nof Application Services, 461\u2013462\nself-delegation, 244, 248\nDELETE method, HTTP, 135, 458\nDependency Injection\navoiding when implementing Aggregates, \n387\nfulfilling dependencies, 543\nimplicit lookup, 533\npreventing client awareness of \nimplementations, 276\u2013277\nwww.EBooksWorld.ir\n", "page": 638, "type": "text", "section": "Page 638"}
{"text": "INDEX\n596\nDependency Inversion Principle. See DIP \n(Dependency Inversion Principle)\nDescribing characteristic, of Value Objects, \n221\nDesign\nagile, 55\nwith modules, 333\u2013336\nDesign Patterns and Contracts (Jezequel et. \nal.), 208\nDesign Patterns (Gamma et. al.), 389\nDesign rules, modules, 334\u2013335\nDesign-by-contract approach, 208\nDevelopers\nbenefits of DDD to, 4\u20135\nbenefits of Ubiquitous Language, 21\nchallenges in applying DDD, 30\ndelivering business value and, 8\nhow DDD helps in software \ndevelopment, 9\non level playing field with domain \nexperts, 7\nDIP (Dependency Inversion Principle)\nexample of use of, 115\u2013116\nHexagonal Architecture and, 126\ninfrastructure and, 532\nlayering infrastructure, 411\nLayers Architecture pattern and, 123\u2013125\nin UML, 510\u2013511\nDisconnected Domain Model, 362\nDiscussion instances, Factory examples, \n395\u2013397\nDistributed Cache/Grid, data synchronization \nand, 147\nDistributed Computing\nData Fabrics supporting, 167\u2013168\nprinciples of, 451\nDistribution, Aggregate design and, 363\u2013364\nDocumentation, in developing Ubiquitous \nLanguage, 22\nDomain\nthe big picture, 43\u201344\nmapping domain data to views. See CQRS \n(Command-Query Responsibility \nSegregation)\nmodeling complex, 10\nproblem space and solution space of, \n56\u201358\nwith Subdomains and Bounded Contexts, \n45\nDomain Dependency Resolver (DDR), 516\nDomain Event\nwith Aggregate characteristics, 294\u2013295\narchitectural styles for forwarding stored \nEvents, 312\nassigning unique identifiers to, 156\nautonomous services and systems and, \n305\u2013306\ncommunicating to remote Bounded \nContexts regarding, 303\ncontract for, 290\nCQRS command model and, 144\u2013145\nCQRS query model and, 145\u2013146\ncreating properties, 290\u2013291\nData Fabrics and, 165\u2013166\nde-duplication, 329\u2013331\nenrichment, 294, 453, 471, 481, 573\u2013575\nEvent Store and, 307\u2013312\neventual consistency and, 108\nIdentity and Access Context and, 80, \n104\u2013105\nidentity of, 295\u2013296\nimplementing, 318\u2013319\nlatency tolerances, 306\u2013307\nmessaging infrastructure consistency and, \n303\u2013304\nmodeling behavioral operations, 291\u2013293\nmodeling Events, 288\u2013289\nnaming and publishing, 289\noverview of, 285\nPublished Language used in, 100\npublishers and, 297\u2013300\npublishing, 121, 296\u2013297\npublishing message-based notifications, \n324\u2013329\npublishing NotificationLog, 319\u2013323\npublishing notifications as RESTful \nresources, 312\u2013317\npublishing notifications using messaging \nmiddleware, 317\u2013318\nreview, 324\u2013329\nsubscribers and, 300\u2013302\nsystem autonomy and, 469\ntactical modeling tools, 29\ntracking changes, 216\u2013217\nwhen to use and why to use, 285\u2013288\nDomain Event Publisher, 121, 530\nDomain experts\nadvantages of engaging, 3\u20134\navailability of, 36\nbenefits of DDD to, 5\u20136\nchallenges of applying DDD, 29\u201330\ncontribution to software design, 27\nin delivering business value, 8\ninfluence on Ubiquitous Language, 21\ninvolving in whiteboard drawing of \ndomain, 52\non level playing field with developers, 7\nin software development, 9\nwww.EBooksWorld.ir\n", "page": 639, "type": "text", "section": "Page 639"}
{"text": " \nINDEX\n597\nDomain Layer\naccessing Infrastructure Layer, 121\u2013122\ncreating and naming modules of non-\nmodel components, 343\u2013344\nDIP (Dependency Inversion Principle) \nand, 124\nin Layers Architecture, 119\nunidirectional and downward references \nfrom Infrastructure Layer, 411\nDomain model\nabstract business domains, 50\nanalyzing best model for business, 22\napplications and, 509\nbenefit of, 26\u201327\nBounded Context encompassing more \nthan, 66\u201368\ncharacteristics of sound models, 69\nclean boundaries around, 28\nData Fabrics and, 441\ndesigning, 191\ndetermining health of, 13\u201314\nDisconnected Domain Model, 362\nFactories in, 389\u2013391\nHibernate and, 15\u201316\njustification for, 34\u201337\nmodeling complex domains in simplest \nmanner, 10\nmodule naming conventions and, 339\npublishing Domain Events from, 296\u2013297\nreducing costs of doing business, 57\nSaaS Ovation example, 91\nshielding from dependencies, 453\ntailoring to specific business areas, 44\nValue Objects in development of, 577\u2013580\nwhat anemia does to your model, 16\u201320\nwhat it is, 4\nDomain names, module naming conventions \nand, 337\nDomain objects\nwith multiple roles, 200\u2013205\nrendering, 512\u2013513\nDomain Payload Objects (DPOs)\nPresentation Model and, 520\nrendering Aggregate instances from, \n515\u2013516\nDomain Services\nApplication Services compared with, 120, \n521, 526\u2013527\nApplication Services supporting, 541\navoiding dependency injection, 387\nin bad design example, 76\nfor business priorities, 231\ncalculation service, 277\u2013280\ncreating Events, 295\ndetermining need for, 268\u2013272\nmini-layer of, 281\nmodel navigation and, 362\u2013363\nmodeling, 272\u2013275\noverview of, 265\u2013267\nperforming business operations, 545\u2013546\nproviding Standard Types, 238\nregistering subscribers to Domain Events, \n300\u2013302\nreview, 284\nSeparated Interface and, 275\u2013277\ntesting, 281\u2013284\ntransformation services, 280\nuses of, 268\nfor validating object compositions, \n215\u2013216\nwhat they are and what they are not, \n267\u2013268\nDon\u2019t repeat yourself (DRY) principle, 6\nDouble-Dispatch\nDomain Payload Objects and, 516\nfor handling client output types, 530\npublishing internal state of Aggregates, \n514\u2013515\nDownstream models, upstream models \ninfluencing, 99\u2013100\nDPOs (Domain Payload Objects)\nPresentation Model and, 520\nrendering Aggregate instances from, \n515\u2013516\nDrawings, Context Maps, 89\u201391, 449\nDRY (Don\u2019t repeat yourself) principle, 6\nDTO Assemblers, 141, 513\nDTOs (Data Transfer Objects)\ncomplexity and, 523\nCQRS and, 141\nDomain Payload Objects compared with, \n515\u2013516\nmimicking Anemic Domain Model, 532\nPresentation Model and, 520\nquerying repositories and, 138\nRead Model Projections and, 572\nrendering from Aggregate instances, \n513\u2013514\nE\nEager loading strategy, 516\nEclipse, 71\nEclipseLink, 407\nEDA (event-driven architecture)\nevent sourcing, 160\u2013163\nexample of use of, 117\u2013118\nintegration implementation using, \n469\u2013508\nwww.EBooksWorld.ir\n", "page": 640, "type": "text", "section": "Page 640"}
{"text": "INDEX\n598\nEDA (continued \n)\nleveraging eventual consistency, 108\nlong-running processes (sagas), 153\u2013159\noverview of, 147\u2013149\nPipes and Filters and, 149\u2013153\nEditing, handling user edits, 518\u2013521\nEiffel programming language, 208\nEJB (Enterprise JavaBeans), 534\nEncapsulation, power of self-encapsulation, \n207\nEncrypting passwords, 269\u2013271\nEnrichment, of Domain Events, 294, 453, \n471, 481, 573\u2013575\nEnterprise architecture\nContext Maps are not EA diagrams, 90\nimproving organization of, 28\nEnterprise component containers, 534\u2013537\nEnterprise JavaBeans (EJB), 534\nEnterprise resource planning (ERP)\ndelivering business value and, 8\nSubdomains as modules in, 57\nEntities\nAggregate with multiple Entities, 358\napplication assigning identity, 175\u2013178\nBounded Context assigning identity, \n182\u2013183\nclustering into Aggregate, 347\nconstructing, 205\u2013207\ncreating and assigning identity, 410\ndeveloper focus on, 53\ndomain objects with multiple roles, \n200\u2013205\nessential behaviors, 196\u2013200\noverview of, 171\npersistence mechanism assigning identity \nof, 179\u2013182\nreasons for using, 171\u2013173\nrefactoring as Value Objects, 357\nrepositories and, 402\nreview, 218\nRoot Entity, 380\u2013382\nstability of identity, 188\u2013190\nsurrogate identities, 186\u2013188\ntactical modeling tools, 29\ntracking changes, 216\u2013217\nuncovering Entities and their properties, \n192\u2013196\nunique identity of, 156, 173\u2013174\nuser providing identity, 174\u2013175\nvalidating attributes and properties, \n208\u2013211\nvalidating object compositions, 215\u2013216\nvalidating whole objects, 211\u2013215\nValue Objects preferred when possible, \n219\u2013220, 382\nwhen timing of identity generation \nmatters, 183\u2013186\nEnum (Java)\nenum-as-state objects, 261\u2013263\nsupport for Standard Types, 235\u2013238\nEquality, of Value Objects, 227\u2013228\nERP (enterprise resource planning)\ndelivering business value and, 8\nSubdomains as modules in, 57\nEvans, Eric, 367, 510\nEvent Sourcing\naggregates and. See Aggregates and Event \nSourcing (A+ES)\napplying to DDD, 539\nexample of use of EDA and, 118\nin functional languages, 583\noverview of, 160\u2013163\ntracking changes and, 217\nunit tests and specifications, 582\u2013583\nEvent Store\nAggregate Event Stream persistence in, \n539\nBLOB persistence and, 568\u2013569\ncommitting Changes collection to, 547\nfunctional databases and, 583\nimplementing, 561\u2013565\nimplementing with relational database, \n543\nloading events from, 543\u2013545\nmaintaining for Domain Events, 307\u2013312\nmessaging infrastructure consistency and, \n304\nreconstituting Aggregate instance from, \n545\ntracking changes, 216\u2013217\nEvent Streams\ncaching, 559\nconcurrency control, 554\u2013558\nimmutability of, 577\noverview of, 539\u2013540\nEvent-based messages, in exchange of media \nbetween Bounded Contexts, 453\u2013454\nEvent-driven architecture. See EDA (event-\ndriven architecture)\nEvent-driven fabrics, 165\u2013166\nEvents. See also Domain Event\nAggregates as series of, 539\narchitectural styles for forwarding stored, \n312\nconsuming Events in local and foreign \nBounded Contexts, 287\nwww.EBooksWorld.ir\n", "page": 641, "type": "text", "section": "Page 641"}
{"text": " \nINDEX\n599\ncontract generation and maintenance, \n580\u2013581\nde-duplication, 329\u2013331\nenrichment of, 573\u2013575\nimmutability of, 577\nincorporating into Ubiquitous Language, \n287\nloading from Event Store, 543\u2013545\nperforming business operations, 545\u2013546\nRead Model Projections, 570\u2013572\nreplicating and publishing, 547\u2013548\nserializing, 576\u2013577\nsize of Bounded Contexts and, 68\nEventual consistency\nacceptable update delay, 359\nfor execution outside Aggregate \nboundaries, 364\u2013366\nimplementing in Aggregate design, 376\u2013378\nfor multiple Aggregates, 364\ntechnical mechanisms needed for, 368\nvs. transactional consistency, 366\u2013367\nExecute(), 552\nExecutive, merging executives and trackers \ninto Aggregates, 156\nExplicit Copy-before-Write, collection-\noriented repositories and, 407\nF\nF# language, 583\nFacade\nEJB Session Facades, 534\nmanaging transactions and, 433\u2013435\nPresentation Model and, 520\u2013521\nservices acting as, 68\nFactories\non Aggregate Root, 391\u2013392\nfor application-generated identities, 178\nCalendarEntry instances example, \n392\u2013395\ncreating Aggregates, 121\ncreating Collaborator subclasses, \n464\u2013465\nDiscussion instances example, 395\u2013397\nin Domain Model, 389\u2013391\nEntity instantiations and, 207\noverview of, 389\nreview, 400\nof services, 276\u2013277, 397\u2013399\nFactory Method\non Aggregate Root, 391\u2013392\nCalendarEntry instances example, \n392\u2013395\nDesign Patterns (Gamma et. al.) and, 389\nUbiquitous Language and, 390\nFallacies of Distributed Computing\n(Deutsch), 451\nFanout exchange, RabbitMQ, 317\nFielding, Roy T., 133\u2013134\nFilters. See Pipes and Filters\nFinder methods, in repository interface, 409\nFormats, for information exchange, 452\nFowler, Martin, 131, 164, 229, 276, 441\nFunctional databases, 583\nFunction/Entry Processor, 441\nFunctions, 228\nFundamental Identity pattern, 199\u2013200\nG\nGang of Four, 4\nGemFire\nconcurrency and, 385\u2013386\ndistributed processing and, 167\npersistence-oriented repositories and, \n418\u2013420\nGeneric Subdomains\napplication support in, 509\nassessment of problem space and solution \nspace, 58, 61\ndefined, 52\nIdentity and Access Context and, 80\njustification for domain modeling, 35\nin SaaS Ovation Domain Model, 91\nGeneric utilities, patching in, 552\u2013553\nGET method, HTTP\napplying HTTP verbs to resources, \n135\u2013136\nrequesting current logs, 313\u2013315\nRESTful notifications, 458\nGiven-When-Expect, unit tests, 582\nGlobal transactions, as reason to break \nAggregate design rules, 369\nGlobally unique identifiers. See GUIDs \n(globally unique identifiers)\nGlossary, for developing Ubiquitous \nLanguage, 22\nGoogle Protocol Buffers, 576\u2013577\nGraphical clients, 517\nGraphical user interfaces (GUIs), 512\nGreenfield development\nBounded Contexts and, 72\nContext Maps in, 89\nGrid Computing. See Data Fabrics\nGuards\nEntity assertions, 207\nwww.EBooksWorld.ir\n", "page": 642, "type": "text", "section": "Page 642"}
{"text": "INDEX\n600\nGuards (continued \n)\nas form of validation, 208\u2013211\nparameter validity and, 248\nGUIDs (globally unique identifiers)\nassigning to Aggregate instances, 410\nidentity creation patterns and, 175\nreferencing Aggregate instances, 361\u2013362\nGUIs (graphical user interfaces), 512\nH\nHATEOAS (Hypermedia as the Engine of \nApplication State), 136\nHedhman, Niclas, 357\nHelland, Pat, 156, 363\u2013364, 480\nHexagonal Architecture\nadapter for RESTful HTTP port, 461\nadapters for handling client output types, \n529\u2013530\nadvantages of, 129\nEDA (event-driven architecture) and, \n147\u2013148\nexample of use of, 116\nhow ports and adapters work, 127\nJAX-RS example, 128\u2013129\nmodule naming conventions and, 338\noutside and inside dimensions of, 126\noverview of, 125\nports, 126\u2013127\nversatility of, 129\u2013130\nHibernate\nenum-as-state objects and, 261\u2013263\nmany Values backed by database entity, \n255\u2013260\nmany Values backed by join table, 260\noptimistic concurrency, 350, 385\u2013386\nas persistence mechanism, 179\u2013182, 373\nfor persistent Domain Models, 15\nfor persistent Value Objects, 251\u2013253\nserializing many Values into single \ncolumn, 253\u2013255\nsurrogate identities and, 186\u2013188\ntheta joins supported by, 363\ntransaction management with, 432\u2013437\nHibernate repository\ncreating and assigning identity, 410\nimplementation classes, 410\u2013411\nimplementing methods, 412\u2013415\ninterfaces for, 407\u2013408\nremoving Aggregate instances, 409\nHTML, 100\nHTTP\nAPI availability and, 450\u2013451\nmethods (GET, PUT, POST, and \nDELETE), 313\u2013315, 458\nRESTful HTTP, 135\u2013136, 450\u2013451\nstandardization of, 134\nHypermedia as the Engine of Application \nState (HATEOAS), 136\nI\nIDE\nalignment of Bounded Contexts with, \n71\nValue Objects supporting, 578\nIdempotent, HTTP method, 136\nIdentity\naccess management and, 91\u201392\napplications generating, 175\u2013178\nBounded Contexts assigning, 182\u2013183\ncreating Root Entity with unique identity, \n380\u2013382\nof Domain Events, 294\u2013296\npersistence mechanism generating, 179\u2013182\nreferences between Aggregates, 359\u2013361\nreferencing Aggregates by globally unique \nidentity, 361\u2013362\nsegregating types by, 439\nstability of, 188\u2013190\nsurrogate identities, 186\u2013188\nuniqueness of, 173\u2013174\nuser providing, 174\u2013175\nwhen timing of creation matters, \n183\u2013186\nIdentity and Access Context\napplication support in, 509\ncentralizing security and permissions, \n80\u201381\nmini-layer of Domain Services and, 281\nrole assignments via, 200, 469\u2013471, 480\nservice providing translation to \nCollaboration Context, 398\nsessionProvider bean, 435\u2013437\nuncovering Entities and Entity properties, \n192\nIdentity module, authentication service \nplaced in, 273\nImmutability\ncreating explicitly named immutable \ntypes, 577\u2013578\nof Events, 291, 577\ninstantiation not a guarantee of, 222\nSide-Effect-Free Functions and, 228\u2013229\ntesting for, 241\nusing immutable Values results in less \nresponsibility, 232\u2013233\nof Value Objects, 221\u2013223\nImplementation classes, 275\u2013276, 410\u2013411\nImplementations, technical, 273\nwww.EBooksWorld.ir\n", "page": 643, "type": "text", "section": "Page 643"}
{"text": " \nINDEX\n601\nImplementing\nAggregates and Event Sourcing (A+ES), \n540, 561\u2013565\nAnticorruption Layer (ACL), 469\nCollaboration Context, 74\nDomain Events, 318\u2013319\nevent stores, 543, 561\u2013565\neventual consistency, 376\u2013378\nqueues, 312\nValue Objects, 243\u2013248\nImplementing Aggregates\navoiding dependency injection, 387\ncreating Root Entity, 380\u2013382\ninformation hiding (Law of Demeter and \nTell, Don\u2019t Ask), 382\u2013384\noptimistic concurrency, 385\u2013387\noverview of, 380\nValue Objects preferred over Entities \nwhen possible, 382\nImplementing DDD\nreasons for, 6\u20137\nrequirements for, 2\u20134\nImplementing repositories\nclasses, 410\u2013411\nCoherence in, 420\u2013425\nHibernate in, 407\u2013415\nmethods, 412\u2013415\nMongoDB in, 425\u2013430\ntesting with in-memory implementations, \n445\u2013447\nTopLink in, 416\u2013417\nImplementing RESTful resources\nBounded Contexts and, 459\u2013462\nHTTP clients, 463\u2013469\nHTTP servers, 135\u2013136\nImplicit copy-on-read, track changes \nmechanism for persistence, 406\u2013407\nImplicit copy-on-write, track changes \nmechanism for persistence, 406\u2013407\nInformation\nexchanging across system boundaries, \n452\u2013458\nhiding (Law of Demeter and Tell, Don\u2019t \nAsk), 382\u2013384\nInfrastructure Layer\napplications and, 532\u2013534\ncreating and naming modules of non-\nmodel components, 343\u2013344\nDIP (Dependency Inversion Principle) \nand, 122\u2013124\nDomain Layer accessing, 121\u2013122\nhousing technical implementations in \nmodule in, 273\nin Layers Architecture, 119\nunidirectional and downward references \nto Domain Layer, 411\nIn-memory editions, of repositories, 445\u2013447\nInstantiation, not a guarantee of \nimmutability, 222\nIntegrating Bounded Contexts\nAgile Project Management Context and, \n109\nDDD integrations and, 182\ndistributed systems and, 451\nDomain Services and, 280\nexchanging information across system \nboundaries, 452\u2013458\nfeed based notifications, 105\nimplementing RESTful clients, 463\u2013469\nimplementing RESTful resources, \n459\u2013462\nintegration basics, 450\u2013451\nintegration between Bounded Contexts, \n49\u201350\nintegration using RESTful resources, \n458\u2013459\nlong-running processes (sagas) and, \n481\u2013493\nmessage-based approach to, 469\noverview of, 449\nprocess state machines and time-out \ntrackers, 493\u2013503\nresponsibilities and, 476\u2013481\nreview, 508\nServices as Factories and, 397\nsophistication of design, 503\u2013507\nstaying informed about product owners \nand team members, 469\u2013476\nwith Subdomains, 46\ntechnical characteristics of integration, \n100\nValue Objects and, 219\u2013220\nwhen messaging or system is unavailable, \n507\u2013508\nIntegration\nAgile Project Management Context with \nIdentity and Access Context, 104\u2013107\nCollaboration Context with Agile Project \nManagement Context, 107\u2013110\nCollaboration Context with Identity and \nAccess Context, 101\u2013103\nintegration patterns, 92\u201394\nof Value Objects, 232\u2013233\nIntelliJ IDEA, 71\nIntention Revealing Interface, compliance \nwith Ubiquitous Language, 197\nwww.EBooksWorld.ir\n", "page": 644, "type": "text", "section": "Page 644"}
{"text": "INDEX\n602\nInterfaces\nfor Hibernate repository, 407\u2013408\nIntention Revealing Interface, 197\nreusable, 338\nSeparated Interface. See Separated \nInterface\nuser interfaces. See User Interface Layer\nIntermediate formats, for information \nexchange, 452\nInvariants\nin Aggregate design, 371\nconsistency and, 359\ndetermining true invariants when \ndetermining Aggregate clusters, \n353\u2013355\nEntities and, 205\nInversion-of-control containers, Spring, \n434\u2013437\nIterative modeling, benefits of DDD, 28\nIterative refinement, of Context Maps, \n97\u201398\nJ\nJava\ncollections in, 403\u2013404\nenum support for Standard Types, 235\u2013238\nJava 8 Jigsaw modules, 336\nMBean standard, 328\nnaming implementation classes, 275\u2013276\npackages, 333, 336\u2013337\nUUID generator, 176\nJavaBeans, 15\u201316, 245\u2013246\nJDBC, auto-incrementing sequences, 182\nJigsaw modules, Java 7, 336\nJMS, publishing Events to messaging \ninfrastructure, 547\nJoin table, many Values backed by, 260\nJSON\nbinary JSON format in MongoDB, 426\nclient integrators and, 462\u2013463\nformat for information exchange, 452\npublished language and, 100\nK\nKing, Gavin, 262\nKnowledge\ncentralizing, 7\u20138\nPrinciple of least knowledge, 383\nL\nLambda syntax, 553\u2013554\nLatency\nlong-running processes (sagas) and, 159\nlow latency trading systems, 540\ntolerances for Domain Events, 306\u2013307\nLaw of Demeter, 382\u2013384\nLayer Supertype\nmanaging surrogate identities and \noptimistic concurrency versioning, 380\nmany Values backed by database entity, \n255\u2013260\nsurrogate identities and, 187\u2013188\nLayers, 511\nLayers Architecture\nApplication Layer, 119\u2013121\narchitectural styles and, 511\nclient-server styles and, 115\ncreating modules, 343\u2013344\nDIP (Dependency Inversion Principle) \nand, 123\u2013125\nDomain Layer, 121\u2013122\nInfrastructure Layer, 122\u2013123\nnaming modules, 338\noverview of, 119\nstrict and relaxed, 120\nUser Interface Layer, 119\nLazy loading\nDisconnected Domain Model and, 362\nDomain Payload Objects and, 516\nperformance issues due to, 375\nLearning curve, for DDD, 2\nLegacy systems, integration with, 159\nLinguistic boundaries\nBounded Context and, 48\nContext Maps and, 96\nLinguistics, as driver in DDD, 71\nLiskov Substitution Principle (LSP), 438\u2013439\nLoad balancing, 550\u2013551\nLogs\nHTTP GET method and, 313\u2013315\npatching in, 552\u2013553\nLong-running processes\navoiding responsibility, 481\u2013493\ndesigning, 155\nexample of use of EDA, 118\nexecutives and trackers and, 156\u2013159\noverview of, 153\nstepping through, 154\u2013156\nLookups. See Standard Types\nLSP (Liskov Substitution Principle), 438\u2013439\nM\nManagers, benefits of DDD to, 6\nMartin, Robert C., 123\nMassTransit, messaging middleware, 303\nMBean standard, Java, 328\nwww.EBooksWorld.ir\n", "page": 645, "type": "text", "section": "Page 645"}
{"text": " \nINDEX\n603\nMeaningful Whole pattern, 223\nMeasurement characteristic, of Value \nObjects, 221\nMedia types in use, 453\u2013458, 462, 467\nMedia types, resource URIs and, 104\u2013105\nMediator pattern\nDomain Payload Objects and, 516\nfor handling client output types, 530\nloose coupling in Layers Architecture, 120\nPresentation Model using, 520\npublishing internal state of Aggregates, \n514\u2013515\nMemoization, 583\nMemory consumption, Aggregate design and, \n374\u2013375\nMessage-based approach, to Integrating \nBounded Contexts\nlong-running processes (sagas) and \navoiding responsibility, 481\u2013493\noverview of, 469\nresponsibilities and, 476\u2013481\nstaying informed about product owners \nand team members, 469\u2013476\nwhen messaging or system is unavailable, \n507\u2013508\nMessage-oriented middleware (MoM)\npublished notifications, 317\u2013318\nSOA services and, 267\nMessaging\nCommand Handlers and, 143\ndealing with multiple, disparate clients, \n517\nEvent messages, 295\ninfrastructure consistency and, 303\u2013304\nin Infrastructure Layer, 122\nintegration basics, 450\nmessage handlers, 550\npublishing Events to messaging \ninfrastructure, 547\nMeyer, Bertrand, 139, 208, 229\nMidlevel developer, benefits of DDD to, 4\u20135\nMini-layer of Domain Services, 281\nMission statements, Ubiquitous Language \nin, 27\nModels/modeling\nActor Model, 295\nAggregate models, 348\ncollaboration model, 53\u201355\ncontinuous modeling as benefit of DDD, \n28\nCQRS command model and, 144\u2013145\nCQRS query model and, 145\u2013146\nData Model Leakage, 249\u2013251\nDomain Event behaviors, 291\u2013293\nDomain Events, 288\u2013289\nDomain Model. See Domain model\nDomain Services, 272\u2013275\nidentities and, 194\nnavigation and, 362\u2013363\nPresentation Model. See Presentation \nModel\npull vs. push models, 312\ntactical modeling, 29, 75\ntactical modeling vs. strategic modeling, \n34\nTransaction Script approach to, 532\nunderstanding invariants in consistency \nboundaries, 353\u2013355\nUnified Modeling Language. See UML \n(Unified Modeling Language)\nupstream models influencing \ndownstream, 99\u2013100\nModel-View-Presenter (Dolphin), 518\nModules\nAgile Project Management Context and, \n110, 340\u2013343\napplication support in, 510\navoiding miniature Bounded Contexts, 70\ncomposing multiple Bounded Contexts, \n531\ncontextual boundaries and, 344\ndesigning with, 333\u2013336\ndrawing Context Maps and, 90\nhiding technical classes in, 122\nhousing technical implementations in \nInfrastructure Layer, 273\nnaming conventions, 336\u2013339\nof non-model components, 343\u2013344\noverview of, 333\npublisher in, 297\nreview, 344\nseparating Subdomain from Core \nDomain, 48\nsize of Bounded Contexts and, 68\nSubdomains as ERP modules, 57\nTable module in Transaction Scripts, 441\nMoM (Message-oriented middleware)\npublished notifications, 317\u2013318\nSOA services and, 267\nMongoDB\nconcurrency and, 385\u2013386\nimplementing persistence-oriented \nrepository, 425\u2013430\npersistence-oriented repositories and, \n418\u2013420\nMSMQ, 547\nwww.EBooksWorld.ir\n", "page": 646, "type": "text", "section": "Page 646"}
{"text": "INDEX\n604\nMultichannel publishing, 325\nMutability Values, 221\nMutate(), 552\nMySQL\nauto-incrementing sequences, 180\u2013182\nBLOB persistence, 568\u2013569\nrelational persistence, 565\u2013567\nserialization of many Values into single \ncolumn, 254\u2013255\nValue Object persistence, 251\u2013253\nN\nNamespaces, C#, 333, 336\u2013337\nNaming conventions\nBounded Context model, 337\u2013339\nDomain Events, 289\nmodules, 336\u2013337\n.NET, implementation of Protocol Buffers, \n576\u2013577\nNewbie or junior developer, benefits of DDD \nto, 4\nNoSQL databases, 249, 418\nNotifications\nevent-carrying, 473\u2013476\npublished using messaging middleware, \n317\u2013318\npublishing as RESTful resources, 312\u2013317\npublishing message-based notifications, \n324\u2013329\npublishing the NotificationLog,\n319\u2013323\nas RESTful resource, 453\u2013457\nNServiceBus, 303\nO\nObject oriented languages, 403\nObject schizophrenia, 202\u2013203\nObject-relational mapping. See ORM (object-\nrelational mapping)\nObjects\ndomain objects with multiple roles, \n200\u2013205\nrendering domain objects, 512\u2013513\nvalidating object compositions, 215\u2013216\nvalidating whole Entities, 211\u2013215\nValue Objects. See Value Objects\nObserver pattern\ndata synchronization and, 147\nloose coupling in Layers Architecture, 120\nmultiparty activities, 364\npublishing Domain Events with, 296\nOHS. See Open Host Service (OHS)\nOnion architecture. See Hexagonal \nArchitecture\nOpen Host Service (OHS)\nBounded Context relationships, 93\u201394\nContext Maps and, 460\ndefined, 100\nLayers Architecture pattern and, 120\nservice-oriented components in Bounded \nContext, 67\nOpen Session In View (OSIV), 516\nOptimistic concurrency\nHibernate providing, 350\nLayer Supertype and, 380\nusage scenarios applied to Aggregate \ndesign, 373\u2013374\nversion attribute and, 385\u2013387\nOracle\nauto-incrementing sequences, 179\u2013180\nCoherence. See Coherence\nTopLink. See TopLink\nOrganizational patterns, 92\u201394\nOrganizational relationships, Context Maps \nand, 91\u201392\nORM (object-relational mapping)\nenum-as-state objects, 261\u2013263\nEvent Sourcing contrasted with, 162\nHibernate tool and. See Hibernate\nmany Values backed by database entity, \n255\u2013260\nmany Values backed by join table, 260\npersistence and, 249\nserialization of many Values into single \ncolumn, 253\u2013255\nsingle Value Objects, 251\u2013253\nOSGi bundles, 336\nOSIV (Open Session In View), 516\nP\nPackages, Java, 333, 336\u2013337\nParallel processing, 159\nPartner activities (Helland), 156\nPartnerships\nBounded Context relationships, 92\nreference by identity forming, 364\nPasswords\nencrypting, 269\u2013271\ntesting authentication service, 281\u2013284\nPerformance issues, Aggregates and Event \nSourcing (A+ES) and, 558\u2013561\nPermissions, centralizing in Identity and \nAccess Context, 80\u201381\nPersistence\nAggregates and Event Sourcing (A+ES) \nand, 558\nBLOB persistence, 568\u2013569\nin Infrastructure Layer, 122\nwww.EBooksWorld.ir\n", "page": 647, "type": "text", "section": "Page 647"}
{"text": " \nINDEX\n605\nRead Model Projections, 570\u2013572\nrelational persistence, 565\u2013567\nrepositories and, 401\nof Value Objects, 248\u2013249\nPersistence mechanisms\nfor dealing with concurrency, 350\ngenerating identity of Entities, 179\u2013182\nusing single transaction to manage \nconsistency, 354\nPersistence stores\ncollection-oriented repositories and, \n406\u2013407\ngenerating identity of Entities, 178\nmessaging infrastructure consistency and, \n304\nValue Objects and, 248\u2013250\nPersistence-oriented repositories\nCoherence implementation of, 420\u2013425\nMongoDB in implementation of, 425\u2013430\noverview of, 418\u2013420\nPipes and Filters\nbasic characteristics of, 150\u2013151\nEDA and, 118\nhow it works, 149\u2013150\nlong-running processes (sagas) and, \n153\u2013159\nmessage-based systems and, 149\nmessaging approach, 151\u2013152\nPL. See Published Language (PL)\nPolling models, 312\nPorts and Adapters architecture. See\nHexagonal Architecture\nPOST method, HTTP, 135, 458\nPower Types, modeling Standard Types as, 233\nPresentation Model\nLayers Architecture pattern and, 120\nrendition adapters and user edit handling, \n518\u2013521\nstate representation of domain objects, 516\nPrimitive types, Application Services and, \n522\u2013523\nPrinciple of least knowledge, 383\nPriorities, business, 230\u2013231\nProblem space\nassessing for Context Map, 96\u201397\nof domains, 56\u201358\nProcess state machines, 493\u2013503\nProcesses, long-running. See Long-running \nprocesses\nProduct owners\nresponsibilities and, 476\u2013481\nstaying informed about, 469\u2013476\nProject relationships, Context Maps and, \n91\u201392\nProperties\nDomain Events, 290\u2013291\nEntities, 208\u2013211\nValue Objects, 224\u2013225\nProtocol Buffers, 452, 576\u2013577\nPublished Language (PL)\nBounded Context relationships, 93\u201394\ncombining DDD and RESTful HTTP, \n137\ndefined, 100\ninformation exchange and, 453\nserializing Events as, 580\nPublishers, Domain Events, 297\u2013300\nPublishing Domain Events\nfrom Domain Model, 296\u2013297\nmessage-based notifications, 324\u2013329\nnotifications published as RESTful \nresources, 312\u2013317\nnotifications published using messaging \nmiddleware, 317\u2013318\noverview of, 289\npublishing the NotificationLog,\n319\u2013323\nPublish-Subscribe pattern\nevent notification and, 303\nintegration basics, 450\nmultiparty activities, 364\noverview of, 296\u2013297\npublisher, 297\u2013300\npull vs. push models, 312\nsubscriber, 300\u2013302\nPull model, Publish-Subscribe pattern, 312\nPush model, Publish-Subscribe pattern, 312\nput(), Coherence cache and, 424 \nPUT method, HTTP\napplying HTTP verbs to resources, 135\nRESTful notifications and, 458\nQ\nQuantifying characteristic, of Value Objects, \n221\nQueries\nAggregate Root query interface, 516\nCommand-Query Responsibility \nSegregation. See CQRS (Command-\nQuery Responsibility Segregation)\nCommand-Query Separation principle. \nSee CQS (Command-Query \nSeparation)\ncontinuous queries, 166\nquery performance as reason to break \nAggregate design rules, 369\u2013370\nrepositories and, 138\nuse case optimal query, 432, 517\nwww.EBooksWorld.ir\n", "page": 648, "type": "text", "section": "Page 648"}
{"text": "INDEX\n606\nQuery (read) model, in CQRS\nclient driving command processing, 143\ncommand processors, 143\u2013144\ndealing with inconsistency in, 146\u2013147\ndefined, 140\nevent subscriber updating query model, \n145\u2013146\noverview of, 141\u2013142\nQuery methods, 229\nQueues, implementing, 312\nR\nRabbitMQ\nabstraction layer around, 327\nEvent de-duplication, 329\u2013331\nFanout exchange, 317\nmessaging middleware, 303\nnotifications from, 471\u2013472\npublishing Events, 547\nRandom number generators, for unique \nidentifiers, 175\nRead (query) model, in CQRS. See Query \n(read) model, in CQRS\nRead Model Projections\npersistence and, 570\u2013572\nuse in Aggregate design, 573\nRealization view, Bounded Contexts and, 57\nReference by identity\nbetween Aggregates, 359\u2013361\npreferred by globally unique identity, \n361\u2013362\nscalability and distribution of Aggregates \nand, 363\u2013364\nRelational databases\nfor implementing Event Store, 543\npersistence and, 565\u2013567\nRelational persistence, 565\u2013567\nRelationships, Context Maps and, 90\nRelaxed Layers Architecture, 120\nRemote associations, reference by identity \nforming, 364\nRemote procedure calls. See RPCs (remote \nprocedure calls)\nremove(), Coherence cache and, 424\nRendition adapters, 518\u2013521\nReplaceability, of Value Objects, 226\u2013227\nReplication\ndata replication, 164\u2013165\nevent replication, 547\u2013548\nRepositories\naccessing repository instances in \nInfrastructure Layer, 121\u2013122\nadditional behaviors, 430\u2013432\nAnticorruption Layer (ACL) implemented \nvia, 101, 469\navoiding dependency injection and, 387\nin bad design example, 76\nCoherence in implementation of, 420\u2013425\ncollection-oriented, 402\u2013407\nData Access Objects compared with, \n440\u2013441\nHibernate in implementation of, 407\u2013415\nidentity generation and, 178\nmanaging transactions, 432\u2013437\nmodel navigation and, 362\u2013363\nMongoDB in implementation of, 425\u2013430\nnot accessing from Aggregate instances, \n266, 279\nobtaining Aggregate instances from, 121\noverview of, 401\u2013402\npersistence-oriented, 418\u2013420\nquerying, 138\nreading Aggregate instances and \ndelegating to DTO assemblers, \n513\u2013514\nreview, 448\ntesting, 129, 441\u2013445\ntesting with in-memory implementations, \n445\u2013447\nTopLink in implementation of, 416\u2013417\ntype hierarchies in, 437\u2013440\nResponsibility Layers, refactoring model and, \n77\nRepresentational State Transfer. See REST \n(Representational State Transfer)\nResponsibilities. See also Roles\navoiding, 481\u2013493\nintegrating Bounded Contexts and, \n476\u2013481\nof objects, 200\nSingle Responsibility principle, 270\u2013271\nteam members and product owners and, \n476\u2013481\nusing immutable Values results in less \nresponsibility, 232\u2013233\nREST (Representational State Transfer)\nas architectural style, 133\u2013134\ncreating/naming modules of non-model \ncomponents, 343\u2013344\nDDD and, 136\u2013138\nEvent Store feeding event notifications to \nclients, 307\u2013308\nin exchange of media between Bounded \nContexts, 453\u2013454\nHexagonal Architecture supporting, \n130\u2013132\nwww.EBooksWorld.ir\n", "page": 649, "type": "text", "section": "Page 649"}
{"text": " \nINDEX\n607\nHTTP clients, 136\nHTTP servers, 135\u2013136\nimplementing RESTful clients, 463\u2013469\nimplementing RESTful resources, \n459\u2013462\nIntegrating Bounded Contexts, 458\u2013459\nintegration basics, 450\npublishing Events as RESTful resources, \n312\u2013317\nservice-oriented components in Bounded \nContext, 67\nstate representation of domain objects, \n516\nRIA (rich Internet applications)\ndealing with multiple, disparate clients, \n517\nuser interfaces and, 512\nRiak\nBitcask model, 569\nconcurrency and, 385\u2013386\npersistence-oriented repositories and, \n418\u2013420\nRich Internet applications (RIA)\ndealing with multiple, disparate clients, \n517\nuser interfaces and, 512\nRoles\nassigning, 469\u2013471\ndomain objects with multiple, 200\u2013205\ndomain-specific, 463\nevent-carrying notification for, 473\u2013476\noverview of, 200\nresponsibilities and, 476\u2013481\nRoot Entity\nmany Aggregates containing only single \nEntity, 357\noptimistic concurrency and, 385\u2013386\nrequires globally unique identity, 177\nRPCs (remote procedure calls)\nautonomous services and systems, \n305\u2013306\nintegration basics, 450\u2013451\nOpen Host Service as, 100\nsystem integration and, 103\nsystem-level, 267\nRuby language\neffecting class namespaces, 333\npatching classes with specialized \nbehaviors, 225\u2013226\nS\nSaaS (software as a service), 40\u201341\nSagas. See Long-running processes\nsave()\nCoherence cache and, 423\npersistence-oriented repositories and, 418\nSave-like Repository method, 418\nScalability\nAggregate design and, 363\u2013364\nlimitations of single large-cluster \nAggregate, 356\nwith Domain Events, 287, 316, 322\nScrum\nAggregate models and, 348\nagile projects and, 82\u201383\nSecurity\nApplication Services and, 521\ncentralizing in Identity and Access \nContext, 80\u201381\nleveraging Spring Security, 525\u2013526\nSecurity patterns, 199\u2013200\nSegregated Core\ncreating, 77\u201378\nteam use of, 97\nSelf-delegation, 244, 248\nSelf-encapsulation, 248\nSenior developer, benefits of DDD to, 5\nSeparate Ways, Bounded Context \nrelationships, 93\u201394\nSeparated Interface\nimplementing REST client and, 464\nmodeling Domain Services and, 272\nnotification services and, 318\ntechnical implementations and, 275\u2013277\nSerialization\nof command objects, 550\nconversion between bytes and strongly \ntyped Event objects, 563\u2013564\nof events, 576\u2013577\ninformation exchange and, 452, 457\u2013458\nof many Values into single column, \n253\u2013255\nServers, RESTful HTTP servers, 135\u2013136\nService Factories\nfulfilling dependencies, 543\nlook up repository, 533\u2013534\nService-oriented ambiguity (Fowler), 131\nService-Oriented Architecture. See SOA \n(Service-Oriented Architecture)\nServices\nApplication Services. See Application \nServices\nauthentication services, 281\u2013284\nautonomous, 305\u2013306\nbusiness services, 66\u201368\ncode smells indicating need for, 265\nwww.EBooksWorld.ir\n", "page": 650, "type": "text", "section": "Page 650"}
{"text": "INDEX\n608\nServices (continued \n)\ncreating, 277\u2013280\ndesign principles for, 130\nDomain Services. See Domain Services\nfactories of, 276\u2013277, 397\u2013399\nnotification services, 318\nOHS. See Open Host Service (OHS)\nopening, 510\nSaaS (software as a service), 40\u201341\nsize of Bounded Contexts and, 68\nSOA. See SOA (Service-Oriented \nArchitecture)\nstateless, 268\ntactical modeling tools, 29\ntransactional services, 352\u2013353\nWeb services, 67\nSession\nas alternative to repository, 402\nHibernate, 407\nSession Facades, EJB (Enterprise JavaBeans), \n534\nSet collections, repositories mimicking, \n404\u2013406\nShallow copies, creating Value Objects, 244\nShared Kernel\nBounded Context relationships, 92\ncombining DDD and RESTful HTTP, 137\nContext Maps and, 460\ndeploying Value Objects in Commands \nand/or in Events, 580\ninformation exchange and, 452\u2013453\nSide-Effect-Free Functions\nEvent behaviors and, 294\nJava enum and, 236\nmodeling on identities, 194\nValue Objects and, 228\u2013232\nSimplification, benefits of DDD, 10\nSingle Responsibility, 143, 152, 270, 309\nsize(), for counting collection instances, \n430\u2013431\nSmart UI Anti-Pattern, 67\nSnapshots, of Aggregate state, 161\u2013162, \n559\u2013561\nSOA (Service-Oriented Architecture)\ndesign principles for services, 130\nexample of use of, 117\ngoals of DDD and, 132\u2013133\nHexagonal Architecture supporting, \n130\u2013131\nhow DDD helps, 10\nservices in, 267\nSOA manifesto and, 131\u2013132\nSOAP (Simple Object Access Protocol)\nAPIs made available with, 450\nHexagonal Architecture supporting, \n130\u2013132\nservice-oriented components in Bounded \nContext, 67\u201368\nSoftware\ndomain experts contributing to design, 27\nwith true business value, 9\u201310\nSoftware as a service (SaaS), 40\u201341\nSolution space\nassessment of, 59\u201360\nof domains, 56\u201358\nSophistication of design, integrating Bounded \nContexts, 503\u2013507\nSpecifications, 582\u2013583\nSpring\nenterprise component containers, \n534\u2013537\ninversion-of-control containers, 434\u2013437\nleveraging Spring Security, 525\u2013526\nStandard Types\nAgile Project Management Context and, \n108\nconsuming remote, 233\nexpressed as Values, 234\u2013235, 238\u2013239\nJava enum for supporting, 235\u2013238\ntype hierarchies and, 439\u2013440\nState\nmediators publishing internal state of \nAggregates, 514\u2013515\npersisting enum-as-state objects, 261\u2013263\nrepresenting state of Aggregate instances, \n516\u2013517\nState pattern\ndisadvantages of, 237\nStandard Type as, 236\u2013237, 440\nStateless services, 268\nStatic methods, Domain Services as \nalternative to, 278\nStorage. See Repositories\nStory points, as alternative to estimating task \nhours, 375\nStrategic business initiatives, 9\u201310\nStrategic design\naligning Subdomains with Bounded \nContexts, 57\nalignment with the DDD community, \n55\u201356\nbig picture of, 44\u201352\ncutting through complexity, 46\nessential nature of, 53\u201356\nwww.EBooksWorld.ir\n", "page": 651, "type": "text", "section": "Page 651"}
{"text": " \nINDEX\n609\nfocusing on Core Domain, 50-52\nGeneric Subdomains, 52\nidentifying multiple Subdomains in one \nBounded Context, 49\u201352, 57\u201358\nproblem and solution space, 56\u201357\nSupporting Subdomains, 52\nunderstanding Bounded Contexts, 62\u201372\nunderstanding Subdomains, 44\u201350\nusing to refactor problem code, 76\u201379\nvision of Core Domain, 58\nwhen dealing with a Big Ball of Mud, 55, \n57\nwhen doing greenfield development, \n72\u201373\nwith Context Maps, 50, 95\u2013110\nStrategic tools, benefits of DDD, 28\u201329\nStrategy pattern\nDDR (Domain Dependency Resolver) \nand, 516\nusing Value type as, 243\u2013244\nStrict Layers Architecture, 120\nStructural freedom, with Aggregates and \nEvent Sourcing (A+ES), 558\nSubdomains\nabstract business domain and, 50\nalignment with Bounded Contexts, 57, 60\ndistinguishing between types of domains, \n44\nin e-Commerce example, 48\u201350\nhow to use, 44\u201345\nmapping three contexts, 96\nmodules and, 48\nproblem space and, 56\npublishing Events to, 302\nseparating by functionality, 46\nSupporting Subdomains. See Supporting \nSubdomains\ntactical modeling and, 35\ntypes of, 52\nwhiteboard illustration of, 51\nSubscribers\nDomain Events and, 300\u2013302\npublishing notifications using messaging \nmiddleware, 317\nSupervising Controller and Passive View \n(Fowler), 518\nSupporting Subdomains\napplication support in, 509\nassessment of problem space and solution \nspace, 58\nContext Maps and, 98\ndefined, 52\ninvesting in what produces biggest \nbenefit, 10\njustification for Domain Models, 35\nfor SaaS Ovation Domain Model, 91\nSurrogate identities\nEntities and, 186\u2013188\nLayer Supertype and, 255\u2013256, 380\nwhen persisting Value Objects, 255\u2013260\nSymmetry style. See Hexagonal Architecture\nSystems. See also Applications\nBounded Context encompassing more \nthan Domain Model, 66\u201368\nContext Maps are not system topology \ndiagrams, 90\ndecoupling service from client, 550\nexchanging information across system \nboundaries, 452\u2013458\nT\nTable Data Gateway, in Transaction Scripts, \n441\nTable Module, in Transaction Scripts, 441\nTactical modeling\nstrategic modeling compared with, 34\nUbiquitous Language and, 75\nTactical patterns, 36\nTactical tools, 10, 28\u201329\nTask hours, used to estimate of memory \noverhead of Aggregate type, 372\u2013373\nTeam members\nbenefits of asking whose job it is in \nAggregate design, 378\u2013379\nresponsibilities and, 476\u2013481\nstaying informed about, 469\u2013476\nTeams\nestimating Aggregate type memory \noverhead using in task hours, 372\u2013373\nfacilitating inter-team communication, \n88\nsingle team for single Bounded Context, \n72\nUbiquitous Language as shared language \nof, 20\u201321\nTechnical components\nalignment with Bounded Contexts, 71\u201372\nhousing in Infrastructure Layer, 273\nreasons to break Aggregate design rules, \n368\u2013369\nTell, Don\u2019t Ask, information hiding in \nAggregate implementation, 382\u2013384\nTemporal decoupling, between clients and \nApplication Service, 551\nwww.EBooksWorld.ir\n", "page": 652, "type": "text", "section": "Page 652"}
{"text": "INDEX\n610\nTenants\ncomparing with Users, 192\u2013193\nsubscribing organizations registered as, \n348\nUUID applied to identifying, 194\nTests/testing\nDomain Services, 281\u2013284\nHexagonal Architecture and, 129\nrepositories, 441\u2013445\nrepositories with in-memory \nimplementations, 445\u2013447\ntest-first approach, 37\u201338\nunit tests, 582\u2013583\nValue Objects, 239\u2013243\nTextual descriptions, at User Interface Layer, \n236\nTheta joins, 363\nTilkov, Stefan, 133\nTime-demands, challenges of applying DDD, \n29\nTimelessness, Hexagonal Architecture \nsupporting, 125\nTimeline, justification for domain modeling, \n36\nTime-out trackers, integrating Bounded \nContexts, 493\u2013503\nTime-sensitivity\nof identity generation, 183\u2013186\nlong-running processes (sagas) and, 158\nTopLink\nimplementing repository for, 416\u2013417\nUnit of Work in, 407\nTrack changes\nto Entities, 216\u2013217\npersistence mechanisms and, 406\u2013407\nTrackers, merging executives and trackers \ninto Aggregates, 156\nTrain wreck, 76\nTransaction Script\njustification for domain modeling, 36\u201337\nmodeling Core Domain, 532\npatterns used in, 441\nTransactional consistency\nAggregates and, 364\nvs. eventual consistency, 366\u2013367\ninvariants and, 353\u2013354\nTransactional consistency boundary. See\nAggregates\nTransactions, managing in repositories, \n432\u2013437\nTransformation services, 280\nTransformations, uses of Domain Services, \n268\nTranslations, drawing Context Maps and, 90\nTranslators\nDomain Services use for integration, 280\nimplementing REST client and, 465\u2013467\nTwo-party activities, 364\nTypes\nchecking static types, 578\ncreating explicitly named immutable \ntypes, 577\u2013578\nhierarchies in repositories, 437\u2013440\ninformation exchange and type safety, \n452\u2013453\nprimitive, 522\u2013523\nstandard. See Standard Types\nU\nUbiquitous Language\nBusinessPriority, 240\ncollaboration and, 53\u201354, 74\ndesigning Domain Model and, 191\ndomain experts and developers jointly \ndeveloping, 9\nEntities properties and, 197\u2013198\nEvent-centric approach to Aggregate \ndesign and, 540\nFactory Method and, 390\nIntention Revealing Interface complying \nwith, 197\nmodule naming conventions and, 338\nnaming object behaviors and, 31\u201332\nprinciples, 24\u201325\nprocess of producing, 3\nrefining, 23\u201324\nScrum terminology as starting point, 348\nShared Kernel and, 92\nas shared team language, 20\u201321\nSOA causing fragmentation of, 132\nsolution space and, 59\ntechniques for capturing, 22\u201323\nUML (Unified Modeling Language)\nof Application Services, 533\nDIP (Dependency Inversion Principle) \nrepresentation in, 510\u2013511\ntechniques for developing Ubiquitous \nLanguage, 22\nUnique identity, of Entities, 173\u2013174\nUnit of Work\nas alternative to repository, 402\nfor handling transactions, 354\nin TopLink, 407\nUnit tests, 582\u2013583\nUniversally unique identifiers. See UUIDs \n(universally unique identifiers)\nwww.EBooksWorld.ir\n", "page": 653, "type": "text", "section": "Page 653"}
{"text": " \nINDEX\n611\nUpstream models, influencing downstream, \n99\u2013100\nURIs\nintegration of Bounded Contexts using \nRESTful resources, 458\u2013459\nmedia types and, 104\u2013105\nresources and, 135\nUsage scenarios\nadjusting Aggregate design, 375\u2013376\napplying to Aggregate design, 373\u2013374\nUse case optimal queries, 517\nUse case optimal query, 432\nUse cases\nAggregate design and, 358\u2013359\nCreate a Product use case, 481\u2013482\ndetermining whose job it is, 367\nUser Entity\ncomparing with Tenants, 192\u2013193\nUUID applied to identifying, 195\u2013196\nUser Interface Layer\ncreating and naming modules of non-\nmodel components, 343\u2013344\nDIP (Dependency Inversion Principle) \nand, 124\nFacade business method invoked by, 433\nin Layers Architecture, 119\ntextual descriptions and, 236\nviews in Bounded Context, 67\nUser interfaces\ndealing with multiple, disparate clients, \n517\u2013518\neventual consistency and, 377\u2013378\nmediators publishing internal state of \nAggregates, 514\u2013515\noverview of, 512\nreasons to break Aggregate design rules, \n367\u2013368\nrendering Aggregate instances from \nDomain Payload Objects, 515\u2013516\nrendering data transfer objects from \nAggregate instances, 513\u2013514\nrendering domain objects, 512\u2013513\nrendition adapters and user edit handling, \n518\u2013521\nrepresenting state of Aggregate instances, \n516\u2013517\nviews impacted by references by identity, \n363\nWeb user interfaces, 512\nUser pattern, security patterns, 199\u2013200\nUser-aggregate affinity rule, 369\nUsers\nhandling user edits, 518\u2013521\nimprovements in user experience due to \nDDD, 27\u201328\nproviding identity of Entities, 174\u2013175\nUtilities, patching in, 552\u2013553\nUUIDs (universally unique identifiers)\nassigning to processes, 156\nassigning to Tenants, 194\u2013195\nassigning to Users, 195\u2013196\ncreating Aggregate Root Entity with \nunique identity, 381\nidentity creation patterns and, 175\u2013177\nV\nValidating Entities\nattributes and properties, 208\u2013211\nobject compositions, 215\u2013216\nwhole objects, 211\u2013215\nValue Objects\nAgile Project Management Context and, \n108\u2013109\nbacked by database entity (ORM), \n255\u2013260\nbacked by join table (ORM), 260\ncharacteristics of Values, 221\nclustering into Aggregates, 347\nconceptual wholeness of, 223\u2013226\nData Model Leakage and, 249\u2013251\ndeveloper focus on, 53\nin development of Domain Models, \n577\u2013580\ndistinguishing Entities from, 172\nenum-as-state objects (ORM), 261\u2013263\nequality of, 227\u2013228\nimmutability of, 221\u2013223\nimplementing, 243\u2013248\nintegration based on prioritizing or \nminimalism, 232\u2013233\nJava enum for supporting Standard Type, \n235\u2013238\nmeasuring, quantifying, describing, 221\nnot everything is a Value Object, 232\noverview of, 219\u2013220\npersisting, 248\u2013249\npreferred over Entities when possible, 382\nrefactoring Entities as, 357\nreplaceability of, 226\u2013227\nreview, 263\nserialization of many Values into single \ncolumn (ORM), 253\u2013255\nside-effect-free behavior, 228\u2013232\nsingle Value Objects (ORM), 251\u2013253\nStandard Types expressed as, 234\u2013235, \n238\u2013239\nwww.EBooksWorld.ir\n", "page": 654, "type": "text", "section": "Page 654"}
{"text": "INDEX\n612\nValue Objects (continued \n)\ntactical modeling tools, 29\ntesting, 239\u2013243\nunique identity and, 173\nuse case optimal query, 432, 517\nVerbs, HTTP, 135\nversion attribute, optimistic concurrency \nand, 385\u2013387\nView Model, state representation of domain \nobjects, 516\nViews, mapping domain data to. See CQRS \n(Command-Query Responsibility \nSegregation)\nVision documents, Ubiquitous Language in, 27\nVisual Basic, historical influence on Anemic \nDomain Model, 14\u201315\nVMware GemFire. See GemFire\nW\nWeb protocols, 134\u2013135\nWeb services, service-oriented components in \nBounded Context, 67\nWeb user interfaces, 512\nWebber, Jim, 317\nWhiteboard\ndrawing Context Maps, 90\nillustration of Core Domain, 52\nillustration of Subdomain, 51\nWhole Value pattern, 223, 357\nWilliams, Wes, 163\nX\nXML\npublished language and, 100\nstandard intermediate formats for \ninformation exchange, 452\nY\nYAGNI (\"You Ain\u2019t Gonna Need It\") \nprinciple, 514\nYoung, Greg, 539\nZ\nZero-argument constructors, 248\nwww.EBooksWorld.ir\n", "page": 655, "type": "text", "section": "Page 655"}
{"text": "* Available to new subscribers only. Discount applies to the Safari Library and is valid for m\n rst \n12 consecutive monthly billing cycles. Safari Library is not available in all countries.\nTry Safari Books Online FREE for 15 days\nGet online access to Thousands of Books and Videos\nFREE 15-DAY TRIAL + 15% OFF*\ninformit.com/safaritrial\nFeed your brain\nGain unlimited access to thousands of books and videos about technology, \ndigital media and professional development from O\u2019Reilly Media, \nAddison-Wesley, Microsoft Press, Cisco Press, McGraw Hill, Wiley, WROX, \nPrentice Hall, Que, Sams, Apress, Adobe Press and other top publishers.\nSee it, believe it\nWatch hundreds of expert-led instructional videos on today\u2019s hottest topics.\nWAIT, THERE\u2019S MORE!\nGain a competitive edge\nBe first to learn about the newest technologies and subjects with Rough Cuts \npre-published manuscripts and new technology overviews in Short Cuts.\nAccelerate your project\nCopy and paste code, create smart searches that let you know when new \nbooks about your favorite topics are available, and customize your library \nwith favorites, highlights, tags, notes, mash-ups and more.\nwww.EBooksWorld.ir\n", "page": 656, "type": "text", "section": "Page 656"}
{"text": "Activate your FREE Online Edition at \ninformit.com/safarifree\nSTEP 1: \n \nEnter the coupon code: VUQLOGA.\nSTEP 2: \n \nNew Safari users, complete the brief registration form. \nSafari subscribers, just log in.\nIf you have diffi\n culty registering on Safari or accessing the online edition, \nplease e-mail customer-service@safaribooksonline.com\nYour purchase of Implementing Domain-Driven Design includes access to a free online \nedition for 45 days through the Safari Books Online subscription service. Nearly every \nAddison-Wesley Professional book is available online through Safari Books Online, along with \nthousands of books and videos from publishers such as Cisco Press, Exam Cram, IBM Press, \nO\u2019Reilly Media, Prentice Hall, Que, Sams, and VMware Press. \nSafari Books Online is a digital library providing searchable, on-demand access to thousands \nof technology, digital media, and professional development books and videos from leading \npublishers. With one monthly or yearly subscription price, you get unlimited access to learning \ntools and information on topics including mobile app and software development, tips and tricks \non using your favorite gadgets, networking, project management, graphic design, and much \nmore.\nFREE \nOnline Edition\nwww.EBooksWorld.ir\n", "page": 657, "type": "text", "section": "Page 657"}
