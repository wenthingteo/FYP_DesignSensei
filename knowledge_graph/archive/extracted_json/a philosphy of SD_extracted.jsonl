{"text": "A Philosophy of Software Design\nJohn Ousterhout\nStanford University\n", "page": 2, "type": "text", "section": "Page 2"}
{"text": "A Philosophy of Software Design\nby John Ousterhout\nCopyright \u00a9 2018 John K. Ousterhout.\nAll rights reserved. No part of this book may be reproduced, in any form or by any means, without\npermission in writing from the author.\nPublished by Yaknyam Press, Palo Alto, CA.\nCover design by Pete Nguyen and Shirin Oreizy (www.hellonextstep.com).\nPrinting History:\nApril 2018:                First Edition (v1.0)\nNovember 2018:        First Edition (v1.01)\nISBN 978-1-7321022-0-0\nDigital book(s) (epub and mobi) produced by Booknook.biz.\n", "page": 3, "type": "text", "section": "Page 3"}
{"text": "Contents\nPreface\n1    Introduction\n1.1       How to use this book\n2    The Nature of Complexity\n2.1       Complexity defined\n2.2       Symptoms of complexity\n2.3       Causes of complexity\n2.4       Complexity is incremental\n2.5       Conclusion\n3    Working Code Isn\u2019t Enough\n3.1       Tactical programming\n3.2       Strategic programming\n3.3       How much to invest?\n3.4       Startups and investment\n3.5       Conclusion\n4    Modules Should Be Deep\n4.1       Modular design\n4.2       What\u2019s in an interface?\n4.3       Abstractions\n4.4       Deep modules\n4.5       Shallow modules\n4.6       Classitis\n4.7       Examples: Java and Unix I/O\n4.8       Conclusion\n5    Information Hiding (and Leakage)\n", "page": 4, "type": "text", "section": "Page 4"}
{"text": "5.1       Information hiding\n5.2       Information leakage\n5.3       Temporal decomposition\n5.4       Example: HTTP server\n5.5       Example: too many classes\n5.6       Example: HTTP parameter handling\n5.7       Example: defaults in HTTP responses\n5.8       Information hiding within a class\n5.9       Taking it too far\n5.10      Conclusion\n6    General-Purpose Modules are Deeper\n6.1       Make classes somewhat general-purpose\n6.2       Example: storing text for an editor\n6.3       A more general-purpose API\n6.4       Generality leads to better information hiding\n6.5       Questions to ask yourself\n6.6       Conclusion\n7    Different Layer, Different Abstraction\n7.1       Pass-through methods\n7.2       When is interface duplication OK?\n7.3       Decorators\n7.4       Interface versus implementation\n7.5       Pass-through variables\n7.6       Conclusion\n8    Pull Complexity Downwards\n8.1       Example: editor text class\n8.2       Example: configuration parameters\n8.3       Taking it too far\n8.4       Conclusion\n9    Better Together Or Better Apart?\n9.1       Bring together if information is shared\n", "page": 5, "type": "text", "section": "Page 5"}
{"text": "9.2       Bring together if it will simplify the interface\n9.3       Bring together to eliminate duplication\n9.4       Separate general-purpose and special-purpose code\n9.5       Example: insertion cursor and selection\n9.6       Example: separate class for logging\n9.7       Example: editor undo mechanism\n9.8       Splitting and joining methods\n9.9       Conclusion\n10  Define Errors Out Of Existence\n10.1     Why exceptions add complexity\n10.2     Too many exceptions\n10.3     Define errors out of existence\n10.4     Example: file deletion in Windows\n10.5     Example: Java substring method\n10.6     Mask exceptions\n10.7     Exception aggregation\n10.8     Just crash?\n10.9     Design special cases out of existence\n10.10   Taking it too far\n10.11   Conclusion\n11  Design it Twice\n12  Why Write Comments? The Four Excuses\n12.1     Good code is self-documenting\n12.2     I don\u2019t have time to write comments\n12.3     Comments get out of date and become misleading\n12.4     All the comments I have seen are worthless\n12.5     Benefits of well-written comments\n13  Comments Should Describe Things that Aren\u2019t Obvious from the Code\n13.1     Pick conventions\n13.2     Don\u2019t repeat the code\n13.3     Lower-level comments add precision\n", "page": 6, "type": "text", "section": "Page 6"}
{"text": "13.4     Higher-level comments enhance intuition\n13.5     Interface documentation\n13.6     Implementation comments: what and why, not how\n13.7     Cross-module design decisions\n13.8     Conclusion\n13.9     Answers to questions from Section 13.5\n14  Choosing Names\n14.1     Example: bad names cause bugs\n14.2     Create an image\n14.3     Names should be precise\n14.4     Use names consistently\n14.5     A different opinion: Go style guide\n14.6     Conclusion\n15  Write The Comments First\n15.1     Delayed comments are bad comments\n15.2     Write the comments first\n15.3     Comments are a design tool\n15.4     Early comments are fun comments\n15.5     Are early comments expensive?\n15.6     Conclusion\n16  Modifying Existing Code\n16.1     Stay strategic\n16.2     Maintaining comments: keep the comments near the code\n16.3     Comments belong in the code, not the commit log\n16.4     Maintaining comments: avoid duplication\n16.5     Maintaining comments: check the diffs\n16.6     Higher-level comments are easier to maintain\n17  Consistency\n17.1     Examples of consistency\n17.2     Ensuring consistency\n17.3     Taking it too far\n", "page": 7, "type": "text", "section": "Page 7"}
{"text": "17.4     Conclusion\n18  Code Should be Obvious\n18.1     Things that make code more obvious\n18.2     Things that make code less obvious\n18.3     Conclusion\n19  Software Trends\n19.1     Object-oriented programming and inheritance\n19.2     Agile development\n19.3     Unit tests\n19.4     Test-driven development\n19.5     Design patterns\n19.6     Getters and setters\n19.7     Conclusion\n20  Designing for Performance\n20.1     How to think about performance\n20.2     Measure before modifying\n20.3     Design around the critical path\n20.4     An example: RAMCloud Buffers\n20.5     Conclusion\n21  Conclusion\nIndex\nSummary of Design Principles\nSummary of Red Flags\n", "page": 8, "type": "text", "section": "Page 8"}
{"text": "Preface\nPeople have been writing programs for electronic computers for more than 80\nyears, but there has been surprisingly little conversation about how to design\nthose programs or what good programs should look like. There has been\nconsiderable discussion about software development processes such as agile\ndevelopment and about development tools such as debuggers, version control\nsystems, and test coverage tools. There has also been extensive analysis of\nprogramming techniques such as object-oriented programming and functional\nprogramming, and of design patterns and algorithms. All of these discussions\nhave been valuable, but the core problem of software design is still largely\nuntouched. David Parnas\u2019 classic paper \u201cOn the Criteria to be used in\nDecomposing Systems into Modules\u201d appeared in 1971, but the state of the art in\nsoftware design has not progressed much beyond that paper in the ensuing 45\nyears.\nThe most fundamental problem in computer science is problem\ndecomposition: how to take a complex problem and divide it up into pieces that\ncan be solved independently. Problem decomposition is the central design task\nthat programmers face every day, and yet, other than the work described here, I\nhave not been able to identify a single class in any university where problem\ndecomposition is a central topic. We teach for loops and object-oriented\nprogramming, but not software design.\nIn addition, there is a huge variation in quality and productivity among\nprogrammers, but we have made little attempt to understand what makes the best\nprogrammers so much better or to teach those skills in our classes. I have talked\nwith several people I consider to be great programmers, but most of them had\ndifficulty articulating specific techniques that give them their advantage. Many\npeople assume that software design skill is an innate talent that cannot be taught.\nHowever, there is quite a bit of scientific evidence that outstanding performance\nin many fields is related more to high-quality practice than innate ability (see, for\nexample, Talent is Overrated by Geoff Colvin).\nFor many years these issues have perplexed and frustrated me. I have\nwondered whether software design can be taught, and I have hypothesized that\n", "page": 9, "type": "text", "section": "Page 9"}
{"text": "design skill is what separates great programmers from average ones. I finally\ndecided that the only way to answer these questions was to attempt to teach a\ncourse on software design. The result is CS 190 at Stanford University. In this\nclass I put forth a set of principles of software design. Students then work\nthrough a series of projects to assimilate and practice the principles. The class is\ntaught in a fashion similar to a traditional English writing class. In an English\nclass, students use an iterative process where they write a draft, get feedback, and\nthen rewrite to make improvements. In CS 190, students develop a substantial\npiece of software from scratch. We then go through extensive code reviews to\nidentify design problems, and students revise their projects to fix the problems.\nThis allows students to see how their code can be improved by applying design\nprinciples.\nI have now taught the software design class three times, and this book is\nbased on the design principles that emerged from the class. The principles are\nfairly high level and border on the philosophical (\u201cDefine errors out of\nexistence\u201d), so it is hard for students to understand the ideas in the abstract.\nStudents learn best by writing code, making mistakes, and then seeing how their\nmistakes and the subsequent fixes relate to the principles.\nAt this point you may well be wondering: what makes me think I know all\nthe answers about software design? To be honest, I don\u2019t. There were no classes\non software design when I learned to program, and I never had a mentor to teach\nme design principles. At the time I learned to program, code reviews were\nvirtually nonexistent. My ideas about software design come from personal\nexperience writing and reading code. Over my career I have written about\n250,000 lines of code in a variety of languages. I\u2019ve worked on teams that\ncreated three operating systems from scratch, multiple file and storage systems,\ninfrastructure tools such as debuggers, build systems, and GUI toolkits, a\nscripting language, and interactive editors for text, drawings, presentations, and\nintegrated circuits. Along the way I\u2019ve experienced firsthand the problems of\nlarge systems and experimented with various design techniques. In addition, I\u2019ve\nread a considerable amount of code written by other people, which has exposed\nme to a variety of approaches, both good and bad.\nOut of all of this experience, I\u2019ve tried to extract common threads, both about\nmistakes to avoid and techniques to use. This book is a reflection of my\nexperiences: every problem described here is one that I have experienced\n", "page": 10, "type": "text", "section": "Page 10"}
{"text": "personally, and every suggested technique is one that I have used successfully in\nmy own coding.\nI don\u2019t expect this book to be the final word on software design; I\u2019m sure\nthere are valuable techniques that I\u2019ve missed, and some of my suggestions may\nturn out to be bad ideas in the long run. However, I hope that the book will start a\nconversation about software design. Compare the ideas in this book with your\nown experiences and decide for yourself whether the approaches described here\nreally do reduce software complexity. This book is an opinion piece, so some\nreaders will disagree with some of my suggestions. If you do disagree, try to\nunderstand why. I\u2019m interested in hearing about things that work for you, things\nthat don\u2019t work, and any other ideas you may have about software design. I hope\nthat the ensuing conversations will improve our collective understanding of\nsoftware design. I will incorporate what I learn in future editions of this book.\nThe best way to communicate with me about the book is to send email to the\nfollowing address:\nsoftware-design-book@googlegroups.com\nI\u2019m interested in hearing specific feedback about the book, such as bugs or\nsuggestions for improvement, as well as general thoughts and experiences related\nto software design. I\u2019m particularly interested in compelling examples that I can\nuse in future editions of the book. The best examples illustrate an important\ndesign principle and are simple enough to explain in a paragraph or two. If you\nwould like to see what other people are saying on the email address and\nparticipate in discussions, you can join the Google Group software-design-book.\nIf for some reason the software-design-book Google Group should disappear\nin the future, search on the Web for my home page; it will contain updated\ninstructions for how to communicate about the book. Please don\u2019t send book-\nrelated email to my personal email address.\nI recommend that you take the suggestions in this book with a grain of salt.\nThe overall goal is to reduce complexity; this is more important than any\nparticular principle or idea you read here. If you try an idea from this book and\nfind that it doesn\u2019t actually reduce complexity, then don\u2019t feel obligated to keep\nusing it (but, do let me know about your experience; I\u2019d like to get feedback on\nwhat works and what doesn\u2019t).\nMany people have offered criticisms or made suggestions that improved the\n", "page": 11, "type": "text", "section": "Page 11"}
{"text": "Many people have offered criticisms or made suggestions that improved the\nquality of the book. The following people offered helpful comments on various\ndrafts of the book: Jeff Dean, Sanjay Ghemawat, John Hartman, Brian\nKernighan, James Koppel, Amy Ousterhout, Kay Ousterhout, Rob Pike, Partha\nRanganathan, Keith Schwartz, and Alex Snaps. Christos Kozyrakis suggested the\nterms \u201cdeep\u201d and \u201cshallow\u201d for classes and interfaces, replacing previous terms\n\u201cthick\u201d and \u201cthin\u201d, which were somewhat ambiguous. I am indebted to the\nstudents in CS 190; the process of reading their code and discussing it with them\nhas helped to crystallize my thoughts about design.\n", "page": 12, "type": "text", "section": "Page 12"}
{"text": "Chapter 1\nIntroduction\n(It\u2019s All About Complexity)\nWriting computer software is one of the purest creative activities in the\nhistory of the human race. Programmers aren\u2019t bound by practical limitations\nsuch as the laws of physics; we can create exciting virtual worlds with behaviors\nthat could never exist in the real world. Programming doesn\u2019t require great\nphysical skill or coordination, like ballet or basketball. All programming requires\nis a creative mind and the ability to organize your thoughts. If you can visualize a\nsystem, you can probably implement it in a computer program.\nThis means that the greatest limitation in writing software is our ability to\nunderstand the systems we are creating. As a program evolves and acquires more\nfeatures, it becomes complicated, with subtle dependencies between its\ncomponents. Over time, complexity accumulates, and it becomes harder and\nharder for programmers to keep all of the relevant factors in their minds as they\nmodify the system. This slows down development and leads to bugs, which slow\ndevelopment even more and add to its cost. Complexity increases inevitably over\nthe life of any program. The larger the program, and the more people that work\non it, the more difficult it is to manage complexity.\nGood development tools can help us deal with complexity, and many great\ntools have been created over the last several decades. But there is a limit to what\nwe can do with tools alone. If we want to make it easier to write software, so that\nwe can build more powerful systems more cheaply, we must find ways to make\nsoftware simpler. Complexity will still increase over time, in spite of our best\nefforts, but simpler designs allow us to build larger and more powerful systems\nbefore complexity becomes overwhelming.\nThere are two general approaches to fighting complexity, both of which will\nbe discussed in this book. The first approach is to eliminate complexity by\n", "page": 13, "type": "text", "section": "Page 13"}
{"text": "making code simpler and more obvious. For example, complexity can be reduced\nby eliminating special cases or using identifiers in a consistent fashion.\nThe second approach to complexity is to encapsulate it, so that programmers\ncan work on a system without being exposed to all of its complexity at once. This\napproach is called modular design. In modular design, a software system is\ndivided up into modules, such as classes in an object-oriented language. The\nmodules are designed to be relatively independent of each other, so that a\nprogrammer can work on one module without having to understand the details of\nother modules.\nBecause software is so malleable, software design is a continuous process\nthat spans the entire lifecycle of a software system; this makes software design\ndifferent from the design of physical systems such as buildings, ships, or bridges.\nHowever, software design has not always been viewed this way. For much of the\nhistory of programming, design was concentrated at the beginning of a project,\nas it is in other engineering disciplines. The extreme of this approach is called\nthe waterfall model, in which a project is divided into discrete phases such as\nrequirements definition, design, coding, testing, and maintenance. In the\nwaterfall model, each phase completes before the next phase starts; in many\ncases different people are responsible for each phase. The entire system is\ndesigned at once, during the design phase. The design is frozen at the end of this\nphase, and the role of the subsequent phases is to flesh out and implement that\ndesign.\nUnfortunately, the waterfall model rarely works well for software. Software\nsystems are intrinsically more complex than physical systems; it isn\u2019t possible to\nvisualize the design for a large software system well enough to understand all of\nits implications before building anything. As a result, the initial design will have\nmany problems. The problems do not become apparent until implementation is\nwell underway. However, the waterfall model is not structured to accommodate\nmajor design changes at this point (for example, the designers may have moved\non to other projects). Thus, developers try to patch around the problems without\nchanging the overall design. This results in an explosion of complexity.\nBecause of these issues, most software development projects today use an\nincremental approach such as agile development, in which the initial design\nfocuses on a small subset of the overall functionality. This subset is designed,\nimplemented, and then evaluated. Problems with the original design are\ndiscovered and corrected, then a few more features are designed, implemented\n", "page": 14, "type": "text", "section": "Page 14"}
{"text": "and evaluated. Each iteration exposes problems with the existing design, which\nare fixed before the next set of features is designed. By spreading out the design\nin this way, problems with the initial design can be fixed while the system is still\nsmall; later features benefit from experience gained during the implementation of\nearlier features, so they have fewer problems.\nThe incremental approach works for software because software is malleable\nenough to allow significant design changes partway through implementation. In\ncontrast, major design changes are much more challenging for physical systems:\nfor example, it would not be practical to change the number of towers supporting\na bridge in the middle of construction.\nIncremental development means that software design is never done. Design\nhappens continuously over the life of a system: developers should always be\nthinking about design issues. Incremental development also means continuous\nredesign. The initial design for a system or component is almost never the best\none; experience inevitably shows better ways to do things. As a software\ndeveloper, you should always be on the lookout for opportunities to improve the\ndesign of the system you are working on, and you should plan on spending some\nfraction of your time on design improvements.\nIf software developers should always be thinking about design issues, and\nreducing complexity is the most important element of software design, then\nsoftware developers should always be thinking about complexity. This book is\nabout how to use complexity to guide the design of software throughout its\nlifetime.\nThis book has two overall goals. The first is to describe the nature of\nsoftware complexity: what does \u201ccomplexity\u201d mean, why does it matter, and how\ncan you recognize when a program has unnecessary complexity? The book\u2019s\nsecond, and more challenging, goal is to present techniques you can use during\nthe software development process to minimize complexity. Unfortunately, there\nisn\u2019t a simple recipe that will guarantee great software designs. Instead, I will\npresent a collection of higher-level concepts that border on the philosophical,\nsuch as \u201cclasses should be deep\u201d or \u201cdefine errors out of existence.\u201d These\nconcepts may not immediately identify the best design, but you can use them to\ncompare design alternatives and guide your exploration of the design space.\n1.1    How to use this book\nMany of the design principles described here are somewhat abstract, so they may\n", "page": 15, "type": "text", "section": "Page 15"}
{"text": "Many of the design principles described here are somewhat abstract, so they may\nbe hard to appreciate without looking at actual code. It has been a challenge to\nfind examples that are small enough to include in the book, yet large enough to\nillustrate problems with real systems (if you encounter good examples, please\nsend them to me). Thus, this book may not be sufficient by itself for you to learn\nhow to apply the principles.\nThe best way to use this book is in conjunction with code reviews. When you\nread other people\u2019s code, think about whether it conforms to the concepts\ndiscussed here and how that relates to the complexity of the code. It\u2019s easier to\nsee design problems in someone else\u2019s code than your own. You can use the red\nflags described here to identify problems and suggest improvements. Reviewing\ncode will also expose you to new design approaches and programming\ntechniques.\nOne of the best ways to improve your design skills is to learn to recognize red\nflags: signs that a piece of code is probably more complicated than it needs to be.\nOver the course of this book I will point out red flags that suggest problems\nrelated to each major design issue; the most important ones are summarized at\nthe back of the book. You can then use these when you are coding: when you see\na red flag, stop and look for an alternate design that eliminates the problem.\nWhen you first try this approach, you may have to try several design alternatives\nbefore you find one that eliminates the red flag. Don\u2019t give up easily: the more\nalternatives you try before fixing the problem, the more you will learn. Over\ntime, you will find that your code has fewer and fewer red flags, and your designs\nare cleaner and cleaner. Your experience will also show you other red flags that\nyou can use to identify design problems (I\u2019d be happy to hear about these).\nWhen applying the ideas from this book, it\u2019s important to use moderation and\ndiscretion. Every rule has its exceptions, and every principle has its limits. If you\ntake any design idea to its extreme, you will probably end up in a bad place.\nBeautiful designs reflect a balance between competing ideas and approaches.\nSeveral chapters have sections titled \u201cTaking it too far,\u201d which describe how to\nrecognize when you are overdoing a good thing.\nAlmost all of the examples in this book are in Java or C++, and much of the\ndiscussion is in terms of designing classes in an object-oriented language.\nHowever, the ideas apply in other domains as well. Almost all of the ideas related\nto methods can also be applied to functions in a language without object-oriented\n", "page": 16, "type": "text", "section": "Page 16"}
{"text": "features, such as C. The design ideas also apply to modules other than classes,\nsuch as subsystems or network services.\nWith this background, let\u2019s discuss in more detail what causes complexity,\nand how to make software systems simpler.\n", "page": 17, "type": "text", "section": "Page 17"}
{"text": "Chapter 2\nThe Nature of Complexity\nThis book is about how to design software systems to minimize their complexity.\nThe first step is to understand the enemy. Exactly what is \u201ccomplexity\u201d? How\ncan you tell if a system is unnecessarily complex? What causes systems to\nbecome complex? This chapter will address those questions at a high level;\nsubsequent chapters will show you how to recognize complexity at a lower level,\nin terms of specific structural features.\nThe ability to recognize complexity is a crucial design skill. It allows you to\nidentify problems before you invest a lot of effort in them, and it allows you to\nmake good choices among alternatives. It is easier to tell whether a design is\nsimple than it is to create a simple design, but once you can recognize that a\nsystem is too complicated, you can use that ability to guide your design\nphilosophy towards simplicity. If a design appears complicated, try a different\napproach and see if that is simpler. Over time, you will notice that certain\ntechniques tend to result in simpler designs, while others correlate with\ncomplexity. This will allow you to produce simpler designs more quickly.\nThis chapter also lays out some basic assumptions that provide a foundation\nfor the rest of the book. Later chapters take the material of this chapter as given\nand use it to justify a variety of refinements and conclusions.\n2.1    Complexity defined\nFor the purposes of this book, I define \u201ccomplexity\u201d in a practical way.\nComplexity is anything related to the structure of a software system that\nmakes it hard to understand and modify the system. Complexity can take\nmany forms. For example, it might be hard to understand how a piece of code\nworks; it might take a lot of effort to implement a small improvement, or it might\nnot be clear which parts of the system must be modified to make the\nimprovement; it might be difficult to fix one bug without introducing another. If\n", "page": 18, "type": "text", "section": "Page 18"}
{"text": "a software system is hard to understand and modify, then it is complicated; if it is\neasy to understand and modify, then it is simple.\nYou can also think of complexity in terms of cost and benefit. In a complex\nsystem, it takes a lot of work to implement even small improvements. In a simple\nsystem, larger improvements can be implemented with less effort.\nComplexity is what a developer experiences at a particular point in time\nwhen trying to achieve a particular goal. It doesn\u2019t necessarily relate to the\noverall size or functionality of the system. People often use the word \u201ccomplex\u201d\nto describe large systems with sophisticated features, but if such a system is easy\nto work on, then, for the purposes of this book, it is not complex. Of course,\nalmost all large and sophisticated software systems are in fact hard to work on, so\nthey also meet my definition of complexity, but this need not necessarily be the\ncase. It is also possible for a small and unsophisticated system to be quite\ncomplex.\nComplexity is determined by the activities that are most common. If a system\nhas a few parts that are very complicated, but those parts almost never need to be\ntouched, then they don\u2019t have much impact on the overall complexity of the\nsystem. To characterize this in a crude mathematical way:\nThe overall complexity of a system (C) is determined by the complexity of\neach part p (cp) weighted by the fraction of time developers spend working on\nthat part (tp). Isolating complexity in a place where it will never be seen is almost\nas good as eliminating the complexity entirely.\nComplexity is more apparent to readers than writers. If you write a piece of\ncode and it seems simple to you, but other people think it is complex, then it is\ncomplex. When you find yourself in situations like this, it\u2019s worth probing the\nother developers to find out why the code seems complex to them; there are\nprobably some interesting lessons to learn from the disconnect between your\nopinion and theirs. Your job as a developer is not just to create code that you can\nwork with easily, but to create code that others can also work with easily.\n2.2    Symptoms of complexity\nComplexity manifests itself in three general ways, which are described in the\nparagraphs below. Each of these manifestations makes it harder to carry out\n", "page": 19, "type": "text", "section": "Page 19"}
{"text": "development tasks.\nChange amplification: The first symptom of complexity is that a seemingly\nsimple change requires code modifications in many different places. For\nexample, consider a Web site containing several pages, each of which displays a\nbanner with a background color. In many early Web sites, the color was specified\nexplicitly on each page, as shown in Figure 2.1(a). In order to change the\nbackground for such a Web site, a developer might have to modify every existing\npage by hand; this would be nearly impossible for a large site with thousands of\npages. Fortunately, modern Web sites use an approach like that in Figure 2.1(b),\nwhere the banner color is specified once in a central place, and all of the\nindividual pages reference that shared value. With this approach, the banner\ncolor of the entire Web site can be changed with a single modification. One of\nthe goals of good design is to reduce the amount of code that is affected by each\ndesign decision, so design changes don\u2019t require very many code modifications.\nCognitive load: The second symptom of complexity is cognitive load, which\nrefers to how much a developer needs to know in order to complete a task. A\nhigher cognitive load means that developers have to spend more time learning\nthe required information, and there is a greater risk of bugs because they have\nmissed something important. For example, suppose a function in C allocates\nmemory, returns a pointer to that memory, and assumes that the caller will free\nthe memory. This adds to the cognitive load of developers using the function; if a\ndeveloper fails to free the memory, there will be a memory leak. If the system\ncan be restructured so that the caller doesn\u2019t need to worry about freeing the\nmemory (the same module that allocates the memory also takes responsibility for\nfreeing it), it will reduce the cognitive load. Cognitive load arises in many ways,\nsuch as APIs with many methods, global variables, inconsistencies, and\ndependencies between modules.\nSystem designers sometimes assume that complexity can be measured by\nlines of code. They assume that if one implementation is shorter than another,\nthen it must be simpler; if it only takes a few lines of code to make a change, then\nthe change must be easy. However, this view ignores the costs associated with\ncognitive load. I have seen frameworks that allowed applications to be written\nwith only a few lines of code, but it was extremely difficult to figure out what\nthose lines were. Sometimes an approach that requires more lines of code is\nactually simpler, because it reduces cognitive load.\n", "page": 20, "type": "text", "section": "Page 20"}
{"text": "Figure 2.1: Each page in a Web site displays a colored banner. In (a) the background color for the banner is\nspecified explicitly in each page. In (b) a shared variable holds the background color and each page\nreferences that variable. In (c) some pages display an additional color for emphasis, which is a darker shade\nof the banner background color; if the background color changes, the emphasis color must also change.\nUnknown unknowns: The third symptom of complexity is that it is not\nobvious which pieces of code must be modified to complete a task, or what\ninformation a developer must have to carry out the task successfully. Figure\n2.1(c) illustrates this problem. The Web site uses a central variable to determine\nthe banner background color, so it appears to be easy to change. However, a few\nWeb pages use a darker shade of the background color for emphasis, and that\ndarker color is specified explicitly in the individual pages. If the background\ncolor changes, then the the emphasis color must change to match. Unfortunately,\ndevelopers are unlikely to realize this, so they may change the central bannerBg\nvariable without updating the emphasis color. Even if a developer is aware of the\nproblem, it won\u2019t be obvious which pages use the emphasis color, so the\ndeveloper may have to search every page in the Web site.\nOf the three manifestations of complexity, unknown unknowns are the worst.\nAn unknown unknown means that there is something you need to know, but there\nis no way for you to find out what it is, or even whether there is an issue. You\nwon\u2019t find out about it until bugs appear after you make a change. Change\namplification is annoying, but as long as it is clear which code needs to be\nmodified, the system will work once the change has been completed. Similarly, a\nhigh cognitive load will increase the cost of a change, but if it is clear which\ninformation to read, the change is still likely to be correct. With unknown\nunknowns, it is unclear what to do or whether a proposed solution will even\nwork. The only way to be certain is to read every line of code in the system,\n", "page": 21, "type": "text", "section": "Page 21"}
{"text": "which is impossible for systems of any size. Even this may not be sufficient,\nbecause a change may depend on a subtle design decision that was never\ndocumented.\nOne of the most important goals of good design is for a system to be obvious.\nThis is the opposite of high cognitive load and unknown unknowns. In an\nobvious system, a developer can quickly understand how the existing code works\nand what is required to make a change. An obvious system is one where a\ndeveloper can make a quick guess about what to do, without thinking very hard,\nand yet be confident that the guess is correct. Chapter 18 discusses techniques for\nmaking code more obvious.\n2.3    Causes of complexity\nNow that you know the high-level symptoms of complexity and why complexity\nmakes software development difficult, the next step is to understand what causes\ncomplexity, so that we can design systems to avoid the problems. Complexity is\ncaused by two things: dependencies and obscurity. This section discusses these\nfactors at a high level; subsequent chapters will discuss how they relate to lower-\nlevel design decisions.\nFor the purposes of this book, a dependency exists when a given piece of\ncode cannot be understood and modified in isolation; the code relates in some\nway to other code, and the other code must be considered and/or modified if the\ngiven code is changed. In the Web site example of Figure 2.1(a), the background\ncolor creates dependencies between all of the pages. All of the pages need to\nhave the same background, so if the background is changed for one page, then it\nmust be changed for all of them. Another example of dependencies occurs in\nnetwork protocols. Typically there is separate code for the sender and receiver for\nthe protocol, but they must each conform to the protocol; changing the code for\nthe sender almost always requires corresponding changes at the receiver, and vice\nversa. The signature of a method creates a dependency between the\nimplementation of that method and the code that invokes it: if a new parameter is\nadded to a method, all of the invocations of that method must be modified to\nspecify that parameter.\nDependencies are a fundamental part of software and can\u2019t be completely\neliminated. In fact, we intentionally introduce dependencies as part of the\nsoftware design process. Every time you write a new class you create\ndependencies around the API for that class. However, one of the goals of\n", "page": 22, "type": "text", "section": "Page 22"}
{"text": "software design is to reduce the number of dependencies and to make the\ndependencies that remain as simple and obvious as possible.\nConsider the Web site example. In the old Web site with the background\nspecified separately on each page, all of the Web pages were dependent on each\nother. The new Web site fixed this problem by specifying the background color\nin a central place and providing an API that individual pages use to retrieve that\ncolor when they are rendered. The new Web site eliminated the dependency\nbetween the pages, but it created a new dependency around the API for retrieving\nthe background color. Fortunately, the new dependency is more obvious: it is\nclear that each individual Web page depends on the bannerBg color, and a\ndeveloper can easily find all the places where the variable is used by searching\nfor its name. Furthermore, compilers help to manage API dependencies: if the\nname of the shared variable changes, compilation errors will occur in any code\nthat still uses the old name. The new Web site replaced a nonobvious and\ndifficult-to-manage dependency with a simpler and more obvious one.\nThe second cause of complexity is obscurity. Obscurity occurs when\nimportant information is not obvious. A simple example is a variable name that\nis so generic that it doesn\u2019t carry much useful information (e.g., time). Or, the\ndocumentation for a variable might not specify its units, so the only way to find\nout is to scan code for places where the variable is used. Obscurity is often\nassociated with dependencies, where it is not obvious that a dependency exists.\nFor example, if a new error status is added to a system, it may be necessary to\nadd an entry to a table holding string messages for each status, but the existence\nof the message table might not be obvious to a programmer looking at the status\ndeclaration. Inconsistency is also a major contributor to obscurity: if the same\nvariable name is used for two different purposes, it won\u2019t be obvious to developer\nwhich of these purposes a particular variable serves.\nIn many cases, obscurity comes about because of inadequate documentation;\nChapter 13 deals with this topic. However, obscurity is also a design issue. If a\nsystem has a clean and obvious design, then it will need less documentation. The\nneed for extensive documentation is often a red flag that the design isn\u2019t quite\nright. The best way to reduce obscurity is by simplifying the system design.\nTogether, dependencies and obscurity account for the three manifestations of\ncomplexity described in Section 2.2. Dependencies lead to change amplification\nand a high cognitive load. Obscurity creates unknown unknowns, and also\n", "page": 23, "type": "text", "section": "Page 23"}
{"text": "contributes to cognitive load. If we can find design techniques that minimize\ndependencies and obscurity, then we can reduce the complexity of software.\n2.4    Complexity is incremental\nComplexity isn\u2019t caused by a single catastrophic error; it accumulates in lots of\nsmall chunks. A single dependency or obscurity, by itself, is unlikely to affect\nsignificantly the maintainability of a software system. Complexity comes about\nbecause hundreds or thousands of small dependencies and obscurities build up\nover time. Eventually, there are so many of these small issues that every possible\nchange to the system is affected by several of them.\nThe incremental nature of complexity makes it hard to control. It\u2019s easy to\nconvince yourself that a little bit of complexity introduced by your current\nchange is no big deal. However, if every developer takes this approach for every\nchange, complexity accumulates rapidly. Once complexity has accumulated, it is\nhard to eliminate, since fixing a single dependency or obscurity will not, by\nitself, make a big difference. In order to slow the growth of complexity, you must\nadopt a \u201czero tolerance\u201d philosophy, as discussed in Chapter 3.\n2.5    Conclusion\nComplexity comes from an accumulation of dependencies and obscurities. As\ncomplexity increases, it leads to change amplification, a high cognitive load, and\nunknown unknowns. As a result, it takes more code modifications to implement\neach new feature. In addition, developers spend more time acquiring enough\ninformation to make the change safely and, in the worst case, they can\u2019t even find\nall the information they need. The bottom line is that complexity makes it\ndifficult and risky to modify an existing code base.\n", "page": 24, "type": "text", "section": "Page 24"}
{"text": "Chapter 3\nWorking Code Isn\u2019t Enough\n(Strategic vs. Tactical Programming)\nOne of the most important elements of good software design is the mindset\nyou adopt when you approach a programming task. Many organizations\nencourage a tactical mindset, focused on getting features working as quickly as\npossible. However, if you want a good design, you must take a more strategic\napproach where you invest time to produce clean designs and fix problems. This\nchapter discusses why the strategic approach produces better designs and is\nactually cheaper than the tactical approach over the long run.\n3.1    Tactical programming\nMost programmers approach software development with a mindset I call tactical\nprogramming. In the tactical approach, your main focus is to get something\nworking, such as a new feature or a bug fix. At first glance this seems totally\nreasonable: what could be more important than writing code that works?\nHowever, tactical programming makes it nearly impossible to produce a good\nsystem design.\nThe problem with tactical programming is that it is short-sighted. If you\u2019re\nprogramming tactically, you\u2019re trying to finish a task as quickly as possible.\nPerhaps you have a hard deadline. As a result, planning for the future isn\u2019t a\npriority. You don\u2019t spend much time looking for the best design; you just want to\nget something working soon. You tell yourself that it\u2019s OK to add a bit of\ncomplexity or introduce a small kludge or two, if that allows the current task to\nbe completed more quickly.\nThis is how systems become complicated. As discussed in the previous\nchapter, complexity is incremental. It\u2019s not one particular thing that makes a\nsystem complicated, but the accumulation of dozens or hundreds of small things.\n", "page": 25, "type": "text", "section": "Page 25"}
{"text": "If you program tactically, each programming task will contribute a few of these\ncomplexities. Each of them probably seems like a reasonable compromise in\norder to finish the current task quickly. However, the complexities accumulate\nrapidly, especially if everyone is programming tactically.\nBefore long, some of the complexities will start causing problems, and you\nwill begin to wish you hadn\u2019t taken those early shortcuts. But, you will tell\nyourself that it\u2019s more important to get the next feature working than to go back\nand refactor existing code. Refactoring may help out in the long run, but it will\ndefinitely slow down the current task. So, you look for quick patches to work\naround any problems you encounter. This just creates more complexity, which\nthen requires more patches. Pretty soon the code is a mess, but by this point\nthings are so bad that it would take months of work to clean it up. There\u2019s no way\nyour schedule can tolerate that kind of delay, and fixing one or two of the\nproblems doesn\u2019t seem like it will make much difference, so you just keep\nprogramming tactically.\nIf you have worked on a large software project for very long, I suspect you\nhave seen tactical programming at work and have experienced the problems that\nresult. Once you start down the tactical path, it\u2019s difficult to change.\nAlmost every software development organization has at least one developer\nwho takes tactical programming to the extreme: a tactical tornado. The tactical\ntornado is a prolific programmer who pumps out code far faster than others but\nworks in a totally tactical fashion. When it comes to implementing a quick\nfeature, nobody gets it done faster than the tactical tornado. In some\norganizations, management treats tactical tornadoes as heroes. However, tactical\ntornadoes leave behind a wake of destruction. They are rarely considered heroes\nby the engineers who must work with their code in the future. Typically, other\nengineers must clean up the messes left behind by the tactical tornado, which\nmakes it appear that those engineers (who are the real heroes) are making slower\nprogress than the tactical tornado.\n3.2    Strategic programming\nThe first step towards becoming a good software designer is to realize that\nworking code isn\u2019t enough. It\u2019s not acceptable to introduce unnecessary\ncomplexities in order to finish your current task faster. The most important thing\nis the long-term structure of the system. Most of the code in any system is\nwritten by extending the existing code base, so your most important job as a\n", "page": 26, "type": "text", "section": "Page 26"}
{"text": "developer is to facilitate those future extensions. Thus, you should not think of\n\u201cworking code\u201d as your primary goal, though of course your code must work.\nYour primary goal must be to produce a great design, which also happens to\nwork. This is strategic programming.\nStrategic programming requires an investment mindset. Rather than taking\nthe fastest path to finish your current project, you must invest time to improve the\ndesign of the system. These investments will slow you down a bit in the short\nterm, but they will speed you up in the long term, as illustrated in Figure 3.1.\nSome of the investments will be proactive. For example, it\u2019s worth taking a\nlittle extra time to find a simple design for each new class; rather than\nimplementing the first idea that comes to mind, try a couple of alternative\ndesigns and pick the cleanest one. Try to imagine a few ways in which the system\nmight need to be changed in the future and make sure that will be easy with your\ndesign. Writing good documentation is another example of a proactive\ninvestment.\nOther investments will be reactive. No matter how much you invest up front,\nthere will inevitably be mistakes in your design decisions. Over time, these\nmistakes will become obvious. When you discover a design problem, don\u2019t just\nignore it or patch around it; take a little extra time to fix it. If you program\nstrategically, you will continually make small improvements to the system\ndesign. This is the opposite of tactical programming, where you are continually\nadding small bits of complexity that cause problems in the future.\n3.3    How much to invest?\nSo, what is the right amount of investment? A huge up-front investment, such as\ntrying to design the entire system, won\u2019t be effective. This is the waterfall\nmethod, and we know it doesn\u2019t work. The ideal design tends to emerge in bits\nand pieces, as you get experience with the system. Thus, the best approach is to\nmake lots of small investments on a continual basis. I suggest spending about 10\u2013\n20% of your total development time on investments. This amount is small\nenough that it won\u2019t impact your schedules significantly, but large enough to\nproduce significant benefits over time. Your initial projects will thus take 10\u2013\n20% longer than they would in a purely tactical approach. That extra time will\nresult in a better software design, and you will start experiencing the benefits\nwithin a few months. It won\u2019t be long before you\u2019re developing at least 10\u201320%\nfaster than you would if you had programmed tactically. At this point your\n", "page": 27, "type": "text", "section": "Page 27"}
{"text": "investments become free: the benefits from your past investments will save\nenough time to cover the cost of future investments. You will quickly recover the\ncost of the initial investment. Figure 3.1 illustrates this phenomenon.\nFigure 3.1: At the beginning, a tactical approach to programming will make progress more quickly than a\nstrategic approach. However, complexity accumulates more rapidly under the tactical approach, which\nreduces productivity. Over time, the strategic approach results in greater progress. Note: this figure is\nintended only as a qualitative illustration; I am not aware of any empirical measurements of the precise\nshapes of the curves.\nConversely, if you program tactically, you will finish your first projects 10\u2013\n20% faster, but over time your development speed will slow as complexity\naccumulates. It won\u2019t be long before you\u2019re programming at least 10\u201320%\nslower. You will quickly give back all of the time you saved at the beginning, and\nfor the rest of system\u2019s lifetime you will be developing more slowly than if you\nhad taken the strategic approach. If you haven\u2019t ever worked in a badly degraded\ncode base, talk to someone who has; they will tell you that poor code quality\nslows development by at least 20%.\n3.4    Startups and investment\nIn some environments there are strong forces working against the strategic\napproach. For example, early-stage startups feel tremendous pressure to get their\nearly releases out quickly. In these companies, it might seem that even a 10\u201320%\ninvestment isn\u2019t affordable. As a result, many startups take a tactical approach,\nspending little effort on design and even less on cleanup when problems pop up.\nThey rationalize this with the thought that, if they are successful, they\u2019ll have\nenough money to hire extra engineers to clean things up.\nIf you are in a company leaning in this direction, you should realize that once\na code base turns to spaghetti, it is nearly impossible to fix. You will probably\npay high development costs for the life of the product. Furthermore, the payoff\n", "page": 28, "type": "text", "section": "Page 28"}
{"text": "for good (or bad) design comes pretty quickly, so there\u2019s a good chance that the\ntactical approach won\u2019t even speed up your first product release.\nAnother thing to consider is that one of the most important factors for\nsuccess of a company is the quality of its engineers. The best way to lower\ndevelopment costs is to hire great engineers: they don\u2019t cost much more than\nmediocre engineers but have tremendously higher productivity. However, the best\nengineers care deeply about good design. If your code base is a wreck, word will\nget out, and this will make it harder for you to recruit. As a result, you are likely\nto end up with mediocre engineers. This will increase your future costs and\nprobably cause the system structure to degrade even more.\nFacebook is an example of a startup that encouraged tactical programming.\nFor many years the company\u2019s motto was \u201cMove fast and break things.\u201d New\nengineers fresh out of college were encouraged to dive immediately into the\ncompany\u2019s code base; it was normal for engineers to push commits into\nproduction in their first week on the job. On the positive side, Facebook\ndeveloped a reputation as a company that empowered its employees. Engineers\nhad tremendous latitude, and there were few rules and restrictions to get in their\nway.\nFacebook has been spectacularly successful as a company, but its code base\nsuffered because of the company\u2019s tactical approach; much of the code was\nunstable and hard to understand, with few comments or tests, and painful to work\nwith. Over time the company realized that its culture was unsustainable.\nEventually, Facebook changed its motto to \u201cMove fast with solid infrastructure\u201d\nto encourage its engineers to invest more in good design. It remains to be seen\nwhether Facebook can successfully clean up the problems that accumulated over\nyears of tactical programming.\nIn fairness to Facebook, I should point out that Facebook\u2019s code probably\nisn\u2019t much worse than average among startups. Tactical programming is\ncommonplace among startups; Facebook just happens to be a particularly visible\nexample.\nFortunately, it is also possible to succeed in Silicon Valley with a strategic\napproach. Google and VMware grew up around the same time as Facebook, but\nboth of these companies embraced a more strategic approach. Both companies\nplaced a heavy emphasis on high quality code and good design, and both\ncompanies built sophisticated products that solved complex problems with\nreliable software systems. The companies\u2019 strong technical cultures became well\n", "page": 29, "type": "text", "section": "Page 29"}
{"text": "known in Silicon Valley. Few other companies could compete with them for\nhiring the top technical talent.\nThese examples show that a company can succeed with either approach.\nHowever, it\u2019s a lot more fun to work in a company that cares about software\ndesign and has a clean code base.\n3.5    Conclusion\nGood design doesn\u2019t come for free. It has to be something you invest in\ncontinually, so that small problems don\u2019t accumulate into big ones. Fortunately,\ngood design eventually pays for itself, and sooner than you might think.\nIt\u2019s crucial to be consistent in applying the strategic approach and to think of\ninvestment as something to do today, not tomorrow. When you get in a crunch it\nwill be tempting to put off cleanups until after the crunch is over. However, this\nis a slippery slope; after the current crunch there will almost certainly be another\none, and another after that. Once you start delaying design improvements, it\u2019s\neasy for the delays to become permanent and for your culture to slip into the\ntactical approach. The longer you wait to address design problems, the bigger\nthey become; the solutions become more intimidating, which makes it easy to\nput them off even more. The most effective approach is one where every\nengineer makes continuous small investments in good design.\n", "page": 30, "type": "text", "section": "Page 30"}
{"text": "Chapter 4\nModules Should Be Deep\nOne of the most important techniques for managing software complexity is to\ndesign systems so that developers only need to face a small fraction of the overall\ncomplexity at any given time. This approach is called modular design, and this\nchapter presents its basic principles.\n4.1    Modular design\nIn modular design, a software system is decomposed into a collection of modules\nthat are relatively independent. Modules can take many forms, such as classes,\nsubsystems, or services. In an ideal world, each module would be completely\nindependent of the others: a developer could work in any of the modules without\nknowing anything about any of the other modules. In this world, the complexity\nof a system would be the complexity of its worst module.\nUnfortunately, this ideal is not achievable. Modules must work together by\ncalling each others\u2019s functions or methods. As a result, modules must know\nsomething about each other. There will be dependencies between the modules: if\none module changes, other modules may need to change to match. For example,\nthe arguments for a method create a dependency between the method and any\ncode that invokes the method. If the required arguments change, all invocations\nof the method must be modified to conform to the new signature. Dependencies\ncan take many other forms, and they can be quite subtle. The goal of modular\ndesign is to minimize the dependencies between modules.\nIn order to manage dependencies, we think of each module in two parts: an\ninterface and an implementation. The interface consists of everything that a\ndeveloper working in a different module must know in order to use the given\nmodule. Typically, the interface describes what the module does but not how it\ndoes it. The implementation consists of the code that carries out the promises\nmade by the interface. A developer working in a particular module must\n", "page": 31, "type": "text", "section": "Page 31"}
{"text": "understand the interface and implementation of that module, plus the interfaces\nof any other modules invoked by the given module. A developer should not need\nto understand the implementations of modules other than the one he or she is\nworking in.\nConsider a module that implements balanced trees. The module probably\ncontains sophisticated code for ensuring that the tree remains balanced. However,\nthis complexity is not visible to users of the module. Users see a relatively simple\ninterface for invoking operations to insert, remove, and fetch nodes in the tree. To\ninvoke an insert operation, the caller need only provide the key and value for the\nnew node; the mechanisms for traversing the tree and splitting nodes are not\nvisible in the interface.\nFor the purposes of this book, a module is any unit of code that has an\ninterface and an implementation. Each class in an object-oriented programming\nlanguage is a module. Methods within a class, or functions in a language that\nisn\u2019t object-oriented, can also be thought of as modules: each of these has an\ninterface and an implementation, and modular design techniques can be applied\nto them. Higher-level subsystems and services are also modules; their interfaces\nmay take different forms, such as kernel calls or HTTP requests. Much of the\ndiscussion about modular design in this book focuses on designing classes, but\nthe techniques and concepts apply to other kinds of modules as well.\nThe best modules are those whose interfaces are much simpler than their\nimplementations. Such modules have two advantages. First, a simple interface\nminimizes the complexity that a module imposes on the rest of the system.\nSecond, if a module is modified in a way that does not change its interface, then\nno other module will be affected by the modification. If a module\u2019s interface is\nmuch simpler than its implementation, there will be many aspects of the module\nthat can be changed without affecting other modules.\n4.2    What\u2019s in an interface?\nThe interface to a module contains two kinds of information: formal and\ninformal. The formal parts of an interface are specified explicitly in the code, and\nsome of these can be checked for correctness by the programming language. For\nexample, the formal interface for a method is its signature, which includes the\nnames and types of its parameters, the type of its return value, and information\nabout exceptions thrown by the method. Most programming languages ensure\nthat each invocation of a method provides the right number and types of\n", "page": 32, "type": "text", "section": "Page 32"}
{"text": "arguments to match its signature. The formal interface for a class consists of the\nsignatures for all of its public methods, plus the names and types of any public\nvariables.\nEach interface also includes informal elements. These are not specified in a\nway that can be understood or enforced by the programming language. The\ninformal parts of an interface include its high-level behavior, such as the fact that\na function deletes the file named by one of its arguments. If there are constraints\non the usage of a class (perhaps one method must be called before another), these\nare also part of the class\u2019s interface. In general, if a developer needs to know a\nparticular piece of information in order to use a module, then that information is\npart of the module\u2019s interface. The informal aspects of an interface can only be\ndescribed using comments, and the programming language cannot ensure that\nthe description is complete or accurate1. For most interfaces the informal aspects\nare larger and more complex than the formal aspects.\nOne of the benefits of a clearly specified interface is that it indicates exactly\nwhat developers need to know in order to use the associated module. This helps\nto eliminate the \u201cunknown unknowns\u201d problem described in Section 2.2.\n4.3    Abstractions\nThe term abstraction is closely related to the idea of modular design. An\nabstraction is a simplified view of an entity, which omits unimportant\ndetails. Abstractions are useful because they make it easier for us to think about\nand manipulate complex things.\nIn modular programming, each module provides an abstraction in form of its\ninterface. The interface presents a simplified view of the module\u2019s functionality;\nthe details of the implementation are unimportant from the standpoint of the\nmodule\u2019s abstraction, so they are omitted from the interface.\nIn the definition of abstraction, the word \u201cunimportant\u201d is crucial. The more\nunimportant details that are omitted from an abstraction, the better. However, a\ndetail can only be omitted from an abstraction if it is unimportant. An abstraction\ncan go wrong in two ways. First, it can include details that are not really\nimportant; when this happens, it makes the abstraction more complicated than\nnecessary, which increases the cognitive load on developers using the\nabstraction. The second error is when an abstraction omits details that really are\nimportant. This results in obscurity: developers looking only at the abstraction\nwill not have all the information they need to use the abstraction correctly. An\n", "page": 33, "type": "text", "section": "Page 33"}
{"text": "abstraction that omits important details is a false abstraction: it might appear\nsimple, but in reality it isn\u2019t. The key to designing abstractions is to understand\nwhat is important, and to look for designs that minimize the amount of\ninformation that is important.\nAs an example, consider a file system. The abstraction provided by a file\nsystem omits many details, such as the mechanism for choosing which blocks on\na storage device to use for the data in a given file. These details are unimportant\nto users of the file system (as long as the system provides adequate performance).\nHowever, some of the details of a file system\u2019s implementation are important to\nusers. Most file systems cache data in main memory, and they may delay writing\nnew data to the storage device in order to improve performance. Some\napplications, such as databases, need to know exactly when data is written\nthrough to storage, so they can ensure that data will be preserved after system\ncrashes. Thus, the rules for flushing data to secondary storage must be visible in\nthe file system\u2019s interface.\nWe depend on abstractions to manage complexity not just in programming,\nbut pervasively in our everyday lives. A microwave oven contains complex\nelectronics to convert alternating current into microwave radiation and distribute\nthat radiation throughout the cooking cavity. Fortunately, users see a much\nsimpler abstraction, consisting of a few buttons to control the timing and\nintensity of the microwaves. Cars provide a simple abstraction that allows us to\ndrive them without understanding the mechanisms for electrical motors, battery\npower management, anti-lock brakes, cruise control, and so on.\n4.4    Deep modules\nThe best modules are those that provide powerful functionality yet have simple\ninterfaces. I use the term deep to describe such modules. To visualize the notion\nof depth, imagine that each module is represented by a rectangle, as shown in\nFigure 4.1. The area of each rectangle is proportional to the functionality\nimplemented by the module. The top edge of a rectangle represents the module\u2019s\ninterface; the length of that edge indicates the complexity of the interface. The\nbest modules are deep: they have a lot of functionality hidden behind a simple\ninterface. A deep module is a good abstraction because only a small fraction of\nits internal complexity is visible to its users.\n", "page": 34, "type": "text", "section": "Page 34"}
{"text": "Figure 4.1: Deep and shallow modules. The best modules are deep: they allow a lot of functionality to be\naccessed through a simple interface. A shallow module is one with a relatively complex interface, but not\nmuch functionality: it doesn\u2019t hide much complexity.\nModule depth is a way of thinking about cost versus benefit. The benefit\nprovided by a module is its functionality. The cost of a module (in terms of\nsystem complexity) is its interface. A module\u2019s interface represents the\ncomplexity that the module imposes on the rest of the system: the smaller and\nsimpler the interface, the less complexity that it introduces. The best modules are\nthose with the greatest benefit and the least cost. Interfaces are good, but more,\nor larger, interfaces are not necessarily better!\nThe mechanism for file I/O provided by the Unix operating system and its\ndescendants, such as Linux, is a beautiful example of a deep interface. There are\nonly five basic system calls for I/O, with simple signatures:\nint open(const char* path, int flags, mode_t permissions);\nssize_t read(int fd, void* buffer, size_t count);\nssize_t write(int fd, const void* buffer, size_t count);\noff_t lseek(int fd, off_t offset, int referencePosition);\nint close(int fd);\nThe open system call takes a hierarchical file name such as /a/b/c and returns an\ninteger file descriptor, which is used to reference the open file. The other\narguments for open provide optional information such as whether the file is being\nopened for reading or writing, whether a new file should be created if there is no\nexisting file, and access permissions for the file, if a new file is created. The read\nand write system calls transfer information between buffer areas in the\napplication\u2019s memory and the file; close ends the access to the file. Most files\nare accessed sequentially, so that is the default; however, random access can be\nachieved by invoking the lseek system call to change the current access position.\nA modern implementation of the Unix I/O interface requires hundreds of\n", "page": 35, "type": "text", "section": "Page 35"}
{"text": "A modern implementation of the Unix I/O interface requires hundreds of\nthousands of lines of code, which address complex issues such as:\nHow are files represented on disk in order to allow efficient access?\nHow are directories stored, and how are hierarchical path names processed\nto find the files they refer to?\nHow are permissions enforced, so that one user cannot modify or delete\nanother user\u2019s files?\nHow are file accesses implemented? For example, how is functionality\ndivided between interrupt handlers and background code, and how do these\ntwo elements communicate safely?\nWhat scheduling policies are used when there are concurrent accesses to\nmultiple files?\nHow can recently accessed file data be cached in memory in order to reduce\nthe number of disk accesses?\nHow can a variety of different secondary storage devices, such as disks and\nflash drives, be incorporated into a single file system?\nAll of these issues, and many more, are handled by the Unix file system\nimplementation; they are invisible to programmers who invoke the system calls.\nImplementations of the Unix I/O interface have evolved radically over the years,\nbut the five basic kernel calls have not changed.\nAnother example of a deep module is the garbage collector in a language\nsuch as Go or Java. This module has no interface at all; it works invisibly behind\nthe scenes to reclaim unused memory. Adding garbage collection to a system\nactually shrinks its overall interface, since it eliminates the interface for freeing\nobjects. The implementation of a garbage collector is quite complex, but that\ncomplexity is hidden from programmers using the language.\nDeep modules such as Unix I/O and garbage collectors provide powerful\nabstractions because they are easy to use, yet they hide significant\nimplementation complexity.\n4.5    Shallow modules\nOn the other hand, a shallow module is one whose interface is relatively complex\nin comparison to the functionality that it provides. For example, a class that\nimplements linked lists is shallow. It doesn\u2019t take much code to manipulate a\nlinked list (inserting or deleting an element takes only a few lines), so the linked\nlist abstraction doesn\u2019t hide very many details. The complexity of a linked list\n", "page": 36, "type": "text", "section": "Page 36"}
{"text": "interface is nearly as great as the complexity of its implementation. Shallow\nclasses are sometimes unavoidable, but they don\u2019t provide help much in\nmanaging complexity.\nHere is an extreme example of a shallow method, taken from a project in a\nsoftware design class:\nprivate void addNullValueForAttribute(String attribute) {\n       data.put(attribute, null);\n}\nFrom the standpoint of managing complexity, this method makes things worse,\nnot better. The method offers no abstraction, since all of its functionality is\nvisible through its interface. For example, callers probably need to know that the\nattribute will be stored in the data variable. It is no simpler to think about the\ninterface than to think about the full implementation. If the method is\ndocumented properly, the documentation will be longer than the method\u2019s code.\nIt even takes more keystrokes to invoke the method than it would take for a caller\nto manipulate the data variable directly. The method adds complexity (in the\nform of a new interface for developers to learn) but provides no compensating\nbenefit.\n Red Flag: Shallow Module \nA shallow module is one whose interface is complicated relative to the\nfunctionality it provides. Shallow modules don\u2019t help much in the battle\nagainst complexity, because the benefit they provide (not having to learn about\nhow they work internally) is negated by the cost of learning and using their\ninterfaces. Small modules tend to be shallow.\n4.6    Classitis\nUnfortunately, the value of deep classes is not widely appreciated today. The\nconventional wisdom in programming is that classes should be small, not deep.\nStudents are often taught that the most important thing in class design is to break\nup larger classes into smaller ones. The same advice is often given about\nmethods: \u201cAny method longer than N lines should be divided into multiple\n", "page": 37, "type": "text", "section": "Page 37"}
{"text": "methods\u201d (N can be as low as 10). This approach results in large numbers of\nshallow classes and methods, which add to overall system complexity.\nThe extreme of the \u201cclasses should be small\u201d approach is a syndrome I call\nclassitis, which stems from the mistaken view that \u201cclasses are good, so more\nclasses are better.\u201d In systems suffering from classitis, developers are encouraged\nto minimize the amount of functionality in each new class: if you want more\nfunctionality, introduce more classes. Classitis may result in classes that are\nindividually simple, but it increases the complexity of the overall system. Small\nclasses don\u2019t contribute much functionality, so there have to be a lot of them,\neach with its own interface. These interfaces accumulate to create tremendous\ncomplexity at the system level. Small classes also result in a verbose\nprogramming style, due to the boilerplate required for each class.\n4.7    Examples: Java and Unix I/O\nOne of the most visible examples of classitis today is the Java class library. The\nJava language doesn\u2019t require lots of small classes, but a culture of classitis\nseems to have taken root in the Java programming community. For example, to\nopen a file in order to read serialized objects from it, you must create three\ndifferent objects:\nFileInputStream fileStream =\nnew FileInputStream(fileName);\nBufferedInputStream bufferedStream =\nnew BufferedInputStream(fileStream);\nObjectInputStream objectStream =\nnew ObjectInputStream(bufferedStream);\nA FileInputStream object provides only rudimentary I/O: it is not capable of\nperforming buffered I/O, nor can it read or write serialized objects. The\nBufferedInputStream object adds buffering to a FileInputStream, and the\nObjectInputStream adds the ability to read and write serialized objects. The first\ntwo objects in the code above, fileStream and bufferedStream, are never used\nonce the file has been opened; all future operations use objectStream.\nIt is particularly annoying (and error-prone) that buffering must be requested\nexplicitly by creating a separate BufferedInputStream object; if a developer\nforgets to create this object, there will be no buffering and I/O will be slow.\nPerhaps the Java developers would argue that not everyone wants to use buffering\n", "page": 38, "type": "text", "section": "Page 38"}
{"text": "for file I/O, so it shouldn\u2019t be built into the base mechanism. They might argue\nthat it\u2019s better to keep buffering separate, so people can choose whether or not to\nuse it. Providing choice is good, but interfaces should be designed to make the\ncommon case as simple as possible (see the formula on page 6). Almost every\nuser of file I/O will want buffering, so it should be provided by default. For those\nfew situations where buffering is not desirable, the library can provide a\nmechanism to disable it. Any mechanism for disabling buffering should be\ncleanly separated in the interface (for example, by providing a different\nconstructor for FileInputStream, or through a method that disables or replaces\nthe buffering mechanism), so that most developers do not even need to be aware\nof its existence.\nIn contrast, the designers of the Unix system calls made the common case\nsimple. For example, they recognized that sequential I/O is most common, so\nthey made that the default behavior. Random access is still relatively easy to do,\nusing the lseek system call, but a developer doing only sequential access need\nnot be aware of that mechanism. If an interface has many features, but most\ndevelopers only need to be aware of a few of them, the effective complexity of\nthat interface is just the complexity of the commonly used features.\n4.8    Conclusion\nBy separating the interface of a module from its implementation, we can hide the\ncomplexity of the implementation from the rest of the system. Users of a module\nneed only understand the abstraction provided by its interface. The most\nimportant issue in designing classes and other modules is to make them deep, so\nthat they have simple interfaces for the common use cases, yet still provide\nsignificant functionality. This maximizes the amount of complexity that is\nconcealed.\n1There exist languages, mostly in the research community, where the overall behavior of a method or\nfunction can be described formally using a specification language. The specification can be checked\nautomatically to ensure that it matches the implementation. An interesting question is whether such a formal\nspecification could replace the informal parts of an interface. My current opinion is that an interface\ndescribed in English is likely to be more intuitive and understandable for developers than one written in a\nformal specification language.\n", "page": 39, "type": "text", "section": "Page 39"}
{"text": "Chapter 5\nInformation Hiding (and Leakage)\nChapter 4 argued that modules should be deep. This chapter, and the next few\nthat follow, discuss techniques for creating deep modules.\n5.1    Information hiding\nThe most important technique for achieving deep modules is information hiding.\nThis technique was first described by David Parnas1. The basic idea is that each\nmodule should encapsulate a few pieces of knowledge, which represent design\ndecisions. The knowledge is embedded in the module\u2019s implementation but does\nnot appear in its interface, so it is not visible to other modules.\nThe information hidden within a module usually consists of details about\nhow to implement some mechanism. Here are some examples of information that\nmight be hidden within a module:\nHow to store information in a B-tree, and how to access it efficiently.\nHow to identify the physical disk block corresponding to each logical block\nwithin a file.\nHow to implement the TCP network protocol.\nHow to schedule threads on a multi-core processor.\nHow to parse JSON documents.\nThe hidden information includes data structures and algorithms related to the\nmechanism. It can also include lower-level details such as the size of a page, and\nit can include higher-level concepts that are more abstract, such as an assumption\nthat most files are small.\nInformation hiding reduces complexity in two ways. First, it simplifies the\ninterface to a module. The interface reflects a simpler, more abstract view of the\nmodule\u2019s functionality and hides the details; this reduces the cognitive load on\ndevelopers who use the module. For instance, a developer using a B-tree class\nneed not worry about the ideal fanout for nodes in the tree or how to keep the\n", "page": 40, "type": "text", "section": "Page 40"}
{"text": "tree balanced. Second, information hiding makes it easier to evolve the system. If\na piece of information is hidden, there are no dependencies on that information\noutside the module containing the information, so a design change related to that\ninformation will affect only the one module. For example, if the TCP protocol\nchanges (to introduce a new mechanism for congestion control, for instance), the\nprotocol\u2019s implementation will have to be modified, but no changes should be\nneeded in higher-level code that uses TCP to send and receive data.\nWhen designing a new module, you should think carefully about what\ninformation can be hidden in that module. If you can hide more information, you\nshould also be able to simplify the module\u2019s interface, and this makes the module\ndeeper.\nNote: hiding variables and methods in a class by declaring them private isn\u2019t\nthe same thing as information hiding. Private elements can help with information\nhiding, since they make it impossible for the items to be accessed directly from\noutside the class. However, information about the private items can still be\nexposed through public methods such as getter and setter methods. When this\nhappens the nature and usage of the variables are just as exposed as if the\nvariables were public.\nThe best form of information hiding is when information is totally hidden\nwithin a module, so that it is irrelevant and invisible to users of the module.\nHowever, partial information hiding also has value. For example, if a particular\nfeature or piece of information is only needed by a few of a class\u2019s users, and it is\naccessed through separate methods so that it isn\u2019t visible in the most common\nuse cases, then that information is mostly hidden. Such information will create\nfewer dependencies than information that is visible to every user of the class.\n5.2    Information leakage\nThe opposite of information hiding is information leakage. Information leakage\noccurs when a design decision is reflected in multiple modules. This creates a\ndependency between the modules: any change to that design decision will require\nchanges to all of the involved modules. If a piece of information is reflected in\nthe interface for a module, then by definition it has been leaked; thus, simpler\ninterfaces tend to correlate with better information hiding. However, information\ncan be leaked even if it doesn\u2019t appear in a module\u2019s interface. Suppose two\nclasses both have knowledge of a particular file format (perhaps one class reads\nfiles in that format and the other class writes them). Even if neither class exposes\n", "page": 41, "type": "text", "section": "Page 41"}
{"text": "that information in its interface, they both depend on the file format: if the format\nchanges, both classes will need to be modified. Back-door leakage like this is\nmore pernicious than leakage through an interface, because it isn\u2019t obvious.\nInformation leakage is one of the most important red flags in software\ndesign. One of the best skills you can learn as a software designer is a high level\nof sensitivity to information leakage. If you encounter information leakage\nbetween classes, ask yourself \u201cHow can I reorganize these classes so that this\nparticular piece of knowledge only affects a single class?\u201d If the affected classes\nare relatively small and closely tied to the leaked information, it may make sense\nto merge them into a single class. Another possible approach is to pull the\ninformation out of all of the affected classes and create a new class that\nencapsulates just that information. However, this approach will be effective only\nif you can find a simple interface that abstracts away from the details; if the new\nclass exposes most of the knowledge through its interface, then it won\u2019t provide\nmuch value (you\u2019ve simply replaced back-door leakage with leakage through an\ninterface).\n Red Flag: Information Leakage \nInformation leakage occurs when the same knowledge is used in multiple\nplaces, such as two different classes that both understand the format of a\nparticular type of file.\n5.3    Temporal decomposition\nOne common cause of information leakage is a design style I call temporal\ndecomposition. In temporal decomposition, the structure of a system corresponds\nto the time order in which operations will occur. Consider an application that\nreads a file in a particular format, modifies the contents of the file, and then\nwrites the file out again. With temporal decomposition, this application might be\nbroken into three classes: one to read the file, another to perform the\nmodifications, and a third to write out the new version. Both the file reading and\nfile writing steps have knowledge about the file format, which results in\ninformation leakage. The solution is to combine the core mechanisms for reading\nand writing files into a single class. This class will get used during both the\n", "page": 42, "type": "text", "section": "Page 42"}
{"text": "reading and writing phases of the application. It\u2019s easy to fall into the trap of\ntemporal decomposition, because the order in which operations must occur is\noften on your mind when you code. However, most design decisions manifest\nthemselves at several different times over the life of the application; as a result,\ntemporal decomposition often results in information leakage.\nOrder usually does matter, so it will be reflected somewhere in the\napplication. However, it shouldn\u2019t be reflected in the module structure unless that\nstructure is consistent with information hiding (perhaps the different stages use\ntotally different information). When designing modules, focus on the\nknowledge that\u2019s needed to perform each task, not the order in which tasks\noccur.\n Red Flag: Temporal Decomposition \nIn temporal decomposition, execution order is reflected in the code structure:\noperations that happen at different times are in different methods or classes. If\nthe same knowledge is used at different points in execution, it gets encoded in\nmultiple places, resulting in information leakage.\n5.4    Example: HTTP server\nTo illustrate the issues in information hiding, let\u2019s consider the design decisions\nmade by students implementing the HTTP protocol in a software design course.\nIt\u2019s useful to see both the things they did well and they areas where they had\nproblems.\nHTTP is a mechanism used by Web browsers to communicate with Web\nservers. When a user clicks on a link in a Web browser or submits a form, the\nbrowser uses HTTP to send a request over the network to a Web server. Once the\nserver has processed the request, it sends a response back to the browser; the\nresponse normally contains a new Web page to display. The HTTP protocol\nspecifies the format of requests and responses, both of which are represented\ntextually. Figure 5.1 shows a sample HTTP request describing a form submission.\nThe students in the course were asked to implement one or more classes to make\nit easy for Web servers to receive incoming HTTP requests and send responses.\n", "page": 43, "type": "text", "section": "Page 43"}
{"text": "Figure 5.1: A POST request in the HTTP protocol consists of text sent over a TCP socket. Each request\ncontains an initial line, a collection of headers terminated by an empty line, and an optional body. The initial\nline contains the request type (POST is used for submitting form data), a URL indicating an operation\n(/comments/create) and optional parameters (photo_id has the value 246), and the HTTP protocol version\nused by the sender. Each header line consists of a name such as Content-Length followed by its value. For\nthis request, the body contains additional parameters (comment and priority).\n5.5    Example: too many classes\nThe most common mistake made by students was to divide their code into a large\nnumber of shallow classes, which led to information leakage between the classes.\nOne team used two different classes for receiving HTTP requests; the first class\nread the request from the network connection into a string, and the second class\nparsed the string. This is an example of a temporal decomposition (\u201cfirst we read\nthe request, then we parse it\u201d). Information leakage occurred because an HTTP\nrequest can\u2019t be read without parsing much of the message; for example, the\nContent-Length header specifies the length of the request body, so the headers\nmust be parsed in order to compute the total request length. As a result, both\nclasses needed to understand most of the structure of HTTP requests, and parsing\ncode was duplicated in both classes. This approach also created extra complexity\nfor callers, who had to invoke two methods in different classes, in a particular\norder, to receive a request.\nBecause the classes shared so much information, it would have been better to\nmerge them into a single class that handles both request reading and parsing.\nThis provides better information hiding, since it isolates all knowledge of the\nrequest format in one class, and it also provides a simpler interface to callers (just\none method to invoke).\nThis example illustrates a general theme in software design: information\nhiding can often be improved by making a class slightly larger. One reason\nfor doing this is to bring together all of the code related to a particular capability\n(such as parsing an HTTP request), so that the resulting class contains everything\n", "page": 44, "type": "text", "section": "Page 44"}
{"text": "related to that capability. A second reason for increasing the size of a class is to\nraise the level of the interface; for example, rather than having separate methods\nfor each of three steps of a computation, have a single method that performs the\nentire computation. This can result in a simpler interface. Both of these benefits\napply in the example of the previous paragraph: combining the classes brings\ntogether all of the code related to parsing an HTTP request, and it replaces two\nexternally-visible methods with one. The combined class is deeper than the\noriginal classes.\nOf course, it is possible to take the notion of larger classes too far (such as a\nsingle class for the entire application). Chapter 9 will discuss conditions under\nwhich it makes sense to separate code into multiple smaller classes.\n5.6    Example: HTTP parameter handling\nAfter an HTTP request has been received by a server, the server needs to access\nsome of the information from the request. The code that handles the request in\nFigure 5.1 might need to know the value of the photo_id parameter. Parameters\ncan be specified in the first line of the request (photo_id in Figure 5.1) or,\nsometimes, in the body (comment and priority in Figure 5.1). Each parameter\nhas a name and a value. The values of parameters use a special encoding called\nURL encoding; for example, in the value for comment in Figure 5.1, \u201c+\u201d is used to\nrepresent a space character, and \u201c%21\u201d is used instead of \u201c!\u201d. In order to process\na request, the server will need the values for some of the parameters, and it will\nwant them in unencoded form.\nMost of the student projects made two good choices with respect to\nparameter handling. First, they recognized that server applications don\u2019t care\nwhether a parameter is specified in the header line or the body of the request, so\nthey hid this distinction from callers and merged the parameters from both\nlocations together. Second, they hid knowledge of URL encoding: the HTTP\nparser decodes parameter values before returning them to the Web server, so that\nthe value of the comment parameter in Figure 5.1 will be returned as \u201cWhat a cute\nbaby!\u201d, not \u201cWhat+a+cute+baby%21\u201d). In both of these cases, information\nhiding resulted in simpler APIs for the code using the HTTP module.\nHowever, most of the students used an interface for returning parameters that\nwas too shallow, and this resulted in lost opportunities for information hiding.\nMost projects used an object of type HTTPRequest to hold the parsed HTTP\n", "page": 45, "type": "text", "section": "Page 45"}
{"text": "request, and the HTTPRequest class had a single method like the following one to\nreturn parameters:\npublic Map<String, String> getParams() {\n       return this.params;\n}\nRather than returning a single parameter, the method returns a reference to the\nMap used internally to store all of the parameters. This method is shallow, and it\nexposes the internal representation used by the HTTPRequest class to store\nparameters. Any change to that representation will result in a change to the\ninterface, which will require modifications to all callers. When implementations\nare modified, the changes often involve changes in the representation of key data\nstructures (to improve performance, for example). Thus, it\u2019s important to avoid\nexposing internal data structures as much as possible. This approach also makes\nmore work for callers: a caller must first invoke getParams, then it must call\nanother method to retrieve a specific parameter from the Map. Finally, callers\nmust realize that they should not modify the Map returned by getParams, since\nthat will affect the internal state of the HTTPRequest.\nHere is a better interface for retrieving parameter values:\npublic String getParameter(String name) { ... }\npublic int getIntParameter(String name) { ... }\ngetParameter returns a parameter value as a string. It provides a slightly deeper\ninterface than getParams above; more importantly, it hides the internal\nrepresentation of parameters. getIntParameter converts the value of a parameter\nfrom its string form in the HTTP request to an integer (e.g., the photo_id\nparameter in Figure 5.1). This saves the caller from having to request string-to-\ninteger conversion separately, and hides that mechanism from the caller.\nAdditional methods for other data types, such as getDoubleParameter, could be\ndefined if needed. (All of these methods will throw exceptions if the desired\nparameter doesn\u2019t exist, or if it can\u2019t be converted to the requested type; the\nexception declarations have been omitted in the code above).\n5.7    Example: defaults in HTTP responses\nThe HTTP projects also had to provide support for generating HTTP responses.\nThe most common mistake students made in this area was inadequate defaults.\nEach HTTP response must specify an HTTP protocol version; one team required\n", "page": 46, "type": "text", "section": "Page 46"}
{"text": "callers to specify this version explicitly when creating a response object.\nHowever, the response version must correspond to that in the request object, and\nthe request must already be passed as an argument when sending the response (it\nindicates where to send the response). Thus, it makes more sense for the HTTP\nclasses to provide the response version automatically. The caller is unlikely to\nknow what version to specify, and if the caller does specify a value, it probably\nresults in information leakage between the HTTP library and the caller. HTTP\nresponses also include a Date header specifying the time when the response was\nsent; the HTTP library should provide a sensible default for this as well.\nDefaults illustrate the principle that interfaces should be designed to make\nthe common case as simple as possible. They are also an example of partial\ninformation hiding: in the normal case, the caller need not be aware of the\nexistence of the defaulted item. In the rare cases where a caller needs to override\na default, it will have to know about the value, and it can invoke a special method\nto modify it.\nWhenever possible, classes should \u201cdo the right thing\u201d without being\nexplicitly asked. Defaults are an example of this. The Java I/O example on page\n26 illustrates this point in a negative way. Buffering in file I/O is so universally\ndesirable that noone should ever have to ask explicitly for it, or even be aware of\nits existence; the I/O classes should do the right thing and provide it\nautomatically. The best features are the ones you get without even knowing they\nexist.\n Red Flag: Overexposure \nIf the API for a commonly used feature forces users to learn about other\nfeatures that are rarely used, this increases the cognitive load on users who\ndon\u2019t need the rarely used features.\n5.8    Information hiding within a class\nThe examples in this chapter focused on information hiding as it relates to the\nexternally visible APIs for classes, but information hiding can also be applied at\nother levels in the system, such as within a class. Try to design the private\nmethods within a class so that each method encapsulates some information or\n", "page": 47, "type": "text", "section": "Page 47"}
{"text": "capability and hides it from the rest of the class. In addition, try to minimize the\nnumber of places where each instance variable is used. Some variables may need\nto be accessed widely across the class, but others may be needed in only a few\nplaces; if you can reduce the number of places where a variable is used, you will\neliminate dependencies within the class and reduce its complexity.\n5.9    Taking it too far\nInformation hiding only makes sense when the information being hidden is not\nneeded outside its module. If the information is needed outside the module, then\nyou must not hide it. Suppose that the performance of a module is affected by\ncertain configuration parameters, and that different uses of the module will\nrequire different settings of the parameters. In this case it is important that the\nparameters are exposed in the interface of the module, so that they can be turned\nappropriately. As a software designer, your goal should be to minimize the\namount of information needed outside a module; for example, if a module can\nautomatically adjust its configuration, that is better than exposing configuration\nparameters. But, it\u2019s important to recognize which information is needed outside\na module and make sure it is exposed.\n5.10     Conclusion\nInformation hiding and deep modules are closely related. If a module hides a lot\nof information, that tends to increase the amount of functionality provided by the\nmodule while also reducing its interface. This makes the module deeper.\nConversely, if a module doesn\u2019t hide much information, then either it doesn\u2019t\nhave much functionality, or it has a complex interface; either way, the module is\nshallow.\nWhen decomposing a system into modules, try not to be influenced by the\norder in which operations will occur at runtime; that will lead you down the path\nof temporal decomposition, which will result in information leakage and shallow\nmodules. Instead, think about the different pieces of knowledge that are needed\nto carry out the tasks of your application, and design each module to encapsulate\none or a few of those pieces of knowledge. This will produce a clean and simple\ndesign with deep modules.\n", "page": 48, "type": "text", "section": "Page 48"}
{"text": "1David Parnas, \u201cOn the Criteria to be Used in Decomposing Systems into Modules,\u201d Communications\nof the ACM, December 1972.\n", "page": 49, "type": "text", "section": "Page 49"}
{"text": "Chapter 6\nGeneral-Purpose Modules are Deeper\nOne of the most common decisions that you will face when designing a new\nmodule is whether to implement it in a general-purpose or special-purpose\nfashion. Some might argue that you should take a general-purpose approach, in\nwhich you implement a mechanism that can be used to address a broad range of\nproblems, not just the ones that are important today. In this case, the new\nmechanism may find unanticipated uses in the future, thereby saving time. The\ngeneral-purpose approach seems consistent with the investment mindset\ndiscussed in Chapter 3, where you spend a bit more time up front to save time\nlater on.\nOn the other hand, we know that it\u2019s hard to predict the future needs of a\nsoftware system, so a general-purpose solution might include facilities that are\nnever actually needed. Furthermore, if you implement something that is too\ngeneral-purpose, it might not do a good job of solving the particular problem you\nhave today. As a result, some might argue that it\u2019s better to focus on today\u2019s\nneeds, building just what you know you need, and specializing it for the way you\nplan to use it today. If you take the special-purpose approach and discover\nadditional uses later, you can always refactor it to make it general-purpose. The\nspecial-purpose approach seems consistent with an incremental approach to\nsoftware development.\n6.1    Make classes somewhat general-purpose\nIn my experience, the sweet spot is to implement new modules in a somewhat\ngeneral-purpose fashion. The phrase \u201csomewhat general-purpose\u201d means that\nthe module\u2019s functionality should reflect your current needs, but its interface\nshould not. Instead, the interface should be general enough to support multiple\nuses. The interface should be easy to use for today\u2019s needs without being tied\nspecifically to them. The word \u201csomewhat\u201d is important: don\u2019t get carried away\n", "page": 50, "type": "text", "section": "Page 50"}
{"text": "and build something so general-purpose that it is difficult to use for your current\nneeds.\nThe most important (and perhaps surprising) benefit of the general-purpose\napproach is that it results in simpler and deeper interfaces than a special-purpose\napproach. The general-purpose approach can also save you time in the future, if\nyou reuse the class for other purposes. However, even if the module is only used\nfor its original purpose, the general-purpose approach is still better because of its\nsimplicity.\n6.2    Example: storing text for an editor\nLet\u2019s consider an example from a software design class in which students were\nasked to build simple GUI text editors. The editors had to display a file and allow\nusers to point, click, and type to edit the file. The editors had to support multiple\nsimultaneous views of the same file in different windows; they also had to\nsupport multi-level undo and redo for modifications to the file.\nEach of the student projects included a class that managed the underlying text\nof the file. The text classes typically provided methods for loading a file into\nmemory, reading and modifying the text of the file, and writing the modified text\nback to a file.\nMany of the student teams implemented special-purpose APIs for the text\nclass. They knew that the class was going to be used in an interactive editor, so\nthey thought about the features that the editor had to provide and tailored the API\nof the text class to those specific features. For example, if a user of the editor\ntyped the backspace key, the editor deleted the character immediately to the left\nof the cursor; if the user typed the delete key, the editor deleted the character\nimmediately to the right of the cursor. Knowing this, some of the teams created\none method in the text class to support each of these specific features:\nvoid backspace(Cursor cursor);\nvoid delete(Cursor cursor);\nEach of these methods takes the cursor position as its argument; a special type\nCursor represents this position. The editor also had to support a selection that\ncould be copied or deleted. The students handled this by defining a Selection\nclass and passing an object of this class to the text class during deletions:\nvoid deleteSelection(Selection selection);\nThe students probably thought that it would be easier to implement the user\ninterface if the methods of the text class corresponded to the features visible to\n", "page": 51, "type": "text", "section": "Page 51"}
{"text": "users. In reality, however, this specialization provided little benefit for the user\ninterface code, and it created a high cognitive load for developers working on\neither the user interface or the text class. The text class ended up with a large\nnumber of shallow methods, each of which was only suitable for one user\ninterface operation. Many of the methods, such as delete, were only invoked in a\nsingle place. As a result, a developer working on the user interface had to learn\nabout a large number of methods for the text class.\nThis approach created information leakage between the user interface and the\ntext class. Abstractions related to the user interface, such as the selection or the\nbackspace key, were reflected in the text class; this increased the cognitive load\nfor developers working on the text class. Each new user interface operation\nrequired a new method to be defined in the text class, so a developer working on\nthe user interface was likely to end up working on the text class as well. One of\nthe goals in class design is to allow each class to be developed independently, but\nthe specialized approach tied the user interface and text classes together.\n6.3    A more general-purpose API\nA better approach is to make the text class more generic. Its API should be\ndefined only in terms of basic text features, without reflecting the higher-level\noperations that will be implemented with it. For example, only two methods are\nneeded for modifying text:\nvoid insert(Position position, String newText);\nvoid delete(Position start, Position end);\nThe first method inserts an arbitrary string at an arbitrary position within the\ntext, and the second method deletes all of the characters at positions greater than\nor equal to start but less than end. This API also uses a more generic type\nPosition instead of Cursor, which reflects a specific user interface. The text\nclass should also provide general-purpose facilities for manipulating positions\nwithin the text, such as the following:\nPosition changePosition(Position position, int numChars);\nThis method returns a new position that is a given number of characters away\nfrom a given position. If the numChars argument is positive, the new position is\nlater in the file than position; if numChars is negative, the new position is before\nposition. The method automatically skips to the next or previous line when\n", "page": 52, "type": "text", "section": "Page 52"}
{"text": "necessary. With these methods, the delete key can be implemented with the\nfollowing code (assuming the cursor variable holds the current cursor position):\ntext.delete(cursor, text.changePosition(cursor, 1));\nSimilarly, the backspace key can be implemented as follows:\ntext.delete(text.changePosition(cursor, -1), cursor);\nWith the general-purpose text API, the code to implement user interface\nfunctions such as delete and backspace is a bit longer than with the original\napproach using a specialized text API. However, the new code is more obvious\nthan the old code. A developer working in the user interface module probably\ncares about which characters are deleted by the backspace key. With the new\ncode, this is obvious. With the old code, the developer had to go to the text class\nand read the documentation and/or code of the backspace method to verify the\nbehavior. Furthermore, the general-purpose approach has less code overall than\nthe specialized approach, since it replaces a large number of special-purpose\nmethods in the text class with a smaller number of general-purpose ones.\nA text class implemented with the general-purpose interface could potentially\nbe used for other purposes besides an interactive editor. As one example, suppose\nyou were building an application that modified a specified file by replacing all\noccurrences of a particular string with another string. Methods from the\nspecialized text class, such as backspace and delete, would have little value for\nthis application. However, the general-purpose text class would already have\nmost of the functionality needed for the new application. All that is missing is a\nmethod to search for the next occurrence of a given string, such as this:\nPosition findNext(Position start, String string);\nOf course, an interactive text editor is likely to have a mechanism for searching\nand replacing, in which case the text class would already include this method.\n6.4    Generality leads to better information hiding\nThe general-purpose approach provides a cleaner separation between the text and\nuser interface classes, which results in better information hiding. The text class\nneed not be aware of specifics of the user interface, such as how the backspace\nkey is handled; these details are now encapsulated in the user interface class.\nNew user interface features can be added without creating new supporting\nfunctions in the text class. The general-purpose interface also reduces cognitive\nload: a developer working on the user interface only needs to learn a few simple\nmethods, which can be reused for a variety of purposes.\n", "page": 53, "type": "text", "section": "Page 53"}
{"text": "The backspace method in the original version of the text class was a false\nabstraction. It purported to hide information about which characters are deleted,\nbut the user interface module really needs to know this; user interface developers\nare likely to read the code of the backspace method in order to confirm its\nprecise behavior. Putting the method in the text class just makes it harder for user\ninterface developers to get the information they need. One of the most important\nelements of software design is determining who needs to know what, and when.\nWhen the details are important, it is better to make them explicit and as obvious\nas possible, such as the revised implementation of the backspace operation.\nHiding this information behind an interface just creates obscurity.\n6.5    Questions to ask yourself\nIt is easier to recognize a clean general-purpose class design than it is to create\none. Here are some questions you can ask yourself, which will help you to find\nthe right balance between general-purpose and special-purpose for an interface.\nWhat is the simplest interface that will cover all my current needs? If you\nreduce the number of methods in an API without reducing its overall capabilities,\nthen you are probably creating more general-purpose methods. The special-\npurpose text API had at least three methods for deleting text: backspace, delete,\nand deleteSelection. The more general-purpose API had only one method for\ndeleting text, which served all three purposes. Reducing the number of methods\nmakes sense only as long as the API for each individual method stays simple; if\nyou have to introduce lots of additional arguments in order to reduce the number\nof methods, then you may not really be simplifying things.\nIn how many situations will this method be used? If a method is designed for\none particular use, such as the backspace method, that is a red flag that it may be\ntoo special-purpose. See if you can replace several special-purpose methods with\na single general-purpose method.\nIs this API easy to use for my current needs? This question can help you to\ndetermine when you have gone too far in making an API simple and general-\npurpose. If you have to write a lot of additional code to use a class for your\ncurrent purpose, that\u2019s a red flag that the interface doesn\u2019t provide the right\nfunctionality. For example, one approach for the text class would be to design it\naround single-character operations: insert inserts a single character and delete\ndeletes a single character. This API is both simple and general-purpose.\n", "page": 54, "type": "text", "section": "Page 54"}
{"text": "However, it would not be particularly easy to use for a text editor: higher-level\ncode would contain lots of loops to insert or delete ranges of characters. The\nsingle-character approach would also be inefficient for large operations. Thus it\u2019s\nbetter for the text class to have built-in support for operations on ranges of\ncharacters.\n6.6    Conclusion\nGeneral-purpose interfaces have many advantages over special-purpose ones.\nThey tend to be simpler, with fewer methods that are deeper. They also provide a\ncleaner separation between classes, whereas special-purpose interfaces tend to\nleak information between classes. Making your modules somewhat general-\npurpose is one of the best ways to reduce overall system complexity.\n", "page": 55, "type": "text", "section": "Page 55"}
{"text": "Chapter 7\nDifferent Layer, Different Abstraction\nSoftware systems are composed in layers, where higher layers use the facilities\nprovided by lower layers. In a well-designed system, each layer provides a\ndifferent abstraction from the layers above and below it; if you follow a single\noperation as it moves up and down through layers by invoking methods, the\nabstractions change with each method call. For example:\nIn a file system, the uppermost layer implements a file abstraction. A file\nconsists of a variable-length array of bytes, which can be updated by\nreading and writing variable-length byte ranges. The next lower layer in the\nfile system implements a cache in memory of fixed-size disk blocks; callers\ncan assume that frequently used blocks will stay in memory where they can\nbe accessed quickly. The lowest layer consists of device drivers, which move\nblocks between secondary storage devices and memory.\nIn a network transport protocol such as TCP, the abstraction provided by the\ntopmost layer is a stream of bytes delivered reliably from one machine to\nanother. This level is built on a lower level that transmits packets of bounded\nsize between machines on a best-effort basis: most packets will be delivered\nsuccessfully, but some packets may be lost or delivered out of order.\nIf a system contains adjacent layers with similar abstractions, this is a red\nflag that suggests a problem with the class decomposition. This chapter discusses\nsituations where this happens, the problems that result, and how to refactor to\neliminate the problems.\n7.1    Pass-through methods\nWhen adjacent layers have similar abstractions, the problem often manifests\nitself in the form of pass-through methods. A pass-through method is one that\ndoes little except invoke another method, whose signature is similar or identical\nto that of the calling method. For example, a student project implementing a GUI\n", "page": 56, "type": "text", "section": "Page 56"}
{"text": "text editor contained a class consisting almost entirely of pass-through methods.\nHere is an extract from that class:\npublic class TextDocument ... {\n        private TextArea textArea;\n        private TextDocumentListener listener;\n        ...\n        public Character getLastTypedCharacter() {\n                return textArea.getLastTypedCharacter();\n        }\n        public int getCursorOffset() {\n                return textArea.getCursorOffset();\n        }\n        public void insertString(String textToInsert,\nint offset) {\n                textArea.insertString(textToInsert, offset);\n        }\n        public void willInsertString(String stringToInsert, int offset) {\n                if (listener != null) {\n                     listener.willInsertString(this, stringToInsert, offset);\n                }\n        }\n        ...\n}\n13 of the 15 public methods in that class were pass-through methods.\n Red Flag: Pass-Through Method \nA pass-through method is one that does nothing except pass its arguments to\nanother method, usually with the same API as the pass-through method. This\ntypically indicates that there is not a clean division of responsibility between\nthe classes.\nPass-through methods make classes shallower: they increase the interface\n", "page": 57, "type": "text", "section": "Page 57"}
{"text": "Pass-through methods make classes shallower: they increase the interface\ncomplexity of the class, which adds complexity, but they don\u2019t increase the total\nfunctionality of the system. Of the four methods above, only the last one has any\nfunctionality, and even there it is trivial: the method checks the validity of one\nvariable. Pass-through methods also create dependencies between classes: if the\nsignature changes for the insertString method in TextArea, then the\ninsertString method in TextDocument will have to change to match.\nPass-through methods indicate that there is confusion over the division of\nresponsibility between classes. In the example above, the TextDocument class\noffers an insertString method, but the functionality for inserting text is\nimplemented entirely in TextArea. This is usually a bad idea: the interface to a\npiece of functionality should be in the same class that implements the\nfunctionality. When you see pass-through methods from one class to another,\nconsider the two classes and ask yourself \u201cExactly which features and\nabstractions is each of these classes responsible for?\u201d You will probably notice\nthat there is an overlap in responsibility between the classes.\nThe solution is to refactor the classes so that each class has a distinct and\ncoherent set of responsibilities. Figure 7.1 illustrates several ways to do this. One\napproach, shown in Figure 7.1(b), is to expose the lower level class directly to the\ncallers of the higher level class, removing all responsibility for the feature from\nthe higher level class. Another approach is to redistribute the functionality\nbetween the classes, as in Figure 7.1(c). Finally, if the classes can\u2019t be\ndisentangled, the best solution may be to merge them as in Figure 7.1(d).\nIn the example above, there were three classes with intertwined\nresponsibilities: \nTextDocument, TextArea, and \nTextDocumentListener. The\nstudent eliminated the pass-through methods by moving methods between\nclasses and collapsing the three classes into just two, whose responsibilities were\nmore clearly differentiated.\n7.2    When is interface duplication OK?\nHaving methods with the same signature is not always bad. The important thing\nis that each new method should contribute significant functionality. Pass-through\nmethods are bad because they contribute no new functionality.\nOne example where it\u2019s useful for a method to call another method with the\nsame signature is a dispatcher. A dispatcher is a method that uses its arguments\n", "page": 58, "type": "text", "section": "Page 58"}
{"text": "to select one of several other methods to invoke; then it passes most or all of its\narguments to the chosen method. The signature for the dispatcher is often the\nsame as the signature for the methods that it calls. Even so, the dispatcher\nprovides useful functionality: it chooses which of several other methods should\ncarry out each task.\nFigure 7.1: Pass-through methods. In (a), class C1 contains three pass-through methods, which do nothing\nbut invoke methods with the same signature in C2 (each symbol represents a particular method signature).\nThe pass-through methods can be eliminated by having C1\u2019s callers invoke C2 directly as in (b), by\nredistributing functionality between C1 and C2 to avoid calls between the classes as in (c), or by combining\nthe classes as in (d).\nFor example, when a Web server receives an incoming HTTP request from a\nWeb browser, it invokes a dispatcher that examines the URL in the incoming\nrequest and selects a specific method to handle the request. Some URLs might be\nhandled by returning the contents of a file on disk; others might be handled by\ninvoking a procedure in a language such as PHP or JavaScript. The dispatch\nprocess can be quite intricate, and is usually driven by a set of rules that are\nmatched against the incoming URL.\nIt is fine for several methods to have the same signature as long as each of\nthem provides useful and distinct functionality. The methods invoked by a\ndispatcher have this property. Another example is interfaces with multiple\nimplementations, such as disk drivers in an operating system. Each driver\nprovides support for a different kind of disk, but they all have the same interface.\nWhen several methods provide different implementations of the same interface,\nit reduces cognitive load. Once you have worked with one of these methods, it\u2019s\neasier to work with the others, since you don\u2019t need to learn a new interface.\nMethods like this are usually in the same layer and they don\u2019t invoke each other.\n", "page": 59, "type": "text", "section": "Page 59"}
{"text": "7.3    Decorators\nThe decorator design pattern (also known as a \u201cwrapper\u201d) is one that encourages\nAPI duplication across layers. A decorator object takes an existing object and\nextends its functionality; it provides an API similar or identical to the underlying\nobject, and its methods invoke the methods of the underlying object. In the Java\nI/O example from Chapter 4, the BufferedInputStream class is a decorator: given\nan InputStream object, it provides the same API but introduces buffering. For\nexample, when its read method is invoked to read a single character, it invokes\nread on the underlying InputStream to read a much larger block, and saves the\nextra characters to satisfy future read calls. Another example occurs in\nwindowing systems: a Window class implements a simple form of window that is\nnot scrollable, and a ScrollableWindow class decorates the Window class by\nadding horizontal and vertical scrollbars.\nThe motivation for decorators is to separate special-purpose extensions of a\nclass from a more generic core. However, decorator classes tend to be shallow:\nthey introduce a large amount of boilerplate for a small amount of new\nfunctionality. Decorator classes often contain many pass-through methods. It\u2019s\neasy to overuse the decorator pattern, creating a new class for every small new\nfeature. This results in an explosion of shallow classes, such as the Java I/O\nexample.\nBefore creating a decorator class, consider alternatives such as the following:\nCould you add the new functionality directly to the underlying class, rather\nthan creating a decorator class? This makes sense if the new functionality is\nrelatively general-purpose, or if it is logically related to the underlying class,\nor if most uses of the underlying class will also use the new functionality.\nFor example, virtually everyone who creates a Java InputStream will also\ncreate a BufferedInputStream, and buffering is a natural part of I/O, so\nthese classes should have been combined.\nIf the new functionality is specialized for a particular use case, would it\nmake sense to merge it with the use case, rather than creating a separate\nclass?\nCould you merge the new functionality with an existing decorator, rather\nthan creating a new decorator? This would result in a single deeper\ndecorator class rather than multiple shallow ones.\nFinally, ask yourself whether the new functionality really needs to wrap the\n", "page": 60, "type": "text", "section": "Page 60"}
{"text": "existing functionality: could you implement it as a stand-alone class that is\nindependent of the base class? In the windowing example, the scrollbars\ncould probably be implemented separately from the main window, without\nwrapping all of its existing functionality.\nSometimes decorators make sense, but there is usually a better alternative.\n7.4    Interface versus implementation\nAnother application of the \u201cdifferent layer, different abstraction\u201d rule is that the\ninterface of a class should normally be different from its implementation: the\nrepresentations used internally should be different from the abstractions that\nappear in the interface. If the two have similar abstractions, then the class\nprobably isn\u2019t very deep. For example, in the text editor project discussed in\nChapter 6, most of the teams implemented the text module in terms of lines of\ntext, with each line stored separately. Some of the teams also designed the APIs\nfor the text class around lines, with methods such as getLine and putLine.\nHowever, this made the text class shallow and awkward to use. In the higher-level\nuser interface code, it\u2019s common to insert text in the middle of a line (e.g., when\nthe user is typing) or to delete a range of text that spans lines. With a line-\noriented API for the text class, callers were forced to split and join lines to\nimplement the user-interface operations. This code was nontrivial and it was\nduplicated and scattered across the implementation of the user interface.\nThe text classes were much easier to use when they provided a character-\noriented interface, such as an insert method that inserts an arbitrary string of\ntext (which may include newlines) at an arbitrary position in the text and a\ndelete method that deletes the text between two arbitrary positions in the text.\nInternally, the text was still represented in terms of lines. A character-oriented\ninterface encapsulates the complexity of line splitting and joining inside the text\nclass, which makes the text class deeper and simplifies higher level code that\nuses the class. With this approach, the text API is quite different from the line-\noriented storage mechanism; the difference represents valuable functionality\nprovided by the class.\n7.5    Pass-through variables\nAnother form of API duplication across layers is a pass-through variable, which\nis a variable that is passed down through a long chain of methods. Figure 7.2(a)\n", "page": 61, "type": "text", "section": "Page 61"}
{"text": "shows an example from a datacenter service. A command-line argument\ndescribes certificates to use for secure communication. This information is only\nneeded by a low-level method m3, which calls a library method to open a socket,\nbut it is passed down through all the methods on the path between main and m3.\nThe cert variable appears in the signature of each of the intermediate methods.\nPass-through variables add complexity because they force all of the\nintermediate methods to be aware of their existence, even though the methods\nhave no use for the variables. Furthermore, if a new variable comes into\nexistence (for example, a system is initially built without support for certificates,\nbut you later decide to add that support), you may have to modify a large number\nof interfaces and methods to pass the variable through all of the relevant paths.\nEliminating pass-through variables can be challenging. One approach is to\nsee if there is already an object shared between the topmost and bottommost\nmethods. In the datacenter service example of Figure 7.2, perhaps there is an\nobject containing other information about network communication, which is\navailable to both main and m3. If so, main can store the certificate information in\nthat object, so it needn\u2019t be passed through all of the intervening methods on the\npath to m3 (see Figure 7.2(b)). However, if there is such an object, then it may\nitself be a pass-through variable (how else does m3 get access to it?).\nAnother approach is to store the information in a global variable, as in Figure\n7.2(c). This avoids the need to pass the information from method to method, but\nglobal variables almost always create other problems. For example, global\nvariables make it impossible to create two independent instances of the same\nsystem in the same process, since accesses to the global variables will conflict. It\nmay seem unlikely that you would need multiple instances in production, but\nthey are often useful in testing.\nThe solution I use most often is to introduce a context object as in Figure\n7.2(d). A context stores all of the application\u2019s global state (anything that would\notherwise be a pass-through variable or global variable). Most applications have\nmultiple variables in their global state, representing things such as configuration\noptions, shared subsystems, and performance counters. There is one context\nobject per instance of the system. The context allows multiple instances of the\nsystem to coexist in a single process, each with its own context.\nUnfortunately, the context will probably be needed in many places, so it can\npotentially become a pass-through variable. To reduce the number of methods\nthat must be aware of it, a reference to the context can be saved in most of the\n", "page": 62, "type": "text", "section": "Page 62"}
{"text": "system\u2019s major objects. In the example of Figure 7.2(d), the class containing m3\nstores a reference to the context as an instance variable in its objects. When a\nnew object is created, the creating method retrieves the context reference from its\nobject and passes it to the constructor for the new object. With this approach, the\ncontext is available everywhere, but it only appears as an explicit argument in\nconstructors.\nFigure 7.2: Possible techniques for dealing with a pass-through variable. In (a), cert is passed through\nmethods m1 and m2 even though they don\u2019t use it. In (b), main and m3 have shared access to an object, so\nthe variable can be stored there instead of passing it through m1 and m2. In (c), cert is stored as a global\nvariable. In (d), cert is stored in a context object along with other system-wide information, such as a\ntimeout value and performance counters; a reference to the context is stored in all objects whose methods\nneed access to it.\nThe context object unifies the handling of all system-global information and\neliminates the need for pass-through variables. If a new variable needs to be\nadded, it can be added to the context object; no existing code is affected except\nfor the constructor and destructor for the context. The context makes it easy to\nidentify and manage the global state of the system, since it is all stored in one\n", "page": 63, "type": "text", "section": "Page 63"}
{"text": "place. The context is also convenient for testing: test code can change the global\nconfiguration of the application by modifying fields in the context. It would be\nmuch more difficult to implement such changes if the system used pass-through\nvariables.\nContexts are far from an ideal solution. The variables stored in a context have\nmost of the disadvantages of global variables; for example, it may not be obvious\nwhy a particular variable is present, or where it is used. Without discipline, a\ncontext can turn into a huge grab-bag of data that creates nonobvious\ndependencies throughout the system. Contexts may also create thread-safety\nissues; the best way to avoid problems is for variables in a context to be\nimmutable. Unfortunately, I haven\u2019t found a better solution than contexts.\n7.6    Conclusion\nEach piece of design infrastructure added to a system, such as an interface,\nargument, function, class, or definition, adds complexity, since developers must\nlearn about this element. In order for an element to provide a net gain against\ncomplexity, it must eliminate some complexity that would be present in the\nabsence of the design element. Otherwise, you are better off implementing the\nsystem without that particular element. For example, a class can reduce\ncomplexity by encapsulating functionality so that users of the class needn\u2019t be\naware of it.\nThe \u201cdifferent layer, different abstraction\u201d rule is just an application of this\nidea: if different layers have the same abstraction, such as pass-through methods\nor decorators, then there\u2019s a good chance that they haven\u2019t provided enough\nbenefit to compensate for the additional infrastructure they represent. Similarly,\npass-through arguments require each of several methods to be aware of their\nexistence (which adds to complexity) without contributing additional\nfunctionality.\n", "page": 64, "type": "text", "section": "Page 64"}
{"text": "Chapter 8\nPull Complexity Downwards\nThis chapter introduces another way of thinking about how to create deeper\nclasses. Suppose that you are developing a new module, and you discover a piece\nof unavoidable complexity. Which is better: should you let users of the module\ndeal with the complexity, or should you handle the complexity internally within\nthe module? If the complexity is related to the functionality provided by the\nmodule, then the second answer is usually the right one. Most modules have\nmore users than developers, so it is better for the developers to suffer than the\nusers. As a module developer, you should strive to make life as easy as possible\nfor the users of your module, even if that means extra work for you. Another way\nof expressing this idea is that it is more important for a module to have a\nsimple interface than a simple implementation.\nAs a developer, it\u2019s tempting to behave in the opposite fashion: solve the easy\nproblems and punt the hard ones to someone else. If a condition arises that\nyou\u2019re not certain how to deal with, the easiest thing is to throw an exception and\nlet the caller handle it. If you are not certain what policy to implement, you can\ndefine a few configuration parameters to control the policy and leave it up to the\nsystem administrator to figure out the best values for them.\nApproaches like these will make your life easier in the short term, but they\namplify complexity, so that many people must deal with a problem, rather than\njust one person. For example, if a class throws an exception, every caller of the\nclass will have to deal with it. If a class exports configuration parameters, every\nsystem administrator in every installation will have to learn how to set them.\n8.1    Example: editor text class\nConsider the class that manages the text of a file for a GUI text editor, which was\ndiscussed in Chapters 6 and 7. The class provides methods to read a file from\ndisk into memory, query and modify the in-memory copy of the file, and write\n", "page": 65, "type": "text", "section": "Page 65"}
{"text": "the modified version back to disk. When students had to implement this class,\nmany of them chose a line-oriented interface, with methods to read, insert, and\ndelete whole lines of text. This resulted in a simple implementation for the class,\nbut it created complexity for higher level software. At the level of the user\ninterface, operations rarely involve whole lines. For example, keystrokes cause\nindividual characters to be inserted within an existing line; copying or deleting\nthe selection can modify parts of several different lines. With the line-oriented\ntext interface, higher-level software had to split and join lines in order to\nimplement the user interface.\nA character-oriented interface such as the one described in Section 6.3 pulls\ncomplexity downward. The user interface software can now insert and delete\narbitrary ranges of text without splitting and merging lines, so it becomes\nsimpler. The implementation of the text class probably becomes more complex:\nif it represents the text internally as a collection of lines, it will have to split and\nmerge lines to implement the character-oriented operations. This approach is\nbetter because it encapsulates the complexity of splitting and merging within the\ntext class, which reduces the overall complexity of the system.\n8.2    Example: configuration parameters\nConfiguration parameters are an example of moving complexity upwards instead\nof down. Rather than determining a particular behavior internally, a class can\nexport a few parameters that control its behavior, such as the size of a cache or\nthe number of times to retry a request before giving up. Users of the class must\nthen specify appropriate values for the parameters. Configuration parameters\nhave become very popular in systems today; some systems have hundreds of\nthem.\nAdvocates argue that configuration parameters are good because they allow\nusers to tune the system for their particular requirements and workloads. In some\nsituations it is hard for low-level infrastructure code to know the best policy to\napply, whereas users are much more familiar with their domains. For instance, a\nuser might know that some requests are more time-critical than others, so it\nmakes sense for the user to specify a higher priority for those requests. In\nsituations like this, configuration parameters can result in better performance\nacross a broader variety of domains.\nHowever, configuration parameters also provide an easy excuse to avoid\ndealing with important issues and pass them on to someone else. In many cases,\n", "page": 66, "type": "text", "section": "Page 66"}
{"text": "it\u2019s difficult or impossible for users or administrators to determine the right\nvalues for the parameters. In other cases, the right values could have been\ndetermined automatically with a little extra work in the system implementation.\nConsider a network protocol that must deal with lost packets. If it sends a request\nbut doesn\u2019t receive a response within a certain time period, it resends the request.\nOne way to determine the retry interval is to introduce a configuration parameter.\nHowever, the transport protocol could compute a reasonable value on its own by\nmeasuring the response time for requests that succeed and then using a multiple\nof this for the retry interval. This approach pulls complexity downward and saves\nusers from having to figure out the right retry interval. It has the additional\nadvantage of computing the retry interval dynamically, so it will adjust\nautomatically if operating conditions change. In contrast, configuration\nparameters can easily become out of date.\nThus, you should avoid configuration parameters as much as possible. Before\nexporting a configuration parameter, ask yourself: \u201cwill users (or higher-level\nmodules) be able to determine a better value than we can determine here?\u201d When\nyou do create configuration parameters, see if you can compute reasonable\ndefaults automatically, so users will only need to provide values under\nexceptional conditions. Ideally, each module should solve a problem completely;\nconfiguration parameters result in an incomplete solution, which adds to system\ncomplexity.\n8.3    Taking it too far\nUse discretion when pulling complexity downward; this is an idea that can easily\nbe overdone. An extreme approach would be to pull all of the functionality of the\nentire application down into a single class, which clearly doesn\u2019t make sense.\nPulling complexity down makes the most sense if (a) the complexity being pulled\ndown is closely related to the class\u2019s existing functionality, (b) pulling the\ncomplexity down will result in many simplifications elsewhere in the application,\nand (c) pulling the complexity down simplifies the class\u2019s interface. Remember\nthat the goal is to minimize overall system complexity.\nChapter 6 described how some students defined methods in the text class that\nreflected the user interface, such as a method that implements the functionality\nof the backspace key. It might seem that this is good, since it pulls complexity\ndownward. However, adding knowledge of the user interface to the text class\ndoesn\u2019t simplify higher-level code very much, and the user-interface knowledge\n", "page": 67, "type": "text", "section": "Page 67"}
{"text": "doesn\u2019t relate to the core functions of the text class. In this case, pulling\ncomplexity down just resulted in information leakage.\n8.4    Conclusion\nWhen developing a module, look for opportunities to take a little bit of extra\nsuffering upon yourself in order to reduce the suffering of your users.\n", "page": 68, "type": "text", "section": "Page 68"}
{"text": "Chapter 9\nBetter Together Or Better Apart?\nOne of the most fundamental questions in software design is this: given two\npieces of functionality, should they be implemented together in the same place,\nor should their implementations be separated? This question applies at all levels\nin a system, such as functions, methods, classes, and services. For example,\nshould buffering be included in the class that provides stream-oriented file I/O,\nor should it be in a separate class? Should the parsing of an HTTP request be\nimplemented entirely in one method, or should it be divided among multiple\nmethods (or even multiple classes)? This chapter discusses the factors to consider\nwhen making these decisions. Some of these factors have already been discussed\nin previous chapters, but they will be revisited here for completeness.\nWhen deciding whether to combine or separate, the goal is to reduce the\ncomplexity of the system as a whole and improve its modularity. It might appear\nthat the best way to achieve this goal is to divide the system into a large number\nof small components: the smaller the components, the simpler each individual\ncomponent is likely to be. However, the act of subdividing creates additional\ncomplexity that was not present before subdivision:\nSome complexity comes just from the number of components: the more\ncomponents, the harder to keep track of them all and the harder to find a\ndesired component within the large collection. Subdivision usually results\nin more interfaces, and every new interface adds complexity.\nSubdivision can result in additional code to manage the components. For\nexample, a piece of code that used a single object before subdivision might\nnow have to manage multiple objects.\nSubdivision creates separation: the subdivided components will be farther\napart than they were before subdivision. For example, methods that were\ntogether in a single class before subdivision may be in different classes after\nsubdivision, and possibly in different files. Separation makes it harder for\ndevelopers to see the components at the same time, or even to be aware of\n", "page": 69, "type": "text", "section": "Page 69"}
{"text": "their existence. If the components are truly independent, then separation is\ngood: it allows the developer to focus on a single component at a time,\nwithout being distracted by the other components. On the other hand, if\nthere are dependencies between the components, then separation is bad:\ndevelopers will end up flipping back and forth between the components.\nEven worse, they may not be aware of the dependencies, which can lead to\nbugs.\nSubdivision can result in duplication: code that was present in a single\ninstance before subdivision may need to be present in each of the\nsubdivided components.\nBringing pieces of code together is most beneficial if they are closely related.\nIf the pieces are unrelated, they are probably better off apart. Here are a few\nindications that two pieces of code are related:\nThey share information; for example, both pieces of code might depend on\nthe syntax of a particular type of document.\nThey are used together: anyone using one of the pieces of code is likely to\nuse the other as well. This form of relationship is only compelling if it is\nbidirectional. As a counter-example, a disk block cache will almost always\ninvolve a hash table, but hash tables can be used in many situations that\ndon\u2019t involve block caches; thus, these modules should be separate.\nThey overlap conceptually, in that there is a simple higher-level category\nthat includes both of the pieces of code. For example, searching for a\nsubstring and case conversion both fall under the category of string\nmanipulation; flow control and reliable delivery both fall under the category\nof network communication.\nIt is hard to understand one of the pieces of code without looking at the\nother.\nThe rest of this chapter uses more specific rules as well as examples to show\nwhen it makes sense to bring pieces of code together and when it makes sense to\nseparate them.\n9.1    Bring together if information is shared\nSection 5.4 introduced this principle in the context of a project implementing an\nHTTP server. In its first implementation, the project used two different methods\nin different classes to read in and parse HTTP requests. The first method read the\ntext of an incoming request from a network socket and placed it in a string\n", "page": 70, "type": "text", "section": "Page 70"}
{"text": "object. The second method parsed the string to extract the various components of\nthe request. With this decomposition, both of the methods ended up with\nconsiderable knowledge of the format of HTTP requests: the first method was\nonly trying to read the request, not parse it, but it couldn\u2019t identify the end of the\nrequest without doing most of the work of parsing it (for example, it had to parse\nheader lines in order to identify the header containing the overall request length).\nBecause of this shared information, it is better to both read and parse the request\nin the same place; when the two classes were combined into one, the code got\nshorter and simpler.\n9.2    Bring together if it will simplify the interface\nWhen two or more modules are combined into a single module, it may be\npossible to define an interface for the new module that is simpler or easier to use\nthan the original interfaces. This often happens when the original modules each\nimplement part of the solution to a problem. In the HTTP server example from\nthe preceding section, the original methods required an interface to return the\nHTTP request string from the first method and pass it to the second. When the\nmethods were combined, these interfaces were eliminated.\nIn addition, when the functionality of two or more classes is combined, it\nmay be possible to perform some functions automatically, so that most users\nneed not be aware of them. The Java I/O library illustrates this opportunity. If the\nFileInputStream and BufferedInputStream classes were combined and buffering\nwere provided by default, the vast majority of users would never even need to be\naware of the existence of buffering. A combined FileInputStream class might\nprovide methods to disable or replace the default buffering mechanism, but most\nusers would not need to learn about them.\n9.3    Bring together to eliminate duplication\nIf you find the same pattern of code repeated over and over, see if you can\nreorganize the code to eliminate the repetition. One approach is to factor the\nrepeated code out into a separate method and replace the repeated code snippets\nwith calls to the method. This approach is most effective if the repeated code\nsnippet is long and the replacement method has a simple signature. If the snippet\nis only one or two lines long, there may not be much benefit in replacing it with a\nmethod call. If the snippet interacts in complex ways with its environment (such\nas by accessing numerous local variables), then the replacement method might\n", "page": 71, "type": "text", "section": "Page 71"}
{"text": "require a complex signature (such as many pass-by-reference arguments), which\nwould reduce its value.\nAnother way to eliminate duplication is to refactor the code so that the\nsnippet in question only needs to be executed in one place. Suppose you are\nwriting a method that needs to return errors at several different points, and the\nsame cleanup actions need to be performed at each of these points before\nreturning (see Figure 9.1 for an example). If the programming language supports\ngoto, you can move the cleanup code to the very end of the method and then goto\nthat snippet at each of the points where an error return is required, as in Figure\n9.2. Goto statements are generally considered a bad idea, and they can result in\nindecipherable code if used indiscriminately, but they are useful in situations like\nthis where they are used to escape from nested code.\n9.4    Separate general-purpose and special-purpose code\nIf a module contains a mechanism that can be used for several different purposes,\nthen it should provide just that one general-purpose mechanism. It should not\ninclude code that specializes the mechanism for a particular use, nor should it\ncontain other general-purpose mechanisms. Special-purpose code associated\nwith a general-purpose mechanism should normally go in a different module\n(typically one associated with the particular purpose). The GUI editor discussion\nin Chapter 6 illustrated this principle: the best design was one where the text\nclass provided general-purpose text operations, while operations particular to the\nuser interface (such as deleting the selection) were implemented in the user\ninterface module. This approach eliminated information leakage and additional\ninterfaces that were present in an earlier design where the specialized user\ninterface operations were implemented in the text class.\n Red Flag: Repetition \nIf the same piece of code (or code that is almost the same) appears over and\nover again, that\u2019s a red flag that you haven\u2019t found the right abstractions.\n", "page": 72, "type": "text", "section": "Page 72"}
{"text": "Figure 9.1: This code processes incoming network packets of different types; for each type, if the packet is\ntoo short for that type, a message gets logged. In this version of the code, the LOG statement is duplicated\nfor several different packet types.\n", "page": 73, "type": "text", "section": "Page 73"}
{"text": "Figure 9.2: A reorganization of the code from Figure 9.1 so that there is only one copy of the LOG\nstatement.\nIn general, the lower layers of a system tend to be more general-purpose and\nthe upper layers more special-purpose. For example, the topmost layer of an\napplication consists of features totally specific to that application. The way to\nseparate special-purpose code from general-purpose code is to pull the special-\npurpose code upwards, into the higher layers, leaving the lower layers general-\npurpose. When you encounter a class that includes both general-purpose and\nspecial-purpose features for the same abstraction, see if the class can be\nseparated into two classes, one containing the general-purpose features, and the\nother layered on top of it to provide the special-purpose features.\n9.5    Example: insertion cursor and selection\nThe next sections work through three examples that illustrate the principles\ndiscussed above. In two of the examples the best approach is to separate the\nrelevant pieces of code; in the third example it is better to join them together.\nThe first example consists of the insertion cursor and the selection in the GUI\neditor project from Chapter 6. The editor displayed a blinking vertical line\nindicating where text typed by the user would appear in the document. It also\ndisplayed a highlighted range of characters called the selection, which was used\nfor copying or deleting text. The insertion cursor was always visible, but there\ncould be times when no text was selected. If the selection existed, the insertion\ncursor was always positioned at one end of it.\nThe selection and insertion cursor are related in some ways. For example, the\ncursor is always positioned at one end of the selection, and the cursor and\nselection tend to be manipulated together: clicking and dragging the mouse sets\nboth of them, and text insertion first deletes the selected text, if there is any, and\nthen inserts new text at the cursor position. Thus, it might seem logical to use a\nsingle object to manage both the selection and the cursor, and one project team\ntook this approach. The object stored two positions in the file, along with\nbooleans indicating which end was the cursor and whether the selection existed.\nHowever, the combined object was awkward. It provided no benefit for\nhigher-level code, since the higher-level code still needed to be aware of the\nselection and cursor as distinct entities, and it manipulated them separately\n(during text insertion, it first invoked a method on the combined object to delete\n", "page": 74, "type": "text", "section": "Page 74"}
{"text": "the selected text; then it invoked another method to retrieve the cursor position in\norder to insert new text). The combined object was actually more complex to\nimplement than separate objects. It avoided storing the cursor position as a\nseparate entity, but instead had to store a boolean indicating which end of the\nselection was the cursor. In order to retrieve the cursor position, the combined\nobject had to first test the boolean and then choose the appropriate end of the\nselection.\n Red Flag: Special-General Mixture \nThis red flag occurs when a general-purpose mechanism also contains code\nspecialized for a particular use of that mechanism. This makes the mechanism\nmore complicated and creates information leakage between the mechanism\nand the particular use case: future modifications to the use case are likely to\nrequire changes to the underlying mechanism as well.\nIn this case, the selection and cursor were not closely enough related to\ncombine them. When the code was revised to separate the selection and the\ncursor, both the usage and the implementation became simpler. Separate objects\nprovided a simpler interface than a combined object from which selection and\ncursor information had to be extracted. The cursor implementation also got\nsimpler because the cursor position was represented directly, rather than\nindirectly through a selection and a boolean. In fact, in the revised version no\nspecial classes were used for either the selection or the cursor. Instead, a new\nPosition class was introduced to represent a location in the file (a line number\nand character within line). The selection was represented with two Positions and\nthe cursor with one. Positions also found other uses in the project. This example\nalso demonstrates the benefits of a lower-level but more general-purpose\ninterface, which were discussed in Chapter 6.\n9.6    Example: separate class for logging\nThe second example involved error logging in a student project. A class\ncontained several code sequences like the following:\ntry {\n", "page": 75, "type": "text", "section": "Page 75"}
{"text": "      rpcConn = connectionPool.getConnection(dest);\n} catch (IOException e) {\n      NetworkErrorLogger.logRpcOpenError(req, dest, e);\n      return null;\n}\nRather than logging the error at the point where it was detected, a separate\nmethod in a special error logging class was invoked. The error logging class was\ndefined at the end of the same source file:\nprivate static class NetworkErrorLogger {\n     /**\n      *  Output information relevant to an error that occurs when trying\n      *  to open a connection to send an RPC.\n      *\n      *  @param req\n      *       The RPC request that would have been sent through the\nconnection\n      *  @param dest\n      *       The destination of the RPC\n      *  @param e\n      *       The caught error\n      */\n     public static void logRpcOpenError(RpcRequest req, AddrPortTuple\ndest, Exception e) {\n         logger.log(Level.WARNING, \"Cannot send message: \" + req + \". \\n\" +\n\"Unable to find or open connection to \" + dest + \" :\" +\ne);\n      }\n...\n}\nThe \nNetworkErrorLogger \nclass \ncontained \nseveral \nmethods \nsuch \nas\nlogRpcSendError and logRpcReceiveError, each of which logged a different kind\nof error.\nThis separation added complexity with no benefit. The logging methods were\nshallow: most consisted of a single line of code, but they required a considerable\namount of documentation. Each method was only invoked in a single place. The\n", "page": 76, "type": "text", "section": "Page 76"}
{"text": "logging methods were highly dependent on their invocations: someone reading\nthe invocation would most likely flip over to the logging method to make sure\nthat the right information was being logged; similarly, someone reading the\nlogging method would probably flip over to the invocation site to understand the\npurpose of the method.\nIn this example, it would be better to eliminate the logging methods and\nplace the logging statements at the locations where the errors were detected. This\nwould make the code easier to read and eliminate the interfaces required for the\nlogging methods.\n9.7    Example: editor undo mechanism\nIn the GUI editor project from Section 6.2, one of the requirements was to\nsupport multi-level undo/redo, not just for changes to the text itself, but also for\nchanges in the selection, insertion cursor, and view. For example, if a user\nselected some text, deleted it, scrolled to a different place in the file, and then\ninvoked undo, the editor had to restore its state to what it was just before the\ndeletion. This included restoring the deleted text, selecting it again, and also\nmaking the selected text visible in the window.\nSome of the student projects implemented the entire undo mechanism as part\nof the text class. The text class maintained a list of all the undoable changes. It\nautomatically added entries to this list whenever the text was changed. For\nchanges to the selection, insertion cursor, and view, the user interface code\ninvoked additional methods in the text class, which then added entries for those\nchanges to the undo list. When undo or redo was requested by the user, the user\ninterface code invoked a method in the text class, which then processed the\nentries in the undo list. For entries related to text, it updated the internals of the\ntext class; for entries related to other things, such as the selection, the text class\ncalled back to the user interface code to carry out the undo or redo.\nThis approach resulted in an awkward set of features in the text class. The\ncore of undo/redo consists of a general-purpose mechanism for managing a list\nof actions that have been executed and stepping through them during undo and\nredo operations. The core was located in the text class along with special-\npurpose handlers that implemented undo and redo for specific things such as text\nand the selection. The special-purpose undo handlers for the selection and the\ncursor had nothing to do with anything else in the text class; they resulted in\ninformation leakage between the text class and the user interface, as well as extra\n", "page": 77, "type": "text", "section": "Page 77"}
{"text": "methods in each module to pass undo information back and forth. If a new sort\nof undoable entity were added to the system in the future, it would require\nchanges to the text class, including new methods specific to that entity. In\naddition, the general-purpose undo core had little to do with the general-purpose\ntext facilities in the class.\nThese problems can be solved by extracting the general-purpose core of the\nundo/redo mechanism and placing it in a separate class:\npublic class History {\n        public interface Action {\n               public void redo();\n               public void undo();\n        }\n        History() {...}\n        void addAction(Action action) {...}\n        void addFence() {...}\n        void undo() {...}\n        void redo() {...}\n}\nIn this design, the History class manages a collection of objects that implement\nthe interface History.Action. Each History.Action describes a single operation,\nsuch as a text insertion or a change in the cursor location, and it provides\nmethods that can undo or redo the operation. The History class knows nothing\nabout the information stored in the actions or how they implement their undo and\nredo methods. History maintains a history list describing all of the actions\nexecuted over the lifetime of an application, and it provides undo and redo\nmethods that walk backwards and forwards through the list in response to user-\nrequested undos and redos, calling \nundo and \nredo methods in the\nHistory.Actions.\nHistory.Actions are special-purpose objects: each one understands a\nparticular kind of undoable operation. They are implemented outside the History\nclass, in modules that understand particular kinds of undoable actions. The text\nclass might implement UndoableInsert and UndoableDelete objects to describe\n", "page": 78, "type": "text", "section": "Page 78"}
{"text": "text insertions and deletions. Whenever it inserts text, the text class creates a new\nUndoableInsert object describing the insertion and invokes History.addAction\nto add it to the history list. The editor\u2019s user interface code might create\nUndoableSelection and UndoableCursor objects that describe changes to the\nselection and insertion cursor.\nThe History class also allows actions to be grouped so that, for example, a\nsingle undo request from the user can restore deleted text, reselect the deleted\ntext, and reposition the insertion cursor. There are a number of ways to group\nactions; the History class uses fences, which are markers placed in the history\nlist to separate groups of related actions. Each call to History.redo walks\nbackwards through the history list, undoing actions until it reaches the next\nfence. The placement of fences is determined by higher-level code by invoking\nHistory.addFence.\nThis approach divides the functionality of undo into three categories, each of\nwhich is implemented in a different place:\nA general-purpose mechanism for managing and grouping actions and\ninvoking undo/redo operations (implemented by the History class).\nThe specifics of particular actions (implemented by a variety of classes,\neach of which understands a small number of action types).\nThe policy for grouping actions (implemented by high-level user interface\ncode to provide the right overall application behavior).\nEach of these categories can be implemented without any understanding of the\nother categories. The History class does not know what kind of actions are being\nundone; it could be used in a variety of applications. Each action class\nunderstands only a single kind of action, and neither the History class nor the\naction classes needs to be aware of the policy for grouping actions.\nThe key design decision was the one that separated the general-purpose part\nof the undo mechanism from the special-purpose parts and put the general-\npurpose part in a class by itself. Once that was done, the rest of the design fell\nout naturally.\nNote: the suggestion to separate general-purpose code from special-purpose\ncode refers to code related to a particular mechanism. For example, special-\npurpose undo code (such as code to undo a text insertion) should be separated\nfrom general-purpose undo code (such as code to manage the history list).\nHowever, it often makes sense to combine special-purpose code for one\n", "page": 79, "type": "text", "section": "Page 79"}
{"text": "mechanism with general-purpose code for another. The text class is an example\nof this: it implements a general-purpose mechanism for managing text, but it\nincludes special-purpose code related to undoing. The undo code is special-\npurpose because it only handles undo operations for text modifications. It doesn\u2019t\nmake sense to combine this code with the general-purpose undo infrastructure in\nthe History class, but it does make sense to put it in the text class, since it is\nclosely related to other text functions.\n9.8    Splitting and joining methods\nThe issue of when to subdivide applies not just to classes, but also to methods:\nare there times when it is better to divide an existing method into multiple\nsmaller methods? Or, should two smaller methods be combined into one larger\none? Long methods tend to be more difficult to understand than shorter ones, so\nmany people argue that length alone is a good justification for breaking up a\nmethod. Students in classes are often given rigid criteria, such as \u201cSplit up any\nmethod longer than 20 lines!\u201d\nHowever, length by itself is rarely a good reason for splitting up a method. In\ngeneral, developers tend to break up methods too much. Splitting up a method\nintroduces additional interfaces, which add to complexity. It also separates the\npieces of the original method, which makes the code harder to read if the pieces\nare actually related. You shouldn\u2019t break up a method unless it makes the overall\nsystem simpler; I\u2019ll discuss how this might happen below.\nLong methods aren\u2019t always bad. For example, suppose a method contains\nfive 20-line blocks of code that are executed in order. If the blocks are relatively\nindependent, then the method can be read and understood one block at a time;\nthere\u2019s not much benefit in moving each of the blocks into a separate method. If\nthe blocks have complex interactions, it\u2019s even more important to keep them\ntogether so readers can see all of the code at once; if each block is in a separate\nmethod, readers will have to flip back and forth between these spread-out\nmethods in order to understand how they work together. Methods containing\nhundreds of lines of code are fine if they have a simple signature and are easy to\nread. These methods are deep (lots of functionality, simple interface), which is\ngood.\n", "page": 80, "type": "text", "section": "Page 80"}
{"text": "Figure 9.3: A method (a) can be split either by by extracting a subtask (b) or by dividing its functionality\ninto two separate methods (c). A method should not be split if it results in shallow methods, as in (d).\nWhen designing methods, the most important goal is to provide clean and\nsimple abstractions. Each method should do one thing and do it completely.\nThe method should have a clean and simple interface, so that users don\u2019t need to\nhave much information in their heads in order to use it correctly. The method\nshould be deep: its interface should be much simpler than its implementation. If\na method has all of these properties, then it probably doesn\u2019t matter whether it is\nlong or not.\nSplitting up a method only makes sense if it results in cleaner abstractions,\noverall. There are two ways to do this, which are diagrammed in Figure 9.3. The\nbest way is by factoring out a subtask into a separate method, as shown in Figure\n9.3(b). The subdivision results in a child method containing the subtask and a\nparent method containing the remainder of the original method; the parent\ninvokes the child. The interface of the new parent method is the same as the\noriginal method. This form of subdivision makes sense if there is a subtask that\nis cleanly separable from the rest of the original method, which means (a)\nsomeone reading the child method doesn\u2019t need to know anything about the\nparent method and (b) someone reading the parent method doesn\u2019t need to\nunderstand the implementation of the child method. Typically this means that the\nchild method is relatively general-purpose: it could conceivably be used by other\nmethods besides the parent. If you make a split of this form and then find\nyourself flipping back and forth between the parent and child to understand how\nthey work together, that is a red flag (\u201cConjoined Methods\u201d) indicating that the\nsplit was probably a bad idea.\nThe second way to break up a method is to split it into two separate methods,\neach visible to callers of the original method, as in Figure 9.3(c). This makes\nsense if the original method had an overly complex interface because it tried to\ndo multiple things that were not closely related. If this is the case, it may be\n", "page": 81, "type": "text", "section": "Page 81"}
{"text": "possible to divide the method\u2019s functionality into two or more smaller methods,\neach of which has only a part of the original method\u2019s functionality. If you make\na split like this, the interface for each of the resulting methods should be simpler\nthan the interface of the original method. Ideally, most callers should only need\nto invoke one of the two new methods; if callers must invoke both of the new\nmethods, then that adds complexity, which makes it less likely that the split is a\ngood idea. The new methods will be more focused in what they do. It is a good\nsign if the new methods are more general-purpose than the original method (i.e.,\nyou can imagine using them separately in other situations).\nSplits of the form shown in Figure 9.3(c) don\u2019t make sense very often,\nbecause they result in callers having to deal with multiple methods instead of\none. When you split this way, you run the risk of ending up with several shallow\nmethods, as in Figure 9.3(d). If the caller has to invoke each of the separate\nmethods, passing state back and forth between them, then splitting is not a good\nidea. If you\u2019re considering a split like the one in Figure 9.3(c), you should judge\nit based on whether it simplifies things for callers.\nThere are also situations where a system can be made simpler by joining\nmethods together. For example, joining methods might replace two shallow\nmethods with one deeper method; it might eliminate duplication of code; it\nmight eliminate dependencies between the original methods, or intermediate data\nstructures; it might result in better encapsulation, so that knowledge that was\npreviously present in multiple places is now isolated in a single place; or it might\nresult in a simpler interface, as discussed in Section 9.2.\n Red Flag: Conjoined Methods \nIt should be possible to understand each method independently. If you can\u2019t\nunderstand the implementation of one method without also understanding the\nimplementation of another, that\u2019s a red flag. This red flag can occur in other\ncontexts as well: if two pieces of code are physically separated, but each can\nonly be understood by looking at the other, that is a red flag.\n9.9    Conclusion\nThe decision to split or join modules should be based on complexity. Pick the\n", "page": 82, "type": "text", "section": "Page 82"}
{"text": "The decision to split or join modules should be based on complexity. Pick the\nstructure that results in the best information hiding, the fewest dependencies, and\nthe deepest interfaces.\n", "page": 83, "type": "text", "section": "Page 83"}
{"text": "Chapter 10\nDefine Errors Out Of Existence\nException handling is one of the worst sources of complexity in software\nsystems. Code that deals with special conditions is inherently harder to write\nthan code that deals with normal cases, and developers often define exceptions\nwithout considering how they will be handled. This chapter discusses why\nexceptions contribute disproportionately to complexity, then it shows how to\nsimplify exception handling. The key overall lesson from this chapter is to reduce\nthe number of places where exceptions must be handled; in many cases the\nsemantics of operations can be modified so that the normal behavior handles all\nsituations and there is no exceptional condition to report (hence the title of this\nchapter).\n10.1  Why exceptions add complexity\nI use the term exception to refer to any uncommon condition that alters the\nnormal flow of control in a program. Many programming languages include a\nformal exception mechanism that allows exceptions to be thrown by lower-level\ncode and caught by enclosing code. However, exceptions can occur even without\nusing a formal exception reporting mechanism, such as when a method returns a\nspecial value indicating that it didn\u2019t complete its normal behavior. All of these\nforms of exceptions contribute to complexity.\nA particular piece of code may encounter exceptions in several different\nways:\nA caller may provide bad arguments or configuration information.\nAn invoked method may not be able to complete a requested operation. For\nexample, an I/O operation may fail, or a required resource may not be\navailable.\nIn a distributed system, network packets may be lost or delayed, servers may\nnot respond in a timely fashion, or peers may communicate in unexpected\nways.\n", "page": 84, "type": "text", "section": "Page 84"}
{"text": "The code may detect bugs, internal inconsistencies, or situations it is not\nprepared to handle.\nLarge systems have to deal with many exceptional conditions, particularly if they\nare distributed or need to be fault-tolerant. Exception handling can account for a\nsignificant fraction of all the code in a system.\nException handling code is inherently more difficult to write than normal-\ncase code. An exception disrupts the normal flow of the code; it usually means\nthat something didn\u2019t work as expected. When an exception occurs, the\nprogrammer can deal with it in two ways, each of which can be complicated. The\nfirst approach is to move forward and complete the work in progress in spite of\nthe exception. For example, if a network packet is lost, it can be resent; if data is\ncorrupted, perhaps it can be recovered from a redundant copy. The second\napproach is to abort the operation in progress and report the exception upwards.\nHowever, aborting can be complicated because the exception may have occurred\nat a point where system state is inconsistent (a data structure might have been\npartially initialized); the exception handling code must restore consistency, such\nas by unwinding any changes made before the exception occurred.\nFurthermore, exception handling code creates opportunities for more\nexceptions. Consider the case of resending a lost network packet. Perhaps the\npacket wasn\u2019t actually lost, but was simply delayed. In this case, resending the\npacket will result in duplicate packets arriving at the peer; this introduces a new\nexceptional condition that the peer must handle. Or, consider the case of\nrecovering lost data from a redundant copy: what if the redundant copy has also\nbeen lost? Secondary exceptions occurring during recovery are often more subtle\nand complex than the primary exceptions. If an exception is handled by aborting\nthe operation in progress, then this must be reported to the caller as another\nexception. To prevent an unending cascade of exceptions, the developer must\neventually find a way to handle exceptions without introducing more exceptions.\nLanguage support for exceptions tends to be verbose and clunky, which\nmakes exception handling code hard to read. For example, consider the following\ncode, which reads a collection of tweets from a file using Java\u2019s support for\nobject serialization and deserialization:\ntry (\n      FileInputStream fileStream =\n                   new FileInputStream(fileName);\n      BufferedInputStream bufferedStream =\n", "page": 85, "type": "text", "section": "Page 85"}
{"text": "                   new BufferedInputStream(fileStream);\n      ObjectInputStream objectStream =\n                   new ObjectInputStream(bufferedStream);\n) {\n      for (int i = 0; i < tweetsPerFile; i++) {\n            tweets.add((Tweet) objectStream.readObject());\n      }\n}\ncatch (FileNotFoundException e) {\n      ...\n}\ncatch (ClassNotFoundException e) {\n      ...\n}\ncatch (EOFException e) {\n      // Not a problem: not all tweet files have full\n      // set of tweets.\n}\ncatch (IOException e) {\n      ...\n}\ncatch (ClassCastException e) {\n      ...\n}\nJust the basic try-catch boilerplate accounts for more lines of code than the\ncode for normal-case operation, without even considering the code that actually\nhandles the exceptions. It is hard to relate the exception handling code to the\nnormal-case code: for example, it\u2019s not obvious where each exception is\ngenerated. An alternative approach is to break up the code into many distinct try\nblocks; in the extreme case there could be a try for each line of code that can\ngenerate an exception. This would make it clear where exceptions occur, but the\ntry blocks themselves break up the flow of the code and make it harder to read;\nin addition, some exception handling code might end up duplicated in multiple\ntry blocks.\nIt\u2019s difficult to ensure that exception handling code really works. Some\n", "page": 86, "type": "text", "section": "Page 86"}
{"text": "It\u2019s difficult to ensure that exception handling code really works. Some\nexceptions, such as I/O errors, can\u2019t easily be generated in a test environment, so\nit\u2019s hard to test the code that handles them. Exceptions don\u2019t occur very often in\nrunning systems, so exception handling code rarely executes. Bugs can go\nundetected for a long time, and when the exception handling code is finally\nneeded, there\u2019s a good chance that it won\u2019t work (one of my favorite sayings:\n\u201ccode that hasn\u2019t been executed doesn\u2019t work\u201d). A recent study found that more\nthan 90% of catastrophic failures in distributed data-intensive systems were\ncaused by incorrect error handling1. When exception handling code fails, it\u2019s\ndifficult to debug the problem, since it occurs so infrequently.\n10.2  Too many exceptions\nProgrammers exacerbate the problems related to exception handling by defining\nunnecessary exceptions. Most programmers are taught that it\u2019s important to\ndetect and report errors; they often interpret this to mean \u201cthe more errors\ndetected, the better.\u201d This leads to an over-defensive style where anything that\nlooks even a bit suspicious is rejected with an exception, which results in a\nproliferation of unnecessary exceptions that increase the complexity of the\nsystem.\nI made this mistake myself in the design of the Tcl scripting language. Tcl\ncontains an unset command that can be used to remove a variable. I defined\nunset so that it throws an error if the variable doesn\u2019t exist. At the time I thought\nthat it must be a bug if someone tries to delete a variable that doesn\u2019t exist, so Tcl\nshould report it. However, one of the most common uses of unset is to clean up\ntemporary state created by some previous operation. It\u2019s often hard to predict\nexactly what state was created, particularly if the operation aborted partway\nthrough. Thus, the simplest thing is to delete all of the variables that might\npossibly have been created. The definition of unset makes this awkward:\ndevelopers end up enclosing calls to unset in catch statements to catch and\nignore errors thrown by unset. In retrospect, the definition of the unset\ncommand is one of the biggest mistakes I made in the design of Tcl.\nIt\u2019s tempting to use exceptions to avoid dealing with difficult situations:\nrather than figuring out a clean way to handle it, just throw an exception and punt\nthe problem to the caller. Some might argue that this approach empowers callers,\nsince it allows each caller to handle the exception in a different way. However, if\nyou are having trouble figuring out what to do for the particular situation, there\u2019s\n", "page": 87, "type": "text", "section": "Page 87"}
{"text": "a good chance that the caller won\u2019t know what to do either. Generating an\nexception in a situation like this just passes the problem to someone else and\nadds to the system\u2019s complexity.\nThe exceptions thrown by a class are part of its interface; classes with lots of\nexceptions have complex interfaces, and they are shallower than classes with\nfewer exceptions. An exception is a particularly complex element of an interface.\nIt can propagate up through several stack levels before being caught, so it affects\nnot just the method\u2019s caller, but potentially also higher-level callers (and their\ninterfaces).\nThrowing exceptions is easy; handling them is hard. Thus, the complexity of\nexceptions comes from the exception handling code. The best way to reduce the\ncomplexity damage caused by exception handling is to reduce the number of\nplaces where exceptions have to be handled. The rest of this chapter will\ndiscuss four techniques for reducing the number of exception handlers.\n10.3  Define errors out of existence\nThe best way to eliminate exception handling complexity is to define your APIs\nso that there are no exceptions to handle: define errors out of existence. This\nmay seem sacrilegious, but it is very effective in practice. Consider the Tcl unset\ncommand discussed above. Rather than throwing an error when unset is asked to\ndelete an unknown variable, it should have simply returned without doing\nanything. I should have changed the definition of unset slightly: rather than\ndeleting a variable, unset should ensure that a variable no longer exists. With the\nfirst definition, unset can\u2019t do its job if the variable doesn\u2019t exist, so generating\nan exception makes sense. With the second definition, it is perfectly natural for\nunset to be invoked with the name of a variable that doesn\u2019t exist. In this case, its\nwork is already done, so it can simply return. There is no longer an error case to\nreport.\n10.4  Example: file deletion in Windows\nFile deletion provides another example of how errors can be defined away. The\nWindows operating system does not permit a file to be deleted if it is open in a\nprocess. This is a continual source of frustration for developers and users. In\norder to delete a file that is in use, the user must search through the system to\n", "page": 88, "type": "text", "section": "Page 88"}
{"text": "find the process that has the file open, and then kill that process. Sometimes\nusers give up and reboot their system, just so they can delete a file.\nThe Unix operating system defines file deletion more elegantly. In Unix, if a\nfile is open when it is deleted, Unix does not delete the file immediately. Instead,\nit marks the file for deletion, then the delete operation returns successfully. The\nfile name has been removed from its directory, so no other processes can open\nthe old file and a new file with the same name can be created, but the existing\nfile data persists. Processes that already have the file open can continue to read it\nand write it normally. Once the file has been closed by all of the accessing\nprocesses, its data is freed.\nThe Unix approach defines away two different kinds of errors. First, the\ndelete operation no longer returns an error if the file is currently in use; the\ndelete succeeds, and the file will eventually be deleted. Second, deleting a file\nthat\u2019s in use does not create exceptions for the processes using the file. One\npossible approach to this problem would have been to delete the file immediately\nand mark all of the opens of the file to disable them; any attempts by other\nprocesses to read or write the deleted file would fail. However, this approach\nwould create new errors for those processes to handle. Instead, Unix allows them\nto keep accessing the file normally; delaying the file deletion defines errors out\nof existence.\nIt may seem strange that Unix allows a process to continue to read and write\na doomed file, but I have never encountered a situation where this caused\nsignificant problems. The Unix definition of file deletion is much simpler to\nwork with, both for developers and users, than the Windows definition.\n10.5  Example: Java substring method\nAs a final example, consider the Java String class and its substring method.\nGiven two indexes into a string, substring returns the substring starting at the\ncharacter given by the first index and ending with the character just before the\nsecond index. However, if either index is outside the range of the string, then\nsubstring throws IndexOutOfBoundsException. This exception is unnecessary\nand complicates the use of this method. I often find myself in a situation where\none or both of the indices may be outside the range of the string, and I would like\nto extract all of the characters in the string that overlap the specified range.\nUnfortunately, this requires me to check each of the indices and round them up to\n", "page": 89, "type": "text", "section": "Page 89"}
{"text": "zero or down to the end of the string; a one-line method call now becomes 5\u201310\nlines of code.\nThe Java substring method would be easier to use if it performed this\nadjustment automatically, so that it implemented the following API: \u201creturns the\ncharacters of the string (if any) with index greater than or equal to beginIndex\nand less than endIndex.\u201d This is a simple and natural API, and it defines the\nIndexOutOfBoundsException exception out of existence. The method\u2019s behavior is\nnow well-defined even if one or both of the indexes are negative, or if beginIndex\nis greater than endIndex. This approach simplifies the API for the method while\nincreasing its functionality, so it makes the method deeper. Many other languages\nhave taken the error-free approach; for example, Python returns an empty result\nfor out-of-range list slices.\nWhen I argue for defining errors out of existence, people sometimes counter\nthat throwing errors will catch bugs; if errors are defined out of existence, won\u2019t\nthat result in buggier software? Perhaps this is why the Java developers decided\nthat substring should throw exceptions. The error-ful approach may catch some\nbugs, but it also increases complexity, which results in other bugs. In the error-\nful approach, developers must write additional code to avoid or ignore the errors,\nand this increases the likelihood of bugs; or, they may forget to write the\nadditional code, in which case unexpected errors may be thrown at runtime. In\ncontrast, defining errors out of existence simplifies APIs and it reduces the\namount of code that must be written.\nOverall, the best way to reduce bugs is to make software simpler.\n10.6  Mask exceptions\nThe second technique for reducing the number of places where exceptions must\nbe handled is exception masking. With this approach, an exceptional condition is\ndetected and handled at a low level in the system, so that higher levels of\nsoftware need not be aware of the condition. Exception masking is particularly\ncommon in distributed systems. For instance, in a network transport protocol\nsuch as TCP, packets can be dropped for various reasons such as corruption and\ncongestion. TCP masks packet loss by resending lost packets within its\nimplementation, so all data eventually gets through and clients are unaware of the\ndropped packets.\nA more controversial example of masking occurs in the NFS network file\n", "page": 90, "type": "text", "section": "Page 90"}
{"text": "A more controversial example of masking occurs in the NFS network file\nsystem. If an NFS file server crashes or fails to respond for any reason, clients\nreissue their requests to the server over and over again until the problem is\neventually resolved. The low-level file system code on the client does not report\nany exceptions to the invoking application. The operation in progress (and hence\nthe application) just hangs until the operation can complete successfully. If the\nhang lasts more than a short time, the NFS client prints messages on the user\u2019s\nconsole of the form \u201cNFS server xyzzy not responding still trying.\u201d\nNFS users often complain about the fact that their applications hang while\nwaiting for an NFS server to resume normal operation. Many people have\nsuggested that NFS should abort operations with an exception rather than\nhanging. However, reporting exceptions would make things worse, not better.\nThere\u2019s not much an application can do if it loses access to its files. One\npossibility would be for the application to retry the file operation, but this would\nstill hang the application, and it\u2019s easier to perform the retry in one place in the\nNFS layer, rather than at every file system call in every application (a compiler\nshouldn\u2019t have to worry about this!). The other alternative is for applications to\nabort and return errors to their callers. It\u2019s unlikely that the callers would know\nwhat to do either, so they would abort as well, resulting in a collapse of the user\u2019s\nworking environment. Users still wouldn\u2019t be able to get any work done while the\nfile server was down, and they would have to restart all of their applications once\nthe file server came back to life.\nThus, the best alternative is for NFS to mask the errors and hang\napplications. With this approach, applications don\u2019t need any code to deal with\nserver problems, and they can resume seamlessly once the server comes back to\nlife. If users get tired of waiting, they can always abort applications manually.\nException masking doesn\u2019t work in all situations, but it is a powerful tool in\nthe situations where it works. It results in deeper classes, since it reduces the\nclass\u2019s interface (fewer exceptions for users to be aware of) and adds\nfunctionality in the form of the code that masks the exception. Exception\nmasking is an example of pulling complexity downward.\n10.7  Exception aggregation\nThe third technique for reducing complexity related to exceptions is exception\naggregation. The idea behind exception aggregation is to handle many exceptions\n", "page": 91, "type": "text", "section": "Page 91"}
{"text": "with a single piece of code; rather than writing distinct handlers for many\nindividual exceptions, handle them all in one place with a single handler.\nConsider how to handle missing parameters in a Web server. A Web server\nimplements a collection of URLs. When the server receives an incoming URL, it\ndispatches to a URL-specific service method to process that URL and generate a\nresponse. The URL contains various parameters that are used to generate the\nresponse. Each service method will call a lower-level method (let\u2019s call it\ngetParameter) to extract the parameters that it needs from the URL. If the URL\ndoes not contain the desired parameter, getParameter throws an exception.\nWhen students in a software design class implemented such a server, many of\nthem wrapped each distinct call to getParameter in a separate exception handler\nto catch NoSuchParameter exceptions, as in Figure 10.1. This resulted in a large\nnumber of handlers, all of which did essentially the same thing (generate an error\nresponse).\nFigure 10.1: The code at the top dispatches to one of several methods in a Web server, each of which\nhandles a particular URL. Each of those methods (bottom) uses parameters from the incoming HTTP\nrequest. In this figure, there is a separate exception handler for each call to getParameter; this results in\nduplicated code.\nA better approach is to aggregate the exceptions. Instead of catching the\nexceptions in the individual service methods, let them propagate up to the top-\nlevel dispatch method for the Web server, as in Figure 10.2. A single handler in\n", "page": 92, "type": "text", "section": "Page 92"}
{"text": "this method can catch all of the exceptions and generate an appropriate error\nresponse for missing parameters.\nThe aggregation approach can be taken even further in the Web example.\nThere are many other errors besides missing parameters that can occur while\nprocessing a Web page; for example, a parameter might not have the right syntax\n(the service method expected an integer, but the value was \u201cxyz\u201d), or the user\nmight not have permission for the requested operation. In each case, the error\nshould result in an error response; the errors differ only in the error message to\ninclude in the response (\u201cparameter 'quantity' not present in URL\u201d or \u201cbad\nvalue 'xyz' for 'quantity' parameter; must be positive integer\u201d). Thus, all\nconditions resulting in an error response can be handled with a single top-level\nexception handler. The error message can be generated at the time the exception\nis thrown and included as a variable in the exception record; for example,\ngetParameter will generate the \u201cparameter 'quantity' not present in URL\u201d\nmessage. The top-level handler extracts the message from the exception and\nincorporates it into the error response.\nFigure 10.2: This code is functionally equivalent to Figure 10.1, but exception handling has been\naggregated: a single exception handler in the dispatcher catches all of the NoSuchParameter exceptions from\nall of the URL-specific methods.\nThe aggregation described in the preceding paragraph has good properties\nfrom the standpoint of encapsulation and information hiding. The top-level\nexception handler encapsulates knowledge about how to generate error\nresponses, but it knows nothing about specific errors; it just uses the error\nmessage provided in the exception. The getParameter method encapsulates\nknowledge about how to extract a parameter from a URL, and it also knows how\n", "page": 93, "type": "text", "section": "Page 93"}
{"text": "to describe extraction errors in a human-readable form. These two pieces of\ninformation are closely related, so it makes sense for them to be in the same\nplace. However, getParameter knows nothing about the syntax of an HTTP error\nresponse. As new functionality is added to the Web server, new methods like\ngetParameter may be created with their own errors. If the new methods throw\nexceptions in the same way as getParameter (by generating exceptions that\ninherit from the same superclass and including an error message in each\nexception), they can plug into the existing system with no other changes: the top-\nlevel handler will automatically generate error responses for them.\nThis example illustrates a generally-useful design pattern for exception\nhandling. If a system processes a series of requests, it\u2019s useful to define an\nexception that aborts the current request, cleans up the system\u2019s state, and\ncontinues with the next request. The exception is caught in a single place near the\ntop of the system\u2019s request-handling loop. This exception can be thrown at any\npoint in the processing of a request to abort the request; different subclasses of\nthe exception can be defined for different conditions. Exceptions of this type\nshould be clearly distinguished from exceptions that are fatal to the entire system.\nException aggregation works best if an exception propagates several levels up\nthe stack before it is handled; this allows more exceptions from more methods to\nbe handled in the same place. This is the opposite of exception masking:\nmasking usually works best if an exception is handled in a low-level method. For\nmasking, the low-level method is typically a library method used by many other\nmethods, so allowing the exception to propagate would increase the number of\nplaces where it is handled. Masking and aggregation are similar in that both\napproaches position an exception handler where it can catch the most exceptions,\neliminating many handlers that would otherwise need to be created.\nAnother example of exception aggregation occurs in the RAMCloud storage\nsystem for crash recovery. A RAMCloud system consists of a collection of\nstorage servers that keep multiple copies of each object, so the system can\nrecover from a variety of failures. For example, if a server crashes and loses all of\nits data, RAMCloud reconstructs the lost data using copies stored on other\nservers. Errors can also happen on a smaller scale; for example, a server may\ndiscover that an individual object is corrupted.\nRAMCloud does not have separate recovery mechanisms for each different\nkind of error. Instead, RAMCloud \u201cpromotes\u201d many smaller errors into larger\nones. RAMCloud could, in principle, handle a corrupted object by restoring that\n", "page": 94, "type": "text", "section": "Page 94"}
{"text": "one object from a backup copy. However, it doesn\u2019t do this. Instead, if it\ndiscovers a corrupted object it crashes the server containing the object.\nRAMCloud uses this approach because crash recovery is quite complex and this\napproach minimized the number of different recovery mechanisms that had to be\ncreated. Creating a recovery mechanism for crashed servers was unavoidable, so\nRAMCloud uses the same mechanism for other kinds of recovery as well. This\nreduced the amount of code that had to be written, and it also meant that server\ncrash recovery gets invoked more often. As a result, bugs in recovery are more\nlikely to be discovered and fixed.\nOne disadvantage of promoting a corrupted object into a server crash is that\nit increases the cost of recovery considerably. This is not a problem in\nRAMCloud, since object corruption is quite rare. However, error promotion may\nnot make sense for errors that happen frequently. As one example, it would not\nbe practical to crash a server anytime one of its network packets is lost.\nOne way of thinking about exception aggregation is that it replaces several\nspecial-purpose mechanisms, each tailored for a particular situation, with a\nsingle general-purpose mechanism that can handle multiple situations. This\nprovides another illustration of the benefits of general-purpose mechanisms.\n10.8  Just crash?\nThe fourth technique for reducing complexity related to exception handling is to\ncrash the application. In most applications there will be certain errors that it\u2019s not\nworth trying to handle. Typically, these errors are difficult or impossible to\nhandle and don\u2019t occur very often. The simplest thing to do in response to these\nerrors is to print diagnostic information and then abort the application.\nOne example is \u201cout of memory\u201d errors that occur during storage allocation.\nConsider the malloc function in C, which returns NULL if it cannot allocate the\ndesired block of memory. This is an unfortunate behavior, because it assumes\nthat every single caller of malloc will check the return value and take appropriate\naction if there is no memory. Applications contain numerous calls to malloc, so\nchecking the result after each call would add significant complexity. If a\nprogrammer forgets the check (which is fairly likely), then the application will\ndereference a null pointer if memory runs out, resulting in a crash that\ncamouflages the real problem.\nFurthermore, there isn\u2019t much an application can do when it discovers that\nmemory is exhausted. In principle the application could look for unneeded\n", "page": 95, "type": "text", "section": "Page 95"}
{"text": "memory to free, but if the application had unneeded memory it could already\nhave freed it, which would have prevented the out-of-memory error in the first\nplace. Today\u2019s systems have so much memory that memory almost never runs\nout; if it does, it usually indicates a bug in the application. Thus, it rarely make\nsense to try to handle out-of-memory errors; this creates too much complexity\nfor too little benefit.\nA better approach is to define a new method ckalloc, which calls malloc,\nchecks the result, and aborts the application with an error message if memory is\nexhausted. The application never invokes malloc directly; it always invokes\nckalloc.\nIn newer languages such as C++ and Java, the new operator throws an\nexception if memory is exhausted. There\u2019s not much point in catching this\nexception, since there\u2019s a good chance that the exception handler will also try to\nallocate memory, which will also fail. Dynamically allocated memory is such a\nfundamental element of any modern application that it doesn\u2019t make sense for\nthe application to continue if memory is exhausted; it\u2019s better to crash as soon as\nthe error is detected.\nThere are many other examples of errors where crashing the application\nmakes sense. For most programs, if an I/O error occurs while reading or writing\nan open file (such as a disk hard error), or if a network socket cannot be opened,\nthere\u2019s not much the application can do to recover, so aborting with a clear error\nmessage is a sensible approach. These errors are infrequent, so they are unlikely\nto affect the overall usability of the application. Aborting with an error message\nis also appropriate if an application encounters an internal error such as an\ninconsistent data structure. Conditions like this probably indicate bugs in the\nprogram.\nWhether or not it is acceptable to crash on a particular error depends on the\napplication. For a replicated storage system, it isn\u2019t appropriate to abort on an I/O\nerror. Instead, the system must use replicated data to recover any information that\nwas lost. The recovery mechanisms will add considerable complexity to the\nprogram, but recovering lost data is an essential part of the value the system\nprovides to its users.\n10.9  Design special cases out of existence\nFor the same reason that it makes sense to define errors out of existence, it also\n", "page": 96, "type": "text", "section": "Page 96"}
{"text": "For the same reason that it makes sense to define errors out of existence, it also\nmakes sense to define other special cases out of existence. Special cases can\nresult in code that is riddled with if statements, which make the code hard to\nunderstand and lead to bugs. Thus, special cases should be eliminated wherever\npossible. The best way to do this is by designing the normal case in a way that\nautomatically handles the special cases without any extra code.\nIn the text editor project described in Chapter 6, students had to implement a\nmechanism for selecting text and copying or deleting the selection. Most students\nintroduced a state variable in their selection implementation to indicate whether\nor not the selection exists. They probably chose this approach because there are\ntimes when no selection is visible on the screen, so it seemed natural to represent\nthis notion in the implementation. However, this approach resulted in numerous\nchecks to detect the \u201cno selection\u201d condition and handle it specially.\nThe selection handling code can be simplified by eliminating the \u201cno\nselection\u201d special case, so that the selection always exists. When there is no\nselection visible on the screen, it can be represented internally with an empty\nselection, whose starting and ending positions are the same. With this approach,\nthe selection management code can be written without any checks for \u201cno\nselection\u201d. When copying the selection, if the selection is empty then 0 bytes will\nbe inserted at the new location (if implemented correctly, there will be no need to\ncheck for 0 bytes as a special case). Similarly, it should be possible to design the\ncode for deleting the selection so that the empty case is handled without any\nspecial-case checks. Consider a selection all on a single line. To delete the\nselection, extract the portion of the line preceding the selection and concatenate\nit with the portion of the line following the selection to form the new line. If the\nselection is empty, this approach will regenerate the original line.\nThis example also illustrates the \u201cdifferent layer, different abstraction\u201d idea\nfrom Chapter 7. The notion of \u201cno selection\u201d makes sense in terms of how the\nuser thinks about the application\u2019s interface, but that doesn\u2019t mean it has to be\nrepresented explicitly inside the application. Having a selection that always\nexists, but is sometimes empty and thus invisible, results in a simpler\nimplementation.\n10.10  Taking it too far\nDefining away exceptions, or masking them inside a module, only makes sense if\nthe exception information isn\u2019t needed outside the module. This was true for the\n", "page": 97, "type": "text", "section": "Page 97"}
{"text": "examples in this chapter, such the Tcl unset command and the Java substring\nmethod; in the rare situations where a caller cares about the special cases\ndetected by the exceptions, there are other ways for it to get this information.\nHowever, it is possible to take this idea too far. In a module for network\ncommunication, a student team masked all network exceptions: if a network error\noccurred, the module caught it, discarded it, and continued as if there were no\nproblem. This meant that applications using the module had no way to find out if\nmessages were lost or a peer server failed; without this information, it was\nimpossible to build robust applications. In this case, it is essential for the module\nto expose the exceptions, even though they add complexity to the module\u2019s\ninterface.\nWith exceptions, as with many other areas in software design, you must\ndetermine what is important and what is not important. Things that are not\nimportant should be hidden, and the more of them the better. But when\nsomething is important, it must be exposed.\n10.11  Conclusion\nSpecial cases of any form make code harder to understand and increase the\nlikelihood of bugs. This chapter focused on exceptions, which are one of the\nmost significant sources of special-case code, and discussed how to reduce the\nnumber of places where exceptions must be handled. The best way to do this is\nby redefining semantics to eliminate error conditions. For exceptions that can\u2019t\nbe defined away, you should look for opportunities to mask them at a low level,\nso their impact is limited, or aggregate several special-case handlers into a single\nmore generic handler. Together, these techniques can have a significant impact\non overall system complexity.\n1Ding Yuan et. al., \u201cSimple Testing Can Prevent Most Critical Failures: An Analysis of Production\nFailures in Distributed Data-Intensive Systems,\u201d 2014 USENIX Conference on Operating System Design\nand Implementation.\n", "page": 98, "type": "text", "section": "Page 98"}
{"text": "Chapter 11\nDesign it Twice\nDesigning software is hard, so it\u2019s unlikely that your first thoughts about how to\nstructure a module or system will produce the best design. You\u2019ll end up with a\nmuch better result if you consider multiple options for each major design\ndecision: design it twice.\nSuppose you are designing the class that will manage the text of a file for a\nGUI text editor. The first step is to define the interface that the class will present\nto the rest of the editor; rather than picking the first idea that comes to mind,\nconsider several possibilities. One choice is a line-oriented interface, with\noperations to insert, modify, and delete whole lines of text. Another option is an\ninterface based on individual character insertions and deletions. A third choice is\na string-oriented interface, which operates on arbitrary ranges of characters that\nmay cross line boundaries. You don\u2019t need to pin down every feature of each\nalternative; it\u2019s sufficient at this point to sketch out a few of the most important\nmethods.\nTry to pick approaches that are radically different from each other; you\u2019ll\nlearn more that way. Even if you are certain that there is only one reasonable\napproach, consider a second design anyway, no matter how bad you think it will\nbe. It will be instructive to think about the weaknesses of that design and contrast\nthem with the features of other designs.\nAfter you have roughed out the designs for the alternatives, make a list of the\npros and cons of each one. The most important consideration for an interface is\nease of use for higher level software. In the example above, both the line-oriented\ninterface and the character-oriented interface will require extra work in software\nthat uses the text class. The line-oriented interface will require higher level\nsoftware to split and join lines during partial-line and multi-line operations such\nas cutting and pasting the selection. The character-oriented interface will require\nloops to implement operations that modify more than a single character. It is also\nworth considering other factors:\n", "page": 99, "type": "text", "section": "Page 99"}
{"text": "Does one alternative have a simpler interface than another? In the text\nexample, all of the text interfaces are relatively simple.\nIs one interface more general-purpose than another?\nDoes one interface enable a more efficient implementation than another? In\nthe text example, the character-oriented approach is likely to be significantly\nslower than the others, because it requires a separate call into the text\nmodule for each character.\nOnce you have compared alternative designs, you will be in a better position\nto identify the best design. The best choice may be one of the alternatives, or you\nmay discover that you can combine features of multiple alternatives into a new\ndesign that is better than any of the original choices.\nSometimes none of the alternatives is particularly attractive; when this\nhappens, see if you can come up with additional schemes. Use the problems you\nidentified with the original alternatives to drive the new design(s). If you were\ndesigning the text class and considered only the line-oriented and character-\noriented approaches, you might notice that each of the alternatives is awkward\nbecause it requires higher level software to perform additional text\nmanipulations. That\u2019s a red flag: if there\u2019s going to be a text class, it should\nhandle all of the text manipulation. In order to eliminate the additional text\nmanipulations, the text interface needs to match more closely the operations\nhappening in higher level software. These operations don\u2019t always correspond to\nsingle characters or single lines. This line of reasoning should lead you to a\nrange-oriented API for text, which eliminates the problem with the earlier\ndesigns.\nThe design-it-twice principle can be applied at many levels in a system. For a\nmodule, you can use this approach first to pick the interface, as described above.\nThen you can apply it again when you are designing the implementation: for the\ntext class, you might consider implementations such as a linked list of lines,\nfixed-size blocks of characters, or a \u201cgap buffer.\u201d The goals will be different for\nthe implementation than for the interface: for the implementation, the most\nimportant things are simplicity and performance. It\u2019s also useful to explore\nmultiple designs at higher levels in the system, such as when choosing features\nfor a user interface, or when decomposing a system into major modules. In each\ncase, it\u2019s easier to identify the best approach if you can compare a few\nalternatives.\nDesigning it twice does not need to take a lot of extra time. For a smaller\n", "page": 100, "type": "text", "section": "Page 100"}
{"text": "Designing it twice does not need to take a lot of extra time. For a smaller\nmodule such as a class, you may not need more than an hour or two to consider\nalternatives. This is a small amount of time compared to the days or weeks you\nwill spend implementing the class. The initial design experiments will probably\nresult in a significantly better design, which will more than pay for the time spent\ndesigning it twice. For larger modules you\u2019ll spend more time in the initial\ndesign explorations, but the implementation will also take longer, and the\nbenefits of a better design will also be higher.\nI have noticed that the design-it-twice principle is sometimes hard for really\nsmart people to embrace. When they are growing up, smart people discover that\ntheir first quick idea about any problem is sufficient for a good grade; there is no\nneed to consider a second or third possibility. This makes it easy to develop bad\nwork habits. However, as these people get older, they get promoted into\nenvironments with harder and harder problems. Eventually, everyone reaches a\npoint where your first ideas are no longer good enough; if you want to get really\ngreat results, you have to consider a second possibility, or perhaps a third, no\nmatter how smart you are. The design of large software systems falls in this\ncategory: no-one is good enough to get it right with their first try.\nUnfortunately, I often see smart people who insist on implementing the first\nidea that comes to mind, and this causes them to underperform their true\npotential (it also makes them frustrating to work with). Perhaps they\nsubconsciously believe that \u201csmart people get it right the first time,\u201d so if they try\nmultiple designs it would mean they are not smart after all. This is not the case.\nIt isn\u2019t that you aren\u2019t smart; it\u2019s that the problems are really hard! Furthermore,\nthat\u2019s a good thing: it\u2019s much more fun to work on a difficult problem where you\nhave to think carefully, rather than an easy problem where you don\u2019t have to\nthink at all.\nThe design-it-twice approach not only improves your designs, but it also\nimproves your design skills. The process of devising and comparing multiple\napproaches will teach you about the factors that make designs better or worse.\nOver time, this will make it easier for you to rule out bad designs and hone in on\nreally great ones.\n", "page": 101, "type": "text", "section": "Page 101"}
{"text": "Chapter 12\nWhy Write Comments? The Four Excuses\nIn-code documentation plays a crucial role in software design. Comments are\nessential to help developers understand a system and work efficiently, but the\nrole of comments goes beyond this. Documentation also plays an important role\nin abstraction; without comments, you can\u2019t hide complexity. Finally, the\nprocess of writing comments, if done correctly, will actually improve a\nsystem\u2019s design. Conversely, a good software design loses much of its value if it\nis poorly documented.\nUnfortunately, this view is not universally shared. A significant fraction of\nproduction code contains essentially no comments. Many developers think that\ncomments are a waste of time; others see the value in comments, but somehow\nnever get around to writing them. Fortunately, many development teams\nrecognize the value of documentation, and it feels like the prevalence of these\nteams is gradually increasing. However, even in teams that encourage\ndocumentation, comments are often viewed as drudge work and many developers\ndon\u2019t understand how to write them, so the resulting documentation is often\nmediocre. Inadequate documentation creates a huge and unnecessary drag on\nsoftware development.\nIn this chapter I will discuss the excuses developers use to avoid writing\ncomments, and the reasons why comments really do matter. Chapter 13 will then\ndescribe how to write good comments and the next few chapters after that will\ndiscuss related issues such as choosing variable names and how to use\ndocumentation to improve a system\u2019s design. I hope these chapters will convince\nyou of three things: good comments can make a big difference in the overall\nquality of software; it isn\u2019t hard to write good comments; and (this may be hard\nto believe) writing comments can actually be fun.\nWhen developers don\u2019t write comments, they usually justify their behavior\nwith one or more of the following excuses:\n\u201cGood code is self-documenting.\u201d\n", "page": 102, "type": "text", "section": "Page 102"}
{"text": "\u201cI don\u2019t have time to write comments.\u201d\n\u201cComments get out of date and become misleading.\u201d\n\u201cThe comments I have seen are all worthless; why bother?\u201d In the sections\nbelow I will address each of these excuses in turn.\n12.1  Good code is self-documenting\nSome people believe that if code is written well, it is so obvious that no\ncomments are needed. This is a delicious myth, like a rumor that ice cream is\ngood for your health: we\u2019d really like to believe it! Unfortunately, it\u2019s simply not\ntrue. To be sure, there are things you can do when writing code to reduce the\nneed for comments, such as choosing good variable names (see Chapter 14).\nNonetheless, there is still a significant amount of design information that can\u2019t be\nrepresented in code. For example, only a small part of a class\u2019s interface, such as\nthe signatures of its methods, can be specified formally in the code. The informal\naspects of an interface, such as a high-level description of what each method\ndoes or the meaning of its result, can only be described in comments. There are\nmany other examples of things that can\u2019t be described in the code, such as the\nrationale for a particular design decision, or the conditions under which it makes\nsense to call a particular method.\nSome developers argue that if others want to know what a method does, they\nshould just read the code of the method: this will be more accurate than any\ncomment. It\u2019s possible that a reader could deduce the abstract interface of the\nmethod by reading its code, but it would be time-consuming and painful. In\naddition, if you write code with the expectation that users will read method\nimplementations, you will try to make each method as short as possible, so that\nit\u2019s easy to read. If the method does anything nontrivial, you will break it up into\nseveral smaller methods. This will result in a large number of shallow methods.\nFurthermore, it doesn\u2019t really make the code easier to read: in order to\nunderstand the behavior of the top-level method, readers will probably need to\nunderstand the behaviors of the nested methods. For large systems it isn\u2019t\npractical for users to read the code to learn the behavior.\nMoreover, comments are fundamental to abstractions. Recall from Chapter 4\nthat the goal of abstractions is to hide complexity: an abstraction is a simplified\nview of an entity, which preserves essential information but omits details that can\nsafely be ignored. If users must read the code of a method in order to use it,\nthen there is no abstraction: all of the complexity of the method is exposed.\n", "page": 103, "type": "text", "section": "Page 103"}
{"text": "Without comments, the only abstraction of a method is its declaration, which\nspecifies its name and the names and types of its arguments and results. The\ndeclaration is missing too much essential information to provide a useful\nabstraction by itself. For example, a method to extract a substring might have two\narguments, start and end, indicating the range of characters to extract. From the\ndeclaration alone, it isn\u2019t possible to tell whether the extracted substring will\ninclude the character indicated by end, or what happens if start > end.\nComments allow us to capture the additional information that callers need,\nthereby completing the simplified view while hiding implementation details. It\u2019s\nalso important that comments are written in a human language such as English;\nthis makes them less precise than code, but it provides more expressive power, so\nwe can create simple, intuitive descriptions. If you want to use abstractions to\nhide complexity, comments are essential.\n12.2  I don\u2019t have time to write comments\nIt\u2019s tempting to prioritize comments lower than other development tasks. Given a\nchoice between adding a new feature and documenting an existing feature, it\nseems logical to choose the new feature. However, software projects are almost\nalways under time pressure, and there will always be things that seem higher\npriority than writing comments. Thus, if you allow documentation to be de-\nprioritized, you\u2019ll end up with no documentation.\nThe counter-argument to this excuse is the investment mindset discussed on\npage 15. If you want a clean software structure, which will allow you to work\nefficiently over the long-term, then you must take some extra time up front in\norder to create that structure. Good comments make a huge difference in the\nmaintainability of software, so the effort spent on them will pay for itself quickly.\nFurthermore, writing comments needn\u2019t take a lot of time. Ask yourself how\nmuch of your development time you spend typing in code (as opposed to\ndesigning, compiling, testing, etc.), assuming you don\u2019t include any comments; I\ndoubt that the answer is more than 10%. Now suppose that you spend as much\ntime typing comments as typing code; this should be a safe upper bound. With\nthese assumptions, writing good comments won\u2019t add more than about 10% to\nyour development time. The benefits of having good documentation will quickly\noffset this cost.\nFurthermore, many of the most important comments are those related to\nabstractions, such as the top-level documentation for classes and methods.\n", "page": 104, "type": "text", "section": "Page 104"}
{"text": "Chapter 15 will argue that these comments should be written as part of the\ndesign process, and that the act of writing the documentation serves as an\nimportant design tool that improves the overall design. These comments pay for\nthemselves immediately.\n12.3  Comments get out of date and become misleading\nComments do sometimes get out of date, but this need not be a major problem in\npractice. Keeping documentation up-to-date does not require an enormous effort.\nLarge changes to the documentation are only required if there have been large\nchanges to the code, and the code changes will take more time than the\ndocumentation changes. Chapter 16 discusses how to organize documentation so\nthat it is as easy as possible to keep it updated after code modifications (the key\nideas are to avoid duplicated documentation and keep the documentation close to\nthe corresponding code). Code reviews provide a great mechanism for detecting\nand fixing stale comments.\n12.4  All the comments I have seen are worthless\nOf the four excuses, this is probably the one with the most merit. Every software\ndeveloper has seen comments that provide no useful information, and most\nexisting documentation is so-so at best. Fortunately, this problem is solvable;\nwriting solid documentation is not hard, once you know how. The next chapters\nwill lay out a framework for how to write good documentation and maintain it\nover time.\n12.5  Benefits of well-written comments\nNow that I have discussed (and, hopefully, debunked) the arguments against\nwriting comments, let\u2019s consider the benefits that you will get from good\ncomments. The overall idea behind comments is to capture information that\nwas in the mind of the designer but couldn\u2019t be represented in the code. This\ninformation ranges from low-level details, such as a hardware quirk that\nmotivates a particularly tricky piece of code, up to high-level concepts such as\nthe rationale for a class. When other developers come along later to make\nmodifications, the comments will allow them to work more quickly and\naccurately. Without documentation, future developers will have to rederive or\nguess at the developer\u2019s original knowledge; this will take additional time, and\n", "page": 105, "type": "text", "section": "Page 105"}
{"text": "there is a risk of bugs if the new developer misunderstands the original\ndesigner\u2019s intentions. Comments are valuable even when the original designer is\nthe one making the changes: if it has been more than a few weeks since you last\nworked in a piece of code, you will have forgotten many of the details of the\noriginal design.\nChapter 2 described three ways in which complexity manifests itself in\nsoftware systems:\nChange amplification: a seemingly simple change requires code\nmodifications in many places.\nCognitive load: in order to make a change, the developer must accumulate a\nlarge amount of information.\nUnknown unknowns: it is unclear what code needs to be modified, or what\ninformation must be considered in order to make those modifications.\nGood documentation helps with the last two of these issues. Documentation can\nreduce cognitive load by providing developers with the information they need to\nmake changes and by making it easy for developers to ignore information that is\nirrelevant. Without adequate documentation, developers may have to read large\namounts of code to reconstruct what was in the designer\u2019s mind. Documentation\ncan also reduce the unknown unknowns by clarifying the structure of the system,\nso that it is clear what information and code is relevant for any given change.\nChapter 2 pointed out that the primary causes of complexity are\ndependencies and obscurity. Good documentation can clarify dependencies, and\nit fills in gaps to eliminate obscurity.\nThe next few chapters will show you how to write good documentation. They\nwill also discuss how to integrate documentation-writing into the design process\nso that it improves the design of your software.\n", "page": 106, "type": "text", "section": "Page 106"}
{"text": "Chapter 13\nComments Should Describe Things that Aren\u2019t\nObvious from the Code\nThe reason for writing comments is that statements in a programming language\ncan\u2019t capture all of the important information that was in the mind of the\ndeveloper when the code was written. Comments record this information so that\ndevelopers who come along later can easily understand and modify the code. The\nguiding principle for comments is that comments should describe things that\naren\u2019t obvious from the code.\nThere are many things that aren\u2019t obvious from the code. Sometimes it\u2019s low-\nlevel details that aren\u2019t obvious. For example, when a pair of indices describe a\nrange, it isn\u2019t obvious whether the elements given by the indices are inside the\nrange or out. Sometimes it\u2019s not clear why code is needed, or why it was\nimplemented in a particular way. Sometimes there are rules the developer\nfollowed, such as \u201calways invoke a before b.\u201d You might be able to guess at a rule\nby looking at all of the code, but this is painful and error-prone; a comment can\nmake the rule explicit and clear.\nOne of the most important reasons for comments is abstractions, which\ninclude a lot of information that isn\u2019t obvious from the code. The idea of an\nabstraction is to provide a simple way of thinking about something, but code is\nso detailed that it can be hard to see the abstraction just from reading the code.\nComments can provide a simpler, higher-level view (\u201cafter this method is\ninvoked, network traffic will be limited to maxBandwidth bytes per second\u201d). Even\nif this information can be deduced by reading the code, we don\u2019t want to force\nusers of a module to do that: reading the code is time-consuming and forces them\nto consider a lot of information that isn\u2019t needed to use the module. Developers\nshould be able to understand the abstraction provided by a module without\nreading any code other than its externally visible declarations. The only way\nto do this is by supplementing the declarations with comments.\n", "page": 107, "type": "text", "section": "Page 107"}
{"text": "This chapter discusses what information needs to be described in comments\nand how to write good comments. As you will see, good comments typically\nexplain things at a different level of detail than the code, which is more detailed\nin some situations and less detailed (more abstract) in others.\n13.1  Pick conventions\nThe first step in writing comments is to decide on conventions for commenting,\nsuch as what you will comment and the format you will use for comments. If you\nare programming in a language for which there exists a document compilation\ntool, such as Javadoc for Java, Doxygen for C++, or godoc for Go!, follow the\nconventions of the tools. None of these conventions is perfect, but the tools\nprovide enough benefits to make up for that. If you are programming in an\nenvironment where there are no existing conventions to follow, try to adopt the\nconventions from some other language or project that is similar; this will make it\neasier for other developers to understand and adhere to your conventions.\nConventions serve two purposes. First, they ensure consistency, which makes\ncomments easier to read and understand. Second, they help to ensure that you\nactually write comments. If you don\u2019t have a clear idea what you are going to\ncomment and how, it\u2019s easy to end up writing no comments at all.\nMost comments fall into one of the following categories:\nInterface: a comment block that immediately precedes the declaration of a\nmodule such as a class, data structure, function, or method. The comment\ndescribe\u2019s the module\u2019s interface. For a class, the comment describes the\noverall abstraction provided by the class. For a method or function, the\ncomment describes its overall behavior, its arguments and return value, if any,\nany side effects or exceptions that it generates, and any other requirements the\ncaller must satisfy before invoking the method.\nData structure member: a comment next to the declaration of a field in a data\nstructure, such as an instance variable or static variable for a class.\nImplementation comment: a comment inside the code of a method or\nfunction, which describes how the code works internally.\nCross-module comment: a comment describing dependencies that cross\nmodule boundaries.\nThe most important comments are those in the first two categories. Every class\nshould have an interface comment, every class variable should have a comment,\nand every method should have an interface comment. Occasionally, the\n", "page": 108, "type": "text", "section": "Page 108"}
{"text": "declaration for a variable or method is so obvious that there is nothing useful to\nadd in a comment (getters and setters sometimes fall in this category), but this is\nrare; it is easier to comment everything rather than spend energy worrying about\nwhether a comment is needed. Implementation comments are often unnecessary\n(see Section 13.6 below). Cross-module comments are the most rare of all and\nthey are problematic to write, but when they are needed they are quite important;\nSection 13.7 discusses them in more detail.\n13.2  Don\u2019t repeat the code\nUnfortunately, many comments are not particularly helpful. The most common\nreason is that the comments repeat the code: all of the information in the\ncomment can easily be deduced from the code next to the comment. Here is a\ncode sample that appeared in a recent research paper:\nptr_copy = get_copy(obj)\n# Get pointer copy\nif is_unlocked(ptr_copy):\n# Is obj free?\n    return obj\n# return current obj\nif is_copy(ptr_copy):\n# Already a copy?\n    return obj\n# return obj\nthread_id = get_thread_id(ptr_copy)\nif thread_id == ctx.thread_id:\n# Locked by current ctx\n    return ptr_copy\n# Return copy\nThere is no useful information in any of these comments except for the \u201cLocked\nby\u201d comment, which suggests something about the thread that might not be\nobvious from the code. Notice that these comments are at roughly the same level\nof detail as the code: there is one comment per line of code, which describes that\nline. Comments like this are rarely useful.\nHere are more examples of comments that repeat the code:\n// Add a horizontal scroll bar\nhScrollBar = new JScrollBar(JScrollBar.HORIZONTAL);\nadd(hScrollBar, BorderLayout.SOUTH);\n// Add a vertical scroll bar\nvScrollBar = new JScrollBar(JScrollBar.VERTICAL);\nadd(vScrollBar, BorderLayout.EAST);\n// Initialize the caret-position related values\ncaretX     = 0;\n", "page": 109, "type": "text", "section": "Page 109"}
{"text": "caretY     = 0;\ncaretMemX  = null;\nNone of these comments provide any value. For the first two comments, the code\nis already clear enough that it doesn\u2019t really need comments; in the third case, a\ncomment might be useful, but the current comment doesn\u2019t provide enough\ndetail to be helpful.\nAfter you have written a comment, ask yourself the following question: could\nsomeone who has never seen the code write the comment just by looking at the\ncode next to the comment? If the answer is yes, as in the examples above, then\nthe comment doesn\u2019t make the code any easier to understand. Comments like\nthese are why some people think that comments are worthless.\nAnother common mistake is to use the same words in the comment that\nappear in the name of the entity being documented:\n/*\n * Obtain a normalized resource name from REQ.\n */\nprivate static String[] getNormalizedResourceNames(\n            HTTPRequest req) ...\n/*\n * Downcast PARAMETER to TYPE.\n */\nprivate static Object downCastParameter(String parameter, String type)\n...\n/*\n * The horizontal padding of each line in the text.\n */\nprivate static final int textHorizontalPadding = 4;\nThese comments just take the words from the method or variable name, perhaps\nadd a few words from argument names and types, and form them into a sentence.\nFor example, the only thing in the second comment that isn\u2019t in the code is the\nword \u201cto\u201d! Once again, these comments could be written just by looking at the\ndeclarations, without any understanding the methods of variables; as a result,\nthey have no value.\n", "page": 110, "type": "text", "section": "Page 110"}
{"text": " Red Flag: Comment Repeats Code \nIf the information in a comment is already obvious from the code next to the\ncomment, then the comment isn\u2019t helpful. One example of this is when the\ncomment uses the same words that make up the name of the thing it is\ndescribing.\nAt the same time, there is important information that is missing from the\ncomments: for example, what is a \u201cnormalized resource name\u201d, and what are the\nelements of the array returned by getNormalizedResourceNames? What does\n\u201cdowncast\u201d mean? What are the units of padding, and is the padding on one side\nof each line or both? Describing these things in comments would be helpful.\nA first step towards writing good comments is to use different words in the\ncomment from those in the name of the entity being described. Pick words\nfor the comment that provide additional information about the meaning of the\nentity, rather than just repeating its name. For example, here is a better comment\nfor textHorizontalPadding:\n/*\n * The amount of blank space to leave on the left and\n * right sides of each line of text, in pixels.\n */\nprivate static final int textHorizontalPadding = 4;\nThis comment provides additional information that is not obvious from the\ndeclaration itself, such as the units (pixels) and the fact that padding applies to\nboth sides of each line. Instead of using the term \u201cpadding\u201d, the comment\nexplains what padding is, in case the reader isn\u2019t already familiar with the term.\n13.3  Lower-level comments add precision\nNow that you know what not to do, let\u2019s discuss what information you should put\nin comments. Comments augment the code by providing information at a\ndifferent level of detail. Some comments provide information at a lower, more\ndetailed, level than the code; these comments add precision by clarifying the\nexact meaning of the code. Other comments provide information at a higher,\nmore abstract, level than the code; these comments offer intuition, such as the\n", "page": 111, "type": "text", "section": "Page 111"}
{"text": "reasoning behind the code, or a simpler and more abstract way of thinking about\nthe code. Comments at the same level as the code are likely to repeat the code.\nThis section discusses the lower-level approach in more detail, and the next\nsection discusses the higher-level approach.\nPrecision is most useful when commenting variable declarations such as\nclass instance variables, method arguments, and return values. The name and\ntype in a variable declaration are typically not very precise. Comments can fill in\nmissing details such as:\nWhat are the units for this variable?\nAre the boundary conditions inclusive or exclusive?\nIf a null value is permitted, what does it imply?\nIf a variable refers to a resource that must eventually be freed or closed, who\nis responsible for freeing or closing it?\nAre there certain properties that are always true for the variable (invariants),\nsuch as \u201cthis list always contains at least one entry\u201d?\nSome of this information could potentially be figured out by examining all of the\ncode where the variable is used. However, this is time-consuming and error-\nprone; the declaration\u2019s comment should be clear and complete enough to make\nthis unnecessary. When I say that the comment for a declaration should describe\nthings that aren\u2019t obvious from the code, \u201cthe code\u201d refers to the code next to the\ncomment (the declaration), not \u201call of the code in the application.\u201d\nThe most common problem with comments for variables is that the\ncomments are too vague. Here are two examples of comments that aren\u2019t precise\nenough:\n// Current offset in resp Buffer\nuint32_t offset;\n// Contains all line-widths inside the document and\n// number of appearances.\nprivate TreeMap<Integer, Integer> lineWidths;\nIn the first example, it\u2019s not clear what \u201ccurrent\u201d means. In the second example,\nit\u2019s not clear that the keys in the TreeMap are line widths and values are\noccurrence counts. Also, are widths measured in pixels or characters? The\nrevised comments below provide additional details:\n//  Position in this buffer of the first object that hasn't\n//  been returned to the client.\n", "page": 112, "type": "text", "section": "Page 112"}
{"text": "uint32_t offset;\n//  Holds statistics about line lengths of the form <length, count>\n//  where length is the number of characters in a line (including\n//  the newline), and count is the number of lines with\n//  exactly that many characters. If there are no lines with\n//  a particular length, then there is no entry for that length.\nprivate TreeMap<Integer, Integer> numLinesWithLength;\nThe second declaration uses a longer name that conveys more information. It also\nchanges \u201cwidth\u201d to \u201clength\u201d, because this term is more likely to make people\nthink that the units are characters rather than pixels. Notice that the second\ncomment documents not only the details of each entry, but also what it means if\nan entry is missing.\nWhen documenting a variable, think nouns, not verbs. In other words, focus\non what the variable represents, not how it is manipulated. Consider the\nfollowing comment:\n/* FOLLOWER VARIABLE: indicator variable that allows the Receiver and\nthe\n * PeriodicTasks thread to communicate about whether a heartbeat has\nbeen\n * received within the follower's election timeout window.\n * Toggled to TRUE when a valid heartbeat is received.\n * Toggled to FALSE when the election timeout window is reset.  */\nprivate boolean receivedValidHeartbeat;\nThis documentation describes how the variable is modified by several pieces of\ncode in the class. The comment will be both shorter and more useful if it\ndescribes what the variable represents rather than mirroring the code structure:\n/* True means that a heartbeat has been received since the last time\n * the election timer was reset. Used for communication between the\n * Receiver and PeriodicTasks threads.  */\nprivate boolean receivedValidHeartbeat;\nGiven this documentation, it\u2019s easy to infer that the variable must be set to true\nwhen a heartbeat is received and false when the election timer is reset.\n13.4  Higher-level comments enhance intuition\nThe second way in which comments can augment code is by providing intuition.\n", "page": 113, "type": "text", "section": "Page 113"}
{"text": "The second way in which comments can augment code is by providing intuition.\nThese comments are written at a higher level than the code. They omit details\nand help the reader to understand the overall intent and structure of the code.\nThis approach is commonly used for comments inside methods, and for interface\ncomments. For example, consider the following code:\n// If there is a LOADING readRpc using the same session\n// as PKHash pointed to by assignPos, and the last PKHash\n// in that readRPC is smaller than current assigning\n// PKHash, then we put assigning PKHash into that readRPC.\nint readActiveRpcId = RPC_ID_NOT_ASSIGNED;\nfor (int i = 0; i < NUM_READ_RPC; i++) {\n      if (session == readRpc[i].session\n                 && readRpc[i].status == LOADING\n                 && readRpc[i].maxPos < assignPos\n                 && readRpc[i].numHashes < MAX_PKHASHES_PERRPC) {\n          readActiveRpcId = i;\n          break;\n      }\n}\nThe comment is too low-level and detailed. On the one hand, it partially repeats\nthe code: \u201cif there is a LOADING readRPC\u201d just duplicates the test\nreadRpc[i].status == LOADING. On the other hand, the comment doesn\u2019t explain\nthe overall purpose of this code, or how it fits into the method that contains it. As\na result, the comment doesn\u2019t help the reader to understand the code.\nHere is a better comment:\n// Try to append the current key hash onto an existing\n// RPC to the desired server that hasn't been sent yet.\nThis comment doesn\u2019t contain any details; instead, it describes the code\u2019s overall\nfunction at a higher level. With this high-level information, a reader can explain\nalmost everything that happens in the code: the loop must be iterating over all the\nexisting remote procedure calls (RPCs); the session test is probably used to see\nif a particular RPC is destined for the right server; the LOADING test suggests that\nRPCs can have multiple states, and in some states it isn\u2019t safe to add more\nhashes; the MAX - PKHASHES_PERRPC test suggests that there is a limit to how\nmany hashes can be sent in a single RPC. The only thing not explained by the\ncomment is the maxPos test. Furthermore, the new comment provides a basis for\n", "page": 114, "type": "text", "section": "Page 114"}
{"text": "readers to judge the code: does it do everything that is needed to add the key\nhash to an existing RPC? The original comment didn\u2019t describe the overall intent\nof the code, so it\u2019s hard for a reader to decide whether the code is behaving\ncorrectly.\nHigher-level comments are more difficult to write than lower-level comments\nbecause you must think about the code in a different way. Ask yourself: What is\nthis code trying to do? What is the simplest thing you can say that explains\neverything in the code? What is the most important thing about this code?\nEngineers tend to be very detail-oriented. We love details and are good at\nmanaging lots of them; this is essential for being a good engineer. But, great\nsoftware designers can also step back from the details and think about a system\nat a higher level. This means deciding which aspects of the system are most\nimportant, and being able to ignore the low-level details and think about the\nsystem only in terms of its most fundamental characteristics. This is the essence\nof abstraction (finding a simple way to think about a complex entity), and it\u2019s\nalso what you must do when writing higher-level comments. A good higher-level\ncomment expresses one or a few simple ideas that provide a conceptual\nframework, such as \u201cappend to an existing RPC.\u201d Given the framework, it\nbecomes easy to see how specific code statements relate to the overall goal.\nHere is another code sample, which has a good higher-level comment:\nif  (numProcessedPKHashes < readRpc[i].numHashes) {\n       // Some of the key hashes couldn't be looked up in\n       // this request (either because they aren't stored\n       // on the server, the server crashed, or there\n       // wasn't enough space in the response message).\n       // Mark the unprocessed hashes so they will get\n       // reassigned to new RPCs.\n       for (size_t p = removePos; p < insertPos; p++) {\n              if  (activeRpcId[p] == i) {\n                     if  (numProcessedPKHashes > 0) {\n                           numProcessedPKHashes--;\n                     } else {\n                           if  (p < assignPos)\n                                assignPos = p;\n                           activeRpcId[p] = RPC_ID_NOT_ASSIGNED;\n", "page": 115, "type": "text", "section": "Page 115"}
{"text": "                     }\n              }\n       }\n}\nThis comment does two things. The second sentence provides an abstract\ndescription of what the code does. The first sentence is different: it explains (in\nhigh level terms) why the code is executed. Comments of the form \u201chow we get\nhere\u201d are very useful for helping people to understand code. For example, when\ndocumenting a method, it can be very helpful to describe the conditions under\nwhich the method is most likely to be invoked (especially if the method is only\ninvoked in unusual situations).\n13.5  Interface documentation\nOne of the most important roles for comments is to define abstractions. Recall\nfrom Chapter 4 that an abstraction is a simplified view of an entity, which\npreserves essential information but omits details that can safely be ignored. Code\nisn\u2019t suitable for describing abstractions; it\u2019s too low level and it includes\nimplementation details that shouldn\u2019t be visible in the abstraction. The only way\nto describe an abstraction is with comments. If you want code that presents\ngood abstractions, you must document those abstractions with comments.\nThe first step in documenting abstractions is to separate interface comments\nfrom implementation comments. Interface comments provide information that\nsomeone needs to know in order to use a class or method; they define the\nabstraction. Implementation comments describe how a class or method works\ninternally in order to implement the abstraction. It\u2019s important to separate these\ntwo kinds of comments, so that users of an interface are not exposed to\nimplementation details. Furthermore, these two forms had better be different. If\ninterface comments must also describe the implementation, then the class or\nmethod is shallow. This means that the act of writing comments can provide\nclues about the quality of a design; Chapter 15 will return to this idea.\nThe interface comment for a class provides a high-level description of the\nabstraction provided by the class, such as the following:\n/**\n * This class implements a simple server-side interface to the HTTP\n * protocol: by using this class, an application can receive HTTP\n", "page": 116, "type": "text", "section": "Page 116"}
{"text": " * requests, process them, and return responses. Each instance of\n * this class corresponds to a particular socket used to receive\n * requests. The current implementation is single-threaded and\n * processes one request at a time.\n */\npublic class Http {...}\nThis comment describes the overall capabilities of the class, without any\nimplementation details or even the specifics of particular methods. It also\ndescribes what each instance of the class represents. Finally, the comments\ndescribe the limitations of the class (it does not support concurrent access from\nmultiple threads), which may be important to developers contemplating whether\nto use it.\nThe interface comment for a method includes both higher-level information\nfor abstraction and lower-level details for precision:\nThe comment usually starts with a sentence or two describing the behavior\nof the method as perceived by callers; this is the higher-level abstraction.\nThe comment must describe each argument and the return value (if any).\nThese comments must be very precise, and must describe any constraints on\nargument values as well as dependencies between arguments.\nIf the method has any side effects, these must be documented in the\ninterface comment. A side effect is any consequence of the method that\naffects the future behavior of the system but is not part of the result. For\nexample, if the method adds a value to an internal data structure, which can\nbe retrieved by future method calls, this is a side effect; writing to the file\nsystem is also a side effect.\nA method\u2019s interface comment must describe any exceptions that can\nemanate from the method.\nIf there are any preconditions that must be satisfied before a method is\ninvoked, these must be described (perhaps some other method must be\ninvoked first; for a binary search method, the list being searched must be\nsorted). It is a good idea to minimize preconditions, but any that remain\nmust be documented.\nHere is the interface comment for a method that copies data out of a Buffer\nobject:\n/**\n * Copy a range of bytes from a buffer to an external location.\n", "page": 117, "type": "text", "section": "Page 117"}
{"text": " *\n * \\param offset\n *        Index within the buffer of the first byte to copy.\n * \\param length\n *        Number of bytes to copy.\n * \\param dest\n *        Where to copy the bytes: must have room for at least\n *        length bytes.\n *\n * \\return\n *        The return value is the actual number of bytes copied,\n *        which may be less than length if the requested range of\n *        bytes extends past the end of the buffer. 0 is returned\n *        if there is no overlap between the requested range and\n *        the actual buffer.\n */\nuint32_t\nBuffer::copy(uint32_t offset, uint32_t length, void* dest)\n...\nThe syntax of this comment (e.g., \\return) follows the conventions of Doxygen,\na program that extracts comments from C/C++ code and compiles them into Web\npages. The goal of the comment is to provide all the information a developer\nneeds in order to invoke the method, including how special cases are handled\n(note how this method follows the advice of Chapter 10 and defines out of\nexistence any errors associated with the range specification). The developer\nshould not need to read the body of the method in order to invoke it, and the\ninterface comment provides no information about how the method is\nimplemented, such as how it scans its internal data structures to find the desired\ndata.\nFor a more extended example, let\u2019s consider a class called IndexLookup,\nwhich is part of a distributed storage system. The storage system holds a\ncollection of tables, each of which contains many objects. In addition, each table\ncan have one or more indexes; each index provides efficient access to objects in\nthe table based on a particular field of the object. For example, one index might\nbe used to look up objects based on their name field, and another index might be\n", "page": 118, "type": "text", "section": "Page 118"}
{"text": "used to look up objects based on their age field. With these indexes, applications\ncan quickly extract all of the objects with a particular name, or all of those with\nan age in a given range.\nThe IndexLookup class provides a convenient interface for performing\nindexed lookups. Here is an example of how it might be used in an application:\nquery = new IndexLookup(table, index, key1, key2);\nwhile  (true) {\n        object = query.getNext();\n        if  (object == NULL) {\n              break;\n        }\n        ... process object ...\n}\nThe application first constructs an object of type IndexLookup, providing\narguments that select a table, an index, and a range within the index (for\nexample, if the index is based on an age field, key1 and key2 might be specified\nas 21 and 65 to select all objects with ages between those values). Then the\napplication calls the getNext method repeatedly. Each invocation returns one\nobject that falls within the desired range; once all of the matching objects have\nbeen returned, getNext returns NULL. Because the storage system is distributed,\nthe implementation of this class is somewhat complex. The objects in a table\nmay be spread across multiple servers, and each index may also be distributed\nacross a different set of servers; the code in the IndexLookup class must first\ncommunicate with all of the relevant index servers to collect information about\nthe objects in the range, then it must communicate with the servers that actually\nstore the objects in order to retrieve their values.\nNow let\u2019s consider what information needs to be included in the interface\ncomment for this class. For each piece of information given below, ask yourself\nwhether a developer needs to know that information in order to use the class (my\nanswers to the questions are at the end of the chapter):\n1. The format of messages that the IndexLookup class sends to the servers\nholding indexes and objects.\n2. The comparison function used to determine whether a particular object\nfalls in the desired range (is comparison done using integers, floating-point\nnumbers, or strings?).\n", "page": 119, "type": "text", "section": "Page 119"}
{"text": "3. The data structure used to store indexes on servers.\n4. Whether or not IndexLookup issues multiple requests to different servers\nconcurrently.\n5. The mechanism for handling server crashes.\nHere is the original version of the interface comment for the IndexLookup\nclass; the excerpt also includes a few lines from the class\u2019s definition, which are\nreferred to in the comment:\n/*\n * This class implements the client side framework for index range\n * lookups. It manages a single LookupIndexKeys RPC and multiple\n * IndexedRead RPCs. Client side just includes \"IndexLookup.h\" in\n * its header to use IndexLookup class. Several parameters can be set\n * in the config below:\n * - The number of concurrent indexedRead RPCs\n * - The max number of PKHashes a indexedRead RPC can hold at a time\n * - The size of the active PKHashes\n *\n * To use IndexLookup, the client creates an object of this class by\n * providing all necessary information. After construction of\n * IndexLookup, client can call getNext() function to move to next\n * available object. If getNext() returns NULL, it means we reached\n * the last object. Client can use getKey, getKeyLength, getValue,\n * and getValueLength to get object data of current object.\n */\n class IndexLookup {\n       ...\n   private:\n       /// Max number of concurrent indexedRead RPCs\n       static const uint8_t NUM_READ_RPC = 10;\n       /// Max number of PKHashes that can be sent in one\n       /// indexedRead RPC\n       static const uint32_t MAX_PKHASHES_PERRPC = 256;\n       /// Max number of PKHashes that activeHashes can\n       /// hold at once.\n", "page": 120, "type": "text", "section": "Page 120"}
{"text": "       static const size_t MAX_NUM_PK = (1 << LG_BUFFER_SIZE);\n }\nBefore reading further, see if you can identify the problems with this comment.\nHere are the problems that I found:\nMost of the first paragraph concerns the implementation, not the interface.\nAs one example, users don\u2019t need to know the names of the particular\nremote procedure calls used to communicate with the servers. The\nconfiguration parameters referred to in the second half of the first paragraph\nare all private variables that are relevant only to the maintainer of the class,\nnot to its users. All of this implementation information should be omitted\nfrom the comment.\nThe comment also includes several things that are obvious. For example,\nthere\u2019s no need to tell users to include IndexLookup.h: anyone who writes\nC++ code will be able to guess that this is necessary. In addition, the text\n\u201cby providing all necessary information\u201d says nothing, so it can be omitted.\nA shorter comment for this class is sufficient (and preferable):\n/*\n * This class is used by client applications to make range queries\n * using indexes. Each instance represents a single range query.\n *\n * To start a range query, a client creates an instance of this\n * class. The client can then call getNext() to retrieve the objects\n * in the desired range. For each object returned by getNext(), the\n * caller can invoke getKey(), getKeyLength(), getValue(), and\n * getValueLength() to get information about that object.\n */\nThe last paragraph of this comment is not strictly necessary, since it mostly\nduplicates information in the comments for individual methods. However, it can\nbe helpful to have examples in the class documentation that illustrate how its\nmethods work together, particularly for deep classes with usage patterns that are\nnonobvious. Note that the new comment does not mention NULL return values\nfrom getNext. This comment is not intended to document every detail of each\nmethod; it just provides high level information to help readers understand how\nthe methods work together and when each method might be invoked. For details,\nreaders can refer to the interface comments for individual methods. This\n", "page": 121, "type": "text", "section": "Page 121"}
{"text": "comment also does not mention server crashes; that is because server crashes are\ninvisible to users of this class (the system automatically recovers from them).\n Red Flag: Implementation Documentation\nContaminates Interface \nThis red flag occurs when interface documentation, such as that for a method,\ndescribes implementation details that aren\u2019t needed in order to use the thing\nbeing documented.\nNow consider the following code, which shows the first version of the\ndocumentation for the isReady method in IndexLookup:\n/**\n * Check if the next object is RESULT_READY. This function is\n * implemented in a DCFT module, each execution of isReady() tries\n * to make small progress, and getNext() invokes isReady() in a\n * while loop, until isReady() returns true.\n *\n * isReady() is implemented in a rule-based approach. We check\n * different rules by following a particular order, and perform\n * certain actions if some rule is satisfied.\n *\n * \\return\n *         True means the next Object is available. Otherwise, return\n *         false.\n */\nbool IndexLookup::isReady() { ... }\nOnce again, most of this documentation, such as the reference to DCFT and the\nentire second paragraph, concerns the implementation, so it doesn\u2019t belong here;\nthis is one of the most common errors in interface comments. Some of the\nimplementation documentation is useful, but it should go inside the method,\nwhere it will be clearly separated from interface documentation. In addition, the\nfirst sentence of the documentation is cryptic (what does RESULT_READY mean?)\n", "page": 122, "type": "text", "section": "Page 122"}
{"text": "and some important information is missing. Finally, it isn\u2019t necessary to describe\nthe implementation of getNext here. Here is a better version of the comment:\n/*\n * Indicates whether an indexed read has made enough progress for\n * getNext to return immediately without blocking. In addition, this\n * method does most of the real work for indexed reads, so it must\n * be invoked (either directly, or indirectly by calling getNext) in\n * order for the indexed read to make progress.\n *\n * \\return\n *         True means that the next invocation of getNext will not block\n *         (at least one object is available to return, or the end of\nthe\n *         lookup has been reached); false means getNext may block.\n */\nThis version of the comment provides more precise information about what\n\u201cready\u201d means, and it provides the important information that this method must\neventually be invoked if the indexed retrieval is to move forward.\n13.6  Implementation comments: what and why, not how\nImplementation comments are the comments that appear inside methods to help\nreaders understand how they work internally. Most methods are so short and\nsimple that they don\u2019t need any implementation comments: given the code and\nthe interface comments, it\u2019s easy to figure out how a method works.\nThe main goal of implementation comments is to help readers\nunderstand what the code is doing (not how it does it). Once readers know\nwhat the code is trying to do, it\u2019s usually easy to understand how the code works.\nFor short methods, the code only does one thing, which is already described in\nits interface comment, so no implementation comments are needed. Longer\nmethods have several blocks of code that do different things as part of the\nmethod\u2019s overall task. Add a comment before each of the major blocks to provide\na high-level (more abstract) description of what that block does. Here is an\nexample:\n// Phase 1: Scan active RPCs to see if any have completed.\nFor loops, it\u2019s helpful to have a comment before the loop that describes what\n", "page": 123, "type": "text", "section": "Page 123"}
{"text": "For loops, it\u2019s helpful to have a comment before the loop that describes what\nhappens in each iteration:\n// Each iteration of the following loop extracts one request from\n// the request message, increments the corresponding object, and\n// appends a response to the response message.\nNotice how this comment describes the loop at a more abstract and intuitive\nlevel; it doesn\u2019t go into any details about how a request is extracted from the\nrequest message or how the object is incremented. Loop comments are only\nneeded for longer or more complex loops, where it may not be obvious what the\nloop is doing; many loops are short and simple enough that their behavior is\nalready obvious.\nIn addition to describing what the code is doing, implementation comments\nare also useful to explain why. If there are tricky aspects to the code that won\u2019t be\nobvious from reading it, you should document them. For example, if a bug fix\nrequires the addition of code whose purpose isn\u2019t totally obvious, add a comment\ndescribing why the code is needed. For bug fixes where there is a well-written\nbug report describing the problem, the comment can refer to the issue in the bug\ntracking database rather than repeating all its details (\u201cFixes RAM-436, related\nto device driver crashes in Linux 2.4.x\u201d). Developers can look in the bug\ndatabase for more details (this is an example of avoiding duplication in\ncomments, which will be discussed in Chapter 16).\nFor longer methods, it can be helpful to write comments for a few of the most\nimportant local variables. However, most local variables don\u2019t need\ndocumentation if they have good names. If all of the uses of a variable are visible\nwithin a few lines of each other, it\u2019s usually easy to understand the variable\u2019s\npurpose without a comment. In this case it\u2019s OK to let readers read the code to\nfigure out the meaning of the variable. However, if the variable is used over a\nlarge span of code, then you should consider adding a comment to describe the\nvariable. When documenting variables, focus on what the variable represents, not\nhow it is manipulated in the code.\n13.7  Cross-module design decisions\nIn a perfect world, every important design decision would be encapsulated within\na single class. Unfortunately, real systems inevitably end up with design\ndecisions that affect multiple classes. For example, the design of a network\nprotocol will affect both the sender and the receiver, and these may be\n", "page": 124, "type": "text", "section": "Page 124"}
{"text": "implemented in different places. Cross-module decisions are often complex and\nsubtle, and they account for many bugs, so good documentation for them is\ncrucial.\nThe biggest challenge with cross-module documentation is finding a place to\nput it where it will naturally be discovered by developers. Sometimes there is an\nobvious central place to put such documentation. For example, the RAMCloud\nstorage system defines a Status value, which is returned by each request to\nindicate success or failure. Adding a Status for a new error condition requires\nmodifying many different files (one file maps Status values to exceptions,\nanother provides a human-readable message for each Status, and so on).\nFortunately, there is one obvious place where developers will have to go when\nadding a new status value, which is the declaration of the Status enum. We took\nadvantage of this by adding comments in that enum to identify all of the other\nplaces that must also be modified:\ntypedef enum Status {\n       STATUS_OK = 0,\n       STATUS_UNKNOWN_TABLET                = 1,\n       STATUS_WRONG_VERSION                 = 2,\n       ...\n       STATUS_INDEX_DOESNT_EXIST            = 29,\n       STATUS_INVALID_PARAMETER             = 30,\n       STATUS_MAX_VALUE                     = 30,\n       // Note: if you add a new status value you must make the following\n       // additional updates:\n       // (1)  Modify STATUS_MAX_VALUE to have a value equal to the\n       //      largest defined status value, and make sure its definition\n       //      is the last one in the list. STATUS_MAX_VALUE is used\n       //      primarily for testing.\n       // (2)  Add new entries in the tables \"messages\" and \"symbols\" in\n       //      Status.cc.\n       // (3)  Add a new exception class to ClientException.h\n       // (4)  Add a new \"case\" to ClientException::throwException to map\n       //      from the status value to a status-specific ClientException\n       //      subclass.\n", "page": 125, "type": "text", "section": "Page 125"}
{"text": "       // (5)  In the Java bindings, add a static class for the exception\n       //      to ClientException.java\n       // (6)  Add a case for the status of the exception to throw the\n       //      exception in ClientException.java\n       // (7)  Add the exception to the Status enum in Status.java, making\n       //      sure the status is in the correct position corresponding to\n       //      its status code.\n}\nNew status values will be added at the end of the existing list, so the comments\nare also placed at the end, where they are most likely to be seen.\nUnfortunately, in many cases there is not an obvious central place to put\ncross-module documentation. One example from the RAMCloud storage system\nwas the code for dealing with zombie servers, which are servers that the system\nbelieves have crashed, but in fact are still running. Neutralizing zombie servers\nrequired code in several different modules, and these pieces of code all depend\non each other. None of the pieces of code is an obvious central place to put\ndocumentation. One possibility is to duplicate parts of the documentation in each\nlocation that depends on it. However, this is awkward, and it is difficult to keep\nsuch documentation up to date as the system evolves. Alternatively, the\ndocumentation can be located in one of the places where it is needed, but in this\ncase it\u2019s unlikely that developers will see the documentation or know where to\nlook for it.\nI have recently been experimenting with an approach where cross-module\nissues are documented in a central file called designNotes. The file is divided up\ninto clearly labeled sections, one for each major topic. For example, here is an\nexcerpt from the file:\n...\nZombies\n-------\nA zombie is a server that is considered dead by the rest of the\ncluster; any data stored on the server has been recovered and will\nbe managed by other servers. However, if a zombie is not actually\ndead (e.g., it was just disconnected from the other servers for a\nwhile) two forms of inconsistency can arise:\n* A zombie server must not serve read requests once replacement servers\nhave taken over; otherwise it may return stale data that does not\n", "page": 126, "type": "text", "section": "Page 126"}
{"text": "reflect writes accepted by the replacement servers.\n* The zombie server must not accept write requests once replacement\nservers have begun replaying its log during recovery; if it does,\nthese writes may be lost (the new values may not be stored on the\nreplacement servers and thus will not be returned by reads).\nRAMCloud uses two techniques to neutralize zombies. First,\n...\nThen, in any piece of code that relates to one of these issues there is a short\ncomment referring to the designNotes file:\n// See \"Zombies\" in designNotes.\nWith this approach, there is only a single copy of the documentation and it is\nrelatively easy for developers to find it when they need it. However, this has the\ndisadvantage that the documentation is not near any of the pieces of code that\ndepend on it, so it may be difficult to keep up-to-date as the system evolves.\n13.8  Conclusion\nThe goal of comments is to ensure that the structure and behavior of the system\nis obvious to readers, so they can quickly find the information they need and\nmake modifications to the system with confidence that they will work. Some of\nthis information can be represented in the code in a way that will already be\nobvious to readers, but there is a significant amount of information that can\u2019t\neasily be deduced from the code. Comments fill in this information.\nWhen following the rule that comments should describe things that aren\u2019t\nobvious from the code, \u201cobvious\u201d is from the perspective of someone reading\nyour code for the first time (not you). When writing comments, try to put\nyourself in the mindset of the reader and ask yourself what are the key things he\nor she will need to know. If your code is undergoing review and a reviewer tells\nyou that something is not obvious, don\u2019t argue with them; if a reader thinks it\u2019s\nnot obvious, then it\u2019s not obvious. Instead of arguing, try to understand what they\nfound confusing and see if you can clarify that, either with better comments or\nbetter code.\n13.9  Answers to questions from Section 13.5\nDoes a developer need to know each of the following pieces of information in\n", "page": 127, "type": "text", "section": "Page 127"}
{"text": "Does a developer need to know each of the following pieces of information in\norder to use the IndexLookup class?\n1. The format of messages that the IndexLookup class sends to the servers\nholding indexes and objects. No: this is an implementation detail that\nshould be hidden within the class.\n2. The comparison function used to determine whether a particular object\nfalls in the desired range (is comparison done using integers, floating-\npoint numbers, or strings?). Yes: users of the class need to know this\ninformation.\n3. The data structure used to store indexes on servers. No: this information\nshould be encapsulated on the servers; not even the implementation of\nIndexLookup should need to know this.\n4. Whether or not IndexLookup issues multiple requests to different servers\nconcurrently. Possibly: if IndexLookup uses special techniques to improve\nperformance, then the documentation should provide some high-level\ninformation about this, since users may care about performance.\n5. The mechanism for handling server crashes. No: RAMCloud recovers\nautomatically from server crashes, so crashes are not visible to application-\nlevel software; thus, there is no need to mention crashes in the interface\ndocumentation for IndexLookup. If crashes were reflected up to\napplications, then the interface documentation would need to describe how\nthey manifest themselves (but not the details of how crash recovery works).\n", "page": 128, "type": "text", "section": "Page 128"}
{"text": "Chapter 14\nChoosing Names\nSelecting names for variables, methods, and other entities is one of the most\nunderrated aspects of software design. Good names are a form of documentation:\nthey make code easier to understand. They reduce the need for other\ndocumentation and make it easier to detect errors. Conversely, poor name\nchoices increase the complexity of code and create ambiguities and\nmisunderstandings that can result in bugs. Name choice is an example of the\nprinciple that complexity is incremental. Choosing a mediocre name for a\nparticular variable, as opposed to the best possible name, probably won\u2019t have\nmuch impact on the overall complexity of a system. However, software systems\nhave thousands of variables; choosing good names for all of these will have a\nsignificant impact on complexity and manageability.\n14.1  Example: bad names cause bugs\nSometimes even a single poorly named variable can have severe consequences.\nThe most challenging bug I ever fixed came about because of a poor name\nchoice. In the late 1980\u2019s and early 1990\u2019s my graduate students and I created a\ndistributed operating system called Sprite. At some point we noticed that files\nwould occasionally lose data: one of the data blocks suddenly became all zeroes,\neven though the file had not been modified by a user. The problem didn\u2019t happen\nvery often, so it was exceptionally difficult to track down. A few of the graduate\nstudents tried to find the bug, but they were unable to make progress and\neventually gave up. However, I consider any unsolved bug to be an intolerable\npersonal insult, so I decided to track it down.\nIt took six months, but I eventually found and fixed the bug. The problem\nwas actually quite simple (as are most bugs, once you figure them out). The file\nsystem code used the variable name block for two different purposes. In some\nsituations, block referred to a physical block number on disk; in other situations,\n", "page": 129, "type": "text", "section": "Page 129"}
{"text": "block referred to a logical block number within a file. Unfortunately, at one point\nin the code there was a block variable containing a logical block number, but it\nwas accidentally used in a context where a physical block number was needed; as\na result, an unrelated block on disk got overwritten with zeroes.\nWhile tracking down the bug, several people, including myself, read over the\nfaulty code, but we never noticed the problem. When we saw the variable block\nused as a physical block number, we reflexively assumed that it really held a\nphysical block number. It took a long process of instrumentation, which\neventually showed that the corruption must be happening in a particular\nstatement, before I was able to get past the mental block created by the name and\ncheck to see exactly where its value came from. If different variable names had\nbeen used for the different kinds of blocks, such as fileBlock and diskBlock, it\u2019s\nunlikely that the error would have happened; the programmer would have known\nthat fileBlock couldn\u2019t be used in that situation.\nUnfortunately, most developers don\u2019t spend much time thinking about names.\nThey tend to use the first name that comes to mind, as long as it\u2019s reasonably\nclose to matching the thing it names. For example, block is a pretty close match\nfor both a physical block on disk and a logical block within a file; it\u2019s certainly\nnot a horrible name. Even so, it resulted in a huge expenditure of time to track\ndown a subtle bug. Thus, you shouldn\u2019t settle for names that are just \u201creasonably\nclose\u201d. Take a bit of extra time to choose great names, which are precise,\nunambiguous, and intuitive. The extra attention will pay for itself quickly, and\nover time you\u2019ll learn to choose good names quickly.\n14.2  Create an image\nWhen choosing a name, the goal is to create an image in the mind of the reader\nabout the nature of the thing being named. A good name conveys a lot of\ninformation about what the underlying entity is, and, just as important, what it is\nnot. When considering a particular name, ask yourself: \u201cIf someone sees this\nname in isolation, without seeing its declaration, its documentation, or any code\nthat uses the name, how closely will they be able to guess what the name refers\nto? Is there some other name that will paint a clearer picture?\u201d Of course, there is\na limit to how much information you can put in a single name; names become\nunwieldy if they contain more than two or three words. Thus, the challenge is to\nfind just a few words that capture the most important aspects of the entity.\n", "page": 130, "type": "text", "section": "Page 130"}
{"text": "Names are a form of abstraction: they provide a simplified way of thinking\nabout a more complex underlying entity. Like other forms of abstraction, the best\nnames are those that focus attention on what is most important about the\nunderlying entity while omitting details that are less important.\n14.3  Names should be precise\nGood names have two properties: precision and consistency. Let\u2019s start with\nprecision. The most common problem with names is that they are too generic or\nvague; as a result, it\u2019s hard for readers to tell what the name refers to; the reader\nmay assume that the name refers to something different from reality, as in the\nblock bug above. Consider the following method declaration:\n/**\n * Returns the total number of indexlets this object is managing.\n */\nint IndexletManager::getCount() {...}\nThe term \u201ccount\u201d is too generic: count of what? If someone sees an invocation of\nthis method, they are unlikely to know what it does unless they read its\ndocumentation. A more precise name like getActiveIndexlets or numIndexlets\nwould be better: with one of these names, readers will probably be able to guess\nwhat the method returns without having to look at its documentation.\nHere are some other examples of names that aren\u2019t precise enough, taken\nfrom various student projects:\nA project building a GUI text editor used the names x and y to refer to the\nposition of a character in the file. These names are too generic. They could\nmean many things; for example, they might also represent the coordinates\n(in pixels) of a character on the screen. Someone seeing the name x in\nisolation is unlikely to think that it refers to the position of a character\nwithin a line of text. The code would be clearer if it used names such as\ncharIndex and lineIndex, which reflect the specific abstractions that the\ncode implements.\nAnother editor project contained the following code:\n// Blink state: true when cursor visible.\nprivate boolean blinkStatus = true;\nThe name blinkStatus doesn\u2019t convey enough information. The word\n\u201cstatus\u201d is too vague for a boolean value: it gives no clue about what a true\n", "page": 131, "type": "text", "section": "Page 131"}
{"text": "or false value means. The word \u201cblink\u201d is also vague, since it doesn\u2019t\nindicate what is blinking. The following alternative is better:\n// Controls cursor blinking: true means the cursor is visible,\n// false means the cursor is not displayed.\nprivate boolean cursorVisible = true;\nThe name cursorVisible conveys more information; for example, it allows\nreaders to guess what a true value means (as a general rule, names of\nboolean variables should always be predicates). The word \u201cblink\u201d is no\nlonger in the name, so readers will have to consult the documentation if they\nwant to know why the cursor isn\u2019t always visible; this information is less\nimportant.\nA project implementing a consensus protocol contained the following code:\n// Value representing that the server has not voted (yet) for\n// anyone for the current election term.\nprivate static final String VOTED_FOR_SENTINEL_VALUE = \"null\";\nThe name for this value indicates that it\u2019s special but it doesn\u2019t say what the\nspecial meaning is. A more specific name such as NOT_YET_VOTED would be\nbetter.\nA variable named result was used in a method with no return value. This\nname has multiple problems. First, it creates the misleading impression that\nit will be the return value of the method. Second, it provides essentially no\ninformation about what it actually holds, except that it is some computed\nvalue. The name should provide information about what the result actually\nis, such as mergedLine or totalChars. In methods that do actually have\nreturn values, then using the name result is reasonable. This name is still a\nbit generic, but readers can look at the method documentation to see its\nmeaning, and it\u2019s helpful to know that the value will eventually become the\nreturn value.\n Red Flag: Vague Name \nIf a variable or method name is broad enough to refer to many different things,\nthen it doesn\u2019t convey much information to the developer and the underlying\nentity is more likely to be misused.\n", "page": 132, "type": "text", "section": "Page 132"}
{"text": "Like all rules, the rule about choosing precise names has a few exceptions.\nFor example, it\u2019s fine to use generic names like i and j as loop iteration\nvariables, as long as the loops only span a few lines of code. If you can see the\nentire range of usage of a variable, then the meaning of the variable will\nprobably be obvious from the code so you don\u2019t need a long name. For example,\nconsider the following code:\nfor  (i = 0; i < numLines; i++) {\n       ...\n}\nIt\u2019s clear from this code that i is being used to iterate over each of the lines in\nsome entity. If the loop gets so long that you can\u2019t see it all at once, or if the\nmeaning of the iteration variable is harder to figure out from the code, then a\nmore descriptive name is in order.\nIt\u2019s also possible for a name to be too specific, such as in this declaration for\na method that deletes a range of text:\nvoid delete(Range selection) {...}\nThe argument name selection is too specific, since it suggests that the text being\ndeleted is always selected in the user interface. However, this method can be\ninvoked on any range of text, selected or not. Thus, the argument name should be\nmore generic, such as range.\nIf you find it difficult to come up with a name for a particular variable that is\nprecise, intuitive, and not too long, this is a red flag. It suggests that the variable\nmay not have a clear definition or purpose. When this happens, consider\nalternative factorings. For example, perhaps you are trying to use a single\nvariable to represent several things; if so, separating the representation into\nmultiple variables may result in a simpler definition for each variable. The\nprocess of choosing good names can improve your design by identifying\nweaknesses.\n Red Flag: Hard to Pick Name \nIf it\u2019s hard to find a simple name for a variable or method that creates a clear\nimage of the underlying object, that\u2019s a hint that the underlying object may not\nhave a clean design.\n", "page": 133, "type": "text", "section": "Page 133"}
{"text": "14.4 Use names consistently\nThe second important property of good names is consistency. In any program\nthere are certain variables that are used over and over again. For example, a file\nsystem manipulates block numbers repeatedly. For each of these common usages,\npick a name to use for that purpose, and use the same name everywhere. For\nexample, a file system might always use fileBlock to hold the index of a block\nwithin a file. Consistent naming reduces cognitive load in much the same way as\nreusing a common class: once the reader has seen the name in one context, they\ncan reuse their knowledge and instantly make assumptions when they see the\nname in a different context.\nConsistency has three requirements: first, always use the common name for\nthe given purpose; second, never use the common name for anything other than\nthe given purpose; third, make sure that the purpose is narrow enough that all\nvariables with the name have the same behavior. This third requirement was\nviolated in the file system bug at the beginning of the chapter. The file system\nused block for variables with two different behaviors (file blocks and disk\nblocks); this led to a false assumption about the meaning of a variable, which in\nturn resulted in a bug.\nSometimes you will need multiple variables that refer to the same general\nsort of thing. For example, a method that copies file data will need two block\nnumbers, one for the source and one for the destination. When this happens, use\nthe common name for each variable but add a distinguishing prefix, such as\nsrcFileBlock and dstFileBlock.\nLoops are another area where consistent naming can help. If you use names\nsuch as i and j for loop variables, always use i in outermost loops and j for\nnested loops. This allows readers to make instant (safe) assumptions about what\u2019s\nhappening in the code when they see a given name.\n14.5  A different opinion: Go style guide\nNot everyone shares my views about naming. Some of the developers of the Go\nlanguage argue that names should be very short, often only a single character. In\na presentation on name choice for Go, Andrew Gerrand states that \u201clong names\nobscure what the code does.\u201d1 He presents this code sample, which uses single-\nletter variable names:\nfunc RuneCount(b []byte) int {\n", "page": 134, "type": "text", "section": "Page 134"}
{"text": "       i, n := 0, 0\n       for i < len(b) {\n             if b[i] < RuneSelf {\n                   i++\n             } else {\n                   _, size := DecodeRune(b[i:])\n                   i += size\n             }\n             n++\n       }\n       return n\n}\nand argues that it is more readable than the following version, which uses longer\nnames:\nfunc RuneCount(buffer []byte) int {\n       index, count := 0, 0\n       for index < len(buffer) {\n             if buffer[index] < RuneSelf {\n                   index++\n             } else {\n                   _, size := DecodeRune(buffer[index:])\n                   index += size\n             }\n             count++\n       }\n       return count\n}\nPersonally, I don\u2019t find the second version any more difficult to read than the\nfirst. If anything, the name count gives a slightly better clue to the behavior of\nthe variable than n. With the first version I ended up reading through the code\ntrying to figure out what n means, whereas I didn\u2019t feel that need with the second\nversion. But, if n is used consistently throughout the system to refer to counts\n(and nothing else), then the short name will probably be clear to other\ndevelopers.\n", "page": 135, "type": "text", "section": "Page 135"}
{"text": "The Go culture encourages the use of the same short name for multiple\ndifferent things: ch for character or channel, d for data, difference, or distance,\nand so on. To me, ambiguous names like these are likely to result in confusion\nand error, just as in the block example.\nOverall, I would argue that readability must be determined by readers, not\nwriters. If you write code with short variable names and the people who read it\nfind it easy to understand, then that\u2019s fine. If you start getting complaints that\nyour code is cryptic, then you should consider using longer names (a Web search\nfor \u201cgo language short names\u201d will identify several such complaints). Similarly,\nif I start getting complaints that long variable names make my code harder to\nread, then I\u2019ll consider using shorter ones.\nGerrand makes one comment that I agree with: \u201cThe greater the distance\nbetween a name\u2019s declaration and its uses, the longer the name should be.\u201d The\nearlier discussion about using loop variables named i and j is an example of this\nrule.\n14.6  Conclusion\nWell chosen names help to make code more obvious; when someone encounters\nthe variable for the first time, their first guess about its behavior, made without\nmuch thought, will be correct. Choosing good names is an example of the\ninvestment mindset discussed in Chapter 3: if you take a little extra time up front\nto select good names, it will be easier for you to work on the code in the future.\nIn addition, you will be less likely to introduce bugs. Developing a skill for\nnaming is also an investment. When you first decide to stop settling for mediocre\nnames, you may find it frustrating and time-consuming to come up with good\nnames. However, as you get more experience you\u2019ll find that it becomes easier;\neventually, you\u2019ll get to the point where it takes almost no extra time to choose\ngood names, so you will get the benefits almost for free.\n1https://talks.golang.org/2014/names.slide#1\n", "page": 136, "type": "text", "section": "Page 136"}
{"text": "Chapter 15\nWrite The Comments First\n(Use Comments As Part Of The Design Process)\nMany developers put off writing documentation until the end of the\ndevelopment process, after coding and unit testing are complete. This is one of\nthe surest ways to produce poor quality documentation. The best time to write\ncomments is at the beginning of the process, as you write the code. Writing the\ncomments first makes documentation part of the design process. Not only does\nthis produce better documentation, but it also produces better designs and it\nmakes the process of writing documentation more enjoyable.\n15.1  Delayed comments are bad comments\nAlmost every developer I have ever met puts off writing comments. When asked\nwhy they don\u2019t write documentation earlier, they say that the code is still\nchanging. If they write documentation early, they say, they\u2019ll have to rewrite it\nwhen the code changes; better to wait until the code stabilizes. However, I\nsuspect that there is also another reason, which is that they view documentation\nas drudge work; thus, they put it off as long as possible.\nUnfortunately, this approach has several negative consequences. First,\ndelaying documentation often means that it never gets written at all. Once you\nstart delaying, it\u2019s easy to delay a bit more; after all, the code will be even more\nstable in a few more weeks. By the time the code has inarguably stabilized, there\nis a lot of it, which means the task of writing documentation has become huge\nand even less attractive. There\u2019s never a convenient time to stop for a few days\nand fill in all of the missing comments, and it\u2019s easy to rationalize that the best\nthing for the project is to move on and fix bugs or write the next new feature.\nThis will create even more undocumented code.\nEven if you do have the self-discipline to go back and write the comments\n", "page": 137, "type": "text", "section": "Page 137"}
{"text": "Even if you do have the self-discipline to go back and write the comments\n(and don\u2019t fool yourself: you probably don\u2019t), the comments won\u2019t be very good.\nBy this time in the process, you have checked out mentally. In your mind, this\npiece of code is done; you are eager to move on to your next project. You know\nthat writing comments is the right thing to do, but it\u2019s no fun. You just want to\nget through it as quickly as possible. Thus, you make a quick pass over the code,\nadding just enough comments to look respectable. By now, it\u2019s been a while\nsince you designed the code, so your memories of the design process are\nbecoming fuzzy. You look at the code as you are writing the comments, so the\ncomments repeat the code. Even if you try to reconstruct the design ideas that\naren\u2019t obvious from the code, there will be things you don\u2019t remember. Thus, the\ncomments are missing some of the most important things they should describe.\n15.2  Write the comments first\nI use a different approach to writing comments, where I write the comments at\nthe very beginning:\nFor a new class, I start by writing the class interface comment.\nNext, I write interface comments and signatures for the most important\npublic methods, but I leave the method bodies empty.\nI iterate a bit over these comments until the basic structure feels about right.\nAt this point I write declarations and comments for the most important class\ninstance variables in the class.\nFinally, I fill in the bodies of the methods, adding implementation\ncomments as needed.\nWhile writing method bodies, I usually discover the need for additional\nmethods and instance variables. For each new method I write the interface\ncomment before the body of the method; for instance variables I fill in the\ncomment at the same time that I write the variable declaration.\nWhen the code is done, the comments are also done. There is never a backlog of\nunwritten comments.\nThe comments-first approach has three benefits. First, it produces better\ncomments. If you write the comments as you are designing the class, the key\ndesign issues will be fresh in your mind, so it\u2019s easy to record them. It\u2019s better to\nwrite the interface comment for each method before its body, so you can focus on\nthe method\u2019s abstraction and interface without being distracted by its\nimplementation. During the coding and testing process you will notice and fix\n", "page": 138, "type": "text", "section": "Page 138"}
{"text": "problems with the comments. As a result, the comments improve over the course\nof development.\n15.3  Comments are a design tool\nThe second, and most important, benefit of writing the comments at the\nbeginning is that it improves the system design. Comments provide the only way\nto fully capture abstractions, and good abstractions are fundamental to good\nsystem design. If you write comments describing the abstractions at the\nbeginning, you can review and tune them before writing implementation code.\nTo write a good comment, you must identify the essence of a variable or piece of\ncode: what are the most important aspects of this thing? It\u2019s important to do this\nearly in the design process; otherwise you are just hacking code.\nComments serve as a canary in the coal mine of complexity. If a method or\nvariable requires a long comment, it is a red flag that you don\u2019t have a good\nabstraction. Remember from Chapter 4 that classes should be deep: the best\nclasses have very simple interfaces yet implement powerful functions. The best\nway to judge the complexity of an interface is from the comments that describe\nit. If the interface comment for a method provides all the information needed to\nuse the method and is also short and simple, that indicates that the method has a\nsimple interface. Conversely, if there\u2019s no way to describe a method completely\nwithout a long and complicated comment, then the method has a complex\ninterface. You can compare a method\u2019s interface comment with the\nimplementation to get a sense of how deep the method is: if the interface\ncomment must describe all the major features of the implementation, then the\nmethod is shallow. The same idea applies to variables: if it takes a long comment\nto fully describe a variable, it\u2019s a red flag that suggests you may not have chosen\nthe right variable decomposition. Overall, the act of writing comments allows\nyou to evaluate your design decisions early, so you can discover and fix\nproblems.\n Red Flag: Hard to Describe \nThe comment that describes a method or variable should be simple and yet\ncomplete. If you find it difficult to write such a comment, that\u2019s an indicator\nthat there may be a problem with the design of the thing you are describing.\n", "page": 139, "type": "text", "section": "Page 139"}
{"text": "Of course, comments are only a good indicator of complexity if they are\ncomplete and clear. If you write a method interface comment that doesn\u2019t provide\nall the information needed to invoke the method, or one that is so cryptic that it\u2019s\nhard to understand, then that comment doesn\u2019t provide a good measure of the\nmethod\u2019s depth.\n15.4  Early comments are fun comments\nThe third and final benefit of writing comments early is that it makes comment-\nwriting more fun. For me, one of the most enjoyable parts of programming is the\nearly design phase for a new class, where I\u2019m fleshing out the abstractions and\nstructure for the class. Most of my comments are written during this phase, and\nthe comments are how I record and test the quality of my design decisions. I\u2019m\nlooking for the design that can be expressed completely and clearly in the fewest\nwords. The simpler the comments, the better I feel about my design, so finding\nsimple comments is a source of pride. If you are programming strategically,\nwhere your main goal is a great design rather than just writing code that works,\nthen writing comments should be fun, since that\u2019s how you identify the best\ndesigns.\n15.5  Are early comments expensive?\nNow let\u2019s revisit the argument for delaying comments, which is that it avoids the\ncost of reworking the comments as the code evolves. A simple back-of-the-\nenvelope calculation will show that this doesn\u2019t save much. First, estimate the\ntotal fraction of development time that you spend typing in code and comments\ntogether, including time to revise code and comments; it\u2019s unlikely that this will\nbe more than about 10% of all development time. Even if half of your total code\nlines are comments, writing comments probably doesn\u2019t account for more than\nabout 5% of your total development time. Delaying the comments until the end\nwill save only a fraction of this, which isn\u2019t very much.\nWriting the comments first will mean that the abstractions will be more\nstable before you start writing code. This will probably save time during coding.\nIn contrast, if you write the code first, the abstractions will probably evolve as\nyou code, which will require more code revisions than the comments-first\napproach. When you consider all of these factors, it\u2019s possible that it might be\nfaster overall to write the comments first.\n", "page": 140, "type": "text", "section": "Page 140"}
{"text": "15.6  Conclusion\nIf you haven\u2019t ever tried writing the comments first, give it a try. Stick with it\nlong enough to get used to it. Then think about how it affects the quality of your\ncomments, the quality of your design, and your overall enjoyment of software\ndevelopment. After you have tried this for a while, let me know whether your\nexperience matches mine, and why or why not.\n", "page": 141, "type": "text", "section": "Page 141"}
{"text": "Chapter 16\nModifying Existing Code\nChapter 1 described how software development is iterative and incremental. A\nlarge software system develops through a series of evolutionary stages, where\neach stage adds new capabilities and modifies existing modules. This means that\na system\u2019s design is constantly evolving. It isn\u2019t possible to conceive the right\ndesign for a system at the outset; the design of a mature system is determined\nmore by changes made during the system\u2019s evolution than by any initial\nconception. Previous chapters described how to squeeze out complexity during\nthe initial design and implementation; this chapter discusses how to keep\ncomplexity from creeping in as the system evolves.\n16.1  Stay strategic\nChapter 3 introduced the distinction between tactical programming and strategic\nprogramming: in tactical programming, the primary goal is to get something\nworking quickly, even if that results in additional complexity; in strategic\nprogramming, the most important goal is to produce a great system design. The\ntactical approach very quickly leads to a messy system design. If you want to\nhave a system that is easy to maintain and enhance, then \u201cworking\u201d isn\u2019t a high\nenough standard; you have to prioritize design and think strategically. This idea\nalso applies when you are modifying existing code.\nUnfortunately, when developers go into existing code to make changes such\nas bug fixes or new features, they don\u2019t usually think strategically. A typical\nmindset is \u201cwhat is the smallest possible change I can make that does what I\nneed?\u201d Sometimes developers justify this because they are not comfortable with\nthe code being modified; they worry that larger changes carry a greater risk of\nintroducing new bugs. However, this results in tactical programming. Each one\nof these minimal changes introduces a few special cases, dependencies, or other\nforms of complexity. As a result, the system design gets just a bit worse, and the\nproblems accumulate with each step in the system\u2019s evolution.\n", "page": 142, "type": "text", "section": "Page 142"}
{"text": "If you want to maintain a clean design for a system, you must take a strategic\napproach when modifying existing code. Ideally, when you have finished with\neach change, the system will have the structure it would have had if you had\ndesigned it from the start with that change in mind. To achieve this goal, you\nmust resist the temptation to make a quick fix. Instead, think about whether the\ncurrent system design is still the best one, in light of the desired change. If not,\nrefactor the system so that you end up with the best possible design. With this\napproach, the system design improves with every modification.\nThis is also an example of the investment mindset introduced on page 15: if\nyou invest a little extra time to refactor and improve the system design, you\u2019ll end\nup with a cleaner system. This will speed up development, and you will recoup\nthe effort that you invested in the refactoring. Even if your particular change\ndoesn\u2019t require refactoring, you should still be on the lookout for design\nimperfections that you can fix while you\u2019re in the code. Whenever you modify\nany code, try to find a way to improve the system design at least a little bit in the\nprocess. If you\u2019re not making the design better, you are probably making it\nworse.\nAs discussed in Chapter 3, an investment mindset sometimes conflicts with\nthe realities of commercial software development. If refactoring the system \u201cthe\nright way\u201d would take three months but a quick and dirty fix would take only two\nhours, you may have to take the quick and dirty approach, particularly if you are\nworking against a tight deadline. Or, if refactoring the system would create\nincompatibilities that affect many other people and teams, then the refactoring\nmay not be practical.\nNonetheless, you should resist these compromises as much as possible. Ask\nyourself \u201cIs this the best I can possibly do to create a clean system design, given\nmy current constraints?\u201d Perhaps there\u2019s an alternative approach that would be\nalmost as clean as the 3-month refactoring but could be done in a couple of days?\nOr, if you can\u2019t afford to do a large refactoring now, get your boss to allocate time\nfor you to come back to it after the current deadline. Every development\norganization should plan to spend a small fraction of its total effort on cleanup\nand refactoring; this work will pay for itself over the long run.\n16.2 Maintaining comments: keep the comments near the\ncode\nWhen you change existing code, there\u2019s a good chance that the changes will\n", "page": 143, "type": "text", "section": "Page 143"}
{"text": "When you change existing code, there\u2019s a good chance that the changes will\ninvalidate some of the existing comments. It\u2019s easy to forget to update comments\nwhen you modify code, which results in comments that are no longer accurate.\nInaccurate comments are frustrating to readers, and if there are very many of\nthem, readers begin to distrust all of the comments. Fortunately, with a little\ndiscipline and a couple of guiding rules, it\u2019s possible to keep comments up-to-\ndate without a huge effort. This section and the following ones put forth some\nspecific techniques.\nThe best way to ensure that comments get updated is to position them\nclose to the code they describe, so developers will see them when they change\nthe code. The farther a comment is from its associated code, the less likely it is\nthat it will be updated properly. For example, the best place for a method\u2019s\ninterface comment is in the code file, right next to the body of the method. Any\nchanges to the method will involve this code, so the developer is likely to see the\ninterface comments and update them if needed.\nAn alternative for languages like C and C++ that have separate code and\nheader files, is to place the interface comments next to the method\u2019s declaration\nin the .h file. However, this is a long way from the code; developers won\u2019t see\nthose comments when modifying the method\u2019s body, and it takes additional work\nto open a different file and find the interface comments to update them. Some\nmight argue that interface comments should go in header files so that users can\nlearn how to use an abstraction without having to look at the code file. However,\nusers should not need to read either code or header files; they should get their\ninformation from documentation compiled by tools such as Doxygen or Javadoc.\nIn addition, many IDEs will extract and present documentation to users, such as\nby displaying a method\u2019s documentation when the method\u2019s name is typed.\nGiven tools such as these, the documentation should be located in the place that\nis most convenient for developers working on the code.\nWhen writing implementation comments, don\u2019t put all the comments for an\nentire method at the top of the method. Spread them out, pushing each comment\ndown to the narrowest scope that includes all of the code referred to by the\ncomment. For example, if a method has three major phases, don\u2019t write one\ncomment at the top of the method that describes all of the phases in detail.\nInstead, write a separate comment for each phase and position that comment just\nabove the first line of code in that phase. On the other hand, it can also be helpful\n", "page": 144, "type": "text", "section": "Page 144"}
{"text": "to have a comment at the top of a method\u2019s implementation that describes the\noverall strategy, like this:\n//  We proceed in three phases:\n//  Phase 1: Find feasible candidates\n//  Phase 2: Assign each candidate a score\n//  Phase 3: Choose the best, and remove it\nAdditional details can be documented just above the code for each phase.\nIn general, the farther a comment is from the code it describes, the more\nabstract it should be (this reduces the likelihood that the comment will be\ninvalidated by code changes).\n16.3  Comments belong in the code, not the commit log\nA common mistake when modifying code is to put detailed information about\nthe change in the commit message for the source code repository, but then not to\ndocument it in the code. Although commit messages can be browsed in the\nfuture by scanning the repository\u2019s log, a developer who needs the information is\nunlikely to think of scanning the repository log. Even if they do scan the log, it\nwill be tedious to find the right log message.\nWhen writing a commit message, ask yourself whether developers will need\nto use that information in the future. If so, then document this information in the\ncode. An example is a commit message describing a subtle problem that\nmotivated a code change. If this isn\u2019t documented in the code, then a developer\nmight come along later and undo the change without realizing that they have re-\ncreated a bug. If you want to include a copy of this information in the commit\nmessage as well, that\u2019s fine, but the most important thing is to get it in the code.\nThis illustrates the principle of placing documentation in the place where\ndevelopers are most likely to see it; the commit log is rarely that place.\n16.4  Maintaining comments: avoid duplication\nThe second technique for keeping comments up to date is to avoid duplication. If\ndocumentation is duplicated, it is more difficult for developers to find and update\nall of the relevant copies. Instead, try to document each design decision exactly\nonce. If there are multiple places in the code that are affected by a particular\ndecision, don\u2019t repeat the documentation at each of these points. Instead, find the\nmost obvious single place to put the documentation. For example, suppose there\n", "page": 145, "type": "text", "section": "Page 145"}
{"text": "is tricky behavior related to a variable, which affects several different places\nwhere the variable is used. You can document that behavior in the comment next\nto the variable\u2019s declaration. This is a natural place that developers are likely to\ncheck if they\u2019re having trouble understanding code that uses the variable.\nIf there is no \u201cobvious\u201d single place to put a particular piece of\ndocumentation where developers will find it, create a designNotes file as\ndescribed in Section 13.7. Or, pick the best of the available places and put the\ndocumentation there. In addition, add short comments in the other places that\nrefer to the central location: \u201cSee the comment in xyz for an explanation of the\ncode below.\u201d If the reference becomes obsolete because the master comment was\nmoved or deleted, this inconsistency will be self-evident because developers\nwon\u2019t find the comment at the indicated place; they can use revision control\nhistory to find out what happened to the comment and then update the reference.\nIn contrast, if the documentation is duplicated and some of the copies don\u2019t get\nupdated, there will be no indication to developers that they are using stale\ninformation.\nDon\u2019t redocument one module\u2019s design decisions in another module. For\nexample, don\u2019t put comments before a method call that explain what happens in\nthe called method. If readers want to know, they should look at the interface\ncomments for the method. Good development tools will usually provide this\ninformation automatically, for example, by displaying the interface comments for\na method if you select the method\u2019s name or hover the mouse over it. Try to\nmake it easy for developers to find appropriate documentation, but don\u2019t do it by\nrepeating the documentation.\nIf information is already documented someplace outside your program,\ndon\u2019t repeat the documentation inside the program; just reference the\nexternal documentation. For example, if you write a class that implements the\nHTTP protocol, there\u2019s no need for you to describe the HTTP protocol inside\nyour code. There are already numerous sources for this documentation on the\nWeb; just add a short comment to your code with a URL for one of these\nsources. Another example is features that are already documented in a user\nmanual. Suppose you are writing a program that implements a collection of\ncommands, with one method responsible for implementing each command. If\nthere is a user manual that describes those commands, there\u2019s no need to\nduplicate this information in the code. Instead, include a short note like the\nfollowing in the interface comment for each command method:\n", "page": 146, "type": "text", "section": "Page 146"}
{"text": "// Implements the Foo command; see the user manual for details.\nIt\u2019s important that readers can easily find all the documentation needed to\nunderstand your code, but that doesn\u2019t mean you have to write all of that\ndocumentation.\n16.5 Maintaining comments: check the diffs\nOne good way to make sure documentation stays up to date is to take a few\nminutes before committing a change to your revision control system to scan over\nall the changes for that commit; make sure that each change is properly reflected\nin the documentation. These pre-commit scans will also detect several other\nproblems, such as accidentally leaving debugging code in the system or failing to\nfix TODO items.\n16.6  Higher-level comments are easier to maintain\nOne final thought on maintaining documentation: comments are easier to\nmaintain if they are higher-level and more abstract than the code. These\ncomments do not reflect the details of the code, so they will not be affected by\nminor code changes; only changes in overall behavior will affect these\ncomments. Of course, as discussed in Chapter 13, some comments do need to be\ndetailed and precise. But in general, the comments that are most useful (they\ndon\u2019t simply repeat the code) are also easiest to maintain.\n", "page": 147, "type": "text", "section": "Page 147"}
{"text": "Chapter 17\nConsistency\nConsistency is a powerful tool for reducing the complexity of a system and\nmaking its behavior more obvious. If a system is consistent, it means that similar\nthings are done in similar ways, and dissimilar things are done in different ways.\nConsistency creates cognitive leverage: once you have learned how something is\ndone in one place, you can use that knowledge to immediately understand other\nplaces that use the same approach. If a system is not implemented in a consistent\nfashion, developers must learn about each situation separately. This will take\nmore time.\nConsistency reduces mistakes. If a system is not consistent, two situations\nmay appear the same when in fact they are different. A developer may see a\npattern that looks familiar and make incorrect assumptions based on previous\nencounters with that pattern. On the other hand, if the system is consistent,\nassumptions made based on familiar-looking situations will be safe. Consistency\nallows developers to work more quickly with fewer mistakes.\n17.1  Examples of consistency\nConsistency can be applied at many levels in a system; here are a few examples.\nNames. Chapter 14 has already discussed the benefits of using names in a\nconsistent way.\nCoding style. It is common nowadays for development organizations to have\nstyle guides that restrict program structure beyond the rules enforced by\ncompilers. Modern style guides address a range of issues, such as indentation,\ncurly-brace placement, order of declarations, naming, commenting, and\nrestrictions on language features considered dangerous. Style guidelines make\ncode easier to read and can reduce some kinds of errors.\nInterfaces. An interface with multiple implementations is another example of\n", "page": 148, "type": "text", "section": "Page 148"}
{"text": "Interfaces. An interface with multiple implementations is another example of\nconsistency. Once you understand one implementation of the interface, any other\nimplementation becomes easier to understand because you already know the\nfeatures it will have to provide.\nDesign patterns. Design patterns are generally-accepted solutions to certain\ncommon problems, such as the model-view-controller approach to user interface\ndesign. If you can use an existing design pattern to solve the problem, the\nimplementation will proceed more quickly, it is more likely to work, and your\ncode will be more obvious to readers. Design patterns are discussed in more\ndetail in Section 19.5.\nInvariants. An invariant is a property of a variable or structure that is always\ntrue. For example, a data structure storing lines of text might enforce an invariant\nthat each line is terminated by a newline character. Invariants reduce the number\nof special cases that must be considered in code and make it easier to reason\nabout the code\u2019s behavior.\n17.2  Ensuring consistency\nConsistency is hard to maintain, especially when many people work on a project\nover a long time. People in one group may not know about conventions\nestablished in another group. Newcomers don\u2019t know the rules, so they\nunintentionally violate the conventions and create new conventions that conflict\nwith existing ones. Here are a few tips for establishing and maintaining\nconsistency:\nDocument. Create a document that lists the most important overall conventions,\nsuch as coding style guidelines. Place the document in a spot where developers\nare likely to see it, such as a conspicuous place on the project Wiki. Encourage\nnew people joining the group to read the document, and encourage existing\npeople to review it every once in a while. Several style guides from various\norganizations have been published on the Web; consider starting with one of\nthese.\nFor conventions that are more localized, such as invariants, find an\nappropriate spot in the code to document them. If you don\u2019t write the\nconventions down, it\u2019s unlikely that other people will follow them.\nEnforce. Even with good documentation, it\u2019s hard for developers to remember\nall of the conventions. The best way to enforce conventions is to write a tool that\n", "page": 149, "type": "text", "section": "Page 149"}
{"text": "checks for violations, and make sure that code cannot be committed to the\nrepository unless it passes the checker. Automated checkers work particularly\nwell for low-level syntactic conventions.\nOne of my recent projects had problems with line termination characters.\nSome developers worked on Unix, where lines are terminated by newlines; others\nworked on Windows, where lines are normally terminated by a carriage-return\nfollowed by a newline. If a developer on one system made a small edit to a file\npreviously edited on the other system, the editor would sometimes replace all of\nthe line terminators with ones appropriate for that system. This gave the\nappearance that every line of the file had been modified, which made it hard to\ntrack the meaningful changes. We established a convention that files should\ncontain newlines only, but it was hard to ensure that every tool used by every\ndeveloper followed the convention. Every time a new developer joined the\nproject, we would experience a rash of line termination problems while that\ndeveloper adjusted to the convention.\nWe eventually solved this problem by writing a short script that was executed\nautomatically before changes are committed to the source code repository. The\nscript checks all of the files that have been modified and aborts the commit if any\nof them contain carriage returns. The script can also be run manually to repair\ndamaged files by replacing carriage-return/newline sequences with newlines.\nThis instantly eliminated the problems, and it also helped train new developers.\nCode reviews provide another opportunity for enforcing conventions and for\neducating new developers about the conventions. The more nit-picky that code\nreviewers are, the more quickly everyone on the team will learn the conventions,\nand the cleaner the code will be.\nWhen in Rome ... The most important convention of all is that every developer\nshould follow the old adage \u201cWhen in Rome, do as the Romans do.\u201d When\nworking in a new file, look around to see how the existing code is structured. Are\nall public variables and methods declared before private ones? Are the methods\nin alphabetical order? Do variables use \u201ccamel case,\u201d as in firstServerName, or\n\u201csnake case,\u201d as in first_server_name? When you see anything that looks like it\nmight possibly be a convention, follow it. When making a design decision, ask\nyourself if it\u2019s likely that a similar decision was made elsewhere in the project; if\nso, find an existing example and use the same approach in your new code.\nDon\u2019t change existing conventions. Resist the urge to \u201cimprove\u201d on existing\n", "page": 150, "type": "text", "section": "Page 150"}
{"text": "Don\u2019t change existing conventions. Resist the urge to \u201cimprove\u201d on existing\nconventions. Having a \u201cbetter idea\u201d is not a sufficient excuse to introduce\ninconsistencies. Your new idea may indeed be better, but the value of\nconsistency over inconsistency is almost always greater than the value of one\napproach over another. Before introducing inconsistent behavior, ask yourself\ntwo questions. First, do you have significant new information justifying your\napproach that wasn\u2019t available when the old convention was established? Second,\nis the new approach so much better that it is worth taking the time to update all\nof the old uses? If your organization agrees that the answers to both questions are\n\u201cyes,\u201d then go ahead and make the upgrade; when you are done, there should be\nno sign of the old convention. However, you still run the risk that other\ndevelopers will not know about the new convention, so they may reintroduce the\nold approach in the future. Overall, reconsidering established conventions is\nrarely a good use of developer time.\n17.3  Taking it too far\nConsistency means not only that similar things should be done in similar ways,\nbut that dissimilar things should be done in different ways. If you become\noverzealous about consistency and try to force dissimilar things into the same\napproach, such as by using the same variable name for things that are really\ndifferent or using an existing design pattern for a task that doesn\u2019t fit the pattern,\nyou\u2019ll create complexity and confusion. Consistency only provides benefits when\ndevelopers have confidence that \u201cif it looks like an x, it really is an x.\u201d\n17.4  Conclusion\nConsistency is another example of the investment mindset. It will take a bit of\nextra work to ensure consistency: work to decide on conventions, work to create\nautomated checkers, work to look for similar situations to mimic in new code,\nand work in code reviews to educate the team. The return on this investment is\nthat your code will be more obvious. Developers will be able to understand the\ncode\u2019s behavior more quickly and accurately, and this will allow them to work\nfaster, with fewer bugs.\n", "page": 151, "type": "text", "section": "Page 151"}
{"text": "Chapter 18\nCode Should be Obvious\nObscurity is one of the two main causes of complexity described in Section 2.3.\nObscurity occurs when important information about a system is not obvious to\nnew developers. The solution to the obscurity problem is to write code in a way\nthat makes it obvious; this chapter discusses some of the factors that make code\nmore or less obvious.\nIf code is obvious, it means that someone can read the code quickly, without\nmuch thought, and their first guesses about the behavior or meaning of the code\nwill be correct. If code is obvious, a reader doesn\u2019t need to spend much time or\neffort to gather all the information they need to work with the code. If code is not\nobvious, then a reader must expend a lot of time and energy to understand it. Not\nonly does this reduce their efficiency, but it also increases the likelihood of\nmisunderstanding and bugs. Obvious code needs fewer comments than\nnonobvious code.\n\u201cObvious\u201d is in the mind of the reader: it\u2019s easier to notice that someone\nelse\u2019s code is nonobvious than to see problems with your own code. Thus, the\nbest way to determine the obviousness of code is through code reviews. If\nsomeone reading your code says it\u2019s not obvious, then it\u2019s not obvious, no matter\nhow clear it may seem to you. By trying to understand what made the code\nnonobvious, you will learn how to write better code in the future.\n18.1  Things that make code more obvious\nTwo of the most important techniques for making code obvious have already\nbeen discussed in previous chapters. The first is choosing good names (Chapter\n14). Precise and meaningful names clarify the behavior of the code and reduce\nthe need for documentation. If a name is vague or ambiguous, then readers will\nhave read through the code in order to deduce the meaning of the named entity;\nthis is time-consuming and error-prone. The second technique is consistency\n", "page": 152, "type": "text", "section": "Page 152"}
{"text": "(Chapter 17). If similar things are always done in similar ways, then readers can\nrecognize patterns they have seen before and immediately draw (safe)\nconclusions without analyzing the code in detail.\nHere are a few other general-purpose techniques for making code more\nobvious:\nJudicious use of white space. The way code is formatted can impact how easy it\nis to understand. Consider the following parameter documentation, in which\nwhitespace has been squeezed out:\n/**\n *  ...\n *  @param numThreads The number of threads that this manager should\n *  spin up in order to manage ongoing connections. The MessageManager\n *  spins up at least one thread for every open connection, so this\n *  should be at least equal to the number of connections you expect\n *  to be open at once. This should be a multiple of that number if\n *  you expect to send a lot of messages in a short amount of time.\n *  @param handler Used as a callback in order to handle incoming\n *  messages on this MessageManager's open connections. See\n *  {@code MessageHandler} and {@code handleMessage} for details.\n */\nIt\u2019s hard to see where the documentation for one parameter ends and the next\nbegins. It\u2019s not even obvious how many parameters there are, or what their names\nare. If a little whitespace is added, the structure suddenly becomes clear and the\ndocumentation is easier to scan:\n/**\n *  @param numThreads\n *           The number of threads that this manager should spin up in\n *           order to manage ongoing connections. The MessageManager\nspins\n *           up at least one thread for every open connection, so this\n *           should be at least equal to the number of connections you\n *           expect to be open at once. This should be a multiple of\nthat\n *           number if you expect to send a lot of messages in a short\n *           amount of time.\n", "page": 153, "type": "text", "section": "Page 153"}
{"text": " *  @param handler\n *           Used as a callback in order to handle incoming messages on\n *           this MessageManager's open connections. See\n *           {@code MessageHandler} and {@code handleMessage} for\ndetails.\n */\nBlank lines are also useful to separate major blocks of code within a method,\nsuch as in the following example:\nvoid* Buffer::allocAux(size_t numBytes)\n{\n        //  Round up the length to a multiple of 8 bytes, to ensure\nalignment.\n        uint32_t numBytes32 =  (downCast<uint32_t>(numBytes) + 7) & ~0x7;\n        assert(numBytes32 != 0);\n \n        //  If there is enough memory at firstAvailable, use that. Work\ndown\n        //  from the top, because this memory is guaranteed to be aligned\n        //  (memory at the bottom may have been used for variable-size\nchunks).\n        if  (availableLength >= numBytes32) {\n              availableLength -= numBytes32;\n              return firstAvailable + availableLength;\n        }\n        //  Next, see if there is extra space at the end of the last chunk.\n        if  (extraAppendBytes >= numBytes32) {\n              extraAppendBytes -= numBytes32;\n              return lastChunk->data + lastChunk->length + extraAppendBytes;\n        }\n        //  Must create a new space allocation; allocate space within it.\n        uint32_t allocatedLength;\n        firstAvailable = getNewAllocation(numBytes32, &allocatedLength);\n        availableLength = allocatedLength numBytes32;\n", "page": 154, "type": "text", "section": "Page 154"}
{"text": "        return firstAvailable + availableLength;\n}\nThis approach works particularly well if the first line after each blank line is a\ncomment describing the next block of code: the blank lines make the comments\nmore visible.\nWhite space within a statement helps to clarify the structure of the statement.\nCompare the following two statements, one of which has whitespace and one of\nwhich doesn\u2019t:\nfor(int pass=1;pass>=0&&!empty;pass--) {\nfor (int pass = 1; pass >= 0 && !empty; pass--) {\nComments. Sometimes it isn\u2019t possible to avoid code that is nonobvious. When\nthis happens, it\u2019s important to use comments to compensate by providing the\nmissing information. To do this well, you must put yourself in the position of the\nreader and figure out what is likely to confuse them, and what information will\nclear up that confusion. The next section shows a few examples.\n18.2 Things that make code less obvious\nThere are many things that can make code nonobvious; this section provides a\nfew examples. Some of these, such as event-driven programming, are useful in\nsome situations, so you may end up using them anyway. When this happens,\nextra documentation can help to minimize reader confusion.\nEvent-driven programming. In event-driven programming, an application\nresponds to external occurrences, such as the arrival of a network packet or the\npress of a mouse button. One module is responsible for reporting incoming\nevents. Other parts of the application register interest in certain events by asking\nthe event module to invoke a given function or method when those events occur.\nEvent-driven programming makes it hard to follow the flow of control. The\nevent handler functions are never invoked directly; they are invoked indirectly by\nthe event module, typically using a function pointer or interface. Even if you find\nthe point of invocation in the event module, it still isn\u2019t possible to tell which\nspecific function will be invoked: this will depend on which handlers were\nregistered at runtime. Because of this, it\u2019s hard to reason about event-driven code\nor convince yourself that it works.\nTo compensate for this obscurity, use the interface comment for each handler\n", "page": 155, "type": "text", "section": "Page 155"}
{"text": "To compensate for this obscurity, use the interface comment for each handler\nfunction to indicate when it is invoked, as in this example:\n/**\n * This method is invoked in the dispatch thread by a transport if a\n * transport-level error prevents an RPC from completing.\n */\nvoid\nTransport::RpcNotifier::failed() {\n        ...\n}\n Red Flag: Nonobvious Code \nIf the meaning and behavior of code cannot be understood with a quick\nreading, it is a red flag. Often this means that there is important information\nthat is not immediately clear to someone reading the code.\nGeneric containers. Many languages provide generic classes for grouping two\nor more items into a single object, such as Pair in Java or std::pair in C++.\nThese classes are tempting because they make it easy to pass around several\nobjects with a single variable. One of the most common uses is to return multiple\nvalues from a method, as in this Java example:\nreturn new Pair<Integer, Boolean>(currentTerm, false);\nUnfortunately, generic containers result in nonobvious code because the grouped\nelements have generic names that obscure their meaning. In the example above,\nthe caller must reference the two returned values with result.getKey() and\nresult.getValue(), which give no clue about the actual meaning of the values.\nThus, it\u2019s better not to use generic containers. If you need a container, define\na new class or structure that is specialized for the particular use. You can then\nuse meaningful names for the elements, and you can provide additional\ndocumentation in the declaration, which is not possible with the generic\ncontainer.\nThis example illustrates a general rule: software should be designed for\nease of reading, not ease of writing. Generic containers are expedient for the\n", "page": 156, "type": "text", "section": "Page 156"}
{"text": "person writing the code, but they create confusion for all the readers that follow.\nIt\u2019s better for the person writing the code to spend a few extra minutes to define a\nspecific container structure, so that the resulting code is more obvious.\nDifferent types for declaration and allocation. Consider the following Java\nexample:\nprivate List<Message> incomingMessageList;\n...\nincomingMessageList = new ArrayList<Message>();\nThe variable is declared as a List, but the actual value is an ArrayList. This code\nis legal, since List is a superclass of ArrayList, but it can mislead a reader who\nsees the declaration but not the actual allocation. The actual type may impact\nhow the variable is used (ArrayLists have different performance and thread-\nsafety properties than other subclasses of List), so it is better to match the\ndeclaration with the allocation.\nCode that violates reader expectations. Consider the following code, which is\nthe main program for a Java application\npublic static void main(String[] args) {\n        ...\n        new RaftClient(myAddress, serverAddresses);\n}\nMost applications exit when their main programs return, so readers are likely to\nassume that will happen here. However, that is not the case. The constructor for\nRaftClient creates additional threads, which continue to operate even though the\napplication\u2019s main thread finishes. This behavior should be documented in the\ninterface comment for the RaftClient constructor, but the behavior is\nnonobvious enough that it\u2019s worth putting a short comment at the end of main as\nwell. The comment should indicate that the application will continue executing\nin other threads. Code is most obvious if it conforms to the conventions that\nreaders will be expecting; if it doesn\u2019t, then it\u2019s important to document the\nbehavior so readers aren\u2019t confused.\n18.3  Conclusion\nAnother way of thinking about obviousness is in terms of information. If code is\nnonobvious, that usually means there is important information about the code\n", "page": 157, "type": "text", "section": "Page 157"}
{"text": "that the reader does not have: in the RaftClient example, the reader might not\nknow that the RaftClient constructor created new threads; in the Pair example,\nthe reader might not know that result.getKey() returns the number of the\ncurrent term.\nTo make code obvious, you must ensure that readers always have the\ninformation they need to understand it. You can do this in three ways. The best\nway is to reduce the amount of information that is needed, using design\ntechniques such as abstraction and eliminating special cases. Second, you can\ntake advantage of information that readers have already acquired in other\ncontexts (for example, by following conventions and conforming to expectations)\nso readers don\u2019t have to learn new information for your code. Third, you can\npresent the important information to them in the code, using techniques such as\ngood names and strategic comments.\n", "page": 158, "type": "text", "section": "Page 158"}
{"text": "Chapter 19\nSoftware Trends\nAs a way of illustrating the principles discussed in this book, this chapter\nconsiders several trends and patterns that have become popular in software\ndevelopment over the last few decades. For each trend, I will describe how that\ntrend relates to the principles in this book and use the principles to evaluate\nwhether that trend provides leverage against software complexity.\n19.1  Object-oriented programming and inheritance\nObject-oriented programming is one of the most important new ideas in software\ndevelopment over the last 30\u201340 years. It introduced notions such as classes,\ninheritance, private methods, and instance variables. If used carefully, these\nmechanisms can help to produce better software designs. For example, private\nmethods and variables can be used to ensure information hiding: no code outside\na class can invoke private methods or access private variables, so there can\u2019t be\nany external dependencies on them.\nOne of the key elements of object-oriented programming is inheritance.\nInheritance comes in two forms, which have different implications for software\ncomplexity. The first form of inheritance is interface inheritance, in which a\nparent class defines the signatures for one or more methods, but does not\nimplement the methods. Each subclass must implement the signatures, but\ndifferent subclasses can implement the same methods in different ways. For\nexample, the interface might define methods for performing I/O; one subclass\nmight implement the I/O operations for disk files, and another subclass might\nimplement the same operations for network sockets.\nInterface inheritance provides leverage against complexity by reusing the\nsame interface for multiple purposes. It allows knowledge acquired in solving\none problem (such as how to use an I/O interface to read and write disk files) to\nbe used to solve other problems (such as communicating over a network socket).\n", "page": 159, "type": "text", "section": "Page 159"}
{"text": "Another way of thinking about this is in terms of depth: the more different\nimplementations there are of an interface, the deeper the interface becomes. In\norder for an interface to have many implementations, it must capture the essential\nfeatures of all the underlying implementations while steering clear of the details\nthat differ between the implementations; this notion is at the heart of abstraction.\nThe second form of inheritance is implementation inheritance. In this form, a\nparent class defines not only signatures for one or more methods, but also default\nimplementations. Subclasses can choose to inherit the parent\u2019s implementation\nof a method or override it by defining a new method with the same signature.\nWithout implementation inheritance, the same method implementation might\nneed to be duplicated in several subclasses, which would create dependencies\nbetween those subclasses (modifications would need to be duplicated in all\ncopies of the method). Thus, implementation inheritance reduces the amount of\ncode that needs to be modified as the system evolves; in other words, it reduces\nthe change amplification problem described in Chapter 2.\nHowever, implementation inheritance creates dependencies between the\nparent class and each of its subclasses. Class instance variables in the parent\nclass are often accessed by both the parent and child classes; this results in\ninformation leakage between the classes in the inheritance hierarchy and makes it\nhard to modify one class in the hierarchy without looking at the others. For\nexample, a developer making changes to the parent class may need to examine all\nof the subclasses to ensure that the changes don\u2019t break anything. Similarly, if a\nsubclass overrides a method in the parent class, the developer of the subclass\nmay need to examine the implementation in the parent. In the worst case,\nprogrammers will need complete knowledge of the entire class hierarchy\nunderneath the parent class in order to make changes to any of the classes. Class\nhierarchies that use implementation inheritance extensively tend to have high\ncomplexity.\nThus, implementation inheritance should be used with caution. Before using\nimplementation inheritance, consider whether an approach based on composition\ncan provide the same benefits. For instance, it may be possible to use small\nhelper classes to implement the shared functionality. Rather than inheriting\nfunctions from a parent, the original classes can each build upon the features of\nthe helper classes.\nIf there is no viable alternative to implementation inheritance, try to separate\nthe state managed by the parent class from that managed by subclasses. One way\n", "page": 160, "type": "text", "section": "Page 160"}
{"text": "to do this is for certain instance variables to be managed entirely by methods in\nthe parent class, with subclasses using them only in a read-only fashion or\nthrough other methods in the parent class. This applies the notion of information\nhiding within the class hierarchy to reduce dependencies.\nAlthough the mechanisms provided by object-oriented programming can\nassist in implementing clean designs, they do not, by themselves, guarantee good\ndesign. For example, if classes are shallow, or have complex interfaces, or permit\nexternal access to their internal state, then they will still result in high\ncomplexity.\n19.2  Agile development\nAgile development is an approach to software development that emerged in the\nlate 1990\u2019s from a collection of ideas about how to make software development\nmore lightweight, flexible, and incremental; it was formally defined during a\nmeeting of practitioners in 2001. Agile development is mostly about the process\nof software development (organizing teams, managing schedules, the role of unit\ntesting, interacting with customers, etc.) as opposed to software design.\nNonetheless, it relates to some of the design principles in this book.\nOne of the most important elements of agile development is the notion that\ndevelopment should be incremental and iterative. In the agile approach, a\nsoftware system is developed in a series of iterations, each of which adds and\nevaluates a few new features; each iteration includes design, test, and customer\ninput. In general, this is similar to the incremental approach advocated here. As\nmentioned in Chapter 1, it isn\u2019t possible to visualize a complex system well\nenough at the outset of a project to determine the best design. The best way to\nend up with a good design is to develop a system in increments, where each\nincrement adds a few new abstractions and refactors existing abstractions based\non experience. This is similar to the agile development approach.\nOne of the risks of agile development is that it can lead to tactical\nprogramming. Agile development tends to focus developers on features, not\nabstractions, and it encourages developers to put off design decisions in order to\nproduce working software as soon as possible. For example, some agile\npractitioners argue that you shouldn\u2019t implement general-purpose mechanisms\nright away; implement a minimal special-purpose mechanism to start with, and\nrefactor into something more generic later, once you know that it\u2019s needed.\nAlthough these arguments make sense to a degree, they argue against an\n", "page": 161, "type": "text", "section": "Page 161"}
{"text": "investment approach, and they encourage a more tactical style of programming.\nThis can result in a rapid accumulation of complexity.\nDeveloping incrementally is generally a good idea, but the increments of\ndevelopment should be abstractions, not features. It\u2019s fine to put off all\nthoughts about a particular abstraction until it\u2019s needed by a feature. Once you\nneed the abstraction, invest the time to design it cleanly; follow the advice of\nChapter 6 and make it somewhat general-purpose.\n19.3  Unit tests\nIt used to be that developers rarely wrote tests. If tests were written at all, they\nwere written by a separate QA team. However, one of the tenets of agile\ndevelopment is that testing should be tightly integrated with development, and\nprogrammers should write tests for their own code. This practice has now\nbecome widespread. Tests are typically divided into two kinds: unit tests and\nsystem tests. Unit tests are the ones most often written by developers. They are\nsmall and focused: each test usually validates a small section of code in a single\nmethod. Unit tests can be run in isolation, without setting up a production\nenvironment for the system. Unit tests are often run in conjunction with a test\ncoverage tool to ensure that every line of code in the application is tested.\nWhenever developers write new code or modify existing code, they are\nresponsible for updating the unit tests to maintain proper test coverage.\nThe second kind of test consists of system tests (sometimes called integration\ntests), which ensure that the different parts of an application all work together\nproperly. They typically involve running the entire application in a production\nenvironment. System tests are more likely to be written by a separate QA or\ntesting team.\nTests, particularly unit tests, play an important role in software design\nbecause they facilitate refactoring. Without a test suite, it\u2019s dangerous to make\nmajor structural changes to a system. There\u2019s no easy way to find bugs, so it\u2019s\nlikely that bugs will go undetected until the new code is deployed, where they are\nmuch more expensive to find and fix. As a result, developers avoid refactoring in\nsystems without good test suites; they try to minimize the number of code\nchanges for each new feature or bug fix, which means that complexity\naccumulates and design mistakes don\u2019t get corrected.\nWith a good set of tests, developers can be more confident when refactoring\nbecause the test suite will find most bugs that are introduced. This encourages\n", "page": 162, "type": "text", "section": "Page 162"}
{"text": "developers to make structural improvements to a system, which results in a better\ndesign. Unit tests are particularly valuable: they provide a higher degree of code\ncoverage than system tests, so they are more likely to uncover any bugs.\nFor example, during the development of the Tcl scripting language, we\ndecided to improve performance by replacing Tcl\u2019s interpreter with a byte-code\ncompiler. This was a huge change that affected almost every part of the core Tcl\nengine. Fortunately, Tcl had an excellent unit test suite, which we ran on the new\nbyte-code engine. The existing tests were so effective in uncovering bugs in the\nnew engine that only a single bug turned up after the alpha release of the byte-\ncode compiler.\n19.4  Test-driven development\nTest-driven development is an approach to software development where\nprogrammers write unit tests before they write code. When creating a new class,\nthe developer first writes unit tests for the class, based on its expected behavior.\nNone of the tests pass, since there is no code for the class. Then the developer\nworks through the tests one at a time, writing enough code for that test to pass.\nWhen all of the tests pass, the class is finished.\nAlthough I am a strong advocate of unit testing, I am not a fan of test-driven\ndevelopment. The problem with test-driven development is that it focuses\nattention on getting specific features working, rather than finding the best\ndesign. This is tactical programming pure and simple, with all of its\ndisadvantages. Test-driven development is too incremental: at any point in time,\nit\u2019s tempting to just hack in the next feature to make the next test pass. There\u2019s no\nobvious time to do design, so it\u2019s easy to end up with a mess.\nAs mentioned in Section 19.2, the units of development should be\nabstractions, not features. Once you discover the need for an abstraction, don\u2019t\ncreate the abstraction in pieces over time; design it all at once (or at least enough\nto provide a reasonably comprehensive set of core functions). This is more likely\nto produce a clean design whose pieces fit together well.\nOne place where it makes sense to write the tests first is when fixing bugs.\nBefore fixing a bug, write a unit test that fails because of the bug. Then fix the\nbug and make sure that the unit test now passes. This is the best way to make\nsure you really have fixed the bug. If you fix the bug before writing the test, it\u2019s\npossible that the new unit test doesn\u2019t actually trigger the bug, in which case it\nwon\u2019t tell you whether you really fixed the problem.\n", "page": 163, "type": "text", "section": "Page 163"}
{"text": "19.5 Design patterns\nA design pattern is a commonly used approach for solving a particular kind of\nproblem, such as an iterator or an observer. The notion of design patterns was\npopularized by the book Design Patterns: Elements of Reusable Object-Oriented\nSoftware by Gamma, Helm, Johnson, and Vlissides, and design patterns are now\nwidely used in object-oriented software development.\nDesign patterns represent an alternative to design: rather than designing a\nnew mechanism from scratch, just apply a well-known design pattern. For the\nmost part, this is good: design patterns arose because they solve common\nproblems, and because they are generally agreed to provide clean solutions. If a\ndesign pattern works well in a particular situation, it will probably be hard for\nyou to come up with a different approach that is better.\nThe greatest risk with design patterns is over-application. Not every problem\ncan be solved cleanly with an existing design pattern; don\u2019t try to force a problem\ninto a design pattern when a custom approach will be cleaner. Using design\npatterns doesn\u2019t automatically improve a software system; it only does so if the\ndesign patterns fit. As with many ideas in software design, the notion that design\npatterns are good doesn\u2019t necessarily mean that more design patterns are better.\n19.6  Getters and setters\nIn the Java programming community, getter and setter methods are a popular\ndesign pattern. A getter and a setter are associated with an instance variable for a\nclass. They have names like getFoo and setFoo, where Foo is the name of the\nvariable. The getter method returns the current value of the variable, and the\nsetter method modifies the value.\nGetters and setters aren\u2019t strictly necessary, since instance variables can be\nmade public. The argument for getters and setters is that they allow additional\nfunctions to be performed while getting and setting, such as updating related\nvalues when a variable changes, notifying listeners of changes, or enforcing\nconstraints on values. Even if these features aren\u2019t needed initially, they can be\nadded later without changing the interface.\nAlthough it may make sense to use getters and setters if you must expose\ninstance variables, it\u2019s better not to expose instance variables in the first place.\nExposed instance variables mean that part of the class\u2019s implementation is\nvisible externally, which violates the idea of information hiding and increases the\n", "page": 164, "type": "text", "section": "Page 164"}
{"text": "complexity of the class\u2019s interface. Getters and setters are shallow methods\n(typically only a single line), so they add clutter to the class\u2019s interface without\nproviding much functionality. It\u2019s better to avoid getters and setters (or any\nexposure of implementation data) as much as possible.\nOne of the risks of establishing a design pattern is that developers assume the\npattern is good and try to use it as much as possible. This has led to overusage of\ngetters and setters in Java.\n19.7  Conclusion\nWhenever you encounter a proposal for a new software development paradigm,\nchallenge it from the standpoint of complexity: does the proposal really help to\nminimize complexity in large software systems? Many proposals sound good on\nthe surface, but if you look more deeply you will see that some of them make\ncomplexity worse, not better.\n", "page": 165, "type": "text", "section": "Page 165"}
{"text": "Chapter 20\nDesigning for Performance\nUp until this point, the discussion of software design has focused on complexity;\nthe goal has been to make software as simple and understandable as possible.\nBut what if you are working on a system that needs to be fast? How should\nperformance considerations affect the design process? This chapter discusses\nhow to achieve high performance without sacrificing clean design. The most\nimportant idea is still simplicity: not only does simplicity improve a system\u2019s\ndesign, but it usually makes systems faster.\n20.1  How to think about performance\nThe first question to address is \u201chow much should you worry about performance\nduring the normal development process?\u201d If you try to optimize every statement\nfor maximum speed, it will slow down development and create a lot of\nunnecessary complexity. Furthermore, many of the \u201coptimizations\u201d won\u2019t\nactually help performance. On the other hand, if you completely ignore\nperformance issues, it\u2019s easy to end up with a large number of significant\ninefficiencies spread throughout the code; the resulting system can easily be 5\u2013\n10x slower than it needs to be. In this \u201cdeath by a thousand cuts\u201d scenario it\u2019s\nhard to come back later and improve the performance, because there is no single\nimprovement that will have much impact.\nThe best approach is something between these extremes, where you use basic\nknowledge of performance to choose design alternatives that are \u201cnaturally\nefficient\u201d yet also clean and simple. The key is to develop an awareness of which\noperations are fundamentally expensive. Here are a few examples of operations\nthat are relatively expensive today:\nNetwork communication: even within a datacenter, a round-trip message\nexchange can take 10\u201350 \u00b5s, which is tens of thousands of instruction times.\nWide-area round-trips can take 10\u2013100 ms.\nI/O to secondary storage: disk I/O operations typically take 5\u201310 ms, which\n", "page": 166, "type": "text", "section": "Page 166"}
{"text": "is millions of instruction times. Flash storage takes 10\u2013100 \u00b5s. New\nemerging nonvolatile memories may be as fast as 1 \u00b5s, but this is still\naround 2000 instruction times.\nDynamic memory allocation (malloc in C, new in C++ or Java) typically\ninvolves significant overhead for allocation, freeing, and garbage collection.\nCache misses: fetching data from DRAM into an on-chip processor cache\ntakes a few hundred instruction times; in many programs, overall\nperformance is determined as much by cache misses as by computational\ncosts.\nThe best way to learn which things are expensive is to run micro-benchmarks\n(small programs that measure the cost of a single operation in isolation). In the\nRAMCloud project, we created a simple program that provides a framework for\nmicrobenchmarks. It took a few days to create the framework, but the framework\nmakes it possible to add new micro-benchmarks in five or ten minutes. This has\nallowed us to accumulate dozens of micro-benchmarks. We use these both to\nunderstand the performance of existing libraries used in RAMCloud, and also to\nmeasure the performance of new classes written for RAMCloud.\nOnce you have a general sense for what is expensive and what is cheap, you\ncan use that information to choose cheap operations whenever possible. In many\ncases, a more efficient approach will be just as simple as a slower approach. For\nexample, when storing a large collection of objects that will be looked up using a\nkey value, you could use either a hash table or an ordered map. Both are\ncommonly available in library packages, and both are simple and clean to use.\nHowever, hash tables can easily be 5\u201310x faster. Thus, you should always use a\nhash table unless you need the ordering properties provided by the map.\nAs another example, consider allocating an array of structures in a language\nsuch as C or C++. There are two ways you can do this. One way is for the array\nto hold pointers to structures, in which case you must first allocate space for the\narray, then allocate space for each individual structure. It is much more efficient\nto store the structures in the array itself, so you only allocate one large block for\neverything.\nIf the only way to improve efficiency is by adding complexity, then the\nchoice is more difficult. If the more efficient design adds only a small amount of\ncomplexity, and if the complexity is hidden, so it doesn\u2019t affect any interfaces,\nthen it may be worthwhile (but beware: complexity is incremental). If the faster\ndesign adds a lot of implementation complexity, or if it results in more\n", "page": 167, "type": "text", "section": "Page 167"}
{"text": "complicated interfaces, then it may be better to start off with the simpler\napproach and optimize later if performance turns out to be a problem. However,\nif you have clear evidence that performance will be important in a particular\nsituation, then you might as well implement the faster approach immediately.\nIn the RAMCloud project one of our overall goals was to provide the lowest\npossible latency for client machines accessing the storage system over a\ndatacenter network. As a result, we decided to use special hardware for\nnetworking, which allowed RAMCloud to bypass the kernel and communicate\ndirectly with the network interface controller to send and receive packets. We\nmade this decision even though it added complexity, because we knew from prior\nmeasurements that kernel-based networking would be too slow to meet our\nneeds. In most of the rest of the RAMCloud system we were able to design for\nsimplicity; getting this one big issue \u201cright\u201d made many other things easier.\nIn general, simpler code tends to run faster than complex code. If you have\ndefined away special cases and exceptions, then no code is needed to check for\nthose cases and the system runs faster. Deep classes are more efficient than\nshallow ones, because they get more work done for each method call. Shallow\nclasses result in more layer crossings, and each layer crossing adds overhead.\n20.2  Measure before modifying\nBut suppose that your system is still too slow, even though you have designed it\nas described above. It\u2019s tempting to rush off and start making performance\ntweaks, based on your intuitions about what is slow. Don\u2019t do this! Programmers\u2019\nintuitions about performance are unreliable. This is true even for experienced\ndevelopers. If you start making changes based on intuition, you\u2019ll waste time on\nthings that don\u2019t actually improve performance, and you\u2019ll probably make the\nsystem more complicated in the process.\nBefore making any changes, measure the system\u2019s existing behavior. This\nserves two purposes. First, the measurements will identify the places where\nperformance tuning will have the biggest impact. It isn\u2019t sufficient just to\nmeasure the top-level system performance. This may tell you that the system is\ntoo slow, but it won\u2019t tell you why. You\u2019ll need to measure deeper to identify in\ndetail the factors that contribute to overall performance; the goal is to identify a\nsmall number of very specific places where the system is currently spending a lot\nof time, and where you have ideas for improvement. The second purpose of the\nmeasurements is to provide a baseline, so that you can re-measure performance\n", "page": 168, "type": "text", "section": "Page 168"}
{"text": "after making your changes to ensure that performance actually improved. If the\nchanges didn\u2019t make a measurable difference in performance, then back them out\n(unless they made the system simpler). There\u2019s no point in retaining complexity\nunless it provides a significant speedup.\n20.3  Design around the critical path\nAt this point, let\u2019s assume that you have carefully analyzed performance and have\nidentified a piece of code that is slow enough to affect the overall system\nperformance. The best way to improve its performance is with a \u201cfundamental\u201d\nchange, such as introducing a cache, or using a different algorithmic approach\n(balanced tree vs. list, for instance). Our decision to bypass the kernel for\nnetwork communication in RAMCloud is an example of a fundamental fix. If\nyou can identify a fundamental fix, then you can implement it using the design\ntechniques discussed in previous chapters.\nUnfortunately, situations will sometimes arise where there isn\u2019t a\nfundamental fix. This brings us to the core issue for this chapter, which is how to\nredesign an existing piece of code so that it runs faster. This should be your last\nresort, and it shouldn\u2019t happen often, but there are cases where it can make a big\ndifference. The key idea is to design the code around the critical path.\nStart off by asking yourself what is the smallest amount of code that must be\nexecuted to carry out the desired task in the common case. Disregard any existing\ncode structure. Imagine instead that you are writing a new method that\nimplements just the critical path, which is the minimum amount of code that\nmust be executed in the the most common case. The current code is probably\ncluttered with special cases; ignore them in this exercise. The current code might\npass through several method calls on the critical path; imagine instead that you\ncould put all the relevant code in a single method. The current code may also use\na variety of variables and data structures; consider only the data needed for the\ncritical path, and assume whatever data structure is most convenient for the\ncritical path. For example, it may make sense to combine multiple variables into\na single value. Assume that you could completely redesign the system in order to\nminimize the code that must be executed for the critical path. Let\u2019s call this code\n\u201cthe ideal.\u201d\nThe ideal code probably clashes with your existing class structure, and it may\nnot be practical, but it provides a good target: this represents the simplest and\nfastest that the code can ever be. The next step is to look for a new design that\n", "page": 169, "type": "text", "section": "Page 169"}
{"text": "comes as close as possible to the ideal while still having a clean structure. You\ncan apply all of the design ideas from previous chapters of this book, but with\nthe additional constraint of keeping the ideal code (mostly) intact. You may have\nto add a bit of extra code to the ideal in order to allow clean abstractions; for\nexample, if the code involves a hash table lookup, it\u2019s OK to introduce an extra\nmethod call to a general-purpose hash table class. In my experience it\u2019s almost\nalways possible to find a design that is clean and simple, yet comes very close to\nthe ideal.\nOne of the most important things that happens in this process is to remove\nspecial cases from the critical path. When code is slow, it\u2019s often because it must\nhandle a variety of situations, and the code gets structured to simplify the\nhandling of all the different cases. Each special case adds a little bit of code to\nthe critical path, in the form of extra conditional statements and/or method calls.\nEach of these additions makes the code a bit slower. When redesigning for\nperformance, try to minimize the number of special cases you must check.\nIdeally, there will be a single if statement at the beginning, which detects all\nspecial cases with one test. In the normal case, only this one test will need to be\nmade, after which the the critical path can be executed with no additional tests\nfor special cases. If the initial test fails (which means a special case has occurred)\nthe code can branch to a separate place off the critical path to handle it.\nPerformance isn\u2019t as important for special cases, so you can structure the special-\ncase code for simplicity rather than performance.\n20.4  An example: RAMCloud Buffers\nLet\u2019s consider an example, in which the Buffer class of the RAMCloud storage\nsystem was optimized to achieve a speedup of about 2x for the most common\noperations.\nRAMCloud uses Buffer objects to manage variable-length arrays of memory,\nsuch as request and response messages for remote procedure calls. Buffers are\ndesigned to reduce overheads from memory copying and dynamic storage\nallocation. A Buffer stores what appears to be a linear array of bytes, but for\nefficiency it allows the underlying storage to be divided into multiple\ndiscontiguous chunks of memory, as shown in Figure 20.1. A Buffer is created\nby appending chunks of data. Each chunk is either external or internal. If a\nchunk is external, its storage is owned by the caller; the Buffer keeps a reference\nto this storage. External chunks are typically used for large chunks in order to\n", "page": 170, "type": "text", "section": "Page 170"}
{"text": "avoid memory copies. If a chunk is internal, the Buffer owns the storage for the\nchunk; data supplied by the caller is copied into the Buffer\u2019s internal storage.\nEach Buffer contains a small built-in allocation, which is a block of memory\navailable for storing internal chunks. If this space is exhausted, then the Buffer\ncreates additional allocations, which must be freed when the Buffer is destroyed.\nInternal chunks are convenient for small chunks where the memory copying\ncosts are negligible. Figure 20.1 shows a Buffer with 5 chunks: the first chunk is\ninternal, the next two are external, and the final two chunks are internal.\nFigure 20.1: A Buffer object uses a collection of memory chunks to store what appears to be a linear array\nof bytes. Internal chunks are owned by the Buffer and freed when the Buffer is destroyed; external chunks\nare not owned by the Buffer.\nThe Buffer class itself represents a \u201cfundamental fix,\u201d in that it eliminates\nexpensive memory copies that would have been required without it. For example,\nwhen assembling a response message containing a short header and the contents\nof a large object in the RAMCloud storage system, RAMCloud uses a Buffer\nwith two chunks. The first chunk is an internal one that contains the header; the\nsecond chunk is an external one that refers to the object contents in the\nRAMCloud storage system. The response can be collected in the Buffer without\ncopying the large object.\nAside from the fundamental approach of allowing discontiguous chunks, we\ndid not attempt to optimize the code of the Buffer class in the original\nimplementation. Over time, however, we noticed Buffers being used in more and\nmore situations; for example, at least four Buffers are created during the\nexecution of each remote procedure call. Eventually, it became clear that\nspeeding up the implementation of Buffer could have a noticeable impact on\noverall system performance. We decided to see if we could improve the\nperformance of the Buffer class.\nThe most common operation for Buffer is to allocate space for a small\namount of new data using an internal chunk. This happens, for example, when\n", "page": 171, "type": "text", "section": "Page 171"}
{"text": "creating headers for request and response messages. We decided to use this\noperation as the critical path for optimization. In the simplest possible case, the\nspace can be allocated by enlarging the last existing chunk in the Buffer.\nHowever, this is only possible if the last existing chunk is internal, and if there is\nenough space in its allocation to accommodate the new data. The ideal code\nwould perform a single check to confirm that the simple approach is possible,\nthen it would adjust the size of the existing chunk.\nFigure 20.2 shows the original code for the critical path, which starts with the\nmethod Buffer::alloc. In the fastest possible case, Buffer::alloc calls Buffer::\nallocateAppend, which calls Buffer::Allocation::allocateAppend. From a\nperformance standpoint, this code has two problems. The first problem is that\nnumerous special cases are checked individually:\nBuffer::allocateAppend checks to see if the Buffer currently has any\nallocations.\nThe code checks twice to see if the current allocation has enough room for\nthe new data: once in Buffer::Allocation::allocateAppend, and again\nwhen its return value is tested by Buffer::allocateAppend.\nBuffer::alloc tests the return value from Buffer::allocAppend to confirm\nyet again that the allocation succeeded.\nFurthermore, rather than trying to expand the last chunk directly, the code\nallocates new space without any consideration of the last chunk. Then\nBuffer::alloc checks to see if that space happens to be adjacent to the last\nchunk, in which case it merges the new space with the existing chunk. This\nresults in additional checks. Overall, this code tests 6 distinct conditions in the\ncritical path.\nThe second problem with the original code is that it has too many layers, all\nof which are shallow. This is both a performance problem and a design problem.\nThe critical path makes two additional method calls in addition to the original\ninvocation of Buffer::alloc. Each method call takes additional time, and the\nresult of each call must be checked by its caller, which results in more special\ncases to consider. Chapter 7 discussed how abstractions should normally change\nas you pass from one layer to another, but all three of the methods in Figure 20.2\nhave identical signatures and they provide essentially the same abstraction; this is\na red flag. Buffer::allocateAppend is nearly a pass-though method; its only\ncontribution is to create a new allocation if needed. The extra layers make the\ncode both slower and more complicated.\n", "page": 172, "type": "text", "section": "Page 172"}
{"text": "To fix these problems, we refactored the Buffer class so that its design is\ncentered around the most performance-critical paths. We considered not just the\nallocation code above but several other commonly executed paths, such as\nretrieving the total number of bytes of data currently stored in a Buffer. For each\nof these critical paths, we tried to identify the smallest amount of code that must\nbe executed in the common case. Then we designed the rest of the class around\nthese critical paths. We also applied the design principles from this book to\nsimplify the class in general. For example, we eliminated shallow layers and\ncreated deeper internal abstractions. The refactored class is 20% smaller than the\noriginal version (1476 lines of code, versus 1886 lines in the original).\n", "page": 173, "type": "text", "section": "Page 173"}
{"text": "Figure 20.2: The original code for allocating new space at the end of a Buffer, using an internal chunk.\nFigure 20.3: The new code for allocating new space in an internal chunk of a Buffer.\nFigure 20.3 shows the new critical path for allocating internal space in a\nBuffer. The new code is not only faster, but it is also easier to read, since it avoids\nshallow abstractions. The entire path is handled in a single method, and it uses a\nsingle test to rule out all of the special cases. The new code introduces a new\ninstance variable, extraAppendBytes, in order to simplify the critical path. This\nvariable keeps track of how much unused space is available immediately after the\nlast chunk in the Buffer. If there is no space available, or if the last chunk in the\nBuffer isn\u2019t an internal chunk, or if the Buffer contains no chunks at all, then\nextraAppendBytes is zero. The code in Figure 20.3 represents the least possible\namount of code to handle this common case.\nNote: the update to totalLength could have been eliminated by recomputing\nthe total Buffer length from the individual chunks whenever it is needed.\nHowever, this approach would be expensive for a large Buffer with many chunks,\nand fetching the total Buffer length is another common operation. Thus, we\nchose to add a small amount of extra overhead to alloc in order to ensure that the\nBuffer length is always immediately available.\nThe new code is about twice as fast as the old code: the total time to append a\n1-byte string to a Buffer using internal storage dropped from 8.8 ns to 4.75 ns.\nMany other Buffer operations also speeded up because of the revisions. For\nexample, the time to construct a new Buffer, append a small chunk in internal\nstorage, and destroy the Buffer dropped from 24 ns to 12 ns.\n", "page": 174, "type": "text", "section": "Page 174"}
{"text": "20.5  Conclusion\nThe most important overall lesson from this chapter is that clean design and high\nperformance are compatible. The Buffer class rewrite improved its performance\nby a factor of 2 while simplifying its design and reducing code size by 20%.\nComplicated code tends to be slow because it does extraneous or redundant\nwork. On the other hand, if you write clean, simple code, your system will\nprobably be fast enough that you don\u2019t have to worry much about performance in\nthe first place. In the few cases where you do need to optimize performance, the\nkey is simplicity again: find the critical paths that are most important for\nperformance and make them as simple as possible.\n", "page": 175, "type": "text", "section": "Page 175"}
{"text": "Chapter 21\nConclusion\nThis book is about one thing: complexity. Dealing with complexity is the most\nimportant challenge in software design. It is what makes systems hard to build\nand maintain, and it often makes them slow as well. Over the course of the book\nI have tried to describe the root causes that lead to complexity, such as\ndependencies and obscurity. I have discussed red flags that can help you identify\nunnecessary complexity, such as information leakage, unneeded error conditions,\nor names that are too generic. I have presented some general ideas you can use to\ncreate simpler software systems, such as striving for classes that are deep and\ngeneric, defining errors out of existence, and separating interface documentation\nfrom implementation documentation. And, finally, I have discussed the\ninvestment mindset needed to produce simple designs.\nThe downside of all these suggestions is that they create extra work in the\nearly stages of a project. Furthermore, if you aren\u2019t used to thinking about design\nissues, then you will slow down even more while you learn good design\ntechniques. If the only thing that matters to you is making your current code\nwork as soon as possible, then thinking about design will seem like drudge work\nthat is getting in the way of your real goal.\nOn the other hand, if good design is an important goal for you, then the ideas\nin this book should make programming more fun. Design is a fascinating puzzle:\nhow can a particular problem be solved with the simplest possible structure? It\u2019s\nfun to explore different approaches, and it\u2019s a great feeling to discover a solution\nthat is both simple and powerful. A clean, simple, and obvious design is a\nbeautiful thing.\nFurthermore, the investments you make in good design will pay off quickly.\nThe modules you defined carefully at the beginning of a project will save you\ntime later as you reuse them over and over. The clear documentation that you\nwrote six months ago will save you time when you return to the code to add a\nnew feature. The time you spent honing your design skills will also pay for itself:\n", "page": 176, "type": "text", "section": "Page 176"}
{"text": "as your skills and experience grow, you will find that you can produce good\ndesigns more and more quickly. Good design doesn\u2019t really take much longer\nthan quick-and-dirty design, once you know how.\nThe reward for being a good designer is that you get to spend a larger fraction\nof your time in the design phase, which is fun. Poor designers spend most of\ntheir time chasing bugs in complicated and brittle code. If you improve your\ndesign skills, not only will you produce higher quality software more quickly, but\nthe software development process will be more enjoyable.\n", "page": 177, "type": "text", "section": "Page 177"}
{"text": "Index\nabstraction, 21\naggregating exceptions, 82\nagile development, 2, 153\nchange amplification, 7, 99\nclass interface comment, 110\nclassitis, 26\ncoding style, 141\ncognitive load, 7, 43, 99\ncomments\nas design tool, 131\nbenefits, 98\ncanary in the coal mine, 131\nconventions for, 102\nduplication, 138\nfor intuition, 107\nfor precision, 105\nimplementation, 116\ninterface, 110\nnear code, 137\nobsolete, 98\nprocrastination, 129\nrepeating code, 103\nrole in abstraction, 101\nworthless, 98\nwriting before code, 129\ncomplexity\n", "page": 178, "type": "text", "section": "Page 178"}
{"text": "causes of, 9\ndefinition, 5\nincremental nature of, 11, 161\npulling downwards, 55, 82\nsymptoms, 7\ncomposition, 152\nconfiguration parameters, 56\nconjoined methods, 71\nconsistency, 141, 146\ncontext object, 51\ncross-module design decisions, 117\ndecorator, 49\ndeep module, 22\ndefaults, 36\ndependency, 9\ndesign it twice, 91\ndesign patterns, 142, 156\ndesignNotes file, 118, 139\ndisk I/O, 160\ndispatcher, 47\ndo the right thing, 36\neditor text class example, 40, 50, 56\nevent-driven programming, 148\nexample\nlinked list, 25\nexamples\nconfiguration parameters, 56\neditor text class, 40, 50, 56, 91\nfile data loss, 121\nfile deletion, 79\n", "page": 179, "type": "text", "section": "Page 179"}
{"text": "HTTP parameters, 34\nHTTP response, 36\nHTTP server, 32, 60\nIndexLookup, 112\nJava I/O, 26, 49, 61\nJava substring, 80\nmissing parameter, 82\nNFS server crash, 81\nnon-existent selection, 87\nout of memory, 86\nRAMCloud Buffer, 163\nRAMCloud error promotion, 85\nRAMCloud Status, 117\nselection/cursor, 65\nTcl unset, 78\nundo, 67\nUnix I/O, 23\nWeb site colors, 7\nexception, 75\naggregation, 82\nmasking, 81\nFacebook, 17\nfalse abstraction, 22, 43\nfence, for undo, 69\nfile data loss example, 121\nfile deletion example, 79\nfile descriptor, 23\nflash storage, 160\ngarbage collection, 160\ngeneral-purpose class, 40, 66\n", "page": 180, "type": "text", "section": "Page 180"}
{"text": "general-purpose code, 62, 67\ngeneric containers, 149\ngetter, 156\nglobal variable, 51\nGo language, 126\nshort names in, 126\nGoogle, 17\nHTTP parameters example, 34\nHTTP response example, 36\nHTTP server example, 32, 60\nimplementation, 19, 50\nimplementation documentation, 116\nimplementation inheritance, 152\nincremental development, 2, 39\nIndexLookup example, 112\ninformation hiding, 29\ninformation leakage, 30\ninheritance, 151\nintegration tests, 154\ninterface, 19, 50\nformal parts, 20\ninformal parts, 21\ninterface comment\nclass, 110\nmethod, 110\ninterface documentation, 110\ninterface inheritance, 151\ninvariants, 142\ninvestment mindset, 15, 128, 136, 144\n", "page": 181, "type": "text", "section": "Page 181"}
{"text": "Java I/O example, 26, 49, 61\nJava substring example, 80\nlinked list example, 25\nlong method, 70\nmasking exceptions, 81\nmemory allocation, dynamic, 160\nmethod interface comment, 110\nmicro-benchmark, 160\nmissing parameter example, 82\nmodular design, 2, 19\nmodule, 20\nnames\nconsistency, 126, 141\ngeneric, 123\nhow to choose, 121\nmaking code more obvious, 146\nprecise, 123\nshort names in Go, 126\nnetwork communication, 160\nNFS server crash example, 81\nnon-existent selection example, 87\nnonvolatile memory, 160\nobject-oriented programming, 151\nobscurity, 10, 145\nobvious code, 9, 145\nout of memory example, 86\nParnas, David, 29\n", "page": 182, "type": "text", "section": "Page 182"}
{"text": "pass-through method, 46\npass-through variable, 50\nperformance\nmicro-benchmark, 160\nperformance, designing for, 159\nprivate variables, 30\nRAMCloud Buffer example, 163\nRAMCloud error promotion example, 85\nRAMCloud Status example, 117\nselection/cursor example, 65\nself-documenting code, 96\nsetter, 156\nshallow module, 25\nsmall classes, 26\nspecial-purpose code, 62, 67\nspecification, formal, 21\nstrategic programming, 14, 135\nstyle, coding, 141\nsubstring example (Java), 80\nsystem tests, 154\ntactical programming, 13, 135, 153\ntactical tornado, 14\nTcl unset example, 78\ntemporal decomposition, 31\ntest-driven development, 155\ntests\nintegration, 154\nsystem, 154\nunit, 154\n", "page": 183, "type": "text", "section": "Page 183"}
{"text": "try block, 77\nundo example, 67\nunit tests, 154\nUnix I/O example, 23\nunknown unknowns, 8, 99\nURL encoding, 34\nVMware, 17\nwaterfall model, 2\nWeb site colors example, 7\nwhite space, 146\n", "page": 184, "type": "text", "section": "Page 184"}
{"text": "Summary of Design Principles\nHere are the most important software design principles discussed in this book:\n1. Complexity is incremental: you have to sweat the small stuff (see p. 11).\n2. Working code isn\u2019t enough (see p. 14).\n3. Make continual small investments to improve system design (see p. 15).\n4. Modules should be deep (see p. 22)\n5. Interfaces should be designed to make the most common usage as simple as\npossible (see p. 27).\n6. It\u2019s more important for a module to have a simple interface than a simple\nimplementation (see pp. 55, 71).\n7. General-purpose modules are deeper (see p. 39).\n8. Separate general-purpose and special-purpose code (see p. 62).\n9. Different layers should have different abstractions (see p. 45).\n10. Pull complexity downward (see p. 55).\n11. Define errors (and special cases) out of existence (see p. 79).\n12. Design it twice (see p. 91).\n13. Comments should describe things that are not obvious from the code (see p.\n101).\n14. Software should be designed for ease of reading, not ease of writing (see p.\n149).\n15. The increments of software development should be abstractions, not\nfeatures (see p. 154).\n", "page": 185, "type": "text", "section": "Page 185"}
{"text": "Summary of Red Flags\nHere are a few of of the most important red flags discussed in this book. The\npresence of any of these symptoms in a system suggests that there is a problem\nwith the system\u2019s design:\nShallow Module: the interface for a class or method isn\u2019t much simpler than its\nimplementation (see pp. 25, 110).\nInformation Leakage: a design decision is reflected in multiple modules (see p.\n31).\nTemporal Decomposition: the code structure is based on the order in which\noperations are executed, not on information hiding (see p. 32).\nOverexposure: An API forces callers to be aware of rarely used features in order\nto use commonly used features (see p. 36).\nPass-Through Method: a method does almost nothing except pass its arguments\nto another method with a similar signature (see p. 46).\nRepetition: a nontrivial piece of code is repeated over and over (see p. 62).\nSpecial-General Mixture: special-purpose code is not cleanly separated from\ngeneral purpose code (see p. 65).\nConjoined Methods: two methods have so many dependencies that its hard to\nunderstand the implementation of one without understanding the implementation\nof the other (see p. 72).\nComment Repeats Code: all of the information in a comment is immediately\nobvious from the code next to the comment (see p. 104).\nImplementation Documentation Contaminates Interface: an interface\ncomment describes implementation details not needed by users of the thing\nbeing documented (see p. 114).\nVague Name: the name of a variable or method is so imprecise that it doesn\u2019t\nconvey much useful information (see p. 123).\n", "page": 186, "type": "text", "section": "Page 186"}
{"text": "Hard to Pick Name: it is difficult to come up with a precise and intuitive name\nfor an entity (see p. 125).\nHard to Describe: in order to be complete, the documentation for a variable or\nmethod must be long. (see p. 131).\nNonobvious Code: the behavior or meaning of a piece of code cannot be\nunderstood easily. (see p. 148).\n", "page": 187, "type": "text", "section": "Page 187"}
{"text": "About the Author\nJohn Ousterhout is the Bosack Lerner Professor of Computer Science at Stanford\nUniversity. He is the creator of the Tcl scripting language and is also well known\nfor his work in distributed operating systems and storage systems. Ousterhout\nreceived a BS degree in Physics from Yale University and a PhD in Computer\nScience from Carnegie Mellon University. He is a member of the National\nAcademy of Engineering and has received numerous awards, including the ACM\nSoftware System Award, the ACM Grace Murray Hopper Award, the National\nScience Foundation Presidential Young Investigator Award, and the U.C.\nBerkeley Distinguished Teaching Award.\n", "page": 188, "type": "text", "section": "Page 188"}
