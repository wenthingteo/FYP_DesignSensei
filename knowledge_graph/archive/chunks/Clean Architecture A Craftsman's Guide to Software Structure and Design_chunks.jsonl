{"text": "Tests: Conclusion\nChapter 5     Object-Oriented Programming\nEncapsulation? Inheritance? Polymorphism? Conclusion\nChapter 6     Functional Programming\nSquares of Integers\nImmutability and Architecture\nSegregation of Mutability\nEvent Sourcing\nConclusion\nPART III      Design Principles\nChapter 7     SRP: The Single Responsibility Principle\nSymptom 1: Accidental Duplication\nSymptom 2: Merges\nSolutions\nConclusion\nChapter 8     OCP: The Open-Closed Principle\nA Thought Experiment\nDirectional Control\nInformation Hiding\nConclusion\nChapter 9     LSP: The Liskov Substitution Principle\nGuiding the Use of Inheritance\nThe Square/Rectangle Problem\nLSP and Architecture\nExample LSP Violation\nConclusion\nChapter 10   ISP: The Interface Segregation Principle\nISP and Language\nISP and Architecture\nConclusion\nChapter 11   DIP: The Dependency Inversion Principle", "domains": ["Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 8", "position": 8, "chunk_type": "semantic", "token_estimate": 103}
{"text": "Stable Abstractions: Factories\nConcrete Components\nConclusion\nPART IV      Component Principles\nChapter 12   Components\nA Brief History of Components\nRelocatability\nLinkers\nConclusion\nChapter 13   Component Cohesion\nThe Reuse/Release Equivalence Principle\nThe Common Closure Principle\nThe Common Reuse Principle\nThe Tension Diagram for Component Cohesion\nConclusion\nChapter 14   Component Coupling\nThe Acyclic Dependencies Principle\nTop-Down Design\nThe Stable Dependencies Principle\nThe Stable Abstractions Principle\nConclusion\nPART V       Architecture\nChapter 15   What Is Architecture? Development\nDeployment\nOperation\nMaintenance\nKeeping Options Open\nDevice Independence\nJunk Mail\nPhysical Addressing\nConclusion\nChapter 16   Independence\nUse Cases\nOperation", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 9", "position": 9, "chunk_type": "semantic", "token_estimate": 91}
{"text": "But What About the Web?: Frameworks Are Tools, Not Ways of Life\nTestable Architectures\nConclusion\nChapter 22   The Clean Architecture\nThe Dependency Rule\nA Typical Scenario\nConclusion\nChapter 23   Presenters and Humble Objects\nThe Humble Object Pattern\nPresenters and Views\nTesting and Architecture\nDatabase Gateways\nData Mappers\nService Listeners\nConclusion\nChapter 24   Partial Boundaries\nSkip the Last Step\nOne-Dimensional Boundaries\nFacades\nConclusion\nChapter 25   Layers and Boundaries\nHunt the Wumpus\nClean Architecture? Crossing the Streams\nSplitting the Streams\nConclusion\nChapter 26   The Main Component\nThe Ultimate Detail\nConclusion\nChapter 27   Services: Great and Small\nService Architecture? Service Benefits? The Kitty Problem\nObjects to the Rescue\nComponent-Based Services\nCross-Cutting Concerns", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 11", "position": 11, "chunk_type": "semantic", "token_estimate": 109}
{"text": "Conclusion: Chapter 28   The Test Boundary\nTests as System Components\nDesign for Testability\nThe Testing API\nConclusion\nChapter 29   Clean Embedded Architecture\nApp-titude Test\nThe Target-Hardware Bottleneck\nConclusion\nPART VI      Details\nChapter 30   The Database Is a Detail\nRelational Databases\nWhy Are Database Systems So Prevalent? What If There Were No Disk? Details\nBut What about Performance? Anecdote\nConclusion\nChapter 31   The Web Is a Detail\nThe Endless Pendulum\nThe Upshot\nConclusion\nChapter 32   Frameworks Are Details\nFramework Authors\nAsymmetric Marriage\nThe Risks\nThe Solution\nI Now Pronounce You \u2026\nConclusion\nChapter 33   Case Study: Video Sales\nThe Product\nUse Case Analysis\nComponent Architecture\nDependency Management\nConclusion", "domains": ["Software Quality Attributes", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 12", "position": 12, "chunk_type": "semantic", "token_estimate": 107}
{"text": "Chapter 34   The Missing Chapter: Package by Layer\nPackage by Feature\nPorts and Adapters\nPackage by Component\nThe Devil Is in the Implementation Details\nOrganization versus Encapsulation\nOther Decoupling Modes\nConclusion: The Missing Advice\nPART VII     Appendix\nAppendix A   Architecture Archaeology\nIndex", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 13", "position": 13, "chunk_type": "semantic", "token_estimate": 42}
{"text": "Although it might not make sense to talk about physics and physical scale in software architecture, we: do appreciate and care about certain physical constraints. Processor speed and network bandwidth\ncan deliver a harsh verdict on a system\u2019s performance. Memory and storage can limit the ambitions of\nany code base. Software may be such stuff as dreams are made on, but it runs in the physical world. This is the monstrosity in love, lady, that the will is infinite, and the execution confined; that the desire is boundless,\nand the act a slave to limit. \u2014William Shakespeare\nThe physical world is where we and our companies and our economies live. This gives us another\ncalibration we can understand software architecture by, other less physical forces and quantities\nthrough which we can talk and reason. Architecture represents the significant design decisions that shape a system, where significant is measured by cost of\nchange. \u2014Grady Booch\nTime, money, and effort give us a sense of scale to sort between the large and the small, to distinguish\nthe architectural stuff from the rest. This measure also tells us how we can determine whether an\narchitecture is good or not: Not only does a good architecture meet the needs of its users, developers,\nand owners at a given point in time, but it also meets them over time. If you think good architecture is expensive, try bad architecture. \u2014Brian Foote and Joseph Yoder\nThe kinds of changes a system\u2019s development typically experiences should not be the changes that are\ncostly, that are hard to make, that take managed projects of their own rather than being folded into the\ndaily and weekly flow of work. That point leads us to a not-so-small physics-related problem: time travel. How do we know what\nthose typical changes will be so that we can shape those significant decisions around them? How do\nwe reduce future development effort and cost without crystal balls and time machines? Architecture is the decisions that you wish you could get right early in a project, but that you are not necessarily more\nlikely to get them right than any other. \u2014Ralph Johnson\nUnderstanding the past is hard enough as it is; our grasp of the present is slippery at best; predicting\nthe future is nontrivial. This is where the road forks many ways. Down the darkest path comes the idea that strong and stable architecture comes from authority and\nrigidity.", "domains": ["Software Quality Attributes"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 15", "position": 15, "chunk_type": "semantic", "token_estimate": 406}
{"text": "PREFACE: The title of this book is Clean Architecture. That\u2019s an audacious name. Some would even call it\narrogant. So why did I choose that title, and why did I write this book? I wrote my very first line of code in 1964, at the age of 12. The year is now 2016, so I have been\nwriting code for more than half a century. In that time, I have learned a few things about how to\nstructure software systems\u2014things that I believe others would likely find valuable. I learned these things by building many systems, both large and small. I have built small embedded\nsystems and large batch processing systems. I have built real-time systems and web systems. I have\nbuilt console apps, GUI apps, process control apps, games, accounting systems, telecommunications\nsystems, design tools, drawing apps, and many, many others. I have built single-threaded apps, multithreaded apps, apps with few heavy-weight processes, apps\nwith many light-weight processes, multiprocessor apps, database apps, mathematical apps,\ncomputational geometry apps, and many, many others. I\u2019ve built a lot of apps. I\u2019ve built a lot of systems. And from them all, and by taking them all into\nconsideration, I\u2019ve learned something startling. The architecture rules are the same! This is startling because the systems that I have built have all been so radically different. Why should\nsuch different systems all share similar rules of architecture? My conclusion is that the rules of\nsoftware architecture are independent of every other variable. This is even more startling when you consider the change that has taken place in hardware over the\nsame half-century. I started programming on machines the size of kitchen refrigerators that had half-\nmegahertz cycle times, 4K of core memory, 32K of disk memory, and a 10 character per second\nteletype interface. I am writing this preface on a bus while touring in South Africa. I am using a\nMacBook with four i7 cores running at 2.8 gigahertz each. It has 16 gigabytes of RAM, a terabyte of\nSSD, and a 2880\u00d71800 retina display capable of showing extremely high-definition video. The\ndifference in computational power is staggering. Any reasonable analysis will show that this\nMacBook is at least 1022 more powerful than those early computers that I started using half a century\nago. Twenty-two orders of magnitude is a very large number. It is the number of angstroms from Earth to\nAlpha-Centuri.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 17", "position": 17, "chunk_type": "semantic", "token_estimate": 399}
{"text": "The first value of software is its behavior. Programmers are hired to make machines behave in a way: that makes or saves money for the stakeholders. We do this by helping the stakeholders develop a\nfunctional specification, or requirements document. Then we write the code that causes the\nstakeholder\u2019s machines to satisfy those requirements. When the machine violates those requirements, programmers get their debuggers out and fix the\nproblem. Many programmers believe that is the entirety of their job. They believe their job is to make the\nmachine implement the requirements and to fix any bugs. They are sadly mistaken.", "domains": ["Domain-Driven Design"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 33", "position": 33, "chunk_type": "semantic", "token_estimate": 100}
{"text": "Edsger Wybe Dijkstra was born in Rotterdam in 1930. He survived the bombing of Rotterdam during: World War II, along with the German occupation of the Netherlands, and in 1948 graduated from high\nschool with the highest possible marks in math, physics, chemistry, and biology. In March 1952, at the\nage of 21 (and just 9 months before I was born), Dijkstra took a job with the Mathematical Center of\nAmsterdam as the Netherlands\u2019 very first programmer. In 1955, having been a programmer for three years, and while still a student, Dijkstra concluded that\nthe intellectual challenge of programming was greater than the intellectual challenge of theoretical\nphysics. As a result, he chose programming as his long-term career. In 1957, Dijkstra married Maria Debets. At the time, you had to state your profession as part of the\nmarriage rites in the Netherlands. The Dutch authorities were unwilling to accept \u201cprogrammer\u201d as\nDijkstra\u2019s profession; they had never heard of such a profession. To satisfy them, Dijkstra settled for\n\u201ctheoretical physicist\u201d as his job title. As part of deciding to make programming his career, Dijkstra conferred with his boss, Adriaan van\nWijngaarden. Dijkstra was concerned that no one had identified a discipline, or science, of\nprogramming, and that he would therefore not be taken seriously. His boss replied that Dijkstra might\nvery well be one of the people who would discover such disciplines, thereby evolving software into\na science. Dijkstra started his career in the era of vacuum tubes, when computers were huge, fragile, slow,", "domains": ["Design Patterns"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 41", "position": 41, "chunk_type": "semantic", "token_estimate": 253}
{"text": "The problem that Dijkstra recognized, early on, was that programming is hard, and that programmers: don\u2019t do it very well. A program of any complexity contains too many details for a human brain to\nmanage without help. Overlooking just one small detail results in programs that may seem to work,\nbut fail in surprising ways. Dijkstra\u2019s solution was to apply the mathematical discipline of proof. His vision was the construction\nof a Euclidian hierarchy of postulates, theorems, corollaries, and lemmas. Dijkstra thought that\nprogrammers could use that hierarchy the way mathematicians do. In other words, programmers\nwould use proven structures, and tie them together with code that they would then prove correct\nthemselves. Of course, to get this going, Dijkstra realized that he would have to demonstrate the technique for\nwriting basic proofs of simple algorithms. This he found to be quite challenging. During his investigation, Dijkstra discovered that certain uses of goto statements prevent modules\nfrom being decomposed recursively into smaller and smaller units, thereby preventing use of the\ndivide-and-conquer approach necessary for reasonable proofs. Other uses of goto, however, did not have this problem. Dijkstra realized that these \u201cgood\u201d uses of\ngoto corresponded to simple selection and iteration control structures such as if/then/else and\ndo/while. Modules that used only those kinds of control structures could be recursively subdivided\ninto provable units. Dijkstra knew that those control structures, when combined with sequential execution, were special. They had been identified two years before by B\u00f6hm and Jacopini, who proved that all programs can\nbe constructed from just three structures: sequence, selection, and iteration. This discovery was remarkable: The very control structures that made a module provable were the\nsame minimum set of control structures from which all programs can be built. Thus structured\nprogramming was born. Dijkstra showed that sequential statements could be proved correct through simple enumeration. The\ntechnique mathematically traced the inputs of the sequence to the outputs of the sequence. This\napproach was no different from any normal mathematical proof. Dijkstra tackled selection through reapplication of enumeration. Each path through the selection was\nenumerated. If both paths eventually produced appropriate mathematical results, then the proof was", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 42", "position": 42, "chunk_type": "semantic", "token_estimate": 359}
{"text": "solid.: Iteration was a bit different. To prove an iteration correct, Dijkstra had to use induction. He proved\nthe case for 1 by enumeration. Then he proved the case that if N was assumed correct, N + 1 was\ncorrect, again by enumeration. He also proved the starting and ending criteria of the iteration by\nenumeration. Such proofs were laborious and complex\u2014but they were proofs. With their development, the idea\nthat a Euclidean hierarchy of theorems could be constructed seemed reachable.", "domains": ["Design Principles"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 43", "position": 43, "chunk_type": "semantic", "token_estimate": 81}
{"text": "But the proofs never came. The Euclidean hierarchy of theorems was never built. And programmers: at large never saw the benefits of working through the laborious process of formally proving each and\nevery little function correct. In the end, Dijkstra\u2019s dream faded and died. Few of today\u2019s programmers\nbelieve that formal proofs are an appropriate way to produce high-quality software. Of course, formal, Euclidian style, mathematical proofs are not the only strategy for proving\nsomething correct. Another highly successful strategy is the scientific method.", "domains": ["Design Patterns"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 44", "position": 44, "chunk_type": "semantic", "token_estimate": 84}
{"text": "It is this ability to create falsifiable units of programming that makes structured programming valuable: today. This is the reason that modern languages do not typically support unrestrained goto statements. Moreover, at the architectural level, this is why we still consider functional decomposition to be one\nof our best practices. At every level, from the smallest function to the largest component, software is like a science and,\ntherefore, is driven by falsifiability. Software architects strive to define modules, components, and\nservices that are easily falsifiable (testable). To do so, they employ restrictive disciplines similar to\nstructured programming, albeit at a much higher level. It is those restrictive disciplines that we will study in some detail in the chapters to come.", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 45", "position": 45, "chunk_type": "semantic", "token_estimate": 120}
{"text": "5: OBJECT-ORIENTED PROGRAMMING\nAs we will see, the basis of a good architecture is the understanding and application of the principles\nof object-oriented design (OO). But just what is OO? One answer to this question is \u201cThe combination of data and function.\u201d Although often cited, this is a\nvery unsatisfying answer because it implies that o.f() is somehow different from f(o). This is\nabsurd. Programmers were passing data structures into functions long before 1966, when Dahl and\nNygaard moved the function call stack frame to the heap and invented OO. Another common answer to this question is \u201cA way to model the real world.\u201d This is an evasive\nanswer at best. What does \u201cmodeling the real world\u201d actually mean, and why is it something we\nwould want to do? Perhaps this statement is intended to imply that OO makes software easier to\nunderstand because it has a closer relationship to the real world\u2014but even that statement is evasive\nand too loosely defined. It does not tell us what OO is. Some folks fall back on three magic words to explain the nature of OO: encapsulation, inheritance,\nand polymorphism. The implication is that OO is the proper admixture of these three things, or at\nleast that an OO language must support these three things. Let\u2019s examine each of these concepts in turn.", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 46", "position": 46, "chunk_type": "semantic", "token_estimate": 221}
{"text": "ENCAPSULATION?: The reason encapsulation is cited as part of the definition of OO is that OO languages provide easy\nand effective encapsulation of data and function. As a result, a line can be drawn around a cohesive\nset of data and functions. Outside of that line, the data is hidden and only some of the functions are\nknown. We see this concept in action as the private data members and the public member functions of\na class. This idea is certainly not unique to OO. Indeed, we had perfect encapsulation in C. Consider this\nsimple C program:\nClick here to view code image\npoint.h\nstruct Point;\nstruct Point* makePoint(double x, double y);\ndouble distance (struct Point *p1, struct Point *p2);\nClick here to view code image\npoint.c\n#include \"point.h\"\n#include <stdlib.h>\n#include <math.h>\n \nstruct Point {\n  double x,y;\n};\n \nstruct Point* makepoint(double x, double y) {\n  struct Point* p = malloc(sizeof(struct Point));\n  p->x = x;\n  p->y = y;\n  return p;\n}\n \ndouble distance(struct Point* p1, struct Point* p2) {\n  double dx = p1->x - p2->x;\n  double dy = p1->y - p2->y;\n  return sqrt(dx*dx+dy*dy);\n}\nThe users of point.h have no access whatsoever to the members of struct Point. They can call\nthe makePoint() function, and the distance() function, but they have absolutely no knowledge of\nthe implementation of either the Point data structure or the functions. This is perfect encapsulation\u2014in a non-OO language. C programmers used to do this kind of thing all\nthe time. We would forward declare data structures and functions in header files, and then implement\nthem in implementation files. Our users never had access to the elements in those implementation\nfiles.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 47", "position": 47, "chunk_type": "semantic", "token_estimate": 275}
{"text": "But then came OO in the form of C++\u2014and the perfect encapsulation of C was broken.: The C++ compiler, for technical reasons,1 needed the member variables of a class to be declared in\nthe header file of that class. So our Point program changed to look like this:\nClick here to view code image\npoint.h\nclass Point {\npublic:\n  Point(double x, double y);\n  double distance(const Point& p) const;\n \nprivate:\n  double x;\n  double y;\n};\nClick here to view code image\npoint.cc\n#include \"point.h\"\n#include <math.h>\n \nPoint::Point(double x, double y)\n: x(x), y(y)\n{}\ndouble Point::distance(const Point& p) const {\n  double dx = x-p.x;\n  double dy = y-p.y;\n  return sqrt(dx*dx + dy*dy);\n}\nClients of the header file point.h know about the member variables x and y! The compiler will\nprevent access to them, but the client still knows they exist. For example, if those member names are\nchanged, the point.cc file must be recompiled! Encapsulation has been broken. Indeed, the way encapsulation is partially repaired is by introducing the public, private, and\nprotected keywords into the language. This, however, was a hack necessitated by the technical need\nfor the compiler to see those variables in the header file. Java and C# simply abolished the header/implementation split altogether, thereby weakening\nencapsulation even more. In these languages, it is impossible to separate the declaration and\ndefinition of a class. For these reasons, it is difficult to accept that OO depends on strong encapsulation. Indeed, many OO\nlanguages2 have little or no enforced encapsulation. OO certainly does depend on the idea that programmers are well-behaved enough to not circumvent", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 48", "position": 48, "chunk_type": "semantic", "token_estimate": 266}
{"text": "encapsulated data. Even so, the languages that claim to provide OO have only weakened the once: perfect encapsulation we enjoyed with C.\nINHERITANCE? If OO languages did not give us better encapsulation, then they certainly gave us inheritance. Well\u2014sort of. Inheritance is simply the redeclaration of a group of variables and functions within an\nenclosing scope. This is something C programmers3 were able to do manually long before there was\nan OO language. Consider this addition to our original point.h C program:\nClick here to view code image\nnamedPoint.h\nstruct NamedPoint;\n \nstruct NamedPoint* makeNamedPoint(double x, double y, char* name);\nvoid setName(struct NamedPoint* np, char* name);\nchar* getName(struct NamedPoint* np);\nClick here to view code image\nnamedPoint.c\n#include \"namedPoint.h\"\n#include <stdlib.h>\n \nstruct NamedPoint {\n  double x,y;\n  char* name;\n};\n \nstruct NamedPoint* makeNamedPoint(double x, double y, char* name) {\n  struct NamedPoint* p = malloc(sizeof(struct NamedPoint));\n  p->x = x;\n  p->y = y;\n  p->name = name;\n  return p;\n}\n \nvoid setName(struct NamedPoint* np, char* name) {\n  np->name = name;\n}\n \nchar* getName(struct NamedPoint* np) {\n  return np->name;\n}\nClick here to view code image\nmain.c", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 49", "position": 49, "chunk_type": "semantic", "token_estimate": 181}
{"text": "#include \"point.h\": #include \"namedPoint.h\"\n#include <stdio.h>\n \nint main(int ac, char** av) {\n  struct NamedPoint* origin = makeNamedPoint(0.0, 0.0, \"origin\");\n  struct NamedPoint* upperRight = makeNamedPoint (1.0, 1.0, \"upperRight\");\n  printf(\"distance=%f\\n\",\n    distance(\n             (struct Point*) origin, \n             (struct Point*) upperRight));\n}\nIf you look carefully at the main program, you\u2019ll see that the NamedPoint data structure acts as though\nit is a derivative of the Point data structure. This is because the order of the first two fields in\nNamedPoint is the same as Point. In short, NamedPoint can masquerade as Point because\nNamedPoint is a pure superset of Point and maintains the ordering of the members that correspond\nto Point. This kind of trickery was a common practice4 of programmers prior to the advent of OO. In fact, such\ntrickery is how C++ implements single inheritance. Thus we might say that we had a kind of inheritance long before OO languages were invented. That\nstatement wouldn\u2019t quite be true, though. We had a trick, but it\u2019s not nearly as convenient as true\ninheritance. Moreover, multiple inheritance is a considerably more difficult to achieve by such\ntrickery. Note also that in main.c, I was forced to cast the NamedPoint arguments to Point. In a real OO\nlanguage, such upcasting would be implicit. It\u2019s fair to say that while OO languages did not give us something completely brand new, it did make\nthe masquerading of data structures significantly more convenient. To recap: We can award no point to OO for encapsulation, and perhaps a half-point for inheritance. So far, that\u2019s not such a great score. But there\u2019s one more attribute to consider. POLYMORPHISM? Did we have polymorphic behavior before OO languages? Of course we did. Consider this simple C\ncopy program. Click here to view code image\n#include <stdio.h>\nvoid copy() {\n  int c;", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 50", "position": 50, "chunk_type": "semantic", "token_estimate": 298}
{"text": "Imagine what software was like before a safe and convenient mechanism for polymorphism was: available. In the typical calling tree, main functions called high-level functions, which called mid-\nlevel functions, which called low-level functions. In that calling tree, however, source code\ndependencies inexorably followed the flow of control (Figure 5.1). Figure 5.1 Source code dependencies versus flow of control\nFor main to call one of the high-level functions, it had to mention the name of the module that\ncontained that function In C, this was a #include. In Java, it was an import statement. In C#, it was\na using statement. Indeed, every caller was forced to mention the name of the module that contained\nthe callee. This requirement presented the software architect with few, if any, options. The flow of control was\ndictated by the behavior of the system, and the source code dependencies were dictated by that flow\nof control. When polymorphism is brought into play, however, something very different can happen (Figure 5.2).", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 53", "position": 53, "chunk_type": "semantic", "token_estimate": 166}
{"text": "Figure 5.2 Dependency inversion: In Figure 5.2, module HL1 calls the F() function in module ML1. The fact that it calls this function\nthrough an interface is a source code contrivance. At runtime, the interface doesn\u2019t exist. HL1 simply\ncalls F() within ML1.7\nNote, however, that the source code dependency (the inheritance relationship) between ML1 and the\ninterface I points in the opposite direction compared to the flow of control. This is called\ndependency inversion, and its implications for the software architect are profound. The fact that OO languages provide safe and convenient polymorphism means that any source code\ndependency, no matter where it is, can be inverted. Now look back at that calling tree in Figure 5.1, and its many source code dependencies. Any of those\nsource code dependencies can be turned around by inserting an interface between them. With this approach, software architects working in systems written in OO languages have absolute\ncontrol over the direction of all source code dependencies in the system. They are not constrained to\nalign those dependencies with the flow of control. No matter which module does the calling and\nwhich module is called, the software architect can point the source code dependency in either\ndirection. That is power! That is the power that OO provides. That\u2019s what OO is really all about\u2014at least from\nthe architect\u2019s point of view. What can you do with that power? As an example, you can rearrange the source code dependencies of\nyour system so that the database and the user interface (UI) depend on the business rules (Figure 5.3),\nrather than the other way around.", "domains": ["Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 54", "position": 54, "chunk_type": "semantic", "token_estimate": 269}
{"text": "Figure 5.3 The database and the user interface depend on the business rules: This means that the UI and the database can be plugins to the business rules. It means that the source\ncode of the business rules never mentions the UI or the database. As a consequence, the business rules, the UI, and the database can be compiled into three separate\ncomponents or deployment units (e.g., jar files, DLLs, or Gem files) that have the same dependencies\nas the source code. The component containing the business rules will not depend on the components\ncontaining the UI and database. In turn, the business rules can be deployed independently of the UI and the database. Changes to the\nUI or the database need not have any effect on the business rules. Those components can be deployed\nseparately and independently. In short, when the source code in a component changes, only that component needs to be redeployed. This is independent deployability. If the modules in your system can be deployed independently, then they can be developed\nindependently by different teams. That\u2019s independent developability.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 55", "position": 55, "chunk_type": "semantic", "token_estimate": 181}
{"text": "Click here to view code image: (println (take 25 (map (fn [x] (* x x)) (range))))\nIf you don\u2019t know Lisp, then this might look a little strange. So let me reformat it a bit and add some\ncomments. Click here to view code image\n(println ;___________________ Print\n  (take 25 ;_________________ the first 25\n    (map (fn [x] (* x x)) ;__ squares\n      (range)))) ;___________ of Integers\nIt should be clear that println, take, map, and range are all functions. In Lisp, you call a function\nby putting it in parentheses. For example, (range) calls the range function. The expression (fn [x] (* x x)) is an anonymous function that calls the multiply function, passing\nits input argument in twice. In other words, it computes the square of its input. Looking at the whole thing again, it\u2019s best to start with the innermost function call. \u2022 The range function returns a never-ending list of integers starting with 0. \u2022 This list is passed into the map function, which calls the anonymous squaring function on each\nelement, producing a new never-ending list of all the squares. \u2022 The list of squares is passed into the take function, which returns a new list with only the first 25\nelements. \u2022 The println function prints its input, which is a list of the first 25 squares of integers. If you find yourself terrified by the concept of never-ending lists, don\u2019t worry. Only the first 25\nelements of those never-ending lists are actually created. That\u2019s because no element of a never-ending\nlist is evaluated until it is accessed. If you found all of that confusing, then you can look forward to a glorious time learning all about\nClojure and functional programming. It is not my goal to teach you about these topics here. Instead, my goal here is to point out something very dramatic about the difference between the\nClojure and Java programs. The Java program uses a mutable variable\u2014a variable that changes state\nduring the execution of the program. That variable is i\u2014the loop control variable. No such mutable\nvariable exists in the Clojure program. In the Clojure program, variables like x are initialized, but\nthey are never modified. This leads us to a surprising statement: V\nariables in functional languages do not vary.", "domains": ["Design Patterns"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 57", "position": 57, "chunk_type": "semantic", "token_estimate": 380}
{"text": "One of the most common compromises in regard to immutability is to segregate the application, or the: services within the application, into mutable and immutable components. The immutable components\nperform their tasks in a purely functional way, without using any mutable variables. The immutable\ncomponents communicate with one or more other components that are not purely functional, and allow\nfor the state of variables to be mutated (Figure 6.1). Figure 6.1 Mutating state and transactional memory\nSince mutating state exposes those components to all the problems of concurrency, it is common", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 58", "position": 58, "chunk_type": "semantic", "token_estimate": 91}
{"text": "practice to use some kind of transactional memory to protect the mutable variables from concurrent: updates and race conditions. Transactional memory simply treats variables in memory the same way a database treats records on\ndisk.1 It protects those variables with a transaction- or retry-based scheme. A simple example of this approach is Clojure\u2019s atom facility:\nClick here to view code image\n(def counter (atom 0)) ; initialize counter to 0\n(swap! counter inc)    ; safely increment counter. In this code, the counter variable is defined as an atom. In Clojure, an atom is a special kind of\nvariable whose value is allowed to mutate under very disciplined conditions that are enforced by the\nswap! function. The swap! function, shown in the preceding code, takes two arguments: the atom to be mutated, and a\nfunction that computes the new value to be stored in the atom. In our example code, the counter atom\nwill be changed to the value computed by the inc function, which simply increments its argument. The strategy used by swap! is a traditional compare and swap algorithm. The value of counter is\nread and passed to inc. When inc returns, the value of counter is locked and compared to the value\nthat was passed to inc. If the value is the same, then the value returned by inc is stored in counter\nand the lock is released. Otherwise, the lock is released, and the strategy is retried from the\nbeginning. The atom facility is adequate for simple applications. Unfortunately, it cannot completely safeguard\nagainst concurrent updates and deadlocks when multiple dependent variables come into play. In those\ninstances, more elaborate facilities can be used. The point is that well-structured applications will be segregated into those components that do not\nmutate variables and those that do. This kind of segregation is supported by the use of appropriate\ndisciplines to protect those mutated variables. Architects would be wise to push as much processing as possible into the immutable components, and\nto drive as much code as possible out of those components that must allow mutation.", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 59", "position": 59, "chunk_type": "semantic", "token_estimate": 346}
{"text": "The limits of storage and processing power have been rapidly receding from view. Nowadays it is: common for processors to execute billions of instructions per second and to have billions of bytes of\nRAM. The more memory we have, and the faster our machines are, the less we need mutable state. As a simple example, imagine a banking application that maintains the account balances of its", "domains": ["Design Patterns"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 59", "position": 59, "chunk_type": "semantic", "token_estimate": 66}
{"text": "customers. It mutates those balances when deposit and withdrawal transactions are executed.: Now imagine that instead of storing the account balances, we store only the transactions. Whenever\nanyone wants to know the balance of an account, we simply add up all the transactions for that\naccount, from the beginning of time. This scheme requires no mutable variables. Obviously, this approach sounds absurd. Over time, the number of transactions would grow without\nbound, and the processing power required to compute the totals would become intolerable. To make\nthis scheme work forever, we would need infinite storage and infinite processing power. But perhaps we don\u2019t have to make the scheme work forever. And perhaps we have enough storage\nand enough processing power to make the scheme work for the reasonable lifetime of the application. This is the idea behind event sourcing.2 Event sourcing is a strategy wherein we store the\ntransactions, but not the state. When state is required, we simply apply all the transactions from the\nbeginning of time. Of course, we can take shortcuts. For example, we can compute and save the state every midnight. Then, when the state information is required, we need compute only the transactions since midnight. Now consider the data storage required for this scheme: We would need a lot of it. Realistically,\noffline data storage has been growing so fast that we now consider trillions of bytes to be small\u2014so\nwe have a lot of it. More importantly, nothing ever gets deleted or updated from such a data store. As a consequence, our\napplications are not CRUD; they are just CR. Also, because neither updates nor deletions occur in the\ndata store, there cannot be any concurrent update issues. If we have enough storage and enough processor power, we can make our applications entirely\nimmutable\u2014and, therefore, entirely functional. If this still sounds absurd, it might help if you remembered that this is precisely the way your source\ncode control system works.", "domains": ["Design Patterns"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 60", "position": 60, "chunk_type": "semantic", "token_estimate": 326}
{"text": "Good software systems begin with clean code. On the one hand, if the bricks aren\u2019t well made, the: architecture of the building doesn\u2019t matter much. On the other hand, you can make a substantial mess\nwith well-made bricks. This is where the SOLID principles come in. The SOLID principles tell us how to arrange our functions and data structures into classes, and how\nthose classes should be interconnected. The use of the word \u201cclass\u201d does not imply that these\nprinciples are applicable only to object-oriented software. A class is simply a coupled grouping of\nfunctions and data. Every software system has such groupings, whether they are called classes or not. The SOLID principles apply to those groupings. The goal of the principles is the creation of mid-level software structures that:\n\u2022 Tolerate change,\n\u2022 Are easy to understand, and\n\u2022 Are the basis of components that can be used in many software systems. The term \u201cmid-level\u201d refers to the fact that these principles are applied by programmers working at\nthe module level. They are applied just above the level of the code and help to define the kinds of\nsoftware structures used within modules and components. Just as it is possible to create a substantial mess with well-made bricks, so it is also possible to", "domains": ["Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 62", "position": 62, "chunk_type": "semantic", "token_estimate": 215}
{"text": "create a system-wide mess with well-designed mid-level components. For this reason, once we have: covered the SOLID principles, we will move on to their counterparts in the component world, and\nthen to the principles of high-level architecture. The history of the SOLID principles is long. I began to assemble them in the late 1980s while\ndebating software design principles with others on USENET (an early kind of Facebook). Over the\nyears, the principles have shifted and changed. Some were deleted. Others were merged. Still others\nwere added. The final grouping stabilized in the early 2000s, although I presented them in a different\norder. In 2004 or thereabouts, Michael Feathers sent me an email saying that if I rearranged the principles,\ntheir first words would spell the word SOLID\u2014and thus the SOLID principles were born. The chapters that follow describe each principle more thoroughly. Here is the executive summary:\n\u2022 SRP: The Single Responsibility Principle\nAn active corollary to Conway\u2019s law: The best structure for a software system is heavily influenced\nby the social structure of the organization that uses it so that each software module has one, and only\none, reason to change. \u2022 OCP: The Open-Closed Principle\nBertrand Meyer made this principle famous in the 1980s. The gist is that for software systems to be\neasy to change, they must be designed to allow the behavior of those systems to be changed by\nadding new code, rather than changing existing code. \u2022 LSP: The Liskov Substitution Principle\nBarbara Liskov\u2019s famous definition of subtypes, from 1988. In short, this principle says that to build\nsoftware systems from interchangeable parts, those parts must adhere to a contract that allows those\nparts to be substituted one for another. \u2022 ISP: The Interface Segregation Principle\nThis principle advises software designers to avoid depending on things that they don\u2019t use. \u2022 DIP: The Dependency Inversion Principle\nThe code that implements high-level policy should not depend on the code that implements low-\nlevel details. Rather, details should depend on policies. These principles have been described in detail in many different publications1 over the years. The\nchapters that follow will focus on the architectural implications of these principles instead of\nrepeating those detailed discussions. If you are not already familiar with these principles, what\nfollows is insufficient to understand them in detail and you would be well advised to study them in\nthe footnoted documents. 1.", "domains": ["Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 63", "position": 63, "chunk_type": "semantic", "token_estimate": 400}
{"text": "create a system-wide mess with well-designed mid-level components. For this reason, once we have: If you are not already familiar with these principles, what\nfollows is insufficient to understand them in detail and you would be well advised to study them in\nthe footnoted documents. 1. For example, Agile Software Development, Principles, Patterns, and Practices, Robert C. Martin, Prentice Hall, 2002,\nhttp://www.butunclebob.com/ArticleS.UncleBob.PrinciplesOfOod, and https://en.wikipedia.org/wiki/SOLID_(object-oriented_design)\n(or just google SOLID).", "domains": ["Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 63", "position": 63, "chunk_type": "semantic", "token_estimate": 68}
{"text": "7: SRP: THE SINGLE RESPONSIBILITY PRINCIPLE\nOf all the SOLID principles, the Single Responsibility Principle (SRP) might be the least well\nunderstood. That\u2019s likely because it has a particularly inappropriate name. It is too easy for\nprogrammers to hear the name and then assume that it means that every module should do just one\nthing. Make no mistake, there is a principle like that. A function should do one, and only one, thing. We use\nthat principle when we are refactoring large functions into smaller functions; we use it at the lowest\nlevels. But it is not one of the SOLID principles\u2014it is not the SRP. Historically, the SRP has been described this way:\nA module should have one, and only one, reason to change. Software systems are changed to satisfy users and stakeholders; those users and stakeholders are the\n\u201creason to change\u201d that the principle is talking about. Indeed, we can rephrase the principle to say\nthis:\nA module should be responsible to one, and only one, user or stakeholder. Unfortunately, the words \u201cuser\u201d and \u201cstakeholder\u201d aren\u2019t really the right words to use here. There\nwill likely be more than one user or stakeholder who wants the system changed in the same way. Instead, we\u2019re really referring to a group\u2014one or more people who require that change. We\u2019ll refer", "domains": ["Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 64", "position": 64, "chunk_type": "semantic", "token_estimate": 220}
{"text": "to that group as an actor.: Thus the final version of the SRP is:\nA module should be responsible to one, and only one, actor. Now, what do we mean by the word \u201cmodule\u201d? The simplest definition is just a source file. Most of\nthe time that definition works fine. Some languages and development environments, though, don\u2019t use\nsource files to contain their code. In those cases a module is just a cohesive set of functions and data\nstructures. That word \u201ccohesive\u201d implies the SRP. Cohesion is the force that binds together the code responsible\nto a single actor. Perhaps the best way to understand this principle is by looking at the symptoms of violating it. SYMPTOM 1: ACCIDENTAL DUPLICATION\nMy favorite example is the Employee class from a payroll application. It has three methods:\ncalculatePay(), reportHours(), and save() (Figure 7.1). Figure 7.1 The Employee class\nThis class violates the SRP because those three methods are responsible to three very different\nactors. \u2022 The calculatePay() method is specified by the accounting department, which reports to the CFO. \u2022 The reportHours() method is specified and used by the human resources department, which\nreports to the COO. \u2022 The save() method is specified by the database administrators (DBAs), who report to the CTO. By putting the source code for these three methods into a single Employee class, the developers have", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 65", "position": 65, "chunk_type": "semantic", "token_estimate": 228}
{"text": "There are many different solutions to this problem. Each moves the functions into different classes.: Perhaps the most obvious way to solve the problem is to separate the data from the functions. The\nthree classes share access to EmployeeData, which is a simple data structure with no methods\n(Figure 7.3). Each class holds only the source code necessary for its particular function. The three\nclasses are not allowed to know about each other. Thus any accidental duplication is avoided. Figure 7.3 The three classes do not know about each other\nThe downside of this solution is that the developers now have three classes that they have to\ninstantiate and track. A common solution to this dilemma is to use the Facade pattern (Figure 7.4).", "domains": ["Design Patterns"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 67", "position": 67, "chunk_type": "semantic", "token_estimate": 124}
{"text": "Figure 7.4 The Facade pattern: The EmployeeFacade contains very little code. It is responsible for instantiating and delegating to the\nclasses with the functions. Some developers prefer to keep the most important business rules closer to the data. This can be done\nby keeping the most important method in the original Employee class and then using that class as a\nFacade for the lesser functions (Figure 7.5). Figure 7.5 The most important method is kept in the original Employee class and used as a Facade for the lesser functions\nYou might object to these solutions on the basis that every class would contain just one function. This\nis hardly the case. The number of functions required to calculate pay, generate a report, or save the\ndata is likely to be large in each case. Each of those classes would have many private methods in\nthem. Each of the classes that contain such a family of methods is a scope. Outside of that scope, no one\nknows that the private members of the family exist.", "domains": ["Design Patterns"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 68", "position": 68, "chunk_type": "semantic", "token_estimate": 174}
{"text": "8: OCP: THE OPEN-CLOSED PRINCIPLE\nThe Open-Closed Principle (OCP) was coined in 1988 by Bertrand Meyer.1 It says:\nA software artifact should be open for extension but closed for modification. In other words, the behavior of a software artifact ought to be extendible, without having to modify\nthat artifact. This, of course, is the most fundamental reason that we study software architecture. Clearly, if simple\nextensions to the requirements force massive changes to the software, then the architects of that\nsoftware system have engaged in a spectacular failure. Most students of software design recognize the OCP as a principle that guides them in the design of\nclasses and modules. But the principle takes on even greater significance when we consider the level\nof architectural components. A thought experiment will make this clear.", "domains": ["Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 70", "position": 70, "chunk_type": "semantic", "token_estimate": 132}
{"text": "Now imagine that the stakeholders ask that this same information be turned into a report to be printed: on a black-and-white printer. The report should be properly paginated, with appropriate page\nheaders, page footers, and column labels. Negative numbers should be surrounded by parentheses. Clearly, some new code must be written. But how much old code will have to change? A good software architecture would reduce the amount of changed code to the barest minimum. Ideally, zero. How? By properly separating the things that change for different reasons (the Single Responsibility\nPrinciple), and then organizing the dependencies between those things properly (the Dependency\nInversion Principle). By applying the SRP, we might come up with the data-flow view shown in Figure 8.1. Some analysis\nprocedure inspects the financial data and produces reportable data, which is then formatted\nappropriately by the two reporter processes. Figure 8.1 Applying the SRP\nThe essential insight here is that generating the report involves two separate responsibilities: the\ncalculation of the reported data, and the presentation of that data into a web- and printer-friendly\nform. Having made this separation, we need to organize the source code dependencies to ensure that\nchanges to one of those responsibilities do not cause changes in the other. Also, the new organization\nshould ensure that the behavior can be extended without undo modification. We accomplish this by partitioning the processes into classes, and separating those classes into\ncomponents, as shown by the double lines in the diagram in Figure 8.2. In this figure, the component\nat the upper left is the Controller. At the upper right, we have the Interactor. At the lower right, there\nis the Database. Finally, at the lower left, there are four components that represent the Presenters and\nthe Views.", "domains": ["Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 71", "position": 71, "chunk_type": "semantic", "token_estimate": 292}
{"text": "Figure 8.2 Partitioning the processes into classes and separating the classes into components: Classes marked with <I> are interfaces; those marked with <DS> are data structures. Open\narrowheads are using relationships. Closed arrowheads are implements or inheritance relationships. The first thing to notice is that all the dependencies are source code dependencies. An arrow pointing\nfrom class A to class B means that the source code of class A mentions the name of class B, but class\nB mentions nothing about class A. Thus, in Figure 8.2, FinancialDataMapper knows about\nFinancialDataGateway through an implements relationship, but FinancialGateway knows nothing\nat all about FinancialDataMapper. The next thing to notice is that each double line is crossed in one direction only. This means that all\ncomponent relationships are unidirectional, as shown in the component graph in Figure 8.3. These\narrows point toward the components that we want to protect from change.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 72", "position": 72, "chunk_type": "semantic", "token_estimate": 149}
{"text": "Figure 8.3 The component relationships are unidirectional: Let me say that again: If component A should be protected from changes in component B, then\ncomponent B should depend on component A. We want to protect the Controller from changes in the Presenters. We want to protect the Presenters\nfrom changes in the Views. We want to protect the Interactor from changes in\u2014well, anything. The Interactor is in the position that best conforms to the OCP. Changes to the Database, or the\nController, or the Presenters, or the Views, will have no impact on the Interactor. Why should the Interactor hold such a privileged position? Because it contains the business rules. The Interactor contains the highest-level policies of the application. All the other components are\ndealing with peripheral concerns. The Interactor deals with the central concern. Even though the Controller is peripheral to the Interactor, it is nevertheless central to the Presenters\nand Views. And while the Presenters might be peripheral to the Controller, they are central to the\nViews. Notice how this creates a hierarchy of protection based on the notion of \u201clevel.\u201d Interactors are the\nhighest-level concept, so they are the most protected. Views are among the lowest-level concepts, so\nthey are the least protected. Presenters are higher level than Views, but lower level than the\nController or the Interactor. This is how the OCP works at the architectural level. Architects separate functionality based on how,\nwhy, and when it changes, and then organize that separated functionality into a hierarchy of\ncomponents. Higher-level components in that hierarchy are protected from the changes made to\nlower-level components.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 73", "position": 73, "chunk_type": "semantic", "token_estimate": 267}
{"text": "that diagram was intended to make sure that the dependencies between the components pointed in the: correct direction. For example, the FinancialDataGateway interface between the FinancialReportGenerator and\nthe FinancialDataMapper exists to invert the dependency that would otherwise have pointed from\nthe Interactor component to the Database component. The same is true of the\nFinancialReportPresenter interface, and the two View interfaces.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 74", "position": 74, "chunk_type": "semantic", "token_estimate": 60}
{"text": "The FinancialReportRequester interface serves a different purpose. It is there to protect the: FinancialReportController from knowing too much about the internals of the Interactor. If that\ninterface were not there, then the Controller would have transitive dependencies on the\nFinancialEntities. Transitive dependencies are a violation of the general principle that software entities should not\ndepend on things they don\u2019t directly use. We\u2019ll encounter that principle again when we talk about the\nInterface Segregation Principle and the Common Reuse Principle. So, even though our first priority is to protect the Interactor from changes to the Controller, we also\nwant to protect the Controller from changes to the Interactor by hiding the internals of the Interactor.", "domains": ["Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 74", "position": 74, "chunk_type": "semantic", "token_estimate": 114}
{"text": "9: LSP: THE LISKOV SUBSTITUTION PRINCIPLE\nIn 1988, Barbara Liskov wrote the following as a way of defining subtypes. What is wanted here is something like the following substitution property: If for each object o1 of type S there is an\nobject o2 of type T such that for all programs P defined in terms of T, the behavior of P is unchanged when o1 is\nsubstituted for o2 then S is a subtype of T.1\nTo understand this idea, which is known as the Liskov Substitution Principle (LSP), let\u2019s look at some\nexamples.", "domains": ["Design Principles"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 75", "position": 75, "chunk_type": "semantic", "token_estimate": 94}
{"text": "In the early years of the object-oriented revolution, we thought of the LSP as a way to guide the use of: inheritance, as shown in the previous sections. However, over the years the LSP has morphed into a\nbroader principle of software design that pertains to interfaces and implementations. The interfaces in question can be of many forms. We might have a Java-style interface, implemented\nby several classes. Or we might have several Ruby classes that share the same method signatures. Or\nwe might have a set of services that all respond to the same REST interface. In all of these situations, and more, the LSP is applicable because there are users who depend on\nwell-defined interfaces, and on the substitutability of the implementations of those interfaces. The best way to understand the LSP from an architectural viewpoint is to look at what happens to the\narchitecture of a system when the principle is violated.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 77", "position": 77, "chunk_type": "semantic", "token_estimate": 155}
{"text": "purplecab.com/driver/Bob: Our system will append the dispatch information onto this URI and send it with a PUT, as follows:\nClick here to view code image\npurplecab.com/driver/Bob \n       /pickupAddress/24 Maple St.\n       /pickupTime/153\n       /destination/ORD\nClearly, this means that all the dispatch services, for all the different companies, must conform to the\nsame REST interface. They must treat the pickupAddress, pickupTime, and destination fields\nidentically. Now suppose the Acme taxi company hired some programmers who didn\u2019t read the spec very\ncarefully. They abbreviated the destination field to just dest. Acme is the largest taxi company in our\narea, and Acme\u2019s CEO\u2019s ex-wife is our CEO\u2019s new wife, and \u2026 Well, you get the picture. What\nwould happen to the architecture of our system? Obviously, we would need to add a special case. The dispatch request for any Acme driver would\nhave to be constructed using a different set of rules from all the other drivers. The simplest way to accomplish this goal would be to add an if statement to the module that\nconstructed the dispatch command:\nClick here to view code image\nif (driver.getDispatchUri().startsWith(\"acme.com\"))\u2026\nBut, of course, no architect worth his or her salt would allow such a construction to exist in the\nsystem. Putting the word \u201cacme\u201d into the code itself creates an opportunity for all kinds of horrible\nand mysterious errors, not to mention security breaches. For example, what if Acme became even more successful and bought the Purple Taxi company. What\nif the merged company maintained the separate brands and the separate websites, but unified all of the\noriginal companies\u2019 systems? Would we have to add another if statement for \u201cpurple\u201d? Our architect would have to insulate the system from bugs like this by creating some kind of dispatch\ncommand creation module that was driven by a configuration database keyed by the dispatch URI. The configuration data might look something like this:\nClick here to view code image", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 78", "position": 78, "chunk_type": "semantic", "token_estimate": 318}
{"text": "10: ISP: THE INTERFACE SEGREGATION PRINCIPLE\nThe Interface Segregation Principle (ISP) derives its name from the diagram shown in Figure 10.1. Figure 10.1 The Interface Segregation Principle\nIn the situation illustrated in Figure 10.1, there are several users who use the operations of the OPS\nclass. Let\u2019s assume that User1 uses only op1, User2 uses only op2, and User3 uses only op3. Now imagine that OPS is a class written in a language like Java. Clearly, in that case, the source code", "domains": ["Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 80", "position": 80, "chunk_type": "semantic", "token_estimate": 82}
{"text": "The lesson here is that depending on something that carries baggage that you don\u2019t need can cause you: troubles that you didn\u2019t expect. We\u2019ll explore this idea in more detail when we discuss the Common Reuse Principle in Chapter 13,\n\u201cComponent Cohesion.\u201d", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 82", "position": 82, "chunk_type": "semantic", "token_estimate": 42}
{"text": "11: DIP: THE DEPENDENCY INVERSION PRINCIPLE\nThe Dependency Inversion Principle (DIP) tells us that the most flexible systems are those in which\nsource code dependencies refer only to abstractions, not to concretions. In a statically typed language, like Java, this means that the use, import, and include statements\nshould refer only to source modules containing interfaces, abstract classes, or some other kind of\nabstract declaration. Nothing concrete should be depended on. The same rule applies for dynamically typed languages, like Ruby and Python. Source code\ndependencies should not refer to concrete modules. However, in these languages it is a bit harder to\ndefine what a concrete module is. In particular, it is any module in which the functions being called\nare implemented. Clearly, treating this idea as a rule is unrealistic, because software systems must depend on many\nconcrete facilities. For example, the String class in Java is concrete, and it would be unrealistic to\ntry to force it to be abstract. The source code dependency on the concrete java.lang.string cannot,\nand should not, be avoided. By comparison, the String class is very stable. Changes to that class are very rare and tightly\ncontrolled. Programmers and architects do not have to worry about frequent and capricious changes\nto String. For these reasons, we tend to ignore the stable background of operating system and platform facilities", "domains": ["Design Patterns", "Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 83", "position": 83, "chunk_type": "semantic", "token_estimate": 225}
{"text": "Every change to an abstract interface corresponds to a change to its concrete implementations.: Conversely, changes to concrete implementations do not always, or even usually, require changes to\nthe interfaces that they implement. Therefore interfaces are less volatile than implementations. Indeed, good software designers and architects work hard to reduce the volatility of interfaces. They\ntry to find ways to add functionality to implementations without making changes to the interfaces. This\nis Software Design 101. The implication, then, is that stable software architectures are those that avoid depending on volatile\nconcretions, and that favor the use of stable abstract interfaces. This implication boils down to a set\nof very specific coding practices:\n\u2022 Don\u2019t refer to volatile concrete classes. Refer to abstract interfaces instead. This rule applies in\nall languages, whether statically or dynamically typed. It also puts severe constraints on the creation\nof objects and generally enforces the use of Abstract Factories. \u2022 Don\u2019t derive from volatile concrete classes. This is a corollary to the previous rule, but it bears\nspecial mention. In statically typed languages, inheritance is the strongest, and most rigid, of all the\nsource code relationships; consequently, it should be used with great care. In dynamically typed\nlanguages, inheritance is less of a problem, but it is still a dependency\u2014and caution is always the\nwisest choice. \u2022 Don\u2019t override concrete functions. Concrete functions often require source code dependencies. When you override those functions, you do not eliminate those dependencies\u2014indeed, you inherit\nthem. To manage those dependencies, you should make the function abstract and create multiple\nimplementations. \u2022 Never mention the name of anything concrete and volatile. This is really just a restatement of\nthe principle itself.", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 84", "position": 84, "chunk_type": "semantic", "token_estimate": 280}
{"text": "To comply with these rules, the creation of volatile concrete objects requires special handling. This: caution is warranted because, in virtually all languages, the creation of an object requires a source\ncode dependency on the concrete definition of that object. In most object-oriented languages, such as Java, we would use an Abstract Factory to manage this\nundesirable dependency.", "domains": ["Design Patterns", "Domain-Driven Design"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 84", "position": 84, "chunk_type": "semantic", "token_estimate": 58}
{"text": "The diagram in Figure 11.1 shows the structure. The Application uses the ConcreteImpl through: the Service interface. However, the Application must somehow create instances of the\nConcreteImpl. To achieve this without creating a source code dependency on the ConcreteImpl, the\nApplication calls the makeSvc method of the ServiceFactory interface. This method is\nimplemented by the ServiceFactoryImpl class, which derives from ServiceFactory. That\nimplementation instantiates the ConcreteImpl and returns it as a Service. Figure 11.1 Use of the Abstract Factory pattern to manage the dependency\nThe curved line in Figure 11.1 is an architectural boundary. It separates the abstract from the\nconcrete. All source code dependencies cross that curved line pointing in the same direction, toward\nthe abstract side. The curved line divides the system into two components: one abstract and the other concrete. The\nabstract component contains all the high-level business rules of the application. The concrete\ncomponent contains all the implementation details that those business rules manipulate. Note that the flow of control crosses the curved line in the opposite direction of the source code\ndependencies. The source code dependencies are inverted against the flow of control\u2014which is why\nwe refer to this principle as Dependency Inversion.", "domains": ["Design Patterns", "Design Principles", "Domain-Driven Design", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 85", "position": 85, "chunk_type": "semantic", "token_estimate": 198}
{"text": "The concrete component in Figure 11.1 contains a single dependency, so it violates the DIP. This is: typical. DIP violations cannot be entirely removed, but they can be gathered into a small number of\nconcrete components and kept separate from the rest of the system. Most systems will contain at least one such concrete component\u2014often called main because it\ncontains the main1 function. In the case illustrated in Figure 11.1, the main function would instantiate\nthe ServiceFactoryImpl and place that instance in a global variable of type ServiceFactory. The\nApplication would then access the factory through that global variable.", "domains": ["Design Patterns", "Domain-Driven Design", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 85", "position": 85, "chunk_type": "semantic", "token_estimate": 99}
{"text": "If the SOLID principles tell us how to arrange the bricks into walls and rooms, then the component: principles tell us how to arrange the rooms into buildings. Large software systems, like large\nbuildings, are built out of smaller components. In Part IV, we will discuss what software components are, which elements should compose them, and\nhow they should be composed together into systems.", "domains": ["Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 87", "position": 87, "chunk_type": "semantic", "token_estimate": 64}
{"text": "Click here to view code image: *200\n                TLS\n     START,     CLA\n                TAD BUFR\n                JMS GETSTR\n                CLA\n                TAD BUFR\n                JMS PUTSTR\n                JMP START\n     BUFR,      3000\n \n     GETSTR,    0\n                DCA PTR\n     NXTCH,     KSF\n                JMP -1\n                KRB\n                DCA I PTR\n                TAD I PTR\n                AND K177\n                ISZ PTR\n                TAD MCR\n                SZA\n                JMP NXTCH\n \n     K177,      177\n     MCR,       -15\nNote the *200 command at the start of this program. It tells the compiler to generate code that will be\nloaded at address 2008. This kind of programming is a foreign concept for most programmers today. They rarely have to think\nabout where a program is loaded in the memory of the computer. But in the early days, this was one of\nthe first decisions a programmer needed to make. In those days, programs were not relocatable. How did you access a library function in those olden days? The preceding code illustrates the\napproach used. Programmers included the source code of the library functions with their application\ncode, and compiled them all as a single program.1 Libraries were kept in source, not in binary. The problem with this approach was that, during this era, devices were slow and memory was\nexpensive and, therefore, limited. Compilers needed to make several passes over the source code, but\nmemory was too limited to keep all the source code resident. Consequently, the compiler had to read\nin the source code several times using the slow devices. This took a long time\u2014and the larger your function library, the longer the compiler took. Compiling a\nlarge program could take hours. To shorten the compile times, programmers separated the source code of the function library from the\napplications. They compiled the function library separately and loaded the binary at a known address\n\u2014say, 20008. They created a symbol table for the function library and compiled that with their\napplication code. When they wanted to run an application, they would load the binary function", "domains": ["Design Patterns"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 89", "position": 89, "chunk_type": "semantic", "token_estimate": 317}
{"text": "The linking loader allowed programmers to divide their programs up onto separately compilable and: loadable segments. This worked well when relatively small programs were being linked with\nrelatively small libraries. However, in the late 1960s and early 1970s, programmers got more\nambitious, and their programs got a lot bigger. Eventually, the linking loaders were too slow to tolerate. Function libraries were stored on slow\ndevices such a magnetic tape. Even the disks, back then, were quite slow. Using these relatively slow\ndevices, the linking loaders had to read dozens, if not hundreds, of binary libraries to resolve the\nexternal references. As programs grew larger and larger, and more library functions accumulated in\nlibraries, a linking loader could take more than an hour just to load the program. Eventually, the loading and the linking were separated into two phases. Programmers took the slow\npart\u2014the part that did that linking\u2014and put it into a separate application called the linker. The output\nof the linker was a linked relocatable that a relocating loader could load very quickly. This allowed\nprogrammers to prepare an executable using the slow linker, but then they could load it quickly, at any\ntime. Then came the 1980s. Programmers were working in C or some other high-level language. As their\nambitions grew, so did their programs. Programs that numbered hundreds of thousands of lines of\ncode were not unusual. Source modules were compiled from .c files into .o files, and then fed into the linker to create\nexecutable files that could be quickly loaded. Compiling each individual module was relatively fast,\nbut compiling all the modules took a bit of time. The linker would then take even more time.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 91", "position": 91, "chunk_type": "semantic", "token_estimate": 280}
{"text": "Turnaround had again grown to an hour or more in many cases.: It seemed as if programmers were doomed to endlessly chase their tails. Throughout the 1960s,\n1970s, and 1980s, all the changes made to speed up workflow were thwarted by programmers\u2019\nambitions, and the size of the programs they wrote. They could not seem to escape from the hour-long\nturnaround times. Loading time remained fast, but compile-link times were the bottleneck. We were, of course, experiencing Murphy\u2019s law of program size:\nPrograms will grow to fill all available compile and link time. But Murphy was not the only contender in town. Along came Moore,3 and in the late 1980s, the two\nbattled it out. Moore won that battle. Disks started to shrink and got significantly faster. Computer\nmemory started to get so ridiculously cheap that much of the data on disk could be cached in RAM. Computer clock rates increased from 1 MHz to 100 MHz. By the mid-1990s, the time spent linking had begun to shrink faster than our ambitions could make\nprograms grow. In many cases, link time decreased to a matter of seconds. For small jobs, the idea of\na linking loader became feasible again. This was the era of Active-X, shared libraries, and the beginnings of .jar files. Computers and\ndevices had gotten so fast that we could, once again, do the linking at load time. We could link\ntogether several .jar files, or several shared libraries in a matter of seconds, and execute the\nresulting program. And so the component plugin architecture was born. Today we routinely ship .jar files or DLLs or shared libraries as plugins to existing applications. If\nyou want to create a mod to Minecraft, for example, you simply include your custom .jar files in a\ncertain folder. If you want to plug Resharper into Visual Studio, you simply include the appropriate\nDLLs.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 92", "position": 92, "chunk_type": "semantic", "token_estimate": 313}
{"text": "These dynamically linked files, which can be plugged together at runtime, are the software: components of our architectures. It has taken 50 years, but we have arrived at a place where\ncomponent plugin architecture can be the casual default as opposed to the herculean effort it once\nwas. 1. My first employer kept several dozen decks of the subroutine library source code on a shelf. When you wrote a new program, you\nsimply grabbed one of those decks and slapped it onto the end of your deck. 2. Actually, most of those old machines used core memory, which did not get erased when you powered the computer down. We often\nleft the function library loaded for days at a time. 3. Moore\u2019s law: Computer speed, memory, and density double every 18 months. This law held from the 1950s to 2000, but then, at least\nfor clock rates, stopped cold.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 92", "position": 92, "chunk_type": "semantic", "token_estimate": 149}
{"text": "Which classes belong in which components? This is an important decision, and requires guidance: from good software engineering principles. Unfortunately, over the years, this decision has been made\nin an ad hoc manner based almost entirely on context. In this chapter we will discuss the three principles of component cohesion:\n\u2022 REP: The Reuse/Release Equivalence Principle\n\u2022 CCP: The Common Closure Principle\n\u2022 CRP: The Common Reuse Principle\nTHE REUSE/RELEASE EQUIV", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 93", "position": 93, "chunk_type": "semantic", "token_estimate": 71}
{"text": "The granule of reuse is the granule of release.: The last decade has seen the rise of a menagerie of module management tools, such as Maven,\nLeiningen, and RVM. These tools have grown in importance because, during that time, a vast number\nof reusable components and component libraries have been created. We are now living in the age of\nsoftware reuse\u2014a fulfillment of one of the oldest promises of the object-oriented model. The Reuse/Release Equivalence Principle (REP) is a principle that seems obvious, at least in\nhindsight. People who want to reuse software components cannot, and will not, do so unless those", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 93", "position": 93, "chunk_type": "semantic", "token_estimate": 102}
{"text": "components are tracked through a release process and are given release numbers.: This is not simply because, without release numbers, there would be no way to ensure that all the\nreused components are compatible with each other. Rather, it also reflects the fact that software\ndevelopers need to know when new releases are coming, and which changes those new releases will\nbring. It is not uncommon for developers to be alerted about a new release and decide, based on the changes\nmade in that release, to continue to use the old release instead. Therefore the release process must\nproduce the appropriate notifications and release documentation so that users can make informed\ndecisions about when and whether to integrate the new release. From a software design and architecture point of view, this principle means that the classes and\nmodules that are formed into a component must belong to a cohesive group. The component cannot\nsimply consist of a random hodgepodge of classes and modules; instead, there must be some\noverarching theme or purpose that those modules all share. Of course, this should be obvious. However, there is another way to look at this issue that is perhaps\nnot quite so obvious. Classes and modules that are grouped together into a component should be\nreleasable together. The fact that they share the same version number and the same release tracking,\nand are included under the same release documentation, should make sense both to the author and to\nthe users. This is weak advice: Saying that something should \u201cmake sense\u201d is just a way of waving your hands\nin the air and trying to sound authoritative. The advice is weak because it is hard to precisely explain\nthe glue that holds the classes and modules together into a single component. Weak though the advice\nmay be, the principle itself is important, because violations are easy to detect\u2014they don\u2019t \u201cmake\nsense.\u201d If you violate the REP, your users will know, and they won\u2019t be impressed with your\narchitectural skills. The weakness of this principle is more than compensated for by the strength of the next two\nprinciples. Indeed, the CCP and the CRP strongly define the this principle, but in a negative sense.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 94", "position": 94, "chunk_type": "semantic", "token_estimate": 369}
{"text": "Gather into components those classes that change for the same reasons and at the same times. Separate into different: components those classes that change at different times and for different reasons. This is the Single Responsibility Principle restated for components. Just as the SRP says that a class\nshould not contain multiples reasons to change, so the Common Closure Principle (CCP) says that a\ncomponent should not have multiple reasons to change. For most applications, maintainability is more important than reusability. If the code in an application\nmust change, you would rather that all of the changes occur in one component, rather than being\ndistributed across many components.1 If changes are confined to a single component, then we need to\nredeploy only the one changed component. Other components that don\u2019t depend on the changed", "domains": ["Design Patterns", "Design Principles", "Software Quality Attributes", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 94", "position": 94, "chunk_type": "semantic", "token_estimate": 134}
{"text": "component do not need to be revalidated or redeployed.: The CCP prompts us to gather together in one place all the classes that are likely to change for the\nsame reasons. If two classes are so tightly bound, either physically or conceptually, that they always\nchange together, then they belong in the same component. This minimizes the workload related to\nreleasing, revalidating, and redeploying the software. This principle is closely associated with the Open Closed Principle (OCP). Indeed, it is \u201cclosure\u201d in\nthe OCP sense of the word that the CCP addresses. The OCP states that classes should be closed for\nmodification but open for extension. Because 100% closure is not attainable, closure must be\nstrategic. We design our classes such that they are closed to the most common kinds of changes that\nwe expect or have experienced. The CCP amplifies this lesson by gathering together into the same component those classes that are\nclosed to the same types of changes. Thus, when a change in requirements comes along, that change\nhas a good chance of being restricted to a minimal number of components.", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 95", "position": 95, "chunk_type": "semantic", "token_estimate": 184}
{"text": "As stated earlier, the CCP is the component form of the SRP. The SRP tells us to separate methods: into different classes, if they change for different reasons. The CCP tells us to separate classes into\ndifferent components, if they change for different reasons. Both principles can be summarized by the\nfollowing sound bite:\nGather together those things that change at the same times and for the same reasons. Separate those things that\nchange at different times or for different reasons.", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 95", "position": 95, "chunk_type": "semantic", "token_estimate": 81}
{"text": "Don\u2019t force users of a component to depend on things they don\u2019t need.: The Common Reuse Principle (CRP) is yet another principle that helps us to decide which classes\nand modules should be placed into a component. It states that classes and modules that tend to be\nreused together belong in the same component. Classes are seldom reused in isolation. More typically, reusable classes collaborate with other\nclasses that are part of the reusable abstraction. The CRP states that these classes belong together in\nthe same component. In such a component we would expect to see classes that have lots of\ndependencies on each other. A simple example might be a container class and its associated iterators. These classes are reused\ntogether because they are tightly coupled to each other. Thus they ought to be in the same component. But the CRP tells us more than just which classes to put together into a component: It also tells us\nwhich classes not to keep together in a component. When one component uses another, a dependency\nis created between the components. Perhaps the using component uses only one class within the used", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 95", "position": 95, "chunk_type": "semantic", "token_estimate": 191}
{"text": "component\u2014but that still doesn\u2019t weaken the dependency. The using component still depends on the: used component. Because of that dependency, every time the used component is changed, the using component will\nlikely need corresponding changes. Even if no changes are necessary to the using component, it will\nlikely still need to be recompiled, revalidated, and redeployed. This is true even if the using\ncomponent doesn\u2019t care about the change made in the used component. Thus when we depend on a component, we want to make sure we depend on every class in that\ncomponent. Put another way, we want to make sure that the classes that we put into a component are\ninseparable\u2014that it is impossible to depend on some and not on the others. Otherwise, we will be\nredeploying more components than is necessary, and wasting significant effort. Therefore the CRP tells us more about which classes shouldn\u2019t be together than about which classes\nshould be together. The CRP says that classes that are not tightly bound to each other should not be in\nthe same component.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 96", "position": 96, "chunk_type": "semantic", "token_estimate": 178}
{"text": "Figure 13.1 Cohesion principles tension diagram: An architect who focuses on just the REP and CRP will find that too many components are impacted\nwhen simple changes are made. In contrast, an architect who focuses too strongly on the CCP and\nREP will cause too many unneeded releases to be generated. A good architect finds a position in that tension triangle that meets the current concerns of the\ndevelopment team, but is also aware that those concerns will change over time. For example, early in\nthe development of a project, the CCP is much more important than the REP, because develop-ability\nis more important than reuse. Generally, projects tend to start on the right hand side of the triangle, where the only sacrifice is\nreuse. As the project matures, and other projects begin to draw from it, the project will slide over to\nthe left. This means that the component structure of a project can vary with time and maturity. It has\nmore to do with the way that project is developed and used, than with what the project actually does.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 97", "position": 97, "chunk_type": "semantic", "token_estimate": 181}
{"text": "In the past, our view of cohesion was much simpler than the REP, CCP, and CRP implied. We once: thought that cohesion was simply the attribute that a module performs one, and only one, function. However, the three principles of component cohesion describe a much more complex variety of\ncohesion. In choosing the classes to group together into components, we must consider the opposing\nforces involved in reusability and develop-ability. Balancing these forces with the needs of the\napplication is nontrivial. Moreover, the balance is almost always dynamic. That is, the partitioning\nthat is appropriate today might not be appropriate next year. As a consequence, the composition of the\ncomponents will likely jitter and evolve with time as the focus of the project changes from develop-\nability to reusability. 1. See the section on \u201cThe Kitty Problem\u201d in Chapter 27, \u201cServices: Great and Small.\u201c\n2. Thanks to Tim Ottinger for this idea.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 97", "position": 97, "chunk_type": "semantic", "token_estimate": 152}
{"text": "The next three principles deal with the relationships between components. Here again we will run: into the tension between develop-ability and logical design. The forces that impinge upon the\narchitecture of a component structure are technical, political, and volatile.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 98", "position": 98, "chunk_type": "semantic", "token_estimate": 39}
{"text": "Allow no cycles in the component dependency graph.: Have you ever worked all day, gotten some stuff working, and then gone home, only to arrive the next\nmorning to find that your stuff no longer works? Why doesn\u2019t it work? Because somebody stayed later\nthan you and changed something you depend on! I call this \u201cthe morning after syndrome.\u201d\nThe \u201cmorning after syndrome\u201d occurs in development environments where many developers are\nmodifying the same source files. In relatively small projects with just a few developers, it isn\u2019t too\nbig a problem. But as the size of the project and the development team grow, the mornings after can\nget pretty nightmarish. It is not uncommon for weeks to go by without the team being able to build a\nstable version of the project. Instead, everyone keeps on changing and changing their code trying to\nmake it work with the last changes that someone else made. Over the last several decades, two solutions to this problem have evolved, both of which came from\nthe telecommunications industry. The first is \u201cthe weekly build,\u201d and the second is the Acyclic", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 98", "position": 98, "chunk_type": "semantic", "token_estimate": 186}
{"text": "The solution to this problem is to partition the development environment into releasable components.: The components become units of work that can be the responsibility of a single developer, or a team\nof developers. When developers get a component working, they release it for use by the other\ndevelopers. They give it a release number and move it into a directory for other teams to use. They\nthen continue to modify their component in their own private areas. Everyone else uses the released\nversion. As new releases of a component are made available, other teams can decide whether they will\nimmediately adopt the new release. If they decide not to, they simply continue using the old release. Once they decide that they are ready, they begin to use the new release. Thus no team is at the mercy of the others. Changes made to one component do not need to have an\nimmediate affect on other teams. Each team can decide for itself when to adapt its own components to\nnew releases of the components. Moreover, integration happens in small increments. There is no\nsingle point in time when all developers must come together and integrate everything they are doing. This is a very simple and rational process, and it is widely used. To make it work successfully,", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 99", "position": 99, "chunk_type": "semantic", "token_estimate": 218}
{"text": "however, you must manage the dependency structure of the components. There can be no cycles. If: there are cycles in the dependency structure, then the \u201cmorning after syndrome\u201d cannot be avoided. Consider the component diagram in Figure 14.1. It shows a rather typical structure of components\nassembled into an application. The function of this application is unimportant for the purpose of this\nexample. What is important is the dependency structure of the components. Notice that this structure is\na directed graph. The components are the nodes, and the dependency relationships are the directed\nedges. Figure 14.1 Typical component diagram\nNotice one more thing: Regardless of which component you begin at, it is impossible to follow the\ndependency relationships and wind up back at that component. This structure has no cycles. It is a\ndirected acyclic graph (DAG). Now consider what happens when the team responsible for Presenters makes a new release of their\ncomponent. It is easy to find out who is affected by this release; you just follow the dependency\narrows backward. Thus View and Main will both be affected. The developers currently working on\nthose components will have to decide when they should integrate their work with the new release of\nPresenters. Notice also that when Main is released, it has utterly no effect on any of the other components in the\nsystem. They don\u2019t know about Main, and they don\u2019t care when it changes. This is nice. It means that\nthe impact of releasing Main is relatively small. When the developers working on the Presenters component would like to run a test of that\ncomponent, they just need to build their version of Presenters with the versions of the Interactors\nand Entities components that they are currently using. None of the other components in the system\nneed be involved. This is nice. It means that the developers working on Presenters have relatively\nlittle work to do to set up a test, and that they have relatively few variables to consider. When it is time to release the whole system, the process proceeds from the bottom up. First the\nEntities component is compiled, tested, and released. Then the same is done for Database and", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 100", "position": 100, "chunk_type": "semantic", "token_estimate": 366}
{"text": "Suppose that a new requirement forces us to change one of the classes in Entities such that it makes: use of a class in Authorizer. For example, let\u2019s say that the User class in Entities uses the\nPermissions class in Authorizer. This creates a dependency cycle, as shown in Figure 14.2. This cycle creates some immediate problems. For example, the developers working on the Database\ncomponent know that to release it, the component must be compatible with Entities. However, with\nthe cycle in place, the Database component must now also be compatible with Authorizer. But\nAuthorizer depends on Interactors. This makes Database much more difficult to release. Entities, Authorizer, and Interactors have, in effect, become one large component\u2014which\nmeans that all of the developers working on any of those components will experience the dreaded\n\u201cmorning after syndrome.\u201d They will be stepping all over one another because they must all use\nexactly the same release of one another\u2019s components. Figure 14.2 A dependency cycle\nBut this is just part of the trouble. Consider what happens when we want to test the Entities\ncomponent. To our chagrin, we find that we must build and integrate with Authorizer and\nInteractors. This level of coupling between components is troubling, if not intolerable. You may have wondered why you have to include so many different libraries, and so much of\neverybody else\u2019s stuff, just to run a simple unit test of one of your classes. If you investigate the matter\na bit, you will probably discover that there are cycles in the dependency graph. Such cycles make it\nvery difficult to isolate components. Unit testing and releasing become very difficult and error prone. In addition, build issues grow geometrically with the number of modules. Moreover, when there are cycles in the dependency graph, it can be very difficult to work out the", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 101", "position": 101, "chunk_type": "semantic", "token_estimate": 307}
{"text": "It is always possible to break a cycle of components and reinstate the dependency graph as a DAG.: There are two primary mechanisms for doing so:\n1. Apply the Dependency Inversion Principle (DIP). In the case in Figure 14.3, we could create an\ninterface that has the methods that User needs. We could then put that interface into Entities and\ninherit it into Authorizer. This inverts the dependency between Entities and Authorizer,\nthereby breaking the cycle.", "domains": ["Design Patterns", "Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 102", "position": 102, "chunk_type": "semantic", "token_estimate": 76}
{"text": "Figure 14.3 Inverting the dependency between Entities and Authorizer: 2. Create a new component that both Entities and Authorizer depend on. Move the class(es) that\nthey both depend on into that new component (Figure 14.4). Figure 14.4 The new component that both Entities and Authorizer depend on\nTHE \u201cJITTERS\u201d\nThe second solution implies that the component structure is volatile in the presence of changing\nrequirements. Indeed, as the application grows, the component dependency structure jitters and\ngrows. Thus the dependency structure must always be monitored for cycles. When cycles occur, they\nmust be broken somehow. Sometimes this will mean creating new components, making the\ndependency structure grow. TOP-DOWN DESIGN\nThe issues we have discussed so far lead to an inescapable conclusion: The component structure", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 103", "position": 103, "chunk_type": "semantic", "token_estimate": 124}
{"text": "cannot be designed from the top down. It is not one of the first things about the system that is: designed, but rather evolves as the system grows and changes. Some readers may find this point to be counterintuitive. We have come to expect that large-grained\ndecompositions, like components, will also be high-level functional decompositions. When we see a large-grained grouping such as a component dependency structure, we believe that the\ncomponents ought to somehow represent the functions of the system. Yet this does not seem to be an\nattribute of component dependency diagrams. In fact, component dependency diagrams have very little do to with describing the function of the\napplication. Instead, they are a map to the buildability and maintainability of the application. This is\nwhy they aren\u2019t designed at the beginning of the project. There is no software to build or maintain, so\nthere is no need for a build and maintenance map. But as more and more modules accumulate in the\nearly stages of implementation and design, there is a growing need to manage the dependencies so that\nthe project can be developed without the \u201cmorning after syndrome.\u201d Moreover, we want to keep\nchanges as localized as possible, so we start paying attention to the SRP and CCP and collocate\nclasses that are likely to change together. One of the overriding concerns with this dependency structure is the isolation of volatility. We don\u2019t\nwant components that change frequently and for capricious reasons to affect components that\notherwise ought to be stable. For example, we don\u2019t want cosmetic changes to the GUI to have an\nimpact on our business rules. We don\u2019t want the addition or modification of reports to have an impact\non our highest-level policies. Consequently, the component dependency graph is created and molded\nby architects to protect stable high-value components from volatile components. As the application continues to grow, we start to become concerned about creating reusable elements. At this point, the CRP begins to influence the composition of the components. Finally, as cycles\nappear, the ADP is applied and the component dependency graph jitters and grows. If we tried to design the component dependency structure before we designed any classes, we would\nlikely fail rather badly. We would not know much about common closure, we would be unaware of\nany reusable elements, and we would almost certainly create components that produced dependency\ncycles. Thus the component dependency structure grows and evolves with the logical design of the\nsystem.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 104", "position": 104, "chunk_type": "semantic", "token_estimate": 414}
{"text": "Depend in the direction of stability.: Designs cannot be completely static. Some volatility is necessary if the design is to be maintained. By\nconforming to the Common Closure Principle (CCP), we create components that are sensitive to\ncertain kinds of changes but immune to others. Some of these components are designed to be volatile. We expect them to change. Any component that we expect to be volatile should not be depended on by a component that is", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 104", "position": 104, "chunk_type": "semantic", "token_estimate": 77}
{"text": "difficult to change. Otherwise, the volatile component will also be difficult to change.: It is the perversity of software that a module that you have designed to be easy to change can be made\ndifficult to change by someone else who simply hangs a dependency on it. Not a line of source code\nin your module need change, yet your module will suddenly become more challenging to change. By\nconforming to the Stable Dependencies Principle (SDP), we ensure that modules that are intended to\nbe easy to change are not depended on by modules that are harder to change.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 105", "position": 105, "chunk_type": "semantic", "token_estimate": 99}
{"text": "What is meant by \u201cstability\u201d? Stand a penny on its side. Is it stable in that position? You would likely: say \u201cno.\u201d However, unless disturbed, it will remain in that position for a very long time. Thus\nstability has nothing directly to do with frequency of change. The penny is not changing, but it is\ndifficult to think of it as stable. Webster\u2019s Dictionary says that something is stable if it is \u201cnot easily moved.\u201d Stability is related to\nthe amount of work required to make a change. On the one hand, the standing penny is not stable\nbecause it requires very little work to topple it. On the other hand, a table is very stable because it\ntakes a considerable amount of effort to turn it over. How does this relate to software? Many factors may make a software component hard to change\u2014for\nexample, its size, complexity, and clarity, among other characteristics. We will ignore all those\nfactors and focus on something different here. One sure way to make a software component difficult to\nchange, is to make lots of other software components depend on it. A component with lots of incoming\ndependencies is very stable because it requires a great deal of work to reconcile any changes with all\nthe dependent components. The diagram in Figure 14.5 shows X, which is a stable component. Three components depend on X, so\nit has three good reasons not to change. We say that X is responsible to those three components. Conversely, X depends on nothing, so it has no external influence to make it change. We say it is\nindependent.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 105", "position": 105, "chunk_type": "semantic", "token_estimate": 270}
{"text": "Figure 14.5 X: a stable component: Figure 14.6 shows Y, which is a very unstable component. No other components depend on Y, so we\nsay that it is irresponsible. Y also has three components that it depends on, so changes may come from\nthree external sources. We say that Y is dependent. Figure 14.6 Y: a very unstable component", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 106", "position": 106, "chunk_type": "semantic", "token_estimate": 59}
{"text": "How can we measure the stability of a component? One way is to count the number of dependencies: that enter and leave that component. These counts will allow us to calculate the positional stability of\nthe component. \u2022 Fan-in: Incoming dependencies. This metric identifies the number of classes outside this component\nthat depend on classes within the component. \u2022 Fan-out: Outgoing depenencies. This metric identifies the number of classes inside this component\nthat depend on classes outside the component.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 106", "position": 106, "chunk_type": "semantic", "token_estimate": 79}
{"text": "\u2022 I: Instability: I = Fan-out , (Fan-in + Fan-out). This metric has the range [0, 1]. I = 0 indicates a: maximally stable component. I = 1 indicates a maximally unstable component. The Fan-in and Fan-out metrics1 are calculated by counting the number of classes outside the\ncomponent in question that have dependencies with the classes inside the component in question. Consider the example in Figure 14.7. Figure 14.7 Our example\nLet\u2019s say we want to calculate the stability of the component Cc. We find that there are three classes\noutside Cc that depend on classes in Cc. Thus, Fan-in = 3. Moreover, there is one class outside Cc\nthat classes in Cc depend on. Thus, Fan-out = 1 and I = 1/4. In C++, these dependencies are typically represented by #include statements. Indeed, the I metric is\neasiest to calculate when you have organized your source code such that there is one class in each\nsource file. In Java, the I metric can be calculated by counting import statements and qualified\nnames. When the I metric is equal to 1, it means that no other component depends on this component (Fan-in\n= 0), and this component depends on other components (Fan-out > 0). This situation is as unstable as\na component can get; it is irresponsible and dependent. Its lack of dependents gives the component no\nreason not to change, and the components that it depends on may give it ample reason to change. In contrast, when the I metric is equal to 0, it means that the component is depended on by other\ncomponents (Fan-in > 0), but does not itself depend on any other components (Fan-out = 0). Such a\ncomponent is responsible and independent. It is as stable as it can get. Its dependents make it hard to\nchange the component, and its has no dependencies that might force it to change. The SDP says that the I metric of a component should be larger than the I metrics of the components\nthat it depends on. That is, I metrics should decrease in the direction of dependency.", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 107", "position": 107, "chunk_type": "semantic", "token_estimate": 352}
{"text": "If all the components in a system were maximally stable, the system would be unchangeable. This is: not a desirable situation. Indeed, we want to design our component structure so that some components\nare unstable and some are stable. The diagram in Figure 14.8 shows an ideal configuration for a\nsystem with three components. The changeable components are on top and depend on the stable component at the bottom. Putting the\nunstable components at the top of the diagram is a useful convention because any arrow that points up\nis violating the SDP (and, as we shall see later, the ADP). Figure 14.8 An ideal configuration for a system with three components\nThe diagram in Figure 14.9 shows how the SDP can be violated. Figure 14.9 SDP violation\nFlexible is a component that we have designed to be easy to change. We want Flexible to be\nunstable. However, some developer, working in the component named Stable, has hung a\ndependency on Flexible. This violates the SDP because the I metric for Stable is much smaller\nthan the I metric for Flexible. As a result, Flexible will no longer be easy to change. A change to", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 108", "position": 108, "chunk_type": "semantic", "token_estimate": 195}
{"text": "Flexible will force us to deal with Stable and all its dependents.: To fix this problem, we somehow have to break the dependence of Stable on Flexible. Why does\nthis dependency exist? Let\u2019s assume that there is a class C within Flexible that another class U\nwithin Stable needs to use (Figure 14.10). Figure 14.10 U within Stable uses C within Flexible\nWe can fix this by employing the DIP. We create an interface class called US and put it in a component\nnamed UServer. We make sure that this interface declares all the methods that U needs to use. We then\nmake C implement this interface as shown in Figure 14.11. This breaks the dependency of Stable on\nFlexible, and forces both components to depend on UServer. UServer is very stable (I = 0), and\nFlexible retains its necessary instability (I = 1). All the dependencies now flow in the direction of\ndecreasing I. Figure 14.11 C implements the interface class US\nAbstract Components\nYou may find it strange that we would create a component\u2014in this example, UService\u2014that contains\nnothing but an interface. Such a component contains no executable code! It turns out, however, that\nthis is a very common, and necessary, tactic when using statically typed languages like Java and C#. These abstract components are very stable and, therefore, are ideal targets for less stable components\nto depend on.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 109", "position": 109, "chunk_type": "semantic", "token_estimate": 231}
{"text": "When using dynamically typed languages like Ruby and Python, these abstract components don\u2019t exist: at all, nor do the dependencies that would have targeted them. Dependency structures in these\nlanguages are much simpler because dependency inversion does not require either the declaration or\nthe inheritance of interfaces.", "domains": ["Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 110", "position": 110, "chunk_type": "semantic", "token_estimate": 47}
{"text": "A component should be as abstract as it is stable.: WHERE DO WE PUT THE HIGH-LEVEL POLICY? Some software in the system should not change very often. This software represents high-level\narchitecture and policy decisions. We don\u2019t want these business and architectural decisions to be\nvolatile. Thus the software that encapsulates the high-level policies of the system should be placed\ninto stable components (I = 0). Unstable components (I = 1) should contain only the software that is\nvolatile\u2014software that we want to be able to quickly and easily change. However, if the high-level policies are placed into stable components, then the source code that\nrepresents those policies will be difficult to change. This could make the overall architecture\ninflexible. How can a component that is maximally stable (I = 0) be flexible enough to withstand\nchange? The answer is found in the OCP. This principle tells us that it is possible and desirable to\ncreate classes that are flexible enough to be extended without requiring modification. Which kind of\nclasses conform to this principle? Abstract classes.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 110", "position": 110, "chunk_type": "semantic", "token_estimate": 177}
{"text": "The Stable Abstractions Principle (SAP) sets up a relationship between stability and abstractness. On: the one hand, it says that a stable component should also be abstract so that its stability does not\nprevent it from being extended. On the other hand, it says that an unstable component should be\nconcrete since it its instability allows the concrete code within it to be easily changed. Thus, if a component is to be stable, it should consist of interfaces and abstract classes so that it can\nbe extended. Stable components that are extensible are flexible and do not overly constrain the\narchitecture. The SAP and the SDP combined amount to the DIP for components. This is true because the SDP says\nthat dependencies should run in the direction of stability, and the SAP says that stability implies\nabstraction. Thus dependencies run in the direction of abstraction. The DIP, however, is a principle that deals with classes\u2014and with classes there are no shades of\ngray. Either a class is abstract or it is not. The combination of the SDP and the SAP deals with\ncomponents, and allows that a component can be partially abstract and partially stable.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 110", "position": 110, "chunk_type": "semantic", "token_estimate": 195}
{"text": "The A metric is a measure of the abstractness of a component. Its value is simply the ratio of: interfaces and abstract classes in a component to the total number of classes in the component. \u2022 Nc: The number of classes in the component. \u2022 Na: The number of abstract classes and interfaces in the component. \u2022 A: Abstractness. A = Na \u00f7 Nc. The A metric ranges from 0 to 1. A value of 0 implies that the component has no abstract classes at\nall. A value of 1 implies that the component contains nothing but abstract classes.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 111", "position": 111, "chunk_type": "semantic", "token_estimate": 99}
{"text": "Figure 14.13 Zones of exclusion: The Zone of Pain\nConsider a component in the area of (0, 0). This is a highly stable and concrete component. Such a\ncomponent is not desirable because it is rigid. It cannot be extended because it is not abstract, and it\nis very difficult to change because of its stability. Thus we do not normally expect to see well-\ndesigned components sitting near (0, 0). The area around (0, 0) is a zone of exclusion called the Zone\nof Pain. Some software entities do, in fact, fall within the Zone of Pain. An example would be a database\nschema. Database schemas are notoriously volatile, extremely concrete, and highly depended on. This\nis one reason why the interface between OO applications and databases is so difficult to manage, and\nwhy schema updates are generally painful. Another example of software that sits near the area of (0, 0) is a concrete utility library. Although\nsuch a library has an I metric of 1, it may actually be nonvolatile. Consider the String component,\nfor example. Even though all the classes within it are concrete, it is so commonly used that changing it\nwould create chaos. Therefore String is nonvolatile. Nonvolatile components are harmless in the (0, 0) zone since they are not likely to be changed. For\nthat reason, it is only volatile software components that are problematic in the Zone of Pain. The more\nvolatile a component in the Zone of Pain, the more \u201cpainful\u201d it is. Indeed, we might consider\nvolatility to be a third axis of the graph. With this understanding, Figure 14.13 shows only the most\npainful plane, where volatility = 1. The Zone of Uselessness\nConsider a component near (1, 1). This location is undesirable because it is maximally abstract, yet\nhas no dependents. Such components are useless. Thus this area is called the Zone of Uselessness. The software entities that inhabit this region are a kind of detritus. They are often leftover abstract\nclasses that no one ever implemented. We find them in systems from time to time, sitting in the code", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 112", "position": 112, "chunk_type": "semantic", "token_estimate": 351}
{"text": "base, unused.: A component that has a position deep within the Zone of Uselessness must contain a significant\nfraction of such entities. Clearly, the presence of such useless entities is undesirable.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 113", "position": 113, "chunk_type": "semantic", "token_estimate": 31}
{"text": "It seems clear that our most volatile components should be kept as far from both zones of exclusion as: possible. The locus of points that are maximally distant from each zone is the line that connects (1, 0)\nand (0, 1). I call this line the Main Sequence.2\nA component that sits on the Main Sequence is not \u201ctoo abstract\u201d for its stability, nor is it \u201ctoo\nunstable\u201d for its abstractness. It is neither useless nor particularly painful. It is depended on to the\nextent that it is abstract, and it depends on others to the extent that it is concrete. The most desirable position for a component is at one of the two endpoints of the Main Sequence. Good architects strive to position the majority of their components at those endpoints. However, in\nmy experience, some small fraction of the components in a large system are neither perfectly abstract\nnor perfectly stable. Those components have the best characteristics if they are on, or close, to the\nMain Sequence.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 113", "position": 113, "chunk_type": "semantic", "token_estimate": 169}
{"text": "This leads us to our last metric. If it is desirable for components to be on, or close, to the Main: Sequence, then we can create a metric that measures how far away a component is from this ideal. \u2022 D3: Distance. D = |A+I\u20131| . The range of this metric is [0, 1]. A value of 0 indicates that the\ncomponent is directly on the Main Sequence. A value of 1 indicates that the component is as far\naway as possible from the Main Sequence. Given this metric, a design can be analyzed for its overall conformance to the Main Sequence. The D\nmetric for each component can be calculated. Any component that has a D value that is not near zero\ncan be reexamined and restructured. Statistical analysis of a design is also possible. We can calculate the mean and variance of all the D\nmetrics for the components within a design. We would expect a conforming design to have a mean and\nvariance that are close to zero. The variance can be used to establish \u201ccontrol limits\u201d so as to identify\ncomponents that are \u201cexceptional\u201d in comparison to all the others. In the scatterplot in Figure 14.14, we see that the bulk of the components lie along the Main Sequence,\nbut some of them are more than one standard deviation (Z = 1) away from the mean. These aberrant\ncomponents are worth examining more closely. For some reason, they are either very abstract with\nfew dependents or very concrete with many dependents.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 113", "position": 113, "chunk_type": "semantic", "token_estimate": 255}
{"text": "Figure 14.14 Scatterplot of the components: Another way to use the metrics is to plot the D metric of each component over time. The graph in\nFigure 14.15 is a mock-up of such a plot. You can see that some strange dependencies have been\ncreeping into the Payroll component over the last few releases. The plot shows a control threshold\nat D = 0.1. The R2.1 point has exceeded this control limit, so it would be worth our while to find out\nwhy this component is so far from the main sequence. Figure 14.15 Plot of D for a single component over time", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 114", "position": 114, "chunk_type": "semantic", "token_estimate": 103}
{"text": "The strategy behind that facilitation is to leave as many options open as possible, for as long as possible.: Perhaps this statement has surprised you. Perhaps you thought that the goal of software architecture\nwas to make the system work properly. Certainly we want the system to work properly, and certainly\nthe architecture of the system must support that as one of its highest priorities. However, the architecture of a system has very little bearing on whether that system works. There are\nmany systems out there, with terrible architectures, that work just fine. Their troubles do not lie in\ntheir operation; rather, they occur in their deployment, maintenance, and ongoing development. This is not to say that architecture plays no role in supporting the proper behavior of the system. It\ncertainly does, and that role is critical. But the role is passive and cosmetic, not active or essential. There are few, if any, behavioral options that the architecture of a system can leave open. The primary purpose of architecture is to support the life cycle of the system. Good architecture\nmakes the system easy to understand, easy to develop, easy to maintain, and easy to deploy. The\nultimate goal is to minimize the lifetime cost of the system and to maximize programmer productivity.", "domains": ["Design Patterns"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 118", "position": 118, "chunk_type": "semantic", "token_estimate": 213}
{"text": "A software system that is hard to develop is not likely to have a long and healthy lifetime. So the: architecture of a system should make that system easy to develop, for the team(s) who develop it. Different team structures imply different architectural decisions. On the one hand, a small team of five\ndevelopers can quite effectively work together to develop a monolithic system without well-defined\ncomponents or interfaces. In fact, such a team would likely find the strictures of an architecture\nsomething of an impediment during the early days of development. This is likely the reason why so\nmany systems lack good architecture: They were begun with none, because the team was small and\ndid not want the impediment of a superstructure. On the other hand, a system being developed by five different teams, each of which includes seven\ndevelopers, cannot make progress unless the system is divided into well-defined components with\nreliably stable interfaces. If no other factors are considered, the architecture of that system will likely\nevolve into five components\u2014one for each team. Such a component-per-team architecture is not likely to be the best architecture for deployment,\noperation, and maintenance of the system. Nevertheless, it is the architecture that a group of teams\nwill gravitate toward if they are driven solely by development schedule.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 118", "position": 118, "chunk_type": "semantic", "token_estimate": 217}
{"text": "Unfortunately, deployment strategy is seldom considered during initial development. This leads to: architectures that may make the system easy to develop, but leave it very difficult to deploy. For example, in the early development of a system, the developers may decide to use a \u201cmicro-\nservice architecture.\u201d They may find that this approach makes the system very easy to develop since\nthe component boundaries are very firm and the interfaces relatively stable. However, when it comes\ntime to deploy the system, they may discover that the number of micro-services has become daunting;\nconfiguring the connections between them, and the timing of their initiation, may also turn out to be a\nhuge source of errors. Had the architects considered deployment issues early on, they might have decided on fewer\nservices, a hybrid of services and in-process components, and a more integrated means of managing\nthe interconnections.", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 119", "position": 119, "chunk_type": "semantic", "token_estimate": 145}
{"text": "The primary cost of maintenance is in spelunking and risk. Spelunking is the cost of digging through: the existing software, trying to determine the best place and the best strategy to add a new feature or\nto repair a defect. While making such changes, the likelihood of creating inadvertent defects is always\nthere, adding to the cost of risk. A carefully thought-through architecture vastly mitigates these costs. By separating the system into\ncomponents, and isolating those components through stable interfaces, it is possible to illuminate the\npathways for future features and greatly reduce the risk of inadvertent breakage.", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 120", "position": 120, "chunk_type": "semantic", "token_estimate": 98}
{"text": "\u2022 It is not necessary to adopt REST early in development, because the high-level policy should be: agnostic about the interface to the outside world. Nor is it necessary to adopt a micro-services\nframework, or a SOA framework. Again, the high-level policy should not care about these things. \u2022 It is not necessary to adopt a dependency injection framework early in development, because the\nhigh-level policy should not care how dependencies are resolved. I think you get the point. If you can develop the high-level policy without committing to the details that\nsurround it, you can delay and defer decisions about those details for a long time. And the longer you\nwait to make those decisions, the more information you have with which to make them properly. This also leaves you the option to try different experiments. If you have a portion of the high-level\npolicy working, and it is agnostic about the database, you could try connecting it to several different\ndatabases to check applicability and performance. The same is true with web systems, web\nframeworks, or even the web itself. The longer you leave options open, the more experiments you can run, the more things you can try, and\nthe more information you will have when you reach the point at which those decisions can no longer\nbe deferred. What if the decisions have already been made by someone else? What if your company has made a\ncommitment to a certain database, or a certain web server, or a certain framework? A good architect\npretends that the decision has not been made, and shapes the system such that those decisions can\nstill be deferred or changed for as long as possible. A good architect maximizes the number of decisions not made.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 121", "position": 121, "chunk_type": "semantic", "token_estimate": 293}
{"text": "JMP .-1: JMP .-1\n        TLS\n        JMP I PRTCHR\nPRTCHR is a subroutine that prints one character on the teleprinter. The beginning zero was used as the\nstorage for the return address. (Don\u2019t ask.) The TSF instruction skipped the next instruction if the\nteleprinter was ready to print a character. If the teleprinter was busy, then TSF just fell through to the\nJMP .-1 instruction, which just jumped back to the TSF instruction. If the teleprinter was ready, then\nTSF would skip to the TLS instruction, which sent the character in the A register to the teleprinter. Then the JMP I PRTCHR instruction returned to the caller. At first this strategy worked fine. If we needed to read cards from the card reader, we used code that\ntalked directly to the card reader. If we needed to punch cards, we wrote code that directly\nmanipulated the punch. The programs worked perfectly. How could we know this was a mistake? But big batches of punched cards are difficult to manage. They can be lost, mutilated, spindled,\nshuffled, or dropped. Individual cards can be lost and extra cards can be inserted. So data integrity\nbecame a significant problem. Magnetic tape was the solution. We could move the card images to tape. If you drop a magnetic tape,\nthe records don\u2019t get shuffled. You can\u2019t accidentally lose a record, or insert a blank record simply by\nhanding the tape. The tape is much more secure. It\u2019s also faster to read and write, and it is very easy\nto make backup copies. Unfortunately, all our software was written to manipulate card readers and card punches. Those\nprograms had to be rewritten to use magnetic tape. That was a big job. By the late 1960s, we had learned our lesson\u2014and we invented device independence. The operating\nsystems of the day abstracted the IO devices into software functions that handled unit records that\nlooked like cards. The programs would invoke operating system services that dealt with abstract unit-\nrecord devices. Operators could tell the operating system whether those abstract services should be\nconnected to card readers, magnetic tape, or any other unit-record device. Now the same program could read and write cards, or read and write tape, without any change. The\nOpen\u2013Closed Principle was born (but not yet named).", "domains": ["Design Patterns"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 122", "position": 122, "chunk_type": "semantic", "token_estimate": 382}
{"text": "The first bullet\u2014use cases\u2014means that the architecture of the system must support the intent of the: system. If the system is a shopping cart application, then the architecture must support shopping cart\nuse cases. Indeed, this is the first concern of the architect, and the first priority of the architecture. The\narchitecture must support the use cases. However, as we discussed previously, architecture does not wield much influence over the behavior\nof the system. There are very few behavioral options that the architecture can leave open. But\ninfluence isn\u2019t everything. The most important thing a good architecture can do to support behavior is\nto clarify and expose that behavior so that the intent of the system is visible at the architectural level. A shopping cart application with a good architecture will look like a shopping cart application. The", "domains": ["Design Patterns"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 125", "position": 125, "chunk_type": "semantic", "token_estimate": 138}
{"text": "The architecture also plays a huge role in determining the ease with which the system is deployed.: The goal is \u201cimmediate deployment.\u201d A good architecture does not rely on dozens of little\nconfiguration scripts and property file tweaks. It does not require manual creation of directories or\nfiles that must be arranged just so. A good architecture helps the system to be immediately deployable\nafter build. Again, this is achieved through the proper partitioning and isolation of the components of the system,\nincluding those master components that tie the whole system together and ensure that each component\nis properly started, integrated, and supervised.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 127", "position": 127, "chunk_type": "semantic", "token_estimate": 103}
{"text": "A good architecture balances all of these concerns with a component structure that mutually satisfies: them all. Sounds easy, right? Well, it\u2019s easy for me to write that. The reality is that achieving this balance is pretty hard. The problem is that most of the time we don\u2019t\nknow what all the use cases are, nor do we know the operational constraints, the team structure, or the\ndeployment requirements. Worse, even if we did know them, they will inevitably change as the system\nmoves through its life cycle. In short, the goals we must meet are indistinct and inconstant. Welcome\nto the real world. But all is not lost: Some principles of architecture are relatively inexpensive to implement and can\nhelp balance those concerns, even when you don\u2019t have a clear picture of the targets you have to hit. Those principles help us partition our systems into well-isolated components that allow us to leave as\nmany options open as possible, for as long as possible. A good architecture makes the system easy to change, in all the ways that it must change, by leaving\noptions open.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 127", "position": 127, "chunk_type": "semantic", "token_estimate": 186}
{"text": "Consider the use cases. The architect wants the structure of the system to support all the necessary use: cases, but does not know what all those use cases are. However, the architect does know the basic\nintent of the system. It\u2019s a shopping cart system, or it\u2019s a bill of materials system, or it\u2019s an order\nprocessing system. So the architect can employ the Single Responsibility Principle and the Common\nClosure Principle to separate those things that change for different reasons, and to collect those things\nthat change for the same reasons\u2014given the context of the intent of the system. What changes for different reasons? There are some obvious things. User interfaces change for\nreasons that have nothing to do with business rules. Use cases have elements of both. Clearly, then, a\ngood architect will want to separate the UI portions of a use case from the business rule portions in\nsuch a way that they can be changed independently of each other, while keeping those use cases\nvisible and clear.", "domains": ["Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 127", "position": 127, "chunk_type": "semantic", "token_estimate": 171}
{"text": "In short, the decoupling that we did for the sake of the use cases also helps with operations. However,: to take advantage of the operational benefit, the decoupling must have the appropriate mode. To run in\nseparate servers, the separated components cannot depend on being together in the same address\nspace of a processor. They must be independent services, which communicate over a network of\nsome kind. Many architects call such components \u201cservices\u201d or \u201cmicro-services,\u201d depending upon some vague\nnotion of line count. Indeed, an architecture based on services is often called a service-oriented\narchitecture. If that nomenclature set off some alarm bells in your mind, don\u2019t worry. I\u2019m not going to tell you that\nSoA is the best possible architecture, or that micro-services are the wave of the future. The point\nbeing made here is that sometimes we have to separate our components all the way to the service\nlevel. Remember, a good architecture leaves options open. The decoupling mode is one of those options. Before we explore that topic further, let\u2019s look to the other two bullets. INDEPENDENT DEVELOP-ABILITY\nThe third bullet was development. Clearly when components are strongly decoupled, the interference\nbetween teams is mitigated. If the business rules don\u2019t know about the UI, then a team that focuses on\nthe UI cannot much affect a team that focuses on the business rules. If the use cases themselves are\ndecoupled from one another, then a team that focuses on the addOrder use case is not likely to\ninterfere with a team that focuses on the deleteOrder use case. So long as the layers and use cases are decoupled, the architecture of the system will support the\norganization of the teams, irrespective of whether they are organized as feature teams, component\nteams, layer teams, or some other variation.", "domains": ["Architectural Patterns and Styles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 129", "position": 129, "chunk_type": "semantic", "token_estimate": 300}
{"text": "duplicated, we are honor-bound as professionals to reduce and eliminate it.: But there are different kinds of duplication. There is true duplication, in which every change to one\ninstance necessitates the same change to every duplicate of that instance. Then there is false or\naccidental duplication. If two apparently duplicated sections of code evolve along different paths\u2014if\nthey change at different rates, and for different reasons\u2014then they are not true duplicates. Return to\nthem in a few years, and you\u2019ll find that they are very different from each other. Now imagine two use cases that have very similar screen structures. The architects will likely be\nstrongly tempted to share the code for that structure. But should they? Is that true duplication? Or it is\naccidental? Most likely it is accidental. As time goes by, the odds are that those two screens will diverge and\neventually look very different. For this reason, care must be taken to avoid unifying them. Otherwise,\nseparating them later will be a challenge. When you are vertically separating use cases from one another, you will run into this issue, and your\ntemptation will be to couple the use cases because they have similar screen structures, or similar\nalgorithms, or similar database queries and/or schemas. Be careful. Resist the temptation to commit\nthe sin of knee-jerk elimination of duplication. Make sure the duplication is real. By the same token, when you are separating layers horizontally, you might notice that the data\nstructure of a particular database record is very similar to the data structure of a particular screen\nview. You may be tempted to simply pass the database record up to the UI, rather than to create a\nview model that looks the same and copy the elements across. Be careful: This duplication is almost\ncertainly accidental. Creating the separate view model is not a lot of effort, and it will help you keep\nthe layers properly decoupled. DECOUPLING MODES (AGAIN)\nBack to modes. There are many ways to decouple layers and use cases. They can be decoupled at the\nsource code level, at the binary code (deployment) level, and at the execution unit (service) level. \u2022 Source level. We can control the dependencies between source code modules so that changes to one\nmodule do not force changes or recompilation of others (e.g., Ruby Gems). In this decoupling mode the components all execute in the same address space, and communicate\nwith each other using simple function calls.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 130", "position": 130, "chunk_type": "semantic", "token_estimate": 410}
{"text": "duplicated, we are honor-bound as professionals to reduce and eliminate it.: We can control the dependencies between source code modules so that changes to one\nmodule do not force changes or recompilation of others (e.g., Ruby Gems). In this decoupling mode the components all execute in the same address space, and communicate\nwith each other using simple function calls. There is a single executable loaded into computer\nmemory. People often call this a monolithic structure. \u2022 Deployment level. We can control the dependencies between deployable units such as jar files,\nDLLs, or shared libraries, so that changes to the source code in one module do not force others to\nbe rebuilt and redeployed. Many of the components may still live in the same address space, and communicate through function\ncalls. Other components may live in other processes in the same processor, and communicate\nthrough interprocess communications, sockets, or shared memory. The important thing here is that", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 130", "position": 130, "chunk_type": "semantic", "token_estimate": 156}
{"text": "The story of P is not isolated. I\u2019ve seen it many times and in many places. Indeed, P is a superposition: of all those places. But there are worse fates than P.\nConsider W, a local business that manages fleets of company cars. They recently hired an \u201cArchitect\u201d\nto get their rag-tag software effort under control. And, let me tell you, control was this guy\u2019s middle\nname. He quickly realized that what this little operation needed was a full-blown, enterprise-scale,\nservice-oriented \u201cARCHITECTURE.\u201d He created a huge domain model of all the different\n\u201cobjects\u201d in the business, designed a suite of services to manage these domain objects, and put all the\ndevelopers on a path to Hell. As a simple example, suppose you wanted to add the name, address,\nand phone number of a contact person to a sales record. You had to go to the ServiceRegistry and\nask for the service ID of the ContactService. Then you had to send a CreateContact message to\nthe ContactService. Of course, this message had dozens of fields that all had to have valid data in\nthem\u2014data to which the programmer had no access, since all the programmer had was a name,\naddress, and phone number. After faking the data, the programmer had to jam the ID of the newly\ncreated contact into the sales record and send the UpdateContact message to the\nSaleRecordService. Of course, to test anything you had to fire up all the necessary services, one by one, and fire up the\nmessage bus, and the BPel server, and \u2026 And then, there were the propagation delays as these\nmessages bounced from service to service, and waited in queue after queue. And then if you wanted to add a new feature\u2014well, you can imagine the coupling between all those\nservices, and the sheer volume of WSDLs that needed changing, and all the redeployments those\nchanges necessitated \u2026\nHell starts to seem like a nice place by comparison. There\u2019s nothing intrinsically wrong with a software system that is structured around services. The\nerror at W was the premature adoption and enforcement of a suite of tools that promised SoA\u2014that\nis, the premature adoption of a massive suite of domain object services. The cost of those errors was\nsheer person-hours\u2014person-hours in droves\u2014flushed down the SoA vortex. I could go on describing one architectural failure after another. But let\u2019s talk about an architectural\nsuccess instead.", "domains": ["Architectural Patterns and Styles"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 135", "position": 135, "chunk_type": "semantic", "token_estimate": 401}
{"text": "One of the first decisions was to write our own web server, specific to the needs of FitNesse. This: might sound absurd. Even in 2001 there were plenty of open source web servers that we could have\nused. Yet writing our own turned out to be a really good decision because a bare-bones web server is\na very simple piece of software to write and it allowed us to postpone any web framework decision\nuntil much later.2\nAnother early decision was to avoid thinking about a database. We had MySQL in the back of our\nminds, but we purposely delayed that decision by employing a design that made the decision\nirrelevant. That design was simply to put an interface between all data accesses and the data\nrepository itself. We put the data access methods into an interface named WikiPage. Those methods provided all the\nfunctionality we needed to find, fetch, and save pages. Of course, we didn\u2019t implement those methods\nat first; we simply stubbed them out while we worked on features that didn\u2019t involve fetching and\nsaving the data. Indeed, for three months we simply worked on translating wiki text into HTML. This didn\u2019t require\nany kind of data storage, so we created a class named MockWikiPage that simply left the data access\nmethods stubbed. Eventually, those stubs became insufficient for the features we wanted to write. We needed real data\naccess, not stubs. So we created a new derivative of WikiPage named InMemoryPage. This\nderivative implemented the data access method to manage a hash table of wiki pages, which we kept\nin RAM. This allowed us to write feature after feature for a full year. In fact, we got the whole first version of\nthe FitNesse program working this way. We could create pages, link to other pages, do all the fancy\nwiki formatting, and even run tests with FIT. What we couldn\u2019t do was save any of our work. When it came time to implement persistence, we thought again about MySQL, but decided that wasn\u2019t\nnecessary in the short term, because it would be really easy to write the hash tables out to flat files. So we implemented FileSystemWikiPage, which just moved the functionality out to flat files, and\nthen we continued developing more features. Three months later, we reached the conclusion that the flat file solution was good enough; we decided\nto abandon the idea of MySQL altogether. We deferred that decision into nonexistence and never\nlooked back.", "domains": ["Domain-Driven Design", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 136", "position": 136, "chunk_type": "semantic", "token_estimate": 412}
{"text": "Early in the development of FitNesse, we drew a boundary line between business rules and: databases. That line prevented the business rules from knowing anything at all about the database,\nother than the simple data access methods. That decision allowed us to defer the choice and\nimplementation of the database for well over a year. It allowed us to try the file system option, and it\nallowed us to change direction when we saw a better solution. Yet it did not prevent, or even impede,\nmoving in the original direction (MySQL) when someone wanted it. The fact that we did not have a database running for 18 months of development meant that, for 18\nmonths, we did not have schema issues, query issues, database server issues, password issues,\nconnection time issues, and all the other nasty issues that raise their ugly heads when you fire up a\ndatabase. It also meant that all our tests ran fast, because there was no database to slow them down. In short, drawing the boundary lines helped us delay and defer decisions, and it ultimately saved us\nan enormous amount of time and headaches. And that\u2019s what a good architecture should do. WHICH LINES DO YOU DRAW, AND WHEN DO\nYOU DRAW THEM? You draw lines between things that matter and things that don\u2019t. The GUI doesn\u2019t matter to the\nbusiness rules, so there should be a line between them. The database doesn\u2019t matter to the GUI, so\nthere should be a line between them. The database doesn\u2019t matter to the business rules, so there\nshould be a line between them. Some of you may have rejected one or more of those statements, especially the part about the business\nrules not caring about the database. Many of us have been taught to believe that the database is\ninextricably connected to the business rules. Some of us have even been convinced that the database\nis the embodiment of the business rules. But, as we shall see in another chapter, this idea is misguided. The database is a tool that the business\nrules can use indirectly. The business rules don\u2019t need to know about the schema, or the query\nlanguage, or any of the other details about the database. All the business rules need to know is that\nthere is a set of functions that can be used to fetch or save data. This allows us to put the database\nbehind an interface. You can see this clearly in Figure 17.1.", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 137", "position": 137, "chunk_type": "semantic", "token_estimate": 415}
{"text": "Early in the development of FitNesse, we drew a boundary line between business rules and: This allows us to put the database\nbehind an interface. You can see this clearly in Figure 17.1. The BusinessRules use the DatabaseInterface to load\nand save data. The DatabaseAccess implements the interface and directs the operation of the actual\nDatabase.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 137", "position": 137, "chunk_type": "semantic", "token_estimate": 56}
{"text": "Figure 17.1 The database behind an interface: The classes and interfaces in this diagram are symbolic. In a real application, there would be many\nbusiness rule classes, many database interface classes, and many database access implementations. All of them, though, would follow roughly the same pattern. Where is the boundary line? The boundary is drawn across the inheritance relationship, just below\nthe DatabaseInterface (Figure 17.2). Figure 17.2 The boundary line\nNote the two arrows leaving the DatabaseAccess class. Those two arrows point away from the\nDatabaseAccess class. That means that none of these classes knows that the DatabaseAccess class\nexists. Now let\u2019s pull back a bit. We\u2019ll look at the component that contains many business rules, and the\ncomponent that contains the database and all its access classes (Figure 17.3).", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 138", "position": 138, "chunk_type": "semantic", "token_estimate": 130}
{"text": "Figure 17.3 The business rules and database components: Note the direction of the arrow. The Database knows about the BusinessRules. The\nBusinessRules do not know about the Database. This implies that the DatabaseInterface classes\nlive in the BusinessRules component, while the DatabaseAccess classes live in the Database\ncomponent. The direction of this line is important. It shows that the Database does not matter to the\nBusinessRules, but the Database cannot exist without the BusinessRules. If that seems strange to you, just remember this point: The Database component contains the code that\ntranslates the calls made by the BusinessRules into the query language of the database. It is that\ntranslation code that knows about the BusinessRules. Having drawn this boundary line between the two components, and having set the direction of the\narrow toward the BusinessRules, we can now see that the BusinessRules could use any kind of\ndatabase. The Database component could be replaced with many different implementations\u2014the\nBusinessRules don\u2019t care. The database could be implemented with Oracle, or MySQL, or Couch, or Datomic, or even flat files. The business rules don\u2019t care at all. And that means that the database decision can be deferred and\nyou can focus on getting the business rules written and tested before you have to make the database\ndecision. WHAT ABOUT INPUT AND OUTPUT? Developers and customers often get confused about what the system is. They see the GUI, and think\nthat the GUI is the system. They define a system in terms of the GUI, so they believe that they should\nsee the GUI start working immediately. They fail to realize a critically important principle: The IO is\nirrelevant.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 139", "position": 139, "chunk_type": "semantic", "token_estimate": 276}
{"text": "This may be hard to grasp at first. We often think about the behavior of the system in terms of the: behavior of the IO. Consider a video game, for example. Your experience is dominated by the\ninterface: the screen, the mouse, the buttons, and the sounds. You forget that behind that interface there\nis a model\u2014a sophisticated set of data structures and functions\u2014driving it. More importantly, that\nmodel does not need the interface. It would happily execute its duties, modeling all the events in the\ngame, without the game ever being displayed on the screen. The interface does not matter to the model\n\u2014the business rules. And so, once again, we see the GUI and BusinessRules components separated by a boundary line\n(Figure 17.4). Once again, we see that the less relevant component depends on the more relevant\ncomponent. The arrows show which component knows about the other and, therefore, which\ncomponent cares about the other. The GUI cares about the BusinessRules. Figure 17.4 The boundary between GUI and BusinessRules components\nHaving drawn this boundary and this arrow, we can now see that the GUI could be replaced with any\nother kind of interface\u2014and the BusinessRules would not care.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 140", "position": 140, "chunk_type": "semantic", "token_estimate": 200}
{"text": "Figure 17.5 Plugging in to the business rules: Because the user interface in this design is considered to be a plugin, we have made it possible to\nplug in many different kinds of user interfaces. They could be web based, client/server based, SOA\nbased, Console based, or based on any other kind of user interface technology. The same is true of the database. Since we have chosen to treat it as a plugin, we can replace it with\nany of the various SQL databases, or a NOSQL database, or a file system-based database, or any\nother kind of database technology we might deem necessary in the future. These replacements might not be trivial. If the initial deployment of our system was web-based, then\nwriting the plugin for a client-server UI could be challenging. It is likely that some of the\ncommunications between the business rules and the new UI would have to be reworked. Even so, by\nstarting with the presumption of a plugin structure, we have at very least made such a change\npractical.", "domains": ["Architectural Patterns and Styles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 141", "position": 141, "chunk_type": "semantic", "token_estimate": 175}
{"text": "Figure 17.6 ReSharper depends on Visual Studio: That\u2019s a deeply asymmetric relationship, and it is one that we desire to have in our own systems. We\nwant certain modules to be immune to others. For example, we don\u2019t want the business rules to break\nwhen someone changes the format of a web page, or changes the schema of the database. We don\u2019t\nwant changes in one part of the system to cause other unrelated parts of the system to break. We don\u2019t\nwant our systems to exhibit that kind of fragility. Arranging our systems into a plugin architecture creates firewalls across which changes cannot\npropagate. If the GUI plugs in to the business rules, then changes in the GUI cannot affect those\nbusiness rules. Boundaries are drawn where there is an axis of change. The components on one side of the boundary\nchange at different rates, and for different reasons, than the components on the other side of the\nboundary. GUIs change at different times and at different rates than business rules, so there should be a\nboundary between them. Business rules change at different times and for different reasons than\ndependency injection frameworks, so there should be a boundary between them. This is simply the Single Responsibility Principle again. The SRP tells us where to draw our\nboundaries.", "domains": ["Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 142", "position": 142, "chunk_type": "semantic", "token_estimate": 219}
{"text": "To draw boundary lines in a software architecture, you first partition the system into components.: Some of those components are core business rules; others are plugins that contain necessary functions\nthat are not directly related to the core business. Then you arrange the code in those components such\nthat the arrows between them point in one direction\u2014toward the core business. You should recognize this as an application of the Dependency Inversion Principle and the Stable", "domains": ["Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 142", "position": 142, "chunk_type": "semantic", "token_estimate": 75}
{"text": "At runtime, a boundary crossing is nothing more than a function on one side of the boundary calling a: function on the other side and passing along some data. The trick to creating an appropriate boundary\ncrossing is to manage the source code dependencies. Why source code? Because when one source code module changes, other source code modules may\nhave to be changed or recompiled, and then redeployed. Managing and building firewalls against this\nchange is what boundaries are all about.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 144", "position": 144, "chunk_type": "semantic", "token_estimate": 81}
{"text": "From a deployment point of view, this amounts to nothing more than a single executable file\u2014the so-: called monolith. This file might be a statically linked C or C++ project, a set of Java class files\nbound together into an executable jar file, a set of .NET binaries bound into a single .EXE file, and so\non. The fact that the boundaries are not visible during the deployment of a monolith does not mean that\nthey are not present and meaningful. Even when statically linked into a single executable, the ability\nto independently develop and marshal the various components for final assembly is immensely\nvaluable. Such architectures almost always depend on some kind of dynamic polymorphism1 to manage their\ninternal dependencies. This is one of the reasons that object-oriented development has become such\nan important paradigm in recent decades. Without OO, or an equivalent form of polymorphism,\narchitects must fall back on the dangerous practice of using pointers to functions to achieve the\nappropriate decoupling. Most architects find prolific use of pointers to functions to be too risky, so\nthey are forced to abandon any kind of component partitioning. The simplest possible boundary crossing is a function call from a low-level client to a higher-level\nservice. Both the runtime dependency and the compile-time dependency point in the same direction,\ntoward the higher-level component. In Figure 18.1, the flow of control crosses the boundary from left to right. The Client calls function\nf() on the Service. It passes along an instance of Data. The <DS> marker simply indicates a data\nstructure. The Data may be passed as a function argument or by some other more elaborate means. Note that the definition of the Data is on the called side of the boundary. Figure 18.1 Flow of control crosses the boundary from a lower level to a higher level\nWhen a high-level client needs to invoke a lower-level service, dynamic polymorphism is used to\ninvert the dependency against the flow of control. The runtime dependency opposes the compile-time\ndependency. In Figure 18.2, the flow of control crosses the boundary from left to right as before. The high-level", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 145", "position": 145, "chunk_type": "semantic", "token_estimate": 355}
{"text": "Client calls the f() function of the lower-level ServiceImpl through the Service interface. Note,: however, that all dependencies cross the boundary from right to left toward the higher-level\ncomponent. Note, also, that the definition of the data structure is on the calling side of the boundary. Figure 18.2 Crossing the boundary against the flow of control\nEven in a monolithic, statically linked executable, this kind of disciplined partitioning can greatly aid\nthe job of developing, testing, and deploying the project. Teams can work independently of each other\non their own components without treading on each other\u2019s toes. High-level components remain\nindependent of lower-level details. Communications between components in a monolith are very fast and inexpensive. They are typically\njust function calls. Consequently, communications across source-level decoupled boundaries can be\nvery chatty. Since the deployment of monoliths usually requires compilation and static linking, components in\nthese systems are typically delivered as source code.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 146", "position": 146, "chunk_type": "semantic", "token_estimate": 152}
{"text": "The simplest physical representation of an architectural boundary is a dynamically linked library like: a .Net DLL, a Java jar file, a Ruby Gem, or a UNIX shared library. Deployment does not involve\ncompilation. Instead, the components are delivered in binary, or some equivalent deployable form. This is the deployment-level decoupling mode. The act of deployment is simply the gathering of these\ndeployable units together in some convenient form, such as a WAR file, or even just a directory. With that one exception, deployment-level components are the same as monoliths. The functions\ngenerally all exist in the same processor and address space. The strategies for segregating the\ncomponents and managing their dependencies are the same.2\nAs with monoliths, communications across deployment component boundaries are just function calls", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 146", "position": 146, "chunk_type": "semantic", "token_estimate": 127}
{"text": "Both monoliths and deployment components can make use of threads. Threads are not architectural: boundaries or units of deployment, but rather a way to organize the schedule and order of execution. They may be wholly contained within a component, or spread across many components.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 147", "position": 147, "chunk_type": "semantic", "token_estimate": 44}
{"text": "A much stronger physical architectural boundary is the local process. A local process is typically: created from the command line or an equivalent system call. Local processes run in the same\nprocessor, or in the same set of processors within a multicore, but run in separate address spaces. Memory protection generally prevents such processes from sharing memory, although shared memory\npartitions are often used. Most often, local processes communicate with each other using sockets, or some other kind of\noperating system communications facility such as mailboxes or message queues. Each local process may be a statically linked monolith, or it may be composed of dynamically linked\ndeployment components. In the former case, several monolithic processes may have the same\ncomponents compiled and linked into them. In the latter, they may share the same dynamically linked\ndeployment components. Think of a local process as a kind of uber-component: The process consists of lower-level\ncomponents that manage their dependencies through dynamic polymorphism. The segregation strategy between local processes is the same as for monoliths and binary\ncomponents. Source code dependencies point in the same direction across the boundary, and always\ntoward the higher-level component. For local processes, this means that the source code of the higher-level processes must not contain the\nnames, or physical addresses, or registry lookup keys of lower-level processes. Remember that the\narchitectural goal is for lower-level processes to be plugins to higher-level processes. Communication across local process boundaries involve operating system calls, data marshaling and\ndecoding, and interprocess context switches, which are moderately expensive. Chattiness should be\ncarefully limited.", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 147", "position": 147, "chunk_type": "semantic", "token_estimate": 261}
{"text": "Most systems, other than monoliths, use more than one boundary strategy. A system that makes use of: service boundaries may also have some local process boundaries. Indeed, a service is often just a\nfacade for a set of interacting local processes. A service, or a local process, will almost certainly be\neither a monolith composed of source code components or a set of dynamically linked deployment\ncomponents. This means that the boundaries in a system will often be a mixture of local chatty boundaries and\nboundaries that are more concerned with latency. 1. Static polymorphism (e.g., generics or templates) can sometimes be a viable means of dependency management in monolithic systems,\nespecially in languages like C++. However, the decoupling afforded by generics cannot protect you from the need for recompilation\nand redeployment the way dynamic polymorphism can. 2. Although static polymorphism is not an option in this case.", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 148", "position": 148, "chunk_type": "semantic", "token_estimate": 148}
{"text": "Software systems are statements of policy. Indeed, at its core, that\u2019s all a computer program actually: is. A computer program is a detailed description of the policy by which inputs are transformed into\noutputs. In most nontrivial systems, that policy can be broken down into many different smaller statements of\npolicy. Some of those statements will describe how particular business rules are to be calculated. Others will describe how certain reports are to be formatted. Still others will describe how input\ndata are to be validated. Part of the art of developing a software architecture is carefully separating those policies from one\nanother, and regrouping them based on the ways that they change. Policies that change for the same\nreasons, and at the same times, are at the same level and belong together in the same component. Policies that change for different reasons, or at different times, are at different levels and should be\nseparated into different components. The art of architecture often involves forming the regrouped components into a directed acyclic\ngraph. The nodes of the graph are the components that contain policies at the same level. The directed\nedges are the dependencies between those components. They connect components that are at different\nlevels. Those dependencies are source code, compile-time dependencies. In Java, they are import\nstatements. In C#, they are using statements. In Ruby, they are require statements. They are the", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 149", "position": 149, "chunk_type": "semantic", "token_estimate": 233}
{"text": "A strict definition of \u201clevel\u201d is \u201cthe distance from the inputs and outputs.\u201d The farther a policy is from: both the inputs and the outputs of the system, the higher its level. The policies that manage input and\noutput are the lowest-level policies in the system. The data flow diagram in Figure 19.1 depicts a simple encryption program that reads characters from\nan input device, translates the characters using a table, and then writes the translated characters to an\noutput device. The data flows are shown as curved solid arrows. The properly designed source code\ndependencies are shown as straight dashed lines. Figure 19.1 A simple encryption program\nThe Translate component is the highest-level component in this system because it is the component\nthat is farthest from the inputs and outputs.1\nNote that the data flows and the source code dependencies do not always point in the same direction. This, again, is part of the art of software architecture. We want source code dependencies to be\ndecoupled from data flow and coupled to level. It would be easy to create an incorrect architecture by writing the encryption program like this:\nClick here to view code image\nfunction encrypt() {\n  while(true)", "domains": ["Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 150", "position": 150, "chunk_type": "semantic", "token_estimate": 200}
{"text": "Another way to look at this issue is to note that lower-level components should be plugins to the: higher-level components. The component diagram in Figure 19.3 shows this arrangement. The\nEncryption component knows nothing of the IODevices component; the IODevices component\ndepends on the Encryption component. Figure 19.3 Lower-level components should plug in to higher-level components", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 152", "position": 152, "chunk_type": "semantic", "token_estimate": 56}
{"text": "At this point, this discussion of policies has involved a mixture of the Single Responsibility: Principle, the Open-Closed Principle, the Common Closure Principle, the Dependency Inversion\nPrinciple, the Stable Dependencies Principle, and the Stable Abstractions Principle. Look back and\nsee if you can identify where each principle was used, and why. 1. Meilir Page-Jones called this component the \u201cCentral Transform\u201d in his book The Practical Guide to Structured Systems Design,\n2nd ed. (Yourdon Press, 1988).", "domains": ["Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 152", "position": 152, "chunk_type": "semantic", "token_estimate": 75}
{"text": "Section: We\u2019ll call this kind of object an Entity.1", "domains": ["Domain-Driven Design"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 154", "position": 154, "chunk_type": "semantic", "token_estimate": 9}
{"text": "An Entity is an object within our computer system that embodies a small set of critical business rules: operating on Critical Business Data. The Entity object either contains the Critical Business Data or\nhas very easy access to that data. The interface of the Entity consists of the functions that implement\nthe Critical Business Rules that operate on that data. For example, Figure 20.1 shows what our Loan entity might look like as a class in UML. It has three\npieces of Critical Business Data, and presents three related Critical Business Rules at its interface. Figure 20.1 Loan entity as a class in UML\nWhen we create this kind of class, we are gathering together the software that implements a concept\nthat is critical to the business, and separating it from every other concern in the automated system we\nare building. This class stands alone as a representative of the business. It is unsullied with concerns\nabout databases, user interfaces, or third-party frameworks. It could serve the business in any system,\nirrespective of how that system was presented, or how the data was stored, or how the computers in\nthat system were arranged. The Entity is pure business and nothing else. Some of you may be concerned that I called it a class. Don\u2019t be. You don\u2019t need to use an object-\noriented language to create an Entity. All that is required is that you bind the Critical Business Data\nand the Critical Business Rules together in a single and separate software module.", "domains": ["Domain-Driven Design", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 154", "position": 154, "chunk_type": "semantic", "token_estimate": 253}
{"text": "For example, imagine an application that is used by bank officers to create a new loan. The bank may: decide that it does not want the loan officers to offer loan payment estimates until they have first\ngathered, and validated, contact information and ensured that the candidate\u2019s credit score is 500 or\nhigher. For this reason, the bank may specify that the system will not proceed to the payment\nestimation screen until the contact information screen has been filled out and verified, and the credit\nscore has been confirmed to be greater than the cutoff. This is a use case.2 A use case is a description of the way that an automated system is used. It\nspecifies the input to be provided by the user, the output to be returned to the user, and the processing\nsteps involved in producing that output. A use case describes application-specific business rules as\nopposed to the Critical Business Rules within the Entities. Figure 20.2 shows an example of a use case. Notice that in the last line it mentions the Customer. This\nis a reference to the Customer entity, which contains the Critical Business Rules that govern the\nrelationship between the bank and its customers. Figure 20.2 Example use case\nUse cases contain the rules that specify how and when the Critical Business Rules within the Entities\nare invoked. Use cases control the dance of the Entities. Notice also that the use case does not describe the user interface other than to informally specify the\ndata coming in from that interface, and the data going back out through that interface. From the use\ncase, it is impossible to tell whether the application is delivered on the web, or on a thick client, or\non a console, or is a pure service. This is very important. Use cases do not describe how the system appears to the user. Instead, they\ndescribe the application-specific rules that govern the interaction between the users and the Entities. How the data gets in and out of the system is irrelevant to the use cases. A use case is an object. It has one or more functions that implement the application-specific business\nrules. It also has data elements that include the input data, the output data, and the references to the\nappropriate Entities with which it interacts.", "domains": ["Domain-Driven Design", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 155", "position": 155, "chunk_type": "semantic", "token_estimate": 388}
{"text": "Entities have no knowledge of the use cases that control them. This is another example of the: direction of the dependencies following the Dependency Inversion Principle. High-level concepts,\nsuch as Entities, know nothing of lower-level concepts, such as use cases. Instead, the lower-level\nuse cases know about the higher-level Entities. Why are Entities high level and use cases lower level? Because use cases are specific to a single\napplication and, therefore, are closer to the inputs and outputs of that system. Entities are\ngeneralizations that can be used in many different applications, so they are farther from the inputs and\noutputs of the system. Use cases depend on Entities; Entities do not depend on use cases.", "domains": ["Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 156", "position": 156, "chunk_type": "semantic", "token_estimate": 116}
{"text": "Use cases expect input data, and they produce output data. However, a well-formed use case object: should have no inkling about the way that data is communicated to the user, or to any other component. We certainly don\u2019t want the code within the use case class to know about HTML or SQL! The use case class accepts simple request data structures for its input, and returns simple response\ndata structures as its output. These data structures are not dependent on anything. They do not derive\nfrom standard framework interfaces such as HttpRequest and HttpResponse. They know nothing of\nthe web, nor do they share any of the trappings of whatever user interface might be in place. This lack of dependencies is critical. If the request and response models are not independent, then the\nuse cases that depend on them will be indirectly bound to whatever dependencies the models carry\nwith them. You might be tempted to have these data structures contain references to Entity objects. You might\nthink this makes sense because the Entities and the request/response models share so much data. Avoid this temptation! The purpose of these two objects is very different. Over time they will change\nfor very different reasons, so tying them together in any way violates the Common Closure and Single\nResponsibility Principles. The result would be lots of tramp data, and lots of conditionals in your\ncode.", "domains": ["Domain-Driven Design", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 156", "position": 156, "chunk_type": "semantic", "token_estimate": 233}
{"text": "Business rules are the reason a software system exists. They are the core functionality. They carry the: code that makes, or saves, money. They are the family jewels. The business rules should remain pristine, unsullied by baser concerns such as the user interface or\ndatabase used. Ideally, the code that represents the business rules should be the heart of the system,\nwith lesser concerns being plugged in to them. The business rules should be the most independent and\nreusable code in the system. 1. This is Ivar Jacobson\u2019s name for this concept (I. Jacobson et al., Object Oriented Software Engineering, Addison-Wesley, 1992).", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 156", "position": 156, "chunk_type": "semantic", "token_estimate": 102}
{"text": "Imagine that you are looking at the blueprints of a building. This document, prepared by an architect,: provides the plans for the building. What do these plans tell you? If the plans you are viewing are for a single-family residence, then you\u2019ll likely see a front entrance, a\nfoyer leading to a living room, and perhaps a dining room. There will likely be a kitchen a short\ndistance away, close to the dining room. Perhaps there is a dinette area next to the kitchen, and\nprobably a family room close to that. When you looked at those plans, there would be no question that\nyou were looking at a single family home. The architecture would scream: \u201cHOME.\u201d\nNow suppose you were looking at the architecture of a library. You would likely see a grand\nentrance, an area for check-in/out clerks, reading areas, small conference rooms, and gallery after\ngallery capable of holding bookshelves for all the books in the library. That architecture would\nscream: \u201cLIBRARY\n.\u201d\nSo what does the architecture of your application scream? When you look at the top-level directory\nstructure, and the source files in the highest-level package, do they scream \u201cHealth Care System,\u201d or\n\u201cAccounting System,\u201d or \u201cInventory Management System\u201d? Or do they scream \u201cRails,\u201d or\n\u201cSpring/Hibernate,\u201d or \u201cASP\u201d?", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 158", "position": 158, "chunk_type": "semantic", "token_estimate": 213}
{"text": "true belief. They show you the way to use the framework. Often they assume an all-encompassing, all-: pervading, let-the-framework-do-everything position. This is not the position you want to take. Look at each framework with a jaded eye. View it skeptically. Yes, it might help, but at what cost? Ask yourself how you should use it, and how you should protect yourself from it. Think about how\nyou can preserve the use-case emphasis of your architecture. Develop a strategy that prevents the\nframework from taking over that architecture.", "domains": ["Design Patterns"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 160", "position": 160, "chunk_type": "semantic", "token_estimate": 87}
{"text": "If your system architecture is all about the use cases, and if you have kept your frameworks at arm\u2019s: length, then you should be able to unit-test all those use cases without any of the frameworks in place. You shouldn\u2019t need the web server running to run your tests. You shouldn\u2019t need the database\nconnected to run your tests. Your Entity objects should be plain old objects that have no dependencies\non frameworks or databases or other complications. Your use case objects should coordinate your\nEntity objects. Finally, all of them together should be testable in situ, without any of the complications\nof frameworks.", "domains": ["Domain-Driven Design"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 160", "position": 160, "chunk_type": "semantic", "token_estimate": 104}
{"text": "Your architecture should tell readers about the system, not about the frameworks you used in your: system. If you are building a health care system, then when new programmers look at the source\nrepository, their first impression should be, \u201cOh, this is a heath care system.\u201d Those new\nprogrammers should be able to learn all the use cases of the system, yet still not know how the system\nis delivered. They may come to you and say:\n\u201cWe see some things that look like models\u2014but where are the views and controllers?\u201d\nAnd you should respond:\n\u201cOh, those are details that needn\u2019t concern us at the moment. We\u2019ll decide about them later.\u201d", "domains": ["Domain-Driven Design"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 160", "position": 160, "chunk_type": "semantic", "token_estimate": 111}
{"text": "Over the last several decades we\u2019ve seen a whole range of ideas regarding the architecture of: systems. These include:\n\u2022 Hexagonal Architecture (also known as Ports and Adapters), developed by Alistair Cockburn, and\nadopted by Steve Freeman and Nat Pryce in their wonderful book Growing Object Oriented\nSoftware with Tests\n\u2022 DCI from James Coplien and Trygve Reenskaug\n\u2022 BCE, introduced by Ivar Jacobson from his book Object Oriented Software Engineering: A Use-\nCase Driven Approach\nAlthough these architectures all vary somewhat in their details, they are very similar. They all have\nthe same objective, which is the separation of concerns. They all achieve this separation by dividing\nthe software into layers. Each has at least one layer for business rules, and another layer for user and\nsystem interfaces. Each of these architectures produces systems that have the following characteristics:\n\u2022 Independent of frameworks. The architecture does not depend on the existence of some library of\nfeature-laden software. This allows you to use such frameworks as tools, rather than forcing you to\ncram your system into their limited constraints. \u2022 Testable. The business rules can be tested without the UI, database, web server, or any other", "domains": ["Design Patterns", "Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 161", "position": 161, "chunk_type": "semantic", "token_estimate": 196}
{"text": "The concentric circles in Figure 22.1 represent different areas of software. In general, the further in: you go, the higher level the software becomes. The outer circles are mechanisms. The inner circles\nare policies. The overriding rule that makes this architecture work is the Dependency Rule:\nSource code dependencies must point only inward, toward higher-level policies. Nothing in an inner circle can know anything at all about something in an outer circle. In particular,\nthe name of something declared in an outer circle must not be mentioned by the code in an inner\ncircle. That includes functions, classes, variables, or any other named software entity. By the same token, data formats declared in an outer circle should not be used by an inner circle,\nespecially if those formats are generated by a framework in an outer circle. We don\u2019t want anything in\nan outer circle to impact the inner circles.", "domains": ["Domain-Driven Design"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 162", "position": 162, "chunk_type": "semantic", "token_estimate": 150}
{"text": "ENTITIES: Entities encapsulate enterprise-wide Critical Business Rules. An entity can be an object with\nmethods, or it can be a set of data structures and functions. It doesn\u2019t matter so long as the entities can\nbe used by many different applications in the enterprise. If you don\u2019t have an enterprise and are writing just a single application, then these entities are the\nbusiness objects of the application. They encapsulate the most general and high-level rules. They are\nthe least likely to change when something external changes. For example, you would not expect these\nobjects to be affected by a change to page navigation or security. No operational change to any\nparticular application should affect the entity layer.", "domains": ["Software Quality Attributes", "Domain-Driven Design"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 163", "position": 163, "chunk_type": "semantic", "token_estimate": 117}
{"text": "The software in the interface adapters layer is a set of adapters that convert data from the format most: convenient for the use cases and entities, to the format most convenient for some external agency such\nas the database or the web. It is this layer, for example, that will wholly contain the MVC architecture\nof a GUI. The presenters, views, and controllers all belong in the interface adapters layer. The\nmodels are likely just data structures that are passed from the controllers to the use cases, and then\nback from the use cases to the presenters and views. Similarly, data is converted, in this layer, from the form most convenient for entities and use cases, to\nthe form most convenient for whatever persistence framework is being used (i.e., the database). No\ncode inward of this circle should know anything at all about the database. If the database is a SQL\ndatabase, then all SQL should be restricted to this layer\u2014and in particular to the parts of this layer\nthat have to do with the database. Also in this layer is any other adapter necessary to convert data from some external form, such as an\nexternal service, to the internal form used by the use cases and entities.", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 163", "position": 163, "chunk_type": "semantic", "token_estimate": 208}
{"text": "At the lower right of the diagram in Figure 22.1 is an example of how we cross the circle boundaries.: It shows the controllers and presenters communicating with the use cases in the next layer. Note the\nflow of control: It begins in the controller, moves through the use case, and then winds up executing in\nthe presenter. Note also the source code dependencies: Each points inward toward the use cases. We usually resolve this apparent contradiction by using the Dependency Inversion Principle. In a\nlanguage like Java, for example, we would arrange interfaces and inheritance relationships such that\nthe source code dependencies oppose the flow of control at just the right points across the boundary. For example, suppose the use case needs to call the presenter. This call must not be direct because\nthat would violate the Dependency Rule: No name in an outer circle can be mentioned by an inner\ncircle. So we have the use case call an interface (shown in Figure 22.1 as \u201cuse case output port\u201d) in\nthe inner circle, and have the presenter in the outer circle implement it. The same technique is used to cross all the boundaries in the architectures. We take advantage of\ndynamic polymorphism to create source code dependencies that oppose the flow of control so that we\ncan conform to the Dependency Rule, no matter which direction the flow of control travels.", "domains": ["Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 164", "position": 164, "chunk_type": "semantic", "token_estimate": 233}
{"text": "Typically the data that crosses the boundaries consists of simple data structures. You can use basic: structs or simple data transfer objects if you like. Or the data can simply be arguments in function\ncalls. Or you can pack it into a hashmap, or construct it into an object. The important thing is that\nisolated, simple data structures are passed across the boundaries. We don\u2019t want to cheat and pass\nEntity objects or database rows. We don\u2019t want the data structures to have any kind of dependency", "domains": ["Domain-Driven Design"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 164", "position": 164, "chunk_type": "semantic", "token_estimate": 87}
{"text": "The diagram in Figure 22.2 shows a typical scenario for a web-based Java system using a database.: The web server gathers input data from the user and hands it to the Controller on the upper left. The\nController packages that data into a plain old Java object and passes this object through the\nInputBoundary to the UseCaseInteractor. The UseCaseInteractor interprets that data and uses\nit to control the dance of the Entities. It also uses the DataAccessInterface to bring the data used\nby those Entities into memory from the Database. Upon completion, the UseCaseInteractor\ngathers data from the Entities and constructs the OutputData as another plain old Java object. The\nOutputData is then passed through the OutputBoundary interface to the Presenter. Figure 22.2 A typical scenario for a web-based Java system utilizing a database\nThe job of the Presenter is to repackage the OutputData into viewable form as the ViewModel,\nwhich is yet another plain old Java object. The ViewModel contains mostly Strings and flags that the\nView uses to display the data. Whereas the OutputData may contain Date objects, the Presenter\nwill load the ViewModel with corresponding Strings already formatted properly for the user. The\nsame is true of Currency objects or any other business-related data. Button and MenuItem names\nare placed in the ViewModel, as are flags that tell the View whether those Buttons and MenuItems\nshould be gray.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 165", "position": 165, "chunk_type": "semantic", "token_estimate": 231}
{"text": "The Humble Object pattern1 is a design pattern that was originally identified as a way to help unit: testers to separate behaviors that are hard to test from behaviors that are easy to test. The idea is very\nsimple: Split the behaviors into two modules or classes. One of those modules is humble; it contains\nall the hard-to-test behaviors stripped down to their barest essence. The other module contains all the\ntestable behaviors that were stripped out of the humble object. For example, GUIs are hard to unit test because it is very difficult to write tests that can see the\nscreen and check that the appropriate elements are displayed there. However, most of the behavior of\na GUI is, in fact, easy to test. Using the Humble Object pattern, we can separate these two kinds of\nbehaviors into two different classes called the Presenter and the View.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 167", "position": 167, "chunk_type": "semantic", "token_estimate": 148}
{"text": "It has long been known that testability is an attribute of good architectures. The Humble Object: pattern is a good example, because the separation of the behaviors into testable and non-testable parts\noften defines an architectural boundary. The Presenter/View boundary is one of these boundaries, but\nthere are many others.", "domains": ["Software Quality Attributes"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 168", "position": 168, "chunk_type": "semantic", "token_estimate": 50}
{"text": "Between the use case interactors and the database are the database gateways.2 These gateways are: polymorphic interfaces that contain methods for every create, read, update, or delete operation that\ncan be performed by the application on the database. For example, if the application needs to know\nthe last names of all the users who logged in yesterday, then the UserGateway interface will have a\nmethod named getLastNamesOfUsersWhoLoggedInAfter that takes a Date as its argument and\nreturns a list of last names. Recall that we do not allow SQL in the use cases layer; instead, we use gateway interfaces that have", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 168", "position": 168, "chunk_type": "semantic", "token_estimate": 100}
{"text": "appropriate methods. Those gateways are implemented by classes in the database layer. That: implementation is the humble object. It simply uses SQL, or whatever the interface to the database is,\nto access the data required by each of the methods. The interactors, in contrast, are not humble\nbecause they encapsulate application-specific business rules. Although they are not humble, those\ninteractors are testable, because the gateways can be replaced with appropriate stubs and test-\ndoubles.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 169", "position": 169, "chunk_type": "semantic", "token_estimate": 74}
{"text": "What about services? If your application must communicate with other services, or if your: application provides a set of services, will we find the Humble Object pattern creating a service\nboundary? Of course! The application will load data into simple data structures and then pass those structures\nacross the boundary to modules that properly format the data and send it to external services. On the\ninput side, the service listeners will receive data from the service interface and format it into a\nsimple data structure that can be used by the application. That data structure is then passed across the\nservice boundary.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 169", "position": 169, "chunk_type": "semantic", "token_estimate": 102}
{"text": "At each architectural boundary, we are likely to find the Humble Object pattern lurking somewhere: nearby. The communication across that boundary will almost always involve some kind of simple\ndata structure, and the boundary will frequently divide something that is hard to test from something\nthat is easy to test. The use of this pattern at architectural boundaries vastly increases the testability of", "domains": ["Software Quality Attributes"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 169", "position": 169, "chunk_type": "semantic", "token_estimate": 63}
{"text": "Full-fledged architectural boundaries are expensive. They require reciprocal polymorphic Boundary: interfaces, Input and Output data structures, and all of the dependency management necessary to\nisolate the two sides into independently compilable and deployable components. That takes a lot of\nwork. It\u2019s also a lot of work to maintain. In many situations, a good architect might judge that the expense of such a boundary is too high\u2014but\nmight still want to hold a place for such a boundary in case it is needed later. This kind of anticipatory design is often frowned upon by many in the Agile community as a violation\nof YAGNI: \u201cYou Aren\u2019t Going to Need It.\u201d Architects, however, sometimes look at the problem and\nthink, \u201cYeah, but I might.\u201d In that case, they may implement a partial boundary.", "domains": ["Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 171", "position": 171, "chunk_type": "semantic", "token_estimate": 131}
{"text": "One way to construct a partial boundary is to do all the work necessary to create independently: compilable and deployable components, and then simply keep them together in the same component. The reciprocal interfaces are there, the input/output data structures are there, and everything is all set\nup\u2014but we compile and deploy all of them as a single component. Obviously, this kind of partial boundary requires the same amount of code and preparatory design", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 171", "position": 171, "chunk_type": "semantic", "token_estimate": 74}
{"text": "work as a full boundary. However, it does not require the administration of multiple components.: There\u2019s no version number tracking or release management burden. That difference should not be\ntaken lightly. This was the early strategy behind FitNesse. The web server component of FitNesse was designed\nto be separable from the wiki and testing part of FitNesse. The idea was that we might want to\ncreate other web-based applications by using that web component. At the same, we did not want\nusers to have to download two components. Recall that one of our design goals was \u201cdownload and\ngo.\u201d It was our intent that users would download one jar file and execute it without having to hunt for\nother jar files, work out version compatibilities, and so on. The story of FitNesse also points out one of the dangers of this approach. Over time, as it became\nclear that there would never be a need for a separate web component, the separation between the web\ncomponent and the wiki component began to weaken. Dependencies started to cross the line in the\nwrong direction. Nowadays, it would be something of a chore to re-separate them. ONE-DIMENSIONAL BOUNDARIES\nThe full-fledged architectural boundary uses reciprocal boundary interfaces to maintain isolation in\nboth directions. Maintaining separation in both directions is expensive both in initial setup and in\nongoing maintenance. A simpler structure that serves to hold the place for later extension to a full-fledged boundary is\nshown in Figure 24.1. It exemplifies the traditional Strategy pattern. A ServiceBoundary interface is\nused by clients and implemented by ServiceImpl classes. Figure 24.1 The Strategy pattern\nIt should be clear that this sets the stage for a future architectural boundary. The necessary\ndependency inversion is in place in an attempt to isolate the Client from the ServiceImpl. It should\nalso be clear that the separation can degrade pretty rapidly, as shown by the nasty dotted arrow in the", "domains": ["Design Patterns", "Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 172", "position": 172, "chunk_type": "semantic", "token_estimate": 321}
{"text": "An even simpler boundary is the Facade pattern, illustrated in Figure 24.2. In this case, even the: dependency inversion is sacrificed. The boundary is simply defined by the Facade class, which lists\nall the services as methods, and deploys the service calls to classes that the client is not supposed to\naccess. Figure 24.2 The Facade pattern\nNote, however, that the Client has a transitive dependency on all those service classes. In static\nlanguages, a change to the source code in one of the Service classes will force the Client to\nrecompile. Also, you can imagine how easy backchannels are to create with this structure.", "domains": ["Design Patterns", "Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 173", "position": 173, "chunk_type": "semantic", "token_estimate": 105}
{"text": "It is easy to think of systems as being composed of three components: UI, business rules, and: database. For some simple systems, this is sufficient. For most systems, though, the number of\ncomponents is larger than that. Consider, for example, a simple computer game. It is easy to imagine the three components. The UI\nhandles all messages from the player to the game rules. The game rules store the state of the game in\nsome kind of persistent data structure. But is that all there is?", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 174", "position": 174, "chunk_type": "semantic", "token_estimate": 86}
{"text": "Let\u2019s put some flesh on these bones. Let\u2019s assume that the game is the venerable Hunt the Wumpus: adventure game from 1972. This text-based game uses very simple commands like GO EAST and\nSHOOT WEST. The player enters a command, and the computer responds with what the player sees,\nsmells, hears, and experiences. The player is hunting for a Wumpus in a system of caverns, and must\navoid traps, pits, and other dangers lying in wait. If you are interested, the rules of the game are easy\nto find on the web. Let\u2019s assume that we\u2019ll keep the text-based UI, but decouple it from the game rules so that our version\ncan use different languages in different markets. The game rules will communicate with the UI\ncomponent using a language-independent API, and the UI will translate the API into the appropriate", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 174", "position": 174, "chunk_type": "semantic", "token_estimate": 141}
{"text": "human language.: If the source code dependencies are properly managed, as shown in Figure 25.1, then any number of\nUI components can reuse the same game rules. The game rules do not know, nor do they care, which\nhuman language is being used. Figure 25.1 Any number of UI components can reuse the game rules\nLet\u2019s also assume that the state of the game is maintained on some persistent store\u2014perhaps in flash,\nor perhaps in the cloud, or maybe just in RAM. In any of those cases, we don\u2019t want the game rules to\nknow the details. So, again, we\u2019ll create an API that the game rules can use to communicate with the\ndata storage component. We don\u2019t want the game rules to know anything about the different kinds of data storage, so the\ndependencies have to be properly directed following the Dependency Rule, as shown in Figure 25.2. Figure 25.2 Following the Dependency Rule\nCLEAN ARCHITECTURE? It should be clear that we could easily apply the clean architecture approach in this context,1 with all\nthe use cases, boundaries, entities, and corresponding data structures. But have we really found all the", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 175", "position": 175, "chunk_type": "semantic", "token_estimate": 191}
{"text": "significant architectural boundaries?: For example, language is not the only axis of change for the UI. We also might want to vary the\nmechanism by which we communicate the text. For example, we might want to use a normal shell\nwindow, or text messages, or a chat application. There are many different possibilities. That means that there is a potential architectural boundary defined by this axis of change. Perhaps we\nshould construct an API that crosses that boundary and isolates the language from the communications\nmechanism; that idea is illustrated in Figure 25.3. Figure 25.3 The revised diagram\nThe diagram in Figure 25.3 has gotten a little complicated, but should contain no surprises. The\ndashed outlines indicate abstract components that define an API that is implemented by the\ncomponents above or below them. For example, the Language API is implemented by English and\nSpanish. GameRules communicates with Language through an API that GameRules defines and Language\nimplements. Language communicates with TextDelivery using an API that Language defines but\nTextDelivery implements. The API is defined and owned by the user, rather than by the\nimplementer. If we were to look inside GameRules, we would find polymorphic Boundary interfaces used by the\ncode inside GameRules and implemented by the code inside the Language component. We would\nalso find polymorphic Boundary interfaces used by Language and implemented by code inside\nGameRules. If we were to look inside of Language, we would find the same thing: Polymorphic Boundary\ninterfaces implemented by the code inside TextDelivery, and polymorphic Boundary interfaces\nused by TextDelivery and implemented by Language. In each case, the API defined by those Boundary interfaces is owned by the upstream component. The variations, such as English, SMS, and CloudData, are provided by polymorphic interfaces", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 176", "position": 176, "chunk_type": "semantic", "token_estimate": 291}
{"text": "defined in the abstract API component, and implemented by the concrete components that serve them.: For example, we would expect polymorphic interfaces defined in Language to be implemented by\nEnglish and Spanish. We can simplify this diagram by eliminating all the variations and focusing on just the API\ncomponents. Figure 25.4 shows this diagram. Figure 25.4 Simplified diagram\nNotice that the diagram is oriented in Figure 25.4 so that all the arrows point up. This puts\nGameRules at the top. This orientation makes sense because GameRules is the component that\ncontains the highest-level policies. Consider the direction of information flow. All input comes from the user through the TextDelivery\ncomponent at the bottom left. That information rises through the Language component, getting\ntranslated into commands to GameRules. GameRules processes the user input and sends appropriate\ndata down to DataStorage at the lower right. GameRules then sends output back down to Language, which translates the API back to the\nappropriate language and then delivers that language to the user through TextDelivery. This organization effectively divides the flow of data into two streams.2 The stream on the left is\nconcerned with communicating with the user, and the stream on the right is concerned with data\npersistence. Both streams meet at the top3 at GameRules, which is the ultimate processor of the data\nthat goes through both streams.", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 177", "position": 177, "chunk_type": "semantic", "token_estimate": 225}
{"text": "Are there always two data streams as in this example? No, not at all. Imagine that we would like to: play Hunt the Wumpus on the net with multiple players. In this case, we would need a network\ncomponent, like that shown in Figure 25.5. This organization divides the data flow into three streams,", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 177", "position": 177, "chunk_type": "semantic", "token_estimate": 54}
{"text": "all controlled by the GameRules.: Figure 25.5 Adding a network component\nSo, as systems become more complex, the component structure may split into many such streams.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 178", "position": 178, "chunk_type": "semantic", "token_estimate": 26}
{"text": "At this point you may be thinking that all the streams eventually meet at the top in a single component.: If only life were so simple! The reality, of course, is much more complex. Consider the GameRules component for Hunt the Wumpus. Part of the game rules deal with the\nmechanics of the map. They know how the caverns are connected, and which objects are located in\neach cavern. They know how to move the player from cavern to cavern, and how to determine the\nevents that the player must deal with. But there is another set of policies at an even higher level\u2014policies that know the health of the\nplayer, and the cost or benefit of a particular event. These policies could cause the player to gradually\nlose health, or to gain health by discovering food. The lower-level mechanics policy would declare\nevents to this higher-level policy, such as FoundFood or FellInPit. The higher-level policy would\nthen manage the state of the player (as shown in Figure 25.6). Eventually that policy would decide\nwhether the player wins or loses.", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 178", "position": 178, "chunk_type": "semantic", "token_estimate": 180}
{"text": "implemented in 200 lines of Kornshell, and extrapolated it out with all these crazy architectural: boundaries? This example is intended to show that architectural boundaries exist everywhere. We, as architects,\nmust be careful to recognize when they are needed. We also have to be aware that such boundaries,\nwhen fully implemented, are expensive. At the same time, we have to recognize that when such\nboundaries are ignored, they are very expensive to add in later\u2014even in the presence of\ncomprehensive test-suites and refactoring discipline. So what do we do, we architects? The answer is dissatisfying. On the one hand, some very smart\npeople have told us, over the years, that we should not anticipate the need for abstraction. This is the\nphilosophy of YAGNI: \u201cYou aren\u2019t going to need it.\u201d There is wisdom in this message, since over-\nengineering is often much worse than under-engineering. On the other hand, when you discover that\nyou truly do need an architectural boundary where none exists, the costs and risks can be very high to\nadd such a boundary. So there you have it. O Software Architect, you must see the future. You must guess\u2014intelligently. You must weigh the costs and determine where the architectural boundaries lie, and which should be\nfully implemented, and which should be partially implemented, and which should be ignored. But this is not a one-time decision. You don\u2019t simply decide at the start of a project which boundaries\nto implement and which to ignore. Rather, you watch. You pay attention as the system evolves. You\nnote where boundaries may be required, and then carefully watch for the first inkling of friction\nbecause those boundaries don\u2019t exist. At that point, you weigh the costs of implementing those boundaries versus the cost of ignoring them\n\u2014and you review that decision frequently. Your goal is to implement the boundaries right at the\ninflection point where the cost of implementing becomes less than the cost of ignoring. It takes a watchful eye. 1. It should be just as clear that we would not apply the clean architecture approach to something as trivial as this game. After all, the\nentire program can probably be written in 200 lines of code or less. In this case, we\u2019re using a simple program as a proxy for a much\nlarger system with significant architectural boundaries. 2.", "domains": ["Design Patterns", "Design Principles"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 180", "position": 180, "chunk_type": "semantic", "token_estimate": 390}
{"text": "implemented in 200 lines of Kornshell, and extrapolated it out with all these crazy architectural: In this case, we\u2019re using a simple program as a proxy for a much\nlarger system with significant architectural boundaries. 2. If you are confused by the direction of the arrows, remember that they point in the direction of source code dependencies, not in the\ndirection of data flow. 3. In days long past, we would have called that top component the Central Transform. See Practical Guide to Structured Systems\nDesign, 2nd ed., Meilir Page-Jones, 1988.", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 180", "position": 180, "chunk_type": "semantic", "token_estimate": 91}
{"text": "In every system, there is at least one component that creates, coordinates, and oversees the others. I: call this component Main.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 181", "position": 181, "chunk_type": "semantic", "token_estimate": 21}
{"text": "The Main component is the ultimate detail\u2014the lowest-level policy. It is the initial entry point of the: system. Nothing, other than the operating system, depends on it. Its job is to create all the Factories,\nStrategies, and other global facilities, and then hand control over to the high-level abstract portions of\nthe system. It is in this Main component that dependencies should be injected by a Dependency Injection\nframework. Once they are injected into Main, Main should distribute those dependencies normally,\nwithout using the framework. Think of Main as the dirtiest of all the dirty components. Consider the following Main component from a recent version of Hunt the Wumpus. Notice how it\nloads up all the strings that we don\u2019t want the main body of the code to know about. Click here to view code image", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 181", "position": 181, "chunk_type": "semantic", "token_estimate": 136}
{"text": "public class Main implements HtwMessageReceiver {: private static HuntTheWumpus game;\n  private static int hitPoints = 10;\n  private static final List<String> caverns = new   ArrayList<>();\n  private static final String[] environments = new String[]{\n    \"bright\",\n    \"humid\",\n    \"dry\",\n    \"creepy\",\n    \"ugly\",\n    \"foggy\",\n    \"hot\",\n    \"cold\",\n    \"drafty\",\n    \"dreadful\"\n  };\n \n  private static final String[] shapes = new String[] {\n    \"round\",\n    \"square\",\n    \"oval\",\n    \"irregular\",\n    \"long\",\n    \"craggy\",\n    \"rough\",\n    \"tall\",\n    \"narrow\"\n  };\n \n  private static final String[] cavernTypes = new String[] {\n    \"cavern\",\n    \"room\",\n    \"chamber\",\n    \"catacomb\",\n    \"crevasse\",\n    \"cell\",\n    \"tunnel\",\n    \"passageway\",\n    \"hall\",\n    \"expanse\"\n  };\n \n  private static final String[] adornments = new String[] {\n   \"smelling of sulfur\",\n    \"with engravings on the walls\",\n    \"with a bumpy floor\",\n    \"\",\n    \"littered with garbage\",\n    \"spattered with guano\",\n    \"with piles of Wumpus droppings\",\n    \"with bones scattered around\",\n    \"with a corpse on the floor\",\n    \"that seems to vibrate\",\n    \"that feels stuffy\",\n    \"that fills you with dread\"\n  };\nNow here\u2019s the main function. Notice how it uses the HtwFactory to create the game. It passes in the\nname of the class, htw.game.HuntTheWumpusFacade, because that class is even dirtier than Main.", "domains": ["Design Patterns", "Design Principles", "Domain-Driven Design"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 182", "position": 182, "chunk_type": "semantic", "token_estimate": 170}
{"text": "This prevents changes in that class from causing Main to recompile/redeploy.: Click here to view code image\npublic static void main(String[] args) throws IOException {\n   game = HtwFactory.makeGame(\"htw.game.HuntTheWumpusFacade\",\n                                 new Main());\n   createMap();\n   BufferedReader br = \n     new BufferedReader(new InputStreamReader(System.in));\n   game.makeRestCommand().execute();\n   while (true) {\n     System.out.println(game.getPlayerCavern());\n     System.out.println(\"Health: \" + hitPoints + \" arrows: \" + \n                           game.getQuiver());\n     HuntTheWumpus.Command c = game.makeRestCommand();\n      System.out.println(\">\");\n      String command = br.readLine();\n      if (command.equalsIgnoreCase(\"e\"))\n        c = game.makeMoveCommand(EAST);\n      else if (command.equalsIgnoreCase(\"w\"))\n        c = game.makeMoveCommand(WEST);\n      else if (command.equalsIgnoreCase(\"n\"))\n        c = game.makeMoveCommand(NORTH);\n      else if (command.equalsIgnoreCase(\"s\"))\n        c = game.makeMoveCommand(SOUTH);\n      else if (command.equalsIgnoreCase(\"r\"))\n        c = game.makeRestCommand();\n      else if (command.equalsIgnoreCase(\"sw\"))\n        c = game.makeShootCommand(WEST);\n      else if (command.equalsIgnoreCase(\"se\"))\n        c = game.makeShootCommand(EAST);\n      else if (command.equalsIgnoreCase(\"sn\"))\n        c = game.makeShootCommand(NORTH);\n      else if (command.equalsIgnoreCase(\"ss\"))\n        c = game.makeShootCommand(SOUTH);\n      else if (command.equalsIgnoreCase(\"q\"))\n        return;\n \n      c.execute();\n    }\n  }\nNotice also that main creates the input stream and contains the main loop of the game, interpreting the\nsimple input commands, but then defers all processing to other, higher-level components. Finally, notice that main creates the map. Click here to view code image\nprivate static void createMap() {\n   int nCaverns = (int) (Math.random() * 30.0 + 10.0);\n   while (nCaverns-- > 0)\n     caverns.add(makeName());\n \n    for (String cavern : caverns) {\n      maybeConnectCavern(cavern, NORTH);\n      maybeConnectCavern(cavern, SOUTH);", "domains": ["Design Patterns", "Domain-Driven Design", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 183", "position": 183, "chunk_type": "semantic", "token_estimate": 193}
{"text": "maybeConnectCavern(cavern, EAST);: EAST);\n      maybeConnectCavern(cavern, WEST);\n    }\n \n    String playerCavern = anyCavern();\n    game.setPlayerCavern(playerCavern);\n    game.setWumpusCavern(anyOther(playerCavern));\n    game.addBatCavern(anyOther(playerCavern));\n    game.addBatCavern(anyOther(playerCavern));\n    game.addBatCavern(anyOther(playerCavern));\n \n    game.addPitCavern(anyOther(playerCavern));\n    game.addPitCavern(anyOther(playerCavern));\n    game.addPitCavern(anyOther(playerCavern));\n \n    game.setQuiver(5);\n  }\n \n  // much code removed\u2026\n}\nThe point is that Main is a dirty low-level module in the outermost circle of the clean architecture. It\nloads everything up for the high level system, and then hands control over to it.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 184", "position": 184, "chunk_type": "semantic", "token_estimate": 59}
{"text": "Think of Main as a plugin to the application\u2014a plugin that sets up the initial conditions and: configurations, gathers all the outside resources, and then hands control over to the high-level policy\nof the application. Since it is a plugin, it is possible to have many Main components, one for each\nconfiguration of your application. For example, you could have a Main plugin for Dev, another for Test, and yet another for Production. You could also have a Main plugin for each country you deploy to, or each jurisdiction, or each\ncustomer. When you think about Main as a plugin component, sitting behind an architectural boundary, the\nproblem of configuration becomes a lot easier to solve.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 184", "position": 184, "chunk_type": "semantic", "token_estimate": 116}
{"text": "27: SERVICES: GREAT AND SMALL\nService-oriented \u201carchitectures\u201d and micro-service \u201carchitectures\u201d have become very popular of\nlate. The reasons for their current popularity include the following:\n\u2022 Services seem to be strongly decoupled from each other. As we shall see, this is only partially true. \u2022 Services appear to support independence of development and deployment. Again, as we shall see,\nthis is only partially true. SERVICE ARCHITECTURE? First, let\u2019s consider the notion that using services, by their nature, is an architecture. This is patently\nuntrue. The architecture of a system is defined by boundaries that separate high-level policy from\nlow-level detail and follow the Dependency Rule. Services that simply separate application\nbehaviors are little more than expensive function calls, and are not necessarily architecturally\nsignificant. This is not to say that all services should be architecturally significant. There are often substantial\nbenefits to creating services that separate functionality across processes and platforms\u2014whether they\nobey the Dependency Rule or not. It\u2019s just that services, in and of themselves, do not define an\narchitecture.", "domains": ["Architectural Patterns and Styles"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 185", "position": 185, "chunk_type": "semantic", "token_estimate": 171}
{"text": "A helpful analogy is the organization of functions. The architecture of a monolithic or component-: based system is defined by certain function calls that cross architectural boundaries and follow the\nDependency Rule. Many other functions in those systems, however, simply separate one behavior\nfrom another and are not architecturally significant. So it is with services. Services are, after all, just function calls across process and/or platform\nboundaries. Some of those services are architecturally significant, and some aren\u2019t. Our interest, in\nthis chapter, is with the former. SERVICE BENEFITS? The question mark in the preceding heading indicates that this section is going to challenge the current\npopular orthodoxy of service architecture. Let\u2019s tackle the benefits one at a time.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 186", "position": 186, "chunk_type": "semantic", "token_estimate": 118}
{"text": "One of the big supposed benefits of breaking a system up into services is that services are strongly: decoupled from each other. After all, each service runs in a different process, or even a different\nprocessor; therefore those services do not have access to each other\u2019s variables. What\u2019s more, the\ninterface of each service must be well defined. There is certainly some truth to this\u2014but not very much truth. Yes, services are decoupled at the level\nof individual variables. However, they can still be coupled by shared resources within a processor,\nor on the network. What\u2019s more, they are strongly coupled by the data they share. For example, if a new field is added to a data record that is passed between services, then every\nservice that operates on the new field must be changed. The services must also strongly agree about\nthe interpretation of the data in that field. Thus those services are strongly coupled to the data record\nand, therefore, indirectly coupled to each other. As for interfaces being well defined, that\u2019s certainly true\u2014but it is no less true for functions. Service\ninterfaces are no more formal, no more rigorous, and no better defined than function interfaces. Clearly, then, this benefit is something of an illusion.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 186", "position": 186, "chunk_type": "semantic", "token_estimate": 208}
{"text": "Another of the supposed benefits of services is that they can be owned and operated by a dedicated: team. That team can be responsible for writing, maintaining, and operating the service as part of a\ndev-ops strategy. This independence of development and deployment is presumed to be scalable. It is\nbelieved that large enterprise systems can be created from dozens, hundreds, or even thousands of\nindependently developable and deployable services. Development, maintenance, and operation of the\nsystem can be partitioned between a similar number of independent teams. There is some truth to this belief\u2014but only some. First, history has shown that large enterprise", "domains": ["Design Patterns"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 186", "position": 186, "chunk_type": "semantic", "token_estimate": 103}
{"text": "systems can be built from monoliths and component-based systems as well as service-based systems.: Thus services are not the only option for building scalable systems. Second, the decoupling fallacy means that services cannot always be independently developed,\ndeployed, and operated. To the extent that they are coupled by data or behavior, the development,\ndeployment, and operation must be coordinated.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 187", "position": 187, "chunk_type": "semantic", "token_estimate": 59}
{"text": "How would we have solved this problem in a component-based architecture? Careful consideration: of the SOLID design principles would have prompted us to create a set of classes that could be\npolymorphically extended to handle new features. The diagram in Figure 27.2 shows the strategy. The classes in this diagram roughly correspond to the\nservices shown in Figure 27.1. However, note the boundaries. Note also that the dependencies follow\nthe Dependency Rule. Much of the logic of the original services is preserved within the base classes of the object model. However, that portion of the logic that was specific to rides has been extracted into a Rides\ncomponent. The new feature for kittens has been placed into a Kittens component. These two\ncomponents override the abstract base classes in the original components using a pattern such as\nTemplate Method or Strategy. Note again that the two new components, Rides and Kittens, follow the Dependency Rule. Note", "domains": ["Design Patterns", "Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 188", "position": 188, "chunk_type": "semantic", "token_estimate": 156}
{"text": "also that the classes that implement those features are created by factories under the control of the UI.: Clearly, in this scheme, when the Kitty feature is implemented, the TaxiUI must change. But nothing\nelse needs to be changed. Rather, a new jar file, or Gem, or DLL is added to the system and\ndynamically loaded at runtime. Thus the Kitty feature is decoupled, and independently developable and deployable. Figure 27.2 Using an object-oriented approach to deal with cross-cutting concerns\nCOMPONENT-BASED SERVICES\nThe obvious question is: Can we do that for services? And the answer is, of course: Yes! Services do\nnot need to be little monoliths. Services can, instead, be designed using the SOLID principles, and\ngiven a component structure so that new components can be added to them without changing the", "domains": ["Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 189", "position": 189, "chunk_type": "semantic", "token_estimate": 133}
{"text": "existing components within the service.: Think of a service in Java as a set of abstract classes in one or more jar files. hink of each new\nfeature or feature extension as another jar file that contains classes that extend the abstract classes in\nthe first jar files. Deploying a new feature then becomes not a matter of redeploying the services, but\nrather a matter of simply adding the new jar files to the load paths of those services. In other words,\nadding new features conforms to the Open-Closed Principle. The service diagram in Figure 27.3 shows the structure. The services still exist as before, but each\nhas its own internal component design, allowing new features to be added as new derivative classes. Those derivative classes live within their own components. Figure 27.3 Each service has its own internal component design, enabling new features to be added as new derivative classes\nCROSS-CUTTING CONCERNS\nWhat we have learned is that architectural boundaries do not fall between services. Rather, those\nboundaries run through the services, dividing them into components.", "domains": ["Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 190", "position": 190, "chunk_type": "semantic", "token_estimate": 177}
{"text": "To deal with the cross-cutting concerns that all significant systems face, services must be designed: with internal component architectures that follow the Dependency Rule, as shown in the diagram in\nFigure 27.4. Those services do not define the architectural boundaries of the system; instead, the\ncomponents within the services do. Figure 27.4 Services must be designed with internal component architectures that follow the Dependency Rule", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 191", "position": 191, "chunk_type": "semantic", "token_estimate": 65}
{"text": "As useful as services are to the scalability and develop-ability of a system, they are not, in and of: themselves, architecturally significant elements. The architecture of a system is defined by the\nboundaries drawn within that system, and by the dependencies that cross those boundaries. That\narchitecture is not defined by the physical mechanisms by which elements communicate and execute. A service might be a single component, completely surrounded by an architectural boundary. Alternatively, a service might be composed of several components separated by architectural\nboundaries. In rare2 cases, clients and services may be so coupled as to have no architectural\nsignificance whatever. 1. Therefore the number of micro-services will be roughly equal to the number of programmers. 2. We hope they are rare. Unfortunately, experience suggests otherwise.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 191", "position": 191, "chunk_type": "semantic", "token_estimate": 128}
{"text": "There is a great deal of confusion about tests. Are they part of the system? Are they separate from the: system? Which kinds of tests are there? Are unit tests and integration tests different things? What\nabout acceptance tests, functional tests, Cucumber tests, TDD tests, BDD tests, component tests, and\nso on? It is not the role of this book to get embroiled in that particular debate, and fortunately it isn\u2019t\nnecessary. From an architectural point of view, all tests are the same. Whether they are the tiny little\ntests created by TDD, or large FitNesse, Cucumber, SpecFlow, or JBehave tests, they are\narchitecturally equivalent. Tests, by their very nature, follow the Dependency Rule; they are very detailed and concrete; and they\nalways depend inward toward the code being tested. In fact, you can think of the tests as the outermost\ncircle in the architecture. Nothing within the system depends on the tests, and the tests always depend\ninward on the components of the system.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 192", "position": 192, "chunk_type": "semantic", "token_estimate": 165}
{"text": "Tests are also independently deployable. In fact, most of the time they are deployed in test systems,: rather than in production systems. So, even in systems where independent deployment is not\notherwise necessary, the tests will still be independently deployed. Tests are the most isolated system component. They are not necessary for system operation. No user\ndepends on them. Their role is to support development, not operation. And yet, they are no less a\nsystem component than any other. In fact, in many ways they represent the model that all other system\ncomponents should follow.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 193", "position": 193, "chunk_type": "semantic", "token_estimate": 95}
{"text": "The extreme isolation of the tests, combined with the fact that they are not usually deployed, often: causes developers to think that tests fall outside of the design of the system. This is a catastrophic\npoint of view. Tests that are not well integrated into the design of the system tend to be fragile, and\nthey make the system rigid and difficult to change. The issue, of course, is coupling. Tests that are strongly coupled to the system must change along with\nthe system. Even the most trivial change to a system component can cause many coupled tests to break\nor require changes. This situation can become acute. Changes to common system components can cause hundreds, or even\nthousands, of tests to break. This is known as the Fragile Tests Problem. It is not hard to see how this can happen. Imagine, for example, a suite of tests that use the GUI to\nverify business rules. Such tests may start on the login screen and then navigate through the page\nstructure until they can check particular business rules. Any change to the login page, or the navigation\nstructure, can cause an enormous number of tests to break. Fragile tests often have the perverse effect of making the system rigid. When developers realize that\nsimple changes to the system can cause massive test failures, they may resist making those changes. For example, imagine the conversation between the development team and a marketing team that\nrequests a simple change to the page navigation structure that will cause 1000 tests to break. The solution is to design for testability. The first rule of software design\u2014whether for testability or\nfor any other reason\u2014is always the same: Don\u2019t depend on volatile things. GUIs are volatile. Test\nsuites that operate the system through the GUI must be fragile. Therefore design the system, and the\ntests, so that business rules can be tested without using the GUI.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 193", "position": 193, "chunk_type": "semantic", "token_estimate": 320}
{"text": "The way to accomplish this goal is to create a specific API that the tests can use to verify all the: business rules. This API should have superpowers that allow the tests to avoid security constraints,\nbypass expensive resources (such as databases), and force the system into particular testable states. This API will be a superset of the suite of interactors and interface adapters that are used by the", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 193", "position": 193, "chunk_type": "semantic", "token_estimate": 69}
{"text": "user interface.: The purpose of the testing API is to decouple the tests from the application. This decoupling\nencompasses more than just detaching the tests from the UI: The goal is to decouple the structure of\nthe tests from the structure of the application.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 194", "position": 194, "chunk_type": "semantic", "token_estimate": 44}
{"text": "Structural coupling is one of the strongest, and most insidious, forms of test coupling. Imagine a test: suite that has a test class for every production class, and a set of test methods for every production\nmethod. Such a test suite is deeply coupled to the structure of the application. When one of those production methods or classes changes, a large number of tests must change as\nwell. Consequently, the tests are fragile, and they make the production code rigid. The role of the testing API is to hide the structure of the application from the tests. This allows the\nproduction code to be refactored and evolved in ways that don\u2019t affect the tests. It also allows the\ntests to be refactored and evolved in ways that don\u2019t affect the production code. This separation of evolution is necessary because as time passes, the tests tend to become\nincreasingly more concrete and specific. In contrast, the production code tends to become\nincreasingly more abstract and general. Strong structural coupling prevents\u2014or at least impedes\u2014\nthis necessary evolution, and prevents the production code from being as general, and flexible, as it\ncould be.", "domains": ["Design Patterns"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 194", "position": 194, "chunk_type": "semantic", "token_estimate": 190}
{"text": "The superpowers of the testing API could be dangerous if they were deployed in production systems.: If this is a concern, then the testing API, and the dangerous parts of its implementation, should be kept\nin a separate, independently deployable component.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 194", "position": 194, "chunk_type": "semantic", "token_estimate": 41}
{"text": "alternatives:: \u2022 \u201cFirmware is held in non-volatile memory devices such as ROM, EPROM, or flash memory.\u201d\n(https://en.wikipedia.org/wiki/Firmware)\n\u2022 \u201cFirmware is a software program or set of instructions programmed on a hardware device.\u201d\n(https://techterms.com/definition/firmware)\n\u2022 \u201cFirmware is software that is embedded in a piece of hardware.\u201d (https://www.lifewire.com/what-\nis-firmware-2625881)\n\u2022 Firmware is \u201cSoftware (programs or data) that has been written onto read-only memory (ROM).\u201d\n(http://www.webopedia.com/TERM/F/firmware.html)\nDoug\u2019s statement makes me realize that these accepted definitions of firmware are wrong, or at least\nobsolete. Firmware does not mean code lives in ROM. It\u2019s not firmware because of where it is\nstored; rather, it is firmware because of what it depends on and how hard it is to change as hardware\nevolves. Hardware does evolve (pause and look at your for phone for evidence), so we should\nstructure our embedded code with that reality in mind. I have nothing against firmware, or firmware engineers (I\u2019ve been known to write some firmware\nmyself). But what we really need is less firmware and more software. Actually, I am disappointed\nthat firmware engineers write so much firmware! Non-embedded engineers also write firmware! You non-embedded developers essentially write\nfirmware whenever you bury SQL in your code or when you spread platform dependencies throughout\nyour code. Android app developers write firmware when they don\u2019t separate their business logic\nfrom the Android API. I\u2019ve been involved in a lot of efforts where the line between the product code (the software) and the\ncode that interacts with the product\u2019s hardware (the firmware) is fuzzy to the point of nonexistence. For example, in the late 1990s I had the fun of helping redesign a communications subsystem that was\ntransitioning from time-division multiplexing (TDM) to voice over IP (VOIP). VOIP is how things are\ndone now, but TDM was considered the state of the art from the 1950s and 1960s, and was widely\ndeployed in the 1980s and 1990s. Whenever we had a question for the systems engineer about how a call should react to a given\nsituation, he would disappear and a little later emerge with a very detailed answer. \u201cWhere did he get\nthat answer?\u201d we asked. \u201cFrom the current product\u2019s code,\u201d he\u2019d answer. The tangled legacy code\nwas the spec for the new product! The existing implementation had no separation between TDM and\nthe business logic of making calls.", "domains": ["Design Patterns"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 196", "position": 196, "chunk_type": "semantic", "token_estimate": 388}
{"text": "alternatives:: The tangled legacy code\nwas the spec for the new product! The existing implementation had no separation between TDM and\nthe business logic of making calls. The whole product was hardware/technology dependent from top\nto bottom and could not be untangled. The whole product had essentially become firmware. Consider another example: Command messages arrive to this system via serial port. Unsurprisingly,\nthere is a message processor/dispatcher. The message processor knows the format of messages, is\nable to parse them, and can then dispatch the message to the code that can handle the request. None of\nthis is surprising, except that the message processor/dispatcher resides in the same file as code that\ninteracts with a UART2 hardware. The message processor is polluted with UART details. The", "domains": ["Design Patterns"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 196", "position": 196, "chunk_type": "semantic", "token_estimate": 126}
{"text": "message processor could have been software with a potentially long useful life, but instead it is: firmware. The message processor is denied the opportunity to become software\u2014and that is just not\nright! I\u2019ve known and understood the need for separating software from hardware for a long time, but\nDoug\u2019s words clarified how to use the terms software and firmware in relationship to each other. For engineers and programmers, the message is clear: Stop writing so much firmware and give your\ncode a chance at a long useful life. Of course, demanding it won\u2019t make it so. Let\u2019s look at how we\ncan keep embedded software architecture clean to give the software a fighting chance of having a long\nand useful life. APP-TITUDE TEST\nWhy does so much potential embedded software become firmware? It seems that most of the\nemphasis is on getting the embedded code to work, and not so much emphasis is placed on structuring\nit for a long useful life. Kent Beck describes three activities in building software (the quoted text is\nKent\u2019s words and the italics are my commentary):\n1. \u201cFirst make it work.\u201d Y\nou are out of business if it doesn\u2019t work. 2. \u201cThen make it right.\u201d Refactor the code so that you and others can understand it and evolve it as\nneeds change or are better understood. 3. \u201cThen make it fast.\u201d Refactor the code for \u201cneeded\u201d performance. Much of the embedded systems software that I see in the wild seems to have been written with \u201cMake\nit work\u201d in mind\u2014and perhaps also with an obsession for the \u201cMake it fast\u201d goal, achieved by adding\nmicro-optimizations at every opportunity. In The Mythical Man-Month, Fred Brooks suggests we\n\u201cplan to throw one away.\u201d Kent and Fred are giving virtually the same advice: Learn what works,\nthen make a better solution. Embedded software is not special when it comes to these problems. Most non-embedded apps are\nbuilt just to work, with little regard to making the code right for a long useful life. Getting an app to work is what I call the App-titude test for a programmer. Programmers, embedded\nor not, who just concern themselves with getting their app to work are doing their products and\nemployers a disservice. There is much more to programming than just getting an app to work.", "domains": ["Software Quality Attributes"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 197", "position": 197, "chunk_type": "semantic", "token_estimate": 387}
{"text": "Let\u2019s see how to apply some of the architectural principles to embedded software and firmware to: help you eliminate the target-hardware bottleneck. Layers\nLayering comes in many flavors. Let\u2019s start with three layers, as shown in Figure 29.1. At the bottom,\nthere is the hardware. As Doug warns us, due to technology advances and Moore\u2019s law, the hardware\nwill change. Parts become obsolete, and new parts use less power or provide better performance or\nare cheaper. Whatever the reason, as an embedded engineer, I don\u2019t want to have a bigger job than is\nnecessary when the inevitable hardware change finally happens.", "domains": ["Software Quality Attributes"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 199", "position": 199, "chunk_type": "semantic", "token_estimate": 101}
{"text": "Figure 29.1 Three layers: The separation between hardware and the rest of the system is a given\u2014at least once the hardware is\ndefined (Figure 29.2). Here is where the problems often begin when you are trying to pass the App-\ntitude test. There is nothing that keeps hardware knowledge from polluting all the code. If you are not\ncareful about where you put things and what one module is allowed to know about another module,\nthe code will be very hard to change. I\u2019m not just talking about when the hardware changes, but when\nthe user asks for a change, or when a bug needs to be fixed. Figure 29.2 Hardware must be separated from the rest of the system\nSoftware and firmware intermingling is an anti-pattern. Code exhibiting this anti-pattern will resist\nchanges. In addition, changes will be dangerous, often leading to unintended consequences. Full\nregression tests of the whole system will be needed for minor changes. If you have not created\nexternally instrumented tests, expect to get bored with manual tests\u2014and then you can expect new bug\nreports. The Hardware Is a Detail", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 200", "position": 200, "chunk_type": "semantic", "token_estimate": 185}
{"text": "bits, where a HAL might provide Led_TurnOn(5). That is a pretty low-level hardware abstraction: layer. Let\u2019s consider raising the level of abstraction from a hardware perspective to the\nsoftware/product perspective. What is the LED indicating? Suppose that it indicated low battery\npower. At some level, the firmware (or a board support package) could provide Led_TurnOn(5),\nwhile the HAL provides Indicate_LowBattery(). You can see the HAL expressing services needed\nby the application. You can also see that layers may contain layers. It is more of a repeating fractal\npattern than a limited set of predefined layers. The GPIO assignments are details that should be\nhidden from the software. DON\u2019T REVEAL HARDW", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 202", "position": 202, "chunk_type": "semantic", "token_estimate": 110}
{"text": "typedef char                Int_8;: t_8;\n \n#elif defined(_ACME_A42)\n    typedef unsigned long       Uint_32;\n    typedef unsigned int        Uint_16;\n    typedef unsigned char       Uint_8;\n \n    typedef long                Int_32;\n    typedef int                 Int_16;\n    typedef char                Int_8;\n#else\n    #error <acmetypes.h> is not supported for this environment\n#endif\n \n#endif\nThe acmetypes.h header file should not be used directly. If you do, your code gets tied to one of the\nACME DSPs. You are using an ACME DSP, you say, so what is the harm? You can\u2019t compile your\ncode unless you include this header. If you use the header and define _ACME_X42 or _ACME_A42, your\nintegers will be the wrong size if you try to test your code off-target. If that is not bad enough, one day\nyou\u2019ll want to port your application to another processor, and you will have made that task much\nmore difficult by not choosing portability and by not limiting what files know about ACME. Instead of using acmetypes.h, you should try to follow a more standardized path and use stdint.h. But what if the target compiler does not provide stdint.h? You can write this header file. The\nstdint.h you write for target builds uses the acmetypes.h for target compiles like this:\nClick here to view code image\n#ifndef _STDINT_H_\n#define _STDINT_H_\n \n#include <acmetypes.h>\n \ntypedef Uint_32 uint32_t;\ntypedef Uint_16 uint16_t;\ntypedef Uint_8  uint8_t;\n \ntypedef Int_32  int32_t;\ntypedef Int_16  int16_t;\ntypedef Int_8   int8_t;\n \n#endif\nHaving your embedded software and firmware use stdint.h helps keep your code clean and\nportable. Certainly, all of the software should be processor independent, but not all of the firmware\ncan be. This next code snippet takes advantage of special extensions to C that gives your code access\nto the peripherals in the micro-controller. It\u2019s likely your product uses this micro-controller so that\nyou can use its integrated peripherals. This function outputs a line that says \"hi\" to the serial output\nport. (This example is based on real code from the wild.) Click here to view code image", "domains": ["Software Quality Attributes"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 203", "position": 203, "chunk_type": "semantic", "token_estimate": 324}
{"text": "If you have ever moved your software from one RTOS to another, you know it is painful. If your: software depended on an OSAL instead of the OS directly, you would largely be writing a new OSAL\nthat is compatible with the old OSAL. Which would you rather do: modify a bunch of complex\nexisting code, or write new code to a defined interface and behavior? This is not a trick question. I\nchoose the latter. You might start worrying about code bloat about now. Really, though, the layer becomes the place\nwhere much of the duplication around using an OS is isolated. This duplication does not have to\nimpose a big overhead. If you define an OSAL, you can also encourage your applications to have a\ncommon structure. You might provide message passing mechanisms, rather than having every thread\nhandcraft its concurrency model. The OSAL can help provide test points so that the valuable application code in the software layer can\nbe tested off-target and off-OS. A clean embedded architecture\u2019s software is testable off the target\noperating system. A successful OSAL provides that seam or set of substitution points that facilitate\noff-target testing.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 206", "position": 206, "chunk_type": "semantic", "token_estimate": 194}
{"text": "In addition to adding a HAL and potentially an OSAL inside each of the major layers (software, OS,: firmware, and hardware), you can\u2014and should\u2014apply the principles described throughout this book. These principles encourage separation of concerns, programming to interfaces, and substitutability. The idea of a layered architecture is built on the idea of programming to interfaces. When one module\ninteracts with another though an interface, you can substitute one service provider for another. Many\nreaders will have written their own small version of printf for deployment in the target. As long as\nthe interface to your printf is the same as the standard version of printf, you can override the\nservice one for the other. One basic rule of thumb is to use header files as interface definitions. When you do so, however, you\nhave to be careful about what goes in the header file. Limit header file contents to function\ndeclarations as well as the constants and struct names that are needed by the function. Don\u2019t clutter the interface header files with data structures, constants, and typedefs that are needed by\nonly the implementation. It\u2019s not just a matter of clutter: That clutter will lead to unwanted\ndependencies. Limit the visibility of the implementation details. Expect the implementation details to\nchange. The fewer places where code knows the details, the fewer places where code will have to be\ntracked down and modified. A clean embedded architecture is testable within the layers because modules interact through\ninterfaces. Each interface provides that seam or substitution point that facilitates off-target testing.", "domains": ["Architectural Patterns and Styles", "Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 206", "position": 206, "chunk_type": "semantic", "token_estimate": 259}
{"text": "turn on and off segments of code. I recall one especially problematic case where the statement: #ifdef BOARD_V2 was mentioned several thousand times in a telecom application. This repetition of code violates the Don\u2019t Repeat Yourself (DRY) principle.5 If I see #ifdef\nBOARD_V2 once, it\u2019s not really a problem. Six thousand times is an extreme problem. Conditional\ncompilation identifying the target-hardware\u2019s type is often repeated in embedded systems. But what\nelse can we do? What if there is a hardware abstraction layer? The hardware type would become a detail hidden\nunder the HAL. If the HAL provides a set of interfaces, instead of using conditional compilation, we\ncould use the linker or some form of runtime binding to connect the software to the hardware.", "domains": ["Design Patterns", "Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 207", "position": 207, "chunk_type": "semantic", "token_estimate": 124}
{"text": "From an architectural point of view, the database is a non-entity\u2014it is a detail that does not rise to: the level of an architectural element. Its relationship to the architecture of a software system is rather\nlike the relationship of a doorknob to the architecture of your home. I realize that these are fighting words. Believe me, I\u2019ve had the fight. So let me be clear: I am not\ntalking about the data model. The structure you give to the data within your application is highly\nsignificant to the architecture of your system. But the database is not the data model. The database is\npiece of software. The database is a utility that provides access to the data. From the architecture\u2019s\npoint of view, that utility is irrelevant because it\u2019s a low-level detail\u2014a mechanism. And a good\narchitect does not allow low-level mechanisms to pollute the system architecture.", "domains": ["Domain-Driven Design"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 209", "position": 209, "chunk_type": "semantic", "token_estimate": 148}
{"text": "This reality is why I say that the database is a detail. It\u2019s just a mechanism we use to move the data: back and forth between the surface of the disk and RAM. The database is really nothing more than a\nbig bucket of bits where we store our data on a long-term basis. But we seldom use the data in that\nform. Thus, from an architectural viewpoint, we should not care about the form that the data takes while it\nis on the surface of a rotating magnetic disk. Indeed, we should not acknowledge that the disk exists at\nall. BUT WHAT ABOUT PERFORMANCE? Isn\u2019t performance an architectural concern? Of course it is\u2014but when it comes to data storage, it\u2019s a\nconcern that can be entirely encapsulated and separated from the business rules. Yes, we need to get\nthe data in and out of the data store quickly, but that\u2019s a low-level concern. We can address that", "domains": ["Software Quality Attributes"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 211", "position": 211, "chunk_type": "semantic", "token_estimate": 158}
{"text": "Where did that need come from? It originated from the highly effective marketing campaigns: employed by the database vendors at the time. They had managed to convince high-level executives\nthat their corporate \u201cdata assets\u201d needed protection, and that the database systems they offered were\nthe ideal means of providing that protection. We see the same kind of marketing campaigns today. The word \u201centerprise\u201d and the notion of\n\u201cService-Oriented Architecture\u201d have much more to do with marketing than with reality. What should I have done in that long-ago scenario? I should have bolted an RDBMS on the side of\nthe system and provided some narrow and safe data access channel to it, while maintaining the\nrandom access files in the core of the system. What did I do? I quit and became a consultant.", "domains": ["Architectural Patterns and Styles"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 213", "position": 213, "chunk_type": "semantic", "token_estimate": 133}
{"text": "Of course, it would be incorrect to think that those oscillations started with the web. Before the web,: there was client\u2013server architecture. Before that, there were central minicomputers with arrays of\ndumb terminals. Before that, there were mainframes with smart green-screen terminals (that were\nvery much analogous to modern-day browsers). Before that, there were computer rooms and punched\ncards \u2026\nAnd so the story goes. We can\u2019t seem to figure out where we want the computer power. We go back\nand forth between centralizing it and distributing it. And, I imagine, those oscillations will continue\nfor some time to come. When you look at it in the overall scope of IT history, the web didn\u2019t change anything at all. The web\nwas simply one of many oscillations in a struggle that began before most of us were born and will\ncontinue well after most of us have retired. As architects, though, we have to look at the long term. Those oscillations are just short-term issues\nthat we want to push away from the central core of our business rules. Let me tell you the story of company Q. Company Q built a very popular personal finance system. It\nwas a desktop app with a very useful GUI. I loved using it. Then came the web. In its next release, company Q changed the GUI to look, and behave, like a\nbrowser. I was thunderstruck! What marketing genius decided that personal finance software, running\non a desktop, should have the look and feel of a web browser? Of course, I hated the new interface. Apparently everyone else did, too\u2014because after a few\nreleases, company Q gradually removed the browser-like feel and turned its personal finance system\nback into a regular desktop GUI. Now imagine you were a software architect at Q. Imagine that some marketing genius convinces\nupper management that the whole UI has to change to look more like the web. What do you do? Or,\nrather, what should you have done before this point to protect your application from that marketing\ngenius? You should have decoupled your business rules from your UI. I don\u2019t know whether the Q architects\nhad done that. One day I\u2019d love to hear their story. Had I been there at the time, I certainly would have\nlobbied very hard to isolate the business rules from the GUI, because you never know what the\nmarketing geniuses will do next. Now consider company A, which makes a lovely smartphone.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 215", "position": 215, "chunk_type": "semantic", "token_estimate": 413}
{"text": "What is the solution?: Don\u2019t marry the framework! Oh, you can use the framework\u2014just don\u2019t couple to it. Keep it at arm\u2019s length. Treat the framework\nas a detail that belongs in one of the outer circles of the architecture. Don\u2019t let it into the inner circles. If the framework wants you to derive your business objects from its base classes, say no! Derive\nproxies instead, and keep those proxies in components that are plugins to your business rules. Don\u2019t let frameworks into your core code. Instead, integrate them into components that plug in to your\ncore code, following the Dependency Rule. For example, maybe you like Spring. Spring is a good dependency injection framework. Maybe you\nuse Spring to auto-wire your dependencies. That\u2019s fine, but you should not sprinkle @autowired\nannotations all throughout your business objects. Your business objects should not know about Spring. Instead, you can use Spring to inject dependencies into your Main component. It\u2019s OK for Main to\nknow about Spring since Main is the dirtiest, lowest-level component in the architecture. I NOW PRONOUNCE YOU \u2026\nThere are some frameworks that you simply must marry. If you are using C++, for example, you will\nlikely have to marry STL\u2014it\u2019s hard to avoid. If you are using Java, you will almost certainly have to\nmarry the standard library. That\u2019s normal\u2014but it should still be a decision. You must understand that when you marry a\nframework to your application, you will be stuck with that framework for the rest of the life cycle of\nthat application. For better or for worse, in sickness and in health, for richer, for poorer, forsaking all\nothers, you will be using that framework. This is not a commitment to be entered into lightly.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 219", "position": 219, "chunk_type": "semantic", "token_estimate": 291}
{"text": "Figure 33.1 shows a typical use-case analysis.: Figure 33.1 A typical use-case analysis\nThe four main actors are evident. According to the Single Responsibility Principle, these four actors\nwill be the four primary sources of change for the system. Every time some new feature is added, or\nsome existing feature is changed, that step will be taken to serve one of these actors. Therefore we", "domains": ["Design Principles"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 221", "position": 221, "chunk_type": "semantic", "token_estimate": 65}
{"text": "Now that we know the actors and use cases, we can create a preliminary component architecture: (Figure 33.2). The double lines in the drawing represent architectural boundaries as usual. You can see the typical\npartitioning of views, presenters, interactors, and controllers. You can also see that I\u2019ve broken each\nof those categories up by their corresponding actors. Each of the components in Figure 33.2 represents a potential .jar file or .dll file. Each of those\ncomponents will contain the views, presenters, interactors, and controllers that have been allocated to\nit. Note the special components for the Catalog View and the Catalog Presenter. This is how I dealt\nwith the abstract View Catalog use case. I assume that those views and presenters will be coded into\nabstract classes within those components, and that the inheriting components will contain view and\npresenter classes that will inherit from those abstract classes.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 222", "position": 222, "chunk_type": "semantic", "token_estimate": 148}
{"text": "Figure 33.2 A preliminary component architecture: Would I really break the system up into all these components, and deliver them as .jar or .dll files? Yes and no. I would certainly break the compile and build environment up this way, so that I could\nbuild independent deliverables like that. I would also reserve the right to combine all those\ndeliverables into a smaller number of deliverables if necessary. For example, given the partitioning\nin Figure 33.2, it would be easy to combine them into five .jar files\u2014one for views, presenters,\ninteractors, controllers, and utilities, respectively. I could then independently deploy the components\nthat are most likely to change independently of each other. Another possible grouping would be to put the views and presenters together into the same .jar file,\nand put the interactors, controllers, and utilities in their own .jar file. Still another, even more\nprimitive, grouping would be to create two .jar files, with views and presenters in one file, and\neverything else in the other. Keeping these options open will allow us to adapt the way we deploy the system based on how the\nsystem changes over time.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 223", "position": 223, "chunk_type": "semantic", "token_estimate": 190}
{"text": "The architecture diagram in Figure 33.2 includes two dimensions of separation. The first is the: separation of actors based on the Single Responsibility Principle; the second is the Dependency Rule. The goal of both is to separate components that change for different reasons, and at different rates. The different reasons correspond to the actors; the different rates correspond to the different levels of\npolicy. Once you have structured the code this way, you can mix and match how you want to actually deploy\nthe system. You can group the components into deployable deliverables in any way that makes sense,\nand easily change that grouping when conditions change. 1. This is my own notation for \u201cabstract\u201d use cases. It would have been more standard to use a UML stereotype such as <<abstract>>,\nbut I don\u2018t find adhering to such standards very useful nowadays.", "domains": ["Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 224", "position": 224, "chunk_type": "semantic", "token_estimate": 142}
{"text": "The first, and perhaps simplest, design approach is the traditional horizontal layered architecture,: where we separate our code based on what it does from a technical perspective. This is often called\n\u201cpackage by layer.\u201d Figure 34.1 shows what this might look like as a UML class diagram. In this typical layered architecture, we have one layer for the web code, one layer for our \u201cbusiness\nlogic,\u201d and one layer for persistence. In other words, code is sliced horizontally into layers, which", "domains": ["Architectural Patterns and Styles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 225", "position": 225, "chunk_type": "semantic", "token_estimate": 81}
{"text": "are used as a way to group similar types of things. In a \u201cstrict layered architecture,\u201d layers should: depend only on the next adjacent lower layer. In Java, layers are typically implemented as packages. As you can see in Figure 34.1, all of the dependencies between layers (packages) point downward. In\nthis example, we have the following Java types:\n\u2022 OrdersController: A web controller, something like a Spring MVC controller, that handles\nrequests from the web. \u2022 OrdersService: An interface that defines the \u201cbusiness logic\u201d related to orders. \u2022 OrdersServiceImpl: The implementation of the orders service.1\n\u2022 OrdersRepository: An interface that defines how we get access to persistent order information. \u2022 JdbcOrdersRepository: An implementation of the repository interface. Figure 34.1 Package by layer\nIn \u201cPresentation Domain Data Layering,\u201d2 Martin Fowler says that adopting such a layered", "domains": ["Architectural Patterns and Styles", "Domain-Driven Design", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 226", "position": 226, "chunk_type": "semantic", "token_estimate": 136}
{"text": "architecture is a good way to get started. He\u2019s not alone. Many of the books, tutorials, training: courses, and sample code you\u2019ll find will also point you down the path of creating a layered\narchitecture. It\u2019s a very quick way to get something up and running without a huge amount of\ncomplexity. The problem, as Martin points out, is that once your software grows in scale and\ncomplexity, you will quickly find that having three large buckets of code isn\u2019t sufficient, and you will\nneed to think about modularizing further. Another problem is that, as Uncle Bob has already said, a layered architecture doesn\u2019t scream\nanything about the business domain. Put the code for two layered architectures, from two very\ndifferent business domains, side by side and they will likely look eerily similar: web, services, and\nrepositories. There\u2019s also another huge problem with layered architectures, but we\u2019ll get to that later.", "domains": ["Architectural Patterns and Styles"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 227", "position": 227, "chunk_type": "semantic", "token_estimate": 151}
{"text": "Another option for organizing your code is to adopt a \u201cpackage by feature\u201d style. This is a vertical: slicing, based on related features, domain concepts, or aggregate roots (to use domain-driven design\nterminology). In the typical implementations that I\u2019ve seen, all of the types are placed into a single\nJava package, which is named to reflect the concept that is being grouped. With this approach, as shown in Figure 34.2, we have the same interfaces and classes as before, but\nthey are all placed into a single Java package rather than being split among three packages. This is a\nvery simple refactoring from the \u201cpackage by layer\u201d style, but the top-level organization of the code\nnow screams something about the business domain. We can now see that this code base has something\nto do with orders rather than the web, services, and repositories. Another benefit is that it\u2019s\npotentially easier to find all of the code that you need to modify in the event that the \u201cview orders\u201d\nuse case changes. It\u2019s all sitting in a single Java package rather than being spread out.3\nI often see software development teams realize that they have problems with horizontal layering\n(\u201cpackage by layer\u201d) and switch to vertical layering (\u201cpackage by feature\u201d) instead. In my opinion,\nboth are suboptimal. If you\u2019ve read this book so far, you might be thinking that we can do much better\n\u2014and you\u2019re right.", "domains": ["Domain-Driven Design", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 227", "position": 227, "chunk_type": "semantic", "token_estimate": 236}
{"text": "Section: Figure 34.2 Package by feature", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 228", "position": 228, "chunk_type": "semantic", "token_estimate": 6}
{"text": "Figure 34.3 A code base with an inside and an outside: The \u201cinside\u201d region contains all of the domain concepts, whereas the \u201coutside\u201d region contains the\ninteractions with the outside world (e.g., UIs, databases, third-party integrations). The major rule here\nis that the \u201coutside\u201d depends on the \u201cinside\u201d\u2014never the other way around. Figure 34.4 shows a\nversion of how the \u201cview orders\u201d use case might be implemented. The com.mycompany.myapp.domain package here is the \u201cinside,\u201d and the other packages are the\n\u201coutside.\u201d Notice how the dependencies flow toward the \u201cinside.\u201d The keen-eyed reader will notice\nthat the OrdersRepository from previous diagrams has been renamed to simply be Orders. This\ncomes from the world of domain-driven design, where the advice is that the naming of everything on\nthe \u201cinside\u201d should be stated in terms of the \u201cubiquitous domain language.\u201d To put that another way,\nwe talk about \u201corders\u201d when we\u2019re having a discussion about the domain, not the \u201corders repository.\u201d", "domains": ["Design Patterns", "Domain-Driven Design", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 229", "position": 229, "chunk_type": "semantic", "token_estimate": 158}
{"text": "Although I agree wholeheartedly with the discussions about SOLID, REP, CCP, and CRP and most of: the advice in this book, I come to a slightly different conclusion about how to organize code. So I\u2019m\ngoing to present another option here, which I call \u201cpackage by component.\u201d To give you some\nbackground, I\u2019ve spent most of my career building enterprise software, primarily in Java, across a\nnumber of different business domains. Those software systems have varied immensely, too. A large\nnumber have been web-based, but others have been client\u2013server4, distributed, message-based, or\nsomething else. Although the technologies differed, the common theme was that the architecture for", "domains": ["Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 230", "position": 230, "chunk_type": "semantic", "token_estimate": 106}
{"text": "most of these software systems was based on a traditional layered architecture.: I\u2019ve already mentioned a couple of reasons why layered architectures should be considered bad, but\nthat\u2019s not the whole story. The purpose of a layered architecture is to separate code that has the same\nsort of function. Web stuff is separated from business logic, which is in turn separated from data\naccess. As we saw from the UML class diagram, from an implementation perspective, a layer\ntypically equates to a Java package. From a code accessibility perspective, for the\nOrdersController to be able to have a dependency on the OrdersService interface, the\nOrdersService interface needs to be marked as public, because they are in different packages. Likewise, the OrdersRepository interface needs to be marked as public so that it can be seen\noutside of the repository package, by the OrdersServiceImpl class. In a strict layered architecture, the dependency arrows should always point downward, with layers\ndepending only on the next adjacent lower layer. This comes back to creating a nice, clean, acyclic\ndependency graph, which is achieved by introducing some rules about how elements in a code base\nshould depend on each other. The big problem here is that we can cheat by introducing some\nundesirable dependencies, yet still create a nice, acyclic dependency graph. Suppose that you hire someone new who joins your team, and you give the newcomer another\norders-related use case to implement. Since the person is new, he wants to make a big impression\nand get this use case implemented as quickly as possible. After sitting down with a cup of coffee for a\nfew minutes, the newcomer discovers an existing OrdersController class, so he decides that\u2019s\nwhere the code for the new orders-related web page should go. But it needs some orders data from\nthe database. The newcomer has an epiphany: \u201cOh, there\u2019s an OrdersRepository interface already\nbuilt, too. I can simply dependency-inject the implementation into my controller. Perfect!\u201d After a few\nmore minutes of hacking, the web page is working. But the resulting UML diagram looks like Figure\n34.5. The dependency arrows still point downward, but the OrdersController is now additionally\nbypassing the OrdersService for some use cases. This organization is often called a relaxed layered\narchitecture, as layers are allowed to skip around their adjacent neighbor(s). In some situations, this\nis the intended outcome\u2014if you\u2019re trying to follow the CQRS5 pattern, for example.", "domains": ["Architectural Patterns and Styles", "Domain-Driven Design", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 231", "position": 231, "chunk_type": "semantic", "token_estimate": 402}
{"text": "most of these software systems was based on a traditional layered architecture.: This organization is often called a relaxed layered\narchitecture, as layers are allowed to skip around their adjacent neighbor(s). In some situations, this\nis the intended outcome\u2014if you\u2019re trying to follow the CQRS5 pattern, for example. In many other\ncases, bypassing the business logic layer is undesirable, especially if that business logic is\nresponsible for ensuring authorized access to individual records, for example. While the new use case works, it\u2019s perhaps not implemented in the way that we were expecting. I see\nthis happen a lot with teams that I visit as a consultant, and it\u2019s usually revealed when teams start to\nvisualize what their code base really looks like, often for the first time.", "domains": ["Architectural Patterns and Styles"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 231", "position": 231, "chunk_type": "semantic", "token_estimate": 127}
{"text": "Figure 34.5 Relaxed layered architecture: What we need here is a guideline\u2014an architectural principle\u2014that says something like, \u201cWeb\ncontrollers should never access repositories directly.\u201d The question, of course, is enforcement. Many\nteams I\u2019ve met simply say, \u201cWe enforce this principle through good discipline and code reviews,\nbecause we trust our developers.\u201d This confidence is great to hear, but we all know what happens\nwhen budgets and deadlines start looming ever closer. A far smaller number of teams tell me that they use static analysis tools (e.g., NDepend, Structure101,\nCheckstyle) to check and automatically enforce architecture violations at build time. You may have\nseen such rules yourself; they usually manifest themselves as regular expressions or wildcard strings\nthat state \u201ctypes in package **/web should not access types in **/data\u201d; and they are executed after\nthe compilation step. This approach is a little crude, but it can do the trick, reporting violations of the architecture\nprinciples that you\u2019ve defined as a team and (you hope) failing the build. The problem with both", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 232", "position": 232, "chunk_type": "semantic", "token_estimate": 170}
{"text": "approaches is that they are fallible, and the feedback loop is longer than it should be. If left: unchecked, this practice can turn a code base into a \u201cbig ball of mud.\u201d6 I\u2019d personally like to use the\ncompiler to enforce my architecture if at all possible. This brings us to the \u201cpackage by component\u201d option. It\u2019s a hybrid approach to everything we\u2019ve seen\nso far, with the goal of bundling all of the responsibilities related to a single coarse-grained\ncomponent into a single Java package. It\u2019s about taking a service-centric view of a software system,\nwhich is something we\u2019re seeing with micro-service architectures as well. In the same way that ports\nand adapters treat the web as just another delivery mechanism, \u201cpackage by component\u201d keeps the\nuser interface separate from these coarse-grained components. Figure 34.6 shows what the \u201cview\norders\u201d use case might look like. In essence, this approach bundles up the \u201cbusiness logic\u201d and persistence code into a single thing,\nwhich I\u2019m calling a \u201ccomponent.\u201d Uncle Bob presented his definition of \u201ccomponent\u201d earlier in the\nbook, saying:\nComponents are the units of deployment. They are the smallest entities that can be deployed as part of a system. In\nJava, they are jar files.", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 233", "position": 233, "chunk_type": "semantic", "token_estimate": 205}
{"text": "Figure 34.6 View orders use case: My definition of a component is slightly different: \u201cA grouping of related functionality behind a nice\nclean interface, which resides inside an execution environment like an application.\u201d This definition\ncomes from my \u201cC4 software architecture model,\u201d7 which is a simple hierarchical way to think about\nthe static structures of a software system in terms of containers, components, and classes (or code). It\nsays that a software system is made up of one or more containers (e.g., web applications, mobile\napps, stand-alone applications, databases, file systems), each of which contains one or more\ncomponents, which in turn are implemented by one or more classes (or code). Whether each\ncomponent resides in a separate jar file is an orthogonal concern. A key benefit of the \u201cpackage by component\u201d approach is that if you\u2019re writing code that needs to do\nsomething with orders, there\u2019s just one place to go\u2014the OrdersComponent. Inside the component,\nthe separation of concerns is still maintained, so the business logic is separate from data persistence,\nbut that\u2019s a component implementation detail that consumers don\u2019t need to know about. This is akin to\nwhat you might end up with if you adopted a micro-services or Service-Oriented Architecture\u2014a", "domains": ["Architectural Patterns and Styles", "Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 234", "position": 234, "chunk_type": "semantic", "token_estimate": 203}
{"text": "On the face of it, the four approaches do all look like different ways to organize code and, therefore,: could be considered different architectural styles. This perception starts to unravel very quickly if\nyou get the implementation details wrong, though. Something I see on a regular basis is an overly liberal use of the public access modifier in languages\nsuch as Java. It\u2019s almost as if we, as developers, instinctively use the public keyword without\nthinking. It\u2019s in our muscle memory. If you don\u2019t believe me, take a look at the code samples for\nbooks, tutorials, and open source frameworks on GitHub. This tendency is apparent, regardless of\nwhich architectural style a code base is aiming to adopt\u2014horizontal layers, vertical layers, ports and\nadapters, or something else. Marking all of your types as public means you\u2019re not taking advantage\nof the facilities that your programming language provides with regard to encapsulation. In some cases,\nthere\u2019s literally nothing preventing somebody from writing some code to instantiate a concrete\nimplementation class directly, violating the intended architecture style.", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 235", "position": 235, "chunk_type": "semantic", "token_estimate": 175}
{"text": "Looking at this issue another way, if you make all types in your Java application public, the: packages are simply an organization mechanism (a grouping, like folders), rather than being used for\nencapsulation. Since public types can be used from anywhere in a code base, you can effectively\nignore the packages because they provide very little real value. The net result is that if you ignore the\npackages (because they don\u2019t provide any means of encapsulation and hiding), it doesn\u2019t really matter\nwhich architectural style you\u2019re aspiring to create. If we look back at the example UML diagrams, the\nJava packages become an irrelevant detail if all of the types are marked as public. In essence, all\nfour architectural approaches presented earlier in this chapter are exactly the same when we overuse\nthis designation (Figure 34.7). Take a close look at the arrows between each of the types in Figure 34.7: They\u2019re all identical\nregardless of which architectural approach you\u2019re trying to adopt. Conceptually the approaches are\nvery different, but syntactically they are identical. Furthermore, you could argue that when you make\nall of the types public, what you really have are just four ways to describe a traditional horizontally\nlayered architecture. This is a neat trick, and of course nobody would ever make all of their Java\ntypes public. Except when they do. And I\u2019ve seen it. The access modifiers in Java are not perfect,8 but ignoring them is just asking for trouble. The way\nJava types are placed into packages can actually make a huge difference to how accessible (or", "domains": ["Architectural Patterns and Styles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 235", "position": 235, "chunk_type": "semantic", "token_estimate": 262}
{"text": "inaccessible) those types can be when Java\u2019s access modifiers are applied appropriately. If I bring: the packages back and mark (by graphically fading) those types where the access modifier can be\nmade more restrictive, the picture becomes pretty interesting (Figure 34.8). Figure 34.7 All four architectural approaches are the same\nMoving from left to right, in the \u201cpackage by layer\u201d approach, the OrdersService and\nOrdersRepository interfaces need to be public, because they have inbound dependencies from\nclasses outside of their defining package. In contrast, the implementation classes\n(OrdersServiceImpl and JdbcOrdersRepository) can be made more restrictive (package\nprotected). Nobody needs to know about them; they are an implementation detail. In the \u201cpackage by feature\u201d approach, the OrdersController provides the sole entry point into the\npackage, so everything else can be made package protected. The big caveat here is that nothing else in\nthe code base, outside of this package, can access information related to orders unless they go through\nthe controller. This may or may not be desirable. In the ports and adapters approach, the OrdersService and Orders interfaces have inbound\ndependencies from other packages, so they need to be made public. Again, the implementation\nclasses can be made package protected and dependency injected at runtime.", "domains": ["Design Patterns", "Domain-Driven Design", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 236", "position": 236, "chunk_type": "semantic", "token_estimate": 205}
{"text": "Figure 34.8 Grayed-out types are where the access modifier can be made more restrictive: Finally, in the \u201cpackage by component\u201d approach, the OrdersComponent interface has an inbound\ndependency from the controller, but everything else can be made package protected. The fewer\npublic types you have, the smaller the number of potential dependencies. There\u2019s now no way9 that\ncode outside this package can use the OrdersRepository interface or implementation directly, so we\ncan rely on the compiler to enforce this architectural principle. You can do the same thing in .NET\nwith the internal keyword, although you would need to create a separate assembly for every\ncomponent. Just to be absolutely clear, what I\u2019ve described here relates to a monolithic application, where all of\nthe code resides in a single source code tree. If you are building such an application (and many\npeople are), I would certainly encourage you to lean on the compiler to enforce your architectural\nprinciples, rather than relying on self-discipline and post-compilation tooling.", "domains": ["Domain-Driven Design", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 237", "position": 237, "chunk_type": "semantic", "token_estimate": 165}
{"text": "decouple your source code dependencies. With Java, you have module frameworks like OSGi and the: new Java 9 module system. With module systems, when used properly, you can make a distinction\nbetween types that are public and types that are published. For example, you could create an Orders\nmodule where all of the types are marked as public, but publish only a small subset of those types\nfor external consumption. It\u2019s been a long time coming, but I\u2019m enthusiastic that the Java 9 module\nsystem will give us another tool to build better software, and spark people\u2019s interest in design\nthinking once again. Another option is to decouple your dependencies at the source code level, by splitting code across\ndifferent source code trees. If we take the ports and adapters example, we could have three source\ncode trees:\n\u2022 The source code for the business and domain (i.e., everything that is independent of technology and\nframework choices): OrdersService, OrdersServiceImpl, and Orders\n\u2022 The source code for the web: OrdersController\n\u2022 The source code for the data persistence: JdbcOrdersRepository\nThe latter two source code trees have a compile-time dependency on the business and domain code,\nwhich itself doesn\u2019t know anything about the web or the data persistence code. From an\nimplementation perspective, you can do this by configuring separate modules or projects in your build\ntool (e.g., Maven, Gradle, MSBuild). Ideally you would repeat this pattern, having a separate source\ncode tree for each and every component in your application. This is very much an idealistic solution,\nthough, because there are real-world performance, complexity, and maintenance issues associated\nwith breaking up your source code in this way. A simpler approach that some people follow for their ports and adapters code is to have just two\nsource code trees:\n\u2022 Domain code (the \u201cinside\u201d)\n\u2022 Infrastructure code (the \u201coutside\u201d)\nThis maps on nicely to the diagram (Figure 34.9) that many people use to summarize the ports and\nadapters architecture, and there is a compile-time dependency from the infrastructure to the domain.", "domains": ["Design Patterns", "Software Quality Attributes", "Domain-Driven Design", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 238", "position": 238, "chunk_type": "semantic", "token_estimate": 339}
{"text": "Figure 34.9 Domain and infrastructure code: This approach to organizing source code will also work, but be aware of the potential trade-off. It\u2019s\nwhat I call the \u201cP\u00e9riph\u00e9rique anti-pattern of ports and adapters.\u201d The city of Paris, France, has a ring\nroad called the Boulevard P\u00e9riph\u00e9rique, which allows you to circumnavigate Paris without entering\nthe complexities of the city. Having all of your infrastructure code in a single source code tree means\nthat it\u2019s potentially possible for infrastructure code in one area of your application (e.g., a web\ncontroller) to directly call code in another area of your application (e.g., a database repository),\nwithout navigating through the domain. This is especially true if you\u2019ve forgotten to apply appropriate\naccess modifiers to that code. CONCLUSION: THE MISSING ADVICE\nThe whole point of this chapter is to highlight that your best design intentions can be destroyed in a\nflash if you don\u2019t consider the intricacies of the implementation strategy. Think about how to map your\ndesired design on to code structures, how to organize that code, and which decoupling modes to apply\nduring runtime and compile-time. Leave options open where applicable, but be pragmatic, and take\ninto consideration the size of your team, their skill level, and the complexity of the solution in\nconjunction with your time and budgetary constraints. Also think about using your compiler to help\nyou enforce your chosen architectural style, and watch out for coupling in other areas, such as data\nmodels. The devil is in the implementation details. 1. This is arguably a horrible way to name a class, but as we\u2019ll see later, perhaps it doesn\u2019t really matter. 2. https://martinfowler.com/bliki/PresentationDomainDataLayering.html.", "domains": ["Design Patterns", "Domain-Driven Design"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 239", "position": 239, "chunk_type": "semantic", "token_estimate": 274}
{"text": "3. This benefit is much less relevant with the navigation facilities of modern IDEs, but it seems there has been a renaissance moving: back to lightweight text editors, for reasons I am clearly too old to understand. 4. My first job after graduating from university in 1996 was building client\u2013server desktop applications with a technology called\nPowerBuilder, a super-productive 4GL that exceled at building database-driven applications. A couple of years later, I was building\nclient\u2013server applications with Java, where we had to build our own database connectivity (this was pre-JDBC) and our own GUI\ntoolkits on top of AWT. That\u2019s \u201cprogress\u201c for you! 5. In the Command Query Responsibility Segregation pattern, you have separate patterns for updating and reading data. 6. http://www.laputan.org/mud/\n7. See https://www.structurizr.com/help/c4 for more information. 8. In Java, for example, although we tend to think of packages as being hierarchical, it\u2019s not possible to create access restrictions based\non a package and subpackage relationship. Any hierarchy that you create is in the name of those packages, and the directory structure\non disk, only. 9. Unless you cheat and use Java\u2019s reflection mechanism, but please don\u2019t do that!", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 240", "position": 240, "chunk_type": "semantic", "token_estimate": 190}
{"text": "the applications to the supervisor. The boundary prevented the applications from knowing which kind: of device the output was going to. The second boundary was dependency inverted. The supervisor could start the applications, but had\nno compile-time dependencies upon them. The flow of control passed from the supervisor to the\napplications. The polymorphic interface that inverted the dependency was simply this: Every\napplication was started by jumping to the exact same memory address within the overlay area. The\nboundary prevented the supervisor from knowing anything about the applications other than the\nstarting point.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 248", "position": 248, "chunk_type": "semantic", "token_estimate": 93}
{"text": "of a console \u201cshell.\u201d Many of the divisions of Teradyne shared the MOP source code, but each had: forked it for its own uses. Consequently, we would send source code updates around to each other in\nthe form of marked-up listings that we would then integrate manually (and very carefully). A special-purpose utility layer controlled the measurement hardware, the positioning tables, and the\nlaser. The boundary between this layer and the MOP was muddled at best. While the utility layer\ncalled the MOP, the MOP had been specifically modified for that layer, and often called back into it. Indeed, we didn\u2019t really think of these two as separate layers. To us, it was just some code that we\nadded to the MOP in a highly coupled way. Next came the isolation layer. This layer provided a virtual machine interface for the application\nprograms, which were written in a completely different domain-specific data-driven language (DSL). The language had operations for moving the laser, moving the table, making cuts, making\nmeasurements, and so on. Our customers would write their laser trimming application programs in\nthis language, and the isolation layer would execute them. This approach was not intended to create a machine-independent laser trim language. Indeed, the\nlanguage had many idiosyncrasies that were deeply coupled to the layers below. Rather, this approach\ngave the application programmers a \u201csimpler\u201d language than M356 assembler in which to program\ntheir trim jobs. Trim jobs could be loaded from tape and executed by the system. Essentially, our system was an\noperating system for trim applications. The system was written in M365 assembler and compiled in a single compilation unit that produced\nabsolute binary code. The boundaries in this application were soft at best. Even the boundary between the system code and\nthe applications written in the DSL was not well enforced. There were couplings everywhere. But that was typical of software in the early 1970s. ALUMINUM DIE-CAST MONITORING\nIn the middle of the 1970s, while OPEC was placing an embargo on oil, and gasoline shortages were\ncausing angry drivers to get into fights at gas stations, I began working at Outboard Marine\nCorporation (OMC). This is the parent company of Johnson Motors and Lawnboy lawnmowers. OMC maintained a huge facility in Waukegan, Illinois, for creating die-cast aluminum parts for all of\nthe company\u2019s motors and products. Aluminum was melted down in huge furnaces, and then carried in\nlarge buckets to dozens upon dozens of individually operated aluminum die-cast machines.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 250", "position": 250, "chunk_type": "semantic", "token_estimate": 413}
{"text": "exactly enough RAM to hold the pointers at the start of each chip.: Finally, we changed every call to every subroutine on every chip into an indirect call through the\nappropriate RAM vector. When our processor booted, it would scan each chip and load the vector table at the start of each chip\ninto the RAM vectors. Then it would jump into the main program. This worked very well. Now, when we fixed a bug, or added a feature, we could simply recompile\none or two chips, and send just those chips to the field service engineers. We had made the chips independently deployable. We had invented polymorphic dispatch. We had\ninvented objects. This was a plugin architecture, quite literally. We plugged those chips in. We eventually engineered it\nso that a feature could be installed into our products by plugging the chip with that feature into one of\nthe open chip sockets. The menu control would automatically appear, and the binding into the main\napplication would happen automatically. Of course, we didn\u2019t know about object-oriented principles at the time, and we knew nothing about\nseparating user interface from business rules. But the rudiments were there, and they were very\npowerful. One unexpected side benefit of the approach was that we could patch the firmware over a dial-up\nconnection. If we found a bug in the firmware, we could dial up our devices and use the on-board\nmonitor program to alter the RAM vector for the faulty subroutine to point to a bit of empty RAM. Then we\u2019d enter the repaired subroutine into that RAM area, by typing it in machine code, in\nhexadecimal. This was a great boon to our field service operation, and to our customers. If they had a problem, they\ndidn\u2019t need us to ship new chips and schedule an urgent field service call. The system could be\npatched, and a new chip could be installed at the next regularly scheduled maintenance visit.", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 254", "position": 254, "chunk_type": "semantic", "token_estimate": 327}
{"text": "The 4-TEL service area computer (SAC) was based on an M365 minicomputer. This system: communicated with all the COL\nTs out in the field, through either dedicated or dial-up modems. It\nwould command those COL\nTs to measure telephone lines, would receive back the raw results, and\nwould then perform a complex analysis of those results to identify and locate any faults.", "domains": ["Design Patterns"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 254", "position": 254, "chunk_type": "semantic", "token_estimate": 62}
{"text": "The system was written in 1976 in M365 assembler. It was a single, monolithic program of roughly: 60,000 lines. The operating system was a home-grown, nonpreemptive, task-switcher based on\npolling. We called it MPS for multiprocessing system. The M365 computer had no built-in stack, so\ntask-specific variables were kept in a special area of memory and swapped out at every context\nswitch. Shared variables were managed with locks and semaphores. Reentrancy issues and race\nconditions were constant problems. There was no isolation of device control logic, or UI logic, from the business rules of the system. For\nexample, modem control code could be found smeared throughout the bulk of the business rules and\nUI code. There was no attempt to gather it into a module or abstract the interface. The modems were\ncontrolled, at the bit level, by code that was scattered everywhere around the system. The same was true for the terminal UI. Messages and formatting control code were not isolated. They\nranged far and wide throughout the 60,000-line code base. The modem modules we were using were designed to be mounted on PC boards. We bought those\nunits from a third party, and integrated them with other circuitry onto a board that fit into our custom\nbackplane. These units were expensive. So, after a few years, we decided to design our own\nmodems. We, in the software group, begged the hardware designer to use the same bit formats for\ncontrolling the new modem. We explained that the modem control code was smeared everywhere, and\nthat our system would have to deal with both kinds of modems in the future. So, we begged and\ncajoled, \u201cPlease make the new modem look just like the old modem from a software control point of\nview.\u201d", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 255", "position": 255, "chunk_type": "semantic", "token_estimate": 294}
{"text": "And where did we want to? Everywhere! And so there was SQL smeared throughout the body of that: code. Of course, in those days SQL was hardly a solid standard. There were lots of special vendor-specific\nquirks. So the special SQL and special UNIFY API calls were also smeared throughout the code. This worked great! The system was a success. The craftsmen used it, and the telephone companies\nloved it. Life was all smiles. Then the UNIFY product we were using was cancelled. Oh. Oh. So we decided to switch to SyBase. Or was it Ingress? I don\u2019t remember. Suffice it to say, we had to\nsearch through all that C code, find all the embedded SQL and special API calls, and replace them\nwith corresponding gestures for the new vendor. After three months of effort or so, we gave up. We couldn\u2019t make it work. We were so coupled to\nUNIFY that there was no serious hope of restructuring the code at any practical expense. So, we hired a third party to maintain UNIFY for us, based on a maintenance contract. And, of course,\nthe maintenance rates went up year after year after year.", "domains": ["Design Principles"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 264", "position": 264, "chunk_type": "semantic", "token_estimate": 195}
{"text": "failed to answer and identify myself, it would call the next number, and the next. If I still wasn\u2019t: reached, ER would record a message from the caller. ER would then, periodically, try to find me to deliver that message, and any other message left for me\nby anyone else. This was the first voice mail system ever, and we11 held the patent to it. We built all the hardware for this system\u2014the computer board, the memory board, the voice/telecom\nboards, everything. The main computer board was Deep Thought, the Intel 80286 processor that I\nmentioned earlier. The voice boards each supported one telephone line. They consisted of a telephone interface, a voice\nencoder/decoder, some memory, and an Intel 80186 microcomputer. The software for the main computer board was written in C. The operating system was MP/M-86, an\nearly command-line\u2013driven, multiprocessing, disk operating system. MP/M was the poor man\u2019s\nUNIX. The software for the voice boards was written in assembler, and had no operating system. Communication between Deep Thought and the voice boards occurred through shared memory. The architecture of this system would today be called service oriented. Each telephone line was\nmonitored by a listener process running under MP/M. When a call came in, an initial handler process\nwas started and the call was passed to it. As the call proceeded from state to state, the appropriate\nhandler process would be started and take control. Messages were passed between these services through disk files. The currently running service\nwould determine what the next service should be; would write the necessary state information into a\ndisk file; would issue the command line to start that service; and then would exit. This was the first time I had built a system like this. Indeed, this was the first time I had been the\nprincipal architect of an entire product. Everything having to do with software was mine\u2014and it\nworked like a champ. I would not say that the architecture of this system was \u201cclean\u201d in the sense of this book; it was not a\n\u201cplugin\u201d architecture. However, it definitely showed signs of true boundaries. The services were\nindependently deployable, and lived within their own domain of responsibility. There were high-\nlevel processes and low-level processes, and many of the dependencies ran in the right direction.", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 265", "position": 265, "chunk_type": "semantic", "token_estimate": 384}
{"text": "ER had failed as a product, but we still had all this hardware and software that we could use to: enhance our existing product lines. Moreover, our marketing success with VRS convinced us that we\nshould offer a voice response system for interacting with telephone craftsmen that did not depend on\nour test systems. Thus was born CDS, the Craft Dispatch System. CDS was essentially ER, but specifically focused on\nthe very narrow domain of managing the deployment of telephone repairmen in the field. When a problem was discovered in a phone line, a trouble ticket was created in the service center. Trouble tickets were kept in an automated system. When a repairman in the field finished a job, he\nwould call the service center for the next assignment. The service center operator would pull up the\nnext trouble ticket and read it off to the repairman. We set about to automate that process. Our goal was for the repairman in the field to call into CDS\nand ask for the next assignment. CDS would consult the trouble ticket system, and read off the results. CDS would keep track of which repairman was assigned to which trouble ticket, and would inform\nthe trouble ticket system of the status of the repair. There were quite a few interesting features of this system having to do with interacting with the\ntrouble ticket system, the plant management system, and any automated testing systems. The experience with the service-oriented architecture of ER made me want to try the same idea more\naggressively. The state machine for a trouble ticket was much more involved than the state machine\nfor handling a call with ER. I set about to create what would now be called a micro-service\narchitecture. Every state transition of any call, no matter how insignificant, caused the system to start up a new\nservice. Indeed, the state machine was externalized into a text file that the system read. Each event\ncoming into the system from a phone line turned into a transition in that finite state machine. The\nexisting process would start a new process dictated by the state machine to handle that event; then the\nexisting process would either exit or wait on a queue. This externalized state machine allowed us to change the flow of the application without changing any\ncode (the Open-Closed Principle).", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Design Principles"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 266", "position": 266, "chunk_type": "semantic", "token_estimate": 393}
{"text": "ER had failed as a product, but we still had all this hardware and software that we could use to: The\nexisting process would start a new process dictated by the state machine to handle that event; then the\nexisting process would either exit or wait on a queue. This externalized state machine allowed us to change the flow of the application without changing any\ncode (the Open-Closed Principle). We could easily add a new service, independently of any of the\nothers, and wire it into the flow by modifying the text file that contained the state machine. We could\neven do this while the system was running. In other words we had hot-swapping and an effective", "domains": ["Design Patterns", "Design Principles"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 266", "position": 266, "chunk_type": "semantic", "token_estimate": 117}
{"text": "BPEL (Business Process Execution Language).: The old ER approach of using disk files to communicate between services was too slow for this much\nmore rapid flip-flopping of services, so we invented a shared memory mechanism that we called the\n3DBB.12 The 3DBB allowed data to be accessed by name; the names we used were names assigned\nto each state machine instance. The 3DBB was great for storing strings and constants, but couldn\u2019t be used for holding complex data\nstructures. The reason for this is technical but easy to understand. Each process in MP/M lived in its\nown memory partition. Pointers to data in one memory partition had no meaning in another memory\npartition. As a consequence, the data in the 3DBB could not contain pointers. Strings were fine, but\ntrees, linked lists, or any data structure with pointers would not work. The trouble tickets in the trouble ticket system came from many different sources. Some were\nautomated, and some were manual. The manual entries were created by operators who were talking to\ncustomers about their troubles. As the customers described their problems, the operators would type\nin their complaints and observations in a structured text stream. It looked something like this:\nClick here to view code image\n/pno 8475551212 /noise /dropped-calls\nYou get the idea. The / character started a new topic. Following the slash was a code, and following\nthe code were parameters. There were thousands of codes, and an individual trouble ticket could\nhave dozens of them in the description. Worse, since they were manually entered, they were often\nmisspelled or improperly formatted. They were meant for humans to interpret, not for machines to\nprocess. Our problem was to decode these semi-free-form strings, interpret and fix any errors, and then turn\nthem into voice output so we could read them to the repairman, up on a pole, listening with a handset. This required, among other things, a very flexible parsing and data representation technique. That data\nrepresentation had to be passed through the 3DBB, which could handle only strings. And so, on an airplane, flying between customer visits, I invented a scheme that I called FLD: Field\nLabeled Data. Nowadays we would call this XML or JSON. The format was different, but the idea\nwas the same. FLDs were binary trees that associated names with data in a recursive hierarchy.", "domains": ["Design Patterns"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 267", "position": 267, "chunk_type": "semantic", "token_estimate": 392}
{"text": "In 1988, a group of Teradyne employees left the company to form a startup named Clear: Communications. I joined them a few months later. Our mission was to build the software for a\nsystem that would monitor the communications quality of T1 lines\u2014the digital lines that carried long-\ndistance communications across the country. The vision was a huge monitor with a map of the United\nStates crisscrossed by T1 lines flashing red if they were degrading. Remember, graphical user interfaces were brand new in 1988. The Apple Macintosh was only five\nyears old. Windows was a joke back then. But Sun Microsystems was building Sparcstations that had\ncredible X-Windows GUIs. So we went with Sun\u2014and therefore with C and UNIX. This was a startup. We worked 70 to 80 hours per week. We had the vision. We had the motivation. We had the will. We had the energy. We had the expertise. We had equity. We had dreams of being\nmillionaires. We were full of shit. The C code poured out of every orifice of our bodies. We slammed it here, and shoved it there. We\nconstructed huge castles in the air. We had processes, and message queues, and grand, superlative\narchitectures. We wrote a full seven-layer ISO communications stack from scratch\u2014right down to the\ndata link layer. We wrote GUI code. GOOEY CODE! OMG! We wrote GOOOOOEY code. I personally wrote a 3000-line C function named gi(); its name stood for Graphic Interpreter. It was\na masterpiece of goo. It was not the only goo I wrote at Clear, but it was my most infamous. Architecture? Are you joking? This was a startup. We didn\u2019t have time for architecture. Just code,\ndammit! Code for your very lives! So we coded. And we coded. And we coded. But, after three years, what we failed to do was sell. Oh, we had an installation or two. But the market was not particularly interested in our grand vision,\nand our venture capital financiers were getting pretty fed up. I hated my life at this point. I saw all my effort and dreams crashing down. I had conflicts at work,\nconflicts at home because of work, and conflicts with myself. And then I got a phone call that changed everything.", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 268", "position": 268, "chunk_type": "semantic", "token_estimate": 377}
{"text": "Second, Sun released a C++ compiler. I had been interested in C++ and OO since 1983, but: compilers were difficult to come by. So when the opportunity presented itself, I changed languages\nright away. I left the 3000-line C functions behind, and started to write C++ code at Clear. And I\nlearned \u2026\nI read books. Of course, I read The C++ Programming Language and The Annotated C++\nReference Manual (The ARM) by Bjarne Stroustrup. I read Rebecca Wirfs-Brock\u2019s lovely book on\nresponsibility-driven design: Designing Object Oriented Software. I read OOA and OOD and OOP\nby Peter Coad. I read Smalltalk-80 by Adele Goldberg. I read Advanced C++ Programming Styles\nand Idioms by James O. Coplien. But perhaps most significantly of all, I read Object Oriented\nDesign with Applications by Grady Booch. What a name! Grady Booch. How could anyone forget a name like that. What\u2019s more, he was the\nChief Scientist at a company called Rational! How I wanted to be a Chief Scientist! And so I read\nhis book. And I learned, and I learned, and I learned \u2026\nAs I learned, I also began debating on Netnews, the way people now debate on Facebook. My\ndebates were about C++ and OO. For two years, I relieved the frustrations that were building at work\nby debating with hundreds of folks on Usenet about the best language features and the best principles\nof design. After a while, I even started making a certain amount of sense. It was in one of those debates that the foundations of the SOLID principles were laid. And all that debating, and perhaps even some of the sense, got me noticed \u2026", "domains": ["Design Principles"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 269", "position": 269, "chunk_type": "semantic", "token_estimate": 278}
{"text": "1. One of the stories we heard about the particular machine at ASC was that it was shipped in a large semi-trailer truck along with a: household of furniture. On the way, the truck hit a bridge at high speed. The computer was fine, but it slid forward and crushed the\nfurniture into splinters. 2. Today we would say that it had a clock rate of 142 kHz. 3. Imagine the mass of that disk. Imagine the kinetic energy! One day we came in and saw little metal shavings dropping out from the\nbutton of the cabinet. We called the maintenance man. He advised us to shut the unit down. When he came to repair it, he said that\none of the bearings had worn out. Then he told us stories about how these disks, if not repaired, could tear loose from their moorings,\nplow through concrete block walls, and embed themselves into cars in the parking lot. 4. Cathode ray tube: monochrome, green-screen, ASCII displays. 5. The magic number 72 came from Hollerith punched cards, which held 80 characters each. The last 8 characters were \u201creserved\u201d for\nsequence numbers in case you dropped the deck. 6. Yes, I understand that\u2019s an oxymoron. 7. They had a little clear plastic window that allowed you to see the silicon chip inside, and allowed the UV to erase the data. 8. Yes, I know that when software is burned into ROM, it\u2019s called firmware\u2014but even firmware is really still soft. 9. RKO7. 10. This was later renamed as Bob\u2019s Only Successful Software. 11. Our company held the patent. Our employment contract made it clear that anything we invented belonged to our company. My boss\ntold me: \u201cYou sold it to us for one dollar, and we didn\u2019t pay you that dollar.\u201d\n12. Three-Dimensional Black Board. If you were born in the 1950s, you likely get this reference: Drizzle, Drazzle, Druzzle, Drone. 13. Computer Aided Software Engineering", "domains": ["Design Patterns"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 274", "position": 274, "chunk_type": "semantic", "token_estimate": 324}
{"text": "INDEX: Numbers\n3DBB shared memory system, Craft Dispatch System archaeology project, 363\n4-TEL, archaeology projects\nBOSS, 351\u2013352\nC language, 349\u2013351\nDLU/DRU, 354\u2013356\noverview of, 339\u2013344\npCCU, 352\u2013354\nSAC (service area computer), 344\u2013349\nVRS, 357\u2013359\n8085 computer, archaeological projects\n4-TEL, 341\nBOSS, 351\nC language and, 349\u2013351\nDLU/DRU, 356\n8086 Intel microcomputer, SAC archaeology project, 347\u2013348\nA\nAbstract classes\nconclusion, 132\nDependency Inversion Principle and, 87\nleftover in Zone of Uselessness, 129\u2013130\nplacing high-level policy, 126\u2013128\nservices in Java as set of, 246\nAbstract components, 125\u2013126\nAbstract Factories, 89\u201390\nAbstractions\nprinciple of stable. See SAP (Stable Abstractions Principle)\nsource code dependencies and, 87\nstable, 88\u201389\nAccess modifiers, architectural packages, 316\u2013319\nAccidental duplication, 154\u2013155\nActors, 62\u201365", "domains": ["Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 275", "position": 275, "chunk_type": "semantic", "token_estimate": 114}
{"text": "Address segments, relocatable binaries, 99\u2013100: ADP (Acyclic Dependencies Principle)\nbreaking cycle, 117\u2013118\ncomponent dependency graph effected by, 118\neffect of cycle in component dependency graph, 115\u2013117\neliminating dependency cycles, 113\u2013115\njitters, 118\noverview of, 112\nweekly build, 112\u2013113\nAluminum die-cast monitoring, archaeology project, 338\u2013339\nAPIs, testing, 252\u2013253\nApp-titude test, 258\u2013261\nApplication-specific business rules, use cases, 192\u2013193, 204\nArchitects\ngoal to minimize human resources, 160\nregistry exam archaeology project, 370\u2013373\nseparate details from policy, 142\nArchitecture\nclean. See Clean architecture\nclean embedded. See Clean embedded architecture\ndesign vs., 4\nin DLU/DRU archaeology project, 356\nEisenhower\u2019s matrix of importance vs. urgency, 16\u201317\ngetting software right, 2\nimmutability and, 52\nindependence. See Independence\nISP and, 86\nLSP and, 80\nplugin, 170\u2013171\nin ROSE archaeology product, 368\u2013370\nin SAC archaeology project, 345\u2013347\nas senior to function, 18\nas software value, 14\u201315\nstability, 122\u2013126\ntesting, 213\nthree big concerns in, 24\nvalue of function vs., 15\u201316\nin VRS archaeology project, 358\u2013359\nArchitecture archaeology projects\n4-TEL, 339\u2013344\naluminum die-cast monitoring, 338\u2013339", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 276", "position": 276, "chunk_type": "semantic", "token_estimate": 165}
{"text": "dreaded monolith, 176\u2013178: local processes, 179\u2013180\nservices, 180\u2013181\nthreads, 179\nBoundary crossing\nin clean architecture, 206\nclean architecture scenario, 207\u2013208\ncreating appropriate, 176\nDependency Rule for data in, 207\nBreaking cycle, Acyclic Dependencies Principle, 117\u2013118\nBusiness managers\nEisenhower\u2019s matrix of importance vs. urgency, 17\npreference for function vs. architecture, 15\u201316\nBusiness rules\nboundaries between GUI and, 169\u2013170\nclean architecture for, 202\u2013203\nconclusion, 194\ncreating Entities, 190\u2013191\ndecoupling from UI, 287\u2013289\ndecoupling layers, 152\u2013153\ndecoupling use cases, 153\ndesigning for testability, 251\nin Hunt the Wumpus adventure game, 222\u2013223\nindependent developability, 47\nkeeping close to data, 67\nplugging into, 170\u2013173\npolicy statements calculating, 184\nrequest/response models and, 193\u2013194\nin SAC archaeology project, 346\u2013347\nseparating components with boundary lines, 165\u2013169\nunderstanding, 189\u2013190\nuse cases for, 191\u2013193, 204\nC\nC++ language\ninheritance in, 40\nlearning, 366\nmarrying STL framework in, 293\npolymorphism in, 42\nROSE application, 369\u2013370\nweakening encapsulation, 36\u201337", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 279", "position": 279, "chunk_type": "semantic", "token_estimate": 147}
{"text": "C language: BOSS archaeology project using, 351\u2013352\nDLU/DRU archaeology project using, 356\nencapsulation in, 34\u201336\ninheritance in, 38\u201340\npolymorphism in, 40\u201342\nredesigning SAC in, 347\u2013348\nC language, archaeology project, 349\u2013351\nC# programming language\nabstract components in, 125\ndependency inversion, 45\nusing statements for dependencies, 184\nweakening encapsulation, 36\u201337\nC Programming Language (Kernighan & Ritchie), 351\nC4 software architecture model, 314\u2013315\nCarew, Mike, 356\nCASE (Computer Aided Software Engineering) tool, 368\nCase study. See Video sales case study\nCathode ray tube (CRT) terminals, Union Accounting archaeology project, 328\u2013329\nCCP (Common Closure Principle)\ndecoupling layers, 152\ngrouping policies into components, 186\u2013187\nkeeping changes localized, 118\noverview of, 105\u2013107\nStable Dependencies Principle and, 120\ntension diagram, 108\u2013110\nCCU/CMU (COL\nT control unit/COL\nT measurement unit), pCCU archaeology project, 353\u2013354\nCDS (Craft Dispatch System), archaeology project\noverview of, 361\u2013363\nCentral office line testers. See COL\nTs (central office line testers)\nCentral offices (COs), 4-TEL archaeology project, 339\u2013340\nChange, ease of software, 14\u201315\nChurch, Alonzo, 22\u201323, 50\nCICS-COBOL program, aluminum die-cast archaeology project, 339\nClasses\nabstract. See Abstract classes\nCommon Reuse Principle, 107\u2013108\nDIP and, 89\nLSP use in guiding inheritance, 78\npartitioning processes into, 71\u201372\nReuse/Release Equivalence Principle, 105", "domains": ["Design Patterns", "Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 280", "position": 280, "chunk_type": "semantic", "token_estimate": 195}
{"text": "SRP examples, 67: Clean architecture\ncharacteristics of, 201\u2013203\nconclusion, 209\nDependency Rule, 203\u2013207\nframeworks tend to violate, 293\ntypical scenario, 208\nusing layers and boundaries, 223\u2013226\nClean embedded architecture\napp-titude test, 258\u2013261\nconclusion, 273\ndon\u2019t reveal hardware details to user of HAL, 265\u2013269\nDRY conditional compilation directives, 272\nhardware is detail, 263\u2013264\nis testable embedded architecture, 262\nlayers, 262\u2013263\noperating system is detail, 269\u2013271\noverview of, 255\u2013258\nprogramming to interfaces and substitutability, 271\u2013272\ntarget-hardware bottleneck, 261\nCleancoders.com, 297\nClear Communications, 364\u2013367\nphone call, 367\nsetup, 366\nUncle Bob, 367\nClojure, 50\u201351, 53\u201354\nCodd, Edgar, 278\nCode\nin aluminum die-cast archaeology project, 338\u2013339\ndecreasing productivity/increased cost of, 5\u20137\nfoolishness of overconfidence, 9\u201312\nrising costs of development payroll, 8\u20139\nin SAC archaeology project, 345\nsignature of messy, 7\u20138\nsource code dependencies. See Source code dependencies\nCode organization\nconclusion, 321\ndevil is in the details, 315\u2013316\nother decoupling modes, 319\u2013320\noverview of, 303\u2013304\npackage by component, 310\u2013315", "domains": ["Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 281", "position": 281, "chunk_type": "semantic", "token_estimate": 154}
{"text": "package by feature, 306\u2013307: package by layer, 304\u2013306\nports and adapters, 308\u2013310\nvs. encapsulation, 316\u2013319\nCohesion, Single Responsibility Principle, 63", "domains": ["Design Patterns", "Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 282", "position": 282, "chunk_type": "semantic", "token_estimate": 20}
{"text": "Ts (central office line testers): in 4-TEL archaeology project, 340\u2013344\npCCU archaeology project, 352\u2013354\nin service area computer archaeology project, 344\u2013349\nCommon Closure Principle. See CCP (Common Closure Principle)\nCommon Reuse Principle. See CRP (Common Reuse Principle)\nCommunications\nacross deployment component boundaries, 179\nacross local process boundaries, 180\nacross service boundaries, 180\u2013181\nacross source-level decoupled boundaries, 178\nConway\u2019s law, 149\nas function calls between components in monoliths, 178\nin types of decoupling modes, 155\u2013157\nCompare and swap algorithm, 54\nCompiled languages, 96\nCompilers\nenforce architectural principles with, 319\nlocation of source code, 97\u201398\nrelocatable binaries, 99\u2013100\nComponent architecture, video sales case study, 300\u2013302\nComponent-based systems\nbuilding scalable, 241\ndesigning services using SOLID, 245\u2013246\nfunction calls, 240\nOO approach for cross-cutting concerns, 244\u2013245\nComponent cohesion\nCommon Closure Principle, 105\u2013107\nCommon Reuse Principle, 107\u2013108\nconclusion, 110\noverview of, 104\nReuse/Release Equivalence Principle, 104\u2013105\ntension diagram, 108\u2013110\nComponent coupling\nADP. See ADP (Acyclic Dependencies Principle)\nconclusion, 132", "domains": ["Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 282", "position": 282, "chunk_type": "semantic", "token_estimate": 154}
{"text": "Fragile Tests Problem, 251: overview of, 111\nStable Abstractions Principle. See SAP (Stable Abstractions Principle)\nStable Dependencies Principle, 120\u2013126\ntop-down design, 118\u2013119\nComponent dependency graph\nbreak cycle of components/reinstate as DAG, 117\u2013118\neffect of cycle in, 115\u2013117\nComponent-per-team architecture, 137\u2013138\nComponents\nconcrete, 91\ndeployment of, 178\u2013179\nhistory of, 96\u201399\nlinkers, 100\u2013102\noverview of, 96\npackage by, 313\u2013315\npartitioning processes into classes/separating classes into, 71\u201372\nprinciples, 93\nrelocatability, 99\u2013100\ntests as system, 250\nComputer Aided Software Engineering (CASE) tool, 368\nConcrete components, Dependency Inversion Principle, 91\nConcurrent tasks, BOSS archaeology project, 351\u2013352\nConcurrent updates, 52\u201353\nConstantine, Larry, 29\nControl, flow of. See Flow of control\nControl structures, program, 27\u201328\nControl, transfer of, 22\nControllers\nin clean architecture, 203, 205\nclean architecture scenario, 207\u2013208\ncrossing circle boundaries, 206\nConway\u2019s law, 149\nCopper wires, pCCU archaeology project, 352\u2013354\nCore code, avoid frameworks in, 293\nCOs (central offices), 4-TEL archaeology project, 339\u2013340\nCoupling. See also Component coupling\navoid allowing framework, 293\nto premature decisions, 160\nCraft Dispatch System. See CDS (Craft Dispatch System), archaeology project\nCritical Business Data, 190\u2013191", "domains": ["Design Patterns", "Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 283", "position": 283, "chunk_type": "semantic", "token_estimate": 175}
{"text": "drawing boundary line between business rules and, 165: gateways, 214\nin Hunt the Wumpus adventure game, 222\u2013223\nindependent developability, 47\nleaving options open in development, 141, 197\nplugin architecture, 171\nrelational, 278\nschema in Zone of Pain, 129\nseparating components with boundary lines, 165\u2013169\nDatabase is detail\nanecdote, 281\u2013283\nconclusion, 283\ndetails, 281\nif there were no disks, 280\u2013281\noverview of, 277\u2013278\nperformance, 281\nrelational databases, 278\nwhy database systems are so prevalent, 279\u2013280\nDCI system architecture, 202\nDeadlocks, from mutable variables, 52\nDecoupling\nas fallacy of services, 240\u2013241\nindependent deployment, 154, 241\nindependent development, 153\u2013154, 241\nkitty problem example, 242\u2013243\nlayers, 151\u2013152\nmodes, 153, 155\u2013158\nOO approach for cross-cutting concerns, 244\u2013245\npurpose of testing API, 252\u2013253\nsource code dependencies, 319\nuse cases, 152\nDeMarco, Tom, 29\nDependencies\nADP. See ADP (Acyclic Dependencies Principle)\narchitectural framework for policy, 184\ncalculating stability metrics, 123\ncase study. See Video sales case study\nCommon Reuse Principle and, 107\u2013108\nDIP. See DIP (Dependency Inversion Principle)\nin Laser Trim archaeology project, 338\nmanaging undesirable, 89\u201390", "domains": ["Design Principles", "Software Quality Attributes", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 285", "position": 285, "chunk_type": "semantic", "token_estimate": 170}
{"text": "OCP example, 72: in package by layer, 304\u2013306, 310\u2013311\nsoftware destroyed by unmanaged, 256\nstable. See SDP (Stable Dependencies Principle)\ntransitive, 75\nunderstanding component, 121\nin Union Accounting archaeology project, 333\u2013334\nDependency graph, 115\u2013118\nDependency Injection framework, Main component, 232\nDependency inversion, 44\u201347\nDependency management\nmetrics. See ADP (Acyclic Dependencies Principle)\nvia full-fledged architectural boundaries, 218\nvia polymorphism in monolithic systems, 177\nvideo sales case study, 302\nDependency Rule\nclean architecture and, 203\u2013206\nclean architecture scenario, 207\u2013208\ncrossing boundaries, 206\ndefined, 91\ndependency management, 302\ndesigning services to follow, 247\nEntities, 204\nframeworks and drivers, 205\nframeworks tending to violate, 293\nin Hunt the Wumpus adventure game, 223\ninterface adapters, 205\nOO approach for cross-cutting concerns, 244\u2013245\nservices may follow, 240\ntests following, 250\nuse cases, 204\nwhich data crosses boundaries, 207\nDeployment\narchitecture determines ease of, 150\ncomponents, 178\u2013180\ncomponents as units of, 96\nimpact of architecture on, 138\ntests use independent, 250\nDeployment-level decoupling mode, 156\u2013157, 178\u2013179\nDesign\napproaches to. See Code organization", "domains": ["Design Patterns", "Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 286", "position": 286, "chunk_type": "semantic", "token_estimate": 165}
{"text": "architecture vs., 4: decreasing productivity/increases cost of code, 5\u20137\ngetting it right, 2\ngoal of good, 4\u20135\nreducing volatility of interfaces, 88\nsignature of a mess, 7\u20138\nSOLID principles of, 57\u201359\nfor testability, 251\nDesigning Object-Oriented C++ Applications Using the Booch Method, 369\nDetail\ndatabase is. See Database is detail\ndon\u2019t reveal hardware, to user of HAL, 265\u2013269\nframework is, 291\u2013295\nhardware is, 263\u2013264\nseparating from policy, 140\u2013142\nstory of architectural success, 163\u2013165\nweb is, 285\u2013289\nDevelopers\ndecreasing productivity/increasing cost of code, 5\u20137\nEisenhower\u2019s matrix of importance vs. urgency, 17\nfoolishness of overconfidence, 9\u201312\npreference for function vs. architecture, 15\u201316\nscope vs. shape in determining cost of change, 15\nsignature of a mess, 8\u20139\nas stakeholders, 18\nDevelopment\nimpact of architecture on, 137\u2013138\nindependent. See Independent developability\nrole of architecture in supporting, 149\u2013150\nrole of test to support, 250\nDevice independence\ndefined, 142\u2013143\nIO device of UI as, 288\u2013289\njunk mail example, 144\u2013145\nphysical addressing example, 145\u2013146\nin programming, 44\nDigital revolution, and telephone companies, 352\u2013354\nDijkstra, Edsger Wybe\napplying discipline of proof to programming, 27\ndiscovery of structured programming, 22\nhistory of, 26", "domains": ["Design Principles", "Software Quality Attributes", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 287", "position": 287, "chunk_type": "semantic", "token_estimate": 184}
{"text": "proclamation on goto statements, 28\u201329: on testing, 31\nDIP (Dependency Inversion Principle)\nbreaking cycle of components, 117\u2013118\nconclusion, 91\nconcrete components, 91\ncrossing circle boundaries, 206\ndefined, 59\ndrawing boundary lines, 173\nEntities without knowledge of use cases as, 193\nfactories, 89\u201390\nin good software architecture, 71\nnot all components should be stable, 125\noverview of, 87\u201388\nstable abstractions, 88\u201389\nStable Abstractions Principle, 127\nDirected acyclic graph. See DAGs (directed acyclic graphs)\nDirectional control, Open-Closed Principle, 74\nDisks\nif there were no, 280\u2013281\nprevalence of database systems due to, 279\u2013280\nin Union Accounting archaeology project, 326\u2013330\nDispatch code, service area computer project, 345\nDisplay local unit/display remote unit (DLU/DRU) archaeology project, 354\u2013356\nDLU/DRU (display local unit/display remote unit), archaeology project, 354\u2013356\nDo/while/until statements, 22, 27\nDon\u2019t Repeat Yourself (DRY) principle, conditional compilation directives, 272\nDrawing lines. See Boundaries\nDrivers, Dependency Rule, 205\nDRY (Don\u2019t Repeat Yourself) principle, conditional compilation directives, 272\nDSL (domain-specific data-driven language), Laser Trim archaeology project, 337\nDuplication\naccidental, 63\u201365\ntrue vs. accidental, 154\u2013155\nDynamic polymorphism, 177\u2013178, 206\nDynamically linked libraries, as architectural boundaries, 178\u2013179\nDynamically typed languages\nDIP and, 88\nISP and, 85\nE", "domains": ["Design Patterns", "Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 288", "position": 288, "chunk_type": "semantic", "token_estimate": 188}
{"text": "Editing, Laser Trim archaeology project, 336: Educational Testing Service (ETS), 370\u2013372\nEisenhower, matrix of importance vs. urgency, 16\u201317\nEmbedded architecture. See Clean embedded architecture\nEncapsulation\nin defining OOP, 35\u201337\norganization vs., 316\u2013319\noveruse of public and, 316\nEntities\nbusiness rules and, 190\u2013191\nclean architecture scenario, 207\u2013208\ncreating testable architecture, 198\nDependency Rule for, 204\nrisks of frameworks, 293\nuse cases vs., 191\u2013193\nEnumeration, Dijkstra\u2019s proof for sequence/selection, 28\nEPROM (Erasable Programmable Read-Only Memory) chips, 4-TEL archaeology project, 341\u2013343\nER (Electronic Receptionist)\narchaeology project, 359\u2013361\nCraft Dispatch System was, 362\u2013364\nETS (Educational Testing Service), 370\u2013372\nEurope, redesigning SAC for US and, 347\u2013348\nEvent sourcing, storing transactions, 54\u201355\nExecutables\ndeployment of monoliths, 176\u2013178\nlinking components as, 96\nExternal agency, clean architecture independence from, 202\nExternal definition, compilers, 100\nExternal reference, compilers, 100\nF\nFacade pattern, partial boundaries, 220\nFan-in/fan-out metrics, component stability, 122\u2013123\nFeathers, Michael, 58\nFile systems, mitigating time delay, 279\u2013280\nFirewalls, boundary crossings via, 176\nFirmware\nin 4-TEL archaeology project, 343\u2013344\ndefinitions of, 256\u2013257\neliminating target-hardware bottleneck, 262\u2013263\nfuzzy line between software and, 263\u2013264", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 289", "position": 289, "chunk_type": "semantic", "token_estimate": 174}
{"text": "Functions: avoid overriding concrete, 89\nbreaking down into parts (functional decomposition), 29\none of three big concerns in architecture, 24\nprinciple of doing one thing, 62\nseparating from data, 66\nSRP examples, 67\nG\nGateways, database, 214\nGE Datanet 30 computer, Union Accounting archaeology project, 326\u2013330\nGoto statements\nDijkstra replaces with iteration control structures, 27\nDijkstra\u2019s proclamation on harmfulness of, 28\u201329\nhistory of structured programming, 22\nremoved in structured programming, 23\nGrowing Object Oriented Software with Tests (Freeman & Pryce), 202\nGUI (graphical user interface). See also UI (user interface)\ndecoupling business rules from, 287\u2013289\ndesigning for testability, 251\ndeveloping architects registry exam, 371\u2013372\ninput/output and boundary lines, 169\u2013170\nplugin architecture, 170\u2013171\nplugin argument, 172\u2013173\nseparating from business rules with boundaries, 165\u2013169\nunit testing, 212\nweb is, 288\nH\nHAL (hardware abstraction layer)\navoid revealing hardware details to user of, 265\u2013269\nas boundary line between software/firmware, 264\nDRY conditional compilation directives, 272\noperating system is detail and, 269\u2013271\nHardware\neliminating target-hardware bottleneck with layers, 262\u2013263\nfirmware becomes obsolete through evolution of, 256\nin SAC archaeology project, 346\u2013347\nHeader files, programming to interfaces with, 272\nHexagonal Architecture (Ports and Adapters), 202\nHigh-level policy", "domains": ["Design Patterns", "Design Principles", "Software Quality Attributes", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 291", "position": 291, "chunk_type": "semantic", "token_estimate": 192}
{"text": "decoupling from lower level input/output policies, 185\u2013186: separating details from, 140\u2013142\nsplitting data streams, 227\u2013228\nwhere to place, 126\nHuman resources, goal of architect to minimize, 160\nHumble Object pattern\ndata mappers, 214\u2013215\ndatabase getaways, 214\nPresenters and Views, 212\u2013213\nPresenters as form of, 212\ntesting and architecture, 213\nunderstanding, 212\nHunt the Wumpus game\nlayers and boundaries. See Layers and boundaries\nMain component from, 232\u2013237\nI\nIBM System/7, aluminum die-cast archaeology project, 338\u2013339\nIf/then/else statements, 22, 27\nImmutability, 52\u201354\nImplementation strategy. See Code organization\nImportance, urgency vs. Eisenhower\u2019s matrix of, 16\u201317\nIncoming dependencies, stability metrics, 122\u2013123\nIndependence\nconclusion, 158\ndecoupling layers, 151\u2013152\ndecoupling mode, 153\ndecoupling use cases, 152\ndeployment, 150\ndevelopment, 149\u2013150\nduplication, 154\u2013155\nindependent deployability, 154\nindependent developability, 153\u2013154\nleaving options open, 150\u2013151\noperation, 149\noverview of, 147\u2013148\ntypes of decoupling modes, 155\u2013158\nuse cases, 148\nIndependent components\ncalculating stability metrics, 123\nunderstanding, 121", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 292", "position": 292, "chunk_type": "semantic", "token_estimate": 147}
{"text": "Independent deployability: in 4-TEL archaeology project, 344\nas fallacy of services, 241\nkitty problem example, 242\u2013243\nin OO approach for cross-cutting concerns, 244\u2013245\noverview of, 154\nIndependent developability\nas fallacy of services, 241\nkitty problem example, 242\u2013243\nin OO approach for cross-cutting concerns, 244\u2013245\noverview of, 153\u2013154\nof UI and database, 47\nInduction, Dijkstra\u2019s proof related to iteration, 28\nInformation hiding, Open-Closed Principle, 74\u201375\nInheritance relationships\ncrossing circle boundaries, 206\ndefining OOP, 37\u201340\ndependency inversion, 46\ndependency management, 302\nguiding use of, 78\nInput/output\nbusiness rules for use cases, 193\u2013194\ndecoupling higher-level policy from lower level, 185\u2013187\npolicy level defined as distance from, 184\nseparating components with boundary lines, 169\u2013170\nIntegers, functional programming example, 50\u201351\nIntegration, weekly build issues, 112\u2013113\nInterface adapters, Dependency Rule for, 205\nInterface Segregation Principle. See ISP (Interface Segregation Principle)\nIO device\nUNIX functions, 41\u201344\nweb is, 288\u2013289\nIsolation, test, 250\u2013251\nISP (Interface Segregation Principle)\narchitecture and, 86\nCommon Reuse Principle compared with, 108\nconclusion, 86\ndefined, 59\nlanguage type and, 85\noverview of, 84\u201385\nIteration, 27\u201328", "domains": ["Design Patterns", "Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 293", "position": 293, "chunk_type": "semantic", "token_estimate": 171}
{"text": "J: Jacobson, Ivar, 196, 202\nJar files\ncomponent architecture, 301\ncomponents as, 96\ncreating partial boundary, 219\ndefining function of components, 313\ndesigning component-based services, 245\u2013246\nDownload and Go rule for, 163\nin source-level decoupling mode, 176\nJava\nabstract components in, 125\ncode organization approaches in. See Code organization\ncomponents as jar files in, 96\nDIP and, 87\nimport statements for dependencies, 184\nISP example, 84\u201385\nmarrying standard library framework in, 293\nmodule frameworks in, 319\npackage by layer in, 304\u2013306\nsquares of integers example in, 50\u201351\nweakening encapsulation, 36\u201337\nJitters, breaking cycle of components, 118\nJunk mail example, 144\u2013145\nK\nKitty problem example, 242\u2013245\nL\nLanguages\nclean architecture and, 223\u2013226\nHunt the Wumpus adventure game, 222\u2013223\nLaser Trim, archaeology project\n4-TEL project, 339\noverview of, 334\u2013338\nLayered architecture\npackage by layer code organization, 304\u2013306\nrelaxed, 311\u2013312\nwhy it is considered bad, 310\u2013311\nLayers\napproach to code organization, 304\u2013306", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 294", "position": 294, "chunk_type": "semantic", "token_estimate": 149}
{"text": "clean architecture using, 202\u2013203: decoupling, 151\u2013152\nduplication of, 155\neliminating target-hardware bottleneck, 262\u2013263\nindependent developability, 154\nLayers and boundaries\nclean architecture, 223\u2013226\nconclusion, 228\ncrossing streams, 226\nHunt the Wumpus adventure game, 222\u2013223\noverview of, 221\u2013222\nsplitting streams, 227\u2013228\nLeiningen tool, module management, 104\nLevel\nhierarchy of protection and, 74\npolicy and, 184\u2013187\nLibraries\nlocation of source code, 97\u201398\nrelocatable binaries, 99\u2013100\nLife cycle, architecture supports system, 137\nLinkers, separating from loaders, 100\u2013102\nLiskov, Barbara, 78\nLiskov Substitution Principle (LSP). See LSP (Liskov Substitution Principle)\nLISP langauge, functional programming, 23\nLisp language, squares of integers example, 50\u201351\nLoaders\nlinking, 100\u2013102\nrelocatable binaries, 99\u2013100\nLocal process boundaries, 179\u2013180\nLSP (Liskov Substitution Principle)\narchitecture and, 80\nconclusion, 82\ndefined, 59\nguiding use of inheritance, 78\noverview of, 78\nsquare/rectangle example problem, 79\nviolation of, 80\u201382\nM\nM365 computer\n4-TEL archaeology project, 340\u2013341", "domains": ["Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 295", "position": 295, "chunk_type": "semantic", "token_estimate": 140}
{"text": "Laser Trim archaeology project, 335\u2013338: SAC archaeology project, 345\u2013347\nMailboxes, local processes communicate via, 180\nMain component\nconclusion, 237\nas concrete component, 91\ndefined, 232\nobject-oriented programming, 40\npolymorphism, 45\nsmall impact of releasing, 115\nas ultimate detail, 232\u2013237\nMain Sequence\navoiding Zones of Exclusion via, 130\ndefining relationship between abstraction/stability, 127\u2013128\nmeasuring distance from, 130\u2013132\nZone of Pain, 129\nZone of Uselessness, 129\u2013130\nMaintenance, impact of architecture on, 139\u2013140\nMarketing campaigns, database vendor, 283\nMaster Operating Program (MOP), Laser Trim archaeology project, 336\nMathematics\ncontrasting science with, 30\ndiscipline of proof, 27\u201328\nMaven tool, module management, 104\nMcCarthy, John, 23\nMemory\nearly layout of, 98\u201399\nlocal processes and, 179\nRAM. See RAM\nMerges, SRP examples, 65\nMessage queues, local processes communicate via, 180\nMetrics\nabstraction, 127\ndistance from Main Sequence, 130\u2013132\nMeyer, Bertrand, 70\nMicro-service architecture\nin Craft Dispatch System archaeology project, 362\u2013363\ndecoupling mode, 153\ndeployment strategy, 138\npopularity of, 239\nModems, SAC archaeology project, 346\u2013347", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 296", "position": 296, "chunk_type": "semantic", "token_estimate": 158}
{"text": "Modules: Common Reuse Principle, 107\u2013108\ndefined, 62\nmanagement tools, 104\npublic types vs. published types, 319\nReuse/Release Equivalence Principle, 105\nMonoliths\nbuilding scalable systems, 241\ndeployment-level components vs., 179\ndeployment of, 176\u2013178\nfunction calls, 240\nlocal processes as statically linked, 180\nthreads, 179\nMoore\u2019s Law, 101\nMOP (Master Operating Program), Laser Trim archaeology project, 336\nMorning after syndrome\neliminating dependency cycles to solve, 113\u2013115\nmanaging dependencies to prevent, 118\noverview of, 112\nweekly build issues, 112\u2013113\nMPS (multiprocessing system), SAC archaeology project, 345\u2013346\nMutability, 52\u201354\nMutable variables, 51, 54\u201355\nN\nNational Council of Architects Registry Board (NCARB), 370\u2013372\n.NET, components as DLLs, 96\nNetNews, presence of author on, 367\u2013369\nNewkirk, Jim, 371\u2013372\nNygaard, Kristen, 22\nO\nObject-oriented databases, ROSE product, 368\u2013370\nObject Oriented Design with Applications (Booch), 366, 368\nObject-oriented programming\nconclusion, 47\nfor cross-cutting concerns, 244\u2013245\ndependency inversion, 44\u201347\ndeployment of monoliths, 177\nencapsulation, 35\u201337\nhistory of, 22", "domains": ["Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 297", "position": 297, "chunk_type": "semantic", "token_estimate": 149}
{"text": "inheritance, 37\u201340: overview of, 34\u201335\npolymorphism, 40\u201343\npower of polymorphism, 43\u201344\nObject Oriented Software Engineering (Jacobson), 196, 202\nObject relational mappers (ORMs), 214\u2013215\nObjects, invented in 4-TEL archaeology project, 344\nOCP (Open-Closed Principle)\nbirth of, 142\nCommon Closure Principle compared with, 106\nconclusion, 75\nin Craft Dispatch System archaeology project, 363\ndefined, 59\ndependency management, 302\ndesigning component-based services, 246\ndirectional control, 74\ninformation hiding, 74\u201375\noverview of, 70\nthought experiment, 71\u201374\nOMC (Outboard Marine Corporation), aluminum die-cast archaeology project, 338\u2013339\nOne-dimensional boundaries, 219\nOpen-Closed Principle. See OCP (Open-Closed Principle)\nOperating system abstraction layer (OSAL), clean embedded architecture, 270\u2013271\nOperating system (OS), is detail, 269\u2013271\nOperations\narchitecture supports system, 138\u2013139, 149\ndecoupling use cases for, 153\nuse cases affected by changes in, 204\nOptions, keeping open\ngood architecture makes system easy to change, 150\u2013151\noperational architecture, 149\npurpose of architecture, 140\u2013142, 197\nvia decoupling mode, 153\nOrganization vs. encapsulation, 316\u2013319\nORMs (object relational mappers), 214\u2013215\nOS (operating system), is detail, 269\u2013271\nOSAL (operating system abstraction layer), clean embedded architecture, 270\u2013271\nOscillations, web as one of many, 285\u2013289\nOutgoing dependencies, stability metrics, 122\u2013123\nOverconfidence, foolishness of, 9\u201312", "domains": ["Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 298", "position": 298, "chunk_type": "semantic", "token_estimate": 186}
{"text": "P: Package by component, 310\u2013315, 318\nPackage by feature, 306\u2013307, 317\nPackage by layer\naccess modifiers, 317\u2013318\nhorizontal layering of code, 304\u2013306\nwhy it is considered bad, 310\u2013311\nPackages, organization vs. encapsulation, 316\u2013319\nPage-Jones, Meilir, 29\nPartial boundaries\nconclusion, 220\nfacades, 220\none-dimensional boundaries, 219\nreasons to implement, 217\u2013218\nskip last step, 218\u2013219\nPatches, in 4-TEL archaeology project, 344\nPCCU, archaeology project, 352\u2013354\nPDP-11/60 computer, 349\u2013351\nPerformance, as low-level concern, 281\nP\u00e9riph\u00e9rique anti-pattern of ports and adapters, 320\u2013321\nPhysical addressing example, 145\u2013146\nPlugin architecture\nin 4-TEL archaeology project, 344\nfor device independence, 44\ndrawing boundaries for axis of change, 173\nof lower-level components into higher-level components, 187\nMain component as, 237\nstart with presumption of, 170\u2013171\nPointers\nin creating polymorphic behavior, 43\nfunctional, 22\u201323\nPolicy\nin clean architecture, 203\nhigh-level. See High-level policy\noverview of, 183\u2013184\nsoftware systems as statements of, 183\nsplitting data streams, 227\u2013228\nPolymorphic dispatch, 4-TEL archaeology project, 344\nPolymorphism\ncrossing circle boundaries with dynamic, 206\ndependency inversion, 44\u201347", "domains": ["Design Patterns", "Design Principles", "Software Quality Attributes", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 299", "position": 299, "chunk_type": "semantic", "token_estimate": 162}
{"text": "flow of control in dynamic, 177\u2013178: in object-oriented programming, 22, 40\u201343\npower of, 43\u201344\nPorts and adapters\naccess modifiers, 318\napproach to code organization, 308\u2013310\ndecouple dependencies with source code trees, 319\u2013320\nP\u00e9riph\u00e9rique anti-pattern of, 320\u2013321\nPositional stability, component, 122\u2013123\nPremature decisions, coupling to, 160\u2013163\n\u201cPresentation Domain Data Layering\u201d (Fowler), 305\u2013306\nPresenters\nin clean architecture, 203, 205\nclean architecture scenario, 207\u2013208\ncomponent architecture, 301\ncrossing circle boundaries, 206\nPresenters and humble objects\nconclusion, 215\ndata mappers, 214\u2013215\ndatabase getaways, 214\nHumble Object pattern, 212\noverview of, 211\u2013212\nPresenters and Views, 212\u2013213\nservice listeners, 215\ntesting and architecture, 213\nProcesses, partitioning into classes/separating classes, 71\u201372\nProcessor\nis detail, 265\u2013269\nmutability and, 52\nProduct, video sales case study, 298\nProductivity\ndecreasing, increasing cost of code, 5\u20137\nsignature of a mess, 8\u20139\nProgramming languages\nabstract components in, 125\u2013126\ncomponents, 96\ndynamically typed, 88\nISP and, 85\nstatically typed, 87\nvariables in functional languages, 51\nProgramming paradigms", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 300", "position": 300, "chunk_type": "semantic", "token_estimate": 153}
{"text": "4-TEL archaeology project, 341, 343\u2013344: replacing disks, 280\u2013281\nRational (company), 367, 368\nRDBMS (relational database management systems), 279\u2013283\nReal-time operating system (RTOS) is detail, 269\u2013271\nRelational database management systems (RDBMS), 279\u2013283\nRelational databases, 278, 281\u2013283\nRelaxed layered architecture, 311\u2013312\nReleases\neffect of cycle in component dependency graph, 115\u2013117\neliminating dependency cycles, 113\u2013115\nnumbering new component, 113\nReuse/Release Equivalence Principle for new, 104\u2013105\nRemote terminals, DLU/DRU archaeology project, 354\u2013356\nREP (Reuse/Release Equivalence Principle), 104\u2013105, 108\u2013110\nRequest models, business rules, 193\u2013194\nReSharper, plugin argument, 172\u2013173\nResponse models, business rules, 193\u2013194\nREST, leave options open in development, 141\nReusability. See CRP (Common Reuse Principle)", "domains": ["Architectural Patterns and Styles", "Software Quality Attributes", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 301", "position": 301, "chunk_type": "semantic", "token_estimate": 101}
{"text": "Reuse/Release Equivalence Principle (REP), 104\u2013105, 108\u2013110: Risks\narchitecture should mitigate costs of, 139\u2013140\nof frameworks, 293\u2013294\nROM boards, 4-TEL archaeology project, 341\nROSE product, archaeology project, 368\u2013370\nRTOS (real-time operating system) is detail, 269\u2013271\nRuby\ncomponents as gem files, 96\nDIP and, 88\nISP and, 85\nRVM tool, module management, 104\nS\nSAC (service area computer), archaeology project\n4-TEL using, 340\u2013341\narchitecture, 345\u2013347\nconclusion, 349\ndispatch determination, 345\nDLU/DRU archaeology project, 354\u2013356\nEurope, 348\u2013349\ngrand redesign, 347\u2013348\noverview of, 344\nSAP (Stable Abstractions Principle)\navoiding zones of exclusion, 130\ndistance from main sequence, 130\u2013132\ndrawing boundary lines, 173\nintroduction to, 126\u2013127\nmain sequence, 127\u2013130\nmeasuring abstraction, 127\nwhere to put high-level policy, 126\nSC (service center), 4-TEL archaeology project, 339\u2013340\nScalability\nkitty problem and services, 242\u2013243\nservices not only option for building, 241\nSchmidt, Doug, 256\u2013258\nScientific methods, proving statements false, 30\u201331\nScope, of changing architecture, 15\nScreaming architecture. See Architecture, screaming\nSDP (Stable Dependencies Principle)\nabstract components, 125\u2013126", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 302", "position": 302, "chunk_type": "semantic", "token_estimate": 159}
{"text": "not all components should be, 124\u2013125: not all components should be stable, 123\u2013125\noverview of, 120\nstability, 120\u2013121\nstability metrics, 122\u2013123\nStable Abstractions Principle, 127\nSecurity, testing API, 253\nSelection, as program control structure, 27\u201328\nSeparation of components, as big concern in architecture, 24\nSequence, as program control structure, 27\u201328\nSerial communication bus, SAC archaeology project, 347\nService area computer. See SAC (service area computer), archaeology project\nService center (SC), 4-TEL archaeology project, 339\u2013340\nService-level decoupling mode, 153, 156\u2013157\nServices\ncomponent-based, 245\u2013246\nconclusion, 247\ncross-cutting concerns, 246\u2013247\ndecoupling fallacy, 240\u2013241\nas function calls vs. architecture, 240\nHumble Object boundaries for, 214\u2013215\nindependent development/deployment fallacy, 241\nkitty problem, 242\u2013243\nobjects to the rescue, 244\u2013245\noverview of, 239\nas strongest boundary, 180\u2013181\nSet program interrupt (SPI) instruction, aluminum die-cast archaeology project, 339\nShape, of change, 15\nSingle Responsibility Principle. See SRP (Single Responsibility Principle)\nSOA (service-oriented architecture)\ndecoupling mode, 153\nin Electronic Receptionist archaeology project, 360\u2013361\nreasons for popularity of, 239\nSockets, local processes communicate via, 180\nSoftware\nclean embedded architecture isolates OS from, 270\ncomponents. See Components\neliminating target-hardware bottleneck with layers, 262\u2013263\nfuzzy line between firmware and, 263\u2013264\ngetting it right, 1\u20132\nSOLID principles, 58", "domains": ["Architectural Patterns and Styles", "Design Principles", "Software Quality Attributes", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 303", "position": 303, "chunk_type": "semantic", "token_estimate": 195}
{"text": "value of architecture vs. behavior, 14\u201318: Software development\nfighting for architecture over function, 18\nlike a science, 31\nSoftware reuse\nCommon Reuse Principle, 107\u2013108\nreusable components and, 104\nReuse/Release Equivalence Principle, 104\u2013105\nSOLID principles\nDependency Inversion Principle. See DIP (Dependency Inversion Principle)\ndesigning component-based services using, 245\u2013246\nhistory of, 57\u201359\nInterface Segregation Principle. See ISP (Interface Segregation Principle)\nLiskov Substitution Principle. See LSP (Liskov Substitution Principle)\nOO approach for cross-cutting concerns, 244\u2013245\nOpen-Closed Principle. See OCP (Open-Closed Principle)\nSingle Responsibility Principle. See SRP (Single Responsibility Principle)\nSource code, compiling, 97\u201398\nSource code dependencies\ncreating boundary crossing via, 176\ncrossing circle boundaries, 206\ndecoupling, 184\u2013185, 319\ndependency inversion, 44\u201347\nlocal processes as, 180\nOCP example, 72\nreferring only to abstractions, 87\u201388\nUI components reuse game rules via, 222\u2013223\nSource code trees, decoupling dependencies, 319\u2013321\nSource-level decoupling mode, 155\u2013157, 176\u2013178\nSpelunking, architecture mitigates costs of, 139\u2013140\nSPI (set program interrupt) instruction, aluminum die-cast archaeology project, 339\nSplitting data streams, 227\u2013228\nSquare/rectangle problem, LSP, 79\nSquares of integers, functional programming, 50\u201351\nSRP (Single Responsibility Principle)\naccidental duplication example, 63\u201365\nCommon Closure Principle vs., 106\u2013107\nconclusion, 66\u201367\ndecoupling layers, 152\ndefined, 59\ndependency management, 302", "domains": ["Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 304", "position": 304, "chunk_type": "semantic", "token_estimate": 191}
{"text": "in good software architecture, 71: grouping policies into components, 186\u2013187\nkeeping changes localized, 118\nmerges, 65\noverview of, 61\u201363\nsolutions, 66\u201367\nuse case analysis, 299\nwhere to draw boundaries, 172\u2013173\nStability, component\nmeasuring, 122\u2013123\nrelationship between abstraction and, 127\u2013130\nSAP. See SAP (Stable Abstractions Principle)\nunderstanding, 120\u2013121\nStable Abstractions Principle. See SAP (Stable Abstractions Principle)\nStable components\nabstract components as, 125\u2013126\nas harmless in Zone of Pain, 129\nnot all components should be, 123\u2013125\nplacing high-level policies in, 126\nStable Abstractions Principle, 126\u2013127\nStable Dependencies Principle. See SDP (Stable Dependencies Principle)\nStakeholders\nscope vs. shape for cost of change, 15\nseniority of architecture over function, 18\nvalues provided by software systems, 14\nState\nconcurrency issues from mutation, 53\nstoring transactions but not, 54\u201355\nStatic analysis tools, architecture violations, 313\nStatic vs. dynamic polymorphism, 177\nStrategy pattern\ncreating one-dimensional boundaries, 219\nOO approach for cross-cutting concerns, 244\u2013245\nStreams, data\nclean architecture and, 224\u2013226\ncrossing, 226\nsplitting, 227\u2013228\nStructural coupling, testing API, 252\nStructure. See Architecture\nStructured programming\nDijkstra\u2019s proclamation on goto statements, 28\u201329", "domains": ["Design Patterns", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 305", "position": 305, "chunk_type": "semantic", "token_estimate": 172}
{"text": "discipline of proof, 27\u201328: functional decomposition in, 29\nhistory of, 22\nlack of formal proofs, 30\noverview of, 26\nrole of science in, 30\u201331\nrole of tests in, 31\nvalue of, 31\u201332\nSubstitution\nLSP. See LSP (Liskov Substitution Principle)\nprogramming to interfaces and, 271\u2013272\nSubtypes, defining, 78\nT\nTarget-hardware bottleneck, 261, 262\u2013272\nTAS (Teradyne Applied Systems), 334\u2013338, 339\u2013344\nTemplate Method pattern, OO approach for cross-cutting concerns, 244\u2013245\nTest boundary\nconclusion, 253\ndesigning for testability, 251\nFragile Tests Problem, 251\noverview of, 249\u2013250\ntesting API, 252\u2013253\ntests as system components, 250\nTestable architecture\nclean architecture creating, 202\nclean embedded architecture as, 262\u2013272\noverview of, 198\nTesting\nand architecture, 213\nPresenters and Views, 212\u2013213\nin structured programming, 31\nunit. See Unit testing\nvia Humble Object pattern, 212\nThreads\nmutability and, 52\nschedule/order of execution, 179\nThree-tiered \u201carchitecture\u201d (as topology), 161\nTop-down design, component structure, 118\u2013119\nTransactional memory, 53\nTransactions, storing, 54\u201355", "domains": ["Design Patterns", "Design Principles", "Software Quality Attributes", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 306", "position": 306, "chunk_type": "semantic", "token_estimate": 149}
{"text": "Transitive dependencies, violating software principles, 75: Trouble tickets, CDS archaeology project, 362\u2013364\nTrue duplication, 154\u2013155\nTurning, Alan, 23\nU\nUI (user interface). See also GUI (graphical user interface)\napplying LSP to, 80\nclean architecture independent from, 202\ncrossing circle boundaries, 206\ndecoupling business rules from, 287\u2013289\ndecoupling layers, 152\u2013153\ndecoupling use cases, 153\nHunt the Wumpus adventure game, 222\u2013223\nindependent developability, 47, 154\nInterface Segregation Principle, 84\nprogramming to, 271\u2013272\nreducing volatility of, 88\nSAC archaeology project, 346\nUML class diagram\npackage by layer, 304\u2013305, 310\nports and adapters, 308\u2013310\nrelaxed layered architecture, 311\u2013312\nUncle Bob, 367, 369\nUNIFY database system, VRS archaeology project, 358\u2013359\nUnion Accounting system, archaeology project, 326\u2013334\nUnit testing\ncreating testable architecture, 198\neffect of cycle in component dependency graph, 116\u2013117\nvia Humble Object pattern, 212\nUNIX, IO device driver functions, 41\u201344\nUpgrades, risks of frameworks, 293\nUrgency, Eisenhower\u2019s matrix of importance vs., 16\u201317\nUse cases\narchitecture must support, 148\nbusiness rules for, 191\u2013194\nclean architecture scenario, 207\u2013208\ncoupling to premature decisions with, 160\ncreating testable architecture, 198\ncrossing circle boundaries, 206\ndecoupling, 152", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Design Principles", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 307", "position": 307, "chunk_type": "semantic", "token_estimate": 178}
{"text": "decoupling mode, 153: Dependency Rule for, 204\nduplication of, 155\ngood architecture centered on, 196, 197\nindependent developability and, 154\nvideo sales case study, 298\u2013300\nUser interface\nGUI. See GUI (graphical user interface)\nUI. See UI (user interface)\nUtility library, Zone of Pain, 129\nUucp connection, 366", "domains": ["Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 308", "position": 308, "chunk_type": "semantic", "token_estimate": 47}
{"text": "alues, software system: architecture (structure), 14\u201315\nbehavior, 14\nEisenhower\u2019s matrix of importance vs. urgency, 16\u201317\nfighting for seniority of architecture, 18\nfunction vs. architecture, 15\u201316\noverview of, 14\nV\nariables, functional language, 51\nV\narian 620/f minicomputer, Union Accounting archaeology project, 331\u2013334\nVideo sales case study\ncomponent architecture, 300\u2013302\nconclusion, 302\ndependency management, 302\non process/decisions of good architect, 297\u2013298\nproduct, 298\nuse case analysis, 298\u2013300\nView Model, Presenters and Views, 213\nViews\ncomponent architecture, 301\nPresenters and, 212\u2013213\nVignette Grande, architects registry exam, 371\u2013372\nVisual Studio, plugin argument, 172\u2013173\nV\noice technologies, archaeology projects\nElectronic Receptionist, 359\u2013361\nV\noice Response System, 357\u2013359\nV\nolatile components\ndependency graph and, 118\ndesign for testability, 251", "domains": ["Software Quality Attributes", "Code Organization"], "source": "Clean Architecture A Craftsman's Guide to Software Structure and Design.pdf", "section": "Page 308", "position": 308, "chunk_type": "semantic", "token_estimate": 114}
