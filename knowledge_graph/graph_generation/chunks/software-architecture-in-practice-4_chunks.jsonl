{"text": "T: he SEI Series in Software Engineering is a collaborative undertaking of \nthe Carnegie Mellon Software Engineering Institute (SEI) and Addison-\nWesley to develop and publish books on software engineering and related \ntopics. The common goal of the SEI and Addison-Wesley is to provide the \nmost current information on these topics in a form that is easily usable by \npractitioners and students. Titles in the series describe frameworks, tools, methods, and technologies \ndesigned to help organizations, teams, and individuals improve their technical \nor management capabilities. Some books describe processes and practices for \ndeveloping higher-quality software, acquiring programs for complex systems, \nRU\u0003GHOLYHULQJ\u0003VHUYLFHV\u0003PRUH\u0003H\u038d\n\u0003HFWLYHO\\\u0011\u00032WKHU\u0003ERRNV\u0003IRFXV\u0003RQ\u0003VRIWZDUH\u0003DQG\u0003\nsystem architecture and product-line development. Still others, from the \nSEI\u2019s CERT Program, describe technologies and practices needed to manage \nsoftware and network security risk. These and all titles in the series address \ncritical problems in software engineering for which practical solutions are \navailable. Visit informit.com/sei for a complete list of available publications. The SEI Series in Software Engineering\nMake sure to connect with us! informit.com/socialconnect", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 3", "position": 3, "chunk_type": "semantic", "token_estimate": 167}
{"text": "Availability  51: 4.1  \nAvailability General Scenario  53\n4.2  \nTactics for Availability  55\n4.3  \nTactics-Based Questionnaire for Availability  62\n4.4  \nPatterns for Availability  66\n4.5  \nFor Further Reading  68\n4.6  \nDiscussion Questions  69", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 7", "position": 7, "chunk_type": "semantic", "token_estimate": 32}
{"text": "Performance  133: 9.1  \nPerformance General Scenario  134\n9.2  \nTactics for Performance  137\n9.3  \nTactics-Based Questionnaire for Performance  145\n9.4  \nPatterns for Performance  146", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 8", "position": 8, "chunk_type": "semantic", "token_estimate": 23}
{"text": "Security  169: 11.1  \nSecurity General Scenario  170\n11.2  \nTactics for Security  172\n11.3  \nTactics-Based Questionnaire for Security  176\n11.4  \nPatterns for Security  179\n11.5  \nFor Further Reading  180\n11.6  \nDiscussion Questions  180", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 9", "position": 9, "chunk_type": "semantic", "token_estimate": 32}
{"text": "Testability  183: 12.1  \nTestability General Scenario  186\n12.2  \nTactics for Testability  187\n12.3  \nTactics-Based Questionnaire for Testability  192\n12.4 Patterns for Testability  192\n12.5  \nFor Further Reading  194\n12.6  \nDiscussion Questions  195", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 9", "position": 9, "chunk_type": "semantic", "token_estimate": 32}
{"text": "Software Interfaces  217: 15.1  \nInterface Concepts  218\n15.2  \nDesigning an Interface  222\n15.3  \nDocumenting the Interface  228\n15.4  \nSummary  230\n15.5  \nFor Further Reading  230\n15.6  \nDiscussion Questions  231", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 10", "position": 10, "chunk_type": "semantic", "token_estimate": 29}
{"text": "Virtualization  233: 16.1  \nShared Resources  234\n16.2  \nVirtual Machines  235\n16.3  \nVM Images  238\n16.4  \nContainers  239\n16.5  \nContainers and VMs  241\n16.6  \nContainer Portability  242\n16.7  \nPods  242\n16.8  \nServerless Architecture  243\n16.9  \nSummary  244\n16.10  \nFor Further Reading  245\n16.11  \nDiscussion Questions  245", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 10", "position": 10, "chunk_type": "semantic", "token_estimate": 45}
{"text": "x Contents: 17.3  \nUsing Multiple Instances to Improve Performance and \nAvailability  253\n17.4  \nSummary  261\n17.5  \nFor Further Reading  262\n17.6  \nDiscussion Questions  262", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 11", "position": 11, "chunk_type": "semantic", "token_estimate": 24}
{"text": "xv: Preface\nWhen we set out to write the fourth edition of Software Architecture in Practice, our first \nquestion to ourselves was: Does architecture still matter? With the rise of cloud infrastruc-\ntures, microservices, frameworks, and reference architectures for every conceivable domain \nand quality attribute, one might think that architectural knowledge is hardly needed anymore. All the architect of today needs to do is select from the rich array of tools and infrastructure \nalternatives out there, instantiate and configure them, and voila! An architecture. We were (and are) pretty sure this is not true. Admittedly, we are somewhat biased. So we \nspoke to some of our colleagues\u2014working architects in the healthcare and automotive domains, \nin social media and aviation, in defense and finance and e-commerce\u2014none of whom can afford \nto let dogmatic bias rule them. What we heard confirmed our belief\u2014that architecture is just as \nrelevant today as it was more than 20 years ago, when we wrote the first edition. Let\u2019s examine a few of the reasons that we heard. First, the rate of new requirements has \nbeen accelerating for many years, and it continues to accelerate even now. Architects today are \nfaced with a nonstop and ever-increasing stream of feature requests and bugs to fix, driven by \ncustomer and business needs and by competitive pressures. If architects aren\u2019t paying attention \nto the modularity of their system (and, no, microservices are not a panacea here), that system \nwill quickly become an anchor\u2014hard to understand, change, debug, and modify, and weigh-\ning down the business. Second, while the level of abstraction in systems is increasing\u2014we can and do regularly \nuse many sophisticated services, blissfully unaware of how they are implemented\u2014the com-\nplexity of the systems we are being asked to create is increasing at least as quickly. This is an \narms race, and the architects aren\u2019t winning! Architecture has always been about taming com-\nplexity, and that just isn\u2019t going to go away anytime soon. Speaking of raising the level of abstraction, model-based systems engineering (MBSE) \nhas emerged as a potent force in the engineering field over the last decade or so. MBSE is \nthe formalized application of modeling to support (among other things) system design. The \nInternational Council on Systems Engineering (INCOSE) ranks MBSE as one of a select set of \n\u201ctransformational enablers\u201d that underlie the entire discipline of systems engineering.", "domains": ["Architectural Patterns and Styles", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 16", "position": 16, "chunk_type": "semantic", "token_estimate": 392}
{"text": "xv: MBSE is \nthe formalized application of modeling to support (among other things) system design. The \nInternational Council on Systems Engineering (INCOSE) ranks MBSE as one of a select set of \n\u201ctransformational enablers\u201d that underlie the entire discipline of systems engineering. A model \nis a graphical, mathematical, or physical representation of a concept or a construct that can be \nreasoned about. INCOSE is trying to move the engineering field from a document-based men-\ntality to a model-based mentality, where structural models, behavioral models, performance \nmodels, and more are all used consistently to build systems better, faster, and cheaper. MBSE \nper se is beyond the scope of this book, but we can\u2019t help but notice that what is being modeled \nis architecture. And who builds the models? Architects.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 16", "position": 16, "chunk_type": "semantic", "token_estimate": 127}
{"text": "xvi Preface: Third, the meteoric growth (and unprecedented levels of employee turnover) that char-\nacterizes the world of information systems means that no one understands everything in any \nreal-world system. Just being smart and working hard aren\u2019t good enough. Fourth, despite having tools that automate much of what we used to do ourselves\u2014think \nabout all of the orchestration, deployment, and management functions baked into Kubernetes, \nfor example\u2014we still need to understand the quality attribute properties of these systems that \nwe depend upon, and we need to understand the emergent quality attribute properties when we \ncombine systems together. Most quality attributes\u2014performance, security, availability, safety, \nand so on\u2014are susceptible to \u201cweakest link\u201d problems, and those weakest links may only \nemerge and bite us when we compose systems. Without a guiding hand to ward off disaster, \nthe composition is very likely to fail. That guiding hand belongs to an architect, regardless of \ntheir title. Given these considerations, we felt safe and secure that there was indeed a need for this \nbook. But was there a need for a fourth edition? Again (and this should be abundantly obvious), \nwe concluded an emphatic \u201cyes\u201d! Much has changed in the computing landscape since the \nlast edition was published. Some quality attributes that were not previously considered have \nrisen to importance in the daily lives of many architects. As software continues to pervade \nall aspects of our society, safety considerations have become paramount for many systems; \nthink about all of the ways that software controls the cars that we now drive. Likewise, energy \nefficiency is a quality that few architects considered a decade ago, but now must pay attention \nto, from massive data centers with unquenchable needs for energy to the small (even tiny) \n \nbattery-operated mobile and IoT devices that surround us. Also, given that we are, more than \never, building systems by leveraging preexisting components, the quality attribute of integra-\nbility is consuming ever-increasing amounts of our attention. Finally, we are building different kinds of systems, and building them in different ways \nthan a decade ago. Systems these days are often built on top of virtualized resources that \nreside in a cloud, and they need to provide and depend on explicit interfaces. Also, they are \nincreasingly mobile, with all of the opportunities and challenges that mobility brings. So, in \nthis edition we have added chapters on virtualization, interfaces, mobility, and the cloud.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 17", "position": 17, "chunk_type": "semantic", "token_estimate": 396}
{"text": "1: 1 \nWhat Is Software \nArchitecture? We are called to be architects of the future, not its victims. \u2014R. Buckminster Fuller\nWriting (on our part) and reading (on your part) a book about software architecture, which \ndistills the experience of many people, presupposes that\n1. \nhaving a reasonable software architecture is important to the successful development of \na software system and\n2. \nthere is a sufficient body of knowledge about software architecture to fill up a book. There was a time when both of these assumptions needed justification. Early editions of \nthis book tried to convince readers that both of these assumptions are true and, once you were \nconvinced, supply you with basic knowledge so that you could apply the practice of architec-\nture yourself. Today, there seems to be little controversy about either aim, and so this book is \nmore about the supplying than the convincing. The basic principle of software architecture is every software system is constructed to satisfy \nan organization\u2019s business goals, and that the architecture of a system is a bridge between \nthose (often abstract) business goals and the final (concrete) resulting system. While the path \nfrom abstract goals to concrete systems can be complex, the good news is that software archi-\ntectures can be designed, analyzed, and documented using known techniques that will support \nthe achievement of these business goals. The complexity can be tamed, made tractable. These, then, are the topics for this book: the design, analysis, and documentation of archi-\ntectures. We will also examine the influences, principally in the form of business goals that \nlead to quality attribute requirements, that inform these activities. In this chapter, we will focus on architecture strictly from a software engineering point \nof view. That is, we will explore the value that a software architecture brings to a development \nproject. Later chapters will take business and organizational perspectives. PART I Introduction", "domains": ["Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 20", "position": 20, "chunk_type": "semantic", "token_estimate": 314}
{"text": "2 Part I Introduction | Chapter 1 What Is Software Architecture?: 1.1  \nWhat Software Architecture Is and What It Isn\u2019t\nThere are many definitions of software architecture, easily discoverable with a web search, but \nthe one we like is this:\nThe software architecture of a system is the set of structures needed to reason about \nthe system. These structures comprise software elements, relations among them, and \nproperties of both. This definition stands in contrast to other definitions that talk about the system\u2019s \u201cearly\u201d \nor \u201cmajor\u201d or \u201cimportant\u201d decisions. While it is true that many architectural decisions are \nmade early, not all are\u2014especially in Agile and spiral-development projects. It\u2019s also true \nthat many decisions that are made early are not what we would consider architectural. Also, \nit\u2019s hard to look at a decision and tell whether it\u2019s \u201cmajor.\u201d Sometimes only time will tell. And \nsince deciding on an architecture is one of the architect\u2019s most important obligations, we need \nto know which decisions an architecture comprises. Structures, by contrast, are fairly easy to identify in software, and they form a powerful \ntool for system design and analysis. So, there we are: Architecture is about reasoning-enabling structures. Let\u2019s look at some of the implications of our definition. Architecture Is a Set of Software Structures\nThis is the first and most obvious implication of our definition. A structure is simply a set \nof elements held together by a relation. Software systems are composed of many structures, \nand no single structure can lay claim to being the architecture. Structures can be grouped \ninto categories, and the categories themselves provide useful ways to think about the architec-\nture. Architectural structures can be organized into three useful categories, which will play an \nimportant role in the design, documentation, and analysis of architectures:\n1. Component-and-connector structures\n2. Module structures\n3. Allocation structures\nWe\u2019ll delve more into these types of structures in the next section. Although software comprises an endless supply of structures, not all of them are archi-\ntectural. For example, the set of lines of source code that contain the letter \u201cz,\u201d ordered by \nincreasing length from shortest to longest, is a software structure. But it\u2019s not a very interesting \none, nor is it architectural. A structure is architectural if it supports reasoning about the system \nand the system\u2019s properties. The reasoning should be about an attribute of the system that is \nimportant to some stakeholder(s).", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 21", "position": 21, "chunk_type": "semantic", "token_estimate": 400}
{"text": "1.1 What Software Architecture Is and What It Isn\u2019t 3: Perhaps all of the people who \ndesigned the system are long gone, the documentation has vanished (or was never produced), \nthe source code has been lost (or was never delivered), and all we have at hand is the exe-\ncuting binary code. This reveals the difference between the architecture of a system and the \nrepresentation of that architecture. Given that an architecture can exist independently of its \ndescription or specification, this raises the importance of architecture documentation, which \nis described in Chapter 22. 1. In this book, we use the term \u201celement\u201d when we mean either a module or a component, and don\u2019t want to distin-\nguish between the two.", "domains": ["Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 22", "position": 22, "chunk_type": "semantic", "token_estimate": 120}
{"text": "4 Part I Introduction | Chapter 1 What Is Software Architecture?: Not All Architectures Are Good Architectures\nOur definition is indifferent as to whether the architecture for a system is a good one or a bad \none. An architecture may either support or hinder achieving the important requirements for \na system. Assuming that we do not accept trial and error as the best way to choose an archi-\ntecture for a system\u2014that is, picking an architecture at random, building the system from it, \nand then hacking away and hoping for the best\u2014this raises the importance of architecture \ndesign, which is treated in Chapter 20 and architecture evaluation, which will be dealt with in \nChapter 21. Architecture Includes Behavior\nThe behavior of each element is part of the architecture insofar as that behavior can help you \nreason about the system. The behavior of elements embodies how they interact with each other \nand with the environment. This is clearly part of our definition of architecture and will have an \neffect on the properties exhibited by the system, such as its runtime performance. Some aspects of behavior are below the architect\u2019s level of concern. Nevertheless, to the \nextent that an element\u2019s behavior influences the acceptability of the system as a whole, this \nbehavior must be considered part of the system\u2019s architectural design, and should be docu-\nmented as such. System and Enterprise Architectures\nTwo disciplines related to software architecture are system architecture and enterprise \narchitecture. Both of these disciplines have broader concerns than software and affect \nsoftware architecture through the establishment of constraints within which a software \nsystem, and its architect, must live. System Architecture\nA system\u2019s architecture is a representation of a system in which there is a mapping \nof functionality onto hardware and software components, a mapping of the software \narchitecture onto the hardware architecture, and a concern for the human interaction \nwith these components. That is, system architecture is concerned with the totality of \nhardware, software, and humans. A system architecture will influence, for example, the functionality that is assigned \nto different processors and the types of networks that connect those processors. The software architecture will determine how this functionality is structured and how \nthe software programs residing on the various processors interact. A description of the software architecture, as it is mapped to hardware and network-\ning components, allows reasoning about qualities such as performance and reliability.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 23", "position": 23, "chunk_type": "semantic", "token_estimate": 398}
{"text": "4 Part I Introduction | Chapter 1 What Is Software Architecture?: The software architecture will determine how this functionality is structured and how \nthe software programs residing on the various processors interact. A description of the software architecture, as it is mapped to hardware and network-\ning components, allows reasoning about qualities such as performance and reliability. A description of the system architecture will allow reasoning about additional qualities \nsuch as power consumption, weight, and physical dimensions. When designing a particular system, there is frequently negotiation between the \nsystem architect and the software architect over the distribution of functionality and, \nconsequently, the constraints placed on the software architecture.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 23", "position": 23, "chunk_type": "semantic", "token_estimate": 108}
{"text": "1.2 Architectural Structures and Views 7: Three Kinds of Structures\nArchitectural structures can be divided into three major categories, depending on the broad \nnature of the elements they show and the kinds of reasoning they support:\n1. Component-and-connector (C&C) structures focus on the way the elements interact \nwith each other at runtime to carry out the system\u2019s functions. They describe how the \nsystem is structured as a set of elements that have runtime behavior (components) and \ninteractions (connectors). Components are the principal units of computation and could \nbe services, peers, clients, servers, filters, or many other types of runtime element. Connectors are the communication vehicles among components, such as call-return, \nprocess synchronization operators, pipes, or others. C&C structures help answer ques-\ntions such as the following:\n \n\u25a0What are the major executing components and how do they interact at runtime? \u25a0What are the major shared data stores? \u25a0Which parts of the system are replicated? \u25a0How does data progress through the system? \u25a0Which parts of the system can run in parallel? \u25a0Can the system\u2019s structure change as it executes and, if so, how? By extension, these structures are crucially important for asking questions about the \nsystem\u2019s runtime properties, such as performance, security, availability, and more. C&C structures are the most common ones that we see, but two other categories of \nstructures are important and should not be overlooked. Figure 1.2 shows a sketch of a C&C structure of a system using an informal notation \nthat is explained in the figure\u2019s key. The system contains a shared repository that is \naccessed by servers and an administrative component. A set of client tellers can interact \nwith the account servers and communicate among themselves using a publish-subscribe \nconnector. 2. Module structures partition systems into implementation units, which in this book we \ncall modules. Module structures show how a system is structured as a set of code or data \nunits that have to be constructed or procured. Modules are assigned specific computa-\ntional responsibilities and are the basis of work assignments for programming teams. In \nany module structure, the elements are modules of some kind (perhaps classes, packages, \nlayers, or merely divisions of functionality, all of which are units of implementation). Modules represent a static way of considering the system. Modules are assigned areas of \nfunctional responsibility; there is less emphasis in these structures on how the resulting \nsoftware manifests itself at runtime. Module implementations include packages, classes, \nand layers.", "domains": ["Architectural Patterns and Styles", "Software Quality Attributes", "Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 26", "position": 26, "chunk_type": "semantic", "token_estimate": 404}
{"text": "1.2 Architectural Structures and Views 7: Modules are assigned areas of \nfunctional responsibility; there is less emphasis in these structures on how the resulting \nsoftware manifests itself at runtime. Module implementations include packages, classes, \nand layers. Relations among modules in a module structure include uses, generalization \n(or \u201cis-a\u201d), and \u201cis part of.\u201d Figures 1.3 and 1.4 show examples of module elements and \nrelations, respectively, using the Unified Modeling Language (UML) notation.", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 26", "position": 26, "chunk_type": "semantic", "token_estimate": 71}
{"text": "8 Part I Introduction | Chapter 1 What Is Software Architecture?: Client\nClient Teller 1\nAccount \nServer\u2014Main\nAccount \nDatabase\nAccount\nServer\u2014Backup\nServer\nDatabase\nDatabase\napplication\nInterface\nPublish-subscribe\nClient-server \nrequest/reply \nw/automatic \nfailover\nDatabase\naccess\nKey\nAdministrative\nFIGURE 1.2 A component-and-connector structure", "domains": ["Architectural Patterns and Styles", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 27", "position": 27, "chunk_type": "semantic", "token_estimate": 40}
{"text": "1.2 Architectural Structures and Views 9: System.IO.Log\nCommonDialog\nAbstract class\n(italics)\nClass with provided\ninterface\nIAnimatable\nUIElement\n\u00abinterface\u00bb\nIAnimatable\nInterface not\nshown as\nlollipop\nPackage\nClass\nSaveFileDialog\nFileName\nFilter\nShowDialog()\nOnFileOk(\u2026)\nClass showing \nattribute and \noperation \ncompartments\nSaveFileDialog\nFIGURE 1.3 Module elements in UML\nDepends-on \nrelation\n\u00abuse\u00bb\nIs-part-of\nrelation\ncom.sun.ebank.web\nDispatcher\nDispatcher\nContext\nListener\nAccount\n\u00abinterface\u00bb\nObserver\nChecking\nAccount\nSavings\nAccount\nAdmin\nAccountView\nBeanManager\ncom.sun.ebank.web.taglib\nTwo forms of \nis-a relation (class \ninheritance and\ninterface realization)\nFIGURE 1.4 Module relations in UML", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 28", "position": 28, "chunk_type": "semantic", "token_estimate": 81}
{"text": "10 Part I Introduction | Chapter 1 What Is Software Architecture?: Module structures allow us to answer questions such as the following:\n \n\u25a0What is the primary functional responsibility assigned to each module? \u25a0What other software elements is a module allowed to use? \u25a0What other software does it actually use and depend on? \u25a0What modules are related to other modules by generalization or specialization (i.e., \ninheritance) relationships? Module structures convey this information directly, but they can also be used to \nanswer questions about the impact on the system when the responsibilities assigned \nto each module change. Thus module structures are the primary tools for reasoning \nabout a system\u2019s modifiability. 3. Allocation structures establish the mapping from software structures to the system\u2019s \nnonsoftware structures, such as its organization, or its development, test, and execution \nenvironments. Allocation structures answer questions such as the following:\n \n\u25a0Which processor(s) does each software element execute on? \u25a0In which directories or files is each element stored during development, testing, and \nsystem building? \u25a0What is the assignment of each software element to development teams? Some Useful Module Structures\nUseful module structures include:\n \n\u25a0Decomposition structure. The units are modules that are related to each other by the \n\u201cis-a-submodule-of\u201d relation, showing how modules are decomposed into smaller mod-\nules recursively until the modules are small enough to be easily understood. Modules in \nthis structure represent a common starting point for design, as the architect enumerates \nwhat the units of software will have to do and assigns each item to a module for subse-\nquent (more detailed) design and eventual implementation. Modules often have products \n(such as interface specifications, code, and test plans) associated with them. The decom-\nposition structure determines, to a large degree, the system\u2019s modifiability. That is, do \nchanges fall within the purview of a few (preferably small) modules? This structure is \noften used as the basis for the development project\u2019s organization, including the structure \nof the documentation, and the project\u2019s integration and test plans. Figure 1.5 shows an \nexample of a decomposition structure. \u25a0Uses structure. In this important but often overlooked structure, the units are also mod-\nules, and perhaps classes. The units are related by the uses relation, a specialized form \nof dependency. One unit of software uses another if the correctness of the first requires \nthe presence of a correctly functioning version (as opposed to a stub) of the second.", "domains": ["Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 29", "position": 29, "chunk_type": "semantic", "token_estimate": 394}
{"text": "1.2 Architectural Structures and Views 11: for measuring social debt\u2014the amount of communication that actually is, as opposed \nto merely should be, taking place among teams\u2014as it defines which teams should be \ntalking to each other. Figure 1.6 shows a uses structure and highlights the modules that \nmust be present in an increment if the module admin.client is present. \u25a0Layer structure. The modules in this structure are called layers. A layer is an abstract \n\u201cvirtual machine\u201d that provides a cohesive set of services through a managed interface. Layers are allowed to use other layers in a managed fashion; in strictly layered systems, \na layer is only allowed to use a single other layer. This structure imbues a system with \nportability\u2014that is, the ability to change the underlying virtual machine. Figure 1.7 \nshows a layer structure of the UNIX System V operating system. ATIA-M\nWindows apps\nCommon code \nfor thick clients", "domains": ["Architectural Patterns and Styles", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 30", "position": 30, "chunk_type": "semantic", "token_estimate": 150}
{"text": "12 Part I Introduction | Chapter 1 What Is Software Architecture?: Static\nweb\nartifacts\nNotation: UML\nestore.webapp\nweb::shared\nestore.core\nweb::accessControl\nadmin.core\ndao\nutil\nweb::estore\nadmin.client\n\u00abuse\u00bb\n\u00abuse\u00bb\n\u00abuse\u00bb\n\u00abuse\u00bb\n\u00abuse\u00bb\n\u00abuse\u00bb\n\u00abuse\u00bb\n\u00abuse\u00bb\n\u00abuse\u00bb\n\u00abuse\u00bb\n\u00abuse\u00bb\n\u00abuse\u00bb\n\u00abuse\u00bb\n\u00abuse\u00bb\nFIGURE 1.6 Uses structure\nUser programs\nSystem call interface\nFile subsystem\nBuffering\nmechanism\nBlock I/O\ndevice drivers\nHardware control\nCharacter \ndevice drivers\nProcess control subsystem\n(IPC, scheduler, memory mgmt)\nLibraries\nKey\nUser-level\nlayer\nKernel-level\nlayer\nAllowed\nto use\nFIGURE 1.7 Layer structure", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 31", "position": 31, "chunk_type": "semantic", "token_estimate": 81}
{"text": "Legend: For each A, there are 0 or more Bs; \neach B is related to exactly one A; \nA\u2019s PK is needed as part of B\u2019s PK\nEntity\nPK = Primary key\nFK# = Foreign key\nI# = Index\nColumn name\n(bold means \nrequired column)\nData type\nFIGURE 1.9 Data model\nSome Useful C&C Structures\nC&C structures show a runtime view of the system. In these structures, the modules just \ndescribed have all been compiled into executable forms. Thus all C&C structures are orthog-\nonal to the module-based structures and deal with the dynamic aspects of a running system. For example, one code unit (module) could be compiled into a single service that is repli-\ncated thousands of times in an execution environment. Or 1,000 modules can be compiled and \nlinked together to produce a single runtime executable (component). The relation in all C&C structures is attachment, showing how the components and the \nconnectors are hooked together. (The connectors themselves can be familiar constructs such \nas \u201cinvokes.\u201d) Useful C&C structures include:\n \n\u25a0Service structure. The units here are services that interoperate through a service coordi-\nnation mechanism, such as messages. The service structure is an important structure to \nhelp engineer a system composed of components that may have been developed inde-\npendently of each other. \u25a0Concurrency structure. This C&C structure allows the architect to determine opportuni-\nties for parallelism and the locations where resource contention may occur. The units are \ncomponents, and the connectors are their communication mechanisms. The components \nare arranged into \u201clogical threads.\u201d A logical thread is a sequence of computations that \ncould be allocated to a separate physical thread later in the design process. The concur-\nrency structure is used early in the design process to identify and manage issues associ-\nated with concurrent execution.", "domains": ["Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 33", "position": 33, "chunk_type": "semantic", "token_estimate": 297}
{"text": "1.2 Architectural Structures and Views 15: Some Useful Allocation Structures\nAllocation structures define how the elements from C&C or module structures map onto things \nthat are not software\u2014typically hardware (possibly virtualized), teams, and file systems. Useful allocation structures include:\n \n\u25a0Deployment structure. The deployment structure shows how software is assigned to \nhardware processing and communication elements. The elements are software elements \n(usually a process from a C&C structure), hardware entities (processors), and commu-\nnication pathways. Relations are \u201callocated-to,\u201d showing on which physical units the \nsoftware elements reside, and \u201cmigrates-to,\u201d if the allocation is dynamic. This structure \ncan be used to reason about performance, data integrity, security, and availability. It is of \nparticular interest in distributed systems and is the key structure involved in the achieve-\nment of the quality attribute of deployability (see Chapter 5). Figure 1.10 shows a simple \ndeployment structure in UML. 1\n*\n1\n1\n\u00abinternet\u00bb\n\u00abintranet\u00bb\n\u00abdeploy\u00bb\n\u00abdeploy\u00bb\n\u00abintranet\u00bb\nNotation:", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 34", "position": 34, "chunk_type": "semantic", "token_estimate": 153}
{"text": "16 Part I Introduction | Chapter 1 What Is Software Architecture?: team to each of its microservices, for example, is a statement about its work assignment \nstructure. On large development projects, it is useful to identify units of functional com-\nmonality and assign those to a single team, rather than having them be implemented by \neveryone who needs them. This structure will also determine the major communication \npathways among the teams: regular web conferences, wikis, email lists, and so forth. Table 1.1 summarizes these structures. It lists the meaning of the elements and relations \nin each structure and tells what each might be used for. Relating Structures to Each Other\nEach of these structures provides a different perspective and design handle on a system, and \neach is valid and useful in its own right. Although the structures give different system perspec-\ntives, they are not independent. Elements of one structure will be related to elements of other \nstructures, and we need to reason about these relations. For example, a module in a decom-\nposition structure may be manifested as one, part of one, or several components in one of the \nC&C structures, reflecting its runtime alter-ego. In general, mappings between structures are \nmany to many. Figure 1.11 shows a simple example of how two structures might relate to each other. The \nimage on the left shows a module decomposition view of a tiny client-server system. In this \nsystem, two modules must be implemented: the client software and the server software. The \nimage on the right shows a C&C view of the same system. At runtime, ten clients are running \nand accessing the server. Thus this little system has two modules and eleven components (and \nten connectors). Client\nServer\nModule\nSystem\nDecomposition View\nKey:\nClient-Server View\nKey:\nComponent\nRequest-Reply", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 35", "position": 35, "chunk_type": "semantic", "token_estimate": 298}
{"text": "1.2 Architectural Structures and Views 17: TABLE 1.1 Useful Architectural Structures\nSoftware \nStructure\nElement Types\nRelations\nUseful for\nQuality Concerns \nAffected\nModule \nstructures\nDecomposition\nModule\nIs a submodule of\nResource allocation and project \nstructuring and planning; \nencapsulation\nModifiability\nUses\nModule\nUses (i.e., requires the \ncorrect presence of)\nDesigning subsets and \nextensions\n\u201cSubsetability,\u201d \nextensibility\nLayers\nLayer\nAllowed to use the services \nof; provides abstraction to\nIncremental development; \nimplementing systems on top of \n\u201cvirtual machines\u201d\nPortability, \nmodifiability \nClass\nClass, object\nIs an instance of; is a \ngeneralization of \nIn object-oriented systems, \nfactoring out commonality; \nplanning extensions of \nfunctionality\nModifiability, \nextensibility\nData model\nData entity\n{one, many}-to-{one, many}; \ngeneralizes; specializes\nEngineering global data \nstructures for consistency and \nperformance\nModifiability, \nperformance\nC&C \nstructures\nService\nService, service \nregistry\nAttachment (via \nmessage-passing)\nScheduling analysis; \nperformance analysis; \nrobustness analysis\nInteroperability, \navailability, \nmodifiability\nConcurrency\nProcesses, \nthreads\nAttachment (via \ncommunication and \nsynchronization \nmechanisms)\nIdentifying locations where \nresource contention exists, \nopportunities for parallelism\nPerformance\nAllocation \nstructures\nDeployment\nComponents, \nhardware \nelements\nAllocated to; migrates to\nMapping software elements to \nsystem elements\nPerformance, \nsecurity, energy, \navailability, \ndeployability\nImplementation\nModules, file \nstructure\nStored in\nConfiguration control, \nintegration, test activities\nDevelopment \nefficiency\nWork assignment\nModules, \norganizational \nunits\nAssigned to\nProject management, best \nuse of expertise and available \nresources, management of \ncommonality\nDevelopment \nefficiency", "domains": ["Software Quality Attributes", "Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 36", "position": 36, "chunk_type": "semantic", "token_estimate": 209}
{"text": "18 Part I Introduction | Chapter 1 What Is Software Architecture?: Whereas the correspondence between the elements in the decomposition structure and \nthe client-server structure is obvious, these two views are used for very different things. For \nexample, the view on the right could be used for performance analysis, bottleneck prediction, \nand network traffic management, which would be extremely difficult or impossible to do with \nthe view on the left. (In Chapter 9, we\u2019ll learn about the map-reduce pattern, in which copies \nof simple, identical functionality are distributed across hundreds or thousands of processing \nnodes\u2014one module for the whole system, but one component per node.) Individual projects sometimes consider one structure to be dominant and cast other struc-\ntures, when possible, in terms of the dominant structure. Often, the dominant structure is the \nmodule decomposition structure, and for good reason: It tends to spawn the project structure, \nsince it mirrors the team structure of development. In other projects, the dominant structure might \nbe a C&C structure that shows how the system\u2019s functionality and/or critical quality attributes \nare achieved at runtime. Fewer Is Better\nNot all systems warrant consideration of many architectural structures. The larger the system, \nthe more dramatic the difference between these structures tends to be; but for small systems, \nwe can often get by with fewer structures. For example, instead of working with each of sev-\neral C&C structures, usually a single one will do. If there is only one process, then the process \nstructure collapses to a single node and need not be explicitly represented in the design. If \nno distribution will occur (that is, if the system is implemented on a single processor), then \nthe deployment structure is trivial and need not be considered further. In general, you should \ndesign and document a structure only if doing so brings a positive return on the investment, \nusually in terms of decreased development or maintenance costs. Which Structures to Choose? We have briefly described a number of useful architectural structures, and many more are \ncertainly possible. Which ones should an architect choose to work on? Which ones should the \narchitect choose to document? Surely not all of them. A good answer is that you should think \nabout how the various structures available to you provide insight and leverage into the system\u2019s \nmost important quality attributes, and then choose the ones that will play the best role in deliv-\nering those attributes.", "domains": ["Architectural Patterns and Styles", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 37", "position": 37, "chunk_type": "semantic", "token_estimate": 403}
{"text": "1.3 What Makes a \u201cGood\u201d Architecture? 19: 1.3  \nWhat Makes a \u201cGood\u201d Architecture? There is no such thing as an inherently good or bad architecture. Architectures are either \nmore or less fit for some purpose. A three-tier layered service-oriented architecture may be \njust the ticket for a large enterprise\u2019s web-based B2B system but completely wrong for an \navionics application. An architecture carefully crafted to achieve high modifiability does not \nmake sense for a throw-away prototype (and vice versa!). One of the messages of this book is \nthat architectures can, in fact, be evaluated\u2014one of the great benefits of paying attention to \nthem\u2014but such evaluation only makes sense in the context of specific stated goals. Nevertheless, some rules of thumb should be followed when designing most architec-\ntures. Failure to apply any of these guidelines does not automatically mean that the archi-\ntecture will be fatally flawed, but it should at least serve as a warning sign that should be \ninvestigated. These rules can be applied proactively for greenfield development, to help build \nthe system \u201cright.\u201d Or they can be applied as analysis heuristics, to understand the potential \nproblem areas in existing systems and to guide the direction of its evolution. We divide our observations into two clusters: process recommendations and product (or \nstructural) recommendations. Our process recommendations are as follows:\n1. A software (or system) architecture should be the product of a single architect or a small \ngroup of architects with an identified technical leader. This approach is important to \ngive the architecture its conceptual integrity and technical consistency. This recom-\nmendation holds for agile and open source projects as well as \u201ctraditional\u201d ones. There \nshould be a strong connection between the architects and the development team, to avoid \n\u201civory tower,\u201d impractical designs. 2. The architect (or architecture team) should, on an ongoing basis, base the architecture on \na prioritized list of well-specified quality attribute requirements. These will inform the \ntradeoffs that always occur. Functionality matters less. 3. The architecture should be documented using views. (A view is simply a representa-\ntion of one or more architectural structures.) The views should address the concerns of \nthe most important stakeholders in support of the project timeline. This might mean \nminimal documentation at first, with the documentation then being elaborated later. Concerns usually are related to construction, analysis, and maintenance of the system, \nas well as education of new stakeholders. 4.", "domains": ["Architectural Patterns and Styles", "Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 38", "position": 38, "chunk_type": "semantic", "token_estimate": 399}
{"text": "20 Part I Introduction | Chapter 1 What Is Software Architecture?: Our structural rules of thumb are as follows:\n1. The architecture should feature well-defined modules whose functional responsibili-\nties are assigned on the principles of information hiding and separation of concerns. The information-hiding modules should encapsulate things likely to change, thereby \ninsulating the software from the effects of those changes. Each module should have a \nwell- \ndefined interface that encapsulates or \u201chides\u201d the changeable aspects from other \nsoftware that uses its facilities. These interfaces should allow their respective develop-\nment teams to work largely independently of each other. 2. Unless your requirements are unprecedented\u2014possible, but unlikely\u2014your quality \nattributes should be achieved by using well-known architectural patterns and tactics \n(described in Chapters 4 through 13) specific to each attribute. 3. The architecture should never depend on a particular version of a commercial product or \ntool. If it must, it should be structured so that changing to a different version is straight-\nforward and inexpensive. 4. Modules that produce data should be separate from modules that consume data. This \ntends to increase modifiability because changes are frequently confined to either the \nproduction or the consumption side of data. If new data is added, both sides will have to \nchange, but the separation allows for a staged (incremental) upgrade. 5. Don\u2019t expect a one-to-one correspondence between modules and components. For exam-\nple, in systems with concurrency, multiple instances of a component may be running in \nparallel, where each component is built from the same module. For systems with multiple \nthreads of concurrency, each thread may use services from several components, each of \nwhich was built from a different module. 6. Every process should be written so that its assignment to a specific processor can be \neasily changed, perhaps even at runtime. This is a driving force in the increasing trends \ntoward virtualization and cloud deployment, as we will discuss in Chapters 16 and 17. 7. The architecture should feature a small number of simple component interaction patterns. That is, the system should do the same things in the same way throughout. This practice \nwill aid in understandability, reduce development time, increase reliability, and enhance \nmodifiability. 8. The architecture should contain a specific (and small) set of resource contention areas, \nwhose resolution is clearly specified and maintained.", "domains": ["Design Patterns", "Design Principles", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 39", "position": 39, "chunk_type": "semantic", "token_estimate": 384}
{"text": "20 Part I Introduction | Chapter 1 What Is Software Architecture?: 8. The architecture should contain a specific (and small) set of resource contention areas, \nwhose resolution is clearly specified and maintained. For example, if network utilization \nis an area of concern, the architect should produce (and enforce) for each development \nteam guidelines that will result in acceptable levels of network traffic. If performance is \na concern, the architect should produce (and enforce) time budgets.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 39", "position": 39, "chunk_type": "semantic", "token_estimate": 75}
{"text": "1.5 For Further Reading 21: 1.4  \nSummary\nThe software architecture of a system is the set of structures needed to reason about the sys-\ntem. These structures comprise software elements, relations among them, and properties of \nboth. There are three categories of structures:\n \n\u25a0Module structures show the system as a set of code or data units that have to be con-\nstructed or procured. \u25a0Component-and-connector structures show the system as a set of elements that have \nruntime behavior (components) and interactions (connectors). \u25a0Allocation structures show how elements from module and C&C structures relate to \nnonsoftware structures (such as CPUs, file systems, networks, and development teams). Structures represent the primary engineering leverage points of an architecture. Each \nstructure brings with it the power to manipulate one or more quality attributes. Collectively, \nstructures represent a powerful approach for creating the architecture (and, later, for analyzing \nit and explaining it to its stakeholders). And, as we will see in Chapter 22, the structures that \nthe architect has chosen as engineering leverage points are also the primary candidates to \nchoose as the basis for architecture documentation. Every system has a software architecture, but this architecture may or may not be docu-\nmented and disseminated. There is no such thing as an inherently good or bad architecture. Architectures are either \nmore or less fit for some purpose. 1.5  \nFor Further Reading\nIf you\u2019re keenly interested in software architecture as a field of study, you might be interested \nin reading some of the pioneering work. Most of it does not mention \u201csoftware architecture\u201d \nat all, as this phrase evolved only in the mid-1990s, so you\u2019ll have to read between the lines. Edsger Dijkstra\u2019s 1968 paper on the T.H.E. operating system introduced the concept \nof layers [Dijkstra 68]. The early work of David Parnas laid many conceptual foundations, \nincluding information hiding [Parnas 72], program families [Parnas 76], the structures inher-\nent in software systems [Parnas 74], and the uses structure to build subsets and supersets of \nsystems [Parnas 79]. All of Parnas\u2019s papers can be found in the more easily accessible collec-\ntion of his important papers [Hoffman 00]. Modern distributed systems owe their existence to \nthe concept of cooperating sequential processes that (among others) Sir C. A. R. (Tony) Hoare \nwas instrumental in conceptualizing and defining [Hoare 85]. In 1972, Dijkstra and Hoare, along with Ole-Johan Dahl, argued that programs should be \ndecomposed into independent components with small and simple interfaces.", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 40", "position": 40, "chunk_type": "semantic", "token_estimate": 405}
{"text": "22 Part I Introduction | Chapter 1 What Is Software Architecture?: approach structured programming, but arguably this was the debut of software architecture \n[Dijkstra 72]. Mary Shaw and David Garlan, together and separately, produced a major body of work \nthat helped create the field of study we call software architecture. They established some of \nits fundamental principles and, among other things, catalogued a seminal family of architec-\ntural styles (a concept similar to patterns), several of which appear in this chapter as architectural \nstructures. Start with [Garlan 95]. Software architectural patterns have been extensively catalogued in the series Pattern-\nOriented Software Architecture [Buschmann 96 and others]. We also deal with architectural \npatterns throughout Part II of this book. Early papers on architectural views as used in industrial development projects are [Soni 95] \nand [Kruchten 95]. The former grew into a book [Hofmeister 00] that presents a comprehen-\nsive picture of using views in development and analysis. A number of books have focused on practical implementation issues associated with archi-\ntectures, such as George Fairbanks\u2019 Just Enough Software Architecture [Fairbanks 10], Woods \nand Rozanski\u2019s Software Systems Architecture [Woods 11], and  \nMartin\u2019s Clean Architecture: \nA Craftsman\u2019s Guide to Software Structure and Design [Martin 17]. 1.6  \nDiscussion Questions\n1. Is there a different definition of software architecture that you are familiar with? If \nso, compare and contrast it with the definition given in this chapter. Many definitions \ninclude considerations like \u201crationale\u201d (stating the reasons why the architecture is what \nit is) or how the architecture will evolve over time. Do you agree or disagree that these \nconsiderations should be part of the definition of software architecture? 2. Discuss how an architecture serves as a basis for analysis. What about decision making? What kinds of decision making does an architecture empower? 3. What is architecture\u2019s role in project risk reduction? 4. Find a commonly accepted definition of system architecture and discuss what it has in \ncommon with software architecture. Do the same for enterprise architecture. 5. Find a published example of a software architecture. Which structures are shown? Given \nits purpose, which structures should have been shown? What analysis does the architec-\nture support? Critique it: What questions do you have that the representation does not \nanswer? 6. Sailing ships have architectures, which means they have \u201cstructures\u201d that lend them-\nselves to reasoning about the ship\u2019s performance and other quality attributes. Look \nup the technical definitions for barque, brig, cutter, frigate, ketch, schooner, and \nsloop.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 41", "position": 41, "chunk_type": "semantic", "token_estimate": 411}
{"text": "22 Part I Introduction | Chapter 1 What Is Software Architecture?: Sailing ships have architectures, which means they have \u201cstructures\u201d that lend them-\nselves to reasoning about the ship\u2019s performance and other quality attributes. Look \nup the technical definitions for barque, brig, cutter, frigate, ketch, schooner, and \nsloop. Propose a useful set of \u201cstructures\u201d for distinguishing and reasoning about ship \narchitectures.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 41", "position": 41, "chunk_type": "semantic", "token_estimate": 61}
{"text": "26 Part I Introduction | Chapter 2 Why Is Software Architecture Important?: Even if you already believe us that architecture is important and don\u2019t need that point \nhammered home 13 more times, think of these 13 points (which form the outline for this chap-\nter) as 13 useful ways to use architecture in a project, or to justify the resources devoted to \narchitecture. 2.1  \nInhibiting or Enabling a System\u2019s Quality Attributes\nA system\u2019s ability to meet its desired (or required) quality attributes is substantially deter-\nmined by its architecture. If you remember nothing else from this book, remember that. This relationship is so important that we\u2019ve devoted all of Part II of this book to expound-\ning that message in detail. Until then, keep these examples in mind as a starting point:\n \n\u25a0If your system requires high performance, then you need to pay attention to managing \nthe time-based behavior of elements, their use of shared resources, and the frequency \nand volume of their interelement communication. \u25a0If modifiability is important, then you need to pay attention to assigning responsibilities \nto elements and limiting the interactions (coupling) of those elements so that the major-\nity of changes to the system will affect a small number of those elements. Ideally, each \nchange will affect just a single element. \u25a0If your system must be highly secure, then you need to manage and protect interelement \ncommunication and control which elements are allowed to access which information. You may also need to introduce specialized elements (such as an authorization mechanism) \ninto the architecture to set up a strong \u201cperimeter\u201d to guard against intrusion. \u25a0If you want your system to be safe and secure, you need to design in safeguards and \nrecovery mechanisms. \u25a0If you believe that scalability of performance will be important to the success of your \nsystem, then you need to localize the use of resources to facilitate the introduction of \nhigher-capacity replacements, and you must avoid hard-coding in resource assumptions \nor limits. \u25a0If your projects need the ability to deliver incremental subsets of the system, then you \nmust manage intercomponent usage. \u25a0If you want the elements from your system to be reusable in other systems, then you need \nto restrict interelement coupling so that when you extract an element, it does not come \nout with too many attachments to its current environment to be useful. The strategies for these and other quality attributes are supremely architectural.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 45", "position": 45, "chunk_type": "semantic", "token_estimate": 402}
{"text": "2.2 Reasoning about and Managing Change 27: 2.2  \nReasoning about and Managing Change\nThis is a corollary to the previous point. Modifiability\u2014the ease with which changes can be made to a system\u2014 is a quality attri-\nbute (and hence covered by the arguments in the previous section), but it is such an important \nquality that we have awarded it its own spot in the List of Thirteen. The software development \ncommunity is coming to grips with the fact that roughly 80 percent of a typical software sys-\ntem\u2019s total cost occurs after initial deployment. Most systems that people work on are in this \nphase. Many programmers and software designers never get to work on new development\u2014\nthey work under the constraints of the existing architecture and the existing body of code. Virtually all software systems change over their lifetimes, to accommodate new features, to \nadapt to new environments, to fix bugs, and so forth. But the reality is that these changes are \noften fraught with difficulty. Every architecture, no matter what it is, partitions possible changes into three categories: \nlocal, nonlocal, and architectural. \u25a0A local change can be accomplished by modifying a single element\u2014for example, add-\ning a new business rule to a pricing logic module. \u25a0A nonlocal change requires multiple element modifications but leaves the underlying \narchitectural approach intact\u2014for example, adding a new business rule to a pricing logic \nmodule, then adding new fields to the database that this new business rule requires, and \nthen revealing the results of applying the rule in the user interface. \u25a0An architectural change affects the fundamental ways in which the elements interact \nwith each other and will probably require changes all over the system\u2014for example, \nchanging a system from single-threaded to multi-threaded. Obviously, local changes are the most desirable, so an effective architecture is one in \nwhich the most common changes are local, and hence easy to make. Nonlocal changes are not \nas desirable but do have the virtue that they can usually be staged\u2014that is, rolled out\u2014in an \norderly manner over time. For example, you might first make changes to add a new pricing \nrule, then make the changes to actually deploy the new rule. Deciding when changes are essential, determining which change paths have the least risk, \nassessing the consequences of proposed changes, and arbitrating sequences and priorities for \nrequested changes all require broad insight into the relationships, performance, and behaviors \nof system software elements.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 46", "position": 46, "chunk_type": "semantic", "token_estimate": 404}
{"text": "2.2 Reasoning about and Managing Change 27: For example, you might first make changes to add a new pricing \nrule, then make the changes to actually deploy the new rule. Deciding when changes are essential, determining which change paths have the least risk, \nassessing the consequences of proposed changes, and arbitrating sequences and priorities for \nrequested changes all require broad insight into the relationships, performance, and behaviors \nof system software elements. These tasks are all part of the job description for an architect. Reasoning about the architecture and analyzing the architecture can provide the insights nec-\nessary to make decisions about anticipated changes. If you do not take this step, and if you do \nnot pay attention to maintaining the conceptual integrity of your architecture, then you will \nalmost certainly accumulate architecture debt. We deal with this subject in Chapter 23.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 46", "position": 46, "chunk_type": "semantic", "token_estimate": 141}
{"text": "2.4 Communication among Stakeholders 29: \u25a0the manager is worried that (in addition to cost and schedule concerns) the architecture \nwill allow teams to work largely independently, interacting in disciplined and controlled \nways; and\n \n\u25a0the architect is worried about strategies to achieve all of those goals. Architecture provides a common language in which different concerns can be expressed, \nnegotiated, and resolved at a level that is intellectually manageable even for large, complex \nsystems. Without such a language, it is difficult to understand large systems sufficiently to \nmake the early decisions that influence both quality and usefulness. Architectural analysis, as \nwe will see in Chapter 21, both depends on this level of communication and enhances it. Chapter 22, on architecture documentation, covers stakeholders and their concerns in \ngreater depth. \u201cWhat Happens When I Push This Button?\u201d: Architecture as a Vehicle for \nStakeholder Communication\nThe project review droned on and on. The government-sponsored development was \nbehind schedule and over budget, and it was large enough that these lapses were \nattracting the U.S. Congress\u2019s attention. And now the government was making up for \npast neglect by holding a marathon come-one-come-all review session. The contractor \nhad recently undergone a buyout, which hadn\u2019t helped matters. It was the afternoon \nof the second day, and the agenda called for presentation of the software architecture. The young architect\u2014an apprentice to the chief architect for the system\u2014was bravely \nexplaining how the software architecture for the massive system would enable it to meet \nits very demanding real-time, distributed, high-reliability requirements. He had a solid \npresentation and a solid architecture to present. It was sound and sensible. But the \naudience\u2014about 30 government representatives who had varying roles in the manage-\nment and oversight of this sticky project\u2014was tired. Some of them were even thinking \nthat perhaps they should have gone into real estate instead of enduring another one of \nthese marathon let\u2019s-finally-get-it-right-this-time reviews. The slide showed, in semiformal box-and-line notation, what the major software \nelements were in a runtime view of the system. The names were all acronyms, sug-\ngesting no semantic meaning without explanation, which the young architect gave. The \nlines showed data flow, message passing, and process synchronization. The elements \nwere internally redundant, as the architect was explaining. \u201cIn the event of a failure,\u201d he \nbegan, using a laser pointer to denote one of the lines, \u201ca restart mechanism triggers \nalong this path when. . .", "domains": ["Design Patterns", "Design Principles", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 48", "position": 48, "chunk_type": "semantic", "token_estimate": 397}
{"text": "30 Part I Introduction | Chapter 2 Why Is Software Architecture Important?: \u201cNo, I mean what does the system do,\u201d interrupted the questioner. \u201cDoes it reset the \ndisplays? And what happens if this occurs during a system reconfiguration?\u201d\nThe architect looked a little surprised and flicked off the laser pointer. This was not an \narchitectural question, but since he was an architect and therefore fluent in the require-\nments, he knew the answer. \u201cIf the command line is in setup mode, the displays will \nreset,\u201d he said. \u201cOtherwise, an error message will be put on the control console, but the \nsignal will be ignored.\u201d He put the laser pointer back on. \u201cNow, the restart mechanism \nthat I was talking about. . . .\u201d\n\u201cWell, I was just wondering,\u201d said the users\u2019 delegate. \u201cBecause I see from your chart \nthat the display console is sending signal traffic to the target location module.\u201d\n\u201cWhat should happen?\u201d asked another member of the audience, addressing the first \nquestioner. \u201cDo you really want the user to get mode data during its reconfiguring?\u201d \nAnd for the next 45 minutes, the architect watched as the audience consumed his time \nslot by debating what the correct behavior of the system was supposed to be in various \nesoteric states\u2014an absolutely essential conversation that should have happened when \nthe requirements were being formulated but, for whatever reason, had not. The debate was not architectural, but the architecture (and the graphical rendition of \nit) had sparked debate. It is natural to think of architecture as the basis for communica-\ntion among some of the stakeholders besides the architects and developers: Managers, \nfor example, use the architecture to create teams and allocate resources among them. But users? The architecture is invisible to users, after all; why should they latch on to it \nas a tool for system understanding? The fact is that they do. In this case, the questioner had sat through two days of view-\ngraphs all about function, operation, user interface, and testing. But it was the first slide on \narchitecture that\u2014even though he was tired and wanted to go home\u2014made him realize \nhe didn\u2019t understand something. Attendance at many architecture reviews has convinced \nme that seeing the system in a new way prods the mind and brings new questions to the \nsurface. For users, architecture often serves as that new way, and the questions that a \nuser poses will be behavioral in nature.", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 49", "position": 49, "chunk_type": "semantic", "token_estimate": 404}
{"text": "30 Part I Introduction | Chapter 2 Why Is Software Architecture Important?: Attendance at many architecture reviews has convinced \nme that seeing the system in a new way prods the mind and brings new questions to the \nsurface. For users, architecture often serves as that new way, and the questions that a \nuser poses will be behavioral in nature. In a memorable architecture evaluation exercise \na few years ago, the user representatives were much more interested in what the system \nwas going to do than in how it was going to do it, and naturally so. Up until that point, \ntheir only contact with the vendor had been through its marketers. The architect was the \nfirst legitimate expert on the system to whom they had access, and they didn\u2019t hesitate to \nseize the moment. Of course, careful and thorough requirements specifications would ameliorate this, \nbut for a variety of reasons, they are not always created or available. In their absence, a \nspecification of the architecture often serves to trigger questions and improve clarity. It \nis probably more prudent to recognize this possibility than to resist it. Sometimes such an exercise will reveal unreasonable requirements, whose utility \ncan then be revisited. A review of this type that emphasizes synergy between require-\nments and architecture would have let the young architect in our story off the hook by \ngiving him a place in the overall review session to address that kind of information. And \nthe user representative wouldn\u2019t have felt like a fish out of water, asking his question at \na clearly inappropriate moment. \u2014PCC", "domains": ["Design Patterns", "Domain-Driven Design"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 49", "position": 49, "chunk_type": "semantic", "token_estimate": 263}
{"text": "2.6 Constraints on Implementation 31: 2.5  \nEarly Design Decisions\nSoftware architecture is a manifestation of the earliest design decisions about a system, and \nthese early bindings carry enormous weight with respect to the system\u2019s remaining devel-\nopment, its deployment, and its maintenance life. It is also the earliest point at which these \nimportant design decisions affecting the system can be scrutinized. Any design, in any discipline, can be viewed as a sequence of decisions. When painting a \npicture, an artist decides on the material for the canvas and the media for recording\u2014oil paint, \nwatercolor, crayon\u2014even before the picture is begun. Once the picture is begun, other deci-\nsions are immediately made: Where is the first line, what is its thickness, what is its shape? All \nof these early design decisions have a strong influence on the final appearance of the picture, \nand each decision constrains the many decisions that follow. Each decision, in isolation, might \nappear innocent enough, but the early ones in particular have disproportionate weight simply \nbecause they influence and constrain so much of what follows. So it is with architecture design. An architecture design can also be viewed as a set \nof decisions. Changing these early decisions will cause a ripple effect, in terms of the addi-\ntional decisions that must now be changed. Yes, sometimes the architecture must be refactored \nor redesigned, but this is not a task we undertake lightly\u2014because the \u201cripple\u201d might turn into \nan avalanche. What are these early design decisions embodied by software architecture? Consider:\n \n\u25a0Will the system run on one processor or be distributed across multiple processors? \u25a0Will the software be layered? If so, how many layers will there be? What will each \none do? \u25a0Will components communicate synchronously or asynchronously? Will they interact by \ntransferring control or data, or both? \u25a0Will the information that flows through the system be encrypted? \u25a0Which operating system will we use? \u25a0Which communication protocol will we choose? Imagine the nightmare of having to change any of these or a myriad of other related \ndecisions. Decisions like these begin to flesh out some of the structures of the architecture and \ntheir interactions. 2.6  \nConstraints on Implementation\nIf you want your implementation to conform to an architecture, then it must conform to the \ndesign decisions prescribed by the architecture.", "domains": ["Architectural Patterns and Styles", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 50", "position": 50, "chunk_type": "semantic", "token_estimate": 382}
{"text": "32 Part I Introduction | Chapter 2 Why Is Software Architecture Important?: Element builders must be fluent in the specifications of their individual elements, but \nthey may not be aware of the architectural tradeoffs\u2014the architecture (or architect) simply \nconstrains them in such a way as to meet the tradeoffs. A classic example is when an archi-\ntect assigns performance budgets to the pieces of software involved in some larger piece of \nfunctionality. If each software unit stays within its budget, the overall transaction will meet its \nperformance requirement. Implementers of each of the constituent pieces may not know the \noverall budget, but only their own. Conversely, the architects need not be experts in all aspects of algorithm design or the \nintricacies of the programming language\u2014although they should certainly know enough not to \ndesign something that is difficult to build. Architects, however, are the people responsible for \nestablishing, analyzing, and enforcing the architectural decisions and tradeoffs. 2.7  \nInfluences on Organizational Structure\nNot only does architecture prescribe the structure of the system being developed, but that \nstructure becomes engraved in the structure of the development project (and sometimes the \nstructure of the entire organization). The normal method for dividing up the labor in a large \nproject is to assign different groups different portions of the system to construct. This so-called \nwork-breakdown structure of a system is manifested in the architecture in the work assignment \nstructure described in Chapter 1. Because the architecture includes the broadest decompo-\nsition of the system, it is typically used as the basis for the work-breakdown  \nstructure. The \nwork-breakdown structure in turn dictates units of planning, scheduling, and budget; inter-\nteam communication channels; configuration control and file-system organization; integration \nand test plans and procedures; and even project minutiae such as how the project intranet is \norganized and who sits with whom at the company picnic. Teams communicate with each \nother in terms of the interface specifications for their elements. The maintenance activity, \nwhen launched, will also reflect the software structure, with teams formed to maintain spe-\ncific elements from the architecture\u2014the database, the business rules, the user interface, the \ndevice drivers, and so forth. A side effect of establishing the work-breakdown structure is to freeze some aspects of \nthe software architecture. A group that is responsible for one of the subsystems may resist \nhaving its responsibilities distributed across other groups. If these responsibilities have been \nformalized in a contractual relationship, changing responsibilities could become expensive or \neven litigious.", "domains": ["Design Patterns", "Software Quality Attributes", "Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 51", "position": 51, "chunk_type": "semantic", "token_estimate": 410}
{"text": "2.9 Cost and Schedule Estimates 33: 2.8  \nEnabling Incremental Development\nOnce an architecture has been defined, it can serve as the basis for incremental development. The first increment can be a skeletal system in which at least some of the infrastructure\u2014how \nthe elements initialize, communicate, share data, access resources, report errors, log activity, \nand so forth\u2014is present, but much of the system\u2019s application functionality is not. Building the infrastructure and building the application functionality can go hand in \nhand. Design and build a little infrastructure to support a little end-to-end functionality; repeat \nuntil done. Many systems are built as skeletal systems that can be extended using plug-ins, packages, \nor extensions. Examples include the R language, Visual Studio Code, and most web browsers. The extensions, when added, provide additional functionality over and above what is present \nin the skeleton. This approach aids the development process by ensuring that the system is exe-\ncutable early in the product\u2019s life cycle. The fidelity of the system increases as extensions are \nadded, or early versions are replaced by more complete versions of these parts of the software. In some cases, the parts may be low-fidelity versions or prototypes of the final functionality; \nin other cases, they may be surrogates that consume and produce data at the appropriate rates \nbut do little else. Among other things, this allows potential performance (and other) problems \nto be identified early in the product\u2019s life cycle. This practice gained attention in the early 2000s through the ideas of Alistair Cockburn \nand his notion of a \u201cwalking skeleton.\u201d More recently, it has been adopted by those employing \nMVP (minimum viable product) as a strategy for risk reduction. The benefits of incremental development include a reduction of the potential risk in the \nproject. If the architecture is for a family of related systems, the infrastructure can be reused \nacross the family, lowering the per-system cost of each. 2.9  \nCost and Schedule Estimates\nCost and schedule estimates are an important tool for the project manager. They help the proj-\nect manager acquire the necessary resources as well as monitor progress on the project. One \nof the duties of an architect is to help the project manager create cost and schedule estimates \nearly in the project\u2019s life cycle.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 52", "position": 52, "chunk_type": "semantic", "token_estimate": 375}
{"text": "2.12 Restricting the Vocabulary of Design Alternatives 35: Commercial off-the-shelf components, open source software, publicly available apps, and \nnetworked services are all examples of independently developed elements. The complexity \nand ubiquity of integrating many independently developed elements into your system have \nspawned an entire industry of software tools, such as Apache Ant, Apache Maven, MSBuild, \nand Jenkins. For software, the payoffs can take the following forms:\n \n\u25a0Decreased time to market (It should be easier to use someone else\u2019s ready solution than \nto build your own.) \u25a0Increased reliability (Widely used software should have its bugs ironed out already.) \u25a0Lower cost (The software supplier can amortize development cost across its customer \nbase.) \u25a0Flexibility (If the element you want to buy is not terribly special-purpose, it\u2019s likely to be \navailable from several sources, which in turn increases your buying leverage.) An open system is one that defines a set of standards for software elements\u2014how they \nbehave, how they interact with other elements, how they share data, and so forth. The goal of \nan open system is to enable, and even encourage, many different suppliers to be able to pro-\nduce elements. This can avoid \u201cvendor lock-in,\u201d a situation in which a single vendor is the only \none who can provide an element and charges a premium price for doing so. Open systems are \nenabled by an architecture that defines the elements and their interactions. 2.12  \nRestricting the Vocabulary of Design Alternatives\nAs useful architectural solutions are collected, it becomes clear that although software ele-\nments can be combined in more or less infinite ways, there is something to be gained by \nvoluntarily restricting ourselves to a relatively small number of choices of elements and their \ninteractions. By doing so, we minimize the design complexity of the system we are building. A software engineer is not an artiste where creativity and freedom are paramount. Instead, \nengineering is about discipline, and discipline comes, in part, by restricting the vocabulary \nof alternatives to proven solutions. Examples of these proven design solutions include tactics \nand patterns, which will be discussed extensively in Part II. Reusing off-the-shelf elements is \nanother approach to restricting your design vocabulary. Restricting your design vocabulary to proven solutions can yield the following benefits:\n \n\u25a0Enhanced reuse\n \n\u25a0More regular and simpler designs that are more easily understood and communicated, \nand bring more reliably predictable outcomes\n \n\u25a0Easier analysis with greater confidence\n \n\u25a0Shorter selection time\n \n\u25a0Greater interoperability", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 54", "position": 54, "chunk_type": "semantic", "token_estimate": 400}
{"text": "36 Part I Introduction | Chapter 2 Why Is Software Architecture Important?: Unprecedented designs are risky. Proven designs are, well, proven. This is not to say that \nsoftware design can never be innovative or offer new and exciting solutions. It can. But these \nsolutions should not be invented for the sake of novelty; rather, they should be sought when \nexisting solutions are insufficient to solve the problem at hand. Properties of software follow from the choice of architectural tactics or patterns. Tactics \nand patterns that are more desirable for a particular problem should improve the resulting \ndesign solution, perhaps by making it easier to arbitrate conflicting design constraints, by \nincreasing insights into poorly understood design contexts, and by helping surface inconsisten-\ncies in requirements. We will discuss architectural tactics and patterns in Part II. 2.13  \nA Basis for Training\nThe architecture, including a description of how the elements interact with each other to carry \nout the required behavior, can serve as the first introduction to the system for new project \nmembers. This reinforces our point that one important use of software architecture is to sup-\nport and encourage communication among the various stakeholders. The architecture serves \nas a common reference point for all of these people. Module views are excellent means of showing someone the structure of a project: who does \nwhat, which teams are assigned to which parts of the system, and so forth. Component-and-\nconnector views are excellent choices for explaining how the system is expected to work \nand accomplish its job. Allocation views show a new project member where their assigned part \nfits into the project\u2019s development or deployment environment. 2.14  \nSummary\nSoftware architecture is important for a wide variety of technical and nontechnical reasons. Our List of Thirteen includes the following benefits:\n1. An architecture will inhibit or enable a system\u2019s driving quality attributes. 2. The decisions made in an architecture allow you to reason about and manage change as \nthe system evolves. 3. The analysis of an architecture enables early prediction of a system\u2019s qualities. 4. A documented architecture enhances communication among stakeholders. 5. The architecture is a carrier of the earliest, and hence most-fundamental, hardest-to-\nchange design decisions. 6. An architecture defines a set of constraints on subsequent implementation. 7. The architecture dictates the structure of an organization, or vice versa. 8. An architecture can provide the basis for incremental development.", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 55", "position": 55, "chunk_type": "semantic", "token_estimate": 397}
{"text": "40 Part II Quality Attributes | Chapter 3 Understanding Quality Attributes: 3.1  \nFunctionality\nFunctionality is the ability of the system to do the work for which it was intended. Of all of the \nrequirements, functionality has the strangest relationship to architecture. First of all, functionality does not determine architecture. That is, given a set of required \nfunctionality, there is no end to the architectures you could create to satisfy that functionality. At the very least, you could divide up the functionality in any number of ways and assign the \nsub-pieces to different architectural elements. In fact, if functionality were the only thing that mattered, you wouldn\u2019t have to divide \nthe system into pieces at all: A single monolithic blob with no internal structure would do just \nfine. Instead, we design our systems as structured sets of cooperating architectural elements\u2014\nmodules, layers, classes, services, databases, apps, threads, peers, tiers, and on and on\u2014to \nmake them understandable and to support a variety of other purposes. Those \u201cother purposes\u201d \nare the other quality attributes that we\u2019ll examine in the remaining sections of this chapter, and \nin the subsequent quality attribute chapters in Part II. Although functionality is independent of any particular structure, it is achieved by assign-\ning responsibilities to architectural elements. This process results in one of the most basic \narchitectural structures\u2014module decomposition. Although responsibilities can be allocated arbitrarily to any module, software architecture \nconstrains this allocation when other quality attributes are important. For example, systems are \nfrequently (or perhaps always) divided so that several people can cooperatively build them. The \narchitect\u2019s interest in functionality is how it interacts with and constrains other qualities. Functional Requirements\nAfter more than 30 years of writing about and discussing the distinction between func-\ntional requirements and quality requirements, the definition of functional requirements \nstill eludes me. Quality attribute requirements are well defined: Performance has to \ndo with the system\u2019s timing behavior, modifiability has to do with the system\u2019s ability to \nsupport changes in its behavior or other qualities after initial deployment, availability has \nto do with the system\u2019s ability to survive failures, and so forth. Function, however, is a much more slippery concept. An international standard (ISO \n25010) defines functional suitability as \u201cthe capability of the software product to provide \nfunctions which meet stated and implied needs when the software is used under spec-\nified conditions.\u201d That is, functionality is the ability to provide functions.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 59", "position": 59, "chunk_type": "semantic", "token_estimate": 400}
{"text": "3.2 Quality Attribute Considerations 41: I much prefer using the word \u201cresponsibility\u201d to describe computations that a system \nmust perform. Questions such as \u201cWhat are the timing constraints on that set of respon-\nsibilities?\u201d, \u201cWhat modifications are anticipated with respect to that set of responsibili-\nties?\u201d, and \u201cWhat class of users is allowed to execute that set of responsibilities?\u201d make \nsense and are actionable. The achievement of qualities induces responsibility; think of the user name/password \nexample just mentioned. Further, one can identify responsibilities as being associated \nwith a particular set of requirements. So does this mean that the term \u201cfunctional requirement\u201d shouldn\u2019t be used? People \nhave an understanding of the term, but when precision is desired, we should talk about \nsets of specific responsibilities instead. Paul Clements has long ranted against the careless use of the term \u201cnonfunctional,\u201d \nand now it\u2019s my turn to rant against the careless use of the term \u201cfunctional\u201d\u2014which is \nprobably equally ineffectually. \u2014LB\n3.2  \nQuality Attribute Considerations\nJust as a system\u2019s functions do not stand on their own without due consideration of quality \nattributes, neither do quality attributes stand on their own; they pertain to the functions of the \nsystem. If a functional requirement is \u201cWhen the user presses the green button, the Options \ndialog appears,\u201d a performance QA annotation might describe how quickly the dialog will \nappear; an availability QA annotation might describe how often this function is allowed to \nfail, and how quickly it will be repaired; a usability QA annotation might describe how easy it \nis to learn this function. Quality attributes as a distinct topic have been studied by the software community at \nleast since the 1970s. A variety of taxonomies and definitions have been published (we discuss \nsome of these in Chapter 14), many of which have their own research and practitioner commu-\nnities. However, there are three problems with most discussions of system quality attributes:\n1. The definitions provided for an attribute are not testable. It is meaningless to say that a \nsystem will be \u201cmodifiable.\u201d Every system will be modifiable with respect to one set of \nchanges and not modifiable with respect to another. The other quality attributes are sim-\nilar in this regard: A system may be robust with respect to some faults and brittle with \nrespect to others, and so forth. 2. Discussion often focuses on which quality a particular issue belongs to.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 60", "position": 60, "chunk_type": "semantic", "token_estimate": 397}
{"text": "3.2 Quality Attribute Considerations 41: 2. Discussion often focuses on which quality a particular issue belongs to. Is a denial-\nof-service attack on a system an aspect of availability, an aspect of performance, an \naspect of security, or an aspect of usability? All four attribute communities would claim \n\u201cownership\u201d of the denial-of-service attack. All are, to some extent, correct. But this \ndebate over categorization doesn\u2019t help us, as architects, understand and create architec-\ntural solutions to actually manage the attributes of concern.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 60", "position": 60, "chunk_type": "semantic", "token_estimate": 82}
{"text": "42 Part II Quality Attributes | Chapter 3 Understanding Quality Attributes: 3. Each attribute community has developed its own vocabulary. The performance commu-\nnity has \u201cevents\u201d arriving at a system, the security community has \u201cattacks\u201d arriving at \na system, the availability community has \u201cfaults\u201d arriving, and the usability community \nhas \u201cuser input.\u201d All of these may actually refer to the same occurrence, but they are \ndescribed using different terms. A solution to the first two problems (untestable definitions and overlapping issues) is to use \nquality attribute scenarios as a means of characterizing quality attributes (see Section 3.3). A \nsolution to the third problem is to illustrate the concepts that are fundamental to that attribute \ncommunity in a common form, which we do in Chapters 4\u201314. We will focus on two categories of quality attributes. The first category includes those \nattributes that describe some property of the system at runtime, such as availability, perfor-\nmance, or usability. The second category includes those that describe some property of the \ndevelopment of the system, such as modifiability, testability, or deployability. Quality attributes can never be achieved in isolation. The achievement of any one will \nhave an effect\u2014sometimes positive and sometimes negative\u2014on the achievement of others. For \nexample, almost every quality attribute negatively affects performance. Take portability: The \nmain technique for achieving portable software is to isolate system dependencies, which intro-\nduces overhead into the system\u2019s execution, typically as process or procedure boundaries, which \nthen hurts performance. Determining a design that may satisfy quality attribute requirements is \npartially a matter of making the appropriate tradeoffs; we discuss design in Chapter 21. In the next three sections, we focus on how quality attributes can be specified, what archi-\ntectural decisions will enable the achievement of particular quality attributes, and what ques-\ntions about quality attributes will enable the architect to make the correct design decisions. 3.3  \nSpecifying Quality Attribute Requirements: Quality Attribute \nScenarios\nWe use a common form to specify all QA requirements as scenarios. This addresses the vocab-\nulary problems we identified previously. The common form is testable and unambiguous; it is \nnot sensitive to whims of categorization. Thus it provides regularity in how we treat all quality \nattributes. Quality attribute scenarios have six parts:\n \n\u25a0Stimulus. We use the term \u201cstimulus\u201d to describe an event arriving at the system or the \nproject.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 61", "position": 61, "chunk_type": "semantic", "token_estimate": 388}
{"text": "42 Part II Quality Attributes | Chapter 3 Understanding Quality Attributes: Quality attribute scenarios have six parts:\n \n\u25a0Stimulus. We use the term \u201cstimulus\u201d to describe an event arriving at the system or the \nproject. The stimulus can be an event to the performance community, a user operation \nto the usability community, or an attack to the security community, and so forth. We \nuse the same term to describe a motivating action for developmental qualities. Thus a \nstimulus for modifiability is a request for a modification; a stimulus for testability is the \ncompletion of a unit of development. \u25a0Stimulus source. A stimulus must have a source\u2014it must come from somewhere. Some entity (a human, a computer system, or any other actor) must have generated the", "domains": ["Software Quality Attributes", "Domain-Driven Design"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 61", "position": 61, "chunk_type": "semantic", "token_estimate": 124}
{"text": "3.3 Specifying Quality Attribute Requirements: Quality Attribute Scenarios 43: stimulus. The source of the stimulus may affect how it is treated by the system. A request \nfrom a trusted user will not undergo the same scrutiny as a request by an untrusted user. \u25a0Response. The response is the activity that occurs as the result of the arrival of the stim-\nulus. The response is something the architect undertakes to satisfy. It consists of the \nresponsibilities that the system (for runtime qualities) or the developers (for development-\ntime qualities) should perform in response to the stimulus. For example, in a performance \nscenario, an event arrives (the stimulus) and the system should process that event and \ngenerate a response. In a modifiability scenario, a request for a modification arrives (the \nstimulus) and the developers should implement the modification\u2014without side effects\u2014\nand then test and deploy the modification. \u25a0Response measure. When the response occurs, it should be measurable in some fash-\nion so that the scenario can be tested\u2014that is, so that we can determine if the architect \nachieved it. For performance, this could be a measure of latency or throughput; for \nmodifiability, it could be the labor or wall clock time required to make, test, and deploy \nthe modification. These four characteristics of a scenario are the heart of our quality attribute specifi-\ncations. But two more characteristics are important, yet often overlooked: environment and \nartifact. \u25a0Environment. The environment is the set of circumstances in which the scenario takes \nplace. Often this refers to a runtime state: The system may be in an overload condition or \nin normal operation, or some other relevant state. For many systems, \u201cnormal\u201d opera-\ntion can refer to one of a number of modes. For these kinds of systems, the environment \nshould specify in which mode the system is executing. But the environment can also \nrefer to states in which the system is not running at all: when it is in development, or \ntesting, or refreshing its data, or recharging its battery between runs. The environment \nsets the context for the rest of the scenario. For example, a request for a modification that \narrives after the code has been frozen for a release may be treated differently than one \nthat arrives before the freeze. The fifth successive failure of a component may be treated \ndifferently than the first failure of that component. \u25a0Artifact. The stimulus arrives at some target.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 62", "position": 62, "chunk_type": "semantic", "token_estimate": 402}
{"text": "3.3 Specifying Quality Attribute Requirements: Quality Attribute Scenarios 43: \u25a0Artifact. The stimulus arrives at some target. This is often captured as just the system \nor project itself, but it\u2019s helpful to be more precise if possible. The artifact may be a \ncollection of systems, the whole system, or one or more pieces of the system. A failure or \na change request may affect just a small portion of the system. A failure in a data store \nmay be treated differently than a failure in the metadata store. Modifications to the user \ninterface may have faster response times than modifications to the middleware. To summarize, we capture quality attribute requirements as six-part scenarios. While it \nis common to omit one or more of these six parts, particularly in the early stages of thinking \nabout quality attributes, knowing that all of the parts are there forces the architect to consider \nwhether each part is relevant. We have created a general scenario for each of the quality attributes presented in Chap-\nters 4\u201313 to facilitate brainstorming and elicitation of concrete scenarios. We distinguish", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 62", "position": 62, "chunk_type": "semantic", "token_estimate": 180}
{"text": "44 Part II Quality Attributes | Chapter 3 Understanding Quality Attributes: Stimulus\nResponse\nResponse\nMeasure\nSource\n3\n2\n1\n4\nEnvironment\nArtifact\n6\n1\n2\n3\n4\n5\ngeneral quality attribute scenarios\u2014general scenarios\u2014which are system independent and \ncan pertain to any system, from concrete quality attribute scenarios\u2014concrete scenarios\u2014\nwhich are specific to the particular system under consideration. To translate these generic attribute characterizations into requirements for a particular \nsystem, the general scenarios need to be made system specific. But, as we have found, it is \nmuch easier for a stakeholder to tailor a general scenario into one that fits their system than it \nis for them to generate a scenario from thin air. Figure 3.1 shows the parts of a quality attribute scenario just discussed. Figure 3.2 shows \nan example of a general scenario, in this instance for availability. FIGURE 3.1 The parts of a quality attribute scenario\nStimulus\nResponse\nResponse\nMeasure\nSource\n3\n2\n1\n4\nEnvironment\nArtifact\nInternal/external:\npeople, hardware,\nsoftware, physical\ninfrastructure,\nphysical\nenvironment\nFault: omission,\ncrash, incorrect\ntiming, incorrect\nresponse\nNormal operation,\nstartup, shutdown,\nrepair mode, degraded\noperation, overloaded\noperation\nPrevent the fault\nfrom becoming a\nfailure\nDetect the fault\nRecover from the \nfault\nTime or time interval\nwhen the system must\nbe available\nAvailability percentage\nTime to detect the fault\nProcessors, communication\nchannels, storage, processes, \naffected artifacts in the \nsystem\u2019s environment\nFIGURE 3.2 A general scenario for availability", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 63", "position": 63, "chunk_type": "semantic", "token_estimate": 233}
{"text": "3.4 Achieving Quality Attributes through Architectural Patterns and Tactics 45: Not My Problem\nSome time ago I was doing an architecture analysis on a complex system created by \nand for Lawrence Livermore National Laboratory. If you visit this organization\u2019s website \n(llnl.gov) and try to figure out what Livermore Labs does, you will see the word \u201csecurity\u201d \nmentioned over and over. The lab focuses on nuclear security, international and domes-\ntic security, and environmental and energy security. Serious stuff . . . Keeping this emphasis in mind, I asked my clients to describe the quality attributes of \nconcern for the system that I was analyzing. I\u2019m sure you can imagine my surprise when \nsecurity wasn\u2019t mentioned once! The system stakeholders mentioned performance, \nmodifiability, evolvability, interoperability, configurability, and portability, and one or two \nmore, but the word \u201csecurity\u201d never passed their lips. Being a good analyst, I questioned this seemingly shocking and obvious omission. Their answer was simple and, in retrospect, straightforward: \u201cWe don\u2019t care about it. Our systems are not connected to any external network, and we have barbed-wire \nfences and guards with machine guns.\u201d\nOf course, someone at Livermore Labs was very interested in security. But not the \nsoftware architects. The lesson here is that the software architect may not bear the \nresponsibility for every QA requirement. \u2014RK\n3.4  \nAchieving Quality Attributes through Architectural Patterns \nand Tactics\nWe now turn to the techniques an architect can use to achieve the required quality attributes: \narchitectural patterns and tactics. A tactic is a design decision that influences the achievement of a quality attribute \nresponse\u2014it directly affects the system\u2019s response to some stimulus. Tactics may impart por-\ntability to one design, high performance to another, and integrability to a third. An architectural pattern describes a particular recurring design problem that arises in \nspecific design contexts and presents a well-proven architectural solution for the problem. The \nsolution is specified by describing the roles of its constituent elements, their responsibilities \nand relationships, and the ways in which they collaborate. Like the choice of tactics, the choice \nof an architectural pattern has a profound effect on quality attributes\u2014usually more than one. Patterns typically comprise multiple design decisions and, in fact, often comprise multi-\nple quality attribute tactics. We say that patterns often bundle tactics and, consequently, fre-\nquently make tradeoffs among quality attributes. We will look at example relationships between tactics and patterns in each of our quality \nattribute\u2013specific chapters.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 64", "position": 64, "chunk_type": "semantic", "token_estimate": 404}
{"text": "46 Part II Quality Attributes | Chapter 3 Understanding Quality Attributes: While we discuss patterns and tactics as though they were foundational design decisions, \nthe reality is that architectures often emerge and evolve as a result of many small decisions and \nbusiness forces. For example, a system that was once tolerably modifiable may deteriorate over \ntime, through the actions of developers adding features and fixing bugs. Similarly, a system\u2019s \nperformance, availability, security, and any other quality may (and typically does) deteriorate \nover time, again through the well-intentioned actions of programmers who are focused on \ntheir immediate tasks and not on preserving architectural integrity. This \u201cdeath by a thousand cuts\u201d is common on software projects. Developers may make \nsuboptimal decisions due to a lack of understanding of the structures of the system, schedule \npressures, or perhaps a lack of clarity in the architecture from the start. This kind of deterio-\nration is a form of technical debt known as architecture debt. We discuss architecture debt in \nChapter 23. To reverse this debt, we typically refactor. Refactoring may be done for many reasons. For example, you might refactor a system to \nimprove its security, placing different modules into different subsystems based on their secu-\nrity properties. Or you might refactor a system to improve its performance, removing bottle-\nnecks and rewriting slow portions of the code. Or you might refactor to improve the system\u2019s \nmodifiability. For example, when two modules are affected by the same kinds of changes over \nand over because they are (at least partial) duplicates of each other, the common functionality \ncould be factored out into its own module, thereby improving cohesion and reducing the num-\nber of places that need to be changed when the next (similar) change request arrives. Code refactoring is a mainstay practice of agile development projects, as a cleanup step \nto make sure that teams have not produced duplicative or overly complex code. However, the \nconcept applies to architectural elements as well. Successfully achieving quality attributes often involves process-related decisions, in \naddition to architecture-related decisions. For example, a great security architecture is worth-\nless if your employees are susceptible to phishing attacks or do not choose strong passwords. We are not dealing with the process aspects in this book, but be aware that they are important. 3.5  \nDesigning with Tactics\nA system design consists of a collection of decisions. Some of these decisions help control the \nquality attribute responses; others ensure achievement of system functionality.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 65", "position": 65, "chunk_type": "semantic", "token_estimate": 411}
{"text": "46 Part II Quality Attributes | Chapter 3 Understanding Quality Attributes: 3.5  \nDesigning with Tactics\nA system design consists of a collection of decisions. Some of these decisions help control the \nquality attribute responses; others ensure achievement of system functionality. We depict this \nrelationship in Figure 3.3. Tactics, like patterns, are design techniques that architects have \nbeen using for years. In this book, we isolate, catalog, and describe them. We are not inventing \ntactics here, but rather just capturing what good architects do in practice. Why do we focus on tactics? There are three reasons:\n1. Patterns are foundational for many architectures, but sometimes there may be no pattern \nthat solves your problem completely. For example, you might need the high-availability \nhigh-security broker pattern, not the textbook broker pattern. Architects frequently need \nto modify and adapt patterns to their particular context, and tactics provide a systematic \nmeans for augmenting an existing pattern to fill the gaps.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 65", "position": 65, "chunk_type": "semantic", "token_estimate": 156}
{"text": "3.5 Designing with Tactics 47: 2. If no pattern exists to realize the architect\u2019s design goal, tactics allow the architect to \nconstruct a design fragment from \u201cfirst principles.\u201d Tactics give the architect insight into \nthe properties of the resulting design fragment. 3. Tactics provide a way of making design and analysis more systematic within some lim-\nitations. We\u2019ll explore this idea in the next section. Stimulus\nResponse\nTactics\nto Control\nResponse\nFIGURE 3.3 Tactics are intended to control responses to stimuli. Like any design concept, the tactics that we present here can and should be refined as \nthey are applied to design a system. Consider performance: Schedule resources is a common \nperformance tactic. But this tactic needs to be refined into a specific scheduling strategy, such \nas shortest-job-first, round-robin, and so forth, for specific purposes. Use an intermediary is \na modifiability tactic. But there are multiple types of intermediaries (layers, brokers, prox-\nies, and tiers, to name just a few), which are realized in different ways. Thus a designer will \nemploy refinements to make each tactic concrete. In addition, the application of a tactic depends on the context. Again, consider perfor-\nmance: Manage sampling rate is relevant in some real-time systems but not in all real-time \nsystems, and certainly not in database systems or stock-trading systems where losing a single \nevent is highly problematic. Note that there are some \u201csuper-tactics\u201d\u2014tactics that are so fundamental and so perva-\nsive that they deserve special mention. For example, the modifiability tactics of encapsulation, \nrestricting dependencies, using an intermediary, and abstracting common services are found \nin the realization of almost every pattern ever! But other tactics, such as the scheduling tactic \nfrom performance, also appear in many places. For example, a load balancer is an intermedi-\nary that does scheduling. We see monitoring appearing in many quality attributes: We monitor \naspects of a system to achieve energy efficiency, performance, availability, and safety. Thus \nwe should not expect a tactic to live in only one place, for just a single quality attribute. Tactics \nare design primitives and, as such, are found over and over in different aspects of design. This \nis actually an argument for why tactics are so powerful and deserving of our attention\u2014and \nyours. Get to know them; they\u2019ll be your friends.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 66", "position": 66, "chunk_type": "semantic", "token_estimate": 379}
{"text": "48 Part II Quality Attributes | Chapter 3 Understanding Quality Attributes: 3.6  \nAnalyzing Quality Attribute Design Decisions: Tactics-Based \nQuestionnaires\nIn this section, we introduce a tool the analyst can use to understand potential quality attribute \nbehavior at various stages through the architecture\u2019s design: tactics-based questionnaires. Analyzing how well quality attributes have been achieved is a critical part of the task of \ndesigning an architecture. And (no surprise) you shouldn\u2019t wait until your design is complete \nbefore you begin to do it. Opportunities for quality attribute analysis crop up at many different \npoints in the software development life cycle, even very early ones. At any point, the analyst (who might be the architect) needs to respond appropriately to \nwhatever artifacts have been made available for analysis. The accuracy of the analysis and \nexpected degree of confidence in the analysis results will vary according to the maturity of the \navailable artifacts. But no matter the state of the design, we have found tactics-based question-\nnaires to be helpful in gaining insights into the architecture\u2019s ability (or likely ability, as it is \nrefined) to provide the needed quality attributes. In Chapters 4\u201313, we include a tactics-based questionnaire for each quality attribute cov-\nered in the chapters. For each question in the questionnaire, the analyst records the following \ninformation:\n \n\u25a0Whether each tactic is supported by the system\u2019s architecture. \u25a0Whether there are any obvious risks in the use (or nonuse) of this tactic. If the tactic has \nbeen used, record how it is realized in the system, or how it is intended to be realized \n(e.g., via custom code, generic frameworks, or externally produced components). \u25a0The specific design decisions made to realize the tactic and where in the code base the \nimplementation (realization) may be found. This is useful for auditing and architecture \nreconstruction purposes. \u25a0Any rationale or assumptions made in the realization of this tactic. To use these questionnaires, simply follow these four steps:\n1. For each tactics question, fill the \u201cSupported\u201d column with \u201cY\u201d if the tactic is supported \nin the architecture and with \u201cN\u201d otherwise. 2. If the answer in the \u201cSupported\u201d column is \u201cY,\u201d then in the \u201cDesign Decisions and \nLocation\u201d column describe the specific design decisions made to support the tactic and \nenumerate where these decisions are, or will be, manifested (located) in the architecture. For example, indicate which code modules, frameworks, or packages implement this \ntactic. 3.", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 67", "position": 67, "chunk_type": "semantic", "token_estimate": 398}
{"text": "50 Part II Quality Attributes | Chapter 3 Understanding Quality Attributes: 3.9  \nDiscussion Questions\n1. What is the relationship between a use case and a quality attribute scenario? If you \nwanted to add quality attribute information to a use case, how would you do it? 2. Do you suppose that the set of tactics for a quality attribute is finite or infinite? Why? 3. Enumerate the set of responsibilities that an automatic teller machine should support and \npropose a design to accommodate that set of responsibilities. Justify your proposal. 4. Choose an architecture that you are familiar with (or choose the ATM architecture you \ndefined in question 3) and walk through the performance tactics questionnaire (found in \nChapter 9). What insight did these questions provide into the design decisions made (or \nnot made)?", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 69", "position": 69, "chunk_type": "semantic", "token_estimate": 133}
{"text": "51: 4\n \nAvailability\nTechnology does not always rhyme \nwith perfection and reliability. Far from it in reality! \u2014Jean-Michel Jarre\nAvailability refers to a property of software\u2014namely, that it is there and ready to carry out \nits task when you need it to be. This is a broad perspective and encompasses what is normally \ncalled reliability (although it may encompass additional considerations such as downtime due \nto periodic maintenance). Availability builds on the concept of reliability by adding the notion \nof recovery\u2014that is, when the system breaks, it repairs itself. Repair may be accomplished by \nvarious means, as we\u2019ll see in this chapter. Availability also encompasses the ability of a system to mask or repair faults such that \nthey do not become failures, thereby ensuring that the cumulative service outage period does \nnot exceed a required value over a specified time interval. This definition subsumes concepts \nof reliability, robustness, and any other quality attribute that involves a concept of unaccept-\nable failure. A failure is the deviation of the system from its specification, where that deviation is \nexternally visible. Determining that a failure has occurred requires some external observer in \nthe environment. A failure\u2019s cause is called a fault. A fault can be either internal or external to the system \nunder consideration. Intermediate states between the occurrence of a fault and the occurrence \nof a failure are called errors. Faults can be prevented, tolerated, removed, or forecast. Through \nthese actions, a system becomes \u201cresilient\u201d to faults. Among the areas with which we are \nconcerned are how system faults are detected, how frequently system faults may occur, what \nhappens when a fault occurs, how long a system is allowed to be out of operation, when faults \nor failures may occur safely, how faults or failures can be prevented, and what kinds of notifi-\ncations are required when a failure occurs. Availability is closely related to, but clearly distinct from, security. A denial-of-service \nattack is explicitly designed to make a system fail\u2014that is, to make it unavailable. Availability \nis also closely related to performance, since it may be difficult to tell when a system has failed", "domains": ["Design Patterns", "Software Quality Attributes", "Domain-Driven Design"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 70", "position": 70, "chunk_type": "semantic", "token_estimate": 353}
{"text": "52 Part II Quality Attributes | Chapter 4 Availability: and when it is simply being egregiously slow to respond. Finally, availability is closely allied \nwith safety, which is concerned with keeping the system from entering a hazardous state and \nrecovering or limiting the damage when it does. One of the most demanding tasks in building a high-availability fault-tolerant system is \nto understand the nature of the failures that can arise during operation. Once those are under-\nstood, mitigation strategies can be designed into the system. Since a system failure is observable by users, the time to repair is the time until the fail-\nure is no longer observable. This may be an imperceptible delay in a user\u2019s response time or it \nmay be the time it takes someone to fly to a remote location in the Andes to repair a piece of \nmining machinery (as was recounted to us by a person responsible for repairing the software \nin a mining machine engine). The notion of \u201cobservability\u201d is critical here: If a failure could \nhave been observed, then it is a failure, whether or not it was actually observed. In addition, we are often concerned with the level of capability that remains when a fail-\nure has occurred\u2014a degraded operating mode. Distinguishing between faults and failures allows us to discuss repair strategies. If code \ncontaining a fault is executed but the system is able to recover from the fault without any observ-\nable deviation from the otherwise specified behavior, we say that no failure has occurred. The availability of a system can be measured as the probability that it will provide the \nspecified services within the required bounds over a specified time interval. A well-known \nexpression is used to derive steady-state availability (which came from the world of hardware):\nMTBF/(MTBF + MTTR)\nwhere MTBF refers to the mean time between failures and MTTR refers to the mean time to \nrepair. In the software world, this formula should be interpreted to mean that when thinking \nabout availability, you should think about what will make your system fail, how likely it is that \nsuch an event will occur, and how much time will be required to repair it.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 71", "position": 71, "chunk_type": "semantic", "token_estimate": 365}
{"text": "52 Part II Quality Attributes | Chapter 4 Availability: A well-known \nexpression is used to derive steady-state availability (which came from the world of hardware):\nMTBF/(MTBF + MTTR)\nwhere MTBF refers to the mean time between failures and MTTR refers to the mean time to \nrepair. In the software world, this formula should be interpreted to mean that when thinking \nabout availability, you should think about what will make your system fail, how likely it is that \nsuch an event will occur, and how much time will be required to repair it. From this formula, it is possible to calculate probabilities and make claims like \u201cthe sys-\ntem exhibits 99.999 percent availability\u201d or \u201cthere is a 0.001 percent probability that the system \nwill not be operational when needed.\u201d Scheduled downtimes (when the system is intentionally \ntaken out of service) should not be considered when calculating availability, since the system \nis deemed \u201cnot needed\u201d then; of course, this is dependent on the specific requirements for the \nsystem, which are often encoded in a service level agreement (SLA). This may lead to seem-\ningly odd situations where the system is down and users are waiting for it, but the downtime is \nscheduled and so is not counted against any availability requirements. Detected faults can be categorized prior to being reported and repaired. This categori-\nzation is commonly based on the fault\u2019s severity (critical, major, or minor) and service impact \n(service-affecting or non-service-affecting). It provides the system operator with a timely and \naccurate system status and allows for an appropriate repair strategy to be employed. The repair \nstrategy may be automated or may require manual intervention. As just mentioned, the availability expected of a system or service is frequently expressed \nas an SLA. The SLA specifies the availability level that is guaranteed and, usually, the", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 71", "position": 71, "chunk_type": "semantic", "token_estimate": 302}
{"text": "4.1 Availability General Scenario 53: penalties that the provider will suffer if the SLA is violated. For example, Amazon provides \nthe following SLA for its EC2 cloud service:\nAWS will use commercially reasonable efforts to make the Included Services each \navailable for each AWS region with a Monthly Uptime Percentage of at least 99.99%, \nin each case during any monthly billing cycle (the \u201cService Commitment\u201d). In the \nevent any of the Included Services do not meet the Service Commitment, you will be \neligible to receive a Service Credit as described below. Table 4.1 provides examples of system availability requirements and associated threshold \nvalues for acceptable system downtime, measured over observation periods of 90 days and \none year. The term high availability typically refers to designs targeting availability of 99.999 \npercent (\u201c5 nines\u201d) or greater. As mentioned earlier, only unscheduled outages contribute to \nsystem downtime. TABLE 4.1 System Availability Requirements\nAvailability\nDowntime/90 Days\nDowntime/Year\n99.0%\n21 hr, 36 min\n3 days, 15.6 hr\n99.9%\n2 hr, 10 min\n8 hr, 0 min, 46 sec\n99.99%\n12 min, 58 sec\n52 min, 34 sec\n99.999%\n1 min, 18 sec\n5 min, 15 sec\n99.9999%\n8 sec\n32 sec\n \n4.1  \nAvailability General Scenario\nWe can now describe the individual portions of an availability general scenario as summa-\nrized in Table 4.2. TABLE 4.2 Availability General Scenario \nPortion of \nScenario\nDescription\nPossible Values\nSource\nThis specifies where the fault comes \nfrom. Internal/external: people, hardware, \nsoftware, physical infrastructure, physical \nenvironment\nStimulus\nThe stimulus to an availability scenario \nis a fault. Fault: omission, crash, incorrect timing, \nincorrect response\nArtifact\nThis specifies which portions of the \nsystem are responsible for and affected \nby the fault. Processors, communication channels, \nstorage, processes, affected artifacts in the \nsystem\u2019s environment \ncontinues", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 72", "position": 72, "chunk_type": "semantic", "token_estimate": 290}
{"text": "54 Part II Quality Attributes | Chapter 4 Availability: Portion of \nScenario\nDescription\nPossible Values\nEnvironment\nWe may be interested in not only \nhow a system behaves in its \u201cnormal\u201d \nenvironment, but also how it behaves \nin situations such as when it is already \nrecovering from a fault. Normal operation, startup, shutdown, repair \nmode, degraded operation, overloaded \noperation\nResponse\nThe most commonly desired response \nis to prevent the fault from becoming a \nfailure, but other responses may also \nbe important, such as notifying people \nor logging the fault for later analysis. This section specifies the desired \nsystem response. Prevent the fault from becoming a failure\nDetect the fault:\n \n\u25a0\nLog the fault\n \n\u25a0\nNotify the appropriate entities (people or \nsystems)\n \n\u25a0\nRecover from the fault\n \n\u25a0\nDisable the source of events causing the \nfault\n \n\u25a0\nBe temporarily unavailable while a repair \nis being effected\n \n\u25a0\nFix or mask the fault/failure or contain the \ndamage it causes\n \n\u25a0\nOperate in a degraded mode while a \nrepair is being effected\nResponse  \nmeasure\nWe may focus on a number of \nmeasures of availability, depending \non the criticality of the service being \nprovided. \u25a0\nTime or time interval when the system \nmust be available\n \n\u25a0\nAvailability percentage (e.g., 99.999 \npercent)\n \n\u25a0\nTime to detect the fault\n \n\u25a0\nTime to repair the fault\n \n\u25a0\nTime or time interval in which system can \nbe in degraded mode\n \n\u25a0\nProportion (e.g., 99 percent) or rate (e.g., \nup to 100 per second) of a certain class \nof faults that the system prevents, or \nhandles without failing\nAn example concrete availability scenario derived from the general scenario in Table 4.2 \nis shown in Figure 4.1. The scenario is this: A server in a server farm fails during normal \noperation, and the system informs the operator and continues to operate with no downtime. TABLE 4.2 Availability General Scenario continued", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 73", "position": 73, "chunk_type": "semantic", "token_estimate": 309}
{"text": "4.2 Tactics for Availability 55: Stimulus\nResponse\nResponse\nMeasure\nSource\n3\n2\n1\n4\nEnvironment\nArtifact\nServer in a\nserver farm\nServer\nfails\nNormal\noperation\nSystem informs\noperator\nSystem continues\nto operate\nNo downtime\nServer\nFIGURE 4.1 Sample concrete availability scenario\n4.2  \nTactics for Availability\nA failure occurs when the system no longer delivers a service that is consistent with its speci-\nfication and this failure is observable by the system\u2019s actors. A fault (or combination of faults) \nhas the potential to cause a failure. Availability tactics, in turn, are designed to enable a system \nto prevent or endure system faults so that a service being delivered by the system remains \ncompliant with its specification. The tactics we discuss in this section will keep faults from \nbecoming failures or at least bound the effects of the fault and make repair possible, as illus-\ntrated in Figure 4.2. Fault\nFault masked,\nprevented, or\nrepair made\nTactics\nto Control\nResponse\nFIGURE 4.2 Goal of availability tactics", "domains": ["Software Quality Attributes", "Domain-Driven Design"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 74", "position": 74, "chunk_type": "semantic", "token_estimate": 164}
{"text": "56 Part II Quality Attributes | Chapter 4 Availability: Availability tactics have one of three purposes: fault detection, fault recovery, or fault \nprevention. The tactics for availability are shown in Figure 4.3. These tactics will often be pro-\nvided by a software infrastructure, such as a middleware package, so your job as an architect \nmay be choosing and assessing (rather than implementing) the right availability tactics and the \nright combination of tactics. Detect Faults\nPrevent Faults\nRecover from Faults\nAvailability Tactics\nMonitor\nPing/Echo\nHeartbeat\nTimestamp\nCondition Monitoring\nSanity Checking\nVoting\nException Detection\nSelf-Test\nRedundant Spare\nRollback\nException Handling\nSoftware Upgrade\nRetry\nIgnore Faulty Behavior\nGraceful Degradation\n5HFRQ\u0182JXUDWLRQ\nShadow\nState Resynchronization\nEscalating Restart\nNonstop Forwarding\nRemoval from Service\nTransactions\nPredictive Model\nException Prevention\nIncrease Competence Set\nReintroduction\nPreparation\nand Repair\nFIGURE 4.3 Availability tactics\nDetect Faults\nBefore any system can take action regarding a fault, the presence of the fault must be detected \nor anticipated. Tactics in this category include:\n \n\u25a0Monitor. This component is used to monitor the state of health of various other parts \nof the system: processors, processes, I/O, memory, and so forth. A system monitor can", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 75", "position": 75, "chunk_type": "semantic", "token_estimate": 188}
{"text": "4.2 Tactics for Availability 57: detect failure or congestion in the network or other shared resources, such as from a \ndenial-of-service attack. It orchestrates software using other tactics in this category to \ndetect malfunctioning components. For example, the system monitor can initiate self-\ntests, or be the component that detects faulty timestamps or missed heartbeats.1\n \n\u25a0Ping/echo. In this tactic, an asynchronous request/response message pair is exchanged \nbetween nodes; it is used to determine reachability and the round-trip delay through the \nassociated network path. In addition, the echo indicates that the pinged component is \nalive. The ping is often sent by a system monitor. Ping/echo requires a time threshold to \nbe set; this threshold tells the pinging component how long to wait for the echo before \nconsidering the pinged component to have failed (\u201ctimed out\u201d). Standard implementa-\ntions of ping/echo are available for nodes interconnected via Internet Protocol (IP). \u25a0Heartbeat. This fault detection mechanism employs a periodic message exchange \nbetween a system monitor and a process being monitored. A special case of heartbeat is \nwhen the process being monitored periodically resets the watchdog timer in its monitor \nto prevent it from expiring and thus signaling a fault. For systems where scalability is a \nconcern, transport and processing overhead can be reduced by piggybacking heartbeat \nmessages onto other control messages being exchanged. The difference between heart-\nbeat and ping/echo lies in who holds the responsibility for initiating the health check\u2014\nthe monitor or the component itself. \u25a0Timestamp. This tactic is used to detect incorrect sequences of events, primarily in dis-\ntributed message-passing systems. A timestamp of an event can be established by assign-\ning the state of a local clock to the event immediately after the event occurs. Sequence \nnumbers can also be used for this purpose, since timestamps in a distributed system may \nbe inconsistent across different processors. See Chapter 17 for a fuller discussion of the \ntopic of time in a distributed system. \u25a0Condition monitoring. This tactic involves checking conditions in a process or device, \nor validating assumptions made during the design. By monitoring conditions, this tactic \nprevents a system from producing faulty behavior. The computation of checksums is a \ncommon example of this tactic. However, the monitor must itself be simple (and, ideally, \nprovably correct) to ensure that it does not introduce new software errors. \u25a0Sanity checking. This tactic checks the validity or reasonableness of specific operations \nor outputs of a component.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 76", "position": 76, "chunk_type": "semantic", "token_estimate": 403}
{"text": "4.2 Tactics for Availability 57: \u25a0Sanity checking. This tactic checks the validity or reasonableness of specific operations \nor outputs of a component. It is typically based on a knowledge of the internal design, \nthe state of the system, or the nature of the information under scrutiny. It is most often \nemployed at interfaces, to examine a specific information flow. \u25a0Voting. Voting involves comparing computational results from multiple sources that \nshould be producing the same results and, if they are not, deciding which results to use. This tactic depends critically on the voting logic, which is usually realized as a simple, \nrigorously reviewed, and tested singleton so that the probability of error is low. Voting \n1. When the detection mechanism is implemented using a counter or timer that is periodically reset, this special-\nization of the system monitor is referred to as a watchdog. During nominal operation, the process being monitored \nwill periodically reset the watchdog counter/timer as part of its signal that it\u2019s working correctly; this is sometimes \nreferred to as \u201cpetting the watchdog.\u201d", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 76", "position": 76, "chunk_type": "semantic", "token_estimate": 174}
{"text": "58 Part II Quality Attributes | Chapter 4 Availability: also depends critically on having multiple sources to evaluate. Typical schemes include \nthe following:\n \n\u25a0Replication is the simplest form of voting; here, the components are exact clones \nof each other. Having multiple copies of identical components can be effective in \nprotecting against random failures of hardware but cannot protect against design or \nimplementation errors, in hardware or software, since there is no form of diversity \nembedded in this tactic. \u25a0Functional redundancy, in contrast, is intended to address the issue of common-mode \nfailures (where replicas exhibit the same fault at the same time because they share the \nsame implementation) in hardware or software components, by implementing design \ndiversity. This tactic attempts to deal with the systematic nature of design faults by \nadding diversity to redundancy. The outputs of functionally redundant components \nshould be the same given the same input. The functional redundancy tactic is still \nvulnerable to specification errors\u2014and, of course, functional replicas will be more \nexpensive to develop and verify. \u25a0Analytic redundancy permits not only diversity among components\u2019 private sides, but \nalso diversity among the components\u2019 inputs and outputs. This tactic is intended to \ntolerate specification errors by using separate requirement specifications. In embedded \nsystems, analytic redundancy helps when some input sources are likely to be unavail-\nable at times. For example, avionics programs have multiple ways to compute aircraft \naltitude, such as using barometric pressure, with the radar altimeter, and geometrically \nusing the straight-line distance and look-down angle of a point ahead on the ground. The voter mechanism used with analytic redundancy needs to be more sophisticated \nthan just letting majority rule or computing a simple average. It may have to under-\nstand which sensors are currently reliable (or not), and it may be asked to produce a \nhigher-fidelity value than any individual component can, by blending and smoothing \nindividual values over time. \u25a0Exception detection. This tactic focuses on the detection of a system condition that alters \nthe normal flow of execution. It can be further refined as follows:\n \n\u25a0System exceptions will vary according to the processor hardware architecture \nemployed. They include faults such as divide by zero, bus and address faults, illegal \nprogram instructions, and so forth. \u25a0The parameter fence tactic incorporates a known data pattern (such as 0xDEADBEEF) \nplaced immediately after any variable-length parameters of an object. This allows for \nruntime detection of overwriting the memory allocated for the object\u2019s variable-length \nparameters.", "domains": ["Software Quality Attributes", "Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 77", "position": 77, "chunk_type": "semantic", "token_estimate": 404}
{"text": "58 Part II Quality Attributes | Chapter 4 Availability: \u25a0The parameter fence tactic incorporates a known data pattern (such as 0xDEADBEEF) \nplaced immediately after any variable-length parameters of an object. This allows for \nruntime detection of overwriting the memory allocated for the object\u2019s variable-length \nparameters. \u25a0Parameter typing employs a base class that defines functions that add, find, and iterate \nover type-length-value (TLV) formatted message parameters. Derived classes use the \nbase class functions to provide functions to build and parse messages. Use of parameter \ntyping ensures that the sender and the receiver of messages agree on the type of the \ncontent, and detects cases where they don\u2019t. \u25a0Timeout is a tactic that raises an exception when a component detects that it or another \ncomponent has failed to meet its timing constraints. For example, a component", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 77", "position": 77, "chunk_type": "semantic", "token_estimate": 134}
{"text": "4.2 Tactics for Availability 59: awaiting a response from another component can raise an exception if the wait time \nexceeds a certain value. \u25a0Self-test. Components (or, more likely, whole subsystems) can run procedures to test \nthemselves for correct operation. Self-test procedures can be initiated by the component \nitself or invoked from time to time by a system monitor. These may involve employing \nsome of the techniques found in condition monitoring, such as checksums. Recover from Faults\nRecover from faults tactics are refined into preparation and repair tactics and reintroduction \ntactics. The latter are concerned with reintroducing a failed (but rehabilitated) component \nback into normal operation. Preparation and repair tactics are based on a variety of combinations of retrying a com-\nputation or introducing redundancy:\n \n\u25a0Redundant spare. This tactic refers to a configuration in which one or more duplicate \ncomponents can step in and take over the work if the primary component fails. This \ntactic is at the heart of the hot spare, warm spare, and cold spare patterns, which differ \nprimarily in how up-to-date the backup component is at the time of its takeover. \u25a0Rollback. A rollback permits the system to revert to a previous known good state \n(referred to as the \u201crollback line\u201d)\u2014rolling back time\u2014upon the detection of a failure. Once the good state is reached, then execution can continue. This tactic is often com-\nbined with the transactions tactic and the redundant spare tactic so that after a rollback \nhas occurred, a standby version of the failed component is promoted to active status. Rollback depends on a copy of a previous good state (a checkpoint) being available to \nthe components that are rolling back. Checkpoints can be stored in a fixed location and \nupdated at regular intervals, or at convenient or significant times in the processing, such \nas at the completion of a complex operation. \u25a0Exception handling. Once an exception has been detected, the system will handle it \nin some fashion. The easiest thing it can do is simply to crash\u2014but, of course, that\u2019s a \nterrible idea from the point of availability, usability, testability, and plain good sense. There are much more productive possibilities.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 78", "position": 78, "chunk_type": "semantic", "token_estimate": 356}
{"text": "4.2 Tactics for Availability 59: The easiest thing it can do is simply to crash\u2014but, of course, that\u2019s a \nterrible idea from the point of availability, usability, testability, and plain good sense. There are much more productive possibilities. The mechanism employed for exception \nhandling depends largely on the programming environment employed, ranging from \nsimple function return codes (error codes) to the use of exception classes that contain \ninformation helpful in fault correlation, such as the name of the exception, the origin of \nthe exception, and the cause of the exception Software can then use this information to \nmask or repair the fault. \u25a0Software upgrade. The goal of this tactic is to achieve in-service upgrades to executable \ncode images in a non-service-affecting manner. Strategies include the following:\n \n\u25a0Function patch. This kind of patch, which is used in procedural programming, employs \nan incremental linker/loader to store an updated software function into a pre-allocated \nsegment of target memory. The new version of the software function will employ the \nentry and exit points of the deprecated function.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 78", "position": 78, "chunk_type": "semantic", "token_estimate": 173}
{"text": "60 Part II Quality Attributes | Chapter 4 Availability: \u25a0Class patch. This kind of upgrade is applicable for targets executing object-oriented \ncode, where the class definitions include a backdoor mechanism that enables the run-\ntime addition of member data and functions. \u25a0Hitless in-service software upgrade (ISSU). This leverages the redundant spare tactic \nto achieve non-service-affecting upgrades to software and associated schema. In practice, the function patch and class patch are used to deliver bug fixes, while the \nhitless ISSU is used to deliver new features and capabilities. \u25a0Retry. The retry tactic assumes that the fault that caused a failure is transient, and that \nretrying the operation may lead to success. It is used in networks and in server farms \nwhere failures are expected and common. A limit should be placed on the number of \nretries that are attempted before a permanent failure is declared. \u25a0Ignore faulty behavior. This tactic calls for ignoring messages sent from a particular \nsource when we determine that those messages are spurious. For example, we would like \nto ignore the messages emanating from the live failure of a sensor. \u25a0Graceful degradation. This tactic maintains the most critical system functions in the \npresence of component failures, while dropping less critical functions. This is done in \ncircumstances where individual component failures gracefully reduce system functional-\nity, rather than causing a complete system failure. \u25a0Reconfiguration. Reconfiguration attempts to recover from failures by reassigning \nresponsibilities to the (potentially restricted) resources or components left functioning, \nwhile maintaining as much functionality as possible. Reintroduction occurs when a failed component is reintroduced after it has been repaired. Reintroduction tactics include the following:\n \n\u25a0Shadow. This tactic refers to operating a previously failed or in-service upgraded \ncomponent in a \u201cshadow mode\u201d for a predefined duration of time prior to reverting the \ncomponent back to an active role. During this duration, its behavior can be monitored for \ncorrectness and it can repopulate its state incrementally. \u25a0State resynchronization. This reintroduction tactic is a partner to the redundant spare \ntactic. When used with active redundancy\u2014a version of the redundant spare tactic\u2014the \nstate resynchronization occurs organically, since the active and standby components \neach receive and process identical inputs in parallel. In practice, the states of the active \nand standby components are periodically compared to ensure synchronization. This \ncomparison may be based on a cyclic redundancy check calculation (checksum) or, for \nsystems providing safety-critical services, a message digest calculation (a one-way hash \nfunction).", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 79", "position": 79, "chunk_type": "semantic", "token_estimate": 403}
{"text": "60 Part II Quality Attributes | Chapter 4 Availability: In practice, the states of the active \nand standby components are periodically compared to ensure synchronization. This \ncomparison may be based on a cyclic redundancy check calculation (checksum) or, for \nsystems providing safety-critical services, a message digest calculation (a one-way hash \nfunction). When used alongside the passive redundancy version of the redundant spare \ntactic, state resynchronization is based solely on periodic state information transmitted \nfrom the active component(s) to the standby component(s), typically via checkpointing. \u25a0Escalating restart. This reintroduction tactic allows the system to recover from faults \nby varying the granularity of the component(s) restarted and minimizing the level of \nservice affectation. For example, consider a system that supports four levels of restart, \nnumbered 0\u20133. The lowest level of restart (Level 0) has the least impact on services and", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 79", "position": 79, "chunk_type": "semantic", "token_estimate": 138}
{"text": "4.2 Tactics for Availability 61: employs passive redundancy (warm spare), where all child threads of the faulty com-\nponent are killed and recreated. In this way, only data associated with the child threads \nis freed and reinitialized. The next level of restart (Level 1) frees and reinitializes all \nunprotected memory; protected memory is untouched. The next level of restart (Level 2) \nfrees and reinitializes all memory, both protected and unprotected, forcing all applica-\ntions to reload and reinitialize. The final level of restart (Level 3) involves completely \nreloading and reinitializing the executable image and associated data segments. Support \nfor the escalating restart tactic is particularly useful for the concept of graceful deg-\nradation, where a system is able to degrade the services it provides while maintaining \nsupport for mission-critical or safety-critical applications. \u25a0Nonstop forwarding. This concept originated in router design, and assumes that func-\ntionality is split into two parts: the supervisory or control plane (which manages con-\nnectivity and routing information) and the data plane (which does the actual work of \nrouting packets from sender to receiver). If a router experiences the failure of an active \nsupervisor, it can continue forwarding packets along known routes\u2014with neighboring \nrouters\u2014while the routing protocol information is recovered and validated. When the \ncontrol plane is restarted, it implements a \u201cgraceful restart,\u201d incrementally rebuilding its \nrouting protocol database even as the data plane continues to operate.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 80", "position": 80, "chunk_type": "semantic", "token_estimate": 231}
{"text": "revent Faults: Instead of detecting faults and then trying to recover from them, what if your system could \nprevent them from occurring in the first place? Although it might sound as if some measure \nof clairvoyance would be required, it turns out that in many cases it is possible to do just that.2\n \n\u25a0Removal from service. This tactic refers to temporarily placing a system component \nin an out-of-service state for the purpose of mitigating potential system failures. For \nexample, a component of a system might be taken out of service and reset to scrub latent \nfaults (such as memory leaks, fragmentation, or soft errors in an unprotected cache) \nbefore the accumulation of faults reaches the service-affecting level, resulting in system \nfailure. Other terms for this tactic are software rejuvenation and therapeutic reboot. If \nyou reboot your computer every night, you are practicing removal from service. \u25a0Transactions. Systems targeting high-availability services leverage transactional seman-\ntics to ensure that asynchronous messages exchanged between distributed components \nare atomic, consistent, isolated, and durable\u2014properties collectively referred to as \nthe \u201cACID properties.\u201d The most common realization of the transactions tactic is the \n\u201ctwo-phase commit\u201d (2PC) protocol. This tactic prevents race conditions caused by two \nprocesses attempting to update the same data item at the same time. 2. These tactics deal with runtime means to prevent faults from occurring. Of course, an excellent way to prevent \nfaults\u2014at least in the system you\u2019re building, if not in systems that your system must interact with\u2014is to produce \nhigh-quality code. This can be done by means of code inspections, pair programming, solid requirements reviews, \nand a host of other good engineering practices.", "domains": ["Design Patterns", "Design Principles", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 80", "position": 80, "chunk_type": "semantic", "token_estimate": 272}
{"text": "62 Part II Quality Attributes | Chapter 4 Availability: \u25a0Predictive model. A predictive model, when combined with a monitor, is employed to \nmonitor the state of health of a system process to ensure that the system is operating \nwithin its nominal operating parameters, and to take corrective action when the system \nnears a critical threshold. The operational performance metrics monitored are used to \npredict the onset of faults; examples include the session establishment rate (in an HTTP \nserver), threshold crossing (monitoring high and low watermarks for some constrained, \nshared resource), statistics on the process state (e.g., in-service, out-of-service, under \nmaintenance, idle), and message queue length statistics. \u25a0Exception prevention. This tactic refers to techniques employed for the purpose of \npreventing system exceptions from occurring. The use of exception classes, which allows \na system to transparently recover from system exceptions, was discussed earlier. Other \nexamples of exception prevention include error-correcting code (used in telecommuni-\ncations), abstract data types such as smart pointers, and the use of wrappers to prevent \nfaults such as dangling pointers or semaphore access violations. Smart pointers prevent \nexceptions by doing bounds checking on pointers, and by ensuring that resources are \nautomatically de-allocated when no data refers to them, thereby avoiding resource leaks. \u25a0Increase competence set. A program\u2019s competence set is the set of states in which it is \n\u201ccompetent\u201d to operate. For example, the state when the denominator is zero is outside \nthe competence set of most divide programs. When a component raises an exception, it \nis signaling that it has discovered itself to be outside its competence set; in essence, it \ndoesn\u2019t know what to do and is throwing in the towel. Increasing a component\u2019s compe-\ntence set means designing it to handle more cases\u2014faults\u2014as part of its normal oper-\nation. For example, a component that assumes it has access to a shared resource might \nthrow an exception if it discovers that access is blocked. Another component might \nsimply wait for access or return immediately with an indication that it will complete its \noperation on its own the next time it does have access. In this example, the second com-\nponent has a larger competence set than the first. 4.3  \nTactics-Based Questionnaire for Availability\nBased on the tactics described in Section 4.2, we can create a set of availability tactics\u2013inspired \nquestions, as presented in Table 4.3.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 81", "position": 81, "chunk_type": "semantic", "token_estimate": 389}
{"text": "62 Part II Quality Attributes | Chapter 4 Availability: In this example, the second com-\nponent has a larger competence set than the first. 4.3  \nTactics-Based Questionnaire for Availability\nBased on the tactics described in Section 4.2, we can create a set of availability tactics\u2013inspired \nquestions, as presented in Table 4.3. To gain an overview of the architectural choices made to \nsupport availability, the analyst asks each question and records the answers in the table. The \nanswers to these questions can then be made the focus of further activities: investigation of \ndocumentation, analysis of code or other artifacts, reverse engineering of code, and so forth.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 81", "position": 81, "chunk_type": "semantic", "token_estimate": 105}
{"text": "4.3 Tactics-Based Questionnaire for Availability 63: TABLE 4.3 Tactics-Based Questionnaire for Availability\nTactics \nGroup\nTactics Question\nSupport? (Y/N)\nRisk\nDesign \nDecisions \nand \nLocation\nRationale \nand \nAssumptions\nDetect Faults\nDoes the system use ping/\necho to detect failure of a \ncomponent or connection, or \nnetwork congestion? Does the system use a \ncomponent to monitor the \nstate of health of other parts \nof the system? A system \nmonitor can detect failure or \ncongestion in the network or \nother shared resources, such \nas from a denial-of-service \nattack. Does the system use a \nheartbeat\u2014a periodic \nmessage exchange between \na system monitor and a \nprocess\u2014to detect failure of a \ncomponent or connection, or \nnetwork congestion? Does the system use a \ntimestamp to detect incorrect \nsequences of events in \ndistributed systems? Does the system use voting \nto check that replicated \ncomponents are producing the \nsame results? The replicated components \nmay be identical replicas, \nfunctionally redundant, or \nanalytically redundant. Does the system use \nexception detection to detect \na system condition that alters \nthe normal flow of execution \n(e.g., system exception, \nparameter fence, parameter \ntyping, timeout)? Can the system do a self-\ntest to test itself for correct \noperation? continues", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 82", "position": 82, "chunk_type": "semantic", "token_estimate": 192}
{"text": "64 Part II Quality Attributes | Chapter 4 Availability: Tactics \nGroup\nTactics Question\nSupport? (Y/N)\nRisk\nDesign \nDecisions \nand \nLocation\nRationale \nand \nAssumptions\nRecover \nfrom Faults \n(Preparation \nand Repair)\nDoes the system employ \nredundant spares? Is a component\u2019s role as active \nversus spare fixed, or does it \nchange in the presence of a \nfault? What is the switchover \nmechanism? What is the \ntrigger for a switchover? How \nlong does it take for a spare to \nassume its duties? Does the system employ \nexception handling to deal \nwith faults? Typically the handling involves \neither reporting, correcting, or \nmasking the fault. Does the system employ \nrollback, so that it can revert \nto a previously saved good \nstate (the \u201crollback line\u201d) in the \nevent of a fault? Can the system perform in-\nservice software upgrades to \nexecutable code images in a \nnon-service-affecting manner? Does the system systemat-\nically retry in cases where \nthe component or connection \nfailure may be transient? Can the system simply \nignore faulty behavior (e.g., \nignore messages when it \nis determined that those \nmessages are spurious)? Does the system have a policy \nof degradation when resources \nare compromised, maintain-\ning the most critical system \nfunctions in the presence of \ncomponent failures, and drop-\nping less critical functions? Does the system have \nconsistent policies \nand mechanisms for \nreconfiguration after failures, \nreassigning responsibilities to \nthe resources left functioning, \nwhile maintaining as much \nfunctionality as possible? TABLE 4.3 Tactics-Based Questionnaire for Availability continued", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 83", "position": 83, "chunk_type": "semantic", "token_estimate": 240}
{"text": "4.3 Tactics-Based Questionnaire for Availability 65: Tactics \nGroup\nTactics Question\nSupport? (Y/N)\nRisk\nDesign \nDecisions \nand \nLocation\nRationale \nand \nAssumptions\nRecover \nfrom Faults \n(Reintroduction)\nCan the system operate \na previously failed or in-\nservice upgraded component \nin a \u201cshadow mode\u201d for \na predefined time prior to \nreverting the component back \nto an active role? If the system uses active \nor passive redundancy, \ndoes it also employ state \nresynchronization to send \nstate information from active \ncomponents to standby \ncomponents? Does the system employ \nescalating restart to recover \nfrom faults by varying the \ngranularity of the component(s) \nrestarted and minimizing the \nlevel of service affected? Can message processing and \nrouting portions of the system \nemploy nonstop forwarding, \nwhere functionality is split into \nsupervisory and data planes? Prevent Faults\nCan the system remove \ncomponents from service, \ntemporarily placing a system \ncomponent in an out-of-\nservice state for the purpose \nof preempting potential system \nfailures? Does the system employ \ntransactions\u2014bundling state \nupdates so that asynchronous \nmessages exchanged between \ndistributed components are \natomic, consistent, isolated, \nand durable? Does the system use a \npredictive model to monitor \nthe state of health of a \ncomponent to ensure that the \nsystem is operating within \nnominal parameters? When conditions are detected \nthat are predictive of likely \nfuture faults, the model initiates \ncorrective action.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 84", "position": 84, "chunk_type": "semantic", "token_estimate": 214}
{"text": "66 Part II Quality Attributes | Chapter 4 Availability: 4.4  \nPatterns for Availability\nThis section presents a few of the most important architectural patterns for availability. The first three patterns are all centered on the redundant spare tactic, and will be described \nas a group. They differ primarily in the degree to which the backup components\u2019 state matches \nthat of the active component. (A special case occurs when the components are stateless, in which \ncase the first two patterns become identical.) \u25a0Active redundancy (hot spare). For stateful components, this refers to a configuration in \nwhich all of the nodes (active or redundant spare) in a protection group3 receive and pro-\ncess identical inputs in parallel, allowing the redundant spare(s) to maintain a synchro-\nnous state with the active node(s). Because the redundant spare possesses an identical \nstate to the active processor, it can take over from a failed component in a matter of \nmilliseconds. The simple case of one active node and one redundant spare node is com-\nmonly referred to as one-plus-one redundancy. Active redundancy can also be used for \nfacilities protection, where active and standby network links are used to ensure highly \navailable network connectivity. \u25a0Passive redundancy (warm spare). For stateful components, this refers to a configuration \nin which only the active members of the protection group process input traffic. One of \ntheir duties is to provide the redundant spare(s) with periodic state updates. Because the \nstate maintained by the redundant spares is only loosely coupled with that of the active \nnode(s) in the protection group (with the looseness of the coupling being a function of \nthe period of the state updates), the redundant nodes are referred to as warm spares. Passive redundancy provides a solution that achieves a balance between the more highly \navailable but more compute-intensive (and expensive) active redundancy pattern and the \nless available but significantly less complex cold spare pattern (which is also signifi-\ncantly cheaper). \u25a0Spare (cold spare). Cold sparing refers to a configuration in which redundant spares \nremain out of service until a failover occurs, at which point a power-on-reset4 procedure \nis initiated on the redundant spare prior to its being placed in service. Due to its poor \nrecovery performance, and hence its high mean time to repair, this pattern is poorly \nsuited to systems having high-availability requirements.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 85", "position": 85, "chunk_type": "semantic", "token_estimate": 386}
{"text": "66 Part II Quality Attributes | Chapter 4 Availability: Cold sparing refers to a configuration in which redundant spares \nremain out of service until a failover occurs, at which point a power-on-reset4 procedure \nis initiated on the redundant spare prior to its being placed in service. Due to its poor \nrecovery performance, and hence its high mean time to repair, this pattern is poorly \nsuited to systems having high-availability requirements. Benefits:\n \n\u25a0The benefit of a redundant spare is a system that continues to function correctly after \nonly a brief delay in the presence of a failure. The alternative is a system that stops \nfunctioning correctly, or stops functioning altogether, until the failed component is \nrepaired. This repair could take hours or days. 3. A protection group is a group of processing nodes in which one or more nodes are \u201cactive,\u201d with the remaining \nnodes serving as redundant spares. 4. A power-on-reset ensures that a device starts operating in a known state.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 85", "position": 85, "chunk_type": "semantic", "token_estimate": 161}
{"text": "4.4 Patterns for Availability 67: Tradeoffs:\n \n\u25a0The tradeoff with any of these patterns is the additional cost and complexity incurred \nin providing a spare. \u25a0The tradeoff among the three alternatives is the time to recover from a failure versus \nthe runtime cost incurred to keep a spare up-to-date. A hot spare carries the highest \ncost but leads to the fastest recovery time, for example. Other patterns for availability include the following. \u25a0Triple modular redundancy (TMR). This widely used implementation of the voting tactic \nemploys three components that do the same thing. Each component receives identi-\ncal inputs and forwards its output to the voting logic, which detects any inconsistency \namong the three output states. Faced with an inconsistency, the voter reports a fault. It must also decide which output to use, and different instantiations of this pattern use \ndifferent decision rules. Typical choices are letting the majority rule or choosing some \ncomputed average of the disparate outputs. Of course, other versions of this pattern that employ 5 or 19 or 53 redundant compo-\nnents are also possible. However, in most cases, 3 components are sufficient to ensure a \nreliable result. Benefits:\n \n\u25a0TMR is simple to understand and to implement. It is blissfully independent of what \nmight be causing disparate results, and is only concerned about making a reasonable \nchoice so that the system can continue to function. Tradeoffs:\n \n\u25a0There is a tradeoff between increasing the level of replication, which raises the cost, \nand the resulting availability. In systems employing TMR, the statistical likelihood of \ntwo or more components failing is vanishingly small, and three components represents \na sweet spot between availability and cost. \u25a0Circuit breaker. A commonly used availability tactic is retry. In the event of a timeout or \nfault when invoking a service, the invoker simply tries again\u2014and again, and again. A \ncircuit breaker keeps the invoker from trying countless times, waiting for a response that \nnever comes. In this way, it breaks the endless retry cycle when it deems that the system \nis dealing with a fault. That\u2019s the signal for the system to begin handling the fault. Until \nthe circuit break is \u201creset,\u201d subsequent invocations will return immediately without pass-\ning along the service request. Benefits:\n \n\u25a0This pattern can remove from individual components the policy about how many \nretries to allow before declaring a failure.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 86", "position": 86, "chunk_type": "semantic", "token_estimate": 388}
{"text": "4.4 Patterns for Availability 67: Until \nthe circuit break is \u201creset,\u201d subsequent invocations will return immediately without pass-\ning along the service request. Benefits:\n \n\u25a0This pattern can remove from individual components the policy about how many \nretries to allow before declaring a failure. \u25a0At worst, endless fruitless retries would make the invoking component as useless as \nthe invoked component that has failed. This problem is especially acute in distributed \nsystems, where you could have many callers calling an unresponsive component and \neffectively going out of service themselves, causing the failure to cascade across the", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 86", "position": 86, "chunk_type": "semantic", "token_estimate": 94}
{"text": "68 Part II Quality Attributes | Chapter 4 Availability: whole system. The circuit breaker, in conjunction with software that listens to it and \nbegins recovery procedures, prevents that problem. Tradeoffs:\n \n\u25a0Care must be taken in choosing timeout (or retry) values. If the timeout is too long, \nthen unnecessary latency is added. But if the timeout is too short, then the circuit \nbreaker will be tripping when it does not need to\u2014a kind of \u201cfalse positive\u201d\u2014which \ncan lower the availability and performance of these services. Other availability patterns that are commonly used include the following:\n \n\u25a0Process pairs. This pattern employs checkpointing and rollback. In case of failure, the \nbackup has been checkpointing and (if necessary) rolling back to a safe state, so is ready \nto take over when a failure occurs. \u25a0Forward error recovery. This pattern provides a way to get out of an undesirable state \nby moving forward to a desirable state. This often relies upon built-in error-correction \ncapabilities, such as data redundancy, so that errors may be corrected without the need \nto fall back to a previous state or to retry. Forward error recovery finds a safe, possibly \ndegraded state from which the operation can move forward. 4.5  \nFor Further Reading\nPatterns for availability:\n \n\u25a0You can read about patterns for fault tolerance in [Hanmer 13]. General tactics for availability:\n \n\u25a0A more detailed discussion of some of the availability tactics in this chapter is given in \n[Scott 09]. This is the source of much of the material in this chapter. \u25a0The Internet Engineering Task Force has promulgated a number of standards support-\ning availability tactics. These standards include Non-Stop Forwarding [IETF 2004], \nPing/Echo (ICMP [IETF 1981] or ICMPv6 [RFC 2006b] Echo Request/Response), and \nMPLS (LSP Ping) networks [IETF 2006a]. Tactics for availability\u2014fault detection:\n \n\u25a0Triple modular redundancy (TMR) was developed in the early 1960s by Lyons [Lyons 62]. \u25a0The fault detection in the voting tactic is based on the fundamental contributions to \nautomata theory by Von Neumann, who demonstrated how systems having a prescribed \nreliability could be built from unreliable components [Von Neumann 56]. Tactics for availability\u2014fault recovery:\n \n\u25a0Standards-based realizations of active redundancy exist for protecting network \nlinks (i.e., facilities) at both the physical layer of the seven-layer OSI (Open Systems", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 87", "position": 87, "chunk_type": "semantic", "token_estimate": 370}
{"text": "4.6 Discussion Questions 69: Interconnection) model [Bellcore 98, 99; Telcordia 00] and the network/link layer \n[IETF 2005]. \u25a0Some examples of how a system can degrade through use (degradation) are given in \n[Nygard 18]. \u25a0Mountains of papers have been written about parameter typing, but [Utas 05] writes \nabout it in the context of availability (as opposed to bug prevention, its usual context). [Utas 05] has also written about escalating restart. \u25a0Hardware engineers often use preparation and repair tactics. Examples include error \ndetection and correction (EDAC) coding, forward error correction (FEC), and temporal \nredundancy. EDAC coding is typically used to protect control memory structures in \nhigh-availability distributed real-time embedded systems [Hamming 80]. Conversely, \nFEC coding is typically employed to recover from physical layer errors occurring in \nexternal network links [Morelos-Zaragoza 06]. Temporal redundancy involves sampling \nspatially redundant clock or data lines at time intervals that exceed the pulse width of \nany transient pulse to be tolerated, and then voting out any defects detected [Mavis 02]. Tactics for availability\u2014fault prevention:\n \n\u25a0Parnas and Madey have written about increasing an element\u2019s competence set [Parnas 95]. \u25a0The ACID properties, important in the transactions tactic, were introduced by Gray in \nthe 1970s and discussed in depth in [Gray 93]. Disaster recovery:\n \n\u25a0A disaster  \nis an event such as an earthquake, flood, or hurricane that destroys an \nentire data center. The U.S. National Institute of Standards and Technology (NIST) \nidentifies eight different types of plans that should be considered in the event of a \ndisaster, See Section 2.2 of NIST Special Publication 800-34, Contingency Planning \nGuide for Federal Information Systems, https://nvlpubs.nist.gov/nistpubs/Legacy/SP/\nnistspecialpublication800-34r1.pdf. 4.6  \nDiscussion Questions\n1. Write a set of concrete scenarios for availability using each of the possible responses in \nthe general scenario. 2. Write a concrete availability scenario for the software for a (hypothetical) driverless car. 3. Write a concrete availability scenario for a program like Microsoft Word. 4. Redundancy is a key strategy for achieving high availability. Look at the patterns and \ntactics presented in this chapter and decide how many of them exploit some form of \nredundancy and how many do not. 5. How does availability trade off against modifiability and deployability? How would you \nmake a change to a system that is required to have 24/7 availability (i.e., no scheduled or \nunscheduled down time, ever)?", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 88", "position": 88, "chunk_type": "semantic", "token_estimate": 382}
{"text": "70 Part II Quality Attributes | Chapter 4 Availability: 6. Consider the fault detection tactics (ping/echo, heartbeat, system monitor, voting, and \nexception detection). What are the performance implications of using these tactics? 7. Which tactics are used by a load balancer (see Chapter 17) when it detects a failure of an \ninstance? 8. Look up recovery point objective (RPO) and recovery time objective (RTO), and explain \nhow these can be used to set a checkpoint interval when using the rollback tactic.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 89", "position": 89, "chunk_type": "semantic", "token_estimate": 81}
{"text": "71: 5\n \nDeployability\nFrom the day we arrive on the planet \nAnd blinking, step into the sun \nThere\u2019s more to be seen than can ever be seen \nMore to do than can ever be done\n\u2014The Lion King\nThere comes a day when software, like the rest of us, must leave home and venture out into \nthe world and experience real life. Unlike the rest of us, software typically makes the trip \nmany times, as changes and updates are made. This chapter is about making that transition as \norderly and as effective and\u2014most of all\u2014as rapid as possible. That is the realm of continu-\nous deployment, which is most enabled by the quality attribute of deployability. Why has deployability come to take a front-row seat in the world of quality attributes? In the \u201cbad old days,\u201d releases were infrequent\u2014large numbers of changes were bun-\ndled into releases and scheduled. A release would contain new features and bug fixes. One \nrelease per month, per quarter, or even per year was common. Competitive pressures in many \ndomains\u2014with the charge being led by e-commerce\u2014resulted in a need for much shorter \nrelease cycles. In these contexts, releases can occur at any time\u2014possibly hundreds of releases \nper day\u2014and each can be instigated by a different team within an organization. Being able to \nrelease frequently means that bug fixes in particular do not have to wait until the next sched-\nuled release, but rather can be made and released as soon as a bug is discovered and fixed. It also means that new features do not need to be bundled into a release, but can be put into \nproduction at any time. This is not desirable, or even possible, in all domains. If your software exists in a complex \necosystem with many dependencies, it may not be possible to release just one part of it without \ncoordinating that release with the other parts. In addition, many embedded systems, systems \nin hard-to-access locations, and systems that are not networked would be poor candidates for a \ncontinuous deployment mindset. This chapter focuses on the large and growing numbers of systems for which just-in-time \nfeature releases are a significant competitive advantage, and just-in-time bug fixes are essen-\ntial to safety or security or continuous operation. Often these systems are microservice and \ncloud-based, although the techniques here are not limited to those technologies.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 90", "position": 90, "chunk_type": "semantic", "token_estimate": 393}
{"text": "72 Part II Quality Attributes | Chapter 5 Deployability: 5.1  \nContinuous Deployment\nDeployment is a process that starts with coding and ends with real users interacting with the sys-\ntem in a production environment. If this process is fully automated\u2014that is, if there is no human \nintervention\u2014then it is called continuous deployment. If the process is automated up to the point \nof placing (portions of) the system into production and human intervention is required (perhaps \ndue to regulations or policies) for this final step, the process is called continuous delivery. To speed up releases, we need to introduce the concept of a deployment pipeline: the \nsequence of tools and activities that begin when you check your code into a version control \n \nsystem and end when your application has been deployed for users to send it requests. In \nbetween those points, a series of tools integrate and automatically test the newly committed \ncode, test the integrated code for functionality, and test the application for concerns such as \nperformance under load, security, and license compliance. Each stage in the deployment pipeline takes place in an environment established to sup-\nport isolation of the stage and perform the actions appropriate to that stage. The major envi-\nronments are as follows:\n \n\u25a0Code is developed in a development environment for a single module where it is subject \nto standalone unit tests. Once it passes the tests, and after appropriate review, the code is \ncommitted to a version control system that triggers the build activities in the integration \nenvironment. \u25a0An integration environment builds an executable version of your service. A continuous \nintegration server compiles1 your new or changed code, along with the latest compatible \nversions of code for other portions of your service and constructs an executable image \nfor your service.2 Tests in the integration environment include the unit tests from the \nvarious modules (now run against the built system), as well as integration tests designed \nspecifically for the whole system. When the various tests are passed, the built service is \npromoted to the staging environment. \u25a0A staging environment tests for various qualities of the total system. These include perfor-\nmance testing, security testing, license conformance checks, and possibly user testing. For \nembedded systems, this is where simulators of the physical environment (feeding synthetic \ninputs to the system) are brought to bear.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 91", "position": 91, "chunk_type": "semantic", "token_estimate": 386}
{"text": "72 Part II Quality Attributes | Chapter 5 Deployability: These include perfor-\nmance testing, security testing, license conformance checks, and possibly user testing. For \nembedded systems, this is where simulators of the physical environment (feeding synthetic \ninputs to the system) are brought to bear. An application that passes all staging environ-\nment tests\u2014which may include field testing\u2014is deployed to the production environment, \nusing either a blue/green model or a rolling upgrade (see Section 5.6). In some cases, par-\ntial deployments are used for quality control or to test the market response to a proposed \nchange or offering. \u25a0Once in the production environment, the service is monitored closely until all parties \nhave some level of confidence in its quality. At that point, it is considered a normal part \nof the system and receives the same amount of attention as the other parts of the system. 1. If you are developing software using an interpreted language such as Python or JavaScript, there is no compila-\ntion step. 2. In this chapter, we use the term \u201cservice\u201d to denote any independently deployable unit.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 91", "position": 91, "chunk_type": "semantic", "token_estimate": 180}
{"text": "5.1 Continuous Deployment 73: You perform a different set of tests in each environment, expanding the testing scope \nfrom unit testing of a single module in the development environment, to functional testing of \nall the components that make up your service in the integration environment, and ending \nwith broad quality testing in the staging environment and usage monitoring in the production \nenvironment. But not everything always goes according to plan. If you find problems after the software \nis in its production environment, it is often necessary to roll back to a previous version while \nthe defect is being addressed. Architectural choices affect deployability. For example, by employing the microservice \narchitecture pattern (see Section 5.6), each team responsible for a microservice can make its \nown technology choices; this removes incompatibility problems that would previously have \nbeen discovered at integration time (e.g., incompatible choices of which version of a library to \nuse). Since microservices are independent services, such choices do not cause problems. Similarly, a continuous deployment mindset forces you to think about the testing infra-\nstructure earlier in the development process. This is necessary because designing for contin-\nuous deployment requires continuous automated testing. In addition, the need to be able to \nroll back or disable features leads to architectural decisions about mechanisms such as feature \ntoggles and backward compatibility of interfaces. These decisions are best taken early on. The Effect of Virtualization on the Different Environments\nBefore the widespread use of virtualization technology, the environments that we describe \nhere were physical facilities. In most organizations, the development, integration, and \nstaging environments comprised hardware and software procured and operated by \ndifferent groups. The development environment might consist of a few desktop com-\nputers that the development team repurposed as servers. The integration environment \nwas operated by the test or quality-assurance team, and might consist of some racks, \npopulated with previous-generation equipment from the data center. The staging envi-\nronment was operated by the operations team and might have hardware similar to that \nused in production. A lot of time was spent trying to figure out why a test that passed in one environment \nfailed in another environment. One benefit of environments that employ virtualization is \nthe ability to have environment parity, where environments may differ in scale but not in \ntype of hardware or fundamental structure.", "domains": ["Architectural Patterns and Styles", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 92", "position": 92, "chunk_type": "semantic", "token_estimate": 385}
{"text": "74 Part II Quality Attributes | Chapter 5 Deployability: [Bass 15]\nImplementing DevOps is a process improvement effort. DevOps encompasses not \nonly the cultural and organizational elements of any process improvement effort, but \nalso a strong reliance on tools and architectural design. All environments are different, \nof course, but the tools and automation we describe are found in the typical tool chains \nbuilt to support DevOps. The continuous deployment strategy we describe here is the conceptual heart of \nDevOps. Automated testing is, in turn, a critically important ingredient of continuous \ndeployment, and the tooling for that often represents the highest technological hurdle \nfor DevOps. Some forms of DevOps include logging and post-deployment monitoring of \nthose logs, for automatic detection of errors back at the \u201chome office,\u201d or even moni-\ntoring to understand the user experience. This, of course, requires a \u201cphone home\u201d or \nlog delivery capability in the system, which may or may not be possible or allowable in \nsome systems.", "domains": ["Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 93", "position": 93, "chunk_type": "semantic", "token_estimate": 161}
{"text": "5.2 Deployability 75: DevSecOps is a flavor of DevOps that incorporates approaches for security (for the \ninfrastructure and for the applications it produces) into the entire process. DevSecOps \nis increasingly popular in aerospace and defense applications, but is also valid in any \napplication area where DevOps is useful and a security breach would be particularly \ncostly. Many IT applications fall in this category. 5.2  \nDeployability\nDeployability refers to a property of software indicating that it may be deployed\u2014that is, \n \nallocated to an environment for execution\u2014within a predictable and acceptable amount of \ntime and effort. Moreover, if the new deployment is not meeting its specifications, it may \nbe rolled back, again within a predictable and acceptable amount of time and effort. As the \nworld moves increasingly toward virtualization and cloud infrastructures, and as the scale of \ndeployed software-intensive systems inevitably increases, it is one of the architect\u2019s respon-\nsibilities to ensure that deployment is done in an efficient and predictable way, minimizing \noverall system risk.3\nTo achieve these goals, an architect needs to consider how an executable is updated on \na host platform, and how it is subsequently invoked, measured, monitored, and controlled. Mobile systems in particular present a challenge for deployability in terms of how they are \nupdated because of concerns about bandwidth. Some of the issues involved in deploying soft-\nware are as follows:\n \n\u25a0How does it arrive at its host (i.e., push, where updates deployed are unbidden, or pull, \nwhere users or administrators must explicitly request updates)? \u25a0How is it integrated into an existing system? Can this be done while the existing system \nis executing? \u25a0What is the medium, such as DVD, USB drive, or Internet delivery? \u25a0What is the packaging (e.g., executable, app, plug-in)? \u25a0What is the resulting integration into an existing system? \u25a0What is the efficiency of executing the process? \u25a0What is the controllability of the process? With all of these concerns, the architect must be able to assess the associated risks. Architects are primarily concerned with the degree to which the architecture supports deploy-\nments that are:\n \n\u25a0Granular. Deployments can be of the whole system or of elements within a system. If the \narchitecture provides options for finer granularity of deployment, then certain risks can \nbe reduced. 3.", "domains": ["Software Quality Attributes", "Domain-Driven Design"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 94", "position": 94, "chunk_type": "semantic", "token_estimate": 373}
{"text": "5.2 Deployability 75: If the \narchitecture provides options for finer granularity of deployment, then certain risks can \nbe reduced. 3. The quality attribute of testability (see Chapter 12) certainly plays a critical role in continuous deployment, and \nthe architect can provide critical support for continuous deployment by ensuring that the system is testable, in all the \nways just mentioned. However, our concern here is the quality attribute directly related to continuous deployment \nover and above testability: deployability.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 94", "position": 94, "chunk_type": "semantic", "token_estimate": 77}
{"text": "76 Part II Quality Attributes | Chapter 5 Deployability: \u25a0Controllable. The architecture should provide the capability to deploy at varying levels \nof granularity, monitor the operation of the deployed units, and roll back unsuccessful \ndeployments. \u25a0Efficient. The architecture should support rapid deployment (and, if needed, rollback) \nwith a reasonable level of effort. These characteristics will be reflected in the response measures of the general scenario \nfor deployability. 5.3  \nDeployability General Scenario\nTable 5.1 enumerates the elements of the general scenario that characterize deployability. TABLE 5.1 General Scenario for Deployability\nPortion of Scenario\nDescription\nPossible Values\nSource\nThe trigger for the \ndeployment\nEnd user, developer, system administrator, \noperations personnel, component \nmarketplace, product owner. Stimulus\nWhat causes the trigger\nA new element is available to be deployed. This is typically a request to replace a \nsoftware element with a new version (e.g., \nfix a defect, apply a security patch, upgrade \nto the latest release of a component or \nframework, upgrade to the latest version of \nan internally produced element). New element is approved for incorporation. An existing element/set of elements needs \nto be rolled back. Artifacts\nWhat is to be changed\nSpecific components or modules, the \nsystem\u2019s platform, its user interface, its \nenvironment, or another system with which \nit interoperates. Thus the artifact might be a \nsingle software element, multiple software \nelements, or the entire system. Environment\nStaging, production (or a \nspecific subset of either)\nFull deployment. Subset deployment to a specified portion of \nusers, VMs, containers, servers, platforms. Response\nWhat should happen\nIncorporate the new components. Deploy the new components. Monitor the new components. Roll back a previous deployment.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 95", "position": 95, "chunk_type": "semantic", "token_estimate": 268}
{"text": "5.3 Deployability General Scenario 77: Portion of Scenario\nDescription\nPossible Values\nResponse measure\nA measure of cost, time, or \nprocess effectiveness for a \ndeployment, or for a series \nof deployments over time\nCost in terms of:\n \n\u25a0\nNumber, size, and complexity of \naffected artifacts\n \n\u25a0\nAverage/worst-case effort\n \n\u25a0\nElapsed clock or calendar time\n \n\u25a0\nMoney (direct outlay or opportunity cost)\n \n\u25a0\nNew defects introduced\nExtent to which this deployment/rollback \naffects other functions or quality attributes. Number of failed deployments. Repeatability of the process. Traceability of the process. Cycle time of the process. Figure 5.1 illustrates a concrete deployability scenario: \u201cA new release of an authentication/\nauthorization service (which our product uses) is made available in the component marketplace \nand the product owner decides to incorporate this version into the release. The new service is \ntested and deployed to the production environment within 40 hours of elapsed time and no \nmore than 120 person-hours of effort. The deployment introduces no defects and no SLA is \nviolated.\u201d\nStimulus\nResponse\nResponse\nMeasure\nSource\n3\n2\n1\n4\nEnvironment\nArtifact\nComponent\nmarketplace\nNew release of the\nauthentication/authorization\nservice is made available \nand the product owner \ndecides to incorporate it\nProduction\nThe new service is\ntested in-house\nand deployed to\nproduction servers\nWithin 40 hours and \nno more than 120 \nperson-hours of effort\nNo defects introduced\nno SLA violated\nAuthentication/authorization\nservice\n \n; \n \nFIGURE 5.1 Sample concrete deployability scenario", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 96", "position": 96, "chunk_type": "semantic", "token_estimate": 233}
{"text": "78 Part II Quality Attributes | Chapter 5 Deployability: 5.4  \nTactics for Deployability\nA deployment is catalyzed by the release of a new software or hardware element. The deploy-\nment is successful if these new elements are deployed within acceptable time, cost, and quality \nconstraints. We illustrate this relationship\u2014and hence the goal of deployability tactics\u2014in \nFigure 5.2. New elements\narrive\nElements deployed\nwithin time, cost, and \nquality constraints\nTactics\nto Control\nResponse\nFIGURE 5.2 Goal of deployability tactics\nThe tactics for deployability are shown in Figure 5.3. In many cases, these tactics will be \nprovided, at least in part, by a CI/CD (continuous integration/continuous deployment) infra-\nstructure that you buy rather than build. In such a case, your job as an architect is often one of \nchoosing and assessing (rather than implementing) the right deployability tactics and the right \ncombination of tactics. Deployability Tactics\nScale Rollouts\nScript Deployment Commands\nRollback\nManage Service Interactions\nPackage Dependencies\nToggle Features\nManage Deployed System\nManage Deployment Pipeline\nFIGURE 5.3 Deployability tactics", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 97", "position": 97, "chunk_type": "semantic", "token_estimate": 167}
{"text": "5.4 Tactics for Deployability 79: Next, we describe these six deployability tactics in more detail. The first category \nof deployability tactics focuses on strategies for managing the deployment pipeline, and the \nsecond category deals with managing the system as it is being deployed and once it has been \ndeployed. Manage Deployment Pipeline\n \n\u25a0Scale rollouts. Rather than deploying to the entire user base, scaled rollouts deploy a \nnew version of a service gradually, to controlled subsets of the user population, often \nwith no explicit notification to those users. (The remainder of the user base continues \nto use the previous version of the service.) By gradually releasing, the effects of new \ndeployments can be monitored and measured and, if necessary, rolled back. This tactic \nminimizes the potential negative impact of deploying a flawed service. It requires an \narchitectural mechanism (not part of the service being deployed) to route a request from \na user to either the new or old service, depending on that user\u2019s identity. \u25a0Roll back. If it is discovered that a deployment has defects or does not meet user expec-\ntations, then it can be \u201crolled back\u201d to its prior state. Since deployments may involve \nmultiple coordinated updates of multiple services and their data, the rollback mechanism \nmust be able to keep track of all of these, or must be able to reverse the consequences of \nany update made by a deployment, ideally in a fully automated fashion. \u25a0Script deployment commands. Deployments are often complex and require many steps to \nbe carried out and orchestrated precisely. For this reason, deployment is often scripted. These deployment scripts should be treated like code\u2014documented, reviewed, tested, \nand version controlled. A scripting engine executes the deployment script automatically, \nsaving time and minimizing opportunities for human error. Manage Deployed System\n \n\u25a0Manage service interactions. This tactic accommodates simultaneous deployment and \nexecution of multiple versions of system services. Multiple requests from a client could \nbe directed to either version in any sequence. Having multiple versions of the same \nservice in operation, however, may introduce version incompatibilities. In such cases, the \ninteractions between services need to be mediated so that version incompatibilities are \nproactively avoided. This tactic is a resource management strategy, obviating the need to \ncompletely replicate the resources so as to separately deploy the old and new versions. \u25a0Package dependencies.", "domains": ["Design Patterns", "Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 98", "position": 98, "chunk_type": "semantic", "token_estimate": 384}
{"text": "5.4 Tactics for Deployability 79: This tactic is a resource management strategy, obviating the need to \ncompletely replicate the resources so as to separately deploy the old and new versions. \u25a0Package dependencies. This tactic packages an element together with its dependencies \nso that they get deployed together and so that the versions of the dependencies are con-\nsistent as the element moves from development into production. The dependencies may \ninclude libraries, OS versions, and utility containers (e.g., sidecar, service mesh), which \nwe will discuss in Chapter 9. Three means of packaging dependencies are using contain-\ners, pods, or virtual machines; these are discussed in more detail in Chapter 16.", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 98", "position": 98, "chunk_type": "semantic", "token_estimate": 109}
{"text": "80 Part II Quality Attributes | Chapter 5 Deployability: \u25a0Feature toggle. Even when your code is fully tested, you might encounter issues after \ndeploying new features. For that reason, it is convenient to be able to integrate a \u201ckill \nswitch\u201d (or feature toggle) for new features. The kill switch automatically disables a \nfeature in your system at runtime, without forcing you to initiate a new deployment. This \nprovides the ability to control deployed features without the cost and risk of actually \nredeploying services. 5.5  \nTactics-Based Questionnaire for Deployability\n \nBased on the tactics described in Section 5.4, we can create a set of deployability tactics\u2013\ninspired questions, as presented in Table 5.2. To gain an overview of the architectural choices \nmade to support deployability, the analyst asks each question and records the answers in the \ntable. The answers to these questions can then be made the focus of subsequent activities: \ninvestigation of documentation, analysis of code or other artifacts, reverse engineering of \ncode, and so forth. TABLE 5.2 Tactics-Based Questionnaire for Deployability \nTactics \nGroups\nTactics Question\nSupported? (Y/N)\nRisk\nDesign \nDecisions \nand \nLocation\nRationale \nand \nAssumptions\nManage \ndeployment \npipeline\nDo you scale rollouts, rolling \nout new releases gradually (in \ncontrast to releasing in an all-\nor-nothing fashion)? Are you able to automatically \nroll back deployed services \nif you determine that they are \nnot operating in a satisfactory \nfashion? Do you script deployment \ncommands to automatically \nexecute complex sequences of \ndeployment instructions? Manage \ndeployed \nsystem\nDo you manage service \ninteractions so that \nmultiple versions of services \ncan be safely deployed \nsimultaneously? Do you package depen-\ndencies so that services are \ndeployed along with all of the \nlibraries, OS versions, and \nutility containers that they \ndepend on?", "domains": ["Design Patterns", "Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 99", "position": 99, "chunk_type": "semantic", "token_estimate": 284}
{"text": "5.6 Patterns for Deployability 81: Tactics \nGroups\nTactics Question\nSupported? (Y/N)\nRisk\nDesign \nDecisions \nand \nLocation\nRationale \nand \nAssumptions\nDo you employ feature \ntoggles to automatically \ndisable a newly released \nfeature (rather than rolling back \nthe newly deployed service) if \nthe feature is determined to be \nproblematic? 5.6  \nPatterns for Deployability\n \nPatterns for deployability can be organized into two categories. The first category contains pat-\nterns for structuring services to be deployed. The second category contains patterns for how \nto deploy services, which can be parsed into two broad subcategories: all-or-nothing or par-\ntial deployment. The two main categories for deployability are not completely independent of \neach other, because certain deployment patterns depend on certain structural properties of the \nservices. Patterns for Structuring Services\nMicroservice Architecture\nThe microservice architecture pattern structures the system as a collection of independently \ndeployable services that communicate only via messages through service interfaces. There is \nno other form of interprocess communication allowed: no direct linking, no direct reads of \nanother team\u2019s data store, no shared-memory model, no back-doors whatsoever. Services are \nusually stateless, and (because they are developed by a single relatively small team4) are rela-\ntively small\u2014hence the term microservice. Service dependencies are acyclic. An integral part \nof this pattern is a discovery service so that messages can be appropriately routed. Benefits:\n \n\u25a0Time to market is reduced. Since each service is small and independently deployable, \na modification to a service can be deployed without coordinating with teams that own \nother services. Thus, once a team completes its work on a new version of a service and \nthat version has been tested, it can be deployed immediately. 4. At Amazon, service teams are constrained in size by the \u201ctwo pizza rule\u201d: The team must be no larger than can \nbe fed by two pizzas.", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 100", "position": 100, "chunk_type": "semantic", "token_estimate": 299}
{"text": "82 Part II Quality Attributes | Chapter 5 Deployability: \u25a0Each team can make its own technology choices for its service, as long as the technology \nchoices support message passing. No coordination is needed with respect to library ver-\nsions or programming languages. This reduces errors due to incompatibilities that arise \nduring integration\u2014and which are a major source of integration errors. \u25a0Services are more easily scaled than coarser-grained applications. Since each service is \nindependent, dynamically adding instances of the service is straightforward. In this way, \nthe supply of services can be more easily matched to the demand. Tradeoffs:\n \n\u25a0Overhead is increased, compared to in-memory communication, because all commu-\nnication among services occurs via messages across a network. This can be mitigated \nsomewhat by using the service mesh pattern (see Chapter 9), which constrains the \ndeployment of some services to the same host to reduce network traffic. Furthermore, \nbecause of the dynamic nature of microservice deployments, discovery services are \nheavily used, adding to the overhead. Ultimately, those discovery services may become \na performance bottleneck. \u25a0Microservices are less suitable for complex transactions because of the difficulty of \nsynchronizing activities across distributed systems. \u25a0The freedom for every team to choose its own technology comes at a cost\u2014the organi-\nzation must maintain those technologies and the required experience base. \u25a0Intellectual control of the total system may be difficult because of the large number of \nmicroservices. This introduces a requirement for catalogs and databases of interfaces to \nassist in maintaining intellectual control. In addition, the process of properly combining \nservices to achieve a desired outcome may be complex and subtle. \u25a0Designing the services to have appropriate responsibilities and an appropriate level of \ngranularity is a formidable design task. \u25a0To achieve the ability to deploy versions independently, the architecture of the services \nmust be designed to allow for that deployment strategy. Using the manage service inter-\nactions tactic described in Section 5.4 can help achieve this goal. Organizations that have heavily employed the microservice architecture pattern include \nGoogle, Netflix, PayPal, Twitter, Facebook, and Amazon. Many other organizations have \nadopted the microservice architecture pattern as well; books and conferences exist that focus \non how an organization can adopt the microservice architecture pattern for its own needs. Patterns for Complete Replacement of Services\nSuppose there are N instances of Service A and you wish to replace them with N instances of \na new version of Service A, leaving no instances of the original version.", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 101", "position": 101, "chunk_type": "semantic", "token_estimate": 405}
{"text": "5.6 Patterns for Deployability 83: Two different patterns for the complete replacement strategy are possible, both of which \nare realizations of the scale rollouts tactic. We\u2019ll cover them both together:\n1. Blue/green. In a blue/green deployment, N new instances of the service would be created \nand each populated with new Service A (let\u2019s call these the green instances). After the \nN instances of new Service A are installed, the DNS server or discovery service would \nbe changed to point to the new version of Service A. Once it is determined that the new \ninstances are working satisfactorily, then and only then are the N instances of the origi-\nnal Service A removed. Before this cutoff point, if a problem is found in the new version, \nit is a simple matter of switching back to the original (the blue services) with little or no \ninterruption. 2. Rolling upgrade. A rolling upgrade replaces the instances of Service A with instances of \nthe new version of Service A one at a time. (In practice, you can replace more than one \ninstance at a time, but only a small fraction are replaced in any single step.) The steps of \nthe rolling upgrade are as follows:\na. \nAllocate resources for a new instance of Service A (e.g., a virtual machine). b. Install and register the new version of Service A.\nc. \nBegin to direct requests to the new version of Service A.\nd. \nChoose an instance of the old Service A, allow it to complete any active processing, \nand then destroy that instance. e. \nRepeat the preceding steps until all instances of the old version have been replaced. Figure 5.4 shows a rolling upgrade process as implemented by Netflix\u2019s Asgard tool on \nAmazon\u2019s EC2 cloud platform. Benefits:\n \n\u25a0The benefit of these patterns is the ability to completely replace deployed versions of \nservices without having to take the system out of service, thus increasing the system\u2019s \navailability. Tradeoffs:\n \n\u25a0The peak resource utilization for a blue/green approach is 2N instances, whereas the peak \nutilization for a rolling upgrade is N + 1 instances. In either case, resources to host these \ninstances must be procured. Before the widespread adoption of cloud computing, procure-\nment meant purchase: An organization had to purchase physical computers to perform the \nupgrade. Most of the time there was no upgrade in progress, so these additional computers \nlargely sat idle.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 102", "position": 102, "chunk_type": "semantic", "token_estimate": 396}
{"text": "5.6 Patterns for Deployability 85: \u25a0From a client\u2019s perspective, if you are using the blue/green deployment model, then \nat any point in time either the new version or the old version is active, but not both. If \nyou are using the rolling upgrade pattern, both versions are simultaneously active. This \nintroduces the possibility of two types of problems: temporal inconsistency and interface \nmismatch. \u25a0Temporal inconsistency. In a sequence of requests by Client C to Service A, some may \nbe served by the old version of the service and some may be served by the new version. If the versions behave differently, this may cause Client C to produce erroneous, or at \nleast inconsistent, results. (This can be prevented by using the manage service inter-\nactions tactic.) \u25a0Interface mismatch. If the interface to the new version of Service A is different from \nthe interface to the old version of Service A, then invocations by clients of Service A that \nhave not been updated to reflect the new interface will produce unpredictable results. This can be prevented by extending the interface but not modifying the existing inter-\nface, and using the mediator pattern (see Chapter 7) to translate from the extended \ninterface to an internal interface that produces correct behavior. See Chapter 15 for a \nfuller discussion. Patterns for Partial Replacement of Services\nSometimes changing all instances of a service is undesirable. Partial-deployment patterns aim \nat providing multiple versions of a service simultaneously for different user groups; they are \nused for purposes such as quality control (canary testing) and marketing tests (A/B testing). Canary Testing\nBefore rolling out a new release, it is prudent to test it in the production environment, but \nwith a limited set of users. Canary testing is the continuous deployment analog of beta test-\ning.5 Canary testing designates a small set of users who will test the new release. Sometimes, \nthese testers are so-called power users or preview-stream users from outside your organization \nwho are more likely to exercise code paths and edge cases that typical users may use less \nfrequently. Users may or may not know that they are being used as guinea pigs\u2014er, that is, \ncanaries. Another approach is to use testers from within the organization that is developing \nthe software. For example, Google employees almost never use the release that external users \nwould be using, but instead act as testers for upcoming releases.", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 104", "position": 104, "chunk_type": "semantic", "token_estimate": 398}
{"text": "86 Part II Quality Attributes | Chapter 5 Deployability: complete, users are all directed to either the new version or the old version, and instances of \nthe deprecated version are destroyed. Rolling upgrade or blue/green deployment could be used \nto deploy the new version. Benefits:\n \n\u25a0Canary testing allows real users to \u201cbang on\u201d the software in ways that simulated testing \ncannot. This allows the organization deploying the service to collect \u201cin use\u201d data and \nperform controlled experiments with relatively low risk. \u25a0Canary testing incurs minimal additional development costs, because the system being \ntested is on a path to production anyway. \u25a0Canary testing minimizes the number of users who may be exposed to a serious defect \nin the new system. Tradeoffs:\n \n\u25a0Canary testing requires additional up-front planning and resources, and a strategy for \nevaluating the results of the tests needs to be formulated. \u25a0If canary testing is aimed at power users, those users have to be identified and the new \nversion routed to them. A/B Testing\nA/B testing is used by marketers to perform an experiment with real users to determine which \nof several alternatives yields the best business results. A small but meaningful number of users \nreceive a different treatment from the remainder of the users. The difference can be minor, \nsuch as a change to the font size or form layout, or it can be more significant. For example, \nHomeAway (now Vrbo) has used A/B testing to vary the format, content, and look-and-feel \nof its worldwide websites, tracking which editions produced the most rentals. The \u201cwinner\u201d \nwould be kept, the \u201closer\u201d discarded, and another contender designed and deployed. Another \nexample is a bank offering different promotions to open new accounts. An oft-repeated story \nis that Google tested 41 different shades of blue to decide which shade to use to report search \nresults. As in canary testing, DNS servers and discovery-service configurations are set to send \nclient requests to different versions. In A/B testing, the different versions are monitored to see \nwhich one provides the best response from a business perspective. Benefits:\n \n\u25a0A/B testing allows marketing and product development teams to run experiments on, \nand collect data from, real users. \u25a0A/B testing can allow for targeting of users based on an arbitrary set of characteristics. Tradeoffs:\n \n\u25a0A/B testing requires the implementation of alternatives, one of which will be discarded. \u25a0Different classes of users, and their characteristics, need to be identified up front.", "domains": ["Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 105", "position": 105, "chunk_type": "semantic", "token_estimate": 402}
{"text": "5.8 Discussion Questions 87: 5.7  \nFor Further Reading\nMuch of the material in this chapter is adapted from Deployment and Operations for Software \nEngineers by Len Bass and John Klein [Bass 19] and from [Kazman 20b]. A general discussion of deployability and architecture in the context of DevOps can be \nfound in [Bass 15]. The tactics for deployability owe much to the work of Martin Fowler and his colleagues, \nwhich can be found in [Fowler 10], [Lewis 14], and [Sato 14]. Deployment pipelines are described in much more detail in [Humble 10]\nMicroservices and the process of migrating to microservices are described in [Newman 15]. 5.8  \nDiscussion Questions\n1. Write a set of concrete scenarios for deployability using each of the possible responses in \nthe general scenario. 2. Write a concrete deployability scenario for the software for a car (such as a Tesla). 3. Write a concrete deployability scenario for a smartphone app. Now write one for the \nserver-side infrastructure that communicates with this app. 4. If you needed to display the results of a search operation, would you perform A/B testing \nor simply use the color that Google has chosen? Why? 5. Referring to the structures described in Chapter 1, which structures would be involved in \nimplementing the package dependencies tactic? Would you use the uses structure? Why \nor why not? Are there other structures you would need to consider? 6. Referring to the structures described in Chapter 1, which structures would be involved in \nimplementing the manage service interactions tactic? Would you use the uses structure? Why or why not? Are there other structures you would need to consider? 7. Under what circumstances would you prefer to roll forward to a new version of service, \nrather than to roll back to a prior version? When is roll forward a poor choice?", "domains": ["Architectural Patterns and Styles", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 106", "position": 106, "chunk_type": "semantic", "token_estimate": 303}
{"text": "89: 6\n \nEnergy Efficiency\nEnergy is a bit like money: If you have a positive balance, \nyou can distribute it in various ways, but according to the \nclassical laws that were believed at the beginning of the \ncentury, you weren\u2019t allowed to be overdrawn. \u2014Stephen Hawking\nEnergy used by computers used to be free and unlimited\u2014or at least that\u2019s how we behaved. Architects rarely gave much consideration to the energy consumption of software in the past. But those days are now gone. With the dominance of mobile devices as the primary form of \ncomputing for most people, with the increasing adoption of the Internet of Things (IoT) in \nindustry and government, and with the ubiquity of cloud services as the backbone of our com-\nputing infrastructure, energy has become an issue that architects can no longer ignore. Power \nis no longer \u201cfree\u201d and unlimited. The energy efficiency of mobile devices affects us all. Likewise, cloud providers are increasingly concerned with the energy efficiency of their server \nfarms. In 2016, it was reported that data centers globally accounted for more energy consump-\ntion (by 40 percent) than the entire United Kingdom\u2014about 3 percent of all energy consumed \nworldwide. More recent estimates put that share up as high as 10 percent. The energy costs \nassociated with running and, more importantly, cooling large data centers have led people \nto calculate the cost of putting whole data centers in space, where cooling is free and the sun \nprovides unlimited power. At today\u2019s launch prices, the economics are actually beginning to \nlook favorable. Notably, server farms located underwater and in arctic climates are already \na reality. At both the low end and the high end, energy consumption of computational devices has \nbecome an issue that we should consider. This means that we, as architects, now need to add \nenergy efficiency to the long list of competing qualities that we consider when designing a sys-\ntem. And, as with every other quality attribute, there are nontrivial tradeoffs to consider: energy \nusage versus performance or availability or modifiability or time to market. Thus considering \nenergy efficiency as a first-class quality attribute is important for the following reasons:\n1. An architectural approach is necessary to gain control over any important system quality \nattribute, and energy efficiency is no different. If system-wide techniques for monitoring", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 108", "position": 108, "chunk_type": "semantic", "token_estimate": 386}
{"text": "90 Part II Quality Attributes | Chapter 6 Energy Efficiency: and managing energy are lacking, then developers are left to invent them on their own. This will, in the best case, result in an ad hoc approach to energy efficiency that produces \na system that is hard to maintain, measure, and evolve. In the worst case, it will yield an \napproach that simply does not predictably achieve the desired energy efficiency goals. 2. Most architects and developers are unaware of energy efficiency as a quality attribute \nof concern, and hence do not know how to go about engineering and coding for it. More \nfundamentally, they lack an understanding of energy efficiency requirements\u2014how \nto gather them and analyze them for completeness. Energy efficiency is not taught, or \ntypically even mentioned, as a programmer\u2019s concern in today\u2019s educational curricula. In consequence, students may graduate with degrees in engineering or computer science \nwithout ever having been exposed to these issues. 3. Most architects and developers lack suitable design concepts\u2014models, patterns, tactics, \nand so forth\u2014for designing for energy efficiency, as well as managing and monitoring \nit at runtime. But since energy efficiency is a relatively recent concern for the software \nengineering community, these design concepts are still in their infancy and no catalog \nyet exists. Cloud platforms typically do not have to be concerned with running out of energy (except \nin disaster scenarios), whereas this is a daily concern for users of mobile devices and some \nIoT devices. In cloud environments, scaling up and scaling down are core competencies, so \ndecisions must be made on a regular basis about optimal resource allocation. With IoT devices, \ntheir size, form factors, and heat output all constrain their design space\u2014there is no room for \nbulky batteries. In addition, the sheer number of IoT devices projected to be deployed in the \nnext decade makes their energy usage a concern. In all of these contexts, energy efficiency must be balanced with performance and avail-\nability, requiring engineers to consciously reason about such tradeoffs. In the cloud context, \ngreater allocation of resources\u2014more servers, more storage, and so on\u2014creates improved \nperformance capabilities as well as improved robustness against failures of individual devices, \nbut at the cost of energy and capital outlays.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 109", "position": 109, "chunk_type": "semantic", "token_estimate": 370}
{"text": "90 Part II Quality Attributes | Chapter 6 Energy Efficiency: In all of these contexts, energy efficiency must be balanced with performance and avail-\nability, requiring engineers to consciously reason about such tradeoffs. In the cloud context, \ngreater allocation of resources\u2014more servers, more storage, and so on\u2014creates improved \nperformance capabilities as well as improved robustness against failures of individual devices, \nbut at the cost of energy and capital outlays. In the mobile and IoT contexts, greater allocation \nof resources is typically not an option (although shifting the computational burden from a \nmobile device to a cloud back-end is possible), so the tradeoffs tend to center on energy effi-\nciency versus performance and usability. Finally, in all contexts, there are tradeoffs between \nenergy efficiency, on the one hand, and buildability and modifiability, on the other hand. 6.1  \nEnergy Efficiency General Scenario\nFrom these considerations, we can now determine the various portions of the energy efficiency \ngeneral scenario, as presented in Table 6.1.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 109", "position": 109, "chunk_type": "semantic", "token_estimate": 161}
{"text": "6.2 Tactics for Energy Efficiency 93: Energy efficiency is, at its heart, about effectively utilizing resources. We group the tac-\ntics into three broad categories: resource monitoring, resource allocation, and resource adap-\ntation (Figure 6.3). By \u201cresource,\u201d we mean a computational device that consumes energy \nwhile providing its functionality. This is analogous to the definition of a hardware resource in \nChapter 9, which includes CPUs, data stores, network communications, and memory. Monitor Resources\nReduce Resource Demand\nAllocate Resources\n(QHUJ\\\u0003(I\u0182FLHQF\\\u00037DFWLFV\nMetering\n6WDWLF\u0003&ODVVL\u0182FDWLRQ\n'\\QDPLF\u0003&ODVVL\u0182FDWLRQ\nReduce Usage\nDiscovery\nSchedule Resources\nManage Event Arrival\nLimit Event Response\nPrioritize Events\nReduce Computational Overhead\n%RXQG\u0003([HFXWLRQ\u00037LPHV\n,QFUHDVH\u00035HVRXUFH\u00038VDJH\u0003(I\u0182FLHQF\\\nFIGURE 6.3 Energy efficiency tactics\n \nMonitor Resources\nYou can\u2019t manage what you can\u2019t measure, and so we begin with resource monitoring. The \ntactics for resource monitoring are metering, static classification, and dynamic classification. \u25a0Metering. The metering tactic involves collecting data about the energy consumption of \ncomputational resources via a sensor infrastructure, in near real time. At the coarsest level, \nthe energy consumption of an entire data center can be measured from its power meter. Individual servers or hard drives can be measured using external tools such as amp meters \nor watt-hour meters, or using built-in tools such as those provided with metered rack PDUs \n(power distribution units), ASICs (application-specific integrated circuits), and so forth. In \nbattery-operated systems, the energy remaining in a battery can be determined through \na battery management system, which is a component of modern batteries. \u25a0Static classification. Sometimes real-time data collection is infeasible. For example, \nif an organization is using an off-premises cloud, it might not have direct access to \nreal-time energy data. Static classification allows us to estimate energy consumption by", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 112", "position": 112, "chunk_type": "semantic", "token_estimate": 275}
{"text": "94 Part II Quality Attributes | Chapter 6 Energy Efficiency: \u25a0Schedule resources. Scheduling is the allocation of tasks to computational resources. As \nwe will see in Chapter 9, the schedule resources tactic can increase performance. In the \nenergy context, it can be used to effectively manage energy usage, given task constraints \nand respecting task priorities. Scheduling can be based on data collected using one or \nmore resource monitoring tactics. Using an energy discovery service in a cloud context, \nor a controller in a multi-core context, a computational task can dynamically switch \namong computational resources, such as service providers, selecting the ones that offer \nbetter energy efficiency or lower energy costs. For example, one provider may be more \nlightly loaded than another, allowing it to adapt its energy usage, perhaps using some of \nthe tactics described earlier, and consume less energy, on average, per unit of work.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 113", "position": 113, "chunk_type": "semantic", "token_estimate": 146}
{"text": "96 Part II Quality Attributes | Chapter 6 Energy Efficiency: Tactics \nGroup\nTactics Question\nSupported? (Y/N)\nRisk\nDesign \nDecisions \nand \nLocation\nRationale \nand \nAssumptions\nResource \nMonitoring\nDoes the system dynamically \nclassify devices and \ncomputational resources? In \ncases where static classification \nis not accurate due to varying \nload or environmental \nconditions, does the system use \ndynamic models, based on prior \ndata collected, to estimate the \nvarying energy consumption of a \ndevice or resource at runtime? Resource \nAllocation\nDoes the system reduce \nusage to scale down resource \nusage? That is, can the system \ndeactivate resources when \ndemands no longer require \nthem, in an effort to save \nenergy? This may involve \nspinning down hard drives, \ndarkening displays, turning off \nCPUs or servers, running CPUs \nat a slower clock rate, or shutting \ndown memory blocks of the \nprocessor that are not being \nused. Does the system schedule \nresources to more effectively \nutilize energy, given task \nconstraints and respecting \ntask priorities, by switching \ncomputational resources, such \nas service providers, to the \nones that offer better energy \nefficiency or lower energy costs? Is scheduling based on data \ncollected (using one or more \nresource monitoring tactics) \nabout the state of the system? Does the system make use of \na discovery service to match \nservice requests to service \nproviders? In the context of \nenergy efficiency, a service \nrequest could be annotated with \nenergy requirement information, \nallowing the requestor to choose \na service provider based on \nits (possibly dynamic) energy \ncharacteristics. TABLE 6.2 Tactics-Based Questionnaire for Energy Efficiency continued", "domains": ["Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 115", "position": 115, "chunk_type": "semantic", "token_estimate": 250}
{"text": "6.4 Patterns 97: Tactics \nGroup\nTactics Question\nSupported? (Y/N)\nRisk\nDesign \nDecisions \nand \nLocation\nRationale \nand \nAssumptions\nReduce \nResource \nDemand\nDo you consistently attempt to \nreduce resource demand? Here, you may insert the \nquestions in this category from \nthe Tactics-Based Questionnaire \nfor Performance from Chapter 9. 6.4  \nPatterns\nSome examples of patterns used for energy efficiency include sensor fusion, kill abnormal \ntasks, and power monitor. Sensor Fusion\nMobile apps and IoT systems often collect data from their environment using multiple sensors. In this pattern, data from low-power sensors can be used to infer whether data needs to be \ncollected from higher-power sensors. A common example in the mobile phone context is using \naccelerometer data to assess if the user has moved and, if so, to update the GPS location. This \npattern assumes that accessing the low-power sensor is much cheaper, in terms of energy con-\nsumption, than accessing the higher-power sensor. Benefits:\n \n\u25a0The obvious benefit of this pattern is the ability to minimize the usage of more energy-\nintensive devices in an intelligent way rather than, for example, just reducing the fre-\nquency of consulting the more energy-intensive sensor. Tradeoffs:\n \n\u25a0Consulting and comparing multiple sensors adds up-front complexity. \u25a0The higher-energy-consuming sensor will provide higher-quality data, albeit at the cost of \nincreased power consumption. And it will provide this data more quickly, since using the \nmore energy-intensive sensor alone takes less time than first consulting a secondary sensor. \u25a0In cases where the inference frequently results in accessing the higher-power sensor, this \npattern could result in overall higher energy usage. Kill Abnormal Tasks\nMobile systems, because they are often executing apps of unknown provenance, may end up \nunknowingly running some exceptionally power-hungry apps. This pattern provides a way", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 116", "position": 116, "chunk_type": "semantic", "token_estimate": 286}
{"text": "98 Part II Quality Attributes | Chapter 6 Energy Efficiency: to monitor the energy usage of such apps and to interrupt or kill energy-greedy operations. For example, if an app is issuing an audible alert and vibrating the phone and the user is not \nresponding to these alerts, then after a predetermined timeout period the task is killed. Benefits:\n \n\u25a0This pattern provides a \u201cfail-safe\u201d option for managing the energy consumption of apps \nwith unknown energy properties. Tradeoffs:\n \n\u25a0Any monitoring process adds a small amount of overhead to system operations, which \nmay affect performance and, to a small extent, energy usage. \u25a0The usability of this pattern needs to be considered. Killing energy-hungry tasks may be \ncounter to the user\u2019s intention. Power Monitor\nThe power monitor pattern monitors and manages system devices, minimizing the time during \nwhich they are active. This pattern attempts to automatically disable devices and interfaces \nthat are not being actively used by the application. It has long been used within integrated \ncircuits, where blocks of the circuit are shut down when they are not being used, in an effort \nto save energy. Benefits:\n \n\u25a0This pattern can allow for intelligent savings of power at little to no impact to the end \nuser, assuming that the devices being shut down are truly not needed. Tradeoffs:\n \n\u25a0Once a device has been switched off, switching it on adds some latency before it can \nrespond, as compared with keeping it continually running. And, in some cases, the \nstartup may be more energy expensive than a certain period of steady-state operation. \u25a0The power monitor needs to have knowledge of each device and its energy consumption \ncharacteristics, which adds up-front complexity to the system design. 6.5  \nFor Further Reading\nThe first published set of energy tactics appeared in [Procaccianti 14]. These were, in part, the \ninspiration for the tactics presented here. The 2014 paper subsequently inspired  \n[Paradis 21]. Many of the tactics presented in this chapter owe a debt to these two papers. For a good general introduction to energy usage in software development\u2014and what \ndevelopers do not know\u2014you should read [Pang 16].", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 117", "position": 117, "chunk_type": "semantic", "token_estimate": 348}
{"text": "101: 7\n \nIntegrability\nIntegration is a basic law of life; when we resist it, disintegration is \nthe natural result, both inside and outside of us. Thus we come to the \nconcept of harmony through integration. \u2014Norman Cousins\nAccording to the Merriam-Webster dictionary, the adjective integrable means \u201ccapable of \nbeing integrated.\u201d We\u2019ll give you a moment to catch your breath and absorb that profound \ninsight. But for practical software systems, software architects need to be concerned about \nmore than just making separately developed components cooperate; they are also concerned \nwith the costs and technical risks of anticipated and (to varying degrees) unanticipated future \nintegration tasks. These risks may be related to schedule, performance, or technology. A general, abstract representation of the integration problem is that a project needs to \nintegrate a unit of software C, or a set of units C1, C2, \u2026 Cn, into a system S. S might be a \nplatform, into which we integrate {Ci}, or it might be an existing system that already contains \n{C1, C2, \u2026, Cn} and our task is to design for, and analyze the costs and technical risks of, inte-\ngrating {Cn+1, \u2026 Cm}. We assume we have control over S, but the {Ci} may be outside our control\u2014supplied by \nexternal vendors, for example, so our level of understanding of each Ci may vary. The clearer \nour understanding of Ci, the more capable the design and accurate the analysis will be. Of course, S is not static but will evolve, and this evolution may require reanalysis. Integrability (like other quality attributes such as modifiability) is challenging because it is \nabout planning for a future when we have incomplete information at our disposal. Simply put, \nsome integrations will be simpler than others because they have been anticipated and accom-\nmodated in the architecture, whereas others will be more complex because they have not been. Consider a simple analogy: To plug a North American plug (an example of a Ci) into \na North American socket (an interface provided by the electrical system S), the \u201cintegra-\ntion\u201d is trivial. However, integrating a North American plug into a British socket will require \nan adapter. And the device with the North American plug may only run on 110-volt power, \nrequiring further adaptation before it will work in a British 220-volt socket.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 120", "position": 120, "chunk_type": "semantic", "token_estimate": 383}
{"text": "101: However, integrating a North American plug into a British socket will require \nan adapter. And the device with the North American plug may only run on 110-volt power, \nrequiring further adaptation before it will work in a British 220-volt socket. Furthermore, if \nthe component was designed to run at 60 Hz and the system provides 70 Hz, the component \nmay not operate as intended even though it plugs in just fine. The architectural decisions made", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 120", "position": 120, "chunk_type": "semantic", "token_estimate": 76}
{"text": "102 Part II Quality Attributes | Chapter 7 Integrability: by the creators of S and Ci\u2014for example, to provide plug adapters or voltage adapters, or to \nmake the component operate identically at different frequencies\u2014will affect the cost and risk \nof the integration. 7.1  \nEvaluating the Integrability of an Architecture\nIntegration difficulty\u2014the costs and the technical risks\u2014can be thought of as a function of \nthe size of and the \u201cdistance\u201d between the interfaces of {Ci} and S:\nSize is the number of potential dependencies between {Ci} and S.\nDistance is the difficulty of resolving differences at each of the dependencies. Dependencies are often measured syntactically. For example, we say that module A is \ndependent on component B if A calls B, if A inherits from B, or if A uses B. But while syn-\ntactic dependency is important, and will continue to be important in the future, dependency \ncan occur in forms that are not detectable by any syntactic relation. Two components might be \ncoupled temporally or through resources because they share and compete for a finite resource \nat runtime (e.g., memory, bandwidth, CPU), share control of an external device, or have a \ntiming dependency. Or they might be coupled semantically because they share knowledge of \nthe same protocol, file format, unit of measure, metadata, or some other aspect. The reason \nthat these distinctions are important is that temporal and semantic dependencies are not often \nwell understood, explicitly acknowledged, or properly documented. Missing or implicit knowl-\nedge is always a risk for a large, long-lived project, and such knowledge gaps will inevitably \nincrease the costs and risks of integration and integration testing. Consider the trend toward services and microservices in computation today. This \napproach is fundamentally about decoupling components to reduce the number and distance \nof their dependencies. Services only \u201cknow\u201d each other via their published interfaces and, \nif that interface is an appropriate abstraction, changes to one service have less chance to ripple \nto other services in the system. The ever-increasing decoupling of components is an indus-\ntry-wide trend that has been going on for decades. Service orientation, by itself, addresses \n(that is, reduces) only the syntactic aspects of dependency; it does not address the temporal \nor semantic aspects. Supposedly decoupled components that have detailed knowledge of each \nother and make assumptions about each other are in fact tightly coupled, and changing them in \nthe future may well be costly.", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 121", "position": 121, "chunk_type": "semantic", "token_estimate": 400}
{"text": "7.1 Evaluating the Integrability of an Architecture 103: expects a floating point, or perhaps the bits within a data field are interpreted differently, \nthis discrepancy presents a syntactic distance that must be bridged. Differences in data \ntypes are typically easy to observe and predict. For example, such type mismatches \ncould be caught by a compiler. Differences in bit masks, while similar in nature, are \noften more difficult to detect, and the analyst may need to rely on documentation or \nscrutiny of the code to identify them. \u25a0Data semantic distance. The cooperating elements must agree on the data semantics; \nthat is, even if two elements share the same data type, their values are interpreted \ndifferently. For example, if one data value represents altitude in meters and the other \nrepresents altitude in feet, this presents a data semantic distance that must be bridged. This kind of mismatch is typically difficult to observe and predict, although the analyst\u2019s \nlife is improved somewhat if the elements involved employ metadata. Mismatches in \ndata semantics may be discovered by comparing interface documentation or metadata \ndescriptions, if available, or by checking the code, if available. \u25a0Behavioral semantic distance. The cooperating elements must agree on behavior, par-\nticularly with respect to the states and modes of the system. For example, a data element \nmay be interpreted differently in system startup, shutdown, or recovery mode. Such \nstates and modes may, in some cases, be explicitly captured in protocols. As another \nexample, Ci and Cj may make different assumptions regarding control, such as each \nexpecting the other to initiate interactions. \u25a0Temporal distance. The cooperating elements must agree on assumptions about time. Examples of temporal distance include operating at different rates (e.g., one element \nemits values at a rate of 10 Hz and the other expects values at 60 Hz) or making different \ntiming assumptions (e.g., one element expects event A to follow event B and the other \nelement expects event A to follow event B with no more than 50 ms latency). While this \nmight be considered to be a subcase of behavioral semantics, it is so important (and often \nsubtle) that we call it out explicitly. \u25a0Resource distance. The cooperating elements must agree on assumptions about shared \nresources.", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 122", "position": 122, "chunk_type": "semantic", "token_estimate": 369}
{"text": "7.1 Evaluating the Integrability of an Architecture 103: \u25a0Resource distance. The cooperating elements must agree on assumptions about shared \nresources. Examples of resource distance may involve devices (e.g., one element requires \nexclusive access to a device, whereas another expects shared access) or computational \nresources (e.g., one element needs 12 GB of memory to run optimally and the other \nneeds 10 GB, but the target CPU has only 16 GB of physical memory; or three elements \nare simultaneously producing data at 3 Mbps each, but the communication channel \noffers a peak capacity of just 5 Mbps). Again, this distance may be seen as related to \nbehavioral distance, but it should be consciously analyzed. Such details are not typically mentioned in a programming language interface descrip-\ntion. In the organizational context, however, these unstated, implicit interfaces often add time \nand complexity to integration tasks (and modification and debugging tasks). This is why inter-\nfaces are architectural concerns, as we will discuss further in Chapter 15. In essence, integrability is about discerning and bridging the distance between the ele-\nments of each potential dependency. This is a form of planning for modifiability. We will \nrevisit this topic in Chapter 8.", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 122", "position": 122, "chunk_type": "semantic", "token_estimate": 197}
{"text": "104 Part II Quality Attributes | Chapter 7 Integrability: 7.2  \nGeneral Scenario for Integrability\nTable 7.1 presents the general scenario for integrability. TABLE 7.1 General Scenario for Integrability\nPortion of \nScenario\nDescription\nPossible Values\nSource\nWhere does the stimulus \ncome from? One or more of the following:\n \n\u25a0\nMission/system stakeholder\n \n\u25a0\nComponent marketplace\n \n\u25a0\nComponent vendor\nStimulus\nWhat is the stimulus? That is, what kind of \nintegration is being \ndescribed? One of the following:\n \n\u25a0\nAdd new component\n \n\u25a0\nIntegrate new version of existing component\n \n\u25a0\nIntegrate existing components together in a new way\nArtifact\nWhat parts of the system \nare involved in the \nintegration? One of the following:\n \n\u25a0\nEntire system\n \n\u25a0\nSpecific set of components\n \n\u25a0\nComponent metadata\n \n\u25a0\nComponent configuration\nEnvironment\nWhat state is the system \nin when the stimulus \noccurs? One of the following:\n \n\u25a0\nDevelopment\n \n\u25a0\nIntegration\n \n\u25a0\nDeployment\n \n\u25a0\nRuntime\nResponse\nHow will an \u201cintegrable\u201d \nsystem respond to the \nstimulus? One or more of the following:\n \n\u25a0\nChanges are {completed, integrated, tested, deployed}\n \n\u25a0\nComponents in the new configuration are successfully \nand correctly (syntactically and semantically) \nexchanging information\n \n\u25a0\nComponents in the new configuration are successfully \ncollaborating\n \n\u25a0\nComponents in the new configuration do not violate \nany resource limits\nResponse \nmeasure\nHow is the response \nmeasured? One or more of the following:\n \n\u25a0\nCost, in terms of one or more of:\n \n\u25a0\nNumber of components changed\n \n\u25a0\nPercentage of code changed\n \n\u25a0\nLines of code changed\n \n\u25a0\nEffort\n \n\u25a0\nMoney\n \n\u25a0\nCalendar time\n \n\u25a0\nEffects on other quality attribute response measures \n(to capture allowable tradeoffs)", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 123", "position": 123, "chunk_type": "semantic", "token_estimate": 261}
{"text": "7.3 Integrability Tactics 105: Stimulus\nResponse\nResponse\nMeasure\nSource\n3\n2\n1\n4\nEnvironment\nArtifact\nComponent\nmarketplace\n1HZ\u0003GDWD\u0003\u0182OWHULQJ\ncomponent becomes", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 124", "position": 124, "chunk_type": "semantic", "token_estimate": 20}
{"text": "Development: The new component\nLV\u0003LQWHJUDWHG\u0003DQG\u0003\ndeployed\n\u0014\u0003PRQWK\u000f\u0003ZLWK\u0003QR\u0003PRUH\nthan 1 person-month\nof effort\nSystem\nFigure 7.1 illustrates a sample integrability scenario constructed from the general sce-\nnario: A new data filtering component has become available in the component marketplace. The new component is integrated into the system and deployed in 1 month, with no more than \n1 person-month of effort. FIGURE 7.1 Sample integrability scenario\n \n7.3  \nIntegrability Tactics\nThe goals for the integrability tactics are to reduce the costs and risks of adding new com-\nponents, reintegrating changed components, and integrating sets of components together to \nfulfill evolutionary requirements, as illustrated in Figure 7.2. New components\narrive\nComponents are\nintegrated within\ntime, cost, and \nquality constraints\nTactics\nto Control\nResponse\nFIGURE 7.2 Goal of integrability tactics", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 124", "position": 124, "chunk_type": "semantic", "token_estimate": 125}
{"text": "106 Part II Quality Attributes | Chapter 7 Integrability: The tactics achieve these goals either by reducing the number of potential dependencies \nbetween components or by reducing the expected distance between components. Figure 7.3 \nshows an overview of the integrability tactics. Limit Dependencies\nCoordinate\nAdapt\nIntegrability Tactics\nEncapsulate\nUse an Intermediary\nRestrict Communication Paths\nAdhere to Standards\nAbstract Common Services\nDiscover\nTailor Interface\n&RQ\u0182JXUH\u0003%HKDYLRU\nOrchestrate\nManage Resources\nFIGURE 7.3 Integrability tactics\n \nLimit Dependencies\n \nEncapsulate\nEncapsulation is the foundation upon which all other integrability tactics are built. It is there-\nfore seldom seen on its own, but its use is implicit in the other tactics described here. Encapsulation introduces an explicit interface to an element and ensures that all access to \nthe element passes through this interface. Dependencies on the element internals are eliminated, \nbecause all dependencies must flow through the interface. Encapsulation reduces the probability \nthat a change to one element will propagate to other elements, by reducing either the number \nof dependencies or their distances. These strengths are, however, reduced because the interface \nlimits the ways in which external responsibilities can interact with the element (perhaps through \na wrapper). In consequence, the external responsibilities can only directly interact with the ele-\nment through the exposed interface (indirect interactions, such as dependence on quality of ser-\nvice, will likely remain unchanged). Encapsulation may also hide interfaces that are not relevant for a particular integration \ntask. An example is a library used by a service that can be completely hidden from all consum-\ners and changed without these changes propagating to the consumers. Encapsulation, then, can reduce the number of dependencies as well as the syntactic, \ndata, and behavior semantic distances between C and S.", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 125", "position": 125, "chunk_type": "semantic", "token_estimate": 284}
{"text": "7.3 Integrability Tactics 107: Use an Intermediary\nIntermediaries are used for breaking dependencies between a set of components Ci or between \nCi and the system S. Intermediaries can be used to resolve different types of dependencies. For \nexample, intermediaries such as a publish\u2013subscribe bus, shared data repository, or dynamic \nservice discovery all reduce dependencies between data producers and consumers by removing \nany need for either to know the identity of the other party. Other intermediaries, such as data \ntransformers and protocol translators, resolve forms of syntactic and data semantic distance. Determining the specific benefits of a particular intermediary requires knowledge of \nwhat the intermediary actually does. An analyst needs to determine whether the intermediary \nreduces the number of dependencies between a component and the system and which dimen-\nsions of distance, if any, it addresses. Intermediaries are often introduced during integration to resolve specific dependencies, \nbut they can also be included in an architecture to promote integrability with respect to antic-\nipated scenarios. Including a communication intermediary such as a publish\u2013subscribe bus in \nan architecture, and then restricting communication paths to and from sensors to this bus, is an \nexample of using an intermediary with the goal of promoting integrability of sensors. Restrict Communication Paths\nThis tactic restricts the set of elements with which a given element can communicate. In prac-\ntice, this tactic is implemented by restricting a element\u2019s visibility (when developers cannot \nsee an interface, they cannot employ it) and by authorization (i.e., restricting access to only \nauthorized elements). The restrict communication paths tactic is seen in service-oriented \narchitectures (SOAs), in which point-to-point requests are discouraged in favor of forcing all \nrequests to go through an enterprise service bus so that routing and preprocessing can be done \nconsistently. Adhere to Standards\nStandardization in system implementations is a primary enabler of integrability and interoper-\nability, across both platforms and vendors. Standards vary considerably in terms of the scope \nof what they prescribe. Some focus on defining syntax and data semantics. Others include \nricher descriptions, such as those describing protocols that include behavioral and temporal \nsemantics. Standards similarly vary in their scope of applicability or adoption. For example, standards \npublished by widely recognized standards-setting organizations such as the Institute of Electrical \nand Electronics Engineers (IEEE), the International Organization for Standardization (ISO), and \nthe Object Management Group (OMG) are more likely to be broadly adopted.", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 126", "position": 126, "chunk_type": "semantic", "token_estimate": 394}
{"text": "7.3 Integrability Tactics 107: Standards similarly vary in their scope of applicability or adoption. For example, standards \npublished by widely recognized standards-setting organizations such as the Institute of Electrical \nand Electronics Engineers (IEEE), the International Organization for Standardization (ISO), and \nthe Object Management Group (OMG) are more likely to be broadly adopted. Conventions that \nare local to an organization, particularly if well documented and enforced, can provide similar \nbenefits as \u201clocal standards,\u201d though with less expectation of benefits when integrating compo-\nnents from outside the local standard\u2019s sphere of adoption. Adopting a standard can be an effective integrability tactic, although its effectiveness is \nlimited to benefits based on the dimensions of difference addressed in the standard and how \nlikely it is that future component suppliers will conform to the standard. Restricting commu-\nnication with a system S to require use of the standard often reduces the number of potential", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 126", "position": 126, "chunk_type": "semantic", "token_estimate": 149}
{"text": "108 Part II Quality Attributes | Chapter 7 Integrability: dependencies. Depending on what is defined in a standard, it may also address syntactic, data \nsemantic, behavioral semantic, and temporal dimensions of distance. Abstract Common Services\nWhere two elements provide services that are similar but not quite the same, it may be useful \nto hide both specific elements behind a common abstraction for a more general service. This \nabstraction might be realized as a common interface implemented by both, or it might involve \nan intermediary that translates requests for the abstract service to more specific requests for \nthe elements hidden behind the abstraction. The resulting encapsulation hides the details of the \nelements from other components in the system. In terms of integrability, this means that future \ncomponents can be integrated with a single abstraction rather than separately integrated with \neach of the specific elements. When the abstract common services tactic is combined with an intermediary (such as a \nwrapper or adapter), it can also normalize syntactic and semantic variations among the spe-\ncific elements. For example, we see this when systems use many sensors of the same type from \ndifferent manufacturers, each with its own device drivers, accuracy, or timing properties, but \nthe architecture provides a common interface to them. As another example, your browser may \naccommodate various kinds of ad-blocking plug-ins, yet because of the plug-in interface the \nbrowser itself can remain blissfully unaware of your choice. Abstracting common services allows for consistency when handling common infrastruc-\nture concerns (e.g., translations, security mechanisms, and logging). When these features change, \nor when new versions of the components implementing these features change, the changes can \nbe made in a smaller number of places. An abstract service is often paired with an intermediary \nthat may perform processing to hide syntactic and data semantic differences among specific \nelements. Adapt\nDiscover\nA discovery service is a catalog of relevant addresses, which comes in handy whenever there is \na need to translate from one form of address to another, whenever the target address may have \nbeen dynamically bound, or when there are multiple targets. It is the mechanism by which \napplications and services locate each other. A discovery service may be used to enumerate \nvariants of particular elements that are used in different products. Entries in a discovery service are there because they were registered. This registration \ncan happen statically, or it can happen dynamically when a service is instantiated.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 127", "position": 127, "chunk_type": "semantic", "token_estimate": 404}
{"text": "7.3 Integrability Tactics 109: example, a weather discovery service may have an attribute of \u201ccost of forecast\u201d; you can then \nask a weather discovery service for a service that provides free forecasts. The discover tactic works by reducing the dependencies between cooperating services, \nwhich should be written without knowledge of each other. This enables flexibility in the bind-\ning between services, as well as when that binding occurs. Tailor Interface\nTailoring an interface is a tactic that adds capabilities to, or hides capabilities in, an exist-\ning interface without changing the API or implementation. Capabilities such as translation, \nbuffering, and data smoothing can be added to an interface without changing it. An example \nof removing capabilities is hiding particular functions or parameters from untrusted users. A \ncommon dynamic application of this tactic is intercepting filters that add functionality such \nas data validation to help prevent SQL injections or other attacks, or to translate between data \nformats. Another example is using techniques from aspect-oriented programming that weave \nin preprocessing and postprocessing functionality at compile time. The tailor interface tactic allows functionality that is needed by many services to be \nadded or hidden based on context and managed independently. It also enables services with \nsyntactic differences to interoperate without modification to either service. This tactic is typically applied during integration; however, designing an architecture so \nthat it facilitates interface tailoring can support integrability. Interface tailoring is commonly \nused to resolve syntactic and data semantic distance during integration. It can also be applied \nto resolve some forms of behavioral semantic distance, though it can be more complex to do \n(e.g., maintaining a complex state to accommodate protocol differences) and is perhaps more \naccurately categorized as introducing an intermediary. Configure Behavior\nThe tactic of configuring behavior is used by software components that are implemented to be \nconfigurable in prescribed ways that allow them to more easily interact with a range of com-\nponents. The behavior of a component can be configured during the build phase (recompile \nwith a different flag), during system initialization (read a configuration file or fetch data from \na database), or during runtime (specify a protocol version as part of your requests). A simple \nexample is configuring a component to support different versions of a standard on its inter-\nfaces. Ensuring that multiple options are available increases the chances that the assumptions \nof S and a future C will match.", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 128", "position": 128, "chunk_type": "semantic", "token_estimate": 399}
{"text": "7.3 Integrability Tactics 109: A simple \nexample is configuring a component to support different versions of a standard on its inter-\nfaces. Ensuring that multiple options are available increases the chances that the assumptions \nof S and a future C will match. Building configurable behavior into portions of S is an integrability tactic that allows S \nto support a wider range of potential Cs. This tactic can potentially address syntactic, data \nsemantic, behavioral semantic, and temporal dimensions of distance. Coordinate\nOrchestrate\nOrchestrate is a tactic that uses a control mechanism to coordinate and manage the invocation \nof particular services so that they can remain unaware of each other.", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 128", "position": 128, "chunk_type": "semantic", "token_estimate": 108}
{"text": "110 Part II Quality Attributes | Chapter 7 Integrability: Orchestration helps with the integration of a set of loosely coupled reusable services to \ncreate a system that meets a new need. Integration costs are reduced when orchestration is \nincluded in an architecture in a way that supports the services that are likely to be integrated \nin the future. This tactic allows future integration activities to focus on integration with the \norchestration mechanism instead of point-to-point integration with multiple components. Workflow engines commonly make use of the orchestrate tactic. A workflow is a set of \norganized activities that order and coordinate software components to complete a business \nprocess. It may consist of other workflows, each of which may itself consist of aggregated \nservices. The workflow model encourages reuse and agility, leading to more flexible business \nprocesses. Business processes can be managed under a philosophy of business process man-\nagement (BPM) that views processes as a set of competitive assets to be managed. Complex \norchestration can be specified in a language such as BPEL (Business Process Execution \nLanguage). Orchestration works by reducing the number of dependencies between a system S and \nnew components {Ci}, and eliminating altogether the explicit dependencies among the com-\nponents {Ci}, by centralizing those dependencies at the orchestration mechanism. It may also \nreduce syntactic and data semantic distance if the orchestration mechanism is used in conjunc-\ntion with tactics such as adherence to standards. Manage Resources\nA resource manager is a specific form of intermediary that governs access to computing \nresources; it is similar to the restrict communication paths tactic. With this tactic, software \ncomponents are not allowed to directly access some computing resources (e.g., threads or \nblocks of memory), but instead request those resources from a resource manager. Resource \nmanagers are typically responsible for allocating resource access across multiple components \nin a way that preserves some invariants (e.g., avoiding resource exhaustion or concurrent use), \nenforces some fair access policy, or both. Examples of resource managers include operating \nsystems, transaction mechanisms in databases, use of thread pools in enterprise systems, and \nuse of the ARINC 653 standard for space and time partitioning in safety-critical systems. The manage resource tactic works by reducing the resource distance between a system S \nand a component C, by clearly exposing the resource requirements and managing their com-\nmon use.", "domains": ["Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 129", "position": 129, "chunk_type": "semantic", "token_estimate": 387}
{"text": "110 Part II Quality Attributes | Chapter 7 Integrability: Examples of resource managers include operating \nsystems, transaction mechanisms in databases, use of thread pools in enterprise systems, and \nuse of the ARINC 653 standard for space and time partitioning in safety-critical systems. The manage resource tactic works by reducing the resource distance between a system S \nand a component C, by clearly exposing the resource requirements and managing their com-\nmon use. 7.4  \nTactics-Based Questionnaire for Integrability\n \nBased on the tactics described in Section 7.3, we can create a set of integrability tactics\u2013\ninspired questions, as presented in Table 7.2. To gain an overview of the architectural choices \nmade to support integrability, the analyst asks each question and records the answers in the \ntable. The answers to these questions can then be made the focus of further activities: investi-\ngation of documentation, analysis of code or other artifacts, reverse engineering of code, and \nso forth.", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 129", "position": 129, "chunk_type": "semantic", "token_estimate": 155}
{"text": "7.4 Tactics-Based Questionnaire for Integrability 111: TABLE 7.2 Tactics-Based Questionnaire for Integrability\nTactics Group\nTactics Question\nSupported? (Y/N)\nRisk\nDesign \nDecisions \nand \nLocation\nRationale \nand \nAssumptions\nLimit \nDependencies\nDoes the system \nencapsulate functionality \nof each element by \nintroducing explicit \ninterfaces and requiring \nthat all access to the \nelements passes through \nthese interfaces? Does the system broadly \nuse intermediaries for \nbreaking dependencies \nbetween components\u2014for \nexample, removing a data \nproducer\u2019s knowledge of \nits consumers? Does the system abstract \ncommon services, \nproviding a general, \nabstract interface for \nsimilar services? Does the system provide \na means to restrict \ncommunication paths \nbetween components? Does the system adhere \nto standards in terms of \nhow components interact \nand share information with \neach other? Adapt\nDoes the system provide \nthe ability to statically \n(i.e., at compile time) \ntailor interfaces\u2014that \nis, the ability to add or \nhide capabilities of a \ncomponent\u2019s interface \nwithout changing its API or \nimplementation? Does the system \nprovide a discovery \nservice, cataloguing and \ndisseminating information \nabout services? Does the system provide \na means to configure the \nbehavior of components \nat build, initialization, or \nruntime? continues", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 130", "position": 130, "chunk_type": "semantic", "token_estimate": 180}
{"text": "112 Part II Quality Attributes | Chapter 7 Integrability: Tactics Group\nTactics Question\nSupported? (Y/N)\nRisk\nDesign \nDecisions \nand \nLocation\nRationale \nand \nAssumptions\nCoordinate\nDoes the system include \nan orchestration \nmechanism that \ncoordinates and manages \nthe invocation of \ncomponents so they can \nremain unaware of each \nother? Does the system provide \na resource manager \nthat governs access to \ncomputing resources? 7.5  \nPatterns\n \nThe first three patterns are all centered on the tailor interface tactic, and are described here as \na group:\n \n\u25a0Wrappers. A wrapper is a form of encapsulation whereby some component is encased \nwithin an alternative abstraction. A wrapper is the only element allowed to use that \ncomponent; every other piece of software uses the component\u2019s services by going through \nthe wrapper. The wrapper transforms the data or control information for the component it \nwraps. For example, a component may expect input using Imperial measures but find itself \nin a system in which all of the other components produce metric measures. Wrappers can:\n \n\u25a0Translate an element of a component interface into an alternative element\n \n\u25a0Hide an element of a component interface\n \n\u25a0Preserve an element of a component\u2019s base interface without change\n \n\u25a0Bridges. A bridge translates some \u201crequires\u201d assumptions of one arbitrary component \nto some \u201cprovides\u201d assumptions of another component. The key difference between a \nbridge and a wrapper is that a bridge is independent of any particular component. Also, \nthe bridge must be explicitly invoked by some external agent\u2014possibly but not neces-\nsarily by one of the components the bridge spans. This last point should convey the idea \nthat bridges are usually transient and that the specific translation is defined at the time of \nbridge construction (e.g., bridge compile time). The significance of both of these distinc-\ntions will be made clear in the discussion of mediators. Bridges typically focus on a narrower range of interface translations than do wrappers \nbecause bridges address specific assumptions. The more assumptions a bridge tries to \naddress, the fewer components to which it applies. TABLE 7.2 Tactics-Based Questionnaire for Integrability continued", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 131", "position": 131, "chunk_type": "semantic", "token_estimate": 338}
{"text": "7.5 Patterns 113: \u25a0Mediators. Mediators exhibit properties of both bridges and wrappers. The major \n \ndistinction between bridges and mediators, is that mediators incorporate a planning \nfunction that results in runtime determination of the translation, whereas bridges estab-\nlish this translation at bridge construction time. A mediator is also similar to a wrapper insofar as it becomes an explicit component \nin the system architecture. That is, semantically primitive, often transient bridges can be \nthought of as incidental repair mechanisms whose role in a design can remain implicit. In contrast, mediators have sufficient semantic complexity and runtime autonomy (per-\nsistence) to play a first-class role in a software architecture. Benefits:\n \n\u25a0All three patterns allow access to an element without forcing a change to the element or \nits interface. Tradeoffs:\n \n\u25a0Creating any of the patterns requires up-front development work. \u25a0All of the patterns will introduce some performance overhead while accessing the ele-\nment, although typically this overhead is small. Service-Oriented Architecture Pattern\nThe service-oriented architecture (SOA) pattern describes a collection of distributed com-\nponents that provide and/or consume services. In an SOA, service provider components and \nservice consumer components can use different implementation languages and platforms. Services are largely standalone entities: Service providers and service consumers are usually \ndeployed independently, and often belong to different systems or even different organizations. Components have interfaces that describe the services they request from other components \nand the services they provide. A service\u2019s quality attributes can be specified and guaranteed \nwith a service level agreement (SLA), which may sometimes be legally binding. Components \nperform their computations by requesting services from one another. Communication among \nthe services is typically performed by using web services standards such as WSDL (Web \nServices Description Language) or SOAP (Simple Object Access Protocol). The SOA pattern is related to the microservice architecture pattern (see Chapter 5). Micro-\nservice architectures are assumed to compose a single system and be managed by a single \norganization, however, whereas SOAs provide reusable components that are assumed to be \nheterogeneous and managed by distinct organizations. Benefits:\n \n\u25a0Services are designed to be used by a variety of clients, leading them to be more generic. Many commercial organizations will provide and market their service with the goal of \nbroad adoption. \u25a0Services are independent. The only method for accessing a service is through its inter-\nface and through messages over a network.", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 132", "position": 132, "chunk_type": "semantic", "token_estimate": 391}
{"text": "114 Part II Quality Attributes | Chapter 7 Integrability: \u25a0Services can be implemented heterogeneously, using whatever languages and technolo-\ngies are most appropriate. Tradeoffs:\n \n\u25a0SOAs, because of their heterogeneity and distinct ownership, come with a great many \ninteroperability features such as WSDL and SOAP. This adds complexity and overhead. Dynamic Discovery\nDynamic discovery applies the discovery tactic to enable the discovery of service providers at \nruntime. Consequently, a runtime binding can occur between a service consumer and a con-\ncrete service. Use of a dynamic discovery capability sets the expectation that the system will clearly \nadvertise both the services available for integration with future components and the mini-\nmal information that will be available for each service. The specific information available \nwill vary, but typically comprises data that can be mechanically searched during discovery \nand runtime integration (e.g., identifying a specific version of an interface standard by string \nmatch). Benefits:\n \n\u25a0This pattern allows for flexibility in binding services together into a cooperating whole. For example, services may be chosen at startup or runtime based on their pricing or \navailability. Tradeoffs:\n \n\u25a0Dynamic discovery registration and de-registration must be automated, and tools for this \npurpose must be acquired or generated. 7.6  \nFor Further Reading\nMuch of the material for this chapter was inspired by and drawn from [Kazman 20a]. An in-depth discussion of the quality attribute of integrability can be found in \n[Hentonnen 07]. [MacCormack 06] and  \n[Mo 16] define and provide empirical evidence for architecture-\nlevel coupling metrics, which can be useful in measuring designs for integrability. The book Design Patterns: Elements of Reusable Object-Oriented Software [Gamma 94] \ndefines and distinguishes the bridge, wrapper, and adapter patterns.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 133", "position": 133, "chunk_type": "semantic", "token_estimate": 276}
{"text": "7.7 Discussion Questions 115: 7.7  \nDiscussion Questions\n1. Think about an integration that you have done in the past\u2014perhaps integrating a library \nor a framework into your code. Identify the various \u201cdistances\u201d that you had to deal \nwith, as discussed in Section 7.1. Which of these required the greatest effort to resolve? 2. Write a concrete integrability scenario for a system that you are working on (perhaps an \nexploratory scenario for some component that you are considering integrating). 3. Which of the integrability tactics do you think would be the easiest to implement in \npractice, and why? Which would be the most difficult, and why? 4. Many of the integrability tactics are similar to the modifiability tactics. If you make \nyour system highly modifiable, does that automatically mean that it will be easy to inte-\ngrate into another context? 5. A standard use of SOA is to add a shopping cart feature to an e-commerce site. Which \ncommercially available SOA platforms provide different shopping cart services? What \nare the attributes of the shopping carts? Can these attributes be discovered at runtime? 6. Write a program that accesses the Google Play Store, via its API, and returns a list of \nweather forecasting applications and their attributes. 7. Sketch a design for a dynamic discovery service. Which types of distances does this \nservice help to mitigate?", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 134", "position": 134, "chunk_type": "semantic", "token_estimate": 224}
{"text": "117: 8\n \nModifiability\nIt is not the strongest of the species that survive, nor the most \nintelligent, but the one most responsive to change. \u2014Charles Darwin\nChange happens. Study after study shows that most of the cost of the typical software system occurs after it \nhas been initially released. If change is the only constant in the universe, then software change \nis not only constant but ubiquitous. Changes happen to add new features, to alter or even retire \nold ones. Changes happen to fix defects, tighten security, or improve performance. Changes \nhappen to enhance the user\u2019s experience. Changes happen to embrace new technology, new \nplatforms, new protocols, new standards. Changes happen to make systems work together, \neven if they were never designed to do so. Modifiability is about change, and our interest in it is to lower the cost and risk of making \nchanges. To plan for modifiability, an architect has to consider four questions:\n \n\u25a0What can change? A change can occur to any aspect of a system: the functions that \nthe system computes, the platform (the hardware, operating system, middleware), the \nenvironment in which the system operates (the systems with which it must interoperate, \nthe protocols it uses to communicate with the rest of the world), the qualities the system \nexhibits (its performance, its reliability, and even its future modifications), and its capac-\nity (number of users supported, number of simultaneous operations). \u25a0What is the likelihood of the change? One cannot plan a system for all potential \nchanges\u2014the system would never be done or if it was done it would be far too expensive \nand would likely suffer quality attribute problems in other dimensions. Although any-\nthing might change, the architect has to make the tough decisions about which changes \nare likely, and hence which changes will be supported and which will not. \u25a0When is the change made and who makes it? Most commonly in the past, a change was \nmade to source code. That is, a developer had to make the change, which was tested and \nthen deployed in a new release. Now, however, the question of when a change is made is \nintertwined with the question of who makes it. An end user changing the screen saver \nis clearly making a change to one aspect of the system. Equally clear, it is not in the", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 136", "position": 136, "chunk_type": "semantic", "token_estimate": 388}
{"text": "118 Part II Quality Attributes | Chapter 8 Modifiability: same category as changing the system so that it uses a different database management \nsystem. Changes can be made to the implementation (by modifying the source code), \nduring compilation (using compile-time switches), during the build (by choice of librar-\nies), during configuration setup (by a range of techniques, including parameter setting), \nor during execution (by parameter settings, plug-ins, allocation to hardware, and so \nforth). A change can also be made by a developer, an end user, or a system administrator. Systems that learn and adapt supply a whole different answer to the question of when a \nchange is made and \u201cwho\u201d makes it\u2014it is the system itself that is the agent for change. \u25a0What is the cost of the change? Making a system more modifiable involves two types of \ncosts:\n \n\u25a0The cost of introducing the mechanism(s) to make the system more modifiable\n \n\u25a0The cost of making the modification using the mechanism(s)\nFor example, the simplest mechanism for making a change is to wait for a change request \nto come in, then change the source code to accommodate the request. In such a case, the cost \nof introducing the mechanism is zero (since there is no special mechanism); the cost of exer-\ncising it is the cost of changing the source code and revalidating the system. Toward the other end of the spectrum is an application generator, such as a user interface \nbuilder. The builder takes as input a description of the designed UI produced through direct \nmanipulation techniques and which may then produce source code. The cost of introducing \nthe mechanism is the cost of acquiring the UI builder, which may be substantial. The cost of \nusing the mechanism is the cost of producing the input to feed the builder (this cost can be \neither substantial or negligible), the cost of running the builder (close to zero), and finally the \ncost of whatever testing is performed on the result (usually much less than for hand-coding). Still further along the spectrum are software systems that discover their environments, \nlearn, and modify themselves to accommodate any changes. For those systems, the cost of \nmaking the modification is zero, but that ability was purchased along with implementing and \ntesting the learning mechanisms, which may have been quite costly.", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 137", "position": 137, "chunk_type": "semantic", "token_estimate": 384}
{"text": "118 Part II Quality Attributes | Chapter 8 Modifiability: Still further along the spectrum are software systems that discover their environments, \nlearn, and modify themselves to accommodate any changes. For those systems, the cost of \nmaking the modification is zero, but that ability was purchased along with implementing and \ntesting the learning mechanisms, which may have been quite costly. For N similar modifications, a simplified justification for a change mechanism is that\nN * Cost of making change without the mechanism \u2264\nCost of creating the mechanism + (N * cost of making the change using the mechanism)\nHere, N is the anticipated number of modifications that will use the modifiability mechanism\u2014\nbut it is also a prediction. If fewer changes than expected come in, then an expensive modi-\nfication mechanism may not be warranted. In addition, the cost of creating the modifiability \nmechanism could be applied elsewhere (opportunity cost)\u2014in adding new functionality, in \nimproving the performance, or even in non-software investments such as hiring or training. Also, the equation does not take time into account. It might be cheaper in the long run to \nbuild a sophisticated change-handling mechanism, but you might not be able to wait for its \ncompletion. However, if your code is modified frequently, not introducing some architectural \nmechanism and simply piling change on top of change typically leads to substantial technical \ndebt. We address the topic of architectural debt in Chapter 23.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 137", "position": 137, "chunk_type": "semantic", "token_estimate": 237}
{"text": "Part II Quality Attributes | Chapter 8 Modifiability 119: Change is so prevalent in the life of software systems that special names have been given \nto specific flavors of modifiability. Some of the common ones are highlighted here:\n \n\u25a0Scalability is about accommodating more of something. In terms of performance, scal-\nability means adding more resources. Two kinds of performance scalability are horizon-\ntal scalability and vertical scalability. Horizontal scalability (scaling out) refers to adding \nmore resources to logical units, such as adding another server to a cluster of servers. Vertical scalability (scaling-up) refers to adding more resources to a physical unit, such \nas adding more memory to a single computer. The problem that arises with either type \nof scaling is how to effectively utilize the additional resources. Being effective means \nthat the additional resources result in a measurable improvement of some system quality, \ndid not require undue effort to add, and did not unduly disrupt operations. In cloud-\nbased environments, horizontal scalability is called elasticity. Elasticity is a property \nthat enables a customer to add or remove virtual machines from the resource pool (see \nChapter 17 for further discussion of such environments). \u25a0Variability refers to the ability of a system and its supporting artifacts, such as code, \nrequirements, test plans, and documentation, to support the production of a set of \nvariants that differ from each other in a preplanned fashion. Variability is an especially \nimportant quality attribute in a product line, which is a family of systems that are sim-\nilar but vary in features and functions. If the engineering assets associated with these \nsystems can be shared among members of the family, then the overall cost of the product \nline plummets. This is achieved by introducing mechanisms that allow the artifacts to \nbe selected and/or adapt to usages in the different product contexts that are within the \nproduct line\u2019s scope. The goal of variability in a software product line is to make it easy \nto build and maintain products in that family over a period of time. \u25a0Portability refers to the ease with which software that was built to run on one platform \ncan be changed to run on a different platform. Portability is achieved by minimizing \nplatform dependencies in the software, isolating dependencies to well-identified loca-\ntions, and writing the software to run on a \u201cvirtual machine\u201d (for example, a Java Virtual \nMachine) that encapsulates all the platform dependencies.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 138", "position": 138, "chunk_type": "semantic", "token_estimate": 401}
{"text": "Part II Quality Attributes | Chapter 8 Modifiability 119: \u25a0Portability refers to the ease with which software that was built to run on one platform \ncan be changed to run on a different platform. Portability is achieved by minimizing \nplatform dependencies in the software, isolating dependencies to well-identified loca-\ntions, and writing the software to run on a \u201cvirtual machine\u201d (for example, a Java Virtual \nMachine) that encapsulates all the platform dependencies. Scenarios describing porta-\nbility deal with moving software to a new platform by expending no more than a certain \nlevel of effort or by counting the number of places in the software that would have to \nchange. Architectural approaches to dealing with portability are intertwined with those \nfor deployability, a topic addressed in Chapter 5. \u25a0Location independence refers to the case where two pieces of distributed software interact \nand the location of one or both of the pieces is not known prior to runtime. Alternatively, \nthe location of these pieces may change during runtime. In distributed systems, services \nare often deployed to arbitrary locations, and clients of those services must discover \ntheir location dynamically. In addition, services in a distributed system must often \nmake their location discoverable once they have been deployed to a location. Designing \nthe system for location independence means that the location will be easy to modify with \nminimal impact on the rest of the system.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 138", "position": 138, "chunk_type": "semantic", "token_estimate": 231}
{"text": "120 Part II Quality Attributes | Chapter 8 Modifiability: 8 \n.1  \nModifiability General Scenario\nFrom these considerations, we can construct the general scenario for modifiability. Table 8.1 \nsummarizes this scenario. TABLE 8.1 General Scenario for Modifiability\nPortion of \nScenario\nDescription\nPossible Values\nSource\nThe agent that causes a change to \nbe made. Most are human actors, but \nthe system might be one that learns \nor self-modifies, in which case the \nsource is the system itself. End user, developer, system administrator, \nproduct line owner, the system itself\nStimulus\nThe change that the system \nneeds to accommodate. (For this \ncategorization, we regard fixing a \ndefect as a change, to something that \npresumably wasn\u2019t working correctly.) A directive to add/delete/modify functionality, \nor change a quality attribute, capacity, \nplatform, or technology; a directive to add a \nnew product to a product line; a directive to \nchange the location of a service to another \nlocation\nArtifacts\nThe artifacts that are modified. Specific components or modules, the \nsystem\u2019s platform, its user interface, \nits environment, or another system \nwith which it interoperates. Code, data, interfaces, components, \nresources, test cases, configurations, \ndocumentation \nEnvironment\nThe time or stage at which the \nchange is made. Runtime, compile time, build time, initiation \ntime, design time\nResponse\nMake the change and incorporate it \ninto the system. One or more of the following:\n \n\u25a0\nMake modification\n \n\u25a0\nTest modification\n \n\u25a0\nDeploy modification\n \n\u25a0\nSelf-modify\nResponse \nmeasure\nThe resources that were expended to \nmake the change. Cost in terms of:\n \n\u25a0\nNumber, size, complexity of affected \nartifacts\n \n\u25a0\nEffort\n \n\u25a0\nElapsed time\n \n\u25a0\nMoney (direct outlay or opportunity cost)\n \n\u25a0\nExtent to which this modification affects \nother functions or quality attributes\n \n\u25a0\nNew defects introduced\n \n\u25a0\nHow long it took the system to adapt\nFigure 8.1 illustrates a concrete modifiability scenario: A developer wishes to change the \nuser interface. This change will be made to the code at design time, it will take less than three \nhours to make and test the change, and no side effects will occur.", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 139", "position": 139, "chunk_type": "semantic", "token_estimate": 335}
{"text": "8.2 Tactics for Modifiability 121: Stimulus\nResponse\nResponse\nMeasure\nSource\n3\n2\n1\n4\nEnvironment\nArtifact\nDeveloper\nWants to change the\nuser interface\nDesign time\nChange is made\nLess than 3 hours to\nmake and test change;\nno side effects\nUser interface\nFIGURE 8.1 Sample concrete modifiability scenario\n \n8.2  \nTactics for Modifiability\nTactics to control modifiability have as their goal controlling the complexity of making \nchanges, as well as the time and cost to make changes. Figure 8.2 shows this relationship. Change\narrives\nChanges made\nwithin time and\nbudget\nTactics\nto Control\nResponse\nFIGURE 8.2 Goal of modifiability tactics\nTo understand modifiability, we begin with some of the earliest and most fundamental \ncomplexity measures of software design\u2014coupling and cohesion\u2014which were first described \nin the 1960s. Generally, a change that affects one module is easier and less expensive than a change that \naffects more than one module. However, if two modules\u2019 responsibilities overlap in some way,", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 140", "position": 140, "chunk_type": "semantic", "token_estimate": 155}
{"text": "122 Part II Quality Attributes | Chapter 8 Modifiability: then a single change may well affect them both. We can quantify this overlap by measuring \nthe probability that a modification to one module will propagate to the other. This relationship \nis called coupling, and high coupling is an enemy of modifiability. Reducing the coupling \nbetween two modules will decrease the expected cost of any modification that affects either \none. Tactics that reduce coupling are those that place intermediaries of various sorts between \nthe two otherwise highly coupled modules. Cohesion measures how strongly the responsibilities of a module are related. Informally, \nit measures the module\u2019s \u201cunity of purpose.\u201d Unity of purpose can be measured by the change \nscenarios that affect a module. The cohesion of a module is the probability that a change sce-\nnario that affects a responsibility will also affect other (different) responsibilities. The higher \nthe cohesion, the lower the probability that a given change will affect multiple modules. High \ncohesion is good for modifiability; low cohesion is bad for it. If module A has a low cohe-\nsion, then cohesion can be improved by removing responsibilities unaffected by anticipated \nchanges. A third characteristic that affects the cost and complexity of a change is the size of a mod-\nule. All other things being equal, larger modules are more difficult and more costly to change, \nand are more prone to have bugs. Finally, we need to be concerned with the point in the software development life cycle \nwhere a change occurs. If we ignore the cost of preparing the architecture for the modification, \nwe prefer that a change is bound as late as possible. Changes can be successfully made (i.e., \nquickly and at low cost) late in the life cycle only if the architecture is suitably prepared to \naccommodate them. Thus the fourth and final parameter in a model of modifiability is bind-\ning time of modification. An architecture that is suitably equipped to accommodate modifica-\ntions late in the life cycle will, on average, cost less than an architecture that forces the same \nmodification to be made earlier. The preparedness of the system means that some costs will be \nzero, or very low, for modifications that occur late in the life cycle. Now we can understand tactics and their consequences as affecting one or more of these \nparameters: reducing size, increasing cohesion, reducing coupling, and deferring binding time. These tactics are shown in Figure 8.3.", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 141", "position": 141, "chunk_type": "semantic", "token_estimate": 407}
{"text": "122 Part II Quality Attributes | Chapter 8 Modifiability: Now we can understand tactics and their consequences as affecting one or more of these \nparameters: reducing size, increasing cohesion, reducing coupling, and deferring binding time. These tactics are shown in Figure 8.3. Increase Cohesion\nSeveral tactics involve redistributing responsibilities among modules. This step is taken to \nreduce the likelihood that a single change will affect multiple modules. \u25a0Split module. If the module being modified includes responsibilities that are not cohe-\nsive, the modification costs will likely be high. Refactoring the module into several more \ncohesive modules should reduce the average cost of future changes. Splitting a mod-\nule should not simply consist of placing half of the lines of code into each submodule; \ninstead, it should sensibly and appropriately result in a series of submodules that are \ncohesive on their own. \u25a0Redistribute responsibilities. If responsibilities A, A\ue008, and A\ue008\ue008 (all similar responsibili-\nties) are sprinkled across several distinct modules, they should be placed together. This", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 141", "position": 141, "chunk_type": "semantic", "token_estimate": 165}
{"text": "8.2 Tactics for Modifiability 123: refactoring may involve creating a new module, or it may involve moving responsibili-\nties to existing modules. One method for identifying responsibilities to be moved is to \nhypothesize a set of likely changes as scenarios. If the scenarios consistently affect just \none part of a module, then perhaps the other parts have separate responsibilities and \nshould be moved. Alternatively, if some scenarios require modifications to multiple \nmodules, then perhaps the responsibilities affected should be grouped together into a \nnew module. Re \nduce Coupling\nWe now turn to tactics that reduce the coupling between modules. These tactics overlap with \nthe integrability tactics described in Chapter 7, because reducing dependencies among inde-\npendent components (for integrability) is similar to reducing coupling among modules (for \nmodifiability). \u25a0En \ncapsulate. See the discussion in Chapter 7. \u25a0Use an intermediary. See the discussion in Chapter 7. \u25a0Abstract common services. See the discussion in Chapter 7. Increase Cohesion\nDefer Binding\nReduce Coupling\n0RGL\u0182DELOLW\\\u00037DFWLFV\n6SOLW\u00030RGXOH\n5HGLVWULEXWH\u00035HVSRQVLELOLWLHV\n(QFDSVXODWH\n8VH\u0003DQ\u0003,QWHUPHGLDU\\\n$EVWUDFW\u0003&RPPRQ\u00036HUYLFHV\n5HVWULFW\u0003'HSHQGHQFLHV\n&RPSRQHQW\u00035HSODFHPHQW\n&RXSOH\u00107LPH\u00033DUDPHWHUL]DWLRQ\n$VSHFWV\n&RQ\u0182JXUDWLRQ\u00107LPH\u0003%LQGLQJ\nResource Files\n'LVFRYHU\\\n,QWHUSUHW\u00033DUDPHWHUV\n6KDUHG\u00035HSRVLWRULHV\n3RO\\PRUSKLVP\nFIGURE 8.3 Modifiability tactics", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 142", "position": 142, "chunk_type": "semantic", "token_estimate": 181}
{"text": "124 Part II Quality Attributes | Chapter 8 Modifiability: \u25a0Restrict dependencies. This tactic restricts which modules a given module interacts with \nor depends on. In practice, this tactic is implemented by restricting a module\u2019s visibility \n(when developers cannot see an interface, they cannot employ it) and by authorization \n(restricting access to only authorized modules). The restrict dependencies tactic is seen \nin layered architectures, in which a layer is allowed to use only lower layers (sometimes \nonly the next lower layer), and with the use of wrappers, where external entities can see \n(and hence depend on) only the wrapper, and not the internal functionality that it wraps. De \nfer Binding\nBecause the work of people is almost always more expensive error-prone than the work of \ncomputers, letting computers handle a change as much as possible will almost always reduce \nthe cost of making that change. If we design artifacts with built-in flexibility, then exercising \nthat flexibility is usually cheaper than hand-coding a specific change. Parameters are perhaps the best-known mechanism for introducing flexibility, and their \nuse is reminiscent of the abstract common services tactic. A parameterized function f(a, b) \nis more general than the similar function f(a) that assumes b = 0. When we bind the value of \nsome parameters at a different phase in the life cycle than the one in which we defined the \nparameters, we are deferring binding. In general, the later in the life cycle we can bind values, the better. However, putting the \nmechanisms in place to facilitate that late binding tends to be more expensive\u2014a well-known \ntradeoff. And so the equation given earlier in the chapter comes into play. We want to bind as \nlate as possible, as long as the mechanism that allows it is cost-effective.", "domains": ["Architectural Patterns and Styles", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 143", "position": 143, "chunk_type": "semantic", "token_estimate": 292}
{"text": "124 Part II Quality Attributes | Chapter 8 Modifiability: And so the equation given earlier in the chapter comes into play. We want to bind as \nlate as possible, as long as the mechanism that allows it is cost-effective. The following tactics can be used to bind values at compile time or build time:\n \n\u25a0Component replacement (for example, in a build script or makefile)\n \n\u25a0Compile-time parameterization\n \n\u25a0Aspects\nThe following tactics are available to bind values at deployment, startup time, or initial-\nization time:\n \n\u25a0Configuration-time binding\n \n\u25a0Resource files\nTactics to bind values at runtime include the following:\n \n\u25a0Discovery (see Chapter 7)\n \n\u25a0Interpret parameters\n \n\u25a0Shared repositories\n \n\u25a0Polymorphism\nSeparating the building of a mechanism for modifiability from the use of that mecha-\nnism to make a modification admits the possibility of different stakeholders being involved\u2014\none stakeholder (usually a developer) to provide the mechanism and another stakeholder (an \nadministrator or installer) to exercise it later, possibly in a completely different life-cycle", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 143", "position": 143, "chunk_type": "semantic", "token_estimate": 158}
{"text": "8.3 Tactics-Based Questionnaire for Modifiability 125: phase. Installing a mechanism so that someone else can make a change to the system without \nhaving to change any code is sometimes called externalizing the change. 8. 3  \nTactics-Based Questionnaire for Modifiability\nBased on the tactics described in Section 8.2, we can create a set of tactics-inspired questions, \nas presented in Table 8.2. To gain an overview of the architectural choices made to support \nmodifiability, the analyst asks each question and records the answers in the table. The answers \nto these questions can then be made the focus of further activities: investigation of documenta-\ntion, analysis of code or other artifacts, reverse engineering of code, and so forth. TABLE 8.2 Tactics-Based Questionnaire for Modifiability\nTactics \nGroup\nTactics Question\nSupported? (Y/N)\nRisk? Design \nDecisions \nand \nLocation\nRationale \nand \nAssumptions\nIncrease \nCohesion\nDo you make modules more \ncohesive by splitting the \nmodule? For example, if you \nhave a large, complex module, \ncan you split it into two (or more) \nmore cohesive modules? Do you make modules more \ncohesive by redistributing \nresponsibilities? For example, \nif responsibilities in a module \ndo not serve the same purpose, \nthey should be placed in other \nmodules. Reduce \nCoupling\nDo you consistently encapsulate \nfunctionality? This typically \ninvolves isolating the functionality \nunder scrutiny and introducing an \nexplicit interface to it. Do you consistently use an \nintermediary to keep modules \nfrom being too tightly coupled? For example, if A calls concrete \nfunctionality C, you might \nintroduce an abstraction B that \nmediates between A and C.\nDo you restrict dependencies \nbetween modules in a systematic \nway? Or is any system module \nfree to interact with any other \nmodule? continues", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 144", "position": 144, "chunk_type": "semantic", "token_estimate": 275}
{"text": "126 Part II Quality Attributes | Chapter 8 Modifiability: Tactics \nGroup\nTactics Question\nSupported? (Y/N)\nRisk? Design \nDecisions \nand \nLocation\nRationale \nand \nAssumptions\nReduce \nCoupling\nDo you abstract common \nservices, in cases where you \nare providing several similar \nservices? For example, this \ntechnique is often used when you \nwant your system to be portable \nacross operating systems, \nhardware, or other environmental \nvariations. Defer \nBinding\nDoes the system regularly defer \nbinding of important functionality \nso that it can be replaced later in \nthe life cycle? For example, are \nthere plug-ins, add-ons, resource \nfiles, or configuration files that \ncan extend the functionality of the \nsystem? 8.4  \nPatterns\nPatterns for modifiability divide the system into modules in such a way that the modules can \nbe developed and evolved separately with little interaction among them, thereby supporting \nportability, modifiability, and reuse. There are probably more patterns designed to support \nmodifiability than for any other quality attribute. We present a few that are among the most \ncommonly used here. Client-Server Pattern\nThe client-server pattern consists of a server providing services simultaneously to multiple dis-\ntributed clients. The most common example is a web server providing information to multiple \nsimultaneous users of a website. The interactions between a server and its clients follow this sequence:\n \n\u25a0Discovery:\n \n\u25a0Communication is initiated by a client, which uses a discovery service to determine \nthe location of the server. \u25a0The server responds to the client using an agreed-upon protocol. TABLE 8.2 Tactics-Based Questionnaire for Modifiability continued", "domains": ["Architectural Patterns and Styles", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 145", "position": 145, "chunk_type": "semantic", "token_estimate": 245}
{"text": "8.4 Patterns 127: \u25a0Interaction:\n \n\u25a0The client sends requests to the server. \u25a0The server processes the requests and responds. Several points about this sequence are worth noting:\n \n\u25a0The server may have multiple instances if the number of clients grows beyond the \ncapacity of a single instance. \u25a0If the server is stateless with respect to the clients, each request from a client is treated \nindependently. \u25a0If the server maintains state with respect to the clients, then:\n \n\u25a0Each request must identify the client in some fashion. \u25a0The client should send an \u201cend of session\u201d message so that the server can remove \nresources associated with that particular client. \u25a0The server may time out if the client has not sent a request in a specified time so that \nresources associated with the client can be removed. Benefits:\n \n\u25a0The connection between a server and its clients is established dynamically. The server has \nno a priori knowledge of its clients\u2014that is, there is low coupling between the server and \nits clients. \u25a0There is no coupling among the clients. \u25a0The number of clients can easily scale and is constrained only by the capacity of the \nserver. The server functionality can also scale if its capacity is exceeded. \u25a0Clients and servers can evolve independently. \u25a0Common services can be shared among multiple clients. \u25a0The interaction with a user is isolated to the client. This factor has resulted in the devel-\nopment of specialized languages and tools for managing the user interface. Tradeoffs:\n \n\u25a0This pattern is implemented such that communication occurs over a network, perhaps \neven the Internet. Thus messages may be delayed by network congestion, leading to \ndegradation (or at least unpredictability) of performance. \u25a0For clients that communicate with servers over a network shared by other applications, \nspecial provisions must be made for achieving security (especially confidentiality) and \nmaintaining integrity. Plug-in (Microkernel) Pattern\nThe plug-in pattern has two types of elements\u2014elements that provide a core set of functional-\nity and specialized variants (called plug-ins) that add functionality to the core via a fixed set of \ninterfaces. The two types are typically bound together at build time or later.", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 146", "position": 146, "chunk_type": "semantic", "token_estimate": 348}
{"text": "128 Part II Quality Attributes | Chapter 8 Modifiability: Examples of usage include the following cases:\n \n\u25a0The core functionality may be a stripped-down operating system (the microkernel) that \nprovides the mechanisms needed to implement operating system services, such as low-\nlevel address space management, thread management, and interprocess communication \n(IPC). The plug-ins provide the actual operating system functionality, such as device \ndrivers, task management, and I/O request management. \u25a0The core functionality is a product providing services to its users. The plug-ins provide \nportability, such as operating system compatibility or supporting library compatibility. The plug-ins can also provide additional functionality not included in the core product. In addition, they can act as adapters to enable integration with external systems (see \nChapter 7). Benefits:\n \n\u25a0Plug-ins provide a controlled mechanism to extend a core product and make it useful in a \nvariety of contexts. \u25a0The plug-ins can be developed by different teams or organizations than the developers \nof the microkernel. This allows for the development of two different markets: for the \ncore product and for the plug-ins. \u25a0The plug-ins can evolve independently from the microkernel. Since they interact through \nfixed interfaces, as long as the interfaces do not change, the two types of elements are \nnot otherwise coupled. Tradeoffs:\n \n\u25a0Because plug-ins can be developed by different organizations, it is easier to introduce \nsecurity vulnerabilities and privacy threats. Layers Pattern\nThe layers pattern divides the system in such a way that the modules can be developed and \nevolved separately with little interaction among the parts, which supports portability, modifi-\nability, and reuse. To achieve this separation of concerns, the layers pattern divides the soft-\nware into units called layers. Each layer is a grouping of modules that offers a cohesive set of \nservices. The allowed-to-use relationship among the layers is subject to a key constraint: The \nrelations must be unidirectional. Layers completely partition a set of software, and each partition is exposed through a \npublic interface. The layers are created to interact according to a strict ordering relation. If \n(A, B) is in this relation, we say that the software assigned to layer A is allowed to use any \nof the public facilities provided by layer B. (In a vertically arranged representation of layers, \nwhich is almost ubiquitous, A will be drawn higher than B.) In some cases, modules in one \nlayer are required to directly use modules in a nonadjacent lower layer, although normally only \nnext-lower-layer uses are allowed.", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Design Principles", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 147", "position": 147, "chunk_type": "semantic", "token_estimate": 406}
{"text": "8.4 Patterns 129: Benefits:\n \n\u25a0Because a layer is constrained to use only lower layers, software in lower layers can be \nchanged (as long as the interface does not change) without affecting the upper layers. \u25a0Lower-level layers may be reused across different applications. For example, suppose a \ncertain layer allows portability across operating systems. This layer would be useful in \nany system that must run on multiple, different operating systems. The lowest layers are \noften provided by commercial software\u2014an operating system, for example, or network \ncommunications software. \u25a0Because the allowed-to-use relations are constrained, the number of interfaces that any \nteam must understand is reduced. Tradeoffs:\n \n\u25a0If the layering is not designed correctly, it may actually get in the way, by not providing \nthe lower-level abstractions that programmers at the higher levels need. \u25a0Layering often adds a performance penalty to a system. If a call is made from a function \nin the top-most layer, it may have to traverse many lower layers before being executed by \nthe hardware. \u25a0If many instances of layer bridging occur, the system may not meet its portability and \nmodifiability goals, which strict layering helps to achieve. Publish-Subscribe Pattern\nPublish-subscribe is an architectural pattern in which components communicate primarily \nthrough asynchronous messages, sometimes referred to as \u201cevents\u201d or \u201ctopics.\u201d The publish-\ners have no knowledge of the subscribers, and subscribers are only aware of message types. Systems using the publish-subscribe pattern rely on implicit invocation; that is, the component \npublishing a message does not directly invoke any other component. Components publish mes-\nsages on one or more events or topics, and other components register an interest in the publi-\ncation. At runtime, when a message is published, the publish\u2013subscribe (or event) bus notifies \nall of the elements that registered an interest in the event or topic. In this way, the message \npublication causes an implicit invocation of (methods in) other components. The result is loose \ncoupling between the publishers and the subscribers. The publish-subscribe pattern has three types of elements:\n \n\u25a0Publisher component. Sends (publishes) messages. \u25a0Subscriber component. Subscribes to and then receives messages. \u25a0Event bus. Manages subscriptions and message dispatch as part of the runtime \ninfrastructure. Benefits:\n \n\u25a0Publishers and subscribers are independent and hence loosely coupled. Adding or \nchanging subscribers requires only registering for an event and causes no changes to the \npublisher.", "domains": ["Architectural Patterns and Styles", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 148", "position": 148, "chunk_type": "semantic", "token_estimate": 385}
{"text": "130 Part II Quality Attributes | Chapter 8 Modifiability: \u25a0System behavior can be easily changed by changing the event or topic of a message \nbeing published, and consequently which subscribers might receive and act on this \nmessage. This seemingly small change can have large consequences, as features may be \nturned on or off by adding or suppressing messages. \u25a0Events can be logged easily to allow for record and playback and thereby reproduce error \nconditions that can be challenging to recreate manually. Tradeoffs:\n \n\u25a0Some implementations of the publish-subscribe pattern can negatively impact per-\nformance (latency). Use of a distributed coordination mechanism will ameliorate the \nperformance degradation. \u25a0In some cases, a component cannot be sure how long it will take to receive a published \nmessage. In general, system performance and resource management are more difficult to \nreason about in publish-subscribe systems. \u25a0Use of this pattern can negatively impact the determinism produced by synchronous sys-\ntems. The order in which methods are invoked, as a result of an event, can vary in some \nimplementations. \u25a0Use of the publish-subscribe pattern can negatively impact testability. Seemingly small \nchanges in the event bus\u2014such as a change in which components are associated with \nwhich events\u2014can have a wide impact on system behavior and quality of service. \u25a0Some publish-subscribe implementations limit the mechanisms available to flexibly \nimplement security (integrity). Since publishers do not know the identity of their sub-\nscribers, and vice versa, end-to-end encryption is limited. Messages from a publisher to \nthe event bus can be uniquely encrypted, and messages from the event bus to a sub-\nscriber can be uniquely encrypted; however, any end-to-end encrypted communication \nrequires all publishers and subscribers involved to share the same key. 8.5  \nFor Further Reading\nSerious students of software engineering and its history should read two early papers about \ndesigning for modifiability. The first is Edsger Dijkstra\u2019s 1968 paper about the T.H.E. operat-\ning system, which is the first paper that talks about designing systems to use layers, and the \nmodifiability benefits that this approach brings [Dijkstra 68]. The second is David Parnas\u2019s \n1972 paper that introduced the concept of information hiding. [Parnas 72] suggested defining \nmodules not by their functionality, but by their ability to internalize the effects of changes. More patterns for modifiability are given in Software Systems Architecture: Working \nWith Stakeholders Using Viewpoints and Perspectives [Woods 11].", "domains": ["Architectural Patterns and Styles", "Software Quality Attributes", "Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 149", "position": 149, "chunk_type": "semantic", "token_estimate": 390}
{"text": "8.6 Discussion Questions 131: A fully automated way of detecting modularity violations\u2014and other kinds of design \nflaws\u2014has been described in [Mo 19]. The detected violations can be used as a guide to refac-\ntoring, so as to increase cohesion and reduce coupling. Software modules intended for use in a software product line are often imbued with vari-\nation mechanisms that allow them to be quickly modified to serve in different applications\u2014\nthat is, in different members of the product line. Lists of variation mechanisms for components \nin a product line can be found in the works by Bachmann and Clements [Bachmann 05], \nJacobson and colleagues [Jacobson 97], and Anastasopoulos and colleagues [Anastasopoulos 00]. The layers pattern comes in many forms and variations\u2014\u201clayers with a sidecar,\u201d for \nexample. Section 2.4 of [DSA2] sorts them all out, and discusses why (surprisingly for an \narchitectural pattern invented more than a half-century ago) most layer diagrams for soft-\nware that you\u2019ve ever seen are very ambiguous. If you don\u2019t want to spring for the book, then \n[Bachmann 00a] is a good substitute. 8.6  \nDiscussion Questions\n1. Modifiability comes in many flavors and is known by many names; we discussed a few \nin the opening section of this chapter, but that discussion only scratches the surface. Find \none of the IEEE or ISO standards dealing with quality attributes, and compile a list of \nquality attributes that refer to some form of modifiability. Discuss the differences. 2. In the list you compiled for question 1, which tactics and patterns are especially helpful \nfor each? 3. For each quality attribute that you discovered as a result of question 2, write a modifi-\nability scenario that expresses it. 4. In many laundromats, washing machines and dryers accept coins but do not give change. Instead, separate machines dispense change. In an average laundromat, there are six or \neight washers and dryers for every change machine. What modifiability tactics do you \nsee at work in this arrangement? What can you say about availability? 5. For the laundromat in question 4, describe the specific form of modifiability (using a \nmodifiability scenario) that seems to be the aim of arranging the machines as described. 6. A wrapper, introduced in Chapter 7, is a common architectural pattern to aid modifiabil-\nity. Which modifiability tactics does a wrapper embody? 7. Other common architectural patterns that can increase a system\u2019s modifiability include \nblackboard, broker, peer-to-peer, model-view-controller, and reflection.", "domains": ["Architectural Patterns and Styles", "Design Principles", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 150", "position": 150, "chunk_type": "semantic", "token_estimate": 403}
{"text": "8.6 Discussion Questions 131: 7. Other common architectural patterns that can increase a system\u2019s modifiability include \nblackboard, broker, peer-to-peer, model-view-controller, and reflection. Discuss each in \nterms of the modifiability tactics it packages. 8. Once an intermediary has been introduced into an architecture, some modules may \nattempt to circumvent it, either inadvertently (because they are not aware of the", "domains": ["Architectural Patterns and Styles", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 150", "position": 150, "chunk_type": "semantic", "token_estimate": 58}
{"text": "132 Part II Quality Attributes | Chapter 8 Modifiability: intermediary) or intentionally (for performance, for convenience, or out of habit). Discuss some architectural means to prevent an undesirable circumvention of an inter-\nmediary. Discuss some non-architectural means as well. 9. The abstract common services tactic is intended to reduce coupling but might also \nreduce cohesion. Discuss. 10. Discuss the proposition that the client-server pattern is the microkernel pattern with \nruntime binding.", "domains": ["Architectural Patterns and Styles", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 151", "position": 151, "chunk_type": "semantic", "token_estimate": 71}
{"text": "133: 9\nPerformance\nAn ounce of performance is worth pounds of promises. \u2014Mae West\nIt\u2019s about time. Performance, that is: It\u2019s about time and the software system\u2019s ability to meet timing \nrequirements. The melancholy fact is that operations on computers take time. Computations \ntake time on the order of thousands of nanoseconds, disk access (whether solid state or rotat-\ning) takes time on the order of tens of milliseconds, and network access takes time ranging \nfrom hundreds of microseconds within the same data center to upward of 100 milliseconds for \nintercontinental messages. Time must be taken into consideration when designing your system \nfor performance. When events occur\u2014interrupts, messages, requests from users or other systems, or \nclock events marking the passage of time\u2014the system, or some element of the system, must \nrespond to them in time. Characterizing the events that can occur (and when they can occur) \nand the system\u2019s or element\u2019s time-based response to those events is the essence of discussing \nperformance. Web-based system events come in the form of requests from users (numbering in the tens \nor tens of millions) via their clients such as web browsers. Services get events from other ser-\nvices. In a control system for an internal combustion engine, events come from the operator\u2019s \ncontrols and the passage of time; the system must control both the firing of the ignition when \na cylinder is in the correct position and the mixture of the fuel to maximize power and effi-\nciency and minimize pollution. For a web-based system, a database-centric system, or a system processing input signals \nfrom its environment, the desired response might be expressed as the number of requests that can \nbe processed in a unit of time. For the engine control system, the response might be the allow-\nable variation in the firing time. In each case, the pattern of events arriving and the pattern of \nresponses can be characterized, and this characterization forms the language with which to \nconstruct performance scenarios.", "domains": ["Design Patterns", "Design Principles", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 152", "position": 152, "chunk_type": "semantic", "token_estimate": 329}
{"text": "134 Part II Quality Attributes | Chapter 9 Performance: For much of the history of software engineering, which began when computers were slow \nand expensive and the tasks to perform dwarfed the ability to do them, performance has been \nthe driving factor in architecture. As such, it has frequently compromised the achievement of \nall other qualities. As the price/performance ratio of hardware continues to plummet and the \ncost of developing software continues to rise, other qualities have emerged as important com-\npetitors to performance. But performance remains of fundamental importance. There are still (and will likely \nalways be) important problems that we know how to solve with computers, but that we can\u2019t \nsolve fast enough to be useful. All systems have performance requirements, even if they are not expressed. For example, \na word processing tool may not have any explicit performance requirement, but no doubt you \nwould agree that waiting an hour (or a minute, or a second) before seeing a typed character \nappear on the screen is unacceptable. Performance continues to be a fundamentally important \nquality attribute for all software. Performance is often linked to scalability\u2014that is, increasing your system\u2019s capacity for \nwork, while still performing well. They\u2019re certainly linked, although technically scalability is \nmaking your system easy to change in a particular way, and so is a kind of modifiability, as \ndiscussed in Chapter 8. In addition, scalability of services in the cloud is discussed explicitly \nin Chapter 17. Often, performance improvement happens after you have constructed a version of your \nsystem and found its performance to be inadequate. You can anticipate this by architecting \nyour system with performance in mind. For example, if you have designed the system with \na scalable resource pool, and you subsequently determine that this pool is a bottleneck (from \nyour instrumented data), then you can easily increase the size of the pool. If not, your options \nare limited\u2014and mostly all bad\u2014and they may involve considerable rework. It is not useful to spend a lot of your time optimizing a portion of the system that is \nresponsible for only a small percentage of the total time. Instrumenting the system by logging \ntiming information will help you determine where the actual time is spent and allow you to \nfocus on improving the performance of critical portions of the system. 9.1  \nPerformance General Scenario\nA performance scenario begins with an event arriving at the system.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 153", "position": 153, "chunk_type": "semantic", "token_estimate": 400}
{"text": "134 Part II Quality Attributes | Chapter 9 Performance: Instrumenting the system by logging \ntiming information will help you determine where the actual time is spent and allow you to \nfocus on improving the performance of critical portions of the system. 9.1  \nPerformance General Scenario\nA performance scenario begins with an event arriving at the system. Responding correctly \nto the event requires resources (including time) to be consumed. While this is happening, the \nsystem may be simultaneously servicing other events.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 153", "position": 153, "chunk_type": "semantic", "token_estimate": 80}
{"text": "9.1 Performance General Scenario 135: Concurrency\nConcurrency is one of the more important concepts that an architect must understand \nand one of the least-taught topics in computer science courses. Concurrency refers to \noperations occurring in parallel. For example, suppose there is a thread that executes \nthe statements\nx = 1;\nx++;\nand another thread that executes the same statements. What is the value of x after both \nthreads have executed those statements? It could be either 2 or 3. I leave it to you to \nfigure out how the value 3 could occur\u2014or should I say I interleave it to you? Concurrency occurs anytime your system creates a new thread, because threads, \nby definition, are independent sequences of control. Multitasking on your system is \nsupported by independent threads. Multiple users are simultaneously supported on \nyour system through the use of threads. Concurrency also occurs anytime your system \nis executing on more than one processor, whether those processors are packaged sep-\narately or as multi-core processors. In addition, you must consider concurrency when \nyou use parallel algorithms, parallelizing infrastructures such as map-reduce, or NoSQL \ndatabases, or when you use one of a variety of concurrent scheduling algorithms. In \nother words, concurrency is a tool available to you in many ways. Concurrency, when you have multiple CPUs or wait states that can exploit it, is a \ngood thing. Allowing operations to occur in parallel improves performance, because \ndelays introduced in one thread allow the processor to progress on another thread. But \nbecause of the interleaving phenomenon just described (referred to as a race condition), \nconcurrency must also be carefully managed. As our example shows, race conditions can occur when two threads of control are \npresent and there is shared state. The management of concurrency frequently comes \ndown to managing how state is shared. One technique for preventing race conditions is \nto use locks to enforce sequential access to state. Another technique is to partition the \nstate based on the thread executing a portion of code. That is, if we have two instances \nof x, x is not shared by the two threads and no race condition will occur. Race conditions are among the hardest types of bugs to discover; the occurrence of \nthe bug is sporadic and depends on (possibly minute) differences in timing. I once had a \nrace condition in an operating system that I could not track down.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 154", "position": 154, "chunk_type": "semantic", "token_estimate": 398}
{"text": "9.1 Performance General Scenario 135: Race conditions are among the hardest types of bugs to discover; the occurrence of \nthe bug is sporadic and depends on (possibly minute) differences in timing. I once had a \nrace condition in an operating system that I could not track down. I put a test in the code \nso that the next time the race condition occurred, a debugging process was triggered. It \ntook more than a year for the bug to recur so that the cause could be determined. Do not let the difficulties associated with concurrency dissuade you from utilizing this \nvery important technique. Just use it with the knowledge that you must carefully identify \ncritical sections in your code and ensure (or take actions to ensure) that race conditions \nwill not occur in those sections. \u2014LB\nTable 9.1 summarizes the general scenario for performance.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 154", "position": 154, "chunk_type": "semantic", "token_estimate": 143}
{"text": "136 Part II Quality Attributes | Chapter 9 Performance: TABLE 9.1 Performance General Scenario\nPortion of \nScenario\nDescription\nPossible Values\nSource\nThe stimulus can come from a user (or \nmultiple users), from an external system, \nor from some portion of the system \nunder consideration. External:\n \n\u25a0\nUser request\n \n\u25a0\nRequest from external system\n \n\u25a0\nData arriving from a sensor or other \nsystem\nInternal:\n \n\u25a0\nOne component may make a request of \nanother component. \u25a0\nA timer may generate a notification. Stimulus\nThe stimulus is the arrival of an \nevent. The event can be a request for \nservice or a notification of some state \nof either the system under consideration \nor an external system. Arrival of a periodic, sporadic, or \nstochastic event:\n \n\u25a0\nA periodic event arrives at a predictable \ninterval. \u25a0\nA stochastic event arrives according to \nsome probability distribution. \u25a0\nA sporadic event arrives according to \na pattern that is neither periodic nor \nstochastic. Artifact\nThe artifact stimulated may be the whole \nsystem or just a portion of the system. For example, a power-on event may \nstimulate the whole system. A user \nrequest may arrive at (stimulate) the \nuser interface. \u25a0\nWhole system\n \n\u25a0\nComponent within the system\nEnvironment\nThe state of the system or component \nwhen the stimulus arrives. Unusual \nmodes\u2014error mode, overloaded mode\u2014\nwill affect the response. For example, \nthree unsuccessful login attempts are \nallowed before a device is locked out. Runtime. The system or component can \nbe operating in:\n \n\u25a0\nNormal mode\n \n\u25a0\nEmergency mode\n \n\u25a0\nError correction mode\n \n\u25a0\nPeak load\n \n\u25a0\nOverload mode\n \n\u25a0\nDegraded operation mode\n \n\u25a0\nSome other defined mode of the \nsystem\nResponse\nThe system will process the stimulus. Processing the stimulus will take \ntime. This time may be required for \ncomputation, or it may be required \nbecause processing is blocked by \ncontention for shared resources. Requests can fail to be satisfied \nbecause the system is overloaded \nor because of a failure somewhere in \nthe processing chain. \u25a0\nSystem returns a response\n \n\u25a0\nSystem returns an error\n \n\u25a0\nSystem generates no response\n \n\u25a0\nSystem ignores the request if \noverloaded\n \n\u25a0\nSystem changes the mode or level of \nservice\n \n\u25a0\nSystem services a higher-priority event\n \n\u25a0\nSystem consumes resources", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 155", "position": 155, "chunk_type": "semantic", "token_estimate": 367}
{"text": "9.2 Tactics for Performance 137: Stimulus\nResponse\nResponse\nMeasure\nSource\n3\n2\n1\n4\nEnvironment\nArtifact\n500 users\nInitiate 2,000\nrequests in a \n30-second interval\nNormal operations\nProcesses all\nrequests\nAverage latency\nof 2 seconds\nSystem\nPortion of \nScenario\nDescription\nPossible Values\nResponse \nmeasure\nTiming measures can include latency \nor throughput. Systems with timing \ndeadlines can also measure jitter \nof response and ability to meet the \ndeadlines. Measuring how many of the \nrequests go unsatisfied is also a type of \nmeasure, as is how much of a computing \nresource (e.g., a CPU, memory, thread \npool, buffer) is utilized. \u25a0\nThe (maximum, minimum, mean, \nmedian) time the response takes \n(latency)\n \n\u25a0\nThe number or percentage of satisfied \nrequests over some time interval \n(throughput) or set of events received\n \n\u25a0\nThe number or percentage of requests \nthat go unsatisfied\n \n\u25a0\nThe variation in response time (jitter)\n \n\u25a0\nUsage level of a computing resource\nFigure 9.1 gives an example concrete performance scenario: Five hundred users initiate \n2,000 requests in a 30-second interval, under normal operations. The system processes all of \nthe requests with an average latency of two seconds. FIGURE 9.1 Sample performance scenario\n9.2  \nTactics for Performance\nThe goal of performance tactics is to generate a response to events arriving at the system under \nsome time-based or resource-based constraint. The event can be a single event or a stream, and \nis the trigger to perform computation. Performance tactics control the time or resources used \nto generate a response, as illustrated in Figure 9.2.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 156", "position": 156, "chunk_type": "semantic", "token_estimate": 251}
{"text": "138 Part II Quality Attributes | Chapter 9 Performance: Events arrive\nEvents processed\nwithin time and\nresource budgets\nTactics\nto Control\nResponse\nFIGURE 9.2 The goal of performance tactics\nAt any instant during the period after an event arrives but before the system\u2019s response to \nit is complete, either the system is working to respond to that event or the processing is blocked \nfor some reason. This leads to the two basic contributors to the response time and resource \nusage: processing time (when the system is working to respond and actively consuming resources) \nand blocked time (when the system is unable to respond). \u25a0Processing time and resource usage. Processing consumes resources, which takes time. Events are handled by the execution of one or more components, whose time expended \nis a resource. Hardware resources include CPU, data stores, network communication \nbandwidth, and memory. Software resources include entities defined by the system under \ndesign. For example, thread pools and buffers must be managed and access to critical \nsections must be made sequential. For example, suppose a message is generated by one component. It might be placed \non the network, after which it arrives at another component. It is then placed in a buffer; \ntransformed in some fashion; processed according to some algorithm; transformed for \noutput; placed in an output buffer; and sent onward to some component, another system, \nor some actor. Each of these steps contributes to the overall latency and resource con-\nsumption of the processing of that event. Different resources behave differently as their utilization approaches their capacity\u2014\nthat is, as they become saturated. For example, as a CPU becomes more heavily loaded, \nperformance usually degrades fairly steadily. In contrast, when you start to run out of \nmemory, at some point the page swapping becomes overwhelming and performance \ncrashes suddenly. \u25a0Blocked time and resource contention. A computation can be blocked because of con-\ntention for some needed resource, because the resource is unavailable, or because the \ncomputation depends on the result of other computations that are not yet available:\n \n\u25a0Contention for resources. Many resources can be used by only a single client at a time. As a consequence, other clients must wait for access to those resources. Figure 9.2", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 157", "position": 157, "chunk_type": "semantic", "token_estimate": 369}
{"text": "9.2 Tactics for Performance 139: shows events arriving at the system. These events may be in a single stream or in mul-\ntiple streams. Multiple streams vying for the same resource or different events in the \nsame stream vying for the same resource contribute to latency. The more contention \nfor a resource that occurs, the more latency grows. \u25a0Availability of resources. Even in the absence of contention, computation cannot pro-\nceed if a resource is unavailable. Unavailability may be caused by the resource being \noffline or by failure of the component for any reason. \u25a0Dependency on other computation. A computation may have to wait because it must \nsynchronize with the results of another computation or because it is waiting for the \nresults of a computation that it initiated. If a component calls another component and \nmust wait for that component to respond, the time can be significant when the called \ncomponent is at the other end of a network (as opposed to co-located on the same pro-\ncessor), or when the called component is heavily loaded. Whatever the cause, you must identify places in the architecture where resource limitations \nmight cause a significant contribution to overall latency. With this background, we turn to our tactic categories. We can either reduce demand \nfor resources (control resource demand) or make the resources we have available handle the \ndemand more effectively (manage resources). Control Resource Demand\nOne way to increase performance is to carefully manage the demand for resources. This can \nbe done by reducing the number of events processed or by limiting the rate at which the sys-\ntem responds to events. In addition, a number of techniques can be applied to ensure that the \nresources that you do have are applied judiciously:\n \n\u25a0Manage work requests. One way to reduce work is to reduce the number of requests \ncoming into the system to do work. Ways to do that include the following:\n \n\u25a0Manage event arrival. A common way to manage event arrivals from an external system \nis to put in place a service level agreement (SLA) that specifies the maximum event \narrival rate that you are willing to support.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 158", "position": 158, "chunk_type": "semantic", "token_estimate": 357}
{"text": "9.2 Tactics for Performance 139: Ways to do that include the following:\n \n\u25a0Manage event arrival. A common way to manage event arrivals from an external system \nis to put in place a service level agreement (SLA) that specifies the maximum event \narrival rate that you are willing to support. An SLA is an agreement of the form \u201cThe \nsystem or component will process X events arriving per unit time with a response time \nof Y.\u201d This agreement constrains both the system\u2014it must provide that response\u2014and \nthe client\u2014if it makes more than X requests per unit time, the response is not guaran-\nteed. Thus, from the client\u2019s perspective, if it needs more than X requests per unit time \nto be serviced, it must utilize multiple instances of the element processing the requests. SLAs are one method for managing scalability for Internet-based systems. \u25a0Manage sampling rate. In cases where the system cannot maintain adequate response \nlevels, you can reduce the sampling frequency of the stimuli\u2014for example, the rate at \nwhich data is received from a sensor or the number of video frames per second that \nyou process. Of course, the price paid here is the fidelity of the video stream or the \ninformation you gather from the sensor data. Nevertheless, this is a viable strategy if \nthe result is \u201cgood enough.\u201d Such an approach is commonly used in signal processing", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 158", "position": 158, "chunk_type": "semantic", "token_estimate": 228}
{"text": "140 Part II Quality Attributes | Chapter 9 Performance: systems where, for example, different codices can be chosen with different sampling \nrates and data formats. This design choice seeks to maintain predictable levels of \nlatency; you must decide whether having a lower fidelity but consistent stream of data \nis preferable to having erratic latency. Some systems manage the sampling rate dynam-\nically in response to latency measures or accuracy needs. \u25a0Limit event response. When discrete events arrive at the system (or component) too \nrapidly to be processed, then the events must be queued until they can be processed, or \nthey are simply discarded. You may choose to process events only up to a set maximum \nrate, thereby ensuring predictable processing for the events that are actually processed. This tactic could be triggered by a queue size or processor utilization exceeding some \nwarning level. Alternatively, it could be triggered by an event rate that violates an SLA. If you adopt this tactic and it is unacceptable to lose any events, then you must ensure \nthat your queues are large enough to handle the worst case. Conversely, if you choose to \ndrop events, then you need to choose a policy: Do you log the dropped events or simply \nignore them? Do you notify other systems, users, or administrators? \u25a0Prioritize events. If not all events are equally important, you can impose a priority \nscheme that ranks events according to how important it is to service them. If insufficient \nresources are available to service them when they arise, low-priority events might be \nignored. Ignoring events consumes minimal resources (including time), thereby increas-\ning performance compared to a system that services all events all the time. For example, \na building management system may raise a variety of alarms. Life-threatening alarms \nsuch as a fire alarm should be given higher priority than informational alarms such as a \nroom being too cold. \u25a0Reduce computational overhead. For events that do make it into the system, the follow-\ning approaches can be implemented to reduce the amount of work involved in handling \neach event:\n \n\u25a0Reduce indirection. The use of intermediaries (so important for modifiability, as we saw \nin Chapter 8) increases the computational overhead in processing an event stream, so \nremoving them improves latency. This is a classic modifiability/performance tradeoff.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 159", "position": 159, "chunk_type": "semantic", "token_estimate": 381}
{"text": "140 Part II Quality Attributes | Chapter 9 Performance: The use of intermediaries (so important for modifiability, as we saw \nin Chapter 8) increases the computational overhead in processing an event stream, so \nremoving them improves latency. This is a classic modifiability/performance tradeoff. Separation of concerns\u2014another linchpin of modifiability\u2014can also increase the pro-\ncessing overhead necessary to service an event if it leads to an event being serviced by \na chain of components rather than a single component. You may be able to realize the \nbest of both worlds, however: Clever code optimization can let you program using the \nintermediaries and interfaces that support encapsulation (and thus keep the modifiabil-\nity) but reduce, or in some cases eliminate, the costly indirection at runtime. Similarly, \nsome brokers allow for direct communication between a client and a server (after ini-\ntially establishing the relationship via the broker), thereby eliminating the indirection \nstep for all subsequent requests. \u25a0Co-locate communicating resources. Context switching and intercomponent com-\nmunication costs add up, especially when the components are on different nodes on a \nnetwork. One strategy for reducing computational overhead is to co-locate resources. Co-location may mean hosting cooperating components on the same processor to avoid", "domains": ["Design Patterns", "Design Principles", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 159", "position": 159, "chunk_type": "semantic", "token_estimate": 199}
{"text": "9.2 Tactics for Performance 141: the time delay of network communication; it may mean putting the resources in the \nsame runtime software component to avoid even the expense of a subroutine call; or it \nmay mean placing tiers of a multi-tier architecture on the same rack in the data center. \u25a0Periodic cleaning. A special case when reducing computational overhead is to perform \na periodic cleanup of resources that have become inefficient. For example, hash tables \nand virtual memory maps may require recalculation and reinitialization. Many system \nadministrators and even regular computer users do a periodic reboot of their systems \nfor exactly this reason. \u25a0Bound execution times. You can place a limit on how much execution time is used to \nrespond to an event. For iterative, data-dependent algorithms, limiting the number of \niterations is a method for bounding execution times. The cost, however, is usually a \nless accurate computation. If you adopt this tactic, you will need to assess its effect on \naccuracy and see if the result is \u201cgood enough.\u201d This resource management tactic is \nfrequently paired with the manage sampling rate tactic. \u25a0Increase efficiency of resource usage. Improving the efficiency of algorithms used in \ncritical areas can decrease latency and improve throughput and resource consumption. This is, for some programmers, their primary performance tactic. If the system does not \nperform adequately, they try to \u201ctune up\u201d their processing logic. As you can see, this \napproach is actually just one of many tactics available. Manage Resources\nEven if the demand for resources is not controllable, the management of these resources can \nbe. Sometimes one resource can be traded for another. For example, intermediate data may be \nkept in a cache or it may be regenerated depending on which resources are more critical: time, \nspace, or network bandwidth. Here are some resource management tactics:\n \n\u25a0Increase resources. Faster processors, additional processors, additional memory, and \nfaster networks all have the potential to improve performance. Cost is usually a con-\nsideration in the choice of resources, but increasing the resources is, in many cases, the \ncheapest way to get immediate improvement. \u25a0Introduce concurrency. If requests can be processed in parallel, the blocked time can be \nreduced. Concurrency can be introduced by processing different streams of events on \ndifferent threads or by creating additional threads to process different sets of activities.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 160", "position": 160, "chunk_type": "semantic", "token_estimate": 386}
{"text": "9.2 Tactics for Performance 141: If requests can be processed in parallel, the blocked time can be \nreduced. Concurrency can be introduced by processing different streams of events on \ndifferent threads or by creating additional threads to process different sets of activities. (Once concurrency has been introduced, you can choose scheduling policies to achieve \nthe goals you find desirable using the schedule resources tactic.) \u25a0Maintain multiple copies of computations. This tactic reduces the contention that would \noccur if all requests for service were allocated to a single instance. Replicated services \nin a microservice architecture or replicated web servers in a server pool are examples of \nreplicas of computation. A load balancer is a piece of software that assigns new work to \none of the available duplicate servers; criteria for assignment vary but can be as simple \nas a round-robin scheme or assigning the next request to the least busy server. The load \nbalancer pattern is discussed in detail in Section 9.4.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 160", "position": 160, "chunk_type": "semantic", "token_estimate": 161}
{"text": "142 Part II Quality Attributes | Chapter 9 Performance: \u25a0Maintain multiple copies of data. Two common examples of maintaining multiple copies of \ndata are data replication and caching. Data replication involves keeping separate copies \nof the data to reduce the contention from multiple simultaneous accesses. Because the \ndata being replicated is usually a copy of existing data, keeping the copies consistent and \nsynchronized becomes a responsibility that the system must assume. Caching also involves \nkeeping copies of data (with one set of data possibly being a subset of the other), but on \nstorage with different access speeds. The different access speeds may be due to memory \nspeed versus secondary storage speed, or the speed of local versus remote communication. Another responsibility with caching is choosing the data to be cached. Some caches oper-\nate by merely keeping copies of whatever was recently requested, but it is also possible to \npredict users\u2019 future requests based on patterns of behavior, and to begin the calculations \nor prefetches necessary to comply with those requests before the user has made them. \u25a0Bound queue sizes. This tactic controls the maximum number of queued arrivals and \nconsequently the resources used to process the arrivals. If you adopt this tactic, you \nneed to establish a policy for what happens when the queues overflow and decide if not \nresponding to lost events is acceptable. This tactic is frequently paired with the limit \nevent response tactic. \u25a0Schedule resources. Whenever contention for a resource occurs, the resource must be \nscheduled. Processors are scheduled, buffers are scheduled, and networks are sched-\nuled. Your concern as an architect is to understand the characteristics of each resource\u2019s \nuse and choose the scheduling strategy that is compatible with it. (See the \u201cScheduling \nPolicies\u201d sidebar.) Figure 9.3 summarizes the tactics for performance. Control Resource Demand\nManage Resources\nPerformance Tactics\nManage Work Requests\nLimit Event Response\nPrioritize Events\nReduce Computational Overhead\nBound Execution Times\n,QFUHDVH\u0003(I\u0182FLHQF\\\nIncrease Resources\n,QWURGXFH\u0003&RQFXUUHQF\\\nMaintain Multiple Copies of Computations\nMaintain Multiple Copies of Data\nBound Queue Sizes\nSchedule Resources\nFIGURE 9.3 Performance tactics", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 161", "position": 161, "chunk_type": "semantic", "token_estimate": 341}
{"text": "9.2 Tactics for Performance 143: Scheduling Policies\nA scheduling policy conceptually has two parts: a priority assignment and dispatching. All scheduling policies assign priorities. In some cases, the assignment is as simple as \nfirst-in/first-out (or FIFO). In other cases, it can be tied to the deadline of the request \nor its semantic importance. Competing criteria for scheduling include optimal resource \nusage, request importance, minimizing the number of resources used, minimizing \nlatency, maximizing throughput, preventing starvation to ensure fairness, and so forth. You need to be aware of these possibly conflicting criteria and the effect that the chosen \nscheduling policy has on the system\u2019s ability to meet them. A high-priority event stream can be dispatched\u2014assigned to a resource\u2014only if \nthat resource is available. Sometimes this depends on preempting the current user \nof the resource. Possible preemption options are as follows: can occur anytime, can \noccur only at specific preemption points, or executing processes cannot be preempted. Some common scheduling policies are these:\n \n\u25a0\nFirst-in/first-out. FIFO queues treat all requests for resources as equals and satisfy \nthem in turn. One possibility with a FIFO queue is that one request will be stuck \nbehind another one that takes a long time to generate a response. As long as all of \nthe requests are truly equal, this is not a problem\u2014but if some requests are of higher \npriority than others, it creates a challenge. \u25a0\nFixed-priority scheduling. Fixed-priority scheduling assigns each source of resource \nrequests a particular priority and assigns the resources in that priority order. This \nstrategy ensures better service for higher-priority requests. However, it also admits \nthe possibility that a lower-priority, but still important request might take an arbi-\ntrarily long time to be serviced, because it is stuck behind a series of higher-priority \nrequests. Three common prioritization strategies are these:\n \n\u25a0\nSemantic importance. Semantic importance assigns a priority statically according \nto some domain characteristic of the task that generates it. \u25a0\nDeadline monotonic. Deadline monotonic is a static priority assignment that \nassigns a higher priority to streams with shorter deadlines. This scheduling policy \nis used when scheduling streams of different priorities with real-time deadlines. \u25a0\nRate monotonic. Rate monotonic is a static priority assignment for periodic \nstreams that assigns a higher priority to streams with shorter periods. This sched-\nuling policy is a special case of deadline monotonic, but is better known and more \nlikely to be supported by the operating system. \u25a0\nDynamic priority scheduling.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 162", "position": 162, "chunk_type": "semantic", "token_estimate": 405}
{"text": "9.2 Tactics for Performance 143: This sched-\nuling policy is a special case of deadline monotonic, but is better known and more \nlikely to be supported by the operating system. \u25a0\nDynamic priority scheduling. Strategies include these:\n \n\u25a0\nRound-robin. The round-robin scheduling strategy orders the requests and then, \nat every assignment possibility, assigns the resource to the next request in that \norder. A special form of round-robin is a cyclic executive, where possible assign-\nment times are designated at fixed time intervals. \u25a0\nEarliest-deadline-first. Earliest-deadline-first assigns priorities based on the pend-\ning requests with the earliest deadline. \u25a0\nLeast-slack-first. This strategy assigns the highest priority to the job having the \nleast \u201cslack time,\u201d which is the difference between the execution time remaining \nand the time to the job\u2019s deadline.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 162", "position": 162, "chunk_type": "semantic", "token_estimate": 129}
{"text": "144 Part II Quality Attributes | Chapter 9 Performance: For a single processor and processes that are preemptible, both the earliest-\ndeadline-first and least-slack-first scheduling strategies are optimal choices. That is, \nif the set of processes can be scheduled so that all deadlines are met, then these \nstrategies will be able to schedule that set successfully. \u25a0\nStatic scheduling. A cyclic executive schedule is a scheduling strategy in which the \npreemption points and the sequence of assignment to the resource are determined \noffline. The runtime overhead of a scheduler is thereby obviated. Performance Tactics on the Road\nTactics are generic design principles. To exercise this point, think about the design of \nthe systems of roads and highways where you live. Traffic engineers employ a bunch of \ndesign \u201ctricks\u201d to optimize the performance of these complex systems, where perfor-\nmance has a number of measures, such as throughput (how many cars per hour get \nfrom the suburbs to the football stadium), average-case latency (how long it takes, on \naverage, to get from your house to downtown), and worst-case latency (how long does \nit take an emergency vehicle to get you to the hospital). What are these tricks? None \nother than our good old buddies, tactics. Let\u2019s consider some examples:\n \n\u25a0\nManage event rate. Lights on highway entrance ramps let cars onto the highway only \nat set intervals, and cars must wait (queue) on the ramp for their turn. \u25a0\nPrioritize events. Ambulances and police, with their lights and sirens going, have \nhigher priority than ordinary citizens; some highways have high-occupancy vehicle \n(HOV) lanes, giving priority to vehicles with two or more occupants. \u25a0\nMaintain multiple copies. Add traffic lanes to existing roads or build parallel routes. In addition, users of the system can employ their own tricks:\n \n\u25a0\nIncrease resources. Buy a Ferrari, for example. All other things being equal, being \nthe fastest car with a competent driver on an open road will get you to your destina-\ntion more quickly. \u25a0\nIncrease efficiency. Find a new route that is quicker and/or shorter than your current \nroute. \u25a0\nReduce computational overhead. Drive closer to the car in front of you, or load more \npeople into the same vehicle (i.e., carpooling). What is the point of this discussion? To paraphrase Gertrude Stein: Performance is \nperformance is performance.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 163", "position": 163, "chunk_type": "semantic", "token_estimate": 385}
{"text": "144 Part II Quality Attributes | Chapter 9 Performance: What is the point of this discussion? To paraphrase Gertrude Stein: Performance is \nperformance is performance. Engineers have been analyzing and optimizing complex \nsystems for centuries, trying to improve their performance, and they have been employ-\ning the same design strategies to do so. So you should feel some comfort in knowing \nthat when you try to improve the performance of your computer-based system, you are \napplying tactics that have been thoroughly \u201croad tested.\u201d\n\u2014RK", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 163", "position": 163, "chunk_type": "semantic", "token_estimate": 84}
{"text": "9.3 Tactics-Based Questionnaire for Performance 145: 9.3  \nTactics-Based Questionnaire for Performance\nBased on the tactics described in Section 9.2, we can create a set of tactics-inspired questions, \nas presented in Table 9.2. To gain an overview of the architectural choices made to support \nperformance, the analyst asks each question and records the answers in the table. The answers \nto these questions can then be made the focus of further activities: investigation of documenta-\ntion, analysis of code or other artifacts, reverse engineering of code, and so forth. TABLE 9.2 Tactics-Based Questionnaire for Performance \nTactics \nGroup\nTactics Question\nSupported? (Y/N)\nRisk\nDesign \nDecisions \nand \nLocation\nRationale \nand \nAssumptions\nControl \nResource \nDemand\nDo you have in place a service \nlevel agreement (SLA) that \nspecifies the maximum event \narrival rate that you are willing to \nsupport? Can you manage the rate at \nwhich you sample events arriving \nat the system? How will the system limit \nthe response (amount of \nprocessing) for an event? Have you defined different \ncategories of requests and \ndefined priorities for each \ncategory? Can you reduce computational \noverhead by, for example, co-\nlocation, cleaning up resources, \nor reducing indirection? Can you bound the execution \ntime of your algorithms? Can you increase \ncomputational efficiency \nthrough your choice of \nalgorithms? Manage \nResources\nCan you allocate more \nresources to the system or its \ncomponents? Are you employing \nconcurrency? If requests can \nbe processed in parallel, the \nblocked time can be reduced. Can computations be \nreplicated on different \nprocessors? continues", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 164", "position": 164, "chunk_type": "semantic", "token_estimate": 246}
{"text": "146 Part II Quality Attributes | Chapter 9 Performance: Tactics \nGroup\nTactics Question\nSupported? (Y/N)\nRisk\nDesign \nDecisions \nand \nLocation\nRationale \nand \nAssumptions\nManage \nResources\nCan data be cached (to \nmaintain a local copy that can be \nquickly accessed) or replicated \n(to reduce contention)? Can queue sizes be bounded \nto place an upper bound on the \nresources needed to process \nstimuli? Have you ensured that the \nscheduling strategies you are \nusing are appropriate for your \nperformance concerns? 9.4  \nPatterns for Performance\nPerformance concerns have plagued software engineers for decades, so it comes as no surprise \nthat a rich set of patterns have been developed for managing various aspects of performance. In this section, we sample just a few of them. Note that some patterns serve multiple purposes. For example, we saw the circuit breaker pattern in Chapter 4, where it was identified as an \navailability pattern, but it also has a benefit for performance\u2014since it reduces the time that \nyou wait around for nonresponsive services. The patterns we will introduce here are service mesh, load balancer, throttling, and \nmap-reduce. Service Mesh\nThe service mesh pattern is used in microservice architectures. The main feature of the mesh \nis a sidecar\u2014a kind of proxy that accompanies each microservice, and which provides broadly \nuseful capabilities to address application-independent concerns such as interservice communi-\ncations, monitoring, and security. A sidecar executes alongside each microservice and handles \nall interservice communication and coordination. (As we will describe in Chapter 16, these \nelements are often packaged into pods.) They are deployed together, which cuts down on the \nlatency due to networking, thereby boosting performance. This approach allows developers to separate the functionality\u2014the core business logic\u2014\nof the microservice from the implementation, management, and maintenance of cross-cutting \nconcerns, such as authentication and authorization, service discovery, load balancing, encryp-\ntion, and observability. TABLE 9.2 Tactics-Based Questionnaire for Performance continued", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 165", "position": 165, "chunk_type": "semantic", "token_estimate": 310}
{"text": "9.4 Patterns for Performance 147: Benefits:\n \n\u25a0Software to manage cross-cutting concerns can be purchased off the shelf or imple-\nmented and maintained by a specialist team that does nothing else, allowing developers \nof the business logic to focus on only that concern. \u25a0A service mesh enforces the deployment of utility functions onto the same processor \nas the services that use those utility functions. This cuts down on communication time \nbetween the service and its utilities since the communication does not need to use net-\nwork messages. \u25a0The service mesh can be configured to make communication dependent on context, thus \nsimplifying functions such as the canary and A/B testing described in Chapter 3. Tradeoffs:\n \n\u25a0The sidecars introduce more executing processes, and each of these will consume some \nprocessing power, adding to the system\u2019s overhead. \u25a0A sidecar typically includes multiple functions, and not all of these will be needed in \nevery service or every invocation of a service. Load Balancer\nA load balancer is a kind of intermediary that handles messages originating from some set \nof clients and determines which instance of a service should respond to those messages. The \nkey to this pattern is that the load balancer serves as a single point of contact for incoming \nmessages\u2014for example, a single IP address\u2014but it then farms out requests to a pool of pro-\nviders (servers or services) that can respond to the request. In this way, the load can be bal-\nanced across the pool of providers. The load balancer implements some form of the schedule \nresources tactic. The scheduling algorithm may be very simple, such as round-robin, or it may \ntake into account the load on each provider, or the number of requests awaiting service at each \nprovider. Benefits:\n \n\u25a0Any failure of a server is invisible to clients (assuming there are still some remaining \nprocessing resources). \u25a0By sharing the load among several providers, latency can be kept lower and more pre-\ndictable for clients. \u25a0It is relatively simple to add more resources (more servers, faster servers) to the pool \navailable to the load balancer, and no client needs to be aware of this. Tradeoffs:\n \n\u25a0The load balancing algorithm must be very fast; otherwise, it may itself contribute to \nperformance problems. \u25a0The load balancer is a potential bottleneck or single point of failure, so it is itself often \nreplicated (and even load balanced). Load balancers are discussed in much more detail in Chapter 17.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 166", "position": 166, "chunk_type": "semantic", "token_estimate": 403}
{"text": "148 Part II Quality Attributes | Chapter 9 Performance: Throttling\nThe throttling pattern is a packaging of the manage work requests tactic. It is used to limit access \nto some important resource or service. In this pattern, there is typically an intermediary\u2014a \nthrottler\u2014that monitors (requests to) the service and determines whether an incoming request \ncan be serviced. Benefits:\n \n\u25a0By throttling incoming requests, you can gracefully handle variations in demand. In \ndoing so, services never become overloaded; they can be kept in a performance \u201csweet \nspot\u201d where they handle requests efficiently. Tradeoffs:\n \n\u25a0The throttling logic must be very fast; otherwise, it may itself contribute to performance \nproblems. \u25a0If client demand regularly exceeds capacity, buffers will need to be very large, or there is \na risk of losing requests. \u25a0This pattern can be difficult to add to an existing system where clients and servers are \ntightly coupled. Map-Reduce\nThe map-reduce pattern efficiently performs a distributed and parallel sort of a large data set \nand provides a simple means for the programmer to specify the analysis to be done. Unlike \nour other patterns for performance, which are independent of any application, the map- \nreduce \npattern is specifically designed to bring high performance to a specific kind of recurring \nproblem: sort and analyze a large data set. This problem is experienced by any organization \ndealing with massive data\u2014think Google, Facebook, Yahoo, and Netflix\u2014and all of these \norganizations do in fact use map-reduce. The map-reduce pattern has three parts:\n \n\u25a0First is a specialized infrastructure that takes care of allocating software to the hardware \nnodes in a massively parallel computing environment and handles sorting the data as \nneeded. A node may be a virtual machine, a standalone processor, or a core in a multi-\ncore chip. \u25a0Second and third are two programmer-coded functions called, predictably enough, map \nand reduce. \u25a0The map function takes as input a key and a data set. It uses the key to hash the data \ninto a set of buckets. For example, if our data set consisted of playing cards, the key \ncould be the suit. The map function is also used to filter the data\u2014that is, determine \nwhether a data record is to be involved in further processing or discarded. Continuing \nour card example, we might choose to discard jokers or letter cards (A, K, Q, J), \nkeeping only numeric cards, and we could then map each card into a bucket, based on \nits suit.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 167", "position": 167, "chunk_type": "semantic", "token_estimate": 404}
{"text": "148 Part II Quality Attributes | Chapter 9 Performance: The map function is also used to filter the data\u2014that is, determine \nwhether a data record is to be involved in further processing or discarded. Continuing \nour card example, we might choose to discard jokers or letter cards (A, K, Q, J), \nkeeping only numeric cards, and we could then map each card into a bucket, based on \nits suit. The performance of the map phase of the map-reduce pattern is enhanced by \nhaving multiple map instances, each of which processes a different portion of the data", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 167", "position": 167, "chunk_type": "semantic", "token_estimate": 96}
{"text": "9.5 For Further Reading 149: set. An input file is divided into portions, and a number of map instances are created \nto process each portion. Continuing our example, let\u2019s consider that we have 1 billion \nplaying cards, not just a single deck. Since each card can be examined in isolation, \nthe map process can be carried out by tens or hundreds of thousands of instances in \nparallel, with no need for communication among them. Once all of the input data has \nbeen mapped, these buckets are shuffled by the map-reduce infrastructure, and then \nassigned to new processing nodes (possibly reusing the nodes used in the map phase) \nfor the reduce phase. For example, all of the clubs could be assigned to one cluster of \ninstances, all of the diamonds to another cluster, and so forth. \u25a0All of the heavy analysis takes place in the reduce function. The number of reduce \ninstances corresponds to the number of buckets output by the map function. The \nreduce phase does some programmer-specified analysis and then emits the results of \nthat analysis. For example, we could count the number of clubs, diamonds, hearts, and \nspades, or we could sum the numeric values of all of the cards in each bucket. The out-\nput set is almost always much smaller than the input sets\u2014hence the name \u201creduce.\u201d\nThe map instances are stateless and do not communicate with each other. The only com-\nmunication between the map instances and the reduce instances is the data emitted from the \nmap instances as <key, value> pairs. Benefits:\n \n\u25a0Extremely large, unsorted data sets can be efficiently analyzed through the exploitation \nof parallelism. \u25a0A failure of any instance has only a small impact on the processing, since map-reduce \ntypically breaks large input datasets into many smaller ones for processing, allocating \neach to its own instance. Tradeoffs:\n \n\u25a0If you do not have large data sets, the overhead incurred by the map-reduce pattern is not \njustified. \u25a0If you cannot divide your data set into similarly sized subsets, the advantages of parallel-\nism are lost. \u25a0Operations that require multiple reduces are complex to orchestrate. 9.5  \nFor Further Reading\nPerformance is the subject of a rich body of literature. Here are some books we recommend as \ngeneral overviews of performance:\n \n\u25a0 \nFoundations of Software and System Performance Engineering: Process, Performance \nModeling, Requirements, Testing, Scalability, and Practice [Bondi 14].", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 168", "position": 168, "chunk_type": "semantic", "token_estimate": 393}
{"text": "9.5 For Further Reading 149: 9.5  \nFor Further Reading\nPerformance is the subject of a rich body of literature. Here are some books we recommend as \ngeneral overviews of performance:\n \n\u25a0 \nFoundations of Software and System Performance Engineering: Process, Performance \nModeling, Requirements, Testing, Scalability, and Practice [Bondi 14]. This book \nprovides a comprehensive overview of performance engineering, ranging from technical \npractices to organizational ones.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 168", "position": 168, "chunk_type": "semantic", "token_estimate": 64}
{"text": "150 Part II Quality Attributes | Chapter 9 Performance: \u25a0Software Performance and Scalability: A Quantitative Approach [Liu 09]. This book \ncovers performance geared toward enterprise applications, with an emphasis on queue-\ning theory and measurement. \u25a0Performance Solutions: A Practical Guide to Creating Responsive, Scalable Software \n[Smith 01]. This book covers designing with performance in mind, with emphasis on \nbuilding (and populating with real data) practical predictive performance models. To get an overview of some of the many patterns for performance, see Real-Time Design \nPatterns: Robust Scalable Architecture for Real-Time Systems [Douglass 99] and Pattern-\nOriented Software Architecture Volume 3: Patterns for Resource Management [Kircherb03]. In addition, Microsoft has published a catalog of performance and scalability patterns for \ncloud-based applications: https://docs.microsoft.com/en-us/azure/architecture/patterns/category/\nperformance-scalability. 9.6  \nDiscussion Questions\n1. \u201cEvery system has real-time performance constraints.\u201d Discuss. Can you provide a \ncounterexample? 2. Write a concrete performance scenario that describes the average on-time flight arrival \nperformance for an airline. 3. Write several performance scenarios for an online auction site. Think about whether \nyour major concern is worst-case latency, average-case latency, throughput, or some \nother response measure. Which tactics would you use to satisfy your scenarios? 4. Web-based systems often use proxy servers, which are the first element of the system to \nreceive a request from a client (such as your browser). Proxy servers are able to serve up \noften-requested web pages, such as a company\u2019s home page, without bothering the real \napplication servers that carry out transactions. A system may include many proxy servers, \nand they are often located geographically close to large user communities, to decrease \nresponse time for routine requests. What performance tactics do you see at work here? 5. A fundamental difference between interaction mechanisms is whether interaction is \nsynchronous or asynchronous. Discuss the advantages and disadvantages of each with \nrespect to each of these performance responses: latency, deadline, throughput, jitter, miss \nrate, data loss, or any other required performance-related response you may be used to. 6. Find physical-world (that is, non-software) examples of applying each of the manage \nresources tactics. For example, suppose you were managing a brick-and-mortar big-box \nretail store. How would you get people through the checkout lines faster using these \ntactics? 7. User interface frameworks typically are single-threaded. Why is this? What are the per-\nformance implications? (Hint: Think about race conditions.)", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 169", "position": 169, "chunk_type": "semantic", "token_estimate": 384}
{"text": "152 Part II Quality Attributes | Chapter 10 Safety: that connect hardware to software; they are the bridge between the world of 0s and 1s and the \nworld of motion and control. Send a digital value to an actuator (or write a bit string in the \nhardware register corresponding to the actuator) and that value is translated to some mechani-\ncal action, for better or worse. But connecting to the outside world doesn\u2019t have to mean robot arms or uranium centri-\nfuges or missile launchers: Connecting to a simple display screen is enough. Sometimes all the \ncomputer has to do is send erroneous information to its human operators. In September 1983, \na Soviet satellite sent data to its ground system computer, which interpreted that data as a mis-\nsile launched from the United States aimed at Moscow. Seconds later, the computer reported a \nsecond missile in flight. Soon, a third, then a fourth, and then a fifth appeared. Soviet Strategic \nRocket Forces Lieutenant Colonel Stanislav Yevgrafovich Petrov made the astonishing deci-\nsion to ignore the computers, believing them to be in error. He thought it extremely unlikely \nthat the United States would have fired just a few missiles, thereby inviting mass retaliatory \ndestruction. He decided to wait it out, to see if the missiles were real\u2014that is, to see if his \ncountry\u2019s capital city was going to be incinerated. As we know, it wasn\u2019t. The Soviet system \nhad mistaken a rare sunlight condition for missiles in flight. You and/or your parents may well \nowe your life to Lieutenant Colonel Petrov. Of course, the humans don\u2019t always get it right when the computers get it wrong. On \nthe stormy night of June 1, 2009, Air France flight 447 from Rio de Janeiro to Paris plum-\nmeted into the Atlantic Ocean, killing all 228 people on board, despite the aircraft\u2019s engines \nand flight controls working perfectly. The Airbus A-330\u2019s flight recorders, which were not \nrecovered until May 2011, showed that the pilots never knew that the aircraft had entered a \nhigh-altitude stall. The sensors that measure airspeed had become clogged with ice and there-\nfore unreliable; the autopilot disengaged as a result. The human pilots thought the aircraft \nwas going too fast (and in danger of structural failure) when in fact it was going too slow (and \nfalling).", "domains": ["Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 171", "position": 171, "chunk_type": "semantic", "token_estimate": 386}
{"text": "152 Part II Quality Attributes | Chapter 10 Safety: The sensors that measure airspeed had become clogged with ice and there-\nfore unreliable; the autopilot disengaged as a result. The human pilots thought the aircraft \nwas going too fast (and in danger of structural failure) when in fact it was going too slow (and \nfalling). During the entire 3-minute-plus plunge from 35,000 feet, the pilots kept trying to pull \nthe nose up and throttle back to lower the speed, when all they needed to do was lower the \nnose to increase the speed and resume normal flying. Very probably adding to the confusion \nwas the way the A-330\u2019s stall warning system worked. When the system detects a stall, it emits \na loud audible alarm. The software deactivates the stall warning when it \u201cthinks\u201d that the \nangle of attack measurements are invalid. This can occur when the airspeed readings are very \nlow. That is what happened with AF447: Its forward speed dropped below 60 knots, and the \nangle of attack was extremely high. As a consequence of this flight control software rule, the \nstall warning stopped and started several times. Worse, it came on whenever the pilot pushed \n \nforward on the stick (increasing the airspeed and taking the readings into the \u201cvalid\u201d range, \nbut still in stall) and then stopped when he pulled back. That is, doing the right thing resulted \nin exactly the wrong feedback, and vice versa. Was this an unsafe system, or a safe system \noperated unsafely? Ultimately questions like this are decided in the courts. As this edition was going to publication, Boeing was still reeling from the grounding \nof its 737 MAX aircraft after two crashes that appear to have been caused at least partly by \na piece of software called MCAS, which pushed the aircraft\u2019s nose down at the wrong time. Faulty sensors seem to be involved here, too, as well as a baffling design decision that caused \nthe software to rely on only one sensor to determine its behavior, instead of the two available \non the aircraft. It also appears that Boeing never tested the software in question under the", "domains": ["Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 171", "position": 171, "chunk_type": "semantic", "token_estimate": 356}
{"text": "Part II Quality Attributes | Chapter 10 Safety 153: conditions of a sensor failure. The company did provide a way to disable the system in flight, \nalthough remembering how to do that when your airplane is doing its best to kill you may be \nasking a lot of a flight crew\u2014especially when they were never made aware of the existence \nof the MCAS in the first place. In total, 346 people died in the two crashes of the 737 MAX. Okay, enough scary stories. Let\u2019s talk about the principles behind them as they affect \nsoftware and architectures. Safety is concerned with a system\u2019s ability to avoid straying into states that cause or lead \nto damage, injury, or loss of life to actors in its environment. These unsafe states can be caused \nby a variety of factors:\n \n\u25a0Omissions (the failure of an event to occur). \u25a0Commission (the spurious occurrence of an undesirable event). The event could be \nacceptable in some system states but undesirable in others. \u25a0Timing. Early (the occurrence of an event before the time required) or late (the occur-\nrence of an event after the time required) timing can both be potentially problematic. \u25a0Problems with system values. These come in two categories: Coarse incorrect values are \nincorrect but detectable, whereas subtle incorrect values are typically undetectable. \u25a0Sequence omission and commission. In a sequence of events, either an event is missing \n(omission) or an unexpected event is inserted (commission). \u25a0Out of sequence. A sequence of events arrive, but not in the prescribed order. Safety is also concerned with detecting and recovering from these unsafe states to pre-\nvent or at least minimize resulting harm. Any portion of the system can lead to an unsafe state: The software, the hardware por-\ntions, or the environment can behave in an unanticipated, unsafe fashion. Once an unsafe state \nis detected, the potential system responses are similar to those enumerated for availability (in \nChapter 4). The unsafe state should be recognized and the system should be made through\n \n\u25a0Continuing operations after recovering from the unsafe state or placing the system in a \nsafe mode, or\n \n\u25a0Shutting down (fail safe), or\n \n\u25a0Transitioning to a state requiring manual operation (e.g., manual steering if the power \nsteering in a car fails). In addition, the unsafe state should be reported immediately and/or logged.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 172", "position": 172, "chunk_type": "semantic", "token_estimate": 385}
{"text": "Part II Quality Attributes | Chapter 10 Safety 153: The unsafe state should be recognized and the system should be made through\n \n\u25a0Continuing operations after recovering from the unsafe state or placing the system in a \nsafe mode, or\n \n\u25a0Shutting down (fail safe), or\n \n\u25a0Transitioning to a state requiring manual operation (e.g., manual steering if the power \nsteering in a car fails). In addition, the unsafe state should be reported immediately and/or logged. Architecting for safety begins by identifying the system\u2019s safety-critical functions\u2014those \nfunctions that could cause harm as just outlined\u2014using techniques such as failure mode and \neffects analysis (FMEA; also called hazard analysis) and fault tree analysis (FTA). FTA is a \ntop-down deductive approach to identify failures that could result in moving the system into an \nunsafe state. Once the failures have been identified, the architect needs to design mechanisms \nto detect and mitigate the fault (and ultimately the hazard). The techniques outlined in this chapter are intended to discover possible hazards that \ncould result from the system\u2019s operation and help in creating strategies to cope with these \nhazards.", "domains": ["Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 172", "position": 172, "chunk_type": "semantic", "token_estimate": 180}
{"text": "154 Part II Quality Attributes | Chapter 10 Safety: 10.1  \nSafety General Scenario\nWith this background, we can construct the general scenario for safety, shown in Table 10.1. TABLE 10.1 Safety General Scenario\nPortion of\nScenario\nDescription\nPossible Values\nSource\nA data source (a sensor, \na software component \nthat calculates a value, a \ncommunication channel), a time \nsource (clock), or a user action\nSpecific instances of a:\n \n\u25a0\nSensor\n \n\u25a0\nSoftware component\n \n\u25a0\nCommunication channel\n \n\u25a0\nDevice (such as a clock)\nStimulus \nAn omission, commission, or \noccurrence of incorrect data or \ntiming\nA specific instance of an omission:\n \n\u25a0\nA value never arrives. \u25a0\nA function is never performed. A specific instance of a commission:\n \n\u25a0\nA function is performed incorrectly. \u25a0\nA device produces a spurious event. \u25a0\nA device produces incorrect data. A specific instance of incorrect data:\n \n\u25a0\nA sensor reports incorrect data. \u25a0\nA software component produces incorrect \nresults. A timing failure:\n \n\u25a0\nData arrives too late or too early. \u25a0\nA generated event occurs too late or too early \nor at the wrong rate. \u25a0\nEvents occur in the wrong order. Environment \nSystem operating mode\n \n\u25a0\nNormal operation\n \n\u25a0\nDegraded operation\n \n\u25a0\nManual operation\n \n\u25a0\nRecovery mode\nArtifacts\nThe artifact is some part of the \nsystem. Safety-critical portions of the system\nResponse\nThe system does not leave a \nsafe state space, or the system \nreturns to a safe state space, or \nthe system continues to operate \nin a degraded mode to prevent \n(further) injury or damage or \nto minimize injury or damage. Users are advised of the unsafe \nstate or the prevention of entry \ninto the unsafe state. The event \nis logged. Recognize the unsafe state and one or more of \nthe following:\n \n\u25a0\nAvoid the unsafe state\n \n\u25a0\nRecover\n \n\u25a0\nContinue in degraded or safe mode\n \n\u25a0\nShut down\n \n\u25a0\nSwitch to manual operation\n \n\u25a0\nSwitch to a backup system\n \n\u25a0\nNotify appropriate entities (people or systems)\n \n\u25a0\nLog the unsafe state (and the response to it)", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 173", "position": 173, "chunk_type": "semantic", "token_estimate": 333}
{"text": "10.1 Safety General Scenario 155: Stimulus\nResponse\nResponse\nMeasure\nSource\n3\n2\n1\n4\nEnvironment\nArtifact\nA sensor\nFails to report a life-\ncritical value after\n100 ms\nNormal operations\nThe failure is logged, a\nwarning light is illuminated \non the console, and a \nEDFNXS\u0003\u000bORZHU\u0003\u0182GHOLW\\\f\u0003\nsensor is engaged; \nWKH\u0003V\\VWHP\u0003PRQLWRUV\u0003WKH\u0003\npatient using the backup \nsensor\nAfter no more \nthan 300 ms\n3DWLHQW\u0003PRQLWRULQJ\u0003V\\VWHP\nPortion of\nScenario\nDescription\nPossible Values\nResponse \nmeasure\nTime to return to safe state \nspace; damage or injury caused\nOne or more of the following:\n \n\u25a0\nAmount or percentage of entries into unsafe \nstates that are avoided\n \n\u25a0\nAmount or percentages of unsafe states from \nwhich the system can (automatically) recover\n \n\u25a0\nChange in risk exposure: size(loss) * prob(loss)\n \n\u25a0\nPercentage of time the system can recover\n \n\u25a0\nAmount of time the system is in a degraded or \nsafe mode\n \n\u25a0\nAmount or percentage of time the system is \nshut down\n \n\u25a0\nElapsed time to enter and recover (from \nmanual operation, from a safe or degraded \nmode)\nA sample safety scenario is: A sensor in the patient monitoring system fails to report a \nlife-critical value after 100 ms. The failure is logged, a warning light is illuminated on the \nconsole, and a backup (lower-fidelity) sensor is engaged. The system monitors the patient \nusing the backup sensor after no more than 300 ms. Figure 10.1 illustrates this scenario. FIGURE 10.1 Sample concrete safety scenario", "domains": ["Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 174", "position": 174, "chunk_type": "semantic", "token_estimate": 236}
{"text": "156 Part II Quality Attributes | Chapter 10 Safety: 10.2  \nTactics for Safety\nSafety tactics may be broadly categorized as unsafe state avoidance, unsafe state detection, or \nunsafe state remediation. Figure 10.2 shows the goal of the set of safety tactics. Unsafe state entered \nor imminent\nUnsafe state detected,\navoided, or contained;\nrecovery occurs; and \nsafe operation continues\nTactics\nto Control\nResponse\nFIGURE 10.2 Goal of safety tactics\nA logical precondition to avoid or detect entry into an unsafe state is the ability to rec-\nognize what constitutes an unsafe state. The following tactics assume that capability, which \nmeans that you should perform your own hazard analysis or FTA once you have your architec-\nture in hand. Your design decisions may themselves have introduced new safety vulnerabilities \nnot accounted for during requirements analysis. You will note a substantial overlap between the tactics presented here and those presented \nin Chapter 4 on availability. This overlap occurs because availability problems may often lead \nto safety problems, and because many of the design solutions for repairing these problems are \nshared between the qualities. Figure 10.3 summarizes the architectural tactics to achieve safety. Unsafe State Avoidance\nSubstitution\nThis tactic employs protection mechanisms\u2014often hardware-based\u2014for potentially danger-\nous software design features. For example, hardware protection devices such as watchdogs, \nmonitors, and interlocks can be used in lieu of software versions. Software versions of these \nmechanisms can be starved of resources, whereas a separate hardware device provides and \ncontrols its own resources. Substitution is typically beneficial only when the function being \nreplaced is relatively simple.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 175", "position": 175, "chunk_type": "semantic", "token_estimate": 258}
{"text": "10.2 Tactics for Safety 157: Unsafe State\nAvoidance\nRecovery\nContainment\nSafety Tactics\nSubstitution\nPredictive Model\nUnsafe State\nDetection\nSanity Check\nComparison\nTimeout\nCondition Monitoring\nTimestamp\nReplication\nAnalytic Redundancy\nFunctional Redundancy\nMasking\nAbort\nDegradation\nFirewall\nInterlock\nRollback\n5HFRQ\u0182JXUDWLRQ\nRepair State\nBarrier\nRedundancy\nLimit\nConsequences\nFIGURE 10.3 Safety tactics\nPredictive Model\nThe predictive model tactic, as introduced in Chapter 4, predicts the state of health of system \nprocesses, resources, or other properties (based on monitoring the state), not only to ensure \nthat the system is operating within its nominal operating parameters but also to provide early \nwarning of a potential problem. For example, some automotive cruise control systems calcu-\nlate the closing rate between the vehicle and an obstacle (or another vehicle) ahead and warn \nthe driver before the distance and time become too small to avoid a collision. A predictive \nmodel is typically combined with condition monitoring, which we discuss later. Unsafe State Detection\nTimeout\nThe timeout tactic is used to determine whether the operation of a component is meeting its \ntiming constraints. This might be realized in the form of an exception being raised, to indicate \nthe failure of a component if its timing constraints are not met. Thus this tactic can detect \nlate timing and omission failures. Timeout is a particularly common tactic in real-time or", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 176", "position": 176, "chunk_type": "semantic", "token_estimate": 217}
{"text": "158 Part II Quality Attributes | Chapter 10 Safety: embedded systems and distributed systems. It is related to the availability tactics of system \nmonitor, heartbeat, and ping-echo. Timestamp\nAs described in Chapter 4, the timestamp tactic is used to detect incorrect sequences of events, \nprimarily in distributed message-passing systems. A timestamp of an event can be estab-\nlished by assigning the state of a local clock to the event immediately after the event occurs. Sequence numbers can also be used for this purpose, since timestamps in a distributed system \nmay be inconsistent across different processors. Condition Monitoring \nThis tactic involves checking conditions in a process or device, or validating assumptions \nmade during the design, perhaps by using assertions. Condition monitoring identifies system \nstates that may lead to hazardous behavior. However, the monitor should be simple (and, ide-\nally, provable) to ensure that it does not introduce new software errors or contribute signifi-\ncantly to overall workload. Condition monitoring provides the input to a predictive model and \nto sanity checking. Sanity Checking\nThe sanity checking tactic checks the validity or reasonableness of specific operation results, \nor inputs or outputs of a component. This tactic is typically based on a knowledge of the inter-\nnal design, the state of the system, or the nature of the information under scrutiny. It is most \noften employed at interfaces, to examine a specific information flow. Comparison\nThe comparison tactic allows the system to detect unsafe states by comparing the outputs \nproduced by a number of synchronized or replicated elements. Thus the comparison tactic \nworks together with a redundancy tactic, typically the active redundancy tactic presented in \nthe discussion of availability. When the number of replicants is three or greater, the compari-\nson tactic can not only detect an unsafe state but also indicate which component has led to it. Comparison is related to the voting tactic used in availability. However, a comparison may not \nalways lead to a vote; another option is to simply shut down if outputs differ. Containment\nContainment tactics seek to limit the harm associated with an unsafe state that has been \nentered. This category includes three subcategories: redundancy, limit consequences, and \nbarrier. Redundancy\nThe redundancy tactics, at first glance, appear to be similar to the various sparing/redun-\ndancy tactics presented in the discussion of availability. Clearly, these tactics overlap, but since \nthe goals of safety and availability are different, the use of backup components differs. In", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 177", "position": 177, "chunk_type": "semantic", "token_estimate": 405}
{"text": "10.2 Tactics for Safety 159: the realm of safety, redundancy enables the system to continue operation in the case where a \ntotal shutdown or further degradation would be undesirable. Replication is the simplest redundancy tactic, as it just involves having clones of a com-\nponent. Having multiple copies of identical components can be effective in protecting against \nrandom failures of hardware, but it cannot protect against design or implementation errors in \nhardware or software since there is no form of diversity embedded in this tactic. Functional redundancy, by contrast, is intended to address the issue of common-mode \nfailures (where replicas exhibit the same fault at the same time because they share the same \nimplementation) in hardware or software components, by implementing design diversity. This \ntactic attempts to deal with the systematic nature of design faults by adding diversity to redun-\ndancy. The outputs of functionally redundant components should be the same given the same \ninput. The functional redundancy tactic is still vulnerable to specification errors, however, and \nof course, functional replicas will be more expensive to develop and verify. Finally, the analytic redundancy tactic permits not only diversity of components, but also \na higher-level diversity that is visible at the input and output level. As a consequence, it can tol-\nerate specification errors by using separate requirement specifications. Analytic redundancy \noften involves partitioning the system into high assurance and high performance (low assur-\nance) portions. The high assurance portion is designed to be simple and reliable, whereas the \nhigh performance portion is typically designed to be more complex and more accurate, but \nless stable: It changes more rapidly, and may not be as reliable as the high assurance portion. (Hence, here we do not mean high performance in the sense of latency or throughput; rather, \nthis portion \u201cperforms\u201d its task better than the high assurance portion.) Limit Consequences\nThe second subcategory of containment tactics is called limit consequences. These tactics are \nall intended to limit the bad effects that may result from the system entering an unsafe state. The abort tactic is conceptually the simplest. If an operation is determined to be unsafe, \nit is aborted before it can cause damage. This technique is widely employed to ensure that sys-\ntems fail safely. The degradation tactic maintains the most critical system functions in the presence of \ncomponent failures, dropping or replacing functionality in a controlled way.", "domains": ["Design Patterns", "Software Quality Attributes", "Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 178", "position": 178, "chunk_type": "semantic", "token_estimate": 396}
{"text": "10.2 Tactics for Safety 159: This technique is widely employed to ensure that sys-\ntems fail safely. The degradation tactic maintains the most critical system functions in the presence of \ncomponent failures, dropping or replacing functionality in a controlled way. This approach \nallows individual component failures to gracefully reduce system functionality in a planned, \ndeliberate, and safe way, rather than causing a complete system failure. For example, a car \nnavigation system may continue to operate using a (less accurate) dead reckoning algorithm in \na long tunnel where it has lost its GPS satellite signal. The masking tactic masks a fault by comparing the results of several redundant compo-\nnents and employing a voting procedure in case one or more of the components differ. For this \ntactic to work as intended, the voter must be simple and highly reliable. Barrier\nThe barrier tactics contain problems by keeping them from propagating. The firewall tactic is a specific realization of the limit access tactic, which is described in \nChapter 11. A firewall limits access to specified resources, typically processors, memory, and \nnetwork connections.", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 178", "position": 178, "chunk_type": "semantic", "token_estimate": 180}
{"text": "160 Part II Quality Attributes | Chapter 10 Safety: The interlock tactic protects against failures arising from incorrect sequencing of events. Realizations of this tactic provide elaborate protection schemes by controlling all access to \nprotected components, including controlling the correct sequencing of events affecting those \ncomponents. Recovery\nThe final category of safety tactics is recovery, which acts to place the system in a safe state. It \nencompasses three tactics: rollback, repair state, and reconfiguration. The rollback tactic permits the system to revert to a saved copy of a previous known good \nstate\u2014the rollback line\u2014upon the detection of a failure. This tactic is often combined with \ncheckpointing and transactions, to ensure that the rollback is complete and consistent. Once \nthe good state is reached, then execution can continue, potentially employing other tactics such \nas retry or degradation to ensure that the failure does not reoccur. The repair state tactic repairs an erroneous state\u2014effectively increasing the set of states \nthat a component can handle competently (i.e., without failure)\u2014and then continues execu-\ntion. For example, a vehicle\u2019s lane keep assist feature will monitor whether a driver is staying \nwithin their lane and actively return the vehicle to a position between the lines\u2014a safe state\u2014\nif it drifts out. This tactic is inappropriate as a means of recovery from unanticipated faults. Reconfiguration attempts to recover from component failures by remapping the logical \narchitecture onto the (potentially limited) resources left functioning. Ideally, this remapping \nallows full functionality to be maintained. When this is not possible, the system may be able to \nmaintain partial functionality in combination with the degradation tactic. 10.3  \nTactics-Based Questionnaire for Safety\nBased on the tactics described in Section 10.2, we can create a set of tactics-inspired ques-\ntions, as presented in Table 10.2. To gain an overview of the architectural choices made to sup-\nport safety, the analyst asks each question and records the answers in the table. The answers to \nthese questions can then be made the focus of further activities: investigation of documenta-\ntion, analysis of code or other artifacts, reverse engineering of code, and so forth. Prior to beginning the tactics-based questionnaire for safety, you should assess whether \nthe project under review has performed a hazard analysis or FTA to identify what constitutes \nan unsafe state (to be detected, avoided, contained, or recovered from) in your system. Without \nthis analysis, designing for safety is likely to be less effective.", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 179", "position": 179, "chunk_type": "semantic", "token_estimate": 401}
{"text": "10.3 Tactics-Based Questionnaire for Safety 161: TABLE 10.2 Tactics-Based Questionnaire for Safety\nTactics \nGroup\nTactics Question\nSupported? (Y/N)\nRisk\nDesign \nDecisions \nand \nLocation\nRationale \nand \nAssumptions\nUnsafe State \nAvoidance\nDo you employ substitution\u2014\nthat is, safer, often hardware-\nbased protection mechanisms \nfor potentially dangerous \nsoftware design features? Do you use a predictive model \nto predict the state of health of \nsystem processes, resources, \nor other properties\u2014based on \nmonitored information\u2014not \nonly to ensure that the system \nis operating within its nominal \noperating parameters, but also \nto provide early warning of a \npotential problem? Unsafe State \nDetection\nDo you use timeouts to \ndetermine whether the \noperation of a component \nmeets its timing constraints? Do you use timestamps to \ndetect incorrect sequences of \nevents? Do you employ condition \nmonitoring to check \nconditions in a process or \ndevice, particularly to validate \nassumptions made during \ndesign? Is sanity checking employed \nto check the validity or \nreasonableness of specific \noperation results, or inputs or \noutputs of a component? Does the system employ \ncomparison to detect unsafe \nstates, by comparing the \noutputs produced based on \nthe number of synchronized or \nreplicated elements? Containment: \nRedundancy\nDo you use replication\u2014\nclones of a component\u2014to \nprotect against random failures \nof hardware? Do you use functional \nredundancy to address \nthe common-mode failures \nby implementing diversely \ndesigned components? continues", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 180", "position": 180, "chunk_type": "semantic", "token_estimate": 217}
{"text": "162 Part II Quality Attributes | Chapter 10 Safety: Tactics \nGroup\nTactics Question\nSupported? (Y/N)\nRisk\nDesign \nDecisions \nand \nLocation\nRationale \nand \nAssumptions\nContainment: \nRedundancy\nDo you use analytic \nredundancy\u2014functional \n\u201creplicas\u201d that include high \nassurance/high performance \nand low assurance/low \nperformance alternatives\u2014to \nbe able to tolerate specification \nerrors? Containment: \nLimit \nConsequences\nCan the system abort an \noperation that is determined to \nbe unsafe before it can cause \ndamage? Does the system provide \ncontrolled degradation, \nwhere the most critical system \nfunctions are maintained in \nthe presence of component \nfailures, while less critical \nfunctions are dropped or \ndegraded? Does the system mask a fault \nby comparing the results of \nseveral redundant components \nand employ a voting procedure \nin case one or more of the \ncomponents differ? Containment: \nBarrier\nDoes the system support limiting \naccess to critical resources \n(e.g., processors, memory, and \nnetwork connections) through a \nfirewall? Does the system control access \nto protected components and \nprotect against failures arising \nfrom incorrect sequencing of \nevents through interlocks? Recovery\nIs the system able to roll \nback\u2014that is, to revert to a \nprevious known good state\u2014\nupon the detection of a failure? Can the system repair a state \ndetermined to be erroneous, \nwithout failure, and then \ncontinue execution? Can the system reconfigure \nresources, in the event of \nfailures, by remapping the \nlogical architecture onto the \nresources left functioning? TABLE 10.2 Tactics-Based Questionnaire for Safety continued", "domains": ["Design Patterns", "Software Quality Attributes", "Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 181", "position": 181, "chunk_type": "semantic", "token_estimate": 229}
{"text": "10.4 Patterns for Safety 163: 10.4  \nPatterns for Safety\nA system that unexpectedly stops operating, or starts operating incorrectly, or falls into \na degraded mode of operation is likely to affect safety negatively, if not catastrophically. Hence, the first place to look for safety patterns is in patterns for availability, such as the ones \ndescribed in Chapter 4. They all apply here. \u25a0Redundant sensors. If the data produced by a sensor is important to determine whether a \nstate is safe or unsafe, that sensor should be replicated. This protects against the fail-\nure of any single sensor. Also, independent software should monitor each sensor\u2014in \nessence, the redundant spare tactic from Chapter 4 applied to safety-critical hardware. Benefits:\n \n\u25a0This form of redundancy, which is applied to sensors, guards against the failure of a \nsingle sensor. Tradeoffs:\n \n\u25a0Redundant sensors add cost to the system, and processing the inputs from multiple \nsensors is more complicated than processing the input from a single sensor. \u25a0Monitor-actuator. This pattern focuses on two software elements\u2014a monitor and an \nactuator controller\u2014that are employed before sending a command to a physical actuator. The actuator controller performs the calculations necessary to determine the values to \nsend to the physical actuator. The monitor checks these values for reasonableness before \nsending them. This separates the computation of the value from the testing of the value. Benefits:\n \n\u25a0In this form of redundancy applied to actuator control, the monitor acts as a redundant \ncheck on the actuator controller computations. Tradeoffs:\n \n\u25a0The development and maintenance of the monitor take time and resources. \u25a0Because of the separation this pattern achieves between actuator control and moni-\ntoring, this particular tradeoff is easy to manipulate by making the monitor as simple \n(easy to produce but may miss errors) or as sophisticated (more complex but catches \nmore errors) as required. \u25a0Separated safety. Safety-critical systems must frequently be certified as safe by \nsome authority. Certifying a large system is expensive, but dividing a system into \nsafety-critical portions and non-safety-critical portions can reduce those costs. The safety-\ncritical portion must still be certified. Likewise, the division into safety-critical and \nnon-critical portions must be certified to ensure that there is no influence on the \nsafety-critical portion from the non-safety-critical portion.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 182", "position": 182, "chunk_type": "semantic", "token_estimate": 368}
{"text": "164 Part II Quality Attributes | Chapter 10 Safety: Benefits:\n \n\u25a0The cost of certifying the system is reduced because you need to certify only a \n(usually small) portion of the total system. \u25a0Cost and safety benefits accrue because the effort focuses on just those portions of the \nsystem that are germane to safety. Tradeoffs:\n \n\u25a0The work involved in performing the separation can be expensive, such as installing \ntwo different networks in a system to partition safety-critical and non-safety-critical \nmessages. However, this approach limits the risk and consequences of bugs in the \nnon-safety-critical portion from affecting the safety-critical portion. \u25a0Separating the system and convincing the certification agency that the separation \nwas performed correctly and that there are no influences from the non-safety-critical \nportion on the safety-critical portion is difficult, but is far easier than the alternative: \nhaving the agency certify everything to the same rigid level. Design Assurance Levels\nThe separated safety pattern emphasizes dividing the software system into safety-\ncritical portions and non-safety-critical portions. In avionics, the distinction is finer-\ngrained. DO-178C, \u201cSoftware Considerations in Airborne Systems and Equipment \nCertification,\u201d is the primary document by which certification authorities such as Federal \nAviation Administration (FAA), European Union Aviation Safety Agency (EASA), and \nTransport Canada approve all commercial software-based aerospace systems. It \ndefines a ranking called Design Assurance Level (DAL) for each software function. The \nDAL is determined from the safety assessment process and hazard analysis by examin-\ning the effects of a failure condition in the system. The failure conditions are categorized \nby their effects on the aircraft, crew, and passengers:\n \n\u25a0\nA: Catastrophic. Failure may cause deaths, usually with loss of the airplane. \u25a0\nB: Hazardous. Failure has a large negative impact on safety or performance, or \nreduces the crew\u2019s ability to operate the aircraft due to physical distress or a higher \nworkload, or causes serious or fatal injuries among the passengers. \u25a0\nC: Major. Failure significantly reduces the safety margin or significantly increases \ncrew workload, and may result in passenger discomfort (or even minor injuries). \u25a0\nD: Minor. Failure slightly reduces the safety margin or slightly increases crew work-\nload. Examples might include causing passenger inconvenience or a routine flight \nplan change. \u25a0\nE: No effect. Failure has no impact on safety, aircraft operation, or crew workload. Software validation and testing is a terrifically expensive task, undertaken with very \nfinite budgets. DALs help you decide where to put your limited testing resources.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 183", "position": 183, "chunk_type": "semantic", "token_estimate": 403}
{"text": "166 Part II Quality Attributes | Chapter 10 Safety: also a wave of new norms such as ANSI/UL 4600, \u201cStandard for Safety for the Evaluation \nof Autonomous Vehicles and Other Products,\u201d which tackle the challenges that emerge when \nsoftware takes the wheel, figuratively and literally. 10.6  \nDiscussion Questions\n1. List 10 computer-controlled devices that are part of your everyday life right now, and \nhypothesize ways that a malicious or malfunctioning system could use them to hurt you. 2. Write a safety scenario that is designed to prevent a stationary robotic device (such as \nan assembly arm on a manufacturing line) from injuring someone, and discuss tactics to \nachieve it. 3. The U.S. Navy\u2019s F/A-18 Hornet fighter aircraft was one of the early applications of fly-\nby-wire technology, in which onboard computers send digital commands to the control \nsurfaces (ailerons, rudder, etc.) based on the pilot\u2019s input to the control stick and rudder \npedals. The flight control software was programmed to prevent the pilot from com-\nmanding certain violent maneuvers that might cause the aircraft to enter an unsafe flight \nregime. During early flight testing, which often involves pushing the aircraft to (and \nbeyond) its utmost limits, an aircraft entered an unsafe state and \u201cviolent maneuvers\u201d \nwere exactly what were needed to save it\u2014but the computers dutifully prevented them. The aircraft crashed into the ocean because of software designed to keep it safe. Write a \nsafety scenario to address this situation, and discuss the tactics that would have pre-\nvented this outcome. 4. According to slate.com and other sources, a teenage girl in Germany \u201cwent into hiding \nafter she forgot to set her Facebook birthday invitation to private and accidentally invited \nthe entire Internet. After 15,000 people confirmed they were coming, the girl\u2019s parents \ncanceled the party, notified police, and hired private security to guard their home.\u201d \nFifteen hundred people showed up anyway, resulting in several minor injuries and untold \nmayhem. Is Facebook unsafe? Discuss. 5. Write a safety scenario to protect the unfortunate girl in Germany from Facebook. 6. On February 25, 1991, during the Gulf War, a U.S. Patriot missile battery failed to inter-\ncept an incoming Scud missile, which struck a barracks, killing 28 soldiers and injuring \ndozens. The cause of the failure was an inaccurate calculation of the time since boot due \nto arithmetic errors in the software that accumulated over time.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 185", "position": 185, "chunk_type": "semantic", "token_estimate": 395}
{"text": "10.6 Discussion Questions 167: computer program trying to stuff a 64-bit number into a 16-bit space. One bug, one \ncrash. Of all the careless lines of code recorded in the annals of computer science, this \none may stand as the most devastatingly efficient.\u201d Write a safety scenario that addresses \nthe Ariane 5 disaster, and discuss tactics that might have prevented it. 8. Discuss how you think safety tends to \u201ctrade off\u201d against the quality attributes of perfor-\nmance, availability, and interoperability. 9. Discuss the relationship between safety and testability. 10. What is the relationship between safety and modifiability? 11. With the Air France flight 447 story in mind, discuss the relationship between safety and \nusability. 12. Create a list of faults or a fault tree for an automatic teller machine. Include faults deal-\ning with hardware component failure, communications failure, software failure, running \nout of supplies, user errors, and security attacks. How would you use tactics to accom-\nmodate these faults?", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 186", "position": 186, "chunk_type": "semantic", "token_estimate": 161}
{"text": "169: 11\n \nSecurity\nIf you reveal your secrets to the wind, you should not blame the wind \nfor revealing them to the trees. \u2014Kahlil Gibran\nSecurity is a measure of the system\u2019s ability to protect data and information from unauthorized \naccess while still providing access to people and systems that are authorized. An attack\u2014that \nis, an action taken against a computer system with the intention of doing harm\u2014can take a \nnumber of forms. It may be an unauthorized attempt to access data or services or to modify \ndata, or it may be intended to deny services to legitimate users. The simplest approach to characterizing security focuses on three characteristics: confi-\ndentiality, integrity, and availability (CIA):\n \n\u25a0Confidentiality is the property that data or services are protected from unauthorized \naccess. For example, a hacker cannot access your income tax returns on a government \ncomputer. \u25a0Integrity is the property that data or services are not subject to unauthorized manipula-\ntion. For example, your grade has not been changed since your instructor assigned it. \u25a0Availability is the property that the system will be available for legitimate use. For exam-\nple, a denial-of-service attack won\u2019t prevent you from ordering this book from an online \nbookstore. We will use these characteristics in our general scenario for security. One technique that is used in the security domain is threat modeling. An \u201cattack tree,\u201d \nwhich is similar to the fault tree discussed in Chapter 4, is used by security engineers to deter-\nmine possible threats. The root of the tree is a successful attack, and the nodes are possi-\nble direct causes of that successful attack. Children nodes decompose the direct causes, and \nso forth. An attack is an attempt to compromise CIA, with the leaves of attack trees being \nthe stimulus in the scenario. The response to the attack is to preserve CIA or deter attackers \nthrough monitoring of their activities.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 188", "position": 188, "chunk_type": "semantic", "token_estimate": 314}
{"text": "170 Part II Quality Attributes | Chapter 11 Security: Privacy\nAn issue closely related to security is the quality of privacy. Privacy concerns have \nbecome more important in recent years and are enshrined into law in the European \nUnion through the General Data Protection Regulation (GDPR). Other jurisdictions have \nadopted similar regulations. Achieving privacy is about limiting access to information, which in turn is about which \ninformation should be access-limited and to whom access should be allowed. The gen-\neral term for information that should be kept private is personally identifiable information \n(PII). The National Institute of Standards and Technology (NIST) defines PII as \u201cany \ninformation about an individual maintained by an agency, including (1) any information \nthat can be used to distinguish or trace an individual\u2019s identity, such as name, social \nsecurity number, date and place of birth, mother\u2019s maiden name, or biometric records; \nand (2) any other information that is linked or linkable to an individual, such as medical, \neducational, financial, and employment information.\u201d\nThe question of who is permitted access to such data is more complicated. Users are \nroutinely asked to review and agree to privacy agreements initiated by organizations. These privacy agreements detail who, outside of the collecting organization, is entitled \nto see PII. The collecting organization itself should have policies that govern who within \nthat organization can have access to such data. Consider, for example, a tester for a \nsoftware system. To perform tests, realistic data should be used. Does that data include \nPII? Generally, PII is obscured for testing purposes. Frequently the architect, perhaps acting for the project manager, is asked to verify \nthat PII is hidden from members of the development team who do not need to have \naccess to PII. 11.1  \nSecurity General Scenario\nFrom these considerations, we can now describe the individual portions of a security general \nscenario, which is summarized in Table 11.1. TABLE 11.1 Security General Scenario\nPortion of \nScenario\nDescription\nPossible Values\nSource\nThe attack may be from \noutside the organization or \nfrom inside the organization. The source of the attack may \nbe either a human or another \nsystem. It may have been \npreviously identified (either \ncorrectly or incorrectly) or may \nbe currently unknown. \u25a0\nHuman\n \n\u25a0\nAnother system\nwhich is:\n \n\u25a0\nInside the organization\n \n\u25a0\nOutside the organization\n \n\u25a0\nPreviously identified\n \n\u25a0\nUnknown", "domains": ["Software Quality Attributes", "Domain-Driven Design"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 189", "position": 189, "chunk_type": "semantic", "token_estimate": 386}
{"text": "11.1 Security General Scenario 171: Portion of \nScenario\nDescription\nPossible Values\nStimulus\nThe stimulus is an attack. An unauthorized attempt to:\n \n\u25a0\nDisplay data\n \n\u25a0\nCapture data\n \n\u25a0\nChange or delete data\n \n\u25a0\nAccess system services\n \n\u25a0\nChange the system\u2019s behavior\n \n\u25a0\nReduce availability\nArtifact\nWhat is the target of the attack? \u25a0\nSystem services\n \n\u25a0\nData within the system\n \n\u25a0\nA component or resources of the system\n \n\u25a0\nData produced or consumed by the system\nEnvironment\nWhat is the state of the system \nwhen the attack occurs? The system is:\n \n\u25a0\nOnline or offline\n \n\u25a0\nConnected to or disconnected from a network\n \n\u25a0\nBehind a firewall or open to a network\n \n\u25a0\nFully operational\n \n\u25a0\nPartially operational\n \n\u25a0\nNot operational\nResponse\nThe system ensures that \nconfidentiality, integrity, and \navailability are maintained. Transactions are carried out in a fashion such that\n \n\u25a0\nData or services are protected from \nunauthorized access\n \n\u25a0\nData or services are not being manipulated \nwithout authorization\n \n\u25a0\nParties to a transaction are identified with \nassurance\n \n\u25a0\nThe parties to the transaction cannot repudiate \ntheir involvements\n \n\u25a0\nThe data, resources, and system services will \nbe available for legitimate use\nThe system tracks activities within it by\n \n\u25a0\nRecording access or modification\n \n\u25a0\nRecording attempts to access data, resources, \nor services\n \n\u25a0\nNotifying appropriate entities (people or \nsystems) when an apparent attack is occurring\nResponse \nmeasure\nMeasures of a system\u2019s \nresponse are related to the \nfrequency of successful attacks, \nthe time and cost to resist \nand repair attacks, and the \nconsequential damage of those \nattacks. One or more of the following:\n \n\u25a0\nHow much of a resource is compromised or \nensured\n \n\u25a0\nAccuracy of attack detection\n \n\u25a0\nHow much time passed before an attack was \ndetected\n \n\u25a0\nHow many attacks were resisted\n \n\u25a0\nHow long it takes to recover from a successful \nattack\n \n\u25a0\nHow much data is vulnerable to a particular \nattack", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 190", "position": 190, "chunk_type": "semantic", "token_estimate": 315}
{"text": "172 Part II Quality Attributes | Chapter 11 Security: Stimulus\nResponse\nResponse\nMeasure\nSource\n3\n2\n1\n4\nEnvironment\nArtifact\nA disgruntled\nemployee at\na remote\nlocation\nAttempts to\nimproperly modify\nthe pay rate table\nNormal operations\nThe unauthorized\naccess is detected and\nthe system maintains\nan audit trail\nCorrect data is\nrestored within\none day\nDatabase\nFigure 11.1 shows a sample concrete scenario derived from the general scenario: A dis-\ngruntled employee at a remote location attempts to improperly modify the pay rate table \nduring normal operations. The unauthorized access is detected, the system maintains an \naudit trail, and the correct data is restored within one day. FIGURE 11.1 Sample scenario for security\n11.2  \nTactics for Security\nOne method for thinking about how to achieve security in a system is to focus on physical secu-\nrity. Secure installations permit only limited access to them (e.g., by using fences and security \ncheckpoints), have means of detecting intruders (e.g., by requiring legitimate visitors to wear \nbadges), have deterrence mechanisms (e.g., by having armed guards), have reaction mechanisms \n(e.g., automatic locking of doors), and have recovery mechanisms (e.g., off-site backup). These \nlead to our four categories of tactics: detect, resist, react, and recover. The goal of security tactics \nis shown in Figure 11.2, and Figure 11.3 outlines these categories of tactics. Detect Attacks\nThe detect attacks category consists of four tactics: detect intrusion, detect service denial, ver-\nify message integrity, and detect message delay. \u25a0Detect intrusion. This tactic compares network traffic or service request patterns within \na system to a set of signatures or known patterns of malicious behavior stored in a data-\nbase. The signatures can be based on protocol characteristics, request characteristics, \npayload sizes, applications, source or destination address, or port number. \u25a0Detect service denial. This tactic compares the pattern or signature of network traffic \ncoming into a system to historical profiles of known denial-of-service (DoS) attacks.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 191", "position": 191, "chunk_type": "semantic", "token_estimate": 317}
{"text": "11.2 Tactics for Security 173: Attack\nSystem detects,\nresists, or recovers\nTactics\nto Control\nResponse\nFIGURE 11.2 Goal of security tactics\nDetect Attacks\nRecover from\nAttacks\nReact to\nAttacks\nSecurity Tactics\nDetect Intrusion\nDetect Service Denial\nVerify Message Integrity\nDetect Message Delivery Anomalies\nIdentify Actors\nAuthenticate Actors\nAuthorize Actors\nLimit Access\nLimit Exposure\nEncrypt Data\nSeparate Entities\nValidate Input\nChange Credential Settings\nRevoke Access\nRestrict Login\nInform Actors\nAudit\nNonrepudiation\nResist Attacks\nFIGURE 11.3 Security tactics", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 192", "position": 192, "chunk_type": "semantic", "token_estimate": 76}
{"text": "174 Part II Quality Attributes | Chapter 11 Security: \u25a0Verify message integrity. This tactic employs techniques such as checksums or hash \nvalues to verify the integrity of messages, resource files, deployment files, and configu-\nration files. A checksum is a validation mechanism wherein the system separately main-\ntains redundant information for files and messages, and uses this redundant information \nto verify the file or message. A hash value is a unique string generated by a hashing \nfunction, whose input could be files or messages. Even a slight change in the original \nfiles or messages results in a significant change in the hash value. \u25a0 \nDetect message delivery anomalies. This tactic seeks to detect potential man-in-the-\nmiddle-attacks, in which a malicious party is intercepting (and possibly modifying) \nmessages. If message delivery times are normally stable, then by checking the time that \nit takes to deliver or receive a message, it becomes possible to detect suspicious timing \nbehavior. Similarly, abnormal numbers of connections and disconnections may indicate \nsuch an attack. Resist Attacks\nThere are a number of well-known means of resisting an attack:\n \n\u25a0Identify actors. Identifying actors (users or remote computers) focuses on identifying the \nsource of any external input to the system. Users are typically identified through user \nIDs. Other systems may be \u201cidentified\u201d through access codes, IP addresses, protocols, \nports, or some other means. \u25a0Authenticate actors. Authentication means ensuring that an actor is actually who or \nwhat it purports to be. Passwords, one-time passwords, digital certificates, two-factor \nauthentication, and biometric identification provide a means for authentication. Another \nexample is CAPTCHA (Completely Automated Public Turing test to tell Computers and \nHumans Apart), a type of challenge\u2013response test that is used to determine whether the \nuser is human. Systems may require periodic reauthentication, such as when your smart-\nphone automatically locks after a period of inactivity. \u25a0Authorize actors. Authorization means ensuring that an authenticated actor has the \nrights to access and modify either data or services. This mechanism is usually enabled \nby providing some access control mechanisms within a system. Access control can be \nassigned per actor, per actor class, or per role. \u25a0Limit access. This tactic involves limiting access to computer resources. Limiting access \nmight mean restricting the number of access points to the resources, or restricting the \ntype of traffic that can go through the access points. Both kinds of limits minimize \nthe attack surface of a system.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 193", "position": 193, "chunk_type": "semantic", "token_estimate": 398}
{"text": "174 Part II Quality Attributes | Chapter 11 Security: Limiting access \nmight mean restricting the number of access points to the resources, or restricting the \ntype of traffic that can go through the access points. Both kinds of limits minimize \nthe attack surface of a system. For example, a demilitarized zone (DMZ) is used when \nan organization wants to let external users access certain services but not access other \nservices. The DMZ sits between the Internet and an intranet, and is protected by a pair \nof firewalls, one on either side. The internal firewall is a single point of access to the \nintranet; it functions as a limit to the number of access points as well as controls the type \nof traffic allowed through to the intranet.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 193", "position": 193, "chunk_type": "semantic", "token_estimate": 127}
{"text": "11.2 Tactics for Security 175: \u25a0Limit exposure. This tactic focuses on minimizing the effects of damage caused by a \nhostile action. It is a passive defense since it does not proactively prevent attackers from \ndoing harm. Limiting exposure is typically realized by reducing the amount of data or \nservices that can be accessed through a single access point, and hence compromised in a \nsingle attack. \u25a0Encrypt data. Confidentiality is usually achieved by applying some form of encryp-\ntion to data and to communication. Encryption provides extra protection to persistently \nmaintained data beyond that available from authorization. Communication links, by \ncomparison, may not have authorization controls. In such cases, encryption is the only \nprotection for passing data over publicly accessible communication links. Encryption can \nbe symmetric (readers and writers use the same key) or asymmetric (with readers and \nwriters use paired public and private keys). \u25a0Separate entities. Separating different entities limits the scope of an attack. Separation \nwithin the system can be done through physical separation on different servers attached \nto different networks, the use of virtual machines, or an \u201cair gap\u201d\u2014that is, by having no \nelectronic connection between different portions of a system. Finally, sensitive data is \nfrequently separated from nonsensitive data to reduce the possibility of attack by users \nwho have access to nonsensitive data. \u25a0Validate input. Cleaning and checking input as it is received by a system, or portion of \na system, is an important early line of defense in resisting attacks. This is often imple-\nmented by using a security framework or validation class to perform actions such as \nfiltering, canonicalization, and sanitization of input. Data validation is the main form of \ndefense against attacks such as SQL injection, in which malicious code is inserted into \nSQL statements, and cross-site scripting (XSS), in which malicious code from a server \nruns on a client. \u25a0 \nChange credential settings. Many systems have default security settings assigned when \nthe system is delivered. Forcing the user to change those settings will prevent attack-\ners from gaining access to the system through settings that may be publicly available. Similarly, many systems require users to choose a new password after some maximum \ntime period. React to Attacks\nSeveral tactics are intended to respond to a potential attack. \u25a0Revoke access.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 194", "position": 194, "chunk_type": "semantic", "token_estimate": 376}
{"text": "11.2 Tactics for Security 175: React to Attacks\nSeveral tactics are intended to respond to a potential attack. \u25a0Revoke access. If the system or a system administrator believes that an attack is \nunder way, then access can be severely limited to sensitive resources, even for normally \nlegitimate users and uses. For example, if your desktop has been compromised by a \nvirus, your access to certain resources may be limited until the virus is removed from \nyour system. \u25a0Restrict login. Repeated failed login attempts may indicate a potential attack. Many \nsystems limit access from a particular computer if there are repeated failed attempts to \naccess an account from that computer. Of course, legitimate users may make mistakes", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 194", "position": 194, "chunk_type": "semantic", "token_estimate": 116}
{"text": "176 Part II Quality Attributes | Chapter 11 Security: in attempting to log in, so the limited access may last for only a certain time period. In some cases, systems double the lockout time period after each unsuccessful login \nattempt. \u25a0Inform actors. Ongoing attacks may require action by operators, other personnel, or \ncooperating systems. Such personnel or systems\u2014the set of relevant actors\u2014must be \nnotified when the system has detected an attack. Recover from Attacks\nOnce a system has detected and attempted to resist an attack, it needs to recover. Part of recov-\nery is restoration of services. For example, additional servers or network connections may be \nkept in reserve for such a purpose. Since a successful attack can be considered a kind of fail-\nure, the set of availability tactics (from Chapter 4) that deal with recovering from a failure can \nbe brought to bear for this aspect of security as well. In addition to the availability tactics for recovery, the audit and nonrepudiation tactics can \nbe used:\n \n\u25a0Audit. We audit systems\u2014that is, keep a record of user and system actions and their \neffects\u2014to help trace the actions of, and to identify, an attacker. We may analyze audit \ntrails to attempt to prosecute attackers or to create better defenses in the future. \u25a0Nonrepudiation. This tactic guarantees that the sender of a message cannot later deny \nhaving sent the message and that the recipient cannot deny having received the message. For example, you cannot deny ordering something from the Internet, and the merchant \ncannot disclaim getting your order. This could be achieved with some combination of \ndigital signatures and authentication by trusted third parties. 11.3  \nTactics-Based Questionnaire for Security\nBased on the tactics described in Section 11.2, we can create a set of security tactics\u2013inspired \nquestions, as presented in Table 11.2. To gain an overview of the architectural choices made \nto support security, the analyst asks each question and records the answers in the table. The \nanswers to these questions can then be made the focus of further activities: investigation of \ndocumentation, analysis of code or other artifacts, reverse engineering of code, and so forth.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 195", "position": 195, "chunk_type": "semantic", "token_estimate": 354}
{"text": "11.3 Tactics-Based Questionnaire for Security 177: TABLE 11.2 Tactics-Based Questionnaire for Security \nTactics \nGroup\nTactics Question\nSupported? (Y/N)\nRisk\nDesign \nDecisions \nand \nLocation\nRationale \nand \nAssumptions\nDetecting \nAttacks\nDoes the system support the \ndetection of intrusions by, for \nexample, comparing network \ntraffic or service request patterns \nwithin a system to a set of \nsignatures or known patterns \nof malicious behavior stored in \na database? Does the system support \nthe detection of denial-\nof-service attacks by, for \nexample, comparing the pattern \nor signature of network traffic \ncoming into a system to historical \nprofiles of known DoS attacks? Does the system support the \nverification of message \nintegrity via techniques such as \nchecksums or hash values? Does the system support the \ndetection of message delays \nby, for example, checking the \ntime that it takes to deliver a \nmessage? Resisting \nAttacks\nDoes the system support the \nidentification of actors through \nuser IDs, access codes, IP \naddresses, protocols, ports, etc.? Does the system support the \nauthentication of actors \nvia, for example, passwords, \ndigital certificates, two-factor \nauthentication, or biometrics? Does the system support the \nauthorization of actors, \nensuring that an authenticated \nactor has the rights to access and \nmodify either data or services? Does the system support limiting \naccess to computer resources \nvia restricting the number of \naccess points to the resources, or \nrestricting the type of traffic that \ncan go through the access points? Does the system support limiting \nexposure by reducing the amount \nof data or services that can be \naccessed through a single access \npoint? continues", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 196", "position": 196, "chunk_type": "semantic", "token_estimate": 253}
{"text": "178 Part II Quality Attributes | Chapter 11 Security: Tactics \nGroup\nTactics Question\nSupported? (Y/N)\nRisk\nDesign \nDecisions \nand \nLocation\nRationale \nand \nAssumptions\nResisting \nAttacks\nDoes the system support data \nencryption, for data in transit or \ndata at rest? Does the system design consider \nthe separation of entities via \nphysical separation on different \nservers attached to different \nnetworks, virtual machines, or an \n\u201cair gap\u201d? Does the system support \nchanging credential settings, \nforcing the user to change those \nsettings periodically or at critical \nevents? Does the system validate input \nin a consistent, system-wide \nway\u2014for example, using a \nsecurity framework or validation \nclass to perform actions such as \nfiltering, canonicalization, and \nsanitization of external input? Reacting \nto Attacks\nDoes the system support \nrevoking access by limiting \naccess to sensitive resources, \neven for normally legitimate users \nand uses if an attack is under way? Does the system support \nrestricting login in instances \nsuch as multiple failed login \nattempts? Does the system support \ninforming actors such as \noperators, other personnel, or \ncooperating systems when the \nsystem has detected an attack? Recovering \nfrom \nAttacks\nDoes the system support \nmaintaining an audit trail to \nhelp trace the actions of, and to \nidentify, an attacker? Does the system guarantee the \nproperty of nonrepudiation, \nwhich guarantees that the sender \nof a message cannot later deny \nhaving sent the message and that \nthe recipient cannot deny having \nreceived the message? Have you checked the \u201crecover \nfrom faults\u201d category of tactics \nfrom Chapter 4? TABLE 11.2 Tactics-Based Questionnaire for Security continued", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 197", "position": 197, "chunk_type": "semantic", "token_estimate": 251}
{"text": "11.4 Patterns for Security 179: 11.4  \nPatterns for Security\nTwo of the more well-known patterns for security are intercepting validator and intrusion pre-\nvention system. Intercepting Validator\nThis pattern inserts a software element\u2014a wrapper\u2014between the source and the destination \nof messages. This approach assumes greater importance when the source of the messages is \noutside the system. The most common responsibility of this pattern is to implement the verify \nmessage integrity tactic, but it can also incorporate tactics such as detect intrusion and detect \nservice denial (by comparing messages to known intrusion patterns), or detect message deliv-\nery anomalies. Benefits:\n \n\u25a0Depending on the specific validator that you create and deploy, this pattern can cover \nmost of the waterfront of the \u201cdetect attack\u201d category of tactics, all in one package. Tradeoffs:\n \n\u25a0As always, introducing an intermediary exacts a performance price. \u25a0Intrusion patterns change and evolve over time, so this component must be kept up-to-\ndate so that it maintains its effectiveness. This imposes a maintenance obligation on the \norganization responsible for the system. Intrusion Prevention System\nAn intrusion prevention system (IPS) is a standalone element whose main purpose is to iden-\ntify and analyze any suspicious activity. If the activity is deemed acceptable, it is allowed. Conversely, if it is suspicious, the activity is prevented and reported. These systems look for \nsuspicious patterns of overall usage, not just anomalous messages. Benefits:\n \n\u25a0These systems can encompass most of the \u201cdetect attacks\u201d and \u201creact to attacks\u201d tactics. Tradeoffs:\n \n\u25a0The patterns of activity that an IPS looks for change and evolve over time, so the pat-\nterns database must be constantly updated. \u25a0Systems employing an IPS incur a performance cost. \u25a0IPSs are available as commercial off-the-shelf components, which makes them unneces-\nsary to develop but perhaps not entirely suited to a specific application. Other notable security patterns include compartmentalization and distributed responsi-\nbility. Both of these combine the \u201climit access\u201d and \u201climit exposure\u201d tactics\u2014the former with \nrespect to information, the latter with respect to activities.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 198", "position": 198, "chunk_type": "semantic", "token_estimate": 330}
{"text": "180 Part II Quality Attributes | Chapter 11 Security: Just as we included (by reference) tactics for availability in our list of security tactics, \npatterns for availability also apply to security by counteracting attacks that seek to stop the \nsystem from operating. Consider the availability patterns discussed in Chapter 4 here as well. 11.5  \nFor Further Reading\nThe architectural tactics that we have described in this chapter are only one aspect of making \na system secure. Other aspects include the following:\n \n\u25a0Coding. Secure Coding in C and C++[Seacord 13] describes how to code securely. \u25a0Organizational processes. Organizations must have processes that take responsibility \nfor various aspects of security, including ensuring that systems are upgraded to put into \nplace the latest protections. NIST 800-53 provides an enumeration of organizational \nprocesses [NIST 09]. Organizational processes must account for insider threats, which \naccount for 15\u201320 percent of attacks. [Cappelli 12] discusses insider threats. \u25a0Technical processes. Microsoft\u2019s Security Development Lifecycle includes modeling of \nthreats: microsoft.com/download/en/details.aspx?id=16420. The Common Weakness Enumeration is a list of the most common categories of vulnera-\nbilities discovered in systems, including SQL injection and XSS: https://cwe.mitre.org/. NIST has published several volumes that give definitions of security terms [NIST 04], \ncategories of security controls [NIST 06], and an enumeration of security controls that an orga-\nnization could employ [NIST 09]. A security control could be a tactic, but it could also be \norganizational, coding, or technical in nature. Good books on engineering systems for security include Ross Anderson\u2019s Security \nEngineering: A Guide to Building Dependable Distributed Systems, third edition [Anderson 20], \nand the series of books by Bruce Schneier. Different domains have different sets of security practices that are relevant to their \ndomain. The Payment Card Industry (PCI), for example, has established a set of standards \nintended for those involved in credit card processing (pcisecuritystandards.org). The Wikipedia page on \u201cSecurity Patterns\u201d contains brief definitions of a large number \nof security patterns. Access control is commonly performed using a standard called OAuth. You can read \nabout OAuth at https://en.wikipedia.org/wiki/OAuth. 11.6  \nDiscussion Questions\n1. Write a set of concrete scenarios for security for an automobile. Consider in particular \nhow you would specify scenarios regarding control of the vehicle.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 199", "position": 199, "chunk_type": "semantic", "token_estimate": 364}
{"text": "11.6 Discussion Questions 181: 2. One of the most sophisticated attacks on record was carried out by a virus known as \nStuxnet. Stuxnet first appeared in 2009, but became widely known in 2011 when it \nwas revealed that it had apparently severely damaged or incapacitated the high-speed \ncentrifuges involved in Iran\u2019s uranium enrichment program. Read about Stuxnet, and \nsee if you can devise a defense strategy against it, based on the tactics described in this \nchapter. 3. Security and usability are often seen to be at odds with each other. Security often \nimposes procedures and processes that seem like needless overhead to the casual user. Nevertheless, some say that security and usability go (or should go) hand in hand, and \nargue that making the system easy to use securely is the best way to promote security to \nthe users. Discuss. 4. List some examples of critical resources for security, which a DoS attack might target \nand try to exhaust. Which architectural mechanisms could be employed to prevent this \nkind of attack? 5. Which of the tactics detailed in this chapter will protect against an insider threat? Can \nyou think of any that should be added? 6. In the United States, Netflix typically accounts for more than 10 percent of all Internet \ntraffic. How would you recognize a DoS attack on Netflix.com? Can you create a sce-\nnario to characterize this situation? 7. The public disclosure of vulnerabilities in an organization\u2019s production systems is a \nmatter of controversy. Discuss why this is so, and identify the pros and cons of public \ndisclosure of vulnerabilities. How could this issue affect your role as an architect? 8. Similarly, the public disclosure of an organization\u2019s security measures and the software \nto achieve them (via open source software, for example) is a matter of controversy. Discuss why this is so, identify the pros and cons of public disclosure of security mea-\nsures, and describe how this could affect your role as an architect.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 200", "position": 200, "chunk_type": "semantic", "token_estimate": 328}
{"text": "183: 12\n \nTestability\nTesting leads to failure, and failure leads to understanding. \u2014Burt Rutan\nA substantial portion of the cost of developing well-engineered systems is taken up by testing. If a carefully thought-out software architecture can reduce this cost, the payoff is large. Software testability refers to the ease with which software can be made to demonstrate \nits faults through (typically execution-based) testing. Specifically, testability refers to the \nprobability, assuming that the software has at least one fault, that it will fail on its next test \nexecution. Intuitively, a system is testable if it \u201creveals\u201d its faults easily. If a fault is present \nin a system, then we want it to fail during testing as quickly as possible. Of course, calculat-\ning this probability is not easy and\u2014as you will see when we discuss response measures for \n \ntestability\u2014other measures will be used. In addition, an architecture can enhance testability \nby making it easier both to replicate a bug and to narrow down the possible root causes of the \nbug. We do not typically think of these activities as part of testability per se, but in the end just \nrevealing a bug isn\u2019t enough: You also need to find and fix the bug! Figure 12.1 shows a simple model of testing in which a program processes input and pro-\nduces output. An oracle is an agent (human or computational) that decides whether the output \nis correct by comparing the output to the expected result. Output is not just the functionally \nproduced value, but can also include derived measures of quality attributes such as how long \nit took to produce the output. Figure 12.1 also indicates that the program\u2019s internal state can \nbe shown to the oracle, and an oracle can decide whether that state is correct\u2014that is, it can \ndetect whether the program has entered an erroneous state and render a judgment as to the \ncorrectness of the program. Setting and examining a program\u2019s internal state is an aspect of \ntesting that will figure prominently in our tactics for testability. For a system to be properly testable, it must be possible to control each component\u2019s \ninputs (and possibly manipulate its internal state) and then to observe its outputs (and possi-\nbly its internal state, either after or on the way to computing the outputs).", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 202", "position": 202, "chunk_type": "semantic", "token_estimate": 383}
{"text": "183: Setting and examining a program\u2019s internal state is an aspect of \ntesting that will figure prominently in our tactics for testability. For a system to be properly testable, it must be possible to control each component\u2019s \ninputs (and possibly manipulate its internal state) and then to observe its outputs (and possi-\nbly its internal state, either after or on the way to computing the outputs). Frequently, control \nand observation are accomplished through the use of a test harness, a set of specialized soft-\nware (or in some cases, hardware) designed to exercise the software under test. Test harnesses \ncome in various forms, and may include capabilities such as a record-and-playback capability", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 202", "position": 202, "chunk_type": "semantic", "token_estimate": 112}
{"text": "184 Part II Quality Attributes | Chapter 12 Testability: for data sent across interfaces, or a simulator for an external environment in which a piece \nof embedded software is tested, or even distinct software that runs during production (see \nthe sidebar \u201cNetflix\u2019s Simian Army\u201d). The test harness can provide assistance in executing the \ntest procedures and recording the output. A test harness and its accompanying infrastructure \ncan be substantial pieces of software in their own right, with their own architecture, stakehold-\ners, and quality attribute requirements. Netflix\u2019s Simian Army\nNetflix distributes movies and television shows via both DVD and streaming video. Its streaming video service has been extremely successful. In fact, in 2018, Netflix\u2019s \nstreaming video accounted for 15 percent of the global Internet traffic. Naturally, high \navailability is important to Netflix. Netflix hosts its computer services in the Amazon EC2 cloud, and the company \nutilizes a set of services that were originally called the \u201cSimian Army\u201d as a portion of its \ntesting process. Netflix began with a Chaos Monkey, which randomly killed processes \nin the running system. This allows the monitoring of the effect of failed processes and \ngives the ability to ensure that the system will not fail or suffer serious degradation as a \nresult of a process failure. The Chaos Monkey acquired some friends to assist in the testing. The Netflix Simian \nArmy included these, in addition to the Chaos Monkey:\n \n\u25a0\nThe Latency Monkey induced artificial delays in network communication to sim-\nulate service degradation and measured whether upstream services responded \nappropriately. \u25a0\nThe Conformity Monkey identified instances that did not adhere to best practices and \nshut them down. For example, if an instance did not belong to an auto-scaling group, \nit would not appropriately scale when demand went up. Program\nOracle\n{ \n}\nInput\nOutput\nApproved\nRejected\nInternal state\nFIGURE 12.1 A model of testing", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 203", "position": 203, "chunk_type": "semantic", "token_estimate": 310}
{"text": "Part II Quality Attributes | Chapter 12 Testability 185: \u25a0\nThe Doctor Monkey tapped into health checks that ran on each instance as well \nas monitoring other external signs of health (e.g., CPU load) to detect unhealthy \ninstances. \u25a0\nThe Janitor Monkey ensured that the Netflix cloud environment was running free of \nclutter and waste. It searched for unused resources and disposed of them. \u25a0\nThe Security Monkey was an extension of Conformity Monkey. It found security \nviolations or vulnerabilities, such as improperly configured security groups, and \nterminated the offending instances. It also ensured that all SSL and digital rights \nmanagement (DRM) certificates were valid and not coming up for renewal. \u25a0\nThe 10-18 Monkey (localization-internationalization) detected configuration and run-\ntime problems in instances serving customers in multiple geographic regions, using \ndifferent languages and character sets. The name 10-18 comes from L10n-i18n, a \nsort of shorthand for the words \u201clocalization\u201d and \u201cinternationalization.\u201d\nSome members of the Simian Army used fault injection to place faults into the run-\nning system in a controlled and monitored fashion. Other members monitored various \nspecialized aspects of the system and its environment. Both of these techniques have \nbroader applicability than just for Netflix. Given that not all faults are equal in terms of severity, more emphasis should be \nplaced on finding the most severe faults than on finding other faults. The Simian Army \nreflected a determination by Netflix that the targeted faults were the most serious in \nterms of their impacts. Netflix\u2019s strategy illustrates that some systems are too complex and adaptive to be \ntested fully, because some of their behaviors are emergent. One aspect of testing in \nthat arena is logging of operational data produced by the system, so that when failures \noccur, the logged data can be analyzed in the lab to try to reproduce the faults. \u2014LB\nTesting is carried out by various developers, users, or quality assurance personnel. Either \nportions of the system or the entire system may be tested. The response measures for testability \ndeal with how effective the tests are in discovering faults and how long it takes to perform the \ntests to some desired level of coverage. Test cases can be written by the developers, the testing \ngroup, or the customer. In some cases, testing actually drives development, as is the case with \ntest-driven development.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 204", "position": 204, "chunk_type": "semantic", "token_estimate": 387}
{"text": "Part II Quality Attributes | Chapter 12 Testability 185: Test cases can be written by the developers, the testing \ngroup, or the customer. In some cases, testing actually drives development, as is the case with \ntest-driven development. Testing of code is a special case of validation, which entails making sure that an engi-\nneered artifact meets its stakeholders\u2019 needs or is suitable for use. In Chapter 21, we will \ndiscuss architectural design reviews\u2014another kind of validation, in which the artifact being \ntested is the architecture.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 204", "position": 204, "chunk_type": "semantic", "token_estimate": 85}
{"text": "186 Part II Quality Attributes | Chapter 12 Testability: 12.1  \nTestability General Scenario\nTable 12.1 enumerates the elements of the general scenario that characterize testability. TABLE 12.1 Testability General Scenario\nPortion of \nScenario\nDescription\nPossible Values\nSource\nThe test cases can be executed \nby a human or an automated test \ntool. One or more of the following:\n \n\u25a0\nUnit testers\n \n\u25a0\nIntegration testers\n \n\u25a0\nSystem testers\n \n\u25a0\nAcceptance testers\n \n\u25a0\nEnd users\nEither run tests manually or use automated \ntesting tools\nStimulus \nA test or set of tests is initiated. These tests serve to:\n \n\u25a0\nValidate system functions\n \n\u25a0\nValidate qualities\n \n\u25a0\nDiscover emerging threats to quality\nEnvironment \nTesting occurs at various events \nor life-cycle milestones. The set of tests is executed due to:\n \n\u25a0\nThe completion of a coding increment such \nas a class, layer, or service\n \n\u25a0\nThe completed integration of a subsystem\n \n\u25a0\nThe complete implementation of the whole \nsystem\n \n\u25a0\nThe deployment of the system into a \nproduction environment\n \n\u25a0\nThe delivery of the system to a customer\n \n\u25a0\nA testing schedule\nArtifacts \nThe artifact is the portion of the \nsystem being tested and any \nrequired test infrastructure. The portion being tested:\n \n\u25a0\nA unit of code (corresponding to a module in \nthe architecture)\n \n\u25a0\nComponents\n \n\u25a0\nServices\n \n\u25a0\nSubsystems\n \n\u25a0\nThe entire system\n \n\u25a0\nThe test infrastructure\nResponse \nThe system and its test \ninfrastructure can be controlled \nto perform the desired tests, and \nthe results from the test can be \nobserved. One or more of the following:\n \n\u25a0\nExecute test suite and capture results\n \n\u25a0\nCapture activity that resulted in the fault\n \n\u25a0\nControl and monitor the state of the system", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 205", "position": 205, "chunk_type": "semantic", "token_estimate": 276}
{"text": "12.2 Tactics for Testability 187: Stimulus\nResponse\nResponse\nMeasure\nSource\n3\n2\n1\n4\nEnvironment\nArtifact\nDeveloper\nCompletes a code\nunit\nDevelopment\nPerforms a test\nsequence\n85% path\ncoverage within \n30 minutes\nCode unit\nPortion of \nScenario\nDescription\nPossible Values\nResponse \nmeasure \nResponse measures are aimed at \nrepresenting how easily a system \nunder test \u201cgives up\u201d its faults or \ndefects. One or more of the following:\n \n\u25a0\nEffort to find a fault or class of faults\n \n\u25a0\nEffort to achieve a given percentage of state \nspace coverage\n \n\u25a0\nProbability of a fault being revealed by the \nnext test\n \n\u25a0\nTime to perform tests\n \n\u25a0\nEffort to detect faults\n \n\u25a0\nLength of time to prepare test infrastructure\n \n\u25a0\nEffort required to bring the system into a \nspecific state\n \n\u25a0\nReduction in risk exposure: size(loss) \u00d7 \nprobability(loss)\n \nFigure 12.2 shows a concrete scenario for testability: The developer completes a code \nunit during development and performs a test sequence whose results are captured and that \ngives 85 percent path coverage within 30 minutes. FIGURE 12. 2 Sample testability scenario\n12.2  \nTactics for Testability\nTactics for testability are intended to promote easier, more efficient, and more capable testing. Figure 12.3 illustrates the goal of the testability tactics. Architectural techniques for enhanc-\ning the software testability have not received as much attention as other quality attribute dis-\nciplines such as modifiability, performance, and availability, but as we stated earlier, anything \nthe architect can do to reduce the high cost of testing will yield a significant benefit.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 206", "position": 206, "chunk_type": "semantic", "token_estimate": 251}
{"text": "188 Part II Quality Attributes | Chapter 12 Testability: Tests executed\nFaults detected\nTactics\nto Control\nResponse\nFIGURE 12.3 The goal of testability tactics\n \nThere are two categories of tactics for testability. The first category deals with adding \ncontrollability and observability to the system. The second deals with limiting complexity in \nthe system\u2019s design. Control and Observe System State\nControl and observation are so central to testability that some authors define testability in \nthose terms. The two go hand in hand; it makes no sense to control something if you can\u2019t \nobserve what happens when you do. The simplest form of control and observation is to pro-\nvide a software component with a set of inputs, let it do its work, and then observe its outputs. However, the control-and-observe category of testability tactics provides insights into soft-\nware that go beyond its inputs and outputs. These tactics cause a component to maintain some \nsort of state information, allow testers to assign a value to that state information, and make \nthat information accessible to testers on demand. The state information might be an operating \nstate, the value of some key variable, performance load, intermediate process steps, or any-\nthing else useful to re-creating component behavior. Specific tactics include the following:\n \n\u25a0Specialized interfaces. Having specialized testing interfaces allows you to control or \ncapture variable values for a component either through the application of a test harness \nor through normal execution. Examples of specialized test routines, some of which \nmight otherwise not be available except for testing purposes, include these:\n \n\u25a0A set and get method for important variables, modes, or attributes\n \n\u25a0A report method that returns the full state of the object\n \n\u25a0A reset method to set the internal state (e.g., all the attributes of a class) to a specified \ninternal state\n \n\u25a0A method to turn on verbose output, various levels of event logging, performance \ninstrumentation, or resource monitoring", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 207", "position": 207, "chunk_type": "semantic", "token_estimate": 316}
{"text": "12.2 Tactics for Testability 189: Specialized testing interfaces and methods should be clearly identified or kept sepa-\nrate from the access methods and interfaces for required functionality, so that they can \nbe removed if needed. Note, however, that in performance-critical and some safety-\ncritical systems, it is problematic to field different code than that which was tested. If \nyou remove the test code, how will you know the code released has the same behavior, \nparticularly the same timing behavior, as the code you tested? Thus this strategy is more \neffective for other kinds of systems. \u25a0Record/playback. The state that caused a fault is often difficult to re-create. Recording \nthe state when it crosses an interface allows that state to be used to \u201cplay the system \nback\u201d and to re-create the fault. Record refers to capturing information crossing an inter-\nface and playback refers to using it as input for further testing. \u25a0Localize state storage. To start a system, subsystem, or component in an arbitrary state \nfor a test, it is most convenient if that state is stored in a single place. By contrast, if the \nstate is buried or distributed, this approach becomes difficult, if not impossible. The state \ncan be fine-grained, even bit-level, or coarse-grained to represent broad abstractions or \noverall operational modes. The choice of granularity depends on how the states will be \nused in testing. A convenient way to \u201cexternalize\u201d state storage (i.e., to make it amenable \nto manipulation through interface features) is to use a state machine (or state machine \nobject) as the mechanism to track and report current state. \u25a0Abstract data sources. Similar to the case when controlling a program\u2019s state, the ability \nto control its input data makes it easier to test. Abstracting the interfaces lets you substi-\ntute test data more easily. For example, if you have a database of customer transactions, \nyou could design your architecture so that you can readily point your test system at other \ntest databases, or possibly even to files of test data instead, without having to change \nyour functional code. \u25a0Sandbox. \u201cSandboxing\u201d refers to isolating an instance of the system from the real world \nto enable experimentation that is unconstrained by any worries about having to undo the \nconsequences of the experiment. Testing is facilitated by the ability to operate the system \nin such a way that it has no permanent consequences, or so that any consequences can be \nrolled back.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 208", "position": 208, "chunk_type": "semantic", "token_estimate": 404}
{"text": "12.2 Tactics for Testability 189: \u201cSandboxing\u201d refers to isolating an instance of the system from the real world \nto enable experimentation that is unconstrained by any worries about having to undo the \nconsequences of the experiment. Testing is facilitated by the ability to operate the system \nin such a way that it has no permanent consequences, or so that any consequences can be \nrolled back. The sandbox tactic can be used for scenario analysis, training, and simula-\ntion. Simulation, in particular, is a commonly employed strategy for testing and training \nin contexts where failure in the real world might lead to severe consequences. One common form of sandboxing is to virtualize resources. Testing a system often \ninvolves interacting with resources whose behavior is outside the system\u2019s control. Using \na sandbox, you can build a version of the resource whose behavior is under your control. For example, the system clock\u2019s behavior is typically not under our control\u2014it incre-\nments one second each second. Thus, if we want to make the system think it\u2019s midnight \non the day when all of the data structures are supposed to overflow, we need a way to \ndo that, because waiting around is a poor choice. When we can abstract system time \nfrom clock time, we can allow the system (or components) to run at faster than wall-\nclock time, and test the system (or components) at critical time boundaries such as the \nnext transition to or from Daylight Savings Time. Similar virtualizations could be done \nfor other resources, such as the memory, battery, network, and so on. Stubs, mocks, and \ndependency injection are simple but effective forms of virtualization.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 208", "position": 208, "chunk_type": "semantic", "token_estimate": 274}
{"text": "190 Part II Quality Attributes | Chapter 12 Testability: \u25a0Executable assertions. With this tactic, assertions are (usually) hand-coded and placed at \ndesired locations to indicate when and where a program is in a faulty state. The assertions \nare often designed to check that data values satisfy specified constraints. Assertions are \ndefined in terms of specific data declarations, and they must be placed where the data val-\nues are referenced or modified. Assertions can be expressed as pre- and post-conditions for \neach method and also as class-level invariants. This increases the system\u2019s observability, as \nan assertion can be flagged as having failed. Assertions systematically inserted where data \nvalues change can be seen as a manual way to produce an \u201cextended\u201d type. Essentially, the \nuser is annotating a type with additional checking code. Anytime an object of that type is \nmodified, the checking code executes automatically, with warnings being generated if any \nconditions are violated. To the extent that the assertions cover the test cases, they effectively \nembed the test oracle in the code\u2014assuming the assertions are correct and correctly coded. All of these tactics add some capability or abstraction to the software that (were we not inter-\nested in testing) otherwise would not be there. They can be seen as augmenting bare-bones, \nget-the-job-done software with more elaborate software that has some special capabilities \ndesigned to enhance the efficiency and effectiveness of testing. In addition to the testability tactics, a number of techniques are available for replacing \none component with a different version of itself that facilitates testing:\n \n\u25a0Component replacement simply swaps the implementation of a component with a dif-\nferent implementation that (in the case of testability) has features that facilitate testing. Component replacement is often accomplished in a system\u2019s build scripts. \u25a0Preprocessor macros, when activated, can expand to state-reporting code or activate \nprobe statements that return or display information, or return control to a testing console. \u25a0Aspects (in aspect-oriented programs) can handle the cross-cutting concern of how the \nstate is reported. Limit Complexity\nComplex software is much harder to test. Its operating state space is large, and (all else being \nequal) it is more difficult to re-create an exact state in a large state space than to do so in a \nsmall state space. Because testing is not just about making the software fail, but also about \nfinding the fault that caused the failure so that it can be removed, we are often concerned with \nmaking behavior repeatable.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 209", "position": 209, "chunk_type": "semantic", "token_estimate": 408}
{"text": "190 Part II Quality Attributes | Chapter 12 Testability: Its operating state space is large, and (all else being \nequal) it is more difficult to re-create an exact state in a large state space than to do so in a \nsmall state space. Because testing is not just about making the software fail, but also about \nfinding the fault that caused the failure so that it can be removed, we are often concerned with \nmaking behavior repeatable. This category includes two tactics:\n \n\u25a0Limit structural complexity. This tactic includes avoiding or resolving cyclic depen-\ndencies between components, isolating and encapsulating dependencies on the external \nenvironment, and reducing dependencies between components in general (typically \nrealized by lowering the coupling between components). For example, in object-oriented \nsystems you can simplify the inheritance hierarchy:\n \n\u25a0Limit the number of classes from which a class is derived, or the number of classes \nderived from a class. \u25a0Limit the depth of the inheritance tree, and the number of children of a class. \u25a0Limit polymorphism and dynamic calls.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 209", "position": 209, "chunk_type": "semantic", "token_estimate": 170}
{"text": "12.2 Tactics for Testability 191: One structural metric that has been shown empirically to correlate to testability is \nthe response of a class. The response of class C is a count of the number of methods of \nC plus the number of methods of other classes that are invoked by the methods of C. \nKeeping this metric low can increase testability. In addition, architecture-level coupling \nmetrics, such as propagation cost and decoupling level, can be used to measure and track \nthe overall level of coupling in a system\u2019s architecture. Ensuring that the system has high cohesion, loose coupling, and separation of \n \nconcerns\u2014all modifiability tactics (see Chapter 8)\u2014can also help with testability. These characteristics limit the complexity of the architectural elements by giving \neach element a focused task such that it has limited interactions with other elements. Separation of concerns can help achieve controllability and observability, as well as \nreduce the size of the overall program\u2019s state space. Finally, some architectural patterns lend themselves to testability. In a layered pattern, \nyou can test lower layers first, then test higher layers with confidence in the lower layers. \u25a0Limit nondeterminism. The counterpart to limiting structural complexity is limiting \nbehavioral complexity. When it comes to testing, nondeterminism is a pernicious form of \ncomplex behavior, and nondeterministic systems are more difficult to test than deter-\nministic systems. This tactic involves finding all the sources of nondeterminism, such as \nunconstrained parallelism, and weeding them out to the extent possible. Some sources of \nnondeterminism are unavoidable\u2014for instance, in multi-threaded systems that respond \nto unpredictable events\u2014but for such systems, other tactics (such as record/playback) are \navailable to help manage this complexity. Figure 12.4 summarizes the tactics used for testability. Control and Observe\nSystem State\nLimit Complexity\nTestability Tactics\nSpecialized Interfaces\nRecord/Playback\nLocalize State Storage\nAbstract Data Sources\nSandbox\nExecutable Assertions\nLimit Structural Complexity\nLimit Nondeterminism\nFIGURE 12.4 Testability tactics", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Design Principles", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 210", "position": 210, "chunk_type": "semantic", "token_estimate": 311}
{"text": "192 Part II Quality Attributes | Chapter 12 Testability: 12.3  \nTactics-Based Questionnaire for Testability\nBased on the tactics described in Section 12.2, we can create a set of tactics-inspired ques-\ntions, as presented in Table 12.2. To gain an overview of the architectural choices made to \nsupport testability, the analyst asks each question and records the answers in the table. The \nanswers to these questions can then be made the focus of further activities: investigation of \ndocumentation, analysis of code or other artifacts, reverse engineering of code, and so forth. TABLE 12.2 Tactics-Based Questionnaire for Testability \nTactics \nGroup\nTactics Question\nSupported? (Y/N)\nRisk\nDesign \nDecisions \nand \nLocation\nRationale \nand \nAssumptions\nControl and \nObserve \nSystem \nState\nDoes your system have \nspecialized interfaces for \ngetting and setting values? Does your system have a \nrecord/playback \nmechanism? Is your system\u2019s state \nstorage localized? Does your system abstract \nits data sources? Can some or all of your \nsystem operate in a \nsandbox? Is there a role for executable \nassertions in your system? Limit \nComplexity\nDoes your system limit \nstructural complexity in a \nsystematic way? Is there nondeterminism in \nyour system, and is there a \nway to control or limit this \nnondeterminism? 12.4 Patterns for Testability\nPatterns for testability all make it easier to decouple test-specific code from the actual func-\ntionality of a system. We discuss three patterns here: dependency injection, strategy, and inter-\ncepting filter.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 211", "position": 211, "chunk_type": "semantic", "token_estimate": 231}
{"text": "12.4 Patterns for Testability 193: Dependency Injection Pattern\nIn the dependency injection pattern, a client\u2019s dependencies are separated from its behavior. This pattern makes use of inversion of control. Unlike in traditional declarative programming, \nwhere control and dependencies reside explicitly in the code, inversion of control dependen-\ncies means that control and dependencies are provided from, and injected into the code, by \nsome external source. In this pattern, there are four roles:\n \n\u25a0A service (that you want to make broadly available)\n \n\u25a0A client of the service\n \n\u25a0An interface (used by the client, implemented by the service)\n \n\u25a0An injector (that creates an instance of the service and injects it into the client)\nWhen an interface creates the service and injects it into the client, a client is written with \nno knowledge of a concrete implementation. In other words, all of the implementation specif-\nics are injected, typically at runtime. Benefits:\n \n\u25a0Test instances can be injected (rather than production instances), and these test instances \ncan manage and monitor the state of the service. Thus the client can be written with no \nknowledge of how it is to be tested. This is, in fact, how many modern testing frame-\nworks are implemented. Tradeoffs:\n \n\u25a0Dependency injection makes runtime performance less predictable, because it might \nchange the behavior being tested. \u25a0Adding this pattern adds a small amount of up-front complexity and may require retrain-\ning of developers to think in terms of inversion of control. Strategy Pattern\nIn the strategy pattern, a class\u2019s behavior can be changed at runtime. This pattern is often \nemployed when multiple algorithms can be employed to perform a given task, and the specific \nalgorithm to be used can be chosen dynamically. The class simply contains an abstract method \nfor the desired functionality, with the concrete version of this method being selected based on \ncontextual factors. This pattern is often used to replace non-test versions of some functionality \nwith test versions that provide additional outputs, additional internal sanity checking, and so \nforth. Benefits:\n \n\u25a0This pattern makes classes simpler, by not combining multiple concerns (such as differ-\nent algorithms for the same function) into a single class.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 212", "position": 212, "chunk_type": "semantic", "token_estimate": 355}
{"text": "194 Part II Quality Attributes | Chapter 12 Testability: Tradeoffs:\n \n\u25a0The strategy pattern, like all design patterns, adds a small amount of up-front complex-\nity. If the class is simple or if there are few runtime choices, this added complexity is \nlikely wasted. \u25a0For small classes, the strategy pattern can make code slightly less readable. However, as \ncomplexity grows, breaking up the class in this way can enhance readability. Intercepting Filter Pattern\nThe intercepting filter pattern is used to inject pre- and post-processing to a request or a \nresponse between a client and a service. Any number of filters can be defined and applied, in \nan arbitrary order, to the request before passing the request to the eventual service. For exam-\nple, logging and authentication services are filters that are often useful to implement once and \napply universally. Testing filters can be inserted in this way, without disturbing any of the \nother processing in the system. Benefits:\n \n\u25a0This pattern, like the strategy pattern, makes classes simpler, by not placing all of the \npre- and post-processing logic in the class. \u25a0Using an intercepting filter can be a strong motivator for reuse and can dramatically \nreduce the size of the code base. Tradeoffs:\n \n\u25a0If a large amount of data is being passed to the service, this pattern can be highly inef-\nficient and can add a nontrivial amount of latency, as each filter makes a complete pass \nover the entire input. 12.5  \nFor Further Reading\nThe literature on software testing would sink a battleship, but the writing about how to make \nyour system more testable from an architectural standpoint is less voluminous. For a good \noverview of testing, see [Binder 00]. Jeff Voas\u2019s foundational work on testability and the rela-\ntionship between testability and reliability is worth investigating, too. There are several papers \nto choose from, but [Voas 95] is a good start that will point you to others. Bertolino and Strigini [Bertolino 96a, 96b] are the developers of the model of testing \nshown in Figure 12.1. \u201cUncle Bob\u201d Martin has written extensively on test-driven development and the rela-\ntionship between architecture and testing. The best book on this is Robert C. Martin\u2019s Clean \nArchitecture: A Craftsman\u2019s Guide to Software Structure and Design [Martin 17]. An early \nand authoritative reference for test-driven development was written by  \nKent Beck: Test-Driven \nDevelopment by Example [Beck 02].", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 213", "position": 213, "chunk_type": "semantic", "token_estimate": 392}
{"text": "12.6 Discussion Questions 195: The propagation cost coupling metric was first described in [MacCormack 06]. The \ndecoupling level metric was described in [Mo 16]. Model checking is a technique that symbolically executes all possible code paths. The \nsize of a system that can be validated using model checking is limited, but device drivers \nand microkernels have successfully been model checked. See https://en.wikipedia.org/wiki/\nModel_checking for a list of model checking tools. 12.6  \nDiscussion Questions\n1. A testable system is one that gives up its faults easily. That is, if a system contains a \nfault, then it doesn\u2019t take long or much effort to make that fault show up. In contrast, \nfault tolerance is all about designing systems that jealously hide their faults; there, \nthe whole idea is to make it very difficult for a system to reveal its faults. Is it possible \nto design a system that is both highly testable and highly fault tolerant, or are these two \ndesign goals inherently incompatible? Discuss. 2. What other quality attributes do you think testability is most in conflict with? What \nother quality attributes do you think testability is most compatible with? 3. Many of the tactics for testability are also useful for achieving modifiability. Why do \nyou think that is? 4. Write some concrete testability scenarios for a GPS-based navigation app. What tactics \nwould you employ in a design to respond to these scenarios? 5. One of our tactics is to limit nondeterminism, and one method is to use locking to \nenforce synchronization. What impact does the use of locks have on other quality \nattributes? 6. Suppose you\u2019re building the next great social networking system. You anticipate that \nwithin a month of your debut, you will have half a million users. You can\u2019t pay half a \nmillion people to test your system, yet it has to be robust and easy to use when all half \na million are banging away at it. What should you do? What tactics will help you? Write \na testability scenario for this social network system. 7. Suppose you use executable assertions to improve testability. Make a case for, and then \na case against, allowing the assertions to run in the production system as opposed to \nremoving them after testing.", "domains": ["Architectural Patterns and Styles", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 214", "position": 214, "chunk_type": "semantic", "token_estimate": 372}
{"text": "197: 13\n \nUsability\nPeople ignore design that ignores people. \u2014Frank Chimero\nUsability is concerned with how easy it is for the user to accomplish a desired task and the \nkind of user support that the system provides. Over the years, a focus on usability has shown \nitself to be one of the cheapest and easiest ways to improve a system\u2019s quality (or more pre-\ncisely, the user\u2019s perception of quality) and hence end-user satisfaction. Usability comprises the following areas:\n \n\u25a0Learning system features. If the user is unfamiliar with a particular system or a partic-\nular aspect of it, what can the system do to make the task of learning easier? This might \ninclude providing help features. \u25a0Using a system efficiently. What can the system do to make the user more efficient in \nits operation? This might include enabling the user to redirect the system after issuing a \ncommand. For example, the user may wish to suspend one task, perform several opera-\ntions, and then resume that task. \u25a0Minimizing the impact of user errors. What can the system do to ensure that a user error \nhas minimal impact? For example, the user may wish to cancel a command issued incor-\nrectly or undo its effects. \u25a0Adapting the system to user needs. How can the user (or the system itself) adapt to make \nthe user\u2019s task easier? For example, the system may automatically fill in URLs based on \na user\u2019s past entries. \u25a0Increasing confidence and satisfaction. What does the system do to give the user \nconfidence that the correct action is being taken? For example, providing feedback that \nindicates that the system is performing a long-running task, along with the completion \npercentage so far, will increase the user\u2019s confidence in the system. Researchers focusing on human\u2013computer interactions have used the terms user initia-\ntive, system initiative, and mixed initiative to describe which of the human\u2013computer pair \ntakes the initiative in performing certain actions and how the interaction proceeds. Usability \nscenarios can combine initiatives from both perspectives. For example, when canceling a com-\nmand, the user issues a cancel (user initiative) and the system responds. During the cancel,", "domains": ["Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 216", "position": 216, "chunk_type": "semantic", "token_estimate": 355}
{"text": "198 Part II Quality Attributes | Chapter 13 Usability: however, the system may display a progress indicator (system initiative). Thus the cancel oper-\nation may comprise a mixed initiative. In this chapter, we will use this distinction between \nuser initiative and system initiative to discuss the tactics that the architect uses to achieve the \nvarious scenarios. There is a strong connection between the achievement of usability and modifiability. The \nuser interface design process consists of generating and then testing a user interface design. It \nis highly unlikely that you will get this right the first time, so you should plan to iterate this \nprocess\u2014and hence you should design your architecture to make that iteration less painful. This is why usability is strongly connected to modifiability. As you iterate, deficiencies in the \ndesign are\u2014one hopes\u2014corrected and the process repeats. This connection has resulted in standard patterns to support user interface design. Indeed, \none of the most helpful things you can do to achieve usability is to modify your system, over and \nover, to make it better as you learn from your users and discover improvements to be made. 13.1  \nUsability General Scenario\nTable 13.1 enumerates the elements of the general scenario that characterize usability. TABLE 13.1 Usability General Scenario\nPortion of \nScenario\nDescription\nPossible Values\nSource \nWhere does the stimulus come \nfrom? The end user (who may be in a specialized role, \nsuch as a system or network administrator) is the \nprimary source of the stimulus for usability. An external event arriving at a system (to which \nthe user may react) may also be a stimulus source. Stimulus\nWhat does the end user want? End user wants to:\n \n\u25a0\nUse a system efficiently\n \n\u25a0\nLearn to use the system\n \n\u25a0\nMinimize the impact of errors\n \n\u25a0\nAdapt the system\n \n\u25a0\nConfigure the system\nEnvironment\nWhen does the stimulus reach \nthe system? The user actions with which usability is concerned \nalways occur at runtime or at system configuration \ntime. Artifacts\nWhat portion of the system is \nbeing stimulated? Common examples include:\n \n\u25a0", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 217", "position": 217, "chunk_type": "semantic", "token_estimate": 340}
{"text": "\u25a0: A command-line interface\n \n\u25a0\nA voice interface\n \n\u25a0\nA touch screen", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 217", "position": 217, "chunk_type": "semantic", "token_estimate": 12}
{"text": "200 Part II Quality Attributes | Chapter 13 Usability: 13.2  \nTactics for Usability\nFigure 13.2 shows the goal of the set of usability tactics. User interaction\nUser given\nappropriate feedback\nand assistance\nTactics\nto Control\nResponse\nFIGURE 13.2 The goal of usability tactics\nSupport User Initiative\nOnce a system is executing, usability is enhanced by giving the user feedback about what the \nsystem is doing and by allowing the user to make appropriate responses. For example, the tac-\ntics described next\u2014cancel, undo, pause/resume, and aggregate\u2014support the user in either \ncorrecting errors or being more efficient. The architect designs a response for user initiative by enumerating and allocating the \nresponsibilities of the system to respond to the user command. Here are some common exam-\nples of tactics to support user initiative:\n \n\u25a0Cancel. When the user issues a cancel command, the system must be listening for it \n(thus there is the responsibility to have a constant listener that is not blocked by the \nactions of whatever is being canceled); the activity being canceled must be terminated; \nany resources being used by the canceled activity must be freed; and components that \nare collaborating with the canceled activity must be informed so that they can also take \nappropriate action. \u25a0Undo. To support the ability to undo, the system must maintain a sufficient amount of \ninformation about system state so that an earlier state may be restored, at the user\u2019s request. Such a record may take the form of state \u201csnapshots\u201d\u2014for example, checkpoints\u2014\nor a set of reversible operations. Not all operations can be easily reversed. For exam-\nple, changing all occurrences of the letter \u201ca\u201d to the letter \u201cb\u201d in a document cannot be \nreversed by changing all instances of \u201cb\u201d to \u201ca\u201d, because some of those instances of \u201cb\u201d \nmay have existed prior to the original change. In such a case, the system must maintain a", "domains": ["Design Patterns", "Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 219", "position": 219, "chunk_type": "semantic", "token_estimate": 313}
{"text": "13.2 Tactics for Usability 201: more elaborate record of the change. Of course, some operations cannot be undone at all: \nYou can\u2019t unship a package or unfire a missile, for example. Undo comes in flavors. Some systems allow a single undo (where invoking undo \nagain reverts you to the state in which you commanded the first undo, essentially undo-\ning the undo). In other systems, commanding multiple undo operations steps you back \nthrough many previous states, either up to some limit or all the way back to the time \nwhen the application was last opened. \u25a0Pause/resume. When a user has initiated a long-running operation\u2014say, downloading a \nlarge file or a set of files from a server\u2014it is often useful to provide the ability to pause \nand resume the operation. Pausing a long-running operation may be done to temporarily \nfree resources so that they may be reallocated to other tasks. \u25a0Aggregate. When a user is performing repetitive operations, or operations that affect a \nlarge number of objects in the same way, it is useful to provide the ability to aggregate \nthe lower-level objects into a single group, so that the operation may be applied to the \ngroup, thus freeing the user from the drudgery, and potential for mistakes, of doing the \nsame operation repeatedly. An example is aggregating all of the objects in a slide and \nchanging the text to 14-point font. Support System Initiative\nWhen the system takes the initiative, it must rely on a model of the user, a model of the task \nbeing undertaken by the user, or a model of the system state. Each model requires various \ntypes of input to accomplish its initiative. The support system initiative tactics identify the \nmodels the system uses to predict either its own behavior or the user\u2019s intention. Encapsulating \nthis information will make it easier to tailor or modify it. Tailoring and modification can either \nbe dynamically based on past user behavior or happen offline during development. The rele-\nvant tactics are described here:\n \n\u25a0Maintain task model. The task model is used to determine context so the system can \nhave some idea of what the user is attempting to do and provide assistance. For example, \nmany search engines provide predictive type-ahead capabilities, and many mail clients \nprovide spell-correction. Both of these functions are based on task models. \u25a0Maintain user model.", "domains": ["Design Patterns", "Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 220", "position": 220, "chunk_type": "semantic", "token_estimate": 390}
{"text": "13.2 Tactics for Usability 201: Both of these functions are based on task models. \u25a0Maintain user model. This model explicitly represents the user\u2019s knowledge of the sys-\ntem, the user\u2019s behavior in terms of expected response time, and other aspects specific to \na user or a class of users. For example, language-learning apps are constantly monitoring \nareas where a user makes mistakes and then providing additional exercises to correct \nthose behaviors. A special case of this tactic is commonly found in user interface cus-\ntomization, wherein a user can explicitly modify the system\u2019s user model. \u25a0Maintain system model. The system maintains an explicit model of itself. This is used \nto determine expected system behavior so that appropriate feedback can be given to the \nuser. A common manifestation of a system model is a progress bar that predicts the time \nneeded to complete the current activity. Figure 13.3 summarizes the tactics to achieve usability.", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 220", "position": 220, "chunk_type": "semantic", "token_estimate": 153}
{"text": "202 Part II Quality Attributes | Chapter 13 Usability: Support User Initiative\nSupport System Initiative\nUsability Tactics\nCancel\nUndo\nPause/Resume\nAggregate\nMaintain Task Model\nMaintain User Model\nMaintain System Model\nFIGURE 13.3 Usability tactics\n13.3  \nTactics-Based Questionnaire for Usability\nBased on the tactics described in Section 13.2, we can create a set of usability tactics\u2013inspired \nquestions, as presented in Table 13.2. To gain an overview of the architectural choices made \nto support usability, the analyst asks each question and records the answers in the table. The \nanswers to these questions can then be made the focus of further activities: investigation of \ndocumentation, analysis of code or other artifacts, reverse engineering of code, and so forth. TABLE 13.2 Tactics-Based Questionnaire for Usability\nTactics \nGroup\nTactics Question\nSupported? (Y/N)\nRisk\nDesign \nDecisions \nand \nLocation\nRationale \nand \nAssumptions\nSupport \nUser \nInitiative\nIs the system able to listen to and \nrespond to a cancel command? Is it possible to undo the last \ncommand, or the last several \ncommands? Is it possible to pause and then \nresume long-running operations? Is it possible to aggregate UI \nobjects into a group and apply \noperations on the group?", "domains": ["Design Patterns", "Domain-Driven Design"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 221", "position": 221, "chunk_type": "semantic", "token_estimate": 190}
{"text": "13.4 Patterns for Usability 203: Tactics \nGroup\nTactics Question\nSupported? (Y/N)\nRisk\nDesign \nDecisions \nand \nLocation\nRationale \nand \nAssumptions\nSupport \nSystem \nInitiative\nDoes the system maintain a \nmodel of the task? Does the system maintain a \nmodel of the user? Does the system maintain a \nmodel of itself? 13.4  \nPatterns for Usability\nWe will briefly discuss three usability patterns: model-view-controller (MVC) and its variants, \nobserver, and memento. These patterns primarily promote usability by promoting separation of \nconcerns, which in turn makes it easy to iterate the design of a user interface. Other kinds of pat-\nterns are also possible\u2014including patterns used in the design of the user interface itself, such as \nbreadcrumbs, shopping cart, or progressive disclosure\u2014but we will not discuss them here. Model-View-Controller\nMVC is likely the most widely known pattern for usability. It comes in many variants, such as \nMVP (model-view-presenter), MVVM (model-view-view-model), MVA (model-view-adapter), \nand so forth. Essentially all of these patterns are focused on separating the model\u2014the under-\nlying \u201cbusiness\u201d logic of the system\u2014from its realization in one or more UI views. In the \noriginal MVC model, the model would send updates to a view, which a user would see and \ninteract with. User interactions\u2014key presses, button clicks, mouse motions, and so forth\u2014are \ntransmitted to the controller, which interprets them as operations on the model and then sends \nthose operations to the model, which changes its state in response. The reverse path was also \na portion of the original MVC pattern. That is, the model might be changed and the controller \nwould send updates to the view. The sending of updates depends on whether the MVC is in one process or is distributed \nacross processes (and potentially across the network). If the MVC is in one process, then the \nupdates are sent using the observer pattern (discussed in the next subsection). If the MVC is \ndistributed across processes, then the publish-subscribe pattern is often used to send updates \n(see Chapter 8). Benefits:\n \n\u25a0Because MVC promotes clear separation of concerns, changes to one aspect of the sys-\ntem, such as the layout of the UI (the view), often have no consequences for the model or \nthe controller.", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Design Principles", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 222", "position": 222, "chunk_type": "semantic", "token_estimate": 360}
{"text": "204 Part II Quality Attributes | Chapter 13 Usability: \u25a0Additionally, because MVC promotes separation of concerns, developers can be working \non all aspects of the pattern\u2014model, view, and controller\u2014relatively independently and \nin parallel. These separate aspects can also be tested in parallel. \u25a0A model can be used in systems with different views, or a view might be used in systems \nwith different models. Tradeoffs:\n \n\u25a0MVC can become burdensome for complex UIs, as information is often sprinkled \nthroughout several components. For example, if there are multiple views of the same \nmodel, a change to the model may require changes to several otherwise unrelated \ncomponents. \u25a0For simple UIs, MVC adds up-front complexity that may not pay off in downstream \nsavings. \u25a0MVC adds a small amount of latency to user interactions. While this is generally accept-\nable, it might be problematic for applications that require very low latency. Observer\nThe observer pattern is a way to link some functionality with one or more views. This pat-\ntern has a subject\u2014the entity being observed\u2014and one or more observers of that subject. Observers need to register themselves with the subject; then, when the state of the subject \nchanges, the observers are notified. This pattern is often used to implement MVC (and its \nvariants)\u2014for example, as a way to notify the various views of changes to the model. Benefits:\n \n\u25a0This pattern separates some underlying functionality from the concern of how, and how \nmany times, this functionality is presented. \u25a0The observer pattern makes it easy to change the bindings between the subject and the \nobservers at runtime. Tradeoffs:\n \n\u25a0The observer pattern is overkill if multiple views of the subject are not required. \u25a0The observer pattern requires that all observers register and de-register with the subject. If observers neglect to de-register, then their memory is never freed, which effectively \nresults in a memory leak. In addition, this can negatively affect performance, since obso-\nlete observers will continue to be invoked. \u25a0Observers may need to do considerable work to determine if and how to reflect a state \nupdate, and this work may be repeated for each observer. For example, suppose the sub-\nject is changing its state at a fine granularity, such as a temperature sensor that reports \n1/100th degree fluctuations, but the view updates changes only in full degrees. In such \ncases where there is an \u201cimpedance mismatch,\u201d substantial processing resources may \nbe wasted.", "domains": ["Design Patterns", "Design Principles", "Software Quality Attributes", "Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 223", "position": 223, "chunk_type": "semantic", "token_estimate": 396}
{"text": "13.6 Discussion Questions 205: Memento\nThe memento pattern is a common way to implement the undo tactic. This pattern features \nthree major components: the originator, the caretaker, and the memento. The originator is \nprocessing some stream of events that change its state (originating from user interaction). The \ncaretaker is sending events to the originator that cause it to change its state. When the care-\ntaker is about to change the state of the originator, it can request a memento\u2014a snapshot of \nthe existing state\u2014and can use this artifact to restore that existing state if needed, by simply \npassing the memento back to the originator. In this way, the caretaker knows nothing about \nhow state is managed; the memento is simply an abstraction that the caretaker employs. Benefits:\n \n\u25a0The obvious benefit of this pattern is that you delegate the complicated process of imple-\nmenting undo, and figuring out what state to preserve, to the class that is actually cre-\nating and managing that state. In consequence, the originator\u2019s abstraction is preserved \nand the rest of the system does not need to know the details. Tradeoffs:\n \n\u25a0Depending on the nature of the state being preserved, the memento can consume arbi-\ntrarily large amounts of memory, which can affect performance. In a very large docu-\nment, try cutting and pasting many large sections, and then undoing all of that. This is \nlikely to result in your text processor noticeably slowing down. \u25a0In some programming languages, it is difficult to enforce the memento as an opaque \nabstraction. 13.5  \nFor Further Reading\nClaire Marie Karat has investigated the relation between usability and business advantage \n[Karat 94]. Jakob Nielsen has also written extensively on this topic, including a calculation of the \nROI of usability [Nielsen 08]. Bonnie John and Len Bass have investigated the relation between usability and software \narchitecture. They have enumerated approximately two dozen usability scenarios that have \narchitectural impact and given associated patterns for these scenarios [Bass 03]. Greg Hartman has defined attentiveness as the system\u2019s ability to support user initiative \nand allow cancel or pause/resume [Hartman 10]. 13.6  \nDiscussion Questions\n1. Write a concrete usability scenario for your automobile that specifies how long it takes \nyou to set your favorite radio stations. Now consider another part of the driver experience", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 224", "position": 224, "chunk_type": "semantic", "token_estimate": 378}
{"text": "206 Part II Quality Attributes | Chapter 13 Usability: and create scenarios that test other aspects of the response measures from the general \nscenario table (Table 13.1). 2. How might usability trade off against security? How might it trade off against \nperformance? 3. Pick a few of your favorite websites that do similar things, such as social networking or \nonline shopping. Now pick one or two appropriate responses from the usability gen-\neral scenario (such as \u201canticipate the user\u2019s need\u201d) and an appropriate corresponding \nresponse measure. Using the response and response measure you chose, compare the \nwebsites\u2019 usability. 4. Why is it that in so many systems, the cancel button in a dialog box appears to be unre-\nsponsive? Which architectural principles do you think were ignored in these systems? 5. Why do you think that progress bars frequently behave erratically, moving from 10 to \n90 percent in one step and then getting stuck on 90 percent? 6. Research the crash of Air France flight 296 into the forest at Habsheim, France, in 1988. The pilots said they were unable to read the digital display of the radio altimeter or hear \nits audible readout. In this context, discuss the relationship between usability and safety.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 225", "position": 225, "chunk_type": "semantic", "token_estimate": 204}
{"text": "207: 14\nWorking with Other Quality \nAttributes\nQuality is not what happens when what you do matches your \nintentions. It is what happens when what you do matches \nyour customers\u2019 expectations. \u2014Guaspari\nChapters 4\u201313 each dealt with a particular quality attribute (QA) that is important to software \nsystems. Each of those chapters discussed how its particular QA is defined, gave a general \nscenario for that QA, and showed how to write specific scenarios to express precise shades of \nmeaning concerning that QA. In addition, each provided a collection of techniques to achieve \nthat QA in an architecture. In short, each chapter presented a kind of portfolio for specifying \nand designing to achieve a particular QA. However, as you can no doubt infer, those ten chapters only begin to scratch the surface \nof the various QAs that you might need in a software system you\u2019re working on. This chapter will show how to build the same kind of specification and design approach \nfor a QA not covered in our \u201cA list.\u201d\n14.1  \nOther Kinds of Quality Attributes\nThe quality attributes covered so far in Part II of this book all have something in common: \nThey deal with either the system in operation, or the development project that creates and \nfields the system. Put another way, to measure one of those QAs, either you measure the sys-\ntem while it is running (availability, energy efficiency, performance, security, safety, usabil-\nity), or you measure the people doing something to the system while it is not (modifiability, \ndeployability, integrability, testability). While these certainly give you an \u201cA list\u201d of important \nQAs, there are other qualities that could be equally useful.", "domains": ["Software Quality Attributes", "Domain-Driven Design"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 226", "position": 226, "chunk_type": "semantic", "token_estimate": 276}
{"text": "208 Part II Quality Attributes | Chapter 14 Working with Other Quality Attributes: Many systems these days are developed using globally distrib-\nuted teams. One problem that must be overcome when adopting this approach is coordinat-\ning the teams\u2019 activities. The system should be designed so that coordination among teams is \nminimized\u2014that is, the major subsystems should exhibit low coupling. This minimal coordi-\nnation needs to be achieved both for the code and for the data model. Teams working on mod-\nules that communicate with each other may need to negotiate the interfaces of those modules. When a module is used by many other modules, each developed by a different team, com-\nmunication and negotiation become more complex and burdensome. Thus the architectural \nstructure and the social (and business) structure of the project need to be reasonably aligned. Similar considerations apply for the data model. Scenarios for development distributability", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 227", "position": 227, "chunk_type": "semantic", "token_estimate": 149}
{"text": "14.2 Using Standard Lists of Quality Attributes\u2014Or Not 209: will deal with the compatibility of the communication structures and data model of the sys-\ntem being developed and the coordination mechanisms utilized by the organizations doing the \ndevelopment. System Quality Attributes\nPhysical systems, such as aircraft and automobiles and kitchen appliances, that rely on soft-\nware embedded within them are designed to meet a whole litany of QAs: weight, size, electric \nconsumption, power output, pollution output, weather resistance, battery life, and on and on. Often the software architecture can have a profound effect on the system\u2019s QAs. For example, \nsoftware that makes inefficient use of computing resources might require additional memory, \na faster processor, a bigger battery, or even an additional processor (we dealt with the topic of \nenergy efficiency as a QA in Chapter 6). Additional processors will add to a system\u2019s power \nconsumption, of course, but also to its weight, its physical profile, and expense. Conversely, the architecture or implementation of a system can enable or preclude soft-\nware from meeting its QA requirements. For example:\n1. The performance of a piece of software is fundamentally constrained by the perfor-\nmance of the processor that runs it. No matter how well you design the software, you \njust can\u2019t run the latest whole-earth weather forecasting models on Grandpa\u2019s laptop and \nexpect to know if it\u2019s going to rain tomorrow. 2. Physical security is probably more important and more effective than software security \nat preventing fraud and theft. If you don\u2019t believe this, write your laptop\u2019s password on \na slip of paper, tape it to your laptop, and leave it in an unlocked car with the windows \ndown. (Actually, please don\u2019t do that. Consider this a thought experiment.) The lesson here is that if you are the architect for software that resides in a physical sys-\ntem, you will need to understand the QAs that are important for the entire system to achieve, \nand work with the system architects and engineers to ensure that your software architecture \ncontributes positively to achieving them. The scenario techniques we introduced for software QAs work equally well for system \nQAs. If the system engineers and architects aren\u2019t already using them, try to introduce them. 14.2  \nUsing Standard Lists of Quality Attributes\u2014Or Not\nArchitects have no shortage of QA lists for software systems at their disposal.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 228", "position": 228, "chunk_type": "semantic", "token_estimate": 391}
{"text": "System Software: Product Quality\nFunctional \nsuitability\nFunctional \ncompleteness\nFunctional \ncorrectness\nFunctional \nappropriateness\nPerformance \nHI\u0182FLHQF\\\nTime behavior\nResource \nutilization\nCapacity\nCompatibility\nCoexistence\nInteroperability\nLearnability\nOperability\nUser interface \naesthetics\nAccessibility\nReliability\nMaturity\nAvailability\n \n \nFault tolerance\nRecoverability\nSecurity\n&RQ\u0182GHQWLDOLW\\\nIntegrity\n \n \n1RQUHSXGLDWLRQ\nAccountability\nAuthenticity\nMaintainability\n0RGXODULW\\\nReusability\nAnalyzability\n0RGL\u0182DELOLW\\\nTestability\nUsability\nAppropriateness \nrecognizability\nUser error", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 229", "position": 229, "chunk_type": "semantic", "token_estimate": 51}
{"text": "Portability: $GDSWDELOLW\\\nInstallability\nReplaceability\nFIGURE 14.1 ISO/IEC FCD 25010 Product Quality Standard", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 229", "position": 229, "chunk_type": "semantic", "token_estimate": 12}
{"text": "14.2 Using Standard Lists of Quality Attributes\u2014Or Not 211: model. That division is a bit of a stretch in some places, but it nevertheless begins a divide-\nand-conquer march through a breathtaking array of qualities. ISO 25010 lists the following QAs that deal with product quality:\n \n\u25a0Functional suitability. Degree to which a product or system provides functions that meet \nthe stated and implied needs when used under the specified conditions. \u25a0Performance efficiency. Performance relative to the amount of resources used under the \nstated conditions. \u25a0Compatibility. Degree to which a product, system, or component can exchange informa-\ntion with other products, systems, or components, and/or perform its required functions, \nwhile sharing the same hardware or software environment. \u25a0Usability. Degree to which a product or system can be used by specified users to achieve \nspecified goals with effectiveness, efficiency, and satisfaction in a specified context of use. \u25a0Reliability. Degree to which a system, product, or component performs the specified \nfunctions under the specified conditions for a specified period of time. \u25a0Security. Degree to which a product or system protects information and data so that \npersons or other products or systems have the degree of data access appropriate to their \ntypes and levels of authorization. \u25a0Maintainability. Degree of effectiveness and efficiency with which a product or system \ncan be modified by the intended maintainers. \u25a0Portability. Degree of effectiveness and efficiency with which a system, product, or \ncomponent can be transferred from one hardware, software, or other operational or \nusage environment to another. In ISO 25010, these \u201cquality characteristics\u201d are each composed of \u201cquality sub-characteristics\u201d \n(for example, nonrepudiation is a sub-characteristic of security). The standard slogs through \nalmost five dozen separate descriptions of quality sub-characteristics in this way. It defines for \nus the qualities of \u201cpleasure and \u201ccomfort.\u201d It distinguishes between \u201cfunctional correctness\u201d \nand \u201cfunctional completeness,\u201d and then adds \u201cfunctional appropriateness\u201d for good measure. To exhibit \u201ccompatibility,\u201d systems must either have \u201cinteroperability\u201d or just plain \u201ccoexis-\ntence.\u201d \u201cUsability\u201d is a product quality, not a quality-in-use quality, although it includes \u201csat-\nisfaction,\u201d which is a quality-in-use quality. \u201cModifiability\u201d and \u201ctestability\u201d are both part of \n\u201cmaintainability.\u201d So is \u201cmodularity,\u201d which is a strategy for achieving a quality rather than a \ngoal in its own right. \u201cAvailability\u201d is part of \u201creliability.\u201d \u201cInteroperability\u201d is part of \u201ccom-\npatibility.\u201d And \u201cscalability\u201d isn\u2019t mentioned at all. Got all that? Lists like these\u2014and there are many of them floating around\u2014do serve a purpose.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 230", "position": 230, "chunk_type": "semantic", "token_estimate": 402}
{"text": "212 Part II Quality Attributes | Chapter 14 Working with Other Quality Attributes: General lists like these also have some drawbacks. First, no list will ever be complete. As an architect, you will inevitably be called upon to design a system to meet a stakeholder \nconcern not foreseen by any list-maker. For example, some writers speak of \u201cmanageability,\u201d \nwhich expresses how easy it is for system administrators to manage the application. This can \nbe achieved by inserting useful instrumentation for monitoring operations and for debugging \nand performance tuning. We know of an architecture that was designed with the conscious \ngoal of retaining key staff and attracting talented new hires to a quiet region of the American \nMidwest. That system\u2019s architects spoke of imbuing the system with \u201cIowability.\u201d They achieved \nit by bringing in state-of-the-art technology and giving their development teams wide cre-\native latitude. Good luck finding \u201cIowability\u201d in any standard list of QAs, but that QA was as \nimportant to that organization as any other. Second, lists often generate more controversy than understanding. You might argue per-\nsuasively that \u201cfunctional correctness\u201d should be part of \u201creliability,\u201d or that \u201cportability\u201d is just \na kind of \u201cmodifiability,\u201d or that \u201cmaintainability\u201d is a kind of \u201cmodifiability\u201d (not the other \nway around). The writers of ISO 25010 apparently spent time and effort deciding to make \nsecurity its own characteristic, instead of a sub-characteristic of functionality, which it was in \na previous version. We strongly believe that effort in making these arguments could be better \nspent elsewhere. Third, these lists often purport to be taxonomies\u2014that is, lists with the special property \nthat every member can be assigned to exactly one place. But QAs are notoriously squishy in \nthis regard. For example, we discussed denial of service as being part of security, availability, \nperformance, and usability in Chapter 3. These observations reinforce the lesson introduced in Chapter 3: QA names, by them-\nselves, are largely useless and are at best invitations to begin a conversation. Moreover, spend-\ning time worrying about which qualities are subqualities of which other qualities is almost \nuseless. Instead, scenarios provide the best way for us to specify precisely what we mean when \nwe speak of a QA. Use standard lists of QAs to the extent that they are helpful as checklists, but don\u2019t feel \nthe need to slavishly adhere to their terminology or structure. And don\u2019t fool yourself that such \na checklist removes the need for deeper analysis.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 231", "position": 231, "chunk_type": "semantic", "token_estimate": 408}
{"text": "14.3 Dealing with \u201cX-Ability\u201d: Bringing a New QA into the Fold 213: Capture Scenarios for the New Quality Attribute\nThe first step is to interview the stakeholders whose concerns have led to the need for this QA. You can work with them, either individually or as a group, to build a set of attribute charac-\nterizations that refine what is meant by the QA. For example, you might decompose develop-\nment distributability into the subattributes of software segmentation, software composition, \nand team coordination. After that refinement, you can work with the stakeholders to craft a set \nof specific scenarios that characterize what is meant by that QA. An example of this process \ncan be found in Chapter 22, where we describe building a \u201cutility tree.\u201d\nOnce you have a set of specific scenarios, then you can work to generalize the collection. Look at the set of stimuli you\u2019ve collected, the set of responses, the set of response measures, \nand so on. Use those to construct a general scenario by making each part of the general sce-\nnario a generalization of the specific instances you collected. Model the Quality Attribute\nIf you can build (or even better, find) a conceptual model of the QA, that foundation can be \nhelpful in creating a set of design approaches for it. By \u201cmodel,\u201d we don\u2019t mean anything \nmore than an understanding of the set of parameters to which the QA is sensitive and the set \nof architectural characteristics that influence those parameters. For example, a model of mod-\nifiability might tell us that modifiability is a function of how many places in a system have \nto be changed in response to a modification, and the interconnectedness of those places. A \nmodel for performance might tell us that throughput is a function of transactional workload, \nthe dependencies among the transactions, and the number of transactions that can be pro-\ncessed in parallel. Figure 14.2 shows a simple queuing model for performance. Such models are widely used \nto analyze the latency and throughput of various types of queuing systems, including manufac-\nturing and service environments, as well as computer systems. Results\nRouting of \nmessages\nArrivals\nQueue\nServer\nScheduling\nalgorithm\nFIGURE 14.2 A generic queuing model", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 232", "position": 232, "chunk_type": "semantic", "token_estimate": 369}
{"text": "214 Part II Quality Attributes | Chapter 14 Working with Other Quality Attributes: Within this model, seven parameters can affect the latency that the model predicts:\n \n\u25a0Arrival rate\n \n\u25a0Queuing discipline\n \n\u25a0Scheduling algorithm\n \n\u25a0Service time\n \n\u25a0Topology\n \n\u25a0Network bandwidth\n \n\u25a0Routing algorithm\nThese are the only parameters that can affect latency within this model. This is what gives the \nmodel its power. Furthermore, each of these parameters can be affected by various architec-\ntural decisions. This is what makes the model useful for an architect. For example, the routing \nalgorithm can be fixed or it could be a load-balancing algorithm. A scheduling algorithm must \nbe chosen. The topology can be affected by dynamically adding or removing new servers. And \nso forth. If you are creating your own model, your set of scenarios will inform your investigation. Its parameters can be derived from the stimuli (and its sources), the responses (and their mea-\nsures), the artifacts (and their properties), and the environment (and its characteristics). Assemble Design Approaches for the New Quality Attribute\nThe process of generating a set of mechanisms based on a model includes the following steps:\n \n\u25a0Enumerate the model\u2019s parameters. \u25a0For each parameter, enumerate the architectural characteristics (and the mechanisms to \nachieve those characteristics) that can affect this parameter. You can do this by:\n \n\u25a0Revisiting a body of mechanisms you\u2019re familiar with and asking yourself how each \none affects the QA parameter. \u25a0Searching for designs that have successfully dealt with this QA. You can search on the \nname you\u2019ve given the QA itself, but you can also search for the terms you chose when \nyou refined the QA into subattributes. \u25a0Searching for publications and blog posts on this QA and attempting to generalize \ntheir observations and findings. \u25a0Finding experts in this area and interviewing them or simply writing and asking them \nfor advice. What results is a list of mechanisms to, in the example case, control performance and, \nin the more general case, to control the QA that the model is concerned with. This makes the \ndesign problem much more tractable. This list of mechanisms is finite and reasonably small, \nbecause the number of parameters of the model is bounded and for each parameter, the num-\nber of architectural decisions to affect the parameter is limited.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 233", "position": 233, "chunk_type": "semantic", "token_estimate": 375}
{"text": "14.5 Discussion Questions 215: 14.4  \nFor Further Reading\nThe mother of all QA lists may be the one on\u2014where else?\u2014Wikipedia. This list can be \nfound, naturally enough, under \u201cList of system quality attributes.\u201d As this book went to pub-\nlication, you could gorge yourself on definitions of more than 80 distinct QAs. Our favorite is \n\u201cdemonstrability,\u201d which is helpfully defined as the quality of being demonstrable. Who says \nyou can\u2019t believe what you read on the Internet? See Chapter 8 of [Bass 19] to get a list of qualities of a deployment pipeline. These include \ntraceability, testability (of the deployment pipeline), tooling, and cycle time. 14.5  \nDiscussion Questions\n1. The Kingdom of Bhutan measures the happiness of its population, and government \npolicy is formulated to increase Bhutan\u2019s GNH (gross national happiness). Read about \nhow the GNH is measured (try grossnationalhappiness.com) and then sketch a general \nscenario for the QA of happiness that will let you express concrete happiness require-\nments for a software system. 2. Choose a QA not described in Chapters 4\u201313. For that QA, assemble a set of specific \nscenarios that describe what you mean by it. Use that set of scenarios to construct a \ngeneral scenario for it. 3. For the QA you chose for question 2, assemble a set of design mechanisms (patterns and \ntactics) that help you achieve it. 4. Repeat questions 2 and 3 for the QA of development cost, and then for the QA of operat-\ning cost. 5. What might cause you to add a tactic or pattern to the sets of QAs already described in \nChapters 4\u201313 (or any other QA, for that matter)? 6. Discuss how you think development distributability tends to trade off against the QAs of \nperformance, availability, modifiability, and integrability. 7. Research some QA lists for things that are not software systems: qualities of a good car, \nfor example, or a good person to be in a relationship with. Add qualities of your own \nchoosing to the list or lists that you find. 8. Development-time tactics have to do with separating and encapsulating responsibili-\nties. Performance tactics have to do with putting things together. That is why they are \nperpetually in conflict. Must it always be so? Is there a principled way of quantifying the \ntradeoffs?", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 234", "position": 234, "chunk_type": "semantic", "token_estimate": 379}
{"text": "216 Part II Quality Attributes | Chapter 14 Working with Other Quality Attributes: 9. Is there a taxonomy of tactics? Chemists have the periodic table and laws of molecular \ninteraction, atomic physicists have their catalogs of subatomic particles and laws for \nwhat happens when they collide, pharmacologists have their catalogs of chemicals and \nlaws for their interactions with receptors and metabolic systems, and so forth. What is \nthe equivalent for tactics? And are there laws for their interaction? 10. Security is a QA that is especially sensitive to processes that take place in the physical \nworld outside the computer: processes for applying patches, processes for choosing and \nsafeguarding your passwords, processes for physically securing the installations where \ncomputers and data live, processes for deciding whether to trust a piece of imported soft-\nware, processes for deciding whether to trust a human developer or user, and so forth. What are the corresponding processes that are important for performance? Or usability? Are there any? Why is security so process-sensitive? Should processes be a portion of \nthe QA structure or are they orthogonal to it? 11. What is the relationship between each pair of QAs in the following list? \u25a0Performance and security\n \n\u25a0Security and buildability\n \n\u25a0Energy efficiency and time to market", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 235", "position": 235, "chunk_type": "semantic", "token_estimate": 208}
{"text": "217: 15\n \nSoftware Interfaces\nWith Cesare Pautasso\nNASA lost its $125-million Mars Climate Orbiter because spacecraft \nengineers failed to convert from English to metric measurements \nwhen exchanging vital data before the craft was launched. . . . A navigation team at [NASA] used the metric system of millimeters \nand meters in its calculations, while [the company that] designed and \nbuilt the spacecraft provided crucial acceleration data in the English \nsystem of inches, feet and pounds. . . . In a sense, the spacecraft was lost in translation. \u2014Robert Lee Hotz, \u201cMars Probe Lost Due to Simple Math Error,\u201d Los Angeles \nTimes, October 1, 1999\nThis chapter describes the concepts surrounding interfaces, and discusses how to design and \ndocument them. An interface, software or otherwise, is a boundary across which elements meet and interact, \ncommunicate, and coordinate. Elements have interfaces that control access to their internals. Elements may also be subdivided, with each sub-element having its own interface. An element\u2019s actors are the other elements, users, or systems with which it interacts. The \ncollection of actors with which an element interacts is called the environment of the element. By \u201cinteracts,\u201d we mean anything one element does that can impact the processing of another \nelement. This interaction is part of the element\u2019s interface. Interactions can take a variety of \nforms, though most involve the transfer of control and/or data. Some are supported by stan-\ndard programming-language constructs, such as local or remote procedure calls (RPCs), data \nstreams, shared memory, and message passing. These constructs, which provide points of direct interaction with an element, are called \nresources. Other interactions are indirect. For example, the fact that using resource X on \nelement A leaves element B in a particular state is something that other elements using the \nresource may need to know if it affects their processing, even though they never interact with \nelement A directly. That fact about A is a part of the interface between A and the other ele-\nments in A\u2019s environment. In this chapter, we focus only on the direct interactions. PART III Architectural Solutions", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 236", "position": 236, "chunk_type": "semantic", "token_estimate": 346}
{"text": "218 Part III Architectural Solutions | Chapter 15 Software Interfaces: Recall that, in Chapter 1, we defined architecture in terms of elements and their rela-\ntionships. In this chapter, we focus on one type of relationship. Interfaces are a fundamen-\ntal abstraction mechanism necessary to connect elements together. They have an outsized \nimpact on a system\u2019s modifiability, usability, testability, performance, integrability, and more. Furthermore, asynchronous interfaces, which are commonly part of distributed systems, \nrequire event handlers\u2014an architectural element. For a given element\u2019s interface, there can be one or more implementations, each of which \nmight have different performance, scalability, or availability guarantees. Likewise, different \nimplementations for the same interface may be constructed for different platforms. Three points are implied by the discussion thus far:\n1. All elements have interfaces. All elements interact with some actors; otherwise, what is \nthe point of the element\u2019s existence? 2. Interfaces are two-way. When considering interfaces, most software engineers first think \nof a summary of what an element provides. What methods does the element make avail-\nable? What events does it process? But an element also interacts with its environment \nby making use of resources external to it or by assuming that its environment behaves \nin a certain way. If these resources are missing or if the environment doesn\u2019t behave as \nexpected, the element can\u2019t function correctly. So an interface is more than what is pro-\nvided by an element; an interface also includes what is required by an element. 3. An element can interact with more than one actor through the same interface. For \nexample, web servers often restrict the number of HTTP connections that can be open \nsimultaneously. 15.1  \nInterface Concepts\nIn this section, we discuss the concepts of multiple interfaces, resources, operations, proper-\nties, and events, as well as the evolution of interfaces. Multiple Interfaces\nIt is possible to split a single interface into multiple interfaces. Each of these has a related \nlogical purpose, and serves a different class of actors. Multiple interfaces provide a kind of \nseparation of concerns. A specific class of actor might require only a subset of the function-\nality available; this functionality can be provided by one of the interfaces. Conversely, the \nprovider of an element may want to grant actors different access rights, such as read or write, \nor to implement a security policy. Multiple interfaces support different levels of access.", "domains": ["Design Principles", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 237", "position": 237, "chunk_type": "semantic", "token_estimate": 394}
{"text": "218 Part III Architectural Solutions | Chapter 15 Software Interfaces: Conversely, the \nprovider of an element may want to grant actors different access rights, such as read or write, \nor to implement a security policy. Multiple interfaces support different levels of access. For \nexample, an element might expose its functionality through its main interface and give access \nto debugging or performance monitoring data or administrative functions via separate inter-\nfaces. There may be public read-only interfaces for anonymous actors and private interfaces \nthat allow authenticated and authorized actors to modify the state of an element.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 237", "position": 237, "chunk_type": "semantic", "token_estimate": 95}
{"text": "15.1 Interface Concepts 219: Resources\nResources have syntax and semantics:\n \n\u25a0Resource syntax. The syntax is the resource\u2019s signature, which includes any information \nthat another program will need to write a syntactically correct program that uses the \nresource. The signature includes the name of the resource, the names and data types of \narguments, if any, and so forth. \u25a0Resource semantics. What is the result of invoking this resource? Semantics come in a \nvariety of guises, including the following:\n \n\u25a0Assignment of values to data that the actor invoking the resource can access. The \nvalue assignment might be as simple as setting the value of a return argument or as \nfar-reaching as updating a central database. \u25a0Assumptions about the values crossing the interface. \u25a0Changes in the element\u2019s state brought about by using the resource. This includes \nexceptional conditions, such as side effects from a partially completed operation. \u25a0Events that will be signaled or messages that will be sent as a result of using the \nresource. \u25a0How other resources will behave differently in the future as the result of using this \nresource. For example, if you ask a resource to destroy an object, trying to access that \nobject in the future through other resources could produce an error as a result. \u25a0Humanly observable results. These are prevalent in embedded systems. For example, \ncalling a program that turns on a display in a cockpit has a very observable effect\u2014the \ndisplay comes on. In addition, the statement of semantics should make it clear whether \nthe execution of the resource will be atomic or may be suspended or interrupted. Operations, Events, and Properties\nThe resources of provided interfaces consist of operations, events, and properties. These resources \nare complemented by an explicit description of the behavior caused or data exchanged when \naccessing each interface resource in terms of its syntax, structure, and semantics. (Without this \ndescription, how would the programmer or actor know whether or how to use the resources?) Operations are invoked to transfer control and data to the element for processing. Most \noperations also return a result. Operations may fail, and as part of the interface it should be \nclear how actors can detect errors, either signaled as part of the output or through some dedi-\ncated exception-handling channel. In addition, events\u2014which are normally asynchronous\u2014may be described in interfaces.", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 238", "position": 238, "chunk_type": "semantic", "token_estimate": 383}
{"text": "15.1 Interface Concepts 219: Operations may fail, and as part of the interface it should be \nclear how actors can detect errors, either signaled as part of the output or through some dedi-\ncated exception-handling channel. In addition, events\u2014which are normally asynchronous\u2014may be described in interfaces. Incoming events can represent the receipt of a message taken from a queue, or the arrival of a \nstream element that is to be consumed. Active elements\u2014those that do not passively wait to be \ninvoked by other elements\u2014produce outgoing events used to notify listeners (or subscribers) \nabout interesting things happening within the element. In addition to the data transferred via operations and events, an important aspect of inter-\nfaces is metadata, such as access rights, units of measure, or formatting assumptions. Another", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 238", "position": 238, "chunk_type": "semantic", "token_estimate": 128}
{"text": "220 Part III Architectural Solutions | Chapter 15 Software Interfaces: name for this interface metadata is properties. Property values can influence the behavior of \noperations, as highlighted in the quotation that began this chapter. Property values also affect \nthe behavior of the element, depending on its state. Complex interfaces of elements that are both stateful and active will feature a combina-\ntion of operations, events, and properties. Interface Evolution\nAll software evolves, including interfaces. Software that is encapsulated by an interface is free \nto evolve without impact to the elements that use this interface as long as the interface itself \ndoes not change. An interface, however, is a contract between an element and its actors. Just as \na legal contract can be changed only within certain constraints, software interfaces should be \nchanged with care. Three techniques can be used to change an interface: deprecation, version-\ning, and extension. \u25a0Deprecation. Deprecation means removing an interface. Best practice when deprecat-\ning an interface is to give extensive notice to the actors of the element. This warning, \nin theory, allows the actors time to adjust to the interface\u2019s removal. In practice, many \nactors will not adjust in advance, but rather will discover the deprecation only when the \ninterface is removed. One technique when deprecating an interface is to introduce an \nerror code signifying that this interface is to be deprecated at (specific date) or that this \ninterface has been deprecated. \u25a0Versioning. Multiple interfaces support evolution by keeping the old interface and adding \na new one. The old one can be deprecated when it is no longer needed or the decision has \nbeen made to no longer support it. This requires the actor to specify which version of an \ninterface it is using. \u25a0Extension. Extending an interface means leaving the original interface unchanged and \nadding new resources to the interface that embody the desired changes. Figure 15.1(a) \nshows the original interface. If the extension does not contain any incompatibilities \nwith the original interface, then the element can implement the external interface \ndirectly, as shown in Figure 15.1(b). In contrast, if the extension introduces some incom-\npatibilities, then it is necessary to have an internal interface for the element and to add a \nmediator to translate between the external interface and the internal interface, as shown \nin Figure 15.1(c).", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 239", "position": 239, "chunk_type": "semantic", "token_estimate": 384}
{"text": "220 Part III Architectural Solutions | Chapter 15 Software Interfaces: If the extension does not contain any incompatibilities \nwith the original interface, then the element can implement the external interface \ndirectly, as shown in Figure 15.1(b). In contrast, if the extension introduces some incom-\npatibilities, then it is necessary to have an internal interface for the element and to add a \nmediator to translate between the external interface and the internal interface, as shown \nin Figure 15.1(c). As an example of an incompatibility, suppose the original interface \nassumed that apartment numbers were included in the address but the extended interface \nbroke out apartment numbers as a separate parameter. The internal interface would have \nthe apartment number as a separate parameter. Then the mediator, if invoked from the \noriginal interface, would parse the address to determine any apartment number, whereas \nthe mediator would pass the apartment number included in the separate parameter on \nto the internal interface unchanged.", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 239", "position": 239, "chunk_type": "semantic", "token_estimate": 157}
{"text": "15.1 Interface Concepts 221: Element\nActor 1\nActor N\nActor 1\nOriginal\ninterface\nActor N\nActor 1\nActor N\n(a)\nElement\nOriginal\ninterface\nInterface\nextension\nOriginal\ninterface\nInterface\nextension\nMediator that translates between external interfaces\nand internal interface\n(b)\n. . . . . . . . . . Element\nInternal interface\n(c)\nFIGURE 15.1 (a) The original interface. (b) Extending the interface. (c) Using an intermediary.", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 240", "position": 240, "chunk_type": "semantic", "token_estimate": 67}
{"text": "222 Part III Architectural Solutions | Chapter 15 Software Interfaces: 15.2  \nDesigning an Interface\nDecisions about which resources should be externally visible should be driven by the needs \nof actors that use the resources. Adding resources to an interface implies a commitment to \nmaintain those resources as part of the interface for as long as the element will be in use. Once \nactors start to depend on a resource you provide, their elements will break if the resource is \nchanged or removed. The reliability of your architecture is affected when the interface con-\ntract between elements is broken. Some additional design principles for interfaces are highlighted here:\n \n\u25a0Principle of least surprise. Interfaces should behave consistently with the actor\u2019s expec-\ntations. Names play a role here: An aptly named resource gives actors a good hint about \nwhat the resource can be used for. \u25a0Small interfaces principle. If two elements need to interact, have them exchange as little \ninformation as possible. \u25a0Uniform access principle. Avoid leaking implementation details through the interface. A resource should be accessible to its actors in the same way regardless of how they \nare implemented. An actor should be unaware, for example, whether a value is returned \nfrom a cache, from a computation, or from a fresh fetch of the value from some external \nsource. \u25a0Don\u2019t repeat yourself principle. Interfaces should offer a set of composable primitives as \nopposed to many redundant ways to achieve the same goal. Consistency is an important aspect of designing clear interfaces. As an architect, you \nshould establish and follow conventions on how resources are named, how API parameters are \nordered, and how errors should be handled. Of course, not all interfaces are under the control \nof the architect, but insofar as possible the design of interfaces should be consistent throughout \nall elements of the same architecture. Developers will also appreciate it if interfaces follow \nthe conventions of the underlying platform or the programming language idioms they expect. More than winning developers\u2019 goodwill, however, consistency will help minimize the num-\nber of development errors based on misunderstanding. A successful interaction with an interface requires agreement on the following aspects:\n1. Interface scope\n2. Interaction style\n3. Representation and structure of the exchanged data\n4. Error handling\nEach of these constitutes an important aspect of designing an interface. We\u2019ll cover each \nin turn.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 241", "position": 241, "chunk_type": "semantic", "token_estimate": 389}
{"text": "15.2 Designing an Interface 223: Actor 1\nActor N\nElement\nGateway\n. . . Resource\nInteraction\nKey\nInterface Scope\nThe scope of an interface defines the collection of resources directly available to the actors. You, as an interface designer, might want to reveal all resources; alternatively, you might wish \nto constrain the access to certain resources or to certain actors. For example, you might want to \nconstrain access for reasons of security, performance management, and extensibility. A common pattern for constraining and mediating access to resources of an element or \na group of elements is to establish a gateway element. A gateway\u2014often called a message \ngateway\u2014translates actor requests into requests to the target element\u2019s (or elements\u2019) resources, \nand so becomes an actor for the target element or elements. Figure 15.2 provides an example of \na gateway. Gateways are useful for the following reasons:\n \n\u25a0The granularity of resources provided by an element may be different than an actor \nneeds. A gateway can translate between elements and actors. \u25a0Actors may need access to, or be restricted to, specific subsets of the resources. \u25a0The specifics of the resources\u2014their number, protocol, type, location, and properties\u2014\nmay change over time, and the gateway can provide a more stable interface. FIGURE 15.2 A gateway that provides access to a variety of different resources\nWe now turn to the specifics of designing particular interfaces. This means deciding which \noperations, events, and properties it should feature. Additionally, you must choose suitable data \nrepresentation formats and data semantics to ensure the compatibility and interoperability of \nyour architectural elements with each other. Our opening quotation gives one example of the \nimportance of these decisions.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 242", "position": 242, "chunk_type": "semantic", "token_estimate": 274}
{"text": "224 Part III Architectural Solutions | Chapter 15 Software Interfaces: Interaction Styles\nInterfaces are meant to be connected together so that different elements can communicate \n(transfer data) and coordinate (transfer control). There are many ways for such interactions to \ntake place, depending on the mix between communication and coordination, and on whether \nthe elements will be co-located or remotely deployed. For example:\n \n\u25a0Interfaces of co-located elements may provide efficient access to large quantities of data \nvia local shared memory buffers. \u25a0Elements that are expected to be available at the same time can use synchronous calls to \ninvoke the operations they require. \u25a0Elements deployed in an unreliable distributed environment will need to rely on asyn-\nchronous interactions based on consuming and producing events, exchanged via message \nqueues or data streams. Many different interaction styles exist, but we will focus on two of the most widely used: \nRPC and REST. \u25a0Remote Procedure Call (RPC). RPC is modeled on procedure calls in imperative lan-\nguages, except that the called procedure is located elsewhere on a network. The pro-\ngrammer codes the procedure call as if a local procedure were being called (with some \nsyntactic variation); the call is then translated into a message sent to a remote element \nwhere the actual procedure is invoked. Finally, the results are sent back as a message to \nthe calling element. RPC dates from the 1980s and has undergone many modifications since its inception. The early versions of this protocol were synchronous, with the parameters of the mes-\nsage being sent as text. The most recent RPC version, called gRPC, transfers parameters \nin binary, is asynchronous, and supports authentication, bidirectional streaming and flow \ncontrol, blocking or nonblocking bindings, and cancellation and timeouts. gRPC uses \nHTTP 2.0 for transport. \u25a0Representational State Transfer (REST). REST is a protocol for web services. It grew \nout of the original protocol used when the World Wide Web was introduced. REST com-\nprises a set of six constraints imposed on the interactions between elements:\n \n\u25a0Uniform interface. All interactions use the same form (typically HTTP). Resources \non the providing side of the interface are specified via URIs (Uniform Resource \nIdentifiers). Naming conventions should be consistent and, in general, the principle of \nleast surprise should be followed. \u25a0Client-server. The actors are clients and the resource providers are servers using the \nclient-server pattern. \u25a0Stateless. All client-server interactions are stateless.", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 243", "position": 243, "chunk_type": "semantic", "token_estimate": 393}
{"text": "224 Part III Architectural Solutions | Chapter 15 Software Interfaces: \u25a0Stateless. All client-server interactions are stateless. That is, the client should not \nassume that the server has retained any information about the client\u2019s last request. In \nconsequence, interactions such as authorization are encoded into a token and the token \nis passed with each request. \u25a0Cacheable. Caching is applied to resources when applicable. Caching can be imple-\nmented on the server side or the client side.", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 243", "position": 243, "chunk_type": "semantic", "token_estimate": 75}
{"text": "15.2 Designing an Interface 225: \u25a0Tiered system architecture. The \u201cserver\u201d can be broken into multiple independent \nelements, which may be deployed independently. For example, the business logic and \nthe database can be deployed independently. \u25a0Code on demand (optional). It is possible for the server to provide code to the client to \nbe executed. JavaScript is an example. Although not the only protocol that can be used with REST, HTTP is the most common \nchoice. HTTP, which has been standardized by the World Wide Web Consortium (W3C), has \nthe basic form of <command><URI>. Other parameters can be included, but the heart of the \nprotocol is the command and the URI. Table 15.1 lists the five most important commands in \nHTTP and describes their relationship to the traditional CRUD (create, read, update, delete) \ndatabase operations. TABLE 15.1 Most Important Commands in HTTP and \nTheir Relationship to CRUD Database Operations\nHTTP Command\nCRUD Operation Equivalent\npost\ncreate\nget\nread\nput\nupdate/replace\npatch\nupdate/modify\ndelete\ndelete\nRepresentation and Structure of Exchanged Data\nEvery interface provides the opportunity to abstract the internal data representation, which is \ntypically built using programming language data types (e.g., objects, arrays, collections), into \na different one\u2014that is, a representation more suitable for being exchanged across different \nprogramming language implementations and sent across the network. Converting from the \ninternal to the external representation is termed \u201cserialization,\u201d \u201cmarshaling,\u201d or \u201ctranslation.\u201d\nIn the following discussion, we focus on the selection of a general-purpose data inter-\nchange format or representation for sending information over a network. This decision is based \non the following concerns:\n \n\u25a0Expressiveness. Can the representation serialize arbitrary data structures? Is it optimized \nfor trees of objects? Does it need to carry text written in different languages? \u25a0Interoperability. Does the representation used by the interface match what its actors \nexpect and know how to parse? A standard representation (such as JSON, described later \nin this section) will make it easy for actors to transform the bits transmitted across the \nnetwork into internal data structures. Does the interface implement a standard? \u25a0Performance. Does the chosen representation allow efficient usage of the available \ncommunication bandwidth? What is the algorithmic complexity of parsing the repre-\nsentation to read its content into the internal element representation? How much time is \nspent preparing the messages before they can be sent out? What is the monetary cost of \nthe required bandwidth?", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 244", "position": 244, "chunk_type": "semantic", "token_estimate": 393}
{"text": "226 Part III Architectural Solutions | Chapter 15 Software Interfaces: \u25a0Implicit coupling. What are the assumptions shared by the actors and elements that could \nlead to errors and data loss when decoding messages? \u25a0Transparency. Is it possible to intercept the exchanged messages and easily observe their \ncontent? This is a double-edged sword. On the one hand, if self-describing messages \nhelp developers more easily debug message payloads and eavesdroppers more readily \nintercept and interpret their content. On the other hand, binary representations, particu-\nlarly encrypted ones, require special debugging tools, but are more secure. The most common programming-language\u2013independent data representation styles can be \ndivided between textual (e.g., XML or JSON) and binary (e.g., protocol buffers) options. EXtensible Markup Language (XML)\nXML was standardized by the World Wide Web Consortium (W3C) in 1998. XML annota-\ntions to a textual document, called tags, are used to specify how to interpret the information in \nthe document by breaking the information into chunks or fields and identifying the data type \nof each field. Tags can be annotated with attributes. XML is a meta-language: Out of the box, it does nothing except allow you to define a \ncustomized language to describe your data. Your customized language is defined by an XML \nschema, which is itself an XML document that specifies the tags you will use, the data type \nthat should be used to interpret fields enclosed by each tag, and the constraints that apply to \nthe structure of your document. XML schemas enable you as an architect to specify a rich \ninformation structure. XML documents are used as representations of structured data for many purposes: for \nmessages exchanged in a distributed system (SOAP), the content of web pages (XHTML), vec-\ntor images (SVG), business documents (DOCX), web service interface description (WSDL), \nand static configuration files (e.g., MacOS property lists). One strength of XML is that a document annotated using this language can be checked \nto validate that it conforms to a schema. This prevents faults caused by malformed documents \nand eliminates the need for some kinds of error checking by the code that reads and processes \nthe document. The tradeoff is that parsing the document and validating it are relatively expen-\nsive in terms of processing and memory. A document must be read completely before it can \nbe validated and may require multiple read passes to unmarshal. This requirement, coupled \nwith XML\u2019s verbosity, can result in unacceptable runtime performance and bandwidth con-\nsumption.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 245", "position": 245, "chunk_type": "semantic", "token_estimate": 407}
{"text": "226 Part III Architectural Solutions | Chapter 15 Software Interfaces: A document must be read completely before it can \nbe validated and may require multiple read passes to unmarshal. This requirement, coupled \nwith XML\u2019s verbosity, can result in unacceptable runtime performance and bandwidth con-\nsumption. While during XML\u2019s heyday the argument was often made that \u201cXML is human \nreadable,\u201d today this benefit is cited far less often. JavaScript Object Notation (JSON)\nJSON structures data as nested name/value pairs and array data types. The JSON notation \ngrew out of the JavaScript language and was first standardized in 2013; today, however, it \nis independent of any programming language. Like XML, JSON is a textual representation \nfeaturing its own schema language. Compared to XML, however, JSON is significantly less \nverbose, as field names occur only once. Using a name/value representation instead of start \nand end tags, JSON documents can be parsed as they are read.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 245", "position": 245, "chunk_type": "semantic", "token_estimate": 152}
{"text": "15.2 Designing an Interface 227: JSON data types are derived from JavaScript data types, and resemble those of any mod-\nern programming language. This makes JSON serialization and deserialization much more \nefficient than XML. The notation\u2019s original use case was to send JavaScript objects between a \nbrowser and web server\u2014for example, to transfer a lightweight data representation to be ren-\ndered as HTML in the browser, as opposed to performing the rendering on the server side and \nhaving to download more verbose views represented using HTML. Protocol Buffers\nThe Protocol Buffer technology originated at Google and was used internally for several years \nbefore being released as open source in 2008. Like JSON, Protocol Buffers use data types \nthat are close to programming-language data types, making serialization and deserialization \nefficient. As with XML, Protocol Buffer messages have a schema that defines a valid struc-\nture, and that schema can specify both required and optional elements and nested elements. However, unlike both XML and JSON, Protocol Buffers are a binary format, so they are \nextremely compact and use memory and network bandwidth resources quite efficiently. In this \nrespect, Protocol Buffers harken back to a much earlier binary representation called Abstract \nSyntax Notation One (ASN.1), which originated in the early 1980s when network bandwidth \nwas a precious resource and no bit could be wasted. The Protocol Buffers open source project provides code generators to allow easy use of \nProtocol Buffers with many programming languages. You specify your message schema in a \nproto file, which is then compiled by a language-specific protocol buffer compiler. The pro-\ncedures generated by the compilers will be used by an actor to serialize and by an element to \ndeserialize the data. As when using XML and JSON, the interacting elements may be written in different lan-\nguages. Each element then uses the Protocol Buffer compiler specific to its language. Although \nProtocol Buffers can be used for any data-structuring purpose, they are mostly employed as \npart of the gRPC protocol. Protocol Buffers are specified using an interface description language. Since they are \ncompiled by language-specific compilers, the specification is necessary to ensure correct \nbehavior of the interface. It also acts as documentation for the interfaces. Placing the interface \nspecification in a database allows for searching it to see how values propagate through the \nvarious elements.", "domains": ["Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 246", "position": 246, "chunk_type": "semantic", "token_estimate": 386}
{"text": "15.2 Designing an Interface 227: It also acts as documentation for the interfaces. Placing the interface \nspecification in a database allows for searching it to see how values propagate through the \nvarious elements. Error Handling\nWhen designing an interface, architects naturally concentrate on how it is supposed to be used \nin the nominal case, when everything works according to plan. The real world, of course, is far \nfrom the nominal case, and a well-designed system must know how to take appropriate action \nin the face of undesired circumstances. What happens when an operation is called with invalid \nparameters? What happens when a resource requires more memory than is available? What \nhappens when a call to an operation never returns, because it has failed? What happens when \nthe interface is supposed to trigger a notification event based on the value of a sensor, but the \nsensor isn\u2019t responding or is responding with gibberish?", "domains": ["Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 246", "position": 246, "chunk_type": "semantic", "token_estimate": 152}
{"text": "228 Part III Architectural Solutions | Chapter 15 Software Interfaces: Actors need to know whether the element is working correctly, whether their interaction \nis successful and whether an error has occurred. Strategies to do so include the following:\n \n\u25a0Failed operations may throw an exception. \u25a0Operations may return a status indicator with predefined codes, which would need to be \ntested to detect erroneous outcomes. \u25a0Properties may be used to store data indicating whether the latest operation was success-\nful or not, or whether stateful elements are in an erroneous state. \u25a0Error events such as a timeout may be triggered for failed asynchronous interactions. \u25a0The error log may be read by connecting to a specific output data stream. The specification of which exceptions, which status codes, which events, and which \ninformation are used to describe erroneous outcomes becomes part of the interface of an ele-\nment. Common sources of errors (which the interface should handle gracefully) include the \nfollowing:\n \n\u25a0Incorrect, invalid, or illegal information was sent to the interface\u2014for example, calling \nan operation with a null value parameter that should not be null. Associating an error \ncondition with the resource is the prudent thing to do. \u25a0The element is in the wrong state for handling the request. The element may have \nentered the improper state as a result of a previous action or the lack of a previous action \non the part of the same or another actor. Examples of the latter include invoking an oper-\nation or reading a property before the element\u2019s initialization has completed, and writing \nto a storage device that has been taken offline by the system\u2019s human operator. \u25a0A hardware or software error occurred that prevented the element from successfully \nexecuting. Processor failures, failure of the network to respond, and inability to allocate \nmore memory are examples of this kind of error condition. \u25a0The element is not configured correctly. For example, its database connection string \nrefers to the wrong database server. Indicating the source of the error helps the system choose the appropriate correction and \nrecovery strategy. Temporary errors with idempotent operations can be dealt with by wait-\ning and retrying. Errors due to invalid input require fixing the bad requests and resending \nthem. Missing dependencies should be reinstalled before reattempting to use the interface. Implementation bugs should be fixed by adding the usage failure scenario as an additional test \ncase to avoid regressions.", "domains": ["Design Patterns", "Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 247", "position": 247, "chunk_type": "semantic", "token_estimate": 397}
{"text": "228 Part III Architectural Solutions | Chapter 15 Software Interfaces: Missing dependencies should be reinstalled before reattempting to use the interface. Implementation bugs should be fixed by adding the usage failure scenario as an additional test \ncase to avoid regressions. 15.3  \nDocumenting the Interface\nAlthough an interface comprises all aspects of the interaction that an element has with its \nenvironment, what we choose to disclose about an interface\u2014that is, what we put in an inter-\nface\u2019s documentation\u2014is more limited. Writing down every aspect of every possible interac-\ntion is not practical and almost never desirable. Rather, you should expose only what the actors", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 247", "position": 247, "chunk_type": "semantic", "token_estimate": 103}
{"text": "15.3 Documenting the Interface 229: on an interface need to know to interact with it. Put another way, you choose what information \nis permissible and appropriate for people to assume about the element. The interface documentation indicates what other developers need to know about an \ninterface to use it in combination with other elements. A developer might subsequently observe \nproperties that are a manifestation of how the element is implemented, but that are not detailed \nin the interface documentation. Because these are not part of the interface documentation, \nthey are subject to change, and developers use them at their own risk. Also recognize that different people need to know different kinds of information about \nthe interface. You may have to include separate sections in the interface documentation that \naccommodate different stakeholders of the interface. As you document an element\u2019s interface, \nkeep the following stakeholder roles in mind:\n \n\u25a0Developer of the element. Needs to be aware of the contract that their interface must \nfulfill. Developers can test only the information embodied in the interface description. \u25a0Maintainer. A special kind of developer who makes assigned changes to the element and \nits interface while minimizing disruption of existing actors. \u25a0Developer of an element using the interface. Needs to understand the interface\u2019s contract \nand how to use it. Such developers can provide input to the interface design and docu-\nmentation process in terms of use cases that the interface should support. \u25a0Systems integrator and tester. Puts the system together from its constituent elements and \nhas a strong interest in the behavior of the resulting assembly. This role needs detailed \ninformation about all the resources and functionality provided by and required by an \nelement. \u25a0Analyst. This role depends on the types of analyses conducted. For a performance ana-\nlyst, for example, the interface documentation should include a service level agreement \n(SLA) guarantee, so that actors can adjust their requests appropriately. \u25a0Architect looking for assets to reuse in a new system. Often starts by examining the inter-\nfaces of elements from a previous system. The architect may also look in the commercial \nmarketplace to find off-the-shelf elements that can be purchased and do the job. To see \nwhether an element is a candidate, the architect is interested in the capabilities of the inter-\nface resources, their quality attributes, and any variability that the element provides. Describing an element\u2019s interface means making statements about the element that other \nelements can depend on.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 248", "position": 248, "chunk_type": "semantic", "token_estimate": 405}
{"text": "15.3 Documenting the Interface 229: To see \nwhether an element is a candidate, the architect is interested in the capabilities of the inter-\nface resources, their quality attributes, and any variability that the element provides. Describing an element\u2019s interface means making statements about the element that other \nelements can depend on. Documenting an interface means that you have to describe which \nservices and properties are parts of the contract\u2014a step that represents a promise to actors that \nthe element will, indeed, fulfill this contract. Every implementation of the element that does \nnot violate the contract is a valid implementation. A distinction must be drawn between the interface of an element and the documentation \nof that interface. What you can observe about an element is part of its interface\u2014how long an \noperation takes, for example. The documentation of the interface covers a subset of that behav-\nior: It lays out what we want our actors to be able to depend on. \u201cHyrum\u2019s law\u201d (www.hyrumslaw.com) states: \u201cWith a sufficient number of users of an \ninterface, it does not matter what you promise in the contract: All observable behaviors of your \nsystem will be depended on by somebody.\u201d True enough. But, as we said earlier, an actor that \ndepends on what you do not publish about an element\u2019s interface does so at its own risk.", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 248", "position": 248, "chunk_type": "semantic", "token_estimate": 222}
{"text": "230 Part III Architectural Solutions | Chapter 15 Software Interfaces: 15.4  \nSummary\nArchitectural elements have interfaces, which are boundaries over which elements interact \nwith each other. Interface design is an architectural duty, because compatible interfaces allow \narchitectures with many elements to do something productive and useful together. A primary \nuse of an interface is to encapsulate an element\u2019s implementation, so that this implementation \nmay change without affecting other elements. Elements may have multiple interfaces, providing different types of access and privileges \nto different classes of actors. Interfaces state which resources the element provides to its actors \nas well as what the element needs from its environment to function correctly. Like architec-\ntures themselves, interfaces should be as simple as possible, but no simpler. Interfaces have operations, events, and properties; these are the parts of an interface that \nthe architect can design. To do so, the architect must decide the element\u2019s\n \n\u25a0Interface scope\n \n\u25a0Interaction style\n \n\u25a0Representation, structure, and semantics of the exchanged data\n \n\u25a0Error handling\nSome of these issues can be addressed by standardized means. For example, data \nexchange can use mechanisms such as XML, JSON, or Protocol Buffers. All software evolves, including interfaces. Three techniques that can be used to change \nan interface are deprecation, versioning, and extension. The interface documentation indicates what other developers need to know about an \ninterface to use it in combination with other elements. Documenting an interface involves \ndeciding which element operations, events, and properties to expose to the element\u2019s actors, \nand detailing the interface\u2019s syntax and semantics. 15.5  \nFor Further Reading\nTo see the difference between an XML representation, a JSON representation, and a Protocol \nBuffer representation of a postal address, see https://schema.org/PostalAddress, \nhttps://schema.org/PostalAddress, and https://github.com/mgravell/protobuf-net/blob/master/\nsrc/protogen.site/wwwroot/protoc/google/type/postal_address.proto. You can read more about gRPC at https://grpc.io/. REST was defined by Roy Fielding in his PhD thesis: ics.uci.edu/~fielding/pubs/\ndissertation/top.htm.", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 249", "position": 249, "chunk_type": "semantic", "token_estimate": 303}
{"text": "15.6 Discussion Questions 231: 15.6  \nDiscussion Questions\n1. Describe the interface to a dog, or another kind of animal with which you are familiar. Describe its operations, events, and properties. Does a dog have multiple interfaces (e.g., \none for a known human and another for a stranger)? 2. Document the interface to a light bulb. Document its operations, events, and properties. Document its performance and resource utilization. Document any error states it may \nenter and what the result will be. Can you think of multiple implementations that have \nthe same interface you just described? 3. Under what circumstances should performance (e.g., how long an operation takes) be a \npart of an element\u2019s published interface? Under what circumstances should it not? 4. Suppose an architectural element will be used in a high-availability system. How might \nthat affect its interface documentation? Suppose the same element will now be used in a \nhigh-security system. What might you document differently? 5. The section \u201cError Handling\u201d listed a number of different error-handling strategies. For each, when is its use appropriate? Inappropriate? What quality attributes will each \nenhance or diminish? 6. What would you have done to prevent the interface error that led to the loss of the Mars \nClimate Orbiter, as described at the beginning of this chapter? 7. On June 4, 1996, an Ariane 5 rocket failed quite spectacularly, only 37 seconds after \nlaunch. Research this failure, and discuss what better interface discipline could have \ndone to prevent it. 8. A database schema represents an interface between an element and a database; it pro-\nvides the metadata for accessing the database. Given this view, schema evolution is a \nform of interface evolution. Discuss ways in which a schema can evolve and not break \nthe existing interface, and ways in which it does break it. Describe how deprecation, \nversioning, and extension apply to schema evolution.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 250", "position": 250, "chunk_type": "semantic", "token_estimate": 310}
{"text": "234 Part III Architectural Solutions | Chapter 16 Virtualization: 16.1  \nShared Resources\nFor economic reasons, many organizations have adopted some forms of shared resources. These can dramatically lower the costs of deploying a system. There are four resources that we \ntypically care about sharing:\n1. Central processor unit (CPU). Modern computers have multiple CPUs (and each CPU \ncan have multiple processing cores). They may also have one or more graphics processing \nunits (GPUs), or other special-purpose processors, such as a tensor processing unit (TPU). 2. Memory. A physical computer has a fixed amount of physical memory. 3. Disk storage. Disks provide persistent storage for instructions and data, across reboots \nand shutdowns of the computer. A physical computer typically has one or more attached \ndisks, each with a fixed amount of storage capacity. Disk storage can refer to either a \nrotating magnetic or optical hard disk drive device, or a solid-state disk drive device; the \nlatter has neither disks nor any moving parts to drive. 4. Network connection. Today, every nontrivial physical computer has one or more network \nconnections through which all messages pass. Now that we have enumerated the resources that we want to share, we need to think about \nhow to share them, and how to do this in a sufficiently \u201cisolated\u201d way so that different applica-\ntions are unaware of each other\u2019s existence. Processor sharing is achieved through a thread-scheduling mechanism. The scheduler \nselects and assigns an execution thread to an available processor, and that thread maintains \ncontrol until the processor is rescheduled. No application thread can gain control of a proces-\nsor without going through the scheduler. Rescheduling occurs when the thread yields control \nof the processor, when a fixed time interval expires, or when an interrupt occurs. Historically, as applications grew, all the code and data would not fit into physical mem-\nory. Virtual memory technology was developed to deal with this challenge. Memory man-\nagement hardware partitions a process\u2019s address space into pages, and swaps pages between \nphysical memory and secondary storage as needed. The pages that are in physical memory can \nbe accessed immediately, and other pages are stored on the secondary memory until they are \nneeded. The hardware supports the isolation of one address space from another. Disk sharing and isolation are achieved using several mechanisms. First, the physical disks \ncan be accessed only through a disk controller that ensures the data streams to and from each \nthread are delivered in sequence.", "domains": ["Design Patterns", "Design Principles"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 253", "position": 253, "chunk_type": "semantic", "token_estimate": 409}
{"text": "Hosted Hypervisor: Operating System\nHost Computer\nOther\napplication\nOther\napplication\nFIGURE 16.2 Hosted hypervisor\nA hypervisor requires that its guest VMs use the same instruction set as the underly-\ning physical CPU\u2014the hypervisor does not translate or simulate instruction execution. For \nexample, if you have a VM for a mobile or embedded device that uses an ARM processor, you \ncannot run that virtual machine on a hypervisor that uses an x86 processor. Another technol-\nogy, related to hypervisors, supports cross-processor execution; it is called an emulator. An \nemulator reads the binary code for the target or guest processor and simulates the execution \nof guest instructions on the host processor. The emulator often also simulates guest I/O hard-\nware devices. For example, the open source QEMU emulator1 can emulate a full PC system, \nincluding BIOS, x86 processor and memory, sound card, graphics card, and even a floppy disk \ndrive. Hosted/Type 2 hypervisors and emulators allow a user to interact with the applications \nrunning inside the VM through the host machine\u2019s on-screen display, keyboard, and mouse/\ntouchpad. Developers working on desktop applications or working on specialized devices, \nsuch as mobile platforms or devices for the Internet of Things, may use a hosted/Type 2 hyper-\nvisor and/or an emulator as part of their build/test/integrate toolchain. A hypervisor performs two main functions: (1) It manages the code running in each VM, \nand (2) it manages the VMs themselves. To elaborate:\n1. Code that communicates outside the VM by accessing a virtualized disk or network \ninterface is intercepted by the hypervisor and executed by the hypervisor on behalf of \nthe VM. This allows the hypervisor to tag these external requests so that the response to \nthese requests can be routed to the correct VM. 1. qemu.org", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 255", "position": 255, "chunk_type": "semantic", "token_estimate": 291}
{"text": "16.2 Virtual Machines 237: The response to an external request to an I/O device or the network is an asynchro-\nnous interrupt. This interrupt is initially handled by the hypervisor. Since multiple VMs \nare operating on a single physical host machine and each VM may have I/O requests out-\nstanding, the hypervisor must have a method for forwarding the interrupt to the correct \nVM. This is the purpose of the tagging mentioned earlier. 2. VMs must be managed. For example, they must be created and destroyed, among other \nthings. Managing VMs is a function of the hypervisor. The hypervisor does not decide \non its own to create or destroy a VM, but rather acts on instructions from a user or, more \nfrequently, from a cloud infrastructure (you\u2019ll read more about this in Chapter 17). The \nprocess of creating a VM involves loading a VM image (discussed in the next section). In addition to creating and destroying VMs, the hypervisor monitors them. Health \nchecks and resource usage are part of the monitoring. The hypervisor is also located \ninside the defensive security perimeter of the VMs, as a defense against attacks. Finally, the hypervisor is responsible for ensuring that a VM does not exceed its \nresource utilization limits. Each VM has limits on CPU utilization, memory, and disk \nand network I/O bandwidth. Before starting a VM, the hypervisor first ensures that \nsufficient physical resources are available to satisfy that VM\u2019s needs, and then the hyper-\nvisor enforces those limits while the VM is running. A VM is booted just as a bare-metal physical machine is booted. When the machine begins \nexecuting, it automatically reads a special program called the boot loader from disk storage, \neither internal to the computer or connected through a network. The boot loader reads the oper-\nating system code from disk into memory, and then transfers execution to the operating system. In the case of a physical computer, the connection to the disk drive is made during the power-up \nprocess. In the case of the VM, the connection to the disk drive is established by the hypervisor \nwhen it starts the VM. The \u201cVM Images\u201d section discusses this process in more detail. From the perspective of the operating system and software services inside a VM, it \nappears as if the software is executing inside of a bare-metal physical machine. The VM pro-\nvides a CPU, memory, I/O devices, and a network connection.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 256", "position": 256, "chunk_type": "semantic", "token_estimate": 404}
{"text": "16.2 Virtual Machines 237: From the perspective of the operating system and software services inside a VM, it \nappears as if the software is executing inside of a bare-metal physical machine. The VM pro-\nvides a CPU, memory, I/O devices, and a network connection. Given the many concerns that it must address, the hypervisor is a complicated piece \nof software. One concern with VMs is the overhead introduced by the sharing and isolation \nneeded for virtualization. That is, how much slower does a service run on a virtual machine, \ncompared to running directly in a bare-metal physical machine? The answer to this question \nis complicated: It depends on the characteristics of the service and on the virtualization \ntechnology used. For example, services that perform more disk and network I/O incur more \noverhead than services that do not share these host resources. Virtualization technology is \nimproving all the time, but overheads of approximately 10% have been reported by Microsoft \non its Hyper-V hypervisor.2\nThere are two major implications of VMs for an architect:\n1. Performance. Virtualization incurs a performance cost. While Type 1 hypervisors carry \nonly a modest performance penalty, Type 2 hypervisors may impose a significantly \nlarger overhead. 2. https://docs.microsoft.com/en-us/biztalk/technical-guides/system-resource-costs-on-hyper-v", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 256", "position": 256, "chunk_type": "semantic", "token_estimate": 200}
{"text": "238 Part III Architectural Solutions | Chapter 16 Virtualization: 2. Separation of concerns. Virtualization allows an architect to treat runtime resources \nas commodities, deferring provisioning and deployment decisions to another person or \norganization. 16.3  \nVM Images\nWe call the contents of the disk storage that we boot a VM from a VM image. This image \ncontains the bits that represent the instructions and data that make up the software that we will \nrun (i.e., the operating system and services). The bits are organized into files and directories \naccording to the file system used by your operating system. The image also contains the boot \nload program, stored in its predetermined location. There are three approaches you can follow to create a new VM image:\n1. You can find a machine that is already running the software you want and make a snap-\nshot copy of the bits in that machine\u2019s memory. 2. You can start from an existing image and add additional software. 3. You can create an image from scratch. Here, you start by obtaining installation media for \nyour chosen operating system. You boot your new machine from the install media, and \nit formats the machine\u2019s disk drive, copies the operating system onto the drive, and adds \nthe boot loader in the predetermined location. For the first two approaches, repositories of machine images (usually containing open-\nsource software) are available that provide a variety of minimal images with just OS kernels, \nother images that include complete applications, and everything in between. These efficient \nstarting points can support you in quickly trying out a new package or program. However, some issues may arise when you are pulling down and running an image that \nyou (or your organization) did not create:\n \n\u25a0You cannot control the versions of the OS and software. \u25a0The image may have software that contains vulnerabilities or that is not configured \nsecurely; even worse, the image may include malware. Other important aspects of VM images are:\n \n\u25a0These images are very large, so transferring them over a network can be very slow. \u25a0An image is bundled with all of its dependencies. \u25a0You can build a VM image on your development computer and then deploy it to the \ncloud. \u25a0You may wish to add your own services to the VM. While you could easily install services when creating an image, this would lead to a \nunique image for every version of every service.", "domains": ["Design Principles", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 257", "position": 257, "chunk_type": "semantic", "token_estimate": 402}
{"text": "240 Part III Architectural Solutions | Chapter 16 Virtualization: VMs are allocated by locating a physical machine that has sufficient unused resources to \nsupport an additional VM. This is done, conceptually, by querying the hypervisors to find one \nwith spare capacity. Containers are allocated by finding a container runtime engine that has \nsufficient unused resources to support an additional container. This may, in turn, require the \ncreation of an additional VM to support an additional container runtime engine. Figure 16.3 \ndepicts containers running on a container runtime engine running on an operating system run-\nning in a VM under the control of a hypervisor. This sharing of the operating system represents a source of performance improvement \nwhen transferring images. As long as the target machine has a standard container runtime \nengine running on it (and these days all container runtime engines are built to standards), there \nis no need to transfer the operating system as part of the container image. The second source of performance improvement is the use of \u201clayers\u201d in the container \nimages. (Note that container layers are different from the notion of layers in module structures \nthat we introduced in Chapter 1.) To better understand container layers, we will describe how \na container image is constructed. In this case, we will illustrate the construction of a container \nto run the LAMP stack, and we will build the image in layers. (LAMP\u2014which stands for \nLinux, Apache, MySQL, and PHP\u2014is a widely used stack for constructing web applications.) The process of building an image using the LAMP stack is as follows:\n1. Create a container image containing a Linux distribution. (This image can be down-\nloaded from a library using a container management system.) 2. Once you create the image and identify it as an image, execute it (i.e., instantiate it). 3. Use that container to load services\u2014Apache, in our example, using features of Linux. 4. Exit the container and inform the container management system that this is a second \nimage. 5. Execute this second image and load MySQL. 6. Exit the container and give this third image a name. 7. Repeat this process one more time and load PHP. Now you have a fourth container \nimage; this one holds the entire LAMP stack.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 259", "position": 259, "chunk_type": "semantic", "token_estimate": 375}
{"text": "240 Part III Architectural Solutions | Chapter 16 Virtualization: Repeat this process one more time and load PHP. Now you have a fourth container \nimage; this one holds the entire LAMP stack. Because this image was created in steps and you told the container management system to \nmake each step an image, the container management system considers the final image to be \nmade up of \u201clayers.\u201d\nNow you can move the LAMP stack container image to a different location for produc-\ntion use. The initial move requires moving all the elements of the stack. Suppose, however, \nyou update PHP to a newer version and move this revised stack into production (Step 7 in the \npreceding process). The container management system knows that only PHP was revised and \nmoves only the PHP layer of the image. This saves the effort involved in moving the rest of the \nstack. Since changing a software component within an image happens much more frequently \nthan initial image creation, placing a new version of the container into production becomes a \nmuch faster process than it would be using a VM. Whereas loading a VM takes on the order \nof minutes, loading a new version of a container takes on the order of microseconds or milli-\nseconds. Note that this process works only with the uppermost layer of the stack. If, for exam-\nple, you wanted to update MySQL with a newer version, you would need to execute Steps 5 \nthrough 7 in the earlier list.", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 259", "position": 259, "chunk_type": "semantic", "token_estimate": 249}
{"text": "16.5 Containers and VMs 241: You can create a script with the steps for the creation of a container image and store it \nin a file. This file is specific to the tool you are using to create the container image. Such a \nfile allows you to specify which pieces of software are to be loaded into the container and \nsaved as an image. Using version control on the specification file ensures that each member of \nyour team can create an identical container image and modify the specification file as needed. Treating these scripts as code brings a wealth of advantages: These scripts can be consciously \ndesigned, tested, configuration controlled, reviewed, documented, and shared. 16.5  \nContainers and VMs\nWhat are the tradeoffs between delivering your service in a VM and delivering your service in \na container? As we noted earlier, a VM virtualizes the physical hardware: CPU, disk, memory, and \nnetwork. The software that you run on the VM includes an entire operating system, and you \ncan run almost any operating system in a VM. You can also run almost any program in a VM \n(unless it must interact directly with the physical hardware), which is important when working \nwith legacy or purchased software. Having the entire operating system also allows you to run \nmultiple services in the same VM\u2014a desirable outcome when the services are tightly coupled \nor share large data sets, or if you want to take advantage of the efficient interservice commu-\nnication and coordination that are available when the services run within the context of the \nsame VM. The hypervisor ensures that the operating system starts, monitors its execution, and \nrestarts the operating system if it crashes. Container instances share an operating system. The operating system must be compatible \nwith the container runtime engine, which limits the software that can run on a container. The \ncontainer runtime engine starts, monitors, and restarts the service running in a container. This \nengine typically starts and monitors just one program in a container instance. If that one pro-\ngram completes and exits normally, execution of that container ends. For this reason, contain-\ners generally run a single service (although that service can be multi-threaded). Furthermore, \none benefit of using containers is that the size of the container image is small, including only \nthose programs and libraries necessary to support the service we want to run.", "domains": ["Domain-Driven Design"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 260", "position": 260, "chunk_type": "semantic", "token_estimate": 396}
{"text": "242 Part III Architectural Solutions | Chapter 16 Virtualization: \u25a0VMs persist beyond the termination of services running within them; containers \ndo not. \u25a0Some restrictions on port usage exist when using containers that do not exist when \nusing VMs. 16.6  \nContainer Portability\nWe have introduced the concept of a container runtime manager with which the container \ninteracts. Several vendors provide container runtime engines, most notably Docker, containerd, \nand Mesos. Each of these providers has a container runtime engine that provides capabili-\nties to create container images and to allocate and execute container instances. The interface \nbetween the container runtime engine and the container has been standardized by the Open \nContainer Initiative, allowing a container created by one vendor\u2019s package (say, Docker) to be \nexecuted on a container runtime engine provided by another vendor (say, containerd). This means that you can develop a container on your development computer, deploy it to \na production computer, and have it execute there. Of course, the resources available will be \ndifferent in each case, so deployment is still not trivial. If you specify all the resources as con-\nfiguration parameters, the movement of your container into production is simplified. 16.7  \nPods\nKubernetes is open source orchestration software for deploying, managing, and scaling con-\ntainers. It has one more element in its hierarchy: Pods. A Pod is a group of related containers. In Kubernetes, nodes (hardware or VMs) contain Pods, and Pods contain containers, as shown \nin Figure 16.4. The containers in a Pod share an IP address and port space to receive requests \nfrom other services. They can communicate with each other using interprocess communica-\ntion (IPC) mechanisms such as semaphores or shared memory, and they can share ephemeral \nstorage volumes that exist for the lifetime of the Pod. They have the same lifetime\u2014the con-\ntainers in Pods are allocated and deallocated together. For example, service meshes, discussed \nin Chapter 9, are often packaged as a Pod. The purpose of a Pod is to reduce communication costs between closely related contain-\ners. In Figure 16.4, if container 1 and container 2 communicate frequently, the fact they are \ndeployed as a Pod, and thus allocated onto the same VM, allows the use of faster communica-\ntion mechanisms than message passing.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 261", "position": 261, "chunk_type": "semantic", "token_estimate": 373}
{"text": "244 Part III Architectural Solutions | Chapter 16 Virtualization: A consequence of the dynamic allocation and deallocation in response to individual \nrequests is that these short-lived containers cannot maintain any state: The containers must be \nstateless. In a serverless architecture, any state needed for coordination must be stored in an \ninfrastructure service delivered by the cloud provider or passed as parameters. Cloud providers impose some practical limitations on FaaS features. The first is that the \nproviders have a limited selection of base container images, which restricts your program-\nming language options and library dependencies. This is done to reduce the container load \ntime\u2014your service is constrained to be a thin image layer on top of the provider\u2019s base image \nlayer. The next limitation is that the \u201ccold start\u201d time, when your container is allocated and \nloaded the first time, can be several seconds. Subsequent requests are handled nearly instanta-\nneously, as your container image is cached on a node. Finally, the execution time for a request \nis limited\u2014your service must process the request and exit within the provider\u2019s time limit or \nit will be terminated. Cloud providers do this for economic reasons, so that they can tailor the \npricing of FaaS compared to other ways of running containers, and to ensure that no FaaS user \nconsumes too much of the resource pool. Some designers of serverless systems devote con-\nsiderable energy to working around or defeating these limitations\u2014for example, prestarting \nservices to avoid cold-start latency, making dummy requests to keep services in cache, and \nforking or chaining requests from one service to another to extend the effective execution time. 16.9  \nSummary\nVirtualization has been a boon for software and system architects, as it provides efficient, \ncost-effective allocation platforms for networked (typically web-based) services. Hardware \nvirtualization allows for the creation of several virtual machines that share the same physical \nmachine. It does this while enforcing isolation of the CPU, memory, disk storage, and network. Consequently, the resources of the physical machine can be shared among several VMs, while \nthe number of physical machines that an organization must purchase or rent is minimized. A VM image is the set of bits that are loaded into a VM to enable its execution. VM \nimages can be created by various techniques for provisioning, including using operating sys-\ntem functions or loading a pre-created image. Containers are a packaging mechanism that virtualizes the operating system.", "domains": ["Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 263", "position": 263, "chunk_type": "semantic", "token_estimate": 400}
{"text": "244 Part III Architectural Solutions | Chapter 16 Virtualization: VM \nimages can be created by various techniques for provisioning, including using operating sys-\ntem functions or loading a pre-created image. Containers are a packaging mechanism that virtualizes the operating system. A container \ncan be moved from one environment to another if a compatible container runtime engine is \navailable. The interface to container runtime engines has been standardized. Placing several containers into a Pod means that they are all allocated together and any \ncommunication between the containers can be done quickly. Serverless architecture allows for containers to be rapidly instantiated and moves the \nresponsibility for allocation and deallocation to the cloud provider infrastructure.", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 263", "position": 263, "chunk_type": "semantic", "token_estimate": 112}
{"text": "16.11 Discussion Questions 245: 16.10  \nFor Further Reading\nThe material in this chapter is taken from Deployment and Operations for Software Engineers \n[Bass 19], where you can find more detailed discussions. Wikipedia is always a good place to find current details of protocols, container runtime \nengines, and serverless architectures. 16.11  \nDiscussion Questions\n1. Create a LAMP container using Docker. Compare the size of your container image to \none you find on the Internet. What is the source of the difference? Under what circum-\nstances is this a cause of concern for you as an architect? 2. How does the container management system know that only one layer has been changed \nso that it needs to transport only one layer? 3. We have focused on isolation among VMs that are running at the same time on a \nhypervisor. VMs may shut down and stop executing, and new VMs may start up. What \ndoes a hypervisor do to maintain isolation, or prevent leakage, between VMs running at \ndifferent times? Hint: Think about the management of memory, disk, virtual MAC, and \nIP addresses. 4. What set of services would it make sense to group into a Pod (as was done with service \nmeshes) and why? 5. What are the security issues associated with containers? How would you mitigate them? 6. What are the concerns associated with employing virtualization technologies in embed-\nded systems? 7. What class of integration and deployment errors can be avoided with VMs, containers, \nand Pods? What class cannot?", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 264", "position": 264, "chunk_type": "semantic", "token_estimate": 249}
{"text": "247: 17\n \nThe Cloud and Distributed \nComputing\nA distributed system is one in which the failure of a computer you \ndidn\u2019t even know existed can render your own computer unusable. \u2014Leslie Lamport\nCloud computing is about the on-demand availability of resources. This term is used to refer \nto a wide range of computing capabilities. For example, you might say, \u201cAll my photos are \nbacked up to the cloud.\u201d But what does that mean? It means:\n \n\u25a0My photos are stored on someone else\u2019s computers. They worry about the capital invest-\nment and maintenance and upkeep and backups. \u25a0My photos are accessible by me over the Internet. \u25a0I pay only for the space that I use, or that I requisition. \u25a0The storage service is elastic, meaning that it can grow or shrink as my needs change. \u25a0My use of the cloud is self-provisioned: I create an account and can immediately begin \nusing it to store my materials. The computing capabilities delivered from the cloud range from applications such as \nphoto (or other kinds of digital artifact) storage, to fine-grained services exposed through \nAPIs (e.g., text translation or currency conversion), to low-level infrastructure services such as \nprocessors, network, and storage virtualization. In this chapter, we will focus on how a software architect can use infrastructure services \nfrom the cloud to deliver the services that the architect is designing and developing. Along \nthe way, we will take a journey into some of the most important principles and techniques of \ndistributed computing. This means using multiple (real or virtual) computers to work cooper-\natively together, thereby producing faster performance and a more robust system than a single \ncomputer doing all the work. We included this subject matter in this chapter because nowhere \nis distributed computing more ingrained than in cloud-based systems. The treatment we give \nhere is a brief overview of the principles most relevant to architecture. We first discuss how the cloud provides and manages virtual machines.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 266", "position": 266, "chunk_type": "semantic", "token_estimate": 323}
{"text": "248 Part III Architectural Solutions | Chapter 17 The Cloud and Distributed Computing: 17.1  \nCloud Basics\nPublic clouds are owned and provided by cloud service providers. These organizations pro-\nvide infrastructure services to anyone who agrees to the terms of service and can pay for use \nof the services. In general, the services you build using this infrastructure are accessible on the \npublic Internet, although you can provision mechanisms such as firewalls to restrict visibility \nand access. Some organizations operate a private cloud. A private cloud is owned and operated by \nan organization for the use of members of that organization. An organization might choose to \noperate a private cloud because of concerns such as control, security, and cost. In this case, the \ncloud infrastructure and the services developed on it are visible and accessible only within \nthe organization\u2019s network. The hybrid cloud approach is a mixed model, in which some workloads are run in a pri-\nvate cloud and other workloads are run in a public cloud. A hybrid cloud might be used during \na migration from a private cloud to a public cloud (or vice versa), or it might be used because \nsome data are legally required to be subject to greater control and scrutiny than is possible \nwith a public cloud. For an architect designing software using cloud services, there is not much difference, \nfrom a technical perspective, between private clouds and public clouds. Thus we will focus our \ndiscussion here on infrastructure-as-a-service public clouds. A typical public cloud data center has tens of thousands of physical devices\u2014closer to \n100,000 than to 50,000. The limiting factor on the size of a data center is the electric power \nit consumes and the amount of heat that the equipment produces: There are practical limits \nto bringing electrical power into the buildings, distributing it to the equipment, and removing \nthe heat that the equipment generates. Figure 17.1 shows a typical cloud data center. Each \nrack consists of more than 25 computers (each with multiple CPUs), with the exact number \ndepending on the power and cooling available. The data center consists of rows and rows of \nsuch racks, with high-speed network switches connecting the racks. Cloud data centers are one \nreason why energy efficiency (a topic discussed in Chapter 6) has become a critical quality \nattribute in some applications. When you access a cloud via a public cloud provider, you are actually accessing data \ncenters scattered around the globe.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 267", "position": 267, "chunk_type": "semantic", "token_estimate": 408}
{"text": "248 Part III Architectural Solutions | Chapter 17 The Cloud and Distributed Computing: Cloud data centers are one \nreason why energy efficiency (a topic discussed in Chapter 6) has become a critical quality \nattribute in some applications. When you access a cloud via a public cloud provider, you are actually accessing data \ncenters scattered around the globe. The cloud provider organizes its data centers into regions. A cloud region is both a logical and a physical construct. Since the services you develop and \ndeploy to the cloud are accessed over the Internet, cloud regions can help you be sure that the \nservice is physically close to its users, thereby reducing the network delay to access the service. Also, some regulatory constraints, such as the General Data Protection Regulation (GDPR), \nmay restrict the transmission of certain types of data across national borders, so cloud regions \nhelp cloud providers comply with these regulations. A cloud region has many data centers that are physically distributed and have different \nsources for electrical power and Internet connectivity. The data centers within a region are \ngrouped into availability zones, such that the probability of all data centers in two different \navailability zones failing at the same time is extremely low.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 267", "position": 267, "chunk_type": "semantic", "token_estimate": 204}
{"text": "17.1 Cloud Basics 249: FIGURE 17.1 A cloud data center\nChoosing the cloud region that your service will run on is an important design decision. When you ask to be provided with a new virtual machine (VM) that runs in the cloud, you \nmay specify which region the VM will run on. Sometimes the availability zone may be chosen \nautomatically, but you often will want to choose the zone yourself, for availability and busi-\nness continuity reasons. All access to a public cloud occurs over the Internet. There are two main gateways into a \ncloud: a management gateway and a message gateway (Figure 17.2). Here we will focus on the \nmanagement gateway; we discussed message gateways in Chapter 15. Suppose you wish to have a VM allocated for you in the cloud. You send a request to the \nmanagement gateway asking for a new VM instance. This request has many parameters, but \nthree essential parameters are the cloud region where the new instance will run, the instance \ntype (e.g., CPU and memory size), and the ID of a VM image. The management gateway is \nresponsible for tens of thousands of physical computers, and each physical computer has a \nhypervisor that manages the VMs on it. So, the management gateway will identify a hyper-\nvisor that can manage an additional VM of the type you have selected by asking, Is there \nenough unallocated CPU and memory capacity available on that physical machine to meet", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 268", "position": 268, "chunk_type": "semantic", "token_estimate": 243}
{"text": "250: Part III Architectural Solutions | Chapter 17 The Cloud and Distributed Computing\nyour needs? If so, it will ask that hypervisor to create an additional VM; the hypervisor will \nperform this task and return the new VM\u2019s IP address to the management gateway. The man-\nagement gateway then sends that IP address to you. The cloud provider ensures that enough \nphysical hardware resources are available in its data centers so that your request will never fail \ndue to insufficient resources. The management gateway returns not only the IP address for the newly allocated VM, \nbut also a hostname. The hostname returned after allocating a VM reflects the fact that the \nIP address has been added to the cloud Domain Name System (DNS). Any VM image can be \nused to create the new VM instance; that is, the VM image may comprise a simple service or \nbe just one step in the deployment process to create a complex system. The management gateway performs other functions in addition to allocating new VMs. It \nsupports collecting billing information about the VM, and it provides the capability to monitor \nand destroy the VM. The management gateway is accessed through messages over the Internet to its API. These messages can come from another service, such as a deployment service, or they can \nbe generated from a command-line program on your computer (allowing you to script opera-\ntions). The management gateway can also be accessed through a web-based application oper-\nated by the cloud service provider, although this kind of interactive interface is not efficient for \nmore than the most trivial operations. Management\ngateway\nManagement UI\nClient\nMessage\ngateway\nFIGURE 17.2 Gateways into a public cloud", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 269", "position": 269, "chunk_type": "semantic", "token_estimate": 281}
{"text": "17.2 Failure in the Cloud 251: 17.2  \nFailure in the Cloud\nWhen a data center contains tens of thousands of physical computers, it is almost a certainty \nthat one or more will fail every day. Amazon reports that in a data center with around 64,000 \ncomputers, each with two spinning disk drives, approximately 5 computers and 17 disks will \nfail every day. Google reports similar statistics. In addition to computer and disk failures, net-\nwork switches can fail; the data center can overheat, causing all the computers to fail; or some \nnatural disaster may bring the entire data center down. Although your cloud provider will have \nrelatively few total outages, the physical computer on which your specific VM is running may \nfail. If availability is important to your service, you need to think carefully about what level of \navailability you wish to achieve and how to achieve it. We\u2019ll discuss two concepts especially relevant to failure in the cloud: timeouts and long \ntail latency. Timeouts\n Recall from Chapter 4 that timeout is a tactic for availability. In a distributed system, timeouts \nare used to detect failure. There are several consequences of using timeouts:\n \n\u25a0Timeouts can\u2019t distinguish between a failed computer or broken network connection and \na slow reply to a message that exceeds the timeout period. This will cause you to label \nsome slow responses as failures. \u25a0A timeout will not tell you where the failure or slowness occurs. \u25a0Many times, a request to a service triggers that service to make requests to other services, \nwhich make more requests. Even if each of the responses in this chain has a latency that \nis close to (but slower than) the expected average response time, the overall latency may \n(falsely) suggest a failure. A timeout\u2014a decision that a response has taken too long\u2014is commonly used to detect \na failure. A timeout cannot isolate whether the failure is due to a failure in the software of the \nrequested service, the virtual or physical machine that the service is running on, or the net-\nwork connection to the service. In most cases, the cause is not important: You made a request, \nor you were expecting a periodic keep-alive or heartbeat message, and did not receive a timely \nresponse, and now you need to take action to remedy this. This seems simple, but in real systems it can be complicated.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 270", "position": 270, "chunk_type": "semantic", "token_estimate": 395}
{"text": "252 Part III Architectural Solutions | Chapter 17 The Cloud and Distributed Computing: These are the measurements in the \nlong tail on the right side of the histogram. Long tail latencies are a result of congestion or failure somewhere in the path of the \nservice request. Many factors may contribute to congestion\u2014server queues, hypervisor sched-\nuling, or others\u2014but the cause of the congestion is out of your control as a service developer. Your monitoring techniques and your strategies to achieve your required performance and \navailability must reflect the reality of a long tail distribution. Two techniques to handle long tail problems are hedged requests and alternative requests. \u25a0Hedged requests. Make more requests than are needed and then cancel the requests (or \nignore responses) after sufficient responses have been received. For example, suppose \n10 instances of a microservice (see Chapter 5) are to be launched. Issue 11 requests and \nafter 10 have completed, terminate the request that has not responded yet. \u25a0Alternative requests. A variant of the hedged request technique is called alternative \nrequest. In the just-described scenario, issue 10 requests. When 8 requests have com-\npleted, issue 2 more, and when a total of 10 responses have been received, cancel the \n2 requests that are still remaining.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 271", "position": 271, "chunk_type": "semantic", "token_estimate": 207}
{"text": "17.3 Using Multiple Instances to Improve Performance and Availability 253: 0\n0.0%\n2.0%\n4.0%\n6.0%\n8.0%\n10.0%\n12.0%\n14.0%\n16.0%\n20\n40\n60\n80\n100\nReturn Time (s)\n120\n140\n160\n180\n200\n220\nFIGURE 17.3 Long tail distribution of 1,000 \u201claunch instance\u201d requests to AWS\n17.3  \nUsing Multiple Instances to Improve Performance and \nAvailability\nIf a service hosted in a cloud receives more requests than it can process within the required \nlatency, the service becomes overloaded. This can occur because there is an insufficient I/O \nbandwidth, CPU cycles, memory, or some other resource. In some cases, you can resolve a ser-\nvice overload issue by running the service in a different instance type that provides more of the \nresource that is needed. This approach is simple: The design of the service does not change; \ninstead, the service just runs on a larger virtual machine. Called vertical scaling or scaling up, \nthis approach corresponds to the increased resources performance tactic from Chapter 9. There are limits to what can be achieved with vertical scaling. In particular, there may \nnot be a large enough VM instance type to support the workload. In this case, horizontal\nscaling or scaling out provides more resources of the type needed. Horizontal scaling involves \nhaving multiple copies of the same service and using a load balancer to distribute requests \namong them\u2014equivalent to the maintain multiple copies of computations tactic and the load \nbalancer pattern, respectively, from Chapter 9. Distributed Computing and Load Balancers\nLoad balancers can be standalone systems, or they can bundled with other functions. A load \nbalancer must be very efficient because it sits in the path of every message from a client to a", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 272", "position": 272, "chunk_type": "semantic", "token_estimate": 281}
{"text": "254 Part III Architectural Solutions | Chapter 17 The Cloud and Distributed Computing: service, and even when it is packaged with other functions, it is logically isolated. Here, we \ndivide our discussion into two main aspects: how load balancers work and how services that \nsit behind a load balancer must be designed to manage the service state. Once we understand \nthese processes, we can explore the management of the system\u2019s health and how load balancers \ncan improve its availability. A load balancer solves the following problem: There is a single instance of a service \nrunning on a VM or in a container, and too many requests are arriving at this instance for it \nto provide acceptable latency. One solution is to have multiple instances of the service and \ndistribute the requests among them. The distribution mechanism in such a case is a separate \nservice\u2014the load balancer. Figure 17.4 shows a load balancer distributing requests between \ntwo VM (service) instances. The same discussion would apply if there were two container \ninstances. (Containers were discussed in Chapter 16.) Clients\nLoad\nbalancer\nService instances\nFIGURE 17.4 A load balancer distributing requests from two clients to two service instances\nYou may be wondering what constitutes \u201ctoo many requests\u201d and \u201creasonable response \ntime.\u201d We\u2019ll come back to these questions later in this chapter when we discuss autoscaling. For now, let\u2019s focus on how a load balancer works. In Figure 17.4, each request is sent to a load balancer. For the purposes of our discussion, \nsuppose the load balancer sends the first request to instance 1, the second request to instanceb2, \nthe third request back to instance 1, and so forth. This sends half of the requests to each \ninstance, balancing the load between the two instances\u2014hence the name.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 273", "position": 273, "chunk_type": "semantic", "token_estimate": 293}
{"text": "17.3 Using Multiple Instances to Improve Performance and Availability 255: Some observations about this simple example of a load balancer:\n \n\u25a0The algorithm we provided\u2014alternate the messages between the two instances\u2014is \ncalled \u201cround-robin.\u201d This algorithm balances the load uniformly across the service \ninstances only if every request consumes roughly the same resources in its response. Other algorithms for distributing the messages exist for cases where the resource con-\nsumption needed to process requests varies. \u25a0From a client\u2019s perspective, the service\u2019s IP address is actually the address of the load \nbalancer. This address may be associated with a hostname in the DNS. The client does not \nknow, or need to know, how many instances of the service exist or the IP address of any \nof those service instances. This makes the client resilient to changing this information\u2014\nan example of using an intermediary, as discussed in Chapter 8. \u25a0Multiple clients may coexist. Each client sends its messages to the load balancer, which \ndoes not care about the message source. The load balancer distributes the messages as \nthey arrive. (We\u2019ll ignore the concept called \u201csticky sessions\u201d or \u201csession affinity\u201d for \nthe moment.) \u25a0Load balancers may get overloaded. In this case, the solution is to balance the load of the \nload balancer, sometimes referred to as global load balancing. That is, a message goes \nthrough a hierarchy of load balancers before arriving at the service instance. So far, our discussion of load balancers has focused on increasing the amount of work \nthat can be handled. Here, we will consider how load balancers also serve to increase the \navailability of services. Figure 17.4 shows messages from clients passing through the load balancer, but does not \nshow the return messages. Return messages go directly from the service instances to the cli-\nents (determined by the \u201cfrom\u201d field in the IP message header), bypassing the load balancer. As a consequence, the load balancer has no information about whether a message was pro-\ncessed by a service instance, or how long it took to process a message. Without additional \nmechanisms, the load balancer would not know whether any service instance was alive and \nprocessing, or if any instance or all instances had failed. Health checks are a mechanism that allow the load balancer to determine whether an \ninstance is performing properly. This is the purpose of the \u201cfault detection\u201d category of \navailability tactics from Chapter 4.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 274", "position": 274, "chunk_type": "semantic", "token_estimate": 398}
{"text": "17.3 Using Multiple Instances to Improve Performance and Availability 255: Health checks are a mechanism that allow the load balancer to determine whether an \ninstance is performing properly. This is the purpose of the \u201cfault detection\u201d category of \navailability tactics from Chapter 4. The load balancer will periodically check the health \nof the instances assigned to it. If an instance fails to respond to a health check, it is marked \nas unhealthy and no further messages are sent to it. Health checks can consist of pings from \nthe load balancer to the instance, opening a TCP connection to the instance or even sending \na message for processing. In the latter case, the return IP address is the address of the load \nbalancer. It is possible for an instance to move from healthy to unhealthy, and back again. Suppose, \nfor example, that the instance has an overloaded queue. When initially contacted, it may not \nrespond to the load balancer\u2019s health check, but once the queue has been drained, it may \nbe ready to respond again. For this reason, the load balancer checks multiple times before \nmoving an instance to an unhealthy list, and then periodically checks the unhealthy list to \ndetermine whether an instance is again responding. In other cases, a hard failure or crash may \ncause the failed instance to restart and re-register with the load balancer, or a new replacement", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 274", "position": 274, "chunk_type": "semantic", "token_estimate": 231}
{"text": "256 Part III Architectural Solutions | Chapter 17 The Cloud and Distributed Computing: instance may be started and registered with the load balancer, so as to maintain overall service \ndelivery capacity. A load balancer with health checking improves availability by hiding the failure of a ser-\nvice instance from clients. The pool of service instances can be sized to accommodate some \nnumber of simultaneous service instance failures while still providing enough overall service \ncapacity to handle the required volume of client requests within the desired latency. However, \neven when using health checking, a service instance might sometimes start processing a client \nrequest but never return a response. Clients must be designed so that they resend a request if \nthey do not receive a timely response, allowing the load balancer to distribute the request to a \ndifferent service instance. Services must correspondingly be designed such that multiple iden-\ntical requests can be accommodated. State Management in Distributed Systems\nState refers to information internal to a service that affects the computation of a response to a \nclient request. State\u2014or, more precisely, the collection of the values of the variables or data \nstructures that store the state\u2014depends on the history of requests to the service. Management of state becomes important when a service can process more than one client \nrequest at the same time, either because a service instance is multi-threaded, because there are \nmultiple service instances behind a load balancer, or both. The key issue is where the state is \nstored. The three options are:\n1. The history maintained in each service instance, in which case the services are described \nas \u201cstateful.\u201d\n2. The history maintained in each client, in which case the services are described as \n\u201cstateless.\u201d\n3. The history persists outside the services and clients, in a database, in which case the \nservices are described as \u201cstateless.\u201d\nCommon practice is to design and implement services to be stateless. Stateful services \nlose their history if they fail, and recovering that state can be difficult. Also, as we will see in \nthe next section, new service instances may be created, and designing services to be stateless \nallows a new service instance to process a client request and produce the same response as any \nother service instance. In some cases, it may be difficult or inefficient to design a service to be stateless, so we \nmight want a series of messages from a client to be processed by the same service instance.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 275", "position": 275, "chunk_type": "semantic", "token_estimate": 409}
{"text": "17.3 Using Multiple Instances to Improve Performance and Availability 257: Frequently, there is a need to share information across all instances of a service. This \ninformation may consist of state information, as discussed earlier, or it may be other infor-\nmation that is needed for the service instances to work together efficiently\u2014for example, the \nIP address of the load balancer for the service. A solution exists to manage relatively small \namounts of information shared among all instances of a service, as discussed next. Time Coordination in a Distributed System\nDetermining exactly what time it is might seem to be a trivial task, but it is actually not easy. Hardware clocks found in computers will gain or lose one second about every 12 days. If your \ncomputing device is out in the world, so to speak, it may have access to a time signal from a \nGlobal Positioning System (GPS) satellite, which provides a time accurate to within 100 nano-\nseconds or less. Having two or more devices agree on what time it is can be even more challenging. The \nclock readings from two different devices on a network will be different. The Network Time \nProtocol (NTP) is used to synchronize time across different devices that are connected over a \nlocal or wide area network. It involves exchanging messages between a time server and client \ndevices to estimate the network latency, and then applying algorithms to synchronize a client \ndevice\u2019s clock to the time server. NTP is accurate to around 1 millisecond on local area net-\nworks and around 10 milliseconds on public networks. Congestion can cause errors of 100 \nmilliseconds or more. Cloud service providers provide very precise time references for their time servers. For \nexample, Amazon and Google use atomic clocks, which have virtually unmeasurable drift. Both can therefore provide an extremely accurate answer to the question, \u201cWhat time is it?\u201d Of \ncourse, what time it is when you get the answer is another matter. Happily, for many purposes, almost-accurate time is good enough. However, as a prac-\ntical matter, you should assume some level of error exists between the clock readings on two \ndifferent devices. For this reason, most distributed systems are designed so that time synchro-\nnization among devices is not required for applications to function correctly. You can use \ndevice time to trigger periodic actions, to timestamp log entries, and for a few other purposes \nwhere accurate coordination with other devices is not necessary.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 276", "position": 276, "chunk_type": "semantic", "token_estimate": 408}
{"text": "17.3 Using Multiple Instances to Improve Performance and Availability 257: For this reason, most distributed systems are designed so that time synchro-\nnization among devices is not required for applications to function correctly. You can use \ndevice time to trigger periodic actions, to timestamp log entries, and for a few other purposes \nwhere accurate coordination with other devices is not necessary. Also happily, for many proposes, it is more important to know the order of events rather \nthan the time at which those events occurred. Trading decisions on the stock market fall into \nthis category, as do online auctions of any form. Both rely on processing packets in the same \norder in which they were transmitted. For critical coordination across devices, most distributed systems use mechanisms such \nas vector clocks (which are not really clocks, but rather counters that trace actions as they \npropagate through the services in an application) to determine whether one event happened \nbefore another event, rather than comparing times. This ensures that the application can apply \nthe actions in the correct order. Most of the data coordination mechanisms that we discuss \nin the next section rely on this kind of ordering of actions. For an architect, successful time coordination involves knowing whether you really need \nto rely on actual clock times, or whether ensuring correct sequencing suffices. If the former is \nimportant, then know your accuracy requirements and choose a solution accordingly.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 276", "position": 276, "chunk_type": "semantic", "token_estimate": 236}
{"text": "258 Part III Architectural Solutions | Chapter 17 The Cloud and Distributed Computing: Data Coordination in a Distributed System\nConsider the problem of creating a resource lock to be shared across distributed machines. Suppose some critical resource is being accessed by service instances on two distinct VMs \nrunning on two distinct physical computers. We assume this critical resource is a data item\u2014\nfor example, your bank account balance. Changing the account balance requires reading the \ncurrent balance, adding or subtracting the transaction amount, and then writing back the new \nbalance. If we allow both service instances to operate independently on this data item, there \nis the possibility of a race condition, such as two simultaneous deposits overwriting each other. The standard solution in this situation is to lock the data item, so that a service cannot access \nyour account balance until it gets the lock. We avoid a race condition because service instance \n1 is granted a lock on your bank account and can work in isolation to make its deposit until it \nyields the lock. Then service instance 2, which has been waiting for the lock to become avail-\nable, can lock the bank account and make the second deposit. This solution using a shared lock is easy to implement when the services are processes \nrunning on a single machine, and requesting and releasing a lock are simple memory access \noperations that are very fast and atomic. However, in a distributed system, two problems arise \nwith this scheme. First, the two-phase commit protocol traditionally used to acquire a lock \nrequires multiple messages to be transmitted across the network. In the best case, this just \nadds delay to the actions, but in the worst case, any of these messages may fail to be delivered. Second, service instance 1 may fail after it has acquired the lock, preventing service instanceb2 \nfrom proceeding. The solution to these problems involves complicated distributed coordination algorithms. Leslie Lamport, quoted at the beginning of the chapter, developed one of the first such algo-\nrithms, which he named \u201cPaxos.\u201d Paxos and other distributed coordination algorithms rely \non a consensus mechanism to allow participants to reach agreement even when computer or \nnetwork failures occur. These algorithms are notoriously complicated to design correctly, and \neven implementing a proven algorithm is difficult due to subtleties in programming language \nand network interface semantics. In fact, distributed coordination is one of those problems \nthat you should not try to solve yourself.", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 277", "position": 277, "chunk_type": "semantic", "token_estimate": 409}
{"text": "258 Part III Architectural Solutions | Chapter 17 The Cloud and Distributed Computing: These algorithms are notoriously complicated to design correctly, and \neven implementing a proven algorithm is difficult due to subtleties in programming language \nand network interface semantics. In fact, distributed coordination is one of those problems \nthat you should not try to solve yourself. Using one of the existing solution packages, such as \nApache Zookeeper, Consul, and etcd, is almost always a better idea than rolling your own. When service instances need to share information, they store it in a service that uses a distrib-\nuted coordination mechanism to ensure that all services see the same values. Our last distributed computing topic is the automatic creation and destruction of instances. Autoscaling: Automatic Creation and Destruction of Instances\nConsider a traditional data center, where your organization owns all the physical resources. In \nthis environment, your organization needs to allocate enough physical hardware to a system to \nhandle the peak of the largest workload that it has committed to process. When the workload \nis less than the peak, some (or much) of the hardware capacity allocated to the system is idle. Now compare this to a cloud environment. Two of the defining features of the cloud are that \nyou pay only for the resources you requisition and that you can easily and quickly add and", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 277", "position": 277, "chunk_type": "semantic", "token_estimate": 225}
{"text": "17.3 Using Multiple Instances to Improve Performance and Availability 259: release resources (elasticity). Together, these features allow you to create systems that have the \ncapacity to handle your workload, and you don\u2019t pay for any excess capacity. Elasticity applies at different time scales. Some systems see relatively stable workloads, \nin which case you might consider manually reviewing and changing resource allocation on a \nmonthly or quarterly time scale to match this slowly changing workload. Other systems see \nmore dynamic workloads with rapid increases and decreases in the rate of requests, and so \nneed a way to automate adding and releasing service instances. Autoscaling is an infrastructure service that automatically creates new instances when \nneeded and releases surplus instances when they are no longer needed. It usually works in \nconjunction with load balancing to grow and shrink the pool of service instances behind a \nload balancer. Autoscaling containers is slightly different from autoscaling VMs. We discuss \nautoscaling VMs first and then discuss the differences when containers are being autoscaled. Autoscaling VMs\nReturning to Figure 17.4, suppose that the two clients generate more requests than can be \nhandled by the two service instances shown. Autoscaling creates a third instance, based on \nthe same virtual machine image that was used for the first two instances. The new instance \nis registered with the load balancer so that subsequent requests are distributed among three \ninstances rather than two. Figure 17.5 shows a new component, the autoscaler, that monitors \nand autoscales the utilization of the server instances. Once the autoscaler creates a new ser-\nvice instance, it notifies the load balancer of the new IP address so that the load balancer can \ndistribute requests to the new instance, in addition to the requests it distributes to the other \ninstances. Autoscaler\nFIGURE 17.5 An autoscaler monitoring the utilization", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 278", "position": 278, "chunk_type": "semantic", "token_estimate": 301}
{"text": "260 Part III Architectural Solutions | Chapter 17 The Cloud and Distributed Computing: Because the clients do not know how many instances exist or which instance is serving \ntheir requests, autoscaling activities are invisible to service clients. Furthermore, if the client \nrequest rate decreases, an instance can be removed from the load balancer pool, halted, and \ndeallocated, again without the client\u2019s knowledge. As an architect of a cloud-based service, you can set up a collection of rules for the auto-\nscaler that govern its behavior. The configuration information you provide to the autoscaler \nincludes the following items:\n \n\u25a0The VM image to be launched when a new instance is created, and any instance config-\nuration parameters required by the cloud provider, such as security settings\n \n\u25a0The CPU utilization threshold (measured over time) for any instance above which a new \ninstance is launched\n \n\u25a0The CPU utilization threshold (measured over time) for any instance below which an \nexisting instance is shut down\n \n\u25a0The network I/O bandwidth thresholds (measured over time) for creating and deleting \ninstances\n \n\u25a0The minimum and maximum number of instances you want in this group\nThe autoscaler does not create or remove instances based on instantaneous values of the \nCPU utilization or network I/O bandwidth metrics, for two reasons. First, these metrics have \nspikes and valleys and are meaningful only when averaged over a reasonable time interval. Second, allocating and starting a new VM takes a relatively long time, on the order of minutes. The VM image must be loaded and connected to the network, and the operating system must \nboot before it will be ready to process messages. Consequently, autoscaler rules typically are \nof the form, \u201cCreate a new VM when CPU utilization is above 80 percent for 5 minutes.\u201d\nIn addition to creating and destroying VMs based on utilization metrics, you can set rules \nto provide a minimum or maximum number of VMs or to create VMs based on a time sched-\nule. During a typical week, for example, load may be heavier during work hours; based on this \nknowledge, you can allocate more VMs before the beginning of a workday and remove some \nafter the workday is over. These scheduled allocations should be based on historical data about \nthe pattern of usage of your services. When the autoscaler removes an instance, it cannot just shut down the VM. First, it must \nnotify the load balancer to stop sending requests to the service instance.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 279", "position": 279, "chunk_type": "semantic", "token_estimate": 405}
{"text": "260 Part III Architectural Solutions | Chapter 17 The Cloud and Distributed Computing: When the autoscaler removes an instance, it cannot just shut down the VM. First, it must \nnotify the load balancer to stop sending requests to the service instance. Next, because the \ninstance may be in the process of servicing a request, the autoscaler must notify the instance \nthat it should terminate its activities and shut down, after which it can be destroyed. This pro-\ncess is called \u201cdraining\u201d the instance. As a service developer, you are responsible for imple-\nmenting the appropriate interface to receive instructions to terminate and drain an instance of \nyour service. Autoscaling Containers\nBecause containers are executing on runtime engines that are hosted on VMs, scaling con-\ntainers involves two different types of decisions. When scaling VMs, an autoscaler decides \nthat additional VMs are required, and then allocates a new VM and loads it with the appro-\npriate software. Scaling containers means making a two-level decision. First, decide that an", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 279", "position": 279, "chunk_type": "semantic", "token_estimate": 167}
{"text": "17.4 Summary 261: additional container (or Pod) is required for the current workload. Second, decide whether the \nnew container (or Pod) can be allocated on an existing runtime engine instance or whether a \nnew instance must be allocated. If a new instance must be allocated, you need to check whether \na VM with sufficient capacity is available or if an additional VM needs to be allocated. The software that controls the scaling of containers is independent of the software that \ncontrols the scaling of VMs. This allows the scaling of containers to be portable across differ-\nent cloud providers. It is possible that the evolution of containers will integrate the two types of \nscaling. In such a case, you should be aware that you may be creating a dependency between \nyour software and the cloud provider that could be difficult to break. 17.4  \nSummary\nThe cloud is composed of distributed data centers, with each data center containing tens of \nthousands of computers. It is managed through a management gateway that is accessible over \nthe Internet and is responsible for allocating, deallocating, and monitoring VMs, as well as \nmeasuring resource usage and computing billing. Because of the large number of computers in a data center, failure of a computer in such \na center happens quite frequently. You, as an architect of a service, should assume that at some \npoint, the VMs on which your service is executing will fail. You should also assume that your \nrequests for other services will exhibit a long tail distribution, such that as many as 5 percent \nof your requests will take 5 to 10 times longer than the average request. Thus you must be con-\ncerned about the availability of your service. Because single instances of your service may not be able to satisfy all requests in a timely \nmanner, you may decide to run multiple VMs or containers containing instances of your ser-\nvice. These multiple instances sit behind a load balancer. The load balancer receives requests \nfrom clients and distributes the requests to the various instances. The existence of multiple instances of your service and multiple clients has a significant \nimpact on how you handle state. Different decisions on where to keep the state will lead to \ndifferent results. The most common practice is to keep services stateless, because stateless \nservices allow for easier recovery from failure and easier addition of new instances.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 280", "position": 280, "chunk_type": "semantic", "token_estimate": 400}
{"text": "17.4 Summary 261: Different decisions on where to keep the state will lead to \ndifferent results. The most common practice is to keep services stateless, because stateless \nservices allow for easier recovery from failure and easier addition of new instances. Small \namounts of data can be shared among service instances by using a distributed coordination \nservice. Distributed coordination services are complicated to implement, but several proven \nopen source implementations are available for your use. The cloud infrastructure can automatically scale your service by creating new instances \nwhen demand grows and removing instances when demand shrinks. You specify the behavior \nof the autoscaler through a set of rules giving the conditions for the creation or deletion of \ninstances.", "domains": ["Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 280", "position": 280, "chunk_type": "semantic", "token_estimate": 117}
{"text": "262 Part III Architectural Solutions | Chapter 17 The Cloud and Distributed Computing: 17.5  \nFor Further Reading\nMore details about how networks and virtualization work can be found in [Bass 19]. The long tail latency phenomenon in the context of the cloud was first identified in \n[Dean 13]. Paxos was first presented by [Lamport 98]. People found the original article difficult \nto understand, but a very thorough description of Paxos can be found in Wikipedia\u2014https://\nen.wikipedia.org/wiki/Paxos_(computer_science). Around the same time, Brian Oki and \nBarbara Liskov independently developed and published an algorithm called Viewstamped \nReplication that was later shown to be equivalent to Lamport\u2019s Paxos [Oki 88]. A description of Apache Zookeeper can be found at https://zookeeper.apache.org/. Consul \ncan be found at https://www.consul.io/, and etcd can be found at https://etcd.io/\nA discussion of different types of load balancers can be found at https://\ndocs.aws.amazon.com/AmazonECS/latest/developerguide/load-balancer-types.html. Time in a distributed system is discussed in https://medium.com/coinmonks/time-and-\nclocks-and-ordering-of-events-in-a-distributed-system-cdd3f6075e73. Managing state in a distributed system is discussed in https://conferences.oreilly.com/\nsoftware-architecture/sa-ny-2018/public/schedule/detail/64127. 17.6  \nDiscussion Questions\n1. A load balancer is a type of intermediary. Intermediaries enhance modifiability but \ndetract from performance, yet a load balancer exists to increase performance. Explain \nthis apparent paradox. 2. A context diagram displays an entity and other entities with which it communicates. It \nseparates the responsibilities allocated to the chosen entity from those responsibilities \nallocated to other entities, and shows the interactions needed to accomplish the chosen \nentity\u2019s responsibilities. Draw a context diagram for a load balancer. 3. Sketch the set of steps to allocate a VM within a cloud and display its IP address. 4. Research the offerings of a major cloud provider. Write a set of rules that would govern \nthe autoscaling for a service that you would implement on this cloud. 5. Some load balancers use a technique called message queues. Research message queues and \ndescribe the differences between load balancers with and without message queues.", "domains": ["Design Patterns", "Software Quality Attributes", "Domain-Driven Design"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 281", "position": 281, "chunk_type": "semantic", "token_estimate": 316}
{"text": "264 Part III Architectural Solutions | Chapter 18 Mobile Systems: smartphones must provide an open platform for a variety of vastly different applications; \nentertainment systems must work with a wide range of content formats and service providers. In this chapter, we\u2019ll focus on the characteristics shared by many (if not all) mobile systems \nthat an architect must consider when designing a system. 18.1  \nEnergy\nIn this section, we focus on the architectural concerns most relevant to managing the energy of \nmobile systems. For many mobile devices, their source of energy is a battery with a very finite \ncapacity for delivering that energy. Other mobile devices, such as cars and planes, run on the \npower produced by generators, which in turn may be powered by engines that run on fuel\u2014\nagain, a finite resource. The Architect\u2019s Concerns\nThe architect must be concerned with monitoring the power source, throttling energy usage, \nand tolerating loss of power. We elaborate on these concerns in the next three subsections. Monitoring the Power Source\nIn Chapter 6 on energy efficiency, we introduced a category of tactics called \u201cresource moni-\ntoring\u201d for monitoring the usage of computational resources, which are consumers of energy. In mobile systems, we need to monitor the energy source, so that we can initiate appropri-\nate behavior when the energy available becomes low. Specifically, in a mobile device powered \nby a battery, we may need to inform a user that the battery level is low, put the device into \n \nbattery-saving mode, alert applications to the imminent shutdown of the device so they can \nprepare for a restart, and determine the power usage of each application. All of these uses depend on monitoring the current state of the battery. Most laptops or \nsmartphones use a smart battery as a power source. A smart battery is a rechargeable battery \npack with a built-in battery management system (BMS). The BMS can be queried to get the \ncurrent state of the battery. Other mobile systems might use a different battery technology, but \nall have some equivalent capability. For the purposes of this section, we will assume that the \nreading identifies the percentage of capacity left. Battery-powered mobile systems include a component, often in the kernel of the operat-\ning system, that knows how to interact with the BMS and can return the current battery capac-\nity on request. A battery manager is responsible for periodically querying that component to \nretrieve the state of the battery.", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 283", "position": 283, "chunk_type": "semantic", "token_estimate": 408}
{"text": "264 Part III Architectural Solutions | Chapter 18 Mobile Systems: Battery-powered mobile systems include a component, often in the kernel of the operat-\ning system, that knows how to interact with the BMS and can return the current battery capac-\nity on request. A battery manager is responsible for periodically querying that component to \nretrieve the state of the battery. This enables the system to inform the user of the energy status \nand trigger the battery-saving mode, if necessary. To inform the applications that the device is \nabout to shut down, the applications must register with the battery manager. Two characteristics of batteries change as they age: the maximum battery capacity and \nthe maximum sustained current. An architect must allow for managing consumption within", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 283", "position": 283, "chunk_type": "semantic", "token_estimate": 124}
{"text": "18.1 Energy 265: the changing envelope of available power so that the device still performs at  an acceptable \nlevel. Monitoring plays a role in generator-equipped systems as well, since some applications \nmay need to be shut down or put on standby when generator output is low. The battery man-\nager can also determine which applications are currently active and what their energy con-\nsumption is. The overall percentage of the change in battery capacity can then be estimated \nbased on this information. Of course, the battery manager itself utilizes resources\u2014memory and CPU time. The \namount of CPU time consumed by the battery manager can be managed by adjusting the query \ninterval. Throttling Energy Usage\nEnergy usage can be reduced by either terminating or degrading portions of the system that \nconsume energy; this is the throttle usage tactic described in Chapter 6. The specifics of how \nthis is done depend on the individual elements of the system, but a common example is reduc-\ning the brightness or the refresh rate of the display on a smartphone. Other techniques for \nthrottling energy usage include reducing the number of active cores of the processor, reducing \nthe clock rate of the cores, and reducing the frequency of sensor readings. For example, instead \nof asking for GPS location data every few seconds, ask for it every minute or so. Instead of \nrelying on different location data sources such as GPS and cell towers, use just one of those. Tolerating a Loss of Power\nMobile systems should gracefully tolerate power failures and restarts. For example, a require-\nment of such a system could be that following restoration of power, the system is back on and \nworking in the nominal mode within 30 seconds. This requirement implies different require-\nments apply to different portions of the system, such as the following:\n \n\u25a0Example hardware requirements:\n \n\u25a0The system\u2019s computer does not suffer permanent damage if power is cut at any time. \u25a0The system\u2019s computer (re)starts the OS robustly whenever sufficient power is \nprovided. \u25a0The system\u2019s OS has the software scheduled to launch as soon as the OS is ready. \u25a0Example software requirements:\n \n\u25a0The runtime environment can be killed at any moment without affecting the integrity \nof the binaries, configurations, and operational data in permanent storage, and while \nkeeping the state consistent after a restart (whether that is a reset or a resume).", "domains": ["Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 284", "position": 284, "chunk_type": "semantic", "token_estimate": 393}
{"text": "18.1 Energy 265: \u25a0The system\u2019s OS has the software scheduled to launch as soon as the OS is ready. \u25a0Example software requirements:\n \n\u25a0The runtime environment can be killed at any moment without affecting the integrity \nof the binaries, configurations, and operational data in permanent storage, and while \nkeeping the state consistent after a restart (whether that is a reset or a resume). \u25a0Applications need a strategy to deal with data that arrives while the application is \ninoperative. \u25a0The runtime can start after a failure so that the startup time, from system power on \nto the software being in a ready state, is less than a specified period.", "domains": ["Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 284", "position": 284, "chunk_type": "semantic", "token_estimate": 107}
{"text": "18.3 Sensors and Actuators 267: \u25a0Bandwidth. The information to be communicated to other systems should be analyzed \nfor distance, volume, and latency requirements so that appropriate architectural choices \ncan be made. The protocols all vary in terms of those qualities. \u25a0Intermittent/limited/no connectivity. Communication may be lost while the device is in \nmotion (e.g., a smartphone going through a tunnel). The system should be designed so \nthat data integrity is maintained in case of a loss of connectivity, and computation can \nbe resumed without loss of consistency when connectivity returns. The system should be \ndesigned to deal gracefully with limited connectivity or even no connectivity. Degraded \nand fallback modes should be dynamically available to deal with such situations. \u25a0Security. Mobile devices are particularly vulnerable to spoofing, eavesdropping, and man-\nin-the-middle attacks, so responding to such attacks should be part of the architect\u2019s \nconcerns. 18.3  \nSensors and Actuators\nA sensor is a device that detects the physical characteristics of its environment and translates \nthose characteristics into an electronic representation. A mobile device gathers environmental \ndata either to guide its own operation (such as the altimeter in a drone), or to report that data \nback to a user (such as the magnetic compass in your smartphone). A transducer senses external electronic impulses and converts them into a more usable \ninternal form. In this section. we will use the term \u201csensor\u201d to encompass transducers as well, \nand assume the electronic representation is digital. A sensor hub is a coprocessor that helps integrate data from different sensors and process \nit. A sensor hub can help offload these jobs from a product\u2019s main CPU, thereby saving battery \nconsumption and improving performance. Inside the mobile system, software will abstract some characteristics of the environment. This abstraction may map directly to a sensor, such as with measurement of temperature or \npressure, or it may integrate the input of several sensors, such as pedestrians identified in a \nself-driving automobile controller. An actuator is the reverse of a sensor: It takes a digital representation as input and causes \nsome action in the environment. The lane keep assist feature in an automobile utilizes actua-\ntors, as does an audio alert from your smartphone. The Architect\u2019s Concerns\nAn architect has several concerns with respect to sensors:\n \n\u25a0How to create an accurate representation of the environment based on the sensor inputs. \u25a0How the system should respond to that representation of the environment.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 286", "position": 286, "chunk_type": "semantic", "token_estimate": 399}
{"text": "18.3 Sensors and Actuators 267: The Architect\u2019s Concerns\nAn architect has several concerns with respect to sensors:\n \n\u25a0How to create an accurate representation of the environment based on the sensor inputs. \u25a0How the system should respond to that representation of the environment. \u25a0Security and privacy of the sensor data and actuator commands. \u25a0Degraded operation. If sensors fail or become unreadable, the system should enter a \ndegraded mode. For example, if GPS readings are not available in tunnels, the system \ncan use dead reckoning techniques to estimate location.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 286", "position": 286, "chunk_type": "semantic", "token_estimate": 87}
{"text": "268 Part III Architectural Solutions | Chapter 18 Mobile Systems: The representation of the environment that is created and acted upon by a system is \ndomain specific, as is the appropriate approach to degraded operation. We discussed security \nand privacy in detail in Chapter 8, but here we will focus on only the first concern: creating an \naccurate representation of the environment based on the data returned by the sensors. This is \nperformed using the sensor stack\u2014a confederation of devices and software drivers that help \nturn raw data into interpreted information about the environment. Different platforms and domains tend to have their own sensor stacks, and sensor stacks \noften come with their own frameworks to help deal with the devices more easily. Over time, \nsensors are likely to encompass more and more functionality; in turn, the functions of a par-\nticular stack will change over time. Here, we enumerate some of the functions that must be \nachieved in the stack regardless of where a particular decomposition may have placed them:\n \n\u25a0Reading raw data. The lowest level of the stack is a software driver to read the raw data. The driver reads the sensor either directly or, in the case where the sensor is a portion \nof a sensor hub, through the hub. The driver gets a reading from the sensor periodically. The period frequency is a parameter that will influence both the processor load from \nreading and processing the sensor and the accuracy of the created representation. \u25a0Smoothing data. Raw data usually has a great deal of noise or variation. Voltage varia-\ntions, dirt or grime on a sensor, and a myriad of other causes can make two successive \nreadings of a sensor differ. Smoothing is a process that uses a series of measurements \nover time to produce an estimate that tends to be more accurate than single readings. Calculating a moving average and using a Kalman filter are two of the many techniques \nfor smoothing data. \u25a0Converting data. Sensors can report data in many formats\u2014from voltage readings in \nmillivolts to altitude above sea level in feet to temperature in degrees Celsius. It is possible, \nhowever, that two different sensors measuring the same phenomenon might report their \ndata in different formats. The converter is responsible for converting readings from what-\never form is reported by the sensor into a common form meaningful to the application.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 287", "position": 287, "chunk_type": "semantic", "token_estimate": 395}
{"text": "18.4 Resources 269: with battery volume, weight, and thermal properties. The same holds true for resources such \nas networks, processors, and sensors. The tradeoff in the choice of resources is between the contribution of the particular \nresource under consideration and its volume, weight, and cost. Cost is always a factor. Costs \ninclude both the manufacturing costs and nonrecurring engineering costs. Many mobile sys-\ntems are manufactured by the millions and are highly price-sensitive. Thus a small difference \nin the price of a processor multiplied by the millions of copies of the system in which that pro-\ncessor is embedded can make a significant difference to the profitability of the organization \nproducing the system. Volume discounts and reuse of hardware across different products are \ntechniques that device vendors use to reduce costs. Volume, weight, and cost are constraints given both by the marketing department of an \norganization and by the physical considerations of its use. The marketing department is con-\ncerned with customers\u2019 reactions. The physical considerations for the device\u2019s use depend on \nboth human and usage factors. Smartphone displays must be large enough for a human to read; \nautomobiles are constrained by weight limits on roads; trains are constrained by track width; \nand so forth. Other constraints on mobile system resources (and therefore on software architects) \nreflect the following factors:\n \n\u25a0Safety considerations. Physical resources that have safety consequences must not fail or \nmust have backups. Backup processors, networks, or sensors add cost and weight, as well \nas consume space. For example, many aircraft have an emergency source of power that \ncan be used in case of engine failure. \u25a0Thermal limits. Heat can be generated by the system itself (think of your lap on which \nyour laptop sits), which can have a detrimental effect on the system\u2019s performance, even \nto the point of inducing failure. The environment\u2019s ambient temperature\u2014too high or \ntoo low\u2014can have an impact as well. There should be an understanding of the environ-\nment in which the system will be operated prior to making hardware choices. \u25a0Other environmental concerns. Other concerns include exposure to adverse conditions \nsuch as moisture or dust, or being dropped. The Architect\u2019s Concerns\nAn architect must make a number of important decisions surrounding resources and their \nusage:\n \n\u25a0Assigning tasks to electronic control units (ECUs). Larger mobile systems, such as cars \nor airplanes, have multiple ECUs of differing power and capacity.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 288", "position": 288, "chunk_type": "semantic", "token_estimate": 396}
{"text": "270 Part III Architectural Solutions | Chapter 18 Mobile Systems: \u25a0Criticality. More powerful ECUs may be reserved for critical functions. For exam-\nple, engine controllers are more critical and more reliable than the comfort features \nsubsystem. \u25a0Location in the vehicle. First-class passengers may have better Wi-Fi connectivity than \nsecond-class passengers. \u25a0Connectivity. Some functions may be split among several ECUs. If so, they must be on \nthe same internal network and able to communicate with each other. \u25a0Locality of communication. Putting components that intensely communicate with each \nother on the same ECU will improve their performance and reduce network traffic. \u25a0Cost. Typically a manufacturer wants to minimize the number of ECUs deployed. \u25a0Offloading functionality to the cloud. Applications such as route determination and pat-\ntern recognition can be performed partly by the mobile system itself\u2014where the sensors \nare located\u2014and partly from portions of the application that are resident on the cloud\u2014\nwhere more data storage and more powerful processors are available. The architect \nmust determine whether the mobile system has sufficient power for specific functions, \nwhether there is adequate connectivity to offload some functions, and how to satisfy \nperformance requirements when the functions are split between the mobile system and \nthe cloud. The architect should also take into consideration data storage available locally, \ndata update intervals, and privacy concerns. \u25a0Shutting down functions depending on the mode of operations. Subsystems that are not \nbeing used can scale down their footprint, allowing competing subsystems to access \nmore resources, and thereby deliver better performance. In sports cars, an example is \nswitching on a \u201crace mode,\u201d which disables the processes responsible for calculating \ncomfortable suspension parameters based on the road profile and activates calculations \nof torque distribution, braking power, suspension hardening, and centrifugal forces. \u25a0Strategy for displaying information. This issue is tied to available display resolution. It\u2019s possible to do GPS style mapping on a 320 \u00d7 320 pixel display, but a lot of effort has \nto go into minimizing the information on the display. At a resolution of 1,280 \u00d7 720, \nthere are more pixels, so the information display can be richer. (Having the ability to \nchange the information on the display is a strong motivator for a pattern such as MVC \n[see Chapter 13] so that the view can be swapped out based on the specific display \ncharacteristics.)", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 289", "position": 289, "chunk_type": "semantic", "token_estimate": 385}
{"text": "18.5 Life Cycle 271: The Architect\u2019s Concerns\nThe architect must be concerned with the hardware choices, testing, deploying updates, and \nlogging. We elaborate on these concerns in the next four subsections. Hardware First\nFor many mobile systems, the hardware is chosen before the software is designed. Consequently, \nthe software architecture must live with the constraints imposed by the chosen hardware. The main stakeholders in early hardware choices are management, sales, and regulators. Their concerns typically focus on ways to reduce risks rather than ways to promote quality \nattributes. The best approach for a software architect is to actively drive these early discus-\nsions, emphasizing the tradeoffs involved, instead of passively awaiting their outcomes. Testing\nMobile devices present some unique considerations for testing:\n \n\u25a0Test display layouts. Smartphones and tablets come in a wide variety of shapes, sizes, \nand aspect ratios. Verifying the correctness of the layout on all of these devices is \ncomplicated. Some operating system frameworks allow the user interface to be operated \nfrom unit tests, but may miss some unpleasant edge cases. For example, suppose you \ndisplay control buttons on your screen, with the layout specified in HTML and CSS, and \nsuppose it\u2019s automatically generated for all display devices you anticipate using. A naive \ngeneration for a tiny display could produce a control on a 1 \u00d7 1 pixel, or controls right \nat the edge of the display, or controls that overlap. These may easily escape detection \nduring testing. \u25a0Test operational edge cases. \u25a0An application should survive battery exhaustion and shutdown of the system. The \npreservation of state in such cases needs to be ensured and tested. \u25a0The user interface typically operates asynchronously from the software that pro-\nvides the functionality. When the user interface does not react correctly, re-creating \nthe sequence of events that caused the problem is difficult because the problem may \ndepend on the timing, or on a specific set of operations in progress at the time. \u25a0Test resource usage. Some vendors will make simulators of their devices available \nto software architects. That\u2019s helpful, but testing battery usage with a simulator is \nproblematic. \u25a0Test for network transitions. Ensuring that the system makes the best choice when \nmultiple communication networks are available is also difficult. As a device moves from \none network to another (e.g., from a Wi-Fi network to a cellular network and then to a \ndifferent Wi-Fi network), the user should be unaware of these transitions.", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 290", "position": 290, "chunk_type": "semantic", "token_estimate": 401}
{"text": "18.5 Life Cycle 271: Ensuring that the system makes the best choice when \nmultiple communication networks are available is also difficult. As a device moves from \none network to another (e.g., from a Wi-Fi network to a cellular network and then to a \ndifferent Wi-Fi network), the user should be unaware of these transitions. Testing for transportation or industrial systems tends to happen on four levels: the indi-\nvidual software component level, the function level, the device level, and the system level. The \nlevels and boundaries between them may vary depending on the system, but they are implied \nin several reference processes and standards such as Automotive SPICE.", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 290", "position": 290, "chunk_type": "semantic", "token_estimate": 108}
{"text": "272 Part III Architectural Solutions | Chapter 18 Mobile Systems: For example, suppose we are testing a car\u2019s lane keep assist function, where the vehicle \nstays in the lane defined by markings on the road and does so without driver input. Testing of \nthis system may address the following levels:\n1. Software component. A lane detection software component will be tested through the \nusual techniques for unit and end-to-end testing, with the aim of validating the soft-\nware\u2019s stability and correctness. 2. Function. The next step is to run the software component together with other compo-\nnents of the lane keep assist function, such as a mapping component to identify high-\nway exits, in a simulated environment. The aim is to validate the interfacing and safe \nconcurrency when all components of the function are working together. Here, simulators \nare used to provide the software function with inputs that correspond to a vehicle driving \ndown a marked road. 3. Device. The bundled lane keep assist function, even if it passes the tests in the simulated \nenvironment and on the development computers, needs to be deployed on its target ECU \nand tested there for performance and stability. In this device test phase, the environment \nwould still be simulated, but this time through simulated external inputs (messages from \nother ECUs, sensor inputs, and so forth) connected to the ECU\u2019s ports. 4. System. In the final system integration testing phase, all devices with all functions and \nall components are built into full-size configurations, first in a test lab and then in a test \nprototype. For example, the lane keep assist function could be subjected to testing, along \nwith its actions on the steering and acceleration/braking functions, while being fed a \nprojected image or a video of the road. The role of these tests is to confirm that the inte-\ngrated subsystems work together and deliver the desired functionality and system quality \nattributes. An important point here is test traceability: If an issue is found in step 4, it needs to be \nreproducible and traceable through all test setups, since a fix will have to go through all four \ntest levels again. Deploying Updates\nIn a mobile device, updates to the system either fix issues, provide new functionality, or \ninstall features that are unfinished but perhaps were partially installed at the time of an earlier \nrelease. Such an update may target the software, the data, or (less often) the hardware.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 291", "position": 291, "chunk_type": "semantic", "token_estimate": 405}
{"text": "18.6 Summary 273: driving down the highway is a bad idea. This, in turn, implies that the system needs to be \naware of safety-relevant states with respect to updates. \u25a0Partial system deployment. Re-deploying a total application or large subsystem will \nconsume both bandwidth and time. The application or subsystem should be architected \nso that the portions that change frequently can be easily updated. This calls for a specific \ntype of modifiability (see Chapter 8) and an attention to deployability (see Chapter 5). In \naddition, updates should be easy and automated. Accessing physical portions of a device \nto update them may be awkward. Returning to the engine controller example, updating \nthe controller software should not require access to the engine. \u25a0Extendability. Mobile vehicle systems tend to have relatively long lifetimes. Retrofitting \ncars, trains, airplanes, satellites, and so forth will likely become necessary at some \npoint. Retrofitting means adding new technology to old systems, either by replacement \nor addition. This could occur for the following reasons:\n \n\u25a0The component reaches the end of its life before the overall system reaches its end. The end of life means support will be discontinued, which creates high risks in case \nof failures: There will be no trusted source from which to get answers or support with \nreasonable costs\u2014that is, without having to dissect and reverse-engineer the compo-\nnent in question. \u25a0Newer better technology has come out, prompting a hardware/software upgrade. An \nexample is retrofitting a 2000s car with a smartphone-connected infotainment system \ninstead of an old radio/CD player. \u25a0Newer technology is available that adds functionality without replacing existing func-\ntionality. For example, suppose the 2000s-era car never had a radio/CD player at all, or \nlacked a backup camera. Logging\nLogs are critical when investigating and resolving incidents that have occurred or may occur. In mobile systems, the logs should be offloaded to a location where they are accessible regard-\nless of the accessibility of the mobile system itself. This is useful not only for incident han-\ndling, but also for performing various types of analyses on the usage of the system. Many \nsoftware applications do something similar when they encounter a problem and ask for per-\nmission to send the details to the vendor. For mobile systems, this logging capability is partic-\nularly important, and they may very well not ask permission to obtain the data.", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 292", "position": 292, "chunk_type": "semantic", "token_estimate": 390}
{"text": "274 Part III Architectural Solutions | Chapter 18 Mobile Systems: The energy in many mobile systems comes from batteries. Batteries are monitored to \ndetermine both the remaining time on the battery and the usage of individual applications. Energy usage can be controlled by throttling individual applications. Applications should be \nconstructed to survive power failures and restart seamlessly when power is restored. Connectivity means connecting to other systems and the Internet through wireless means. Wireless communication can be via short-distance protocols such as Bluetooth, medium-range \nprotocols such as Wi-Fi protocols, and long-distance cellular protocols. Communication should \nbe seamless when moving from one protocol class to another, and considerations such as band-\nwidth and cost help the architect decide which protocols to support. Mobile systems utilize a variety of sensors. Sensors provide readings of the external envi-\nronment, which the architect then uses to develop a representation within the system of the \nexternal environment. Sensor readings are processed by a sensor stack specific to each oper-\nating system; these stacks will deliver readings meaningful to the representation. It may take \nmultiple sensors to develop a meaningful representation, with the readings from these sensors \nthen being fused (integrated). Sensors may also become degraded over time, so multiple sen-\nsors may be needed to get an accurate representation of the phenomenon being measured. Resources have physical characteristics such as size and weight, have processing capa-\nbilities, and carry a cost. The design choices involve tradeoffs among these factors. Critical \nfunctions may require more powerful and reliable resources. Some functions may be shared \nbetween the mobile system and the cloud, and some functions may be shut down in certain \nmodes to free up resources for other functions. Life-cycle issues include choice of hardware, testing, deploying updates, and logging. Testing of the user interface may be more complicated with mobile systems than with fixed \nsystems. Likewise, deployment is more complicated because of bandwidth, safety consider-\nations, and other issues. 18.7  \nFor Further Reading\nThe Battery University (https://batteryuniversity.com/) has more materials than you care about \non batteries of various types and their measurement. You can read more about various network protocols at the following sites:\nlink-labs.com/blog/complete-list-iot-network-protocols\nhttps://en.wikipedia.org/wiki/Wireless_ad_hoc_network\nhttps://searchnetworking.techtarget.com/tutorial/Wireless-protocols-learning-guide\nhttps://en.wikipedia.org/wiki/IEEE_802\nYou can find out more about sensors in [Gajjarby 17]. Some test tools for mobile applications can be found at these two sites:\nhttps://codelabs.developers.google.com/codelabs/firebase-test-lab/index.html#0\nhttps://firebase.google.com/products/test-lab", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 293", "position": 293, "chunk_type": "semantic", "token_estimate": 387}
{"text": "18.8 Discussion Questions 275: Some of the difficulties involved in making self-driving cars safe are discussed in \u201cAdventures \nin Self Driving Car Safety,\u201d Philip Koopman\u2019s presentation on Slideshare: slideshare.net/\nPhilipKoopman1/adventures-in-self-driving-car-safety?qid=eb5f5305-45fb-419e-83a5-\n998a0b667004&v=&b=&from_search=3. You can find out about Automotive SPICE at automotivespice.com. ISO 26262, \u201cRoad Vehicles: Functional Safety,\u201d is an international standard for func-\ntional safety of automotive electrical and/or electronic systems (iso.org/standard/68383.html). 18.8  \nDiscussion Questions\n1. Which architectural choices would you make to design a system that could tolerate com-\nplete loss of power and have the ability to restart where it left off without compromising \nthe integrity of its data? 2. What are the architectural issues involved in network transitions, such as starting a file \ntransfer over Bluetooth and then moving out of Bluetooth range and switching over to \nWi-Fi, all the while keeping the transfer seamlessly proceeding? 3. Determine the weight and size of the battery in one of your mobile systems. What com-\npromises do you think the architect made because of the size and weight? 4. Which types of problems can a CSS testing tool find? Which does it miss? How do these \nconsiderations affect the testing of mobile devices? 5. Consider an interplanetary probe such as those used in NASA\u2019s Mars exploration program. Does it meet the criteria of a mobile device? Characterize its energy characteristics, net-\nwork connectivity issues (obviously, none of the network types discussed in Section 18.2 \nare up to the task), sensors, resource issues, and special life-cycle considerations. 6. Consider mobility not as a class of computing system, but rather as a quality attribute, like \nsecurity or modifiability. Write a general scenario for mobility. Write a specific mobility \nscenario for a mobile device of your choosing. Describe a set of tactics to achieve the \nquality attribute of \u201cmobility.\u201d\n7. Section 18.5 discussed several aspects of testing that are more challenging in mobile \nsystems. What testability tactics from Chapter 12 can help with these issues?", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 294", "position": 294, "chunk_type": "semantic", "token_estimate": 322}
{"text": "277: 19\n \nArchitecturally Significant \nRequirements\nThe most important single aspect of software development is to be \nclear about what you are trying to build. \u2014Bjarne Stroustrup, creator of C++\nArchitectures exist to build systems that satisfy requirements. By \u201crequirements,\u201d we do not \nnecessarily mean a documented catalog produced using the best techniques that requirements \nengineering has to offer. Instead, we mean the set of properties that, if not satisfied by your \nsystem, will cause the system to be a failure. Requirements exist in as many forms as there are \nsoftware development projects\u2014from polished specifications to verbal shared understanding \n(real or imagined) among principal stakeholders. The technical, economic, and philosophical \njustifications for your project\u2019s requirements practices are beyond the scope of this book. What \nis in scope is that, regardless of how they are captured, they establish the criteria for success or \nfailure, and architects need to know them. To an architect, not all requirements are created equal. Some have a much more pro-\nfound effect on the architecture than others. An architecturally significant requirement (ASR) \nis a requirement that will have a profound effect on the architecture\u2014that is, the architecture \nmight well be dramatically different in the absence of such a requirement. You cannot hope to design a successful architecture if you do not know the ASRs. ASRs \noften, but not always, take the form of quality attribute (QA) requirements\u2014the performance, \nsecurity, modifiability, availability, usability, and so forth, that the architecture must provide \nto the system. In Chapters 4\u201314, we introduced patterns and tactics to achieve QAs. Each time \nyou select a pattern or tactic to use in your architecture, you are doing so because of the need \nto meet QA requirements. The more difficult and important the QA requirement, the more \nlikely it is to significantly affect the architecture, and hence to be an ASR. Architects must identify ASRs, usually after doing a significant bit of work to uncover \ncandidate ASRs. Competent architects know this. Indeed, as we observe experienced architects \ngoing about their duties, we notice that the first thing they do is start talking to the important \nPART IV Scalable Architecture Practices", "domains": ["Software Quality Attributes", "Domain-Driven Design"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 296", "position": 296, "chunk_type": "semantic", "token_estimate": 355}
{"text": "278 Part IV Scalable Architecture Practices | Chapter 19 Architecturally Significant Requirements: stakeholders. They\u2019re gathering the information they need to produce the architecture that will \nrespond to the project\u2019s needs\u2014whether or not this information has been previously identified. This chapter provides some systematic techniques for identifying the ASRs and other \nfactors that will shape the architecture. 19.1  \nGathering ASRs from Requirements Documents\nAn obvious location to look for candidate ASRs is in the requirements document or in user sto-\nries. After all, we are looking for requirements, and requirements should be (duh) in require-\nments documents. Unfortunately, this is not usually the case, although information in the \nrequirements documents can certainly be useful. Don\u2019t Get Your Hopes Up\nMany projects don\u2019t create or maintain the kind of requirements document that professors in \nsoftware engineering classes or authors of traditional software engineering books love to pre-\nscribe. Furthermore, no architect just sits and waits until the requirements are \u201cfinished\u201d before \nstarting work. The architect must begin while the requirements are still in flux. Consequently, \nthe QA requirements are quite likely to be uncertain when the architect starts work. Even \nwhere they exist and are stable, requirements documents often fail an architect in two ways:\n \n\u25a0Most of the information found in a requirements specification does not affect the archi-\ntecture. As we\u2019ve seen over and over, architectures are mostly driven or \u201cshaped\u201d by QA \nrequirements, which determine and constrain the most important architectural deci-\nsions. Even so, the vast bulk of most requirements specifications focus on the required \nfeatures and functionality of a system, which shape the architecture the least. The best \nsoftware engineering practices do prescribe capturing QA requirements. For example, \nthe Software Engineering Body of Knowledge (SWEBOK) says that QA requirements \nare like any other requirements: They must be captured if they are important, and they \nshould be specified unambiguously and be testable. In practice, though, we rarely see adequate capture of QA requirements. How many \ntimes have you seen a requirement of the form \u201cThe system shall be modular\u201d or \u201cThe \nsystem shall exhibit high usability\u201d or \u201cThe system shall meet users\u2019 performance expecta-\ntions\u201d? These are not useful requirements because they are not testable; they are not falsi-\nfiable. But, looking on the bright side, they can be viewed as invitations for the architect to \nbegin a conversation about what the requirements in these areas really are.", "domains": ["Software Quality Attributes", "Domain-Driven Design"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 297", "position": 297, "chunk_type": "semantic", "token_estimate": 399}
{"text": "19.2 Gathering ASRs by Interviewing Stakeholders 279: scope; you will rarely see a requirements document that describes teaming assumptions, \nfor example. In an acquisition context, the requirements document represents the interests \nof the acquirer, not those of the developer. Stakeholders, the technical environment, and \nthe organization itself all play a role in influencing architectures. When we discuss archi-\ntecture design, in Chapter 20, we will explore these requirements in more detail. Sniffing out ASRs from a Requirements Document\nWhile requirements documents won\u2019t tell an architect the whole story, they are still an import-\nant source of ASRs. Of course, ASRs will not be conveniently labeled as such; the architect \nshould expect to perform a bit of investigation and archaeology to ferret them out. Some specific things to look for are the following categories of information:\n \n\u25a0Usage. User roles versus system modes, internationalization, language distinctions. \u25a0Time. Timeliness and element coordination. \u25a0External elements. External systems, protocols, sensors or actuators (devices), \nmiddleware. \u25a0Networking. Network properties and configurations (including their security properties). \u25a0Orchestration. Processing steps, information flows. \u25a0Security properties. User roles, permissions, authentication. \u25a0Data. Persistence and currency. \u25a0Resources. Time, concurrency, memory footprint, scheduling, multiple users, multiple \nactivities, devices, energy usage, soft resources (e.g., buffers, queues), and scalability \nrequirements. \u25a0Project management. Plans for teaming, skill sets, training, team coordination. \u25a0Hardware choices. Processors, families of processors, evolution of processors. \u25a0Flexibility of functionality, portability, calibrations, configurations. \u25a0Named technologies, commercial packages. Anything that is known about their planned or anticipated evolution will be useful informa-\ntion, too. Not only are these categories architecturally significant in their own right, but the pos-\nsible change and evolution of each are also likely to be architecturally significant. Even if the \nrequirements document you\u2019re mining doesn\u2019t mention evolution, consider which of the items \nin the preceding list are likely to change over time, and design the system accordingly. 19.2  \nGathering ASRs by Interviewing Stakeholders\nSuppose your project isn\u2019t producing a comprehensive requirements document. Or maybe it is, \nbut it won\u2019t have the QAs nailed down by the time you need to start your design work. What \ndo you do?", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 298", "position": 298, "chunk_type": "semantic", "token_estimate": 347}
{"text": "280 Part IV Scalable Architecture Practices | Chapter 19 Architecturally Significant Requirements: First, stakeholders often don\u2019t know what their QA requirements actually are. In that \ncase, architects are called upon to help set the QA requirements for a system. Projects that \nrecognize this need for collaboration and encourage it are much more likely to be successful \nthan those that don\u2019t. Relish the opportunity! No amount of nagging your stakeholders will \nsuddenly instill in them the necessary insights. If you insist on quantitative QA requirements, \nyou may get numbers that are arbitrary and at least some of those requirements will be diffi-\ncult to satisfy and, in the end, actually detract from system success. Experienced architects often have deep insights into which QA responses have been \nexhibited by similar systems, and which QA responses are reasonable to expect and to pro-\nvide in the current context. Architects can also usually give quick feedback as to which QA \nresponses will be straightforward to achieve and which will likely be problematic or even \nprohibitive. For example, a stakeholder may ask for 24/7 availability\u2014who wouldn\u2019t want that? However, the architect can explain how much that requirement is likely to cost, which will \ngive the stakeholders information to make a tradeoff between availability and affordability. Also, architects are the only people in the conversation who can say, \u201cI can actually deliver \nan architecture that will do better than what you had in mind\u2014would that be useful to you?\u201d\nInterviewing the relevant stakeholders is the surest way to learn what they know and \nneed. Once again, it behooves a project to capture this critical information in a systematic, \nclear, and repeatable way. Gathering this information from stakeholders can be achieved by \nmany methods. One such method is the Quality Attribute Workshop (QAW), described in the \nsidebar. The Quality Attribute Workshop\nThe QAW is a facilitated, stakeholder-focused method to generate, prioritize, and refine \nquality attribute scenarios before the software architecture is completed. It emphasizes \nsystem-level concerns and specifically the role that software will play in the system. The \nQAW is keenly dependent on the participation of system stakeholders. After introductions and an overview of the workshop steps, the QAW involves the \nfollowing elements:\n \n\u25a0\nBusiness/mission presentation. The stakeholder representing the business concerns \nbehind the system (typically a manager or management representative) spends about \none hour presenting the system\u2019s business context, broad functional requirements, \nconstraints, and known QA requirements.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 299", "position": 299, "chunk_type": "semantic", "token_estimate": 401}
{"text": "282 Part IV Scalable Architecture Practices | Chapter 19 Architecturally Significant Requirements: A software architect related to us that some years ago he delivered an early \ndraft of the architecture to his manager. The manager remarked that a database was \nmissing from the architecture. The architect, pleased that the manager had noticed, \nexplained how he (the architect) had devised a design approach that obviated the need \nfor a bulky, expensive database. The manager, however, pressed for the design to include \na database, because the organization had a database unit employing a number of highly \npaid technical staff who were currently unassigned and needed work. No requirements \nspecification would capture such a requirement, nor would any manager allow such a \nmotivation to be captured. And yet that architecture, had it been delivered without a \ndatabase, would have been just as deficient\u2014from the manager\u2019s point of view\u2014as if it \nhad failed to deliver an important function or QA.", "domains": ["Domain-Driven Design"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 301", "position": 301, "chunk_type": "semantic", "token_estimate": 156}
{"text": "19.3 Gathering ASRs by Understanding the Business Goals 283: Business goals\nQuality attributes\nArchitecture\nNonarchitectural solutions\n3. No influence of a business goal on the architecture. Not all business goals lead to qual-\nity attributes. For example, a business goal to \u201creduce cost\u201d might be realized by lower-\ning the facility\u2019s thermostats in the winter or reducing employees\u2019 salaries or pensions. Figure 19.1 illustrates the major points from this discussion. In the figure, the arrows \nmean \u201cleads to.\u201d The solid arrows highlight the relationships of greatest interest to architects. FIGURE 19.1 Some business goals may lead to quality attribute requirements, or lead directly \nto architectural decisions, or lead to non-architectural solutions. Architects often become aware of an organization\u2019s business and business goals via \nosmosis\u2014working, listening, talking, and soaking up the goals that are at work in an orga-\nnization. Osmosis is not without its benefits, but more systematic ways of determining such \ngoals are both possible and desirable. Moreover, it is worthwhile to capture business goals \nexplicitly, because they often imply ASRs that would otherwise go undetected until it is too \nlate or too expensive to address them. One way to do this is to employ the PALM method, which entails holding a workshop \nwith the architect and key business stakeholders. The heart of PALM consists of these steps:\n \n\u25a0Business goals elicitation. Using the categories given later in this section to guide the \ndiscussion, capture from stakeholders the set of important business goals for this system. Elaborate the business goals and express them as business goal scenarios.1 Consolidate \nalmost-alike business goals to eliminate duplication. Have the participants prioritize the \nresulting set to identify the most important goals. \u25a0Identify potential QAs from business goals. For each important business goal scenario, \nhave the participants describe a QA and response measure value that (if architected into \nthe system) would help achieve the goal. The process of capturing business goals is well served by having a set of candidate busi-\nness goals handy to use as conversation-starters. If you know that many businesses want to \ngain market share, for instance, you can use that motivation to engage the right stakeholders \nin your organization: \u201cWhat are our ambitions about market share for this product, and how \ncould the architecture contribute to meeting them?\u201d\n1. A business goal scenario is a structured seven-part expression that captures a business goal, similar in intent and \nusage to a QA scenario.", "domains": ["Design Principles"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 302", "position": 302, "chunk_type": "semantic", "token_estimate": 402}
{"text": "284 Part IV Scalable Architecture Practices | Chapter 19 Architecturally Significant Requirements: Our research in business goals has led us to adopt the categories shown in the list that \nfollows. These categories can be used as an aid to brainstorming and elicitation. By employing \nthe list of categories, and asking the stakeholders about possible business goals in each cate-\ngory, some assurance of coverage is gained. 1. Growth and continuity of the organization\n2. Meeting financial objectives\n3. Meeting personal objectives\n4. Meeting responsibility to the employees\n5. Meeting responsibility to society\n6. Meeting responsibility to the state\n7. Meeting responsibility to the shareholders\n8. Managing market position\n9. Improving business processes\n10. Managing the quality and reputation of products\n11. Managing change in the environment over time\n \n19.4  \nCapturing ASRs in a Utility Tree\nIn a perfect world, the techniques described in Sections 19.2 and 19.3 would be applied early \non in your development process: You would interview the key stakeholders, elicit their busi-\nness goals and driving architectural requirements, and have them prioritize all of these inputs \nfor you. Of course, the real world, lamentably, is less than perfect. It is often the case that you \ndo not have access to these stakeholders when you need them, for organizational or business \nreasons. So what do you do? Architects can use a construct called a utility tree when the \u201cprimary sources\u201d of require-\nments are not available. A utility tree is a top-down representation of what you, as an architect, \nbelieve to be the QA-related ASRs that are critical to the success of the system. A utility tree begins with the word \u201cUtility\u201d as the root node. Utility is an expression of \nthe overall \u201cgoodness\u201d of the system. You then elaborate on this root node by listing the major \nQAs that the system is required to exhibit. (You might recall that we said in Chapter 3 that QA \nnames by themselves were not very useful. Never fear\u2014they are only being used as intermedi-\nate placeholders for subsequent elaboration and refinement!) Under each QA, record specific refinements of that QA. For example, performance might \nbe decomposed into \u201cdata latency\u201d and \u201ctransaction throughput\u201d or, alternatively, \u201cuser wait \ntime\u201d and \u201ctime to refresh web page.\u201d The refinements that you choose should be the ones that \nare relevant to your system. Under each refinement, you can then record the specific ASRs, \nexpressed as QA scenarios.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 303", "position": 303, "chunk_type": "semantic", "token_estimate": 402}
{"text": "284 Part IV Scalable Architecture Practices | Chapter 19 Architecturally Significant Requirements: For example, performance might \nbe decomposed into \u201cdata latency\u201d and \u201ctransaction throughput\u201d or, alternatively, \u201cuser wait \ntime\u201d and \u201ctime to refresh web page.\u201d The refinements that you choose should be the ones that \nare relevant to your system. Under each refinement, you can then record the specific ASRs, \nexpressed as QA scenarios. Once the ASRs are recorded as scenarios and placed at the leaves of the tree, you can \nevaluate these scenarios against two criteria: the business value of the candidate scenario and \nthe technical risk of achieving it. You can use any scale you like, but we find that a simple \u201cH\u201d \n(high), \u201cM\u201d (medium), and \u201cL\u201d (low) scoring system suffices for each criterion. For business", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 303", "position": 303, "chunk_type": "semantic", "token_estimate": 129}
{"text": "19.4 Capturing ASRs in a Utility Tree 285: value, \u201chigh\u201d designates a must-have requirement, \u201cmedium\u201d identifies a requirement that is \nimportant but would not lead to project failure were it omitted, and \u201clow\u201d describes a nice \nrequirement to meet but not something worth much effort. For technical risk, \u201chigh\u201d means \nthat meeting this ASR is keeping you awake at night, \u201cmedium\u201d means meeting this ASR is \nconcerning but does not carry a high risk, and \u201clow\u201d means that you have confidence in your \nability to meet this ASR. Table 19.1 shows a portion of an example utility tree. Each ASR is labeled with an indica-\ntor of its business value and its technical risk. TABLE 19.1 Tabular Form of the Utility Tree for a System in the Healthcare Space\nQuality \nAttribute\nAttribute \nRefinement \nASR Scenario\nPerformance \nTransaction \nresponse time\nA user updates a patient\u2019s account in response to a change-\nof-address notification while the system is under peak load, \nand the transaction completes in less than 0.75 seconds. (H, H)\nThroughput \nAt peak load, the system is able to complete 150 normalized \ntransactions per second. (M, M)\nUsability \nProficiency training\nA new hire with two or more years\u2019 experience in the \nbusiness can learn, with 1 week of training, to execute any \nof the system\u2019s core functions in less than 5 seconds. (M, L)\nEfficiency of \noperations\nA hospital payment officer initiates a payment plan for a \npatient while interacting with that patient and completes the \nprocess with no input errors. (M, M)\nConfigurability \nData configurability\nA hospital increases the fee for a particular service. The \nconfiguration team makes and tests the change in 1 working \nday; no source code needs to change. (H, L)\nMaintainability\nRoutine changes\nA maintainer encounters response-time deficiencies, fixes \nthe bug, and distributes the bug fix with no more than \n3 person-days of effort. (H, M)\nA reporting requirement requires a change to the report-\ngenerating metadata. Change is made and tested in \n4 person-hours of effort (M, L)\nUpgrades to \ncommercial \ncomponents\nThe database vendor releases a new major version that \nis successfully tested and installed in less than 3 person-\nweeks. (H, M)\nAdding new \nfeature\nA feature that tracks blood bank donors is created and \nsuccessfully integrated within 2 person-months. (M, M)\nSecurity \nConfidentiality \nA physical therapist is allowed to see that part of a patient\u2019s \nrecord dealing with orthopedic treatment, but not other parts \nor any financial information.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 304", "position": 304, "chunk_type": "semantic", "token_estimate": 407}
{"text": "19.4 Capturing ASRs in a Utility Tree 285: (H, M)\nAdding new \nfeature\nA feature that tracks blood bank donors is created and \nsuccessfully integrated within 2 person-months. (M, M)\nSecurity \nConfidentiality \nA physical therapist is allowed to see that part of a patient\u2019s \nrecord dealing with orthopedic treatment, but not other parts \nor any financial information. (H, M)\nResisting attacks\nThe system repels an unauthorized intrusion attempt and \nreports the attempt to authorities within 90 seconds. (H, M)\nAvailability\nNo down time\nThe database vendor releases new software, which is hot-\nswapped into place, with no downtime. (H, L)\nThe system supports 24/7/365 web-based account access \nby patients. (M, M)", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 304", "position": 304, "chunk_type": "semantic", "token_estimate": 111}
{"text": "286 Part IV Scalable Architecture Practices | Chapter 19 Architecturally Significant Requirements: Once you have a utility tree filled out, you can use it to make important checks. For \ninstance:\n \n\u25a0A QA or QA refinement without any ASR scenario is not necessarily an error or omis-\nsion that needs to be rectified, but rather an indication you should investigate whether \nthere are unrecorded ASR scenarios in that area. \u25a0ASR scenarios that receive a (H, H) rating are obviously the ones that deserve the most \nattention from you; these are the most significant of the significant requirements. A very \nlarge number of these scenarios might be a cause for concern regarding whether the \nsystem is, in fact, achievable. 19.5  \nChange Happens\nEdward Berard said, \u201cWalking on water and developing software from a specification are both \neasy if both are frozen.\u201d Nothing in this chapter should be taken to assume that such a mirac-\nulous state of affairs is likely to exist. Requirements\u2014whether captured or not\u2014change all \nthe time. Architects have to adapt and keep up, to ensure that their architectures are still the \nright ones that will bring success to the project. In Chapter 25, where we discuss architecture \ncompetence, we\u2019ll advise that architects need to be great communicators, and this means great \nbidirectional communicators, taking in as well as supplying information. Always keep a chan-\nnel open to the key stakeholders who determine the ASRs so you can keep up with changing \nrequirements. The methods offered in this chapter can be applied repetitively to accommodate \nchange. Even better than keeping up with change is staying one step ahead of it. If you get wind of \na change to the ASRs, you can take preliminary steps to design for it, as an exercise to under-\nstand the implications. If the change will be prohibitively expensive, sharing that information \nwith the stakeholders will be a valuable contribution, and the earlier they know it, the better. Even more valuable might be suggestions about changes that would do (almost) as well in \nmeeting the goals but without breaking the budget. 19.6  \nSummary\nArchitectures are driven by architecturally significant requirements. An ASR must have:\n \n\u25a0A profound impact on the architecture. Including this requirement will likely result in a \ndifferent architecture than if it were not included. \u25a0A high business or mission value. If the architecture is going to satisfy this requirement\u2014\npotentially at the expense of not satisfying others\u2014it must be of high value to important \nstakeholders.", "domains": ["Design Patterns", "Domain-Driven Design"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 305", "position": 305, "chunk_type": "semantic", "token_estimate": 412}
{"text": "288 Part IV Scalable Architecture Practices | Chapter 19 Architecturally Significant Requirements: 3. Create a utility tree for an ATM. (Interview some of your friends and colleagues if you \nwould like to have them contribute QA considerations and scenarios.) Consider a min-\nimum of four different QAs. Ensure that the scenarios that you create at the leaf nodes \nhave explicit responses and response measures. 4. Find a software requirements specification that you consider to be of high quality. Using colored pens (real ones if the document is printed; virtual ones if the document \nis online), color red all the material that you find completely irrelevant to a software \narchitecture for that system. Color yellow all of the material that you think might be rel-\nevant, but not without further discussion and elaboration. Color green all of the material \nthat you are certain is architecturally significant. When you\u2019re done, every part of the \ndocument that\u2019s not white space should be red, yellow, or green. Approximately what \npercentage of each color did your document end up being? Do the results surprise you?", "domains": ["Domain-Driven Design"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 307", "position": 307, "chunk_type": "semantic", "token_estimate": 180}
{"text": "290: Part IV Scalable Architecture Practices | Chapter 20 Designing an Architecture\nAllocation\nThe Architect\n<<gathers>>\nDesign Concepts\nStructures\nArchitectural Drivers\nWork Assignment\nDeployment\nImplementation\n. . . Component-and-Connector\nClient-Server\nConcurrency\nProcess\nShared Data\n. . . Module\nReference\nArchitectures\nExternally\nDeveloped\nComponents\nTactics\nPatterns\nUses\nDecomposition\nLayered\nClass/Generalization\n. . . Architectural Concerns\nConstraints\nQuality Attributes\nPrimary Functionality\nDesign Purpose\n<<produces>>\n<<selects and\ninstantiates>>\nserve as the foundation for educating a new project member. They guide cost and schedule \nestimations, team formation, risk analysis and mitigation, and, of course, implementation. FIGURE 20.1 Overview of the architecture design activity\nPrior to starting architecture design, it is important to determine the scope of the system\u2014\nwhat is inside and what is outside of the system you are creating, and which external entities the \nsystem will interact with. This context can be represented using a system context diagram, like \nthat shown in Figure 20.2. Context diagrams are discussed in more detail in Chapter 22. System Being\nDesigned\nUser\nWorkstation\nSystem under development\nExternal system\n'DWD\u0003\u0183RZ\nKey\nExternal\nServices\nDatabase\nServer\nFIGURE 20.2 Example of a system context diagram", "domains": ["Architectural Patterns and Styles", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 309", "position": 309, "chunk_type": "semantic", "token_estimate": 186}
{"text": "292 Part IV Scalable Architecture Practices | Chapter 20 Designing an Architecture: 20.2  \nThe Steps of ADD\nThe sections that follow describe the steps for ADD. Step 1: Review Inputs\nBefore starting a design round, you need to ensure that the architectural drivers (the inputs to \nthe design process) are available and correct. These include:\n \n\u25a0The purpose of the design round\n \n\u25a0The primary functional requirements\n \n\u25a0The primary quality attribute (QA) scenarios\n \n\u25a0Any constraints\n \n\u25a0Any concerns\nWhy do we explicitly capture the design purpose? You need to make sure that you are \nclear about your goals for a round. In an incremental design context comprising multiple \nrounds, the purpose for a design round may be, for example, to produce a design for early \nestimation, to refine an existing design to build a new increment of the system, or to design \nand generate a prototype to mitigate certain technical risks. In addition, you need to know the \nexisting architecture\u2019s design, if this is not greenfield development. At this point, the primary functionality\u2014typically captured as a set of use cases or user \nstories\u2014and QA scenarios should have been prioritized, ideally by your most important proj-\nect stakeholders. (You can employ several different techniques to elicit and prioritize them, as \ndiscussed in Chapter 19). You, the architect, must now \u201cown\u201d these. For example, you need to \ncheck whether any important stakeholders were overlooked in the original requirements elici-\ntation process, and whether any business conditions have changed since the prioritization was \nperformed. These inputs really do \u201cdrive\u201d design, so getting them right and getting their prior-\nity right are crucial. We cannot stress this point strongly enough. Software architecture design, \nlike most activities in software engineering, is a \u201cgarbage-in-garbage-out\u201d process. The results \nof ADD cannot be good if the inputs are poorly formed. The drivers become part of an architectural design backlog that you should use to per-\nform the different design iterations. When you have made design decisions that account for all \nof the items in the backlog, you\u2019ve completed this round. (We discuss the idea of a backlog in \nmore depth in Section 20.8.) Steps 2\u20137 make up the activities for each design iteration carried out within this design \nround. Step 2: Establish Iteration Goal by Selecting Drivers\nEach design iteration focuses on achieving a particular goal. Such a goal typically involves \ndesigning to satisfy a subset of the drivers.", "domains": ["Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 311", "position": 311, "chunk_type": "semantic", "token_estimate": 398}
{"text": "292 Part IV Scalable Architecture Practices | Chapter 20 Designing an Architecture: Step 2: Establish Iteration Goal by Selecting Drivers\nEach design iteration focuses on achieving a particular goal. Such a goal typically involves \ndesigning to satisfy a subset of the drivers. For example, an iteration goal could be to create \nstructures from elements that will allow a particular performance scenario, or a use case to", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 311", "position": 311, "chunk_type": "semantic", "token_estimate": 66}
{"text": "294 Part IV Scalable Architecture Practices | Chapter 20 Designing an Architecture: Step 5: Instantiate Architectural Elements, Allocate Responsibilities, and \nDefine Interfaces\nOnce you have selected one or more design concepts, you must make another type of design \ndecision: how to instantiate elements out of the design concepts that you just selected. For \nexample, if you selected the layers pattern as a design concept, you must decide how many \nlayers will be used, and their allowed relationships, since the pattern itself does not prescribe \nthese. After instantiating the elements, you then need to allocate responsibilities to each of \nthem. For example, in an app, at least three layers are usually present: presentation, business, \nand data. The responsibilities of these layers differ: The responsibilities of the presentation \nlayer include managing all of the user interactions, the business layer manages application \nlogic and enforces business rules, and the data layer manages the persistence and consistency \nof data. Instantiating elements is only one part of creating structures that satisfy a driver or a \nconcern. The elements that have been instantiated also need to be connected, thereby allowing \nthem to collaborate with each other. This requires the existence of relationships between the \nelements and the exchange of information through some kind of interface. The interface is a \ncontractual specification indicating how information should flow between the elements. In \nSection 20.4, we present more details on how the different types of design concepts are instan-\ntiated, how structures are created, and how interfaces are defined. Step 6: Sketch Views and Record Design Decisions\nAt this point, you have finished performing the design activities for the iteration. However, you \nmay have not taken any actions to ensure that the views\u2014the representations of the structures \nyou created\u2014are preserved. For instance, if you performed step 5 in a conference room, you \nprobably ended up with a series of diagrams on a whiteboard. This information is essential to \nthe rest of the process, and you must capture it so that you can later analyze and communi-\ncate it to other stakeholders. Capturing the views may be as simple as taking a picture of the \nwhiteboard. The views that you have created are almost certainly not complete; thus, these diagrams \nmay need to be revisited and refined in a subsequent iteration. This is typically done to accom-\nmodate elements resulting from other design decisions that you will make to support addi-\ntional drivers.", "domains": ["Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 313", "position": 313, "chunk_type": "semantic", "token_estimate": 403}
{"text": "20.3 More on ADD Step 4: Choose One or More Design Concepts 295: preliminary documentation during the design process, including recording design decisions \nand their rationale. Step 7: Perform Analysis of Current Design and Review Iteration Goal and \nAchievement of Design Purpose\nBy step 7, you should have created a partial design that addresses the goal established for the \niteration. Making sure that this is actually the case is a good idea, to avoid unhappy stakehold-\ners and later rework. You can perform the analysis yourself by reviewing the sketches of the \nviews and design decisions that you captured, but an even better idea is to have someone else \nhelp you review this design. We do this for the same reason that organizations frequently have \na separate testing/quality assurance group: Another person will not share your assumptions, \nand will have a different experience base and a different perspective. This diversity helps to \nfind \u201cbugs,\u201d in both code and architecture. We discuss architectural analysis in more depth in \nChapter 21. Once the design performed in the iteration has been analyzed, you should review the \nstate of your architecture in terms of your established design purpose. This means consid-\nering if, at this point, you have performed enough design iterations to satisfy the drivers that \nare associated with the design round. It also means considering whether the design purpose \nhas been achieved or if additional design rounds are needed in future project increments. In \nSectionb20.6, we discuss simple techniques that allow you to keep track of design progress. Iterate If Necessary\nYou should perform additional iterations and repeat steps 2\u20137 for every driver that was con-\nsidered. More often than not, however, this kind of repetition will not be possible because \nof time or resource constraints that force you to stop the design activities and move on to \nimplementation. What are the criteria for evaluating if more design iterations are necessary? Let risk \nbe your guide. You should at least have addressed the drivers with the highest priority. Ideally, \nyou should have certainty that critical drivers are satisfied or, at least, that the design is \u201cgood \nenough\u201d to satisfy them. 20.3  \nMore on ADD Step 4: Choose One or More Design Concepts\nMost of the time you, as an architect, don\u2019t need to, and should not, reinvent the wheel.", "domains": ["Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 314", "position": 314, "chunk_type": "semantic", "token_estimate": 387}
{"text": "296 Part IV Scalable Architecture Practices | Chapter 20 Designing an Architecture: an existing corpus of solutions to choose from\u2014and we are not always blessed with a rich \n \ncorpus\u2014this is still the hardest part of design. Identification of Design Concepts\nThe identification of design concepts might appear daunting, because of the vast number of \noptions available. There are likely dozens of design patterns and externally developed compo-\nnents that you could use to address any particular issue. To make things worse, these design \nconcepts are scattered across many different sources: in practitioner blogs and websites, in \nresearch literature, and in books. Moreover, in many cases, there is no canonical definition \nof a concept. Different sites, for example, will define the broker pattern in different, largely \ninformal ways. Finally, once you have identified the alternatives that can potentially help you \nachieve the design goals of the iteration, you need to select the best one(s) for your purposes. To address a specific design problem, you can and often will use and combine different \ntypes of design concepts. For example, to build a security driver, you might employ a security \npattern, a security tactic, a security framework, or some combination of these. Once you have more clarity regarding the types of design concepts that you wish to use, \nyou still need to identify alternatives\u2014that is, design candidates. You can achieve this in sev-\neral ways, although you will probably use a combination of these techniques rather than a \nsingle method:\n \n\u25a0Leverage existing best practices. You can identify alternatives by making use of existing \ncatalogs. Some design concepts, such as patterns, are extensively documented; others, \nsuch as externally developed components, are documented in a less thorough way. The \nbenefits of this approach are that you can identify many alternatives and leverage the \nconsiderable knowledge and experience of others. The downsides are that searching and \nstudying the information can require a considerable amount of time, the quality of the \ndocumented knowledge is often unknown, and the assumptions and biases of the authors \nare also unknown. \u25a0Leverage your own knowledge and experience. If the system you are designing is similar \nto other systems you have designed in the past, you will probably want to begin with \nsome of the design concepts that you have used before. The benefit of this approach \nis that the identification of alternatives can be performed rapidly and confidently.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 315", "position": 315, "chunk_type": "semantic", "token_estimate": 397}
{"text": "20.3 More on ADD Step 4: Choose One or More Design Concepts 297: Selection of Design Concepts\nOnce you have identified a list of alternative design concepts, you need to select which one of \nthe alternatives is the most appropriate to solve the design problem at hand. You can achieve \nthis in a relatively simple way, by creating a table that lists the pros and cons associated with \neach alternative and selecting one of the alternatives based on those criteria and your drivers. The table can also contain other criteria, such as the cost associated with the use of the alterna-\ntive. Methods such as SWOT (strengths, weaknesses, opportunities, threats) analysis can help \nyou make this decision. When identifying and selecting design concepts, keep in mind the constraints that are \npart of the architectural drivers, because some constraints will restrict you from selecting par-\nticular alternatives. For example, a constraint might be that all libraries and frameworks must \nemploy an approved license. In that case, even if you have found a framework that could be \nuseful for your needs, you may need to discard it if it does not carry an approved license. You also need to keep in mind that the decisions regarding the selection of design con-\ncepts that you made in previous iterations may restrict the design concepts that you can now \nselect due to incompatibilities. An example would be selecting a web architecture in an initial \niteration and then selecting a user interface framework for local applications in a subsequent \niteration. Creation of Prototypes\nIn case the previously mentioned analysis techniques do not guide you to make an appropriate \nselection of design concepts, you may need to create prototypes and collect measurements \nfrom them. Creating early \u201cthrowaway\u201d prototypes is a useful technique to help in the selec-\ntion of externally developed components. This type of prototype is usually created without \nconsideration for maintainability, reuse, or allowance for achieving other important goals. Such a prototype should not be used as a basis for further development. Although the creation of prototypes can be costly, certain scenarios strongly motivate \nthem. When thinking about whether you should create a prototype, ask these questions:\n \n\u25a0Does the project incorporate emerging technologies? \u25a0Is the technology new in the company? \u25a0Are there certain drivers, particularly QAs, whose satisfaction using the selected tech-\nnology presents risks (i.e., it is not understood whether they can be satisfied)?", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 316", "position": 316, "chunk_type": "semantic", "token_estimate": 401}
{"text": "20.3 More on ADD Step 4: Choose One or More Design Concepts 297: \u25a0Is the technology new in the company? \u25a0Are there certain drivers, particularly QAs, whose satisfaction using the selected tech-\nnology presents risks (i.e., it is not understood whether they can be satisfied)? \u25a0Is there a lack of trusted information, internal or external, that would provide some \ndegree of certainty that the selected technology will be useful to satisfy the project \ndrivers? \u25a0Are there configuration options associated with the technology that need to be tested or \nunderstood? \u25a0Is it unclear whether the selected technology can be easily integrated with other technol-\nogies that are used in the project? If most of your answers to these questions are \u201cyes,\u201d then you should strongly consider the \ncreation of a throwaway prototype.", "domains": ["Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 316", "position": 316, "chunk_type": "semantic", "token_estimate": 131}
{"text": "298 Part IV Scalable Architecture Practices | Chapter 20 Designing an Architecture: To Prototype or Not to Prototype? Architectural decisions must often be made with imperfect knowledge. To decide which \nway to go, a team could run a series of experiments (such as building prototypes) to try \nto reduce their uncertainty about which path to follow. The problem is that such experi-\nments could carry a substantial cost, and the conclusions drawn from them might not be \ndefinitive. For example, suppose a team needs to decide whether the system they are design-\ning should be based on a traditional three-tier architecture or should be composed \nof microservices. Since it is the team\u2019s first project with microservices, they are not \nconfident about that approach. They do a cost estimation for the two alternatives, and \nproject that the cost of developing the three-tier architecture would be $500,000 and \nthat of developing the microservices would be $650,000. If, having developed the three-\ntier architecture, the team later concluded that the wrong architecture was chosen, the \nestimated refactoring cost would be $300,000. If the microservices architecture was the \nfirst one developed, and a later refactoring was needed, its estimated additional cost \nwould be $100,000. What should the team do? To decide whether it is worth it to conduct the experiments, or how much we should \nbe willing to spend on experimentation in relation to the confidence to be gained and the \ncost of being wrong, the team could use a technique known as Value of Information (VoI) \nto settle the questions. The VoI technique is used to calculate the expected gain from a \nreduction in the uncertainty surrounding a decision through some form of data collection \nexercise\u2014in this case, the construction of prototypes. To use VoI, the team will need to \nassess the following parameters: the cost of making the wrong design choice, the cost \nof performing the experiments, the team\u2019s level of confidence in each design choice, and \ntheir level of confidence in the results of the experiments. Using these estimates, VoI \nthen applies Bayes\u2019s Theorem to calculate two quantities: the expected value of perfect \ninformation (EVPI) and the expected value of sample or imperfect information (EVSI). EVPI denotes the maximum one should be willing to pay for the experiments, were they to \nprovide definitive results (e.g., no false positives or false negatives).", "domains": ["Architectural Patterns and Styles", "Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 317", "position": 317, "chunk_type": "semantic", "token_estimate": 390}
{"text": "20.4 More on ADD Step 5: Producing Structures 299: that the architecture of a software system is composed of a set of structures. As we saw in \nChapter 1, these structures can be grouped into three major categories:\n \n\u25a0Module structures, which are composed of elements that exist at development time, such \nas files, modules, and classes\n \n\u25a0Component and connector (C&C) structures, which are composed of elements that exist \nat runtime, such as processes and threads\n \n\u25a0Allocation structures, which are composed of both software elements (from a module \nor C&C structure) and non-software elements that may exist both at development and at \nruntime, such as file systems, hardware, and development teams\nWhen you instantiate a design concept, you may actually affect more than one structure. For example, in a particular iteration, you might instantiate the passive redundancy (warm \nspare) pattern, introduced in Chapter 4. This will result in both a C&C structure and an alloca-\ntion structure. As part of applying this pattern, you will need to choose the number of spares, \nthe degree to which the state of the spares is kept consistent with that of the active node, a \nmechanism for managing and transferring state, and a mechanism for detecting the failure \nof a node. These decisions are responsibilities that must live somewhere in the elements of a \nmodule structure. Instantiating Elements\nHere\u2019s how instantiation might look for each of the design concept categories:\n \n\u25a0Reference architectures. In the case of reference architectures, instantiation typically \nmeans that you perform some sort of customization. This will require you to add or \nremove elements that are part of the structure that is defined by the reference architec-\nture. For example, if you are designing a web application that needs to communicate \nwith an external application to handle payments, you will probably need to add an inte-\ngration component alongside the traditional presentation, business, and data tiers. \u25a0Patterns. Patterns provide a generic structure composed of elements, along with their \nrelationships and their responsibilities. As this structure is generic, you will need to \nadapt it to your specific problem. Instantiation usually involves transforming the generic \nstructure defined by the pattern into a specific one that is adapted to the needs of the \nproblem you are solving. For example, consider the client-server architectural pattern.", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 318", "position": 318, "chunk_type": "semantic", "token_estimate": 379}
{"text": "20.4 More on ADD Step 5: Producing Structures 299: Instantiation usually involves transforming the generic \nstructure defined by the pattern into a specific one that is adapted to the needs of the \nproblem you are solving. For example, consider the client-server architectural pattern. It \nestablishes the basic elements of computation (i.e., clients and servers) and their relation-\nships (i.e., connection and communication), but does not specify how many clients or \nservers you should use for your problem, or what the functionality of each should be, or \nwhich clients should talk to which servers, or which communication protocol they should \nuse. Instantiation fills in these blanks. \u25a0Tactics. This design concept does not prescribe a particular structure. Thus, to instanti-\nate a tactic, you may adapt a different type of design concept (that you\u2019re already using) \nto realize the tactic. Alternatively, you may utilize a design concept that, without any \nneed for adaptation, already realizes the tactic. For example, you might (1) select a secu-\nrity tactic of authenticating actors and instantiate it through a custom-coded solution \nthat you weave into your preexisting login process; or (2) adopt a security pattern that", "domains": ["Architectural Patterns and Styles", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 318", "position": 318, "chunk_type": "semantic", "token_estimate": 190}
{"text": "300 Part IV Scalable Architecture Practices | Chapter 20 Designing an Architecture: includes actor authentication; or (3) integrate an externally developed component such as \na security framework that authenticates actors. \u25a0Externally developed components. The instantiation of these components may or not \nimply the creation of new elements. For example, in the case of object-oriented frame-\nworks, instantiation may require you to create new classes that inherit from the base \nclasses defined in the framework. This will result in new elements. An example that does \nnot involve the creation of new elements is specifying configuration options for a chosen \ntechnology, such as the number of threads in a thread pool. Associating Responsibilities and Identifying Properties\nWhen you are creating elements by instantiating design concepts, you need to consider the \nresponsibilities that are allocated to these elements. For example, if you instantiate the micro-\nservices architecture pattern (Chapter 5), you need to decide what the microservices will do, how \nmany of each you will deploy, and what the properties of those microservices will be. When \ninstantiating elements and allocating responsibilities, you should keep in mind the design \nprinciple that elements should have high cohesion (internally), be defined by a narrow set of \nresponsibilities, and demonstrate low coupling (externally). An important aspect that you need to consider when instantiating design concepts is the \nproperties of the elements. This may involve aspects such as the configuration options, state-\nfulness, resource management, priority, or even hardware characteristics (if the elements that \nyou created are physical nodes) of the chosen technologies. Identifying these properties sup-\nports analysis and the documentation of your design rationale. Establishing Relationships between the Elements\nThe creation of structures also requires making decisions with respect to the relationships \nthat exist between the elements and their properties. Consider again the client-server pattern. In instantiating this pattern, you need to decide which clients will talk to which servers, via \nwhich ports and protocols. You also need to decide whether communication will be synchro-\nnous or asynchronous. Who initiates interactions? How much information is transferred and at \nwhat rate? These design decisions can have a significant impact with respect to achieving QAs such \nas performance. Defining Interfaces\nInterfaces establish a contractual specification that allows elements to collaborate and exchange \ninformation. They may be either external or internal. External interfaces are interfaces of other systems with which your system must interact. These may form constraints for your system, since you usually cannot influence their spec-\nification.", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Software Quality Attributes", "Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 319", "position": 319, "chunk_type": "semantic", "token_estimate": 410}
{"text": "20.5 More on ADD Step 6: Creating Preliminary Documentation during the Design 301: process is useful to identify external interfaces. Since external entities and the system under \ndevelopment interact via interfaces, there should be at least one external interface per external \nsystem (as shown in Figure 20.2). Internal interfaces are interfaces between the elements that result from the instantiation \nof design concepts. To identify the relationships and the interface details, you need to under-\nstand how the elements interact with each other to support use cases or QA scenarios. As we \nsaid in Chapter 15 in our discussion of software Interfaces, \u201cinteracts\u201d means anything one \nelement does that can impact the processing of another element. A particularly common type \nof interaction is the runtime exchange of information. Behavioral representations such as UML sequence diagrams, statecharts, and activity \ndiagrams (see Chapter 22) allow you to model the information that is exchanged between ele-\nments during execution. This type of analysis is also useful to identify relationships between \nelements: If two elements need to exchange information directly or otherwise depend on each \nother, then a relationship between these elements exists. Any information that is exchanged \nbecomes part of the specification of the interface. The identification of interfaces is usually not performed equally across all design iterations. When you are starting the design of a greenfield system, for example, your first iterations will \nproduce only abstract elements such as layers; these elements will then be refined in later \niterations. The interfaces of abstract elements such as layers are typically underspecified. For \nexample, in an early iteration you might simply specify that the UI tier sends \u201ccommands\u201d \nto the business logic tier, and the business logic tier sends \u201cresults\u201d back. As the design pro-\ncess proceeds, and particularly when you create structures to address specific use cases and \nQA scenarios, you will need to refine the interfaces of the elements that participate in these \ninteractions. In some special cases, identifying the appropriate interfaces may be greatly simplified. For example, if you choose a complete technology stack or a set of components that have been \ndesigned to interoperate, then the interfaces will already be defined by those technologies. In \nsuch a case, the specification of interfaces is a relatively trivial task, as the chosen technolo-\ngies have \u201cbaked in\u201d many interface assumptions and decisions. Finally, be aware that not all of the internal interfaces need to be identified in any given \nADD iteration.", "domains": ["Design Patterns", "Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 320", "position": 320, "chunk_type": "semantic", "token_estimate": 408}
{"text": "20.5 More on ADD Step 6: Creating Preliminary Documentation during the Design 301: In \nsuch a case, the specification of interfaces is a relatively trivial task, as the chosen technolo-\ngies have \u201cbaked in\u201d many interface assumptions and decisions. Finally, be aware that not all of the internal interfaces need to be identified in any given \nADD iteration. Some may be delegated to later design activities. 20.5  \nMore on ADD Step 6: Creating Preliminary Documentation \nduring the Design\nAs we will see in Chapter 22, software architecture is documented as a set of views, which \nrepresent the different structures that compose the architecture. The formal documentation of \nthese views is not part of ADD. Structures, however, are produced as part of design. Capturing \nthem, even if they are represented informally (as sketches), along with the design decisions that \nled you to create these structures, is a task that should be performed as part of normal ADD \nactivities.", "domains": ["Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 320", "position": 320, "chunk_type": "semantic", "token_estimate": 157}
{"text": "302 Part IV Scalable Architecture Practices | Chapter 20 Designing an Architecture: Master\nDataset\nBatch\nViews\nPre-\ncomputing\nQuery\nand\nReporting\nReal-Time\nViews\nBatch\nServing\nSpeed\nComponent boundary\nKey\nElement boundary\n'DWD\u0003\u0183RZ\nData\nStream\nRecording Sketches of the Views\nWhen you produce structures by instantiating the design concepts that you have selected \nto address a particular design problem, you will typically not only produce these structures \nin your mind but also create some sketches of them. In the simplest case, you will produce \nthese sketches on a whiteboard, a flipchart, a drawing tool, or even just a piece of paper. Additionally, you may use a modeling tool to draw the structures in a more rigorous way. The \nsketches that you produce are an initial documentation for your architecture that you should \ncapture and that you may flesh out later, if necessary. When you create sketches, you don\u2019t \nnecessarily need to use a more formal language such as UML\u2014although if you\u2019re fluent and \ncomfortable with this process, please do so. If you use some informal notation, you should be \ncareful in maintaining consistency in the use of symbols. Eventually, you will need to add a \nlegend to your diagrams to provide clarity and avoid ambiguity. You should develop a discipline of writing down the responsibilities that you allocate \nto the elements as you create the structures. The reasons for this are simple: As you identify \nan element, you are determining some responsibilities for that element in your mind. Writing \nthem down at that moment ensures that you won\u2019t have to remember the intended responsi-\nbilities later. Also, it is easier to write down the responsibilities associated with your elements \ngradually, rather than documenting all of them together at a later time. Creating this preliminary documentation as you design the architecture requires some \ndiscipline. The benefits are worth the effort, though, as you will be able to later produce the \nmore detailed architecture documentation relatively easily and quickly. One simple way to \ndocument responsibilities, if you are using a whiteboard or a flipchart, is to take a photo of the \nsketch that you have produced and paste it in a document, along with a table that summarizes \nthe responsibilities of every element depicted in the diagram (see an example in Figure 20.4).", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 321", "position": 321, "chunk_type": "semantic", "token_estimate": 380}
{"text": "20.5 More on ADD Step 6: Creating Preliminary Documentation during the Design 303: The diagram is complemented by a table that describes the element\u2019s responsibilities. Table 20.1 serves this purpose for some of the elements identified in Figure 20.4. TABLE 20.1 Elements and Responsibilities\nElement\nResponsibility\nData Stream\nThis element collects data from all data sources in real time, and dispatches it to \nboth the Batch Component and the Speed Component for processing. Batch \nThis is responsible for storing raw data and pre-computing the Batch Views to be \nstored in the Serving Component. . . . . . . Of course, it\u2019s not necessary to document everything at this stage. The three purposes of \ndocumentation are analysis, construction, and education. At the moment you are designing, \nyou should choose a documentation purpose and then document to fulfill that purpose, based \non your risk mitigation concerns. For example, if you have a critical QA scenario that your \narchitecture design needs to meet, and if you will need to prove the proposed design satisfies \nthis criterion in an analysis, then you must take care to document the information that is rel-\nevant for the analysis to be satisfactory. Likewise, if you anticipate having to train new team \nmembers, then you should sketch a C&C view of the system, showing how it operates and how \nthe elements interact at runtime, and perhaps a module view of the system, showing at least the \nmajor layers or subsystems. Finally, remember as you are documenting that your design may eventually be analyzed. Consequently, you need to think about which information should be documented to support \nthis analysis. Recording Design Decisions\nIn each design iteration, you will make important design decisions to achieve your iteration goal. When you study a diagram that represents an architecture, you might see the end product of a \nthought process but can\u2019t always easily understand the decisions that were made to achieve this \nresult. Recording design decisions beyond the representation of the chosen elements, relation-\nships, and properties is fundamental to help clarify how you arrived at the result\u2014that is, the \ndesign rationale. We delve into this topic in detail in Chapter 22.", "domains": ["Design Patterns", "Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 322", "position": 322, "chunk_type": "semantic", "token_estimate": 361}
{"text": "304 Part IV Scalable Architecture Practices | Chapter 20 Designing an Architecture: 20.6  \nMore on ADD Step 7: Perform Analysis of the Current \nDesign and Review the Iteration Goal and Achievement of \nthe Design Purpose\nAt the end of an iteration, it is prudent to do some analysis to reflect on the design decisions \nthat you just made. We describe several techniques to do so in Chapter 21. One kind of anal-\nysis that you need to perform at this point is to assess whether you have done enough design \nwork. In particular:\n \n\u25a0How much design do you need to do? \u25a0How much design have you done so far? \u25a0Are you finished? Practices such as the use of backlogs and Kanban boards can help you track the design \nprogress and answer these questions. Use of an Architectural Backlog\nAn architectural backlog is a to-do list of the pending actions that still need to be performed \nas part of the architecture design process. Initially, you should populate the design backlog \nwith your drivers, but other activities that support the design of the architecture can also be \nincluded\u2014for example:\n \n\u25a0Creation of a prototype to test a particular technology or to address a specific QA risk\n \n\u25a0Exploration and understanding of existing assets (possibly requiring reverse engineering)\n \n\u25a0Issues uncovered in a review of the design decisions made to this point\nAlso, you may add more items to the backlog as decisions are made. As a case in point, \nif you choose a reference architecture, you will probably need to add specific concerns, or QA \nscenarios derived from them, to the architectural design backlog. For example, if we choose a \nweb application reference architecture and discover that it does not provide session manage-\nment, then that becomes a concern that needs to be added to the backlog. Use of a Design Kanban Board\nAnother tool that can be used to track design progress is a Kanban board, such as the one \nshown in Figure 20.5. This board establishes three categories of backlog items: \u201cNot Yet \nAddressed,\u201d \u201cPartially Addressed,\u201d and \u201cCompletely Addressed.\u201d\nAt the beginning of an iteration, the inputs to the design process become entries in the \nbacklog. Initially (in step 1), the entries in your backlog for this design round should be located \nin the \u201cNot Yet Addressed\u201d column of the board.", "domains": ["Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 323", "position": 323, "chunk_type": "semantic", "token_estimate": 388}
{"text": "20.6 More on ADD Step 7: 305: CT-1 MVP release of the solution to\nthe selected consultants, customers,\nand prospective licensees in \n9 months, release in 1.5 years\nConstraint\nHigh Priority\nNot Yet Addressed\n6\n7\n1\nPartially Addressed\nCompletely Addressed\nDiscarded\nHigh Priority\nCT-Infrastructure team is not able\nto support large-scale SaaS setup\nConstraint\nMedium Priority\nQA-3 External user credentials are\nYHUL\u0182HG\u0003DJDLQVW\u0003XVHU\u0003UHJLVWU\\\nQAScenario\nQAScenario\nQA-5 Data center infrastructure has\nuptime of 99.95%\nQA-8 Test code coverage should be\nat least 85% for each CI\nHigh Priority\nQAScenario\n4$\u0010\u0014\u00038VHU\u0003FUHGHQWLDOV\u0003DUH\u0003YHUL\u0182HG\nagainst corporate AD\nHigh Priority\nQAScenario\nQC4 - As sales person prepares\nproposal plan\nHigh Priority\nUseCase\nQN-1 Code base (reuse legacy code if\npossible)\nLow Priority\nCN-2 Choose architecture style\nHigh Priority\nConcern\nQA-4 User-facing parts are available\n99.9% for 4 hours in\nmonths (maintenance window)\nHigh Priority\nQAScenario\nMedium Priority\nUC10-3 \nMedium Priority\nFIGURE 20.5 A Kanban board used to track design progress\nIt is important to establish clear criteria that will allow a driver to be moved to the \n\u201cPartially Addressed\u201d or \u201cCompletely Addressed\u201d columns. A criterion for \u201cCompletely \nAddressed\u201d may be, for example, that the driver has been analyzed or that it has been imple-\nmented in a prototype, and you determine that the requirements for that driver have been satis-\nfied. Drivers that are selected for a particular iteration may not be completely addressed in that \niteration. In that case, they should remain in the \u201cPartially Addressed\u201d column. It can be useful to select a technique that will allow you to differentiate the entries in \nthe board according to their priority. For example, you might use different colors for entries, \ndepending on the priority. A Kanban board makes it easy to visually track the advancement of design, as you can \nquickly see how many of the (most important) drivers are being or have been addressed in the \niteration. This technique also helps you decide whether you need to perform additional iter-\nations. Ideally, the design round is terminated when a majority of your drivers (or at least the \nones with the highest priority) are located under the \u201cCompletely Addressed\u201d column.", "domains": ["Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 324", "position": 324, "chunk_type": "semantic", "token_estimate": 354}
{"text": "310 Part IV Scalable Architecture Practices | Chapter 21 Evaluating an Architecture: Applying this concept to architecture evaluation, you can see that if the system being \nconstructed costs millions or billions of dollars or has large safety-critical implications, then \nthe impact of a risk event will be large. By comparison, if the system is a console-based game \ncosting tens or hundreds of thousands of dollars to create, then the impact of a risk event will \nbe considerably smaller. The probability of a risk event is related to, among other things, how precedented or \nunprecedented the system under development and its architecture are. If you and your organi-\nzation have long and deep experience in this domain, then the probability of producing a bad \narchitecture is less than if this project is your first go. Thus evaluations act like an insurance policy. How much insurance you need depends on \nhow exposed you are to the risk of an unsuitable architecture and your risk tolerance. Evaluations can be done throughout the development process at different phases, with \ndifferent evaluators, and with differences in how the evaluation is performed\u2014we\u2019ll cover \nsome of the options in this chapter. Regardless of their precise details, evaluations build on the \nconcepts you have already learned: Systems are constructed to satisfy business goals, business \ngoals are exemplified by quality attribute scenarios, and quality attribute goals are achieved \nthrough the application of tactics and patterns. 21.2  \nWhat Are the Key Evaluation Activities? Regardless of who performs the evaluation and when it is performed, an evaluation is based \non architectural drivers\u2014primarily architecturally significant requirements (ASRs) expressed \nas quality attribute scenarios. Chapter 19 describes how to determine ASRs. The number of \nASRs that enter into the evaluation is a function of the contextual factors and the cost of the \nevaluation. We next describe the possible contextual factors for architecture evaluation. An evaluation can be carried out at any point in the design process where a candidate \narchitecture, or at least a coherent reviewable part of one, exists. Every evaluation should include (at least) these steps:\n1. The reviewers individually ensure that they understand the current state of the archi-\ntecture. This can be done through shared documentation, through a presentation by the \narchitect, or through some combination of these. 2. The reviewers determine a number of drivers to guide the review. These drivers may \nalready be documented, or they can be developed by the review team or by additional \nstakeholders.", "domains": ["Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 329", "position": 329, "chunk_type": "semantic", "token_estimate": 409}
{"text": "21.5 The Architecture Tradeoff Analysis Method 313: These people are empowered to speak for the development \nproject or have the authority to mandate changes to it. They usually include the project \nmanager and, if an identifiable customer is footing the bill for the development, a repre-\nsentative of that customer may be present as well. The architect is always included\u2014a \ncardinal rule of architecture evaluation is that the architect must willingly participate. \u25a0Architecture stakeholders. Stakeholders have a vested interest in the architecture per-\nforming as advertised. They are the people whose ability to do their job hinges on the \narchitecture promoting modifiability, security, high reliability, or the like. Stakeholders \ninclude developers, testers, integrators, maintainers, performance engineers, users, and", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 332", "position": 332, "chunk_type": "semantic", "token_estimate": 118}
{"text": "21.5 The Architecture Tradeoff Analysis Method 317: or customer representative) presents a system overview from a business perspective. This pre-\nsentation should describe the following aspects of the project:\n \n\u25a0The system\u2019s most important functions\n \n\u25a0Any relevant technical, managerial, economic, or political constraints\n \n\u25a0The business goals and context as they relate to the project\n \n\u25a0The major stakeholders\n \n\u25a0The architectural drivers (emphasizing architecturally significant requirements)\nStep 3: Present the Architecture\nThe lead architect (or architecture team) makes a presentation describing the architecture at \nan appropriate level of detail. The \u201cappropriate level\u201d depends on several factors: how much \nof the architecture has been designed and documented, how much time is available, and the \nnature of the behavioral and quality requirements. In this presentation, the architect covers technical constraints such as the operating sys-\ntem, platforms prescribed for use, and other systems with which this system must interact. Most importantly, the architect describes the architectural approaches (or patterns, or tactics, \nif the architect is fluent in that vocabulary) used to meet the requirements. We expect architectural views, as introduced in Chapter 1 and described in detail in \nChapter 22, to be the primary vehicle by which the architect conveys the architecture. Context \ndiagrams, component-and-connector views, module decomposition or layered views, and \nthe deployment view are useful in almost every evaluation, and the architect should be pre-\npared to show them. Other views can be presented if they contain information relevant to the \narchitecture at hand, especially information relevant to satisfying important quality attribute \nrequirements. Step 4: Identify the Architectural Approaches\nThe ATAM focuses on analyzing an architecture by understanding its architectural \napproaches. Architectural patterns and tactics are useful for (among other reasons) the known \nways in which each one affects particular quality attributes. For example, a layered pattern \ntends to bring portability and maintainability to a system, possibly at the expense of perfor-\nmance. A publish-subscribe pattern is scalable in the number of producers and consumers of \ndata, whereas the active redundancy pattern promotes high availability. Step 5: Generate a Quality Attribute Utility Tree\nThe quality attribute goals are articulated in detail via a quality attribute utility tree, which \nwe introduced in Section 19.4. Utility trees serve to make the requirements concrete by defin-\ning precisely the relevant quality attribute requirements that the architects were working to \nprovide.", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 336", "position": 336, "chunk_type": "semantic", "token_estimate": 384}
{"text": "318 Part IV Scalable Architecture Practices | Chapter 21 Evaluating an Architecture: backdrop against which subsequent information is presented. However, they are not specific \nenough to let us tell if the architecture suffices to achieve those aims. Modifiable in what way? Throughput that is how high? Ported to what platforms and in how much time? The answers to \nthese kinds of questions are expressed as quality attribute scenarios representing architectur-\nally significant requirements. Recall that the utility tree is constructed by the architect and the project decision makers. Together, they determine the importance of each scenario: The architect rates the technical \ndifficulty or risk of the scenario (on a H, M, L scale), and the project decision makers rate its \nbusiness importance. Step 6: Analyze the Architectural Approaches\nThe evaluation team examines the highest-ranked scenarios (as identified in the utility tree) \none at a time; the architect is asked to explain how the architecture supports each one. Evaluation \nteam members\u2014especially the questioners\u2014probe for the architectural approaches that the \narchitect used to carry out the scenario. Along the way, the evaluation team documents the rele-\nvant architectural decisions and identifies and catalogs their risks, non-risks, and tradeoffs. For \nwell-known approaches, the evaluation team asks how the architect overcame known weak-\nnesses in the approach or how the architect gained assurance that the approach sufficed. The \ngoal is for the evaluation team to be convinced that the instantiation of the approach is appropri-\nate for meeting the attribute-specific requirements for which it is intended. Scenario walkthrough leads to a discussion of possible risks and non-risks. For example:\n \n\u25a0The frequency of heartbeats affects the time in which the system can detect a failed \ncomponent. Some assignments will result in unacceptable values of this response; these \nare risks. \u25a0The frequency of heartbeats determines the time for detection of a fault. \u25a0Higher frequency leads to improved availability but also consumes more processing time \nand communication bandwidth (potentially leading to reduced performance). This is a \ntradeoff. These issues, in turn, may catalyze a deeper analysis, depending on how the architect \nresponds. For example, if the architect cannot characterize the number of clients and cannot \nsay how load balancing will be achieved by allocating processes to hardware, there is little \npoint in proceeding to any performance analysis.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 337", "position": 337, "chunk_type": "semantic", "token_estimate": 380}
{"text": "318 Part IV Scalable Architecture Practices | Chapter 21 Evaluating an Architecture: These issues, in turn, may catalyze a deeper analysis, depending on how the architect \nresponds. For example, if the architect cannot characterize the number of clients and cannot \nsay how load balancing will be achieved by allocating processes to hardware, there is little \npoint in proceeding to any performance analysis. If such questions can be answered, the eval-\nuation team can perform at least a rudimentary, or back-of-the-envelope, analysis to determine \nif these architectural decisions are problematic vis-\u00e0-vis the quality attribute requirements \nthey are meant to address. The analysis during step 6 is not meant to be comprehensive. The key is to elicit sufficient \narchitectural information to establish some link between the architectural decisions that have \nbeen made and the quality attribute requirements that need to be satisfied. Figure 21.1 shows a template for capturing the analysis of an architectural approach for \na scenario. As shown in the figure, based on the results of this step, the evaluation team can \nidentify and record a set of risks and non-risks, sensitivity points, and tradeoffs.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 337", "position": 337, "chunk_type": "semantic", "token_estimate": 185}
{"text": "21.5 The Architecture Tradeoff Analysis Method 319: Scenario #: A12\nScenario: Detect and recover from HW failure\nof main switch. Attribute(s)\nAvailability\nEnvironment\nNormal operations\nStimulus\nOne of the CPUs fails\nResponse\n0.999999 availability of switch\nArchitectural decisions\nSensitivity\nTradeoff\nRisk\nNonrisk\nBackup CPU(s)", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 338", "position": 338, "chunk_type": "semantic", "token_estimate": 44}
{"text": "Reasoning: Ensures no common mode failure by using different hardware\nand operating system (see Risk 8)\nWorst-case rollover is accomplished in 4 seconds, as computing\nstate takes that long at worst\nGuaranteed to detect failure within 2 seconds based on rates of\nheartbeat and watchdog\nWatchdog is simple and has proved reliable\nAvailability requirement might be at risk due to lack of backup\ndata channel . . . (see Risk 9)\nArchitecture\ndiagram\nBackup\ny\nSwitch", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 338", "position": 338, "chunk_type": "semantic", "token_estimate": 76}
{"text": "320 Part IV Scalable Architecture Practices | Chapter 21 Evaluating an Architecture: Hiatus and Start of Phase 2\nThe evaluation team summarizes what it has learned and interacts informally with the archi-\ntect during a hiatus of a week or so. More scenarios might be analyzed during this period, if \ndesired, or answers to questions posed in phase 1 may be clarified. Attendees at the phase 2 meeting include an expanded list of participants, with additional \nstakeholders joining the discussion. To use an analogy from programming: Phase 1 is akin \nto when you test your own program, using your own criteria. Phase 2 is when you give your \nprogram to an independent quality assurance group, who will likely subject your program to a \nwider variety of tests and environments. In phase 2, step 1 is repeated so that the stakeholders understand the method and the roles \nthey are to play. Then the evaluation leader recaps the results of steps 2\u20136, and shares the cur-\nrent list of risks, non-risks, sensitivity points, and tradeoffs. After bringing the stakeholders up \nto speed with the evaluation results so far, the remaining three steps can be carried out. Step 7: Brainstorm and Prioritize Scenarios\nThe evaluation team asks the stakeholders to brainstorm quality attribute scenarios that are \noperationally meaningful with respect to the stakeholders\u2019 individual roles. A maintainer will \nlikely propose a modifiability scenario, while a user will probably come up with a scenario \nthat expresses ease of operation, and a quality assurance person will propose a scenario about \ntesting the system or being able to replicate the state of the system leading up to a fault. While utility tree generation (step 5) is used primarily to understand how the architect \nperceived and handled quality attribute architectural drivers, the purpose of scenario brain-\nstorming is to take the pulse of the larger stakeholder community: to understand what sys-\ntem success means for them. Scenario brainstorming works well in larger groups, creating an \natmosphere in which the ideas and thoughts of one person stimulate others\u2019 ideas. Once the scenarios have been collected, they must be prioritized, for the same reasons that \nthe scenarios in the utility tree needed to be prioritized: The evaluation team needs to know \nwhere to devote its limited analysis time. First, stakeholders are asked to merge scenarios they \nfeel represent the same behavior or quality concern. Next, they vote for those scenarios they feel \nare most important.", "domains": ["Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 339", "position": 339, "chunk_type": "semantic", "token_estimate": 406}
{"text": "21.5 The Architecture Tradeoff Analysis Method 321: Step 8: Analyze the Architectural Approaches\nAfter the scenarios have been collected and prioritized in step 7, the evaluation team guides \nthe architect in the process of analyzing the highest-ranked scenarios. The architect explains \nhow architectural decisions contribute to realizing each scenario. Ideally, this activity will be \ndominated by the architect\u2019s explanation of scenarios in terms of previously discussed archi-\ntectural approaches. In this step the evaluation team performs the same activities as in step 6, using the \n \nhighest-ranked, newly generated scenarios. Typically, this step might cover the top five to ten \nscenarios, as time permits. Step 9: Present the Results\nIn step 9, the evaluation team convenes and groups risks into risk themes, based on some \ncommon underlying concern or systemic deficiency. For example, a group of risks about inad-\nequate or out-of-date documentation might be grouped into a risk theme stating that docu-\nmentation is given insufficient consideration. A group of risks about the system\u2019s inability to \nfunction in the face of various hardware and/or software failures might lead to a risk theme \nabout insufficient attention to backup capability or providing high availability. For each risk theme, the evaluation team identifies which of the business goals listed in \nstep 2 are affected. Identifying risk themes and then relating them to specific drivers brings \nthe evaluation full circle by relating the final results to the initial presentation, thereby pro-\nviding a satisfying closure to the exercise. Equally important, it elevates the risks that were \nuncovered to the attention of management. What might otherwise have seemed to a manager \nlike an esoteric technical issue is now identified unambiguously as a threat to something the \nmanager is on record as caring about. The collected information from the evaluation is summarized and presented to stakehold-\ners. The following outputs are presented:\n \n\u25a0The architectural approaches documented\n \n\u25a0The set of scenarios and their prioritization from the brainstorming\n \n\u25a0The utility tree\n \n\u25a0The risks and non-risks discovered\n \n\u25a0The sensitivity points and tradeoffs found\n \n\u25a0Risk themes and the business goals threatened by each one\nGoing Off Script\nYears of experience have taught us that no architecture evaluation exercise ever goes \ncompletely by the book.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 340", "position": 340, "chunk_type": "semantic", "token_estimate": 364}
{"text": "21.5 The Architecture Tradeoff Analysis Method 323: By now, phase 2 was thrown off schedule to such an extent that the architect, to our \nhorror, had to leave to fly back to his home in a distant city. He was none too happy that \nhis architecture was going to be evaluated without him. The junior designers, he said, \nwould never be able to answer our questions. Before his departure, our team huddled. The exercise seemed to be teetering on the brink of disaster. We had an unhappy \ndeparting architect, a blown schedule, and questionable expertise available. We decided \nto split our evaluation team. One half of the team would continue with phase 2 using \nthe junior designers as our information resource. The second half of the team would \ncontinue with phase 2 by telephone the next day with the architect. Somehow we would \nmake the best of a bad situation. Surprisingly, the project manager seemed completely unperturbed by the turn of \nevents. \u201cIt will work out, I\u2019m sure,\u201d he said pleasantly, and then retreated to confer with \nvarious vice presidents about the reorganization. I led the team interviewing the junior designers. We had never gotten a completely sat-\nisfactory architecture presentation from the architect. Discrepancies in the documentation \nwere met with a breezy \u201cOh, well, that\u2019s not how it really works.\u201d So I decided to start over \nwith ATAM step 3. We asked the half dozen or so designers what their view of the archi-\ntecture was. \u201cCould you draw it?\u201d I asked them. They looked at each other nervously, but \none said, \u201cI think I can draw part of it.\u201d He took to the whiteboard and drew a very reason-\nable component-and-connector view. Someone else volunteered to draw a process view. A third person drew the architecture for an important offline part of the system. Others \njumped in to assist. As we looked around the room, everyone was busy transcribing the whiteboard \npictures. None of the pictures corresponded to anything we had seen in the documenta-\ntion so far. \u201cAre these diagrams documented anywhere?\u201d I asked. One of the designers \nlooked up from his busy scribbling for a moment to grin. \u201cThey are now,\u201d he said. As we proceeded to step 8, analyzing the architecture using the scenarios previously \ncaptured, the designers did an astonishingly good job of working together to answer \nour questions. Nobody knew everything, but everybody knew something.", "domains": ["Design Patterns", "Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 342", "position": 342, "chunk_type": "semantic", "token_estimate": 402}
{"text": "21.6 Lightweight Architecture Evaluation 325: Because the participants are all internal to the organization and fewer in number than for \nthe ATAM, giving everyone their say and achieving a shared understanding takes much less \ntime. In addition, an LAE exercise, because it is a lightweight process, can be done regularly; \nin turn, many of the steps of the method can be omitted or only briefly touched upon. The \npotential steps in an LAE exercise, along with our experiences with how these play out in \npractice, are shown in Table 21.3. The LAE exercise is typically convened by and led by the \nproject architect. TABLE 21.3 A Typical Agenda for Lightweight Architecture Evaluation\nStep\nNotes\n1: Present the method steps\nAssuming the participants are familiar with the process, this step \nmay be omitted. 2: Review the business goals\nThe participants are expected to understand the system and its \nbusiness goals and their priorities. A brief review may be done to \nensure that these are fresh in everyone\u2019s mind and that there are no \nsurprises. 3: Review the architecture\nAll participants are expected to be familiar with the system, so a \nbrief overview of the architecture is presented, using at least the \nmodule and C&C views, highlighting any changes since the last \nreview, and one or two scenarios are traced through these views. 4:  \nReview the architectural \napproaches\nThe architect highlights the architectural approaches used for \nspecific quality attribute concerns. This is typically done as a portion \nof step 3. 5:  \nReview the quality attribute \nutility tree\nA utility tree should already exist; the team reviews the existing tree \nand updates it, if needed, with new scenarios, new response goals, \nor new scenario priorities and risk assessments. 6:  \nBrainstorm and prioritize \nscenarios\nA brief brainstorming activity can occur at this time to establish \nwhether any new scenarios merit analysis. 7:  \nAnalyze the architectural \napproaches\nThis step\u2014mapping the highly ranked scenarios onto the \narchitecture\u2014consumes the bulk of the time and should focus \non the most recent changes to the architecture, or on a part of \nthe architecture that the team has not previously analyzed. If the \narchitecture has changed, the high-priority scenarios should be \nreanalyzed in light of these changes. 8:  \nCapture the results\nAt the end of an evaluation, the team reviews the existing and \nnewly discovered risks, non-risks, sensitivities, and tradeoffs, and \ndiscusses whether any new risk themes have arisen.", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 344", "position": 344, "chunk_type": "semantic", "token_estimate": 399}
{"text": "326 Part IV Scalable Architecture Practices | Chapter 21 Evaluating an Architecture: Tactics-Based Questionnaires\nAnother (even lighter) lightweight evaluation method that we discussed in Chapter 3 \nis the tactics-based questionnaire. A tactics-based questionnaire focuses on a sin-\ngle quality attribute at a time. It can be used by the architect to aid in reflection and \nintrospection, or it can be used to structure a question-and-answer session between \nan evaluator (or evaluation team) and an architect (or group of designers). This kind \nof session is typically short\u2014around one hour per quality attribute\u2014but can reveal a \ngreat deal about the design decisions taken, and those not taken, in pursuit of control \nof a quality attribute and the risks that are often buried within those decisions. We have \nprovided quality attribute\u2013specific questionnaires in Chapters 4\u201313 to help guide you in \nthis process. A tactics-based analysis can lead to surprising results in a very short time. For \nexample, once I was analyzing a system that managed healthcare data. We had agreed \nto analyze the quality attribute of security. During the session, I dutifully walked through \nthe security tactics\u2013based questionnaire, asking each question in turn (as you may \nrecall, in these questionnaires each tactic is transformed into a question). For exam-\nple, I asked, \u201cDoes the system support the detection of intrusions?\u201d, \u201cDoes the system \nsupport the verification of message integrity?\u201d, and so forth. When I got to the question \n\u201cDoes the system support data encryption?\u201d, the architect paused and smiled. Then he \n(sheepishly) admitted that the system had a requirement that no data could be passed \nover a network \u201cin the clear\u201d\u2014that is, without encryption. So they XOR\u2019ed all data \nbefore sending it over the network. This is a great example of the kind of risk that a tactics-based questionnaire can \nuncover, very quickly and inexpensively. Yes, they had met the requirement in a strict \nsense\u2014they were not sending any data in the clear. But the encryption algorithm that \nthey chose could be cracked by a high school student with modest abilities! \u2014RK\n21.7  \nSummary\nIf a system is important enough for you to explicitly design its architecture, then that architec-\nture should be evaluated. The number of evaluations and the extent of each evaluation may vary from project to \nproject. A designer should perform an evaluation during the process of making an important \ndecision. The ATAM is a comprehensive method for evaluating software architectures.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 345", "position": 345, "chunk_type": "semantic", "token_estimate": 401}
{"text": "330 Part IV Scalable Architecture Practices | Chapter 22 Documenting an Architecture: 22.1  \nUses and Audiences for Architecture Documentation\nArchitecture documentation must serve varied purposes. It should be sufficiently transparent \nand accessible to be quickly understood by new employees. It should be sufficiently concrete \nto serve as a blueprint for construction or forensics. It should have enough information to serve \nas a basis for analysis. Architecture documentation can be seen as both prescriptive and descriptive. For some \naudiences, it prescribes what should be true, placing constraints on decisions yet to be made. For other audiences, it describes what is true, recounting decisions already made about a sys-\ntem\u2019s design. Many different kinds of people will have an interest in architecture documentation. They \nhope and expect that this documentation will help them do their respective jobs. Understanding \nthe uses of architecture documentation is essential, as those uses determine the important \ninformation to capture. Fundamentally, architecture documentation has four uses. 1. Architecture documentation serves as a means of education. The educational use \nconsists of introducing people to the system. The people may be new members of the \nteam, external analysts, or even a new architect. In many cases, the \u201cnew\u201d person is the \ncustomer to whom you\u2019re showing your solution for the first time\u2014a presentation you \nhope will result in funding or go-ahead approval. 2. Architecture documentation serves as a primary vehicle for communication among \nstakeholders. Its precise use as a communication vehicle depends on which stakeholders \nare doing the communicating. Perhaps one of the most avid consumers of architecture documentation is none other \nthan the project\u2019s future architect. That may be the same person (as noted in the quo-\ntation that opened this chapter) or it may be a replacement, but in either case the future \narchitect is guaranteed to have an enormous stake in the documentation. New archi-\ntects are interested in learning how their predecessors tackled the difficult issues of the \nsystem and why particular decisions were made. Even if the future architect is the same \nperson, he or she will use the documentation as a repository of thought, a storehouse of \ndesign decisions too numerous and hopelessly intertwined to ever be reproducible from \nmemory alone. We enumerate the stakeholders for architecture, and its documentation, in Section 22.8. 3. Architecture documentation serves as the basis for system analysis and construction. Architecture tells implementers which modules to implement and how those modules are \nwired together.", "domains": ["Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 349", "position": 349, "chunk_type": "semantic", "token_estimate": 405}
{"text": "330 Part IV Scalable Architecture Practices | Chapter 22 Documenting an Architecture: Architecture documentation serves as the basis for system analysis and construction. Architecture tells implementers which modules to implement and how those modules are \nwired together. These dependencies determine the other teams with which the develop-\nment team for the module must communicate. For those interested in the design\u2019s ability to meet the system\u2019s quality objectives, the \narchitecture documentation serves as fodder for evaluation. It must contain the informa-\ntion necessary to evaluate a variety of attributes, such as security, performance, usabil-\nity, availability, and modifiability. 4. Architecture documentation serves as the basis for forensics when an incident occurs. When an incident occurs, someone is responsible for tracking down both the immediate", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 349", "position": 349, "chunk_type": "semantic", "token_estimate": 123}
{"text": "22.2 Notations 331: cause of the incident and the underlying cause. Information about the flow of control \nimmediately prior to the incident will provide the \u201cas executed\u201d architecture. For exam-\nple, a database of interface specifications will provide context for the flow of control, \nand component descriptions will indicate what should have happened in each component \non the trace of events. For the documentation to continue to provide value over time, it needs to be kept up \nto date. 22.2  \nNotations\nNotations for documenting views differ considerably in their degree of formality. Roughly \nspeaking, there are three main categories of notation:\n \n\u25a0Informal notations. Views may be depicted (often graphically) using general-purpose \ndiagramming and editing tools and visual conventions chosen for the system at hand. Most \nbox-and-line drawings you\u2019ve probably seen fall into this category\u2014think PowerPoint \nor something similar, or hand-drawn sketches on a whiteboard. The semantics of the \ndescription are characterized in natural language, and cannot be formally analyzed. \u25a0Semiformal notations. Views may be expressed in a standardized notation that pre-\nscribes graphical elements and rules of construction, but does not provide a complete \nsemantic treatment of the meaning of those elements. Rudimentary analysis can be \napplied to determine if a description satisfies syntactic properties. UML and its system-\nengineering adjunct SysML are semiformal notations in this sense. Most widely used \ncommercially available modeling tools employ notations in this category. \u25a0Formal notations. Views may be described in a notation that has a precise (usually math-\nematically based) semantics. Formal analysis of both syntax and semantics is possible. A variety of formal notations for software architecture are available. Generally referred \nto as architecture description languages (ADLs), they typically provide both a graph-\nical vocabulary and an underlying semantics for architecture representation. In some \ncases, these notations are specialized to particular architectural views. In other cases, \nthey allow many views, or even provide the ability to formally define new views. The \nusefulness of ADLs lies in their ability to support automation through associated tools\u2014\nautomation to provide useful analysis of the architecture, or assist in code generation. In \npractice, the use of formal notations is rare. Typically, more formal notations take more time and effort to create and understand, \nbut repay this effort with reduced ambiguity and more opportunities for analysis. Conversely, \nmore informal notations are easier to create, but provide fewer guarantees.", "domains": ["Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 350", "position": 350, "chunk_type": "semantic", "token_estimate": 391}
{"text": "332 Part IV Scalable Architecture Practices | Chapter 22 Documenting an Architecture: notations and representation languages while keeping in mind the important issues you need \nto capture and reason about. 22.3  \nViews\nPerhaps the most important concept associated with software architecture documentation is \nthat of the view. A software architecture is a complex entity that cannot be described in a \nsimple one-dimensional fashion. A view is a representation of a set of system elements and \nrelations among them\u2014not all system elements, but those of a particular type. For example, a \nlayered view of a system would show elements of type \u201clayer\u201d; that is, it would show the sys-\ntem\u2019s decomposition into layers, along with the relations among those layers. A pure layered \nview would not, however, show the system\u2019s services, or clients and servers, or data model, or \nany other type of element. Thus views let us divide the multidimensional entity that is a software architecture into a \nnumber of (we hope) interesting and manageable representations of the system. The concept of \nviews leads to a basic principle of architecture documentation:\nDocumenting an architecture is a matter of documenting the relevant views and then \nadding documentation that applies to more than one view. What are the relevant views? This depends entirely on your goals. As we saw previously, \narchitecture documentation can serve many purposes: a mission statement for implementers, a \nbasis for analysis, the specification for automatic code generation, the starting point for system \nunderstanding and reverse engineering, or the blueprint for project estimation and planning. Different views also expose different quality attributes to different degrees. In turn, the \nquality attributes that are of most concern to you and the other stakeholders in the system\u2019s \ndevelopment will affect which views you choose to document. For instance, a module view \nwill let you reason about your system\u2019s maintainability, a deployment view will let you reason \nabout your system\u2019s performance and reliability, and so forth. Because different views support different goals and uses, we do not advocate using any \nparticular view or collection of views. The views you should document depend on the uses you \nexpect to make of the documentation. Different views will highlight different system elements \nand relations. How many different views to represent is the result of a cost/benefit decision. Each view has a cost and a benefit, and you should ensure that the expected benefits of creat-\ning and maintaining a particular view outweigh its costs.", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Software Quality Attributes", "Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 351", "position": 351, "chunk_type": "semantic", "token_estimate": 408}
{"text": "332 Part IV Scalable Architecture Practices | Chapter 22 Documenting an Architecture: How many different views to represent is the result of a cost/benefit decision. Each view has a cost and a benefit, and you should ensure that the expected benefits of creat-\ning and maintaining a particular view outweigh its costs. The choice of views is driven by the need to document a particular pattern in your design. Some patterns are composed of modules, others consist of components and connectors, and \nstill others have deployment considerations. Module views, component-and-connector (C&C) \nviews, and allocation views are the appropriate mechanism for representing these consider-\nations, respectively. These categories of views correspond, of course, to the three categories \nof architectural structures described in Chapter 1. (Recall from Chapter 1 that a structure is a", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 351", "position": 351, "chunk_type": "semantic", "token_estimate": 132}
{"text": "22.3 Views 333: collection of elements, relations, and properties, whereas a view is a representation of one or \nmore architectural structures.) In this section, we explore these three categories of structure-based views and then intro-\nduce a new category: quality views. Module Views\nA module is an implementation unit that provides a coherent set of responsibilities. A module \nmight take the form of a class, a collection of classes, a layer, an aspect, or any decomposition \nof the implementation unit. Example module views are decomposition, uses, and layers. Every \nmodule view has a collection of properties assigned to it. These properties express important \ninformation associated with each module and the relationships among the modules, as well as \nconstraints on the module. Example properties include responsibilities, visibility information \n(what other modules can use it), and revision history. The relations that modules have to one \nanother include is-part-of, depends-on, and is-a. The way in which a system\u2019s software is decomposed into manageable units remains \none of the important forms of system structure. At a minimum, it determines how a system\u2019s \nsource code is decomposed into units, what kinds of assumptions each unit can make about \nservices provided by other units, and how those units are aggregated into larger ensembles. It \nalso includes shared data structures that impact, and are impacted by, multiple units. Module \nstructures often determine how changes to one part of a system might affect other parts and \nhence the ability of a system to support modifiability, portability, and reuse. The documentation of any software architecture is unlikely to be complete without at \nleast one module view. Table 22.1 summarizes the characteristics of module views. TABLE 22.1 Summary of Module Views\nElements\nModules, which are implementation units of software that provide a coherent set of \nresponsibilities\nRelations\n \n\u25a0\nIs-part-of, which defines a part/whole relationship between the submodule (the \npart) and the aggregate module (the whole)\n \n\u25a0\nDepends-on, which defines a dependency relationship between two modules\n \n\u25a0\nIs-a, which defines a generalization/specialization relationship between a more \nspecific module (the child) and a more general module (the parent)\nConstraints\nDifferent module views may impose topological constraints, such as limitations on \nthe visibility between modules.", "domains": ["Software Quality Attributes", "Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 352", "position": 352, "chunk_type": "semantic", "token_estimate": 362}
{"text": "22.3 Views 333: Table 22.1 summarizes the characteristics of module views. TABLE 22.1 Summary of Module Views\nElements\nModules, which are implementation units of software that provide a coherent set of \nresponsibilities\nRelations\n \n\u25a0\nIs-part-of, which defines a part/whole relationship between the submodule (the \npart) and the aggregate module (the whole)\n \n\u25a0\nDepends-on, which defines a dependency relationship between two modules\n \n\u25a0\nIs-a, which defines a generalization/specialization relationship between a more \nspecific module (the child) and a more general module (the parent)\nConstraints\nDifferent module views may impose topological constraints, such as limitations on \nthe visibility between modules. Usage\n \n\u25a0\nBlueprint for construction of the code\n \n\u25a0\nAnalysis of the impact of changes\n \n\u25a0\nPlanning incremental development\n \n\u25a0\nRequirements traceability analysis\n \n\u25a0\nCommunicating the functionality of a system and the structure of its code base\n \n\u25a0\nSupporting the definition of work assignments, implementation schedules, and \nbudget information\n \n\u25a0\nShowing the data model", "domains": ["Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 352", "position": 352, "chunk_type": "semantic", "token_estimate": 152}
{"text": "334 Part IV Scalable Architecture Practices | Chapter 22 Documenting an Architecture: Properties of modules that help to guide implementation or are input into analysis should \nbe recorded as part of the supporting documentation for a module view. The list of properties \nmay vary but is likely to include the following:\n \n\u25a0Name. A module\u2019s name is, of course, the primary means to refer to it. A module\u2019s name \noften suggests something about its role in the system. In addition, a module\u2019s name may \nreflect its position in a decomposition hierarchy; the name A.B.C, for example, refers to \na module C that is a submodule of a module B, which is itself a submodule of A. \u25a0Responsibilities. The responsibility property for a module is a way to identify its role in \nthe overall system and establishes an identity for it beyond the name. Whereas a mod-\nule\u2019s name may suggest its role, a statement of responsibility establishes that role with \nmuch more certainty. Responsibilities should be described in sufficient detail to make \nclear to the reader what each module does. A module\u2019s responsibilities are often captured \nby tracing to a project\u2019s requirements specification, if there is one. \u25a0Implementation information. Modules are units of implementation. It is therefore useful \nto record information related to their implementation from the point of view of manag-\ning their development and building the system that contains them. This might include:\n \n\u25a0Mapping to source code units. This identifies the files that constitute the implemen-\ntation of a module. For example, a module Account, if implemented in Java, might \nhave several files that constitute its implementation: IAccount.java (an interface), \nAccountImpl.java (implementation of Account functionality), and perhaps even a \nunit test AccountTest.java. \u25a0Test information. The module\u2019s test plan, test cases, test harness, and test data are \nimportant to document. This information may simply be a pointer to the location of \nthese artifacts. \u25a0Management information. A manager may need information about the module\u2019s pre-\ndicted schedule and budget. This information may simply be a pointer to the location \nof these artifacts. \u25a0Implementation constraints. In many cases, the architect will have an implementation \nstrategy in mind for a module or may know of constraints that the implementation \nmust follow. \u25a0Revision history. Knowing the history of a module, including its authors and particular \nchanges, may help you when you\u2019re performing maintenance activities. A module view can be used to explain the system\u2019s functionality to someone not familiar \nwith it.", "domains": ["Design Patterns", "Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 353", "position": 353, "chunk_type": "semantic", "token_estimate": 407}
{"text": "334 Part IV Scalable Architecture Practices | Chapter 22 Documenting an Architecture: Knowing the history of a module, including its authors and particular \nchanges, may help you when you\u2019re performing maintenance activities. A module view can be used to explain the system\u2019s functionality to someone not familiar \nwith it. The various levels of granularity of the module decomposition provide a top-down pre-\nsentation of the system\u2019s responsibilities and, therefore, can guide the learning process. For a \nsystem whose implementation is already in place, module views, if kept up-to-date, are helpful \nbecause they explain the structure of the code base to a new developer on the team. Conversely, it is difficult to use the module views to make inferences about runtime behav-\nior, because these views are just a static partition of the functions of the software. Thus a module \nview is not typically used for analysis of performance, reliability, and many other runtime quali-\nties. For those purposes, we rely on component-and-connector and allocation views.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 353", "position": 353, "chunk_type": "semantic", "token_estimate": 165}
{"text": "22.3 Views 335: Component-and-Connector Views\nC&C views show elements that have some runtime presence, such as processes, services, \nobjects, clients, servers, and data stores. These elements are termed components. Additionally, \nC&C views include as elements the pathways of interaction, such as communication links and \nprotocols, information flows, and access to shared storage. Such interactions are represented \nas connectors in C&C views. Example C&C views include client-server, microservice, and \ncommunicating processes. A component in a C&C view may represent a complex subsystem, which itself can be \ndescribed as a C&C subarchitecture. A component\u2019s subarchitecture may employ a different \npattern than the one in which the component appears. Simple examples of connectors include service invocation, asynchronous message queues, \nevent multicast supporting publish-subscribe interactions, and pipes that represent asynchro-\nnous, order-preserving data streams. Connectors often represent much more complex forms of \ninteraction, such as a transaction-oriented communication channel between a database server \nand a client, or an enterprise service bus that mediates interactions between collections of ser-\nvice users and providers. Connectors need not be binary; that is, they need not have exactly two components with \nwhich they interact. For example, a publish-subscribe connector might have an arbitrary num-\nber of publishers and subscribers. Even if the connector is ultimately implemented using binary \nconnectors, such as a procedure call, it can be useful to adopt n-ary connector representations \nin a C&C view. Connectors embody a protocol of interaction. When two or more components \ninteract, they must obey conventions about order of interactions, locus of control, and handling \nof error conditions and timeouts. The protocol of interaction should be documented. The primary relation within a C&C view is attachment. Attachments indicate which con-\nnectors are attached to which components, thereby defining a system as a graph of components \nand connectors. Compatibility often is defined in terms of information type and protocol. For \nexample, if a web server expects encrypted communication via HTTPS, then the client must \nperform the encryption. An element (component or connector) of a C&C view will have various properties associ-\nated with it. Specifically, every element should have a name and type, with its additional prop-\nerties depending on the type of component or connector. As an architect, you should define \nvalues for the properties that support the intended analyses for the particular C&C view. The \nfollowing are examples of some typical properties and their uses:\n \n\u25a0Reliability.", "domains": ["Architectural Patterns and Styles", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 354", "position": 354, "chunk_type": "semantic", "token_estimate": 396}
{"text": "22.3 Views 335: As an architect, you should define \nvalues for the properties that support the intended analyses for the particular C&C view. The \nfollowing are examples of some typical properties and their uses:\n \n\u25a0Reliability. What is the likelihood of failure for a given component or connector? This \nproperty might be used to help determine overall system availability. \u25a0Performance. What kinds of response time will the component provide under what \nloads? What kind of bandwidth, latency, or jitter can be expected for a given connec-\ntor? This property can be used with others to determine system-wide properties such as \nresponse times, throughput, and buffering needs. \u25a0Resource requirements. What are the processing and storage needs of a component or a \nconnector? If relevant, how much energy does it consume? This property can be used to \ndetermine whether a proposed hardware configuration will be adequate.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 354", "position": 354, "chunk_type": "semantic", "token_estimate": 143}
{"text": "336 Part IV Scalable Architecture Practices | Chapter 22 Documenting an Architecture: \u25a0Functionality. What functions does an element perform? This property can be used to \nreason about the end-to-end computation performed by a system. \u25a0Security. Does a component or a connector enforce or provide security features, such as \nencryption, audit trails, or authentication? This property can be used to determine poten-\ntial system security vulnerabilities. \u25a0Concurrency. Does this component execute as a separate process or thread? This \nproperty can help to analyze or simulate the performance of concurrent components and \nidentify possible deadlocks and bottlenecks. \u25a0Runtime extensibility. Does the messaging structure support evolving data exchanges? Can the connectors be adapted to process those new message types? C&C views are commonly used to show developers and other stakeholders how the sys-\ntem works: One can \u201canimate\u201d or trace through a C&C view, showing an end-to-end thread of \nactivity. C&C views are also used to reason about runtime system quality attributes, such as \nperformance and availability. In particular, a well-documented view allows architects to pre-\ndict overall system properties such as latency or reliability, given estimates or measurements \nof properties of the individual elements and their interactions. Table 22.2 summarizes the characteristics of C&C views. TABLE 22.2 Summary of C&C Views\nElements\n \n\u25a0\nComponents: principal processing units and data stores. \u25a0\nConnectors: pathways of interaction between components. Relations\n \n\u25a0\nAttachments: Components are associated with connectors to yield a graph. Constraints\nComponents can only be attached to connectors, and connectors can only be \nattached to components. \u25a0\nAttachments can only be made between compatible components and \nconnectors. \u25a0\nConnectors cannot appear in isolation; a connector must be attached to a \ncomponent. Usage\nShow how the system works. \u25a0\nGuide development by specifying the structure and behavior of runtime \nelements. \u25a0\nHelp reason about runtime system quality attributes, such as performance and \navailability. Notations for C&C Views\nAs always, box-and-line drawings are available to represent C&C views. Although informal \nnotations are limited in terms of the semantics that they can convey, following some sim-\nple guidelines can lend rigor and depth to the descriptions. The primary guideline is simple: \nAssign each component type and each connector type a separate symbol, and list each of the \ntypes in a key. UML components are a good semantic match to C&C components because they permit \nintuitive documentation of important information such as interfaces, properties, and behavioral", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 355", "position": 355, "chunk_type": "semantic", "token_estimate": 399}
{"text": "22.3 Views 337: descriptions. UML components also distinguish between component types and component \ninstances, which is useful when defining view-specific component types. Allocation Views\nAllocation views describe the mapping of software units to elements of an environment in \nwhich the software is developed or in which it executes. The environment in such a view var-\nies; it might be the hardware, the operating environment in which the software is executed, the \nfile systems supporting development or deployment, or the development organization(s). Table 22.3 summarizes the characteristics of allocation views. These views consist of \nsoftware elements and environmental elements. Examples of environmental elements are a \nprocessor, a disk farm, a file or folder, or a group of developers. The software elements come \nfrom a module or C&C view. TABLE 22.3 Summary of Allocation Views\nElements\nSoftware element and environmental element. A software element has properties \nthat are required of the environment. An environmental element has properties that \nare provided to the software. Relations\nAllocated-to: A software element is mapped (allocated to) an environmental \nelement. Constraints\nVaries by view. Usage\nFor reasoning about performance, availability, security, and safety. For reasoning \nabout distributed development and allocation of work to teams. For reasoning about \nconcurrent access to software versions. For reasoning about the form and \nmechanisms of system installation. The relation in an allocation view is allocated-to. We usually talk about allocation views \nin terms of a mapping from software elements to environmental elements, although the reverse \nmapping would also be relevant and potentially interesting. A single software element can be \nallocated to multiple environmental elements, and multiple software elements can be allocated \nto a single environmental element. If these allocations change over time, during execution \nof the system, then the architecture is said to be dynamic with respect to that allocation. For \nexample, processes might migrate from one processor or virtual machine to another. Software elements and environmental elements have properties in allocation views. One \ngoal of an allocation view is to compare the properties required by the software element with \nthe properties provided by the environmental elements to determine whether the allocation \nwill be successful. For example, to ensure its required response time, a component has to \nexecute on (be allocated to) a processor that provides sufficiently fast processing power.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 356", "position": 356, "chunk_type": "semantic", "token_estimate": 378}
{"text": "22.3 Views 337: One \ngoal of an allocation view is to compare the properties required by the software element with \nthe properties provided by the environmental elements to determine whether the allocation \nwill be successful. For example, to ensure its required response time, a component has to \nexecute on (be allocated to) a processor that provides sufficiently fast processing power. As \nanother example, a computing platform might not allow a task to use more than 10 kilobytes \nof virtual memory; an execution model of the software element in question can be used to \ndetermine the required virtual memory usage. Similarly, if you are migrating a module from", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 356", "position": 356, "chunk_type": "semantic", "token_estimate": 107}
{"text": "338 Part IV Scalable Architecture Practices | Chapter 22 Documenting an Architecture: one team to another, you might want to ensure that the new team has the appropriate skills and \nbackground knowledge to work with that module. Allocation views can depict either static or dynamic views. A static view illustrates \na fixed allocation of resources in an environment. A dynamic view shows the conditions and \nthe triggers for which allocation of resources changes. For example, some systems provision \nand utilize new resources as their loads increase. An example is a load-balancing system in \nwhich new processes or threads are created on another machine. In this view, the conditions \nunder which the allocation view changes, the allocation of runtime software, and the dynamic \nallocation mechanism need to be documented. Recall from Chapter 1 that one of the allocation structures is the work assignment struc-\nture, which allocates modules to teams for development. That allocation can also be changed, \ndepending on the \u201cload\u201d\u2014in this case, the load on development teams already at work. Quality Views\nModule, C&C, and allocation views are all structural views: They primarily show the structures \nthat the architect has designed into the architecture to satisfy functional and quality attribute \nrequirements. These views are excellent choices for guiding and constraining downstream developers, \nwhose primary job is to implement those structures. However, in systems in which certain \nquality attributes (or, for that matter, any stakeholder concerns) are particularly important and \npervasive, structural views may not be the best way to present the architectural solution to \nthose needs. The reason is that the solution may be spread across multiple structures that are \ncumbersome to combine (e.g., because the element types shown in each structure are different). Another kind of view, which we call a quality view, can be tailored for specific stakehold-\ners or to address specific concerns. Quality views are formed by extracting the relevant pieces \nof structural views and packaging them together. Here are five examples:\n \n\u25a0A security view can show all of the architectural measures taken to provide security. It \nwould depict the components that have some security role or responsibility, how those \ncomponents communicate, any data repositories for security information, and reposi-\ntories that are of security interest. The view\u2019s properties would include other security \nmeasures (e.g., physical security) in the system\u2019s environment. The security view would \nalso show the operation of security protocols and where and how humans interact with \nthe security elements.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 357", "position": 357, "chunk_type": "semantic", "token_estimate": 407}
{"text": "338 Part IV Scalable Architecture Practices | Chapter 22 Documenting an Architecture: The view\u2019s properties would include other security \nmeasures (e.g., physical security) in the system\u2019s environment. The security view would \nalso show the operation of security protocols and where and how humans interact with \nthe security elements. Finally, it would capture how the system responds to specific \nthreats and vulnerabilities. \u25a0A communications view might be especially helpful for systems that are globally dis-\npersed and heterogeneous. This view would show all of the component-to-component \nchannels, various network channels, quality-of-service parameter values, and areas \nof concurrency. Such a view can be used to analyze certain kinds of performance and \nreliability, such as deadlock or race condition detection. In addition, it could show (for \nexample) how network bandwidth is dynamically allocated.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 357", "position": 357, "chunk_type": "semantic", "token_estimate": 130}
{"text": "22.4 Combining Views 339: \u25a0An exception or error-handling view could help illuminate and draw attention to error \nreporting and resolution mechanisms. Such a view would show how components detect, \nreport, and resolve faults or errors. It would help the architect identify the sources of \nerrors and specify appropriate corrective actions for each. Finally, it would facilitate \nroot-cause analysis in those cases. \u25a0A reliability view would model reliability mechanisms such as replication and switch-\nover. It would also depict timing issues and transaction integrity. \u25a0A performance view would include those aspects of the architecture useful for inferring \nthe system\u2019s performance. Such a view might show network traffic models, maximum \nlatencies for operations, and so forth. These and other quality views reflect the documentation philosophy of ISO/IEC/IEEE \nstandard 42010:2011, which prescribes creating views driven by the concerns of the architec-\nture\u2019s stakeholders. 22.4  \nCombining Views\nThe basic principle of documenting an architecture as a set of separate views brings a divide-\nand-conquer advantage to the task of documentation. Of course, if those views were irrevo-\ncably different, with no association with one another, no one would be able to understand the \nsystem as a whole. However, because all structures in an architecture are part of the same \narchitecture and exist to achieve a common purpose, many of them have strong associations \nwith each other. Managing how architectural structures are associated is an important part of \nthe architect\u2019s job, independently of whether any documentation of those structures exists. Sometimes the most convenient way to show a strong association between two views is to \ncollapse them into a single combined view. A combined view contains elements and relations \nthat come from two or more other views. Such views can be very useful as long as you do not \ntry to overload them with too many mappings. The easiest way to merge views is to create an overlay that combines the information \nthat would otherwise have appeared in two separate views. This works well if the relationship \nbetween the two views is tight\u2014that is, if there are strong associations between elements in \none view and elements in the other view. In such a case, the structure described by the com-\nbined view will be easier to understand than the two views seen separately. In an overlay, the \nelements and the relations keep the types as defined in their constituent views.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 358", "position": 358, "chunk_type": "semantic", "token_estimate": 395}
{"text": "340 Part IV Scalable Architecture Practices | Chapter 22 Documenting an Architecture: Account\nController\nCustomer\nController\nTx\nController\n*\n1\n1\n1\n1\n1\nKey\nAdmin\nuser PC\nAppServer1\nAppServer2\nDatabase\nserver\nBack-end tier\nComponent tier\nWeb tier\nClient tier\nInternet\nuser PC\nIntranet\nInternet\nBank\nAdmin\nWeb\nbrowser\nWebUI\nAccount\nCustomer\nTx\nBank", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 359", "position": 359, "chunk_type": "semantic", "token_estimate": 54}
{"text": "Client-side: application\nWeb\ncomponent\nStateful\nsession\nbean\nEntity\nbean\nRelational\ndata source\nMachine\nnode\nCommunication \nchannel with \nmultiplicity (1 or *)\nTier\nComment\nJDBC database\naccess\nRemote\ncomponent \ncall\nhttp/\nhttps\n \n\u25a0Deployment view with any C&C view that shows processes. Processes are the compo-\nnents that are deployed onto processors, virtual machines, or containers. Thus there is a \nstrong association between the elements in these views. \u25a0Decomposition view and any work assignment, implementation, uses, or layered views. The decomposed modules form the units of work, development, and uses. In addition, \nthese modules populate layers. Figure 22.1 shows an example of a combined view that is an overlay of client-server, \nmulti-tier, and deployment views. FIGURE 22.1 A combined view\n \n22.5  \nDocumenting Behavior\nDocumenting an architecture requires behavior documentation that complements the struc-\ntural views by describing how architecture elements interact with each other. Reasoning about \ncharacteristics such as a system\u2019s potential to deadlock, a system\u2019s ability to complete a task", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 359", "position": 359, "chunk_type": "semantic", "token_estimate": 159}
{"text": "22.5 Documenting Behavior 341: in the desired amount of time, or maximum memory consumption requires that the archi-\ntecture description provide information about the characteristics of individual elements and \ntheir resource consumption, as well as patterns of interaction among them\u2014that is, how they \nbehave in relation to each other. In this section, we provide guidance as to what types of things \nyou will want to document to reap these benefits. Two kinds of notations are available for documenting behavior: trace-oriented and \ncomprehensive. Traces are sequences of activities or interactions that describe the system\u2019s response to \na specific stimulus when the system is in a specific state. A trace describes a sequence of \nactivities or interactions between structural elements of the system. Although one might con-\nceivably describe all possible traces to generate the equivalent of a comprehensive behavioral \nmodel, trace-oriented documentation does not really seek to do so. Here we describe four nota-\ntions for documenting traces: use cases, sequence diagrams, communication diagrams, and \nactivity diagrams. Although other notations are available (such as message sequence charts, \ntiming diagrams, and the Business Process Execution Language), we have chosen these four as \na representative sample of trace-oriented notations. \u25a0Use cases describe how actors can use a system to accomplish their goals; they are \nfrequently used to capture the functional requirements for a system. UML provides a \ngraphical notation for use case diagrams but does not specify how the text of a use case \nshould be written. The UML use case diagram is a good way to provide an overview \nof the actors and the behavior of a system. Its description, which is textual, should \ninclude the following items: the use case name and a brief description, the actor or actors \nwho initiate the use case (primary actors), other actors who participate in the use case \n(secondary actors), the flow of events, alternative flows, and non-success cases. \u25a0 \nA UML sequence diagram shows a sequence of interactions among instances of ele-\nments pulled from the structural documentation. It is useful, when designing a system, \nfor identifying where interfaces need to be defined. The sequence diagram shows only \nthe instances participating in the scenario being documented. It has two dimensions: \nvertical, representing time, and horizontal, representing the various instances. The inter-\nactions are arranged in time sequence from top to bottom. Figure 22.2 is an example of \na sequence diagram that illustrates the basic UML notation.", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 360", "position": 360, "chunk_type": "semantic", "token_estimate": 402}
{"text": "22.5 Documenting Behavior 341: The inter-\nactions are arranged in time sequence from top to bottom. Figure 22.2 is an example of \na sequence diagram that illustrates the basic UML notation. Sequence diagrams are not \nexplicit about showing concurrency. If that is your goal, use activity diagrams instead. As shown in Figure 22.2, objects (i.e., element instances) have a lifeline, drawn as a \nvertical dashed line down the time axis. The sequence is usually started by an actor on \nthe far left. The instances interact by sending messages, which are shown as horizontal \narrows. A message can be a message sent over a network, a function call, or an event \nsent through a queue. The message usually maps to a resource (operation) in the inter-\nface of the receiver instance. A filled arrowhead on a solid line represents a synchronous \nmessage, whereas an open arrowhead represents an asynchronous message. The dashed \narrow is a return message. The execution occurrence bars along the lifeline indicate that \nthe instance is processing or blocked waiting for a return.", "domains": ["Design Principles"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 360", "position": 360, "chunk_type": "semantic", "token_estimate": 175}
{"text": "342 Part IV Scalable Architecture Practices | Chapter 22 Documenting an Architecture: Key (UML)\n:Login\nPage\n:Login\nController\n:User Direct \nAccess Object\n:Logger\n:User\nlogin\nlogin(\u2026)\ncheckPwd(\u2026)\nnew\n:User\nSession\nActor\nObject\nLifeline\nExecution\noccurrence\nSynchronous\nmessage\nAsynchronous\nmessage\nReturn\nmessage\nregister User Login(\u2026)\n \nFIGURE 22.2 A simple example of a UML sequence diagram\n \n\u25a0A UML communication diagram shows a graph of interacting elements and annotates \neach interaction with a number denoting its order. Similar to sequence diagrams, instances \nshown in a communication diagram are elements described in the accompanying struc-\ntural documentation. Communication diagrams are useful when the task is to verify that \nan architecture can fulfill the functional requirements. Such diagrams are not useful when \nunderstanding of concurrent actions is important, as when conducting a performance \nanalysis. \u25a0UML activity diagrams are similar to flowcharts. They show a business process as a \nsequence of steps (called actions) and include notation to express conditional branch-\ning and concurrency, as well as to show sending and receiving events. Arrows between \nactions indicate the flow of control. Optionally, activity diagrams can indicate the archi-\ntecture element or actor performing the actions. Notably, activity diagrams can express \nconcurrency. A fork node (depicted as a thick bar orthogonal to the flow arrows) splits \nthe flow into two or more concurrent flows of actions. These concurrent flows may later \nbe synchronized into a single flow through a join node (also depicted as an orthogonal \nbar). The join node waits for all incoming flows to complete before proceeding.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 361", "position": 361, "chunk_type": "semantic", "token_estimate": 252}
{"text": "22.5 Documenting Behavior 343: Unlike sequence and communication diagrams, activity diagrams don\u2019t show the \nactual operations being performed on specific objects. Thus these diagrams are useful \nto broadly describe the steps in a specific workflow. Conditional branching (shown by a \ndiamond symbol) allows a single diagram to represent multiple traces, although an activ-\nity diagram usually does not attempt to show all possible traces or the complete behavior \nfor the system (or part of it). Figure 22.3 shows an activity diagram. read\npressure\n[not\nunderwater]\nenter\ndive mode\n[underwater]\ncheck\ndepth\ncheck\nwater\ntemperature\nread\npressure\nbeep\nalarm\n[not ascending\ntoo fast]\n[ascending\ntoo fast]\nsleep\n0.5 sec\n[underwater]\nexit dive\nmode\n[not\nunderwater]\nfinish\ndive mode\nread\nwater\ntemperature\nsleep\n30 sec\nexit dive\nmode\nDepth Meter\nDive Tracker\nThermometer\nFIGURE 22.3 Activity diagram\nIn contrast to trace notations, comprehensive notations show the complete behavior of \nstructural elements. Given this type of documentation, it is possible to infer all possible paths \nfrom the initial state to the final state. State machines are a kind of formalism used by many", "domains": ["Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 362", "position": 362, "chunk_type": "semantic", "token_estimate": 180}
{"text": "inserted: FM/AM\nbutton\n[valid CD]\n[invalid CD] /\nejectDisc()\neject button /\nejectDisc()\neject button /\nejectDisc()\nFM/AM\nbutton\nCD button\n[CD in]\npower\nbutton\npower\nbutton\ncomprehensive notations. This formalism represents the behavior of architecture elements \nbecause each state is an abstraction of all possible histories that could lead to that state. State \nmachine languages allow you to complement a structural description of the elements of the \nsystem with constraints on interactions and timed reactions to both internal and environmental \nstimuli. UML state machine diagrams allow you to trace the behavior of your system, given spe-\ncific inputs. Such a diagram represents states using boxes and transitions between states using \narrows. Thus it models elements of the architecture and helps illustrate their runtime interac-\ntions. Figure 22.4 is an example of a state machine diagram showing the states of a car stereo. FIGURE 22.4 UML state machine diagram for a car stereo system", "domains": ["Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 363", "position": 363, "chunk_type": "semantic", "token_estimate": 154}
{"text": "22.6 Beyond Views 345: Each transition in a state machine diagram is labeled with the event causing the transi-\ntion. For example, in Figure 22.4, the transitions correspond to the buttons the driver can press \nor driving actions that affect the cruise control system. Optionally, the transition can specify a \nguard condition, which is enclosed in brackets. When the event corresponding to the transition \noccurs, the guard condition is evaluated and the transition is enabled only if the guard is true at \nthat time. Transitions can also have consequences, called actions or effects, which are indicated \nby a slash. When an action is present, it indicates that the behavior following the slash will be \nperformed when the transition occurs. The states may also specify entry and exit actions. 22.6  \nBeyond Views\n \nIn addition to views and behavior, comprehensive information about an architecture will \ninclude the following items:\n \n\u25a0Mapping between views. Because all the views of an architecture describe the same \nsystem, it stands to reason that any two views will have much in common. Combining \nviews (as described in Section 22.4) produces a set of views. Illuminating the associa-\ntions among those views can then help that reader gain a powerful insight into how the \narchitecture works as a unified conceptual whole. The associations between elements across views in an architecture are, in general, \nmany-to-many. For instance, each module may map to multiple runtime elements, and \neach runtime element may map to multiple modules. View-to-view associations can be conveniently captured as tables. To create such a \ntable list the elements of the first view in some convenient lookup order. The table itself \nshould be annotated or introduced with an explanation of the association that it depicts\u2014\nthat is, the correspondence between the elements across the two views. Examples include \n\u201cis implemented by\u201d for mapping from a component-and-connector view to a module \nview, \u201cimplements\u201d for mapping from a module view to a component-and-connector view, \n\u201cincluded in\u201d for mapping from a decomposition view to a layered view, and many others. \u25a0Documenting patterns. If you employ patterns in your design, as recommended in \nChapter 20, these patterns should be identified in the documentation. First, record \nthe fact that the given pattern is being used. Then say why this solution approach was \nchosen\u2014why the pattern is appropriate for the problem at hand. Using a pattern involves \nmaking successive design decisions that eventually result in that pattern\u2019s instantiation.", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 364", "position": 364, "chunk_type": "semantic", "token_estimate": 403}
{"text": "22.6 Beyond Views 345: Then say why this solution approach was \nchosen\u2014why the pattern is appropriate for the problem at hand. Using a pattern involves \nmaking successive design decisions that eventually result in that pattern\u2019s instantiation. These design decisions may manifest themselves as newly instantiated elements and the \nrelations among them, which in turn should be documented in structural views. \u25a0One or more context diagrams. A context diagram shows how the system or portion of \nthe system relates to its environment. The purpose of this diagram is to depict the scope \nof a view. Here \u201ccontext\u201d means an environment with which the (part of the) system \ninteracts. Entities in the environment may be humans, other computer systems, or physi-\ncal objects, such as sensors or controlled devices. A context diagram may be created for \neach view, with each diagram showing how different types of elements interact with the", "domains": ["Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 364", "position": 364, "chunk_type": "semantic", "token_estimate": 148}
{"text": "22.8 Architecture Stakeholders 347: as Table 22.4. If you decide to record more than this minimum, the following information \nmight prove useful:\n \n\u25a0What evidence was produced to justify decisions? \u25a0Who did what? \u25a0Why were shortcuts taken? \u25a0Why were tradeoffs made? \u25a0What assumptions did you make? In the same way that we suggest that you record responsibilities as you identify elements, you \nshould record the design decisions as you make them. If you leave it until later, you will not \nremember why you did things. TABLE 22.4 Example Table to Document Design Decisions\nDesign Decisions and Location\nRationale and Assumptions (Include Discarded \nAlternatives)\nIntroduce concurrency (tactic) \nin the TimeServerConnector and \nFaultDetectionService\nConcurrency should be introduced to be able to receive \nand process several events (traps) simultaneously. Use of the messaging pattern through the \nintroduction of a message queue in \nthe communications layer\nAlthough the use of a message queue imposes \na performance penalty, a message queue was \nchosen because some implementations have high \nperformance and, furthermore, this will be helpful to \nsupport quality attribute scenario QA-3. . . . . . . 22.8  \nArchitecture Stakeholders\nIn Chapter 2, we said that one of the key purposes of architecture was to enable communi-\ncation among stakeholders. In this chapter, we have said that architecture documentation is \nproduced in service of architecture stakeholders. So who are they? The set of stakeholders will vary, depending on the organization and the project. The list \nof stakeholders in this section is suggestive but is not intended to be complete. As an architect, \none of your primary obligations is to identify the real stakeholders for your project. Similarly, \nthe documentation needs we lay out here for each stakeholder are typical but not definitive. You\u2019ll need to take the following discussion as a starting point and adapt it according to the \nneeds of your project. Key stakeholders of an architecture include the following:\n \n\u25a0Project managers care about schedule, resource assignments, and perhaps contingency \nplans to release a subset of the system for business reasons. To create a schedule, the", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 366", "position": 366, "chunk_type": "semantic", "token_estimate": 341}
{"text": "348 Part IV Scalable Architecture Practices | Chapter 22 Documenting an Architecture: project manager needs information about the modules to be implemented and in what \nsequence, with some information about their complexity, such as the list of responsi-\nbilities, as well as their dependencies on other modules. The dependencies may suggest \na certain sequence in the implementation. The project manager is not interested in the \ndesign specifics of any element or the exact interface beyond knowing whether those \ntasks have been completed. However, this person is interested in the system\u2019s over-\nall purpose and constraints; its interaction with other systems, which may suggest an \norganization-to-organization interface that the manager will have to establish; and the \nhardware environment, which the manager may have to procure. The project manager \nmight create or help create the work assignment view, in which case he or she will need \na decomposition view to do it. A project manager, then, will likely be interested in the \nfollowing views:\n \n\u25a0Module views. Decomposition and uses and/or layered. \u25a0Allocation views. Deployment and work assignment. \u25a0Other. Top-level context diagrams showing interacting systems and system overview \nand purpose. \u25a0Members of the development team, for whom the architecture provides marching orders, \nare given constraints on how they do their job. Sometimes developers are given responsi-\nbility for an element they did not implement, such as a commercial off-the-shelf product \nor a legacy element. Someone still has to be responsible for that element, to make sure \nthat it performs as advertised and to tailor it as necessary. This person will want to know \nthe following information:\n \n\u25a0The general idea behind the system. Although that information lies in the realm of \nrequirements rather than architecture, a top-level context diagram or system overview \ncan go a long way toward providing the necessary information. \u25a0Which elements the developer has been assigned for implementation\u2014that is, where \nfunctionality should be implemented. \u25a0The details of the assigned element, including the data model with which it must \noperate. \u25a0The elements with which the assigned part interfaces and what those interfaces are. \u25a0The code assets that the developer can utilize. \u25a0The constraints, such as quality attributes, legacy system interfaces, and budget \n(resource or fiscal), that must be met. A developer, then, is likely to want to see\n \n\u25a0Module views. Decomposition, uses and/or layered, and generalization. \u25a0Component-and-connector (C&C) views. Various, showing the component(s) the \ndeveloper was assigned and the components they interact with. \u25a0Allocation views. Deployment, implementation, and installation. \u25a0Other.", "domains": ["Architectural Patterns and Styles", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 367", "position": 367, "chunk_type": "semantic", "token_estimate": 408}
{"text": "348 Part IV Scalable Architecture Practices | Chapter 22 Documenting an Architecture: Deployment, implementation, and installation. \u25a0Other. System overview; a context diagram containing the module(s) the developer \nhas been assigned; the interface documentation of the developer\u2019s element(s) and the", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 367", "position": 367, "chunk_type": "semantic", "token_estimate": 39}
{"text": "22.8 Architecture Stakeholders 349: interface documentation of those elements with which they interact; a variability guide \nto implement required variability; and rationale and constraints. \u25a0Testers and integrators are stakeholders for whom the architecture specifies the correct \nblack-box behavior of the pieces that must fit together. A black-box tester will need to \naccess the interface documentation for the element. Integrators and system testers need \nto see collections of interfaces, behavior specifications, and a uses view so they can \nwork with incremental subsets. Testers and integrators, then, are likely to want to see the \nfollowing views:\n \n\u25a0Module views. Decomposition, uses, and data model. \u25a0C&C views. All. \u25a0Allocation views. Deployment; install; and implementation, to find out where the \nassets to build the module are. \u25a0Other. Context diagrams showing the module(s) to be tested or integrated; the interface \ndocumentation and behavior specification(s) of the module(s) and the interface docu-\nmentation of those elements with which they interact. Testers and integrators deserve special attention because it is not unusual for a project \nto spend roughly half of its overall effort in testing. Ensuring a smooth, automated, and \nerror-free testing process will have a major positive effect on the project\u2019s overall cost. \u25a0Designers of other systems with which this one must interoperate are also stakeholders. For these people, the architecture defines the set of operations provided and required, as \nwell as the protocols for their operation. These stakeholders will likely want to see the \nfollowing artifacts:\n \n\u25a0Interface documentations for those elements with which their system will interact, as \nfound in module and/or C&C views\n \n\u25a0The data model for the system with which their system will interact\n \n\u25a0Top-level context diagrams from various views showing the interactions\n \n\u25a0Maintainers use architecture as a starting point for maintenance activities, revealing the \nareas a prospective change will affect. Maintainers will want to see the same informa-\ntion as developers, as both must make their changes within the same constraints. But \nmaintainers will also want to see a decomposition view that allows them to pinpoint the \nlocations where a change will need to be carried out, and perhaps a uses view to help \nthem build an impact analysis to fully scope out the effects of the change. In addition, \nthey will want to see the design rationale, which will allow them to benefit from the \narchitect\u2019s original thinking and save them time by identifying already discarded design \nalternatives.", "domains": ["Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 368", "position": 368, "chunk_type": "semantic", "token_estimate": 396}
{"text": "350 Part IV Scalable Architecture Practices | Chapter 22 Documenting an Architecture: would otherwise have gone unnoticed until deployment. To serve this purpose, an end \nuser is likely to be interested in the following views:\n \n\u25a0C&C views. Views emphasizing flow of control and transformation of data, to see how \ninputs are transformed into outputs; analysis results dealing with properties of interest, \nsuch as performance or reliability. \u25a0Allocation views. A deployment view to understand how functionality is allocated to \nthe platforms with which the users interact. \u25a0Other. Context diagrams. \u25a0Analysts are interested in whether the design meets the system\u2019s quality objectives. The \narchitecture serves as fodder for architecture evaluation methods and must provide the \ninformation necessary to evaluate quality attributes. For example, architecture includes \nthe model that drives such analytical tools as rate-monotonic real-time schedulability \nanalysis, reliability block diagrams, simulations and simulation generators, theorem \nprovers, and model checkers. These tools require information about resource consump-\ntion, scheduling policies, dependencies, component failure rates, and so forth. Because \nanalysis can encompass almost any subject matter area, analysts may need access to \ninformation documented in any part of the architecture documentation. \u25a0Infrastructure support personnel set up and maintain the infrastructure that supports the \ndevelopment, integration, staging, and production environments of the system. A vari-\nability guide is particularly useful to help set up the software configuration management \nenvironment. Infrastructure support people likely want to see the following views:\n \n\u25a0Module views. Decomposition and uses. \u25a0C&C views. Various, to see what will run on the infrastructure. \u25a0Allocation views. Deployment and install, to see where the software (including the \ninfrastructure) will run; implementation. \u25a0Other. Variability guides. \u25a0Future architects are the most avid readers of architecture documentation, with a vested \ninterest in everything. You, after a period of time, or your replacement (when you \nget promoted and assigned to a more complex project) will want to know all the key \ndesign decisions and why they were made. Future architects are interested in it all, but \nthey will be especially keen to have access to comprehensive and candid rationale and \ndesign information. And, remember, that future architect might be you! Do not expect \nto remember all of these minute design decisions that you\u2019re making now. Remember, \narchitecture documentation is a love letter you write to your future self. 22.9  \nPractical Considerations\nUp to now, this chapter has been concerned with the information that architecture documenta-\ntion should contain. Over and above the contents of architecture documentation, however, are", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 369", "position": 369, "chunk_type": "semantic", "token_estimate": 409}
{"text": "22.9 Practical Considerations 351: issues dealing with its form, distribution, and evolution. In this section, we discuss some of \nthese concerns. Modeling Tools\nMany commercially available modeling tools are available that support the specification of \narchitectural constructs in a defined notation; SysML is a widely used choice. Many of these \ntools offer features aimed at practical large-scale use in industrial settings: interfaces that sup-\nport multiple users, version control, syntactic and semantic consistency checking of the mod-\nels, support for trace links between models and requirements or models and tests, and, in some \ncases, automatic generation of executable source code that implements the models. In many \nprojects, these are must-have capabilities, so the purchase price of the tool\u2014which is not insig-\nnificant in some cases\u2014should be evaluated against what it would cost the project to achieve \nthese capabilities on its own. Online Documentation, Hypertext, and Wikis\nDocumentation for a system can be structured as linked web pages. Web-oriented documents \ntypically consist of short pages (created to fit on one screen) with a deeper structure. One page \nusually provides some overview information and has links to more detailed information. Using tools such as wikis, it\u2019s possible to create a shared document to which many stake-\nholders can contribute. The hosting organization needs to decide what permissions it wants \nto give to various stakeholders; the tool used has to support the chosen permissions policy. In \nthe case of architecture documentation, we want selected stakeholders to comment on and add \nclarifying information to the architecture, but we would want only selected team personnel to \nbe able to actually change it. Follow a Release Strategy\nYour project\u2019s development plan should specify the process for keeping the important docu-\nmentation, including the architecture documentation, current. Document artifacts should be \nsubject to version control, as with any other important project artifact. The architect should \nplan to issue releases of the documentation to support major project milestones, which usually \nmeans far enough ahead of the milestone to give developers time to put the architecture to \nwork. For example, revised documentation could be provided to the development team at the \nend of each iteration or sprint or with each incremental release.", "domains": ["Design Patterns", "Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 370", "position": 370, "chunk_type": "semantic", "token_estimate": 363}
{"text": "352 Part IV Scalable Architecture Practices | Chapter 22 Documenting an Architecture: code\u2013integrate\u2013test development cycle, the browser is able to change its own architecture by \nadding a new component. Service-oriented systems that utilize dynamic service discovery and binding also exhibit \nthese properties. More challenging systems that are highly dynamic, self-organizing, and \nreflective (meaning self-aware) already exist. In these cases, the identities of the components \ninteracting with each other cannot be pinned down, let alone their interactions, in any static \narchitecture document. Another kind of architectural dynamism, equally challenging from a documentation per-\nspective, is found in systems that are rebuilt and redeployed with great rapidity. Some develop-\nment shops, such as those responsible for commercial websites, build and \u201cgo live\u201d with their \nsystem many times every day. Whether they change at runtime or as a result of high-frequency release-and-deploy \ncycles, all dynamic architectures share something in common with respect to documentation: \nThey change much faster than the documentation cycle. In either case, no one is going to hold \nup things until a new architecture document is produced, reviewed, and released. Even so, knowing the architecture of these ever-changing systems is every bit as import-\nant, and arguably more so, than for systems that follow more traditional life cycles. Here\u2019s \nwhat you can do if you\u2019re an architect in a highly dynamic environment:\n \n\u25a0Document what is true about all versions of your system. Your web browser doesn\u2019t go \nout and grab just any piece of software when it needs a new plug-in; a plug-in must have \nspecific properties and a specific interface. And that new piece of software doesn\u2019t just \nplug in anywhere, but rather in a predetermined location in the architecture. Record \nthose invariants. This process may make your documented architecture more a descrip-\ntion of constraints or guidelines that any compliant version of the system must follow. That\u2019s fine. \u25a0Document the ways the architecture is allowed to change. In the examples mentioned \nearlier, this will usually mean adding new components and replacing components with \nnew implementations. The place to do this is the variability guide discussed in Section 22.6\n \n\u25a0Generate interface documentation automatically. If you use explicit interface mech-\nanisms such as protocol buffers (described in Chapter 15), then there are always \nup-to-date definitions of component interfaces; otherwise, the system would not work.", "domains": ["Architectural Patterns and Styles", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 371", "position": 371, "chunk_type": "semantic", "token_estimate": 384}
{"text": "352 Part IV Scalable Architecture Practices | Chapter 22 Documenting an Architecture: The place to do this is the variability guide discussed in Section 22.6\n \n\u25a0Generate interface documentation automatically. If you use explicit interface mech-\nanisms such as protocol buffers (described in Chapter 15), then there are always \nup-to-date definitions of component interfaces; otherwise, the system would not work. Incorporate those interface definitions into a database so that revision histories are avail-\nable and the interfaces can be searched to determine what information is used in which \ncomponents. Traceability\nArchitecture, of course, does not live in a bubble, but in a milieu of information about the \nsystem under development that includes requirements, code, tests, budgets and schedules, and \nmore. The purveyors of each of these areas must ask themselves, \u201cIs my part right? How do I \nknow?\u201d This question takes on different specific forms in different areas; for example, the tes-\nter asks, \u201cAm I testing the right things?\u201d As we saw in Chapter 19, architecture is a response to \nrequirements and business goals, and its version of the \u201cIs my part right?\u201d question is to ensure", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 371", "position": 371, "chunk_type": "semantic", "token_estimate": 187}
{"text": "22.11 For Further Reading 353: that those have been satisfied. Traceability means linking specific design decisions to the spe-\ncific requirements or business goals that led to them, and those links should be captured in \nthe documentation. If, at the end of the day, all ASRs are accounted for (\u201ccovered\u201d) in the \narchitecture\u2019s trace links, then we have assurance that the architecture part is right. Trace links \nmay be represented informally\u2014a table, for instance\u2014or may be supported technologically \nin the project\u2019s tool environment. In either case, trace links should be part of the architecture \ndocumentation. 22.10  \nSummary\nWriting architectural documentation is much like other types of writing. The golden rule is: \nKnow your reader. You must understand the uses to which the writing will be put and the \naudience for the writing. Architectural documentation serves as a means for communication \namong various stakeholders: up the management chain, down into the developers, and across \nto peers. An architecture is a complicated artifact, best expressed by focusing on particular per-\nspectives, called views, which depend on the message to be communicated. You must choose \nthe views to document and choose the notation to document these views. This may involve \ncombining various views that have a large overlap. You must not only document the structure \nof the architecture but also the behavior. In addition, you should document the relations among the views in your documentation, \nthe patterns you use, the system\u2019s context, any variability mechanisms built into the architec-\nture, and the rationale for your major design decisions. There are other practical considerations for creating, maintaining, and distributing the \ndocumentation, such as choosing a release strategy, choosing a dissemination tool such as a \nwiki, and creating documentation for architectures that change dynamically. 22.11  \nFor Further Reading\n \nDocumenting Software Architectures: Views and Beyond [Clements 10a] is a comprehensive \ntreatment of the architecture documentation approach described in this chapter. It details a \nmultitude of different views and notations for them. It also describes how to package the doc-\numentation into a coherent whole. Appendix A covers using the Unified Modeling Language \n(UML) to document architecture and architectural information. ISO/IEC/IEEE 42010:2011 (\u201ceye-so-forty-two-oh-ten\u201d for short) is the ISO (and IEEE) \nstandard, Systems and Software Engineering: Architecture Description.", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 372", "position": 372, "chunk_type": "semantic", "token_estimate": 370}
{"text": "354 Part IV Scalable Architecture Practices | Chapter 22 Documenting an Architecture: AADL (addl.info) is an architecture description language that has become an SAE stan-\ndard for documenting architectures. The SAE is an organization for engineering professionals \nin the aerospace, automotive, and commercial vehicle industries. SysML is a general-purpose systems modeling language intended to support a broad \nrange of analysis and design activities for systems engineering applications. It is defined so that \nsufficient detail can be specified to support a variety of automated analysis and design tools. The SysML standard is maintained by the Object Management Group (OMG); this language \nwas developed by OMG in cooperation with the International Council on Systems Engineering \n(INCOSE). SysML was developed as a profile of UML, which means that it reuses much of \nUML, but also provides the extensions necessary to meet the needs of systems engineers. Copious information about SysML is available online, but Appendix C of [Clements 10a] \ndiscusses how SysML can be used to document architectures. As this book went to press, \nSysML 2.0 was under development. An extended example of documenting architectural decisions while designing can be \nfound in [Cervantes 16]. 22.12  \nDiscussion Questions\n1. Go to the website of your favorite open source system and look for its architectural \ndocumentation. What is there? What is missing? How would this affect your ability to \ncontribute code to this project? 2. Banks are justifiably cautious about security. Sketch the documentation you would need \nfor an ATM to reason about its security architecture. 3. If you are designing a microservice-based architecture, what elements, relations, and \nproperties would you need to document to be able to reason about end-to-end latency or \nthroughput? 4. Suppose your company has just purchased another company and you have been given the \ntask of merging a system in your company with a similar system in the other company. What views of the other system\u2019s architecture would you like to see and why? Would you \nask for the same views of both systems? 5. When would you choose to document behavior using trace notations and when would \nyou use a comprehensive notation? What value do you get and what effort is required for \neach of them? 6. How much of a project\u2019s budget would you devote to software architecture documenta-\ntion? Why? How would you measure the cost and the benefit? How would this change if \nyour project was a safety-critical system or a high-security system?", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 373", "position": 373, "chunk_type": "semantic", "token_estimate": 407}
{"text": "355: 23\n \nManaging Architecture Debt\nWith Yuanfang Cai\nSome debts are fun when you are acquiring them, but none are fun \nwhen you set about retiring them. \u2014Ogden Nash\nWithout careful attention and the input of effort, designs become harder to maintain and evolve \nover time. We call this form of entropy \u201carchitecture debt,\u201d and it is an important and highly \ncostly form of technical debt. The broad field of technical debt has been intensively studied for \nmore than a decade\u2014primarily focusing on code debt. Architecture debt is typically more dif-\nficult to detect and more difficult to eradicate than code debt because it involves nonlocal con-\ncerns. The tools and methods that work well for discovering code debt\u2014code inspections, code \nquality checkers, and so forth\u2014typically do not work well for detecting architecture debt. Of course, not all debt is burdensome and not all debt is bad debt. Sometimes a principle \nis violated when there is a worthy tradeoff\u2014for example, sacrificing low coupling or high \ncohesion to improve runtime performance or time to market. This chapter introduces a process to analyze existing systems for architecture debt. This \nprocess gives the architect both the knowledge and the tools to identify and manage such debt. It \nworks by identifying architecturally connected elements\u2014with problematic design relations\u2014\nand analyzing a model of their maintenance costs. If that model indicates the existence of a \nproblem, typically signaled by an unusually high amount of changes and bugs, this signifies an \narea of architecture debt. Once architecture debt has been identified, if it is bad enough, it should be removed \nthrough refactoring. Without quantitative evidence of payoff, typically it is difficult to get proj-\nect stakeholders to agree to this step. The business case (without architecture debt analysis) \ngoes like this: \u201cI will take three months to refactor this system and give you no new func-\ntionality.\u201d What manager would agree to that? However, armed with the kinds of analyses we \npresent here, you can make a very different pitch to your manager, one couched in terms of \nROI and increased productivity that pays the refactoring effort back, and more, in a short time.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 374", "position": 374, "chunk_type": "semantic", "token_estimate": 357}
{"text": "356 Part IV Scalable Architecture Practices | Chapter 23 Managing Architecture Debt: The process that we advocate requires three types of information:\n \n\u25a0Source code. This is used to determine structural dependencies. \u25a0Revision history, as extracted from a project\u2019s version control system. This is used to \ndetermine the co-evolution of code units. \u25a0Issue information, as extracted from an issue control system. This is used to determine \nthe reason for changes. The model for analyzing debt identifies areas of the architecture that are experiencing \nunusually high rates of bugs and churn (committed lines of code) and attempts to associate \nthese symptoms with design flaws. 23.1  \nDetermining Whether You Have an Architecture Debt \nProblem\n \nIn our process for managing architecture debt, we will focus on the physical manifestation of \narchitectural elements, which means the files in which their source code is stored. How do \nwe determine if a group of files is architecturally connected? One way is to identify the static \ndependencies between the files in your project\u2014this method calls that method, for example. You can find these by employing a static code analysis tool. A second approach is to capture \nthe evolutionary dependencies between files in a project. An evolutionary dependency occurs \nwhen two files change together, and you can extract this information from your revision con-\ntrol system. We can represent the file dependencies using a special kind of adjacency matrix called \na design structure matrix (DSM). While other representations are certainly possible, DSMs \nhave been used in engineering design for decades and are currently supported by a number of \nindustrial tools. In a DSM, entities of interest (in our case, files) are placed both on the rows \nof the matrix and, in the same order, on the columns. The cells of the matrix are annotated to \nindicate the type of dependency. We can annotate a DSM cell with information showing that the file on the row inherits \nfrom the file on the column, or that it calls the file on the column, or that it co-changes with \nthe file on the column. The first two annotations are structural, whereas the third is an evolu-\ntionary (or history) dependency. To repeat: Each row in the DSM represents a file. Entries on a row show the dependencies \nthat this file has on other files in the system.", "domains": ["Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 375", "position": 375, "chunk_type": "semantic", "token_estimate": 385}
{"text": "356 Part IV Scalable Architecture Practices | Chapter 23 Managing Architecture Debt: To repeat: Each row in the DSM represents a file. Entries on a row show the dependencies \nthat this file has on other files in the system. If the system has low coupling, you would expect \nthe DSM to be sparse; that is, any given file will be dependent on a small number of other files. Furthermore, you would hope that the DSM is lower diagonal; that is, all entries appear below \nthe diagonal. This means that a file depends only on lower-level files, not on higher-level ones, \nand that you have no cyclic dependencies in your system. Figure 23.1 shows 11 of the files from the Apache Camel project\u2014an open source integra-\ntion framework\u2014and their structural dependencies (indicated by the labels \u201cdp,\u201d \u201cim,\u201d and \u201cex\u201d \nfor dependency, implementation, and extension, respectively). For example, the file on rowb9 \nof Figure 23.1, MethodCallExpression.java, depends on and extends the file on column 1,", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 375", "position": 375, "chunk_type": "semantic", "token_estimate": 163}
{"text": "358 Part IV Scalable Architecture Practices | Chapter 23 Managing Architecture Debt: ExpressionDefinition.java, and the file on row 11, AssertionClause.java, depends \non the file on column 10, MockEndpoint.java. These static dependencies are extracted by \nreverse-engineering the source code. The matrix shown in Figure 23.1 is quite sparse. It means that these files are not heav-\nily structurally coupled to each other and, as a consequence, you might expect that it would \nbe relatively easy to change these files independently. In other words, this system seems to \nhave relatively little architecture debt. Now consider Figure 23.2, which overlays historical co-change information on Figureb23.1. Historical co-change information is extracted from the version control system. This indicates \nhow often two files change together in commits. Figure 23.2 shows a very different picture of the Camel project. For example, the \ncell at row 8, column 3 is marked with \u201c4\u201d: This means that there is no structural rela-\ntion between BeanExpression.java and MethodNotFoundException.java, but they were \nfound to have changed together four times in the revision history. A cell with both a number \nand text indicates that this pair of files has both structural and evolutionary coupling rela-\ntions. For example, the cell at row 22, column 1 is marked with \u201cdp, 3\u201d: This means that \nXMLTokenizerExpression.java depends on ExpressionDefinition.java, and they \nwere changed together three times. The matrix in Figure 23.2 is rather dense. Although these files are generally not struc-\nturally coupled to each other, they are strongly evolutionarily coupled. Furthermore, we see \nmany annotations in cells above the diagonal in the matrix. Thus the coupling is not just from \nhigher-level to lower-level files, but rather goes in all directions. This project, in fact, suffers from high architecture debt. The architects confirm this. They report that almost every change in the project is costly and complex, and predicting when \nnew features will be ready or when bugs will be fixed is challenging. While this kind of qualitative analysis can, by itself, be of value to an architect or ana-\nlyst, we can do better: We can actually quantify the costs and impact of the debt that our code \nbase is already carrying, and we can do this fully automatically. To do so, we use the con-\ncept of \u201chotspots\u201d\u2014areas of the architecture with design flaws, sometimes called architecture \nanti-patterns or architecture flaws.", "domains": ["Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 377", "position": 377, "chunk_type": "semantic", "token_estimate": 390}
{"text": "360 Part IV Scalable Architecture Practices | Chapter 23 Managing Architecture Debt: We call the sets of elements that make outsized contributions to the maintenance costs \nof a system hotspots. Architecture debt leads to high maintenance costs due to high coupling \nand low cohesion. So, to identify hotspots, we look for anti-patterns that contribute to high \ncoupling and low cohesion. Six common anti-patterns\u2014which occur in virtually every sys-\ntem\u2014are highlighted here:\n \n\u25a0Unstable interface. An influential file\u2014one representing an important service, resource, \nor abstraction in the system\u2014changes frequently with its dependents, as recorded in the \nrevision history. The \u201cinterface\u201d file is the entry point for other system elements to use \nthe service or resource. It is frequently modified due to internal reasons, changes to its \nAPI, or both. To identify this anti-pattern, search for a file with a large number of depen-\ndents that is modified frequently with other files. \u25a0Modularity violation. Structurally decoupled modules frequently change together. To \nidentify this anti-pattern, search for two or more structurally independent files\u2014that is, \nfiles that have no structural dependency on each other\u2014that change together frequently. \u25a0Unhealthy inheritance. A base class depends on its subclasses or a client class depends \non both the base class and one or more of its subclasses. To determine unhealthy inheri-\ntance instances, search for either of the following two sets of relationships in a DSM:\n \n\u25a0In an inheritance hierarchy, a parent depends on its child class. \u25a0In an inheritance hierarchy, a client of the class hierarchy depends on both the parent \nand one or more of its children. \u25a0Cyclic dependency or clique. A group of files is tightly connected. To identify this \nanti-pattern, search for sets of files that form a strongly connected graph, where there is \na structural dependency path between any two elements of the graph. \u25a0Package cycle. Two or more packages depend on each other, rather than forming a \nhierarchical structure, as they should. Detecting this anti-pattern is similar to detecting \na clique: A package cycle is determined by discovering packages that form a strongly \nconnected graph. \u25a0Crossing. A file has both a high number of dependent files and a high number of files on \nwhich it depends, and it changes frequently with its dependents and the files it depends \non. To determine the file at the center of a crossing, search for a file that has both high \nfan-in and fan-out with other files and that has substantial co-change relations with these \nother files.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 379", "position": 379, "chunk_type": "semantic", "token_estimate": 410}
{"text": "362 Part IV Scalable Architecture Practices | Chapter 23 Managing Architecture Debt: The majority of issues in an issue tracking system can be divided into two broad catego-\nries: bug fixes and feature enhancements. Bug fixes and both bug-related and change- \nrelated \nchurn are highly correlated with anti-patterns and hotspots. In other words, those files that par-\nticipate in anti-patterns and require frequent bug fixes or frequent changes are likely hotspots. For each file, we determine the total number of bug fixes and changes, as well as the total \namount of churn that file has experienced. Next, we sum the bug fixes, changes, and churn \nexperienced by the files in each anti-pattern. This gives us a weighting for each anti-pattern in \nterms of its contribution to architecture debt. In this way, all of the debt-laden files, along with \nall of their relationships, can be identified and their debt quantified. Based on this process, a debt-reduction strategy (typically achieved through refactoring) \nis straightforward. Knowing the files implicated in the debt, along with their flawed relation-\nships (as determined by the identified anti-patterns), allows the architect to fashion and jus-\ntify a refactoring plan. If a clique exists, for example, a dependency needs to be removed or \nreversed, so as to break the cycle of dependencies. If unhealthy inheritance is present, some \nfunctionality needs to be moved, typically from a child class to a parent class. If a modularity \nviolation is identified, the unencapsulated \u201csecret\u201d shared among files needs to be encapsu-\nlated as its own abstraction. And so forth. 23.3  \nExample\nWe illustrate this process with a case study, which we call SS1, done with SoftServe, a multi-\nnational software outsourcing company. At the time of the analysis, the SS1 system contained \n797 source files, and we captured its revision history and issues over a two-year period. SS1 \nwas maintained by six full-time developers and many more occasional contributors. Identifying Hotspots\nDuring the period that we studied SS1, 2,756 issues were recorded in its Jira issue-tracker \n(1,079 of which were bugs) and 3,262 commits were recorded in the Git version control \nrepository. We identified hotspots using the process just described. In the end, three clusters of archi-\ntecturally related files were identified as containing the most harmful anti-patterns and hence \nthe most debt in the project.", "domains": ["Design Patterns", "Software Quality Attributes", "Domain-Driven Design"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 381", "position": 381, "chunk_type": "semantic", "token_estimate": 385}
{"text": "23.7 Discussion Questions 365: The definition of architecture debt used in this chapter was borrowed from [Xiao 16]. The \nSoftServe case study was published in  \n[Kazman 15]. Some of the tools used to create and analyze DSMs are described in [Xiao 14]. The tools \nto detect architectural flaws are introduced in [Mo 15]. The impacts of architecture flaws have been discussed and empirically investigated in \nseveral papers, including [Feng 16] and [Mo 18]. 23.7  \nDiscussion Questions\n1. How would you distinguish a project with architecture debt from a \u201cbusy\u201d project where \nlots of features are being implemented? 2. Find examples of projects that have undergone major refactorings. What evidence was \nused to motivate or justify these refactorings? 3. Under what circumstances is accumulating debt a reasonable strategy? How would you \nknow that you had reached the point of too much debt? 4. Is architecture debt more or less detrimental than other kinds of debt, such as code debt, \ndocumentation debt, or testing debt? 5. Discuss the strengths and weaknesses of doing this kind of architecture analysis as com-\npared with the methods discussed in Chapter 21.", "domains": ["Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 384", "position": 384, "chunk_type": "semantic", "token_estimate": 186}
{"text": "367: 24\n \nThe Role of Architects in \nProjects\nI don\u2019t know why people hire architects and then tell them what to do. \u2014Frank Gehry\nAny practice of architecture performed outside of a classroom takes place in the larger context \nof a development project, which is planned and carried out by people working in one or more \norganizations. Architecture, for all its importance, is only the means toward a larger end. In \nthis chapter, we deal with the aspects of architecture and the architect\u2019s responsibilities that \nderive from the realities of development projects. We begin by discussing a key project role with whom you as an architect are likely to \nhave a close working relationship: the project manager. 24.1  \nThe Architect and the Project Manager\nOne of the most important relations within a team is between the software architect and the \nproject manager. The project manager is responsible for the overall performance of the project\u2014\ntypically for keeping it on budget, on schedule, and staffed with the right people doing the \nright jobs. To carry out these responsibilities, the project manager will often turn to the project \narchitect for support. Think of the project manager as primarily responsible for the external-facing aspects of \nthe project and the software architect as responsible for the internal technical aspects of the \nproject. The external view needs to accurately reflect the internal situation, and the internal \nactivities need to accurately reflect the expectations of the external stakeholders. That is, the \nproject manager should know, and reflect to upper management, the progress and the risks \nwithin the project, whereas the software architect should know, and reflect to developers, \nexternal stakeholder concerns. The relationship between the project manager and the software \narchitect can have a large impact on the success of a project. They should have a good working \nrelationship and be mindful of the roles they are filling and the boundaries of those roles. PART V Architecture and the Organization", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 386", "position": 386, "chunk_type": "semantic", "token_estimate": 324}
{"text": "24.2 Incremental Architecture and Stakeholders 369: 24.2  \nIncremental Architecture and Stakeholders\nAgile methodologies are built on the pillar of incremental development, with each increment \ndelivering value to the customer or user. We\u2019ll discuss Agile and architecture in its own sec-\ntion, but even if your project is not an Agile one, you should still expect to develop and release \nyour architecture in increments following a tempo that supports the project\u2019s own test and \nrelease schedule. Incremental architecture, then, is about releasing the architecture in increments. Specifically, \nthis means releasing architecture documentation (as described in Chapter 22) in increments. This, in turn, entails deciding which views to release (out of your planned set) and at which \ndepth. Using the structures we outlined in Chapter 1, consider these as candidates for your first \nincrement:\n \n\u25a0A module decomposition structure. This will inform the team structure for the devel-\nopment project, allowing the project organization to emerge. Teams can be defined, \nstaffed, budgeted, and trained. The team structure will be the basis of project planning \nand budgeting, so this technical structure defines the project\u2019s management structure. \u25a0A module \u201cuses\u201d structure. This will allow increments to be planned, which is critical \nin any project that hopes to release its software incrementally. As we said in Chapter 1, \nthe uses structure is used to engineer systems that can be extended to add functionality, \nor from which useful functional subsets can be extracted. Trying to create a system that \npurposefully supports incremental development is problematic if you don\u2019t plan what \nexactly the increments will be. \u25a0Whichever component-and-connector (C&C) structure(s) best convey the overall solution \napproach. \u25a0A broad-brush deployment structure that at least addresses major questions such as \nwhether the system will be deployed on mobile devices, on a cloud infrastructure, and \nso forth. After that, use the needs of the architecture\u2019s stakeholders as a guide when crafting the con-\ntents of subsequent releases. Recommendations to the Architect\nFirst and foremost, make sure you know who your stakeholders are and what their needs are, \nso that you can design appropriate solutions and documentation. Moreover:\n \n\u25a0Work with the project\u2019s stakeholders to determine the release tempo and the contents of \neach project increment. \u25a0Your first architectural increment should include module decomposition and uses views, \nas well as a preliminary C&C view.", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 388", "position": 388, "chunk_type": "semantic", "token_estimate": 381}
{"text": "24.2 Incremental Architecture and Stakeholders 369: Moreover:\n \n\u25a0Work with the project\u2019s stakeholders to determine the release tempo and the contents of \neach project increment. \u25a0Your first architectural increment should include module decomposition and uses views, \nas well as a preliminary C&C view. \u25a0Use your influence to ensure that early releases deal with the system\u2019s most challenging \nquality attribute requirements, thereby ensuring that no unpleasant architectural sur-\nprises appear late in the development cycle.", "domains": ["Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 388", "position": 388, "chunk_type": "semantic", "token_estimate": 73}
{"text": "24.3 Architecture and Agile Development 371: (a) BDUF Approach\nDesign Effort\n(b) Emergent Approach\nDesign Effort\nDevelopment\nCycles\n(c) Iteration 0 Approach\nDesign Effort\nDevelopment\nCycles\nFIGURE 24.1 Three approaches to architectural design\nAgile programming and architecture have not always been on the best of terms. The \nAgile Manifesto of 2001, the \u201cPrime Directive\u201d of the Agile movement, implies that architec-\nture is emergent and does not need to be planned or designed up-front. It was (and still is) easy to find published treatments of Agile that declare that if you \naren\u2019t delivering working software, then you aren\u2019t doing anything of value. It follows that if \nyou\u2019re working on an architecture, then you\u2019re taking resources away from programming and, \ntherefore, you\u2019re doing nothing of value\u2014architecture, schmarchitecture! Write the code, and \nthe architecture will emerge organically. For medium to large systems, this view has inevitably collapsed under the harsh weight of \nexperience. Solutions to quality attribute requirements cannot simply be \u201cbolted on\u201d to an exist-\ning system in an arbitrarily late stage of development. Solutions for security, high performance, \nsafety, and many more concerns must be designed into the system\u2019s architecture from the begin-\nning, even if the first 20 planned incremental deliveries don\u2019t exercise those capabilities. Yes, you \ncan begin coding and yes, the architecture will emerge\u2014but it will be the wrong one. In short, the Agile Manifesto makes a pretty lousy prenup agreement for any marriage \nbetween Agile and architecture. However, accompanying the Manifesto are 12 Agile principles", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 390", "position": 390, "chunk_type": "semantic", "token_estimate": 249}
{"text": "24.4 Architecture and Distributed Development 373: Agile Principle\nArchitecture-centric View\nThe best architectures, requirements, and \ndesigns emerge from self-organizing teams. No, they don\u2019t. The best architectures are consciously \ndesigned by skilled, talented, trained, and experi-\nenced architects, as we describe in Chapter 20 \nAt regular intervals, the team reflects on \nhow}to become more effective, and then \ntunes and adjusts}its behavior accordingly. Absolutely. So that\u2019s six \u201cAbsolutely\u201d agreements, four general agreements, and two strong disagreements. Agile, as it was first codified, seemed to work best in small organizations building small \nproducts. Organizations of medium to large size wishing to apply Agile to large projects \nquickly found that coordinating the large number of small Agile teams was a formidable chal-\nlenge. In Agile, small teams do small pieces of work over small intervals. One challenge is \nensuring that these many (dozens to hundreds) small teams have divided the work suitably so \nthat no work is overlooked and no work is done twice. Another challenge is sequencing the \nteams\u2019 many tasks so that their results can be amalgamated, frequently and quickly, to pro-\nduce the next small increment of a sensibly working system. One example of an approach to apply Agile at enterprise scale is the Scaled Agile \nFramework (SAFe), which emerged around 2007 and has been refined continuously since then. SAFe provides a reference model of workflows, roles, and processes under which large organi-\nzations can coordinate the activities of many teams, each operating in classic Agile fashion, to \nsystematically and successfully produce a large-scale system. SAFe acknowledges the role of architecture. It admits \u201cintentional architecture,\u201d the defi-\nnition of which will strike a chord with readers of this book. Intentional architecture \u201cdefines \na set of purposeful, planned architectural strategies and initiatives, which enhance solution \ndesign, performance, and usability and provide guidance for inter-team design and imple-\nmentation synchronization.\u201d But SAFe also strongly counsels a counterbalancing force called \n\u201cemergent design,\u201d which \u201cprovides the technical basis for a fully evolutionary and incremen-\ntal implementation approach \u201d (scaledagileframework.com). We would argue that those qual-\nities would emerge from an intentional architecture as well, since the ability to rapidly evolve \nand the ability to support incremental implementations do not happen without careful up-front \nthought. Ways to achieve these are, in fact, covered throughout this book.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 392", "position": 392, "chunk_type": "semantic", "token_estimate": 380}
{"text": "374 Part V Architecture and the Organization | Chapter 24 The Role of Architects in Projects: Distributed development comes with both benefits and challenges:\n \n\u25a0Cost. Labor costs vary depending on location, and there is a perception that moving \nsome development to a low-cost venue will inevitably decrease the overall cost of the \nproject. Indeed, experience has shown that, for software development, savings may be \nreaped in the long term. However, until the developers in the low-cost venue have a \nsufficient level of domain expertise and until the management practices are adapted to \ncompensate for the difficulties of distributed development, a large amount of rework \nmust be done, thereby cutting into and perhaps overwhelming any savings from wages. \u25a0Skill sets and labor availability. Organizations may not be able to hire developers at \na single location: Relocation costs may be high, the size of the developer pool may be \nsmall, or the skill sets needed may be specialized and unavailable in a single location. Developing a system in a distributed fashion allows for the work to move to where the \nworkers are rather than forcing the workers to move to the work location, albeit at the \ncost of additional communication and coordination. \u25a0Local knowledge of markets. Developers who are developing variants of a system to be \nsold in their market have more knowledge about the types of features that are appropri-\nate and the types of cultural issues that may arise. How does distributed development play out on a project? Assume Module A uses an \ninterface from Module B. In time, as circumstances change, this interface may need to be \nmodified. In consequence, the team responsible for Module B must coordinate with the team \nresponsible for Module A, as indicated in Figure 24.2. This kind of coordination is easy if it \ninvolves a short conversation at the shared vending machines, but it\u2019s not so easy if it involves \na preplanned web conference at a time when it is the middle of the night for one of the teams. Coordination\nTeam A\nTeam B\nDependency\nModule A\nModule B\nFIGURE 24.2 Coordination between teams and modules", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 393", "position": 393, "chunk_type": "semantic", "token_estimate": 353}
{"text": "24.4 Architecture and Distributed Development 375: More broadly, methods for coordination include the following options:\n \n\u25a0Informal contacts. Informal contacts, such as meeting at the coffee room or in the hall-\nway, are possible only if the teams are co-located. \u25a0Documentation. Documentation, if it is well written, well organized, and properly dis-\nseminated, can be used as a means to coordinate the teams, whether they are co-located \nor at a distance. \u25a0Meetings. Teams can hold meetings, either scheduled or ad hoc, and either face to face or \nremote, to help bring the team together and raise awareness of issues. \u25a0Asynchronous electronic communication. Various forms of asynchronous electronic \ncommunication can be used as a coordination mechanism, such as email, news groups, \nblogs, and wikis. The choice of coordination method depends on many factors, including the organization\u2019s \ninfrastructure, corporate culture, language skills, time zones involved, and number of teams \ndependent on a particular module. Until an organization has established a working method for \ncoordinating among distributed teams, misunderstandings among the teams will likely cause \ndelays and, in some cases, serious defects in a project. What does this mean for architecture and the architect? It means that allocation of respon-\nsibilities to teams is more important in distributed development than in co-located develop-\nment, where all of the developers are in a single office, or at least in close proximity. It also \nmeans that attention to module dependencies takes on added importance over and above their \nusual role in quality attributes such as modifiability and performance: Dependencies among \nmodules owned by globally distributed teams are more likely to be problematic and should be \nminimized to the extent possible. In addition, documentation is especially important in distributed development. Co-located \nteams have a variety of informal coordination possibilities such as going to the next office or \nmeeting in the coffee room or the hall. Remote teams do not have these informal mechanisms \navailable, so they must rely on more formal mechanisms such as documentation, and team \nmembers must take the initiative to talk to each other when doubts arise. As this book was being prepared for publication, companies around the world were learn-\ning to cope with remote participation and work-from-home practices due to the COVID-19 \ncrisis. It is too soon to definitively state the long-term effects of this pandemic on the business \nworld, but it seems likely to lead to distributed development becoming the norm.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 394", "position": 394, "chunk_type": "semantic", "token_estimate": 400}
{"text": "24.4 Architecture and Distributed Development 375: As this book was being prepared for publication, companies around the world were learn-\ning to cope with remote participation and work-from-home practices due to the COVID-19 \ncrisis. It is too soon to definitively state the long-term effects of this pandemic on the business \nworld, but it seems likely to lead to distributed development becoming the norm. People work-\ning together are now all doing so via teleconference; there are no more hallway conversations \nor meetings at the vending machines. For work to continue at all, everyone is learning to adapt \nto the distributed development paradigm. It will be fascinating to see if this leads to any new \narchitectural trends.", "domains": ["Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 394", "position": 394, "chunk_type": "semantic", "token_estimate": 116}
{"text": "376 Part V Architecture and the Organization | Chapter 24 The Role of Architects in Projects: 24.5  \nSummary\nSoftware architects do their work in the context of a development project of some sort. As \nsuch, they need to understand their role and responsibilities from that perspective. The project manager and the software architect may be seen as occupying complemen-\ntary roles: The manager runs the project from an administrative perspective, and the architect \nruns the project from a technical solution perspective. These two roles intersect in various \nways, and the architect can support the manager to enhance the project\u2019s chance of success. In a project, architectures do not spring fully formed from Zeus\u2019s forehead, but rather are \nreleased in increments that are useful to stakeholders. Thus the architect needs to have a good \nunderstanding of the architecture\u2019s stakeholders and their information needs. Agile methodologies focus on incremental development. Over time, architecture and \nAgile (although they got off to a rough start together) have become indispensable partners. Global development creates a need for an explicit coordination strategy that is based on \nmore formal strategies than are needed for co-located development. 24.6  \nFor Further Reading\nDan Paulish has written an excellent book on managing in an architecture-centric environment\u2014\nArchitecture-centric Software Project Management: A Practical Guide\u2014and the material in \nthis chapter about distributed development is adapted from his book [Paulish 02]. You can read about SAFe at scaledagileframework.com. Before SAFe, some members of \nthe Agile community had independently arrived at a medium-weight management process that \nadvocates up-front architecture. See [Coplein 10] for a description of the role of architecture in \nagile projects. Basic concepts of project management are covered in thebIEEE Guide, Adoption of the \nProject Management Institute (PMI) Standard: A Guide to the Project Management Body of \nKnowledge, sixth edition [IEEE 17]. Software architecture metrics often fall within an architect\u2019s purview on a project. A \npaper by  \nCoulin et al. provides a helpful overview of the literature on this subject and, along \nthe way, categorizes the metrics themselves [Coulin 19]. Architects occupy a unique position within an organization. They are expected to be flu-\nent in all phases of the system\u2019s life cycle, from the cradle to the grave. Of all the members of \na project, they are the ones most sensitive to the needs of all of the project\u2019s and the system\u2019s \nstakeholders. They usually are chosen to be architects in part because of their above-average \ncommunication skills.", "domains": ["Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 395", "position": 395, "chunk_type": "semantic", "token_estimate": 407}
{"text": "382 Part V Architecture and the Organization | Chapter 25 Architecture Competence: General Duty \nArea\nSpecific Duty \nArea\nExample Duties\nDuties \nconcerned \nwith life-cycle \nactivities \nother than \narchitecting\nManaging the \nrequirements\nAnalyze functional and quality attribute software \nrequirements. Understand business, organizational, and \ncustomer needs, and ensure that the requirements meet \nthese needs. Listen to and understand the scope of the \nproject. Understand the client\u2019s key design needs and \nexpectations. Advise on the tradeoffs between software \ndesign choices and requirements choices. Evaluating future \ntechnologies\nAnalyze the current IT environment and recommend \nsolutions for deficiencies. Work with vendors to represent the \norganization\u2019s requirements and influence future products. Develop and present technical white papers. Selecting tools \nand technology\nManage the introduction of new software solutions. Perform technical feasibility studies of new technologies \nand architectures. Evaluate commercial tools and \nsoftware components from an architectural perspective. Develop internal technical standards and contribute to the \ndevelopment of external technical standards. TABLE 25.2 Nontechnical Duties of a Software Architect\n \nGeneral Duty \nArea\nSpecific Duty \nArea\nExample Duties\nManagement\nSupporting project \nmanagement\nProvide feedback on the appropriateness and difficulty \nof the project. Help with budgeting and planning. Follow \nbudgetary constraints. Manage resources. Perform sizing \nand estimation. Perform migration planning and risk \nassessment. Take care of or oversee configuration control. Create development schedules. Measure results using \nmetrics and improve both personal results and teams\u2019 \nproductivity. Identify and schedule architectural releases. Serve as a \u201cbridge\u201d between the technical team and the \nproject manager. Managing the \npeople on the \narchitect\u2019s team\nBuild \u201ctrusted advisor\u201d relationships. Coordinate. Motivate. Advocate. Train. Act as a supervisor. Allocate \nresponsibilities. Organization- \nand business-\nrelated duties\nSupporting the \norganization \nGrow an architecture evaluation capability in the organization. Review and contribute to research and development efforts. Participate in the hiring process for the team. Help with \nproduct marketing. Institute cost-effective and appropriate \nsoftware architecture design reviews. Help develop \nintellectual property. Supporting the \nbusiness\nUnderstand and evaluate business processes. Translate business strategy into technical strategy. Influence the business strategy. Understand and \ncommunicate the business value of software architecture. Help the organization meet its business goals. Understand \ncustomer and market trends. TABLE 25.1 Technical Duties of a Software Architect continued", "domains": ["Design Patterns", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 401", "position": 401, "chunk_type": "semantic", "token_estimate": 360}
{"text": "25.1 Competence of Individuals: Duties, Skills, and Knowledge of Architects 383: General Duty \nArea\nSpecific Duty \nArea\nExample Duties\nLeadership and \nteam building\nProviding technical \nleadership\nBe a thought leader. Produce technology trend analysis or \nroadmaps. Mentor other architects. Building a team \nBuild the development team and align them with the \narchitecture vision. Mentor developers and junior architects. Educate the team on the use of the architecture. Foster \nthe professional development of team members. Coach \nteams of software design engineers for planning, tracking, \nand completion of work within the agreed plan. Mentor and \ncoach staff in the use of software technologies. Maintain \nmorale, both within and outside the architecture group. Monitor and manage team dynamics. Architects also routinely perform many other duties, such as leading code reviews or \ngetting involved in test planning. In many projects, architects pitch in to help with the actual \nimplementation and testing, in critical areas. While important, these are not strictly speaking \narchitectural duties. Skills\nGiven the wide range of duties enumerated in the previous section, which skills does an architect \nneed to possess? Much has been written about the architect\u2019s special role of leadership in a proj-\nect; the ideal architect is an effective communicator, manager, team builder, visionary, and mentor. Some certificate or certification programs emphasize nontechnical skills. Common to these certi-\nfication programs are assessment areas of leadership, organization dynamics, and communication. Table 25.3 enumerates the set of skills most useful to an architect. TABLE 25.3 Skills of a Software Architect\nGeneral Skill \nArea\nSpecific Skill \nArea\nExample Skills\nCommunication \nskills\nOutward \ncommunication \n(beyond the team)\nAbility to make oral and written communications and \npresentations. Ability to present and explain technical \ninformation to diverse audiences. Ability to transfer \nknowledge. Ability to persuade. Ability to see from and sell \nto multiple viewpoints. Inward \ncommunication \n(within the team)\nAbility to listen, interview, consult, and negotiate. Ability to \nunderstand and express complex topics. Interpersonal \nskills\nTeam \nrelationships\nAbility to be a team player. Ability to work effectively with \nsuperiors, subordinates, colleagues, and customers. Ability to maintain constructive working relationships. Ability \nto work in a diverse team environment. Ability to inspire \ncreative collaboration. Ability to build consensus. Ability to \nbe diplomatic and respect others. Ability to mentor others. Ability to handle and resolve conflict. continues", "domains": ["Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 402", "position": 402, "chunk_type": "semantic", "token_estimate": 379}
{"text": "384 Part V Architecture and the Organization | Chapter 25 Architecture Competence: General Skill \nArea\nSpecific Skill \nArea\nExample Skills\nWork skills\nLeadership\nAbility to make decisions. Ability to take initiative and be \ninnovative. Ability to demonstrate independent judgment, \nbe influential, and command respect. Workload \nmanagement\nAbility to work well under pressure, plan, manage time, and \nestimate. Ability to support a wide range of issues and work \non multiple complex tasks concurrently. Ability to effectively \nprioritize and execute tasks in a high-pressure environment. Skills to excel \nin the corporate \nenvironment\nAbility to think strategically. Ability to work under general \nsupervision and under constraints. Ability to organize \nworkflow. Ability to detect where the power is and how it \nflows in an organization. Ability to do what it takes to get \nthe job done. Ability to be entrepreneurial, to be assertive \nwithout being aggressive, and to receive constructive \ncriticism. Skills for handling \ninformation\nAbility to be detail-oriented while maintaining overall vision \nand focus. Ability to see the big picture. Skills for handling \nthe unexpected\nAbility to tolerate ambiguity. Ability to take and manage \nrisks. Ability to solve problems. Ability to be adaptable, \nflexible, open-minded, and resilient. Ability to think \nabstractly\nAbility to look at different things and find a way to see how \nthey are, in fact, just different instances of the same thing. This may be one of the most important skills for an architect \nto have. Knowledge\nA competent architect has an intimate familiarity with an architectural body of knowledge. Table 25.4 gives a set of knowledge areas for an architect. TABLE 25.4 Knowledge Areas of a Software Architect\n \nGeneral \nKnowledge \nArea\nSpecific \nKnowledge \nArea\nSpecific Knowledge Examples\nComputer \nscience \nknowledge\nKnowledge of \narchitecture \nconcepts\nKnowledge of architecture frameworks, architectural patterns, \ntactics, structures and views, reference architectures, \nrelationships to system and enterprise architecture, emerging \ntechnologies, architecture evaluation models and methods, and \nquality attributes. Knowledge \nof software \nengineering \nKnowledge of software development knowledge areas, \nincluding requirements, design, construction, maintenance, \nconfiguration management, engineering management, \nand software engineering process. Knowledge of systems \nengineering. TABLE 25.3 Skills of a Software Architect continued", "domains": ["Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 403", "position": 403, "chunk_type": "semantic", "token_estimate": 348}
{"text": "25.1 Competence of Individuals: Duties, Skills, and Knowledge of Architects 385: General \nKnowledge \nArea\nSpecific \nKnowledge \nArea\nSpecific Knowledge Examples\nComputer \nscience \nknowledge\nDesign \nknowledge\nKnowledge of tools and design and analysis techniques. Know-\nledge of how to design complex multi-product systems. Knowledge \nof object-oriented analysis and design, and UML and SysML \ndiagrams. Programming \nknowledge\nKnowledge of programming languages and programming lang-\nuage models. Knowledge of specialized programming tech-\nniques for security, real time, safety, etc. Knowledge of \ntechnologies \nand platforms\nSpecific \ntechnologies and \nplatforms\nKnowledge of hardware/software interfaces, web-based \napplications, and Internet technologies. Knowledge of specific \nsoftware/operating systems. General \nknowledge of \ntechnologies and \nplatforms\nKnowledge of the IT industry\u2019s future directions and the ways in \nwhich infrastructure impacts an application. Knowledge \nabout the \norganization\u2019s \ncontext and \nmanagement\nDomain \nknowledge\nKnowledge of the most relevant domains and domain-specific \ntechnologies. Industry \nknowledge\nKnowledge of the industry\u2019s best practices and Industry \nstandards. Knowledge of how to work in onshore/offshore team \nenvironments. Business \nknowledge\nKnowledge of the company\u2019s business practices, and its \ncompetition\u2019s products, strategies, and processes. Knowledge \nof business and technical strategy, and business reengineering \nprinciples and processes. Knowledge of strategic planning, \nfinancial models, and budgeting. Leadership and \nmanagement \ntechniques \nKnowledge of how to coach, mentor, and train software team \nmembers. Knowledge of project management. Knowledge of \nproject engineering. What about Experience? Albert Einstein said, \u201cThe only source of knowledge is experience,\u201d and just about every-\nbody says that experience is the best teacher. We agree. However, experience is not the only \nteacher\u2014you can also acquire knowledge from real teachers. How lucky we are that we need \nnot all burn ourselves to acquire the knowledge that touching a hot stove is a bad idea. We consider experience as something that adds to an architect\u2019s store of knowledge, \nwhich is why we don\u2019t treat it separately. As your career advances, you\u2019ll accumulate your own \nwealth of experience, which you\u2019ll store as knowledge. As the old joke goes, a pedestrian in New York stopped a passerby and asked, \u201cExcuse \nme. Could you tell me how to get to Carnegie Hall?\u201d The passerby, who happened to be a \nmusician, replied with a heavy sigh, \u201cPractice, practice, practice.\u201d\nExactly.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 404", "position": 404, "chunk_type": "semantic", "token_estimate": 363}
{"text": "386 Part V Architecture and the Organization | Chapter 25 Architecture Competence: 25.2  \nCompetence of a Software Architecture Organization\nOrganizations, by their practices and structure, can either help or hinder architects in perform-\ning their duties. For example, if an organization has a career path for architects, that will moti-\nvate employees to become architects. If an organization has a standing architecture review \nboard, then the project architect will know how and with whom to schedule a review. The \nabsence of these practices and structures will mean that an architect has to fight battles with \nthe organization or determine how to carry out a review without internal guidance. It makes \nsense, therefore, to ask whether a particular organization is architecturally competent and to \ndevelop instruments whose goal is measuring the architectural competence of an organiza-\ntion. The architectural competence of organizations is the topic of this section. Here is our \ndefinition:\nThe architectural competence of an organization is the ability of that organization \nto grow, use, and sustain the skills and knowledge necessary to effectively carry out \narchitecture-centric practices at the individual, team, and organizational levels to \nproduce architectures with acceptable cost that lead to systems aligned with the orga-\nnization\u2019s business goals. Organizations have duties, skills, and knowledge for architecture, just like individual \narchitects. For example, adequately funding the architecture effort is an organizational duty, \nas is effectively using the available architecture workforce (by appropriate teaming and other \nmeans). These are organizational duties because they are outside the control of individual \narchitects. An organization-level skill might be effective knowledge management or human \nresource management as applied to architects. An example of organizational knowledge is the \ncomposition of an architecture-based life-cycle model that software projects may employ. Here are some things\u2014duties\u2014that an organization could perform to help improve the \nsuccess of its architecture efforts:\n \n\u25a0Personnel-related:\n \n\u25a0Hire talented architects. \u25a0Establish a career track for architects. \u25a0Make the position of architect highly regarded through visibility, rewards, and \nprestige. \u25a0Have architects join professional organizations. \u25a0Establish an architect certification program. \u25a0Establish a mentoring program for architects. \u25a0Establish an architecture training and education program. \u25a0Measure architects\u2019 performance. \u25a0Have architects receive external architect certifications. \u25a0Reward or penalize architects based on project success or failure.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 405", "position": 405, "chunk_type": "semantic", "token_estimate": 368}
{"text": "25.3 Become a Better Architect 387: \u25a0Process-related:\n \n\u25a0Establish organization-wide architecture practices. \u25a0Establish a clear statement of responsibilities and authority for architects. \u25a0Establish a forum for architects to communicate and share information and experience. \u25a0Establish an architecture review board. \u25a0Include architecture milestones in project plans. \u25a0Have architects provide input into product definition. \u25a0Hold an organization-wide architecture conference. \u25a0Measure and track the quality of architectures produced. \u25a0Bring in outside expert consultants on architecture. \u25a0Have architects advise on the development team structure. \u25a0Give architects influence throughout the entire project life cycle. \u25a0Technology-related:\n \n\u25a0Establish and maintain a repository of reusable architectures and architecture-based \nartifacts. \u25a0Create and maintain a repository of design concepts. \u25a0Provide a centralized resource to analyze and help with architecture tools. If you are interviewing for the position of architect in an organization, you\u2019ll probably \nhave a list of questions to determine if you want to work there. To that list, you can add ques-\ntions drawn from the preceding list to help you ascertain the organization\u2019s level of architec-\nture competence. 25.3  \nBecome a Better Architect\nHow do architects become good architects, and how do good architects become great archi-\ntects? We close this chapter with a proposal, which is this: Be mentored, and mentor others. Be Mentored\nWhile experience may be the best teacher, most of us will not have the luxury, in a single life-\ntime, to gain firsthand all the experience needed to make us great architects. But we can gain \nexperience secondhand. Find a skilled architect whom you respect, and attach yourself to that \nperson. Find out if your organization has a mentoring program that you can join. Or establish \nan informal mentoring relationship\u2014find excuses to interact, ask questions, or offer to help \n(for instance, offer to be a reviewer). Your mentor doesn\u2019t have to be a colleague. You can also join professional societies where \nyou can establish mentor relationships with other members. There are meetups. There are pro-\nfessional social networks. Don\u2019t limit yourself to just your organization.", "domains": ["Design Patterns", "Domain-Driven Design"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 406", "position": 406, "chunk_type": "semantic", "token_estimate": 332}
{"text": "394 Part VI Conclusions | Chapter 26 A Glimpse of the Future: Quantum Computing: 26.2  \nQuantum Teleportation\nRecall that it is not possible to copy one qubit to another directly. Thus, if we want to copy one \nqubit to another, we must use indirect means. Furthermore, we must accept the destruction \nof the state of the original qubit. The recipient qubit will have the same state as the original, \ndestroyed qubit. Quantum teleportation is the name given to this copying of the state. There \nis no requirement that the original qubit and the recipient qubit have any physical relationship, \nnor are there constraints on the distance that separates them. In consequence, it is possible to \ntransfer information over great distances, even hundreds or thousands of kilometers, between \nqubits that have been physically implemented. The teleportation of the state of a qubit depends on entanglement. Recall that entangle-\nment means that a measurement of one entangled qubit will guarantee that a measurement of \nthe second qubit will have the same value. Teleportation utilizes three qubits. Qubit A and \u0392 \nare entangled, and then qubit \u03c8 is entangled with qubit A. Qubit \u03c8 is teleported to the location \nof qubit \u0392, and its state becomes the state of qubit \u0392. Roughly speaking, teleportation proceeds \nthrough these four steps:\n1. Entangle qubits A and \u0392. We discussed what this means in the prior section. The loca-\ntions of A and \u0392 can be physically separate. 2. Prepare the \u201cpayload.\u201d The payload qubit will have the state to be teleported. The pay-\nload, which is the qubit \u03c8, is prepared at the location of A. 3. Propagate the payload. The propagation involves two classical bits that are transferred to \nthe location of \u0392. The propagation also involves measuring A and \u03c8, which destroys the \nstate of both of these qubits. 4. Re-create the state of \u03c8 in \u0392. We have omitted many key details, but the point is this: Quantum teleportation is an \nessential ingredient of quantum communication. It relies on transmitting two bits over con-\nventional communication channels. It is inherently secure, since all that an eavesdropper \ncan determine are the two bits sent over conventional channels. Because A and \u0392 commu-\nnicate through entanglement, they are not physically sent over a communication line.", "domains": ["Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 413", "position": 413, "chunk_type": "semantic", "token_estimate": 381}
{"text": "394 Part VI Conclusions | Chapter 26 A Glimpse of the Future: Quantum Computing: It is inherently secure, since all that an eavesdropper \ncan determine are the two bits sent over conventional channels. Because A and \u0392 commu-\nnicate through entanglement, they are not physically sent over a communication line. The \nU.S. National Institute of Science and Technology (NIST) is considering a variety of differ-\nent quantum-based communication protocols to be the basis of a transport protocol called \nHTTPQ, which is intended to be a replacement for HTTPS. Given that it takes decades to \nreplace one communication protocol with another, the goal is for HTTPQ to be adopted prior \nto the availability of quantum computers that can break HTTPS. 26.3  \nQuantum Computing and Encryption\nQuantum computers are extremely proficient at calculating the inverse of a function\u2014in par-\nticular, the inverse of a hash function. There are many cases where this kind of calculation", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 413", "position": 413, "chunk_type": "semantic", "token_estimate": 153}
{"text": "Quantum random access memory (QRAM) is a critical element for implementing and apply-: ing many quantum algorithms. QRAM, or something similar, will be necessary to provide \nefficient access to large amounts of data such as that used in machine learning applications. Currently, no implementation of QRAM exists, but several research groups are exploring how \nsuch an implementation could work. Conventional RAM comprises a hardware device that takes as input a memory location \nand returns as output the contents of that memory location. QRAM is conceptually similar: It \ntakes as input a memory location (likely a superposition of memory locations) and returns as \noutput the superpositioned contents of those memory locations. The memory locations whose \ncontents are returned were written conventionally\u2014that is, each bit has one value. The values \nare returned in superposition, and the amplitudes are determined by the specification of the", "domains": ["Domain-Driven Design"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 414", "position": 414, "chunk_type": "semantic", "token_estimate": 142}
{"text": "26.6 Final Thoughts 397: substantial improvements over classical algorithms, but the remainder of the application areas \nare, thus far, the subject of much and feverish research. As yet, however, none of these efforts \nhas generated public results. As the chapter-opening quotation suggested, quantum computers are at the stage that air-\nplanes were at the time of the Wright brothers. The promise is great but a tremendous amount \nof work must be done to turn the promise into reality. 26.6  \nFinal Thoughts\nQuantum computers are currently in their infancy. Applications for such computers are pri-\nmarily speculation at this point, especially applications that require large amounts of data. Nonetheless, progress is happening rapidly in terms of the number of qubits in actual physical \nexistence. It seems reasonable that Moore\u2019s law will apply to quantum computers, much as it \nhas in conventional computing. If so, then the number of qubits available will grow exponen-\ntially over time. The qubit operations discussed in Section 26.2 lend themselves to a programming style \nwhere operations are chained together to perform useful functionality. This will likely follow \nthe same arc as machine languages for classical computers. Machine languages still exist but \nhave become a realm consigned to only a handful of programmers. Most programmers use \na wide variety of higher-level languages. We should expect to see the same evolution in pro-\ngramming quantum computers. Efforts at quantum computing language design are under way \nbut remain in a nascent state. Programming languages are only the tip of the iceberg. What about the other topics we \nhave covered in this book? Are there new quality attributes relevant to quantum computers, \nnew architectural patterns, an additional architecture view? Almost certainly. What will a network of quantum computers look like? Will hybrid networks of quantum \nand classical computers become widespread? All of these are potential areas into which quan-\ntum computing will almost certainly evolve\u2014eventually. What can architects do in the meantime? First, pay attention to breaking developments. If the systems you are working on today involve areas that quantum computing is likely to \naffect (or, more likely, completely turn on its head), isolate those parts of the system to mini-\nmize the disruption when quantum computing finally shows up. Especially for secure systems, \nfollow the field to find out what to do when your conventional encryption algorithms become \nworthless. But your preparation need not all be defensive.", "domains": ["Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 416", "position": 416, "chunk_type": "semantic", "token_estimate": 398}
{"text": "398 Part VI Conclusions | Chapter 26 A Glimpse of the Future: Quantum Computing: 26.7  \nFor Further Reading\nGeneral overview:\n \n\u25a0Programming Quantum Computers by Eric Johnston, Nic Harrigan, and Mercedes \nGimeno-Segovia discusses quantum computing without reference to physics or linear \nalgebra [Johnston 19]. \u25a0Quantum Computing: Progress and Prospects [NASEM 19] provides an overview of \nthe current state of quantum computing and the challenges to be overcome to make real \nquantum computers. \u25a0Quantum computers not only provide faster solutions compared to classical computers, \nbut also address some problems that can only be solved with quantum computers. This \npowerful theoretical result emerged in May 2018: quantamagazine.org/finally-a-problem-\nthat-only-quantum-computers-will-ever-be-able-to-solve-20180621/.", "domains": ["Design Patterns"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 417", "position": 417, "chunk_type": "semantic", "token_estimate": 105}
{"text": "399: References\n \n[Abrahamsson 10] P. Abrahamsson, M. A. Babar, and P. Kruchten. \u201cAgility and Architecture: \nCan They Coexist?\u201d IEEE Software 27, no. 2 (March\u2013April 2010): 16\u201322. [AdvBuilder 10] Java Adventure Builder Reference Application. https://adventurebuilder.dev\n.java.net\n[Anastasopoulos 00] M. Anastasopoulos and C. Gacek. \u201cImplementing Product Line Variabil-\nities\u201d (IESE-Report no. 089.00/E, V1.0). Kaiserslautern, Germany: Fraunhofer Institut \nExperimentelles Software Engineering, 2000. [Anderson 20] Ross Anderson. Security Engineering: A Guide to Building Dependable \nDistributed Systems, 3rd ed. Wiley, 2020. [Argote 07] L. Argote and G. Todorova. International Review of Industrial and Organizational \nPsychology. John Wiley & Sons, 2007. [Avi\u017eienis 04] Algirdas Avi\u017eienis, Jean-Claude Laprie, Brian Randell, and Carl Landwehr. \u201cBasic Concepts and Taxonomy of Dependable and Secure Computing,\u201d IEEE Trans-\nactions on Dependable and Secure Computing 1, no. 1 (January 2004): 11\u201333. [Bachmann 00a] Felix Bachmann, Len Bass, Jeromy Carriere, Paul Clements, David Garlan, \nJames Ivers, Robert Nord, and Reed Little. \u201cSoftware Architecture Documentation in \nPractice: Documenting Architectural Layers,\u201d CMU/SEI-2000-SR-004, 2000. [Bachmann 00b] F. Bachmann, L. Bass, G. Chastek, P. Donohoe, and F. Peruzzi. \u201cThe  \nArchit \necture-\nBased Design Method,\u201d CMU/SEI-2000-TR-001, 2000. [Bachmann 05] F. Bachmann and P. Clements. \u201cVariability in Software Product Lines,\u201d CMU/\nSEI-2005-TR-012, 2005. [Bachmann 07] Felix Bachmann, Len Bass, and Robert Nord. \u201cModifiability Tactics,\u201d CMU/\nSEI-2007-TR-002, September 2007. [Bachmann 11] F. Bachmann. \u201cGive the Stakeholders What They Want: Design Peer Reviews \nthe ATAM Style,\u201d Crosstalk (November/December 2011): 8\u201310, crosstalkonline.org/ \nstorage/issue-archives/2011/201111/201111-Bachmann.pdf. [Barba \ncci 03] M. Barbacci, R. Ellison, A. Lattanze, J. Stafford, C. Weinstock, and W. Wood. \u201cQuality Attribute Workshops (QAWs), Third Edition,\u201d CMU/SEI-2003-TR-016, sei.cmu\n.edu/reports/03tr016.pdf. [Bass 03] L. Bass and B. E. John. \u201cLinking Usability to Software Architecture Patterns \nthrough General Scenarios,\u201d Journal of Systems and Software 66, no. 3 (2003): 187\u2013197. [Bass 07] Len Bass, Robert Nord, William G. Wood, and David Zubrow. \u201cRisk Themes \nDiscovered through Architecture Evaluations,\u201d in Proceedings of WICSA 07, 2007.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 418", "position": 418, "chunk_type": "semantic", "token_estimate": 307}
{"text": "400 References: [Bass 08] Len Bass, Paul Clements, Rick Kazman, and Mark Klein. \u201cModels for Evaluating \nand Improving Architecture Competence,\u201d CMU/SEI-2008-TR-006, March 2008, \nsei.cmu.edu/library/abstracts/reports/08tr006.cfm. [Bass 15] Len Bass, Ingo Weber, and Liming Zhu. DevOps: A Software Architect\u2019s Perspective. Addison-Wesley, 2015. [Bass 19] Len Bass and John Klein. Deployment and Operations for Software Engineers. Amazon, 2019. [Baudry 03] B. Baudry, Yves Le Traon, Gerson Suny\u00e9, and Jean-Marc J\u00e9z\u00e9quel. \u201cMeasuring \nand Improving Design Patterns Testability,\u201d Proceedings of the Ninth International \nSoftware Metrics Symposium (METRICS \u201903), 2003. [Baudry 05] B. Baudry and Y. Le Traon. \u201cMeasuring Design Testability of a UML Class \nDiagram,\u201d Information & Software Technology 47, no. 13 (October 2005): 859\u2013879. [Beck 02] Kent Beck. Test-Driven Development by Example. Addison-Wesley, 2002. [Beck 04] Kent Beck and Cynthia Andres. Extreme Programming Explained: Embrace \nChange, 2nd ed. Addison-Wesley, 2004. [Beizer 90] B. Beizer. Software Testing Techniques, 2nd ed. International Thomson Computer \nPress, 1990. [Bellcore 98] Bell Communications Research. GR-1230-CORE, SONET Bidirectional Line-\nSwitched Ring Equipment Generic Criteria. 1998. [Bellcore 99] Bell Communications Research. GR-1400-CORE, SONET Dual-Fed \nUnidirectional Path Switched Ring (UPSR) Equipment Generic Criteria. 1999. [Bellomo 15] S. Bellomo, I. Gorton, and R. Kazman. \u201cInsights from 15 Years of ATAM Data: \nTowards Agile Architecture,\u201d IEEE Software 32, no. 5 (September/October 2015): 38\u201345. [Benkler 07] Y. Benkler. The Wealth of Networks: How Social Production Transforms Markets \nand Freedom. Yale University Press, 2007. [Bertolino 96a] Antonia Bertolino and Lorenzo Strigini. \u201cOn the Use of Testability Measures \nfor Dependability Assessment,\u201d IEEE Transactions on Software Engineering 22, no. 2 \n(February 1996): 97\u2013108. [Bertolino 96b] A. Bertolino and P. Inverardi. \u201cArchitecture-Based Software Testing,\u201d in \nProceedings of the Second International Software Architecture Workshop (ISAW-2), \nL. Vidal, A. Finkelstain, G. Spanoudakis, and A. L. Wolf, eds. Joint Proceedings of the \nSIGSOFT \u201996 Workshops, San Francisco, October 1996. ACM Press. [Biffl 10] S. Biffl, A. Aurum, B. Boehm, H. Erdogmus, and P. Grunbacher, eds. Value-Based \nSoftware Engineering. Springer, 2010. [Binder 94] R. V. Binder. \u201cDesign for Testability in Object-Oriented Systems,\u201d CACM 37, no. 9 \n(1994): 87\u2013101. [Binder 00] R. Binder. Testing Object-Oriented Systems: Models, Patterns, and Tools. Addison-Wesley, 2000. [Boehm 78] B. W. Boehm, J. R. Brown, J. R. Kaspar, M. L. Lipow, and G. MacCleod. Characteristics of Software Quality. American Elsevier, 1978. [Boehm 81] B. Boehm. Software Engineering Economics. Prentice Hall, 1981. [Boehm 91] Barry Boehm. \u201cSoftware Risk Management: Principles and Practices,\u201d IEEE \nSoftware 8, no. 1 (January 1991): 32\u201341.", "domains": ["Design Principles", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 419", "position": 419, "chunk_type": "semantic", "token_estimate": 400}
{"text": "References 401: [Boehm 04] B. Boehm and R. Turner. Balancing Agility and Discipline: A Guide for the \nPerplexed. Addison-Wesley, 2004. [Boehm 07] B. Boehm, R. Valerdi, and E. Honour. \u201cThe ROI of Systems Engineering: Some \nQuantitative Results for Software Intensive Systems,\u201d Systems Engineering 11, no. 3 \n(2007): 221\u2013234. [Boehm 10] B. Boehm, J. Lane, S. Koolmanojwong, and R. Turner. \u201cArchitected Agile \nSolutions for Software-Reliant Systems,\u201d Technical Report USC-CSSE-2010-516, 2010. [Bondi 14] A. B. Bondi. Foundations of Software and System Performance Engineering: \nProcess, Performance Modeling, Requirements, Testing, Scalability, and Practice. Addison-Wesley, 2014. [Booch 11] Grady Booch. \u201cAn Architectural Oxymoron,\u201d podcast available at computer.org/\nportal/web/computingnow/onarchitecture. Retrieved January 21, 2011. [Bosch 00] J. Bosch. \u201cOrganizing for Software Product Lines,\u201d Proceedings of the 3rd \nInternational Workshop on Software Architectures for Product Families (IWSAPF-3), \npp. 117\u2013134. Las Palmas de Gran Canaria, Spain, March 15\u201317, 2000. Springer, 2000. [Bouwers 10] E. Bouwers and A. van Deursen. \u201cA Lightweight Sanity Check for Implemented \nArchitectures,\u201d IEEE Software 27, no. 4 (July/August 2010): 44\u201350. [Bredemeyer 11] D. Bredemeyer and R. Malan. \u201cArchitect Competencies: What You Know, What \nYou Do and What You Are,\u201d http://www.bredemeyer.com/Architect/ArchitectSkillsLinks.htm. [Brewer 12] E. Brewer. \u201cCAP Twelve Years Later: How the \u2018Rules\u2019 Have Changed,\u201d IEEE \nComputer (February 2012): 23\u201329. [Brown 10] N. Brown, R. Nord, and I. Ozkaya. \u201cEnabling Agility through Architecture,\u201d \nCrosstalk (November/December 2010): 12\u201317. [Brownsword 96] Lisa Brownsword and Paul Clements. \u201cA Case Study in Successful Product \nLine Development,\u201d Technical Report CMU/SEI-96-TR-016, October 1996. [Brownsword 04] Lisa Brownsword, David Carney, David Fisher, Grace Lewis, Craig Meterys, \nEdwin Morris, Patrick Place, James Smith, and Lutz Wrage. \u201cCurrent Perspectives on \nInteroperability,\u201d CMU/SEI-2004-TR-009, sei.cmu.edu/reports/04tr009.pdf. [Bruntink 06] Magiel Bruntink and Arie van Deursen. \u201cAn Empirical Study into Class \nTestability,\u201d Journal of Systems and Software 79, no. 9 (2006): 1219\u20131232. [Buschmann 96] Frank Buschmann, Regine Meunier, Hans Rohnert, Peter Sommerlad, and \nMichael Stal. Pattern-Oriented Software Architecture Volume 1: A System of Patterns. Wiley, 1996. [Cai 11] Yuanfang Cai, Daniel Iannuzzi, and Sunny Wong. \u201cLeveraging Design Structure \nMatrices in Software Design Education,\u201d Conference on Software Engineering Education \nand Training 2011, pp. 179\u2013188. [Cappelli 12] Dawn M. Cappelli, Andrew P. Moore, and Randall F. Trzeciak. The CERT Guide \nto Insider Threats: How to Prevent, Detect, and Respond to Information Technology \nCrimes (Theft, Sabotage, Fraud). Addison-Wesley, 2012. [Carriere 10] J. Carriere, R. Kazman, and I. Ozkaya.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 420", "position": 420, "chunk_type": "semantic", "token_estimate": 384}
{"text": "402 References: [Cataldo 07] M. Cataldo, M. Bass, J. Herbsleb, and L. Bass. \u201cOn Coordination Mechanisms in \nGlobal Software Development,\u201d Proceedings Second IEEE International Conference on \nGlobal Software Development, 2007. [Cervantes 13] H. Cervantes, P. Velasco, and R. Kazman. \u201cA Principled Way of Using \nFrameworks in Architectural Design,\u201d IEEE Software (March/April 2013): 46\u201353. [Cervantes 16] H. Cervantes and R. Kazman. Designing Software Architectures: A Practical \nApproach. Addison-Wesley, 2016. [Chandran 10] S. Chandran, A. Dimov, and S. Punnekkat. \u201cModeling Uncertainties in the \nEstimation of Software Reliability: A Pragmatic Approach,\u201d Fourth IEEE International \nConference on Secure Software Integration and Reliability Improvement, 2010. [Chang 06] F. Chang, J. Dean, S. Ghemawat, W. Hsieh, et al. \u201cBigtable: A Distributed \nStorage System for Structured Data,\u201d Proceedings of Operating Systems Design and \nImplementation, 2006, http://research.google.com/archive/ bigtable.html. [Chen 10] H.-M. Chen, R. Kazman, and O. Perry. \u201cFrom Software Architecture Analysis to \nService Engineering: An Empirical Study of Enterprise SOA Implementation,\u201d IEEE \nTransactions on Services Computing 3, no. 2 (April\u2013June 2010): 145\u2013160. [Chidamber 94] S. Chidamber and C. Kemerer. \u201cA Metrics Suite for Object Oriented Design,\u201d \nIEEE Transactions on Software Engineering20, no. 6 (June 1994). [Chowdury 19] S. Chowdhury, A. Hindle, R. Kazman, T. Shuto, K. Matsui, and Y. Kamei. \u201cGreenBundle: An Empirical Study on the Energy Impact of Bundled Processing,\u201d \nProceedings of the International Conference on Software Engineering, May 2019. [Clements 01a] P. Clements and L. Northrop. Software Product Lines. Addison-Wesley, 2001. [Clements 01b] P. Clements, R. Kazman, and M. Klein. Evaluating Software Architectures. Addison-Wesley, 2001. [Clements 07] P. Clements, R. Kazman, M. Klein, D. Devesh, S. Reddy, and P. Verma. \u201cThe \nDuties, Skills, and Knowledge of Software Architects,\u201d Proceedings of the Working \nIEEE/IFIP Conference on Software Architecture, 2007. [Clements 10a] Paul Clements, Felix Bachmann, Len Bass, David Garlan, James Ivers, \nReed Little, Paulo Merson, Robert Nord, and Judith Stafford. Documenting Software \nArchitectures: Views and Beyond, 2nd ed. Addison-Wesley, 2010. [Clements 10b] Paul Clements and Len Bass. \u201cRelating Business Goals to Architecturally \nSignificant Requirements for Software Systems,\u201d CMU/SEI-2010-TN-018, May 2010. [Clements 10c] P. Clements and L. Bass. \u201cThe Business Goals Viewpoint,\u201d IEEE Software 27, \nno. 6 (November\u2013December 2010): 38\u201345. [Clements 16] Paul Clements and Linda Northrop. Software Product Lines: Practices and \nPatterns. Addison-Wesley, 2016. [Cockburn 04] Alistair Cockburn. Crystal Clear: A Human-Powered Methodology for Small \nTeams. Addison-Wesley, 2004. [Cockburn 06] Alistair Cockburn. Agile Software Development: The Cooperative Game. Addison-Wesley, 2006. [Conway 68] Melvin E. Conway.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 421", "position": 421, "chunk_type": "semantic", "token_estimate": 398}
{"text": "404 References: [Feng 16] Q. Feng, R. Kazman, Y. Cai, R. Mo, and L. Xiao. \u201cAn Architecture-centric Approach \nto Security Analysis,\u201d in Proceedings of the 13th Working IEEE/IFIP Conference on \nSoftware Architecture (WICSA 2016), 2016. [Fiol 85] C. M. Fiol and M. A. Lyles. \u201cOrganizational Learning,\u201d Academy of Management \nReview 10, no. 4 (1985):. 803. [Fonseca 19] A. Fonseca, R. Kazman, and P. Lago. \u201cA Manifesto for Energy-Aware Software,\u201d \nIEEE Software 36 (November/December 2019): 79\u201382. [Fowler 09] Martin Fowler. \u201cTechnicalDebtQuadrant,\u201d https://martinfowler.com/bliki/\nTechnicalDebtQuadrant.html, 2009. [Fowler 10] Martin Fowler. \u201cBlue Green Deployment,\u201d https://martinfowler.com/bliki/\nBlueGreenDeployment.html, 2010. [Freeman 09] Steve Freeman and Nat Pryce. Growing Object-Oriented Software, Guided by \nTests. Addison-Wesley, 2009. [Gacek 95] Cristina Gacek, Ahmed Abd-Allah, Bradford Clark, and Barry Boehm. \u201cOn the \nDefinition of Software System Architecture,\u201d USC/CSE-95-TR-500, April 1995. [Gagliardi 09] M. Gagliardi, W. Wood, J. Klein, and J. Morley. \u201cA Uniform Approach for \nSystem of Systems Architecture Evaluation,\u201d Crosstalk 22, no. 3 (March/April 2009): \n12\u201315. [Gajjarby 17] Manish J. Gajjarby. Mobile Sensors and Context-Aware Computing. Morgan \nKaufman, 2017. [Gamma 94] E. Gamma, R. Helm, R. Johnson, and J. Vlissides. Design Patterns: Elements of \nReusable Object-Oriented Software. Addison-Wesley, 1994. [Garlan 93] D. Garlan and M. Shaw. \u201cAn Introduction to Software Architecture,\u201d in Ambriola \nand Tortola, eds., Advances in Software Engineering & Knowledge Engineering, Vol. II. World Scientific Pub., 1993, pp. 1\u201339. [Garlan 95] David Garlan, Robert Allen, and John Ockerbloom. \u201cArchitectural Mismatch or \nWhy It\u2019s Hard to Build Systems out of Existing Parts,\u201d 17th International Conference on \nSoftware Engineering, April 1995. [Gilbert 07] T. Gilbert. Human Competence: Engineering Worthy Performance. Pfeiffer, \nTribute Edition, 2007. [Gokhale 05] S. Gokhale, J. Crigler, W. Farr, and D. Wallace. \u201cSystem Availability Analysis \nConsidering Hardware/Software Failure Severities,\u201d Proceedings of the 29th Annual \nIEEE/NASA Software Engineering Workshop (SEW \u201905), Greenbelt, MD, April 2005. IEEE, 2005. [Gorton 10] Ian Gorton. Essential Software Architecture, 2nd ed. Springer, 2010. [Graham 07] T. C. N. Graham, R. Kazman, and C. Walmsley. \u201cAgility and Experimentation: \nPractical Techniques for Resolving Architectural Tradeoffs,\u201d Proceedings of the 29th \nInternational Conference on Software Engineering (ICSE 29), Minneapolis, MN, May \n2007. [Gray 93] Jim Gray and Andreas Reuter. Distributed Transaction Processing: Concepts and \nTechniques. Morgan Kaufmann, 1993. [Grinter 99] Rebecca E. Grinter. \u201cSystems Architecture: Product Designing and Social \nEngineering,\u201d in Proceedings of the International Joint Conference on Work Activities", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 423", "position": 423, "chunk_type": "semantic", "token_estimate": 383}
{"text": "References 405: Coordination and Collaboration (WACC \u201999), Dimitrios Georgakopoulos, Wolfgang \nPrinz, and Alexander L. Wolf, eds. ACM, 1999, pp. 11\u201318. [Hamm 04] \u201cLinus Torvalds\u2019 Benevolent Dictatorship,\u201d BusinessWeek, August 18, 2004, busi-\nnessweek.com/technology/content/aug2004/tc20040818_1593.htm. [Hamming 80] R. W. Hamming. Coding and Information Theory. Prentice Hall, 1980. [Hanmer 13] Robert S. Hanmer. Patterns for Fault Tolerant Software, Wiley Software Patterns \nSeries, 2013. [Harms 10] R. Harms and M. Yamartino. \u201cThe Economics of the Cloud,\u201d http://economics. uchicago.edu/pdf/Harms_110111.pdf. [Hartman 10] Gregory Hartman. \u201cAttentiveness: Reactivity at Scale,\u201d CMU-ISR-10-111, 2010. [Hiltzik 00] M. Hiltzik. Dealers of Lightning: Xerox PARC and the Dawn of the Computer \nAge. Harper Business, 2000. [Hoare 85] C. A. R. Hoare. Communicating Sequential Processes. Prentice Hall International \nSeries in Computer Science, 1985. [Hoffman 00] Daniel M. Hoffman and David M. Weiss. Software Fundamentals: Collected \nPapers by David L. Parnas. Addison-Wesley, 2000. [Hofmeister 00] Christine Hofmeister, Robert Nord, and Dilip Soni. Applied Software \nArchitecture. Addison-Wesley, 2000. [Hofmeister 07] Christine Hofmeister, Philippe Kruchten, Robert L. Nord, Henk Obbink, \nAlexander Ran, and Pierre America. \u201cA General Model of Software Architecture Design \nDerived from Five Industrial Approaches,\u201d Journal of Systems and Software 80, no. 1 \n(January 2007): 106\u2013126. [Hohpe 20] Gregor Hohpe. The Software Architect Elevator: Redefining the Architect\u2019s Role \nin the Digital Enterprise. O\u2019Reilly, 2020. [Howard 04] Michael Howard. \u201cMitigate Security Risks by Minimizing the Code You Expose \nto Untrusted Users,\u201d MSDN Magazine, http://msdn.microsoft.com/en-us/magazine/\ncc163882.aspx. [Hubbard 14] D. Hubbard. How to Measure Anything: Finding the Value of Intangibles in \nBusiness. Wiley, 2014. [Humble 10] Jez Humble and David Farley. Continuous Delivery: Reliable Software Releases \nthrough Build, Test, and Deployment Automation, Addison-Wesley, 2010. [IEEE 94] \u201cIEEE Standard for Software Safety Plans,\u201d STD-1228-1994, http://standards.ieee\n.org/findstds/standard/1228-1994.html. [IEEE 17] \u201cIEEE Guide: Adoption of the Project Management Institute (PMI) Standard: A \nGuide to the Project Management Body of Knowledge (PMBOK Guide), Sixth Edition,\u201d \nprojectsmart.co.uk/pmbok.html. [IETF 04] Internet Engineering Task Force. \u201cRFC 3746, Forwarding and Control Element \nSeparation (ForCES) Framework,\u201d 2004. [IETF 05] Internet Engineering Task Force. \u201cRFC 4090, Fast Reroute Extensions to RSVP-TE \nfor LSP Tunnels,\u201d 2005. [IETF 06a] Internet Engineering Task Force. \u201cRFC 4443, Internet Control Message Protocol \n(ICMPv6) for the Internet Protocol Version 6 (IPv6) Specification,\u201d 2006.", "domains": ["Software Quality Attributes", "Domain-Driven Design"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 424", "position": 424, "chunk_type": "semantic", "token_estimate": 358}
{"text": "406 References: [IETF 06b] Internet Engineering Task Force. \u201cRFC 4379, Detecting Multi-Protocol Label \nSwitched (MPLS) Data Plane Failures,\u201d 2006. [INCOSE 05] International Council on Systems Engineering. \u201cSystem Engineering \nCompetency Framework 2010\u20130205,\u201d incose.org/ProductsPubs/products/competencies-\nframework.aspx. [INCOSE 19] International Council on Systems Engineering, \u201cFeature-Based Systems and \nSoftware Product Line Engineering: A Primer,\u201d Technical Product INCOSE-TP-2019-\n002-03-0404, \nhttps://connect.incose.org/Pages/Product-Details.aspx?ProductCode=PLE_\nPrimer_2019. [Ingeno 18] Joseph Ingeno. Software Architect\u2019s Handbook. Packt Publishing, 2018. [ISO 11] International Organization for Standardization. \u201cISO/IEC 25010: 2011 Systems and \nSoftware Engineering\u2014Systems and Software Quality Requirements and Evaluation \n(SQuaRE)\u2014System and Software Quality Models.\u201d\n[Jacobson 97] I. Jacobson, M. Griss, and P. Jonsson. Software Reuse: Architecture, Process, \nand Organization for Business Success. Addison-Wesley, 1997. [Johnston 19] Eric Johnston, Nic Harrigan, and Mercedes Gimeno-Segovia, Programming \nQuantum Computers. O\u2019Reilly, 2019. [Kanwal 10] F. Kanwal, K. Junaid, and M.A. Fahiem. \u201cA Hybrid Software Architecture \nEvaluation Method for FDD: An Agile Process Mode,\u201d 2010 International Conference on \nComputational Intelligence and Software Engineering (CiSE), December 2010, pp. 1\u20135. [Kaplan 92] R. Kaplan and D. Norton. \u201cThe Balanced Scorecard: Measures That Drive \nPerformance,\u201d Harvard Business Review (January/February 1992): 71\u201379. [Karat 94] Claire Marie Karat. \u201cA Business Case Approach to Usability Cost Justification,\u201d in \nCost-Justifying Usability, R. Bias and D. Mayhew, eds. Academic Press, 1994. [Kazman 94] Rick Kazman, Len Bass, Mike Webb, and Gregory Abowd. \u201cSAAM: A Method \nfor Analyzing the Properties of Software Architectures,\u201d in Proceedings of the 16th \nInternational Conference on Software Engineering (ICSE \u201994). Los Alamitos, CA. IEEE \nComputer Society Press, 1994, pp. 81\u201390. [Kazman 99] R. Kazman and S. J. Carriere. \u201cPlaying Detective: Reconstructing Software \nArchitecture from Available Evidence,\u201d Automated Software Engineering 6, no 2 (April \n1999): 107\u2013138. [Kazman 01] R. Kazman, J. Asundi, and M. Klein. \u201cQuantifying the Costs and Benefits of \nArchitectural Decisions,\u201d Proceedings of the 23rd International Conference on Software \nEngineering (ICSE 23), Toronto, Canada, May 2001, pp. 297\u2013306. [Kazman 02] R. Kazman, L. O\u2019Brien, and C. Verhoef. \u201cArchitecture Reconstruction \nGuidelines, Third Edition,\u201d CMU/SEI Technical Report, CMU/SEI-2002-TR-034, 2002. [Kazman 04] R. Kazman, P. Kruchten, R. Nord, and J. Tomayko. \u201cIntegrating Software-\nArchitecture-Centric Methods into the Rational Unified Process,\u201d Technical Report \nCMU/SEI-2004-TR-011, July 2004, sei.cmu.edu/library/abstracts/reports/04tr011.cfm. [Kazman 05] Rick Kazman and Len Bass. \u201cCategorizing Business Goals for Software \nArchitectures,\u201d CMU/SEI-2005-TR-021, December 2005.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 425", "position": 425, "chunk_type": "semantic", "token_estimate": 366}
{"text": "References 407: [Kazman 09] R. Kazman and H.-M. Chen. \u201cThe Metropolis Model: A New Logic for the \nDevelopment of Crowdsourced Systems,\u201d Communications of the ACM (July 2009): \n76\u201384. [Kazman 15] R. Kazman, Y. Cai, R. Mo, Q. Feng, L. Xiao, S. Haziyev, V. Fedak, and A. \nShapochka. \u201cA Case Study in Locating the Architectural Roots of Technical Debt,\u201d in \nProceedings of the International Conference on Software Engineering (ICSE) 2015, \n2015. [Kazman 18] R. Kazman, S. Haziyev, A. Yakuba, and D. Tamburri. \u201cManaging Energy \nConsumption as an Architectural Quality Attribute,\u201d IEEE Software 35, no. 5 (2018). [Kazman 20a] R. Kazman, P. Bianco, J. Ivers, and J. Klein. \u201cIntegrability,\u201d CMU/SEI-\n2020-TR-001, 2020. [Kazman 20b] R. Kazman, P. Bianco, J. Ivers, and J. Klein. \u201cMaintainability,\u201d CMU/SEI-\n2020-TR-006, 2020. [Kircher 03] Michael Kircher and Prashant Jain. Pattern-Oriented Software Architecture \nVolume 3: Patterns for Resource Management. Wiley, 2003. [Klein 10] J. Klein and M. Gagliardi. \u201cA Workshop on Analysis and Evaluation of Enterprise \nArchitectures,\u201d CMU/SEI-2010-TN-023, sei.cmu.edu/reports/10tn023.pdf. [Klein 93] M. Klein, T. Ralya, B. Pollak, R. Obenza, and M. Gonzalez Harbour. A \nPractitioner\u2019s Handbook for Real-Time Systems Analysis. Kluwer Academic, 1993. [Koopman 10] Phil Koopman. Better Embedded System Software. Drumnadrochit Education, \n2010. [Koziolet 10] H. Koziolek. \u201cPerformance Evaluation of Component-Based Software Systems: \nA Survey,\u201d Performance Evaluation 67, no. 8 (August 2010). [Kruchten 95] P. B. Kruchten. \u201cThe 4+1 View Model of Architecture,\u201d IEEE Software 12, \nno. 6 (November 1995): 42\u201350. [Kruchten 03] Philippe Kruchten. The Rational Unified Process: An Introduction, 3rd ed. Addison-Wesley, 2003. [Kruchten 04] Philippe Kruchten. \u201cAn Ontology of Architectural Design Decisions,\u201d in Jan \nBosch, ed., Proceedings of the 2nd Workshop on Software Variability Management, \nGroningen, Netherlands, December 3\u20134, 2004. [Kruchten 19] P. Kruchten, R. Nord, and I. Ozkaya. Managing Technical Debt: Reducing \nFriction in Software Development. Addison-Wesley, 2019. [Kumar 10a] K. Kumar and T. V. Prabhakar. \u201cPattern-Oriented Knowledge Model for \nArchitecture Design,\u201d in Pattern Languages of Programs Conference 2010, Reno/Tahoe, \nNV: October 15\u201318, 2010. [Kumar 10b] Kiran Kumar and T. V. Prabhakar. \u201cDesign Decision Topology Model for Pattern \nRelationship Analysis,\u201d Asian Conference on Pattern Languages of Programs 2010, \nTokyo, Japan, March 15\u201317, 2010. [Ladas 09] Corey Ladas. Scrumban: Essays on Kanban Systems for Lean Software \nDevelopment. Modus Cooperandi Press, 2009. [Lamport 98] Leslie Lamport. \u201cThe Part-Time Parliament,\u201d ACM Transactions on Computer \nSystems 16, no. 2 (May 1998): 133\u2013169.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 426", "position": 426, "chunk_type": "semantic", "token_estimate": 385}
{"text": "408 References: [Lampson 11] Butler Lampson, \u201cHints and Principles for Computer System Design,\u201d https://\narxiv.org/pdf/2011.02455.pdf. [Lattanze 08] Tony Lattanze. Architecting Software Intensive Systems: A Practitioner\u2019s Guide. Auerbach Publications, 2008. [Le Traon 97] Y. Le Traon and C. Robach. \u201cTestability Measurements for Data Flow Designs,\u201d \nProceedings of the 4th International Symposium on Software Metrics (METRICS \u201997). Washington, DC: November 1997, pp. 91\u201398. [Leveson 04] Nancy G. Leveson. \u201cThe Role of Software in Spacecraft Accidents,\u201d Journal of \nSpacecraft and Rockets 41, no. 4 (July 2004): 564\u2013575. [Leveson 11] Nancy G. Leveson. Engineering a Safer World: Systems Thinking Applied to \nSafety. MIT Press, 2011. [Levitt 88] B. Levitt and J. March. \u201cOrganizational Learning,\u201d Annual Review of Sociology 14 \n(1988): 319\u2013340. [Lewis 14] J. Lewis and M. Fowler. \u201cMicroservices,\u201d https://martinfowler.com/articles/ \nmicroservices.html, 2014. [Liu 00] Jane Liu. Real-Time Systems. Prentice Hall, 2000. [Liu 09] Henry Liu. Software Performance and Scalability: A Quantitative Approach. Wiley, \n2009. [Luftman 00] J. Luftman. \u201cAssessing Business Alignment Maturity,\u201d Communications of AIS \n4, no. 14 (2000). [Lyons 62] R. E. Lyons and W. Vanderkulk. \u201cThe Use of Triple-Modular Redundancy to \nImprove Computer Reliability,\u201d IBM Journal of Research and Development 6, no. 2 \n(April 1962): 200\u2013209. [MacCormack 06] A. MacCormack, J. Rusnak, and C. Baldwin. \u201cExploring the Structure of \nComplex Software Designs: An Empirical Study of Open Source and Proprietary Code,\u201d \nManagement Science 52, no 7 (July 2006): 1015\u20131030. [MacCormack 10] A. MacCormack, C. Baldwin, and J. Rusnak. \u201cThe Architecture of Complex \nSystems: Do Core-Periphery Structures Dominate?\u201d MIT Sloan Research Paper no. 4770-\n10, hbs.edu/research/pdf/10-059.pdf. [Malan 00] Ruth Malan and Dana Bredemeyer. \u201cCreating an Architectural Vision: Collecting \nInput,\u201d July 25, 2000, bredemeyer.com/pdf_files/vision_input.pdf. [Maranzano 05] Joseph F. Maranzano, Sandra A. Rozsypal, Gus H. Zimmerman, Guy W. \nWarnken, Patricia E. Wirth, and David M. Weiss. \u201cArchitecture Reviews: Practice and \nExperience,\u201d IEEE Software (March/April 2005): 34\u201343. [Martin 17] Robert C. Martin. Clean Architecture: A Craftsman\u2019s Guide to Software Structure \nand Design. Pearson, 2017. [Mavis 02] D. G. Mavis. \u201cSoft Error Rate Mitigation Techniques for Modern Microcircuits,\u201d in \n40th Annual Reliability Physics Symposium Proceedings, April 2002, Dallas, TX. IEEE, \n2002. [McCall 77] J. A. McCall, P. K. Richards, and G. F. Walters. Factors in Software Quality. Griffiths Air Force Base, NY: Rome Air Development Center Air Force Systems \nCommand.", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 427", "position": 427, "chunk_type": "semantic", "token_estimate": 373}
{"text": "References 409: [McConnell 07] Steve McConnell. \u201cTechnical Debt,\u201d construx.com/10x_Software_\nDevelopment/Technical_Debt/, 2007. [McGregor 11] John D. McGregor, J. Yates Monteith, and Jie Zhang. \u201cQuantifying Value \nin Software Product Line Design,\u201d in Proceedings of the 15th International Software \nProduct Line Conference, Volume 2 (SPLC \u201911), Ina Schaefer, Isabel John, and Klaus \nSchmid, eds. [Mettler 91] R. Mettler. \u201cFrederick C. Lindvall,\u201d in Memorial Tributes: National Academy of \nEngineering, Volume 4. National Academy of Engineering, 1991, pp. 213\u2013216. [Mo 15] R. Mo, Y. Cai, R. Kazman, and L. Xiao. \u201cHotspot Patterns: The Formal Definition \nand Automatic Detection of Architecture Smells,\u201d in Proceedings of the 12th Working \nIEEE/IFIP Conference on Software Architecture (WICSA 2015), 2015. [Mo 16] R. Mo, Y. Cai, R. Kazman, L. Xiao, and Q. Feng. \u201cDecoupling Level: A New Metric \nfor Architectural Maintenance Complexity,\u201d Proceedings of the International Conference \non Software Engineering (ICSE) 2016, Austin, TX, May 2016. [Mo 18] R. Mo, W. Snipes, Y. Cai, S. Ramaswamy, R. Kazman, and M. Naedele. \u201cExperiences \nApplying Automated Architecture Analysis Tool Suites,\u201d in Proceedings of Automated \nSoftware Engineering (ASE) 2018, 2018. [Moore 03] M. Moore, R. Kazman, M. Klein, and J. Asundi. \u201cQuantifying the Value of \nArchitecture Design Decisions: Lessons from the Field,\u201d Proceedings of the 25th \nInternational Conference on Software Engineering (ICSE 25), Portland, OR, May 2003, \npp. 557\u2013562. [Morelos-Zaragoza 06] R. H. Morelos-Zaragoza. The Art of Error Correcting Coding, 2nd ed. Wiley, 2006. [Muccini 03] H. Muccini, A. Bertolino, and P. Inverardi. \u201cUsing Software Architecture for \nCode Testing,\u201d IEEE Transactions on Software Engineering 30, no. 3 (2003): 160\u2013171. [Muccini 07] H. Muccini. \u201cWhat Makes Software Architecture-Based Testing Distinguishable,\u201d \nin Proceedings of the Sixth Working IEEE/IFIP Conference on Software Architecture, \nWICSA 2007, Mumbai, India, January 2007. [Murphy 01] G. Murphy, D. Notkin, and K. Sullivan. \u201cSoftware Reflexion Models: Bridging \nthe Gap between Design and Implementation,\u201d IEEE Transactions on Software \nEngineering 27 (2001): 364\u2013380. [NASEM 19] National Academies of Sciences, Engineering, and Medicine. Quantum Computing: \nProgress and Prospects. National Academies Press, 2019. https://doi.org/10.17226/25196. [Newman 15] Sam Newman. Building Microservices: Designing Fine-Grained Systems. O\u2019Reilly, 2015. [Nielsen 08] Jakob Nielsen. \u201cUsability ROI Declining, But Still Strong,\u201d useit.com/alertbox/\nroi.html. [NIST 02] National Institute of Standards and Technology. \u201cSecurity Requirements for Cryptographic \nModules,\u201d FIPS Pub. 140-2, http://csrc.nist.gov/publications/fips/fips140-2/fips1402.pdf. [NIST 04] National Institute of Standards and Technology. \u201cStandards for Security Categor-\nization of Federal Information Systems,\u201d FIPS Pub. 199, http://csrc.nist.gov/publications/\nfips/fips199/FIPS-PUB-199-final.pdf.", "domains": ["Architectural Patterns and Styles", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 428", "position": 428, "chunk_type": "semantic", "token_estimate": 391}
{"text": "410 References: [NIST 06] National Institute of Standards and Technology. \u201cMinimum Security Requirements \nfor Federal Information and Information Systems,\u201d FIPS Pub. 200, http://csrc.nist.gov/\npublications/fips/fips200/FIPS-200-final-march.pdf. [NIST 09] National Institute of Standards and Technology. \u201c800-53 v3 Recommended \nSecurity Controls for Federal Information Systems and Organizations,\u201d August 2009, \nhttp://csrc.nist.gov/publications/nistpubs/800-53-Rev3/sp800-53-rev3-final.pdf. [Nord 04] R. Nord, J. Tomayko, and R. Wojcik. \u201cIntegrating Software Architecture-Centric \nMethods into Extreme Programming (XP),\u201d CMU/SEI-2004-TN-036. Software Engineer-\ning Institute, Carnegie Mellon University, 2004. [Nygard 18] Michael T. Nygard. Release It! : Design and Deploy Production-Ready Software, \n2nd ed. Pragmatic Programmers, 2018. [Obbink 02] H. Obbink, P. Kruchten, W. Kozaczynski, H. Postema, A. Ran, L. Dominic, \nR. Kazman, R. Hilliard, W. Tracz, and E. Kahane. \u201cSoftware Architecture Review \nand Assessment (SARA) Report, Version 1.0,\u201d 2002, http://pkruchten.wordpress.com/\narchitecture/SARAv1.pdf/. [O\u2019Brien 03] L. O\u2019Brien and C. Stoermer. \u201cArchitecture Reconstruction Case Study,\u201d CMU/\nSEI Technical Note, CMU/SEI-2003-TN-008, 2003. [ODUSD 08] Office of the Deputy Under Secretary of Defense for Acquisition and Technology. \u201cSystems Engineering Guide for Systems of Systems, Version 1.0,\u201d 2008, acq.osd.mil/se/\ndocs/SE-Guide-for-SoS.pdf. [Oki 88] Brian Oki and Barbara Liskov. \u201cViewstamped Replication: A New Primary Copy \nMethod to Support Highly-Available Distributed Systems,\u201d PODC \u201888: Proceedings of \nthe Seventh Annual ACM Symposium on Principles of Distributed Computing, January \n1988, pp. 8\u201317, https://doi.org/10.1145/62546.62549. [Palmer 02] Stephen Palmer and John Felsing. A Practical Guide to Feature-Driven \nDevelopment. Prentice Hall, 2002. [Pang 16] C. Pang, A. Hindle, B. Adams, and A. Hassan. \u201cWhat Do Programmers Know about \nSoftware Energy Consumption?,\u201d IEEE Software 33, no. 3 (2016): 83\u201389. [Paradis 21] C. Paradis, R. Kazman, and D. Tamburri. \u201cArchitectural Tactics for Energy \nEfficiency: Review of the Literature and Research Roadmap,\u201d Proceedings of the Hawaii \nInternational Conference on System Sciences (HICSS) 54 (2021). [Parnas 72] D. L. Parnas. \u201cOn the Criteria to Be Used in Decomposing Systems into Modules,\u201d \nCommunications of the ACM 15, no. 12 (December 1972). [Parnas 74] D. Parnas. \u201cOn a \u2018Buzzword\u2019: Hierarchical Structure,\u201d in Proceedings of IFIP \nCongress 74, pp. 336\u2013339. North Holland Publishing Company, 1974. [Parnas 76] D. L. Parnas. \u201cOn the Design and Development of Program Families,\u201d IEEE \nTransactions on Software Engineering, SE-2, 1 (March 1976): 1\u20139. [Parnas 79] D. Parnas. \u201cDesigning Software for Ease of Extension and Contraction,\u201d IEEE \nTransactions on Software Engineering, SE-5, 2 (1979): 128\u2013137. [Parnas 95] David Parnas and Jan Madey. \u201cFunctional Documents for Computer Systems,\u201d in \nScience of Computer Programming. Elsevier, 1995. [Paulish 02] Daniel J. Paulish.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 429", "position": 429, "chunk_type": "semantic", "token_estimate": 396}
{"text": "References 411: [Pena 87] William Pena. Problem Seeking: An Architectural Programming Primer. AIA \nPress, 1987. [Perry 92] Dewayne E. Perry and Alexander L. Wolf. \u201cFoundations for the Study of Software \nArchitecture,\u201d SIGSOFT Software Engineering Notes 17, no. 4 (October 1992): 40\u201352. [Pettichord 02] B. Pettichord. \u201cDesign for Testability,\u201d Pacific Northwest Software Quality \nConference, Portland, Oregon, October 2002. [Procaccianti 14] G. Procaccianti, P. Lago, and G. Lewis. \u201cA Catalogue of Green Architectural \nTactics for the Cloud,\u201d in IEEE 8th International Symposium on the Maintenance and \nEvolution of Service-Oriented and Cloud-Based Systems, 2014, pp. 29\u201336. [Powel Douglass 99] B. Powel Douglass. Doing Hard Time: Developing Real-Time Systems \nwith UML, Objects, Frameworks, and Patterns. Addison-Wesley, 1999. [Raiffa 00] H. Raiffa & R. Schlaifer. Applied Statistical Decision Theory. Wiley, 2000. [SAE 96]  \nSAE International,  \n\u201cARP-4761: Guidelines and Methods for Conducting the Safety \nAssessment Process on Civil Airborne Systems and Equipment,\u201d December 1, 1996, \nsae.org/standards/content/arp4761/. [Sangwan 08] Raghvinder Sangwan, Colin Neill, Matthew Bass, and Zakaria El Houda. \u201cIntegrating a Software Architecture-Centric Method into Object-Oriented Analysis and \nDesign,\u201d Journal of Systems and Software 81, no. 5 (May 2008): 727\u2013746. [Sato 14] D. Sato. \u201cCanary Deployment,\u201d https://martinfowler.com/bliki/CanaryRelease.html, \n2014. [Schaarschmidt 20] M. Schaarschmidt, M. Uelschen, E. Pulvermuellerm, and C. Westerkamp. \u201cFramework of Software Design Patterns for Energy-Aware Embedded Systems,\u201d \nProceedings of the 15th International Conference on Evaluation of Novel Approaches to \nSoftware Engineering (ENASE 2020), 2020. [Schmerl 06] B. Schmerl, J. Aldrich, D. Garlan, R. Kazman, and H. Yan. \u201cDiscovering \nArchitectures from Running Systems,\u201d IEEE Transactions on Software Engineering 32, \nno. 7 (July 2006): 454\u2013466. [Schmidt 00] Douglas Schmidt, M. Stal, H. Rohnert, and F. Buschmann. Pattern-Oriented \nSoftware Architecture: Patterns for Concurrent and Networked Objects. Wiley, 2000. [Schmidt 10] Klaus Schmidt. High Availability and Disaster Recovery: Concepts, Design, \nImplementation. Springer, 2010. [Schneier 96] B. Schneier. Applied Cryptography. Wiley, 1996. [Schneier 08] Bruce Schneier. Schneier on Security. Wiley, 2008. [Schwaber 04] Ken Schwaber. Agile Project Management with Scrum. Microsoft Press, 2004. [Scott 09] James Scott and Rick Kazman. \u201cRealizing and Refining Architectural Tactics: \nAvailability,\u201d Technical Report CMU/SEI-2009-TR-006, August 2009. [Seacord 13] Robert Seacord. Secure Coding in C and C++. Addison-Wesley, 2013. [SEI 12] Software Engineering Institute. \u201cA Framework for Software Product Line Practice, \nVersion 5.0,\u201d sei.cmu.edu/productlines/frame_report/ PL.essential.act.htm. [Shaw 94] Mary Shaw. \u201cProcedure Calls Are the Assembly Language of Software Interconnections: \nConnectors Deserve First-Class Status,\u201d Carnegie Mellon University Technical Report, \n1994, http://repository.cmu.edu/cgi/viewcontent.cgi?article=1234&context=sei.", "domains": ["Architectural Patterns and Styles", "Software Quality Attributes", "Domain-Driven Design"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 430", "position": 430, "chunk_type": "semantic", "token_estimate": 392}
{"text": "412 References: [Shaw 95] Mary Shaw. \u201cBeyond Objects: A Software Design Paradigm Based on Process \nControl,\u201d ACM Software Engineering Notes 20, no. 1 (January 1995): 27\u201338. [Smith 01] Connie U. Smith and Lloyd G. Williams. Performance Solutions: A Practical \nGuide to Creating Responsive, Scalable Software. Addison-Wesley, 2001. [Soni 95] Dilip Soni, Robert L. Nord, and Christine Hofmeister. \u201cSoftware Architecture in \nIndustrial Applications,\u201d International Conference on Software Engineering 1995, April \n1995, pp. 196\u2013207. [Stonebraker 09] M. Stonebraker. \u201cThe \u2018NoSQL\u2019 Discussion Has Nothing to Do with SQL,\u201d \nhttp://cacm.acm.org/blogs/blog-cacm/50678-the-nosql-discussion-has-nothing-to-do-\nwith-sql/fulltext. [Stonebraker 10a] M. Stonebraker. \u201cSQL Databases v. NoSQL Databases,\u201d Communications \nof the ACM 53, no 4 (2010): 10. [Stonebraker 10b] M. Stonebraker, D. Abadi, D. J. Dewitt, S. Madden, E. Paulson, A. Pavlo, \nand A. Rasin. \u201cMapReduce and Parallel DBMSs,\u201d Communications of the ACM 53 \n(2010): 6. [Stonebraker 11] M. Stonebraker. \u201cStonebraker on NoSQL and Enterprises,\u201d Communications \nof the ACM 54, no. 8 (2011): 10. [Storey 97] M.-A. Storey, K. Wong, and H. M\u00fcller. \u201cRigi: A Visualization Environment for \nReverse Engineering (Research Demonstration Summary),\u201d 19th International Conference \non Software Engineering (ICSE 97), May 1997, pp. 606\u2013607. IEEE Computer Society \nPress. [Svahnberg 00] M. Svahnberg and J. Bosch. \u201cIssues Concerning Variability in Software Product \nLines,\u201d in Proceedings of the Third International Workshop on Software Architectures for \nProduct Families, Las Palmas de Gran Canaria, Spain, March 15\u201317, 2000, pp. 50\u201360. Springer, 2000. [Taylor 09] R. Taylor, N. Medvidovic, and E. Dashofy. Software Architecture: Foundations, \nTheory, and Practice. Wiley, 2009. [Telcordia 00] Telcordia. \u201cGR-253-CORE, Synchronous Optical Network (SONET) Transport \nSystems: Common Generic Criteria.\u201d 2000. [Urdangarin 08] R. Urdangarin, P. Fernandes, A. Avritzer, and D. Paulish. \u201cExperiences with \nAgile Practices in the Global Studio Project,\u201d Proceedings of the IEEE International \nConference on Global Software Engineering, 2008. [USDOD 12] U.S. Department of Defense, \u201c \nStandard Practice: System Safety, MIL-STD-\n882E,\u201d May 11, 2012, dau.edu/cop/armyesoh/DAU%20Sponsored%20Documents/MIL-\nSTD-882E.pdf. [Utas 05] G. Utas. Robust Communications Software: Extreme Availability, Reliability, and \nScalability for Carrier-Grade Systems. Wiley, 2005. [van der Linden 07] F. van der Linden, K. Schmid, and E. Rommes. Software Product Lines in \nAction. Springer, 2007. [van Deursen 04] A. van Deursen, C. Hofmeister, R. Koschke, L. Moonen, and C. Riva. \u201cSymphony: View-Driven Software Architecture Reconstruction,\u201d Proceedings of the \n4th Working IEEE/IFIP Conference on Software Architecture (WICSA 2004), June 2004, \nOslo, Norway. IEEE Computer Society.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 431", "position": 431, "chunk_type": "semantic", "token_estimate": 383}
{"text": "References 413: [van Vliet 05] H. van Vliet. \u201cThe GRIFFIN Project: A GRId For inFormatIoN about \nArchitectural Knowledge,\u201d http://griffin.cs.vu.nl/, Vrije Universiteit, Amsterdam, April \n16, 2005. [Verizon 12] \u201cVerizon 2012 Data Breach Investigations Report,\u201d verizonbusiness.com/\nresources/reports/rp_data-breach-investigations-report-2012_en_xg.pdf. [Vesely 81] W.E. Vesely, F. F. Goldberg, N. H. Roberts, and D. F. Haasl. \u201cFault Tree Handbook,\u201d \nnrc.gov/reading-rm/doc-collections/nuregs/staff/sr0492/ sr0492.pdf. [Vesely 02] William Vesely, Michael Stamatelatos, Joanne Dugan, Joseph Fragola, Joseph \nMinarick III, and Jan Railsback. \u201cFault Tree Handbook with Aerospace Applications,\u201d \nhq.nasa.gov/office/codeq/doctree/fthb.pdf. [Viega 01] John Viega and Gary McGraw. Building Secure Software: How to Avoid Security \nProblems the Right Way. Addison-Wesley, 2001. [Voas 95] Jeffrey M. Voas and Keith W. Miller. \u201cSoftware Testability: the New Verification,\u201d \nIEEE Software 12, no. 3 (May 1995): 17\u201328. [Von Neumann 56] J. Von Neumann. \u201cProbabilistic Logics and the Synthesis of Reliable \nOrganisms from Unreliable Components,\u201d in Automata Studies, C. E. Shannon and \nJ. McCarthy, eds. Princeton University Press, 1956. [Wojcik 06] R. Wojcik, F. Bachmann, L. Bass, P. Clements, P. Merson, R. Nord, and W. \nWood. \u201cAttribute-Driven Design (ADD), Version 2.0,\u201d Technical Report CMU/SEI-\n2006-TR-023, November 2006, sei.cmu.edu/library/abstracts/reports/06tr023.cfm. [Wood 07] W. Wood. \u201cA Practical Example of Applying Attribute-Driven Design (ADD), \nVersion 2.0,\u201d Technical Report CMU/SEI-2007-TR-005, February 2007, sei.cmu.edu/\nlibrary/abstracts/reports/07tr005.cfm. [Woods 11] E. Woods and N. Rozanski. Software Systems Architecture: Working with Stake-\nholders Using Viewpoints and Perspectives, 2nd ed. Addison-Wesley, 2011. [Wozniak 07] J. Wozniak, V. Baggiolini, D. Garcia Quintas, and J. Wenninger. \u201cSoftware Inter-\nlocks System,\u201d Proceedings of ICALEPCS07, http://ics-web4.sns.ornl.gov/icalepcs07/\nWPPB03/WPPB03.PDF. [Wu 04] W. Wu and T. Kelly, \u201cSafety Tactics for Software Architecture Design,\u201d Proceedings \nof the 28th Annual International Computer Software and Applications Conference \n(COMPSAC), 2004. [Wu 06] W. Wu and T. Kelly. \u201cDeriving Safety Requirements as Part of System Architecture \nDefinition,\u201d in Proceedings of 24th International System Safety Conference. Albuquerque, \nNM: System Safety Society, August 2006. [Xiao 14] L. Xiao, Y. Cai, and R. Kazman. \u201cTitan: A Toolset That Connects Software \nArchitecture with Quality Analysis,\u201d Proceedings of the 22nd ACM SIGSOFT \nInternational Symposium on the Foundations of Software Engineering (FSE 2014), 2014. [Xiao 16] L. Xiao, Y. Cai, R. Kazman, R. Mo, and Q. Feng. \u201cIdentifying and Quantifying \nArchitectural Debts,\u201d Proceedings of the International Conference on Software \nEngineering (ICSE) 2016, 2016. [Yacoub 02] S. Yacoub and H. Ammar. \u201cA Methodology for Architecture-Level Reliability \nRisk Analysis,\u201d IEEE Transactions on Software Engineering 28, no. 6 (June 2002). [Yin 94] James Bieman and Hwei Yin.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 432", "position": 432, "chunk_type": "semantic", "token_estimate": 396}
{"text": "References 413: 6 (June 2002). [Yin 94] James Bieman and Hwei Yin. \u201cDesigning for Software Testability Using Automated \nOracles,\u201d Proceedings International Test Conference, September 1992, pp. 900\u2013907.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 432", "position": 432, "chunk_type": "semantic", "token_estimate": 27}
{"text": "415: About the Authors\nLen Bass is an award-winning author who has lectured widely around the world. His books \non software architecture are standards. In addition to his books on software architecture, Len \nhas also written books on User Interface Software and DevOps. Len has over 50 years\u2019 expe-\nrience in software development, 25 of those at the Software Engineering Institute of Carnegie \nMellon. He also worked for three years at NICTA in Australia and is currently an adjunct fac-\nulty member at Carnegie Mellon University, where he teaches DevOps. Dr. Paul Clements is the Vice President of Customer Success at BigLever Software, Inc., \nwhere he works to spread the adoption of systems and software product line engineering. Prior \nto this, he was a senior member of the technical staff at Carnegie Mellon University\u2019s Software \nEngineering Institute, where for 17 years he worked leading or co-leading projects in soft-\nware product line engineering and software architecture design, documentation, and analysis. Prior to the SEI, he was a computer scientist with the U.S. Naval Research Laboratory in \nWashington, DC, where his work involved applying advanced software engineering principles \nto real-time embedded systems. In addition to this book, Clements is the co-author of two other practitioner-oriented \nbooks about software architecture: Documenting Software Architectures: Views and Beyond \nand Evaluating Software Architectures: Methods and Case Studies.bHe also co-wrote Software \nProduct Lines: Practices and Patterns and was co-author and editor of Constructing Superior \nSoftware. In addition, Clements has authored about a hundred papers in software engineering, \nreflecting his long-standing interest in the design and specification of challenging software \nsystems. Rick Kazman is a Professor at the University of Hawaii and a Visiting Researcher at the \nSoftware Engineering Institute of Carnegie Mellon University. His primary research inter-\nests are software architecture, design and analysis tools, software visualization, and software \nengineering economics. Kazman has been involved in the creation of several highly influen-\ntial methods and tools for architecture analysis, including the ATAM (Architecture Tradeoff \nAnalysis Method), the CBAM (Cost-Benefit Analysis Method), and the Dali and Titan tools.bIn \naddition to this book, he is the author of over 200 publications and is co-author of three patents \nand eight books, including Technical Debt: How to Find It and Fix It, Designing Software \nArchitectures: A Practical Approach, Evaluating Software Architectures: Methods and Case", "domains": ["Domain-Driven Design", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 434", "position": 434, "chunk_type": "semantic", "token_estimate": 384}
{"text": "417: Index\nA/B testing, 86\nAbort tactic, 159\nAbstract common services, 108\nAbstract data sources for testability, 189\nAbstraction, architecture as, 3\nACID (atomic, consistent, isolated, and durable) \nproperties, 61\nAcronym lists in documentation, 346\nActive redundancy, 66\nActivity diagrams for traces, 342\u2013343\nActors\nattack, 174\nelements, 217\nActuators\nmobile systems, 263, 267\u2013268\nsafety concerns, 151\u2013152\nAdapt tactic for integrability, 108\u2013109, 111\nADD method. See Attribute-Driven Design \n(ADD) method\nADLs (architecture description languages), 331\nAggregation for usability, 201\nAgile development, 370\u2013373\nAgile Manifesto, 371\u2013372\nAir France flight 447, 152\nAllocated-to relation\nallocation views, 337\ndeployment structure, 15\nAllocation structures, 10, 15\u201316\nAllocation views\ndocumentation, 348\u2013350\noverview, 337\u2013338\nAllowed-to-use relationship, 128\u2013129\nAlternative requests in long tail latency, 252\nAmazon service-level agreements, 53\nAnalysis\nADD method, 295, 304\u2013305\nATAM, 318\u2013319, 321\nautomated, 363\u2013364\nAnalysts\ndocumentation, 350\nsoftware interface documentation for, 229\nAnalytic redundancy tactic\navailability, 58\nsafety, 159\nApache Camel project, 356\u2013359\nApache Cassandra database, 360\u2013361\nApplications for quantum computing, 396\u2013397\nApproaches\nATAM, 317\u2013319, 321\nCIA, 169\nLightweight Architecture Evaluation, 325\nArchitects\ncommunication with, 29\ncompetence, 379\u2013385\nduties, 379\u2013383\nevaluation by, 311\nknowledge, 384\u2013385\nmentoring, 387\u2013388\nmobile system concerns, 264\u2013273\nrole. See Role of architects\nskills, 383\u2013384\nArchitectural debt\nautomation, 363\u2013364\ndetermining, 356\u2013358\nexample, 362\u2013363\nhotspots, 358\u2013362\nintroduction, 355\u2013356\nquantifying, 363\nsummary, 364\nArchitectural structures, 7\u201310\nallocation, 15\u201316\nC&C, 14\u201316\nlimiting, 18\nmodule, 10\u201314\nrelating to each other, 15\u201318\nselecting, 18\ntable of, 17\nviews, 5\u20136\nArchitecturally significant requirements (ASRs)\nADD method, 289\u2013290\nfrom business goals, 282\u2013284\nchange, 286", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 436", "position": 436, "chunk_type": "semantic", "token_estimate": 247}
{"text": "418 Index: introduction, 277\u2013278\nfrom requirements documents, 278\u2013279\nstakeholder interviews, 279\u2013282\nsummary, 286\u2013287\nutility trees for, 284\u2013286\nArchitecture\nchanges, 27\ncloud. See Cloud and distributed computing\ncompetence. See Competence\ndebt. See Architectural debt\ndesign. See Design and design strategy\ndocumentation. See Documentation\nevaluating. See Evaluating architecture\nintegrability, 102\u2013103\nmodifiability. See Modifiability\npatterns. See Patterns\nperformance. See Performance\nQAW drivers, 281\nQAW plan presentation, 280\nquality attributes. See Quality attributes\nrequirements. See Architecturally significant \nrequirements (ASRs); Requirements\nsecurity. See Security\nstructures. See Architectural structures\ntactics. See Tactics\ntestability. See Testability\nusability. See Usability\nArchitecture description languages (ADLs), 331\nArchitecture Tradeoff Analysis Method \n(ATAM), 313\napproaches, 317\u2013319, 321\nexample exercise, 321\u2013324\noutputs, 314\u2013315\nparticipants, 313\u2013314\nphases, 315\u2013316\npresentation, 316\u2013317\nresults, 321\nscenarios, 318\nsteps, 316\u2013321\nAriane 5 explosion, 151\nArtifacts\nADD method, 291\navailability, 53\ncontinuous deployment, 74\ndeployability, 76\nenergy efficiency, 91\nin evaluation, 312\nintegrability, 104\nmodifiability, 120\u2013121\nperformance, 136\nquality attributes expressions, 43\u201344\nsafety, 154\nsecurity, 171\ntestability, 186\nusability, 198\nAspects for testability, 190\nASRs. See Architecturally significant \nrequirements (ASRs)\nAssertions for system state, 190\nAssurance levels in design, 164\nAsynchronous electronic communication, 375\nATAM. See Architecture Tradeoff Analysis \nMethod (ATAM)\nAtomic, consistent, isolated, and durable (ACID) \nproperties, 61\nAttachment relation for C&C structures, 14\u201316\nAttachments in C&C views, 335\nAttribute-Driven Design (ADD) method\nanalysis, 295, 304\u2013305\ndesign concepts, 295\u2013298\ndesign decisions, 294\ndocumentation, 301\u2013303\ndrivers, 292\u2013294\nelement choice, 293\u2013294\nelement instantiation, 299\u2013300\ninputs, 292\noverview, 289\u2013291\nprototypes, 297\u2013298\nresponsibilities, 299\u2013300\nsteps, 292\u2013295\nstructures, 298\u2013301\nsummary, 306\nviews, 294, 301\u2013302\nAttributes. See Quality attributes\nAudiences for documentation, 330\u2013331\nAudits, 176\nAuthenticate actors tactic, 174\nAuthorize actors tactic, 174\nAutomation, 363\u2013364\nAutoscaling in distributed computing, 258\u2013261\nAvailability\nCIA approach, 169\ncloud, 253\u2013261\ndetect faults tactic, 56\u201359", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 437", "position": 437, "chunk_type": "semantic", "token_estimate": 287}
{"text": "Index 419: general scenario, 53\u201355\nintroduction, 51\u201352\npatterns, 66\u201369\nprevent faults tactic, 61\u201362\nquestionnaires, 62\u201365\nrecover from faults tactics, 59\u201361\ntactics overview, 55\u201356\nAvailability of resources tactic, 139\nAvailability quality attribute, 285\nAvailability zones, 248\nBacklogs in ADD method, 304\nBandwidth in mobile systems, 267\nBare-metal hypervisors, 235\nBarrier tactic, 159\u2013160, 162\nBattery management systems (BMSs), 264\nBDUF (Big Design Up Front), 370\u2013371\nBehavior\ndocumenting, 340\u2013345\nin software architecture, 4\nBehavioral semantic distance in architecture \nintegrability, 103\nBell, Alexander Graham, 263\u2013264\nBest practices in design concepts, 296\nBig Design Up Front (BDUF), 370\u2013371\nBinding\ndynamic discovery services, 114\nintegrability, 109\nmodifiability, 122, 124\u2013125\nBlocked time performance effects, 138\u2013139\nBlue/green deployment pattern, 83\nBMSs (battery management systems), 264\nBound execution times tactic, 141\nBound queue sizes tactic, 142\nBox-and-line drawings in C&C views, 336\nBrainstorming\nATAM, 320\nLightweight Architecture Evaluation, 325\nQAW, 281\nscenarios, 281, 320\nBridges pattern, 112\nBugs, 355, 356, 362\nBuildability architecture category, 208\nBusiness goals\nASRs from, 282\u2013284\nATAM, 314, 316\u2013317\ncategorization, 283\u2013284\nevaluation process, 312\nviews for, 332\nBusiness/mission presentation in QAW, 280\nBusiness support, architect duties for, 382\nC&C structures. See Component-and-connector \n(C&C) patterns and structures\nCaching\nperformance, 142\nREST, 224\nCamel project, 356\u2013359\nCanary testing pattern, 85\nCancel command, 200\nCapturing ASRs in utility trees, 284\u2013286\nCar stereo systems, 344\nCassandra database, 360\u2013361\nCategorization of business goals, 283\u2013284\nCentral processor unit (CPU) in virtualization, \n234\nChange\nASRs, 286\nmodifiability. See Modifiability\nreasoning and managing, 27\nChange credential settings tactic, 175\nChaos Monkey, 184\u2013185\nChaucer, Geoffrey, 379\nChimero, Frank, 197\nCIA (confidentiality, integrity, and availability) \napproach, 169\nCircuit breaker tactic, 67\u201368\nClasses\nenergy efficiency, 93\u201394\npatches, 60\nstructure, 13\ntestability, 191\nClient/server constraints in REST, 224\nClient-server pattern, 126\u2013127\nCliques, 361\u2013362\nCloud and distributed computing\nautoscaling, 258\u2013261\nbasics, 248\u2013250\ndata coordination, 258\nfailures, 251\u2013253\nintroduction, 247\nload balancers, 253\u2013256\nlong tail latency, 252\u2013253\nmobile systems, 270", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 438", "position": 438, "chunk_type": "semantic", "token_estimate": 311}
{"text": "420 Index: performance, 253\u2013261\nstate management, 256\u2013257\nsummary, 261\ntime coordination, 257\ntimeouts, 251\u2013252\nCNOT operations for qubits, 393\nCo-locate communicating resources tactic, \n140\u2013141\nCode, mapping to, 334\nCode on demand in REST, 225\nCohesion\nin modifiability, 122\u2013123\nin testability, 191\nCold spare tactic, 66\nCombining views, 339\u2013340\nCommission issues in safety, 153\nCommon services in integrability, 108\nCommunication\narchitect role in, 368\narchitect skills, 383\ndistributed development, 375\ndocumentation for, 330\nstakeholder, 28\u201330\nCommunication diagrams for traces, 342\nCommunication path restrictions, 107\nCommunications views, 338\nComparison tactic for safety, 158\nCompatibility\nC&C views, 335\nquality attributes, 211\nCompetence\narchitects, 379\u2013385\nintroduction, 379\nmentoring, 387\u2013388\nprogram state sets, 62\nsoftware architecture organizations, 386\u2013387\nsummary, 388\nComplex numbers in quantum computing, 392\nComplexity\nquality attributes, 45\u201346\nin testability, 190\u2013191\nComponent-and-connector (C&C) patterns and \nstructures, 7\u20138\nincremental architecture, 369\ntypes, 14\u201316\nviews, combining, 339\u2013340\nviews, documentation, 348\u2013350\nviews, notations, 336\u2013339\nviews, overview, 335\u2013337\nComponents, 4\nindependently developed, 34\u201335\nreplacing for testability, 190\nComprehensive models for behavior \ndocumentation, 341\nComprehensive notations for state machine \ndiagrams, 343\u2013344\nComputer science knowledge of architects, \n384\u2013385\nConceptual integrity of architecture, 208\nConcrete quality attribute scenarios, 43\u201344\nConcurrency\nC&C views, 14, 336\nhandling, 135\nresource management, 141\nCondition monitoring tactic\navailability, 57\nsafety, 158\nConfidentiality, integrity, and availability (CIA) \napproach, 169\nConfigurability quality attribute, 285\nConfiguring behavior for integrability, 109\nConformity Monkey, 184\nConnectivity in mobile systems, 263, 266\u2013267\nConnectors in C&C views, 335\u2013337\nConsistency\nmobile system data, 272\nsoftware interface design, 222\nConsolidation in QAW, 281\nConstraints\nallocation views, 337\nC&C views, 336\non implementation, 31\u201332\nmodular views, 333\nContacts in distributed development, 375\nContainers\nautoscaling, 260\u2013261\nvirtual machines, 239\u2013242\nContainment tactics, 158\u2013159, 161\u2013162\nContention for resources tactic, 138\u2013139\nContext diagrams, 345\u2013346\nContextual factors in evaluation, 312\u2013313\nContinuous deployment, 72\u201375\nControl information in documentation, 346\nControl resource demand tactic, 139\u2013141, 145", "domains": ["Design Patterns", "Design Principles", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 439", "position": 439, "chunk_type": "semantic", "token_estimate": 304}
{"text": "Index 421: Control tactics for testability, 188\u2013190, 192\nControllable deployments, 76\nConverting data for mobile system sensors, 268\nConway, Damian, 329\nConway\u2019s law, 37\nCoordinate tactic in integrability, 109\u2013110, 112\nCopying qubits, 394\nCosts\narchitect role in, 368\nof change, 118\ndistributed development, 374\nestimates, 33\u201334\nindependently developed elements for, 35\nmobile systems, 270\nCoupling\nexchanged data representation, 226\nin modifiability, 122\u2013126\nin testability, 190\u2013191\nCousins, Norman, 101\nCPU (central processor unit) in virtualization, 234\nCriticality in mobile systems, 270\nCrossing anti-patterns, 360\nCRUD operations in REST, 225\nCustomers, communication with, 28\nCustomization of user interface, 201\nCybersecurity, quantum computing for, 396\u2013397\nCycle time in continuous deployment, 73\u201374\nCyclic dependency, 360, 362\nDAL (Design Assurance Level), 164\nDarwin, Charles, 117\nData coordination in distributed computing, 258\nData model category, 13\u201314\nData replication, 142\nData semantic distance in architecture \nintegrability, 103\nde Saint-Exup\u00e9ry, Antoine, 289\nDeadline monotonic prioritization strategy, 143\nDebt. See Architectural debt\nDecision makers on ATAM teams, 313\nDecisions\ndocumenting, 347\nmapping to quality requirements, 315\nquality design, 48\u201349\nDecomposition\nmodule, 10, 16\nviews, 16, 18, 340\nDefer binding tactic, 124\u2013126\nDegradation tactic\navailability, 60\nsafety, 159\nDemand reduction for energy efficiency, 95, 97\nDemilitarized zones (DMZs), 174\nDenial-of-service attacks, 51\nDependencies\nanti-patterns, 360\narchitectural debt, 356\narchitecture integrability, 102\non computations, 139\ndeployment, 79\nlimiting, 106\u2013107, 111\nmodifiability, 119, 124\nDependency injection pattern, 193\nDepends-on relation for modules, 333\nDeployability, 71\ncontinuous deployment, 72\u201375\ngeneral scenarios, 76\u201377\noverview, 75\u201376\npatterns, 81\u201386\nquestionnaires, 80\u201381\ntactics, 78\u201380\nDeployment pipelines, 72, 79\u201380\nDeployment structure, 15\nDeployment views\ncombining, 340\npurpose, 332\nDeprecation of software interfaces, 220\nDesign and design strategy, 289\nADD. See Attribute-Driven Design (ADD) \nmethod\nassurance levels, 164\nearly decisions, 31\nquality attributes, 214\nsoftware interfaces, 222\u2013228\nDesign Assurance Level (DAL), 164\nDesign structure matrices (DSMs), 356\u2013358\nDesigners, documentation for, 349\nDetect attacks tactics, 172\u2013174, 177\nDetect faults tactic, 56\u201359, 63\nDetect intrusion tactic, 172\nDetect message deliveries anomalies tactic, 174\nDetect service denial tactic, 172\nDevelopers, documentation for, 229, 348\nDevelopment, incremental, 33", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 440", "position": 440, "chunk_type": "semantic", "token_estimate": 335}
{"text": "422 Index: Development distributability attribute, 208\u2013209\nDevelopment environments, 72\nDeviation, failure from, 51\nDevices in mobile systems, 272\nDevOps, 74\u201375\nDiscovery\nenergy efficiency, 94\nintegrability, 108\u2013109\nDisk storage in virtualization, 234\nDisplaying information in mobile systems, \n270\u2013271\nDistances\narchitecture integrability, 102\u2013103\nmobile system connectivity, 266\nDistributed computing. See Cloud and \ndistributed computing\nDistributed development, 373\u2013375\nDMZs (demilitarized zones), 174\nDO-178C document, 164\nDoctor Monkey, 185\nDocumentation\nADD decisions, 294\nADD method, 301\u2013303\narchitect duties, 381\nbehavior, 340\u2013345\ncontents, 345\u2013346\ndistributed development, 375\nintroduction, 329\nnotations, 331\u2013332\npractical considerations, 350\u2013353\nrationale, 346\u2013347\nsoftware interfaces, 228\u2013229\nstakeholders, 347\u2013350\nsummary, 353\ntraceability, 352\u2013353\nuses and audiences for, 330\u2013331\nviews. See Views\nDomain knowledge of architects, 385\nDon\u2019t repeat yourself principle, 222\nDrivers\nADD method, 292\u2013294\nQAW, 281\nDuties, 379\u2013383\nDynamic allocation views, 338\nDynamic classification in energy efficiency, 94\nDynamic discovery pattern, 114\nDynamic environments, documenting, 352\nDynamic priority scheduling strategies, 143\u2013144\nE-scribes, 314\nEarliest-deadline-first scheduling strategy, 143\nEarly design decisions, 31\nEC2 cloud service, 53, 184\nECUs (electronic control units) in mobile \nsystems, 269\u2013270\nEdge cases in mobile systems, 271\nEducation, documentation as, 330\nEfficiency, energy. See Energy efficiency\nEfficient deployments, 76\nEinstein, Albert, 385\nElectric power for cloud centers, 248\nElectronic control units (ECUs) in mobile \nsystems, 269\u2013270\nElements\nADD method, 293\u2013294, 299\u2013300\nallocation views, 337\nC&C views, 336\ndefined, 4\nmodular views, 333\nsoftware interfaces, 217\u2013218\nEmergent approach, 370\u2013371\nEmulators for virtual machines, 236\nEnabling quality attributes, 26\nEncapsulation in integrability, 106\nEncrypt data tactic, 175\nEncryption in quantum computing, 394\u2013395\nEnd users, documentation for, 349\u2013350\nEnergy efficiency, 89\u201390\ngeneral scenario, 90\u201391\npatterns, 97\u201398\nquestionnaire, 95\u201397\ntactics, 92\u201395\nEnergy for mobile systems, 263\u2013265\nEntanglement in quantum computing, 393\u2013394\nEnterprise architecture vs. system architecture, \n4\u20135\nEnvironment\nallocation views, 337\u2013338\navailability, 54\ncontinuous deployment, 72\ndeployability, 76\nenergy efficiency, 91\nintegrability, 104\nmodifiability, 120\u2013121\nperformance, 136\nquality attributes expressions, 43\u201344\nsafety, 154", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 441", "position": 441, "chunk_type": "semantic", "token_estimate": 310}
{"text": "Index 423: security, 171\nsoftware interfaces, 217\ntestability, 186\nusability, 198\nvirtualization effects, 73\nEnvironmental concerns with mobile systems, \n269\nErrors\ndescription, 51\nerror-handling views, 339\nsoftware interface handling of, 227\u2013228\nin usability, 197\nEscalating restart tactic, 60\u201361\nEstimates, cost and schedule, 33\u201334\nEvaluating architecture\narchitect duties, 311, 381\nATAM. See Architecture Tradeoff Analysis \nMethod (ATAM)\ncontextual factors, 312\u2013313\nkey activities, 310\u2013311\nLightweight Architecture Evaluation, \n324\u2013325\noutsider analysis, 312\npeer review, 311\u2013312\nquestionnaires, 326\nrisk reduction, 309\u2013310\nsummary, 326\u2013327\nEvents\nperformance, 133\nsoftware interfaces, 219\u2013220\nEvolution of software interfaces, 220\u2013221\nEvolutionary dependencies in architectural debt, \n356\nException detection tactic, 58\u201359\nException handling tactic, 59\nException prevention tactic, 62\nException views, 339\nExchanged data in software interfaces, 225\u2013227\nExecutable assertions for system state, 190\nExperience in design, 296\nExpressiveness concern for exchanged data \nrepresentation, 225\nExtendability in mobile systems, 273\nEXtensible Markup Language (XML), 226\nExtensions for software interfaces, 220\nExternal interfaces, 300\u2013301\nExternalizing change, 125\nFailures\navailability. See Availability\ncloud, 251\u2013253\ndescription, 51\nFault tree analysis (FTA), 153\nFaults\ndescription, 51\u201352\ndetection, 55\nprevention, 61\u201362\nrecovery from, 59\u201361\nFeature toggle in deployment, 80\nFIFO (first-in/first-out) queues, 143\nFirewall tactic, 159\nFirst-in/first-out (FIFO) queues, 143\nFirst principles from tactics, 47\nFixed-priority scheduling, 143\nFlexibility\ndefer binding tactic, 124\nindependently developed elements for, 35\nFollow-up phase in ATAM, 316\nForensics, documentation for, 330\nFormal documentation notations, 331\nForward error recovery pattern, 68\nFoster, William A., 39\nFTA (fault tree analysis), 153\nFuller, R. Buckminster, 1\nFunction patches, 59\nFunction testing in mobile systems, 272\nFunctional redundancy\navailability, 58\ncontainment, 159\nFunctional requirements, 40\u201341\nFunctional suitability of quality attributes, 211\nFunctionality\nC&C views, 336\ndescription, 40\nFusion of mobile system sensors, 268\nFuture computing. See Quantum computing\nGateway elements in software interfaces, 223\nGehry, Frank, 367\nGeneral Data Protection Regulation (GDPR)\ncloud, 248\nprivacy concerns, 170\nGeneralization structure, 13\nGet method for system state, 188\nGibran, Kahlil, 169", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 442", "position": 442, "chunk_type": "semantic", "token_estimate": 315}
{"text": "424 Index: Glossaries in documentation, 346\nGoals. See Business goals\nGood architecture, 19\u201320\nGraceful degradation, 60\nGranular deployments, 75\nGranularity of gateway resources, 223\nGrover\u2019s algorithm, 395\nHAD operations for qubits, 393\nHardware in mobile systems, 271\nHarrow, Aram W., 396\nHashes in quantum computing, 395\nHassidim, Avinatan, 396\nHawking, Stephen, 89\nHealth checks for load balancers, 255\u2013256\nHeartbeats for fault detection, 57, 318\nHedged requests in long tail latency, 252\nHHL algorithm, 396\nHiatus stage in ATAM, 320\nHigh availability. See Availability\nHighway systems, 144\nHosted hypervisors, 235\u2013236\nHot spare tactic, 66\nHotspots\narchitectural debt, 358\u2013362\nidentifying, 362\u2013363\nHotz, Robert Lee, 217\nHTTP commands for REST, 225\nHubs for mobile system sensors, 267\nHuman body structure, 5\u20136\nHuman resource management, architect role for, \n368\nHybrid clouds, 248\nHypertext for documentation, 351\nHypervisors for virtual machines, 235\u2013237\nHyrum\u2019s law, 229\nIdentify actors tactic, 174\nIEEE standards for mobile system connectivity, \n266\nIgnore faulty behavior tactic, 60\nImages for virtual machines, 238, 260\nImplementation\nconstraints, 31\u201332\nmodules, 334\nstructure, 15\nImplicit coupling, 226\nIn-service software upgrade (ISSU), 60\nIncrease cohesion tactic, 125\nIncrease competence set tactic, 62\nIncrease efficiency tactic, 144\nIncrease efficiency of resource usage tactic, 141\nIncrease resources tactic, 141, 144\nIncrease semantic coherence tactic, 122\u2013123\nIncremental architecture, 369\u2013370\nIncremental development, 33\nInform actors tactic, 176\nInformal contacts in distributed development, \n375\nInformal notations for documentation, 331\nInfrastructure support personnel, documentation \nfor, 350\nInheritance anti-pattern, 360\nInherits-from relation, 13\nInhibiting quality attributes, 26\nInputs in ADD method, 292\nInstances in cloud, 253\u2013261\nIntegrability\narchitecture, 102\u2013103\ngeneral scenario, 104\u2013105\nintroduction, 101\u2013102\npatterns, 112\u2013114\nquestionnaires, 110\u2013112\ntactics, 105\u2013110\nIntegration environments, 72\nIntegration management, architect role in, 368\nIntegrators, documentation for, 349\nIntegrity in CIA approach, 169\nIntercepting filter pattern, 194\nIntercepting validator pattern, 179\nInterfaces\nADD method, 300\u2013301\nanti-patterns, 360\nmismatch in deployability, 85\nmobile system connectivity, 266\nsoftware. See Software interfaces\nInterlock tactic, 160\nIntermediaries in integrability, 107\nIntermediate states in failures, 51\nIntermittent mobile system connectivity, 267\nInternal interfaces, 301\nInternet Protocol (IP) addresses\ncloud, 260\nvirtualization, 234", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 443", "position": 443, "chunk_type": "semantic", "token_estimate": 339}
{"text": "Index 425: Interoperability in exchanged data \nrepresentation, 225\nInterpersonal skills, 383\nInterviewing stakeholders, 279\u2013282\nIntroduce concurrency tactic, 141\nIntrusion prevention system (IPS) pattern, \n179\u2013180\nIowability, 212\nIP (Internet Protocol) addresses\ncloud, 260\nvirtualization, 234\nIs-a relation, 333\nIs-a-submodule-of relation, 10\nIs-an-instance-of relation, 13\nIs-part-of relation, 333\nISO 25010 standard, 40, 209\u2013212\nISSU (in-service software upgrade), 60\nIssue information in architectural debt, 356\nIterations\nADD method, 295, 304\nagile development, 370\u2013371\nJanitor Monkey, 185\nJarre, Jean-Michel, 51\nJavaScript Object Notation (JSON), 226\u2013227\nKanban boards, 304\u2013305\nKill abnormal tasks pattern, 97\u201398\nKnowledge\narchitects, 379\u2013381, 384\u2013385\ndesign concepts, 296\nLabor availability and costs in distributed \ndevelopment, 374\nLAE (Lightweight Architecture Evaluation) \nmethod, 324\u2013325\nLAMP stacks, 240\nLamport, Leslie, 247, 258\nLatency in cloud, 252\u2013253\nLatency Monkey, 184\nLawrence Livermore National Laboratory, 45\nLayer structures, 11\u201312\nLayered views, 332\nLayers pattern, 128\u2013129\nLeaders on ATAM teams, 314\nLearning issues in usability, 197\nLeast-slack-first scheduling strategy, 143\nLevels, restart, 60\u201361\nLife cycle in mobile systems, 263, 270\u2013273\nLightweight Architecture Evaluation (LAE) \nmethod, 324\u2013325\nLikelihood of change, 117\nLimit access tactic, 174\nLimit complexity tactic, 190\u2013192\nLimit consequences tactic, 159, 162\nLimit dependencies tactic, 106\u2013107, 111\nLimit event response tactic, 140\nLimit exposure tactic, 175\nLimit nondeterminism tactic, 191\nLimit structural complexity tactic, 190\u2013191\nLloyd, Seth, 396\nLoad balancer pattern for performance, 147\nLoad balancers\ndescription, 141\ndistributed computing, 253\u2013256\nLocal changes, 27\nLocalize state storage for testability, 189\nLocation factors in mobile systems, 270\nLocation independence in modifiability, 119\nLocks in data coordination, 258\nLogical threads in concurrency, 14\nLogs for mobile systems, 273\nLong tail latency in cloud, 252\u2013253\nLongfellow, Henry Wadsworth, 25\nLoss of mobile system power, 265\nMacros for testability, 190\nMaintain multiple copies tactic, 144\nMaintain multiple copies of computations tactic, \n141\nMaintain multiple copies of data tactic, 142\nMaintain system model tactic, 201\nMaintain task model tactic, 201\nMaintain user model tactic, 201\nMaintainability quality attribute, 211, 285\nMaintainers, documentation for, 229, 349\nManage deployed system tactic, 79\u201380\nManage event rate tactic, 144\nManage resources tactic, 141\u2013142, 145\u2013146\nManage sampling rate tactic\nperformance, 139\u2013140\nquality attributes, 47\nManage service interactions tactic, 79\nManage work requests tactic, 139\u2013140", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 444", "position": 444, "chunk_type": "semantic", "token_estimate": 357}
{"text": "426 Index: Management information in modules, 334\nManagers, communication with, 29\nMap function, 148\u2013149\nMap-reduce pattern, 148\u2013149\nMapping\nto requirements, 315\nto source code units, 334\nbetween views, 345\nMarket knowledge in distributed development, \n374\nMarketability category for quality, 208\n\u201cMars Probe Lost Due to Simple Math Error,\u201d \n217\nMasking tactic, 159\nMatrix inversion in quantum computing, 396\nMCAS software, 152\u2013153\nMean time between failures (MTBF), 52\nMean time to repair (MTTR), 52\nMediators pattern, 113\nMeetings in distributed development, 375\nMemento pattern, 205\nMemory\nquantum computing, 395\u2013396\nvirtualization, 234\nMentoring and architects, 387\u2013388\nMetering in energy efficiency, 93\nMicrokernel pattern, 127\u2013128\nMicroservice architecture pattern, 81\u201382\nMigrates-to relation, 15\nMissile launch incident, 152\nMixed initiative in usability, 197\nMobile systems\nenergy usage, 263\u2013265\nintroduction, 263\u2013264\nlife cycle, 270\u2013273\nnetwork connectivity, 266\u2013267\nresources, 268\u2013270\nsensors and actuators, 267\u2013268\nsummary, 273\u2013274\nModel-View-Controller (MVC) pattern, 203\u2013204\nModeling tools, documentation for, 351\nModels\nquality attributes, 213\u2013214\ntransferable and reusable, 34\nModifiability\ngeneral scenario, 120\u2013121\nintroduction, 117\u2013119\nmanaging, 27\nmobile system connectivity, 266\npatterns, 126\u2013130\nquestionnaires, 125\u2013126\ntactics, 121\u2013126\nin usability, 201\nModularity violations, 360\nModules and module patterns, 7, 9\ncoupling, 122\ndescription, 2\u20133\ndocumentation, 348\u2013350\nincremental architecture, 369\ntypes, 10\u201314\nviews, 333\u2013334\nMonitor-actuator pattern, 163\nMonitor tactic, 56\u201357\nMonitoring mobile system power, 264\u2013265\nMTBF (mean time between failures), 52\nMTTR (mean time to repair), 52\nMultiple instances in cloud, 253\u2013261\nMultiple software interfaces, 218\nMultitasking, 135\nMVC (Model-View-Controller) pattern, 203\u2013204\nNames for modules, 334\nNash, Ogden, 355\nNational Institute of Standards and Technology \n(NIST)\nPII, 170\nquantum computing, 394\nNear Field Communication (NFC), 266\nNetflix\nmap-reduce, 148\nSimian Army, 184\u2013185\nNetwork connectivity\nmobile systems, 263, 266\u2013267\nvirtualization, 234\nNetwork Time Protocol (NTP) for time \ncoordination, 257\nNetwork transitions in mobile systems, 271\nNetworked services, 35\nNFC (Near Field Communication), 266\nNIST (National Institute of Standards and \nTechnology)\nPII, 170\nquantum computing, 394\nNondeterminism in testability, 191", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 445", "position": 445, "chunk_type": "semantic", "token_estimate": 313}
{"text": "Index 427: Nonlocal changes, 27\nNonrepudiation tactic, 176\nNonrisks in ATAM, 314\u2013315\nNonstop forwarding tactic, 61\nNOT operations for qubits, 393\nNotations\nC&C views, 336\u2013339\ndocumentation, 331\u2013332\nNotifications for failures, 51\nNTP (Network Time Protocol) for time \ncoordination, 257\nObject-oriented systems in testability, 190\nObjects in sequence diagrams, 341\nObservability of failures, 52\nObserve system state tactics, 188\u2013190, 192\nObserver pattern, 204\nOff-the-shelf components, 35\nOmissions as safety factor, 153\nOpen system software, 35\nOperating systems with containers, 241\u2013242\nOperations in software interfaces, 219\u2013220\nOrchestrate tactic, 109\u2013110\nOrganizations, architecture influence on, 32\nOut of sequence events as safety factor, 153\nOutages. See Availability\nOutputs in ATAM, 314\u2013315\nOutsider evaluation, 312\nOverlay views, 339\nPackage cycles anti-pattern, 360\nPackage dependencies in deployment, 79\nPALM method, 283\nParameter fence tactic, 58\nParameter typing tactic, 58\nParity, environment, 73\nPartial replacement of services patterns, 85\u201386\nPartial system deployment in mobile systems, \n273\nPartnership and preparation phase in ATAM, 315\nPassive redundancy, 66\nPatches, 59\u201360\nPatterns\nADD method, 299\narchitectural, 18\navailability, 66\u201369\nC&C. See Component-and-connector (C&C) \npatterns and structures\ndeployability, 81\u201386\ndocumenting, 345\nenergy efficiency, 97\u201398\nintegrability, 112\u2013114\nmodifiability, 126\u2013130\npartial replacement of services, 85\u201386\nperformance, 146\u2013149\nquality attributes tactics, 46\u201347\nsafety, 163\u2013164\nsecurity, 179\u2013180\ntestability, 192\u2013194\nusability, 203\u2013205\nPause/resume command, 201\nPeer review, 311\u2013312\nPeople management, architect duties for, 382\nPerformance\nC&C views, 335\ncloud, 253\u2013261\ncontrol resource demand tactics, 139\u2013141\nefficiency, 211\nexchanged data representation, 225\ngeneral scenario, 134\u2013137\nintroduction, 133\u2013134\nmanage resources tactics, 141\u2013142\npatterns, 146\u2013149\nquality attribute, 47, 211, 285\nquestionnaires, 145\u2013146\ntactics overview, 137\u2013139\nviews, 339\nvirtual machines, 237\nPeriodic cleaning tactic, 141\nPersonally identifiable information (PII), 170\nPersonnel-related competence, 386\nPetrov, Stanislav Yevgrafovich, 152\nPhases\nATAM, 315\u2013316\nquantum computing, 392\u2013393\nPII (personally identifiable information), 170\nPing/echo tactic, 57\nPipelines, deployment, 72, 79\u201380\nPlatforms, architect knowledge about, 385\nPlug-in pattern, 127\u2013128\nPMBOK (Project Management Body of \nKnowledge), 368", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 446", "position": 446, "chunk_type": "semantic", "token_estimate": 310}
{"text": "428 Index: Pods in virtualization, 242\u2013243\nPointers, smart, 62\nPolicies, scheduling, 143\u2013144\nPortability\ncontainers, 242\nmodifiability, 119\nquality attributes, 42, 211\nPower for mobile systems, 264\u2013265\nPower monitor pattern, 98\nPower station catastrophe, 151\nPredicting system qualities, 28\nPredictive model tactic\navailability, 62\nsafety, 157\nPreemptible processes, 143\nPreparation-and-repair tactic, 59\u201360\nPreprocessor macros, 190\nPresentation\nATAM, 314\u2013317\nLightweight Architecture Evaluation, 325\nQAW, 280\nPrevent faults\nquestionnaire, 65\ntactics, 61\u201362\nPrinciple of least surprise, 222\nPrinciples, design fragments from, 47\nPrioritize events tactic, 140, 144\nPrioritizing\nATAM scenarios, 320\nLightweight Architecture Evaluation \nscenarios, 325\nQAW, 281\nschedules, 143\u2013144\nPrivacy issues, 170\nPrivate clouds, 248\nProbabilities in quantum computing, 392\u2013393\nProcess pairs pattern, 68\nProcess recommendations, 19\nProcess-related competence, 387\nProcessing time in performance, 138\nProcurement management, architect role in, 368\nProduction environments, 72\nProgramming knowledge of architects, 384\nProject management, architect duties for, 382\nProject Management Body of Knowledge \n(PMBOK), 368\nProject managers\ndocumentation for, 347\u2013348\nworking with, 367\u2013368\nProject roles. See Role of architects\nProperties\nADD method, 300\nsoftware interfaces, 219\u2013220\nProtocol Buffer technology, 227\nProtocols for mobile system connectivity, 266\nPrototypes in ADD method, 297\u2013298\nPublic clouds, 248\nPublicly available apps, 35\nPublish-subscribe connectors, 335\nPublish-subscribe pattern, 129\u2013130\nPublisher role, 335\nQAW (Quality Attribute Workshop), 280\u2013281\nQPUs, 392\u2013393\nQRAM (quantum random access memory), \n395\u2013396\nQuality Attribute Workshop (QAW), 280\u2013281\nQuality attributes, 207\narchitecture, 208\nASRs, 280\u2013281\nATAM, 317\u2013318\ncapture scenarios, 213\nconsiderations, 41\u201342\ndesign approaches, 214\ndevelopment distributability, 208\u2013209\ninhibiting and enabling, 26\nintroduction, 39\nLightweight Architecture Evaluation, 325\nmodels, 213\u2013214\nquality design decisions, 48\u201349\nrequirements, 42\u201345\nstandard lists, 209\u2013212\nsummary, 49\nsystem, 209\ntactics, 45\u201346\nX-ability, 212\u2013214\nQuality design decisions, 48\u201349\nQuality management, architect role for, 368\nQuality of products as business goal, 283\nQuality requirements, mapping decisions to, 315\nQuality views, 338\u2013339\nQuantifying architectural debt, 363", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 447", "position": 447, "chunk_type": "semantic", "token_estimate": 299}
{"text": "Index 429: Quantum computing\nalgorithms, 395\u2013396\napplications, 396\u2013397\nencryption, 394\u2013395\nfuture of, 397\nintroduction, 391\u2013392\nmatrix inversion, 396\nqubits, 392\u2013393\nteleportation, 394\nQuantum random access memory (QRAM), \n395\u2013396\nQubits\ndescription, 392\u2013393\nteleportation, 394\nQuestioners on ATAM teams, 314\nQuestionnaires\narchitecture evaluation, 326\navailability, 62\u201365\ndeployability, 80\u201381\nenergy efficiency, 95\u201397\nintegrability, 110\u2013112\nmodifiability, 125\u2013126\nperformance, 145\u2013146\nquality attributes, 48\u201349\nsafety, 160\u2013162\nsecurity, 176\u2013178\ntestability, 192\nusability, 202\u2013203\nBound queue sizes tactic, 142\nRace conditions, 135\nRate monotonic prioritization strategy, 143\nRationale\ndocumentation, 346\u2013347\nviews, 346\nRaw data with mobile system sensors, 268\nReact to attacks tactics, 175\u2013176, 178\nREAD operations for qubits, 393\nReconfiguration tactic, 60\nRecord/playback method for system state, 189\nRecover from attacks tactics, 176, 178\nRecover from faults tactics, 59\u201361, 64\u201365\nRecovery tactic, 160, 162\nRedistribute responsibilities tactic, 122\u2013123\nReduce computational overhead tactic, 140, 144\nReduce coupling tactic, 123\u2013126\nReduce function in performance, 148\u2013149\nReduce indirection tactic, 140\nRedundancy tactics\navailability, 58\u201359, 66\u201367\nsafety, 158\u2013159, 161\u2013162\nRedundant sensors pattern, 163\nReference architectures in ADD method, 299\nRefined scenarios in QAW, 281\nRefinement in ADD method, 293\nRegions in cloud, 248\nReintroduction tactics, 60\u201361\nRejuvenation tactic, 61\nRelations\nADD elements, 294, 300\nallocation views, 337\narchitectural structures, 16\u201318\nC&C views, 336\nmodular views, 333\nRelease strategy, documenting, 351\nReliability\nC&C views, 335\nindependently developed elements for, 35\nquality attributes, 211\nquality views, 339\nRemote Procedure Call (RPC), 224\nRemoval from service tactic, 61\nRepair tactic, 160\nRepeatability in continuous deployment, 74\nReplacement of services patterns, 82\u201385\nReplication tactic\navailability, 58\nsafety, 159\nReport method for system state, 188\nRepresentation and structure of exchanged data, \n225\u2013227\nRepresentation of architecture, 3\nRepresentational State Transfer (REST) \nprotocol, 224\u2013225\nRequirements\narchitect duties, 382\nASRs. See Architecturally significant \nrequirements (ASRs)\nfunctional, 40\u201341\nmapping to, 315\nquality attributes, 42\u201345\nsystem availability, 53\nReset method for system state, 188\nResist attacks tactics, 174\u2013175, 177\u2013178", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 448", "position": 448, "chunk_type": "semantic", "token_estimate": 308}
{"text": "430 Index: Resource distance in architecture integrability, \n103\nResources\nC&C views, 335\ncontention for, 138\nintegrability management of, 110\nmobile systems, 263, 268\u2013271\nmonitoring in energy efficiency, 93\u201396\nin performance, 138\nsandboxing, 189\nsoftware interfaces, 217, 219\nvirtualization, 234\nResponse\navailability, 54\ndeployability, 76\nenergy efficiency, 91\nintegrability, 104\nmodifiability, 120\u2013121\nperformance, 136\nquality attribute expressions, 43\u201344\nsafety, 154\nsecurity, 171\ntestability, 186\nusability, 199\nResponse measure\navailability, 54\ndeployability, 77\nenergy efficiency, 91\nintegrability, 104\nmodifiability, 120\u2013121\nperformance, 137\nquality attribute expressions, 43\u201344\nsafety, 155\nsecurity, 171\ntestability, 187\nusability, 199\nResponsibilities\nADD method, 300\nmodules, 334\nREST (Representational State Transfer) protocol, \n224\u2013225\nRestart tactic, 60\u201361\nRestrict dependencies tactic, 124\nRestrict login tactic, 175\u2013176\nRestrictions on vocabulary, 35\u201336\nResults\nATAM, 321\nevaluation, 312\nLightweight Architecture Evaluation, 325\nRetry tactic, 60\nReusable models, 34\nReviews, peer, 311\u2013312\nRevision history\narchitectural debt, 356\nmodules, 334\nRevoke access tactic, 175\nRisk\narchitect role in managing, 368\nATAM, 314\u2013315\nevaluation process, 309\u2013310\nRole of architects, 367\nagile development, 370\u2013373\ndistributed development, 373\u2013375\nincremental architecture, 369\u2013370\nproject manager interaction, 367\u2013368\nsummary, 376\nRollback tactic\ndeployment, 79\nfault recovery, 59\nsafety, 160\nRolling upgrade deployment pattern, 83\u201384\nRound-robin scheduling strategy, 143\nRounds in ADD method, 291\nRPC (Remote Procedure Call), 224\nRuntime engines in containers, 239\nRuntime extensibility in C&C views, 336\nRutan, Burt, 183\nSAFe (Scaled Agile Framework), 373\nSafety\ngeneral scenario, 154\u2013155\nintroduction, 151\u2013153\nmobile systems, 269, 272\u2013273\npatterns, 163\u2013164\nquestionnaires, 160\u2013162\ntactics, 156\u2013160\nSampling rate tactic, 139\u2013140\nSandbox tactic, 189\nSanity checking tactic\navailability, 57\nsafety, 158\nSatisfaction in usability, 197\nScalability in modifiability, 119\nScale rollouts, 79", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 449", "position": 449, "chunk_type": "semantic", "token_estimate": 266}
{"text": "Index 431: Scaled Agile Framework (SAFe), 373\nScaling in distributed computing, 258\u2013261\nScenario scribes, 314\nScenarios\nATAM, 318\u2013320\navailability, 53\u201355\ndeployability, 76\u201377\nenergy efficiency, 90\u201391\nintegrability, 104\u2013105\nLightweight Architecture Evaluation, 325\nmodifiability, 120\u2013121\nperformance, 134\u2013137\nQAW, 281\nquality attributes, 42\u201345, 213\nsafety, 154\u2013155\nsecurity, 170\u2013172\ntestability, 186\u2013187\nusability, 198\u2013199\nSchedule resources tactic\nperformance, 142\nquality attributes, 47\nScheduled downtimes, 52\nSchedules\nestimates, 33\u201334\npolicies, 143\u2013144\nof resources for energy efficiency, 94\nScope\narchitect management role in, 368\nsoftware interfaces, 223\nScript deployment commands, 79\nSecurity\nC&C views, 336\ngeneral scenario, 170\u2013172\nintroduction, 169\nmobile system connectivity, 267\npatterns, 179\u2013180\nprivacy issues, 170\nquality attributes, 211\nquestionnaires, 176\u2013178\ntactics, 172\u2013176\nviews, 338\nSecurity Monkey, 185\nSecurity quality attribute, 285\nSelection\ndesign concepts, 296\u2013297\ntools and technology, 382\nSelf-test tactic, 59\nSemantic importance strategy, 143\nSemantics, resource, 219\nSemiformal documentation notations, 331\nSensitivity points in ATAM, 315\nSensor fusion pattern, 97\nSensors in mobile systems, 263, 267\u2013268\nSeparate entities tactic, 175\nSeparated safety pattern, 163\u2013164\nSeparation of concerns\ntestability, 191\nvirtual machines, 238\nSequence diagrams for traces, 341\u2013342\nSequence omission and commission as safety \nfactor, 153\nServerless architecture in virtualization, 243\u2013244\nService impact of faults, 52\nService-level agreements (SLAs)\nAmazon, 53\navailability in, 52\u201353\nService mesh pattern, 146\u2013147\nService-oriented architecture (SOA) pattern, \n113\u2013114\nService structure, 14\nSet method for system state, 188\n737 MAX aircraft, 152\u2013153\nShadow tactic, 60\nShared resources in virtualization, 234\nShushenskaya hydroelectric power station, 151\nSimian Army, 184\u2013185\nSize\nmodules, 122\nqueue, 142\nSkeletal systems, 33\nSketches in ADD method, 301\u2013302\nSkills\narchitects, 379\u2013381, 383\u2013384\ndistributed development, 374\nSLAs (service-level agreements)\nAmazon, 53\navailability in, 52\u201353\nSmall interfaces principle, 222\nSmart pointers, 62\nSmoothing data for mobile system sensors, 268\nSOA (service-oriented architecture) pattern, \n113\u2013114\nSoftware architecture importance, 25\u201326\nchange management, 27", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Design Principles", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 450", "position": 450, "chunk_type": "semantic", "token_estimate": 294}
{"text": "432 Index: constraints, 31\u201332\ncost and schedule estimates, 33\u201334\ndesign decisions, 31\nincremental development, 33\nindependently developed elements, 34\u201335\norganizational structure, 32\nquality attributes, 26\nstakeholder communication, 28\u201330\nsummary, 36\u201337\nsystem qualities prediction, 28\ntraining basis, 36\ntransferable, reusable models, 34\nvocabulary restrictions, 35\u201336\nSoftware architecture overview, 1. See also \nArchitecture\nas abstraction, 3\nbehavior in, 4\ncompetence, 386\u2013387\ndefinitions, 2\ngood and bad, 19\u201320\npatterns, 18\nas set of software structures, 2\u20133\nstructures and views, 5\u201318\nsummary, 21\nsystem architecture vs. enterprise, 4\u20135\nSoftware Engineering Body of Knowledge \n(SWEBOK), 278\nSoftware for mobile systems, 272\nSoftware interfaces\ndesigning, 222\u2013228\ndocumentation, 228\u2013229\nerror handling, 227\u2013228\nevolution, 220\u2013221\nintroduction, 217\u2013218\nmultiple, 218\noperations, events, and properties, 219\u2013220\nrepresentation and structure of exchanged \ndata, 225\u2013227\nresources, 219\nscope, 223\nstyles, 224\u2013225\nsummary, 230\nSoftware rejuvenation tactic, 61\nSoftware upgrade tactic, 59\u201360\nSource\narchitectural debt, 356\ndeployability, 76\nenergy efficiency, 91\nintegrability, 104\nmodifiability, 120\u2013121\nperformance, 136\nsafety, 154\nsecurity, 170\ntestability, 186\nusability, 198\nSource code, mapping to, 334\nSpare tactic, 66\nSpecialized interfaces tactic, 188\u2013189\nSpikes in agile development, 370\nSplit module tactic, 122\nStaging environments, 72\nStakeholders\non ATAM teams, 313\u2013314\ncommunication among, 28\u201330, 330\ndocumentation, 347\u2013350\nevaluation process, 312\nincremental architecture, 369\u2013370\ninterviewing, 279\u2013282\nStandards in integrability, 107\u2013108\nState, system, 188\u2013190, 192\nState machine diagrams, 343\u2013345\nState management in distributed computing, \n256\u2013257\nState resynchronization tactic, 60\nStateless interactions in REST, 224\nStatic allocation views, 338\nStatic classification for energy efficiency, \n93\u201394\nStatic scheduling, 144\nStein, Gertrude, 144\nStimulus\navailability, 53\ndeployability, 76\nenergy efficiency, 91\nintegrability, 104\nmodifiability, 120\u2013121\nperformance, 136\nquality attributes expressions, 42\u201344\nsafety, 154\nsecurity, 171\ntestability, 186\nusability, 198", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 451", "position": 451, "chunk_type": "semantic", "token_estimate": 274}
{"text": "Index 433: Storage\nfor testability, 189\nvirtualization, 234\nStrategy pattern for testability, 193\u2013194\nStroustrup, Bjarne, 277\nStructural complexity in testability, 190\u2013191\nStructures in ADD method, 298\u2013301\nStuxnet virus, 151\nStyles for software interfaces, 224\u2013225\nSubmodules, 334\nSubscriber role, 335\nSubstitution tactic, 156\u2013157\nSubsystems, 6\nSuper-tactics, 47\nSuperposition in quantum computing, 392\nSupport system initiative tactic, 201\u2013203\nSWEBOK (Software Engineering Body of \nKnowledge), 278\nSyntactic distance in architecture integrability, \n102\u2013103\nSyntax for resources, 219\nSystem analysis and construction, documentation \nfor, 330\nSystem architecture vs. enterprise architecture, \n4\u20135\nSystem availability requirements, 53\nSystem efficiency in usability, 197\nSystem exceptions tactic, 58\nSystem initiative in usability, 197\nSystem qualities, predicting, 28\nSystem quality attributes, 209\nSystem values as safety factor, 153\nSystems integrators and testers, software \ninterface documentation for, 229\nTactics\nADD method, 299\u2013300\narchitecture evaluation, 326\navailability, 55\u201365\ndeployability, 78\u201381\nenergy efficiency, 92\u201397\nintegrability, 105\u2013112\nmodifiability, 121\u2013125\nperformance, 137\u2013146\nquality attributes, 45\u201346, 48\u201349\nsafety, 156\u2013162\nsecurity, 172\u2013178\ntestability, 187\u2013192\nusability, 200\u2013203\nTailor interface tactic, 109\nTeam building skills, 383\nTeams in ATAM, 313\u2013314\nTechnical debt. See Architecture debt\nTechnology knowledge of architects, 385\nTechnology-related competence, 387\nTeleportation in quantum computing, 394\nTemporal distance in architecture integrability, \n103\nTemporal inconsistency in deployability, 85\n10-18 Monkey, 185\nTest harnesses, 184\nTestability\ngeneral scenario, 186\u2013187\nintroduction, 183\u2013185\npatterns, 192\u2013194\nquestionnaires, 192\ntactics, 187\u2013191\nTestable requirements, 278\nTesters, documentation for, 349\nTests and testing\ncontinuous deployment, 72\u201373\nmobile systems, 271\u2013272\nmodules, 334\nTherac 25 radiation overdose, 151\nTherapeutic reboot tactic, 61\nThermal limits in mobile systems, 269\nThreads\nconcurrency, 135\nvirtualization, 234\nThrottling mobile system power, 265\nThrottling pattern for performance, 148\nThroughput of systems, 137\nTiered system architectures in REST, 225\nTime and time management\narchitect role, 368\nperformance, 133\nTime coordination in distributed computing, 257\nTime to market, independently developed \nelements for, 35\nTimeout tactic\navailability, 58\u201359\nsafety, 157\u2013158", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 452", "position": 452, "chunk_type": "semantic", "token_estimate": 305}
{"text": "434 Index: Timeouts in cloud, 251\u2013252\nTimestamp tactic\navailability, 57\nsafety, 158\nTiming as safety factor, 153\nTMR (triple modular redundancy), 67\nTraceability\ncontinuous deployment, 74\ndocumentation, 352\u2013353\nTraces for behavior documentation, 341\u2013342\nTradeoffs in ATAM, 315\nTraffic systems, 144\nTraining, architecture for, 36\nTransactions in availability, 61\nTransducers in mobile systems, 267\nTransferable models, 34\nTransforming existing systems, 381\nTransparency in exchanged data representation, \n226\nTriple modular redundancy (TMR), 67\nTwo-phase commits, 61\nType 1 hypervisors, 235\nType 2 hypervisors, 235\nUML. See Unified Modeling Language (UML)\nUnambiguous requirements, 278\nUndo command, 200\u2013201\nUnified Modeling Language (UML)\nactivity diagrams, 342\u2013343\nC&C views, 336\u2013337\ncommunication diagrams, 342\nsequence diagrams, 341\u2013342\nstate machine diagrams, 343\u2013345\nUniform access principle, 222\nUniform interface in REST, 224\nUnity of purpose in modules, 122\nUnsafe state avoidance tactic, 156\u2013157, 161\nUnsafe state detection tactic, 157\u2013158, 161\nUnstable interfaces anti-pattern, 360\nUpdates for mobile systems, 272\u2013273\nUsability\ngeneral scenario, 198\u2013199\nintroduction, 197\u2013198\npatterns, 203\u2013205\nquality attributes, 211\nquestionnaires, 202\u2013203\ntactics, 200\u2013202\nUsability quality attribute, 285\nUsage\nallocation views, 337\nC&C views, 336\nmodular views, 333\nreducing in energy efficiency, 94\nUse an intermediary tactic, 47\nUse cases for traces, 341\nUser initiative in usability, 197\nUser interface customization, 201\nUser needs in usability, 197\nUsers, communication with, 28\nUses\nfor documentation, 330\u2013331\nviews for, 332\nUses structure in decomposition, 10\u201312\nUtility trees\nASRs, 284\u2013286\nATAM, 317\u2013318, 320\nLightweight Architecture Evaluation, 325\nValidate input tactic, 175\nVariability guides for views, 346\nVariability in modifiability, 119\nVector clocks for time coordination, 257\nVerify message integrity tactic, 174\nVersioning in software interfaces, 220\nViews, 332\u2013333\nADD method, 294, 301\u2013302\nallocation, 337\u2013338\narchitectural structures, 5\u20136\nC&C overview, 335\u2013337\ncombining, 339\u2013340\ndocumentation, 348\u2013350\nmapping between, 345\nmodule, 333\u2013334\nnotations, 336\u2013339\nquality, 338\u2013339\nVirtualization and virtual machines\nautoscaling, 259\u2013260\ncloud, 249\u2013250\ncontainers, 239\u2013242\nenvironment effects from, 73\nimages, 238\nintroduction, 233\nlayers as, 11\nPods, 242\u2013243", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 453", "position": 453, "chunk_type": "semantic", "token_estimate": 314}
{"text": "Index 435: in sandboxing, 189\nserverless architecture, 243\u2013244\nshared resources, 234\nsummary, 244\nvirtual machine overview, 235\u2013238\nVocabulary\nquality attributes, 42\nrestrictions, 35\u201336\nVoting tactic, 57\u201358\nVulnerabilities in security views, 338\nWarm spare tactic, 66\nWatchdogs, 57\nWaterfall model, 370\nWeb-based system events, 133\nWest, Mae, 133\nWikis for documentation, 351\nWiMAX standards, 266\nWork assignment structures, 15\u201316\nWork-breakdown structures, 32\nWork skills of architect, 384\nWrappers pattern, 112\nWright, Frank Lloyd, 309\nX-ability, 212\u2013214\nXML (EXtensible Markup Language), 226\nZ operations for qubits, 393", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 454", "position": 454, "chunk_type": "semantic", "token_estimate": 85}
{"text": "437: Special permission to reproduce portions of the following works copyright by Carnegie Mellon \nUniversity is granted by the Software Engineering Institute:\nFelix Bachmann, Len Bass, Paul Clements, David Garlan, James Ivers, Reed Little, Robert \nNord, and Judith A. Stafford. \u201cSoftware Architecture Documentation in Practice: Documenting \nArchitectural Layers,\u201d CMU/SEI-2000-SR-004, March 2000. Felix Bachmann, Len Bass, Paul Clements, David Garlan, James Ivers, Reed Little, Robert Nord, \nand Judith A. Stafford. \u201cDocumenting Software Architectures: Organization of Documentation \nPackage,\u201d CMU/SEI-2001-TN-010, August 2001. Felix Bachmann, Len Bass, Paul Clements, David Garlan, James Ivers, Reed Little, Robert \nNord, and Judith A. Stafford. \u201cDocumenting Software Architecture: Documenting Behavior,\u201d \nCMU/SEI-2002-TN-001, January 2002. Felix Bachmann, Len Bass, Paul Clements, David Garlan, James Ivers, Reed Little, Robert \nNord, and Judith A. Stafford. \u201cDocumenting Software Architecture: Documenting Interfaces,\u201d \nCMU/SEI-2002-TN-015, June 2002. Felix Bachmann and Paul Clements. \u201cVariability in Product Lines,\u201d CMU/SEI-2005-TR-012, \nSeptember 2005. Felix Bachmann, Len Bass, and Robert Nord. \u201cModifiability Tactics,\u201d CMU/SEI-2007-TR-\n002, September 2007. Mario R. Barbacci, Robert Ellison, Anthony J. Lattanze, Judith A. Stafford, Charles B. \nWeinstock, and William G. Wood. \u201cQuality Attribute Workshops (QAWs), Third Edition,\u201d \nCMU/SEI-2003-TR-016, August 2003. Len Bass, Paul Clements, Rick Kazman, and Mark Klein. \u201cModels for Evaluating and \nImproving Architecture Competence,\u201d CMU/SEI-2008-TR-006, March 2008. Len Bass, Paul Clements, Rick Kazman, John Klein, Mark Klein, and Jeannine Siviy. \u201cA \nWorkshop on Architecture Competence,\u201d CMU/SEI-2009-TN-005, April 2009. Lisa Brownsword, David Carney, David Fisher, Grace Lewis, Craig Meyers, Edwin Morris, \nPatrick Place, James Smith, and Lutz Wrage. \u201cCurrent Perspectives on Interoperability,\u201d \nCMU/SEI-2004-TR-009, March 2004. Paul Clements and Len Bass. \u201cRelating Business Goals to Architecturally Significant \nRequirements for Software Systems,\u201d CMU/SEI-2010-TN-018, May 2010.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 456", "position": 456, "chunk_type": "semantic", "token_estimate": 267}
{"text": "438: Rick Kazman and Jeromy Carriere, \u201cPlaying Detective: Reconstructing Software Architecture \nfrom Available Evidence,\u201d CMU/SEI-97-TR-010, October 1997. Rick Kazman, Mark Klein, and Paul Clements. \u201cATAM: Method for Architecture Evaluation,\u201d \nCMU/SEI-2000-TR-004, August 2000. Rick Kazman, Jai Asundi, and Mark Klein, \u201cMaking Architecture Design Decisions, An \nEconomic Approach,\u201d CMU/SEI-2002-TR-035, September 2002. Rick Kazman, Liam O\u2019Brien, and Chris Verhoef, \u201cArchitecture Reconstruction Guidelines, \nThird Edition,\u201d CMU/SEI-2002-TR-034, November 2003. Robert L. Nord, Paul C. Clements, David Emery, and Rich Hilliard. \u201cA Structured Approach \nfor Reviewing Architecture Documentation,\u201d CMU/SEI-2009-TN-030, December 2009. James Scott and Rick Kazman. \u201cRealizing and Refining Architectural Tactics: Availability,\u201d \nCMU/SEI-2009-TR-006 and ESC-TR-2009-006, August 2009. Much of the material in Chapter 5 is adapted from Deployment and Operations for Software \nEngineers by Len Bass and John Klein [Bass 19] and from R. Kazman, P. Bianco, J. Ivers, J. \nKlein, \u201cMaintainability\u201d, CMU/SEI-2020-TR-006, 2020. Much of the material for Chapter 7 was inspired by and drawn from R. Kazman, P. Bianco, J. \nIvers, J. Klein, \"Integrability\", CMU/SEI-2020-TR-001, 2020.", "domains": ["Software Quality Attributes"], "source": "software-architecture-in-practice-4.pdf", "section": "Page 457", "position": 457, "chunk_type": "semantic", "token_estimate": 162}
