{"text": "vi   SWEBOK \u00ae GUIDE V4.0: 3.4. Addressing Conflict in Requirements\b\n1-10\n4. Requirements Specification\b\n1-10\n4.1. Unstructured Natural Language Requirements Specification\b\n1-11\n4.2. Structured Natural Language Requirements Specification\b\n1-12\n4.3. Acceptance Criteria-Based Requirements Specification\b\n1-12\n4.4. Model-Based Requirements Specification\b\n1-14\n4.5. Additional Attributes of Requirement\b\n1-14\n4.6. Incremental and Comprehensive Requirements Specification\b\n1-15\n5. Requirements Validation\b\n1-15\n5.1. Requirements Reviews\b\n1-15\n5.2. Simulation and Execution\b\n1-16\n5.3. Prototyping\b\n1-16\n6. Requirements Management Activities\b\n1-16\n6.1. Requirements Scrubbing\b\n1-16\n6.2. Requirements Change Control \b\n1-17\n6.3. Scope Matching\b\n1-17\n7. Practical Considerations\b\n1-17\n7.1. Iterative Nature of the Requirements Process \b\n1-17\n7.2. Requirements Prioritization\b\n1-17\n7.3. Requirements Tracing \b\n1-18\n7.4. Requirements Stability and Volatility\b\n1-19\n7.5. Measuring Requirements\b\n1-19\n7.6. Requirements Process Quality and Improvement \b\n1-19\n8. Software Requirements Tools\b\n1-20\n8.1. Requirements Management Tools \b\n1-20\n8.2. Requirements Modeling Tools\b\n1-20\n8.3. Functional Test Case Generation Tools\b\n1-20\nMatrix of Topics vs. Reference Material\b\n1-21\nFurther Readings\b\n1-22\nReferences\b\n1-23", "domains": ["Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 7", "position": 7, "chunk_type": "semantic", "token_estimate": 163}
{"text": "Software Design\b: 3-1\nIntroduction\b\n3-1\n1. Software Design Fundamentals\b\n3-2\n1.1. Design Thinking\b\n3-2\n1.2. Context of Software Design\b\n3-2\n1.3. Key Issues in Software Design\b\n3-3\n1.4. Software Design Principles\b\n3-3\n2. Software Design Processes\b\n3-5\n2.1. High-Level Design\b\n3-6\n2.2. Detailed Design\b\n3-6\n3. Software Design Qualities\b\n3-6\n3.1. Concurrency\b\n3-6\n3.2. Control and Event Handling\b\n3-6\n3.3. Data Persistence\b\n3-7\n3.4. Distribution of Components\b\n3-7\n3.5. Errors and Exception Handling, Fault Tolerance\b\n3-7\n3.6. Integration and Interoperability\b\n3-7\n3.7. Assurance, Security, and Safety\b\n3-7\n3.8. Variability\b\n3-7\n4. Recording Software Designs\b\n3-7\n4.1. Model-Based Design\b\n3-8\n4.2. Structural Design Descriptions\b\n3-8\n4.3. Behavioral Design Descriptions\b\n3-9\n4.4. Design Patterns and Styles\b\n3-10\n4.5. Specialized and Domain-Specific Languages\b\n3-10\n4.6. Design Rationale\b\n3-11\n5. Software Design Strategies and Methods\b\n3-11\n5.1. General Strategies\b\n3-11\n5.2. Function-Oriented (or Structured) Design\b\n3-11\n5.3. Data-Centered Design\b\n3-11", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 8", "position": 8, "chunk_type": "semantic", "token_estimate": 146}
{"text": "viii   SWEBOK \u00ae GUIDE V4.0: 5.4. Object-Oriented Design\b\n3-11\n5.5. User-Centered Design\b\n3-12\n5.6. Component-Based Design (CBD)\b\n3-12\n5.7. Event-Driven Design\b\n3-12\n5.8. Aspect-Oriented Design (AOD)\b\n3-12\n5.9. Constraint-Based Design\b\n3-12\n5.10. Domain-Driven Design\b\n3-13\n5.11. Other Methods\b\n3-13\n6. Software Design Quality Analysis and Evaluation\b\n3-13\n6.1. Design Reviews and Audits\b\n3-13\n6.2. Quality Attributes\b\n3-13\n6.3. Quality Analysis and Evaluation Techniques\b\n3-13\n6.4. Measures and Metrics\b\n3-14\n6.5. Verification, Validation, and Certification\b\n3-14\nMatrix of Topics vs. Reference Material\b\n3-14\nFurther Readings\b\n3-16\nReferences\b\n3-16", "domains": ["Architectural Patterns and Styles", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 9", "position": 9, "chunk_type": "semantic", "token_estimate": 87}
{"text": "Software Construction\b: 4-1\nIntroduction\b\n4-1\n1. Software Construction Fundamentals\b\n4-2\n1.1. Minimizing Complexity\b\n4-2\n1.2. Anticipating and Embracing Change\b\n4-2\n1.3. Constructing for Verification\b\n4-4\n1.4. Reusing Assets \b\n4-4\n1.5. Applying Standards in Construction \b\n4-4\n2. Managing Construction\b\n4-4\n2.1. Construction in Life Cycle Models\b\n4-4\n2.2. Construction Planning \b\n4-5\n2.3. Construction Measurement \b\n4-5\n2.4. Managing Dependencies \b\n4-5\n3. Practical Considerations\b\n4-6\n3.1. Construction Design\b\n4-6\n3.2. Construction Languages \b\n4-6\n3.3. Coding \b\n4-7\n3.4. Construction Testing \b\n4-7\n3.5. Reuse in Construction \b\n4-7\n3.6. Construction Quality \b\n4-8\n3.7. Integration\b\n4-9\n3.8. Cross-Platform Development and Migration \b\n4-9\n4. Construction Technologies\b\n4-10\n4.1. API Design and Use \b\n4-10\n4.2. Object-Oriented Runtime Issues \b\n4-10\n4.3. Parameterization, Templates, and Generics \b\n4-10\n4.4. Assertions, Design by Contract, and Defensive Programming \b\n4-10\n4.5. Error Handling, Exception Handling, and Fault Tolerance \b\n4-11", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 9", "position": 9, "chunk_type": "semantic", "token_estimate": 150}
{"text": "TABLE OF CONTENTS   ix: 4.6. Executable Models \b\n4-11\n4.7. State-Based and Table-Driven Construction Techniques \b\n4-11\n4.8. Runtime Configuration and Internationalization\b\n4-12\n4.9. Grammar-Based Input Processing\b\n4-12\n4.10. Concurrency Primitives \b\n4-12\n4.11. Middleware\b\n4-12\n4.12. Construction Methods for Distributed and Cloud-Based Software\b\n4-13\n4.13. Constructing Heterogeneous Systems\b\n4-13\n4.14. Performance Analysis and Tuning\b\n4-13\n4.15. Platform Standards\b\n4-13\n4.16. Test-First Programming\b\n4-14\n4.17. Feedback Loop for Construction\b\n4-14\n5. Software Construction Tools\b\n4-14\n5.1. Development Environments \b\n4-14\n5.2. Visual Programming and Low-Code/Zero-Code Platforms\b\n4-14\n5.3. Unit Testing Tools\b\n4-15\n5.4. Profiling, Performance Analysis, and Slicing Tools \b\n4-15\nMatrix of Topics vs. Reference Material\b\n4-15\nFurther Readings\b\n4-18\nReferences\b\n4-18\b", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 10", "position": 10, "chunk_type": "semantic", "token_estimate": 113}
{"text": "Software Testing\b: 5-1\nIntroduction\b\n5-1\n1. Software Testing Fundamentals\b\n5-3\n1.1. Faults vs. Failures\b\n5-3\n1.2. Key Issues\b\n5-4\n1.2.1. Test Case Creation \b\n5-4\n1.2.2. Test Selection and Adequacy Criteria\b\n5-4\n1.2.3. Prioritization/Minimization\b\n5-4\n1.2.4. Purpose of Testing\b\n5-4\n1.2.5. Assessment and Certification \b\n5-4\n1.2.6. Testing for Quality Assurance/Improvement \b\n5-4\n1.2.7. The Oracle Problem \b\n5-4\n1.2.8. Theoretical and Practical Limitations \b\n5-5\n1.2.9. The Problem of Infeasible Paths \b\n5-5\n1.2.10. Testability \b\n5-5\n1.2.11. Test Execution and Automation\b\n5-5\n1.2.12. Scalability \b\n5-5\n1.2.13. Test Effectiveness\b\n5-5\n1.2.14. Controllability, Replication, and Generalization\b\n5-5\n1.2.15. Off-Line vs. Online Testing\b\n5-6\n1.3. Relationship of Testing to Other Activities\b\n5-6\n2. Test Levels\b\n5-6\n2.1. The Target of the Test \b\n5-6\n2.1.1. Unit Testing \b\n5-6\n2.1.2. Integration Testing \b\n5-7", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 10", "position": 10, "chunk_type": "semantic", "token_estimate": 134}
{"text": "x   SWEBOK \u00ae GUIDE V4.0: 2.1.3. System Testing\b\n5-7\n2.1.4. Acceptance Testing \b\n5-7\n2.2. Objectives of Testing \b\n5-7\n2.2.1. Conformance Testing\b\n5-7\n2.2.2. Compliance Testing\b\n5-8\n2.2.3. Installation Testing \b\n5-8\n2.2.4. Alpha and Beta Testing \b\n5-8\n2.2.5. Regression Testing \b\n5-8\n2.2.6. Prioritization Testing \b\n5-8\n2.2.7. Non-functional Testing \b\n5-8\n2.2.8. Security Testing\b\n5-9\n2.2.9. Privacy Testing \b\n5-9\n2.2.10. Interface and Application Program Interface (API) Testing\b\n5-10\n2.2.11. Configuration Testing \b\n5-10\n2.2.12. Usability and Human-Computer Interaction Testing\b\n5-10\n3. Test Techniques \b\n5-10\n3.1. Specification-Based Techniques\b\n5-10\n3.1.1. Equivalence Partitioning\b\n5-11\n3.1.2. Boundary-Value Analysis\b\n5-11\n3.1.3. Syntax Testing\b\n5-11\n3.1.4. Combinatorial Test Techniques \b\n5-11\n3.1.5. Decision Table\b\n5-11\n3.1.6. Cause-Effect Graphing\b\n5-11\n3.1.7. State Transition Testing \b\n5-12\n3.1.8. Scenario-Based Testing \b\n5-12\n3.1.9. Random Testing\b\n5-12\n3.1.10. Evidence-Based \b\n5-12\n3.1.11. Forcing Exception \b\n5-12\n3.2. Structure-Based Test Techniques\b\n5-13\n3.2.1. Control Flow Testing\b\n5-13\n3.2.2. Data Flow Testing \b\n5-13\n3.2.3. Reference Models for Structure-Based Test Techniques \b\n5-13\n3.3. Experience-Based Techniques\b\n5-13\n3.3.1. Error Guessing\b\n5-13\n3.3.2. Exploratory Testing\b\n5-13\n3.3.3. Further Experience-Based Techniques \b\n5-14\n3.4. Fault-Based and Mutation Techniques \b\n5-14\n3.5. Usage-Based Techniques \b\n5-15\n3.5.1. Operational Profile \b\n5-15\n3.5.2. User Observation Heuristics\b\n5-15\n3.6. Techniques Based on the Nature of the Application\b\n5-15\n3.7. Selecting and Combining Techniques \b\n5-16\n3.7.1. Combining Functional and Structural\b\n5-16\n3.7.2. Deterministic vs. Random \b\n5-16\n3.8. Techniques Based on Derived Knowledge \b\n5-16\n4. Test-Related Measures\b\n5-16\n4.1. Evaluation of the SUT \b\n5-17\n4.1.1. SUT Measurements that Aid in Planning and Designing Tests \b\n5-17", "domains": ["Design Patterns", "Software Quality Attributes", "Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 11", "position": 11, "chunk_type": "semantic", "token_estimate": 269}
{"text": "TABLE OF CONTENTS   xi: 4.1.2. Fault Types, Classification and Statistics\b\n5-17\n4.1.3. Fault Density \b\n5-17\n4.1.4. Life Test, Reliability Evaluation \b\n5-17\n4.1.5. Reliability Growth Models \b\n5-17\n4.2. Evaluation of the Tests Performed \b\n5-18\n4.2.1. Fault Injection\b\n5-18\n4.2.2. Mutation Score \b\n5-18\n4.2.3. Comparison and Relative Effectiveness of Different Techniques \b\n5-18\n5. Test Process \b\n5-18\n5.1. Practical Considerations \b\n5-19\n5.1.1. Attitudes/Egoless Programming \b\n5-19\n5.1.2. Test Guides and Organizational Process \b\n5-19\n5.1.3. Test Management and Dynamic Test Processes\b\n5-19\n5.1.4. Test Documentation\b\n5-19\n5.1.5. Test Team \b\n5-20\n5.1.6. Test Process Measures \b\n5-20\n5.1.7. Test Monitoring and Control \b\n5-20\n5.1.8. Test Completion\b\n5-20\n5.1.9. Test Reusability\b\n5-21\n5.2. Test Sub-Processes and Activities\b\n5-21\n5.2.1. Test Planning Process \b\n5-21\n5.2.2. Test Design and Implementation\b\n5-21\n5.2.3. Test Environment Set-up and Maintenance \b\n5-21\n5.2.4. Controlled Experiments and Test Execution \b\n5-22\n5.2.5. Test Incident Reporting\b\n5-22\n5.3. Staffing \b\n5-22\n6. Software Testing in the Development Processes and the Application Domains\b\n5-23\n6.1. Testing Inside Software Development Processes \b\n5-23\n6.1.1. Testing in Traditional Processes \b\n5-23\n6.1.2. Testing in Line with Shift-Left Movement\b\n5-23\n6.2. Testing in the Application Domains\b\n5-24\n7. Testing of and Testing Through Emerging Technologies \b\n5-26\n7.1. Testing of Emerging Technologies\b\n5-26\n7.2. Testing Through Emerging Technologies\b\n5-27\n8. Software Testing Tools \b\n5-29\n8.1. Testing Tool Support and Selection\b\n5-29\n8.2. Categories of Tools \b\n5-29\nMatrix of Topics vs. Reference Material\b\n5-31\nReferences\b\n5-34", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 12", "position": 12, "chunk_type": "semantic", "token_estimate": 252}
{"text": "xii   SWEBOK \u00ae GUIDE V4.0: 1.3. Software Installation \b\n6-5\n1.4. Scripting and Automating\b\n6-5\n1.5. Effective Testing and Troubleshooting\b\n6-5\n1.6. Performance, Reliability and Load Balancing\b\n6-6\n2. Software Engineering Operations Planning\b\n6-6\n2.1. Operations Plan and Supplier Management\b\n6-6\n2.1.1. Operations Plan\b\n6-6\n2.1.2. Supplier Management\b\n6-7\n2.2. Development and Operational Environments\b\n6-7\n2.3. Software Availability, Continuity, and Service Levels\b\n6-8\n2.4. Software Capacity Management\b\n6-8\n2.5. Software Backup, Disaster Recovery, and Failover\b\n6-8\n2.6. Software and Data Safety, Security, Integrity, Protection, and Controls\b\n6-9\n3. Software Engineering Operations Delivery\b\n6-9\n3.1. Operational Testing, Verification, and Acceptance\b\n6-9\n3.2. Deployment/Release Engineering\b\n6-10\n3.3. Rollback and Data Migration\b\n6-10\n3.4. Change Management\b\n6-11\n3.5. Problem Management\b\n6-11\n4. Software Engineering Operations Control\b\n6-11\n4.1. Incident Management\b\n6-11\n4.2. Monitor, Measure, Track, and Review\b\n6-11\n4.3. Operations Support\b\n6-12\n4.4. Operations Service Reporting\b\n6-12\n5. Practical Considerations\b\n6-12\n5.1. Incident and Problem Prevention\b\n6-12\n5.2. Operational Risk Management\b\n6-12\n5.3. Automating Software Engineering Operations\b\n6-12\n5.4. Software Engineering Operations for Small Organizations\b\n6-13\n6. Software Engineering Operations Tools\b\n6-13\n6.1. Containers and Virtualization\b\n6-13\n6.2. Deployment\b\n6-13\n6.3. Automated Test\b\n6-14\n6.4. Monitoring and Telemetry\b\n6-14\nMatrix of Topics vs. Reference Material\b\n6-14\nReferences \b\n6-15", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 13", "position": 13, "chunk_type": "semantic", "token_estimate": 206}
{"text": "TABLE OF CONTENTS   xiii: 1.6. Categories of Software Maintenance\b\n7-4\n2. Key Issues in Software Maintenance\b\n7-5\n2.1. Technical Issues\b\n7-5\n2.1.1\t Limited Understanding\b\n7-5\n2.1.2\t Testing\b\n7-5\n2.1.3\t Impact Analysis\b\n7-6\n2.1.4\t Maintainability\b\n7-6\n2.2. Management Issues\b\n7-7\n2.2.1. Alignment with Organizational Objectives\b\n7-7\n2.2.2. Staffing\b\n7-7\n2.2.3. Process\b\n7-8\n2.2.4. Supplier Management\b\n7-8\n2.2.5. Organizational Aspects of Maintenance\b\n7-8\n2.3. Software Maintenance Costs \b\n7-9\n2.3.1. Technical Debt Cost Estimation\b\n7-9\n2.3.2. Maintenance Cost Estimation\b\n7-9\n2.4. Software Maintenance Measurement\b\n7-10\n3. Software Maintenance Processes\b\n7-11\n3.1. Software Maintenance Processes\b\n7-11\n3.2. Software Maintenance Activities and Tasks\b\n7-11\n3.2.1. Supporting and Monitoring Activities\b\n7-12\n3.2.2. Planning Activities\b\n7-12\n3.2.3. Configuration Management\b\n7-13\n3.2.4. Software Quality\b\n7-13\n4. Software Maintenance Techniques\b\n7-13\n4.1. Program Comprehension\b\n7-13\n4.2. Software Reengineering\b\n7-13\n4.3. Reverse Engineering\b\n7-14\n4.4. Continuous Integration, Delivery, Testing, and Deployment\b\n7-14\n4.5. Visualizing Maintenance\b\n7-15\n5. Software Maintenance Tools\b\n7-15\nMatrix of Topics vs. Reference Material\b\n7-16\nFurther Readings\b\n7-17\nReferences \b\n7-17", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 14", "position": 14, "chunk_type": "semantic", "token_estimate": 165}
{"text": "xiv   SWEBOK \u00ae GUIDE V4.0: 1.3.5. Interface Control\b\n8-5\n1.4. SCM Plan\b\n8-5\n1.5. Monitoring of Software Configuration Management \b\n8-5\n1.5.1\t SCM Measures and Measurement \b\n8-6\n1.5.2\t In-Process Audits of SCM\b\n8-6\n2. Software Configuration Identification\b\n8-6\n2.1. Identifying Items to Be Controlled\b\n8-6\n2.1.1\t Software Configuration\b\n8-6\n2.1.2\t Software Configuration Item\b\n8-6\n2.2. Configuration Item Identifiers and Attributes\b\n8-7\n2.3. Baseline Identification\b\n8-7\n2.4. Baseline Attributes\b\n8-7\n2.5. Relationships Scheme Definition\b\n8-7\n2.6. Software Libraries \b\n8-8\n3. Software Configuration Change Control \b\n8-9\n3.1. Requesting, Evaluating, and Approving Software Changes \b\n8-9\n3.1.1\t Software Configuration Control Board\b\n8-10\n3.1.2\t Software Change Request Process\b\n8-10\n3.1.3\t Software Change Request Forms Definition\b\n8-10\n3.2. Implementing Software Changes\b\n8-10\n3.3. Deviations and Waivers\b\n8-11\n4. Software Configuration Status Accounting\b\n8-11\n4.1. Software Configuration Status Information\b\n8-11\n4.2. Software Configuration Status Reporting\b\n8-11\n5. Software Configuration Auditing\b\n8-12\n5.1. Software Functional Configuration Audit \b\n8-12\n5.2. Software Physical Configuration Audit \b\n8-12\n5.3. In-Process Audits of a Software Baseline\b\n8-12\n6. Software Release Management and Delivery\b\n8-13\n6.1. Software Building\b\n8-13\n6.2. Software Release Management\b\n8-13\n7. Software Configuration Management Tools\b\n8-14\nMatrix of Topics vs. Reference Material\b\n8-15\nFurther Readings\b\n8-16\nReferences \b\n8-17", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 15", "position": 15, "chunk_type": "semantic", "token_estimate": 205}
{"text": "TABLE OF CONTENTS   xv: 2.3. Effort, Schedule, and Cost Estimation\b\n9-8\n2.4. Resource Allocation \b\n9-9\n2.5. Risk Management \b\n9-9\n2.6. Quality Management \b\n9-9\n2.7. Plan Management \b\n9-10\n3. Software Project Execution\b\n9-11\n3.1. Implementation of Plans \b\n9-11\n3.2. Software Acquisition and Supplier Contract Management \b\n9-11\n3.3. Implementation of Measurement Process \b\n9-12\n3.4. Monitor Process \b\n9-12\n3.5. Control Process \b\n9-12\n3.6. Reporting\b\n9-13\n4. Software Review and Evaluation\b\n9-13\n4.1. Determining Satisfaction of Requirements \b\n9-13\n4.2. Reviewing and Evaluating Performance \b\n9-13\n5. Closure\b\n9-13\n5.1. Determining Closure \b\n9-13\n5.2. Closure Activities \b\n9-14\n6. Software Engineering Measurement\b\n9-14\n6.1. Establish and Sustain Measurement Commitment \b\n9-14\n6.2. Plan the Measurement Process\b\n9-15\n6.3. Perform the Measurement Process\b\n9-15\n6.4. Evaluate Measurement \b\n9-16\n7. Software Engineering Management Tools\b\n9-16\nMatrix of Topics vs. Reference Material\b\n9-17\nFurther Readings\b\n9-18\nReferences\b\n9-18", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 16", "position": 16, "chunk_type": "semantic", "token_estimate": 152}
{"text": "Software Engineering Models and Methods\b: 11-1\nIntroduction\b\n11-1\n1. Modeling\b\n11-1\n1.1. Modeling Principles\b\n11-2\n1.2. Properties and Expression of Models \b\n11-3\n1.3. Syntax, Semantics, and Pragmatics \b\n11-3\n1.4. Preconditions, Postconditions, and Invariants \b\n11-4\n2. Types of Models\b\n11-4\n2.1. Structural Modeling\b\n11-5\n2.2. Behavioral Modeling\b\n11-5\n3. Analysis of Models\b\n11-5\n3.1. Analyzing for Completeness \b\n11-6\n3.2. Analyzing for Consistency \b\n11-6\n3.3. Analyzing for Correctness \b\n11-6\n3.4. Analyzing for Traceability \b\n11.6\n3.5. Analyzing for Interaction \b\n11-6\n4. Software Engineering Methods\b\n11-7\n4.1. Heuristic Methods \b\n11-7\n4.2. Formal Methods \b\n11-8\n4.3. Prototyping Methods \b\n11-9\n4.4. Agile Methods\b\n11-10\nMatrix of Topics vs. Reference Material\b\n11-11\nReferences\b\n11-12", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 17", "position": 17, "chunk_type": "semantic", "token_estimate": 118}
{"text": "Software Security\b: 13-1\nIntroduction\b\n13-1\n1. Software Security Fundamentals\b\n13-1\n1.1. Software Security\b\n13-1\n1.2. Information Security\b\n13-1\n1.3. Cybersecurity \b\n13-2\n2. Security Management and Organization \b\n13-2\n2.1. Capability Maturity Model \b\n13-2\n2.2. Information Security Management System\b\n13-2\n2.3. Agile Practice for Software Security\b\n13-3\n3. Software Security Engineering and Processes\b\n13-3\n3.1. Security Engineering and Secure Development Life Cycle (SDLC) \b\n13-3\n3.2. Common Criteria for Information Technology Security Evaluation \b\n13-3\n4. Security Engineering for Software Systems\b\n13-3\n4.1. Security Requirements \b\n13-3\n4.2. Security Design\b\n13-4\n4.3. Security Patterns\b\n13-4\n4.4. Construction for Security \b\n13-4\n4.5. Security Testing \b\n13-5\n4.6. Vulnerability Management \b\n13-5\n5. Software Security Tools\b\n13-5\n5.1. Security Vulnerability Checking Tools \b\n13-5\n5.2. Penetration Testing Tools\b\n13-6", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 18", "position": 18, "chunk_type": "semantic", "token_estimate": 129}
{"text": "xviii   SWEBOK \u00ae GUIDE V4.0: 6. Domain-Specific Software Security\b\n13-6\n6.1. Security for Container and Cloud\b\n13-6\n6.2. Security for IoT Software\b\n13-6\n6.3. Security for Machine Learning-Based Application\b\n13-6\nMatrix of Topics vs. Reference Material\b\n13-7\nFurther Readings\b\n13-8\nReferences\b\n13-8", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 19", "position": 19, "chunk_type": "semantic", "token_estimate": 42}
{"text": "Software Engineering Economics\b: 15-1\nIntroduction\b\n15-1\n1. Software Engineering Economics Fundamentals\b\n15-3\n1.1. Proposals\b\n15-3\n1.2. Cash Flow\b\n15-3\n1.3. Time-Value of Money\b\n15-3\n1.4. Equivalence\b\n15-4\n1.5. Bases for Comparison\b\n15-4\n1.6. Alternatives\b\n15-4\n1.7. Intangible Assets\b\n15-4\n1.8.\t\nBusiness Model\b\n15-5\n2. The Engineering Decision-Making Process\b\n15-5\n2.1. Process Overview\b\n15-5\n2.2. Understand the Real Problem\b\n15-5\n2.3. Identify All Reasonable Technically Feasible Solutions\b\n15-6\n2.4. Define the Selection Criteria\b\n15-6\n2.5. Evaluate Each Alternative Against the Selection Criteria\b\n15-6\n2.6. Select the Preferred Alternative\b\n15-6\n2.7. Monitor the Performance of the Selected Alternative\b\n15-7\n3. For-Profit Decision-Making\b\n15-7\n3.1. Minimum Acceptable Rate of Return\b\n15-7\n3.2. Economic Life\b\n15-7\n3.3. Planning Horizon\b\n15-8\n3.4. Replacement Decisions\b\n15-8\n3.5. Retirement Decisions\b\n15-9\n3.6. Advanced For-Profit Decision Considerations\b\n15-9\n4. Nonprofit Decision-Making\b\n15-9\n4.1. Benefit-Cost Analysis\b\n15-9\n4.2. Cost-Effectiveness Analysis\b\n15-9\n5. Present Economy Decision-Making\b\n15-9\n5.1. Break-Even Analysis\b\n15-9\n5.2. Optimization Analysis\b\n15-9\n6. Multiple-Attribute Decision-Making\b\n15-10\n6.1. Compensatory Techniques\b\n15-10\n6.2. Non-Compensatory Techniques\b\n15-10\n7. Identifying and Characterizing Intangible Assets\b\n15-10\n7.1. Identify Processes and Define Business Goals\b\n15-10\n7.2. Identify Intangible Assets Linked with Business Goal\b\n15-11\n7.3. Identify Software Products That Support Intangible Assets\b\n15-11\n7.4. Define and Measure Indicators\b\n15-11\n7.5. Intangible Asset Characterization\b\n15-11", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 20", "position": 20, "chunk_type": "semantic", "token_estimate": 211}
{"text": "TABLE OF CONTENTS   xxi: 2.3.3. Input/Output Devices\b\n16-6\n2.3.4. Control Unit\b\n16-6\n3. Data Structures and Algorithms\b\n16-6\n3.1. Types of Data Structures\b\n16-6\n3.2. Operations on Data Structures\b\n16-7\n3.3. Algorithms and Attributes of Algorithms\b\n16-7\n3.4. Algorithm Complexity\b\n16-8\n3.5. Measurement of Complexity\b\n16-8\n3.6. Designing Algorithms\b\n16-8\n3.7. Sorting Techniques\b\n16-9\n3.8. Searching Techniques\b\n16-10\n3.9. Hashing\b\n16-10\n4. Programming Fundamentals and Languages\b\n16-10\n4.1. Programming Language Types\b\n16-10\n4.2. Programming Syntax, Semantics, Type Systems\b\n16-11\n4.3. Subprograms and Coroutines\b\n16-11\n4.4. Object-Oriented Programming \b\n16-12\n4.5. Distributed Programming and Parallel Programming\b\n16-13\n4.6. Debugging\b\n16-13\n4.7. Standards and Guidelines\b\n16-13\n5. Operating Systems\b\n16-15\n5.1. Processor Management\b\n16-15\n5.2. Memory Management\b\n16-16\n5.3. Device Management\b\n16-16\n5.4. Information Management\b\n16-16\n5.5. Network Management\b\n16-16\n6. Database Management\b\n16-17\n6.1. Schema\b\n16-17\n6.2. Data Models and Storage Models\b\n16-17\n6.3. Database Management Systems \b\n16-18\n6.4. Relational Database Management Systems and Normalization\b\n16-18\n6.5. Structured Query Language \b\n16-19\n6.6. Data Mining and Data Warehousing\b\n16-19\n6.7. Database Backup and Recovery\b\n16-20\n7. Computer Networks and Communications\b\n16-20\n7.1. Types of Computer Networks\b\n16-20\n7.2. Layered Architectures of Networks\b\n16-21\n7.3. Open Systems Interconnection Model\b\n16-21\n7.4. Encapsulation and Decapsulation\b\n16-22\n7.5. Application Layer Protocols\b\n16-22\n7.6. Design Techniques for Reliable and Efficient Network\b\n16-22\n7.7. Internet Protocol Suite\b\n16-23\n7.8. Wireless and Mobile Networks\b\n16-23\n7.9. Security and Vulnerabilities\b\n16-23\n8. User and Developer Human Factors\b\n16-24\n8.1. User Human Factors\b\n16-24\n8.2. Developer Human Factors\b\n16-24\n9. Artificial Intelligence and Machine Learning\b\n16-25", "domains": ["Architectural Patterns and Styles", "Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 22", "position": 22, "chunk_type": "semantic", "token_estimate": 258}
{"text": "Mathematical Foundations\b: 17-1\nIntroduction\b\n17-1\n1. Basic Logic\b\n17-1\n1.1. Propositional Logic\b\n17-1\n1.2. Predicate Logic\b\n17-3\n2. Proof Techniques\b\n17-3\n2.1. Direct Proof\b\n17-4\n2.2. Proof by Contradiction\b\n17-4\n2.3. Proof by Induction\b\n17-4\n2.4. Proof by Example\b\n17-5\n3. Set, Relation, Function\b\n17-5\n3.1. Set Operations\b\n17-6\n3.2. Properties of Sets\b\n17-6\n3.3. Relation and Function\b\n17-7\n4. Graph and Tree\b\n17-8\n4.1. Graph\b\n17-8\n4.2. Tree\b\n17-10\n5. Finite-State Machine\b\n17-12\n6. Grammar  \b\n17-13\n6.1. Language Recognition \b\n17-14\n7. Number Theory  \b\n17-14\n7.1. Types of Numbers\b\n17-15\n7.2. Divisibility\b\n17-15\n7.3. Prime Number\b\n17-15\n7.4. Greatest Common Divisor\b\n17-16\n8. Basics of Counting\b\n17-16\n9. Discrete Probability\b\n17-17\n10. Numerical Precision, Accuracy, and Error\b\n17-18\n11. Algebraic Structures\b\n17-19\n11.1. Group\b\n17-19\n11.2. Ring\b\n17-20\n12. Engineering Calculus\b\n17-21\n13. New Advancements\b\n17-21\n13.1. Computational Neurosciences\b\n17-21\n13.2. Genomics\b\n17-21\nMatrix of Topics vs. Reference Material\b\n17-22\nReferences\b\n17-22", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 23", "position": 23, "chunk_type": "semantic", "token_estimate": 155}
{"text": "Engineering Foundations\b: 18-1\nIntroduction\b\n18-1\n1. The Engineering Process\b\n18-1\n2. Engineering Design\b\n18-2\n2.1. Engineering Design in Engineering Education\b\n18-2\n2.2. Design as a Problem-Solving Activity\b\n18-3\n3. Abstraction and Encapsulation\b\n18-3\n3.1. Levels of Abstraction \b\n18-4\n3.2. Encapsulation\b\n18-4\n3.3. Hierarchy\b\n18-4\n3.4. Alternate Abstractions\b\n18-4\n4. Empirical Methods and Experimental Techniques \b\n18-4\n4.1. Designed Experiment\b\n18-5\n4.2. Observational Study\b\n18-5\n4.3. Retrospective Study\b\n18-5\n5. Statistical Analysis \b\n18-5\n5.1. Unit of Analysis (Sampling Units), Population, and Sample\b\n18-5\n5.2. Correlation and Regression\b\n18-8\n6. Modeling, Simulation, and Prototyping\b\n18-8\n6.1. Modeling\b\n18-8\n6.2. Simulation \b\n18-9\n6.3. Prototyping\b\n18-9\n7. Measurement\b\n18-10\n7.1. Levels (Scales) of Measurement\b\n18-10\n7.2. Implications of Measurement Theory for Programming Languages\b\n18-12\n7.3. Direct and Derived Measures\b\n18-13\n7.4. Reliability and Validity\b\n18-14\n7.5. Assessing Reliability\b\n18-14\n7.6. Goal-Question-Metric Paradigm: Why Measure?\b\n18-15\n8. Standards\b\n18-15\n9. Root Cause Analysis\b\n18-16\n9.1. Root Cause Analysis Techniques\b\n18-16\n9.2. Root Cause\u2013Based Improvement\b\n18-17\n10. Industry 4.0 and Software Engineering\b\n18-17\nMatrix of Topics vs. Reference Material\b\n18-18\nFurther Readings\b\n18-19\nReferences\b\n18-20", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 24", "position": 24, "chunk_type": "semantic", "token_estimate": 182}
{"text": "FOREWORD: The Guide to the Software Engineering Body of Knowledge (SWEBOK Guide), published by the \nIEEE Computer Society (IEEE CS), represents the current state of generally accepted, con-\nsensus-based knowledge emanating from the interplay between software engineering theory \nand practice. Its objectives include the provision of guidance for learners, researchers, and prac-\ntitioners to identify and share a common understanding of \u201cgenerally accepted knowledge\u201d in \nsoftware engineering, defining the boundary between software engineering and related disci-\nplines, and providing a foundation for certifications and educational curricula. The origins of the Guide go back to the early 2000s. Much like the software engineering dis-\ncipline, the Guide has continued to evolve over the last 20 years to reflect society\u2019s industrial, \neducational, social, technical, and technological changes. Publication of the 2014 version of the \nGuide (SWEBOK Guide V3) was a significant milestone in establishing software engineering as \na recognized engineering discipline. The goal of developing this update (SWEBOK Guide V4) to the Guide is to improve the \nGuide\u2019s currency, readability, consistency, and usability. The Guide consists of 18 knowledge \nareas (KAs) followed by several appendixes. A KA is an identified area of software engineering \ndefined by its knowledge requirements and described in terms of its component processes, prac-\ntices, inputs, outputs, tools, and techniques. Three appendixes provide, respectively, the speci-\nfications for the KA descriptions, an annotated set of relevant standards for each KA, and a list \nof references cited in the Guide. All KAs have been updated to reflect changes in software engineering since the publication \nof Guide V3, including modern development practices, new techniques, and the advancement \nof standards. One significant change is that Agile and DevOps have been incorporated into \nalmost all KAs because these models have been widely accepted since the previous publication \nof the Guide. Agile models typically involve frequent demonstrations of working software to \na customer in short, iterative cycles. Agile practices exist across KAs. Furthermore, emerging \nplatforms and technologies, including artificial intelligence (AI), machine learning (ML), and \nthe internet of things (IoT), have been incorporated into the foundation KAs. To reflect areas that are becoming particularly important in modern software engineering, \nthe following KAs have been added: the Software Architecture KA, Software Security KA, \nand Software Engineering Operations KA.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 26", "position": 26, "chunk_type": "semantic", "token_estimate": 374}
{"text": "FOREWORD: Furthermore, emerging \nplatforms and technologies, including artificial intelligence (AI), machine learning (ML), and \nthe internet of things (IoT), have been incorporated into the foundation KAs. To reflect areas that are becoming particularly important in modern software engineering, \nthe following KAs have been added: the Software Architecture KA, Software Security KA, \nand Software Engineering Operations KA. This Guide, written under the auspices of the Professional and Educational Activities Board \nof the IEEE Computer Society, represents the next step in the evolution of the software engi-\nneering profession. Steve McConnell\nChief Executive Officer, Construx Software\nHironori Washizaki\nPresident-Elect 2024, President 2025, IEEE Computer Society\n  xxv", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 26", "position": 26, "chunk_type": "semantic", "token_estimate": 104}
{"text": "xxviii   SWEBOK \u00ae GUIDE V4.0: 1. Define Required Body of Knowledge and Recommended Practices. 2. Define Ethics and Professional Standards. 3. Define Educational Curricula for undergraduate, graduate, and continuing education. This book supplies the first component: required body of knowledge and recommended \npractices. The code of ethics and professional practice for software engineering was completed in 1998 \nand approved by both the ACM Council and the IEEE Computer Society Board of Governors. It has been adopted by numerous corporations and other organizations and is included in sev-\neral recent textbooks. The educational curriculum for undergraduates is being completed by a joint effort of the \nIEEE Computer Society and the ACM and is expected to be completed in 2004. Every profession is based on a body of knowledge and recommended practices, although \nthey are not always defined in a precise manner. In many cases, these are formally documented, \nusually in a form that permits them to be used for such purposes as accreditation of academic \nprograms, development of education and training programs, certification of specialists, or pro-\nfessional licensing. Generally, a professional society or related body maintains custody of such \na formal definition. In cases where no such formality exists, the body of knowledge and recom-\nmended practices are \u201cgenerally recognized\u201d by practitioners and may be codified in a variety \nof ways for different uses. It is hoped that readers will find this book useful in guiding them toward the knowledge and \nresources they need in their lifelong career development as software engineering professionals. The book is dedicated to Fletcher Buckley in recognition of his commitment to promoting \nsoftware engineering as a professional discipline and his excellence as a software engineering \npractitioner in radar applications. Leonard L. Tripp, IEEE Fellow 2003\nChair,\u2008Professional\u2008Practices\u2008Committee,\u2008IEEE\u2008\nComputer\u2008Society\u2008(2001\u20132003)\nChair,\u2008Joint\u2008IEEE\u2008Computer\u2008Society\u2008and\u2008ACM\u2008\nSteering\u2008Committee\u2008for\u2008the\u2008Establishment\u2008of \nSoftware\u2008Engineering\u2008as\u2008a\u2008Profession\u2008(1998\u20131999)\nChair,\u2008Software\u2008Engineering\u2008Standards\u2008\u2008Committee,\u2008\nIEEE\u2008Computer\u2008Society\u2008(1992\u20131998)", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 29", "position": 29, "chunk_type": "semantic", "token_estimate": 326}
{"text": "Software Requirements: Steve Tockey, Construx Software, USA. Software Architecture\nRich Hilliard, USA. Software Design\nRich Hilliard, USA. Software Construction\nXin Peng, Software School, Fudan University, China. Steve Schwarm, Synopsys - Black Duck Software, USA. Software Testing\nEda Marchetti, ISTI-CNR, Italy. Said Daoudagh, ISTI-CNR, Italy. Software Engineering Operations\nFrancis Bordeleau, \u00c9cole de technologie sup\u00e9rieure (\u00c9TS), Canada. Alain April, \u00c9cole de technologie sup\u00e9rieure (\u00c9TS), Canada. Software Maintenance\nAli Ouni, \u00c9cole de technologie sup\u00e9rieure (\u00c9TS), Canada\nAlain April, \u00c9cole de technologie sup\u00e9rieure (\u00c9TS), Canada\nPeter Leather, Exceptional Performance, UK. Software Configuration Management\nMaria Isabel S\u00e1nchez Segura, Universidad Carlos III de Madrid, Spain. Bob Aiello, CM Best Practices, USA. Software Engineering Management\nKenneth E. Nidiffer, George Mason University, USA. Software Engineering Process\nJuan Garbajosa, Universidad Polit\u00e9cnica de Madrid, Spain. Software Engineering Models and Methods\nHironori Washizaki, Waseda University, Japan. Akinori Ihara, Wakayama University, Japan. Shinpei Ogata, Shinshu University, Japan. xxix", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 30", "position": 30, "chunk_type": "semantic", "token_estimate": 146}
{"text": "xxx   SWEBOK \u00ae GUIDE V4.0: Software Quality\nAlain April, \u00c9cole de technologie sup\u00e9rieure (\u00c9TS), Canada. Steve Tockey, Construx Software, USA. Steve Schwarm, Synopsys - Black Duck Software, USA. Software Security\nNobukazu Yoshioka, Waseda University, Japan. Seiji Munetoh, IBM Research, Japan. Software Engineering Professional Practice\nKatsuhisa Shintani, Waseda University, Japan. Eiji Hayashiguchi, Waseda University, Japan. Software Engineering Economics\nMaria Isabel S\u00e1nchez Segura, Universidad Carlos III de Madrid, Spain. Steve Tockey, Construx Software, USA. Computing Foundations\nYatheendranath TJ, DhiiHii Labs Private Limited, India. Mathematical Foundations\nYatheendranath TJ, DhiiHii Labs Private Limited, India. Steve Tockey, Construx Software, USA. Engineering Foundations\nYatheendranath TJ, DhiiHii Labs Private Limited, India. Steve Tockey, Construx Software, USA. Appendix A: Knowledge Area Description Specifications\nJuan Garbajosa, Universidad Polit\u00e9cnica de Madrid, Spain. Hironori Washizaki, Waseda University, Japan. Appendix B: IEEE and ISO/IEC Standards Supporting SWEBOK\nAnnette Reilly, USA. Appendix C: Consolidated Reference List\nHironori Washizaki, Waseda University, Japan.", "domains": ["Design Principles", "Software Quality Attributes", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 31", "position": 31, "chunk_type": "semantic", "token_estimate": 148}
{"text": "Software Engineering Body: of Knowledge\nPublication of the 2014 version of the Guide \nto the Software Engineering Body of Knowledge \n(SWEBOK Guide V3) was a major milestone in \nestablishing software engineering as a recog-\nnized engineering discipline. The goal of devel-\noping this update (Version 4) to the SWEBOK \nGuide is to improve the Guide\u2019s currency, read-\nability, consistency and usability. The content \nof the Guide consists of 18 knowledge areas \n(KAs) followed by several appendixes. A KA is \nan identified area of software engineering and \nis described in terms of its generally accepted \nknowledge, such as its component processes, \npractices, inputs, outputs, tools and tech-\nniques. Three appendixes provide, respectively, \nthe specifications for the KA descriptions, an \nannotated set of relevant standards for each \nKA, and a list of references cited in the Guide. All KAs have been updated to reflect \nchanges in software engineering since the \npublication of the Guide V3, including modern \ndevelopment practices, new techniques, and \nthe advancement of standards. One signifi-\ncant change is that Agile and DevOps have \nbeen incorporated into almost all KAs because \nthese models have been widely accepted since \nthe previous publication of the Guide. Agile \nmodels typically involve frequent demonstra-\ntions of working software to a customer in \nshort, iterative cycles. Agile practices exist \nacross KAs. Furthermore, emerging plat-\nforms and technologies, including artificial \n1\t\n http://pascal.computer.org/sev_display/index.action. intelligence (AI), machine learning (ML) and \nthe internet of things (IoT), have been incor-\nporated into the foundation KAs. To reflect areas that are becoming partic-\nularly important in modern software engi-\nneering, the following KAs have been added: \nthe Software Architecture KA, Software \nSecurity KA and Software Engineering \nOperations KA. This Guide, written under the auspices of \nthe Professional and Educational Activities \nBoard of the IEEE Computer Society, rep-\nresents a next step in the evolution of the soft-\nware engineering profession. 1. What Is Software Engineering? ISO/IEC/IEEE Systems and Software \nEngineering \nVocabulary \n(SEVOCAB)1 \ndefines software as \u201ccomputer programs, pro-\ncedures and possibly associated documenta-\ntion and data pertaining to the operation of a \ncomputer system\u201d.1 And software engineering \nis defined as \u201cthe application of a systematic, \ndisciplined, quantifiable approach to the devel-\nopment, operation, and maintenance of soft-\nware; that is, the application of engineering \nto software\u201d [1].", "domains": ["Software Quality Attributes", "Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 38", "position": 38, "chunk_type": "semantic", "token_estimate": 376}
{"text": "xxxviii   SWEBOK \u00ae GUIDE V4.0: In engineering, science \nand practice are applied to generate poten-\ntial solutions to the real-world problem, and \nengineering economics is used to identify the \nmost cost-effective one. In the same way that \nit would not make sense to send a chemist to \nsolve a chemical engineering problem, it does \nnot make sense to send a computer scientist to \nsolve a software engineering problem. In addition to computer science, software \nengineering is related to several other disci-\nplines and professional areas, such as indus-\ntrial engineering, dependability engineering, \nand safety and security engineering. 2. What Are the Objectives of the  \nSWEBOK Guide? The Guide should not be confused with the \nbody of knowledge itself, which exists in the \npublished literature. The Guide\u2019s purpose is \nto describe the generally accepted portion of \nthe body of knowledge, organize that portion, \nand provide topical access to it. The SWEBOK Guide was established with \nthe following five objectives:\n1. To promote a consistent view of software \nengineering worldwide\n2. To specify the scope and clarify the place \nof software engineering with respect to \nother disciplines, such as computer sci-\nence, project management, computer \nengineering and mathematics\n3. To characterize the contents of the soft-\nware engineering discipline\n4. To provide topical access to the Software \nEngineering Body of Knowledge\n5. To provide a foundation for curriculum \ndevelopment and for individual certifica-\ntion and licensing materials\nThe first objective, to promote a consis-\ntent worldwide view of software engineering, \nwas supported by a development process that", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 39", "position": 39, "chunk_type": "semantic", "token_estimate": 255}
{"text": "INTRODUCTION TO THE GUIDE   xxxix: engaged about 130+ reviewers from various \ncountries. More information regarding the \ndevelopment process can be found at www. swebok.org. Professional and learned soci-\neties and public agencies involved in soft-\nware engineering were contacted, made \naware of this project to update the SWEBOK \nGuide, and invited to participate in the review \nprocess. Associate editors were recruited \nfrom America, Asia, Europe, and Oceania. Presentations on the project were made at var-\nious international venues. The second objective, to specify the scope \nof software engineering, underlies the fun-\ndamental organization of the Guide. Material \nthat falls within this discipline is organized \ninto the 18 KAs listed in Table I.1. Each KA \nis treated as a chapter in this Guide. Among \nthem, Chapters 1-15 are regarded as the soft-\nware engineering KAs, while Chapters 16-18 \naddress foundation KAs. TABLE I.1. THE 18 SWEBOK KAS\n1. Software Requirements\n2. Software Architecture\n3. Software Design\n4. Software Construction\n5. Software Testing\n6. Software Engineering Operations\n7. Software Maintenance\n8. Software Configuration Management\n9. Software Engineering Management\n10. Software Engineering Process\n11. Software Engineering Models \nand Methods\n12. Software Quality\n13. Software Security\n14. Software Engineering \nProfessional Practice\n15. Software Engineering Economics\n16. Computing Foundations \n17. Mathematical Foundations\n18. Engineering Foundations\nIn specifying the scope of the discipline, \nit is also important to identify disciplines \nthat intersect with software engineering. To \nthis end, the SWEBOK V4 Guide continues \nto recognize eleven related disciplines, listed \nin Table I.2. Software engineers should, of \ncourse, be knowledgeable about these dis-\nciplines (and KA descriptions in this Guide \nmight refer to them). However, characterizing \nthe knowledge of related disciplines is not an \nobjective of the SWEBOK Guide. TABLE I.2. RELATED DISCIPLINES\nBusiness Analysis\nComputer Engineering\nComputer Science\nCybersecurity \nData Science\nGeneral Management\nInformation Systems and Technology\nMathematics\nProject Management\nQuality Management\nSystems Engineering\nThe relevant elements of computer science, \nmathematics, and engineering foundations \nare presented in the Computing Foundations \nKA,  Mathematical Foundations KA, and \nEngineering Foundations KA of the Guide \n(Chapters 16, 17 and 18).", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 40", "position": 40, "chunk_type": "semantic", "token_estimate": 340}
{"text": "xl   SWEBOK \u00ae GUIDE V4.0: KA provides a two- or three-level break-\ndown, which provides a reasonable way to \nfind topics of interest. The Guide treats the \nselected topics in a way that is compatible \nwith major schools of thought and sepa-\nrates the topics into subtopics that are gen-\nerally found in industry and in software \nengineering literature and standards. The \nbreakdowns are not designed for particular \napplication domains, business uses, manage-\nment philosophies, development methods and \nso forth. Each topic description is meant only \nto give the reader a general understanding \nof the topic and to enable the reader to find \nreference material. The body of knowledge \nis found in the reference materials, not in \nthe Guide. Software plays a core role in various appli-\ncation and technological domains, such as \nautomotive, legal, health care, and finance. Differences in application domains and busi-\nness models (e.g., custom applications, and \nopen source applications) and system types \n(e.g., enterprise and cloud systems, embedded \nand IoT systems, and AI/ML-based sys-\ntems) may influence what practices are \nadopted. Major special techniques and prac-\ntices specific to certain system types are \nalso discussed in some KAs, especially the \nSoftware Requirements KA, the Software \nTesting KA, the Software Quality KA, the \nSoftware Security KA and the Computing \nFoundations KA.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 41", "position": 41, "chunk_type": "semantic", "token_estimate": 215}
{"text": "Confidentiality, Integrity,: and Availability", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 43", "position": 43, "chunk_type": "semantic", "token_estimate": 4}
{"text": "The topic breakdown for the Software: Requirements KA is shown in Figure 1.1. 1. Software Requirements Fundamentals\n1.1. Definition of a Software Requirement  \n\b\n[1*, c1pp5-6] [2*, c4p102]\nFormally, a software requirement has been \ndefined as [28]:\n\u2022\t a condition or capability needed by a user \nto solve a problem or achieve an objective;\n\u2022\t a condition or capability that must be \nmet or possessed by a system or system \ncomponent to satisfy a contract, stan-\ndard, specification or other formally \nimposed document;\n\u2022\t a documented representation or capa-\nbility as in (1) or (2) above. This formal definition is extended in this \nKA to include expressions of a software proj-\nect\u2019s needs and constraints.", "domains": ["Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 44", "position": 44, "chunk_type": "semantic", "token_estimate": 115}
{"text": "1-4   SWEBOK \u00ae GUIDE V4.0: (See also [9, c4].) 1.7. Quality of Service Constraints\nThese requirements do not constrain the use \nof specific, named technologies. Instead, \nthese specify acceptable performance levels an \nautomated solution must exhibit. Examples \nare response time, throughput, accuracy, \nreliability and scalability. ISO/IEC 25010: \n\u201cSystem and software engineering \u2013 Systems \nand software Quality Requirements and \nEvaluation (SQuaRE) \u2013 System and software \nquality models\u201d [27] contains a large list of \nthe kinds of quality characteristics that can be \nrelevant for software. (See also [9, c4].) Safety \nSoftware\nRequirements\nSoftware Project\nRequirements\nFunctional\nRequirements\nNonfunctional\nRequirements\nTechnology\nConstraints\nQuality of Service\nConstraints\nSoftware Product\nRequirements\nFigure 1.2. Categories of Software Requirements", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 46", "position": 46, "chunk_type": "semantic", "token_estimate": 112}
{"text": "SOFTWARE REQUIREMENTS   1-5: and security are also a particularly important \ntopic where requirements tend to be over-\nlooked. (See the Security KA for details on \nthe kinds of specific security requirements \nthat should be considered.) (See also [2*, c13].) 1.8. Why Categorize Requirements This Way? Categorizing requirements this way is useful \nfor the following reasons:\n\u2022\t requirements in one category tend to \ncome from different sources than other \ncategories;\n\u2022\t elicitation \ntechniques \noften \nvary \nby source;\n\u2022\t analysis techniques vary by category;\n\u2022\t specification techniques vary by category;\n\u2022\t validation authorities vary by category;\n\u2022\t the different categories affect the resulting \nsoftware in different ways. In addition, organizing the requirements \nin these categories is beneficial in the fol-\nlowing ways:\n\u2022\t complexity can be better managed because \ndifferent areas can be addressed sepa-\nrately; software engineers can deal with \npolicy and process complexities without \nworrying about automation technology \nissues at the same time (and vice versa). One large problem becomes two smaller \nones. This is classic divide and conquer \ncomplexity management;\n\u2022\t distinct areas of expertise can be iso-\nlated; stakeholders, not software engi-\nneers, are the experts in the policies and \nprocesses to be automated. Software \nengineers, not stakeholders, are the \ntechnology experts. When a business \nexpert is given interspersed functional \nand nonfunctional requirements for \nreview or validation, they might give \nup because they don\u2019t understand \u2014 or \neven care about \u2014 the technology issues. The relevant requirements reviewer can \nfocus on just the subset of requirements \nrelevant to them. The Perfect Technology Filter originally \ndescribed in [18, c1-4] but also explained in \n[8] and [9, c4] helps separate functional from \nnonfunctional requirements. Simply put, \nfunctional requirements are those that would \nstill need to be stated even if a computer with \ninfinite speed, unlimited memory, zero cost, \nno failures, etc., existed on which to construct \nthe software. All other software product \nrequirements are constraints on automation \ntechnologies and are therefore nonfunctional. Large systems often span more than one \nsubject matter area, or domain. As explained \nin [9, c6], recursive design shows how non-\nfunctional requirements in a parent domain \ncan become, or can induce, functional require-\nments in a child domain. For example, a non-\nfunctional requirement about user security \nin a parent banking domain can become or \ncan induce functional requirements in a child \nsecurity domain.", "domains": ["Design Patterns", "Software Quality Attributes", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 47", "position": 47, "chunk_type": "semantic", "token_estimate": 388}
{"text": "SOFTWARE REQUIREMENTS   1-5: As explained \nin [9, c6], recursive design shows how non-\nfunctional requirements in a parent domain \ncan become, or can induce, functional require-\nments in a child domain. For example, a non-\nfunctional requirement about user security \nin a parent banking domain can become or \ncan induce functional requirements in a child \nsecurity domain. Similarly, cross-cutting non-\nfunctional requirements about auditing and \ntransaction management in a parent banking \ndomain can become or induce functional \nrequirements in a child auditing domain and a \nchild transaction domain. Decomposing large \nsystems into a set of related domains signifi-\ncantly reduces complexity. 1.9. System Requirements and Software \nRequirements\nThe International Council on Systems \nEngineering (INCOSE) defines a system as \n\u201can interacting combination of elements to \naccomplish a defined objective. These include \nhardware, software, firmware, people, infor-\nmation, techniques, facilities, services, and \nother support elements\u201d [24]. In some cases, it is either useful or manda-\ntory to distinguish system requirements from \nsoftware requirements. System requirements \napply to larger systems \u2014 for example, an \nautonomous vehicle. Software requirements \napply only to an element of software in that \nlarger system. Some software requirements \nmay be derived from system requirements. (See also [5, c1].) In other cases, the software is \nitself the system of interest, and hardware and", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 47", "position": 47, "chunk_type": "semantic", "token_estimate": 213}
{"text": "SOFTWARE REQUIREMENTS   1-7: Many product require-\nments are tacit or can be found only in infor-\nmation that has yet to be collected. Requirements can also be elicited from \nsources other than stakeholders. Such sources \nand techniques include the following:\n\u2022\t previous versions of the system;\n\u2022\t defect tracking database for previous ver-\nsions of the system;\n\u2022\t systems that interface with the system \nunder development;\n\u2022\t competitive benchmarking;\n\u2022\t literature search;\n\u2022\t quality function deployment (QFD)\u2019s \nHouse of Quality [15];\n\u2022\t observation, where the software engineer \nstudies the work and the environment \nwhere the work is being done;\n\u2022\t apprenticing, where the software engi-\nneer learns by doing the work;\n\u2022\t usage scenario descriptions;", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 49", "position": 49, "chunk_type": "semantic", "token_estimate": 115}
{"text": "1-8   SWEBOK \u00ae GUIDE V4.0: \u2022\t decomposition (e.g., capabilities into \nepics into features into stories);\n\u2022\t task analysis [16];\n\u2022\t design thinking (empathize, define, \nideate, prototype, test) [17];\n\u2022\t ISO/IEC 25010: \u201cSystem and software \nengineering \u2013 Systems and software \nQuality Requirements and Evaluation \n(SQuaRE) \u2013 System and software quality \nmodels\u201d [27];\n\u2022\t security requirements, as discussed in the \nSecurity KA;\n\u2022\t applicable standards and regulations. (See also [5, c3] [6, c4-7].) 3. Requirements Analysis [1*, c8-9]\nRequirements are unlikely to be elicited in \ntheir final form. Further investigation is usu-\nally needed to reveal the full, true require-\nments suggested by the originally elicited \ninformation. Requirements analysis helps \nsoftware developers understand the meaning \nand implications of candidate requirements, \nboth individually and in the context of the \noverall set of requirements. 3.1. Basic Requirements Analysis  \n\b\n[1*, c8-9]\nThe following list of desirable properties of \nrequirements can guide basic requirements \nanalysis. The software engineer seeks to \nestablish any of these properties that do not \nhold yet. Each requirement should:\n\u2022\t be \nunambiguous \n(interpretable \nin \nonly one way);\n\u2022\t be testable (quantified), meaning that \ncompliance or noncompliance can be \nclearly demonstrated;\n\u2022\t be binding, meaning that clients are \nwilling to pay for it and unwilling not \nto have it;\n\u2022\t atomic, represent a single decision\n\u2022\t represent true, actual stakeholder needs;\n\u2022\t use stakeholder vocabulary;\n\u2022\t be acceptable to all stakeholders. The overall collection of requirements \nshould be:\n\u2022\t complete  \u2014 The requirements adequately \naddress boundary conditions, exception \nconditions and security needs;\n\u2022\t concise \u2014 No extraneous content in the \nrequirements\n\u2022\t internally consistent \u2014 No requirement \nconflicts with any other;\n\u2022\t externally consistent \u2014 No requirement \nconflicts with any source material;\n\u2022\t feasible \u2014 A viable, cost-effective solu-\ntion can be created within cost, schedule, \nstaffing, and other constraints. In some cases, an elicited statement rep-\nresents a solution to be implemented rather \nthan the true problem to be solved. This \nrisks implementing a suboptimal solution. The 5-whys technique (e.g., [3*, c4]) involves \nrepeatedly asking, \u201cWhy is this the require-\nment?\u201d to converge on the true problem. Repetition stops when the answer is, \u201cIf that \nisn\u2019t done, then the stakeholder\u2019s problem has \nnot been solved.\u201d Often, the true problem is \nreached in two or three cycles, but the tech-\nnique is called 5-whys to incentivize engineers \nto push it as far as possible. 3.2.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 50", "position": 50, "chunk_type": "semantic", "token_estimate": 393}
{"text": "1-8   SWEBOK \u00ae GUIDE V4.0: Repetition stops when the answer is, \u201cIf that \nisn\u2019t done, then the stakeholder\u2019s problem has \nnot been solved.\u201d Often, the true problem is \nreached in two or three cycles, but the tech-\nnique is called 5-whys to incentivize engineers \nto push it as far as possible. 3.2. Economics of Quality of Service Constraints \n\b\n[3*]\nQuality of service constraints can be partic-\nularly challenging. This is generally because \nengineers do not consider them from an eco-\nnomic perspective [9, c4]. Figure 1.4 illus-\ntrates the economic perspective of a typical \nquality of service constraint, such as capacity, \nthroughput and reliability, where value \nincreases with performance level. This curve is \nmirrored vertically for quality of service con-\nstraints whose value decreases as performance \nlevel increases (response time and mean time \nto repair would be examples). Over the relevant range of performance \nlevels, the stakeholders have a corresponding \nvalue if the system performs at that level. The \nvalue curve has two important points:", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 50", "position": 50, "chunk_type": "semantic", "token_estimate": 166}
{"text": "SOFTWARE REQUIREMENTS   1-9: 1. Perfection point \u2014 This is the most \nfavorable level of performance, beyond \nwhich there is no additional benefit. Even \nif the system can perform better than the \nperfection point, the customer cannot use \nthat capacity. For example, a social media \nsystem that supports more members than \nthe world population would have this \nexcess capacity. 2. Fail point \u2014 This is the least favorable \nlevel of performance, beyond which there \nis no further reduction in benefit. For \nexample, the social media system might \nneed to support at least a minimum \nmarket share to be viable as a platform. A quantified requirement point, even if \nstated explicitly, is usually arbitrary. It is \noften based on what a client feels justified \nrequesting, given what they are paying for \nthe software. Even if the software engineers \ncannot construct a system that fully achieves \nthe stated requirement point, the software \ntypically still has value; it just has less value \nthan the client expected. Further, the ability \nto exceed the requirement point can signifi-\ncantly increase value in some cases. The cost to achieve a given performance \nlevel is usually a step function. First, for a \ngiven investment level, there is some max-\nimum achievable performance level. Then, \nadditional investment is needed, and that \nfurther investment enables performance up \nto a new, more favorable maximum. Figure \n1.5 illustrates the most cost-effective perfor-\nmance level \u2014 the performance level with \nthe maximum positive difference between the \nvalue at that performance level and the cost to \nachieve it. (See the Software Engineering Economics \nKA or [3*] for more information on per-\nforming economic analyses such as this.) The software engineer should pay particular \nattention to positive and negative relation-\nships between quality of service constraints \n(e.g., Figure 14-1 in [1*, c14]). Some quality of \nservice constraints are mutually supporting; \nimproving one\u2019s performance level will auto-\nmatically improve the other\u2019s performance \nlevel. For example, the more modifiable code \nis, the more reliable it tends to be, as both \nmodifiability and reliability are, to a degree, \na consequence of how clean the code is. On \nthe other hand, the higher the code\u2019s speed, \nthe less modifiable it might be, because high \nspeed is often achieved through optimizations \nthat make the code more complex. 3.3. Formal Analysis  \n\b\n[2*, s12.3.2-12.3.3]\nFormal analysis has shown benefits in some \napplication domains, particularly high-integ-\nrity systems (e.g., [5, c6]).", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 51", "position": 51, "chunk_type": "semantic", "token_estimate": 399}
{"text": "SOFTWARE REQUIREMENTS   1-9: 3.3. Formal Analysis  \n\b\n[2*, s12.3.2-12.3.3]\nFormal analysis has shown benefits in some \napplication domains, particularly high-integ-\nrity systems (e.g., [5, c6]). The formal expres-\nsion of requirements depends on the use of a \nspecification language with formally defined \nsemantics. Formality has two benefits. First, \nformal requirements are precise and concise, \nValue\nLevel of Performance\nFail\nPerfection\nFigure 1.4. Value as a Function of Level of \nPerformance\n$\nValue\nCost to\ndeliver\nMost cost-e\ufb00ective\nlevel of performance\nLevel of performance\nFigure 1.5. Most Cost-Effective Level of \nPerformance", "domains": ["Software Quality Attributes", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 51", "position": 51, "chunk_type": "semantic", "token_estimate": 90}
{"text": "1-10   SWEBOK \u00ae GUIDE V4.0: which (in principle) will reduce the possibility \nfor misinterpretation. Second, formal require-\nments can be reasoned over, permitting \ndesired properties of the specified software to \nbe proved. This permits static validation that \nthe software specified by the requirements \ndoes have the properties (e.g., absence of \ndeadlock) that the customer, users and soft-\nware engineer expect it to have. This topic is related to Formal Methods \nin the Software Engineering Models and \nMethods KA. 3.4. Addressing Conflict in Requirements\nWhen a project has more \u2014 and more diverse \n\u2014 stakeholders, conflicts among the require-\nments are more likely. One particularly \nimportant aspect of requirements analysis \nis identifying and managing such conflicts \n(e.g., [6, c17]). Once conflicting requirements \nhave been identified, the engineer may con-\nsider two different approaches to managing \nthat conflict (and possibly other approaches \nas well) and determine the most appropriate \ncourse of action. One approach is to negotiate a resolution \namong the conflicting stakeholders. In most \ncases, it is unwise for the software engineer \nto make a unilateral decision, so it becomes \nnecessary to consult with the stakeholders to \nreach a consensus resolution. It is often also \nimportant, for contractual reasons, that such \ndecisions be traceable back to the customer. A \nspecific example is project scope management \u2014 \nnamely, balancing what\u2019s desired in the stated \nsoftware product requirements with what can \nbe accomplished given the project require-\nments of cost, schedule, staffing and other \nproject-level constraints. There are many \nuseful sources for information on negotiation \nand conflict resolution [25]. Another approach is to apply product family \ndevelopment (e.g., [20]). This involves sepa-\nrating requirements into two categories. The \nfirst category contains the invariant require-\nments. These are requirements that all stake-\nholders agree on. The second category contains \nthe variant requirements, where conflict exists. The software engineer can focus on under-\nstanding the range of variations needed to \nsatisfy all stakeholders. The software can be \ndesigned using design to invariants to accom-\nmodate the invariant requirements and design \nfor change to incorporate customization points \nto configure an instance of the system to best \nfit relevant stakeholders. In a simple example, \nsome users of a weather application require \ntemperatures displayed in degrees Celsius \nwhile others require degrees Fahrenheit. 4. Requirements Specification  \n\b\n[1*, c10-14, c20-26] [2*, s4.4, c5]\nRequirements specification concerns recording \nthe requirements so they can be both remem-\nbered and communicated.", "domains": ["Design Patterns", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 52", "position": 52, "chunk_type": "semantic", "token_estimate": 399}
{"text": "1-10   SWEBOK \u00ae GUIDE V4.0: 4. Requirements Specification  \n\b\n[1*, c10-14, c20-26] [2*, s4.4, c5]\nRequirements specification concerns recording \nthe requirements so they can be both remem-\nbered and communicated. Requirements \nspecification might be the most contentious \ntopic in this KA. Debate centers on ques-\ntions such as:\n\u2022\t should \nrequirements \nbe \nwritten \ndown at all? \u2022\t if requirements are written down, what \nform should they take? \u2022\t if requirements are written down, should \nthey also be maintained over time? There are no standard answers to these \nquestions; the answer to each can depend on \nfactors such as the following:\n\u2022\t the software engineer\u2019s familiarity with \nthe business domain;\n\u2022\t precedent for this kind of software;\n\u2022\t degree of risk (e.g., probability, severity) \nof incorrect requirements;\n\u2022\t staff turnover anticipated during the ser-\nvice life of the software;\n\u2022\t geographic distribution of the develop-\nment team members;\n\u2022\t stakeholder involvement over the course \nof the project;\n\u2022\t whether the use of a third-party service, \npackaged solution or open source library \nis anticipated;\n\u2022\t whether any design or construction will \nbe outsourced;", "domains": ["Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 52", "position": 52, "chunk_type": "semantic", "token_estimate": 181}
{"text": "SOFTWARE REQUIREMENTS   1-11: \u2022\t the \ndegree \nof \nrequirements-based \ntesting expected;\n\u2022\t effort needed to use a candidate specifica-\ntion technique;\n\u2022\t accuracy needed from the require-\nments-based estimates;\n\u2022\t extent of requirements tracing neces-\nsary, if any;\n\u2022\t contractual impositions of requirements \nspecification content and format. As stated in this KA\u2019s introduction, the \nwhats and hows of software requirements \nwork on a project should be determined by \nthe nature of the software constructed, not \nby the life cycle under which it is constructed. Downstream maintainers should not be able \nto discern the life cycle used in earlier devel-\nopment from the form of those requirements \nalone. The chosen life cycle\u2019s effect should be \nlimited to the completeness of the require-\nments at any point in the project. Under a \nwaterfall life cycle, the requirements are \nexpected to be completely specified at the end \nof the Requirements phase. Under an Agile \nlife cycle, the requirements are expected to \nchange, grow, or be eliminated continuously \nand not be complete until the project\u2019s end. Some organizations have a culture of docu-\nmenting requirements; some do not. Dynamic \nstartup projects are often driven by a strong \nproduct vision and limited resources; their \nteams might view requirements documen-\ntation as unnecessary overhead. But as these \nproducts evolve and mature, software engi-\nneers often recognize that they need to recover \nthe requirements that motivated product fea-\ntures in order to assess the impact of proposed \nchanges. Hence, requirements documentation \nand change management become important \nto long-term success. A project\u2019s approach to \nrequirements in general, and to requirements \nspecification in particular, may evolve over \nthe service life of that software. The most basic recommendation for \nrequirements documentation is to base deci-\nsions on an audience analysis. Who are the \ndifferent consumers who will need informa-\ntion from a requirements specification? What \ninformation will they need? How can that \ninformation be packaged and presented so \nthat each consumer can get the information \nthey need with the least effort? There is a degree of overlap and dependency \nbetween requirements analysis and specifica-\ntion. Use of certain requirements specifica-\ntion techniques \u2014 particularly model-based \nrequirements specifications \u2014 permit and \nencourage requirements analysis that can go \nbeyond what has already been presented. Documented software requirements should \nbe subject to the same configuration man-\nagement practices as the other deliverables \nof the software life cycle processes. (See the \nConfiguration Management KA for a detailed \ndiscussion.)", "domains": ["Design Patterns", "Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 53", "position": 53, "chunk_type": "semantic", "token_estimate": 403}
{"text": "SOFTWARE REQUIREMENTS   1-11: Documented software requirements should \nbe subject to the same configuration man-\nagement practices as the other deliverables \nof the software life cycle processes. (See the \nConfiguration Management KA for a detailed \ndiscussion.) In addition, when practical, the \nindividual requirements are also subject to \nconfiguration management and traceability, \nwhich is generally supported by a requirements \nmanagement tool. (See Topic 8, Software \nRequirements Tools.) There are several general categories of \nrequirements specification techniques, each \nof which is discussed below. The requirements \nspecification for a given project may also use \nvarious techniques. ISO/IEC/IEEE 29148 \n[26], as well as [1*, c10-14], [5, c4], [6, c16], \nand many others offer templates for require-\nments documentation. 4.1. Unstructured Natural Language \nRequirements Specification \n \b\n[1*, c11] [2*, s4.4.1]\nNatural language requirements specifications \nexpress requirements in common, ordinary lan-\nguage. Natural language requirements specifi-\ncations can be unstructured or structured. A typical unstructured natural language \nrequirements specification is a collection of \nstatements in natural language, such as, \u201cThe \nsystem shall . . . .\u201d For example, business rules \nare statements that define or constrain some \naspect of the structure or the behavior of the \nbusiness to be automated. \u201cA student cannot \nregister in next semester\u2019s courses if there \nremain any unpaid tuition fees\u201d is an example \nof a business rule that serves as a requirement", "domains": ["Design Patterns", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 53", "position": 53, "chunk_type": "semantic", "token_estimate": 220}
{"text": "1-12   SWEBOK \u00ae GUIDE V4.0: for a university\u2019s course-registration software. Some projects can publish a user manual as \na satisfactory requirements specification, \nalthough there are limits to how effective this \ncan be. (See also [5, c4] [26].) 4.2. Structured Natural Language Requirements \nSpecification \b\n[1*, c8] [2*, s4.4.2]\nStructured natural language requirements \nspecifications impose constraints on how the \nrequirements are expressed; the goal is to \nincrease precision and conciseness. The simplest example might be the \nactor-action format. The actor is the entity \nresponsible for carrying out the action, and \naction is what needs to happen. A trig-\ngering event might precede the actor, and \nthe action might be followed by an optional \ncondition or qualification. The statement \n\u201cWhen an order is shipped, the system shall \ncreate an Invoice unless the Order Terms \nare \u2018Prepaid\u2019\u201d uses actor-action format. The triggering event is \u201cWhen an order is \nshipped.\u201d The actor is \u201cthe system.\u201d The \naction is \u201ccreate an Invoice.\u201d The condition/\nqualification is \u201cexcept the Order Terms are \n\u2018Prepaid\u2019.\u201d \nAnother example is a use case specifica-\ntion template, as shown in Figure 1.6. (See \n[11] for guidelines on writing good use case \nspecifications.) The user story format, \u201cAs a <user> I want \n<capability> so that <benefit>\u201d as well as deci-\nsion tables are other examples. (See also [5, \nc4] [6, c12, c16] [7, c2-5].) 4.3. Acceptance Criteria-Based Requirements \nSpecification\nThis general approach includes two specific \nvariants: acceptance test driven  develop-\nment (ATDD) and behavior driven develop-\nment (BDD). ATDD [2*, s3.2.3, s8.2] is a part of the \nlarger test  driven development (TDD) \napproach. (See the Software Testing KA.). The main idea of TDD is that test cases pre-\ncede construction. Therefore, no new produc-\ntion code is written and no existing code is \nmodified unless at least one test case fails, \neither at the unit test level or at the acceptance \ntest level. The ATDD process has three steps:\n1. A unit of functionality (e.g., a user story) \nis selected for implementation. 2.", "domains": ["Design Patterns", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 54", "position": 54, "chunk_type": "semantic", "token_estimate": 331}
{"text": "1-12   SWEBOK \u00ae GUIDE V4.0: A unit of functionality (e.g., a user story) \nis selected for implementation. 2. One or more software engineers, one or \nmore business domain experts, and pos-\nsibly one or more QA/test professionals \nmeet \u2014 before any production design or \nUse case #66  \nUse case name: Reserve \ufb02ight(s)\nTriggering event(s)  \nCustomer requests reservation(s) on \ufb02ight(s)\nParameters  \nPassenger, itinerary, fare class, payment method(s)\nRequires  \nLegal itinerary, fare class restrictions met\nGuarantees  \nSeat(s) reserved for passenger on itinerary \ufb02ight(s)\nNormal course  \nNon-FF passenger, all domestic itinerary, Economy fare class, credit/debit card\nAlternative course(s)  \nIs FF passenger: [None, Silver, Gold, Platinum, Elite]\n \nItinerary: [all international, mixed domestic + international] \n \nFare class: [Basic economy, Premium Economy, Business, First] \n \nPayment method: [Voucher, FF miles]\nExceptions  \nC/D card declined, voucher doesn\u2019t exist, voucher expired, FF account doesn\u2019t exist,\n \ninsu\ufb03cient miles in FF account\nFigure 1.6. Example of Structured Natural Language Specification for a Single Use Case", "domains": ["Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 54", "position": 54, "chunk_type": "semantic", "token_estimate": 154}
{"text": "SOFTWARE REQUIREMENTS   1-13: Technically, one \nacceptance test case can encompass more \nthan one single requirement, but the gen-\neral idea holds that the ATDD test cases are \nessentially precise, unambiguous statements \nof requirements. The BDD approach [19] is slightly more \nstructured, and business domain experts typ-\nically prefer it over ATDD because it is less \ntechnical in appearance. In BDD, the unit \nof functionality is described as a user story, \nin a form such as this: \u201cAs a <user> I want \n<capability> so that <benefit>.\u201d This leads to \nthe identification and specification of a set of \n\u201cscenarios\u201d in this form: \u201cGiven <some con-\ntext> [and <possibly more context>], when \n<stimulus> then <outcome> [and <possibly \nmore outcomes>].\u201d\nIf the story is \u201cAs a bank customer, I want \nto withdraw cash from the automated teller \nmachine (ATM) so that I can get money \nwithout going to the bank,\u201d one scenario could \nbe that \u201cthe account has a sufficient balance.\u201d \nThis scenario could be detailed as \u201cGiven the \naccount balance is $500, and the customer\u2019s \nbank card is valid, and the automated teller \nmachine contains enough money in its cash \nbox, when the Account Holder requests $100, \nthen the ATM should dispense $100 and the \naccount balance should be $400, and the cus-\ntomer\u2019s bank card should be returned.\u201d\nAnother scenario could be that \u201cthe \naccount has an insufficient balance\u201d and \ncould be detailed as \u201cGiven the account bal-\nance is $50, and the customer\u2019s bank card is \nvalid, and the automated teller machine con-\ntains enough money in its cash box, when \nthe Account Holder requests $100, then the \nATM should not dispense any money, and the \nATM should say there is an insufficient bal-\nance, the balance should remain at $50, and \nthe customer\u2019s bank card should be returned.\u201d\nThe goal of BDD is to have a comprehensive \nset of scenarios for each unit of functionality. In the withdrawing cash situation, additional \nscenarios for \u201cThe Bank Customer\u2019s bank card \nhas been disabled\u201d and \u201cThe ATM does not \ncontain enough money in its cash box\u201d would \nbe necessary. The acceptance test cases are obvious from \nthe BDD scenarios. Acceptance criteria-based requirements \nspecification directly addresses the require-\nments ambiguity problem. Natural languages \nare inherently ambiguous, but test case lan-\nguage is not. In acceptance-based criteria \nrequirements specification, the requirements \nare written using test case language, which is \nvery precise.", "domains": ["Design Patterns", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 55", "position": 55, "chunk_type": "semantic", "token_estimate": 396}
{"text": "SOFTWARE REQUIREMENTS   1-13: Natural languages \nare inherently ambiguous, but test case lan-\nguage is not. In acceptance-based criteria \nrequirements specification, the requirements \nare written using test case language, which is \nvery precise. On the other hand, this does not \ninherently solve the incompleteness problem. However, combining ATDD or BDD with \nappropriate functional test coverage cri-\nteria, such as Domain Testing, Boundary \nValue Analysis and Pairwise Testing (see \nthe Software Testing KA), can reduce the", "domains": ["Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 55", "position": 55, "chunk_type": "semantic", "token_estimate": 74}
{"text": "1-14   SWEBOK \u00ae GUIDE V4.0: likelihood of requirements incompleteness. (See also [9, c1, c12].) 4.4. Model-Based Requirements Specification  \n\b\n[1*, c12] [2*, c5] [4*]\nAnother approach to avoiding the inherent \nambiguity of natural languages is to use mod-\neling languages such as selected elements of \nthe unified modeling language\u2122 (UML) or \nsystems modeling language\u2122 (SysML). Much \nlike the blueprints used in building construc-\ntion, these modeling languages can be used \nin a computing technology-free manner to \nprecisely and concisely specify functional \nrequirements [9, c1-2]. This topic is closely \nrelated to the Software Engineering Models \nand Methods KA. Requirements models fall \ninto two general categories:\n1. Structural models for specifying poli-\ncies to be enforced: These are logical class \nmodels as described in, for example, [9, \nc8]. They are also called conceptual data \nmodels, logical data models and enti-\nty-relationship diagrams. 2. Behavioral models for specifying pro-\ncesses to be carried out: These models \ninclude use case modeling as described in \n[9, c7], interaction diagrams as described \nin [9, c9] and state modeling as described \nin [9, c10]. Other examples are UML \nactivity diagrams and data-flow mod-\neling, as described in [1*, c12-13], [8], \n[10] and [18]. Model-based \nrequirements \nspecifica-\ntions vary in the degree of model formality. Consider the following: \n1. Agile modeling (see, for example, [10]) \nis the least formal. Agile models can be \nlittle more than rough sketches whose \ngoal is to communicate important infor-\nmation rather than demonstrate proper \nuse of modeling notations. In this type \nof modeling, the effect of the communi-\ncation is considered more important than \nthe form of the communication. 2. Semiformal modeling, for example [9, \nc6-12], provides a definition of the mod-\neling language semantics ([9, Appendix \nL]), but that definition has not been \nformally proved to be complete and \nconsistent. 3. Formal modeling, for example, Z, the \nVienna development method (VDM), \nspecification and description language \n(SDL) and [5, c7] have very precisely \ndefined semantics that allow specifica-\ntions to be mechanically analyzed for the \npresence or absence of specific properties \nto help avoid critical reasoning errors. The term correctness by construction has \nbeen used for development in this con-\ntext. (See the Formal Methods section in \nthe Software Engineering Models and \nMethods KA.) Generally, the more formal a requirements \nmodel is, the less ambiguous it is, so soft-\nware engineers are less likely to misinterpret \nthe requirements.", "domains": ["Design Patterns", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 56", "position": 56, "chunk_type": "semantic", "token_estimate": 396}
{"text": "SOFTWARE REQUIREMENTS   1-15: interpret and manage the requirements [6, \nc16]. Possible additional attributes include \nthe following:\n\u2022\t tag to support requirements tracing;\n\u2022\t description (additional details about the \nrequirement);\n\u2022\t rationale \n(why \nthe \nrequirement \nis \nimportant);\n\u2022\t source (role or name of the stakeholder \nwho imposed this requirement);\n\u2022\t use case or relevant triggering event;\n\u2022\t type (classification or category of the \nrequirement \u2014 e.g., functional, quality \nof service);\n\u2022\t dependencies;\n\u2022\t conflicts;\n\u2022\t acceptance criteria;\n\u2022\t priority (see Requirements Prioritization \nlater in this KA);\n\u2022\t stability (see Requirements Stability and \nVolatility later in this KA);\n\u2022\t whether the requirement is common or a \nvariant for product family development \n(e.g., [20]);\n\u2022\t supporting materials;\n\u2022\t the requirement\u2019s change history. Gilb\u2019s Planguage (short for Planning \nLanguage) [7] recommends attributes such as \nscale, meter, minimum, target, outstanding, \npast, trend and record. 4.6. Incremental and Comprehensive \nRequirements Specification\nProjects that explicitly document require-\nments take one of two approaches. One can \nbe called incremental specification. In this \napproach, a version of the requirements speci-\nfication contains only the differences \u2014 addi-\ntions, modifications and deletions \u2014 from \nthe previous version. An advantage of this \napproach is that it can produce a smaller \nvolume of written specifications. The other approach can be called compre-\nhensive specification. In this approach, each \nversion\u2019s requirements specification con-\ntains all requirements, not just changes from \nthe previous version. An advantage of this \napproach is that a reader can understand all \nrequirements in a single document instead of \nhaving to keep track of cumulative additions, \nmodifications and deletions across a series of \nspecifications. Some organizations combine these two \napproaches, producing intermediate releases \n(e.g., x.1, x.2 and x.3) that are specified incre-\nmentally and major releases (e.g., 1.0, 2.0 and \n3.0) that are specified comprehensively. The \nreader never needs to go any further back \nthan the requirements specifications for the \nlast major release to obtain the complete set \nof specifications. 5. Requirements Validation  \n\b\n[1*, c17] [2*, s4.5]\nRequirements validation concerns gaining \nconfidence that the requirements represent \nthe stakeholders\u2019 true needs as they are cur-\nrently understood (and possibly documented). Key questions include the following:\n\u2022\t do these represent all requirements rele-\nvant at this time? \u2022\t are any stated requirements not represen-\ntative of stakeholder needs? \u2022\t are \nthese \nrequirements \nappropri-\nately stated? \u2022\t are the requirements understandable, \nconsistent and complete? \u2022\t does the requirements documentation \nconform to relevant standards?", "domains": ["Design Patterns", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 57", "position": 57, "chunk_type": "semantic", "token_estimate": 401}
{"text": "1-16   SWEBOK \u00ae GUIDE V4.0: practice. Review from multiple perspectives \nis preferred:\n\u2022\t clients, customers and users check that \ntheir wants and needs are completely and \naccurately represented;\n\u2022\t other software engineers with expertise \nin requirements specification check that \nthe document is clear and conforms to \napplicable standards;\n\u2022\t software engineers who will do architec-\nture, design or construction of the soft-\nware that satisfies these requirements \ncheck that the document is sufficient to \nsupport their work. Providing checklists, quality criteria or \na \u201cdefinition of done\u201d to the reviewers can \nguide them to focus on specific aspects of the \nrequirements specification. (See Reviews and \nAudits in the Software Quality KA.) 5.2. Simulation and Execution\nNontechnical stakeholders might not want to \nspend time reviewing a specification in detail. Some specifications can be subjected to sim-\nulation or actual execution in place of or in \naddition to human review. To the extent that \nthe requirements are formally specified (e.g., \nin a model-based specification), software \nengineers can hand interpret that specifica-\ntion and \u201cexecute\u201d the specification. Given \na sufficient set of demonstration scenarios, \nstakeholders can be convinced that the spec-\nification defines their policies and processes \ncompletely and accurately. (See [9, c12].) 5.3. Prototyping  \n\b\n[1*, c17p342] [2*, c4p130]\nIf the requirements specification is not in \na form that allows direct simulation or exe-\ncution, an alternative is to have a software \nengineer build a prototype that concretely \ndemonstrates some important dimension of \nan implementation. This demonstrates the \nsoftware engineer\u2019s interpretation of those \nrequirements. Prototypes can help expose software engi-\nneers\u2019 assumptions and, where needed, give \nuseful feedback on why they are wrong. For \nexample, a user interface\u2019s dynamic behavior \nmight be better understood through an ani-\nmated prototype than through textual \ndescription or graphical models. However, a \ndanger of prototyping is that cosmetic issues \nor quality problems with the prototype can \ndistract the reviewers\u2019 attention from the core \nunderlying functionality. Prototypes can also \nbe costly to develop. However, if a prototype \nhelps engineers avoid the waste caused by \ntrying to satisfy erroneous requirements, its \ncost can be more easily justified. 6. Requirements Management Activities \n\b\n[1*, c27-28] [2*, s4.6]\nRequirements development, as a whole, can be \nthought of as \u201creaching an agreement on what \nsoftware is to be constructed.\u201d (See Figure \n1.3.) In contrast, requirements management \ncan be thought of as \u201cmaintaining that agree-\nment over time.\u201d This topic examines require-\nments management. (See also [5, c9].)", "domains": ["Design Patterns", "Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 58", "position": 58, "chunk_type": "semantic", "token_estimate": 405}
{"text": "SOFTWARE REQUIREMENTS   1-19: (See also [9, c4].) 7.5. Measuring Requirements \n \b\n[1*, c19]\nAs a practical matter, it may be useful to have \nsome concept of the volume of the require-\nments for a particular software product. This number is useful in evaluating the size \nof a new development project or the size of \na change in requirements and in estimating \nthe cost of development or maintenance tasks \n(e.g., [9, c23]), or simply for use as the denom-\ninator in other measurements. Functional size \nmeasurement (FSM) is a technique for evalu-\nating the size of a body of functional require-\nments. Story points can also be considered a \nmeasure of requirements size. Additional information on size measure-\nment and standards can be found in the \nSoftware Engineering Process KA. Many quality indicators have been devel-\noped that can be used to relate the quality of \nsoftware requirements specification to other \nproject variables such as cost, acceptance, \nperformance, schedule and reproducibility. Quality indicators for individual software \nrequirements and a requirements specifica-\ntion document as a whole can be derived from \nthe desirable properties discussed in Section \n3.1, Basic Requirements Analysis, earlier \nin this KA. 7.6. Requirements Process Quality and \nImprovement \b\n[1*, c31]\nThis topic concerns assessing the quality and \nimprovement of the requirements process. Its \npurpose is to emphasize the key role of the", "domains": ["Software Quality Attributes", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 61", "position": 61, "chunk_type": "semantic", "token_estimate": 224}
{"text": "1-20   SWEBOK \u00ae GUIDE V4.0: requirements process in a software product\u2019s \ncost and timeliness and in customer satisfac-\ntion. Furthermore, it helps align the require-\nments process with quality standards and \nprocess improvement models for software and \nsystems. Process quality and improvement are \nclosely related to both the Software Quality \nKA and Software Engineering Process KA, \ncomprising the following:\n\u2022\t requirements process coverage by process \nimprovement standards and models;\n\u2022\t requirements \nprocess \nmeasures \nand \nbenchmarking;\n\u2022\t improvement \nplanning \nand \nimplementation;\n\u2022\t security/CIA (confidentiality, integrity, \nand availability) improvement/planning \nand implementation. 8. Software Requirements Tools [1*, c30]\nTools that help software engineers deal with \nsoftware requirements fall broadly into three \ncategories: requirements management tools, \nrequirements modeling tools and functional \ntest case generation tools, as discussed below. 8.1. Requirements Management Tools  \n\b\n[1*, c30pp506-510]\nRequirements management tools support var-\nious activities, including storing requirements \nattributes, tracing, document generation and \nchange control. Indeed, tracing and change \ncontrol might only be practical when sup-\nported by a tool. Because requirements man-\nagement is fundamental to good requirements \npractice, many organizations have invested \nin tools. However, many more manage their \nrequirements in more ad hoc and generally \nless satisfactory ways (e.g., spreadsheets). (See \nalso [5, c8].) 8.2. Requirements Modeling Tools  \n\b\n[1*, c30p506] [2*, s12.3.3]\nAt a minimum, a requirements modeling tools \nsupport visually creating, modifying and \npublishing model-based requirements speci-\nfications. Some tools extend that by also pro-\nviding static analysis (e.g., syntax correctness, \ncompleteness and consistency). Formal anal-\nysis requires tool support to be practicable for \nanything other than trivial systems, and tools \ngenerally fall into two categories: theorem \nprovers or model checkers. In neither case \ncan proof be fully automated, and the com-\npetence in formal reasoning needed to use the \ntools restricts the wider formal analysis. Some \ntools also dynamically execute a specification \n(simulation). 8.3. Functional Test Case Generation Tools\nThe more formally defined a requirements \nspecification language is, the more likely it \nis that functional test cases can be at least \npartially derived mechanically. For example, \nconverting BDD scenarios into test cases is \nnot difficult. Another example involves state \nmodels. Positive test cases can be derived \nfor each defined transition in that kind of \nmodel. Negative test cases can be derived \nfrom the state and event combinations that \ndo not appear. (See Section 8.2, Testing \nTools in the Testing KA, for more informa-\ntion.)", "domains": ["Design Patterns", "Software Quality Attributes", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 62", "position": 62, "chunk_type": "semantic", "token_estimate": 393}
{"text": "1-20   SWEBOK \u00ae GUIDE V4.0: Negative test cases can be derived \nfrom the state and event combinations that \ndo not appear. (See Section 8.2, Testing \nTools in the Testing KA, for more informa-\ntion.) A process for deriving test cases from \nUML requirements models can be found \nin [9, c12]. In the most general case, such tools can \nonly generate test case inputs. Determining \nan expected result is not always possible, \nadditional business domain expertise might \nbe necessary.", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 62", "position": 62, "chunk_type": "semantic", "token_estimate": 78}
{"text": "SOFTWARE REQUIREMENTS   1-21: MATRIX OF TOPICS VS. REFERENCE MATERIAL\nWiegers  \n2013\n[1*]\nSommerville  \n2018  \n[2*]\nTockey  \n2005 \n[3*\nWing  \n1990  \n[4*]\n1. Software Requirements Fundamentals\n1.1. Definition of a Software Requirement\nc1pp5-6\nc4p102\n1.2. Categories of Software Requirements\nc1pp7-12\ns4.1\n1.3. Software Product Requirements and \nSoftware Project Requirements\nc1pp14-15\n1.4. Functional Requirements\nc1p9\ns4.1.1\n1.5. Nonfunctional Requirements\nc1pp10-11\ns4.1.2\n1.6. Technology Constraints\n1.7. Quality of Service Constraints\n1.8. Why Categorize Requirements This Way? 1.9. System Requirements and Software \nRequirements\n1.10. Derived Requirements\n1.11. Software Requirements Activities\nc1pp15-18\ns4.2\n2. Requirements Elicitation\n2.1. Requirements Sources\nc6\ns4.3\n2.2. Common Requirements Elicitation \nTechniques\nc7\ns4.3\n3. Requirements Analysis\n3.1. Basic Requirements Analysis\nc8-9\n3.2. Economics of Quality of Service \nConstraints\nc1-27\n3.3. Formal Analysis\ns12.3.2-12.3.3\n3.4. Addressing Conflict in Requirements\n4. Requirements Specification\n4.1. Unstructured Natural Language \nRequirements Specification\nc11\ns4.4.1\n4.2. Structured Natural Language \nRequirements Specification\nc8\ns4.4.2\n4.3. Acceptance Criteria-Based Requirements \nSpecification\ns3.2.3, s8.2\n4.4. Model-Based Requirements Specification\nc12\nc5\npp8-11\n4.5. Additional Attributes of Requirements\nc27pp462-463\n4.6. Incremental and Comprehensive \nRequirements Specification\n5. Requirements Validation\n5.1. Requirements Reviews\nc17pp332-342\nc4p130\n5.2. Simulation and Execution\n5.3. Prototyping\nc17p342\nc4p130", "domains": ["Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 63", "position": 63, "chunk_type": "semantic", "token_estimate": 189}
{"text": "Section: Application Programming Interface", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 67", "position": 67, "chunk_type": "semantic", "token_estimate": 4}
{"text": "Section: Interface Description Language", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 67", "position": 67, "chunk_type": "semantic", "token_estimate": 4}
{"text": "Section: Representational State Transfer", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 67", "position": 67, "chunk_type": "semantic", "token_estimate": 4}
{"text": "The breakdown of topics for the Software: Architecture KA is shown in Figure 2.1. 1. Software Architecture Fundamentals \n\b\n[2*c1-2, 38*c2, 41*c1-3, 29*, 34]\n1.1. The Senses of \u201cArchitecture\u201d\b\n[2*c1, 29*]\nSoftware engineering and related disciplines \nuse many senses of \u201carchitecture\u201d. First, \n\u201carchitecture\u201d often refers to a discipline: the \nart and science of constructing things \u2014 in \nthis case, software-intensive systems. The dis-\ncipline involves concepts, principles, processes \nand methods the community has discovered \nand adopted. Second, \u201carchitecture\u201d refers to the various \nprocesses through which that discipline is \nrealized. Software architecture is also consid-\nered part of Software Design; generally con-\nsidered a multistage process, divided into the \nfollowing stages: \n\u2022\t  Architectural design stage \n\u2022\t  High-level design stage \n\u2022\t  Detailed design stage\nSoftware design is the focus of Chapter 3. This chapter focuses on architecting and archi-\ntectural design. Third, \u201carchitecture\u201d refers to the out-\ncome of applying architectural design disci-\npline and processes to devise architectures \nfor software systems. Architectures as out-\ncomes are expressed in architecture descrip-\ntions. This is discussed in topic Software \nArchitecture Description. The concept of \narchitecture has evolved, and many defi-\nnitions are in use today. One early defini-\ntion of architecture, from 1990, emphasized \nsoftware structure:\nArchitecture. The organizational struc-\nture of a system or component. [from: IEEE", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 67", "position": 67, "chunk_type": "semantic", "token_estimate": 215}
{"text": "2-2   SWEBOK \u00ae GUIDE V4.0: Std 610.12\u20131990, IEEE Glossary of Software \nEngineering Terminology] \nThis definition did not do justice to evolving \nthinking about architecture; e.g., this definition \ndoes not allow us to distinguish the detailed \ndesign of a module from its Makefile. Either \nexample reflects an organizational structure of \nthe software system or component but should \nnot be considered architecture. Moreover, \nemphasis on the structure was often limited to \nthe code\u2019s structure and failed to encompass all \nthe structures of the software system:\nThe software architecture of a system is the \nset of structures needed to reason about the \nsystem. These structures comprise software ele-\nments, relations among them, and properties \nof both. [2*]\nDuring the mid-1990s, however, software \narchitecture emerged as a broader discipline \ninvolving a more generic study of software \nstructures and architectures. Many software \nsystem structures are not directly reflected \nin the code structure. Both types of struc-\nture have implications for the system as a \nwhole: What behaviors is the system capable \nof? What interactions does it have with other \nsystems? How are properties like safety and \nsecurity handled? The recognition that soft-\nware contains many different structures has \nprompted discussion of a number of inter-\nesting concepts about software architecture \n(and software design more generally) leading \nto current definitions such as: \narchitecture (of a system). fundamental con-\ncepts or properties of a system in its environ-\nment embodied in its elements, relationships, \nand in the principles of its design and evo-\nlution [23]\nKey ideas in that definition are the fol-\nlowing: (1)\u00a0 Architecture is about what is \nfundamental to a software system; not every \nelement, interconnection, or interface is con-\nsidered fundamental. (2)\u00a0 Architecture con-\nsiders a system in its environment. Much like \nbuilding architecture, software architec-\nture is outward-looking; it considers a sys-\ntem\u2019s context beyond its boundaries including \nthe people, organizations, software, hard-\nware and other devices with which the system \nmust interact. Software\nArchitecture\nTe Senses of\n\u201carchitecture\u201d\nArchitecture\nViews and \nViewpoints\nArchitecture\nin Context\nGoodness in\nArchitecture\nReasoning \nabout\nArchitectures\nArchitecture\nReviews\nArchitecture\nMetrics\nArchitectural\nDesign\nArchitecture\nMethods and \nTactics\nArchitecture\nin the Large\nArchitecture\nStyles and \nPatterns\nArchitecture\nDescription\nLanguages and\nArchitecture\nFramework\nArchitecture \nas Signifcant \nDecisions \nStakeholders \nand Concerns\nUses of \nArchitecture\nSoftware\nArchitecture\nDescription\nSoftware\nArchitecture\nFundamentals\nSoftware\nArchitecture\nProcess\nSoftware\nArchitecture\nEvaluation\nFigure 2.1. Breakdown of Topics for the Software Architecture KA", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 68", "position": 68, "chunk_type": "semantic", "token_estimate": 396}
{"text": "SOFTWARE ARCHITECTURE   2-3: 1.2. Stakeholders and Concerns \n\b\n[2*c3-14, 38*c8-9, 41*c3, 12, 23, 24]\nA software system has many stakeholders with \nvarying roles and interests relative to that \nsystem. These varying interests are termed con-\ncerns, following Dijkstra\u2019s separation of concerns: \nLet me try to explain to you, what to my taste \nis characteristic for all intelligent thinking. It is, that one is willing to study in depth an \naspect of one\u2019s subject matter in isolation for \nthe sake of its own consistency, all the time \nknowing that one is occupying oneself only \nwith one of the aspects. We know that a pro-\ngram must be correct and we can study it from \nthat viewpoint only; we also know that it \nshould be efficient and we can study its effi-\nciency on another day, so to speak. In another \nmood we may ask ourselves whether, and if so: \nwhy, the program is desirable. But nothing is \ngained \u2014 on the contrary! \u2014 by tackling these \nvarious aspects simultaneously. It is what I \nsometimes have called \u201cthe separation of con-\ncerns\u201d, which, even if not perfectly possible, is \nyet the only available technique for effective \nordering of one\u2019s thoughts, that I know of. This \nis what I mean by \u201c[focusing] one\u2019s attention \nupon some aspect\u201d: it does not mean ignoring \nthe other aspects, it is just doing justice to the \nfact that from this aspect\u2019s point of view, the \nother is irrelevant. It is being one- and multi-\nple-track-minded simultaneously. [12]\nWhat is fundamental about a system varies \naccording to stakeholders\u2019 concerns and roles. The software structures, therefore, also vary \nwith stakeholder roles and concerns. (See also \ntopic Design Methods in Software Design KA.) A software system\u2019s customer is most inter-\nested in when the system will be ready and \nhow much it will cost to build and operate. Users are most interested in what it does and \nhow to use it. Designers and programmers \nbuilding the system have their own concerns, \nsuch as whether an algorithm will meet the \nsystem requirements. Those responsible for \nensuring the system is safe to operate have dif-\nferent concerns. Concerns encompass a broad range of \nissues, possibly pertaining to any influence on \na system in its environment, including devel-\nopmental, technological, business, opera-\ntional, organizational, political, economic, \nlegal, regulatory, ecological and social influ-\nences. Like software requirements, they may \nbe classified as functional, non-functional \nor constraint.", "domains": ["Design Principles", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 69", "position": 69, "chunk_type": "semantic", "token_estimate": 402}
{"text": "SOFTWARE ARCHITECTURE   2-3: Concerns encompass a broad range of \nissues, possibly pertaining to any influence on \na system in its environment, including devel-\nopmental, technological, business, opera-\ntional, organizational, political, economic, \nlegal, regulatory, ecological and social influ-\nences. Like software requirements, they may \nbe classified as functional, non-functional \nor constraint. (See Software Requirements \nKA.) Concerns manifest in various familiar \nforms, including requirements, quality attri-\nbutes or \u201cilities\u201d, emergent properties (which \nmay be either desired or prohibited) and var-\nious kinds of constraints (as listed above). See Software Quality KA. Topic 2, Software \nArchitecture Description, shows how concerns \nshape architecture and the work products \ndescribing those architectures. Example \nof concerns are depicted in Figure 2.2. Concerns are not static; concerns evolve over \nthe life cycle of a system and as technolo-\ngies, policies and other influences evolve. For example, due to increased awareness of \nclimate change, there is growing interest in \nconcerns such as energy efficiency, and sus-\ntainability [24]. Figure 2.2. Examples of Architectural Concerns\naffordability, agility, assurance, autonomy, \navailability, behavior, business goals and \nstrategies, complexity, compliance with regu-\nlation, concurrency, control, cost, data acces-\nsibility, deployability, disposability, energy \nefficiency, evolvability, extensibility, feasi-\nbility, flexibility, functionality, information \nassurance, \ninter-process \ncommunication, \ninteroperability, known limitations, main-\ntainability, modifiability, modularity, open-\nness, performance, privacy, quality of service, \nreliability, resource utilization, reusability, \nsafety, scalability, schedule, security, system \nmodes, software structure, subsystem inte-\ngration, sustainability, system features, test-\nability, usability, usage, user experience", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 69", "position": 69, "chunk_type": "semantic", "token_estimate": 238}
{"text": "2-4   SWEBOK \u00ae GUIDE V4.0: 1.3. Uses of Architecture \n\b\n[2*c24, 38*c30, 23, 11, 28]\nA principal use of a software system\u2019s archi-\ntecture is to give those working with it a \nshared understanding of the system to guide \nits design and construction. An architec-\nture also serves as a preliminary conception \nof the software system that provides a basis \nto analyze and evaluate alternatives. A third \ncommon usage is to enable reverse engi-\nneering (or reverse architecting) by helping \nthose working with it to understand an \nexisting software system before undertaking \nmaintenance, enhancement or modification. To support these uses, the architecture should \nbe documented (see topic Software Architecture \nDescription). Conway\u2019s Law posits that \u201corganizations \nwhich design systems . . . are constrained to \nproduce designs which are copies of the com-\nmunication structures of these organiza-\ntions\u201d [11]. Empirical studies have observed \nthat the architectures of these systems often \nmirror the communications structures of \nthose organizations [28]. Depending on the \nsoftware system and the organization, this \ncan be a strength or a weakness. The archi-\ntecture can enhance communication within a \nlarge team or compromise it. Each part of the \norganization can base its planning, costing \nand scheduling activities upon its knowledge \nof the architecture. Creating a well-planned \nand documented architecture is one approach \nto increasing the applicability and reusability \nof software designs and components. The \narchitecture forms the basis for design fam-\nilies of programs or software product lines. This can be done by identifying commonali-\nties among members of such families and by \ndesigning reusable and customizable com-\nponents to account for the variability among \nfamily members. 2. Software Architecture Description \n\b\n[2*c22, 38*, 40*c6, 41*c6-7, 9,23,25]\nIn topic 1, Software Architecture Fundamentals, \na software architecture was defined as the \nfundamental concepts or properties of a soft-\nware system in its environment. But each \nstakeholder can have a different notion of \nwhat is fundamental to that software system, \ngiven their perspective. Having a mental \nmodel of a system\u2019s architecture is perhaps \nfine for small systems and for individuals \nworking alone. However, for large, complex \nsystems developed and operated by teams, a \ntangible representation is invaluable, espe-\ncially as the conception of the system evolves, \nand as people join or leave the team. Having a \nconcrete representation as a work product can \nalso serve as a basis to analyze the architec-\nture, organize its design and guide its imple-\nmentation.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 70", "position": 70, "chunk_type": "semantic", "token_estimate": 402}
{"text": "SOFTWARE ARCHITECTURE   2-5: 2.1. Architecture Views and Viewpoints \b\n[6*c7, 38*c3,c15-23, 40*c6.2, 23]\nAn architecture view represents one or more \naspects of an architecture to address one or \nmore concerns [38*]. Views address distinct \nconcerns \u2014 for example, a logical view (depicts \nhow the system will satisfy the functional \nrequirements); a process view (depicts how the \nsystem will use concurrency); a physical view \n(depicts how the system is to be deployed and \ndistributed) and a development view (depicts \nhow the top-level design is broken down \ninto implementation units, the dependencies \namong those units and how the implementa-\ntion is to be constructed). Separating concerns \nby view allows interested stakeholders to focus \non a few things at a time and offers a means of \nmanaging the architecture\u2019s understandability \nand overall complexity. Architecture practice has evolved from the \nuse of text and informal diagrams to the use \nof more rigorous representations. Each archi-\ntecture view depicts architectural elements of \nthe system using well-defined conventions, \nnotations and models [38*]. The conventions \nfor each view are documented as an architec-\nture viewpoint [23]. Viewpoints guide the cre-\nation, interpretation and uses of architecture \nviews. Each viewpoint links stakeholder audi-\nence concerns with a set of conventions. In \nmodel-based architecting, each view can be \nmachine-checked against its viewpoint. Common viewpoints include the module \nviewpoint, used to express a software system\u2019s \nimplementation in terms of its modules and \ntheir organization [2*]; the component and \nconnector viewpoint, used to express the soft-\nware\u2019s large-scale runtime organization and \ninteractions [2*]; the logical viewpoint, used \nto express fundamental concepts of the soft-\nware\u2019s domain and capability [25]; the sce-\nnarios/use cases viewpoint, used to express \nhow users interact with the system [25]; the \ninformation viewpoint, used to express a sys-\ntem\u2019s key information elements and how they \nare accessed and stored [38*]; and the deploy-\nment viewpoint, used to express how a system \nis configured and deployed for operation [38*]. Other documented viewpoints include view-\npoints for availability, behavior, communi-\ncations, exception handling, performance, \nreliability, safety and security. Each viewpoint provides a vocabulary or \nlanguage for talking about a set of concerns \nand the mechanisms for addressing them. The viewpoint language gives stakeholders \na shared means of expression. Viewpoints \nneed not be limited to one software system \nbut are reusable by an organization or appli-\ncation community for many similar systems.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 71", "position": 71, "chunk_type": "semantic", "token_estimate": 392}
{"text": "SOFTWARE ARCHITECTURE   2-5: The viewpoint language gives stakeholders \na shared means of expression. Viewpoints \nneed not be limited to one software system \nbut are reusable by an organization or appli-\ncation community for many similar systems. When generic representations such as Unified \nModeling Language (UML) are used, they \ncan be specialized to the system, its domain \nor the organizations involved. (See section \n2.3 Architecture Description Languages and \nArchitecture Frameworks.) Beyond specifying forms of representation, \nan architecture viewpoint can capture the \nways of working within a discipline or com-\nmunity of practice. For example, a software \nreliability viewpoint captures existing prac-\ntices from the software reliability community \nfor identifying and analyzing reliability issues, \nformulating alternatives and synthesizing \nand representing solutions. Like engineering \nhandbooks, general-purpose and special-\nized viewpoints provide a means to document \nrepeatable or reusable approaches to recurring \nsoftware issues. Clements et al. have intro-\nduced viewtypes which establish a 3-way cat-\negorization of viewpoints. These categories are \nmodule, component and connector, and allo-\ncation viewtypes [9]. Architecture descriptions frequently use \nmultiple architecture views to represent the \ndiverse structures needed to address different \nstakeholders\u2019 various concerns. There are two \ncommon approaches to the construction of \nviews: the synthetic approach and the projective \napproach. In the synthetic approach, architects \nconstruct views of the system-of-interest and \nintegrate these views within an architecture \ndescription using correspondence rules. In \nthe projective approach, an architect derives \neach view through some routine, possibly \nmechanical, procedure of extraction from a \nsingle unified model (or \u201cuber model\u201d) [23].", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 71", "position": 71, "chunk_type": "semantic", "token_estimate": 250}
{"text": "2-6   SWEBOK \u00ae GUIDE V4.0: A consequence of introducing multiple views \ninto an AD is a potential mismatch between \nthe views. Are they consistent? Are they \ndescribing the same system? This has been \ncalled the multiple views problem [39]. The \nprojective approach limits possible inconsis-\ntencies, since views are derived from a single \n(presumably consistent) model, but at the cost \nof expressiveness: the underlying model may \nnot be capable of capturing arbitrary concerns. Under the synthetic approach, architects inte-\ngrate views into a whole, using linkages or \nother forms of traceability to cross-refer-\nence view elements to achieve consistency \n[23,25]. Viewpoints often include rules for \nestablishing consistency or other relationships \namong views. 2.2. Architecture Patterns, Styles and Reference \nArchitectures\b\n[6*c6,38*c11, 40*c6.3, \n \n\b\n41*c11, 7, 9, 10c2, 13, 17, 18, 19, 37\nInspired by its use in the long history of the \narchitecture of buildings, an architectural style \nis a particular manner of construction yielding \na software system\u2019s characteristic features. An \narchitectural style often expresses a software \nsystem\u2019s large-scale organization. In contrast, \nan architectural pattern expresses a common \nsolution to a recurring problem within the \ncontext of a software system\u2014it need not \napply to the whole system. Design patterns \nare discussed in section 4.4 of Software \nDesign KA. Various architectural styles and patterns \nhave been documented [7,39]: \n\u2022\t General structures (e.g., layered, call-\nand-return, pipes and filters, blackboard, \nservices and microservices) \n\u2022\t Distributed systems (e.g., client-server, \nn-tier, \nbroker, \npublish-subscribe, \npoint-to- \npoint, representational state transfer \n \n(REST)) \n\u2022\t Method-driven (e.g., object-oriented, \nevent-driven, data flow)\n\u2022\t User-computer interaction (e.g., model- \nview-controller, presentation-abstraction- \ncontrol) \n\u2022\t Adaptive systems (e.g., microkernel, \nreflection and meta-level architectures) \n\u2022\t Virtual machines (e.g., interpreters, rule-\nbased, process control) \nPattern catalogs (or systems of patterns) are \nused to express architectural styles and solu-\ntions through coordinated sets of patterns. Examples of pattern catalogs are [7], [19] for \nn-tier architectures, [13] for service-oriented \narchitecture and [37] for microservice architec-\ntures. Pattern catalogs are not limited to archi-\ntecture styles and can be focused on addressing \nspecific concerns, such as security [17]. There is no strict dividing line between \narchitectural styles and patterns. Both pat-\nterns and styles provide solutions to specific \nproblems in given contexts. An architectural \nstyle expresses the global aspects of a system \nor subsystem by defining its  major parts of \nthat (sub)system and how they interact [7,38*]. An architectural style can be expressed as an \narchitectural pattern [7].", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 72", "position": 72, "chunk_type": "semantic", "token_estimate": 398}
{"text": "SOFTWARE ARCHITECTURE   2-7: promote ease of development, integration \nand interoperability and other kinds of stan-\ndardization. Reference architectures have \nbeen developed and used in many domains \nincluding automotive systems, healthcare, \nInternet of Things, cloud computing, avionics, \nmanufacturing and telecommunications. 2.3. Architecture Description Languages and \nArchitecture Frameworks\b\n[2*c22, \b\n41*c6-7, 23,30]\nAn architecture description language (ADL) \nis a domain-specific language for expressing \nsoftware architectures. ADLs arose from \nmodule interconnection languages [36] for \nprogramming in the large. Some ADLs target \na single application domain or architectural \nstyle (such as MetaH for avionics systems in \nan event-driven style), others are wide spec-\ntrum to frame concerns across the enterprise \n(such as ArchiMate\u2122). UML has frequently \nbeen used as an ADL due to its widespread \nuse in software design activities [41*]. ADLs \noften provide capabilities beyond descrip-\ntion to enable architecture analysis or code \ngeneration. An architecture framework captures the \n\u201cconventions, principles and practices for the \ndescription of architectures established within \na specific domain of application and/or com-\nmunity of stakeholders\u201d [23]. Frameworks \ncodify recommended practices within a spe-\ncific domain and are implemented as an inter-\nlocking set of viewpoints or ADLs. Examples \nare AUTOSAR for the automotive industry, \nOMG\u2019s Unified Architecture Framework \n(UAF\u00ae) and ISO Reference Model for Open \nDistributed Processing. 2.4. Architecture as Significant Decisions \b\n[38*c8, 40*c6.1, 1, 23, 26]\nArchitectural design is a creative process. During this activity, architects make many \ndecisions that profoundly affect the archi-\ntecture, the downstream development pro-\ncess and the software system. Many factors \naffect decision-making, including prominent \nconcerns of stakeholders for the software \nsystem, its requirements, and the available \nresources during development and throughout \nthe life cycle. The impact on quality attributes \nand trade-offs among competing quality attri-\nbutes are often the basis for design decisions. The architectural design activity creates \na network of decisions as its outcome, with \nsome decisions deriving from prior decisions. Decision analysis provides one approach to \narchitecture evaluation. Decisions can be \nexplicitly documented, along with an explana-\ntion of the rationale for each nontrivial deci-\nsion. Decision analysis provides one approach \nto architecture evaluation. (See topic 4, \nSoftware Architecture Evaluation.) Architecture rationale captures why an archi-\ntectural decision was made. This includes \nassumptions made before the decision, alter-\nnatives considered, and trade-offs or criteria \nused to select an approach and reject others. Recording rejected decisions and the rea-\nsons for their rejection can also be useful.", "domains": ["Architectural Patterns and Styles", "Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 73", "position": 73, "chunk_type": "semantic", "token_estimate": 398}
{"text": "SOFTWARE ARCHITECTURE   2-7: This includes \nassumptions made before the decision, alter-\nnatives considered, and trade-offs or criteria \nused to select an approach and reject others. Recording rejected decisions and the rea-\nsons for their rejection can also be useful. In \nthe future, this could either prevent a soft-\nware project from making a poor decision\u2014\none rejected earlier for forgotten reasons\u2014or \nallow the development to recognize that rel-\nevant conditions have changed and that they \ncan revisit the decision. Architectural technical debt has been intro-\nduced to reflect that today\u2019s decisions for \nan architecture may have significant con-\nsequences later in the software system\u2019s life \ncycle. Decisions deferred can compromise \nits maintainability or the future evolvability, \nand that debt will have to be paid\u2014typ-\nically by others, not necessarily by those \nwho caused the debt. Such debt has an eco-\nnomic impact on the system\u2019s future devel-\nopment and operations. For example, when \na software project has limited time, it may \ndevelop an initial design with little concern \nfor modularity for its first release. The lack \nof modularity can adversely affect the devel-\nopment time for subsequent releases, impact \ndevelopers, and perhaps compromise future \nmaintainability of the system. Additional \nfunctionality can be added later only by doing \nextensive refactoring which impacts future", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 73", "position": 73, "chunk_type": "semantic", "token_estimate": 212}
{"text": "SOFTWARE ARCHITECTURE   2-9: overarching architecture (of the enterprise, \nsystem or product line/family) provides pri-\nmary requirements and guidance on the form \nand constraints upon the software architec-\nture. This baseline can be enforced through \nspecifications, additional requirements, appli-\ncation programming interfaces (APIs) or con-\nformance suites. 3.1.1. Relation of Architecture to Design\nDesign and architecture are often blurred. It \nhas been said that architecture is the set of \ndecisions that one cannot trust to  designers. In fact, architecture emerged out of software \ndesign as the discipline matured, largely since \nthe 1990s. There are various contrasts: design \noften focuses on an established set of require-\nments, whereas architecture often must shape \nthe requirements through negotiation with \nstakeholders and requirements analysis. In \naddition, architecture often must recognize \nand address a wider range of concerns that \nmay or may not end up as requirements on the \nsoftware system of interest. 3.2. Architectural Design\b\n[2*c20, 20]\nArchitectural design is the application of \ndesign principles and methods within a \nprocess to create and document a software \narchitecture. There are many architecture \nmethods for carrying out this activity. This \nsection describes a general model of architec-\ntural design underlying various architecture \nmethods based upon [20]. Architectural design involves identifying a \nsystem\u2019s major components; their responsibil-\nities, properties, and interfaces; and the rela-\ntionships and interactions among them and \nwith the environment. In architectural design, \nfundamentals of the system are decided, but \nother aspects, such as the internal details of \nmajor components are deferred. Typical concerns in architectural design \ninclude the following:\n\u2022\t Overall architecture styles and com-\nputing paradigms\n\u2022\t Large-scale refinement of the system into \nkey components\n\u2022\t Communication and interaction among \ncomponents\n\u2022\t Allocation of concerns and design \nresponsibilities to components\n\u2022\t Component interfaces\n\u2022\t Understanding and analysis of scaling \nand performance properties, resource \nconsumption properties, and reliability \nproperties\n\u2022\t Large-scale/system-wide approaches to \ndominating concerns (such as safety and \nsecurity, where applicable)\nAn overview of architectural design is pre-\nsented in Figure 2.3. Architectural design is iterative, com-\nprising three major activities: analysis, syn-\nthesis and evaluation. Often, all three major \nactivities are performed concurrently at var-\nious levels of granularity. 3.2.1. Architecture Analysis\nArchitecture analysis gathers and formulates \narchitecturally significant requirements (ASRs), \ndefined as any \u2018\u2018requirement upon a software \nsystem which influences its architecture\u2019\u2019 [31].", "domains": ["Software Quality Attributes", "Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 75", "position": 75, "chunk_type": "semantic", "token_estimate": 382}
{"text": "SOFTWARE ARCHITECTURE   2-11: also the consequences of their interactions. For example, a secure architecture may be \nexcessively costly to build and verify; an easy-\nto-build architecture may not be maintainable \nover the system\u2019s lifetime if it cannot incorpo-\nrate new technologies. The Architecture Tradeoff Analysis Method \n(ATAM) [10] provides a methodical approach \nto evaluating software architectures based on \nquality attributes in a utility tree (provide illus-\ntration) and scenarios illustrating the quali-\nties. Analysis of tradeoffs among competing \nquality requirements and their architectural \napproaches are the key to the architecture \nevaluation. Clements, et al. describe several \nmethods for evaluation including ATAM, \nSoftware Architecture Analysis Method \n(SAAM), and Quality Attribute Workshops \n(QAW) [10]. The SARA Report defines a \ngeneral framework for software architecture \nevaluation [31]. 4.2. Reasoning about Architectures \n\b\n[38*c10, 3, 10, 31]\nEach architecture concern has a distinct basis \nfor evaluation. Evaluation is most effective \nwhen it is based upon robust, existing archi-\ntecture descriptions. ADs can be queried, \nexamined and analyzed. For example, eval-\nuation of functionality or behavior benefits \nfrom having an explicit architecture view \nor other representation of that aspect of the \nsystem to study. Specialized concerns such as \nreliability, safety and security often rely on \nspecialized representations from the respec-\ntive discipline. Often architecture documentation is unfin-\nished, incomplete, out of date or nonexistent. In such cases, the evaluation effort must rely \non the knowledge of participants as a primary \ninformation source. Use cases are frequently used to check \nan architecture\u2019s completeness and consis-\ntency (see Software Engineering Models and \nMethods KA) by comparing the steps in the \nuse case to the software architecture elements \nthat would be involved in carrying out those \nsteps [23]. For a general framework for reasoning \nabout various concerns, see Bass et al. [3]. 4.3. Architecture Reviews\b\n[2*c21, 1, 31]\nArchitecture reviews are an effective approach \nto assess an architecture\u2019s status and quality \nand identify risks by assessing one or more \narchitecture concerns [1]. Many reviews are \ninformal or expertise-based, and some are \nmore structured, organized around a checklist \nof topics to cover. Parnas and Weiss proposed \nan effective approach to conducting reviews, \ncalled active reviews [33], where instead of \nchecklists, each evaluation item entails a \nspecific activity by a reviewer to obtain the \nneeded information. Many organizations have institution-\nalized architecture review practices. For \nexample, an industry group developed a \nframework for defining, conducting and \ndocumenting architecture reviews and their \noutcomes [31].", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 77", "position": 77, "chunk_type": "semantic", "token_estimate": 403}
{"text": "SOFTWARE ARCHITECTURE   2-11: Many organizations have institution-\nalized architecture review practices. For \nexample, an industry group developed a \nframework for defining, conducting and \ndocumenting architecture reviews and their \noutcomes [31]. 4.4. Architecture Metrics\b\n[2*c23]\nAn architecture metric is a quantitative mea-\nsure of a characteristic of an architecture. Various architecture metrics have been \ndefined. Many of these originated as design or \ncode metrics that have been \u201clifted\u201d to apply \nto architecture. Metrics include component \ndependency, cyclicity and cyclomatic com-\nplexity, internal module complexity, module \ncoupling and cohesion, levels of nesting, and \ncompliance with the use of patterns, styles \nand (required) APIs. In continuous development paradigms \n(such as DevOps), other metrics have evolved \nthat focus not on the architecture directly but \non the responsiveness of the process, such as \nmetrics for lead time for changes, deployment \nfrequency, mean time to restore service, and \nchange failure rate\u2014as indicative of the state \nof the architecture.", "domains": ["Design Patterns", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 77", "position": 77, "chunk_type": "semantic", "token_estimate": 152}
{"text": "Perry and Wolf, Foundations for the study of: software architecture [34]\nPerry and Wolf\u2019s Foundations circulated infor-\nmally for several years before its publication in \n1992. It has indeed served as a foundation the \nevolution of the discipline of software archi-\ntecture, introducing a number of ideas that are \nfundamental to the field, including architec-\nture as a discipline; distinguishing architecture \nand design; elements of software architectures; \nmultiple views; architecture styles and types; \nand analogies with other fields. Bass et al., Software Architecture in Practice [2*]\nThis book introduces concepts and recom-\nmended practices of software architecture, \nmeaning how software is structured and how \nthe software\u2019s components interact. The book \naddresses several quality concerns in detail, \nincluding: availability, deployability, energy \nefficiency, modifiability, performance, test-\nability and usability. The authors offer recom-\nmended practices focusing on architectural \ndesign, architecture description, architecture \nevaluation and managing architecture tech-\nnical debt. They also emphasize the impor-\ntance of the business context in which large \nsoftware is designed. In doing so, they present \nsoftware architecture in a real-world setting, \nreflecting both the opportunities and con-\nstraints that organizations encounter. Kruchten, \nThe \n4+1 \nView \nModel \nof \nArchitecture [25]. This seminal paper organizes an approach \nto architecture description using five archi-\ntecture viewpoints. The first four are used to \nproduce the logical view, the development \nview, the process view, and the physical view. These are integrated through selected use \ncases or scenarios to illustrate the architec-\nture. Hence, the model results in 4+1 views. The views are used to describe the software as \nenvisioned by different stakeholders\u2014such as \nend-users, developers, and project managers. Rozanski and Woods, Software Systems \nArchitecture [38*]\nThis is a handbook for the software sys-\ntems architect. It develops key concepts of \nstakeholder, concern, architecture descrip-\ntion, architecture viewpoint and architecture \nview, architecture patterns and styles, with \nexamples. It provides an end-to-end archi-\ntecting process. The authors provide a cat-\nalog of ready-to-use, practical viewpoints for \nthe architect to employ that are applicable to \na wide range of systems. The book is filled \nwith guidance for applying these concepts \nand methods. R.N. Taylor, N. Medvidovi\u0107, E. Dashofy, \nSoftware Architecture: Foundations, Theory, and \nPractice [41*]\nThis is a comprehensive textbook on many \naspects of software architecture, including \nkey ideas; software architecture in the con-\ntext of software engineering; the design pro-\ncess; architecture modeling, analysis and \nvisualization; and chapters on several con-\ncerns including implementation, deployment, \nadaptation, non-functional properties, trust \nand security.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 79", "position": 79, "chunk_type": "semantic", "token_estimate": 407}
{"text": "Perry and Wolf, Foundations for the study of: R.N. Taylor, N. Medvidovi\u0107, E. Dashofy, \nSoftware Architecture: Foundations, Theory, and \nPractice [41*]\nThis is a comprehensive textbook on many \naspects of software architecture, including \nkey ideas; software architecture in the con-\ntext of software engineering; the design pro-\ncess; architecture modeling, analysis and \nvisualization; and chapters on several con-\ncerns including implementation, deployment, \nadaptation, non-functional properties, trust \nand security. P. Clements et al. Documenting Software \nArchitecture: Views and Beyond, 2nd edition [9]. This book provides detailed guidance on cap-\nturing software architectures, using guidance \nand examples to express an architecture so \nthat stakeholders can build, use, and main-\ntain that system. The book introduces a \n3-way categorization of views and therefore \nviewpoints: into module, component and \nconnector and allocation called viewtypes, \nproviding numerous examples of each. Brown, Software Architecture for Developers [5]\nBrown provides an overview of software \narchitecture topics from the perspective of a", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 79", "position": 79, "chunk_type": "semantic", "token_estimate": 154}
{"text": "2-14   SWEBOK \u00ae GUIDE V4.0: developer. He discusses common architec-\nture drivers including architecture principles, \nquality concerns, constraints and functional \nrequirements. He has an in-depth discussion \nof the role of the architect in a development \nsetting and requisite knowledge and skills for \narchitects. He focuses on the practical issues \nof architecture in the delivery process and \non managing risk. An appendix provides a \ncase study. Fairbanks, Just Enough Software Architecture: \nA risk-driven approach [16]\nFairbanks offers a risk-driven approach to \narchitecting within the context of develop-\nment: do just enough software architecture \nto mitigate the identified risks where those \nrisks could result from a small solution space, \nfrom extremely demanding quality require-\nments or from possible high-risk failures. The risk-driven approach is harmonious \nwith low-ceremony and agile approaches. Architecting, as argued by Fairbanks, is \nnot just for architects\u2014but is relevant to all \ndevelopers. Erder, Pureur and Woods, Continuous \nArchitecture in Practice: Software Architecture in \nthe Age of Agility and DevOps. [15]\nThis book shows how \u201cclassical\u201d thinking \nabout software architecture has evolved \nin the present day in the contexts of agile, \ncloud-based and DevOps approaches to \nsoftware development by providing prac-\ntical guidance on a range of quality and \ncross-cutting concerns including security, \nresilience, scalability and integration of \nemerging technologies.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 80", "position": 80, "chunk_type": "semantic", "token_estimate": 210}
{"text": "[1]\t M. Ali Babar, and I. Gorton, \u201cSoftware: Architecture Review: The State of the \nPractice\u201d, IEEE Computer, July 2009. [2]\t * L. Bass, P. Clements, and R. Kazman, \nSoftware Architecture in Practice, 4th edi-\ntion, 2021. [3]\t L. Bass, J. Ivers, M.H. Klein, and \nP. Merson, Reasoning Frameworks, \nCMU/SEI-2005-TR-007, 2005. [4]\t * F. Brooks, The Design of Design, \nAddison-Wesley, 2010. [5]\t S. Brown, Software Architecture for \nDevelopers, 2018, http://leanpub.com/\nsoftware-architecture-for-developers \n[6]\t * D. Budgen, Software Design: Creating \nSolutions for Ill-Structured Problems, \n3rd Edition, CRC Press, 2021. [7]\t F. Buschmann, R. Meunier, H. \nRohnert, P. Sommerlad, and M. Stal, \nPattern Oriented Software Architecture, \nJohn Wiley & Sons, 1996. [8]\t H. Cervantes, R Kazman, Designing \nSoftware Architectures: A Practical \nApproach, 2nd ed., Addison-Wesley, 2024. [9]\t P. Clements et al., Documenting Software \nArchitecture: Views and Beyond, 2nd edi-\ntion Addison-Wesley, 2011. [10]\tP. Clements, R. Kazman, M. Klein, \nEvaluating Software Architectures, \nAddison-Wesley, 2001\n[11]\tM.E. Conway, \u201cHow Do Committees \nInvent?\u201d Datamation, 14(4), 28-31, 1968. [12]\tE.W. Dijkstra, \u201cOn the role of scientific \nthought\u201d, 1974, available at http://www. cs.utexas.edu/users/EWD/transcrip-\ntions/EWD04xx/EWD447.html. [13]\tT. Earl, SOA Design Patterns, \nPrentice-Hall, 2009\n[14]\tP. Eeles, and P. Cripps, The Process \nof Software Architecting, Addison \nWesley, 2010.", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 80", "position": 80, "chunk_type": "semantic", "token_estimate": 198}
{"text": "SOFTWARE ARCHITECTURE   2-15: [15]\tM. Erder, P. Pureur and E. Woods, \nContinuous Architecture in Practice: \nSoftware Architecture in the Age of Agility \nand DevOps, Addison-Wesley, 2021. [16]\tG. Fairbanks, Just Enough Software \nArchitecture: A Risk-Driven Approach, \nMarshall & Brainerd, 2010. [17]\tE. Fernandez-Buglioni, Security \nPatterns in Practice: Designing Secure \nArchitectures Using Software Patterns, \nWiley, 2013. [18]\tR.T. Fielding and R.N. Taylor, \nPrincipled design of the modern web \narchitecture, ACM Transactions on \nInternet Technology, 2(2), 115\u2013150, 2002. [19]\tM. Fowler, D. Rice, M. Foemmel, \nE. Hieatt, R. Mee and R. Stafford, \nPatterns of Enterprise Application \nArchitecture, Addison-Wesley, 2003. [20]\tC. Hofmeister, P.B. Kruchten, R.L. Nord, H. Obbink, A. Ran, and P. \nAmerica, \u201cA general model of soft-\nware architecture design derived \nfrom five industrial approaches\u201d, The \nJournal of Systems and Software, 80, \n106\u2013126, 2007. [21]\tC. Hofmeister, R.L. Nord, and D. Soni, \nApplied Software Architecture, Addison- \nWesley, 2000. [22]\tISO/IEC/IEEE, \u201cISO/IEC/IEEE \n24765:2017 Systems and Software \nEngineering \u2014 Vocabulary,\u201d 2nd ed. 2017. [23]\tISO/IEC/IEEE 42010:2011, \nSystems and software engineering \u2014 \nArchitecture description. [24]\tR. Kazman, S. Haziyev, A. Yakuba, \nand D.A. Tamburri, Managing Energy \nConsumption as an Architectural \nQuality Attribute, IEEE Software, \n35(5), 102\u2013107, 2018\n[25]\tP.B. Kruchten, The \u201c4+1\u201d View Model of \nArchitecture, IEEE Software 12(6), 1995. [26]\tP.B. Kruchten, R.L. Nord, and \nI. Ozkaya, Managing Technical \nDebt: Reducing Friction in Software \nDevelopment. Addison-Wesley, 2019. [27]\tZ. Li, P. Liang and P. Avgeriou, \nArchitecture viewpoints for documenting \narchitectural technical debt. Software \nQuality Assurance, Elsevier, 2016. [28]\tAlan MacCormack, John Rusnak & \nCarliss Baldwin, Exploring the Duality \nbetween Product and Organizational \nArchitectures: A Test of the \n\u2018Mirroring\u2019 Hypothesis. Research Policy, \n41:1309\u20131324, 2012\n[29]\t* M.W. Maier and E. Rechtin, The Art \nof Systems Architecting, 3rd edition, CRC \nPress, 2021. [30]\tN. Medvidovi\u0107, D.S. Rosenblum, D.F. Redmiles and J.E. Robbins, Modeling \nsoftware architectures in the Unified \nModeling Language, ACM Transactions \non Software Engineering and Methodology, \n11(1), 2\u201357, 2002\n[31]\tH. Obbink et al., Report on Software \nArchitecture Review and Assessment \n(SARA), version 1.0, available at https://\nphilippe.kruchten.com/architecture/\nSARAv1.pdf, 2002. [32]\tD.L. Parnas, \u201cOn the criteria to be used \nin decomposing systems into modules\u201d, \nCommunications of the ACM 15(12), \n1053-1058, 1972. [33]\tD.L. Parnas and D.M. Weiss, \n\u201cActive Design Reviews: Principles \nand Practices\u201d, Proceedings of 8th \nInternational Conference on Software \nEngineering, 215-222, 1985. [34]\tD. Perry, A. Wolf, Foundations for the", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 81", "position": 81, "chunk_type": "semantic", "token_estimate": 387}
{"text": "2-16   SWEBOK \u00ae GUIDE V4.0: study of software architecture, ACM \nSIGSOFT Software Engineering Notes, \n17(4), 40\u201352, 1992\n[35]\tE. Poort, H. van Vliet, RCDA: \nArchitecting as a Risk- and Cost \nManagement Discipline, Journal of \nSystems and Software, https://www \n.cs.vu.nl/~hans/publications/y2012 \n/JSS-RCDA.pdf, 2012\n[36]\tR. Prieto-Diaz and J.M. Neighbors, \n\u201cModule Interconnection Languages\u201d, \nJournal of Systems and Software, 6(4), \n307\u2013334, 1986. [37]\tC. Richardson, Microservices Patterns, \nManning Publications, 2019\n[38]\t*N. Rozanski and E. Woods, Software \nSystems Architecture: Working with \nStakeholders Using Viewpoints and \nPerspectives, 2nd edition, Addison-\nWesley, 2011. [39]\tM. Shaw and D. Garlan, Software \nArchitecture: Perspectives on an Emerging \nDiscipline, Prentice Hall, 1996. [40]\t*I. Sommerville, Software Engineering, \n10th edition, 2016. [41]\tR.N. Taylor, N. Medvidovi\u0107, E. Dashofy, \nSoftware Architecture: Foundations, Theory, \nand Practice, Wiley, 2009\n[42]\tR. Weinreich and G. Buchgeher, \nTowards supporting the software archi-\ntecture life cycle, The Journal of Systems \nand Software, 85, 546\u2013561, 2012.", "domains": ["Architectural Patterns and Styles", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 82", "position": 82, "chunk_type": "semantic", "token_estimate": 149}
{"text": "Application Programming: Interface", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 83", "position": 83, "chunk_type": "semantic", "token_estimate": 3}
{"text": "Section: Component-Based Design", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 83", "position": 83, "chunk_type": "semantic", "token_estimate": 3}
{"text": "Section: Entity Relationship Diagram", "domains": ["Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 83", "position": 83, "chunk_type": "semantic", "token_estimate": 4}
{"text": "Section: Interface Description Language", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 83", "position": 83, "chunk_type": "semantic", "token_estimate": 4}
{"text": "Software Design Description: SoC\nSeparation of Concerns", "domains": ["Design Principles", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 83", "position": 83, "chunk_type": "semantic", "token_estimate": 7}
{"text": "3-2   SWEBOK \u00ae GUIDE V4.0: 1.2. Context of Software Design\b\n[4* c13, c14] \n\b\n[21* c19, c20]\nSoftware design is an important part of the \nsoftware development process. To understand \nthe role of software design is to see how it fits \nSoftware\nDesign\nSoftware\nDesign\nFundamentals\nDesign\nTinking\nContext of\nSoftware\nDesign\nKey Issues \nin Software \nDesign\nSoftware\nDesign\nPrinciples\nHigh-Level\nDesign\nDetailed\nDesign\nConcurrency\nControl and Event\nHandling\nData Persistence\nDistribution of\nComponents\nErrors and Exception\nHandling\nIntegration and\nInteroperability\nAssurance, Security, \nSafety\nVariability\nModel-Based\nDesign\nStructural \nDesign Description\nBehavioral\nDesign Description\nDesign Patterns\nSpecialized\nDomain-Speci\ufb01c\nLanguages\nDesign\nRationale\nGeneral Strategies\nFunction-Oriented\nData-Centered\nObject-Oriented\nUser-Centered\nComponent-Based\nEvent-Driven\nAspect-Oriented\nConstraint-Based\nDomain-Driven Design\nOther Methods\nDesign Reviews \nand Audits\nQuality Attributes\nQuality Analysis \nand Evaluation \nTechniques\nMeasures and \nMetrics\nVeri\ufb01cation, \nValidation and\nCerti\ufb01cation\nSoftware\nDesign\nProcesses\nSoftware\nDesign\nQualities\nRecording\nSoftware\nDesign\nSoftware Design\nStrategies and \nMethods\nSoftware Design\nAnalysis and \nEvaluations\nFigure 3.1. Breakdown of topics for the Software Design KA", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 84", "position": 84, "chunk_type": "semantic", "token_estimate": 161}
{"text": "SOFTWARE DESIGN   3-3: into the software development life cycle (see \nSoftware Process KA). To understand that \ncontext, it is important to understand the \nmajor characteristics and roles of software \nrequirements, software construction, software \ntesting, and software maintenance. The con-\ntext varies with many factors, including degree \nof formality and stage of the life cycle. Software design is the transformation of \ncustomer and other requirements, needs, and \nconcerns into implementable design specifica-\ntions. Its contexts include the following:\n\u2022\t Software Design\u2019s relationship with soft-\nware requirements: The requirements \nestablish a set of problems that the soft-\nware design must solve. \u2022\t Software Design\u2019s relationship with soft-\nware architecture: In cases where an \narchitecture has been established, that \narchitecture constrains the design by \ncapturing fundamental aspects of the \nsystem: such as its major components and \ntheir interconnections, application pro-\ngramming interfaces (APIs), styles and \npatterns to be used, and architectural \nprinciples to be observed and enforced. \u2022\t Software Design\u2019s relationship with soft-\nware construction: The software design \nmust provide a guide to implementors on \nbuilding the system. \u2022\t Software Design\u2019s relationship with soft-\nware testing: Software design provides a \nfoundation for an overall testing strategy \nand test cases that ensure that the design \nis properly implemented and operates \nas intended. 1.3. Key Issues in Software Design\b\n[2, 12]\nMany key issues must be dealt with when \ndesigning software. Some are quality con-\ncerns that all software must address (per-\nformance, security, reliability, usability, \nmaintainability, etc.). Another important \nissue is how to refine, organize, intercon-\nnect and package software components. These issues are so fundamental that all \ndesign approaches address them in one \nway or another. (See topic Stakeholders and \nConcerns in Software Architecture KA, sec-\ntion 1.4 Software Design Principles, and topic \n5 Software Design Strategies and Methods.) In contrast, other issues \u201cdeal with some \naspect of software\u2019s behavior that is not in the \napplication domain, but which addresses some \nof the supporting domains\u201d [2]. Such issues, \nwhich often crosscut the system\u2019s function-\nality, are referred to as aspects, which \u201ctend not \nto be units of software\u2019s functional decompo-\nsition, but rather to be properties that affect \nthe performance or semantics of the compo-\nnents in systemic ways\u201d [12]. 1.4.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 85", "position": 85, "chunk_type": "semantic", "token_estimate": 368}
{"text": "SOFTWARE DESIGN   3-3: Such issues, \nwhich often crosscut the system\u2019s function-\nality, are referred to as aspects, which \u201ctend not \nto be units of software\u2019s functional decompo-\nsition, but rather to be properties that affect \nthe performance or semantics of the compo-\nnents in systemic ways\u201d [12]. 1.4. Software Design Principles\b [5, 10, 17, 20]\nA principle is \u201ca fundamental truth or proposi-\ntion that serves as\u00a0the foundation for a system \nof belief or behavior or for a chain of rea-\nsoning.\u201d [Oxford English Dictionary] \nDesign principles provide direction or guid-\nance for making decisions during design. Some principles originated during the early \ndays of software engineering, others even pre-\ndate the discipline, deriving from best prac-\ntices in engineering unrelated to software. (See Engineering Foundations KA.) Decision \nmaking can also be assisted by quantita-\ntive methods, such as discussed in Software \nEngineering Economics KA. Software design \nprinciples are key notions that provide the basis \nfor many different software design concepts, \napproaches and methods. The principles listed \nbelow apply to any of the three stages of design. Many of these principles are interrelated. Whether alone or used in combination with \nother principles, they are reflected elsewhere \nin software design to produce many concepts \nand constructs found in design capture, strat-\negies and methods. This is itself an application \nof the design thinking process above. Software \ndesign principles include the following:\n\u2022\t Abstraction is \u201ca view of an object that \nfocuses on the information relevant to \na particular purpose and ignores the \nremainder of the information\u201d [11].\u201cThe \nabstraction principle . . . helps to identify", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 85", "position": 85, "chunk_type": "semantic", "token_estimate": 265}
{"text": "3-4   SWEBOK \u00ae GUIDE V4.0: essential properties common to super-\nficially different entities\u201d [20]. (See also \ntopic Abstraction in the Computing \nFoundations KA.) \u2022\t Separation of concerns (SoC). A design con-\ncern is an \u201carea of interest with respect to \na software design\u201d [11] that is relevant \nto one or more of its stakeholders. By \nidentifying and separating concerns, the \ndesigner can focus on each concern for the \nsystem in isolation about which Dijkstra \nsaid \u201ceven if not perfectly possible, [SoC] \nis yet the only available technique for \neffective ordering of one\u2019s thoughts \u201d [5] \n(See also topic Stakeholders and Concerns \nin Software Architecture KA.) \u2022\t Modularization (or refinement or decompo-\nsition) structures large software as com-\nprising smaller components or units. Each \ncomponent is named and has well-de-\nfined interfaces for its interactions with \nother components. Smaller components \nare easier to understand and, therefore, to \nmaintain. There are numerous modular-\nization strategies. (See topic 5 Software \nDesign Strategies and Methods.) Traditionally, the goal is to place distinct \nfunctionalities and responsibilities in dif-\nferent components. David Parnas advo-\ncated that each module in a system should \nhave a single responsibility [17]. One way \nto think of modularization is as a special \ncase of more general strategies, such as sep-\naration of concerns or divide and conquer. (see topic Problem-Solving Techniques in \nComputing Foundations). \u2022\t Encapsulation (or information hiding) \nbuilds upon the principles of abstraction \nand modularization so that nonessential \ninformation is less accessible, allowing \nusers of the module to focus on the essen-\ntial elements at the interface. \u2022\t Separation of interface and implementa-\ntion is an application of encapsulation \nthat involves defining a component by \nspecifying its public interfaces, which \nare known to and accessible to clients; \nisolating the use of a component from \nthe details of how that component is \nbuilt. (See Encapsulation (or information \nhiding) above.) \u2022\t Coupling is defined as \u201ca measure of the \ninterdependence among modules in a \ncomputer program\u201d [11]. Most design \nmethods advocate that modules should \nbe loosely or weakly coupled. \u2022\t Cohesion (or localization) is defined as \u201ca \nmeasure of the strength of association \nof the elements within a module\u201d\u00a0 [11]. Cohesion highlights organizing a mod-\nule\u2019s constituents based on their relat-\nedness. Most design methods advocate \nthat modules should maximize their \ncohesion/locality. \u2022\t Uniformity is a principle of consistency \nacross software components\u2014common \nsolutions should be produced to address \ncommon or recurring problems.", "domains": ["Design Principles", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 86", "position": 86, "chunk_type": "semantic", "token_estimate": 401}
{"text": "3-4   SWEBOK \u00ae GUIDE V4.0: Most design methods advocate \nthat modules should maximize their \ncohesion/locality. \u2022\t Uniformity is a principle of consistency \nacross software components\u2014common \nsolutions should be produced to address \ncommon or recurring problems. These \ninclude naming schemes, notations and \nsyntax, interfaces that define access to \nservices and mechanisms, and ordering \nof elements and parameters. This can be \nachieved through conventions such as \nrules, formats and styles. \u2022\t Completeness (or sufficiency) means ensuring \nthat a software component captures the \nimportant characteristics of an abstrac-\ntion and leaves nothing out. Completeness \ntakes various forms, perhaps the most \nimportant of which is design completeness \nagainst requirements: a design should be \nsufficient for designers to demonstrate how \nrequirements will be met and how subse-\nquent work will satisfy those requirements. Design should be complete with respect to \nthe modes and states of the software. \u2022\t Verifiability means that information \nneeded to verify the design against its \nrequirements and other constraints is \navailable. This is relevant for any software \nbut is of particular importance for high-as-\nsurance software, such as software where \nsecurity, reliability or safety-critical con-\ncerns are present. An SDD should be \nsufficient as a basis for verifying a design. (See Software Testing KA and Software \nQuality KA.).) \u2022\t Other design principles. Recently, with the", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 86", "position": 86, "chunk_type": "semantic", "token_estimate": 214}
{"text": "SOFTWARE DESIGN   3-5: increased appearance of autonomous sys-\ntems, the use of machine learning and \nartificial intelligence, and, generally, \nsystems with widening social impacts, \napproaches to Ethically Aligned Design \nhave been developed to address concerns \nincluding universal human values, polit-\nical self-determination, and data agency \nand technical dependability [9]. The gen-\neral principles of Ethically Aligned Design \nare human rights, well-being, data agency, \neffectiveness, transparency, accountability, \nawareness of misuse, and competence. 2. Software Design Processes \n\b\n[4* c3] [21* c2, c7] [10]\nSoftware design is generally considered a mul-\ntistage process or activity. Software design \ncan be divided into the following stages or \nphases. When necessary, we distinguish the \nphase from the general activity:\n\u2022\t Architectural design stage\n\u2022\t High-level design stage\n\u2022\t Detailed design stage\nThe architectural design stage addresses \nthe fundamentals of the system as a whole and \nin relation to its environment (see Software \nArchitecture KA). The \nhigh-level \ndesign \nstage \nis \nout-\nward-facing\u2014developing the top-level struc-\nture and organization of the software, \nidentifying its various components and how \nthat software system and its components \ninteract with the environment and its elements. The detailed design stage is inward-\nfacing\u2014specifying each component in suffi-\ncient detail to facilitate its construction and \nto meet its outside obligations, including how \nsoftware components are further refined into \nmodules and units. Each stage reflects the basic pattern out-\nlined in section 1.1 Design Thinking. Not all stages are found in every soft-\nware process. However, when present, each \nstage creates an obligation upon the next \nstage regarding the software which is under \ndevelopment. Although software developers generally \nfollow similar guidelines for what happens \nin each stage, there are no strict bound-\naries between stages regarding what must be \ndone and when. For example, for many soft-\nware systems, the choice of an algorithm to \nsort data will be deferred to programmers, \nwithin the constraints and guidance provided \nby the system\u2019s requirements, its architecture \ndescription or design specifications. However, \nfor another software system, the existence of \na suitable algorithm could be architecturally \nsignificant and must be determined early in \nthe life cycle. Without that algorithm, there \nis no possibility of constructing the software \nto meet its requirements. Some rules of thumb for each stage include \nthe following:\n\u2022\t The architectural design stage defines \na computational model, the major com-\nputational elements, and the important \nprotocols and relationships among them.", "domains": ["Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 87", "position": 87, "chunk_type": "semantic", "token_estimate": 395}
{"text": "SOFTWARE DESIGN   3-5: Without that algorithm, there \nis no possibility of constructing the software \nto meet its requirements. Some rules of thumb for each stage include \nthe following:\n\u2022\t The architectural design stage defines \na computational model, the major com-\nputational elements, and the important \nprotocols and relationships among them. This stage develops strategies to address \ncrosscutting concerns, such as perfor-\nmance, reliability, security and safety, \nand articulation of crosscutting deci-\nsions, including system-wide styles (e.g., \na transactional n-tier style versus a pipes \nand filters style, together with the ratio-\nnale for such decisions). \u2022\t The high-level design stage includes \nidentification of the primary computa-\ntional elements and significant relation-\nships among them, with a focus on each \nmajor component\u2019s existence, role and \ninterfaces. That definition should be suf-\nficiently detailed to allow designers or \nprogrammers of client components to \ncorrectly and efficiently access each ser-\nvice\u2019s capabilities\u2014without having to \nread its code. \u2022\t The detailed design stage defines each \nmodule\u2019s internal structure, focusing on \ndetailing and justifying choices of algo-\nrithms, data access and data representa-\ntion. The detailed design specifications \nshould be sufficient to allow programmers", "domains": ["Software Quality Attributes", "Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 87", "position": 87, "chunk_type": "semantic", "token_estimate": 188}
{"text": "3-6   SWEBOK \u00ae GUIDE V4.0: to code each module during construction \n(see Software Construction KA). The \ncode is a representation of the solution that \nis sufficiently detailed and complete that a \ncompiler (or interpreter) can execute it. 2.1. High-Level Design\b\n[3* c5] [4* c6] [10]\nHigh-level design specifies the interaction of \na system\u2019s major components with one another \nand with the environment, including users, \ndevices and other systems. High-level design \naddresses the following:\n\u2022\t External events and messages to which \nthe system must respond\n\u2022\t Events and messages which the system \nmust produce\n\u2022\t Specification of the data formats and pro-\ntocols for events and messages\n\u2022\t Specification of the ordering and timing \nrelationships between input events and \nmessages, and output events and messages\n\u2022\t Tracing and analysis of end-to-end trans-\nactions and event threads\n\u2022\t Data persistence (how data is stored \nand managed)\nHigh-level design is undertaken within \nthe envelope established by the system\u2019s soft-\nware architecture (if any). Each of the above \nmay be guided or constrained by architecture \ndirectives. For example, event signaling and \nmessaging will use the protocols and modes \nof interaction established by the architecture. Data formats and protocols will use data and \ncommunication standards specified by the \narchitecture. Absent an explicit architecture \ndesign stage, some of these directives will be \nestablished by the software requirements or \ndecided during high-level design. 2.2. Detailed Design\b\n[10]\nThe detailed design stage proceeds within the \nconstraints established by the high-level design. It specifies major system components\u2019 internal \ncharacteristics, internal modules and their \ninterconnections to other modules, services \nand processes they provide, computing proper-\nties, algorithms, and data access rules and data \nstructures. This includes the following:\n\u2022\t Refinement of major system components \ninto modules or program units, including \nopportunities for using off-the-shelf com-\nponents and application frameworks\n\u2022\t Allocation of design responsibilities to \nmodules and program units\n\u2022\t Interactions among modules\n\u2022\t Scope and visibility among components, \nmodules and program units \n\u2022\t Component modes, component states \nand transitions among them\n\u2022\t Data and control interdependencies\n\u2022\t Data \norganization, \npackaging \nand \nimplementation\n\u2022\t User interfaces\n\u2022\t Requisite algorithms and data structures\n3. Software Design Qualities\b\n[4* c4] [20]\nSoftware requirements and architecture direc-\ntives are intended to guide software toward \ncertain characteristics or design qualities. Design qualities are an important subclass of \nconcerns (see topic Stakeholders and Concerns \nin Software Architecture KA).", "domains": ["Design Patterns", "Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 88", "position": 88, "chunk_type": "semantic", "token_estimate": 393}
{"text": "SOFTWARE DESIGN   3-7: 3.3. Data Persistence\b\n[21* c6, c16]\nData persistence concerns the storage and \nmanagement of data throughout the system. 3.4. Distribution of Components\b\n[21* c17]\nDistribution concerns how software com-\nponents are distributed across hardware \n(including computers, networks and other \ndevices) and how those components commu-\nnicate while meeting performance, reliability, \nscalability, availability, monitorability, busi-\nness continuity and other expectations. 3.5. Errors and Exception Handling, Fault \nTolerance\b\n[21* c11]\nThis concern pertains to how to prevent, \navoid, mitigate, tolerate and process errors \nand exceptional conditions. 3.6. Integration and Interoperability \n\b\n[4* c11, c14, c16]\nThis issue arises at the enterprise or sys-\ntem-of-systems level or for any complex \nsoftware when heterogeneous systems or \napplications need to interwork through \nexchanges of data or accessing one another\u2019s \nservices. Within a software system, the issue \narises when components are designed using \ndifferent frameworks, libraries or protocols. 3.7. Assurance, Security, and Safety \n\b\n[21* c10\u2013c14]\nHigh assurance spans a number of software \nqualities, including security and safety con-\ncerns, pertaining to whether the software \nbehaves as intended in critical situations, such \nas in the face of hazards. Security becomes a \nkey concern for distributed applications where \ncomponents communicate using different pro-\ntocols and media. Design for security concerns \nhow to prevent unauthorized disclosure, cre-\nation, change, deletion, or denial of access to \ninformation and other resources in the face of \nattacks upon the system or violations of system \npolicies to limit damage; provide continuity of \nservice; and assist repair and recovery. Design \nfor safety pertains to managing the software\u2019s \nbehavior in circumstances which might lead to \nharm to or loss of human life or damage to \nproperty or the environment. 3.8. Variability\b\n[6]\nVariability concerns permissible variations in \na software system. It is a fundamental aspect \nof most software [6]. It is the ability to create \nsoftware system variants for different market \nsegments or contexts of use. Interest in variability first arose in software \nproduct lines and system families, to accom-\nmodate and manage deployment of multiple \nvariants such as for different organizations \nor markets. (See appendix B 6, Standards for \nproduct line, methods and tools). It is also \nrelevant to software ecosystems and con-\ntext-aware software. (See also 3.5 Reuse in \nConstruction, Software Construction KA.) Feature models are used to gather require-\nments and dependencies into bundles. (See \nFeature-Driven Development, under topic \n4.1 Agile Methods in Software Engineering \nModels and Methods KA)\n4.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 89", "position": 89, "chunk_type": "semantic", "token_estimate": 402}
{"text": "SOFTWARE DESIGN   3-7: Feature models are used to gather require-\nments and dependencies into bundles. (See \nFeature-Driven Development, under topic \n4.1 Agile Methods in Software Engineering \nModels and Methods KA)\n4. Recording Software Designs \n\b\n[4* c7, c8] [1]\nThe outcome of design processes is accumu-\nlated knowledge and work products recording \nthat knowledge. Work products of software \ndesign capture (1)\u00a0aspects of the problems to \nbe solved, using the vocabulary of the domain; \n(2)\u00a0a solution vocabulary for solving the design \nproblems (see section 1.1 Design Thinking); \n(3)\u00a0the major decisions that have been taken; \nand (4)\u00a0explanations of the rationale for each \nnontrivial decision. Recording the rationale \nfor important decisions enhances the software \nproduct\u2019s long-term maintainability when \nmodifications or enhancements are consid-\nered (see section 4.6 Design Rationale). These \nwork products, often termed design descrip-\ntions or design specifications, can take the form \nof texts, diagrams, models and prototypes", "domains": ["Design Patterns", "Software Quality Attributes", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 89", "position": 89, "chunk_type": "semantic", "token_estimate": 151}
{"text": "3-8   SWEBOK \u00ae GUIDE V4.0: that comprise the blueprints of the software \nto be implemented. A fundamental aspect of software design \nis communication about the design among \ndesigners, and to customers, implementers and \nother stakeholders. This is the case whether \nthe software is developed using agile, tradi-\ntional or formal methods. The communication \nwill vary depending upon the target audi-\nence, the level of detail being communicated, \nand relevance to the concerns of the stake-\nholders. For example, when using traditional \nor formal methods, the design often evolves \nthrough a progression of design descriptions, \nwhile in agile approaches the evolving design \nmay be implicit in the minds of developers \nand only explicit as code. While the latter \napproach supports the agility of developers, \nother stakeholders, such as those concerned \nwith requirements, certification, testing and \nquality assurance may need explicit design \ninformation to do their work. Therefore, \nprojects should make conscious decisions \nabout which design specifications are needed \nbased upon stakeholder audience, subject and \nintended usage. Designers can analyze and evaluate these \nwork products to determine whether the \ndesign can meet the requirements and con-\nstraints on the software. Software design also \nexamines and evaluates alternative solutions \nand trade-offs. In addition to using them \nas inputs and as the starting point for con-\nstruction and testing, stakeholders can use \nthe design work products to plan subsequent \nactivities, such as system verification and \nvalidation. As design concepts evolve, so do their rep-\nresentations (see section 1.1 Design Thinking); \npart of the design process involves creating \nappropriate vocabularies for problems and \nsolutions. An informal sketch may be most \nappropriate for the early stages. It is useful \nto distinguish in-process (\u201cworking\u201d) spec-\nifications from final design products. The \nformer are produced by the design team for the \ndesign team; the latter may be produced for \nknown stakeholders or even for an unknown \nfuture audience. Many notations exist to represent software \ndesign artifacts. Software design is often car-\nried out using multiple types of notation. Two \nbroad areas of concern are software struc-\ntures and software behaviors. Some are used \nto describe a design\u2019s structural organization, \nothers to represent the software\u2019s intended \nbehavior. Below, they are categorized as nota-\ntions for structural and behavioral concerns \n(see section 4.2 Structural Design Descriptions \nand section 4.3 Behavioral Design Descriptions, \nrespectively).", "domains": ["Design Patterns", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 90", "position": 90, "chunk_type": "semantic", "token_estimate": 383}
{"text": "3-8   SWEBOK \u00ae GUIDE V4.0: Some are used \nto describe a design\u2019s structural organization, \nothers to represent the software\u2019s intended \nbehavior. Below, they are categorized as nota-\ntions for structural and behavioral concerns \n(see section 4.2 Structural Design Descriptions \nand section 4.3 Behavioral Design Descriptions, \nrespectively). Certain notations are used \nmostly during architectural design and others \nmainly during detailed design; some are useful \nthroughout all stages of software design. Some \nnotations are closely tied to the context of spe-\ncific design methods (see Software Design \nStrategies and Methods KA). The Unified Modeling Language (UML) is \na widely used family of notations addressing \nboth structural and behavioral concerns and \nis used in all design stages, from architectural \nthrough detailed design [1]. 4.1. Model-Based Design\b\n[4* c7.3] [21* c5.5] \nOver the history of software engineering, \nincluding architecture and design, there \nhas been an evolution from document-based \nartifacts to model-based artifacts. Model-\nBased Design (MBD) is an approach to \nrecording designs where models play an \nimportant role. This trend reflects the limitations of docu-\nment-based artifacts and the increased capa-\nbilities of automated tools. Document-based \nartifacts use natural language and informal \ndiagrams to convey designers\u2019 intentions, \nwhich might introduce ambiguity and \nincompleteness. Even when documents use \nwell-defined formats, relevant information \nmight be spread across documents, making \nunderstandability and analysis difficult. With MBD, appropriate tooling can gather \nand organize relevant information for use by \ndesigners and other stakeholders in an acces-\nsible form. Modern tools have accelerated the trend \nfrom document to model-based artifacts.", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 90", "position": 90, "chunk_type": "semantic", "token_estimate": 250}
{"text": "SOFTWARE DESIGN   3-9: Tooling enables animation or simulation of \nvarious software aspects, analyses of what-if \nscenarios and trade-offs, and rapid proto-\ntyping. Tooling also facilitates continuous \ntesting and integration approaches, enhanced \nand interactive traceability, and knowledge \ncapture and management, which are ineffi-\ncient or even infeasible with document-based \napproaches. Model-driven development (MDD) is a \ndevelopment paradigm that uses models as \nthe development process\u2019 primary artifacts (see \nSoftware Engineering Models and Methods KA). 4.2. Structural Design Descriptions \n\b\n[4* c7, c10] [7* c4] [21* c5.3]\nThe following types of notation, most of which \nare graphical, are used to represent the struc-\ntural aspects of a software design\u2014that is, \nthey are used to describe the major compo-\nnents and how they are interconnected (static \nview) and the allocation of responsibilities to \ncomponents and modules: \n\u2022\t Class and object diagrams are used to rep-\nresent a set of classes and objects and their \ninterrelationships. \u2022\t Component diagrams are used to rep-\nresent a set of components (replaceable \nelements of a system that conform to \nand provide the realization of a set of \ninterfaces) and their interconnections. Component models evolved from ear-\nlier module interconnection languages \ninto the package systems of program-\nming languages like Ada and Java and \nthe sophisticated module systems of cur-\nrent functional language systems such as \nHaskell and Coq. \u2022\t Class responsibility collaborator cards \n(CRCs) are used to denote the names of \ncomponents (classes), their responsibil-\nities and the components they interact \nwith to meet those responsibilities. \u2022\t Deployment diagrams are used to repre-\nsent a set of physical nodes and their inter-\nconnections to model the physical aspects \nof software as deployed on hardware. \u2022\t Entity relationship diagrams (ERDs) are \nused to represent conceptual, logical and \nphysical models of data as stored in infor-\nmation repositories or as a part of inter-\nface descriptions. \u2022\t Interface description languages (IDLs) \nare programming-like languages used to \ndefine the interfaces (names and types \nof exported operations) of software \ncomponents. \u2022\t Structure charts are used to describe the \ncalling structure of programs (that is, they \nshow which modules call, and are called \nby, which other modules). 4.3. Behavioral Design Descriptions \n\b\n[4* c9, c10] [7* c5] [21* c5.4]\nThe following notations and languages, some \ngraphical and some textual, are used to describe \nthe dynamic behavior of software systems and \ntheir components. Many of these notations \nare useful mostly, but not exclusively, during \ndetailed design.", "domains": ["Design Patterns", "Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 91", "position": 91, "chunk_type": "semantic", "token_estimate": 402}
{"text": "SOFTWARE DESIGN   3-9: Behavioral Design Descriptions \n\b\n[4* c9, c10] [7* c5] [21* c5.4]\nThe following notations and languages, some \ngraphical and some textual, are used to describe \nthe dynamic behavior of software systems and \ntheir components. Many of these notations \nare useful mostly, but not exclusively, during \ndetailed design. Moreover, behavioral descrip-\ntions can include rationale for design decisions \n(see section 4.6 Design Rationale). \u2022\t Activity diagrams are used to show flow \nof a computation from activity to activity. They also can represent concurrent activ-\nities, their inputs and outputs and oppor-\ntunities for concurrency. \u2022\t Interaction diagrams characterize the \ninteraction among a group of objects. There are two major kinds of interaction \ndiagrams: communication (or collabora-\ntion) diagrams and sequence diagrams. Communication diagrams show inter-\nactions among objects with an emphasis \non their links and the messages they \nexchange on those links. Sequence dia-\ngrams show interactions among objects, \nwith an emphasis on the temporal ordering \nof messages passed among those objects. \u2022\t Data flow diagrams (DFDs) are used to \nshow data flow among computing ele-\nments. A DFD provides \u201ca description \nbased on modeling the flow of infor-\nmation around a network of operational", "domains": ["Design Patterns", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 91", "position": 91, "chunk_type": "semantic", "token_estimate": 197}
{"text": "3-10   SWEBOK \u00ae GUIDE V4.0: elements, with each element making use \nof or modifying the information flowing \ninto that element\u201d [4]. DFDs have other \nuses, such as security analysis, as they \nidentify possible paths for attack and dis-\nclosure of confidential information. \u2022\t Decision tables and diagrams are used to\nrepresent complex combinations of con-\nditions and actions. \u2022\t Flowcharts are used to represent the flow\nof control and the sequence of associ-\nated actions. \u2022\t State (transition) diagrams and statecharts \nare used to show transitions from state to\nstate and how a component\u2019s behavior\nchanges based on its current state and\nresponse to input events. \u2022\t Formal specification languages are predomi-\nnantly textual languages founded upon basic\nnotions from mathematics (for example,\ntype, set, sequence, logical proposition) to\nrigorously and abstractly define software\ncomponent interfaces and behavior, often in\nterms of pre- and post-conditions, invariants, \ntype checking, and computational models\n(see section Formal Methods in Software\nEngineering Models and Methods KA). \u2022\t Pseudocode and program design lan-\nguages (PDLs) are structured, program-\nming language-like notations used to\ndescribe a procedure\u2019s processing behavior,\ngenerally at the detailed design stage. The\nuse of these languages is less common\ntoday but is still found in the documenta-\ntion of algorithms. 4.4. Design Patterns and Styles \b\n[3* c12] [4* c15] [7* c1, c2] [21* 7.2]\nSuccinctly described, a pattern is \u201ca common \nsolution to a common problem in a given context\u201d \n[7]. Design patterns include the following: \n\u2022\t Creational patterns (e.g., builder, factory,\nprototype, singleton)\n\u2022\t Structural patterns (e.g., adapter, bridge,\ncomposite, \ndecorator, \nfac\u0327ade, \nfly-\nweight, proxy)\n\u2022\t Behavioral patterns (e.g., command,\ninterpreter, iterator, mediator, memento, \nobserver, peer-to-peer, publish-subscribe, \nstate, strategy, template, visitor) \nDesign patterns can be used to reflect idioms \nthat have proven useful in solving particular \ndesign problems in the past, establish a solution \nvocabulary, and document and explain design \ndecisions. They arise at all stages of design, \nincluding architectural design. Often architec-\ntural styles can be viewed as patterns \u201cin the \nlarge,\u201d describing common solutions to archi-\ntecture-level problems that pervade the soft-\nware. (See also topic 2.2 Architecture Styles and \nPatterns, Software Architecture KA). 4.5. Specialized and Domain-Specific \nLanguages\b\n[21* c15]\nNot every design representation falls easily \ninto the structure/behavior dichotomy. For \nexample, user interface design mixes the \nstructural layout of what a user might see with \nthe behavioral logic of sequencing screens \nbased upon user actions.", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Software Quality Attributes", "Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 92", "position": 92, "chunk_type": "semantic", "token_estimate": 399}
{"text": "3-10   SWEBOK \u00ae GUIDE V4.0: Specialized and Domain-Specific \nLanguages\b\n[21* c15]\nNot every design representation falls easily \ninto the structure/behavior dichotomy. For \nexample, user interface design mixes the \nstructural layout of what a user might see with \nthe behavioral logic of sequencing screens \nbased upon user actions. Specialized concerns \nsuch as safety and reliability often have their \nown forms of representation that have evolved \namong specialists in those communities [21]. A recent trend has been the maturing of \ndomain-specific languages (DSLs) and widely \navailable tools to develop them. In this \napproach, part of the design process is codifying \nconcepts and constructs of a specific application \ndomain to create a computer language for that \ndomain so that representing the design using \nthese constructs leads to an animated or exe-\ncutable implementation. DSLs blur the lines \namong modeling languages, design languages \nand programming languages in this approach. There are DSLs and supporting tools for \ndomains such as simulation; real-time, reactive \nand distributed systems; game development; \nuser interfaces; test development; and language \nprocessing tools. The growth of DSLs has been \nfacilitated by increasingly powerful gram-\nmar-driven tools that, given a language defi-\nnition, can generate a graphical user interface, \nsyntax checkers, code generators, compilers \nand linkers for the specialized language.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 92", "position": 92, "chunk_type": "semantic", "token_estimate": 207}
{"text": "SOFTWARE DESIGN   3-11: 4.6. Design Rationale\b\n[3* c16] [4* c12] \n\b\n[21* c6.1]\nA useful design outcome is insight into and \nexplicit documentation of the major decisions \ntaken, along with an explanation of the ratio-\nnale for each decision. Design rationale cap-\ntures why a design decision was made. This \nincludes prior assumptions made, alternatives \nconsidered, and trade-offs and criteria ana-\nlyzed to select one approach and reject others. Although the reasons for decisions are likely \nto be obvious to the current design team, they \ncan be less obvious to those who modify or main-\ntain the system after deployment. Recording the \nrationale enhances the software product\u2019s long-\nterm maintainability. Continuing to capture \nthe rationale for changes during maintenance \nalso contributes to the software\u2019s viability. It can also be useful to capture rejected deci-\nsions and the reasons for rejection. Capturing \nthese rationales can enable a team to revisit \na previously rejected decision when assump-\ntions, requirements or constraints change. The \nimportance of rationale is visible, for example, \nin free and open-source software (FOSS) \nprojects, which often involve large, distributed \nteams of developers with frequent turnover. Design rationale may be captured as part \nof a software design description or as a com-\npanion artifact. Often rationale is captured in \ntext, but other forms of representation can also \nbe used, such as graphs that portray a design \nas an interconnected network of decisions. 5. Software Design Strategies and Methods \n\b\n[21* c3]\nVarious strategies and methods exist to struc-\nture and guide the design process; many of \nthese evolved from programming styles or \nparadigms. In addition to embodying one or \nmore general strategies, most design methods \nfocus on making one or more design concepts \n(whether objects, methods or events) promi-\nnent as organizing themes for the software. These themes then guide the designers as to \nwhat to focus on first, how to proceed, and \nhow to structure modules. 5.1. General Strategies\b\n[4* c13]\nSome often-cited examples of general strategies \nuseful in the design process include divide-and-\nconquer and stepwise refinement strategies; top-\ndown vs. bottom-up strategies; strategies using \nheuristics, patterns and pattern languages; and \niterative and incremental approaches. 5.2. Function-Oriented (or Structured)  \nDesign\b\n[4* c9]\nThis is one of the classical software design \nmethods. It focuses on refinement (or decom-\nposition) to identify major software func-\ntions, elaborating them in a top-down manner.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 93", "position": 93, "chunk_type": "semantic", "token_estimate": 392}
{"text": "SOFTWARE DESIGN   3-11: Function-Oriented (or Structured)  \nDesign\b\n[4* c9]\nThis is one of the classical software design \nmethods. It focuses on refinement (or decom-\nposition) to identify major software func-\ntions, elaborating them in a top-down manner. Structured design often follows structured anal-\nysis, producing DFDs and associated process \ndescriptions. Various tools enable the automated \ntranslation of DFDs into high-level designs. 5.3. Data-Centered Design\b\n[4* c9]\nData-centered design starts from the data \nstructures a program manipulates rather than \nfrom the functions it performs. The software \ndesigner specifies the input and output data \nstructures and then develops program units \nthat transform inputs into outputs. Various \nheuristics have been proposed to deal with spe-\ncial cases, such as cases where there is a mis-\nmatch between the input and output structures. 5.4. Object-Oriented Design\b\n[4* c10]\nNumerous software design methods based \non objects have been proposed. The field \nhas evolved from the early object-oriented \ndesign of the mid-1980s (where nouns depict \nobjects; verbs depict methods; and adjec-\ntives depict attributes), where inheritance \nand polymorphism play key roles, to the field \nof component-based design (CBD), where \nmetainformation can be defined and accessed \n(through reflection, for example). Although \nOOD\u2019s roots stem from the concept of data \nabstraction, responsibility-driven design has \nbeen proposed as an alternative underlying \nprinciple of OOD. Often design strategies", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 93", "position": 93, "chunk_type": "semantic", "token_estimate": 218}
{"text": "3-12   SWEBOK \u00ae GUIDE V4.0: are provided with mnemonics such as SOLID \n(Single-responsibility, Open\u2013closed, Liskov \nsubstitution, \nInterface \nsegregation, \nand \nDependency inversion) principles of class \ndesign and SOFA (Short, One thing, Few \narguments and Abstraction level consistency) \nprinciples for method design. 5.5. User-Centered Design\b\n[3* c9] [16]\nUser-centered design is more than a design \nmethod; it is a multidisciplinary approach \nemphasizing a deep understanding of users \nand their needs as the basis for designing user \nexperiences within the context of their orga-\nnization and the tasks to be accomplished. It \ninvolves gathering user requirements, creating \na user flow of tasks and decisions, creating \nprototypes or mockups representative of user \ninterfaces, and evaluating the design solution \nagainst original requirements [16]. 5.6. Component-Based Design (CBD) \n\b\n[4* c11, c16] [21* c16]\nCBD decomposes a software system into one \nor more standalone components that com-\nmunicate only on well-defined interfaces and \nconform to a system-wide standard com-\nponent model. A software component is an \nindependent unit, having well-defined inter-\nfaces and dependencies that can be composed \nand deployed independently. CBD addresses \nissues related to providing, developing and \nintegrating such components to improve \nreuse. CBD often emphasizes common APIs \nfor all components and specialized APIs for \nspecific services or responsibilities. 5.7. Event-Driven Design\b\n[14, 15]\nEvent-driven design is an approach where a \nsystem or component invokes its operations in \nreaction to events (indirect invocation) [15]. Publish/subscribe messaging (broadcasting) \nis often used as means of transporting events \nvia the network to all interested subscribers. Publish/subscribe keeps the producers and \nconsumers decoupled using a message broker \nwith channels called topics. This differs from \nPoint-to-point messaging where senders and \nreceivers need to know each other to deliver \nand receive a message. Different types of \nevent processing exist, i.e. simple event pro-\ncessing, event stream processing and complex \nevent processing. Message-based systems \nfrequently incorporate identifiable senders \nand receivers within the design. Event-\ndriven systems may not identify senders and \nreceivers explicitly\u2014instead each module \nproduces events while listening for any events \nthey care about or need to respond to [14]. \u201cAnonymous\u201d asynchronous message and \nevent processing are good strategies for scal-\nable systems. 5.8. Aspect-Oriented Design (AOD)\b\n[12]\nAOD is a method by which software is con-\nstructed using aspects to implement the cross-\ncutting concerns and extensions identified in \nsoftware requirements [12]. AOD evolved \nfrom object-oriented design and program-\nming practices.", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Design Principles", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 94", "position": 94, "chunk_type": "semantic", "token_estimate": 392}
{"text": "3-12   SWEBOK \u00ae GUIDE V4.0: Aspect-Oriented Design (AOD)\b\n[12]\nAOD is a method by which software is con-\nstructed using aspects to implement the cross-\ncutting concerns and extensions identified in \nsoftware requirements [12]. AOD evolved \nfrom object-oriented design and program-\nming practices. Although it has yet to become \na widespread design or programming para-\ndigm, the aspect-oriented perspective is fre-\nquently used in application frameworks and \nsoftware libraries where parameters of the \nframework or library can be configured with \naspect declarations. 5.9. Constraint-Based Design\b\n[3* c11]\nConstraints\u2019 role in the design process is to \nlimit the size of a design space to exclude infea-\nsible or unacceptable alternatives. Constraints \naccelerate design because they force a few early \ndecisions. The constraints can reflect limits \nimposed on the hardware, software, data, \noperational procedures, interfaces or anything \nthat affects the software. The constrained \ndesign space can then be explored with search \nor backtracking methods. Constraint-based \ndesign approaches are used in user interface \ndesign, gaming and other applications. In \ngeneral, constraint satisfaction problems can \nbe computationally intractable; however, var-\nious kinds of constraint-based programming", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 94", "position": 94, "chunk_type": "semantic", "token_estimate": 181}
{"text": "SOFTWARE DESIGN   3-13: can be used to approximate or solve con-\nstraint problems. 5.10. Domain-Driven Design\b\n[14]\nDomain-driven design is a method in which \nthe designer uses a domain-specific language \nshared with analysts and other stakeholders to \ndescribe the target software system. Through \nthis shared language, objects, roles, events, \nand activities specified in the software require-\nments can be expressed in the software design \ndescriptions. (See the Requirements KA). 5.11. Other Methods\b\n[21* c18\u2013c21]\nOther approaches to design exist (see Software \nEngineering Models and Methods KA). For example, iterative and adaptive methods \nimplement software increments and reduce \nthe emphasis on rigorous software require-\nments and design. Service-oriented methods builds distrib-\nuted software using web services executed on \ndistributed computers. Software systems are \noften constructed using services from different \nproviders interconnect with standard proto-\ncols (e.g., HTTP, HTTPS, SOAP) designed \nto support service communication and service \ninformation exchange. 6. Software Design Quality Analysis and \nEvaluation\b\n[4* c7] [21* c24]\n6.1. Design Reviews and Audits\b\n[4* c5.3]\nDesign reviews are intended as compre-\nhensive examinations of a design to assess \nconcerns such as status or degree of com-\npletion, coverage of requirements, open or \nunresolved issues and potential problems. A \ndesign review can be undertaken at any stage \nof design. Design reviews can be conducted \nby the design team, by an independent third \nparty or other stakeholder. A design audit is \nmore narrowly focused on a set list of char-\nacteristics (e.g., a functional audit). (See also \nsection 2.3 Reviews and Audits in Software \nQuality KA). 6.2. Quality Attributes\b\n[21* c24]\nVarious attributes contribute to the quality of \na software design, including various \u201cilities\u201d \n(modularity, maintainability, portability, test-\nability, usability) and \u201cnesses\u201d (correctness, \nrobustness). Qualities are a major subset of \nconcerns (see topic Stakeholders and Concerns \nin Software Architecture KA). Some qualities \ncan be observed at runtime (e.g., performance, \nsecurity, availability, functionality, usability); \nothers cannot (e.g., modifiability, portability, \nreusability, testability); some (e.g., concep-\ntual integrity, correctness, completeness) are \nobservable in the design of the software. 6.3. Quality Analysis and Evaluation \nTechniques\b\n[21* c24]\nVarious tools and techniques can help in ana-\nlyzing and evaluating software design quality. (See also topic Software Quality Tools in \nSoftware Quality KA.) \u2022\t Software design reviews include informal \nand rigorous techniques to determine \nsoftware qualities based on SDDs and \nother design artifacts for example, archi-\ntecture reviews, design reviews and \ninspections; scenario-based techniques; \nrequirements tracing.", "domains": ["Architectural Patterns and Styles", "Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 95", "position": 95, "chunk_type": "semantic", "token_estimate": 398}
{"text": "SOFTWARE DESIGN   3-13: (See also topic Software Quality Tools in \nSoftware Quality KA.) \u2022\t Software design reviews include informal \nand rigorous techniques to determine \nsoftware qualities based on SDDs and \nother design artifacts for example, archi-\ntecture reviews, design reviews and \ninspections; scenario-based techniques; \nrequirements tracing. \u2022\t Static analysis: formal or semiformal static \n(nonexecutable) analysis that can be used \nto evaluate a design (for example, fault-\ntree analysis or automated cross-checking). Design vulnerability analysis (for example, \nstatic analysis for security weaknesses) \ncan be performed if security is a concern. Formal design analysis uses mathemat-\nical models that allow designers to predict \nthe behavior and validate the performance \nof the software instead of having to rely \nentirely on testing. Formal design anal-\nysis can be used to detect residual speci-\nfication and design errors (perhaps caused \nby imprecision, ambiguity, and sometimes \nother kinds of mistakes). (See also Software \nEngineering Models and Methods KA.) \u2022\t Simulation and prototyping: dynamic", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 95", "position": 95, "chunk_type": "semantic", "token_estimate": 157}
{"text": "3-14   SWEBOK \u00ae GUIDE V4.0: techniques to evaluate a design (for \nexample, performance simulation or fea-\nsibility prototypes). 6.4. Measures and Metrics \n\b\n[4* c5, c17] [21* c24.5]\nMeasures can be used to assess or to quanti-\ntatively estimate various aspects of a software \ndesign; for example, size, structure, or quality. Most measures that have been proposed are \nbased upon the approach used for producing \nthe design (see topic 5 Software Design \nStrategies and Methods). These measures are \nclassified in two broad categories: \n\u2022\t Function-based (structured) design mea-\nsures: measures obtained by analyzing \nfunctional decomposition; generally rep-\nresented using a structure chart (or hierar-\nchical diagram) on which various measures \ncan be calculated. \u2022\t Object-oriented design measures: the \ndesign structure is typically represented \nas a class diagram, on which various mea-\nsures can be computed. Measures on \nthe properties of the internal content of \neach class can also be calculated. Object-\noriented measures also consider the com-\nplexity of the code based on the lines of \ncode per method or the number of mes-\nsages sent. 6.5. Verification, Validation, and Certification \n\b\n[21* c7, c8]\nSystematic analysis or evaluation of the design \nplays an important role in each of these \nthree areas:\n\u2022\t verification: to confirm that the design \nsatisfies stated requirements;\n\u2022\t validation: to establish that the design will \nallow the system to meet the expectations \nof its stakeholders, including customers, \nusers, operators and maintainers;\n\u2022\t certification: third-party attestation of \nconformity of design to its overall spec-\nification and intended usage. (See also section 2.2 Verification and \nValidation in Software Quality KA.) MATRIX OF TOPICS VS. REFERENCE MATERIAL\nIn table below, cX means chapter X\n1. Software Design \nFundamentals\nBrooks  \n[3*]\nBudgen  \n[4*]\nGamma et al. [7*]\nSommerville \n \n[21*]\nSee also\n1.1 Design Thinking\nc1, c2, c3\nc1, c2\n[20]\n1.2  Context of Software Design\nc13, c14\nc19, c20\n1.3 Key Issues in Software Design\n[2, 12]\n1.4 Software Design Principles\n[5, 10,  \n17, 20]\n2. Software Design Processes\nc3\nc2, c7\n[10]\n2.1 High-level Design\nc5\nc6\n[10]\n2.2 Detailed Design\n[10]\n3. Software Design Qualities\nc4\n[20]\n3.1 Concurrency\nc17\n3.2 Control and \nHandling of Events\nc21\n3.3 Data Persistence\nc6, c16", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 96", "position": 96, "chunk_type": "semantic", "token_estimate": 365}
{"text": "SOFTWARE DESIGN   3-15: 3.4 Distribution of Components\nc17\n3.5 Errors and Exception \nHandling, Fault Tolerance\nc11\n3.6 Integration and \nInteroperability\nc11, c14,  \nc16\n3.7 Assurance, Security and Safety\nc10\u2013c14\n3.8 Variability\n[6]\n4. Recording \nSoftware Designs\nc7, c8\n[1]\n4.1 Model-based Design\nc7.3\nc5.5\n4.2 Structural Design \nDescriptions\nc7, c10\nc4\nc5.3\n4.3 Behavioral Design \nDescriptions\nc9, c10\nc5\nc5.4\n4.4 Design Patterns and Styles\nc12\nc15\nc1, c2\nc7.2\n[7]\n4.5 Specialized and Domain-\nSpecific Languages\nc15\n4.6 Design Rationale\nc16\nc12\nc6.1\n5. Software Design Strategies \nand Methods\nc3\n5.1 General Strategies\nc13\n5.2 Function-Oriented (or \nStructured) Design\nc9\n5.3 Data-Centered Design\nc9\n5.4 Object-Oriented Design\nc10\n5.5 User-Centered Design\nc9\n[16]\n5.6 Component-Based \nDesign (CBD)\nc11, c16\nc16\n5.7 Event-Driven Design\n[14, 15]\n5.8 Aspect-Oriented Design (AOD)\n[12]\n5.9 Constraint-Based Design\nc11\n5.10 Domain-Driven Design\n[13]\n5.11 Other Methods\nc18\u2013c21\n6. Software Design Quality \nAnalysis and Evaluation\nc17\nc24\n6.1 Design Reviews and Audits\nc5.3\n6.2 Quality Attributes\nc24\n6.3 Quality Analysis and \nEvaluation Techniques\nc24\n6.4 Measures and Metrics\nc5, c17\nc24.5\n6.5 Verification, Validation and \nCertification\nc7,c8", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 97", "position": 97, "chunk_type": "semantic", "token_estimate": 182}
{"text": "Application: Programming Interface", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 100", "position": 100, "chunk_type": "semantic", "token_estimate": 3}
{"text": "Section: Graphical User Interface", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 100", "position": 100, "chunk_type": "semantic", "token_estimate": 4}
{"text": "Section: Node Package Manager", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 100", "position": 100, "chunk_type": "semantic", "token_estimate": 4}
{"text": "Portable Operating: System Interface", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 100", "position": 100, "chunk_type": "semantic", "token_estimate": 4}
{"text": "SOFTWARE CONSTRUCTION   4-3: of software construction; changes in the \nenvironments in which software oper-\nates also affect software in diverse ways. Anticipating change helps software engi-\nneers build extensible software, enhancing \na software product without disrupting the \nunderlying structure. Anticipating change \nis supported by many specific techniques \n(see section 3.3, Coding). Moreover, today\u2019s business environments \nrequire many organizations to deliver and \ndeploy software more frequently, faster and \nmore reliably. Anticipating specific, nec-\nessary changes can be difficult, so soft-\nware engineers should be careful to build \nflexibility and adaptability into the soft-\nware to incorporate changes with less diffi-\nculty. These software teams should embrace \nchange by adopting agile development, \npracticing DevOps, and by adopting con-\ntinuous delivery and deployment practices. Such practices align the software develop-\nment process and management with an evo-\nlutionary environment. Software\nConstruction\nSoftware\nConstruction\nFundamentals\nMinimizing\nComplexity\nAnticipating and \nEmbracing Change\nConstruction for \nVerifcation\nReusing Assets\nApplying Standards \nin Construction\nConstruction in \nLife Cycle Models\nConstruction \nPlanning\nConstruction \nMeasurements\nManaging\nDependencies\nConstruction \nDesign\nConstruction \nLanguages\nCoding\nConstruction \nTesting\nReuse in\nConstruction\nConstruction \nQuality\nIntegration\nCross-Platform\nDevelopment \nand Migration \nAPI Design \nand Use\nObject-Oriented \nRuntime Issues\nParameterization,\nTemplates and\nGenerics\nAssertions,\nDesign by Contract \nand Defensive \nProgramming\nError Handling,\nException Handling\nand Fault Tolerance\nExecutable Models\nState-Based and \nTable-Driven \nConstruction Techniques\nRuntime Confguration and\nInternationalization\nGrammar-Based\nInput Processing\nConcurrency Primitives\nMiddleware\nConstruction Methods\nfor Distribution and\nCloud-Based Software\nConstructing\nHeterogeneous Systems\nPerformance Analysis\nand Tuning\nPlatform Standards\nTest-First Programming\nFeedback Loop \nfor Construction\nDevelopment\nEnvironments\nVisual Programming\nand Low-Code/\nZero-Code Platforms\nUnit Testing Tools\nProofng, Performance\nAnalysis and Slicing Tools\nManaging\nConstruction\nPractical\nConsiderations\nConstruction\nTechnologies\nSoftware\nConstruction\nTools\nFigure 4.1. Breakdown of Topics for the Software Construction KA", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 102", "position": 102, "chunk_type": "semantic", "token_estimate": 284}
{"text": "4-4   SWEBOK \u00ae GUIDE V4.0: 1.3. Constructing for Verification \b\n[1-c8, \n\b\nc20-c23, c31, c34]\nConstructing for verification builds software in \nsuch a way that faults can be readily found by \nthe software engineers writing the software as \nwell as by the testers and users during inde-\npendent testing and operational activities. Specific techniques that support constructing \nfor verification include following coding \nstandards to support code reviews and unit \ntesting, organizing code to support automated \ntesting, restricting the use of complex or dif-\nficult-to-understand language structures, and \nrecording software behaviors with logs. 1.4. Reusing Assets \b\n[2-c15]\nReuse means using existing assets to solve dif-\nferent problems. In software construction, \ntypical assets that are reused include frame-\nworks, libraries, modules, components, source \ncode and commercial off-the-shelf (COTS) \nassets. Reuse has two closely related facets: \nconstruction for reuse and construction with reuse. The former means creating reusable software \nassets, whereas the latter means reusing soft-\nware assets to construct a new solution. Reuse \noften transcends project boundaries, which \nmeans reused assets can be constructed in \nother projects or organizations. 1.5. Applying Standards in Construction \b [1-c4]\nApplying external or internal development \nstandards during construction helps achieve \na project\u2019s efficiency, quality and cost objec-\ntives. Specifically, the choices of allowable \nprogramming language subsets and usage \nstandards are important aids in achieving \nhigher security. Standards that directly affect construction \nissues include the following:\n\u2022\t Communication methods (e.g., standards \nfor document formats and content)\n\u2022\t Programming languages (e.g., standards \nfor languages like Java and C++)\n\u2022\t Coding \nstandards \n(e.g., \nstandards \nfor naming conventions, layout and \nindentation)\n\u2022\t Exception handling policies (e.g., stan-\ndards for the information included in \nexceptions and the way how exceptions \nare handled after catching)\n\u2022\t Platforms (e.g., interface standards for \noperating system calls)\n\u2022\t Tools (e.g., diagrammatic standards \nfor notations like UML - Unified \nModeling Language)\nUse of external standards: Construction \ndepends on external standards for construction \nlanguages, construction tools, technical inter-\nfaces and interactions between the Software \nConstruction KA and other KAs. Standards \ncome from numerous sources, including \nhardware and software interface specifica-\ntions (e.g., OMG - Object Management \nGroup) \nand \ninternational \norganizations \n(e.g., IEEE - the Institute of Electrical and \nElectronics Engineers, ISO - the International \nOrganization for Standardization). Use of internal standards: Standards may \nalso be created on an organizational basis at the \ncorporate level or for use on specific projects.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 103", "position": 103, "chunk_type": "semantic", "token_estimate": 394}
{"text": "4-4   SWEBOK \u00ae GUIDE V4.0: Standards \ncome from numerous sources, including \nhardware and software interface specifica-\ntions (e.g., OMG - Object Management \nGroup) \nand \ninternational \norganizations \n(e.g., IEEE - the Institute of Electrical and \nElectronics Engineers, ISO - the International \nOrganization for Standardization). Use of internal standards: Standards may \nalso be created on an organizational basis at the \ncorporate level or for use on specific projects. These standards support coordinating group \nactivities, minimizing complexity, anticipating \nchange and constructing for verification. 2. Managing Construction\n2.1. Construction in Life Cycle Models  \n\b\n[1-c2, c3, c27, c29, 2-c3, c7, 3-c1]\nNumerous models have been created to \ndevelop software; some emphasize construc-\ntion more than others. Some models are more linear from the \nconstruction viewpoint, such as the water-\nfall and staged-delivery life cycle models. These models treat construction as an activity \nthat occurs only after the completion of sig-\nnificant prerequisite work, including detailed \nrequirements work, extensive design work and \ndetailed planning. The more linear approaches \nemphasize the activities that precede con-\nstruction (requirements and design) and create", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 103", "position": 103, "chunk_type": "semantic", "token_estimate": 175}
{"text": "SOFTWARE CONSTRUCTION   4-5: more distinct separations between activities. In these models, construction\u2019s main emphasis \nmight be coding. Other models, such as evolutionary proto-\ntyping and agile development, are more iter-\native. These approaches treat construction as \nan activity that occurs concurrently with or \noverlaps other software development activi-\nties (including requirements, design and plan-\nning). These approaches mix design, coding \nand testing activities, and they often treat the \ncombination of activities as construction (see \nthe Software Engineering Management and \nSoftware Process KAs). The practices of continuous delivery and \ndeployment further mix coding, testing, \ndelivery and deployment activities. In these \npractices, software updates made during con-\nstruction activities are continuously delivered \nand deployed into the production environ-\nment. The whole process is fully automated \nby a deployment pipeline that consists of var-\nious testing and deployment activities. Consequently, what is considered construc-\ntion depends on the life cycle model used. In general, software construction is mostly \ncoding and debugging, but it also involves \nconstruction planning, detailed design, unit \ntesting, integration testing and other activities. 2.2. Construction Planning \b\n[1-c3, c4, \n \n\b\nc21, c27-c29]\nThe choice of construction method is a key \naspect of the construction planning activity. This choice affects the extent to which con-\nstruction prerequisites are performed, the \norder in which they are performed and the \ndegree to which they should be completed \nbefore construction work begins. The approach to construction affects the \nproject team\u2019s ability to reduce complexity, \nanticipate change and construct for verifica-\ntion. Each objective may also be addressed at \nthe process, requirements and design levels, \nbut the choice of construction method will \ninfluence them. Construction planning also defines the \norder in which components are created and \nintegrated, the integration strategy (for \nexample, phased or incremental integration), \nthe software quality management processes, \nthe allocation of task assignments to specific \nsoftware engineers, and other tasks, according \nto the chosen method. 2.3. Construction Measurement \b\n[1-c25, c28]\nNumerous construction activities and arti-\nfacts can be measured, including code devel-\noped, modified, reused, and destroyed; code \ncomplexity; code inspection statistics; fault-fix \nand fault-find rates; effort; and scheduling. These measurements can be useful for man-\naging construction, ensuring quality during \nconstruction and improving the construc-\ntion process, among other uses (see the \nSoftware Engineering Process KA for more \non measurement). 2.4.", "domains": ["Design Patterns", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 104", "position": 104, "chunk_type": "semantic", "token_estimate": 381}
{"text": "SOFTWARE CONSTRUCTION   4-5: These measurements can be useful for man-\naging construction, ensuring quality during \nconstruction and improving the construc-\ntion process, among other uses (see the \nSoftware Engineering Process KA for more \non measurement). 2.4. Managing Dependencies \b\n[2-c25]\nSoftware products often heavily rely on depen-\ndencies, including internal and external (com-\nmercial or open-source) dependencies, which \nallow developers to reuse common functional-\nities instead of reinventing the wheel and sub-\nstantially improve developers\u2019 productivity. In \naddition, package managers (e.g., Maven in \nJava and NPM in JavaScript) are widely used to \nautomate the process of installing, upgrading, \nconfiguring and removing dependencies. The direct and indirect dependencies of \nsoftware products constitute a dependency \nsupply chain network. Any dependency in the \nsupply chain network can introduce poten-\ntial risk to software products and should be \nmanaged by developers or tools. Unnecessary \ndependencies should be avoided to improve \nbuild efficiency. License conflicts between \ndependencies and software products should \nbe avoided to reduce legal risk. Propagation \nof dependencies\u2019 defects or vulnerabilities into \nsoftware products should be avoided to improve \nthe quality of software products. Regulations \nand monitoring mechanisms should be devel-\noped to prevent developers from introducing \nuntrusted external dependencies.", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 104", "position": 104, "chunk_type": "semantic", "token_estimate": 197}
{"text": "4-6   SWEBOK \u00ae GUIDE V4.0: 3. Practical Considerations\nConstruction is an activity in which the soft-\nware engineer often has to deal with some-\ntimes chaotic, changing and even conflicting \nreal-world constraints. Because of real-world \nconstraints, practical considerations drive \nconstruction more than some other KAs, and \nsoftware engineering is perhaps most craft-\nlike in the construction activities compared \nwith other activities. 3.1. Construction Design\b [1-c3, c5, c24, 2-c7]\nSome projects allocate considerable design \nactivity to construction, whereas others allo-\ncate design to a phase explicitly focused on \ndesign. Regardless of the exact allocation, \nsome detailed design work occurs at the con-\nstruction level, and that design work is dic-\ntated by constraints imposed by the real-world \nproblem the software addresses. Just as construction workers building a \nphysical structure must make small modifi-\ncations for unanticipated gaps in the builder\u2019s \nplans, software construction workers must \nmake small or large modifications to flesh out \nsoftware design details during construction. The details of the design activity at the \nconstruction level are essentially the same as \ndescribed in the Software Design KA, but \nthey are applied at a smaller scale to algo-\nrithms, data structures and interfaces. 3.2. Construction Languages \b\n[1-c4]\nConstruction languages include all forms \nof communication by which a human can \nspecify an executable solution to a problem. Consequently, construction languages and \ntheir implementations (e.g., compilers) can \naffect software quality attributes such as per-\nformance, reliability and portability. As a \nresult, they can seriously contribute to secu-\nrity vulnerabilities. The simplest construction language is a \nconfiguration language, in which software \nengineers choose from a limited set of pre-\ndefined options to create new or custom \nsoftware installations. The text-based config-\nuration files used in both the Windows and \nUnix operating systems are examples of this, \nand some program generators\u2019 menu-style \nselection lists constitute another example of a \nconfiguration language. Toolkit languages are used to build appli-\ncations from elements in toolkits (integrated \nsets of application-specific reusable parts); \nthey are more complex than configuration \nlanguages. Toolkit languages may be explic-\nitly defined as application programming lan-\nguages, or the applications might be implied \nby a toolkit\u2019s set of interfaces. Scripting languages are commonly used \napplication programming languages. In some \nscripting languages, scripts are called batch \nfiles or macros. Programming languages are the most flex-\nible construction languages. They also contain \nthe least amount of information about specific \napplication areas and development processes.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 105", "position": 105, "chunk_type": "semantic", "token_estimate": 400}
{"text": "SOFTWARE CONSTRUCTION   4-7: definitions. Formal construction notations \nand methods are at the semantic base of most \nsystem programming notations, where accu-\nracy, time behavior and testability are more \nimportant than ease of mapping into natural \nlanguage. Formal constructions also use pre-\ncisely defined ways of combining symbols that \navoid the ambiguity of many natural language \nconstructions. Visual notations rely much less on the \ntextual notations of linguistic and formal \nconstruction and more on direct visual inter-\npretation and placement of visual entities that \nrepresent the underlying software. Visual \nconstruction is somewhat limited by the dif-\nficulty of making \u201ccomplex\u201d statements using \nonly the arrangement of icons on a display. However, these icons can be powerful tools \nin cases where the primary programming task \nis to build and \u201cadjust\u201d a visual interface to a \nprogram, the detailed behavior of which has \nan underlying definition. Nowadays, \ndomain-specific \nlanguages \n(DSLs) are widely used to build domain-spe-\ncific applications. Unlike a general-pur-\npose programming language, such as C/C++ \nor Java, a DSL is designed for the applica-\ntion construction of a particular domain. Therefore, a DSL usually can be defined \nbased on a higher level of abstraction of the \ntarget domain and can be optimized for a \nspecific class of problems. Furthermore, A \nDSL usually can be expressed by visual nota-\ntions defined by domain-specific concepts \nand rules. 3.3. Coding \b\n[1-c5-c19, c25-c26]\nThe following considerations apply to the \nsoftware construction coding activity:\n\u2022\t Techniques for creating understandable \nsource code, including naming conven-\ntions and source code layout\n\u2022\t Use of classes, enumerated types, vari-\nables, named constants and other sim-\nilar entities\n\u2022\t Use of control structures \n\u2022\t Handling of error conditions \u2014 both \nanticipated and exceptional (e.g., input \nof bad data)\n\u2022\t Prevention \nof \ncode-level \nsecurity \nbreaches (e.g., buffer overflows or array \nindex bounds)\n\u2022\t Resource use through use of exclusion \nmechanisms and discipline in accessing \nserially reusable resources, including \nthreads and database locks\n\u2022\t Source code organization into state-\nments, routines, classes, packages or \nother structures\n\u2022\t Code documentation\n\u2022\t Code tuning\n3.4. Construction Testing \b\n[1-c22, c23, 2-c8]\nConstruction involves two forms of testing, \nwhich are often performed by the software \nengineer who wrote the code: unit testing and \nintegration testing. Construction testing aims to reduce the gap \nbetween when faults are inserted into the code \nand when those faults are detected, thereby \nreducing the cost incurred to fix them.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 106", "position": 106, "chunk_type": "semantic", "token_estimate": 400}
{"text": "4-8   SWEBOK \u00ae GUIDE V4.0: Construction for reuse creates software \nwith the potential to be reused in the future \nfor the present project or for other projects \nwith a broad-based, multisystem perspec-\ntive. Construction for reuse is usually based \non variability analysis and design. To avoid \nthe problem of code clones, developers should \nencapsulate reusable code fragments into \nwell-structured libraries or components. The tasks related to software construc-\ntion for reuse during coding and testing are \nas follows:\n\u2022\t Variability implementation with mech-\nanisms such as parameterization, condi-\ntional compilation and design patterns\n\u2022\t Variability \nencapsulation \nto \nmake \nthe software assets easy to configure \nand customize\n\u2022\t Testing the variability provided by the \nreusable software assets\n\u2022\t Description and publication of reusable \nsoftware assets\nConstruction with reuse means creating \nnew software by reusing existing software \nassets. The most popular reuse method is \nto reuse code from the libraries provided by \nthe language, platform, tools or an organi-\nzational repository. Aside from these, many \napplications developed today use open-source \nlibraries. In addition, reused and off-the-\nshelf software often have the same (or better) \nquality requirements as newly developed soft-\nware (e.g., security level requirements). The tasks related to software construc-\ntion with reuse during coding and testing are \nas follows:\n\u2022\t Selecting reusable units, databases, test \nprocedures or test data\n\u2022\t Evaluating code or test reusability\n\u2022\t Integrating reusable software assets into \nthe current software\n\u2022\t Reporting reuse information on new \ncode, test procedures or test data\nThe forms of reusable software assets are \nnot limited to software artifacts that must be \nlocally integrated. Nowadays, cloud services \nthat provide various services through online \ninterfaces such as RESTful application pro-\ngramming interfaces (APIs) are widely used in \napplications. In the new cloud service model \nBaaS (backend as a service), applications del-\negate their backend implementations to cloud \nservice providers \u2014 for example, utilities such \nas authentication, messaging and storage are \nusually provided by cloud providers. Reuse is best practiced systematically, \naccording to a well-defined, repeatable pro-\ncess. Systematic reuse can enable signifi-\ncant software productivity, quality and cost \nimprovements. Systematic reuse is supported \nby methodologies such as software product \nline engineering and various software frame-\nworks and platforms. Widely used frameworks \nsuch as Spring provide reusable infrastruc-\ntures for enterprise applications so soft-\nware teams can focus on application-specific \nbusiness logic.", "domains": ["Software Quality Attributes", "Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 107", "position": 107, "chunk_type": "semantic", "token_estimate": 389}
{"text": "4-8   SWEBOK \u00ae GUIDE V4.0: Systematic reuse is supported \nby methodologies such as software product \nline engineering and various software frame-\nworks and platforms. Widely used frameworks \nsuch as Spring provide reusable infrastruc-\ntures for enterprise applications so soft-\nware teams can focus on application-specific \nbusiness logic. Commercial platforms pro-\nvide various reusable frameworks, libraries, \ncomponents and tools to support application \ndevelopment to build their ecosystems. 3.6. Construction Quality \b\n[1-c8, c20-c25, \n\b\n2-c8, c24]\nIn addition to faults occurring during require-\nments and design activities, faults introduced \nduring construction can cause serious quality \nproblems (e.g., security vulnerabilities). These \ninclude not only faults in security function-\nality but also faults elsewhere that allow \nbypassing of the security functionality or \ncreate other security weaknesses or violations. Numerous techniques exist to ensure the \nquality of code as it is constructed. The pri-\nmary techniques used to ensure construction \nquality are the following:\n\u2022\t Unit testing and integration testing (see \nsection 3.4, Construction Testing)\n\u2022\t Test-first development (see section 6.1.2 \nin the Software Testing KA)\n\u2022\t Use \nof \nassertions \nand \ndefensive \nprogramming\n\u2022\t Debugging", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 107", "position": 107, "chunk_type": "semantic", "token_estimate": 181}
{"text": "SOFTWARE CONSTRUCTION   4-9: \u2022\t Inspections\n\u2022\t Technical reviews, including securi-\nty-oriented reviews (see section 2.3 in the \nSoftware Quality KA)\n\u2022\t Static analysis (see section 2.2.1 of the \nSoftware Quality KA)\nThe specific technique or techniques \nselected depend on the software constructed \nand on the skill set of the software engi-\nneers performing the construction activities. Programmers should know good practices and \ncommon vulnerabilities (e.g., from widely rec-\nognized lists about common vulnerabilities). Automated static code analysis for security \nweaknesses is available for several common \nprogramming languages and can be used in \nsecurity-critical projects. Construction quality activities are dif-\nferentiated from other quality activities by \ntheir focus. These activities focus on arti-\nfacts that are closely related to code \u2014 such \nas detailed design \u2014 as opposed to other \nartifacts that are less directly connected to \nthe code, such as requirements, high-level \ndesigns and plans. 3.7. Integration \b\n[1-c29, 2-c8, 3-c11]\nDuring construction, a key activity is inte-\ngrating individually constructed routines, \nclasses, components and subsystems into a \nsingle system. In addition, a particular soft-\nware system may need to be integrated with \nother software or hardware systems. Concerns related to construction integra-\ntion include planning the sequence in which \ncomponents are integrated, identifying what \nhardware is needed, creating scaffolding to \nsupport interim versions of the software, \ndetermining the degree of testing and quality \nwork performed on components before they \nare integrated, and determining points in the \nproject at which interim versions of the soft-\nware are tested. Programs can be integrated by means \nof either the phased or the incremental \napproach. Phased integration, also called \nbig bang integration, entails delaying the \nintegration of component software parts until \nall parts intended for release in a version are \ncomplete. Incremental integration is thought \nto offer many advantages over the traditional \nphased integration (e.g., easier error loca-\ntion, improved progress monitoring, earlier \nproduct delivery and improved customer rela-\ntions). In incremental integration, the devel-\nopers write and test a program in small pieces \nand then combine the pieces one at a time. Additional test infrastructure, including, for \nexample, stubs, drivers and mock objects, is \nusually needed to enable incremental integra-\ntion. In addition, by building and integrating \none unit at a time (e.g., a class or compo-\nnent), the construction process can provide \nearly feedback to developers and customers.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 108", "position": 108, "chunk_type": "semantic", "token_estimate": 387}
{"text": "4-10   SWEBOK \u00ae GUIDE V4.0: ways for mobile applications. One way is to \ngenerate native applications using specific \ntools that can compile the universal language \ninto platform-specific formats. The other is \nto develop hybrid applications that combine \nweb applications developed using languages \nlike hypertext markup language version 5 \n(HTML5) and cascading style sheets (CSS) \nand native containers or wrappers for various \noperations systems. For applications that are not developed in \nthis way, developers may consider migrating \nthe applications from one platform to another. The migration usually involves translation of \ndifferent programming languages and plat-\nform-specific APIs and can be partially auto-\nmated by tools. 4. Construction Technologies\n4.1. API Design and Use \b\n[5-c7]\nAn API is a set of signatures that are exported \nand available to the users of a library or a \nframework to write their applications. Besides \nsignatures, an API should always include \nstatements about the program\u2019s effects and/or \nbehaviors (i.e., its semantics). API design should make the API easy to \nlearn and memorize, lead to readable code, be \ndifficult to misuse, be easy to extend, be com-\nplete, and maintain backward compatibility. As the APIs usually outlast their implemen-\ntations for a widely used library or framework, \nan API should be straightforward and stable, \nto facilitate client application development \nand maintenance. API use involves selecting, learning, \ntesting, integrating and possibly extending \nAPIs provided by a library or framework (see \nsection 3.5, Reuse in Construction). For online interfaces such as RESTful \nAPIs, open standers such as OpenAPI play \nan important role. OpenAPI defines a stan-\ndard, language-agnostic interface to HTTP \nAPIs and supports the automatic generation \nof server-side and client-side code, covering \npopular languages such as Java, JavaScript, \nPython, etc.. At the same time, API-first \napproach has been widely used, which \nemphasizes designing and building the APIs \nof an application first. In practice, API-first \napproach is usually accomplished by using an \nAPI description language to establish a con-\ntract for how the API is supposed to behave. 4.2. Object-Oriented Runtime Issues \b [1-c6, c7]\nObject-oriented languages support run-\ntime mechanisms, including polymorphism \nand reflection. These runtime mechanisms \nincrease the flexibility and adaptability of \nobject-oriented programs. Polymorphism is a language\u2019s ability to \nsupport general operations without knowing \nuntil runtime what kind of concrete objects \nthe software will include. Because the pro-\ngram does not know the types of the objects \nin advance, the exact behavior is determined \nat runtime (called dynamic binding).", "domains": ["Design Patterns", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 109", "position": 109, "chunk_type": "semantic", "token_estimate": 404}
{"text": "SOFTWARE CONSTRUCTION   4-11: Assertions are especially useful in high-reli-\nability programs. They enable programmers to \nmore quickly flush out mismatched interface \nassumptions, errors that creep in when code is \nmodified, and other problems. Assertions are \ntypically compiled into the code at develop-\nment time and are later compiled out of the \ncode so they don\u2019t degrade the performance. Design by contract is a development approach \nin which preconditions and postconditions are \nincluded for each routine. When precondi-\ntions and postconditions are used, each rou-\ntine or class is said to form a contract with \nthe rest of the program. A contract precisely \nspecifies the semantics of a routine and thus \nhelps clarify its behavior. Design by contract \nis thought to improve the quality of software \nconstruction. Defensive programming means to protect a \nroutine from being broken by invalid inputs. Common ways to handle invalid inputs \ninclude checking the values of all the input \nparameters and deciding how to handle bad \ninputs. Assertions are often used in defensive \nprogramming to check input values. 4.5. Error Handling, Exception Handling, and \nFault Tolerance \b\n[1-c8, c9]\nHow errors are handled affects software\u2019s \nability to meet requirements related to correct-\nness, robustness and other nonfunctional attri-\nbutes. Assertions are sometimes used to check \nfor errors. Other error-handling techniques \u2014 \nsuch as returning a neutral value, substituting \nthe next piece of valid data, logging a warning \nmessage, returning an error code or shutting \ndown the software \u2014 are also used. Exceptions are used to detect and process \nerrors or exceptional events. The basic struc-\nture of an exception is as follows: A routine \nuses throw to throw a detected exception, \nand an exception-handling block will catch \nthe exception in a try-catch block. The try-\ncatch block may process the erroneous condi-\ntion or return control to the calling routine. Exception-handling policies should be care-\nfully designed following common principles, \nsuch as including in the exception message \nall information that led to the exception, \navoiding empty catch blocks, knowing the \nexceptions the library code throws, perhaps \nbuilding a centralized exception reporter, \nand standardizing the program\u2019s use of \nexceptions. Fault tolerance is a collection of techniques \nthat increase software reliability by detecting \nerrors and then recovering from them or con-\ntaining their effects if recovery is not possible.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 110", "position": 110, "chunk_type": "semantic", "token_estimate": 381}
{"text": "SOFTWARE CONSTRUCTION   4-11: Exception-handling policies should be care-\nfully designed following common principles, \nsuch as including in the exception message \nall information that led to the exception, \navoiding empty catch blocks, knowing the \nexceptions the library code throws, perhaps \nbuilding a centralized exception reporter, \nand standardizing the program\u2019s use of \nexceptions. Fault tolerance is a collection of techniques \nthat increase software reliability by detecting \nerrors and then recovering from them or con-\ntaining their effects if recovery is not possible. The most common fault tolerance strate-\ngies include backing up and retrying, using \nauxiliary code and voting algorithms, and \nreplacing an erroneous value with a phony \nvalue that will have a benign effect. 4.6. Executable Models \b\n[7]\nExecutable models abstract away the details of \nspecific programming languages and deci-\nsions about the software\u2019s organization. Different from traditional software models, \na specification built in an executable mod-\neling language like xUML (executable UML) \ncan be deployed in various software environ-\nments without change. Furthermore, an exe-\ncutable-model compiler (transformer) can \nturn an executable model into an implemen-\ntation using a set of decisions about the target \nhardware and software environment. Thus, \nconstructing executable models is a way of \nconstructing executable software. Executable models are one foundation \nsupporting the model-driven architecture \n(MDA) initiative of the OMG. An executable \nmodel is a way to specify a platform-indepen-\ndent model (PIM); a PIM is a model of a \nsolution to a problem that does not rely on any \nimplementation technologies. Then a plat-\nform-specific model (PSM), which is a model \nthat contains the details of the implementa-\ntion, can be produced by weaving together the \nPIM and the platform on which it relies. 4.7. State-Based and Table-Driven \nConstruction Techniques \b\n[1-c18]\nState-based programming, or automata-based \nprogramming, is a programming technology", "domains": ["Design Patterns", "Software Quality Attributes", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 110", "position": 110, "chunk_type": "semantic", "token_estimate": 297}
{"text": "4-12   SWEBOK \u00ae GUIDE V4.0: that uses finite-state machines to describe \nprogram behaviors. A state machine\u2019s transi-\ntion graphs are used in all stages of software \ndevelopment (specification, implementation, \ndebugging and documentation). The main \nidea is to construct computer programs in the \nsame way technological processes are auto-\nmated. State-based programming is usually \ncombined with object-oriented programming, \nforming a new composite approach called \nstate-based, object-oriented programming. A table-driven method is a schema that \nuses tables to display information rather \nthan convey information with logic state-\nments (such as if and case). When used in \nappropriate \ncircumstances, \ntable-driven \ncode is simpler than complicated logic and \neasier to modify. When using table-driven \nmethods, the programmer addresses two \nissues: what information to store in the table \nor tables and how to efficiently access infor-\nmation in the table. 4.8. Runtime Configuration and \nInternationalization \b\n[1-c3, c10]\nTo achieve more flexibility, a program is \noften constructed to support its variables\u2019 late \nbinding time. For example, runtime configu-\nration binds variable values and program set-\ntings when the program is running, usually by \nupdating and reading configuration files in a \njust-in-time mode. Internationalization is the technical activity \nof preparing a program, usually interactive \nsoftware, to support multiple locales. The cor-\nresponding activity, localization, modifies a \nprogram to support a specific local language. Interactive software may contain dozens or \nhundreds of prompts, status displays, help \nmessages, error messages and so on. The \ndesign and construction processes should \naccommodate string and character set issues, \nincluding which character set is used, what \nkinds of strings are used, how to maintain the \nstrings without changing the code and how to \ntranslate the strings into different languages \nwith minimal impact on the processing code \nand the user interface. 4.9. Grammar-Based Input Processing \b\n[1, 8]\nGrammar-based input processing \ninvolves \nsyntax analysis, or parsing, of the input token \nstream. It involves the creation of a data struc-\nture (called a parse tree or syntax tree) repre-\nsenting the input data. The inorder traversal \nof the parse tree usually gives the expres-\nsion just parsed. Next, the parser checks the \nsymbol table for programmer-defined vari-\nables that populate the tree. After building \nthe parse tree, the program uses it as an input \nto the computational processes. 4.10. Concurrency Primitives \b\n[9-c6]\nA synchronization primitive is a programming \nabstraction provided by a programming lan-\nguage or the operating system that facilitates \nconcurrency and synchronization.", "domains": ["Design Patterns", "Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 111", "position": 111, "chunk_type": "semantic", "token_estimate": 401}
{"text": "SOFTWARE CONSTRUCTION   4-13: location across a network. Middleware can \nbe viewed as a connector between the com-\nponents using the middleware. Modern mes-\nsage-oriented middleware usually provides an \nenterprise service bus (ESB) that supports ser-\nvice-oriented interaction and communication \namong multiple software applications. 4.12. Construction Methods for Distributed and \nCloud-Based Software \b\n[2-c17, c18, 9-c2]\nA distributed system is a collection of physically \nseparate, possibly heterogeneous computer \nsystems networked to provide the users with \naccess to the resources the system maintains. The construction of distributed software is \ndistinguished from traditional software con-\nstruction by issues such as parallelism, com-\nmunication and fault tolerance. Distributed programming typically falls \ninto several basic architectural categories: \nclient-server, three-tier architecture, n-tier \narchitecture, distributed objects, loose cou-\npling or tight coupling (see section 5.6 in the \nComputing Foundations KA and section 2.2 \nin the Software Architecture KA). Nowadays, more applications are migrated \nto the cloud. Cloud-based software often adopts \nmicroservice architecture and container-based \ndeployment. In addition to traditional dis-\ntributed software issues, cloud-based soft-\nware developers also need to consider cloud \ninfrastructure issues such as use of an API \ngateway, service registration and discovery. Distributed systems based on n-tier/ser-\nvice-oriented architectures usually rely on \nACID distributed transactions for the imple-\nmentation of transactions involving multiple \ndistributed components. In contrast, cloud-\nbased microservices cannot enforce distributed \ntransactions consistency, and use some form of \nSAGA-based eventual consistency, initially \nintended for long-running transactions. 4.13. Constructing Heterogeneous Systems \b [8-c9]\nHeterogeneous systems consist of various special-\nized computational units of different types, \nsuch as Graphic Processing Units (GPUs) and \nDigital Signal Processors (DSPs), micro-\ncontrollers and peripheral processors. These \ncomputational units are independently con-\ntrolled and communicate with one another. Embedded systems are typically heteroge-\nneous systems. The design of heterogeneous systems \nmay require combining several specifica-\ntion languages to design different system \nparts (hardware/software codesign). The \nkey issues include multilanguage validation, \nco-simulation and interfacing. During \nthe \nhardware/software \ncode-\nsign, software and virtual hardware develop-\nment proceed concurrently through stepwise \ndecomposition. The hardware part is usually \nsimulated in field programmable gate arrays \n(FPGAs) or application-specific integrated \ncircuits (ASICs). The software part is trans-\nlated into a low-level programming language. 4.14. Performance Analysis and Tuning  \n\b\n[1-c25, c26]\nCode efficiency \u2014 determined by architec-\nture, detailed design decisions, and data struc-\nture and algorithm selection \u2014 influences \nexecution speed and size.", "domains": ["Architectural Patterns and Styles", "Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 112", "position": 112, "chunk_type": "semantic", "token_estimate": 390}
{"text": "SOFTWARE CONSTRUCTION   4-13: 4.14. Performance Analysis and Tuning  \n\b\n[1-c25, c26]\nCode efficiency \u2014 determined by architec-\nture, detailed design decisions, and data struc-\nture and algorithm selection \u2014 influences \nexecution speed and size. Performance analysis \ninvestigates a program\u2019s behavior using infor-\nmation gathered as the program executes to \nidentify possible hot spots in the program to \nbe improved. Code tuning, which improves performance \nat the code level, modifies correct code to \nmake it run more efficiently. Code tuning \nusually involves only small changes that affect \na single class, a single routine or, more com-\nmonly, a few lines of code. A rich set of code \ntuning techniques is available, including those \nfor tuning logic expressions, loops, data trans-\nformations, expressions and routines. Using a \nlow-level language is another common tech-\nnique for improving hot spots in a program. 4.15. Platform Standards \b\n[4-c, 8-c10, 9-c1]\nPlatform standards enable programmers to \ndevelop portable applications that can be exe-\ncuted in compatible environments without", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 112", "position": 112, "chunk_type": "semantic", "token_estimate": 163}
{"text": "4-14   SWEBOK \u00ae GUIDE V4.0: changes. Platform standards usually involve \nstandard services and APIs that compat-\nible platform implementations must use. Typical examples of platform standards are \nJakarta Enterprise Edition (JEE); the por-\ntable operating system interface (POSIX) \nstandard for operating systems, which rep-\nresents a set of standards implemented pri-\nmarily for Unix-based operating systems; \nand HTML5, which defines the standards \nfor developing web applications that can \nrun on different environments (e.g., Apple \niOS, Android). 4.16. Test-First Programming \b\n[1-c22, 2-c8]\nTest-first programming (also known as TDD - \nTest-Driven Development) is a popular devel-\nopment style in which test cases are written \nbefore any code. These test cases, when applied \nto the current code base, will fail. Code is then \nwritten that will allow the test cases to pass. At that time, the new code and associated \nparts of the project can be refactored and opti-\nmized. Test-first programming can usually \ndetect defects earlier and correct them more \neasily than traditional programming styles. Furthermore, writing test cases first forces \nprogrammers to think about requirements and \ndesign before coding, thus exposing require-\nments and design problems sooner. 4.17. Feedback Loop for Construction \n \b\n[3-c3, c16]\nEarly and continuous feedback for the \nconstruction activity is one of the most \nimportant advantages of agile development \nand DevOps. Agile development provides \nearly feedback for construction through fre-\nquent iterations in the development process. DevOps provides even faster feedback from \nthe operation, allowing the developers to \nlearn how well their code performs in pro-\nduction environments. This fast feedback is \nachieved through techniques and practices \nin the DevOps pipeline, such as automated \nbuilding and testing, canary release, and \nA/B testing. 5. Software Construction Tools\n5.1. Development Environments \b\n[1-c30]\nA development environment, or integrated \ndevelopment environment (IDE), provides \ncomprehensive facilities to programmers for \nsoftware construction by integrating a set of \ndevelopment tools. The programmers\u2019 choice \nof development environment can affect soft-\nware construction efficiency and quality. Besides basic code editing functions, \nmodern IDEs often offer other features, like \ncompilation and error detection within the \neditor, integration with source code control, \nbuild/test/debugging tools, compressed or \noutline views of programs, automated code \ntransforms, and support for refactoring. Nowadays, cloud-based development envi-\nronments are available in public or private \ncloud services. These environments can pro-\nvide all the features of modern IDEs and \neven more (e.g., containerized building and \ndeployment), powered by the cloud.", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 113", "position": 113, "chunk_type": "semantic", "token_estimate": 397}
{"text": "4-14   SWEBOK \u00ae GUIDE V4.0: Nowadays, cloud-based development envi-\nronments are available in public or private \ncloud services. These environments can pro-\nvide all the features of modern IDEs and \neven more (e.g., containerized building and \ndeployment), powered by the cloud. Moreover, modern IDEs are often equipped \nwith AI-assisted programming which is \nboosted by the recent advances in Large \nLanguage Models (LLMs). With the support \na programmer can define a function in pseudo-\ncode comments or outline its implementa-\ntion as a prompt for an LLM to generate or \ncomplete the code. The programmer lets the \nLLM complete many of the details, but still \nreviews the generated code and integrates it \ninto their project. 5.2. Visual Programming and Low-Code/Zero-\nCode Platforms \b\n[1-c30]\nVisual programming allows users to create pro-\ngrams by manipulating visual program ele-\nments graphically. As a visual programming \ntool, a GUI (graphical user interface) builder \nenables the developer to create and main-\ntain GUIs in a WYSIWYG (what you see \nis what you get) mode. A GUI builder usu-\nally includes a visual editor that enables the \ndeveloper to design forms and windows and \nmanage the layout of the widgets with drag,", "domains": ["Design Patterns", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 113", "position": 113, "chunk_type": "semantic", "token_estimate": 196}
{"text": "SOFTWARE CONSTRUCTION   4-15: drop and parameter setting features. Some \nGUI builders can automatically generate the \nsource code corresponding to the visual GUI \ndesign. Because GUI applications usually \nfollow the event-driven style (in which events \nand event handling determine the program \nflow), GUI builder tools usually provide code \ngeneration assistants, which automate the \nmost repetitive tasks required for event han-\ndling. The supporting code connects widgets \nwith the outgoing and incoming events that \ntrigger the functions providing the application \nlogic. Some modern IDEs provide integrated \nGUI builders or GUI builder plug-ins. There \nare also many stand-alone GUI builders. Visual programming and other rapid appli-\ncation development tools have evolved into \nlow-code/zero-code platforms. These platforms \nallow developers to build complete applica-\ntions visually through a drag-and-drop inter-\nface and with minimal hand-coding. They \nare usually based on the principles of mod-\nel-driven design, visual programming and \ncode generation. The difference between low-\ncode development and zero-code development \nlies in hand-coding; the former requires a \nlittle hand-coding, whereas the latter requires \npractically none. 5.3. Unit Testing Tools \b\n[1-c22, 2-c8]\nUnit testing verifies the functioning of soft-\nware modules in isolation from other sepa-\nrately testable software elements (for example, \nclasses, routines, components). Unit testing \nis often automated. Developers can use unit \ntesting tools and frameworks to extend and \ncreate an automated testing environment. For \nexample, the developer can code criteria into \nthe test with unit testing tools and frame-\nworks to verify the unit\u2019s correctness under \nvarious data sets. Each test is implemented \nas an object, and a test runner runs the tests. Failed test cases will be automatically flagged \nand reported during the test execution. 5.4. Profiling, Performance Analysis,  \nand Slicing Tools \b\n[1-c25, c26]\nPerformance analysis tools are usually used to \nsupport code tuning. The most common per-\nformance analysis tools are profiling tools. An \nexecution profiling tool monitors the code \nwhile it runs and records how often each \nstatement is executed or how much time the \nprogram spends on each statement or exe-\ncution path. Profiling the code while it runs \ngives insight into how the program works, \nwhere the hot spots are and where the devel-\nopers should focus the code tuning efforts. Program slicing involves computing the set \nof program statements (i.e., the program slice) \nthat might affect the values of specified vari-\nables at some point of interest, which is called \na slicing criterion.", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 114", "position": 114, "chunk_type": "semantic", "token_estimate": 398}
{"text": "SOFTWARE CONSTRUCTION   4-17: 4.3. Parameterization, \nTemplates and Generics\nc1\n4.4. Assertions, Design by \nContract and Defensive \nProgramming\nc8, c9\n4.5. Error Handling, \nException Handling and \nFault Tolerance\nc3, c8\n4.6. Executable Models\n4.7. State-Based and \nTable-Driven Construction \nTechniques\nc18\n4.8. Runtime \nConfiguration and \nInternationalization\nc3, c10\n4.9. Grammar-Based Input \nProcessing\nc5\nc8\n4.10. Concurrency \nPrimitives\nc6\n4.11. Middleware\nc1\nc8\n4.12. Construction \nMethods for Distributed \nand Cloud-Based Software\nc17, \nc18\nc2\n4.13. Constructing \nHeterogeneous Systems\nc9\n4.14. Performance Analysis \nand Tuning\nc25, c26\n4.15. Platform Standards\nc\nc10\nc1\n4.16. Test-First \nProgramming\nc22\nc8\n4.17. Feedback Loop for \nConstruction\nc3, \nc16\n5. Software \nConstruction Tools\n5.1. Development \nEnvironments\nc30\n5.2. Visual Programming \nand Low-Code/Zero-\nCode Platforms\nc30\n5.3. Unit Testing Tools\nc22\nc8\n5.4. Profiling, Performance \nAnalysis and Slicing Tools\nc25, c26", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 116", "position": 116, "chunk_type": "semantic", "token_estimate": 132}
{"text": "[1]\t S. McConnell, Code Complete, 2nd edition,: Redmond, WA: Microsoft Press, 2004. [2]\t I. Sommerville, Software Engineering, \n10th edition, Addison-Wesley, 2016. [3]\t G. Kim et al., The DevOps Handbook: \nHow to Create World-Class Agility, \nReliability & Security in Technology \nOrganizations, 2nd edition, IT \nRevolution, 2021. [4]\t H. Heitk\u00f6tter, S. Hanschke, and T.A. Majchrzak, Evaluating Cross-Platform \nDevelopment Approaches for Mobile \nApplications, 2013, in Cordeiro, J., \nKrempels, K.H. (eds. ), Web Information \nSystems and Technologies. WEBIST \n2012. Lecture Notes in Business \nInformation Processing, vol. 140, \nSpringer, Berlin, Heidelberg. [5]\t P. Clements et al., Documenting Software \nArchitectures: Views and Beyond, 2nd edi-\ntion, Boston: Pearson Education, 2010. [6]\t E. Gamma et al., Design Patterns: \nElements of Reusable Object-Oriented \nSoftware, 1st edition, Reading, MA: \nAddison-Wesley Professional, 1994. [7]\t S.J. Mellor and M.J. Balcer, Executable \nUML: A Foundation for Model-Driven \nArchitecture, 1st edition, Boston: \nAddison-Wesley, 2002. [8]\t L. Null and J. Lobur, The Essentials of \nComputer Organization and Architecture, \n2nd edition, Sudbury, MA: Jones and \nBartlett Publishers, 2006. [9]\t A. Silberschatz et al., Operating System \nConcepts, 8th edition, Hoboken, NJ: \nWiley, 2008.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 117", "position": 117, "chunk_type": "semantic", "token_estimate": 177}
{"text": "Section: Application Program Interface", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 118", "position": 118, "chunk_type": "semantic", "token_estimate": 4}
{"text": "Fast Healthcare Interoperability: Resources", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 118", "position": 118, "chunk_type": "semantic", "token_estimate": 4}
{"text": "Section: Graphical User Interface", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 118", "position": 118, "chunk_type": "semantic", "token_estimate": 4}
{"text": "Health Insurance Portability and: Accountability Act", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 118", "position": 118, "chunk_type": "semantic", "token_estimate": 6}
{"text": "Key Performance Indicator: MC/DC\nModified Condition \nDecision Coverage", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 118", "position": 118, "chunk_type": "semantic", "token_estimate": 8}
{"text": "Section: User Interface", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 118", "position": 118, "chunk_type": "semantic", "token_estimate": 3}
{"text": "Software testing consists of the dynamic vali-: dation that a system under test (SUT) provides \nexpected behaviors on a finite set of test cases \nsuitably selected from the usually infinite exe-\ncution domain. In the above statement, italicized words \ncorrespond to key issues in the Software \nTesting knowledge area (KA). Those terms \nare discussed below. \u2022\t System Under Test: This term can refer to \nthe tested object, which could be a pro-\ngram, a software product, an applica-\ntion, a service-oriented application (e.g., \nweb services, microservices), middleware \n(HW/SW), a services composition, a \nsystem, a System of Systems (SoS), or an \nEcosystem (ECS). \u2022\t Test Case: A test case is the specification \nof all the entities that are essential for the \nexecution, such as input values, execution", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 118", "position": 118, "chunk_type": "semantic", "token_estimate": 126}
{"text": "5-2   SWEBOK \u00ae GUIDE V4.0: and timing conditions, testing procedure, \nand the expected outcomes (e.g., pro-\nduced values, state changes, output mes-\nsages). Input values alone are not always \nsufficient to specify the test cases because \nthe SUT might react to the same input \nwith different behaviors, depending, for \ninstance, on the SUT state or environ-\nmental conditions. A set of test cases is \nusually called a test suite. \u2022\t Dynamic: Dynamic validation requires \nexecuting the SUT on a test suite. Static \ntechniques complement dynamic testing, \nand they are covered in the Software \nQuality KA.1 \n\u2022\t Finite: Even in a simple SUT, executing \nall the possible test cases (i.e., exhaus-\ntive testing) could require months or \nyears. Consequently, in practice, testing \ntargets a subset of all possible test cases \ndetermined by different criteria. Testing \nalways implies a trade-off between lim-\nited resources and schedules on the one \nhand and inherently unlimited test \nrequirements on the other. \u2022\t Selected: Identifying the most suitable \nselection criteria under given conditions \nis a complex problem. Different tech-\nniques can be considered and combined \nto tackle that problem, such as risk anal-\nysis, software requirements, cost reduc-\ntion, \nquality \nattributes \nsatisfaction, \nprioritization, and fault detection. The \nmany proposed test techniques differ in \nhow the test suite is selected, and soft-\nware engineers must be aware that dif-\nferent selection criteria might yield vastly \ndifferent degrees of effectiveness. \u2022\t Expected: For each executed test case, it \nmust be possible, although it might not \nbe easy, to decide whether the observed \nSUT outcomes match the expected ones. Indeed, the observed behavior may be \nchecked against user needs (commonly \nreferred to as testing for validation), against \na specification (testing for verification), or, \n1\t\n It is worth noting that terminology is not uniform among different communities, and some use the \nterm testing to refer to static techniques as well. perhaps, against the foreseen behavior \nfrom implicit requirements or expectations. (See Section 4.3, Acceptance Criteria-\nBased Requirements Specification, in the \nSoftware Requirements KA.) As reflected in this discussion, software \ntesting is a pervasive and holistic activity \ninvolving all the steps of any process devel-\nopment life cycle (e.g., traditional or shift-left \ndevelopment). The remainder of this chapter \npresents the basics of software testing and its \nchallenges, issues, and commonly accepted \npractices and solutions.", "domains": ["Design Patterns", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 119", "position": 119, "chunk_type": "semantic", "token_estimate": 383}
{"text": "5-4   SWEBOK \u00ae GUIDE V4.0: 1.2.6. Testing for Quality Assurance/ \n\t Improvement \n[1*, c16s2; 4, part 1, c5; 9]\nTesting has many aspects, including quality \nimprovement and assurance. These charac-\nteristics involve planned and systematic sup-\nporting processes and activities leveraging \nconfidence that the SUT fulfills established \ntechnical or quality requirements. Thus, \nquality improvement and assurance involve \ndefining methods, tools, skills, and prac-\ntices to achieve the specific quality level and \nobjectives. The list of the main quality char-\nacteristics that testing can measure or assess \nis reported in ISO/IEC 25010:2011 [9]. (See \nalso Section 1.3.2, Software Product Quality, \nin the Software Quality KA.) 1.2.7. The Oracle Problem \n[1*, c1s9, c9s7]\nAn important testing component is the \noracle. Indeed, a test is meaningful only if \nit is possible to decide its observed outcome.", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 121", "position": 121, "chunk_type": "semantic", "token_estimate": 132}
{"text": "SOFTWARE TESTING   5-5: An oracle can be any human or mechanical \nagent that decides whether the SUT behaved \ncorrectly in each test and according to the \nexpected outcomes. Consequently, the oracle \nprovides a \u201cpass\u201d or \u201cfail\u201d verdict. The oracle \ncannot always decide; in these cases, the test \noutput is classified as inconclusive. There are \nmany kinds of oracles \u2014 for example, unam-\nbiguous requirements specifications, behav-\nioral models, and code annotations. The \nautomation of oracles can be difficult and \nexpensive. 1.2.8. Theoretical and Practical Limitations \n[1*, c2s7]\nTesting theory warns against ascribing unjus-\ntified confidence to a series of successful tests. Unfortunately, most established results of \nthe testing theory are negative results in that \nthey state what is not achieved as opposed \nto what is achieved. The most famous quo-\ntation on this point is the Dijkstra aphorism \nthat \u201cprogram testing can be used to show \nthe presence of bugs, but never to show their \nabsence\u201d [3]. The obvious reason for this is \nthat complete testing is not feasible in real-\nistic software. 1.2.9. The Problem of Infeasible Paths \n[1*, c4s7]\nInfeasible paths are control flow paths that \ncannot be exercised by any input data (i.e., test \ncases). Managing (i.e., identifying, solving  or \nremoving) the infeasible paths can help reduce \nthe time and resources devoted to testing. They are a significant problem in path-based \ntesting, particularly in the automated deri-\nvation of test cases to exercise control flow \npaths. Additionally, the detection of infeasible \npaths can also play a role in reducing security \nvulnerabilities. 1.2.10. Testability \n[1*, c17s2]\nThe term software testability has two related \nbut different meanings. On the one hand, it \nrefers to the ease with which a given test cov-\nerage criterion can be satisfied; on the other \nhand, it is defined as the likelihood, possibly \nmeasured statistically, that a test suite will \nexpose a failure if the software is faulty. Both \nmeanings are important. 1.2.11 Test Execution and Automation \n[4, part 1, c4]\nAn important challenge of testing is to \nimprove attainable automation, either \nby developing advanced techniques for \ngenerating the test inputs or, beyond \ntest generation, by finding innovative sup-\nport procedures to (fully) automate the dif-\nferent testing activities \u2014 for instance, to \nincrease the number of test cases generated \nor executed. 1.2.12.", "domains": ["Design Patterns", "Software Quality Attributes", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 122", "position": 122, "chunk_type": "semantic", "token_estimate": 379}
{"text": "SOFTWARE TESTING   5-5: 1.2.11 Test Execution and Automation \n[4, part 1, c4]\nAn important challenge of testing is to \nimprove attainable automation, either \nby developing advanced techniques for \ngenerating the test inputs or, beyond \ntest generation, by finding innovative sup-\nport procedures to (fully) automate the dif-\nferent testing activities \u2014 for instance, to \nincrease the number of test cases generated \nor executed. 1.2.12. Scalability \n[1*, c8s7] \nScalability is the software\u2019s ability to increase \nand scale up on its nonfunctional require-\nments, such as load, number of transactions, \nand volume of data. Scalability is also con-\nnected to the complexity of the platform and \nenvironment in which the program runs, such \nas distributed, wireless networks and virtual-\nized environments, large-scale clusters, and \nmobile clouds. 1.2.13 Test Effectiveness\n[1* c1s1; 2* c8s1; 8]\nEvaluating the SUT, measuring a testing \ntechnique\u2019s efficacy, and judging whether \ntesting can be stopped are important evi-\ndences for software testing, and they may \nrequire defining and selecting the proper test \neffectiveness measures. 1.2.14 Controllability, Replication, and  \n\t Generalization \n[1* c12s12; 4, part 2, c7]\nSpecific aspects of testing include the \nfollowing:", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 122", "position": 122, "chunk_type": "semantic", "token_estimate": 184}
{"text": "5-6   SWEBOK \u00ae GUIDE V4.0: \u2022\t Controllability refers to the transition \nof testing activities from the laboratory \n(i.e., controlled conditions) to reality (i.e., \nuncontrolled conditions). \u2022\t Replication refers to the ability for dif-\nferent people to perform the same \ntesting activities. The purpose is to verify \nwhether a given testing theory works, at \nleast in the laboratory. \u2022\t The generalization of testing is connected \nto external validity \u2014 i.e., the extent to \nwhich the test approach can be applied \nto broader settings or target populations. The generalizability of the software testing \ncan be important for managing the testing \nactivities (in terms of cost and effort) and \nincreasing confidence in the test results. 1.2.15. Offline vs. Online Testing\n[10, c3]\nThe testing process can be executed in two \nsettings: offline and online. Usually, the \nSUT is validated in an environment without \nexternal interaction in offline testing, whereas \nthe SUT interacts with the real application \nenvironment in online testing. The test cases \nare either manually or automatically derived \nin both cases, and the expected outcomes are \nused to assess the SUT. 1.3. Relationship of Testing to Other Activities\nSoftware testing is related to but different \nfrom static software quality management \ntechniques, proofs of correctness, debugging, \nand program construction. However, it is \ninformative to consider testing from the view-\npoint of software quality analysts and certi-\nfiers. For further discussion, see the following:\n\u2022\t Testing vs. Static Software Quality \nManagement Techniques: See Section \n2.2.1, Static Analysis Techniques, in the \nSoftware Quality KA. \u2022\t Testing \nvs. \nQuality \nImprovement/\nAssurance: See Section 1.3.2, Software \nProduct \nQuality, \nin \nthe \nSoftware \nQuality KA. \u2022\t Testing vs. Correctness Proofs and \nFormal Verification: See the Software \nEngineering Models and Methods KA. \u2022\t Testing vs. Debugging: See Construction \nTesting in the Software Construction KA \nand Debugging Tools and Techniques in \nthe Computing Foundations KA. \u2022\t Testing vs. Program Construction: See \nConstruction Testing in the Software \nConstruction KA. \u2022\t Testing vs. Security: See the new KA: \nSoftware Security. \u2022\t Testing vs. Effort Estimation: See the \nSoftware Engineering Management KA. \u2022\t Testing vs. Legal Issues: See the Software \nEngineering Professional Practice KA. 2. Test Levels\n[1*, c1s13; 2*, c8s1]\nSoftware testing is usually performed at dif-\nferent levels throughout development and \nmaintenance. Levels can be distinguished \nbased on the object of testing, the target, or \non the purpose or objective (of the test level). 2.1.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 123", "position": 123, "chunk_type": "semantic", "token_estimate": 393}
{"text": "SOFTWARE TESTING   5-7: 2.1.2. Integration Testing \n[1*, c7, 2*, c8]\nIntegration testing verifies the interac-\ntions among SUT elements (for instance, \ncomponents, modules, or subsystems). Integration strategies involve the incre-\nmental (and systematic) integration of the \nSUT elements considering either identified \nfunctional threads or architecture specifica-\ntions. Typical integration testing strategies \nare top-down, bottom-up, mixed (or sand-\nwiched), and the big bang. They focus on \ndifferent perspectives of the level at which \nSUT elements are integrated. Integration \ntesting is a continuous activity that can \nbe performed at each development stage. It may target different aspects, such as \ninteroperability (e.g., compatibility or con-\nfiguration) of the SUT elements or with \nthe external environment. External inter-\nfaces to other applications, utilities, hard-\nware devices or operating environments can \nalso be considered. 2.1.3. System Testing \n[1*, c8, 2*, c8]\nSystem testing concerns testing the behavior \nof the SUT (according to the definition of \nSection 1). Effective unit and integration \ntesting should have identified many SUT \ndefects. In addition, system testing is usu-\nally considered appropriate for assessing \nnon-functional system requirements, such as \nsecurity, privacy, speed, accuracy, and reli-\nability. (See Functional and Non-Functional \nRequirements in the Software Requirements \nKA and Software Quality Requirements in \nthe Software Quality KA.) 2.1.4. Acceptance Testing \n[1*, c1s7, 2*, c8s4]\nAcceptance testing targets the deployment of a \nSUT. Its main goal is to verify that the SUT \nsatisfies the requirements and the end-users\u2019 \nexpectations. Generally, it is run by or with \nthe end-users to perform those functions and \ntasks for which the software was built. For \nexample, this testing activity could target \nusability testing or operational acceptance. Defining acceptance tests before imple-\nmenting the corresponding functionality is \na key activity of the acceptance test-driven \ndevelopment (ATDD). (See the Software \nRequirements KA, Section 4.3.) 2.2. Objectives of Testing \n[1*, c1s7]\nTesting is conducted considering specific \nobjectives, which are stated (more or less) \nexplicitly and with varying degrees of preci-\nsion. Stating the testing objectives in precise, \nquantitative terms supports measurement and \ncontrol of the test process. Testing can be aimed at verifying dif-\nferent properties. For example, test cases \ncan be designed to check that the functional \nspecifications are correctly implemented, \nwhich is variously referred to in the liter-\nature as conformance testing, correctness \ntesting or functional testing. However, sev-\neral other non-functional properties may \nbe tested as well, including performance, \nreliability, and usability.", "domains": ["Design Patterns", "Software Quality Attributes", "Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 124", "position": 124, "chunk_type": "semantic", "token_estimate": 395}
{"text": "SOFTWARE TESTING   5-7: For example, test cases \ncan be designed to check that the functional \nspecifications are correctly implemented, \nwhich is variously referred to in the liter-\nature as conformance testing, correctness \ntesting or functional testing. However, sev-\neral other non-functional properties may \nbe tested as well, including performance, \nreliability, and usability. (See Models and \nQuality Characteristics in the Software \nQuality KA.) Other important testing objectives include \nbut are not limited to reliability measure-\nments, identification of security and pri-\nvacy vulnerabilities, and usability evaluation; \ndifferent approaches would be necessary \ndepending on the objective. Note that, in \ngeneral, the test objectives vary with the test \ntarget; different purposes are addressed at dif-\nferent levels of testing. The subtopics listed below are those most \ncited in the literature. 2.2.1. Conformance Testing\n[1*, c10s4]\nConformance testing aims to verify that the \nSUT conforms to standards, rules, specifi-\ncations, requirements, design, processes, or \npractices.", "domains": ["Software Quality Attributes", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 124", "position": 124, "chunk_type": "semantic", "token_estimate": 151}
{"text": "5-8   SWEBOK \u00ae GUIDE V4.0: 2.2.2 Compliance Testing\n[1*, c12s3]\nCompliance testing aims to demonstrate the \nSUT\u2019s adherence to a law or regulation. Usually, compliance testing is forced by an \nexternal regulatory body. 2.2.3. Installation Testing \n[1*, c12s2]\nOften, after system and acceptance testing is \ncompleted, and the SUT has been installed in \nthe target environment, the SUT is verified. Installation testing can be viewed as system \ntesting conducted in the operational environ-\nment of hardware configurations and other \noperational constraints. Installation proce-\ndures may also be verified. 2.2.4. Alpha and Beta Testing \n[1*, c13s7, c16s6, 2*, c8s4]\nBefore the SUT is released, it is sometimes \ngiven to a small, selected group of potential \nusers for trial use (alpha testing) and/or to a \nlarger set of representative users (beta testing). These users report problems with the product. Alpha testing and beta testing are often \nuncontrolled and are not always referred to in \na test plan. 2.2.5. Regression Testing \n[1*, c8s11, c13s3; 4, part 1, c5]\nAccording to the definition reported in [5], \nregression testing is the \u201cselective retesting of \na SUT to verify that modifications have not \ncaused unintended effects and that the SUT \nstill complies with its specified requirements.\u201d \nIn practice, the approach is designed to show \nthat the SUT still passes previously passed tests \nin a test suite (in fact, it is sometimes referred \nto as non-regression testing). In some cases, a \ntrade-off must be made between the assur-\nance given by regression testing every time a \nchange is made and the resources required to \nperform the regression tests. This can be quite \ntime-consuming because of the many tests \nthat might be executed. Regression testing \ncan be conducted at each test level described \nin Section 2.1. It may involve functional and \nnon-functional testing, such as reliability, \naccessibility, usability, maintainability, con-\nversion, migration, and compatibility testing. Regression testing may involve selection \n(see Section 1.2.2) and minimization (see \nSection 1.2.3) of test cases, as well as the \nadoption of prioritization approaches (see \nSection 2.2.6) to existing test suites. Regression testing is a fundamental activity \nof Agile, DevOps, test-driven development \n(TDD), and Continuous Development. It is \nusually performed after integration testing and \nbefore deployment to production or operation. 2.2.6. Prioritization Testing \n[1*, c12s7]\nTest case prioritization aims to schedule test \ncases to increase the rate and likelihood of \nfault detection, the coverage of code under \ntest, and the SUT\u2019s reliability.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 125", "position": 125, "chunk_type": "semantic", "token_estimate": 399}
{"text": "5-8   SWEBOK \u00ae GUIDE V4.0: 2.2.6. Prioritization Testing \n[1*, c12s7]\nTest case prioritization aims to schedule test \ncases to increase the rate and likelihood of \nfault detection, the coverage of code under \ntest, and the SUT\u2019s reliability. Typically, pri-\noritization testing relies on heuristics, and \nits performance might vary according to the \nSUT, the environment, and the available test \ncases. Among the different prioritization \nproposals, similarity-based prioritization is \none of the most commonly adopted. In this \napproach to prioritization, test cases are pri-\noritized starting from those most dissimilar \naccording to a predefined distance function. 2.2.7. Non-functional Testing \n[2*, c8]\nNon-Functional testing targets the validation \nof non-functional aspects (such as perfor-\nmance, usability, or reliability), and it is per-\nformed at all test levels. At the state of the \npractice, there are hundreds of non-functional \ntesting techniques that include but are not \nlimited to the following: \n\u2022\t Performance \nTesting \n[4, \npart \n1]: \nPerformance testing verifies that the \nsoftware meets the specified performance \nrequirements and assesses performance", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 125", "position": 125, "chunk_type": "semantic", "token_estimate": 166}
{"text": "SOFTWARE TESTING   5-9: characteristics \n(e.g., \ncapacity \nand \nresponse time). \u2022\t Load Testing [4, part 1]: Load testing \nfocuses on validating the SUT\u2019s behavior \nunder load pressure conditions to dis-\ncover problems (e.g., deadlocks, racing, \nbuffer overflows and memory leaks) or \nreliability, stability, or robustness viola-\ntions. It aims to assess the rate at which \ndifferent service requests are submitted \nto the SUT. \u2022\t Stress Testing [1*, c8s8]: Stress testing \naims to push the SUT beyond its capa-\nbilities by generating a load greater than \nwhat the system is expected to handle. \u2022\t Volume Testing [4, part 1]: Volume \ntesting targets the assessment of the \nSUT\u2019s internal storage limitations and its \nability to exchange data and information. \u2022\t Failover Testing [1*, c17s2; 2*, c8]: \nFailover testing validates the SUT\u2019s \nability to manage heavy loads or unex-\npected failure to continue typical opera-\ntions (e.g., by allocating extra resources). Failover testing is also connected with \nrecoverability validation. \u2022\t Reliability Testing [1*, c15; 2*, c11]: \nReliability testing evaluates the SUT\u2019s \nreliability by identifying and correcting \nfaults. Reliability testing observes the \nSUT in operation or exercises the SUT \nby using test cases according to statis-\ntical models (operational profiles) of the \ndifferent users\u2019 behaviors. Usually, reli-\nability is assessed through reliability \ngrowth models. The continuous devel-\nopment processes (such as DevOps) are \ncurrently facilitating the adoption of reli-\nability testing in the various iterations for \nimproving final SUT quality. \u2022\t Compatibility Testing [4, part 1; 10, c3]: \nCompatibility testing is used to verify \nwhether the software can collaborate with \ndifferent hardware and software facilities \nor with different versions or releases. \u2022\t Scalability Testing [1*, c8s7; 2* c17]: \nScalability testing assesses the soft-\nware\u2019s ability to scale up non-functional \nrequirements such as load, number of \ntransactions, volume of data. It could \nintegrate or extend load, elasticity and \nstress testing. \u2022\t Elasticity Testing [17]: Elasticity testing \nassesses the ability of the SUT (such as \ncloud and distributed systems) to rap-\nidly expand or shrink compute, memory, \nand storage resources without compro-\nmising the capacity to meet peak utili-\nzation. Some elasticity testing objectives \nare to control behaviors, to identify the \nresources to be (un)allocated, and to coor-\ndinate events in parallel. \u2022\t Infrastructure Testing [8, annex H]: \nInfrastructure testing tests and validates \ninfrastructure components to reduce the \nchances of downtime and improve the \nperformance of the IT infrastructure.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 126", "position": 126, "chunk_type": "semantic", "token_estimate": 392}
{"text": "SOFTWARE TESTING   5-9: Some elasticity testing objectives \nare to control behaviors, to identify the \nresources to be (un)allocated, and to coor-\ndinate events in parallel. \u2022\t Infrastructure Testing [8, annex H]: \nInfrastructure testing tests and validates \ninfrastructure components to reduce the \nchances of downtime and improve the \nperformance of the IT infrastructure. \u2022\t Back-to-Back Testing [5]: ISO/IEC/\nIEEE 24765 defines back-to-back testing \nas \u201ctesting in which two or more vari-\nants of a program are executed with \nthe same inputs, the outputs are com-\npared, and errors are analyzed in case of \ndiscrepancies.\u201d\n\u2022\t Recovery Testing [1*, c14s2]: Recovery \ntesting is aimed at verifying software \nrestart capabilities after a system crash or \nother disaster. 2.2.8. Security Testing \n[2*, c13; 4, part 4, annex A]\nSecurity testing focuses on validating that \nthe SUT is protected from external attacks. More precisely, it verifies the confidenti-\nality, integrity, and availability of the sys-\ntems and their data. Usually, security testing \nincludes validation against misuse and abuse \nof the software or system (negative testing). (See Security Testing in the Software \nSecurity KA.) 2.2.9. Privacy Testing \n[2*, c13, c14]\nPrivacy testing is devoted to assessing the \nsecurity and privacy of users\u2019 personal \ndata to prevent local attacks. It specifically", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 126", "position": 126, "chunk_type": "semantic", "token_estimate": 204}
{"text": "5-10   SWEBOK \u00ae GUIDE V4.0: assesses privacy and information-sharing \npolicies, as well as the validation of decen-\ntralized management of users\u2019 social profiles \nand data storage solutions. (See Legal Issue \nin the Software Engineering Professional \nPractice KA.) 2.2.10. Interface and Application Program  \n\t Interface (API) Testing \n[2*, c8s1; 14*, c7s12; 4, part 5, c4, c7]\nInterface defects are common in complex sys-\ntems. Interface testing aims to verify whether \nthe components\u2019 interface provide the correct \nexchange of data and control information. Usually, the test cases are generated from the \ninterface specification. A specific interface \ntesting objective is to simulate the use of APIs \nby end-user applications. That involves gen-\nerating parameters of the API calls, setting \nconditions of the external environment, and \ndefining internal data that affect the API. 2.2.11. Configuration Testing \n[1*, c8s5]\nWhere the SUT is built to serve different \nusers, configuration testing verifies the software \nunder specified configurations. 2.2.12. Usability and Human-Computer  \n\t Interaction Testing \n[2* c8s4; 19*, c6; 4, part 4, annex A]\nThe main task of usability and human-com-\nputer interaction testing is to evaluate how \neasy it is for end-users to learn to use the \nsoftware. It might involve testing the soft-\nware functions that support user tasks, the \ndocumentation that aids users, and the sys-\ntem\u2019s ability to recover from user errors. (See User-Centered Design in the Software \nDesign KA.) 3. Test Techniques \n[1*, c1s15; 4, part 4]\nOver the years, different testing techniques \nhave been developed to increase the SUT\u2019s \noverall quality [4, part 4]. These techniques \nattempt to propose systematic procedures and \napproaches for generating or selecting the \nmost suitable test suites for detecting as many \nfailures as possible. Testing techniques can be classified by \nconsidering different key aspects such as \nspecification, structure, and experience [4, \npart 4]. Additional classification sources can \nbe the faults to be discovered, the predicted \nuse, the models, the nature of the applica-\ntion, or the derived knowledge. For instance, \nmodel-based testing [7; 4, part 1] refers to all \nthe testing techniques that use the concept \nof a model representing behavioral specifi-\ncation, the SUT\u2019s structure, or the available \nknowledge and experience. However, classi-\nfication overlapping is possible, and one cate-\ngory might deal with combining two or more \ntechniques. Alternative classifications that rely on \nthe degree of information about the SUT \nare available in the literature.", "domains": ["Design Patterns", "Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 127", "position": 127, "chunk_type": "semantic", "token_estimate": 389}
{"text": "5-10   SWEBOK \u00ae GUIDE V4.0: However, classi-\nfication overlapping is possible, and one cate-\ngory might deal with combining two or more \ntechniques. Alternative classifications that rely on \nthe degree of information about the SUT \nare available in the literature. Indeed, in \nthe specification-based techniques, also \nknown as black-box techniques, the gen-\neration of test cases is based only on the \nSUT\u2019s input/output behavior, whereas in \nthe structure-based, also called white-box \n(or glass-box or clear-box), techniques, the \ntest cases are generated using the infor-\nmation about how the SUT has been \ndesigned or coded. As some testing techniques are used \nmore than others, the remainder of the sec-\ntion presents the standard testing techniques \nand those commonly adopted at the state of \nthe practice. 3.1. Specification-Based Techniques\n[1*, c6s2; 4, part 4]\nThe underlying idea of specification-based tech-\nniques (sometimes also called domain testing \ntechniques) is to select a few test cases from \nthe input domain that can detect specific cat-\negories of faults (also called domain errors). These techniques check whether the SUT \ncan manage inputs within a certain range and \nreturn the required output.", "domains": ["Design Patterns", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 127", "position": 127, "chunk_type": "semantic", "token_estimate": 186}
{"text": "SOFTWARE TESTING   5-11: 3.1.1. Equivalence Partitioning \n[1*, c9s4]\nEquivalence partitioning involves partitioning \nthe input domain into a collection of subsets \n(or equivalence classes) based on a specified \ncriterion or relation. This criterion or rela-\ntion may be different computational results, a \nrelation based on control flow or data flow, or \na distinction made between valid inputs that \nare accepted and processed by the SUT and \ninvalid inputs, such as out-of-range values, \nthat are not accepted and should generate \nan error message or initiate error processing. A representative test suite (sometimes con-\ntaining only one test case) is usually taken \nfrom each equivalence class. 3.1.2. Bounday Value Analysis \n[1*, c9s5; 4, part 4]\nTest cases are chosen on or near the bound-\naries of the input domain of variables, with the \nunderlying rationale that many faults tend to \nconcentrate near the extreme values of inputs. An extension of this technique is robustness \ntesting, wherein test cases are also chosen out-\nside the input domain of variables to test pro-\ngram robustness in processing unexpected or \nerroneous inputs. 3.1.3. Syntax Testing\n[1*, c10s11, 2*, c5; 4, part 4] \nThe Syntax Testing techniques, also known \nas formal specification-based techniques, \nrely on the SUT specifications in a formal \nlanguage. (See Formal Methods in the \nSoftware Engineering Models and Methods \nKA.) This representation permits automatic \nderivation of functional test cases and, at the \nsame time, provides an oracle for checking \ntest results. 3.1.4. Combinatorial Test Techniques \n[1*, c9s3; 4, part 4]\nThe Combinatorial Test Techniques system-\natically derive the test cases that cover specific \nparameters of values or conditions. According \nto [4, part 4], the commonly used combina-\ntorial test techniques are All combinations \nTesting, Pair-Wise Testing, Each Choice \nTesting, and Base Choice Testing. All combi-\nnations testing focuses on all the possible input \ncombinations, whereas its subset, also called \nt-wise testing, considers every possible combi-\nnation of t input. In this case, more than one \npair is derived (i.e., by including higher-level \ncombinations). Pair-wise testing is a specific \ncombinatorial testing technique where test \ncases are derived by combining values of every \npair of an input set. These techniques are also \nknown as orthogonal array testing (OAT). 3.1.5. Decision Table\n[1*, c9s6; 1*, c13s6; 4, part 4]\nDecision tables (or trees) represent logical rela-\ntionships between conditions (roughly, inputs) \nand actions (roughly, outputs). Usually, they \nare widely adopted for knowledge representa-\ntion (e.g., machine learning (ML)).", "domains": ["Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 128", "position": 128, "chunk_type": "semantic", "token_estimate": 401}
{"text": "SOFTWARE TESTING   5-11: Decision Table\n[1*, c9s6; 1*, c13s6; 4, part 4]\nDecision tables (or trees) represent logical rela-\ntionships between conditions (roughly, inputs) \nand actions (roughly, outputs). Usually, they \nare widely adopted for knowledge representa-\ntion (e.g., machine learning (ML)). Test cases \nare systematically derived by considering \nevery possible combination of conditions \nand their corresponding resultant actions. A related technique is cause-effect graphing. Currently, shift-left development processes \nare taking advantage of this kind of testing \ntechnique because these techniques are useful \nfor documenting the test results and factors \nthat can affect them. 3.1.6. Cause-Effect Graphing\n[1*, c1s6; 4, part 3, part 4]\nCause-effect graphing techniques rely on log-\nical networks that map a set of causes to a \nset of effects by systematically exploring the \npossible combinations of input conditions. They identify the effects and link the effects \nto their causes through model graphs. Cause-\neffect graphing techniques are used in testing \nbecause they allow specification analysis, the \nidentification of the relevant input conditions \nor causes, the consequent transformations, \nand the output conditions.", "domains": ["Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 128", "position": 128, "chunk_type": "semantic", "token_estimate": 174}
{"text": "5-12   SWEBOK \u00ae GUIDE V4.0: 3.1.7. State Transition Testing \n[1*, c10; 4, part 4]\nTechniques based on Finite-State Machines \n(State Transition Testing techniques in [4, \npart 4]) focus on representing the SUT with \na finite-state machine. In this case, the test \nsuite is derived to cover the states and tran-\nsitions according to a specific coverage level. 3.1.8. Scenario-Based Testing \n[2*, c8s3, c19s3; 4, part 4; 7]\nA model in this context is an abstract (formal) \nrepresentation of the SUT or its software \nrequirements. (See Modeling in the Software \nEngineering Models and Methods KA.) Scenario-based testing is used to validate require-\nments, check their consistency, and generate \ntest cases focused on the SUT\u2019s behavioral \naspects. (See Types of Models in the Software \nEngineering Models and Methods KA.) The \nkey components of scenario-based testing are \nthe notation used to represent the model of the \nsoftware or its requirements, workflow models \nor similar models, the test strategy or algorithm \nused for test case generation, the supporting \ninfrastructure for the test execution, and the \nevaluation of test results compared to expected \nresults. Because of the complexity of the tech-\nniques, scenario-based testing approaches are \noften used with test automation harnesses. Among scenario-based testing, workflow \nmodels can also be used to graphically represent \nthe sequence of activities performed by humans \nand/or software applications. In this case, each \nsequence of actions constitutes one workflow \n(also called a scenario). Usually, it is important \nto ensure that both typical and alternate work-\nflows are also tested. For example, business \nprocess testing is part of this scenario-based \ntechnique. In this case, the special focus is on \nthe roles in a workflow specification. 3.1.9. Random Testing \n[1*, c9s7; 4, part 4]\nIn this approach, test cases are generated \npurely at random. This testing falls under \nthe heading of input domain testing because \nthe input domain must be known to be able \nto pick random points within it. Random \ntesting provides a relatively simple approach \nto test automation. Enhanced forms of \nrandom testing (such as adaptive random \ntesting) have been proposed in which other \ninput selection criteria direct the random \ninput sampling. Currently, under the name of fuzz testing, \nthe random selection of invalid and unex-\npected inputs and data is extensively used in \ncybersecurity to find hackable software bugs, \ncoding errors, and security loopholes. (See \nalso Sections 2.2.8 and 8.2.) 3.1.10.", "domains": ["Design Patterns", "Software Quality Attributes", "Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 129", "position": 129, "chunk_type": "semantic", "token_estimate": 392}
{"text": "5-14   SWEBOK \u00ae GUIDE V4.0: test cases are not defined in advance but are \ndynamically designed, executed, and modi-\nfied according to the collected evidence and \ntest results, such as observed product behavior, \npeculiarities of the SUT, the domain and the \nenvironment, the failure process, the types of \npossible faults and failures, and the risk asso-\nciated with a particular product. Usually, the \nintuition, knowledge, and expertise of the \npersonnel in charge of performing the explor-\natory testing can affect the testing effective-\nness. Exploratory testing is widely used in \nshift-left development (such as Agile). (See \nSection 5.4.2.) 3.3.3. Further Experience-Based Techniques \n[4, part 4; 13]\nAt the state of the practice, experience-based \ntechniques may include further approaches \nsuch as Ad Hoc-based, knowledge-based and \nML-based testing techniques. Ad Hoc testing is a widely used technique in \nwhich test cases are derived by relying on the \nsoftware engineer\u2019s skill, intuition, and expe-\nrience with similar programs. It can be useful \nfor identifying test cases that are not easily gen-\nerated by more formalized techniques. Typical \nAd Hoc methodologies are the following: \n\u2022\t Monkey testing runs randomly generated \ntest cases to simulate rundom activities \nand cause the program to stop. \u2022\t Pair (Buddy) testing involves two indi-\nviduals. One generates and runs the test \ncases; the other observes and analyzes \nthe testing process. Pair testing allows \nfor generating test cases with broader and \nbetter test coverage. \u2022\t Gamification aims to convert testing \ntasks to components of gameplay. By \napplying specific techniques (such as \nengaging practitioners or crowdsourcing \ncomplex testing tasks), gamification can \nsubstantially improve software testing \npractice and, consequently, SUT quality. \u2022\t Quick testing, in which a very small test \nsuite is selected and executed to swiftly \nidentify critical issues in the SUT. It aims \nto enhances the probability of detecting \nfaults early in the development process. \u2022\t Smoke testing (also known as Build \nVerification Testing) ensures that the \nSUT\u2019s core functionalities behave prop-\nerly. It also guarantees that the SUT is \noperational before the planned testing \nbegins. In addition, smoke testing pre-\nvents failures because of the test envi-\nronment (e.g., because artifacts or \npackages are not properly built). Smoke \ntesting is also considered a special case of \nquick testing.", "domains": ["Design Patterns", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 131", "position": 131, "chunk_type": "semantic", "token_estimate": 369}
{"text": "5-14   SWEBOK \u00ae GUIDE V4.0: In addition, smoke testing pre-\nvents failures because of the test envi-\nronment (e.g., because artifacts or \npackages are not properly built). Smoke \ntesting is also considered a special case of \nquick testing. Knowledge-based testing and ML-based \ntesting exploit (formal or informal) knowl-\nedge about the SUT or derive it from obser-\nvations of SUT executions for defining its \nbehavioral models (such as ontologies or \ndecision tables) (see Section 3.6.1), rules, \nand non-functional properties. In addition, \nKnowledge-based testing and ML-based \ntesting specify the testing needs and iden-\ntify test objectives for which test cases are \ngenerated. 3.4. Fault-Based and Mutation Techniques \n[1*, c1s14, 1* c3s5; 5]\nWith different degrees of formalization, fault-\nbased testing techniques devise test cases spe-\ncifically to reveal likely or predefined fault \ncategories. A fault model can be introduced \nthat classifies the different faults to better \nfocus the test case generation or selection. In \nthis context, a variety of platforms and devel-\nopment processes (e.g., waterfall, spiral and \nAgile) consider the orthogonal defect clas-\nsification (ODC) a valid methodology for \ncollecting semantic information about the \ndifferent defects and reducing the time and \neffort of the root cause analysis. Mutation Testing was originally conceived as \na technique to evaluate test suites (see Section \n4.2, Evaluation of the Tests Performed) in \nwhich a mutant is a slightly modified ver-\nsion of the SUT (also called gold), differing \nfrom it by a small syntactic change. Every \ntest case exercises both the gold version and", "domains": ["Design Patterns", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 131", "position": 131, "chunk_type": "semantic", "token_estimate": 250}
{"text": "SOFTWARE TESTING   5-15: all generated mutants. If a test case succeeds \nin identifying the difference between the \ngold version and a mutant, the latter is said \nto be \u201ckilled.\u201d The underlying assumption of \nmutation testing, the coupling effect, is that \nmore complex but real faults will be found \nby looking for simple syntactic faults. For \nthe technique to be effective, many mutants \nmust be automatically generated and executed \nsystematically [6]. Mutation testing is also a \ntesting criterion in itself. Test cases are ran-\ndomly generated until enough mutants have \nbeen killed, or tests are specifically designed \nto kill surviving mutants. In the latter case, \nmutation testing can also be categorized as a \nstructure-based technique. Mutation testing \nhas been used effectively for generating fuzz \ntesting. A more recent application of the \nmutation process is metamorphic testing, a \ntechnique that has become increasingly pop-\nular in addressing some ML systems\u2019 testing \nchallenges. In this case, the modifications \n(called also morph) are applied to the inputs \nso a relationship can connect the previous \ninput (and its output) to the new morphed \ninput (and its output). 3.5. Usage-Based Techniques \n[1*, c15s5]\nUsage-based techniques usually rely on a usage \nmodel or profiles. In this case, the testing \nenvironment needs to represent the actual \noperational environment, and the sequence of \ntest case execution should reproduce the SUT \nusage by the target stakeholder. Statistical \nsampling is used for simulating the execu-\ntion of many test cases. Thus, sometimes, the \nterm random testing is also associated with \nthese techniques. Usage-based statistical \ntesting is applied more during the acceptance \ntesting stage. 3.5.1. Operational Profile \n[1*, c15s5, 2*, c11]\nTesting based on operational profiles aims at \ngenerating test cases that might estimate the \nreliability of the SUT or part of it. Therefore, \nthe goal is to infer from the observed test \nresults the future reliability of the software \n(when it is in use). Because the established \nreliability strictly depends on the operating \nprofile, the main difficulty (and cost) in using \nthis testing approach comes from the opera-\ntional profile derivation. Therefore, one pos-\nsible solution is to assign to the input the \nprobabilities or profiles according to their fre-\nquency of occurrence in actual operation. 3.5.2.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 132", "position": 132, "chunk_type": "semantic", "token_estimate": 366}
{"text": "SOFTWARE TESTING   5-15: Therefore, one pos-\nsible solution is to assign to the input the \nprobabilities or profiles according to their fre-\nquency of occurrence in actual operation. 3.5.2. User Observation Heuristics\n[19*, c5, c7; 4, part 4, annex A]\nSpecialized heuristics, also called usability \ninspection methods, are applied to systemat-\nically observe system use under controlled \nconditions to determine how well people can \nuse the system and its interfaces. Usability \nheuristics include cognitive walkthroughs, \nclaims analysis, field observations, thinking \naloud, and even indirect approaches such as \nuser questionnaires and interviews. 3.6. Techniques Based on the Nature of the \nApplication\n[2* c16, c17, c18, c20, c21; 14*, c4s8; 8] \nThe above techniques apply to all kinds of \nsoftware. Additional test derivation and exe-\ncution techniques are based on the nature of \nthe software being tested. Examples are the \nfollowing: \n\u2022\t Object-oriented software \n\u2022\t Component-based software\n\u2022\t Web-based software\n\u2022\t Concurrent programs \n\u2022\t Protocol-based software\n\u2022\t Communication systems\n\u2022\t Real-time systems \n\u2022\t Safety-critical systems\n\u2022\t Service-oriented software \n\u2022\t Open-source software \n\u2022\t Embedded software \n\u2022\t Cloud-based software\n\u2022\t Blockchain-based software\n\u2022\t Big data-based software\n\u2022\t AI/ML/DL-based software", "domains": ["Architectural Patterns and Styles", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 132", "position": 132, "chunk_type": "semantic", "token_estimate": 185}
{"text": "5-16   SWEBOK \u00ae GUIDE V4.0: \u2022\t Mobile apps\n\u2022\t Security and privacy-preserving software\nIn some cases, standards such as ISO/\nIEC/IEEE 29119 [4, part 4, part 5] pro-\nvide examples and support for specifying test \ncases, automating their execution, and main-\ntaining the test suites, such as the case of the \nKeyword-Driven Testing [4, part 5]. 3.7. Selecting and Combining Techniques \n[14*, c7s12; 10; 4, part 5] \nCombining different testing techniques has \nalways been a well-grounded means to assure \nthe required level of SUT quality. Currently, \nespecially in shift-left developments, method-\nologies for adaptive combinations of testing \ntechniques are part of the state of the prac-\ntice. The goal is to improve the effectiveness of \ntesting processes by learning from experience \nand, at the same time, adapting the technique \nselection to the current testing session. 3.7.1. Combining Functional and Structural\n[1*, c9; 4, part 5]\nScenario-based and structure-based test \ntechniques are often contrasted as functional \nvs. structural testing. These two approaches \nto test case selection are nowadays seen as \ncomplements, as they use different sources of \ninformation and have been shown to high-\nlight different problems. Depending on the \ndifferent organizational constraints, such \nas budgetary considerations, they could \nbe combined. 3.7.2. Deterministic vs. Random \n[1*, c9s6]\nTest cases can be selected in a determin-\nistic way, according to many techniques, or \nrandomly drawn from some distribution of \ninputs, such as is usually done in reliability \ntesting. Several analytical and empirical com-\nparisons have been conducted to analyze the \nconditions that make one approach more \neffective than the other. 3.8. Techniques Based on Derived Knowledge \n[2*, c19, c20; 14*, c7] \nTesting techniques can integrate evidence and \nknowledge from different research areas and \ncontexts. For this, approaches and methodol-\nogies are used to support testing activity and \nimprove its effectiveness. Currently, innova-\ntive approaches include using digital twins or \nsimulation methodologies and frameworks, \nexploiting ML and gamification facilities, \nand using (simulated) neuronal networks. 4. Test-Related Measures\n[2*, c24s5; 14*, c10; 4, part 4]\nTesting techniques are like tools that help in \nachieving specific test objectives. To evaluate \nwhether a test objective is reached, well-de-\nfined measures are needed. Measurement is \nusually considered fundamental to quality \nanalysis. Measurement may also be used to \noptimize test planning and execution. Test \nmanagement can use several different process \nmeasures to monitor progress. (See Software \nEngineering Measurement in the Software \nEngineering Management KA for informa-\ntion on measurement programs.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 133", "position": 133, "chunk_type": "semantic", "token_estimate": 402}
{"text": "SOFTWARE TESTING   5-17: especially in the case of structure-based \ntesting techniques, appropriate instrumenta-\ntion of the SUT may also be necessary. However, the proposed set of testing mea-\nsures can also be classified from different \nviewpoints \u2014 from the point of view of those \nproviding and allowing an evaluation of the \nSUT based on the observed test outputs and \nof those that evaluate the thoroughness or \neffectiveness of the executed test suites. 4.1. Evaluation of the SUT \n[2*, c24s5]\nUsually, indicators (i.e., measurable infor-\nmation) can be used to determine whether a \nSUT is performing as expected and achieving \nits expected outcomes. The indicators, some-\ntimes known as key performance indica-\ntors (KPIs), are strongly connected with the \nadopted evaluation measures, methods, data \nanalysis and reporting. 4.1.1. SUT Measurements That Aid in Planning  \n\t and Designing Tests \n[14*, c10; 10, c6; 4, part 1, part 4] \nAll the testing measures proposed in [4, \npart 4] can be used for planning and guiding \ntesting activities. Additionally, in the shift-\nleft development process, specific measures, \nsuch as deployment frequency, lead time, \nmean time to recovery (MTTR), and change \nfailure rate, are also commonly adopted \nto plan and manage the testing activities \nand results. 4.1.2. Fault Types, Classification and Statistics\n [1* c13s4, c13s5, c13s6]\nThe testing literature is rich in classifica-\ntions and taxonomies of faults that can be \ngeneric or specific to a context or quality \nattributes (such as the usability defect clas-\nsification, the taxonomy of HW/SW security \nand privacy vulnerabilities and attacks, and \nthe classification of cybersecurity risks). To \nmake testing more effective, it is important \nto know which types of faults may be found \nin the SUT and the relative frequency with \nwhich these faults have occurred in the past. This information can be useful in making \nquality predictions and in process improve-\nment (See Characterization in the Software \nQuality KA). 4.1.3. Fault Density \n[1*, c13s4; 14*, c10s1]\nTraditionally, a SUT can be evaluated \nby counting discovered faults as the ratio \nbetween the number of faults found and the \nSUT size. Because of the semantics-based \ndefinition of faults, additional measurements \ncan be considered, such as fault depth (the \nminimal number of fault removals needed to \nmake a SUT correct) and fault multiplicity \n(the number of atomic changes needed to \nrepair a single fault). 4.1.4.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 134", "position": 134, "chunk_type": "semantic", "token_estimate": 384}
{"text": "SOFTWARE TESTING   5-17: Because of the semantics-based \ndefinition of faults, additional measurements \ncan be considered, such as fault depth (the \nminimal number of fault removals needed to \nmake a SUT correct) and fault multiplicity \n(the number of atomic changes needed to \nrepair a single fault). 4.1.4. Life Test, Reliability Evaluation \n[1*, c15, 2*, c11; 14*, c1s3]\nA statistical estimate of software reliability, \nwhich can be obtained by observing reli-\nability achieved, can be used to evaluate a \nSUT and decide whether testing can be \nstopped or the SUT is mature enough to be \na candidate for the next shift-left develop-\nment release. Reliability evaluation is taking \na pivotal role in the Cloud (and fog) con-\ntexts [18]. On the one hand, validation and veri-\nfication proposals are focusing on main-\ntaining the high level of reliability and \navailability required by the cloud (fog) ser-\nvices. On the other, testing activities are \nexploiting the computational power of the \ncloud (fog) environment to speed up the \nreliability evaluation and drastically reduce \nits costs. 4.1.5. Reliability Growth Models \n[1*, c15, 2* c11s5]\nReliability growth models predict reli-\nability based on observed failures. They \nassume, in general, that when the faults", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 134", "position": 134, "chunk_type": "semantic", "token_estimate": 197}
{"text": "5-18   SWEBOK \u00ae GUIDE V4.0: that caused the observed failures have been \nfixed (although some models also accept \nimperfect fixes), the product\u2019s reliability \nwill increase. There are many published \nreliability growth models. Notably, these \nmodels are divided into failure-count and \ntime-between-failure models. 4.2. Evaluation of the Tests Performed \n[4, part 4, c6]\nThe behavior of SUT is generally verified \nby executing test suites, which are pivotal \nin finding defects. Therefore, from both the \nresearchers\u2019 and practitioners\u2019 perspectives, a \nfundamental part of software testing is com-\nparing test suites. Usually, evaluating the test \nsuites means comparing techniques for test \ncase generation that produce the test cases. Different criteria are used for that purpose, \nsuch as coverage criteria or mutation anal-\nysis criteria. 4.2.1. Fault Injection\n[1*, c2s5]\nIn fault injection, some faults are artificially \nintroduced into the SUT before testing. When a test suite is executed, some of these \ninjected faults are revealed, as are, possibly, \nsome faults that were already there. In theory, \ndepending on which and how many artificial \nfaults are discovered, the testing effectiveness \ncan be evaluated, and the remaining number \nof genuine faults can be estimated. In prac-\ntice, statisticians question the distribution \nand representativeness of injected faults rel-\native to genuine faults and the small sample \nsize on which any extrapolations are based. Some also argue that this technique should \nbe used with great care because inserting \nfaults into the SUT incurs the obvious risk of \nleaving them there. 4.2.2. Mutation Score \n[1*, c3s5; 6] \nIn mutation testing, the test suite effective-\nness measure is calculated as the ratio of killed \nmutants to the number of generated mutants. The higher the test suite effectiveness value, \nthe better, since it indicates a stronger ability \nto discover the most real injected faults. 4.2.3. Comparison and Relative Effectiveness of  \n\t Different Techniques \n[1*, c1s7; 5; 9] \nRelative effectiveness compares different \ntesting techniques against a specific property, \nsuch as the number of tests needed to find the \nfirst failure, the ratio of the number of faults \nfound through testing to all the faults found \nduring and after testing, and how much reli-\nability was improved. Several studies have \nalready been conducted to compare dif-\nferent techniques analytically and empirically \naccording to each notion of property (or effec-\ntiveness) defined. 5.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 135", "position": 135, "chunk_type": "semantic", "token_estimate": 379}
{"text": "5-18   SWEBOK \u00ae GUIDE V4.0: Several studies have \nalready been conducted to compare dif-\nferent techniques analytically and empirically \naccording to each notion of property (or effec-\ntiveness) defined. 5. Test Process \n[4, part 1, part 2, part 3; 2* c8] \nTesting concepts, strategies, techniques and \nmeasures need to be integrated into a defined \nand controlled test planning process to test \noutput evaluation. The test process supports \ntesting and provides guidelines to those respon-\nsible for different testing activities to ensure \nthe test objectives are met cost-effectively. As described in [4, part 2], the test pro-\ncess is a multi-layered process activity that \nincludes the test specification at the organi-\nzational, management and dynamic levels. The organizational test process defines the \nsteps for creating and maintaining test speci-\nfications, such as organizational test policies, \nstrategies, processes, procedures, and other \nassets [4, part 2]. The test management process defines the \nsteps necessary for management: planning, \nmonitoring and control, and completion. Finally, the dynamic test process speci-\nfies the steps for design and implementation, \nenvironment setup and maintenance, execu-\ntion, and test incident reporting. In the remainder of this section, some \npractical considerations about the test process", "domains": ["Architectural Patterns and Styles", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 135", "position": 135, "chunk_type": "semantic", "token_estimate": 195}
{"text": "SOFTWARE TESTING   5-19: specification, management, and execution, as \nwell as a summary of the test sub-processes \nand activities included in the organizational, \nmanagement and dynamic levels as in [4, part \n2], are provided. 5.1. Practical Considerations \n[4, part 1]\nTesting processes should allow the automation \nof different testing phases and should rely on \nthe controllability, traceability, replicability, \nand risk/cost estimation of the performed \nactivities. In the remainder of this section, \ncommonly applied test steps are described, \ncompatible with and applicable to all life cycle \nmodels. (See Software Life Cycles in the \nSoftware Engineering Process KA.) 5.1.1. Attitudes/Egoless Programming \n[1*, c16; 2*, c3]\nAn important element of successful testing \nis a collaborative attitude toward testing and \nquality assurance (QA) activities. Managers \nhave a key role in fostering a favorable recep-\ntion toward failure discovery and correction \nduring software development and mainte-\nnance. For instance, in shift-left change in \ndevelopment, such as Agile, communication \nand collaboration among testers and devel-\nopers are considered vital for achieving suc-\ncessful testing results. 5.1.2. Test Guides and Organizational Process \n[1*, c12s1, 2* c8; 4, part 2, part 3; \n14*, c7s3]\nVarious aims can guide the testing phases. For \nexample, risk-based testing uses the product \nrisks to prioritize and focus the test strategy, \nand scenario-based testing defines test cases \nbased on specified software scenarios and \nbacklog lists. Usually, the organization of \nthe test process includes defining test policies \n(i.e., specifying the purpose, goals, and overall \nscope of testing) and test strategies (i.e., spec-\nifying the guidelines about how testing will \nbe carried out). For instance, in shift-left \ndevelopments, a test strategy should include \nat least the following data: the purposes (e.g., \ndefined through user stories), the objectives \n(e.g., a test suite), the scope (the SUT), and \nthe environment and methods (e.g., how, and \nwhere the test suite is run). 5.1.3. Test Management and Dynamic Test  \n\t Processes\n[1*, c12; 4, part 2, part 3, 14*, c7s3]\nTest activities conducted at different levels (see \nSection 2, Test Levels) should be organized \n\u2014 with people, tools, policies, and measures \n\u2014 into a well-defined process integral to the \nlife cycle. Test process management includes \ndifferent subprocesses such as planning, mon-\nitoring, control, and completion, whereas the \nDynamic test process includes test design and \nimplementation, test environment set-up and \nmaintenance, test execution, and test incident \nreporting. 5.1.4.", "domains": ["Design Patterns", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 136", "position": 136, "chunk_type": "semantic", "token_estimate": 386}
{"text": "SOFTWARE TESTING   5-19: Test process management includes \ndifferent subprocesses such as planning, mon-\nitoring, control, and completion, whereas the \nDynamic test process includes test design and \nimplementation, test environment set-up and \nmaintenance, test execution, and test incident \nreporting. 5.1.4. Test Documentation\n[1*, c8s12; 14*, c7s8; 4, part 3] \nAccording to [4, part 3], documentation is \nintegral to the formalization of the test pro-\ncess. Test documents can be classified into \nthree hierarchical categories: organizational \ntest documentation, test management docu-\nmentation and dynamic test documentation. Organizational test documentation includes \nthe information necessary for documenting \nthe test policy and the organizational test \nstrategies. Test management documentation \nincludes the test plan, test status report and \ntest completion report. Finally, dynamic test \ndocumentation includes the following docu-\nments: test specification (test design specifica-\ntion, test case specification and test procedure \nspecification), test data requirements, test \nenvironment requirements, test data readiness \nreport, test environment readiness report, and \ntest execution documentation (such as actual \nresults, test results, test execution log and \nincident report). Test documentation should be produced \nand continuously updated with the same", "domains": ["Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 136", "position": 136, "chunk_type": "semantic", "token_estimate": 178}
{"text": "5-20   SWEBOK \u00ae GUIDE V4.0: quality as other software engineering doc-\numentation. Test documentation should \nalso be under the control of software con-\nfiguration management. (See the Software \nConfiguration Management KA.) 5.1.5. Test Team \n[1*, c16; 2* c23s5; 4, part 2, part 3]\nFormalizing the testing process may also \ninvolve formalizing the testing team\u2019s orga-\nnization. Considerations of cost, schedule, \nmaturity levels of the involved organizations \nand criticality of the application can guide the \ndecision. The testing team can be composed of \nmembers involved (or not) in the SUT devel-\nopment (i.e., having or not having an unbi-\nased, independent perspective) or internal \n(or external) personnel. Nowadays, shift-left \ndevelopment does not strongly distinguish \namong testing team members because the test \nsuite is defined and updated according to the \nSUT development and delivered code. 5.1.6. Test Process Measures \n[1*, c18s3, 14*, c10; 4, part 1, part \n2, part 3] \nManagers use several measures for the \nresources spent on testing, as well as for the \nrelative fault-finding effectiveness of the var-\nious test phases, to control and improve the \ntesting process, as well as to provide informa-\ntion for managing process risks. Therefore, \nmonitor and control testing must define \nrequired data and information and state how \nto obtain them. The test measures may cover \nthe number of specified, executed, passed, \nand failed test cases, among other elements. These measures can also be combined with \nspecific process metrics such as residual risk, \ncumulative defects open and closed, test case \nprogress, and defect detection percentage. Evaluation of test phase reports can be com-\nbined with root-cause analysis to evaluate \ntest process effectiveness in finding faults as \nearly as possible. Such an evaluation can be \nassociated with risk analysis. Moreover, the \nresources deemed worth spending on testing \nshould be commensurate with the applica-\ntion\u2019s use and criticality. Different techniques \nhave different costs and yield different confi-\ndence levels in product reliability. 5.1.7. Test Monitoring and Control \n[4, part 1, part 2] \nMonitoring and Control comprise an important \nsub-process of the test management process as \nin [4, part 2], useful for collecting data and \ninformation required during test management \nand assessment. Usually, monitoring and con-\ntrol activities are executed in parallel with \nthe test execution, and sometimes, data col-\nlected might prompt revision of overall pro-\ncess planning. Monitoring assures that testing \nprocess activities comply with a specific test \nplan to trace the requirements satisfaction \nand mitigate the identified risks satisfactorily.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 137", "position": 137, "chunk_type": "semantic", "token_estimate": 405}
{"text": "5-20   SWEBOK \u00ae GUIDE V4.0: Usually, monitoring and con-\ntrol activities are executed in parallel with \nthe test execution, and sometimes, data col-\nlected might prompt revision of overall pro-\ncess planning. Monitoring assures that testing \nprocess activities comply with a specific test \nplan to trace the requirements satisfaction \nand mitigate the identified risks satisfactorily. During test monitoring and control, specific \ndocumentation (test reports) can regularly be \nproduced to help assess and document the \ntest activity. 5.1.8. Test Completion \n[14*, c7s11; 4, part 3]\nA decision must be made about how much \ntesting is enough and when a test stage can \nbe completed. Therefore, the purpose of Test \nCompletion, a sub-process of the test manage-\nment process as in [4, part 2], is to ensure that \ntest requirements are satisfied and verified, \ntest reports are completed, and test results \nare communicated to relevant stakeholders. Thoroughness measures, such as achieved code \ncoverage or functional coverage, and estimates \nof fault density or operational reliability, pro-\nvide useful support but are not sufficient in \nthemselves. The decision also involves consid-\nerations about the costs and risks incurred by \npossible remaining failures, as opposed to the \ncosts incurred by continuing to test (See Test \nSelection and Adequacy Criteria in Section \n1.2, Key Issues.) As for the other activities, in \nthis stage, specific documentation is produced \n(e.g., test completion report) and communi-\ncated to the relevant stakeholders.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 137", "position": 137, "chunk_type": "semantic", "token_estimate": 232}
{"text": "SOFTWARE TESTING   5-21: 5.1.9. Test Reusability\n[14*, c3; 9]\nIt is necessary to add complexity and time \nfor test planning and design to achieve reus-\nability of the testing artifacts, such as the \ntest case or execution environment, which \nis desired when test development is costly, \ntime-consuming, and complex. Test reusability collects and classifies the \ntesting knowledge (test cases and test results) \nto make this information searchable and \nusable for creating new tests or re-executing \nan existing one. Suitable knowledge-based \nrepositories should be configured and man-\naged to test reusability so changes to soft-\nware requirements or design can be reflected \nin changes to the tests. Currently, the reusability of test cases is \npivotal in feature-based or product-line devel-\nopment and regression testing. Test reus-\nability also relates to maintainability because \nreusability can reduce the cost and effort \ninvolved and improve a test\u2019s effectiveness. 5.2. Test Sub-Processes and Activities\n[1*, c1s12; 1*, c12s9; 4, part 2]\nIn the remainder of this section, the main \ntesting activities and sub-processes are briefly \nintroduced. 5.2.1. Test Planning Process \n[1*, c12s1, c12s8; 11; 4, part 2] \nLike all other aspects of project manage-\nment, testing activities must be planned. According to [4, part 2], key aspects of test \nplanning include identification and coor-\ndination of personnel, identification of \nthe test objective and completion criteria, \ndefinition of test facilities and equipment, \ncreation and maintenance of all test-re-\nlated documentation, and risk planning and \nmanagement for possible undesirable out-\ncomes. These activities can be organized at \nthree different levels: (1) process manage-\nment (i.e., identification of test policies, \nstrategies, processes, and procedures), (2) \norganizational management (i.e., definition \nof the test phase, test type and test objective), \nand (3) design and implementation (i.e., defi-\nnition of the test environment, the test execu-\ntion process and monitoring, the completion \nprocess, and reporting). 5.2.2. Test Design and Implementation\n[1*, c12s1, c12s3; 11]\nGeneration of test cases is based on the \nlevel of testing to be performed and the \nchosen testing techniques. According to \nthe dynamic test process, as described in [4, \npart 2], preconditions of the test case gener-\nation are the identification of test objectives \nand the selection of the appropriate testing/\ndemonstration techniques. Test generation \nfocuses on implementing and executing test \ncases. It often relates to tooling (i.e., using \nspecific software, also called a test cases gen-\nerator).", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 138", "position": 138, "chunk_type": "semantic", "token_estimate": 391}
{"text": "5-22   SWEBOK \u00ae GUIDE V4.0: 5.3. Staffing \n[1*, c16; 4, part 3]\nAccording to [4, part 3], staffing includes \ndefining roles, activities, and responsibilities, \nspecifying hiring needs, and defining training \nneeds. Staffing affects project risk because the \nteam\u2019s expertise might undermine the ability \nto discover faults, to address changing require-\nments, to meet deadlines, and increase/reduce \nmaintenance costs. The roles, activities and responsibilities \ndefinition establishes the following roles and \nresponsibilities: the activity leader and sup-\nporting personnel, the test-related roles and \ntheir corresponding responsibilities, and the \nperson responsible for providing the test item(s). Depending on the development lifecycle \nadopted, typical testing roles include but are \nnot limited to scrum master/test lead, QA/\ntest analyst, test designer, test security/perfor-\nmance engineer and consultant, test environ-\nment expert, test executor and test automation \nconsultant or architect. Hiring needs require the identification of \nspecific requirements for which additional \ntesting personnel are needed to complete the \ntesting process (as well as when that personnel \nis needed and the desired skills). Depending \non the business needs, staffing could take \ndifferent forms, from internal transfers to \nexternal hires or even consultants and/or out-\nsourced resources. Finally, the training needs specification \nincludes the definition of the required skill", "domains": ["Software Quality Attributes", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 139", "position": 139, "chunk_type": "semantic", "token_estimate": 201}
{"text": "SOFTWARE TESTING   5-23: level. It also includes the specification of the \ntraining activities (such as classroom training, \nself-paced training, computer-based training, \nor mentoring) useful for providing the neces-\nsary skills to the selected staff. 6. Software Testing in the Development \nProcesses and the Application Domains\n[2*, c8, c15; 14*, c4s8, c7]\nWhatever development process is adopted, \ntesting remains a fundamental activity. However, specific testing activities or termi-\nnologies could be used in some cases, such as \nthe adopted development life cycle and/or the \napplication domain \n6.1. Testing Inside Software Development \nProcesses \n[2*, c8; 14*, c7] \nIn the remainder of this section, peculiarities \nof testing inside the different development \nprocesses are provided. 6.1.1. Testing in Traditional Processes \n[1* c18; 14*, c7] \nThere are a variety of traditional processes, \nessentially based on the SUT development \nprinciples, that can be adopted within the \norganization. Sequential, V, spiral model and \niterative are just some of the processes com-\nmonly applied. (Software Life Cycles in the \nSoftware Engineering Process KA provides \na detailed description of each.) However, in \nall these processes, testing is just one per-\nceived activity; it is sometimes performed at \nthe end of the process, with a tangible risk \nof SUT development failure in case of devi-\nation of the end-user needs or assessment \nissues. During recent years, to evaluate and \ncontrol the overall quality of the SUT, initia-\ntives such as test maturity model integration \n(TMMi) and software process improvement \n(SPI) have been established. As a result, dif-\nferent existing frameworks have been updated \nor improved for the purpose, such as soft-\nware process improvement and capability \ndetermination (SPICE), capability maturity \nmodel integration (CMMI), and unified pro-\ncess (UP). For instance, CMMI is one of the most \nreferenced models; it can guide key SUT \nstakeholders in gaining control of their devel-\nopment and maintenance processes. It is, in \nfact, a well-defined set of best practices in \nsoftware testing that improves SUT quality \nby increasing customer satisfaction. Presented in the early 2000s, the UP model \ncan be seen as a predecessor of the shift-left \nmovement. UP encourages testing early by \noffering several mechanisms to integrate \ntesting more closely with the software devel-\nopment effort, making testing a distinct disci-\npline. Furthermore, UP promotes an iterative \ndevelopment approach for continuously ver-\nifying quality. It also enables use cases and \nrisk to drive SUT development and allows \nstrategic change management.", "domains": ["Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 140", "position": 140, "chunk_type": "semantic", "token_estimate": 396}
{"text": "5-24   SWEBOK \u00ae GUIDE V4.0: A. The internal code quality: Regression, \nprioritization, security, and privacy could \nbe the primary objectives of the internal \ncode quality (Section 2.2). Usually, unit \ntesting and integration testing are the \ntargeted levels (Section 2.1), whereas \nstructure-based is the main testing tech-\nnique (Section 3.2). B. Business needs: Compliance and confor-\nmance, usability, security, and privacy are \njust a subset of the possible objectives of \nthe business needs aspect (Section 2.2). Concerning this aspect, testing focuses \nmore on the system and acceptance test \nlevels and on end-user expectations, as \nwell as usage-based (Section 3.5) and sce-\nnario-based techniques (Section 3.1.8). C.\t Perceived quality: Alpha, beta, instal-\nlation, usability, security, and privacy \ncould be the primary objectives of the \ninternal perceived quality (Section 2.2). Perceived quality usually focuses on the \nacceptance test level and is achieved \nby applying techniques based on soft-\nware engineering\u2019s intuition and experi-\nence (Section 3.3) and usage-based and \nfault-based techniques, such as mutation \ntesting (Section 3.4). D.\t Quality assurance: Performance installa-\ntions, security, and privacy conformance \nand compliance are some main objectives of \nquality assurance (Section 2.2). This aspect \nmay involve all testing levels, and the selec-\ntion of the testing technique depends on \nthe objective and the level chosen. Here, some examples of testing inside the \ndifferent shift-left movements implementa-\ntion are provided:\n\u2022\t In Agile process development, testing \nactivities involve all stakeholders (such as \ncustomers and team personnel) and target \nthe identification of where improvements \ncould be made in future interactions. Managing the risk of regression defects, \nmeeting changing requirements, and \nmanaging their impact on test artifacts \nare also objectives of the Agile testing \nprocess. Typically, test automation is used \nto manage the regression risk, and explor-\natory testing may be used to manage a \nlack of detailed requirements. \u2022\t In TDD, the test cases mainly target \nthe software requirements specifications \nand acceptance, and they are generated \nin advance of the code being written. The tests are based on the user stories \nand implemented using automated com-\nponent testing tools. Indeed, TDD is a \npractice that requires defining and main-\ntaining unit tests and can help clarify the \nuser needs and software requirements \nspecifications. \u2022\t In testing automated builds and contin-\nuous integration (for instance, DevOps), \nthe SUT is continuously developed, inte-\ngrated, delivered and monitored. In this \nprocess, regression testing is continuously \nperformed to timely identify and cor-\nrect development and integration issues.", "domains": ["Software Quality Attributes", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 141", "position": 141, "chunk_type": "semantic", "token_estimate": 404}
{"text": "5-24   SWEBOK \u00ae GUIDE V4.0: \u2022\t In testing automated builds and contin-\nuous integration (for instance, DevOps), \nthe SUT is continuously developed, inte-\ngrated, delivered and monitored. In this \nprocess, regression testing is continuously \nperformed to timely identify and cor-\nrect development and integration issues. Additionally, quick testing techniques, \nsuch as smoke testing, are commonly \nused during continuous integration to \nguarantee that the SUT is testable before \nit is released to the operational stage. 6.2. Testing in the Application Domains\n[2*, c15; 14*, c4s8]\nUsually, an application domain is strictly con-\nnected to a certain reality. Therefore, testing \napproaches could be tailored to the needs of \nthe domain and customized to the adopted \ntechnologies. Below, we provide an overview of dif-\nferent aspects and solutions for software \ntesting applied within several domain-spe-\ncific environments:\n\u2022\t Automotive domain testing: Due to the \ncomplexity of automotive systems, this \ntesting involves aspects of almost every \nsoftware component and its interaction \nwith hardware. Security testing, simula-\ntion testing, reliability/life cycle testing, \nintegrated systems testing, data acquisi-\ntion and signal analysis testing, quality", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 141", "position": 141, "chunk_type": "semantic", "token_estimate": 178}
{"text": "SOFTWARE TESTING   5-25: testing and inspection, and stress/strain \ntesting are just some of the various testing \nperformed in this domain. Several sup-\nporting standards are currently available \nto guide and manage automotive testing \naccording to the peculiarity, the compo-\nnent, or the quality aspect that should \nbe assessed. Autosar2 and Automotive \nSPICE3 are examples. \u2022\t Internet of things (IoT) domain testing: \nThis testing involves application develop-\nment, device management, system man-\nagement, heterogeneity management, \ndata management, and tools for anal-\nysis, deployment, monitoring, visualiza-\ntion and research. Additionally, security, \nprivacy, communications and user/com-\nponent interaction should be considered \nin the quality assessment. For example, \nguidelines and specific conformance test \nsuites for cybersecurity assessment of the \nIoT SUT are detailed in the European \nTelecommunications Standards Institute \n(ETSI) standards.4 \n\u2022\t Legal domain testing: One of the most \nimportant aspects in the legal domain \nis the management of highly sensitive \nusers; therefore, security, privacy and \ntrust are the most common areas of focus \nfor testing. Additionally, because of the \ncopious data collected and exchanged, \nperformance testing of the data reposi-\ntory, testing to show accurate commu-\nnication and integration testing, as well \nas consistency and compliance testing, \nshould also be done. Finally, because the \nlegal domain is characterized by specific \nnomenclature and jargon, involving legal \ndomain experts in test case generation \nis common practice to ensure a focus on \ndesired characteristics and quality. 2\t\n https://www.autosar.org/\n3\t\n https://www.automotivespice.com/\n4\t\n https://www.etsi.org/\n5\t\n https://www.w3.org/2013/07/webmobile-ig-charter.html\n6\t\n www.astm.org. 7\t\nhttps://www.hl7.org/\n8\t\nhttp://fhir.org/\n\u2022\t Mobile domain testing: This testing is \nusually for usability, functional, con-\nfiguration and consistency assessment. Mobile-specific aspects such as screen \nresolution, global positioning system \n(GPS), operating systems, and device \nmanufacturers should also be consid-\nered during testing activity. Finally, the \ntype of mobile applications (native or web \napps) and their interactions need to be \ntested. For example, the W3C Web and \nMobile Interest Group5 provides facil-\nities, guidelines and ad hoc test suites \nuseful for developing and testing web-\nbased content, applications and services. \u2022\t Avionics domain testing6: Usually, avi-\nonics systems include several indepen-\ndent or loosely coupled components and \ncommercial off-the-shelf products. Those \nforces testing to include very general \nprocesses and approaches applicable at \nboth the system and the process levels. Functional and non-functional, integra-\ntion, communication operational, stress, \nsafety, and security testing are exam-\nples of possible approaches. As in other \ndomains, supporting standards such \nas Aeronautical Radio Incorporated \n(ARINC) \nStandards \nand", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 142", "position": 142, "chunk_type": "semantic", "token_estimate": 400}
{"text": "F3153-15 can be used for reference.: \u2022\t Healthcare domain testing: Healthcare \ndomain testing should ensure quality \nin areas such as secure and reliable data \nexchange, stable performance, privacy, \nand safety. Interoperability, usability, per-\nformance and compliance with industry \nregulations, as well as security and safety \nstandards (such as the Health Level Seven \n(HL7),7 Fast Healthcare Interoperability \nResources (FHIR),8 Digital Imaging \nand \nCommunications \nin \nMedicine", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 142", "position": 142, "chunk_type": "semantic", "token_estimate": 64}
{"text": "5-26   SWEBOK \u00ae GUIDE V4.0: (DICOM),9 Health Insurance Portability \nand Accountability Act (HIPAA),10 and \nthe General Data Protection Regulation \n(GDPR)11) should also be considered. \u2022\t Embedded domain testing: Because soft-\nware and hardware are tightly coupled \nin embedded systems, testing activity \nshould assess functional and non-func-\ntional attributes of both software and \nhardware. \u2022\t Graphical user interface (GUI) testing: \nGUI testing involves assessing the UI \n(user interface) (i.e., the elements of the \nuser objects that we can see). Thus, GUI \ntesting targets the design pattern, images, \nalignment, spellings, and the overall look \nand feel of the UI. Testing approaches \nbased on finite-state machines, goal-\ndriven approaches, approaches based on \nabstractions and model-based approaches \ncan be considered. \u2022\t Gaming: Gaming applications and soft-\nware are currently a very active sector of \nsoftware production, causing increased \ndemand for new approaches and ways \nto ensure their quality and security. Among the specific testing techniques, \nplaytesting is one of the most adopted. In this case, real gamers repeat quality \ncontrol methods at many points of the \ngame execution or design process. GUI \ntesting, \nfunctionality \ntesting, \nsecu-\nrity testing, console testing, compliance \ntesting and performance testing can also \nbe considered. \u2022\t Real-time domain testing: Real-time \ntesting usually focuses on assessing \ntiming constraints and deterministic \nbehavior. Usually, unit, integration and \nsystem testing approaches can be adopted. Communication, interaction and behav-\nioral testing can also be performed. \u2022\t Service oriented architecture (SOA) \ntesting: This testing focuses mainly \non \ncorrectly \nimplementing \nbusiness \n9\t\nhttps://www.dicomstandard.org/\n10\t https://www.hhs.gov/hipaa/. 11\t  https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:32016R0679. processes and involves unit and integra-\ntion testing approaches. Structure-based, \nspecification-based and security testing \ncan be applied. The testing activity might \nvary according to the environment, orga-\nnization and set of requirements that \nshould be satisfied. \u2022\t Finance domain testing: This testing \ncovers a wide range of aspects, from man-\naging financial requirements to assessing \nfinancial applications and software pro-\ngrams. As in other domains, domain-spe-\ncific knowledge (such as that held by, for \nexample, banks, credit unions, insurance \ncompanies, credit card companies, con-\nsumer finance businesses, investment funds \nand stock brokerages) could be necessary \nto apply the testing process effectively and \nefficiently. Customer satisfaction, usability, \nsecurity, privacy, third-party component \nand apps integrations, real-time issues, \nand performance are some of the most \nimportant challenges in this domain. 7.", "domains": ["Design Patterns", "Software Quality Attributes", "Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 143", "position": 143, "chunk_type": "semantic", "token_estimate": 378}
{"text": "5-26   SWEBOK \u00ae GUIDE V4.0: Customer satisfaction, usability, \nsecurity, privacy, third-party component \nand apps integrations, real-time issues, \nand performance are some of the most \nimportant challenges in this domain. 7. Testing of and Testing Through \nEmerging Technologies \nIn recent decades, software development was \ndriven by emerging trends such as the wide-\nspread diffusion of mobile technology, cloud \ninfrastructures adoption, big data analysis \nand the software as a service paradigm, which \nhighlighted new constraints and challenges \nfor testing. 7.1. Testing of Emerging Technologies\n\u2022\t Testing artificial intelligence (AI), ML/\ndeep learning (DL) [13]: AI, ML and \nDL are successfully being applied in \npractice. Sooner or later, most business \napplications will have some form of AI, \nML or DL. Because of their peculiarities, \ntesting such applications is challenging \nand might be very expensive. AI, ML or", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 143", "position": 143, "chunk_type": "semantic", "token_estimate": 134}
{"text": "SOFTWARE TESTING   5-27: DL testing refers to any activity designed \nto reveal AI, ML or DL bugs. o\t Three main aspects should be consid-\nered in defining bugs and testing in \nthis scenario: the required conditions \n(correctness, robustness, security, and \nprivacy); the AI, ML or DL items \n(e.g., a bug might exist in the data, \nthe learning program, or the frame-\nwork used); and the involved testing \nactivities (test case generation, test \noracle identification and definition, \nand test case adequacy criteria). o\t In all these applications, a prototype \nmodel is first generated based on his-\ntorical data. Then, offline testing, \nsuch as cross-validation, is con-\nducted to verify that the generated \nmodel satisfies the required condi-\ntions. Usually, after deployment, the \nmodel is used for prediction purposes \nby generating new data. Finally, the \ngenerated data is analyzed through \nonline testing to evaluate how the \nmodel interacts with user behaviors. \u2022\t Testing blockchain [15]: The commonly \nused testing techniques for validating \nblockchains and related applications such \nas smart contracts are stress testing, pen-\netration testing and property testing. However, depending on the specific situa-\ntion, different aspects should be considered \nduring the testing of a blockchain-based \nSUT, such as the following:\n\u2022\t Platform type: The level of validation \ndepends on the type of platform used for \nimplementation \u2014 public or private. The \nlatter requires a much greater testing effort. \u2022\t Connection with other applications: \nIntegration testing should be performed \nto check consistency when the blockchain \nworks with various applications. \u2022\t Performance: Performance testing should \nbe conducted when performance issues \nare a concern. Specific strategies to handle \nmany transactions should be conceived \nto guarantee a satisfactory performance \nlevel. Qualitative and quantitative met-\nrics, such as average transaction valida-\ntion latency and security, should also be \nconsidered. \u2022\t Testing the cloud [1*, c10s10, 2*, c18]: \nTesting the cloud validates the quality of \napplications and infrastructures deployed \nin the cloud by considering both func-\ntional and non-functional properties. The \nfocus is to identify problems posed by \nsystems residing in the cloud. Therefore, \ntesting activities use techniques to val-\nidate \ncloud-based \nservices\u2019 \nperfor-\nmance, scalability, elasticity and security. Moreover, testing should also focus on \ncompatibility and interoperability among \nheterogeneous cloud resources when dif-\nferent deployment models are used (e.g., \nprivate, public or hybrid).", "domains": ["Design Patterns", "Software Quality Attributes", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 144", "position": 144, "chunk_type": "semantic", "token_estimate": 378}
{"text": "SOFTWARE TESTING   5-27: Therefore, \ntesting activities use techniques to val-\nidate \ncloud-based \nservices\u2019 \nperfor-\nmance, scalability, elasticity and security. Moreover, testing should also focus on \ncompatibility and interoperability among \nheterogeneous cloud resources when dif-\nferent deployment models are used (e.g., \nprivate, public or hybrid). \u2022\t Testing concurrent and distributed appli-\ncations [1*, c10s10, 2*, c17]: One main \naspect of testing dynamic, complex, dis-\ntributed or concurrent applications is \ndealing with multiple operating systems \nand updates, multiple browser platforms \nand versions, different types of hardware, \nand many users. For such testing, it\u2019s dif-\nficult to use testing approaches based on \nthe classical hierarchy between compo-\nnents or systems; instead, solutions based \non input/output, dependency threads, \nor dynamic relations often work better. Additionally, the possibility of continuous \nintegration and deployment of the dif-\nferent components forces the testing pro-\ncess to include approaches for managing \ncontinuous test operation, injection, mon-\nitoring and reporting according to the \ntime, bandwidth usage, throughput, and \nadaptability constraints. Finally, there is \nstill the need for solutions that allow the \nreusability of testing knowledge, archi-\ntectures, and code to make the testing \nactivity more effective and less expensive. 7.2. Testing Through Emerging Technologies\n\u2022\t Testing through ML [13]: AI, ML or DL \ntechniques are successfully used to reduce", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 144", "position": 144, "chunk_type": "semantic", "token_estimate": 210}
{"text": "5-28   SWEBOK \u00ae GUIDE V4.0: the effort involved in several activities in \nsoftware engineering (such as behavior \nextraction, testing or bug fixing). These \ntechniques aid both researchers and \npractitioners in adopting and identi-\nfying appropriate methods for their \ndesired applications. There is a growing \ninterest in adopting ML techniques in \nsoftware testing because most software \ntesting issues are being formulated as \nML learning problems. Indeed, AI, ML \nor DL is intensively used in almost all \nsoftware, such as test case design, the \noracle problem, test case evaluation, test \ncase prioritization and refinement, and \nmutation testing automation. Indeed, \nthey can reduce maintenance efforts \nand improve the overall SUT quality \nbecause of their ability to analyze large \namounts of data for classifying, triaging \nand prioritizing bugs more efficiently. From a DevOps perspective, AI, ML \nand DL solutions can be used in SUT \nautomation authoring and execution \nphases of test cases, as well as in the \npost-execution test analysis that identi-\nfies trends, patterns and impact on SUT \ntesting activity. \u2022\t Testing \nthrough \nblockchain \n[15]: \nTesting becomes complicated when dif-\nferent teams, domain experts and users \nneed to work together in collaborative, \nlarge-scale systems and complex soft-\nware systems to achieve a common goal. This is mainly because of the time con-\nstraint, data sharing policies, acceptance \ncriteria and trusted coordination among \nthe teams involved in the testing process. Blockchain technologies can be exploited \nto improve software testing efficiency \nand avoid using centralized authority to \nmanage different testing activities. This \ncan help ensure distributed data man-\nagement, tamper resistance, auditability, \nand automatic requirement compli-\nance to improve the quality of software \ntesting and development. Blockchain-\nbased approaches for trusted test case \nrepository management and to support \ntest-based software and security testing \nare also considered. \u2022\t Testing through the cloud [17]: Testing \nthrough the cloud refers to SUT testing \nperformed by leveraging scalable cloud \ntechnologies. Usually, the cloud is used \nfor testing purposes wherever large-scale \nsimulations and elastic resources are nec-\nessary. Indeed, this can affect cost reduc-\ntion, development, and maintenance of \nthe testing infrastructure (scaffolding), \nand online validation of systems, such as \nML-based SUT. A particular situation is \nthe testing of the cloud through the cloud \nitself. This is an example of the inter-\nsection between testing of and testing \nthrough emerging technologies. The \napplications and infrastructures deployed \nin the cloud can be tested, exploiting the \ncloud\u2019s bandwidth.", "domains": ["Software Quality Attributes", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 145", "position": 145, "chunk_type": "semantic", "token_estimate": 396}
{"text": "5-28   SWEBOK \u00ae GUIDE V4.0: This is an example of the inter-\nsection between testing of and testing \nthrough emerging technologies. The \napplications and infrastructures deployed \nin the cloud can be tested, exploiting the \ncloud\u2019s bandwidth. \u2022\t Testing through simulation [1*, c3s9]: \nSimulation is an important technology \nfor testing activity because it represents \na valid means for evaluating SUT execu-\ntion under critical situations or disasters \nor assessing specific behaviors or recov-\nering activities. The complexity of the \ntesting approach might vary according to \nthe complexity of the simulation system \nadopted and might involve closed-loop \ntesting; assessing the devices, communi-\ncations, and interface; and use of real-time \ndata (e.g., voltage, current and breaker \nstatus). Simulation testing can be applied \nto each development level and might \ninvolve mathematical, formal represen-\ntation of the real system, environment, \nnetwork conditions and control devices. Simulation testing is currently adopted in \nmany application domains. Especially in \nthe automotive and embedded domain, \namong the different proposals, one of the \nemerging solutions for simulation testing \nis hardware-in-the-loop (HIL) simula-\ntion testing. In this case, real signals sent \nto the SUT to simulate reality and to test \nand design the iteration are continuously \nperformed while the real-world system is \nbeing used.", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 145", "position": 145, "chunk_type": "semantic", "token_estimate": 203}
{"text": "SOFTWARE TESTING   5-29: \u2022\t Capture/replay tools [1*, c12s11] automat-\nically re-execute or replay previously exe-\ncuted tests that have recorded inputs and \noutputs (e.g., screens). \u2022\t Oracle/file comparators/assertion checking \ntools [1*, c9s7] assist in deciding whether a \ntest outcome is successful. \u2022\t Coverage analyzers and instrumenters [1*, \nc4] work together. Coverage analyzers \nassess which and how many entities of \nthe program flow graph have been exer-\ncised among all those required by the \nselected test coverage criterion. The anal-\nysis can be done through SUT instru-\nmenters that insert recording probes into \nthe code. \u2022\t Tracers [1*, c1s7] record the history of a \nprogram\u2019s execution paths. \u2022\t Regression testing tools [1*, c12s16] support \nthe re-execution of a test suite after a sec-\ntion of software has been modified. They \ncan also help select a test subset according \nto the change made. \u2022\t Reliability evaluation tools [1*, c8] support \ntest results analysis and graphical visual-\nization to assess reliability-related mea-\nsures according to selected models. \u2022\t Injection-based tools [1*, c3, c7s7] focus on", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 146", "position": 146, "chunk_type": "semantic", "token_estimate": 172}
{"text": "5-30   SWEBOK \u00ae GUIDE V4.0: introducing or reproducing specific prob-\nlems to confirm that the SUT behaves \nsuitably under the corresponding con-\ndition. That can involve managing some \ninput or triggering of events. Usually, \ntwo categories of injection-based tools \nare considered: attack injection and fault \ninjection. \u2022\t Simulation-based tools [1*, c3s9] verify and \nvalidate selected properties. Usually, they \nexploit specific models to enable the auto-\nmated execution of scenarios to assess \nwhether the SUT operates as expected or \nto predict how the SUT would respond to \ndefined inputs. Typical simulation-based \ntools are classified into tools for verifi-\ncation, tools for collaboration, tools for \noptimization, tools for testing automated \nsystems and tools for evaluating software \nconcepts. \u2022\t Security testing tools [1*, c8s3, c12s11] \nfocus on specific security vulnerabilities. Among these are tools for attack injec-\ntion, penetration testing and fuzz testing. \u2022\t Test management tools [1*, c12s11] include \nall the supporting tools that assure effi-\ncient and effective test management and \ndata collection. \u2022\t Cross-browser testing tools [1*, c8s3] enable \nthe tester to quickly build and run user \ninterface test cases across desktop, mobile \nand web applications to check whether \nthe SUT looks and works as expected on \nevery device and browser. \u2022\t Load testing tools [1*, c3] collect valuable \ndata and evidence for SUT performance \nevaluations. \u2022\t Defect tracking tools [1*, c3] help keep \ntrack of detected faults during the SUT \ndevelopment projects. These tools behave \nas tracking systems and usually allow end \nusers to enter fault reports directly. \u2022\t Mobile testing tools [1*, c8s3] support the \nimplementation and testing of mobile \napps by allowing several repeated UI tests \nover the application platform, develop-\nment on real mobile devices or emulators, \ntesting of the mobile apps on real-time \nimplementations and collection of data \nfor specific QA measures. \u2022\t API testing tools [1*, c7s2] check whether \nthe applications meet functionality, per-\nformance, reliability, and security expec-\ntations throughout the automation of \nspecific API tests. \u2022\t CSS validator tools [1*, c7s2] validate cas-\ncading style sheets (CSS) code and dis-\ncover errors, issues and warnings that can \nbe fixed. The CSS Validation Service, \nprovided by W3C for free, is one of the \nmost used validators in practice that helps \nboth web designers and web developers \ncheck CSS. \u2022\t Web application testing tools [1*, c8s3], also \nreferred to as web testing tools, support \nvalidating the functionality and the per-\nformance of web-based SUTs before their \ndeployment into production.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 147", "position": 147, "chunk_type": "semantic", "token_estimate": 405}
{"text": "SOFTWARE TESTING   5-31: MATRIX OF TOPICS VS. REFERENCE MATERIAL\n1*\n2*\n14*\n19*\n1. Software Testing Fundamentals\nc1, c2\nc8\nc7\n1.1. Faults vs. Failures\nc1s5\nc1\nc1s3\n1.2. Key Issues\n1.2.1. Test Case Creation\nc12s1, c12s3\nc8\n1.2.2. Test Selection and Adequacy Criteria\nc1s14, \nc6s6, c12s7\nc8\n1.2.3. Prioritization/Minimization\n1.2.4. Purpose of Testing\nc13s11, c11s4\nc8\n1.2.5. Assessment and Certification\nc7, c25\n1.2.6. Testing for Quality \nImprovement/Assurance\nc16s2\n1.2.7. The Oracle Problem\nc1s9, c9s7\n1.2.8. Theoretical and Practical Limitations\nc2s7\n1.2.9. The Problem of Infeasible Paths\nc4s7\n1.2.10. Testability\nc17s2\n1.2.11. Test Execution and Automation\n1.2.12. Scalability\nc8s7\n1.2.13. Test Effectiveness\nc1s1\nc8s1\n1.2.14. Controllability, Replication and \nGeneralization\nc12s12\n1.2.15. Offline vs. Online Testing\n1.3. Relationship of Testing to Other Activities\n2. Test Levels\nc1s13\nc8s1\n2.1. The Target of the Test\nc1s13\nc8s1\n2.1.1. Unit Testing\nc3\nc8\n2.1.2. Integration Testing \nc7\nc8\n2.1.3. System Testing\nc8\nc8\n2.1.4. Acceptance Testing\nc1s7\nc8s4\n2.2. Objectives of Testing\nc1s7\n2.2.1. Conformance Testing\nc10s4\n2.2.2. Compliance Testing\nc12s3\n2.2.3. Installation Testing\nc12s2\n2.2.4. Alpha and Beta Testing\nc13s7, c16s6\nc8s4\n2.2.5. Regression Testing\nc8s11, c13s3\n2.2.6. Prioritization Testing\nc12s7\n2.2.7. Non-functional testing\nc8s7, c8s8, \nc14s2, \nc15, c17s2\nc8, c 11, c17", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 148", "position": 148, "chunk_type": "semantic", "token_estimate": 201}
{"text": "5-32   SWEBOK \u00ae GUIDE V4.0: 2.2.8. Security Testing\nc13\n2.2.9. Privacy Testing\nc13, c14\n2.2.10. Interface and API Testing\nc8s1\nc7s12\n2.2.11. Configuration Testing\nc8s5\n2.2.12. Usability and Human-Computer \nInteraction Testing\nc8s4\nc6\n3. Test Techniques\nc1s15\n3.1. Specification-Based Techniques\nc6s2\n3.1.1. Equivalence Partitioning\nc9s4\n3.1.2. Boundary Value Analysis\nc9s5\n3.1.3. Syntax Testing\nc10s11\nc5\n3.1.4. Combinatorial Test Techniques\nc9s3\n3.1.5. Decision Table\nc9s6, c13s6 \n3.1.6. Cause-Effect Graphing\nc1s6\n3.1.7. State Transition Testing\nc10\n3.1.8. Scenario Testing\nc8s3.2, c19s3.1\n3.1.9. Random Testing\nc9s7\n3.1.10. Evidence-Based\n3.1.11. Forcing Exception\n3.2. Structure-Based Test Techniques\n3.2.1. Control Flow Testing\nc4\n3.2.2. Data Flow Testing\nc5\n3.2.3. Reference Models for Structure-Based \nTest Techniques\nc4\n3.3. Experience-Based Techniques\n3.3.1. Error Guessing\nc9s8\n3.3.2. Exploratory Testing\n3.3.3. Further Experience-Based Techniques\n3.4. Fault-Based and Mutation Techniques\nc1s14, c3s5\n3.5. Usage-Based Techniques\nc15s5\n3.5.1. Operational Profile \nc15s5\nc11\n3.5.2. User Observation Heuristics\nc5, c7\n3.6. Techniques Based on the Nature of the \nApplication\nc16, c17, \nc18, c20, c21\nc4s8\n3.7. Selecting and Combining Techniques\nc7s12\n3.7.1. Combining Functional and Structural\nc9\n3.7.2. Deterministic vs. Random\nc9s6\n3.8. Techniques Based on Derived Knowledge\nc19, c20\nc7\n4. Test-Related Measures\nc24s5\nc10\n4.1. Evaluation of the SUT\nc24s5", "domains": ["Design Patterns", "Software Quality Attributes", "Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 149", "position": 149, "chunk_type": "semantic", "token_estimate": 198}
{"text": "SOFTWARE TESTING   5-33: 4.1.1. SUT Measurements That Aid in Planning \nand Designing Tests\nc10\n4.1.2. Fault Types, Classification and Statistics\nc13s4, \nc13s5, c13s6\n4.1.3. Fault Density\nc13s4\nc10s1\n4.1.4. Life Test, Reliability Evaluation\nc15\nc11\nc1s3\n4.1.5. Reliability Growth Models\nc15\nc11s5\n4.2. Evaluation of the Tests Performed\n4.2.1. Fault Injection\nc2s5\n4.2.2. Mutation Score\nc3s5\n4.2.3. Comparison and Relative Effectiveness of \nDifferent Techniques\nc1s7\n5. Test Process\nc8\n5.1. Practical Considerations\n5.1.1. Attitudes/Egoless Programming\nc16\nc3\n5.1.2. Test Guides and Organizational Process\nc12s1\nc8\nc7s3\n5.1.3. Test Management and Dynamic \nTest Processes\nc12\nc7s3\n5.1.4. Test Documentation\nc8s12\nc7s8\n5.1.5. Test Team\nc16\nc23s5\n5.1.6. Test Process Measures\nc18s3\nc10\n5.1.7. Test Monitoring and Control\n5.1.8. Test Completion\nc7s11\n5.1.9. Test Reusability\nc3\n5.2. Test Sub-Processes and Activities\nc12s9, c1s12\n5.2.1. Test Planning Process\nc12s1, c12s8\n5.2.2. Test Design and Implementation\nc12s1, c12s3\n5.2.3. Test Environment Set-up  \nand Maintenance\nc12s6\nc8s1\nc13s2\n5.2.4. Controlled Experiments and \nTest Execution\nc12s7\nc4s7,  \nc5s6\n5.2.5. Test Incident Reporting\nc13s4, \nc13s9, c13s11\nc8s3\nc7s8\n5.3. Staffing\nc16\n6. Software Testing in the Development \nProcesses and the Application Domains\nc8, c15\nc4s8, \nc7\n6.1. Testing Inside Software \nDevelopment Processes\nc8\nc7\n6.1.1. Testing in Traditional Processes\nc18\nc7\n6.1.2. Testing in Line with Shift-\nLeft  Movement\nc3, c8s2", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 150", "position": 150, "chunk_type": "semantic", "token_estimate": 214}
{"text": "[1*]\tS. Naik and P. Tripathy, Software: Testing and Quality Assurance: Theory and \nPractice, ed: Wiley, 2008, p. 648. [2*]\tI. Sommerville, Software Engineering, \n10th ed., Addison-Wesley, 2016. [3]\t E.W. Dijkstra, Notes on Structured \nProgramming, Technological University, \nEindhoven, 1970. [4]\t ISO/IEC/IEEE 29119 \u2014 System \nand software engineering \u2014 Software \ntesting, ed. 2021. [5]\t ISO/IEC/IEEE, \u201cISO/IEC/IEEE \n24765:2017 Systems and Software \nEngineering \u2014 Vocabulary,\u201d \n2nd ed. 2017. [6]\t M. Papadakis, M. Kintis, J. Zhang, \nY. Jia, Y. Le Traon, and M. Harman, \nChapter Six \u2014 Mutation Testing \nAdvances: An Analysis and Survey, \nAdv. Comput. 112, 2019: 275-378. [7]\t M. Utting, B. Legeard, F. Bouquet, E. \nFourneret, F. Peureux, and A. Vernotte, \nRecent advances in model-based testing, \nAdvances in Computers, 101, 2016, \npp. 53-120. [8]\t IEEE Std 1012-2016, IEEE Standard \nfor System, Software, and Hardware \nVerification, and Validation, ed. 2016. [9]\t ISO/IEC 25010:2011, Systems and \nsoftware engineering \u2014 Systems \nand Software Quality Requirements \nand Evaluation (SQuaRE) \u2014 \nSystem and Software Quality \nModels, ed. 2011. [10]\tISO/IEC/IEEE 32675:2022 \nInformation technology \u2014 DevOps \u2014 \nBuilding reliable and secure systems \nincluding application build, package and \ndeployment. [11]\tSoftware Engineering Competency \nModel (SWECOM), v1.0, 2014. [12]\tISO/IEC 20246:2017, \u201cSoftware and \nsystems engineering \u2014 Work product \nreviews\u201d, ed, 2017, 42p\n[13]\tV. Riccio, G. Jahangirova, A. Stocco, \net al., Testing machine learning \nbased systems: A systematic mapping, \nEmpir Software Eng, 25, 2020, pp. 5193-5254. [14*]\tC.Y. Laporte, and A. April, Software \nQuality Assurance, IEEE Computer \nSociety Press, 1st ed., 2018. [15]\tS. Demi, R. Colomo-Palacios, and \nM. S\u00e1nchez-Gord\u00f3n, Software \nEngineering Applications Enabled by", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 151", "position": 151, "chunk_type": "semantic", "token_estimate": 255}
{"text": "SOFTWARE TESTING   5-35: Blockchain Technology: A Systematic \nMapping Study, Applied Sciences, 11(7), \n2021, pp. 2960. [16]\tK. Mao, L. Capra, M. Harman, and \nY. Jia. A survey of the use of crowd-\nsourcing in software engineering, \nJournal of Systems and Software, 126, \n2017, pp. 57-84. [17]\tA. Bertolino, G.D. Angelis, M. \nGallego, B. Garc\u00eda, F. Gort\u00e1zar, F. \nLonetti, and E. Marchetti, A system-\natic review on cloud testing, ACM \nComputing Surveys (CSUR), 52(5), \n2019, pp. 1-42. [18]\tR. Achary and P. Raj, Cloud Reliability \nEngineering: Technologies and Tools, CRC \nPress, 2021. [19*]\tJ. Nielsen, Usability Engineering, 1st \ned., Boston: Morgan Kaufmann, 1993.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 152", "position": 152, "chunk_type": "semantic", "token_estimate": 102}
{"text": "Application: Programming Interface", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 153", "position": 153, "chunk_type": "semantic", "token_estimate": 3}
{"text": "Section: Key Performance indicator", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 153", "position": 153, "chunk_type": "semantic", "token_estimate": 4}
{"text": "Section: Site Reliability Engineering", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 153", "position": 153, "chunk_type": "semantic", "token_estimate": 4}
{"text": "6-2   SWEBOK \u00ae GUIDE V4.0: sharing of common processes and tools. The \nrising popularity and growing acceptance of \nDevOps practices [2*] and related standards \n[4], including an ever-evolving set of tools, \nreflect this trend. DevOps aims at automating \nand continuously evolving software engi-\nneering activities to ensure high-quality soft-\nware and to satisfy users who demand quicker \nturnaround from software engineers. In this context, the role of software engi-\nneers involved in software engineering oper-\nations has significantly evolved over the \npast decade with the emergence of practices \nlike infrastructure as code (IaC), Platform-\nas-Code (PaC), Agile infrastructure, soft-\nware-defined \narchitectures/systems, \nand \nthe availability of infrastructure as a ser-\nvice (IaaS) and platform as a service (PaaS) \nsolutions. Tasks traditionally performed by \nIT infrastructure engineers are increasingly \nautomated and made available as a service, \nenabling application developers to perform \nsoftware engineering operations tasks inde-\npendently as part of their daily project activ-\nities. For example, application developers in \nmany organizations can now directly use IaaS \nand PaaS to deploy applications in produc-\ntion environments and to monitor different \naspects of those applications without directly \ninvolving operations engineers. Having end-to-end resources and desired \nstate configuration managed like code, using \npractices such as IaC and PaC, provides value \nin the form of 1) improved repeatability, 2) \nconsistency/standardization, 3) known secu-\nrity policies , 4) self-documentation (transpar-\nency), 5) single source of truth, 6) configuration \ncontrol, and 7) scalability. From an engi-\nneering perspective, the important point is \nthat nearly anything that impacts a software \nproduct directly or indirectly should be con-\nsidered for representation as code. To perform software engineering operations \ntasks, some organizations use the the concept \nof Platform Engineering and Site Reliability \nEngineering (SRE) [6] to increase produc-\ntivity and software quality. The role of platform \nengineering is to build and manage self-service \nplatform capabilities that can be used by soft-\nware engineers to develop, deploy, and operate \nsoftware applications. On the other hand, \nthe role of SRE is to monitor, automate, and \nimprove software operations with respect to \nnon-functional aspects, including availability, \nperformance, latency, and security. SRE is also \nresponsible for change management, emer-\ngency response, capacity planning, and overall \nefficiency of software systems.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 154", "position": 154, "chunk_type": "semantic", "token_estimate": 365}
{"text": "6-2   SWEBOK \u00ae GUIDE V4.0: On the other hand, \nthe role of SRE is to monitor, automate, and \nimprove software operations with respect to \nnon-functional aspects, including availability, \nperformance, latency, and security. SRE is also \nresponsible for change management, emer-\ngency response, capacity planning, and overall \nefficiency of software systems. Although many organizations still use \nconventional IT operations management \nSoftware Engineering\nOperations\nSoftware\nEngineering\nOperations\nFundamentals\nSoftware\nEngineering\nOperations\nPlanning\nSoftware\nEngineering\nOperations\nDelivery\nSoftware\nEngineering\nOperations\nControl\nSoftware\nEngineering\nOperations\nTools\nDefnition of\nSoftware Engineering\nOperations\nSoftware Engineering\nOperations Processes\nSoftware Installation\nScripting and\nAutomating\nEfective Testing and \nTroubleshooting\nPerformance, Reliability \nand Load Balancing\nOperations Plan and\nSupplier Management\nDevelopment \nand Operational \nEnvironment\nSoftware Availability, \nContinuity and \nService Levels\nSoftware Capacity\nManagement\nSoftware and Data \nSafety, Security, \nIntegrity, Protection \nand Controls\nDeployment/Release\nEngineering\nRollback and\nData Migration\nChange Management\nProblem\nManagement\nIncident \nManagement \nMonitor, Measure \nTrack and Review\nOperations \nSupport\nOperations Service \nReporting\nIncident and \nProblem Prevention\nOperational Risk \nManagement\nAutomated \nSoftware\nEngineering \nOperations\nSoftware Engineering\nOperations for\nVery Small Entities\nContainers \nand Incident\nVisualization\nDeployment\nAutomated Tests\nMonitoring and \nTelemetry\nPractical\nConsiderations\nFigure 6.1. Breakdown of Topics for the Software Engineering Operations KA.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 154", "position": 154, "chunk_type": "semantic", "token_estimate": 195}
{"text": "SOFTWARE ENGINEERING OPERATIONS   6-3: processes, this KA focuses mainly on the role \nof software engineers in operations in the \nemerging contexts of DevOps, IaC, PaC, and \nAgile infrastructure practices. In this context, we identify two main soft-\nware engineering roles related to operations: \nOperations engineer, who is responsible for \ndeveloping operations services made available \nas a service and accessible through an appli-\ncation programming interface (API), and \nsoftware engineer, who can use the resulting \noperations services (available as a service) to \nindependently deploy and manage applica-\ntions without directly involving IT operations \nspecialists.", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 155", "position": 155, "chunk_type": "semantic", "token_estimate": 93}
{"text": "The breakdown of topics for the Software: Engineering Operations KA is shown in \nFigure 6.1. 1. Software Engineering Operations \nFundamentals\nThis first section introduces the concepts and \nterminology that form an underlying basis for \nunderstanding the role and scope of software \nengineering operations. 1.1. Definition of Software Engineering \nOperations\b\n[1, c3s3.3][3, c6s6.4.12]\nIn this Guide, the term software engineering \noperations refers to the knowledge, skills, pro-\ncesses and tools used by software engineers or \ntheir organization to ensure that a software \nproduct, including IT infrastructure, system \nsoftware, and application software, operates \nwell during development, maintenance and in \nreal conditions of operations. In ISO/IEC/IEEE 12207 [3], an operator \nis defined as an \u201cindividual or organization \nthat performs the operations of a system.\u201d The \nSWEBOK Guide modifies that definition for \nthe term operations engineer, which refers to \na software engineer who executes software \nengineering operations processes. In this role, \nan operations engineer works closely with soft-\nware engineers to develop and offer operations \nservices such as the following: \n\u2022\t Provisioning, deploying and config-\nuring, and supporting containers and vir-\ntual servers,\n\u2022\t Designing and offering on-demand ser-\nvices (e.g., environment on demand, ver-\nsioning, continuous integration (CI) and \ntesting, deployment, and surveillance) for \nuse by software engineering,\n\u2022\t Monitoring and troubleshooting system \nand application software incidents by \nrunning diagnostics, documenting prob-\nlems and resolutions, prioritizing prob-\nlems, and assessing impact of issues,\n\u2022\t Performing, automating and imple-\nmenting \nappropriate \nprocesses \nfor \nsecurity, data protection and failover \nprocedures,\n\u2022\t Overseeing \ncapacity, \nstorage \nplan-\nning and database management system \n(DBMS) performance,\n\u2022\t Providing documentation and technical \nspecifications to IT staff for planning and \nimplementing new or upgraded IT infra-\nstructure and system software. ISO/IEC/IEEE 20000-1 describes the \nneed to develop and enhance the profes-\nsional competencies of operations engineers. To achieve this goal, software organizations \nshould address the following:\n\u2022\t Staff recruitment: To validate job appli-\ncants\u2019 \nqualifications/competencies, \nincluding their professional certifications, \nand to identify their strengths, weak-\nnesses and potential capabilities against \nthe operations engineer job description, \ncore technologies and computer languages \nmastered and overall experience,\n\u2022\t Resource planning: To staff new or \nexpanded engineering operations services, \nplan the use of new technology, plan the \nassignment of service management staff", "domains": ["Software Quality Attributes", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 155", "position": 155, "chunk_type": "semantic", "token_estimate": 367}
{"text": "6-4   SWEBOK \u00ae GUIDE V4.0: to development project teams, develop \nsuccession planning and other staffing \ngaps created by staff turnover,\n\u2022\t Resource training and development: \nTo identify training and development \nrequirements and create a training and \ndevelopment plan that meets them; also, \nto provide timely, effective delivery of \noperations services. Operations engineers \nshould be trained in the relevant aspects \nof service management (e.g., via training \ncourses, \nself-study, \nmentoring \nand \non-the-job training), and their teamwork \nand leadership skills should be developed. A chronological training record should \nbe maintained for each individual, with \ndescriptions of the training provided. 1.2. Software Engineering Operations Processes \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\b\n[2*, s1][3, c6s6.4.12]\nISO/IEC/IEEE 20000-1 is the reference stan-\ndard that presents an overview of operations pro-\ncesses. It specifies requirements for the design, \ntransition, delivery and improvement of opera-\ntions services. The ISO/IEC/IEEE 20000-1 \ndescribes five main operations process groups: \nservice delivery processes, release processes, \ncontrol processes, resolution processes and rela-\ntionship processes. These operations processes \nare further categorized as technical processes \nin ISO/IEC/IEEE 12207 [3]. Operations pro-\ncesses, from the perspective of a software engi-\nneer, contain the activities and tasks necessary \nto deploy, configure, operate and support an \nexisting software system or product while pre-\nserving its integrity. This international standard \ndescribes four main operations process activi-\nties: 1) prepare for the operation: that requires \nto define an operation strategy; 2) perform the \noperation: which consist of operating and mon-\nitoring; 3) manage the results of operation: \nwhere anomalies are recorded and addressed; \nand finally 4) support the customer: which \nmeans to give assistance and consultation to any \nuser of the operations services. Finally, ISO/IEC/IEEE 32675 [4] intro-\nduces a number of software engineering \noperations activities using an Agile and a \nminimum viable product (MVP) perspec-\ntive.", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 156", "position": 156, "chunk_type": "semantic", "token_estimate": 292}
{"text": "6-4   SWEBOK \u00ae GUIDE V4.0: This international standard \ndescribes four main operations process activi-\nties: 1) prepare for the operation: that requires \nto define an operation strategy; 2) perform the \noperation: which consist of operating and mon-\nitoring; 3) manage the results of operation: \nwhere anomalies are recorded and addressed; \nand finally 4) support the customer: which \nmeans to give assistance and consultation to any \nuser of the operations services. Finally, ISO/IEC/IEEE 32675 [4] intro-\nduces a number of software engineering \noperations activities using an Agile and a \nminimum viable product (MVP) perspec-\ntive. This standard recognizes the influence \nof DevOps as a set of principles and practices \nthat enable better communication and collab-\noration between relevant stakeholders for the \n\u2022 Operations Plan and Supplier Management\n\u2022 Development and Operational Environment\n\u2022 Software CM, Build, Package and Deployment\n\u2022 Software Availability, Continuity and Service Levels\n\u2022 Software Capacity Management\n\u2022 Software Backup, Disaster Recovery and Failover\n\u2022 Software and Data Safety, Security, Integrity, Protection and Controls\n\u2022 Operational Testing, Veri\ufb01cation and Acceptance\n\u2022 Development/Release Engineering\n\u2022 Rollback and Data Migration \n\u2022 Problem Resolution\n\u2022 Incident and Change Management\n\u2022 Monitor, Measure, Track and Review\n\u2022 Service Support and Operations Service Desk\n\u2022 Service Reporting\nOperations Planning\nProcesses\nOperations Delivery\nProcesses\nOperations Control\nProcesses\nFigure 6.2. Software Engineering Operations Processes and Activities", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 156", "position": 156, "chunk_type": "semantic", "token_estimate": 221}
{"text": "SOFTWARE ENGINEERING OPERATIONS   6-5: Ef\ufefffective Testing and  \nTroubleshooting\b\n[2*, c3]\nSoftware engineering operations is respon-\nsible for ensuring the stability of the system. For this purpose, software must be thor-\noughly tested before it is released (deployed \nin production and made available to users). Because manual testing is inefficient, error-\nprone and non-scalable, testing must be auto-\nmated as much as possible throughout the \nentire software process. Also, because the \ntime available for testing is limited, regres-\nsion testing and test coverage strategies (the \nselective retesting of a software application, \nor component, to verify that the software \nto be deployed will not cause unintended \neffects) play an important role in software \nengineering operations. When errors are found (in production after \nthe software is released or during internal \ntesting phases), software engineers and soft-\nware operations engineers need to troubleshoot \nhardware and software incidents by running \ndiagnostics, documenting problems and res-\nolutions, prioritizing problems, and assessing \nthe impact of the issues. The cost \u2014 in both \ntime and money \u2014 of repeating full testing \non a major piece of software is significant. To ensure that the requested problem reports \n(PRs) are valid, the operations engineer should \nreplicate and verify problems by running the \nappropriate tests. Testing certain aspects of \nthe software in production can be particularly", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 157", "position": 157, "chunk_type": "semantic", "token_estimate": 215}
{"text": "6-6   SWEBOK \u00ae GUIDE V4.0: challenging. For example, when software per-\nforms critical functions, bringing it off-line to \ntest might be difficult. Generally, testing the \nsoftware in the production system context is \nchallenging (sometimes impossible) and could \nrequire the use of testing techniques such as \ncanary testing and dark launches. The Software \nTesting KA provides additional information \nand references on testing. 1.6. Performance, Reliability and  \nLoad Balancing\b\n[1, c6s6.2]\nSoftware operations engineers plan for per-\nformance, reliability and load balancing early \nin software projects to ensure they meet the \nproject requirements. (See section 1.2 to 1.7 \nof the Software Requirements KA). A cur-\nrent trend is for software engineers to design \nand use infrastructure/operations services to \nadjust dynamically (e.g. scalability) the infra-\nstructure according to the demand. Using \nDevOps practices enables operations engi-\nneers to anticipate these needs early and pro-\nvide infrastructure services that software \nengineers can use and test during the devel-\nopment stages of a project. 2. Software Engineering Operations \nPlanning\nThis topic introduces some of the generally \naccepted techniques used in software engi-\nneering operations planning. Operations \nengineers must deal with a number of key \nissues to ensure software operates effectively. Operations engineers should document their \nsoftware engineering operations steps and \ntools, using any type, form or medium suit-\nable for the purpose (e.g., Wikis, documents, \nand more). The following topics are typically \nconsidered suitable as evidence of well docu-\nmented operations:\n\u2022\t Policies and plans,\n\u2022\t Service documentation,\n\u2022\t Procedures,\n\u2022\t Processes, and\n\u2022\t Process control records. 2.1. Operations Plan and Supplier Management\n\b\n[1, c4s4.1][3, c6s6.1]\nSoftware engineering operations planning \nshould comprise part of the process of trans-\nlating project requirements and the needs of \nthe developers and maintainers into services, \nand it should provide a road map for directing \nprogress. This process often involves the prod-\nucts and services of suppliers that must be \nwell coordinated to ensure quality service. ISO/IEC/IEEE 20000-1 describes planning \nactivities, as well as ISO/IEC/IEEE 12207, \nwhich lists the activities operations engineers \nconsiders from human, technical and system \nperspectives. 2.1.1. Operations Plan \n\b\n[1, c4s4.1][3,c6s6.4.12.3a]\nWhereas software development typically \nlasts from some months to a few years, the \noperations phase usually lasts many years. Therefore, estimating resources is a key ele-\nment of operations planning. Software engi-\nneering operations planning should begin \nwith the decision to develop a new software \nproduct and should consider its maintenance \nand operations requirements early.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 158", "position": 158, "chunk_type": "semantic", "token_estimate": 401}
{"text": "SOFTWARE ENGINEERING OPERATIONS   6-7: Software engineering operations planning is \naddressed in ISO/IEC/IEEE 12207 [3] and \nISO/IEC/IEEE 32675 [4]. The standards pro-\nvide guidelines for planning, implementing, \nmaintaining, automating and supporting pro-\nduction software. Finally, at the highest plan-\nning level, the operations organization must \nconduct business planning activities (e.g., bud-\ngetary, financial and human resources), just as \nall the other divisions of the organization (refer \nto the Software Engineering Management \nKA). ISO/IEC/IEEE 20000-1 recommends \nthat the operations plan address issues associ-\nated with a number of planning perspectives, \nincluding the following:\n\u2022\t The roles and responsibilities for imple-\nmenting, operating and maintaining the \nnew or changed service,\n\u2022\t Activities to be performed by customers \nand suppliers,\n\u2022\t Changes to the existing service manage-\nment framework and services,\n\u2022\t Communication to the relevant parties,\n\u2022\t New or changed contracts and agreements \nto align with changes in business needs,\n\u2022\t Staffing and recruitment requirements,\n\u2022\t Skills and training requirements (e.g., \nusers, technical support),\n\u2022\t Processes, measures, methods and tools \nto be used in connection with the new or \nchanged service,\n\u2022\t Capacity management,\n\u2022\t Financial management,\n\u2022\t Budgets and timescales,\n\u2022\t Service acceptance criteria, and\n\u2022\t The expected outcomes from operating \nthe new service, expressed in measur-\nable terms. This plan ensures that an operational \nstrategy is defined, conditions for correct oper-\nations are identified and evaluated, the soft-\nware is tested at scale to operate in its intended \nenvironment, and surveillance is provided \nto ensure responsiveness and availability of \nthe software by ensuring constant support. At the individual request level (e.g., problem \nreport (PR) or modification request (MR)) \nneed planning. Once individual requests are \nreceived and validated, the release or version \nplanning activity requires that operations \nengineers perform the following tasks:\n\u2022\t Identify the target availability dates of \nindividual requests,\n\u2022\t Agree on the content of subsequent \nreleases or versions,\n\u2022\t Identify potential conflicts and develop \nalternatives,\n\u2022\t Assess the risk of a given release and \ndevelop a rollback and data migration plan \n(see section 3.3) in case problems arise,\n\u2022\t Inform all stakeholders. 2.1.2. Supplier Management \n\b\n[1, c7s3][3, c6s6.1]\nSupplier management ensures that the orga-\nnization\u2019s suppliers and their performance are \nmanaged appropriately to support the seam-\nless provision of quality products and services. ISO/IEC/IEEE 12207 lists the activities that \nthe operations engineer will perform to estab-\nlish an agreement to acquire suppliers\u2019 products \nand/or services.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 159", "position": 159, "chunk_type": "semantic", "token_estimate": 397}
{"text": "SOFTWARE ENGINEERING OPERATIONS   6-7: Supplier Management \n\b\n[1, c7s3][3, c6s6.1]\nSupplier management ensures that the orga-\nnization\u2019s suppliers and their performance are \nmanaged appropriately to support the seam-\nless provision of quality products and services. ISO/IEC/IEEE 12207 lists the activities that \nthe operations engineer will perform to estab-\nlish an agreement to acquire suppliers\u2019 products \nand/or services. From an operations engineer\u2019s \nperspective, the nature of the relationship \nwith suppliers and the approach should be \ndetermined by the nature of the products and \nservices needed in a project. Managing sup-\npliers of services related to operational soft-\nware includes managing out-sourced services \nand cloud services, like IaaS and PaaS. 2.2. Development and Operational \nEnvironments\b\n[2*, c9]\nThe overall software process requires the use \nof different environments at different stages. These are typically defined as the development \nenvironment, the testing or quality assurance \n(QA) environment, the preproduction envi-\nronment, and the production environment. To build quality into the product and reduce \nthe risks associated with the release of soft-\nware in the production environment (whether \nthe release is associated with new function-\nality or software defects), engineers must", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 159", "position": 159, "chunk_type": "semantic", "token_estimate": 186}
{"text": "6-8   SWEBOK \u00ae GUIDE V4.0: ensure that the different environments are all \ncoherent and synchronized with the produc-\ntion environment. For this reason, DevOps recommends that \nthe creation of all the different environments \nbe automated and built from a single code \nrepository. In mature DevOps organizations, \nthe creation of the different environments is \ncompletely automated and made available as \na service. Also, all environments need to be \nbuilt from the same code source (single source \nof truth) to ensure that all the environments \nare synchronized with the production envi-\nronment in which the software is released. This leads to the concept of infrastructure as \ncode (IaC). 2.3. Software Availability, Continuity, and \nService Levels\b\n[1, c6s6.3]\nService availability and continuity must be \nmanaged to ensure that customer commitments \nare met. Because service availability and conti-\nnuity are defined as nonfunctional requirements \nearly in a project (see the Software Quality \nKA), operations engineers will ensure that \nthe proper infrastructure is planned, designed, \nimplemented and tested. Software availability \nis measured and recorded, and unplanned \nnonavailability is investigated and appropriate \nactions taken. Service reports produce avail-\nability and continuity indicators of operations \nservices against service-level targets. The service-level management process moni-\ntors the agreed software level of service, including \nworkload characteristics, performance and \navailability trend information and customer \nsatisfaction analysis. Defining, agreeing to and \ndocumenting service-level agreements (SLAs) \ncan help clarify the full range of operations \nservices obligations provided. The Software \nMaintenance KA provides additional infor-\nmation and references about SLA\u2019s. 2.4. Software Capacity Management \n\b\n[1, c6s6.5]\nISO/IEC/IEEE 20000-1 describes the need \nto ensure that the software product has the \ncapacity, at all times, to meet current and \nfuture agreed-upon demands created by the \ncustomer\u2019s business needs. The current and \nexpected business requirements for services \nshould be understood in terms of what the \nbusiness needs in order to deliver its prod-\nucts or services to its customers. Business pre-\ndictions and workload estimates should be \ntranslated into specific requirements and doc-\numented. The reaction to variations in work-\nload or environment should be predictable; \ndata on current and previous components, as \nwell as resource utilization at an appropriate \nlevel, should be captured and analyzed to sup-\nport the process. Capacity management is the focal point \nfor all performance and capacity issues. The \nprocess should directly support the develop-\nment of new and changed services by sizing \nand modeling these services.", "domains": ["Software Quality Attributes", "Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 160", "position": 160, "chunk_type": "semantic", "token_estimate": 397}
{"text": "6-8   SWEBOK \u00ae GUIDE V4.0: Capacity management is the focal point \nfor all performance and capacity issues. The \nprocess should directly support the develop-\nment of new and changed services by sizing \nand modeling these services. A capacity plan \ndocumenting the actual performance of the \ninfrastructure and the expected requirements \nshould be produced at a suitable frequency (at \nleast annually), considering the rate of change \nin services and service volumes, informa-\ntion in the change management reports, and \nchanging customer business requirements. The capacity plan should document costed \noptions for meeting business requirements \nand recommend solutions to ensure achieve-\nment of the agreed-upon service-level targets \nas defined in the SLA. The technical infra-\nstructure and its current and projected capac-\nities should be well understood to ensure \noptimal software operations. 2.5. Software Backup, Disaster Recovery, and \nFailover\b\n[1, c6s6.3.4]\nISO/IEC/IEEE 20000-1 also proposes that \nthe following should be quickly available \nfollowing a major service failure or disaster \nto ensure continuity planning and testing: \nbackups of data, documents and software, \nand any equipment or staff necessary for ser-\nvice restoration. Backup and data recovery \nare important activities; successful recovery \nis especially vital. The need for successful \nrecovery should influence which backup and", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 160", "position": 160, "chunk_type": "semantic", "token_estimate": 201}
{"text": "SOFTWARE ENGINEERING OPERATIONS   6-9: recovery methods are used (full or incre-\nmental), how frequently restore points are \nestablished, where they are stored, and how \nlong they are retained. Preparedness and regular test of backup, \ndisaster recovery, and failover should be con-\nstantly rehearsed as changes to the produc-\ntion environment are made. This is another \nessential activity that is triggered when outage \nassessments are done. Testing disaster recovery \nrequires stopping the service, identifying the \ncheckpoint state and triggering the failover \nprocess. Software engineers should under-\nstand that failure is inevitable and that auto-\nmated failover daemons can reduce recovery \ntime drastically. To achieve this, software \napplications should include failure-handling \nlogic; this must be planned during develop-\nment. DevOps can help organizations that \nwant to reduce failovers and disasters by auto-\nmating and launching tests as often as possible \nto ensure readiness in case of a failure or cata-\nstrophic event. 2.6. Software and Data Safety, Security, \nIntegrity, Protection, and Controls \n\b\n[1, c6.s6.6]\nThe need to manage information secu-\nrity effectively within all service activities is \ndescribed in ISO/IEC/IEEE 20000-1. This \nis done by conducting a software risk assess-\nment on the security and availability of infor-\nmation. Operations engineers should strive to \nenforce the following controls:\na. Senior management should define their \ninformation security policy, communi-\ncate it to staff and customers, and act to \nensure its effective implementation,\nb. Information security management roles \nand responsibilities should be defined \nand allocated to post holders,\nc.\tA representative of the management team \nshould be assigned the role of monitoring \nand maintaining the effectiveness of the \ninformation security policy,\nd.\tStaff with significant security roles should \nreceive information security training,\ne.\tAll staff should be made aware of the \ninformation security policy,\nf.\t Expert help on risk assessment and con-\ntrol implementation should be available,\ng.\tChanges should not compromise the \neffective operation of controls, and\n\u2022\t Information security incidents should \nbe reported following incident manage-\nment procedures, and a response should \nbe initiated. In line with the evolution of DevOps, \nDevSecOps is promoting the integration \nof security early and throughout the soft-\nware process, which includes the integra-\ntion of different security mechanisms and \ntools at the operations level. The goal is to \nautomate the detection and correction of \nsecurity issues as early as possible in the \noverall process. 3.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 161", "position": 161, "chunk_type": "semantic", "token_estimate": 390}
{"text": "SOFTWARE ENGINEERING OPERATIONS   6-9: The goal is to \nautomate the detection and correction of \nsecurity issues as early as possible in the \noverall process. 3. Software Engineering Operations \nDelivery\nThis topic introduces some of the gener-\nally accepted processes used during software \nengineering operations  delivery (ISO/IEC/\nIEEE 20000-1): SLA, service reporting, \nservice continuity, availability management, \nbudgeting and accounting for IT services, \ncapacity management, and information secu-\nrity management. 3.1. Operational Testing, Verification, and \nAcceptance\b\n[2*,c10] [3, c6s6.3.5.3d]\nSoftware engineers plan and execute soft-\nware verification as early as possible, using \ntest-driven development (TDD) and accep-\ntance test-driven development (ATDD) \ntechniques and tools that ensure that opera-\ntional testing is ongoing during the develop-\nment of the software, not only at the end of \na project. DevOps plays an important role in \ndeveloping and automating software testing \nservices and integrating different tools to \nboost software productivity and quality. (See TDD and ATDD in the Software \nTesting KA.)", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 161", "position": 161, "chunk_type": "semantic", "token_estimate": 156}
{"text": "6-10   SWEBOK \u00ae GUIDE V4.0: 3.2. Deployment/Release Engineering \n\b\n[2*,c12][3,c6s6.3.5.3d]\nA software operations engineer\u2019s main \nresponsibility relates to the deployment and \nrelease of software to ensure its continued \nperformance. As defined in [2*], \u201cdeploy-\nment is the installation of a specified ver-\nsion of software to a given environment (e.g., \ndeploying code into an integration test envi-\nronment or deploying code in production),\u201d \nwhereas \u201crelease is when we make a feature \n(or set of features) available to all our cus-\ntomers or a segment of customers (e.g., we \nenable the feature to be used by 5% of our \ncustomer base).\u201d Release processes include all \nthe activities related to release management. ISO/IEC/IEEE 12207 [3] lists release con-\ntrol activities and explains the need to iden-\ntify and record release requests, identify the \nsoftware system elements in a release fol-\nlowed by approval, and track the releases in \ntheir specified environments. DevOps advocates integrating develop-\nment and operations in the same team to \nimprove software engineering operations \nefficiency. In traditional software processes, \nwhen an application is ready for deployment, \nit is transferred from a development team to \nan operations team that is responsible for \ndeployment, which is mostly done manually. This results in processes that are inefficient \nfrom both a time and a quality perspective. To improve the efficiency of the deployment \nprocess, DevOps calls for automating the \ndifferent deployment steps, including pack-\naging the code, generating configuration \nfiles, restarting the servers, configuring the \nservers and databases, installing the soft-\nware on the different servers, launching the \nexecution of the application, and executing \nsmoke testing. Different \nrelease \nengineering \nstrate-\ngies can be used to reduce the risks asso-\nciated \nwith \nsoftware \nreleases. These \nstrategies can be grouped into two main cat-\negories: environment-based release strate-\ngies and application-based release strategies. Environment-based release strategies use a \nstaging environment to support the release \nof a new version of an application. In other \nwords, the basic strategy involves deploying \nthe new version of the application to a staging \nenvironment. Application-based release strat-\negies are based on the use of toggles (e.g., fea-\nture toggles) that make it possible to enable \nor disable specific sections of the code (e.g., a \nfeature) using configuration parameters. Deployment and release are supported \nby automation techniques and tools. The \ncanary release testing technique is a partial \nand time-limited deployment of a change in \na service and an evaluation of that change.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 162", "position": 162, "chunk_type": "semantic", "token_estimate": 401}
{"text": "6-10   SWEBOK \u00ae GUIDE V4.0: Deployment and release are supported \nby automation techniques and tools. The \ncanary release testing technique is a partial \nand time-limited deployment of a change in \na service and an evaluation of that change. This evaluation helps the operations engi-\nneer decide whether to proceed with a \ncomplete deployment. Similarly, tools that \nmanage the installation of new software typ-\nically observe the newly started server for a \nwhile, ensuring that the server doesn\u2019t crash \nor otherwise misbehave. The same tech-\nnique is useful for observing recent changes; \nif they do not pass the validation period, \nthey can be automatically rolled back. The \nSoftware Configuration Management KA \nprovides more information about the release \nprocesses. Once the application platform is \ndeployed in the targeted production envi-\nronment, the decision to make it available \nto the users (release it) becomes a busi-\nness decision. 3.3. Rollback and Data Migration \n\b\n[2*, c12][3, c6s6.4.10.3]\nRollback and data migration are terms used to \ndescribe the process of returning software and \nits database to a state where they work prop-\nerly. Software engineers ensure that when \na new version of the software and its data-\nbases have been modified and deployed to \nproduction, they can easily and quickly be \nrolled back in case the new version is causing \ndefects or product degradation in production. This means a planned and rehearsed rollback \nis done before a new version of the software \nis deployed in production. DevOps processes \nautomate this process to make it faster; in \nfact, the automated surveillance can trigger", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 162", "position": 162, "chunk_type": "semantic", "token_estimate": 258}
{"text": "SOFTWARE ENGINEERING OPERATIONS   6-11: rollback and data migration to a previous state \nso quickly that the end user doesn\u2019t notice that \nthere was a problem. Both release strategy \ncategories (described in section 3.2) \u2014 envi-\nronment-based release and application-based \nrelease \u2014 can be used to support rollback. 3.4. Change Management \b\n[1, c9s9.2]\nThis operations process ensures that all \nchanges are assessed, approved, implemented \nand reviewed in a controlled manner. All \nchange requests are recorded and classified \n(e.g., emergency, urgent, major and minor). This process assesses the risk of a change \nand the need for a rollback strategy in case \nof failure. Large systems might require that a \nchange schedule be planned with the product \nmanager and end users. Whereas in traditional software delivery \nprocesses (or software life cycle models), all \nchanges are delivered as part of new soft-\nware releases (containing multiple changes \nrelated to different aspects of the application \nor system) issued at fixed time intervals (e.g., \nevery three months), DevOps aims to deliver \nsmall units of change (a single new function-\nality or service, or defect fix, rather than a \nnew version of an application containing mul-\ntiple changes) on demand and independently \nfrom each other. For this purpose, software \napplications (or services) must be archi-\ntected to enable small, independent software \ndeployments. 3.5. Problem Management\b\n[1, c8s8.3]\nThe objective of this operations process is to \nminimize disruption to the business through \nthe identification and analysis of the cause \nof software and system incidents and prob-\nlems. This approach may require the involve-\nment of a multidisciplinary team, whose \nsoftware engineers and operations engineers \ninvestigate, for example, recurring produc-\ntion problems that might have an underlying \ncause in software infrastructure and system \ncomponents. This might require monitoring, \nlogging and profiling the software and its \ninfrastructure behavior. 4. Software Engineering Operations \nControl\nThis topic introduces some generally accepted \ntechniques used in software engineering \noperations control. 4.1. Incident Management\b\n[1, c8s8.2] \nIncident management is the process of \nrecording, prioritizing and assessing the busi-\nness impact, resolution, escalation and closure \nof software incidents. The modern DevOps \napproach automates software surveillance using \nalerts and logs to prevent minor incidents from \nbecoming major incidents. When an inci-\ndent occurs, proper analysis and/or post mor-\ntems must be conducted to find the source of \nthe incident and appropriate solutions must be \nimplemented to prevent similar incidents to \nhappen again in the future. 4.2.", "domains": ["Design Patterns", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 163", "position": 163, "chunk_type": "semantic", "token_estimate": 400}
{"text": "SOFTWARE ENGINEERING OPERATIONS   6-11: When an inci-\ndent occurs, proper analysis and/or post mor-\ntems must be conducted to find the source of \nthe incident and appropriate solutions must be \nimplemented to prevent similar incidents to \nhappen again in the future. 4.2. Monitor, Measure, Track, and Review   \n\b\n[2*, c14-15]\nSoftware \nengineering \noperations \nactivi-\nties monitor capacity, continuity and avail-\nability. In a DevOps mindset, hope should \nnot be a strategy; instead, engineers should be \ninformed about system quality and operational \nhealth with evidence, such as the following \nkey performance indicators (KPI), which are \navailable to stakeholders in real time:\n\u2022\t Production system\u2019s monitoring and \nproduct telemetry,\n\u2022\t Actionable \nverification \nand \nvalida-\ntion results before and after release to \nproduction,\n\u2022\t End-user activity and resource use,\n\u2022\t Impact analysis results,\n\u2022\t Inter- and intra-related dependencies \nrequired for system operation,\n\u2022\t Configuration changes unrelated to \napproved deployment tasks, and\n\u2022\t Security and resilience performance \ncapability.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 163", "position": 163, "chunk_type": "semantic", "token_estimate": 154}
{"text": "6-12   SWEBOK \u00ae GUIDE V4.0: 4.3. Operations Support\b\n[1, c6, c14s5]\nISO/IEC/IEEE 12207 [3], \u201cISO/IEC/\nIEEE 20000-1 [1] and ISO/IEC/IEEE \n32675 [4] identify the primary software \nengineering operations activities that sup-\nport the operations processes \u2014 activi-\nties that operate the software product in its \nintended environment \u2014 and the primary \nactivities that provide support to the cus-\ntomers of the software products. Operations \nsupport activities are initiated at the plan-\nning stage of the project and are then exe-\ncuted, which often requires techniques and \ntools to proactively monitor the product \nand services and react quickly to events \nand incidents. Support activities are often \ndescribed in SLAs. 4.4. Operations Service Reporting   \n\b\n[1,c6s6.2]\nService reporting aims to produce agreed-\nupon, timely, reliable and accurate informa-\ntion for decision-making. Each service report \nhelps demonstrate how an operations ser-\nvice has performed and whether it has met \nsome stated and agreed-upon end-user objec-\ntive. Typical service reports address perfor-\nmance against service-level targets, as well \nas security breaches, the volume of transac-\ntions and resource use, incidents and failures, \ntrend information, and satisfaction analysis. Operations engineers need to establish auto-\nmated systems and tools for measurement to \ndo the following:\n\u2022\t Determine whether measures are already \navailable or additional instrumentation \nfor collection, analysis and reporting \nis needed,\n\u2022\t Select or develop a framework and tools to \nallow coordination of measurement col-\nlection for analysis, reporting and control. 5. Practical Considerations\nThis topic introduces practical considerations \nfor software engineering operations. 5.1. Incident and Problem Prevention \n\b\n[2*, c7]\nThe overall operations process needs to be \nautomated as much as possible to prevent inci-\ndents and problems, and automated testing \nneeds to be integrated throughout the process. Also, product telemetry should be imple-\nmented with proper analytics techniques to \ndetect problems as early as possible to prevent \nincidents. For this purpose, data collected \nat all layers of the product stack (including \napplication layer, operating system layer and \ninfrastructure layer) must be collected and \nanalyzed. Using product telemetry not only \nallows engineers to detect potential issues but \nalso provides the foundation for identifying \nthe source of the problem. 5.2. Operational Risk Management \n\b\n[3, c6s6.4.12.3c4]\nOperations engineers must manage a number \nof risks. IEEE 2675 [4] defines continuous \nrisk management as a continuous process that \ncan be automated to monitor operations con-\nstantly for risks that can affect software avail-\nability, scalability and security.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 164", "position": 164, "chunk_type": "semantic", "token_estimate": 400}
{"text": "6-12   SWEBOK \u00ae GUIDE V4.0: Operational Risk Management \n\b\n[3, c6s6.4.12.3c4]\nOperations engineers must manage a number \nof risks. IEEE 2675 [4] defines continuous \nrisk management as a continuous process that \ncan be automated to monitor operations con-\nstantly for risks that can affect software avail-\nability, scalability and security. Operations \nengineers can take measures to automate \nthe alerts. To decide what events will trigger \nan alert, they need to talk with product \nowners and software engineers to establish \nan agreed-upon level of risk tolerance. Other \nperspectives are to choose the deployment \nprocess that is appropriate for the risk profile \nof a given service and the risks of exposing \nprivate data. 5.3. Automating Software Engineering \nOperations\b\n[2*, c8]\nAutomation has taken an important place in \nrecent years in modern operations. Software \nengineers achieve the best results when cou-\npling applications and operations automation. Although automation primarily focuses on \nmanaging the life cycle of a system or infra-\nstructure (e.g., user account creation, envi-\nronments and server provisioning, runtime", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 164", "position": 164, "chunk_type": "semantic", "token_estimate": 168}
{"text": "SOFTWARE ENGINEERING OPERATIONS   6-13: Continuous \ntesting involves various stakeholders, such as \ndevelopers, DevOps personnel, and QA and \nend-users. Continuous deployment (aka CD) is an auto-\nmated process of deploying changes to pro-\nduction by verifying intended features and \nvalidations to reduce risk. Jez Humble and \nDavid Farley [8] pointed out that \u201c[t]he biggest \nrisk to any software effort is that you end up \nbuilding something that isn\u2019t useful. The ear-\nlier and more frequently you get working soft-\nware in front of real users, the quicker you get \nfeedback to find out how valuable it really is.\u201d\n6.1. Containers and Virtualization \t\nDifferent container/virtualization technol-\nogies and management tools (also called \norchestrators) are available to operations \nengineers to improve the scalability of appli-\ncations and standardize software deployment \nacross multiple computer and server suppliers. [4, c6,s6.4.12] Operations engineers use their \nknowledge of the size and complexity of each \nproject to identify the best tool for flexibility, \nsecurity and monitoring. 6.2. Deployment\b\n[2*, c12] \nDifferent technologies and tools can be used \nto manage software deployments in different \nenvironments. [4, c5s5.1] Also, different tools \nare usually combined to cover the different \nphases and aspects of software deployment, \nranging from the specification of deployment \nand configuration using descriptor files to the", "domains": ["Software Quality Attributes", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 165", "position": 165, "chunk_type": "semantic", "token_estimate": 207}
{"text": "6-14   SWEBOK \u00ae GUIDE V4.0: automated deployment and management of \nproduction environment resources. 6.3. Automated Test \b\n[2*, c10]\nTo enable fast and constant feedback to the \ndevelopers, testing must be automated as \nmuch as possible throughout the entire soft-\nware delivery process, including throughout \ndevelopment and operations. For this pur-\npose, a testing strategy covering the different \ntypes of test (unit test, integration test, system \ntest, user acceptance test) must be defined, and \ntools to support and automate the different \ntesting phases must be selected. The automa-\ntion of testing is critical to provide continuous \nfeedback to software engineers developing \ncode and thereby to improve software quality. 6.4. Monitoring and Telemetry\b\n[2*, c14-15]\nMonitoring and telemetry are key aspects \nof software engineering operations. They \ncollect data at all layers of the software system \n(including application, operating system and \nserver) and extract information that can be \nused to analyze and monitor different aspects \nof the system to detect issues and follow \nthe evolution of various properties. James \nTurnbull [9] describes a general monitoring \nframework architecture used by engineering \noperations in many technology organizations. Implementing monitoring solutions requires \ncombining different techniques and tools to \ncollect data at different layers. This includes \nlogs at the application level, execution traces \nat the operating system level and resource \nuse information (like CPU and memory use) \nat the server level. Then, based on the col-\nlected data, different analytics techniques \n(e.g., statistical analysis and machine learning \ntechniques) can be used to extract relevant \ninformation. Finally, dashboards can be used \nto visualize the extracted information; dif-\nferent dashboards can be developed to display \nrelevant information to different stakeholders. MATRIX OF TOPICS VS. REFERENCE MATERIAL\nISO 20000-1  \n[1] \nThe DevOps  \nHandbook [2*]\nISO 12207 [3]\n1. Software Engineering Operations \nFundamentals\n1.1. Definition of Software Engineering \nOperations \nc3s3.3\nc6s6.4.12\n1.2. Software Engineering \nOperations Processes\ns1\nc6 s6.4.12\n1.3. Software Installation\nc3, c6s2\nc3s3.1\n1.4. Scripting and Automating\nc9\n1.5. Effective Testing and Troubleshooting\nc3\n1.6. Performance, Reliability and \nLoad Balancing\nc6s6.2\n2. Software Engineering \nOperations Planning\n2.1. Operations Plan and Supplier \nManagement\nc4s4.1\nc6s6.1\n2.2. Development and Operational \nEnvironments\nc9", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 166", "position": 166, "chunk_type": "semantic", "token_estimate": 352}
{"text": "SOFTWARE ENGINEERING OPERATIONS   6-15: 2.3. Software Availability, Continuity \nand Service Levels\nc6s6.3\n2.4. Software Capacity Management\nc6s6.5\n2.5. Software Backup, Disaster Recovery \nand Failover\nc6s6.3.4\n2.6. Software and Data Safety, Security, \nIntegrity, Protection and Controls\nc6s6.6\n3. Software Engineering \nOperations Delivery\n3.1. Operational Testing, Verification and \nAcceptance\nc10\nc6s6.3.5.3d\n3.2. Deployment/Release Engineering\nc12\n3.3. Rollback and\nData Migration\n3.4. Change Management\nc9s9.2\n3.5. Problem Management\nc8s8.3\n4. Software Engineering \nOperations Control\n4.1. Incident Management\nc8s8.2\n4.2. Monitor, Measure, Track and Review \nc14-15\n4.3. Operations Support\nc6, c14s5\n4.4. Operations Service Reporting\nc6s6.2\n5. Practical Considerations \n5.1. Incident and Problem Prevention\nc7\n5.2. Operational Risk Management\nc6s6.4.12.3c4\n5.3. Automating Software Engineering \nOperations\nc8\n5.4. Software Engineering Operations for \nSmall Organizations\n6. Software Engineering \nOperations Tools\nc5s5g\nc12\n6.1. Containers and Virtualization\n6.2. Deployment\nc12\n6.3. Automated Test\nc10\n6.4. Monitoring and Telemetry\nc14-15", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 167", "position": 167, "chunk_type": "semantic", "token_estimate": 142}
{"text": "6-16   SWEBOK \u00ae GUIDE V4.0: Handbook: How to create world-class \nagility, reliability and security in tech-\nnology organizations, 2nd ed., IT \nRevolution Press, 2021. [3]\t IEEE standard, ISO/IEC/IEEE \n12207:2017, Systems and software \nengineering \u2014 Software Life Cycle \nProcesses, ed. IEEE, 2017. [4]\t IEEE standard, ISO/IEC/IEEE \n32675:2022, Information Technology \n\u2014 DevOps: Building Reliable and \nSecure Systems Including Application \nBuild, Package and Deployment, ed. IEEE, 2022. [5]\t ISO/IEC/IEEE, \u201cISO/IEC/IEEE \n24765:2017 Systems and Software \nEngineering \u2014 Vocabulary,\u201d 2nd ed. 2017\n[6]\t B. Beyer, C. Jones, J. Petoff, and N.R. Murphy, Site Reliability Engineering \u2014 \nHow Google Runs Production Systems, \nO\u2019Reilly Media, 2016. [7] \tISO/IEC CD 29110-5-5:2023, Systems \nand software engineering \u2014 Lifecycle \nprofiles for Very Small Entities (VSEs), \nPart 5-5: Agile/DevOps guidelines. [8] \tJ. Humble and D. Farley. Continuous \ndelivery: reliable software releases through \nbuild, test, and deployment automation. Pearson Education, 2010. [9] \t J. Turnbull, The Art of Monitoring. James \nTurnbull, 2014.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 168", "position": 168, "chunk_type": "semantic", "token_estimate": 149}
{"text": "Section: Application Programming Interface", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 169", "position": 169, "chunk_type": "semantic", "token_estimate": 4}
{"text": "Successful software development efforts: result in the delivery of a software product \nthat satisfies user requirements. As those \nrequirements and other factors change, the \nsoftware product must evolve: Once the soft-\nware is in operation, defects are uncovered, \noperating environments change, and new \nuser requirements surface. The maintenance \nphase of the life cycle begins after a warranty \nperiod or after post-implementation support \ndelivery, but maintenance activities occur \nmuch earlier. Software maintenance is an integral part \nof a software life cycle. However, it has not \nreceived the same degree of attention as \nthe other software engineering activities. Historically, software development has had \na much higher profile than software mainte-\nnance. This is now changing as organizations \nstrive to optimize their software engineering \ninvestment by ensuring continuous develop-\nment, maintenance and operation, progres-\nsively eliminating the organizational silos \namong these areas. The growing acceptance \nof DevOps practices and tools have drawn \nfurther attention to the need to continuously \nevolve software while ensuring its smooth \noperation to satisfy users, who are demanding \nquicker turnaround from software engineers \nthan in the past. In this SWEBOK Guide, software main-\ntenance is defined as the totality of activi-\nties required to provide cost-effective support \nfor software in operation. Activities to sup-\nport software operation and maintenance are \nperformed during the pre delivery stage and \nduring the post delivery stage. Pre delivery \nactivities include planning for post delivery \noperations, maintainability and determining \nthe logistics support needed for the tran-\nsition from development to maintenance. Postdelivery activities include software sur-\nveillance, modification, training, and oper-\nating or interfacing with a help desk. The Software Maintenance knowledge area \n(KA) is related to all other aspects of software \nengineering. Therefore, this KA description is \nlinked to all other software engineering KAs \nin the Guide.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 169", "position": 169, "chunk_type": "semantic", "token_estimate": 294}
{"text": "The breakdown of topics for the Software: Maintenance KA is shown in Figure 7.1. 1. Software Maintenance Fundamentals\nThis section introduces the concepts and ter-\nminology that form a basis for understanding \nthe role and scope of software maintenance. Among these concepts are the different cat-\negories of software maintenance. Learning \nabout these categories is critical to under-\nstanding what this knowledge area encom-\npasses and why it is so important. 1.1. Definitions and Terminology \n\b\n[1, s3.1][2*, c1s1.2, c2s2,2] \nThe purpose of software maintenance is \ndefined in the international standard for soft-\nware maintenance: ISO/IEC/IEEE 14764 \n[1]. In the context of software engineering, \nsoftware maintenance is essentially one of \nmany technical processes. The objective of \nsoftware maintenance is to modify existing \nsoftware while preserving its integrity. The \ninternational standard also emphasizes the \nimportance of performing some maintenance \nactivities before final delivery of the software \n(pre delivery activities). Software mainte-\nnance shares knowledge and tools with soft-\nware development and software operation and \nalso has its own processes and  techniques. 1.2. Nature of Software Maintenance \n\b\n[2*, c1s1.3]\nSoftware maintenance sustains the soft-\nware product throughout its life cycle (from \ndevelopment through operations). The soft-\nware is monitored for capacity, continuity \nand \navailability. Modification \nrequests \n(MRs) and incidents or problems reports \n(PRs) are logged and tracked, the impact of \nproposed changes is determined, code and \nother software artifacts are modified, testing \nis conducted, and a new version of the soft-\nware product is released into operation. Also, training and daily ongoing support \nare provided to users. A software maintainer \nis defined as a role or an organization that \nperforms software maintenance activities. Software\nMaintenance\nDe\ufb01nitions and \nTerminology\nTechnical Issues\nManagement \nIssuess\nSoftware \nMaintenance\nCost\nSoftware \nMaintenance\nMeasurements\nNature of\nSoftware \nMaintenance\nNeed of\nSoftware \nMaintenance\nCategories of\nSoftware \nMaintenance\nEvolution of\nSoftware\nKey Issues in\nSoftware\nMaintenance\nSoftware\nMaintenance\nFundamentals\nSoftware\nMaintenance\nProcesses\nSoftware\nMaintenance\nProcesses\nProgram\nComprehension\nSoftware\nReengineering\nReverse\nEngineering\nCI/CD, Testing\nand Deployment\nSoftware\nMaintenance\nActivities \nand Tasks\nSoftware\nMaintenance\nTechniques\nSoftware\nMaintenance\nTools\nFigure 7.1. Breakdown of Topics for the Software Maintenance KA", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 170", "position": 170, "chunk_type": "semantic", "token_estimate": 347}
{"text": "SOFTWARE MAINTENANCE   7-3: In this KA, the term sometimes refers to \nindividuals who perform those activities, to \ncontrast their role with the software devel-\noper\u2019s role. Maintainers can learn from the developers\u2019 \nand operators\u2019 knowledge of the software. Early contact with the developers and early \ninvolvement by the maintainers can reduce \nthe overall maintenance costs and efforts. An \nadditional challenge is created when main-\ntainers join the project after the initial devel-\nopers have left or are no longer available. Maintainers must understand and use soft-\nware artifacts from development (e.g., code, \ntests or documentation), support them imme-\ndiately, and progressively evolve and maintain \nthem over time. 1.3. Need for Software Maintenance  \n\b\n[2*, c1s1.5]\nSoftware maintenance is needed to ensure that \nthe software continues to satisfy user require-\nments throughout its life span. Maintenance \nis necessary regardless of the type of software \nlife cycle model used to develop it (e.g., water-\nfall or Agile). Software products change as a \nresult of both corrective and non-corrective \nactions. Software maintenance is typically \nperformed to do the following:\n\u2022\t Correct faults and latent defects\n\u2022\t Improve the design or performance of \noperational software\n\u2022\t Implement enhancements\n\u2022\t Help users understand the software\u2019s \nfunctionality\n\u2022\t Adapt to changes in interfaced systems or \ninfrastructure\n\u2022\t Prevent security threats\n\u2022\t Remediate technical obsolescence of \nsystem or software elements\n\u2022\t Retire the software\n1.4. Majority of Maintenance Costs \n\b\n[2*, c4s4.3, c5s5.2]\nIt is generally accepted that the relative cost \nof error fixing increases in later phases of \nthe software life cycle. Maintenance also \nuses a significant portion of the total finan-\ncial resources attributed throughout the life \nof a software. A common perception of soft-\nware maintenance is that it merely fixes faults. However, studies and surveys over the years \nhave indicated that most software mainte-\nnance \u2014 over 80% \u2014 is used for enhancing \nand adapting the software [3]. Grouping \nenhancements and corrections together in \nmanagement reports contributes to a mis-\nconception that corrections cost more than \nthey really do. Understanding the categories \nof software maintenance helps us understand \nthe structure of software maintenance costs \n\u2014 that is, where most of that spending goes \n[7]. Also, understanding the factors that affect \nthe maintainability of software can help orga-\nnizations contain costs. Environmental fac-\ntors that affect software maintenance costs \ninclude the following:\n\u2022\t Operating environment (hardware and \nsoftware).", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 171", "position": 171, "chunk_type": "semantic", "token_estimate": 394}
{"text": "SOFTWARE MAINTENANCE   7-3: Also, understanding the factors that affect \nthe maintainability of software can help orga-\nnizations contain costs. Environmental fac-\ntors that affect software maintenance costs \ninclude the following:\n\u2022\t Operating environment (hardware and \nsoftware). \u2022\t Organizational \nenvironment \n(poli-\ncies, competition, process, product and \npersonnel). 1.5. Evolution of Software  \n\b\n[2*, c3s3.5]\nSoftware maintenance as an activity that \nsupports the evolution of software was first \naddressed in the late 1960s. Research, by \nLehman and others [8], over a period of twenty \nyears led to the formulation of eight laws of \nsoftware evolution: \n\u2022\t Continuing Change \u2014 Software must be \ncontinually adapted, or it becomes pro-\ngressively less satisfactory. \u2022\t Increasing Complexity \u2014 As software \nevolves, its complexity increases unless \nwork is done to maintain or reduce that \ncomplexity. \u2022\t Self-Regulation \u2014 The program evolu-\ntion process is self regulating with close \nto normal distribution of measures of \nproduct and process attributes.", "domains": ["Design Patterns", "Software Quality Attributes", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 171", "position": 171, "chunk_type": "semantic", "token_estimate": 152}
{"text": "7-4   SWEBOK \u00ae GUIDE V4.0: \u2022\t Invariant Work Rate \u2014 The average \neffective global activity rate in an evolving \nsoftware package is invariant over the \nproduct\u2019s lifetime. \u2022\t Conservation of Familiarity \u2014 As soft-\nware evolves, all associated with it (e.g., \ndevelopers, sales personnel and users) \nmust maintain mastery of its content and \nbehavior to achieve satisfactory evolution. Excessive growth diminishes that mas-\ntery. Hence, average incremental growth \nremains invariant as the system evolves. \u2022\t Continuing Growth \u2014 Functional con-\ntent of a program must be continually \nincreased to maintain user satisfaction \nover its lifetime. \u2022\t Declining Quality \u2014 The quality of soft-\nware will appear to be declining unless it \nis rigorously maintained and adapted to \nchanges in the operational environment. \u2022\t Feedback System \u2014 Software evolution \nprocesses constitute multilevel, multi-\nloop, multi-agent feedback systems and \nmust be treated as such to achieve sig-\nnificant improvement over any rea-\nsonable base. Key findings of Lehman\u2019s research include \na proposal that maintenance is evolutionary \ndevelopment and that maintenance decisions \nare aided by an understanding of what hap-\npens to software over time. Another way to \nthink of maintenance is as continued devel-\nopment that accommodates extra inputs (or \nconstraints) \u2014 in other words, large software \nprograms are never complete and continue \nto evolve. As they evolve, they grow more \ncomplex unless action is taken to reduce that \ncomplexity. 1.6. Categories of Software Maintenance \n\b\n[1, s3.1.8][2*, c1s1.8, c3s3.3]\nFive categories (types) of software mainte-\nnance have been standardized to classify a \nmaintenance request: corrective, preventive, \nadaptive, additive and perfective. ISO/IEC/\nIEEE 14764 [1], regroups these maintenance \ncategories as either corrections or enhance-\nments, as shown in Figure 7.2. ISO/IEC/IEEE 14764 [1] also defines a \nsixth category \u2014 emergency maintenance: \n\u2022\t Corrective maintenance: Reactive modi-\nfication (or repairs) of a software product \nperformed after delivery to correct dis-\ncovered problems. \u2022\t Preventive maintenance: Modification of \na software product after delivery to cor-\nrect latent faults in the software product \nbefore they occur in the live system. \u2022\t Adaptive maintenance: Modification of a \nsoftware product performed after delivery \nto keep a software product usable in an \nevolving environment. Adaptive mainte-\nnance provides enhancements necessary \nto accommodate changes in the environ-\nment in which a software product operates \n(e.g., an upgrade to the operating system \nresults in changes to the applications).", "domains": ["Design Patterns", "Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 172", "position": 172, "chunk_type": "semantic", "token_estimate": 388}
{"text": "SOFTWARE MAINTENANCE   7-5: Additive maintenance differs from per-\nfective maintenance in that a) it provides \nadditional new functions or features to \nimprove software usability, performance, \nmaintainability or other software quality \nattributes, and b) it adds functionality or \nfeatures with relatively large additions \nor changes for improving software attri-\nbutes after delivery. \u2022\t Perfective maintenance: Modification of \na software product after delivery to pro-\nvide enhancements for users, improve-\nment of program documentation, and \nrecoding to improve software perfor-\nmance, maintainability, or other software \nattributes. \u2022\t Emergency maintenance: Unscheduled \nmodification performed to temporarily \nkeep a system operational, pending cor-\nrective maintenance. 2. Key Issues in Software Maintenance\nA number of key issues must be dealt with to \nensure the effective maintenance of software. Software maintenance provides unique tech-\nnical and management challenges for soft-\nware engineers (e.g.,the challenge of finding \na fault in large complex software developed by \nsomeone else.) Similarly, in an Agile setting, maintainers \nand developers are constantly striving to make \nsure that clients see the value at the end of \neach iteration so maintenance activities have \nto compete with the development of new fea-\ntures for client approval; Planning for a future \nrelease, which often includes coding the next \nrelease while sending out emergency patches \nfor the current release, also creates a challenge \nin balancing maintenance and development \nwork. The following section presents tech-\nnical and management issues related to soft-\nware maintenance. They are grouped under \nthe following topics:\n\u2022\t Technical issues. \u2022\t Management issues. \u2022\t Software maintenance costs. \u2022\t Software maintenance measurement. 2.1. Technical Issues\n2.1.1\t\nLimited Understanding \n\b\n[2*, c6s6.9]\nLimited understanding describes a software \nengineer\u2019s initial comprehension of software \nsomeone else developed. This is reflected in \nhow quickly a software engineer can under-\nstand where to change or correct the soft-\nware. Research suggests a significant portion \nof total maintenance effort is devoted to \nunderstanding the software to be modified. Consequently, the topic of software compre-\nhension is of great interest to software engi-\nneers. A number of comprehension factors \nhave been identified: 1) domain knowledge; 2) \nprogramming practices (e.g., implementation \nissues); 3) documentation; and 4) organisation \nand presentation issues. Comprehension is \nmore difficult in text-oriented representation \n(e.g., in source code), where it is often difficult \nto trace the evolution of software through its \nreleases or versions if changes are not docu-\nmented and the developers are not available \nto explain them.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 173", "position": 173, "chunk_type": "semantic", "token_estimate": 398}
{"text": "SOFTWARE MAINTENANCE   7-5: A number of comprehension factors \nhave been identified: 1) domain knowledge; 2) \nprogramming practices (e.g., implementation \nissues); 3) documentation; and 4) organisation \nand presentation issues. Comprehension is \nmore difficult in text-oriented representation \n(e.g., in source code), where it is often difficult \nto trace the evolution of software through its \nreleases or versions if changes are not docu-\nmented and the developers are not available \nto explain them. Thus, software engineers \nmay initially have a limited understanding \nof the software, and much work must be \ndone to remedy this. Various techniques can \nhelp engineers understand existing software, \nsuch as visualization and reverse engineering \nusing tool-based graphical representations \nof the code. 2.1.2\t\nTesting \n\b\n[1, s6.2][2*, c9, c13s13.4.4] \nTest planning and activities occur during MRs \nand PRs processing. The cost of repeating full \ntesting on a major piece of software is signifi-\ncant, in both time and effort. To ensure a soft-\nware modification is validated, the maintainer \nshould replicate or verify changes by planning \nand executing the appropriate tests \u2014 for \nexample, regression testing is important in \nmaintenance. Regression testing is the selec-\ntive retesting of software or a component to \nverify that the modifications have not caused \nunintended effects. Another challenge is", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 173", "position": 173, "chunk_type": "semantic", "token_estimate": 205}
{"text": "7-6   SWEBOK \u00ae GUIDE V4.0: finding the time to conduct as much testing \nas possible. Coordinating tests can be chal-\nlenging for maintenance team members who \nare simultaneously working on different prob-\nlems. Bringing software offline to test it can \nbe difficult if the software performs critical \nfunctions. The Software Testing KA pro-\nvides additional information and references \non software testing and its subtopic on regres-\nsion testing. 2.1.3\t\nImpact Analysis \n\b\n[1, s5.1.6][2*, c13s13.3] \nImpact analysis assesses the detailed effects \nof proposed changes on existing software. Software engineers should strive to con-\nduct the analysis as cost-effectively as pos-\nsible. Maintainers need detailed knowledge \nof the software\u2019s structure and content. They \nuse that knowledge to perform the impact \nanalysis, which identifies all systems and \nsoftware products that would be affected by \na software change request and develops an \nestimate of the resources needed to accom-\nplish the change. The analysis also deter-\nmines the risks involved in making the \nchange. The change request (originating \nfrom an MR or a PR), must first be analyzed \nand translated into software terms. Impact \nanalysis is performed after a change request \nenters the software configuration man-\nagement (SCM) process. ISO/IEC/IEEE \n14764 [1] states that the impact analysis \ntasks do the following:\n\u2022\t Develop \nan \nidentification \nscheme \nfor MRs/PRs. \u2022\t Develop a scheme for categorizing and \nprioritizing MRs/PRs. \u2022\t Determine the procedures for an operator \nto submit an MR/PR. \u2022\t Identify the information needs and issues \nthat must be tracked and reported to the \nusers and identify the measures that pro-\nvide feedback on those information needs \nand issues. \u2022\t Determine how temporary work-arounds \nwill be provided to the operators. \u2022\t Track \nthe \nwork-around(s) \nthrough \nto removal. \u2022\t Determine what follow-up feedback will \nbe provided to the users. Software maintainers often use the severity \nof a PR as a guide when deciding how and \nwhen to fix the problem. The maintainer con-\nducts an impact analysis that identifies the \naffected components, develops several poten-\ntial solutions, and, finally, recommends a \ncourse of action. Impact analyses of proposed maintenance \nchanges often consider various factors such as \nthe maintenance category, the size of the mod-\nification, the cost involved, the testing needed \nto make the modification, and any impacts on \nperformance, safety and security. Designing \nsoftware with maintainability in mind greatly \nfacilitates impact analysis. More information \ncan be found in the Software Configuration \nManagement KA.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 174", "position": 174, "chunk_type": "semantic", "token_estimate": 399}
{"text": "7-6   SWEBOK \u00ae GUIDE V4.0: Designing \nsoftware with maintainability in mind greatly \nfacilitates impact analysis. More information \ncan be found in the Software Configuration \nManagement KA. 2.1.4\t\nMaintainability \n\b\n[1, s8.8][2*, c12s12.5.5]\nISO/IEC/IEEE 14764 [1] defines main-\ntainability as the capability of the software \nproduct to be modified. Modifications can \ninclude corrections, improvements or adap-\ntation of the software to changes in environ-\nment, as well as changes in requirements and \nfunctional specifications. As an important software quality char-\nacteristic, maintainability should be speci-\nfied, reviewed and controlled during software \ndevelopment activities in order to reduce \nmaintenance costs. When these activities are \ncarried out successfully, the software\u2019s main-\ntainability will benefit. Maintainability is \noften difficult to achieve because it is often not \na primary focus during software development. The developers are typically more focused on \nother activities and might not pay enough \nattention to maintainability requirements. This can result in bad architecturing, missing \nsoftware documentation or test environments, \nwhich is a leading cause of difficulties in pro-\ngram comprehension and subsequent impact", "domains": ["Software Quality Attributes", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 174", "position": 174, "chunk_type": "semantic", "token_estimate": 172}
{"text": "SOFTWARE MAINTENANCE   7-7: analysis during maintenance. The presence of \nsystematic and mature software development \nprocesses, techniques and tools helps enhance \nthe maintainability of software. The Software \nQuality KA provides additional information \nand references on software maintainability. Compromised software maintainability \ntypically increases the burden on software \nengineers who maintain the software in the \nfuture; in other words, it creates technical \ndebt. Technical debt often accumulates when \nthe need to quickly address corrective, emer-\ngency, and additive maintenance tasks, con-\nstrained by limited time and understanding \nof the software, leads to compromises. These \nimmediate but potentially under-considered \nsolutions, often not peer-reviewed, contribute \nto the accumulation of technical debt. This \npractice generally creates a technical debt that \nwill take additional time and effort to address \nduring maintenance. Specifically, software \nengineers must investigate three areas in \ndepth when addressing technical debt:\n1. Code quality versus relevance: Not all \ntechnical debt is urgent. 2. Alignment with organizational objec-\ntives: The software architecture should \nreflect the organization\u2019s goals. 3. Process loss: Ensure complementary \nskills of software engineers involved. 2.2. Management Issues\n2.2.1. Alignment with Organizational \nObjectives \n\b\n[1, s9.1.8][2*, c2s2.3.1.2, c3s3.4]\nThis section describes how to optimizse soft-\nware maintenance activities and economics \nto be aligned with  organizational objectives \nand the priorities of the business, customers \nand users. In many organizations, initial software \ndevelopment is project-based, with a defined \ntime scale and budget. The main goal is to \ndeliver a product that meets user needs on \ntime and within budget. In contrast, soft-\nware maintenance aims to extend the life of \nsoftware and keep it operational for as long \nas possible. In addition, it may be driven by \nthe need to meet user demand for software \nupdates and enhancements. In both cases, the economics of software \nmaintenance is not as visible as those of soft-\nware development. At the organizational \nlevel, it may be seen as an activity that con-\nsumes significant resources with no clear, \nquantifiable benefit for the organization. As \na consequence, adding new features is often \ngiven higher priority than other maintenance \nactivities (such as refactoring, security or per-\nformance improvement) to meet the goals \nand objectives of software customers, as well \nas with constraints such as time and budget. However, such organizational objectives and \nconstraints must be balanced with software \nmaintainability and engineering standards to \navoid code decay and technical debt.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 175", "position": 175, "chunk_type": "semantic", "token_estimate": 389}
{"text": "SOFTWARE MAINTENANCE   7-7: As \na consequence, adding new features is often \ngiven higher priority than other maintenance \nactivities (such as refactoring, security or per-\nformance improvement) to meet the goals \nand objectives of software customers, as well \nas with constraints such as time and budget. However, such organizational objectives and \nconstraints must be balanced with software \nmaintainability and engineering standards to \navoid code decay and technical debt. Applying product management approaches \nto the management of software development \nand maintenance can help organizations:\n\u2022\t Understand the total cost of operational \nsoftware over its full life cycle. \u2022\t Compare the costs and benefits of devel-\noping new software versus enhancing \nexisting software. \u2022\t Resolve staffing and skills issues, as the \nsame team can be responsible for mainte-\nnance and development. \u2022\t Focus more on maintainability require-\nments from the start, as the same team \nhas responsibility for both development \nand maintenance. 2.2.2. Staffing\b\n[1*, s6.4.13.3c] \n\b\n[2*, c2s2.3.1.5, c10s10.4]\nAlthough maintenance work is sometimes \nperceived as less engaging, this view overlooks \nthe critical importance of software main-\ntainers. Given that maintenance constitutes a \nsignificant portion of software lifecycle activi-\nties, recognizing and valuing the contribution \nof maintainers is essential to boosting morale, \nperformance, and reducing staff turnover.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 175", "position": 175, "chunk_type": "semantic", "token_estimate": 205}
{"text": "7-8   SWEBOK \u00ae GUIDE V4.0: Organizations need to design development \nand maintenance teams and roles carefully \nand provide professional development oppor-\ntunities for their staff. 2.2.3. Process\b\n[1*, s6][2*, c5] \nThe software life cycle process is a set of \nactivities, methods, practices and transforma-\ntions that people use to develop and maintain \nsoftware and its associated products. At the \nprocess level, software maintenance activ-\nities share much in common with software \ndevelopment (e.g., SCM is a crucial activity \nin both). Maintenance also requires several \nactivities not found in software development. (Refer to section 3.2.) 2.2.4. Supplier Management \n\b\n[1*, s6.1.2, s8.3, s8.8.2]\nSupplier management ensures that the orga-\nnization\u2019s suppliers and their performance are \nmanaged appropriately to support the seam-\nless provision of quality products and services \nwhen maintenance is contracted to suppliers. The nature of the organization\u2019s relation-\nship with suppliers and its approach to sup-\nplier management should be determined by \nthe nature of these products and services. Contractors can be hired to conduct main-\ntenance tasks and outsourcing or offshoring \nsoftware maintenance is a major industry. Outsourcing maintenance means substituting \ninternal capability with an external supplier\u2019s \ncapability. Approaches to contracting mainte-\nnance include the following:\n\u2022\t Single source or partnership: A single sup-\nplier provides all services, or an external \nservice integrator manages the organiza-\ntion\u2019s relationship with all suppliers. \u2022\t Multi-sourcing: Products and services \nare provided by more than one inde-\npendent supplier. These are combined \ninto a single (software-enabled) service. Multi-sourcing in software services is \nincreasingly common, enabled by the \ngrowth of \u201canything as a service\u201d (XaaS), \napplication \nprogramming \ninterfaces \n(APIs), and data sources. Many organizations outsource entire port-\nfolios of software. Typically, these portfolios \ninclude software that is not mission-critical, as \norganizations do not want to lose control of \nthe software used in their core business. One \nmajor challenge for outsourcers is determining \nthe scope of the maintenance services required, \nthe terms of a service-level agreement (SLA), \nand the contractual details. Outsourcers need \nto invest in good communication infrastruc-\nture and an efficient help desk staffed with \npeople who can communicate effectively with \ncustomers and users [3]. Outsourcing requires \na significant initial investment and the setup \nand review of software maintenance processes \nthat require automation. 2.2.5. Organizational Aspects of Maintenance  \n\b\n[1, s9.1.8][2*, c10]\nOrganizational \naspects \nof \nmaintenance \ninclude determining which teams will be \nresponsible for software maintenance.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 176", "position": 176, "chunk_type": "semantic", "token_estimate": 394}
{"text": "SOFTWARE MAINTENANCE   7-9: leave for more interesting work. In addition, a \nhandoff process must be put in place between \ndevelopers and maintainers, which sometimes \nleads to friction between teams [3]. The introduction of product manage-\nment processes has encouraged a single-team \napproach, particularly for developing and \nmaintaining software that needs to respond \nrapidly to changes in customer and user needs. Because there are many pros and cons to each \noption, the decision should be made on a case-\nby-case basis. What is important is that the \norganization delegates the maintenance tasks \nto an experienced group or person and keeps \nquality documentation on maintenance tasks \nand all changes made to the software, regard-\nless of the organization\u2019s structure. 2.3. Software Maintenance Costs \nSoftware engineers must understand the dif-\nferent categories of software maintenance \ndescribed  in 1.6. Presenting costs trends by \ncategories of Maintenance can show cus-\ntomers where maintenance effort is spent for \neach system supported [7]. The data about \nmaintenance effort by category can be also \nused to accurately estimate the cost of software \nmaintenance. Cost estimation is an important \naspect of planning software maintenance. 2.3.1. Technical Debt Cost Estimation \n\b\n[1, s6.1.7, s8.8.3.6][2*, c12.12.5]\nTechnical debt generally makes code more \nexpensive to maintain than it has to be. Technical debt represents the effort required \nto fix problems that remain in the code when \nan application is initially released by the devel-\nopment team. Several techniques and indica-\ntors can help engineers measure technical debt, \nincluding, size, complexity and the number of \nengineering flaws and violations of good archi-\ntectural design and coding practices in the \nsource code. ISO/IEC/IEEE 14764 provides \nsuggestions for improving maintainability, \nincluding: ensuring legibility, pursuing struc-\ntured code, reducing code complexity, provide \naccurate code comments, using identation and \nwhite space, eliminating language weaknesses \nand compiler dependent constructs, facilitate \nerror-tracing, ensure traceability of code to \ndesign, conduct inspections and code reviews. A software product needs to evolve, by adding \nnew features and capabilities, and its codebase \nmust remain maintainable, easily understood, \nand easy to further evolve. A common barrier \nto addressing technical debt \u2014 or, indeed, of \nimplementing any potential enhancement \u2014 \nis the uncertain reward for doing so. That\u2019s \nwhy it\u2019s so important for organizations to \ndetermine the following:\n\u2022\t The quality of their current software. \u2022\t The current cost of their technical debt. \u2022\t The potential savings from investing in \nquality enhancement.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 177", "position": 177, "chunk_type": "semantic", "token_estimate": 397}
{"text": "7-10   SWEBOK \u00ae GUIDE V4.0: \u2022\t Product changes, program management. \u2022\t Field service engineers. \u2022\t Renting facilities for maintenance. Moreover, as the maintenance and devel-\nopment efforts progress, the estimates should \nbe amended. Historical measurement data \nshould be used as inputs to estimate main-\ntenance costs. Additionally, cost estimates \nare also required during impact analysis of \nindividual MR or PR. The cost estimating \nmethod (e.g., parametric model, comparison \nto analog systems, use of empirical and his-\ntorical data) should be described. Estimates of \nindividual MRs or PRs typically include the \nestimated effort associated with executing a \nchange, resource estimates and an estimated \ntimeline for implementing the change. 2.4. Software Maintenance Measurement \n\b\n[1, s6.1.7][2*, c12]\nMeasurable software maintenance artifacts \ninclude maintenance processes, resources and \nproducts [2*, c12s12.3.1]. Measures include \nsize, complexity, quality, understandability, \nmaintainability and effort. One useful measure \nis the amount of effort (in terms of resources) \nexpended for corrective, preventive, adaptive, \nadditive and perfective maintenance. Complexity and technical debt measures \nof software can also be obtained using avail-\nable tools. These measures constitute a good \nstarting point for the measurement of soft-\nware quality. Maintainers should determine \nwhich measures are appropriate for a spe-\ncific organization based on that organiza-\ntion\u2019s needs. Software measurement programs \nare discussed in the Software Engineering \nManagement KA. The software quality model described in \nthe Software Quality KA describes software \nproduct and process measures specific to soft-\nware maintenance. Measurable characteristics \nof maintainability include the following:\n\u2022\t Modularity measures the degree to which \na system or software is composed of com-\nponents that are independent, such that \na change to one component has minimal \nimpact on other components. \u2022\t Reusability measures how well a compo-\nnent can be reused. \u2022\t Analyzability measures the effort or \nresources the maintainer must expend \neither to diagnose deficiencies or causes \nof failure or to identify components to \nbe modified. \u2022\t Modifiability measures the maintain-\ner\u2019s effort associated with implementing \na specified modification without intro-\nducing defects or degrading existing \nproduct quality. \u2022\t Testability measures the effort main-\ntainers and users expend to test the mod-\nified software. \u2022\t Supportability measures the ease with \nwhich support can be provided for the \nsoftware, encompassing the availability \nand accessibility of documentation, tools, \nand assistance for addressing issues, \nfacilitating effective maintenance and \ntroubleshooting.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 178", "position": 178, "chunk_type": "semantic", "token_estimate": 382}
{"text": "7-10   SWEBOK \u00ae GUIDE V4.0: \u2022\t Testability measures the effort main-\ntainers and users expend to test the mod-\nified software. \u2022\t Supportability measures the ease with \nwhich support can be provided for the \nsoftware, encompassing the availability \nand accessibility of documentation, tools, \nand assistance for addressing issues, \nfacilitating effective maintenance and \ntroubleshooting. Other measures that software maintainers \nuse include the following:\n\u2022\t Reliability: The degree to which a system \nor software performs specific functions \nunder specified conditions for a spec-\nified period, including the following \ncharacteristics:\no\tMaturity: How well a system or soft-\nware can meet the need for reliability. o\tAvailability: Whether a system or soft-\nware is operational and accessible. o\tFault tolerance: How well a system or \nsoftware operates despite hardware or \nsoftware faults. o\tRecoverability: How well a system or \nsoftware can recover data during an \ninterruption or failure. \u2022\t Size of the software (e.g., functional \nsize, LOC). \u2022\t Number of maintenance requests, by \ntime period.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 178", "position": 178, "chunk_type": "semantic", "token_estimate": 162}
{"text": "7-12   SWEBOK \u00ae GUIDE V4.0: ISO/IEC/IEEE 14764 recommends that \nwhen a maintainer uses a development pro-\ncess, the process must be tailored to meet spe-\ncific needs. However, there are a number of processes, \nactivities and practices that are specialized to \nsoftware maintenance:\n\u2022\t Program understanding: This comprises \nthe activities needed to obtain a general \nknowledge of what a software product \ndoes and how the parts work together. \u2022\t Transition: This is a controlled and coor-\ndinated sequence of activities during \nwhich software is transferred progres-\nsively from the developer to the opera-\ntions and maintenance team. \u2022\t MR acceptance/rejection: Modifications \nrequesting work greater than the agreed \nsize, level of effort, or level of complexity \nmay be rejected by maintainers and \nrerouted to a developer. \u2022\t Maintenance help desk: The help desk \nis an end-user and maintenance-coordi-\nnated support function that triggers the \nassessment, prioritization and costing of \nMRs and incidents. \u2022\t Impact analysis: The impact analysis \nidentifies areas impacted by a poten-\ntial change. \u2022\t Maintenance \nservice-level \nindicators \n(SLIs), service-level objectives (SLOs), \nSLAs, and maintenance software and \nhardware licenses and contracts: These \nare contractual agreements that describe \nthe services and quality objectives of \nthird parties. 3.2.1. Supporting and Monitoring Activities  \n\b\n[s6.4.13.3d5, s6.1.8][2*, c3s3.4]\nMaintainers may also perform ongoing sup-\nport activities, such as documentation, SCM, \nverification and validation (V&V), problem \nresolution, software quality assurance (SQA), \nreviews, vulnerability assessments, and audits. Another important management of mainte-\nnance results activity is that of monitoring \ncustomer satisfaction. 3.2.2. Planning Activities \n\b\n[1, s6.1.3, s8.7.2][2*, c10]\nAn important activity for software main-\ntenance is planning, and this process must \naddress the issues associated with a number \nof planning perspectives, including the \nfollowing:\n\u2022\t Business planning (organizational level)\n\u2022\t Maintenance planning (transition level). \u2022\t Release/version planning (software level). \u2022\t MR planning (at individual request level). At the individual request level, planning is \ncarried out during the impact analysis. (See \nsection 2.1.3, Impact Analysis.) The release/\nversion planning activity requires that the \nmaintainer do the following:\n\u2022\t Collect the dates of availability of indi-\nvidual requests. \u2022\t Agree with users on the content of sub-\nsequent releases/versions. \u2022\t Identify potential conflicts and develop \nalternatives. \u2022\t Assess the risk of a given release \nand develop a back-out plan in case \nproblems arise\n\u2022\t Inform all stakeholders.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 180", "position": 180, "chunk_type": "semantic", "token_estimate": 381}
{"text": "SOFTWARE MAINTENANCE   7-13: 4.1. Program Comprehension \n\b\n[2*, c6, c14s14.5]\nMaintainers spend considerable time reading \nand understanding programs in order to \nimplement changes. Code browsers are key \ntools for program comprehension and are used \nto organize and present source code. Clear \nand concise documentation also aids program \ncomprehension. 4.2. Software Reengineering \n\b\n [2*, c7]\nSoftware reengineering refers to the examina-\ntion and alteration of software to reconstitute \nit in a new form. It includes the subsequent \nimplementation of the new form. It is often \nundertaken not to improve maintainability \nbut to replace aging legacy software. Refactoring is a reengineering technique \nthat aims to reorganize a program without \nchanging its behavior. Refactoring seeks to \nimprove the internal structure and the main-\ntainability of software. Refactoring tech-\nniques can be used during maintenance \nactivities to reduce the technical debt of the \ncodebase before and after code changes. In the context of Agile software develop-\nment, the incremental nature of continuous", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 181", "position": 181, "chunk_type": "semantic", "token_estimate": 158}
{"text": "7-14   SWEBOK \u00ae GUIDE V4.0: integration (CI) often requires the code to \nbe continuously refactored to augment its \nquality and reliability. Hence, continuous \nrefactoring supports the volatile software \nlife cycle by providing better ways to reduce \nand manage the growing complexity of soft-\nware systems while improving developer \nproductivity. 4.3. Reverse Engineering \n\b\n[2*, c7, c14s14.5]\nReverse engineering is the process of ana-\nlyzing software to identify the software\u2019s \ncomponents and their interrelationships \nand creating representations of the soft-\nware in another form or at higher levels of \nabstraction. Reverse engineering is passive; \nit does not change the software or result in \nnew software. Reverse engineering efforts \ntypically produce graphical representations \nof different software artifacts, such as call \ngraphs and control flow graphs from source \ncode. Types of reverse engineering include \nthe following:\n\u2022\t Re-documentation. \u2022\t Design recovery. \u2022\t Data reverse engineering \u2014 recovering \nlogical schemata from physical databases. Tools are key for reverse engineering and \nrelated tasks such as re-documentation and \ndesign recovery. Software visualization is \na common reverse engineering technique \nthat helps maintainers explore, analyze and \nunderstand the structure of software systems \nas well as their evolution. Software visual-\nization comprises visually encoding and ana-\nlyzing software systems, including software \nmaintenance practices, evolution, structure \nand software runtime behavior using infor-\nmation visualization, computer graphics and \nhuman-computer \ninteraction. Generally, \nsoftware visualization tools are accompanied \nby various quality assurance features, such \nas quality metrics calculation, technical debt \nestimation, and bad design and coding prac-\ntices (code smells) detection. 4.4. Continuous Integration, Delivery, Testing \nand Deployment\b\n[1, s6.4.13.3 Note 1]\nAutomating \ndevelopment, \noperation \nand \nmaintenance-related tasks saves engineering \nresources. When implemented appropriately, \nsuch automated tasks are generally faster, easier \nand more reliable than they would be if per-\nformed manually. ISO14764 states that auto-\nmation includes distribution and installation of \nsoftware. [1, s6.4.13.3 Note 1]. DevOps supports \nsuch automation while building, packaging and \ndeploying reliable and secure systems. DevOps \ncombines development, operations, and main-\ntenance resources and procedures to perform \nCI, delivery, testing and deployment. [9]\nCI is a software engineering practice that \ncontinually merges artifacts, including source \ncode updates from all members of a team, into \na shared mainline for evolving and testing the \ndeveloped system. With CI, the members of \na team can integrate their changes frequently, \nand each integration can be verified by an \nautomated build (including testing) to detect \nintegration errors as quickly as possible.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 182", "position": 182, "chunk_type": "semantic", "token_estimate": 398}
{"text": "7-14   SWEBOK \u00ae GUIDE V4.0: [9]\nCI is a software engineering practice that \ncontinually merges artifacts, including source \ncode updates from all members of a team, into \na shared mainline for evolving and testing the \ndeveloped system. With CI, the members of \na team can integrate their changes frequently, \nand each integration can be verified by an \nautomated build (including testing) to detect \nintegration errors as quickly as possible. The \nfundamental goal of CI is to automatically \ncatch problematic changes as early as pos-\nsible. CI helps guarantee the working state of \na software system at various points from build \nto release, thereby improving confidence and \nquality in software products and improving \nproductivity in teams. Specifically, CI auto-\nmates the build and release processes with \ncontinuous build, continuous delivery, contin-\nuous testing and continuous deployment. [6, \nc23, c24]. Continuous delivery is a software engi-\nneering practice that enables frequent releases \nof new systems (including software) to staging \nor various test environments through the use \nof automated tools. Continuous delivery con-\ntinuously assembles the latest code and config-\nuration to create release candidates. Continuous testing is a software testing prac-\ntice that involves testing the software at every \nstage of the software development life cycle. The goal of continuous testing is to evaluate \nthe quality of software at every step of the \ncontinuous delivery process by testing early", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 182", "position": 182, "chunk_type": "semantic", "token_estimate": 227}
{"text": "SOFTWARE MAINTENANCE   7-15: and often. Continuous testing involves var-\nious stakeholders such as developers, main-\ntainers, DevOps, SQA, and operational \nsystems teams. Continuous deployment is an automated pro-\ncess of deploying changes to production by \nverifying intended features and validations to \nreduce risk. As Martin Fowler, in the book \nContinuous Delivery, pointed out, \u201cThe biggest \nrisk to any software effort is that you end up \nbuilding something that isn\u2019t useful. The ear-\nlier and more frequently you get working soft-\nware in front of real users, the quicker you get \nfeedback to find out how valuable it really is.\u201d\n4.5. Visualizing Maintenance\nMaintaining a clear understanding of soft-\nware systems\u2019 evolving structures and depen-\ndencies presents a challenge. Visualization is \na valuable supporter in software maintenance \nmanagement, offering a visual representation \nof the software\u2019s components and helping it \nmake informed decisions. With the increasing \nsize and complexity of software systems, visual \nrepresentations can support software mainte-\nnance by enabling dependency analysis, tracing \na software evolution history, visualizing soft-\nware runtime dynamics, and providing com-\nplementary \ndocumentation. Visualization \nrepresents an active research area that syner-\ngizes computational capabilities with human \npattern detection abilities. It produces visual \nrepresentations designed to enhance the main-\ntenance team\u2019s cognitive performance when \nfaced with complex data analysis. 5. Software Maintenance Tools \n\b\n [1, c6s4][2*, c14] \nThis topic encompasses tools that are par-\nticularly important in software maintenance \nwhere existing software is being modified. Maintenance tools are interrelated with \ndevelopment and operations tools. Together, \nthey are part of the SEE. The following are \nexamples of maintenance tools:\n\u2022\t Configuration management, code ver-\nsioning and code review tools,\n\u2022\t software testing tools,\n\u2022\t Software quality assessment tools (to \nassess technical debt and code quality). \u2022\t Program slicers, which select only the \nparts of a program affected by a change. \u2022\t Static analyzers, which allow gen-\neral viewing and summaries of pro-\ngram content. \u2022\t Dynamic analyzers, which allow the \nmaintainer to trace the execution path of \na program. \u2022\t Data flow analyzers, which allow the \nmaintainer to track all possible data flows \nof a program. \u2022\t Cross-referencers, which generate indexes \nof program components. \u2022\t Dependency analyzers, which help main-\ntainers analyze and understand the inter-\nrelationships among components of \na program. \u2022\t Remote Access tools, enabling main-\ntainers to diagnose and modify user sys-\ntems remotely, crucial for real-time issue \nresolution and seamless modifications \nacross environments.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 183", "position": 183, "chunk_type": "semantic", "token_estimate": 398}
{"text": "7-16   SWEBOK \u00ae GUIDE V4.0: MATRIX OF TOPICS VS. REFERENCE MATERIAL\nISO/IEC/IEEE \n14764 2022 [1] \nGrubb and \nTakang 2003 [2*]\n1. Software Maintenance Fundamentals\n1.1. Definitions and Terminology\ns3.1\nc1s1.2, c2s2.2\n1.2. Nature of Software Maintenance\nc1s1.3\n1.3. Need for Software Maintenance\nc1s1.5\n1.4. Majority of Maintenance Costs\nc4s4.3, c5s5.2\n1.5. Evolution of Software\nc3s3.5\n1.6. Categories of Software Maintenance \ns3.1.8\nc1s1.8, c3s3.3\n2. Key Issues in Software Maintenance\n2.1. Technical Issues\n2.1.1. Limited Understanding\nc6s6.9\n2.1.2. Testing\ns6.2\nc9, c13s13.4.4\n2.1.3. Impact Analysis\ns5.1.6\nc13s13.3\n2.1.4. Maintainability\ns8.8\nc12s12.5.5\n2.2. Management Issues\n2.2.1. Alignment with Organizational Objectives\ns9.1.8\nc2s2.3.1.2, c3s3.4\n2.2.2. Staffing\ns6.4.13.3c\nc2s2.3.1.5, c10s10.4\n2.2.3. Process\ns6\nc5\n2.2.4. Supplier Management\ns6.1.2, s8.3, s8.8.2\n2.2.5. Organizational Aspects of Maintenance\ns9.1.8\nc10\n2.3. Maintenance Costs \n2.3.1. Technical Debt Cost Estimation\ns6.1.7, s8.8.3.6\nc12s12.5\n2.3.2. Maintenance Costs Estimation \ns6.2.2, \ns9.1.4, s9.1.9-10\nc12s12.5.6\n2.4. Software Maintenance Measurement\ns6.1.7\nc12\n3. Software Maintenance Process\n3.1. Software Maintenance Processes \ns5.2\nc5\n3.2. Software Maintenance Activities and Tasks\ns6.1\nc6, c7\n3.2.1. Supporting and Monitoring Activities\ns6.4.13.3d5, s6.1.8\nc3s3.4\n3.2.2. Planning Activities\ns6.1.3, s8.7.2\nc10\n3.2.3. Software Configuration Management\ns6.1.3c, s6.4.13.3d4\nc11s11.3\n3.2.4. Software Quality\ns6.1.6, s8.7.2\nc13s13.4\n4. Software Maintenance Techniques \n4.1. Program Comprehension\nc6,c14s14.5\n4.2. Software Reengineering\nc7\n4.3. Reverse Engineering\nc7, c14s14.5", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 184", "position": 184, "chunk_type": "semantic", "token_estimate": 211}
{"text": "A. April and A. Abran, Software Maintenance: Management: Evaluation and Continuous \nImprovement [3]. This book explores the domain of contin-\nuous software maintenance processes. It \nprovides road maps for improving soft-\nware maintenance processes in organiza-\ntions. It describes software maintenance \npractices organized by maturity levels, \nwhich allow for benchmarking and con-\ntinuous improvement. Goals for each key \npractice area are provided, and the pro-\ncess model presented is fully aligned with \nthe architecture and framework of inter-\nnational standards ISO12207, ISO14764 \nand ISO15504, as well as  models such as \nITIL and CoBIT. IEEE std 2675-2021, IEEE Standard for \nDevOps: Building Reliable and Secure Systems \nIncluding Application Build, Package and \nDeployment [5]. Technical principles and processes to build, \npackage, and deploy systems and applica-\ntions in a reliable and secure way are speci-\nfied. Establishing effective compliance and \ninformation technology (IT) controls is the \nfocus. DevOps principles presented include \nmission first, customer focus, shift-left, con-\ntinuous everything, and systems thinking. How stakeholders, including developers and \noperations staff, can collaborate and commu-\nnicate effectively is described. The process \noutcomes and activities herein are aligned \nwith the process model specified in ISO/\nIEC/IEEE 12207:2017 and ISO/IEC/IEEE \n15288:2015.", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 185", "position": 185, "chunk_type": "semantic", "token_estimate": 195}
{"text": "[1]\t IEEE standard, ISO/IEC/IEEE: 14764 IEEE Std. 14764:2022, Software \nEngineering \u2014 Software Life Cycle \nProcesses \u2014 Maintenance, third ed: \n2022 01, 39p. [2*]\tP. Grubb and A.A. Takang, Software \nMaintenance: Concepts and Practice, 2nd \ned. River Edge, NJ: World Scientific \nPublishing, 2003. [3]\t A. April and A. Abran, Software \nMaintenance Management: Evaluation \nand Continuous Improvement. Wiley-\nIEEE Computer Society Press, 2008. [4]\t C. Seybold and R. Keller, Aligning \nSoftware Maintenance to the Offshore \nReality, 12th European Conference \non Software Maintenance and \nReengineering. April 1-4, 2008, \nAthens, Greece, DOI:10.1109/\nCSMR.2008.4493298. [5]\t IEEE standard, IEEE Std. 2675-\n2021, IEEE Standard for DevOps: \nBuilding Reliable and Secure Systems \nIncluding Application Build, Package and \nDeployment, ed: IEEE. 2021. [6] \t W. Titus, T. Manshreck, and H. \nWright. Software engineering at Google: \nLessons learned from programming over \ntime. O\u2019Reilly Media, 2020. [7]\t A. Abran and H. Nguyenkim, \nMeasurement of the maintenance pro-\ncess from a demand-based perspec-\ntive, Journal of Software Maintenance:", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 185", "position": 185, "chunk_type": "semantic", "token_estimate": 156}
{"text": "Figure 8.1 shows the breakdown of topics for: the SCM KA. 1. Management of the SCM Process  \n\b\n[2*, c6, c7]\nSCM controls the evolution and integrity of \na product by identifying its elements (known \nas CIs); managing and controlling change; \nand verifying, recording and reporting on \nconfiguration information. From the soft-\nware engineer\u2019s perspective, SCM facilitates \ndevelopment and change implementation \nactivities. Successful SCM implementation \nrequires careful planning and management, \nwhich requires a strong understanding of \nthe organizational context for, and the con-\nstraints placed on, the design and imple-\nmentation of the SCM process. The SCM \nplan can be developed once for the organi-\nzation and then adjusted as needed for indi-\nvidual projects. 1.1\t Organizational Context for SCM  \n\b\n[2*, c6, ann. D] [3*, Introduction] \n \n\b\n[4*, c25]\nTo plan an SCM process for a project, it is \nnecessary to understand the organizational \ncontext and the relationships among orga-\nnizational elements. SCM interacts not just \nSoftware Con\ufb01guration \nManagement\nOrganizational\nContext for SCM\nConstraints and\nGuidance for the\nSCM Process\nPlanning for SCM\nIdentifying Items\nto be Controlled\nRequesting, Evaluating\nand Approving\nSoftware Changes\nSoftware\nCon\ufb01guration Status\nInformation\nSoftware\nCon\ufb01guration Status\nReporting\nSoftware Functional\nCon\ufb01guration Audit\nSoftware Physical\nCon\ufb01guration Audit\nIn-process Audits\nof a Software\nBaseline\nSoftware Building\nSoftware Release\nManagement\nImplementing\nSoftware Changes\nDeviations and\nWaivers\nSoftware\nCon\ufb01guration\nControl Board\nSoftware Change\nRequest Process\nSoftware Change\nRequest Forms\nDe\ufb01nition\nCon\ufb01guration \nItem Identi\ufb01ers \nand Attributes\nBaselines \nIdenti\ufb01cation\nBaseline Attributes\nRelationships Scheme\nDe\ufb01nition\nSoftware Libraries\nSoftware\nCon\ufb01guration\nSoftware\nCon\ufb01guration\nItem\nSCM Organization\nand Responsibilities\nSCM Resources \nand Schedules\nTool Selection and\nImplementation\nVendor/\nSubcontractor\nControl\nInterface Control\nSCM Plan\nSurveillance of\nSoftware Con\ufb01guration\nManagement SCM \nMeasures and Measurement\nIn-Process Audits of SCM\nManagement of\nthe SCM Process\nSoftware\nCon\ufb01guration\nIdenti\ufb01cation\nSoftware\nCon\ufb01guration\nChange Control\nSoftware\nCon\ufb01guration\nStatus Accounting\nSoftware\nCon\ufb01guration\nAuditing\nSoftware Release\nManagement\n and Delivery\nSoftware\nCon\ufb01guration\nManagement Tools\nFigure 8.1. Breakdown of Topics for the Software Configuration Management KA.", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 188", "position": 188, "chunk_type": "semantic", "token_estimate": 321}
{"text": "SOFTWARE CONFIGURATION MANAGEMENT   8-3: with the particular project but also with sev-\neral other areas of the organization. The organizational elements responsible \nfor software engineering supporting pro-\ncesses might be structured in various ways. The overall responsibility for SCM often \nrests with a distinct part of the organization \nor with a designated individual. However, \nresponsibility for certain SCM tasks might \nbe assigned to other parts of the organization \n(such as the development division). Software is frequently developed as part \nof a larger system containing hardware and \nfirmware elements. In this case, SCM activ-\nities take place in parallel with hardware and \nfirmware CM activities and must be con-\nsistent with system-level CM. Note that \nfirmware contains hardware and software; \ntherefore, both hardware and software CM \nconcepts apply. SCM might interface with an organiza-\ntion\u2019s QA activity on issues such as records \nmanagement and nonconforming items. Regarding the former, project records subject \nto provisions of the organization\u2019s QA pro-\ngram might also be under SCM control. The \nQA team is usually responsible for managing \nnonconforming items. However, SCM might \nassist with tracking and reporting on software \nconfiguration items (SCIs) in this category. Perhaps the closest relationship is with \nthe software development and maintenance \norganizations. It is within this context that \nmany of the software configuration control \ntasks are conducted. Frequently, the same \ntools support development, maintenance, and \nSCM purposes. 1.2\t Constraints and Guidance for the  \nSCM Process  \n\b\n[2*, c6, ann. D, ann. E] [3*, \n \n\b\nc2, c5] [5, c19s2.2] \nConstraints affecting, and guidance for, \nthe SCM process come from many sources. Policies and procedures set forth at corporate \nor other organizational levels might influence \nor prescribe the design and implementation of \nthe SCM process for a project. In addition, \nthe contract between the acquirer and the \nsupplier might contain provisions affecting \nthe SCM process (e.g., certain configura-\ntion audits might be required, or the contract \nmight specify that certain items be placed \nunder CM). When the software to be devel-\noped could affect public safety, external regu-\nlatory bodies may impose constraints. Finally, \nthe SLCP chosen for a software project and \nthe level of formalism selected for imple-\nmentation will also affect SLCP design and \nimplementation. Software engineers can also find guid-\nance for designing and implementing an \nSCM process in \u201cbest practice,\u201d as reflected \nin the software engineering standards issued \nby the various standards organizations.", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 189", "position": 189, "chunk_type": "semantic", "token_estimate": 396}
{"text": "SOFTWARE CONFIGURATION MANAGEMENT   8-3: Finally, \nthe SLCP chosen for a software project and \nthe level of formalism selected for imple-\nmentation will also affect SLCP design and \nimplementation. Software engineers can also find guid-\nance for designing and implementing an \nSCM process in \u201cbest practice,\u201d as reflected \nin the software engineering standards issued \nby the various standards organizations. (See \nAppendix B for more information about these \nstandards.) 1.3\t Planning for SCM  \n\b\n[2*, c6, ann. D, ann. E] [3*, c23] \n \n\b\n[4*, c25]\nSCM process planning for a project should \nbe consistent with the organizational context, \napplicable constraints, commonly accepted \nguidance and the nature of the project (e.g., \nsize, safety criticality and security). The major \nactivities covered in the plan are software con-\nfiguration identification, software configura-\ntion control, SCSA, software configuration \nauditing, and software release management \nand delivery. In addition, issues such as orga-\nnization and responsibilities, resources and \nschedules, tool selection and implementa-\ntion, vendor and subcontractor control, and \ninterface control are typically considered. The \nplanning activity\u2019s results are recorded in an \nSCM plan (SCMP), which is subject to SQA \nreview and audit. Branching and merging strategies should \nbe carefully planned and communicated \nbecause they affect many SCM activities. SCM defines a branch as a set of evolving \nsource file versions [1]. Merging consists of \ncombining different changes to the same file \n[1]. This typically occurs when more than \none person changes a CI. There are many", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 189", "position": 189, "chunk_type": "semantic", "token_estimate": 239}
{"text": "8-4   SWEBOK \u00ae GUIDE V4.0: \u2022\t Ownership: Who is responsible for intro-\nducing new tools? \u2022\t Future: What is the plan for the tools\u2019 use \nin the future? \u2022\t Change: How adaptable are the tools? \u2022\t Branching and merging: Are the tools\u2019 \ncapabilities compatible with planned \nbranching and merging strategies? \u2022\t Integration: Do the various SCM tools \nintegrate among themselves? Do they \nintegrate with other tools in use in the \norganization? \u2022\t Migration: Can the repository maintained \nby the version control tool be ported to \nanother version control tool while main-\ntaining the complete history of the CIs \nit contains? SCM requires a set of tools instead of \na single tool. Such tool sets are sometimes \ncalled workbenches. As part of the tool selec-\ntion planning effort, the team must determine \nwhether the SCM workbench will be open \n(tools from different suppliers will be used in \ndifferent SCM process activities) or integrated \n(elements of the workbench are designed to \nwork together). Organization size and the type of projects \ninvolved may also affect tool selection. (See \nSCM Tools, section 7 of this document)", "domains": ["Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 190", "position": 190, "chunk_type": "semantic", "token_estimate": 182}
{"text": "SOFTWARE CONFIGURATION MANAGEMENT   8-5: 1.3.4\t Vendor/Subcontractor Control  \n\b\n[2*, c13] [3*, c13s9-c14s2] \nA software project might acquire or use pur-\nchased software products, such as compilers or \nother tools. SCM planning considers whether \nand how these items will be managed with \nconfiguration control (e.g., integrated into the \nproject libraries) and how changes or updates \nwill be evaluated and managed. Similar considerations apply to subcon-\ntracted software. When a project uses subcon-\ntracted software, both the SCM requirements \nto be imposed on the subcontractor\u2019s SCM \nprocess and the means for monitoring compli-\nance need to be established. The latter includes \ndetermining what SCM information must be \navailable for effective compliance monitoring. 1.3.5\t Interface Control  \n\b\n[2*, c12] [3*, c23s4]\nWhen a software item interfaces with another \nsoftware or with a hardware item, a change \nto either item can affect the other. Planning \nfor the SCM process considers how the inter-\nfacing items will be identified and how changes \nto the items will be managed and communi-\ncated. The SCM role may be part of a larger, \nsystem-level process for interface specification \nand control involving interface specifications, \ninterface control plans and interface control \ndocuments. In this case, SCM planning for \ninterface control takes place within the con-\ntext of the system-level process. 1.4\t SCM Plan \n\b\n[2*, ann. D] [3*, c23]\nThe results of SCM planning for a given \nproject are recorded in an SCMP, a \u201cliving \ndocument\u201d that serves as a reference for the \nSCM process. The SCMP is maintained \n(updated and approved) as necessary during \nthe software life cycle. For teams to implement \nan SCMP, they\u2019ll typically need to develop a \nnumber of more detailed, subordinate pro-\ncedures to define how specific requirements \nwill be met  during day-to-day activities (e.g., \nwhich branching strategies will be used, how \nfrequently builds will occur, how often auto-\nmated tests of all kinds will be run). Guidance on creating and maintaining an \nSCMP, based on the information produced \nby the planning activity, is available from a \nnumber of sources, such as [2*]. This refer-\nence provides requirements for information to \nbe contained in an SCMP. An SCMP should \ninclude the following sections: \n\u2022\t Introduction (purpose, scope, terms used)\n\u2022\t SCM Management (organization, respon-\nsibilities, authorities, applicable policies, \ndirectives, procedures)\n\u2022\t SCM Activities (configuration identifi-\ncation, configuration control, etc.)", "domains": ["Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 191", "position": 191, "chunk_type": "semantic", "token_estimate": 384}
{"text": "8-6   SWEBOK \u00ae GUIDE V4.0: 1.5.1\t SCM Measures and Measurement  \n\b\n[3*, c9s2, c25s2-s3]\nSCM measures can be designed to provide \nspecific information on the evolving product, \nbut they can also provide insight into how \nwell the SCM process functions and iden-\ntify opportunities for process improvement. SCM process measurements enable teams to \nmonitor the effectiveness of SCM activities \non an ongoing basis. These measurements \nare useful in characterizing the current \nstate of the process and providing a basis for \ncomparison over time. Measurement anal-\nysis may produce insights that lead to pro-\ncess changes and corresponding updates \nto the SCMP. Software libraries and the various SCM \ntool capabilities enable teams to extract useful \ninformation about SCM process characteris-\ntics (as well as project and management infor-\nmation). For example, information about the \ntime required to accomplish various types of \nchanges would be useful in evaluating criteria \nfor determining what levels of authority are \noptimal for authorizing certain changes and \nin estimating the resources needed to make \nfuture changes. Care must be taken to keep the surveillance \nfocused on the insights that can be gained from \nthe measurements, not on the measurements \nthemselves. Software process and product \nmeasurement is further discussed in the \nSoftware Engineering Process KA. Software \nmeasurement programs are described in the \nSoftware Engineering Management KA. 1.5.2\t In-Process Audits of SCM\n[3*, c1s1]\nAudits can be carried out during the software \nengineering process to investigate the status \nof specific configuration elements or to assess \nthe SCM process implementation. In-process \nSCM auditing provides a more formal mech-\nanism for monitoring selected aspects of the \nprocess and may be coordinated with the \nSQA function. (See Software Configuration \nAuditing.) 2. Software Configuration Identification \n\b\n[2*, c8]\nSoftware configuration identification identi-\nfies items to be controlled, establishes iden-\ntification schemes for the items and their \nversions, and establishes the tools and tech-\nniques to be used in acquiring and managing \ncontrolled items. These activities provide the \nbasis for other SCM activities. 2.1\t Identifying Items to Be Controlled  \n\b\n[2*, c8s2.2]\nA first step in controlling change is identi-\nfying the software items to be controlled. This \ninvolves understanding the software configu-\nration within the context of the system con-\nfiguration, selecting SCIs and developing a \nstrategy for labeling software items. 2.1.1. Software Configuration\nSoftware configuration is the functional and \nphysical characteristics of hardware or soft-\nware as set forth in technical documentation \nor achieved in a product.", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 192", "position": 192, "chunk_type": "semantic", "token_estimate": 405}
{"text": "8-6   SWEBOK \u00ae GUIDE V4.0: 2.1.1. Software Configuration\nSoftware configuration is the functional and \nphysical characteristics of hardware or soft-\nware as set forth in technical documentation \nor achieved in a product. It can be viewed as \npart of an overall system configuration. 2.1.2\t\nSoftware Configuration Item  \n\b\n[2*, c8s2.1] [3*, c9]\nA CI is an item or aggregation of hardware, \nsoftware or both, designed to be managed as \na single entity. An SCI is a software entity \nthat has been established as a CI [1]. The \nSCM controls various items in addition to \nthe code itself. Software items with potential \nto become SCIs include plans, specifications \nand design documentation, testing materials, \nsoftware tools, source and executable code, \ncode libraries, data and data dictionaries, and \ndocumentation for installation, maintenance, \noperations and software use. Selecting SCIs is an important process in \nwhich a balance must be achieved between \nproviding adequate visibility for project con-\ntrol purposes and providing a manageable \nnumber of controlled items.", "domains": ["Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 192", "position": 192, "chunk_type": "semantic", "token_estimate": 163}
{"text": "SOFTWARE CONFIGURATION MANAGEMENT   8-7: 2.2\t Configuration Item Identifiers and \nAttributes \n\b\n[2*, c8s2.3, c8s2.4] [3*, c9]\nStatus accounting activity (explained later) \ngathers information about CIs while they \nare developed. The CIs\u2019 scheme is defined \nin order to establish what information must \nbe gathered and tracked for each CI. Unique \nidentifiers and versions are tracked. An example scheme may include the \nfollowing: \nCI name\nCI unique identifier\nCI description\nCI date(s) \nCI type\nCI owner\nThe CI\u2019s unique Identifier can use sig-\nnificant or nonsignificant codification. An \nexample of significant codification could be \nXX-YY, where XX is the iteration abbrevia-\ntion (in case of using an iterative development \nmethod) and YY is the CI abbreviation. 2.3\t Baseline Identification \n\b\n[2*, c8s2.5.4, c8s2.5.5, c8s2.5.6]\nA software baseline is a formally approved \nversion of a CI (regardless of media type) that \nis formally designated and fixed at a specific \ntime during the CI\u2019s life cycle. The term also \nrefers to a particular version of an agreed-\nupon SCI. The baseline can be changed only \nthrough formal change control procedures. A baseline, with all approved changes to the \nbaseline, represents the current approved con-\nfiguration. A baseline consists of one or more \nrelated CIs. 2.4\t Baseline Attributes \n\b\n[2*, c8s2.5.4]\nBaseline attributes are used in the status \naccounting activity and specify information \nabout the baseline established. Example baseline attributes may include \nthe following:\nBaseline name\nBaseline unique identifier\nBaseline description\nBaseline date of creation\nBaseline CIs\n2.5\t Relationships Scheme Definition \n\b\n[3*, c7s4]\nRelationships \nprovide \nthe \nconnections \nrequired to create and sustain structure. The \nability to communicate intent and manage the \nresults are significantly enhanced when effec-\ntive relationships (structuring) are in place \n(e.g., model-based experience (MBX) plat-\nforms). Relationship information exchange \nand interoperability are needed to support \nthe applicable relationship types. The status \naccounting activity is responsible for gathering \ninformation about relationships among CIs. Common types of relationships can be \ndescribed according to the following schemes: \nDependencies: CI-1 and CI-2 depend mutu-\nally on each other. Example: CI-1 depends on C1-2, and vice \nversa, for instance a class model depends on a \nsequence diagram, because any change on any \nof both types of models, affect the other.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 193", "position": 193, "chunk_type": "semantic", "token_estimate": 364}
{"text": "SOFTWARE CONFIGURATION MANAGEMENT   8-7: Common types of relationships can be \ndescribed according to the following schemes: \nDependencies: CI-1 and CI-2 depend mutu-\nally on each other. Example: CI-1 depends on C1-2, and vice \nversa, for instance a class model depends on a \nsequence diagram, because any change on any \nof both types of models, affect the other. CI-1 Code\nCI-2 Code\nDate\nDerivation: One CI derives from another, \ntypically in a sequential relationship, not \nbecause of a lack of resources to handle both \nCIs but because of a constraint that requires \nthat, for instance, CI-1 is completed before \nCI-2 is developed. Example: CI-1 derives from CI-2. CI-1 Code\nCI-2 Code\nDate\nSuccession: Software items evolve as a soft-\nware project proceeds. A software item ver-\nsion is an identified instance of an item. It \ncan be thought of as a state of an evolving \nitem. This is what the succession relationship", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 193", "position": 193, "chunk_type": "semantic", "token_estimate": 151}
{"text": "8-8   SWEBOK \u00ae GUIDE V4.0: reflects, and it is reflexive in that each CI has \nthis relationship with itself. The first succes-\nsion comes up the first time a CI is created. Each time it is changed, a new succession \ncomes up, and tracking these successions is \nthe way to track CI versions. Example: CI versions along a timeline. CI Code\nCurrent Version\nNext Version\nDate\nVariants are program versions resulting \nfrom engineered alternative options. This \ntype of relationship is not as common as the \ntype of relationships described above because \nit is more expensive to maintain. The decision on what relationships to track \nthroughout the project is important because \ntracking some relationships can require extra \nwork. On the other hand, tracking such rela-\ntionships can facilitate decisions on change \nrequests (CRs) for a CI. Relationships between CIs can be tracked \nin a Software Bill of Materials (SBOM). An SBOM is a formal record containing \nthe details and supply chain relationships \nof the CIs used in building software. CIs \nin an SBOM are frequently referred to as \ncomponents. Components can be source code, \nlibraries, modules and other artifacts; they \ncan be open source or proprietary, free or \npaid; and the data can be widely available or \naccess-restricted. A simple example of the relationships \namong three CIs in an SBOM, called CI-1, \nCI-2 and CI-3, is illustrated in Figure 8.2. 2.6\t Software Libraries  \n\b\n[2*, c8s2.5] [3*, c1s3]\nA software library is a controlled collection of \nsource code, scripts, object code, documen-\ntation and related artifacts. Requirements \nand test cases are stored in a repository and \nshould be linked with the code baselines \ndeveloped. Source code is stored in a version \ncontrol system, which provides traceability \nand security for the baselines developed. Multiple development streams are supported \nin version control systems linked to the binary \nobjects (e.g., object code) derived during the \nbuild process. These binary objects are typi-\ncally stored in a repository that should con-\ntain cryptographic hashes used to perform the \nphysical configuration audit (PCA). Successions Records: According to the scheme de\ufb01ned for succession relationships, the next table gives the date when each CI was \ncreated (three \ufb01rst rows), and the fourth row indicates a change made on the CI-1 on 10/05/2021, where the current version was 1 \nand created new version is 2.", "domains": ["Software Quality Attributes", "Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 194", "position": 194, "chunk_type": "semantic", "token_estimate": 386}
{"text": "8-8   SWEBOK \u00ae GUIDE V4.0: These binary objects are typi-\ncally stored in a repository that should con-\ntain cryptographic hashes used to perform the \nphysical configuration audit (PCA). Successions Records: According to the scheme de\ufb01ned for succession relationships, the next table gives the date when each CI was \ncreated (three \ufb01rst rows), and the fourth row indicates a change made on the CI-1 on 10/05/2021, where the current version was 1 \nand created new version is 2. Derivation Record: According to the scheme de\ufb01ned for derivation, CI-3 derives from CI-1 and \nthis relationship came up the day CI-3 was created. Dependency Record: According to the scheme de\ufb01ned for dependencies CI-1 and CI-2 have a \ndependency relationship created the day CI-2 was developed. CI-1 \n\u2013 \n1 \n10/01/2021\nCI-2 \n\u2013 \n1 \n10/04/2021\nCI-3 \n\u2013 \n1 \n10/03/2021\nCI-1 \n1 \n2 \n10/05/2021\nCI-1 \nCI-2 \n10/04/2021\nCI-3 \nCI-1 \n10/03/2021\nCI-1\nCI-2\nCI-3\nsuccession\nsuccession\nsuccession\ndependency\nderivation\nFigure 8.2. Example of reported relationships", "domains": ["Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 194", "position": 194, "chunk_type": "semantic", "token_estimate": 159}
{"text": "SOFTWARE CONFIGURATION MANAGEMENT   8-9: The definitive media library  contains the \nrelease baseline(s) of the artifacts that can \nbe deployed to the test, stage and produc-\ntion systems. The release management process depends \non these software libraries to manage the arti-\nfacts deployed. In terms of access control and \nthe backup facilities, security is a key aspect of \nlibrary management. 3. Software Configuration Change Control  \n\b\n[2*, c9] [3*,c8] [4*, c25s3] [5, c11.s3.3]\nSoftware configuration change control is con-\ncerned with changes required to CIs during \nthe software life cycle. It covers the pro-\ncess for determining what changes to make, \nthe authority for approving certain changes, \nsupport for implementing those changes, \nand the concept of formal deviations from \nproject requirements as well as waivers of \nthem. Information derived from these activ-\nities is useful in measuring change traffic and \nbreakage, as well as aspects of rework. Given that change to CIs can follow spe-\ncific rules depending on the industrial sector, \narea, company, etc., it is very important to \nidentify those rules in the context of the \nsoftware project for which the SCM pro-\ncess is being developed and to adhere strictly \nto those rules. The rest of this section can \nbe useful when no specific rules regarding \nchange control exist in the company or the \nindustrial sector where the software project \nunder development is allocated. 3.1\t Requesting, Evaluating, and Approving \nSoftware Changes  \n\b\n[2*, c9s2.4] [3*, c11s1] [4*, c25s3]\nThe first step in managing changes to con-\ntrolled items is determining what changes to \nmake. The software change request (SCR) \nprocess (Figure 8.3) provides formal pro-\ncedures for submitting and recording CRs; \nevaluating the potential cost and impact of a \nproposed change; and accepting, modifying, \ndeferring or rejecting the proposed change. A CR is a request to expand or reduce the \nproject scope; modify policies, processes, \nplans or procedures; modify costs or budgets; \nmodify implemented code; or revise schedules \n[1]. Requests for changes to SCIs may be orig-\ninated by anyone at any point in the software \nlife cycle and may include a suggested solution \nand requested priority. One source of a CR is \nthe initiation of corrective action in response \nto problem reports. Regardless of the source, \nthe type of change (e.g., defect or enhance-\nment) is usually recorded on the SCR.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 195", "position": 195, "chunk_type": "semantic", "token_estimate": 384}
{"text": "8-10   SWEBOK \u00ae GUIDE V4.0: Recording of the SCR enables the software \nengineers to track defects and collect change \nactivity measurements by change type. Once \nan SCR is received, a technical evaluation \n(also known as an impact analysis) is per-\nformed to determine the extent of the modifi-\ncations necessary should the CR be accepted. A good understanding of the relationships \namong software (and, possibly, hardware) \nitems is important for this task. The infor-\nmation recorded about the CIs\u2019 relationships \ncould be useful for making decisions affecting \nany CI, given the potential impact on other \nCIs. Finally, an established authority \u2014 com-\nmensurate with the affected baseline, the SCI \ninvolved and the nature of the change \u2014 will \nevaluate the CR\u2019s technical and managerial \naspects and accept, modify, reject or defer the \nproposed change. 3.1.1\t\nSoftware Configuration Control Board  \n\b\n[2*, c9s2.2] [3*, c11s1] [4*, c25s3]\nThe authority for accepting or rejecting pro-\nposed changes rests with an entity known as a \nconfiguration control board (CCB). In smaller \nprojects, this authority may reside with the \nleader or an assigned individual rather than \na multi-person board. There can be multiple \nlevels of change authority depending on a \nvariety of criteria \u2014 such as the criticality of \nthe item involved, the nature of the change \n(e.g., impact on budget and schedule), or \nwhere the project is in the life cycle. The com-\nposition of the CCBs used for a system varies \ndepending on these criteria (but an SCM rep-\nresentative is always present). All stakeholders \nappropriate to the CCB level are represented. When a CCB\u2019s scope of authority is limited \nto software, the board is known as a Software \nConfiguration \nControl \nBoard \n(SCCB). The CCB\u2019s activities are subject to software \nquality audits or reviews. 3.1.2\t Software Change Request Process  \n\b\n[3*, c1s4, c8s4] [4*, c25s3]\nAn effective SCR process requires the use \nof supporting tools and procedures for \noriginating CRs, enforcing the change process \nflow, capturing CCB decisions and reporting \nchange process information. Linking this tool \ncapability with the problem-reporting system \ncan facilitate the problem resolution tracking \nand how quickly solutions are developed.", "domains": ["Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 196", "position": 196, "chunk_type": "semantic", "token_estimate": 351}
{"text": "8-10   SWEBOK \u00ae GUIDE V4.0: 3.1.2\t Software Change Request Process  \n\b\n[3*, c1s4, c8s4] [4*, c25s3]\nAn effective SCR process requires the use \nof supporting tools and procedures for \noriginating CRs, enforcing the change process \nflow, capturing CCB decisions and reporting \nchange process information. Linking this tool \ncapability with the problem-reporting system \ncan facilitate the problem resolution tracking \nand how quickly solutions are developed. 3.1.3\t Software Change Request Forms \nDefinition \n\b\n[2*, c9s2.3, c9s2.5] \n \n\b\n[3*, c8s4] [4*, c25s3]\nA CR application must include the following:\n\u2022\t A CR form, which must describe the \nrequest and give the rationale for it\n\u2022\t A change certification form (necessary if \nthe CR is granted)\nThese forms can be managed through the \ncorresponding supporting tool, but humans \nare responsible for designing the forms. 3.2\t Implementing Software Changes  \n\b\n[4*, c25s3]\nApproved SCRs are implemented using the \ndefined software procedures per the applicable \nschedule requirements. Because a number of \napproved SCRs might be implemented simul-\ntaneously, a means for tracking which SCRs \nare incorporated into particular software ver-\nsions and baselines must be provided. At the \nend of the change process, completed changes \nmay undergo configuration audits and soft-\nware quality verification, which includes \nensuring that only approved changes have \nbeen made. The SCR process typically docu-\nments the change\u2019s SCM and other approval \ninformation. Changes may be supported by source code \nversion control tools. These tools allow a team \nof software engineers, or a single software \nengineer, to track and document changes to \nthe source code. These tools provide a single \nrepository for storing the source code, so they \ncan prevent more than one software engineer \nfrom editing the same module at the same \ntime, and they record all changes made to the", "domains": ["Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 196", "position": 196, "chunk_type": "semantic", "token_estimate": 290}
{"text": "SOFTWARE CONFIGURATION MANAGEMENT   8-11: source code. Software engineers check mod-\nules out of the repository, make changes, doc-\nument the changes, and then save the edited \nmodules in the repository. If needed, changes \ncan also be discarded, restoring a previous \nbaseline. More powerful tools can support \nparallel development and geographically dis-\ntributed environments. These tools may mani-\nfest as separate, specialized applications under \nan independent SCM group\u2019s control. They \nmay also appear as an integrated part of the \nsoftware engineering environment. Finally, \nthey may be as elementary as a rudimentary \nchange control system that is provided with \nan operating system. 3.3\t Deviations and Waivers  \n\b\n[1, c3]\nThe constraints imposed on a software engi-\nneering effort or the specifications produced \nduring the development activities might con-\ntain provisions that those working on the \nproject find cannot be satisfied at the desig-\nnated point in the life cycle. A deviation is \na written authorization granted before the \nmanufacture of an item to depart from a par-\nticular performance or design requirement for \na specific number of units or a specific period \nof time. A waiver is a written authorization \nto allow a CI or other designated item in \nresponse to an issue found during production \nor after the project is submitted for inspection \nto depart from specified requirements when \nthe CI or project is nevertheless considered \nsuitable for use, either as it is or after rework \nvia an approved method. In these cases, a \nformal process is used to gain approval for \ndeviations from or waivers of the provisions. 4. Software Configuration Status \nAccounting \n\b\n[2*, c10] [3*, c9] [5, c11s3.4]\nSCSA is an activity of CM consisting of \nrecording and reporting information needed to \nmanage a configuration effectively regarding \nCIs, baselines and relationships among CIs. This activity must be done by following the \nlogical schemes defined in the activity config-\nuration identification for CIs, baselines and \nrelationships for gathering information. 4.1\t Software Configuration Status Information \n\b\n[2*, c10s2.1]\nThe SCSA activity designs and operates a \nsystem for capturing, verifying, validating \nand reporting necessary information as the \nlife cycle proceeds. As in any information \nsystem, the configuration status information \nto be managed for the evolving configurations \nmust be identified, collected and maintained. In addition, the information itself should be \nsecured where relevant.", "domains": ["Software Quality Attributes", "Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 197", "position": 197, "chunk_type": "semantic", "token_estimate": 381}
{"text": "SOFTWARE CONFIGURATION MANAGEMENT   8-11: As in any information \nsystem, the configuration status information \nto be managed for the evolving configurations \nmust be identified, collected and maintained. In addition, the information itself should be \nsecured where relevant. SCSA information \nand measurements are needed to support the \nSCM process and to meet the configuration \nstatus reporting needs of management, soft-\nware engineering, security, performance and \nother related activities. The types of information available include \nbut are not limited to the following:\n\u2022\t Ongoing and approved configuration \nidentification\n\u2022\t Current implementation status of changes\n\u2022\t Impacted CIs and related systems\n\u2022\t Deviations and waivers\n\u2022\t Verification \nand \nvalidation \n(V&V) \nactivities\nAutomated tools support SCSA as tasks \nare performed, and reporting is available in a \nuser-friendly format. 4.2\t Software Configuration Status Reporting \n\b\n[2*, c10s2.4] [3*, c1s5, c9s1]\nReported information can be used by var-\nious organizational and project elements \u2014 \nincluding the development team, operations, \nsecurity, the maintenance team, project man-\nagement, software quality activities teams \nand others. Reporting can take many forms: \nautomated reports, ad hoc queries to answer \nspecific questions, and regular production of \npredesigned reports, including those devel-\noped to meet security, legal or regulatory", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 197", "position": 197, "chunk_type": "semantic", "token_estimate": 195}
{"text": "8-12   SWEBOK \u00ae GUIDE V4.0: requirements. In other words, information \nproduced by the SCSA activity throughout \nthe life cycle can be used to satisfy QA and \nsecurity and to provide evidence of compli-\nance with regulations, governance require-\nments, etc. In addition to reporting the configura-\ntion\u2019s current status, the information obtained \nby the SCSA can serve as a basis for various \nmeasurements. Modern SCM includes a wider scope of \ninformation, including but not limited to the \nfollowing: \n\u2022\t Indicators of integrity (e.g., MAC \n(Message Authentication Code) SHA1 \n(Secure \nHash \nAlgorithm),", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 198", "position": 198, "chunk_type": "semantic", "token_estimate": 91}
{"text": "(Message Digest)): \u2022\t Indicators of security status (e.g., gover-\nnance risk and compliance) \n\u2022\t Evidence of V&V activities (e.g., require-\nments completion)\n\u2022\t Baseline status\n\u2022\t The number of CRs per SCI \n\u2022\t The \naverage \ntime \nneeded \nto \nimplement a CR \n5. Software Configuration Auditing \n\b\n[2*, c11] [5, c11s3.5]\nA software audit is an independent examina-\ntion of a work product or set of work prod-\nucts to assess technical, security, legal and \nregulatory compliance with specifications, \nstandards, contractual agreements or other \ncriteria [1]. Audits are conducted according \nto a well-defined process comprising various \nauditor roles and responsibilities. Because \nof this complexity, each audit must be care-\nfully planned. An audit can require a number \nof individuals to perform various tasks over a \nfairly short time. Tools to support the plan-\nning and conduct of an audit can greatly facil-\nitate the process. Software configuration auditing deter-\nmines the extent to which an item satis-\nfies requirements for functional and physical \ncharacteristics. Informal audits can be con-\nducted at key points in the life cycle. Two \ntypes of formal audits might be required by \nthe governing contract (e.g., a contract cov-\nering critical software): the functional config-\nuration audit (FCA) and the PCA. Successful \ncompletion of these audits can be a prerequi-\nsite for establishing the product baseline. 5.1\t Software Functional Configuration Audit  \n\b\n[2*, c11s2.1]\nThe software FCA ensures that the audited \nsoftware item is consistent with its governing \nspecifications. The software V&V activities\u2019 \noutput (see Verification and Validation in \nthe Software Quality KA) is a key input to \nthis audit. 5.2\t Software Physical Configuration Audit  \n\b\n[2*, c11s2.2]\nThe software PCA ensures that the design \nand reference documentation are consistent \nwith the as-built software product. 5.3\t In-Process Audits of a Software Baseline \n\b\n[2*, c11s2.3]\nAudits can be carried out during the develop-\nment process to investigate the status of specific \nconfiguration elements. In-process audits can \nbe applied to all baseline items to ensure that \nperformance is consistent with specifications \nor that evolving documentation continues to be \nconsistent with the developing baseline item. This task applies to every single CI to be \napproved as part of a baseline. The audit \nconsists of reviewing the CI to determine \nwhether it satisfies requirements.", "domains": ["Software Quality Attributes", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 198", "position": 198, "chunk_type": "semantic", "token_estimate": 374}
{"text": "SOFTWARE CONFIGURATION MANAGEMENT   8-13: 6. Software Release Management and \nDelivery \n\b\n[2*, c14] [3*, c8s2] [4*, c25s4]\nIn this context, release refers to distrib-\nuting software and related artifacts outside \nthe development activity, including internal \nreleases and distribution to customers. When \ndifferent versions of a software item are avail-\nable for delivery (such as versions for different \nplatforms or versions with varying capabili-\nties), re-creating specific versions and pack-\naging the correct materials for version delivery \nare frequently necessary. The software library \nis a key element in accomplishing release and \ndelivery tasks. 6.1\t Software Building\b\n[4*, c25s2]\nSoftware building constructs the correct ver-\nsions of SCIs, using the appropriate config-\nuration data, into a software package for \ndelivery to a customer or other recipient such \nas a team performing testing. For systems \nwith hardware or firmware, the executable \nprogram is delivered to the system-building \nactivity. Build instructions help ensure that \nthe proper build steps are taken in the cor-\nrect sequence. In addition to building soft-\nware for new releases, SCM must usually \nbe able to reproduce previous releases for \nrecovery, testing, maintenance or additional \nrelease purposes. Software is built using supporting tools, \nsuch as compilers. For example, if it is nec-\nessary to rebuild an exact copy of a previously \nbuilt SCI, supporting tools and associated \nbuild instructions must be under SCM con-\ntrol to ensure the availability of the correct \nversions of the tools. Tool capability is useful for selecting the \ncorrect versions of software items for a target \nenvironment and automating the process \nof building the software from the selected \nversion and configuration data. This tool \ncapability is necessary for projects with \nparallel or distributed development envi-\nronments. Most software engineering envi-\nronments provide this capability. However, \nthese tools vary in complexity; some require \nthe software engineer to learn a special-\nized scripting language, while others use a \nmore graphics-oriented approach that hides \nmuch of the complexity of an \u201cintelligent\u201d \nbuild facility. The build process and products are often \nsubject to software quality verification. Outputs of the build process might be needed \nfor future reference. They may become records \nof quality, security, or compliance with orga-\nnizational or regulatory requirements. The \nSBOM listing the artifacts included in the \nbuild is an important CM output. In \ncontinuous \nintegration, \nsoftware \nbuilding is performed automatically when \nchanges to CIs are committed to a source \ncontrol repository.", "domains": ["Software Quality Attributes", "Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 199", "position": 199, "chunk_type": "semantic", "token_estimate": 396}
{"text": "SOFTWARE CONFIGURATION MANAGEMENT   8-13: The \nSBOM listing the artifacts included in the \nbuild is an important CM output. In \ncontinuous \nintegration, \nsoftware \nbuilding is performed automatically when \nchanges to CIs are committed to a source \ncontrol repository. Tools running on a local \nor cloud-based server monitor the project\u2019s \nsource control system and initiate a pipeline of \nsteps to be undertaken every time a change is \ncommitted to a particular branch or area of the \nsource code repository. The tool is configured \nto retrieve a fresh copy of the complete source \ncode for the project and execute the necessary \ncommands to compile and link the code. This \nconfiguration is often combined with steps to \nvalidate coding standards via automated static \nanalysis, execute unit tests and determine \ncode coverage metrics, or extract documenta-\ntion from the source code. The resulting arti-\nfacts are then deployed through the Release \nManagement process. 6.2\t Software Release Management \n\b\n[4*, c25s2]\nSoftware release management encompasses \nthe identification, packaging and delivery of \nthe elements of a product (e.g., an execut-\nable program, documentation, release notes, \nor configuration data). Given that product \nchanges can occur continually, one concern \nfor release management is determining when \nto issue a release. The severity of the prob-\nlems addressed by the release and measure-\nments of the fault densities of prior releases \naffect this decision. The packaging task iden-\ntifies which product items are to be delivered", "domains": ["Design Patterns", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 199", "position": 199, "chunk_type": "semantic", "token_estimate": 235}
{"text": "8-14   SWEBOK \u00ae GUIDE V4.0: and then selects the correct variants of those \nitems, given the product\u2019s intended applica-\ntion. The information documenting the phys-\nical contents of a release is known as a version \ndescription document (VDD). The release \nnotes describe new capabilities, known prob-\nlems and platform requirements necessary for \nproper product operation. The package to be \nreleased also contains installation or upgrade \ninstructions. The latter can be complicated \nbecause some users might have versions that \nare several releases old. In some cases, release \nmanagement might be necessary to track the \nproduct\u2019s distribution to various customers \nor target systems (e.g., when the supplier \nwas required to notify a customer of newly \nreported problems). Finally, a mechanism to \nhelp ensure the released item\u2019s integrity can \nbe implemented (e.g., by including a digital \nsignature). A tool capability is needed for supporting \nthese release management functions. For \nexample, a connection with the tool capa-\nbility supporting the CR process is useful to \nmap release contents to the SCRs that have \nbeen received. This tool capability might also \nmaintain information on various target plat-\nforms and customer environments. In continuous delivery, a pipeline is estab-\nlished to build software continuously, as \ndescribed in the previous section. The resulting \nartifacts from the build process include exe-\ncutable code and libraries, which can then be \ncombined into an installation package and \ndeployed into an environment for verification \nor production use. 7. Software Configuration Management \nTools \n\b\n[3*, c26s1]\nMany tools can assist with CM at many levels. The scope of these tools varies depending on \nwho uses the tools. CM is most effective when \nintegrated with other processes and by exten-\nsion with other existing tools. The selection of \nCM tool can be made depending on the scope \nthat the tool is going to have. Overview of tools:\n\u2022\t The configuration management system \n(CMS) provides enabling technology and \nlogic to facilitate CM activities. \u2022\t Version control stores the source code, \nconfiguration files and related artifacts. \u2022\t Build automation (pipeline) is established \nto enable continuous delivery. \u2022\t A repository stores binaries that are cre-\nated during the build process to extract \nthe latest build artifacts and redeploy \nthem as required \u2014 used in the release \nverification process. \u2022\t Configuration \nmanagement \ndatabase \n(CMDB) or similar persistence store. \u2022\t Change control tools. \u2022\t Release/deployment tools. The CMS supports the unique identifica-\ntion of artifacts.", "domains": ["Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 200", "position": 200, "chunk_type": "semantic", "token_estimate": 397}
{"text": "8-14   SWEBOK \u00ae GUIDE V4.0: \u2022\t Release/deployment tools. The CMS supports the unique identifica-\ntion of artifacts. Both individual artifacts and \ncollections are specified in CM systems and \nrelated repositories. Structuring creates a log-\nical relationship between artifacts. Validation \nand release establish the artifacts\u2019 integ-\nrity, as part of the release management pro-\ncess. Baselines are identified where stability is \nintended. For example, interface management \nis identified and controlled, making it part of \nthe baseline process. Change management, \nincluding variants and nonconformances, \nis reviewed and approved, and its imple-\nmentation is planned. Verification and audit \nactivities are performed as part of the identi-\nfication, change and release management pro-\ncess. Status and performance accounting are \nrecorded as events occur and are made avail-\nable through the CMS. Individual support tools are typically suffi-\ncient for small organizations or development \ngroups that do not issue variants of their soft-\nware products or face other complex SCM \nrequirements. The following are examples of \nthese tools:\n\u2022\t Version control tools: These tools track, \ndocument and store individual CIs such as \nsource code and external documentation. \u2022\t Build handling tools: In their simplest \nform, such tools compile and link an exe-\ncutable version of the software. More", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 200", "position": 200, "chunk_type": "semantic", "token_estimate": 203}
{"text": "SOFTWARE CONFIGURATION MANAGEMENT   8-15: advanced building tools extract the latest \nversion from the version control soft-\nware, perform quality checks, run regres-\nsion tests, and produce various forms of \nreports, among other tasks. \u2022\t Change control tools: These tools pri-\nmarily support the control of CRs and \nevent notifications (e.g., CR status \nchanges, milestones reached). Project-related support tools mainly sup-\nport workspace management for develop-\nment teams and integrators. In addition, \nthey can support distributed development \nenvironments. Such tools are appropriate for \nmedium-to-large organizations that use vari-\nants of their software products and parallel \ndevelopment and do not have certification \nrequirements. Companywide-process support tools \ncan \nautomate portions of a companywide pro-\ncess, providing support for workflow man-\nagement, roles and responsibilities. They can \nhandle many items, large volumes of data, and \nnumerous life cycles. In addition, such tools \nadd to project-related support by supporting a \nmore formal development process, including \ncertification requirements. MATRIX OF TOPICS VS. REFERENCE MATERIAL\nTopic\nIEEE 828-2012\n[2*]\nHass 2003 \n[3*]\nSommerville 2016\n[4*]\n1. Management of the SCM Process\nc6, c7\n1.1. Organizational Context for SCM\nc6, ann.D \nIntroduction\nc25\n1.2. Constraints and Guidance for the SCM Process\nc6, ann.D,  \nann.E\nc2,c5\n1.3. Planning for SCM\nc6, ann.D,  \nann.E\nc23\nc25\n1.3.1. SCM Organization and Responsibilities\nann.Ds5-6\nc10-11\nc25\n1.3.2. SCM Resources and Schedules\nann.Ds8\nc23\n1.3.3. Tool Selection and Implementation\nc26s2, s6\n1.3.4. Vendor/Subcontractor Control\nc13\nc13s9-c14s2\n1.3.5. Interface Control\nc12\nc23s4\n1.4. SCM Plan\nann.D\nc23\n1.5. Surveillance of Software Configuration \nManagement\nc11s3\n1.5.1. SCM Measures and Measurement\nc9s2; c25s2-s3\n1.5.2. In-Process Audits of SCM\nc1s1\n2. Software Configuration Identification\nc8\n2.1. Identifying Items to Be Controlled\nc8s2.2\nc1s2\n2.1.1. Software Configuration", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 201", "position": 201, "chunk_type": "semantic", "token_estimate": 279}
{"text": "9-2   SWEBOK \u00ae GUIDE V4.0: is essentially actual and necessary but not suf-\nficient. Other human factors may affect the \nproject\u2019s success. During the software devel-\nopment lifecycle, it is impossible to separate \nthe human factors from the technical ones. Therefore, people management activities, \nsuch as team and teamwork, leadership, com-\nmunication, and coordination activities, are \nimportant to project success. Software reuse can be a key factor in main-\ntaining and improving productivity and \ncompetitiveness. Factors such as cultural differences and \ndiverse attitudes may affect the develop-\nment team. A significant number of software \nprojects failed due to social issues. A \u201chigh \nquality\u201d developer can produce inappro-\npriate or poor quality products that require \nrework if presented with poor requirements or \ncommunication. Other issues can complicate effective man-\nagement of software projects and software life \ncycle processes, including the following:\n\u2022\t Clients often do not know what is needed \nor what is feasible. \u2022\t Increased understanding and changing \nconditions will likely generate new or \nchanged software requirements. \u2022\t Clients often do not appreciate the com-\nplexities inherent in software engi-\nneering, \nparticularly \nregarding \nthe \nimpact of changing requirements. \u2022\t As a result of changing requirements and \nsoftware malleability, software is often \nbuilt iteratively rather than as a linear \nsequence of phases. \u2022\t Software is nominally an enduring capa-\nbility that must be supported and contin-\nuously improved throughout its lifecycle. \u2022\t Software construction differs from hard-\nware implementation in that design is \nusually part of software construction, \nwhereas in hardware-oriented systems, \ndesign precedes hardware implementa-\ntion to \u201cget it right\u201d prior to procurement \nor fabrication of hardware [12]. \u2022\t Software engineering necessarily incorpo-\nrates creativity and discipline. Maintaining \nan appropriate balance between the two is \nsometimes difficult [5]. \u2022\t The development of software capabilities \noften involves a high degree of novelty \nand complexity. \u2022\t Typically, the underlying technology has \na high rate of change. \u2022\t Computer software has become a key \ncomponent of most modern systems. Software has been elevated to a highly \nprominent role because of its flexibility \nand relatively low replication cost com-\npared with hardware. \u2022\t A significant number of software projects \nfailed due to human issues. Physical mea-\nsurement units such as the length and \nweight measures are challenging to apply \nto the software. This difficulty impacts \nhow to plan, monitor, and control soft-\nware development projects. \u2022\t Software rework to remove faults and \nrespond to change.", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 205", "position": 205, "chunk_type": "semantic", "token_estimate": 401}
{"text": "9-4   SWEBOK \u00ae GUIDE V4.0: \u2022\t The Software Configuration Management \nKA deals with the identification, control, \nstatus accounting and auditing of soft-\nware configurations, along with software \nrelease management and delivery and \nsoftware configuration management tools. \u2022\t The Software Engineering Process KA \ndescribes software life cycle models and \nthe relationships between processes and \nwork products. Software Engineering \nManagement\nInitiation \nand Scope \nDe\ufb01nition\nSoftware \nEngineering\nMeasurement\nDetermination \nand Negotiation \nof Requirements\nFeasibility\nAnalysis\nProcess for the\nReview and \nRevision of\nRequirements\nProcess\nPlanning\nDetermine\nDeliverables\nE\ufb00ort, \nSchedule,\nand Cost \nEstimation\nImplementation\nof Plans\nSoftware \nAcquisition \nand Supplier \nContract\nManagement\nImplementation \nof Measurement\nProcess\nMonitor Process\nControl Process\nReporting\nDetermine\nSatisfaction of\nRequirements\nReviewing\nand Evaluating\nPerformance\nDetermine\nClosure\nClosure\nActivities\nEstablish \nand Sustain\nMeasurement\nCommitment\nPlan the \nMeasurement\nProcess\nPerform the \nMeasurement\nProcess\nEvaluate\nMeasurement\nSoftware \nProject \nPlanning\nSoftware \nProject \nEnactment\nSoftware\nReview and \nEvaluation\nClosure\nSoftware \nEngineering\nManagement \nTools\nFigure 9.1. Breakdown of Topics for the Software Engineering Management KA", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 207", "position": 207, "chunk_type": "semantic", "token_estimate": 160}
{"text": "Because most software development life cycle: (SDLC) models require similar activities that \nmay be executed in different ways, the topic \nbreakdown, shown in Figure 9-1, is activi-\nty-based. The top-level elements shown in \nthe figure are activities that are usually per-\nformed when a software development project \nis being managed, regardless of which SDLC \nmodel is being used (see Software Life Cycle \nModels in the Software Engineering Process \nKA). This breakdown does not recommend \na specific life cycle model. However, it is \nimportant to note the choice of the SDLC \ncan have a impact on program activities to \naccommodate changing requirements. Delivery speed, continuous adaptation and \nfrequent modular upgrades to deliver new \ncapabilities are often key business differenti-\nators and project management imperative [11, \n13]. These imperatives should be balanced \nwith risk management activities. Several software life cycle process models \nhave been and are being developed to shorten \ndevelopment cycles in response to changing \nbusiness needs, specifically, changing soft-\nware requirements. Most of these pro-\ncesses involve Agile SDLC approaches [14]. The Agile approach assumes that teams can \ndevelop \nhigh-quality, \nadaptive \nsoftware \nusing continuous design improvement prin-\nciples and testing based on rapid feedback \nand change. In comparison, the traditional \napproach assumes that software-intensive sys-\ntems are fully specifiable and predictable and \ncan be built through meticulous and exten-\nsive planning. The management style asso-\nciated with the Agile approach emphasizes \nleadership and collaboration at the team level, \nwhereas the management style of the highly \npredictive approach is more formal (top-\ndown). Many Agile approaches integrate dif-\nferent management approaches. For example, Dev/Sec/Ops is a culture \nand an Agile approach to modern software \ndelivery that aligns development (Dev), secu-\nrity (Sec) and operations (Ops) groups into an \nintegrated team focused on continuous, incre-\nmental delivery of capabilities. The main char-\nacteristic of Dev/Sec/Ops is that this approach \nautomates, continuously monitors and applies \nsecurity at all phases of the software life cycle: \nplan, develop, build, test, release, deliver, \ndeploy, operate and monitor. In Dev/Sec/\nOps, testing and security are shifted to the \nleft through automated unit, functional, inte-\ngration and security testing. This is a key \nDev/Sec/Ops differentiator; security/quality \nassurance (QA) and other nonfunctional \nand functional capabilities are tested and \nbuilt simultaneously [11, 14].", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 208", "position": 208, "chunk_type": "semantic", "token_estimate": 373}
{"text": "Because most software development life cycle: In Dev/Sec/\nOps, testing and security are shifted to the \nleft through automated unit, functional, inte-\ngration and security testing. This is a key \nDev/Sec/Ops differentiator; security/quality \nassurance (QA) and other nonfunctional \nand functional capabilities are tested and \nbuilt simultaneously [11, 14]. Whereas Dev/\nSec/Ops encompasses the culture and pro-\ncesses that enable rapid, continual delivery \nof cyber-resilient systems, complex soft-\nware-embedded systems can have additional \ndemands that must also be integrated into \nthe Dev/Sec/Ops culture and processes, such \nas safety. Elevating these demands to be on \npar with Dev/Sec/Ops highlights the impor-\ntance of incorporating quality into all program \naspects. The complexity of the end-to-end \nDevSecOps tools and of using emerging tech-\nnologies such as artificial intelligence (AI) and \nmachine learning (ML) to leverage those tools \nadds another dimension [15]. For example, \nAgile and DevOps approaches are reasonably \nwell-established, but in case of AI-based soft-\nware, new SLDCs maybe required to manage \nthe complexity brought by AI to the software. It is important to understand the differ-\nence between phases and activities and why \nan activities breakdown is used. The Project \nManagement Institute (PMI) describes a \nphase this way:  \u201cThe completion and approval \nof one or more deliverables characterizes a \nproject phase.\u201d A deliverable is a measurable, \nverifiable work product such as a specification,", "domains": ["Software Quality Attributes", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 208", "position": 208, "chunk_type": "semantic", "token_estimate": 221}
{"text": "9-6   SWEBOK \u00ae GUIDE V4.0: feasibility study report, detailed design docu-\nment or working prototype. Some deliverables \ncorrespond to part of the project management \nprocess, whereas others are the end products \nor components of the end products for which \nthe project was conceived. The deliverables, \nand hence the phases, are part of a generally \nsequential process designed to ensure proper \ncontrol of the project and to attain the desired \nproduct or service, which is the project\u2019s objec-\ntive. From a project management perspective, \nphases help accomplish project objectives and \nmaintain control over the project. The activity-based breakdown in Figure \n9-1 shows what happens but does not imply \nwhen, how or how many times each activity \noccurs. The seven topics are the following:\n\u2022\t Initiation and Scope Definition, which \ndeals with the decision to embark on a \nsoftware engineering project\n\u2022\t Software \nProject \nPlanning, \nwhich \naddresses the activities undertaken to pre-\npare for a successful software engineering \nproject from the management perspective\n\u2022\t Software Project Enactment, which deals \nwith generally accepted SEM activities \nthat occur during a software engineering \nproject\u2019s execution\n\u2022\t Review and Evaluation, which deals with \nensuring that technical, schedule, cost \nand quality engineering activities are \nsatisfactory \n\u2022\t Closure, which addresses the activities \naccomplished to complete a project\n\u2022\t Software \nEngineering \nMeasurement, \nwhich deals with the effective develop-\nment and implementation of measure-\nment programs in software engineering \norganizations\n\u2022\t Software \nEngineering \nManagement \nTools, which describes the selection and \nuse of tools for managing a software \nengineering project\n1. Initiation and Scope Definition \nProject initiation focuses on reviewing the \nsoftware requirements and determining the \nneed, scope, feasibility, and authorization for \na software project Once project feasibility has \nbeen established, the remaining tasks in this \nsection are specifying the software require-\nments and selecting the processes for require-\nments revision and review. 1.1. Determination and Negotiation of \nRequirements \b\n[3*, c3]\nDetermining and negotiating the project \nrequirements are the overarching goals of \nthe tasks undertaken during this phase (see \nthe Software Architecture KA and Software \nRequirements KA). Activities should include \nsoftware requirements review (e.g., elicita-\ntion, analysis, specification, and validation). Methods and techniques should be selected \nand applied considering the various stake-\nholder perspectives. Requirements provide the \nbasis for all that follows on a software project \nand are captured in a Project Charter or other \nhigh-level project initiation document. 1.2.", "domains": ["Design Patterns", "Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 209", "position": 209, "chunk_type": "semantic", "token_estimate": 390}
{"text": "SOFTWARE ENGINEERING MANAGEMENT   9-7: Software Project Planning\nA key step in software project planning should \nbe selecting an appropriate SDLC model and, \nperhaps, tailoring it based on project scope, \nsoftware requirements and a risk assess-\nment. The SWX [2] states that project life \ncycles occupy a continuum from predictive to \nadaptive. Factors that characterize the posi-\ntions of software project life cycles within \nthe continuum include (but are not limited \nto) the various ways requirements and plans \nare handled, how risk and cost are managed, \nand key stakeholder involvement. Highly pre-\ndictive software project life cycles emphasize \nrequirements specification and detailed plan-\nning during the project\u2019s initiation and plan-\nning phases. Detailed plans based on a known \narchitecture, requirements and constraints are \nused to reduce risk and cost. Milestones are \nplanned, versus continuous key stakeholder \ninvolvement. Highly adaptive software project \nlife cycles, on the other hand, are character-\nized by progressive requirements specification \nbased on short iterative development cycles. Risk and cost are reduced by progressive evo-\nlution of initial plans, and key stakeholders \nare continuously involved [2]. Other factors to consider include the \nnature of the application domain, func-\ntional and technical complexity, and software \nquality requirements. (See Software Quality \nRequirements in the Software Quality KA.) In all SDLCs, risk assessment should be \nan element of initial project planning, and \nthe \u201crisk profile\u201d of the project should be dis-\ncussed and accepted by all relevant stake-\nholders. Software \nquality \nmanagement \nprocesses (see Software Quality Management \nProcesses in the Software Quality KA) \nshould be planned along with project plan-\nning. This planning should establish proce-\ndures and responsibilities for software quality \nassurance (SQA), verification and valida-\ntion, reviews, and audits. (See the Software \nQuality KA.) Processes and responsibilities", "domains": ["Design Patterns", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 210", "position": 210, "chunk_type": "semantic", "token_estimate": 288}
{"text": "SOFTWARE ENGINEERING MANAGEMENT   9-9: concurrently and sequentially can be identi-\nfied and documented, using a Gantt chart, \nfor example. In predictive SDLC projects, \nthe expected schedule of tasks, with projected \nstart times, durations and end times, is typ-\nically produced during planning. In adaptive \nSDLC projects, an overall estimate of effort \nand schedule is typically developed from the \ninitial understanding of the requirements, or, \nalternatively, constraints on overall effort and \nschedule may be specified and used to deter-\nmine an initial estimate of the number of iter-\native cycles and estimates of effort and other \nresources allocated to each cycle. Resource \nrequirements \n(for \nexample, \npeople and tools needed) can usually be \ntranslated into cost estimates. The estima-\ntion of effort, schedule and cost is an itera-\ntive activity that should be negotiated and \nrevised among affected stakeholders until \nconsensus is reached on resources and time \navailable for project completion. Program \nmanagers often use a model that links four \nassociation role types: responsible, account-\nable, consulted, and informed (i.e., RACI) to \nfacilitate this process. Responsible\u00a0 roles pro-\nduce deliverables;\u00a0 accountable\u00a0 roles check \nthe deliverables;\u00a0 consulted\u00a0 roles advise on \ntasks; and\u00a0 informed\u00a0 roles are kept informed \nthroughout these processes. Project managers \nshould constantly monitor stakeholder require-\nments and changes as they evolve to analyze \ntheir impact on the project cost and schedule. This is usually more important in Agile soft-\nware development projects, where stakeholder \nrequirements are dynamic because changes \nmight occur rapidly as the project progresses. 2.4. Resource Allocation \b\n[3*, c5, c10, c11]\nEquipment, facilities and people should be \nallocated to the identified tasks, including \nallocating responsibilities for completing var-\nious project elements and the overall project. A matrix that shows who is responsible for, \naccountable for, consulted about and informed \nabout each task can be used. Resource allo-\ncation is based on and constrained by the \navailability of resources and their optimal \nuse, and by issues relating to personnel (e.g., \nproductivity of individuals and teams, team \ndynamics, and team structures). 2.5. Risk Management \b\n[3*, c9] [5*, c5]\nRisk and uncertainty are related but distinct \nconcepts. Uncertainty results from a lack of \ninformation. Risk is effect of uncertainty on \nobjectives that has negative (threats) or positive \n(opportunities) consequences on objectives.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 212", "position": 212, "chunk_type": "semantic", "token_estimate": 371}
{"text": "SOFTWARE ENGINEERING MANAGEMENT   9-9: Uncertainty results from a lack of \ninformation. Risk is effect of uncertainty on \nobjectives that has negative (threats) or positive \n(opportunities) consequences on objectives. Risk management entails identifying risk \nfactors, analyzing probability and potential \nimpact of each risk factor, prioritizing risk \nfactors, and developing risk mitigation strat-\negies to reduce the probability of a negative \nevent and to minimize the negative impact if \na risk factor becomes a problem. Risk man-\nagement data can be used to represent the \nproject risk profile; this data is often part of \na risk register. A risk register is a document \nused as a risk management tool. It can be used \nto fulfill regulatory compliance, serving as a \nrepository for all risks identified and for addi-\ntional information about each risk [2]. Risk \nassessment methods (e.g., expert judgment, \nhistorical data, decision trees and process \nsimulations) can sometimes be used to iden-\ntify and evaluate risk factors. Project abandonment conditions can also \nbe determined with all relevant stakeholders. Software-unique aspects of risk, such as soft-\nware engineers\u2019 tendency to add unneeded \nfeatures or the risks related to software\u2019s \nintangible nature, can influence risk man-\nagement for software projects. Particular \nattention should be paid to managing risks \nrelated to software quality requirements such \nas safety or security [11]. (See the Software \nQuality KA.) Risk management should be \ndone not only at the beginning of a project, \nbut also at periodic intervals throughout the \nproject life cycle. 2.6. Quality Management  \n\b\n[3*, c4] [4*, c2]\nAccording to the PMBOK\u00ae Guide, Project \nquality management includes the performing", "domains": ["Software Quality Attributes", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 212", "position": 212, "chunk_type": "semantic", "token_estimate": 263}
{"text": "9-10   SWEBOK \u00ae GUIDE V4.0: organization\u2019s processes and activities that \ndetermine quality policies, objectives and \nresponsibilities so the project will satisfy \nthe needs for which it was undertaken. This \nsection discusses additional considerations \nfor managing software project quality [1]. Software quality requirements for a soft-\nware project and the associated work prod-\nucts should be identified, perhaps both \nquantitatively and qualitatively. Quality \nattributes of software include but are not \nlimited to safety, security, reliability, avail-\nability, performance, ease of use and ease of \nmodification. SWX Section 1.9 lists quality \nattributes that are important for software \nusers (e.g., efficiency, safety, security, reli-\nability, availability) and quality attributes \nthat are important to software developers \nand maintainers (e.g., maintainability is \nimportant to those who provide sustain-\nment services) [1]. ISO/IEC 25000 series \nof standards provides extensive lists of \nsoftware quality attributes that align with \ndifferent stakeholder needs [2]. This align-\nment is consistent with ISO/IEC/IEEE \n15939 and practical software and systems \nmeasurement (PSM) [2, 9.11]. Large portions of system functionality \nare shifting from hardware to software to \ncapitalize on the increased flexibility and \nspeed of component delivery that soft-\nware can provide. However, with these \nbenefits come other challenges \u2014 for \nexample, the need for increased man-\nagement of software quality require-\nments (e.g., cybersecurity) throughout \nthe SDLC [11]. Thresholds for acceptable \nquality measurements should be set for \neach software quality requirement based \non stakeholder needs and expectations. Procedures concerned with ongoing SQA \nand quality improvement throughout \nthe development process and with veri-\nfying and validating the deliverable soft-\nware product should also be specified \nduring quality planning (e.g., technical \nreviews and inspections or demonstra-\ntions of completed functionality). (See \nthe Software Quality KA.) 2.7. Plan Management \b\n[3*, c4]\nExcept for older predictive programs, doc-\numenting and managing formal plans are \nbecoming less emphasized in managing most \nsoftware projects. (e.g., documentation plans \nare rarely used, especially when Model-Based \nSystems Engineering (MBSE) is used for \nproduct data). The said, where they are used, \nplans should be developed and managed for \nsoftware projects when change is expected. The magnitude of the planning effort and the \nplan\u2019s content should be determined partly \nby the risk of not developing the plan. The \nmanagement of the project plan should itself \nbe planned. Plans and processes selected for \nsoftware development should be systemat-\nically monitored, reviewed, reported and, \nwhen appropriate, revised.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 213", "position": 213, "chunk_type": "semantic", "token_estimate": 393}
{"text": "9-10   SWEBOK \u00ae GUIDE V4.0: The \nmanagement of the project plan should itself \nbe planned. Plans and processes selected for \nsoftware development should be systemat-\nically monitored, reviewed, reported and, \nwhen appropriate, revised. Plans associated \nwith supporting processes (e.g., documenta-\ntion, software configuration management, \nand problem resolution) also should be man-\naged. Reporting, monitoring and controlling \na project should fit within the selected SDLC \nand the realities of the project. Plans should \naccount for the various artifacts that will be \nused to manage the project. Project managers of predictive life cycle \nsoftware projects put substantial effort into \nup-front development of the project plan and \nintegration of subsidiary plans developed \nby support personnel from other organiza-\ntional units (e.g., estimation specialists in the \nProject Management Office (PMO)). In other types of programs (e.g., adap-\ntive programs) where formal plans are not \nusually used, the emphasis should be on \nselecting and retaining project information \nuseful in project control and future projects, \nand establishing strategy, policies, and pro-\ncedures. For example, in adaptive programs, \nmanagers will usually spend less effort up \nfront on developing detailed scope, cost and \nschedule plans. But significant effort is typ-\nically spent defining monitor and control \nprocesses, such as requirements traceability, \nto ensure coordination among the project \nmembers or teams as the emerging plans are \nimplemented [2].", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 213", "position": 213, "chunk_type": "semantic", "token_estimate": 219}
{"text": "SOFTWARE ENGINEERING MANAGEMENT   9-11: 3. Software Project Execution\nDuring software project enactment (also \nknown as project execution), plans are imple-\nmented, and the processes embodied in the \nplans are enacted. Throughout, there should \nbe a focus on adherence to the selected SDLC \nprocesses, with an overriding expectation that \nadherence will satisfy stakeholder require-\nments and achieve the project\u2019s objectives. Fundamental to enactment are the ongoing \nmanagement activities of monitoring, con-\ntrolling and reporting. 3.1. Implementation of Plans \b\n[4*, c2]\nProject activities should follow the project plan \nand supporting plans. Project activities use \nresources (personnel, technology and funding) \nand generate work products (software design, \nsoftware code and software test cases). 3.2. Software Acquisition and Supplier \nContract Management \b\n[3*, c3, c4]\nSoftware acquisition and supplier contract \nmanagement concern issues involved in con-\ntracting with customers of the software \ndevelopment organization who acquire the \ndeliverable work products and with suppliers \nwho supply products or services to the soft-\nware engineering organization. Software acquisition is common practice \nin software development projects, with inte-\ngrated development environments (IDEs) \nand package libraries allowing software \nengineers to acquire third-party libraries \nwith minimal steps, facilitating the assess-\nment of risk, legality and suitability. However, software is no longer exclusively \nacquired as a shrink-wrapped product via \na complex supply chain process and pur-\nchasing route. The ease of acquiring soft-\nware has resulted in a common attack \nsurface and led to security vulnerabilities. Organizations should consider introducing \ntechnical or procedural controls to minimize \nrisk potentially exposed by unfiltered access \nto external library repositories. The different software acquisition classes \ninclude commercial off-the-shelf (COTS) \nsoftware \u2014 an existing product acquired \u201cas \nis\u201d from another software vendor, with appli-\ncable license terms; software developed exclu-\nsively for the organization by another party \n\u2014 typically contracted and sometimes a cus-\ntomization of COTS software; open source \nsoftware \u2014 nominally free, although the orga-\nnization may purchase enhanced support or \nmaintenance and must review the license for \nrestrictions on use; customer loaned software \n\u2014 typically to provide simulation or integra-\ntion with another system element; software as \na service (SaaS) \u2014 which might include soft-\nware the organization rents to fulfill a partic-\nular need (for example, a cloud-based hosting, \nsource control or development environment). Software projects typically use different \nacquisition approaches to obtain the necessary \nsoftware components.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 214", "position": 214, "chunk_type": "semantic", "token_estimate": 386}
{"text": "SOFTWARE ENGINEERING MANAGEMENT   9-11: The different software acquisition classes \ninclude commercial off-the-shelf (COTS) \nsoftware \u2014 an existing product acquired \u201cas \nis\u201d from another software vendor, with appli-\ncable license terms; software developed exclu-\nsively for the organization by another party \n\u2014 typically contracted and sometimes a cus-\ntomization of COTS software; open source \nsoftware \u2014 nominally free, although the orga-\nnization may purchase enhanced support or \nmaintenance and must review the license for \nrestrictions on use; customer loaned software \n\u2014 typically to provide simulation or integra-\ntion with another system element; software as \na service (SaaS) \u2014 which might include soft-\nware the organization rents to fulfill a partic-\nular need (for example, a cloud-based hosting, \nsource control or development environment). Software projects typically use different \nacquisition approaches to obtain the necessary \nsoftware components. However, regardless of \nhow the software components are obtained, \nthe following activities should be performed: \nverifying that each component is complete, \ncorrect and consistent concerning the archi-\ntectural design and software requirements for \nthat component; integrating the components; \nverifying that the integrated components are \ncorrect, complete and consistent concerning \nthe architectural design and the software \nrequirements; and validating that the inte-\ngrated components will satisfy their intended \npurpose when used in their intended oper-\nating environment. Different \nacquisition \napproaches \n(for \nobtaining software components) require dif-\nferent approaches to managing the project. For example, custom development requires \ndetailed planning for the numbers and skills \nof the software developers, organizing the \ndevelopment team(s), allocating requirements \nto the teams, specifying project metrics to be \ncollected, monitoring progress, and applying \ncorrective actions when actual progress does \nnot agree with planned progress. Licensing \ncomponents involves evaluating candidate \ncomponents; selecting appropriate compo-\nnents; and negotiating terms, conditions, and \ndelivery dates for the selected components.", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 214", "position": 214, "chunk_type": "semantic", "token_estimate": 292}
{"text": "9-12   SWEBOK \u00ae GUIDE V4.0: This anal-\nysis might examine cost overruns, schedule \nslippage or other measures. Outlier identifica-\ntion and analysis of quality and other measure-\nment data should be performed (e.g., defect \nanalysis). (See Software Quality Measurement \nin the Software Quality KA.) Risk exposures \nshould be recalculated. (See Section 2.5, Risk \nManagement.) These activities can enable \nproblem detection and exception identification \nbased on thresholds that have been exceeded. Outcomes should be reported as necessary \nor when thresholds have been exceeded. For \nexample, the timely identification, mitigation, \nand resolution of software security vulnerabil-\nities and weaknesses that exceed expectations \ncan affect the system\u2019s security posture [11]. 3.5. Control Process \b\n[3*, c7, c8]\nProject monitoring activities provide the basis \nfor making decisions. Where appropriate, and \nwhen the probability and impact of risk fac-\ntors are understood, changes can be made to \nthe project. This may take the form of cor-\nrective action (e.g., retesting certain software \ncomponents). It might involve incorporating \nadditional actions (e.g., deciding to use pro-\ntotyping to assist in software requirements \nvalidation; see Prototyping in the Software \nRequirements KA). It might also entail \nrevising the project plan and other project \ndocuments (e.g., the software requirements \nspecification) to accommodate unanticipated \nevents and their implications.", "domains": ["Software Quality Attributes", "Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 215", "position": 215, "chunk_type": "semantic", "token_estimate": 207}
{"text": "SOFTWARE ENGINEERING MANAGEMENT   9-13: In some instances, the control process \nmight lead to abandonment of the project. In all cases, the software development team \nshould adhere to software configuration con-\ntrol and software configuration management \nprocedures. (See the Software Configuration \nManagement KA.) Decisions should be doc-\numented and communicated to all relevant \nparties, plans should be revisited and revised \nwhen necessary, and relevant data should \nbe recorded. (See Section 6.3, Perform the \nMeasurement Process.) 3.6. Reporting \b\n[3*, c11]\nProgress to date should be reported at spec-\nified and agreed-upon times both within the \norganization (e.g., to a project steering com-\nmittee) and to external stakeholders (e.g., cli-\nents or users). Reports should focus on the \ninformation needs of the target audience \nas opposed to the detailed status reporting \nwithin the project team. 4. Software Review and Evaluation\nAt prespecified times and as needed, overall \nprogress toward the stated objectives and \nsatisfaction of stakeholder (user and cus-\ntomer) requirements should be evaluated. Similarly, assessments of the effectiveness of \nthe software process, the personnel involved, \nand the tools and methods used should also \nbe undertaken regularly and as circum-\nstances demand. 4.1. Determining Satisfaction of Requirements \n\b\n[4*, c8]\nAchieving stakeholder satisfaction is a prin-\ncipal goal of the software engineering man-\nager. Progress toward this goal should be \nassessed periodically. Progress should be \nassessed upon achieving a major project \nmilestone (e.g., completing software design \narchitecture or completing a software tech-\nnical review) or upon completion of an iter-\native development cycle that results in a \nproduct increment. Variances from software \nrequirements should be identified, and appro-\npriate actions should be taken. As in the control process activity above (see \nSection 3.5, Control Process), software con-\nfiguration control and software configuration \nmanagement procedures should be followed \n(see the Software Configuration Management \nKA). Decisions should be documented and \ncommunicated to all relevant parties; plans \nshould be revisited and revised as neces-\nsary; and relevant data should be recorded \n(see Section 6.3, Perform the Measurement \nProcess). 4.2. Reviewing and Evaluating Performance \n\b\n[3*, c8, c10]\nPeriodic performance reviews for project per-\nsonnel can provide insight into the likelihood \nof adherence to plans and processes and pos-\nsible areas of difficulty (e.g., team member \nconflicts). The various project methods, tools \nand techniques should be evaluated for effec-\ntiveness and appropriateness. The project\u2019s \nprocess should also be systematically and \nperiodically assessed for relevance, utility and \nefficacy.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 216", "position": 216, "chunk_type": "semantic", "token_estimate": 401}
{"text": "SOFTWARE ENGINEERING MANAGEMENT   9-15: support to conduct the process should \nalso be allocated. 6.2. Plan the Measurement Process  \n\b\n[7*, c1, c2]1\n\u2022\t Characterize the organizational unit. The \norganizational unit provides the context \nfor measurement, so the organizational \ncontext should be explicit, including the \norganization\u2019s constraints on the mea-\nsurement process. The characterization \ncan be stated in terms of organizational \nprocesses, application domains, tech-\nnology, organizational interfaces and \norganizational structure. \u2022\t  Identify information needs. Information \nneeds are based on the organizational \nunit\u2019s goals, constraints, risks, and prob-\nlems and may be derived from business, \norganizational, regulatory and/or product \nobjectives. Stakeholders should identify, \nprioritize, document, communicate and \nreview these needs. \u2022\t Select measures. Select candidate mea-\nsures, with clear links to the information \nneeds. Select measures based on the pri-\norities of the information needs and other \ncriteria such as cost of collection; degree \nof process disruption during collection; \nease of obtaining accurate, consistent \ndata; and ease of analysis and reporting. Internal \nquality \ncharacteristics \n(see \nModels and Quality Characteristics in \nthe Software Quality KA) are often not \ncontained in the contractually binding \nsoftware requirements. Therefore, con-\nsider measuring the software\u2019s internal \nquality to provide an early indicator of \npotential issues that might affect external \nstakeholders. \u2022\t Define data collection, analysis and \nreporting procedures. This encompasses \ncollection procedures and schedules, \nstorage, verification, analysis, reporting \nand data configuration management. \u2022\t Select criteria for evaluating the infor-\nmation products. The organizational \nunit\u2019s technical and business objectives \ninfluence evaluation criteria. Information \nproducts include those associated with \nthe product produced and those associ-\nated with the processes used to manage \nand measure the project. \u2022\t Provide resources for measurement tasks. The appropriate stakeholders should \nreview and approve the measurement \nplan to include all data collection pro-\ncedures; storage, analysis, and reporting \nprocedures; evaluation criteria; sched-\nules; and responsibilities. Criteria for \nreviewing these artifacts should be estab-\nlished at the organizational unit level or \nhigher and should be used as the basis for \nthese reviews. Such criteria should con-\nsider experience, resource availability and \npotential disruptions to projects when \nchanges from current practices are pro-\nposed. Approval demonstrates commit-\nment to the measurement process. o\tIdentify resources to be made avail-\nable for implementing the planned and \napproved measurement tasks. Resource \navailability may be staged in cases where \nchanges are piloted before widespread \ndeployment. Consider the resources \nnecessary for successful deployment of \nnew procedures or measures.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 218", "position": 218, "chunk_type": "semantic", "token_estimate": 399}
{"text": "SOFTWARE ENGINEERING MANAGEMENT   9-15: Resource \navailability may be staged in cases where \nchanges are piloted before widespread \ndeployment. Consider the resources \nnecessary for successful deployment of \nnew procedures or measures. o\tAcquire and deploy supporting tech-\nnologies. This includes evaluating \navailable \nsupporting \ntechnologies, \nselecting the most appropriate tech-\nnologies, acquiring those technologies \nand deploying those technologies. 6.3. Perform the Measurement Process  \n\b\n[7*, c1, c2]\nIntegrate measurement procedures with rel-\nevant software processes. The measurement \nprocedures, such as data collection, should \nbe integrated into the software processes they \nmeasure. This might involve changing current \nsoftware processes to accommodate data col-\nlection or generation activities. It might also \ninvolve analyzing current software processes \nto minimize additional effort and evaluating", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 218", "position": 218, "chunk_type": "semantic", "token_estimate": 118}
{"text": "9-18   SWEBOK \u00ae GUIDE V4.0: 4.2. Reviewing and \nEvaluating Performance\nc8, c10\n5. Closure\n5.1. Determining Closure\n5.2. Closure Activities\n6. Software Engineering \nMeasurement\n6.1. Establish and Sustain \nMeasurement Commitment\nc1, c2\n6.2. Plan the \nMeasurement Process\nc1, c2\n6.3. Perform the \nMeasurement Process\nc1, c2\n6.4. Evaluate Measurement\nc1, c2\n7. Software Engineering \nManagement Tools\nc5, c6, c7", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 221", "position": 221, "chunk_type": "semantic", "token_estimate": 59}
{"text": "SOFTWARE ENGINEERING MANAGEMENT   9-19: [2]\t Software Extension to the Project \nManagement Body of Knowledge \n(PMBOK\u00ae Guide), Fifth Edition, \nProject Management Institute, 2013. [3*]\tR. E. Fairley, Managing and Leading \nSoftware Projects. Hoboken, NJ: Wiley \nIEEE Computer Society Press, 2009. [4*]\tI. Sommerville, Software Engineering, \n10th ed., New York: Addison-\nWesley, 2015. [5*]\tB. Boehm and R. Turner, Balancing \nAgility and Discipline: A Guide for \nthe Perplexed. Boston: Addison-\nWesley, 2003. [6]\t IEEE, IEEE Standard Adoption of ISO/\nIEC 15939: 2007 Systems and Software \nEngineering Measurement Process, ed: \nIEEE, 2017. [7*]\tJ. McGarry et al., Practical Software \nMeasurement: Objective Information \nfor Decision Makers, Addison-Wesley \nProfessional, 2001. [8]\t J. McDonald, Managing the \nDevelopment of Software-Intensive \nSystems. Hoboken, NJ: John Wiley and \nSons, Inc., 2010. [9] \t Practical Software and Systems \nMeasurement Continuous Iterative \nDevelopment Measurement Framework \nParts 1-3: Concepts, Definitions, \nPrinciples, and Measures, Version 2.1,  \n15 April 2021. [10]\tS. Sheard, M. Bouyaud, M. Osaisai, \nJ. Siviy, and K. Nidiffer, \u201cBook Club\u201d \nGuides a Working Group to Create \nINCOSE System-Software Interface \nProducts, INSIGHT, Volume 24, \nIssue 2, 2021. [11]\tK. Nidiffer, C. Woody, and T.A. Chick, Program Manager\u2019s Guidebook \nfor Software Assurance, Special Report, \nCMU/SEI-2018-SR-025, Software \nSolutions and CERT Divisions, \nSoftware Engineering Institute/\nCarnegie Mellon University, \nAugust 2018. [12]\tR.E. Fairley, Systems Engineering of \nSoftware-Enabled Systems, ISBN 978-1-\n119-53501-0, 2019. [13]\tDefense Innovation Board, Software Is \nNever Done: Refactoring the Acquisition \nCode for Competitive Advantage Defense, \nv3.3, March 12, 2019. [14]\t\u201cDevOps: Building Reliable and Secure \nSystems Including Application Build, \nPackage, and Deployment,\u201d IEEE \nStandard, 2675-2021, 2021. [15]\tM. Chemuturi and T. Cagley, Mastering \nSoftware Project Management: Best \nPractices, Tools and Techniques, J. Ross \nPublishing, July 2010.", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 222", "position": 222, "chunk_type": "semantic", "token_estimate": 274}
{"text": "SOFTWARE ENGINEERING PROCESS   10-3: KAs \nand \nthe \nSoftware \nEngineering \nManagement, Software Engineering Models \nand Methods, Software Quality, Software \nArchitecture, and Software Testing KAs. The \nMeasurement and Root Cause Analysis sec-\ntions in the Engineering Foundations KA is \nalso closely related. 1.2 Software Engineering Process Definition \n\b\n[1*,c5][2] [7][14][20]\nA process is a \u201cset of interrelated or interacting \nactivities that transforms inputs into outputs\u201d, \nwhere activity is a \u201cset of cohesive tasks of a pro-\ncess,\u201d and a task is a \u201crequired, recommended, \nor permissible action, intended to contribute to \nthe achievement of one or more outcomes of \na process\u201d [1]. According to [2], a process is a \n\u201cpredetermined course of events defined by its \npurpose or by its effect, achieved under given \nconditions.\u201d A third definition, following [7], is \na \u201csystem of activities, which use resources to \ntransform inputs into outputs.\u201d And a fourth \none is a \u201cset of interrelated or interacting activ-\nities which transforms inputs into outputs to \ndeliver an intended result\u201d [20]. That is, the \ndescription of a process includes required inputs, \ntransforming activities, and the outputs gener-\nated. These definitions address any processes \nthat are applied to the software part of software \nsystems. Software systems also include hard-\nware, and they also involve people and manual \nprocedures. The output of one process can be \nan input to another process. Processes may \ninclude controls (e.g. directives and constraints) \nand enabling mechanisms (e.g. tools, technolo-\ngies or resources such as workforce and infra-\nstructure)  associated with the processes [14]. 2. Life Cycles1\n2.1. Life Cycle Definition, Process Categories, \nand Terminology \n\b\n[1*,c5-6][3*,c2][8*,c1-3][13]\nA life cycle, according to [1], is the \u201cevolution \nof a system, product, service, project or other \n1\t  Lifecycle, life-cycle and life cycle are different spellings. Merriam-Webster prefers the spelling \u201clife cycle\u201d. human-made entity from conception through \nretirement.\u201d In software engineering, life \ncycles help convey information about software \nsystems, the \u201csystem[s] for which software is \nof primary importance to the stakeholders\u201d \n[1]. The concept of life cycles was put in place \nbecause simply identifying and defining the \nprocesses required to produce software did \nnot adequately describe all the complexity \nof software systems. It was also necessary to \ndefine life cycles, which include a number of \nprocesses and constraints [8].", "domains": ["Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 225", "position": 225, "chunk_type": "semantic", "token_estimate": 373}
{"text": "SOFTWARE ENGINEERING PROCESS   10-3: The concept of life cycles was put in place \nbecause simply identifying and defining the \nprocesses required to produce software did \nnot adequately describe all the complexity \nof software systems. It was also necessary to \ndefine life cycles, which include a number of \nprocesses and constraints [8]. In software engineering, development refers \nto a crucial stage of a system, product, ser-\nvice or project life cycle: that of building (or \nchanging) a software system according to \nthe stakeholders\u2019 needs. From a production/\nindustrial management perspective, software \nsystems are referred to as products. In this \ncontext, the term software product development \nlifecycle makes sense. Product life cycle can be defined as the \n\u201cseries of phases that represent the evolution \nof a product, from concept through delivery, \ngrowth, maturity, to retirement\u201d [13]. This \ndefinition is not specific to software sys-\ntems but applies to all products more gener-\nally. Likewise, the life cycle concept, which is \nlinked to the product concept, is not specific \nto software engineering. Software systems contain software units \nthat are an \u201catomic-level software component \nof the software architecture that can be sub-\njected to stand-alone testing.\u201d (See the Testing \nKA.) The life cycle of a software system (and \nkeep in mind that software engineering uses \nan interdisciplinary approach) comprises all \nthe processes, activities and tasks from the \nideation of the software system to the retire-\nment of the system, including production, \noperation and evolution, as well as acquisi-\ntion, when needed, and supply. Likewise, we \ncan look at the life cycle of an element of a \nsoftware system (a software unit). A soft-\nware system life cycle will consider both the \nbusiness and the technical needs of the stake-\nholders and the system\u2019s ability to produce,", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 225", "position": 225, "chunk_type": "semantic", "token_estimate": 292}
{"text": "10-4   SWEBOK \u00ae GUIDE V4.0: Therefore, life cycle processes are interre-\nlated processes; that is, each individual pro-\ncess (its inputs and outputs) may depend on \nother processes. The interrelated nature of the \nprocesses involved make the overall software \nengineering process highly complex. T\ufeffhe specification of life cycles is a pow-\nerful tool for implementing an engineering \napproach to the creation, operation and \nretirement of software systems. A life cycle \nshould be defined following engineering prin-\nciples that guide engineering as a discipline \n[8]. The specification of a life cycle includes \nthe specification of every process and the \nassociated constraints. The process specifica-\ntion should be useful to humans so that they \ncan communicate with one another using this \nspecification. The specification should be easy \nto understand and correct because life cycle \nspecifications are the basis for technical and", "domains": ["Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 226", "position": 226, "chunk_type": "semantic", "token_estimate": 139}
{"text": "10-8   SWEBOK \u00ae GUIDE V4.0: 6. Retirement: At this stage, the team fol-\nlows established procedures to dispose of \nthe system. The stages are not supposed to be sequen-\ntial, by any means. Actually, the specifica-\ntion of the life cycle for a software system will \ninclude the transitions between these stages. It should be clear that these stages have been \nidentified for a general life cycle. Specific life \ncycles will have specific stages, meaningful \nto a particular project\u2019s stakeholders; these \nstages will fit into these general stages. 2.7. Software Engineering Process Management \n\b\n[1*,c5][2]\nProcess management is defined as \u201cdirection, \ncontrol, and coordination of work performed \nto develop a product or perform a service\u201d \n[2]. Several management levels govern the \nsoftware engineering process, as explained \nin reference [1], see also KA 9, Software \nEngineering Management. The lowest level is \nthe technical processes; the second is the tech-\nnical management level, which will include \nproject management processes. The third level \nis the (executive) management level, focused \non organizational enabling processes, such \nas knowledge management, life cycle model \nmanagement, or portfolio management. 2.8. Software Life Cycle Adaptation \n\b\n[5] [14] [23][29]\nEach software system has its differential char-\nacteristics. These differential characteristics, \ntogether with the stakeholders\u2019 needs, lead to \nspecific life cycles. This adaptation will include \nidentifying all the relevant characteristics, \nselecting the appropriate standards or docu-\nments internal to an organization, selecting a \ndevelopment strategy/life cycle model, stages, \nand processes, and documenting the decisions \nand rationale. The adaptation will not require \nkeeping the names provided in Section 2, \nor including them all [5, 14, 23]. The ISO/\nIEC 29110 series, Systems and Software \nEngineering Standards and Guides for Very \nSmall Entities (VSEs) [29], is an example of \na series derived from ISO/IEC/IEEE 12207. 2.9. Practical Considerations\b\n[8*,c2-3]\nDefining a life cycle process includes the spec-\nification of the four categories presented in \nSection 2. This means addressing technical \nprocesses (definition of the processes that will \nbe required), organizational processes (this \nincludes human resources, among other pro-\ncesses), technical management processes (how \nprocesses are related, how they are monitored \nand managed), and agreement processes. The discipline of software engineering has \nbeen evolving since its conception for several \nreasons. The community has never stopped \nlearning, while the complexity of the prod-\nucts has been ever-increasing.", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 230", "position": 230, "chunk_type": "semantic", "token_estimate": 383}
{"text": "SOFTWARE ENGINEERING PROCESS   10-9: information about what is happening (the \nstatus of the process and the product) while the \nlife cycle process is executed. If we are uncer-\ntain about the accuracy of estimations and \nmeasurements, the project might not be suc-\ncessful. In this case, a reflection should take \nplace on the overall approach. Historically, \na lot of polemics have grown about the pre-\ndictive life cycle versus the Agile life cycle. In software engineering, discussions should \nalways be supported by realistic process and \nproduct estimations and measurements, which \ncan accurately reduce the level of uncertainty. 2.10. Software Process Infrastructure, Tools, \nMethods\b\n[3*,c2][8*,c2-3][2]\nSeveral notations have been used for defining \nsoftware processes, including natural language, \nspecifying textual lists of constituent activi-\nties and tasks, data-flow diagrams, state charts, \nintegration definition (IDEF0), Petri nets, and \nunified modeling language (UML) activity dia-\ngrams, and business process modeling notation \n(BPMN) [2, 3]. Software process infrastructure \nincludes tools to support the definition of these \nprocesses (e.g., a BPMN toolkit) but mainly to \nsupport all specific processes (testing or con-\nfiguration management). Process definitions \nwill often include methods and formalism (e.g., \nRational Unified Process or extreme program-\nming) [3]. Tools will, ideally, have to support \nthese methods and, as important, be integrated \nwith them. Therefore, it is not enough that a \ntool supports testing. Once a code unit has been \nsuccessfully tested, for example, this becomes \nuseful information that should be recorded so \nthat the rest of the team can be aware of this \nfact. This means that the configuration man-\nagement tool and the testing tool will have to be \nintegrated [3, 8]. The term software engineering \nenvironment, representing a set of integrated \ntools, is sometimes used. The term CASE (com-\nputer-aided software engineering) was popular \nin the 1980s and 1990s. Somehow, the power \ntools of the 1980s and 1990s were oversold as a \ncure for the software crisis. In any case, today, \nthe automation of some processes (e.g., config-\nuration management, or at least version control; \ntesting; ticket management) is seen as essential \nfor the implementation of successful life cycles. You can also read KA 11, Software Engineering \nModels and Methods. 2.11. Software Engineering Process Monitoring \nand its Relationship with the Software \nProduct\b\n[1*,c5-6][3*,c2][4*c4-10]\n\b\n[8*c2-3]\nDevelopers must monitor the software engi-\nneering process execution, assess whether the \nprocess objectives are met, and assess risks.", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 231", "position": 231, "chunk_type": "semantic", "token_estimate": 393}
{"text": "10-12   SWEBOK \u00ae GUIDE V4.0: Software Faster. Addison-Wesley \nProfessional, December 2021. [9]\t J. Shore and S. Warden, The Art of Agile \nDevelopment, O\u2019Reilly Media, 2nd ed. October 2021. [10] \tProject Management Institute, Agile \nPractice Guide. Project Management \nInstitute and Agile Alliance. September 2017. [11]\tISO/IEC/IEEE Std 32675:2022 \nInformation technology \u2014 DevOps \u2014 \nBuilding reliable and secure systems \nincluding application build, package and \ndeployment. [12]\tISO/IEC/IEEE 24774:2021 Systems \nand software engineering \u2014 Life cycle \nmanagement \u2014 Specification for pro-\ncess description. [13]\tProject Management Institute, A \nGuide to the Project Management Body \nof Knowledge (PMBOK\u00ae Guide) \u2014 \nSixth Edition. [14]\tISO/IEC/IEEE 24748-1:2018(E) \nSystems and software engineering \n\u2014 Life cycle management \u2014 Part 1: \nGuidelines for life cycle management. [15]\tW.A. Shewhart and W.E. Deming, \nStatistical Method from the Viewpoint \nof Quality Control. Dover, New \nYork, 1986. [16]\t\u201cThe Agile Manifesto.\u201d https://\nagilemanifesto.org. [Accessed \nMarch 5, 2022]. [17]\tS. McConnell, More Effective Agile: A \nRoadmap for Software Leaders, 2019. [18]\t\u201cSubway Map to Agile Practices.\u201d Agile \nAlliance. https://www.agilealliance.org \n/agile101/subway-map-to-agile \n-practices/. [Accessed March 5, 2022]. [19]\tJ. Eckstein and J. Buck, Company-wide \nAgility with Beyond Budgeting, Open \nSpace & Sociocracy: Survive & Thrive on \nDisruption, 2021. [20]\tISO/IEC TR 29110-5-3:2018 Systems \nand software engineering \u2014 Lifecycle \nprofiles for very small entities (VSEs) \u2014 \nPart 5-3: Service delivery guidelines. [21]\tN. Fenton and J. Bieman, Software \nMetrics, 3rd ed. CRC Press, 2014. [22]\tCMMI Institute \u2014 CMMI V2.0. https://cmmiinstitute.com/cmmi. [Accessed 5 March 2022]. [23]\tISO/IEC/IEEE 24748-3:2020. Part 3: \nGuidelines for the application of ISO/\nIEC/IEEE 12207 (software life cycle \nprocesses). [24]\tD.R. Kiran, Total Quality manage-\nment. Elsevier, 2017. [25]\t\nJ. Rumbaugh, G. Booch, I. Jacobson. The Unified Software Development \nProcess, 1999\n[26]\tP. Kruchten. The Rational Unified \nProcess: An Introduction. 3rd Ed. 2004\n[27]\tThe Eclipse Foundation https://www. eclipse.org/org/foundation/ [Accessed \n25 April 2024]. [28]\tT. Dings\u00f8yr, Postmortem reviews: pur-\npose and approaches in software engi-\nneering, Information and Software \nTechnology, Volume 47, Issue 5, 2005, \nPages 293-303. [29]\tISO/IEC TR 29110-1:2016 Systems \nand software engineering Lifecycle pro-\nfiles for Very Small Entities (VSEs) \nPart 1: Overview", "domains": ["Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 234", "position": 234, "chunk_type": "semantic", "token_estimate": 343}
{"text": "Software engineering models and methods: impose structure on software engineering to \nmake it systematic, repeatable and ultimately \nmore success-oriented. Models provide an \napproach to problem-solving, a notation and \nprocedures for model construction and anal-\nysis. Methods provide an approach to the sys-\ntematic specification, design, construction, \ntesting and verification of the end-item soft-\nware and associated work products. Software engineering models and methods \nvary widely in scope \u2014 from addressing a \nsingle software life cycle phase to covering the \ncomplete software life cycle. This knowledge \narea (KA) focuses on models and methods \nthat encompass multiple software life cycle \nphases regardless of the type of life cycle pro-\ncess models such as iterative models and agile \nones, since other KAs cover methods specific \nto single life cycle phases.", "domains": ["Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 235", "position": 235, "chunk_type": "semantic", "token_estimate": 127}
{"text": "11-2   SWEBOK \u00ae GUIDE V4.0: Stakeholders are those people or parties with a \nstated or implied interest in the software (e.g., \nusers, buyers, suppliers, architects, certifying \nauthorities, evaluators, developers, software \nengineers). Although there are many modeling lan-\nguages, notations, techniques and tools in \nthe literature and in practice, some general, \nunifying concepts apply to them all. The fol-\nlowing sections provide background on these \ngeneral concepts. 1.1. Modeling Principles \n \b\n[1*, c2s2, c5s1, c5s2, 2*, c2s2, 3*, c5s0]\nModeling provides the software engineer \nwith an organized and systematic approach \nfor representing significant aspects of the \nsoftware under study, facilitating deci-\nsion-making about the software or elements, \nand communicating those significant deci-\nsions to others in the stakeholder commu-\nnities. Three general principles guide such \nmodeling activities:\n\u2022\t Model the essentials: Good models do not \nusually represent every aspect or fea-\nture of the software under every possible \ncondition. Modeling typically involves \nonly those aspects or features that pose \nspecific questions, abstracting away any \nnonessential information. This approach \nkeeps models manageable and useful. \u2022\t Provide perspective: Modeling provides \nviews of the software under study using \ndefined rules for expressing the model \nwithin each view. This perspective-driven \napproach provides dimensionality to the \nmodel (e.g., providing a structural view, \na behavioral view, a temporal view, an \norganizational view and/or other views \nif relevant). Organizing information into \nviews focuses the software modeling \nefforts on specific concerns relevant to \nthat view using the appropriate notation, \nvocabulary, methods and tools. \u2022\t Enable effective communications: Modeling \nuses the application domain vocabulary \nof the software, a modeling language \nand semantic expression (in other words, \nmeaning within context). When used \nrigorously and systematically, mod-\neling results in a reporting approach \nthat facilitates effective communica-\ntion of software information to project \nstakeholders. Software\nEngineering Models\nand Methods\nModeling\nTypes of Models\nAnalysis of\nModels \nSoftware\nEngineering\nMethods  \nModeling\nPrinciples\nProperties and\nExpression of\nModels\nSyntax,\nSemantics and\nPragmatics\nPreconditions,\nPostconditions\nand Invariants     \nBehavioral\nModeling\nStructure\nModeling\nAnalyzing for\nCompleteness\nAnalyzing for\nConsistency\nAnalyzing for\nCorrectness\nAnalyzing for\nTraceability\nAnalyzing for\nInteraction\nHeuristic\nMethods\nFormal\nMethods\nPrototyping\nMethods\nAgile\nMethods\nFigure 11.1. Breakdown of Topics for the Software Engineering Models and Methods KA", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 236", "position": 236, "chunk_type": "semantic", "token_estimate": 362}
{"text": "SOFTWARE ENGINEERING MODELS AND METHODS   11-3: A model is an abstraction or simplification \nof a system. A consequence of using abstrac-\ntion is that, because no single abstraction \ncompletely describes a software component, \nthe software model comprises an aggregation \nof abstractions, which, when taken together, \ndescribe selected aspects, perspectives or \nviews \u2014 only those that are needed to make \ninformed decisions and respond to the reasons \nfor creating the model in the first place. This \nsimplification points to assumptions about the \ncontext within which the model is placed that \nshould also be captured in the model. Then, \nwhen the model is reused, these assumptions \ncan be validated first to establish the rele-\nvancy of the reused model within its new use \nand context. 1.2. Properties and Expression of Models  \n\b\n[1*, c5s2, c5s3, 3*, c4s1.1p7, c4s6p3, \n \n\b\nc5s0p3]\nProperties of models are those distinguishing \nfeatures of a particular model that charac-\nterize its completeness, consistency and cor-\nrectness within the chosen modeling notation \nand tooling. Properties of models include the \nfollowing:\n\u2022\t Completeness \u2014 the degree to which all \nrequirements have been implemented and \nverified within the model\n\u2022\t Consistency \u2014 the degree to which the \nmodel contains no conflicting require-\nments, assertions, constraints, functions \nor component descriptions\n\u2022\t Correctness \u2014 the degree to which the \nmodel satisfies its requirements and \ndesign specifications and is free of defects\nModels are constructed to represent objects \nneeded for target domains and their behaviors \nto answer specific questions about how the \nsoftware is expected to operate. Interrogating \nthe models \u2014 through exploration, simula-\ntion or review \u2014 might expose areas of uncer-\ntainty within the model and the software to \nwhich the model refers. These uncertain-\nties or unanswered questions regarding the \nrequirements, design and/or implementation \ncan then be handled appropriately. The primary expression element of a model \nis an entity. An entity may represent concrete \nartifacts (e.g., processors, sensors or robots) \nor abstract artifacts (e.g., software modules \nor communication protocols). Model entities \nare connected to other entities using relations \n(lines or textual operators on target entities). Expression of model entities may be accom-\nplished using textual or graphical modeling \nlanguages; both modeling language types con-\nnect model entities through specific language \nconstructs. The meaning of an entity may \nbe represented by its shape, its textual attri-\nbutes or both. Generally, textual information \nadheres to language-specific syntactic struc-\nture.", "domains": ["Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 237", "position": 237, "chunk_type": "semantic", "token_estimate": 396}
{"text": "SOFTWARE ENGINEERING MODELS AND METHODS   11-3: The meaning of an entity may \nbe represented by its shape, its textual attri-\nbutes or both. Generally, textual information \nadheres to language-specific syntactic struc-\nture. The precise meanings related to the mod-\neling of context, structure or behavior using \nthese entities and relations are dependent on \nthe modeling language used, the design rigor \napplied to the modeling effort, the specific \nview being constructed and the entity to which \nthe specific notation element may be attached. Multiple views of the model may be required to \ncapture the needed semantics of the software. When using automation-supported models, \nmodels may be checked for completeness and \nconsistency. The usefulness of these checks \ndepends greatly on the level of semantic and \nsyntactic rigor applied to the modeling effort \nand on explicit tool support. Correctness can \nbe checked through model simulation, execu-\ntion or review. 1.3. Syntax, Semantics, and Pragmatics  \n\b\n[2*, c2s2.2.2p6, 3*, c5s0]\nModels can be surprisingly deceptive. The fact \nthat a model is an abstraction with missing \ninformation can give people the illusion that \nthey completely understand the software after \nstudying a single model. A complete model \n(\u201ccomplete\u201d being relative to the modeling \neffort) may be a union of multiple submodels \nand any special function models. Examination \nof and decision-making regarding a single \nmodel within this collection of submodels \nmay be problematic.", "domains": ["Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 237", "position": 237, "chunk_type": "semantic", "token_estimate": 226}
{"text": "11-4   SWEBOK \u00ae GUIDE V4.0: With many soft-\nware engineers working on part of a model \nover time, and with tool updates and perhaps \nnew requirements, there are opportunities for \nportions of the model to represent something \ndifferent from the original author\u2019s intent and \ninitial model context. 1.4. Preconditions, Postconditions, and Invariants \n\b\n[2*, c4s4, 4*, c10s4p2, c10s5p2p4]\nWhen modeling functions or methods, \nthe software engineer typically starts with \nassumptions about the software\u2019s state before, \nduring and after the function or method exe-\ncutes. These assumptions are essential to the \ncorrect operation of the function or method \nand are grouped, for discussion, as a set of \npreconditions, postconditions and invariants. \u2022\t Preconditions are conditions that must be \nsatisfied before execution of the function \nor method. If these preconditions do not \nhold before execution of the function or \nmethod, the function or method might \nproduce erroneous results. \u2022\t Postconditions are conditions guaranteed \nto be true after the function or method \nhas executed successfully. Typically, the \npostconditions represent how the soft-\nware\u2019s state has changed, how parameters \npassed to the function or method have \nchanged, how data values have changed, \nor how the return value has been affected. \u2022\t Invariants are conditions within the oper-\national environment that persist (in other \nwords, do not change) before and after \nexecution of the function or method. These invariants are relevant and neces-\nsary to the software and to the correct \noperation of the function or method. 2. Types of Models\nA typical model consists of an aggregation \nof submodels. Each submodel is a partial \ndescription and is created for a specific pur-\npose. A submodel may comprise one or more", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 238", "position": 238, "chunk_type": "semantic", "token_estimate": 276}
{"text": "SOFTWARE ENGINEERING MODELS AND METHODS   11-5: diagrams. The collection of submodels may \nuse multiple modeling languages or a single \nmodeling language. The unified modeling \nlanguage (UML) recognizes a rich collec-\ntion of modeling diagrams. These diagrams, \nalong with the modeling language constructs, \nare used in two common model types: struc-\ntural models and behavioral models. (See \nSection 1.1.) Depending on modeling lan-\nguages, there can be other types of models. For instance, the systems modeling language \n(SysML) provides two other types of models: \nrequirements models and parametric models. 2.1. Structural Modeling \n\b\n[1*, c7s2.2, c7s2.5, c7s3.1, c7s3.2, 3*, c5s3, \n\b\nc8s1, 4*, c4, 17]\nStructural models illustrate the software\u2019s \nphysical or logical composition of software \nfrom its various component parts. Structural \nmodeling establishes the defined boundary \nbetween the software being implemented or \nmodeled and the environment in which it is to \noperate. Some common structural constructs \nused in structural modeling are composition, \ndecomposition, generalization, and special-\nization of entities; identification of relevant \nrelations and cardinality between entities; and \nthe definition of process or functional inter-\nfaces. Structure diagrams provided by the \nUML for structural modeling include class, \ncomponent, object, deployment, and pack-\naging diagrams. Information modeling is a kind of struc-\ntural modeling and focuses on data and \nother information. An information model is \nan abstract representation that identifies and \ndefines a set of concepts, properties, relations \nand constraints on data entities. The semantic \nor conceptual information model is often used \nto provide some formalism and context to the \nsoftware as viewed from the problem perspec-\ntive, without concern for how this model is \nmapped to the implementation of the software. The semantic or conceptual information model \nis an abstraction and, as such, includes only the \nconcepts, properties, relations and constraints \nneeded to conceptualize a real-world view of \nthe information. Subsequent transformations \nof the semantic or conceptual information \nmodel become logical and then physical data \nmodels as implemented in the software. 2.2. Behavioral Modeling  \n\b\n[1*, c7s2.1, c7s2.3, c7s2.4, 2*, c9s2, 3*, \n\b\n c5s4, 8, c1s5.4]\nBehavioral models identify and define soft-\nware functions. Behavioral models generally \ntake three basic forms: state machines, con-\ntrol-flow models and data-flow models. State \nmachines provide a model that represents \nthe software as a collection of defined states, \nevents and transitions. The software tran-\nsitions from one state to the next through a \nguarded or unguarded triggering event that \noccurs in the modeled environment.", "domains": ["Design Patterns", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 239", "position": 239, "chunk_type": "semantic", "token_estimate": 400}
{"text": "SOFTWARE ENGINEERING MODELS AND METHODS   11-5: State \nmachines provide a model that represents \nthe software as a collection of defined states, \nevents and transitions. The software tran-\nsitions from one state to the next through a \nguarded or unguarded triggering event that \noccurs in the modeled environment. Control-\nflow models depict how a sequence of events \ncauses processes to be activated or deacti-\nvated. Data-flow models represent data-flow \nbehavior as a sequence of steps where data \nmoves through processes toward data stores \nor data sinks. These models are described in \nthe way of event-triggered, time concepts \n(i.e., logical, physical, discrete, continuous, \nrelative, or absolute time), or combinations \nthereof. Behavioral diagrams provided by the \nUML for behavioral modeling include use \ncase, activity, state machine, and interaction \n(sequence, communication, timing, and inter-\naction overview) diagrams. 3. Analysis of Models\nThe development of models allows the soft-\nware engineer to study, reason about and \nunderstand software structure, function, \noperational use and assembly considerations. Analysis of constructed models is needed to \nensure that the models are complete, con-\nsistent and correct enough to serve their \nintended purpose for the stakeholders. The following sections briefly describe the \nanalysis techniques generally used to ensure \nthat the software engineer and other relevant \nstakeholders gain appropriate value from the \ndevelopment and use of models.", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 239", "position": 239, "chunk_type": "semantic", "token_estimate": 216}
{"text": "11-6   SWEBOK \u00ae GUIDE V4.0: 3.1. Analyzing for Completeness  \n\b\n[3*, c4s1.1p7, c4s6, 5*, pp8-11]\nTo ensure software fully meets the needs of \nthe stakeholders, completeness \u2014 from the \nrequirements elicitation process to code imple-\nmentation \u2014 is critical. Completeness is the \ndegree to which all specified requirements have \nbeen implemented and verified. Engineers can \ncheck models for completeness with a modeling \ntool that uses structural analysis and state-\nspace reachability analysis (which ensure some \nset of correct inputs reach all paths in the state \nmodels). Models may also be checked manually \nfor completeness by using inspections or other \nreview techniques. (See the Software Quality \nKA.) Errors and warnings generated by these \nanalysis tools and found by inspection or review \nindicate that corrective actions are probably \nneeded to ensure model completeness. 3.2. Analyzing for Consistency  \n\b\n[3*, c4s1.1p7, c4s6, 5*, pp8-11]\nConsistency is the degree to which models \ncontain no conflicting requirements, asser-\ntions, constraints, functions or component \ndescriptions. Typically, consistency checking \nis accomplished with the modeling tool using \nan automated analysis function. Models may \nalso be checked manually for consistency \nusing inspections or other review techniques. (See the Software Quality KA.) As with com-\npleteness, errors and warnings generated by \nthese analysis tools and found by inspection or \nreview indicate the need for corrective action. 3.3. Analyzing for Correctness \b\n[5*, pp8-11]\nCorrectness is the degree to which a model \nsatisfies its software requirements and soft-\nware design specifications, is free of defects, \nand ultimately meets the stakeholders\u2019 needs. Analyzing for correctness includes verifying \nthe model\u2019s syntactic correctness (that is, cor-\nrect use of the modeling language grammar \nand constructs) and semantic correctness (that \nis, use of the modeling language constructs to \ncorrectly represent the meaning of that which \nis being modeled). To analyze a model for syn-\ntactic and semantic correctness, one analyzes it \n\u2014 either automatically (e.g., using the modeling \ntool to check for model syntactic correctness) \nor manually (using inspections or other review \ntechniques) \u2014 searching for possible defects \nand then removing or repairing the confirmed \ndefects before the software is released for use. 3.4. Analyzing for Traceability  \n\b\n[3*, c4s7.1, c4s7.2]\nDeveloping software typically involves using, \ncreating and modifying many work products \nsuch as planning documents, process specifica-\ntions, software requirements, diagrams, designs \nand pseudo-code, handwritten and tool-gen-\nerated code, manual and automated test cases \nand reports, and files and data.", "domains": ["Design Patterns", "Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 240", "position": 240, "chunk_type": "semantic", "token_estimate": 396}
{"text": "SOFTWARE ENGINEERING MODELS AND METHODS   11-7: within the software model. This analysis \nexamines the dynamic behavior of the inter-\nactions among the software model\u2019s different \nparts, including other software layers (such as \nthe operating system, middleware and appli-\ncations). Examining interactions between the \ncomputer software application and the user \ninterface software might also be important \nfor some software applications. Some soft-\nware modeling environments provide simula-\ntion facilities to study aspects of the dynamic \nbehavior of modeled software. Stepping \nthrough the simulation allows the software \nengineer to review the interaction design and \nverify that the software\u2019s different parts work \ntogether to provide the intended functions. 4. Software Engineering Methods\nSoftware engineering methods provide an \norganized and systematic approach to devel-\noping software for a target computer. There \nare numerous methods from which to choose, \nand the software engineer needs to choose an \nappropriate method or methods for the soft-\nware development task at hand. This choice \ncan dramatically affect the success of the \nproject. When software engineers, working \nwith people who have the right skill sets and \nthe right tools, use these software engineering \nmethods, they can visualize the software\u2019s \ndetails and ultimately transform the represen-\ntation into a working set of code and data. Selected software engineering methods \nare discussed below. The topic areas are orga-\nnized into discussions of Heuristic Methods, \nFormal Methods, Prototyping Methods and \nAgile Methods. 4.1. Heuristic Methods \b\n[1*, c13, c15, c16, 3*, \nc2s2.2, c7s1, c5, 8, \b\npp.xiii-xvii  9, c2s2, 11, \n\b\nc1, 12, c1s1, 19, pp.220-242]\nHeuristic methods are experience-based soft-\nware engineering methods that are fairly widely \npracticed in the software industry. This topic \narea contains five broad discussion categories: \nstructured analysis and design methods, data \nmodeling methods, object-oriented analysis \nand design methods, aspect-oriented develop-\nment methods, and model-driven and mod-\nel-based development methods. \u2022\t Structured analysis and design methods: \nThese methods develop the software \nmodel primarily from a functional or \nbehavioral viewpoint. It starts from a \nhigh-level view of the software (including \ndata and control elements). It then pro-\ngressively decomposes or refines the \nmodel components through increasingly \ndetailed designs. The detailed designs \neventually converge to specific software \ndetails or specifications that must be \ncoded (by hand, automatically generated \nor both), built, tested and verified. \u2022\t Data modeling methods: The data model \nis constructed from the viewpoint of the \ndata or information used. Data tables and \nrelationships define the data models.", "domains": ["Design Patterns", "Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 241", "position": 241, "chunk_type": "semantic", "token_estimate": 401}
{"text": "11-8   SWEBOK \u00ae GUIDE V4.0: \u2022\t Aspect-Oriented Development Methods: The \naspect-oriented approach aims to separate \ncrosscutting concerns from non-crosscut-\nting ones in the system and keeps them \nencapsulated throughout the entire life \ncycle to solve their scattering and tangling \nproblem. Aspect is the unit of modularity \nto encapsulate crosscutting concerns. At \nthe software level, there is a \u201cweaver\u201d \nthat is in charge of joining the portions \nof functionality (advices) encapsulated \nin the incumbencies at certain points of \nbase behavior (join points), according to \nwell-defined predicates (pointcuts). \u2022\t Model-Driven \nand \nModel-Based \nDevelopment Methods: \nModel-Driven \nDevelopment (MDD) is an approach \nusing models as primary artifacts of \nthe development process. In MDD, usu-\nally the implementation or other models \nare (semi)automatically transformed from \nthe models. Model-Based Development \n(MBD) uses models to analyze the system, \nwhere models are not necessarily the pri-\nmary artifacts. Some literature refers to \nMBD as the acronym for Model-Based \nDesign. Model-Based Design is a mod-\nel-centric approach to developing con-\ntrol, signal processing, communications, \nand other dynamic systems, focusing \non executable specification and simula-\ntion. See Software Design KA. Model-\nDriven Requirements and Model-Based \nRequirements apply the same mentality to \nspecification of software requirements, see \nthe Software Requirements KA for more \ninformation on this topic. MDD/MBD is a \nprerequisite to Model-Based Architecture, \nsee the Software Architecture KA. Sometimes, test cases are generated from \nmodels, see the Software Testing KA. 4.2. Formal Methods  \n\b[1*, c18, 3*, c27, 5*, pp8-24, 10, pp.xi-xiv]\nFormal methods are software engineering \nmethods that apply rigorous, mathemati-\ncally based notation and language to specify, \ndevelop and verify the software. Through \nuse of a specification language, the software \nmodel can be systematically checked for con-\nsistency (or lack of ambiguity), complete-\nness, and correctness, either automatically \nor semiautomatically. This topic is related to \nthe Formal Analysis section in the Software \nRequirements KA. This section addresses specification lan-\nguages, program refinement and derivation, \nformal verification, logical inference, and \nlightweight formal methods. \u2022\t Specification languages: Specification lan-\nguages provide the mathematical basis \nfor a formal method. Specification lan-\nguages are formal, higher-level computer \nlanguages (not a classic 3rd-generation \nlanguage (3GL) programming language) \nused during the software specification, \nrequirements analysis and/or design stages \nto describe specific input/output behavior. Specification languages are not directly \nexecutable languages. Instead, they typ-\nically comprise a notation and syntax, \nsemantics for the use of the notation, and \na set of allowed relations for objects.", "domains": ["Software Quality Attributes", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 242", "position": 242, "chunk_type": "semantic", "token_estimate": 399}
{"text": "11-8   SWEBOK \u00ae GUIDE V4.0: Specification languages are not directly \nexecutable languages. Instead, they typ-\nically comprise a notation and syntax, \nsemantics for the use of the notation, and \na set of allowed relations for objects. \u2022\t Program \nrefinement \nand \nderivation: \nProgram refinement creates a lower-level \n(or more detailed) specification using a \nseries of transformations. Through suc-\ncessive transformations, the software \nengineer derives an executable represen-\ntation of a program. Specifications may \nbe refined, adding details until the model \ncan be formulated in a 3GL program-\nming language or in an executable por-\ntion of the chosen specification language. This specification refinement is made \npossible by defining specifications with \nprecise semantic properties. For example, \nthe specifications must set out not only \nthe relationships between entities but \nalso the exact runtime meanings of those \nrelationships and operations. \u2022\t Formal verification: Model checking is a \nformal verification method. It typically \ninvolves performing a state-space explo-\nration or reachability analysis to demon-\nstrate that the represented software design", "domains": ["Design Patterns", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 242", "position": 242, "chunk_type": "semantic", "token_estimate": 165}
{"text": "SOFTWARE ENGINEERING MODELS AND METHODS   11-9: has or preserves certain model properties \nof interest. An example of model checking \nis an analysis that verifies correct program \nbehavior under all possible interleaving of \nevent or message arrivals. Formal verifica-\ntion requires a rigorously specified model \nof the software and its operational envi-\nronment. This model often takes the form \nof a finite-state machine or other formally \ndefined automaton. \u2022\t Logical inference: Logical inference is a \nmethod of designing software that spec-\nifies preconditions and postconditions \naround each significant design block. Using mathematical logic, it develops the \nproof that those preconditions and post-\nconditions must hold under all inputs. This allows the software engineer to pre-\ndict software behavior without having \nto execute the software. Some inte-\ngrated development environments (IDEs) \ninclude ways to represent these proofs and \nthe design or code. \u2022\t Lightweight Formal Methods: Lightweight \nformal \nmethods \nare \nlightweight \napproaches \nthat \nbalance \npractical \nusability and rigorous verification. For \ninstance, Alloy takes from formal specifi-\ncation the idea of a precise and expressive \nnotation based on a tiny core of simple and \nrobust concepts, but it replaces conven-\ntional analysis based on theorem proving \nwith a fully automatic analysis that gives \nimmediate feedback. Unlike theorem \nproving, this analysis is not \u201ccomplete\u201d: it \nexamines only a finite space of cases. 4.3. Prototyping Methods  \n\b\n[1*, c12s2, 3*, c2s3.1, 6*, c7s3p5]\nSoftware prototyping is an activity that gen-\nerally creates incomplete or minimally func-\ntional versions of a software application, \nusually for trying out specific new features; \nsoliciting feedback on software requirements \nor user interfaces; further exploring software \nrequirements, software design, or imple-\nmentation options; or gaining some other \nuseful insight into the software. The software \nengineer selects a prototyping method to \nfirst understand the least understood soft-\nware aspects or components. This approach \ncontrasts with other software engineering \nmethods that usually begin development with \nthe best-understood portions first. Typically, \nthe prototype does not become the final soft-\nware product without extensive development \nrework or refactoring. This section briefly discusses prototyping \nstyles, targets and evaluation techniques. \u2022\t Prototyping style: \nPrototyping \nstyles \ndescribe the various approaches to devel-\noping prototypes. A prototype can be \ndeveloped as throwaway code or a paper \nproduct, as an evolution of a working \ndesign, or as an executable specification. Different prototyping life cycle processes \nare typically used for each style.", "domains": ["Design Patterns", "Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 243", "position": 243, "chunk_type": "semantic", "token_estimate": 391}
{"text": "SOFTWARE ENGINEERING MODELS AND METHODS   11-9: A prototype can be \ndeveloped as throwaway code or a paper \nproduct, as an evolution of a working \ndesign, or as an executable specification. Different prototyping life cycle processes \nare typically used for each style. The style \nchosen is based on the type of results the \nproject needs, the quality of the results \nneeded and the results\u2019 urgency. \u2022\t Prototyping target: The prototyping target \nis the specific product served by the pro-\ntotyping effort. Examples of prototyping \ntargets are a requirements specification, \nan architectural design element or com-\nponent, an algorithm, and a human-ma-\nchine user interface. \u2022\t Prototyping evaluation techniques: The \nsoftware engineer or other project stake-\nholders may use or evaluate the prototype \nin many ways, driven primarily by the \nunderlying reasons that led to prototype \ndevelopment. Prototypes may be evalu-\nated or tested against the implemented \nsoftware or target requirements (e.g., a \nrequirements prototype). The prototype \nmight also serve as a model for future \nsoftware development (e.g., as in a user \ninterface specification). 4.4. Agile Methods  \n\b\n[3*, c3, 6*, c7s3p7, 7*, c6, App. A, \n \n\b\n13, 14, 15, 16, 18]\nAgile methods were developed in the 1990s to \nreduce the apparent large overhead associated", "domains": ["Design Patterns", "Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 243", "position": 243, "chunk_type": "semantic", "token_estimate": 204}
{"text": "11-10   SWEBOK \u00ae GUIDE V4.0: \u2022\t FDD: This is a model-driven, short, iter-\native software development approach \nusing a five-phase process: (1) develop a \nproduct model to scope the breadth of \nthe domain, (2) create the list of needs \nor features, (3) build the feature develop-\nment plan, (4) develop designs for itera-\ntion-specific features, and (5) code, test, \nand then integrate the features. FDD is \nsimilar to an incremental software devel-\nopment approach. It is similar to XP, \nexcept that code ownership is assigned \nto individuals rather than to the team. In addition, FDD emphasizes an overall \narchitectural approach to the software, \nwhich promotes building features cor-\nrectly the first time rather than rely on \ncontinual refactoring. \u2022\t Lean: This is an application of lean man-\nufacturing principles adapted from the \nToyota Production System to software \ndevelopment. The approach adopts the \nstrategy of making a Minimum Viable \nProduct, in which a team releases the \nsimplest version of its product. The team \nlearns feedback from users and iterates \nbased on the feedback. The concept of \nLean is to optimize the entire develop-\nment process, rather than optimizing the \nindividual development process. By over-\nlooking the entire value flow, including \ndesign, manufacturing, sales, and ser-\nvice delivery, this approach optimizes \nthe flow to quickly deliver the service to \nusers. Kanban is also lightweight process \nthat applies many of the Lean. However, \nthey are some fundamental differences \nbecause Kanban supports managing \nworkflow and visualization. There are many more variations of Agile \nmethods in the literature and in practice. There will always be a place for heavyweight,", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 244", "position": 244, "chunk_type": "semantic", "token_estimate": 264}
{"text": "11-12   SWEBOK \u00ae GUIDE V4.0: 2. Types of  \nModels\n2.1. Structural  \nModeling\nc9s5, c10s5\nc8s1, c5s3\nc4\n2.2. Behavioral  \nModeling\nc9s3, c10s6\nc9s2\nc5s4\n3. Analysis  \nof Models\n3.1. Analyzing for \nCompleteness\nc4s1.1p7,  \nc4s6\npp8-11\n3.2. Analyzing for \nConsistency\nc4s1.1p7,  \nc4s6\npp8-11\n3.3. Analyzing for \nCorrectness \npp8-11\n3.4. Traceability\nc4s7.1, c4s7.2\n3.5. Interaction  \nAnalysis\nc10, c11\nc29s1.1,  \nc29s5\nc5\n4. Software \nEngineering  \nMethods\n4.1. Heuristic  \nMethods\nc13\nc2s2.2, \nc7s1, c5s4.1\n4.2. Formal  \nMethods\nc18s2\nc27\npp8-24\n4.3. Prototyping  \nMethods\nc14s1, c14s2,  \nc14s3\nc2s3.1\nc7s3p5\n4.4. Agile  \nMethods\nc14s5, c14s6\nc3\nc7s3p7\nc6,  \napp.", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 246", "position": 246, "chunk_type": "semantic", "token_estimate": 93}
{"text": "SOFTWARE ENGINEERING MODELS AND METHODS   11-13: Systems with UML and MARTE: \nDeveloping Cyber-Physical Systems, \nMorgan Kaufmann, 2013. [9]\t M. Brambilla, J. Cabot, and M. \nWimmer, Model-Driven Software \nEngineering in Practice, Morgan & \nClaypool Publishers, 2017. [10]\tD. Jackson, Software Abstractions, \nrevised edition, The MIT Press, 2016. [11]\tR. Aarenstrup, Managing Model-\nBased Design, CreateSpace Independent \nPublishing Platform, 2015. [12]\tC. Larman, Applying UML and \nPatterns: An Introduction to Object-\noriented Analysis and Design and Iterative \nDevelopment, Germany: Prentice Hall \nPTR, 2005. [13]\tM. Poppendieck and T. Poppendieck, \nLean Software Development: An \nAgile Toolkit, Addison-Wesley \nProfessional, 2003. [14]\tT. Ohno, Toyota Production System: \nBeyond Large-Scale Production, Taylor & \nFrancis Distribution, 2021\n[15]\tD.J. Anderson, Kanban: Successful \nEvolutionary Change for Your Technology \nBusiness, Blue Hole Press; Blue Book ed. edition, 2010. [16]\tJ. Goodpasture, Project management the \nagile way: Making it work in the enter-\nprise, J. Ross Publishing, 2010. [17]\tISO/IEC 19505-1:2012, Information \ntechnology \u2014 Object Management \nGroup Unified Modeling Language \n(OMG UML) \u2014 Part 1: Infrastructure. [18]\tISO/IEC/IEEE 32675:2022, \nInformation technology \u2014 DevOps \u2014 \nBuilding reliable and secure systems \nincluding application build, package and \ndeployment. [19]\tG. Kiczales, J. Lamping, A. Mendhekar, \nC. Maeda, C. Lopes, J. M. Loingtier, \nand J. Irwin, Aspect-oriented pro-\ngramming, ECOOP\u201997, LNCS, Vol. 1241, 1997.", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 247", "position": 247, "chunk_type": "semantic", "token_estimate": 210}
{"text": "What is software quality, and why is it so: important that it is included in many knowl-\nedge areas (KAs) of the SWEBOK Guide? One \nreason is that the term software quality is over-\nloaded. Software quality may refer to the desir-\nable characteristics of software products, to the \nextent to which a particular software product \nhas those characteristics (software product \nquality), and to the processes, tools and tech-\nniques used to achieve those characteristics \n(software process quality). Over the years, \nauthors and organizations have defined the term \nquality differently. Phil Crosby defined quality \nas \u201cconformance to requirements\u201d [2]. Watts \nHumphrey referred to it as \u201cachieving excellent \nlevels of \u201cfitness for use\u201d [3]. Meanwhile, IBM \ncoined the phrase \u201cmarket-driven quality,\u201d \nwhere the \u201ccustomer is the final arbiter\u201d [4]. Finally, fitness for purpose is also a term that \nrefers to software qualit. Fitness for purpose is \nthe suitability of a product, system, or service \nfor use by the intended users, for the intended \nuse, in the intended situations, and intended \nenvironmental conditions. More recently, software (product) quality \nhas been defined as the \u201ccapability of a soft-\nware product to satisfy stated and implied \nneeds under specified conditions\u201d [4] and as \n\u201cthe degree to which a software product meets \nestablished requirements; however, quality \ndepends upon the degree to which those \nestablished requirements accurately represent \nstakeholder needs, wants, and expectations\u201d \n[6]. Both definitions embrace the premise of \nconformance to requirements. Neither refers \nto different types of requirements (require-\nments categorized according to functionality, \nreliability, performance, dependability, or any \nother characteristic). Significantly, however, \nthese definitions emphasize that quality is an \nimportant characteristic of requirements. These definitions also illustrate another \nreason for the recurring discussions about soft-\nware quality throughout the SWEBOK Guide \n\u2014 the often-unclear distinction between \nsoftware quality and software quality require-\nments (\u201cthe -ilities\u201d is a common shorthand \nfor these terms). Software quality require-\nments (Quality of Service Constraints in the \nSoftware Requirements KA) are attributes of \n(or constraints on) functional requirements \n(what the system does). Software requirements", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 248", "position": 248, "chunk_type": "semantic", "token_estimate": 336}
{"text": "12-2   SWEBOK \u00ae GUIDE V4.0: may also specify resource use, a communi-\ncation protocol, or many other characteris-\ntics (Technology Constraints in the Software \nRequirements KA). This KA attempts to \nclarify requirements by using software quality \nin the broadest sense from the definitions \nabove and by using software quality require-\nments as constraints on functional require-\nments. Software product quality is achieved \nby conforming to all requirements regard-\nless of specified characteristics or grouping or \nnaming of requirements. Software quality is also discussed in many \nother SWEBOK Guide Knowledge Areas \nbecause it is a basic concept of a software engi-\nneering effort. The primary goal for all engineered \nproducts is to deliver maximum stakeholder \nvalue while balancing the constraints of develop-\nment, maintenance, and operational cost, some-\ntimes characterized as fitness for use. Stakeholder \nvalue is expressed in requirements. For software \nproducts, stakeholders could value price (what \nthey pay for the product), lead time (how fast \nthey get the product), and software quality. (See \nthe Software Requirements KA for a broader \ndiscussion of this.) The software process quality aspect, \nwhich is implied by the above, must be made \nexplicit. The quality of a software process can \nbe also observed in process characteristics \nsuch as efficiency, effectiveness, usability, and \nlearnability. Defects in that process will likely \nshow up as defects in the resulting software \nproduct, as well. Finally, the Agile and DevOps move-\nments aim at improving the software pro-\ncess and product quality through compliance \nby promoting quick iteration feedback loops \nand eliminating organizational silos by col-\nlocating users and software engineers. Other \npractices like pair programming and the auto-\nmation of development, testing, and oper-\nations services also bring value, improve \nefficiency, and can detect defects early. (Refer \nto the Process KA for Agile life cycles and the \nSoftware Operations KA for more informa-\ntion on DevOps processes.) This KA provides an overview of practices, \ntools, and techniques for understanding soft-\nware quality and planning and appraising \nthe state of software quality during develop-\nment, maintenance and operation, from both \na software product perspective and a software \nprocess perspective. Cited references provide \nadditional details.", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 249", "position": 249, "chunk_type": "semantic", "token_estimate": 355}
{"text": "SOFTWARE QUALITY   12-3: 1. Software Quality Fundamentals\nAgreeing on what constitutes software quality \nfor all stakeholders and communicating that \nagreement to software engineers requires \nthat the many aspects of quality be formally \ndefined and communicated. The main chal-\nlenges the software engineer faces to ensure \nquality include the following:\n\u2022\t Difficulty in clearly defining requirements;\n\u2022\t Maintaining effective communication \nwith the client/user;\n\u2022\t Deviations from specifications;\n\u2022\t Architecture and design errors;\n\u2022\t Coding errors;\n\u2022\t Noncompliance with current processes/\nprocedures;\n\u2022\t Inadequate work product reviews and tests;\n\u2022\t Documentation errors. Software quality is defined as \u201cconfor-\nmance to established requirements; the capa-\nbility of a software product to satisfy stated \nand implied needs when under specified con-\nditions\u201d [6]. It is further defined \u201cby the degree \nto which a software product meets established \nrequirements; however, quality depends upon \nthe degree to which those established require-\nments accurately represent stakeholder needs, \nwants, and expectations\u201d [6]. Quality often \nmeans the absence of defects. The word defect \nis overloaded with too many meanings, as \nengineers and others use the word to refer \nto all different types of anomalies. However, \ndifferent engineering cultures and standards \noften understand \u201cdefect\u201d and other terms \nas having more specific meanings. To avoid \nconfusion, software engineers should use the \nmeaning provided by their standards [14]:\n\u2022\t Error: \u201cA human action that produces an \nincorrect result.\u201d Also called human error;\n\u2022\t Defect: (synonym of a fault) An \u201cimper-\nfection or deficiency in a work product \nwhere that work product does not meet its \nrequirements or specifications and needs \nto be either repaired or replaced.\u201d A defect \nis inserted when a person developing the \nsoftware makes an error. It hides in the \nsoftware until (and if) it is discovered;\n\u2022\t Failure: The \u201ctermination of the ability of \na system to perform a required function \nor its inability to perform within previ-\nously specified limits; an externally visible \ndeviation from the system\u2019s specification \nevent in which a system or system compo-\nnent does not perform a required function \nwithin specified limits.\u201d A failure is pro-\nduced when the software executes a defect. A software engineer should understand \nsoftware quality concepts, characteristics, and \nvalues and their application to the many devel-\nopment, maintenance, and operation activi-\nties. An important concept is that the software \nrequirements are expected to define the required \nsoftware quality attributes.", "domains": ["Design Patterns", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 250", "position": 250, "chunk_type": "semantic", "token_estimate": 391}
{"text": "SOFTWARE QUALITY   12-5: on Software Reliability target industries \nwhere safety and reliability are important. The Plan-Do-Check-Act (PDCA) para-\ndigms differ from standards in that it often \nproposes \u201cbest practices\u201d for software engi-\nneers from a specific perspective. (Refer to the \nSoftware Engineering Process KA for more \ninformation about the PDCA paradigm for \nsoftware.) Other industry \u201cbest practices\u201d models such \nas the Control Objectives for Information and \nRelated Technologies (COBIT) for informa-\ntion technology governance [27], the Project \nManagement Body of Knowledge (PMBOK\u00ae) \nfor project management [25], the Business \nAnalysis Body of Knowledge (BABOK\u00ae) [28], \nthe Capability Maturity Model Integration \n(CMMI) [29] and The Open Group \nArchitecture Framework (TOGAF) propose \nsoftware related practices that can improve the \nquality of software processes and products [30]. Software organizations can also consider the \npossible advantages of obtaining registrations \nor certifications (e.g., ISO 9001 for quality \n[10], ISO 27001 for security [31], (e.g., ISO \n9001 for quality [10], ISO 27001 for security \n[31] and ISO 20000 for operations [32]), and \nsoftware engineers can also obtain Scrum and \nScaled Agile Framework\u00ae (SAFe\u00ae) certifica-\ntions for Agile processes [22]. The use of these \nmodels and certifications have been shown \nto augment stakeholders\u2019 confidence that the \nsoftware engineers\u2019 knowledge and skills are \nup to date and recognized internationally. 1.4. Software Dependability and Integrity \nLevels \b\n[1*, c4s4.8, c7s7.3.3] [11]\nSoftware-intensive and safety-critical sys-\ntems are those in which a system failure could \nharm human life, other living things, physical \nstructures, or the environment. The software \nin these systems is considered safety-critical \nand requires the use of systematic methods \nand tools to ensure its high level of quality. A growing number of industries are using \nincreasing numbers of safety-critical soft-\nware, including transportation systems, chem-\nical and nuclear plants, and medical devices. Software failure in these systems could have \ncatastrophic effects. Engineers use industry \nstandards, such as software considerations in \nairborne systems and equipment certification \nDO-178C [8] and railway applications EN \n50128 [18], and emerging processes, tools, \nand techniques to develop safety-critical soft-\nware more safely. These standards, tools and \ntechniques reduce the risk of injecting faults \ninto the software and thus improve software \navailability, reliability, and maintainability. Software engineers and their managers must \nunderstand the threats and issues and develop \nthe skills needed to anticipate and prevent \naccidents before they occur [15]. Safety-critical software can be catego-\nrized as direct or indirect.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 252", "position": 252, "chunk_type": "semantic", "token_estimate": 394}
{"text": "SOFTWARE QUALITY   12-5: Software engineers and their managers must \nunderstand the threats and issues and develop \nthe skills needed to anticipate and prevent \naccidents before they occur [15]. Safety-critical software can be catego-\nrized as direct or indirect. Direct software is \nembedded in a safety-critical system, such as \nan aircraft\u2019s flight control computer. Indirect \nsoftware includes software applications used \nto develop safety-critical software. Indirect \nsoftware is included in software engineering \nenvironments and software test environments. Three \ncomplementary \ntechniques \nfor \nreducing failure risk are avoidance, detec-\ntion and removal, and damage limitation. These techniques impact software functional \nrequirements, performance requirements and \ndevelopment processes. Increasing risk implies \nincreasing SQA and more rigorous review \ntechniques such as inspections [16]. Higher risk \nlevels might necessitate more thorough inspec-\ntions of requirements, design, and code, or the \nuse of more formal verification and valida-\ntion techniques. Another technique for man-\naging and controlling software risk is building \nassurance cases. An assurance case is a reasoned, \nauditable artifact created to support the con-\ntention that its claim or claims are satisfied. It contains the following relationships: one or \nmore claims about properties, arguments that \nlogically link the evidence and any assump-\ntions to the claims, and a body of evidence and \nassumptions supporting these arguments [9]. 1.4.1. Dependability \b\n[7, c10] \nIn cases where system failure may have severe \nconsequences, overall dependability (e.g.,", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 252", "position": 252, "chunk_type": "semantic", "token_estimate": 227}
{"text": "12-6   SWEBOK \u00ae GUIDE V4.0: hardware, software, and human or oper-\national dependability) is the main quality \nrequirement, aside from basic software func-\ntionality, for the following reasons: System \nfailures affect many people; users often reject \nsystems that are unreliable, unsafe, or inse-\ncure; system failure costs could be important; \nand undependable systems might cause infor-\nmation loss. Many standards address dif-\nferent perspectives of dependability, such as \nreliability and availability. System and soft-\nware dependability regroups several related \nquality characteristics: availability, reliability, \nmaintainability and supportability, safety and \nsecurity [21]. When developing dependable \nsoftware, engineers can apply tools and tech-\nniques to reduce the risk of injecting faults into \nthe intermediate deliverables or the final soft-\nware product. They can use static, dynamic, or \nformal methods for verification and validation \n(V&V), and testing processes, as well as other \nspecialized techniques, methods, and tools to \nidentify defects that affect dependability as \nearly as possible in the software life cycle [7*, \nc10.5]. Additionally, they may have to incor-\nporate specific mechanisms into the software \nto guard against external attacks and to tol-\nerate faults during its operation. 1.4.2. Integrity Levels of Software  \n\b\n[1*, c4s4.8, c7s7.3.2] [11]\nDefining integrity levels is a method of risk \nmanagement. An integrity level is \u201ca value rep-\nresenting project-unique characteristics (e.g., \ncomplexity, criticality, risk, safety level, secu-\nrity level, desired performance, and reliability) \nthat define the importance of the system, \nsoftware, or hardware to the user\u201d [11]. The \ncharacteristics used to determine software \nintegrity level vary depending on the intended \napplication and use of the system. The soft-\nware is a part of the system, and its integrity \nlevel is determined as a part of that system. The assigned software integrity levels \nmight change as the software evolves. Design, \ncoding, procedural and technology features \nimplemented in the system or software can \nraise or lower the assigned software integrity \nlevels. The software integrity levels estab-\nlished for a project result from agreements \namong the acquirer, supplier, developer, and \nindependent assurance authorities. A software \nintegrity level scheme is used to determine soft-\nware integrity levels [11].", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 253", "position": 253, "chunk_type": "semantic", "token_estimate": 348}
{"text": "12-8   SWEBOK \u00ae GUIDE V4.0: and products development decisions as well \nas behavior of personnel. Software engineers \nshould promote the use of graphically repre-\nsented processes and procedures that imple-\nment the quality policy and explain the roles, \nactivities to be executed and the expected \nresults of key software engineering activi-\nties. Consequently, for a QMS to be used \nin improvement its processes should be doc-\numented with its user in mind and iden-\ntify where quality controls are to be verified. Finally, procedures explain in detail what \nsteps are taken to execute a specific activity. 2.3. Evaluate Quality Management\nOnce the QMS is in place, the ISO/IEC \nTechnical Specification TS 33061:2021 [23] \nStandard defines a process assessment model \nfor software life cycle processes using five pro-\ncess capabilities levels (from level 0: incomplete \nto level 5: optimizing process). Additionally, \nsoftware engineers can assess the maturity of \ntheir QMS activities in their software projects \nusing the IEEE 730:2014 Standard guidance \n[6]. Management sponsorship supports pro-\ncess and product evaluations. The evaluation \nfindings feed into an improvement program \nfor identifying detailed actions and improve-\nment projects to be addressed in a feasible \ntime frame. Periodically, the software engi-\nneers will gather and analyze quality assur-\nance evaluation results. This can be achieved \nby looking at quality measures and defect \ncharacterization produced by the projects. 2.3.1. Software Quality Measurement  \n\b\n[1*, c10] [7, c24s24.5]\nSoftware quality measurements are used \nto support decision-making. With the \nincreasing sophistication of software, quality \nquestions go beyond whether the software \nworks to how well it achieves measurable \nquality goals. Quantifying some attribute \nof software can help engineers evaluate its \nquality or the quality of its process. (Process \nmeasurement is described in detail in the \nProcess KA.) Software quality measurement helps engi-\nneers \nmake \ndeterminations \nabout \nsoft-\nware quality (because models of software \nproduct quality include measures to deter-\nmine the degree to which the software product \nachieves quality goals); managerial questions \nabout effort, cost, and schedule; when to stop \ntesting and release a product (see Test-Related \nMeasures\u00a0 in the Software Testing KA); and \nthe efficacy of process improvement efforts. The CoSQ assurance activities are an issue \nfrequently raised in deciding how a project \nor a software development and maintenance \norganization should be organized.", "domains": ["Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 255", "position": 255, "chunk_type": "semantic", "token_estimate": 376}
{"text": "12-8   SWEBOK \u00ae GUIDE V4.0: Software quality measurement helps engi-\nneers \nmake \ndeterminations \nabout \nsoft-\nware quality (because models of software \nproduct quality include measures to deter-\nmine the degree to which the software product \nachieves quality goals); managerial questions \nabout effort, cost, and schedule; when to stop \ntesting and release a product (see Test-Related \nMeasures\u00a0 in the Software Testing KA); and \nthe efficacy of process improvement efforts. The CoSQ assurance activities are an issue \nfrequently raised in deciding how a project \nor a software development and maintenance \norganization should be organized. Often, \ngeneric models of cost are used; these models \nare based on when a defect is found and how \nmuch effort it takes to fix the defect rela-\ntive to finding the defect earlier in develop-\nment. Software quality measurement data \ncollected internally may offer a better picture \nof cost within the project or organization. Although the software quality measurement \ndata may be useful by itself (e.g., the number \nof defective requirements or the proportion \nof defective requirements), mathematical \nand graphical techniques can help project \nstakeholders interpret the measures. (See \nthe Engineering Mathematical Foundations \nKA.) These techniques include the following:\n\u2022\t Descriptive statistics-based analysis (e.g., \nPareto analysis, run charts, scatter plots, \nnormal distribution);\n\u2022\t Statistical tests (e.g., the binomial test, \nchi-squared test);\n\u2022\t Trend analysis (e.g., control charts; see \nThe Quality Toolbox in Further Readings);\n\u2022\t Prediction (e.g., reliability models). Descriptive statistics-based techniques and \ntests often provide a snapshot of the more \ntroublesome areas of the software product \nunder examination. The resulting charts and \ngraphs are visualization aids decision-makers \ncan use to focus resources and conduct process \nimprovements where they seem most needed. Results from trend analysis may indicate that \na schedule is slipping or that certain classes \nof faults may become more likely unless some", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 255", "position": 255, "chunk_type": "semantic", "token_estimate": 298}
{"text": "SOFTWARE QUALITY   12-9: corrective action is taken in development. The \npredictive techniques help estimate testing \neffort and schedule and predict failures. (More \ndiscussion on measurement in general appears \nin the Software Engineering Process and \nSoftware Engineering Management KAs. More specific information on testing mea-\nsurement is presented in the Software Testing \nKA.) Software quality measurement also \nincludes measuring defect occurrences and \napplying statistical methods to understand \nwhat types of defects occur most frequently. Three widely used software quality measure-\nments are error density (number of errors per \nunit size of documents/software), defect den-\nsity (number of defects found divided by the \nsize of the software), and failure rate (mean \ntime to failure). Reliability models are built \nfrom failure data collected during software \ntesting or from software in service and thus \ncan be used to estimate the probability of \nfuture failures and assist in decisions about \nwhen to stop testing. This information can \nbe used in SPI to determine methods to pre-\nvent, reduce or eliminate defect recurrence. The information also helps engineers under-\nstand trends, how well detection and contain-\nment techniques are working, and how well \nthe development and maintenance processes \nare progressing. They can use these measure-\nment methods to develop defect profiles for \na specific application domain. Then, for the \nnext software project within that organi-\nzation, the profiles can be used to guide the \nSQM processes \u2014 that is, to focus effort \non where problems are most likely to occur. Similarly, benchmarks, or defect counts typ-\nical of that domain, may help engineers deter-\nmine when the product is ready for delivery. (Discussion about using measurement data to \nimprove development and maintenance pro-\ncesses appears in the Software Engineering \nManagement and Software Engineering \nProcess KAs.) 2.4. Perform Corrective and Preventive Actions \nIt is important that when quality manage-\nment objectives are not met, corrective actions \nbe documented and submitted so that the \nQMS be improved to prevent problem from \nreoccurring in future software projects. This \nrequires that project participants have a way \nof reporting software engineering process \nand tools problems to an independent orga-\nnization that will document and monitor the \nprogress of the corrective actions and inform \nthe relevant stakeholders. 2.4.1.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 256", "position": 256, "chunk_type": "semantic", "token_estimate": 366}
{"text": "12-10   SWEBOK \u00ae GUIDE V4.0: may provide defect trends reports that can be \nprovided to the organization\u2019s management. 3. Software Quality Assurance Process\n3.1. Prepare for Quality Assurance  \n\b\n[1*, c1s1.5, c4s4.6]  [6]\nSoftware quality assurance (SQA) is defined as \n\u201ca set of activities that define and assess the \nadequacy of software processes to provide evi-\ndence that establishes confidence that the soft-\nware processes are appropriate for and produce \nsoftware products of suitable quality for their \nintended purposes.\u201d To correct a common \nmisunderstanding, SQA is not only testing of \na software. A key attribute of SQA, in critical \nsystems, is the objectivity of the SQA function \nconcerning the quality of a software product. In this case, the SQA function might also be \norganizationally independent of the project; \nthat is, free from technical, managerial, and \nfinancial pressures [6]. SQA has two aspects: \nproduct assurance and process assurance, \nwhich are introduced in Section 2.3. The software quality plan (in some industry \nsectors, it is termed the software quality \nassurance plan (SQAP)) defines the activities \nand tasks used to ensure that software devel-\noped for a specific product satisfies the proj-\nect\u2019s established requirements and user needs \nwithin project cost and schedule constraints \nand is commensurate with project risks. The \nSQAP first ensures that quality targets are \nclearly defined and understood. The SQAP\u2019s quality activities and tasks \nare specified, along with their costs, resource \nrequirements, objectives, and schedule in \nrelation to related objectives, in the software \nengineering management, software develop-\nment and software maintenance plans. The \nSQAP identifies documents, standards, prac-\ntices, and conventions governing the project \nand how these items are checked and mon-\nitored to ensure adequacy and compliance. The SQAP also identifies measures; statistical \ntechniques; procedures for problem reporting \nand corrective action; resources such as tools, \ntechniques, and methodologies; security for \nphysical media; training; and SQA reporting \nand documentation. Moreover, the SQAP \naddresses the SQA activities of any other type \nof activity described in the software plans \u2014 \nsuch as procurement of supplier software for \nthe project, commercial off-the-shelf (COTS) \nsoftware installation and service after soft-\nware delivery. It can also contain acceptance \ncriteria and reporting and management activ-\nities that are critical to software quality. The \nSQA plan should not conflict with the soft-\nware configuration management plan or any \nother relevant project plannning artifact.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 257", "position": 257, "chunk_type": "semantic", "token_estimate": 387}
{"text": "SOFTWARE QUALITY   12-11: They include quality require-\nments (called Quality of Service Constraints in \nthe Software Requirements KA) and func-\ntional requirements. Thus, software engineers \nare responsible for eliciting quality require-\nments that might not be explicit at the outset \nand for understanding their importance and \nthe difficulty in defining them, measuring \nthem, and establishing them for final accep-\ntance. Software engineers should understand \nhow to define quality requirements as well as \ntheir quality targets to ensure they can effec-\ntively be measured at the acceptance stage \nof the project. During the project planning, \nsoftware engineers must keep these quality \nrequirements in mind. They must also antici-\npate potential additional development costs if \nattributes such as safety, security and depend-\nability are important. An international standard on what con-\nstitutes a software product\u2019s many measur-\nable quality characteristics was reached and \nis described in ISO/IEC 25010:2011 [4]. This \nstandard proposes several software product \nquality models, consisting of characteristics \nand sub-characteristics, for software product \nquality and software quality in use. Another \nis IEEE 982.1:2005 Standard Dictionary \nof Measures to Produce Reliable Software. These software characteristics are commonly \ncalled product quality requirements, which are \nnonfunctional software requirements [7*, \nc4,s4.6.1.2]. Software engineers should know \nthe many software characteristics that can be \nplanned, implemented, and measured during \nsoftware construction (e.g., functional suit-\nability, performance efficiency, compatibility, \nusability, reliability, security, maintainability, \nand portability). Software engineers should \nalso know that certain quality characteris-\ntics have conflicting impacts. For example, \ntrying to augment the security characteristic \nby encrypting data might adversely affect the", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 258", "position": 258, "chunk_type": "semantic", "token_estimate": 256}
{"text": "12-12   SWEBOK \u00ae GUIDE V4.0: performance characteristic. This international \nstandard also proposes a general data quality \nmodel that focuses on data quality as part of \na computer system and defines quality char-\nacteristics for target data used by humans \nand systems. Another software product quality perspec-\ntive is the quality of work products. The term \nwork product means any artifact resulting from \na process used to create the final software \nproduct. Work products include system/sub-\nsystem specifications, software requirements \nspecifications for a system\u2019s software compo-\nnents, software design descriptions, source \ncode, software test documentation and test \nreports. Sound engineering practice requires \nthat intermediate work products relevant to \nquality be evaluated using work product reviews \nand inspections (discussed later in this chapter) \nthroughout the software engineering process. 3.4. V&V and Testing \b\n[1*, c7] [11]\nVerification ensures that the product is built \ncorrectly in that the output products of a life \ncycle phase meet the specifications imposed \non them in previous phases. Verification is \ndefined as \u201cthe process of evaluating a system \nor component to determine whether the prod-\nucts of a given development phase satisfy the \nconditions imposed at the start of that phase\u201d \n[11]. Alternatively, validation ensures that the \nright product is built \u2014 the product fulfills its \nspecific intended purpose. It is defined as \u201cthe \nprocess of evaluating a system or component \nduring or at the end of the development pro-\ncess to determine whether it satisfies specified \nrequirements.\u201d\nThe purpose of V&V is to help the devel-\nopment organization build quality into the \nsoftware throughout the development life \ncycle. V&V includes software testing tasks. Software testing is a necessary activity to \nensure product quality. However, in most \ncases, software testing is insufficient to \nestablish confidence that the software fits \nits intended use. V&V tasks listed in IEEE \nStandard 1012:2016 [11] objectively assess \nproducts and processes throughout the life \ncycle. This assessment demonstrates whether \nthe requirements are correct, complete, accu-\nrate, consistent, and testable. The verifica-\ntion process and the validation process should \nbegin early in development or maintenance. This prevents defects late in the life cycle, \nwhich would incur rework and significantly \nincrease costs. Software engineers should \nidentify the product integrity level and ensure \nthe minimum V&V tasks are assigned for key \nproduct features concerning both the product\u2019s \nimmediate predecessor and the planned spec-\nifications. Optional V&V tasks are also listed \nand can improve software product quality.", "domains": ["Software Quality Attributes", "Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 259", "position": 259, "chunk_type": "semantic", "token_estimate": 400}
{"text": "12-12   SWEBOK \u00ae GUIDE V4.0: Software engineers should \nidentify the product integrity level and ensure \nthe minimum V&V tasks are assigned for key \nproduct features concerning both the product\u2019s \nimmediate predecessor and the planned spec-\nifications. Optional V&V tasks are also listed \nand can improve software product quality. Keeping a record of the traceability among \nsoftware work products can help augment \nthe quality of the V&V activities. Traceability \nis defined as the \u201cability to trace the history, \napplication or location of an object\u201d [14]. Early planning of V&V activities ensures \nthat each resource, role, and responsibility \nis clearly assigned. The resulting V&V plan \ndocuments the various resources and their \nroles and SQA activities, as well as the \ntechniques and tools to be used. Software \nengineers should choose and apply the \nproper V&V task depending on the soft-\nware integrity level. (Refer to Section 1.4.2) \nV&V can also be executed by an indepen-\ndent organization for very critical software. Independent verification and validation \n(IV&V) are defined as \u201cV&V performed by \nan organization that is technically, mana-\ngerially, and financially independent of the \ndevelopment organization\u201d [11]. Software V&V tasks can be sorted into \nstatic, dynamic and formal tasks [20]. Dynamic techniques involve executing the \nsoftware; static techniques involve analyzing \ndocuments and source code but not executing \nthe software; formal techniques use mathe-\nmatics and formal specification languages. It should be noted that there are no strong \nboundaries between \"Static analysis tech-\nniques\", \"Dynamic analysis techniques\" and \n\"Formal analysis techniques\". For example, \nstatic and dynamic analysis techniques usu-\nally have a strong formal background such as \ndata-flow analysis or model checking.", "domains": ["Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 259", "position": 259, "chunk_type": "semantic", "token_estimate": 268}
{"text": "SOFTWARE QUALITY   12-13: 3.4.1. Static Analysis Techniques\nStatic analysis techniques directly ana-\nlyze a work product\u2019s content and structure \n(including requirements, interface specifica-\ntions, designs, and models) without executing \nthe software. The only way to detect non-ex-\necutable code is through static analysis as no \ndynamic test can verify that. Static techniques \ncan be executed manually or with the help of a \ntool. Tools and techniques for statically exam-\nining software work can help software engi-\nneers in this task. For example, code reading, \npeer review of a work product, and static anal-\nysis of source code control flow are considered \nstatic techniques because they do not involve \nexecuting the software code. We will see, in section 3.4.5 that review \nand audit processes are consideredstatic anal-\nysis activities, meaning that no software or \nmodels are executed. Instead, they examine \nsoftware engineering artifacts (also called \nintermediary or work products) concerning \nstandards established by the organization or \nproject for those artifacts. 3.4.2. Dynamic Analysis Techniques\nDynamic analysis techniques involve exe-\ncuting or simulating the software code, looking \nfor errors and defects. Different dynamic \ntechniques are performed throughout soft-\nware development, maintenance, and opera-\ntion. Generally, these are testing techniques, \nbut simulation, model analysis and model \nchecking are considered dynamic analysis \ntechniques. (See the Software Engineering \nModels and Methods KA.) \u201cIn addition, black \nbox testing is considered a dynamic analysis \ntechnique, as the software engineer analyzes \nthe output received following the entry of \ninputs.\u201d (See the Software Testing KA.) 3.4.3. Formal Analysis Techniques\n\b\n[7*, c10s10.5]\nFormal analysis techniques (also called formal \nmethods) are \u201cmathematical approaches to \nsoftware development where you define a \nformal model of the software. You may then \nformally analyze this model to search for \nerrors and inconsistencies\u201d [7*, c10s10.5]. Sometimes, the software requirements may \nbe written using a more formal specification \nlanguage known as formal methods. They are \nnotably used to verify software requirements \nand designs. They have mostly been used to \nverify crucial parts of critical systems, such \nas specific security and safety requirements. (See also Formal Methods in the Software \nEngineering Models and Methods KA.) Different groups may perform testing during \nsoftware development, including groups \nindependent of the development team. The \nSoftware Testing KA is devoted entirely to \nthis subject. 3.4.4. Software Quality Control and Testing  \n\b\n[1*, c7s7.10]\nTesting is considered an important product \nquality control activity part of a soft-\nware development project\u2019s V&V processes.", "domains": ["Software Quality Attributes", "Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 260", "position": 260, "chunk_type": "semantic", "token_estimate": 400}
{"text": "12-14   SWEBOK \u00ae GUIDE V4.0: 3.4.5. Technical Reviews and Audits  \n\b\n[1*, c5, c6] [23, s4, s5]\nWe have seen SQC techniques for assessing \nthe quality of the software in section 2.4.1. For the other artefacts, product quality con-\ntrol is assessed using reviews and inspections \nof these work products. These SQC activities \nare planned and executed during develop-\nment, maintenance, and operations activities \n[17]. Peer reviews are defined as \u201cthe review \nof work products performed by peers during \ndevelopment of the work products to identify \ndefects for removal\u201d [14]. For example, during \nsoftware development, a code review (often \ndone by using a pull request technique/tool) \noccurs when a peer reviews the code, often at \nthe software developer\u2019s request, before it can \nbe merged into a project. Reviews are valuable because they can iden-\ntify issues early in development or even before \na component is designed. Fixing a defect in a \ncomponent that has been coded is much more \nexpensive than catching it beforehand. Different types of work product reviews (e.g., \nformal, and informal) are distinguished by pur-\npose, level of independence, tools and tech-\nniques used, roles involved, and by the subject \nof the activity. Reviews play important roles in \nsoftware quality, in SCM, and in the sharing \nof knowledge among colleagues. However, \nthese different roles share a single purpose \u2014 \nto ensure the quality of the delivered products. Reviews should be part of the software engi-\nneering culture and should be planned, exe-\ncuted, and documented during the software life \ncycle. In Agile life cycles, pair programming \ninvites continuous reviews. Different review \ntypes for work products are described in the \nISO/IEC 20246:2017 Standard [12]: \n\u2022\t Ad hoc reviews \u2014 unstructured reviews \nwhere each reviewer is expected to find as \nmany defects as possible of any type; \n\u2022\t Checklist-based reviews \u2014 system-\natic reviews identifying issues based on \nchecklists; \n\u2022\t Scenario-based reviews \u2014 reviews where \nreviewers are provided with structured \nguidelines on how to read through the \nwork product under review; \n\u2022\t Perspective-based reviews \u2014 reviews \nwhere reviewers take on different stake-\nholder viewpoints and review the work \nproduct from that stakeholder\u2019s view-\npoint; and \n\u2022\t Role-based reviews \u2014 reviews in which \nthe reviewer evaluates the work product \nfrom the perspective of various stake-\nholder roles, which might differ from \ntheir daily role. Audits are more formal activities that are \noften mandated to be performed by third \nparties to ensure independence.", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 261", "position": 261, "chunk_type": "semantic", "token_estimate": 402}
{"text": "12-14   SWEBOK \u00ae GUIDE V4.0: Different review \ntypes for work products are described in the \nISO/IEC 20246:2017 Standard [12]: \n\u2022\t Ad hoc reviews \u2014 unstructured reviews \nwhere each reviewer is expected to find as \nmany defects as possible of any type; \n\u2022\t Checklist-based reviews \u2014 system-\natic reviews identifying issues based on \nchecklists; \n\u2022\t Scenario-based reviews \u2014 reviews where \nreviewers are provided with structured \nguidelines on how to read through the \nwork product under review; \n\u2022\t Perspective-based reviews \u2014 reviews \nwhere reviewers take on different stake-\nholder viewpoints and review the work \nproduct from that stakeholder\u2019s view-\npoint; and \n\u2022\t Role-based reviews \u2014 reviews in which \nthe reviewer evaluates the work product \nfrom the perspective of various stake-\nholder roles, which might differ from \ntheir daily role. Audits are more formal activities that are \noften mandated to be performed by third \nparties to ensure independence. In mature \norganizations, technical reviews and audits \nare fully integrated with the overall project \nplans. Therefore, technical reviews and audits \nshould be planned, approved, and conducted. Although a project audit often addresses the \nwhole project\u2019s current state, technical reviews \ncan also be more focused and address a spe-\ncific project phase [24]. System requirements \nreviews help ensure that the level of under-\nstanding of top-level system requirements is \nadequate to support further requirements anal-\nysis and design activities and that the system \ncan proceed into initial system design with \nacceptable risk; System functional or pre-\nliminary design reviews help ensure that the \nsystem under review can proceed into prelimi-\nnary or detailed design with acceptable risk and \nthat all system requirements and functional \nperformance requirements derived from the \napproved preliminary system specification are \ndefined and consistent with the project budget, \nprogram schedule, risk, and other program and \nsystem constraints; Preliminary design reviews \nhelp ensure that the preliminary design for \nthe system under review is sufficiently mature \nand ready to proceed into detailed design and \ncan meet the stated performance requirements \nwithin program budget, schedule, risk and \nother program and system constraints; Test \nreadiness reviews assess test objectives, test \nmethods and procedures, test scope, safety, \nreadiness for the project test and evaluation, \nand whether test resources have been properly", "domains": ["Design Patterns", "Software Quality Attributes", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 261", "position": 261, "chunk_type": "semantic", "token_estimate": 363}
{"text": "12-18   SWEBOK \u00ae GUIDE V4.0: and Computers, Addison-Wesley \nProfessional, 1995. [16]\t T. Gilb and D. Graham, Software \nInspection, Addison-Wesley \nProfessional, 1993. [17*]\tK. Wiegers, Peer Reviews in Software: \nA Practical Guide, Addison-Wesley \nProfessional, 2001. [18]\t BS EN 50128:2011+A2:2020, \n\u201cStandard for Railway Applications \n\u2013 Communications, Signaling and \nProcessing Systems \u2013 Software for \nRailway Control and Protection \nSystems,\u201d British-Adopted European \nStandard, 10 August 2020. [19]\t K. Iberle, They don\u2019t care about quality, \nproceedings of STAR East, Orlando, \nUnited States, 2013, available at \nhttps://kiberle.com/publications/. [20]\t D. Wallace, L. M. Ippolito, and \nB.B. Cuthill, Reference Information \nfor the Software Verification and \nValidation Process, National Institute \nof Standards and Technology \n(NIST), U.D. Department of \nCommerce, Special Publication \n500-234, 1996. [21]\t IEC 60300-1:2014, \u201cDependability \nManagement \u2014 Part 1: Guidance for \nManagement and Application,\u201d version \n3, 25 September 2014. [22]\t D. Leffingwell, Safe 4.5 Reference \nGuide: Scaled Agile Framework For \nLean Enterprises, 2nd ed., New-York, \nAddison-Wesley, 2018. [23]\t ISO/IEC TS 33061:2021, \n\u201cInformation technology \u2014 Process \nassessment \u2014 Process Assessment \nModel for Software Life Cycle \nProcesses,\u201d 2021-04. [24]\t IEEE Std 15288.2:2014, \u201cIEEE \nStandard for Technical Reviews and \nAudits on Defense Programs.\u201d\n[25]\t A guide to the Project management \nBody of Knowledge, 7th edition, PMI, \n2021, 368p. [26]\t ISO/IEC/IEEE 90003:2018, \n\u201cGuidelines for the application of \nISO 9001:2015 to computer soft-\nware\u201d, 2018-11. [27]\t COBIT, \u201cControl Objectives for \nInformation Technology\u201d, version \n2019, ISACA and the IT Governance \nInstitute. [28]\t BABOK, \u201cA guide to the Business \nAnalysis Body of Knowledge\u201d, version \n3, International Institute of Business \nAnalysis, 04-2015. [29]\t CMMI, \u201cCapability Maturity Model \nIntegration\u201d, version 10, ISACA, 2023. [30]\t TOGAF, \u201cOpen Group Architecture \nFramework\u201d, version 10, 04-2022. [31]\t ISO/IEC 27001:2022, \u201cInformation \nsecurity, cybersecurity, and pri-\nvacy protection  Information \nsecurity \u2014management systems \u2014 \nRequirements\u201d, 10-2022.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 265", "position": 265, "chunk_type": "semantic", "token_estimate": 283}
{"text": "Section: Software Security", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 266", "position": 266, "chunk_type": "semantic", "token_estimate": 3}
{"text": "Security has become a significant issue in soft-: ware development because of potential misuse \nand increasing malicious activity targeting \ncomputer systems. In addition to the usual \ncorrectness and reliability concerns, software \ndevelopers must pay attention to the security \nof the software they develop. Secure software \ndevelopment builds security by following \na set of established and/or recommended \nrules and practices. Secure software mainte-\nnance complements secure software develop-\nment by ensuring that no security problems \nare introduced during software maintenance \nand that identified vulnerabilities, which are \nerrors that attackers can exploit, can be han-\ndled during the software life cycle. Security \nvulnerabilities are not only introduced at the \ndevelopment, but also by third party compo-\nnents such as libraries, COTS, or OS.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 266", "position": 266, "chunk_type": "semantic", "token_estimate": 121}
{"text": "The breakdown of topics for the Software: Security knowledge area (KA) is shown in \nFigure 13.1. 1. Software Security Fundamentals \b [37, 9]\nA generally accepted belief about software \nsecurity is that it is much better to design \nsecurity into software than to patch it in after \nthe software is developed. To design secu-\nrity into software, one must consider every \ndevelopment life cycle stage. Secure software \ndevelopment involves software requirements \nsecurity, software design security, software \nconstruction security and software testing \nsecurity. In addition, security must be consid-\nered during software maintenance, as secu-\nrity faults and loopholes can be and often are \nintroduced during maintenance. 1.1. Software Security \b\n[10*]\nSecurity is a product quality characteristic \nrepresenting the degree to which a product or \nsystem protects information and data so that \npersons or other products or systems have data \naccess appropriate to their types and levels of \nauthorization [10]. (For more information \nabout product quality, refer to the Software \nQuality KA.) 1.2. Information Security \b\n[11*]\nInformation security preserves confidenti-\nality, integrity and availability of informa-\ntion. Other properties, such as authenticity, \naccountability, non-repudiation and reliability \ncan also be involved [11]. Confidentiality is \nthe property of ensuring that information is \nnot disclosed to unauthorized individuals, \nentities or processes. Integrity is the property \nof accuracy and completeness. Availability \nis the property of being accessible and \nusable on demand by an authorized entity. Software engineers should define the secu-\nrity properties of their software and maintain \nthem throughout the software development \nlife cycle.", "domains": ["Software Quality Attributes", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 266", "position": 266, "chunk_type": "semantic", "token_estimate": 252}
{"text": "13-2   SWEBOK \u00ae GUIDE V4.0: 1.3. Cybersecurity \b\n[12*][38]\nCybersecurity is safeguarding of people, \nsociety, organizations and nations from cyber \nrisks. Safeguarding means to keep cyber risk \nat a tolerable level. Generally, cybersecurity addresses secu-\nrity issues in cyberspace, including the \nfollowing:\n\u2022\t Social engineering attacks\n\u2022\t Hacking\n\u2022\t The proliferation of malicious soft-\nware (malware)\n\u2022\t Spyware\n\u2022\t Other potentially unwanted software [12]\nSoftware engineers should consider the \nmitigation of such threats as part of software \ndevelopment. 2. Security Management and Organization \n\b\n[1*, c7][13]\nSecurity governance and management are \nmost effective when they are systematic; in \nother words, when they are woven into the \nculture and fabric of organizational behaviors \nand actions. Project managers need to elevate \nsoftware security from a stand-alone tech-\nnical concern to an enterprise issue [1]. 2.1. Capability Maturity Model  \n\b\n[3*, c22][14]\nMany organizations practice security engi-\nneering in the development of computer pro-\ngrams, including operating systems, functions \nthat manage and enforce security, packaged \nsoftware products, middleware, and applica-\ntions. Therefore, a diverse array of individuals \nmust know how to apply appropriate methods \nand practices, including product developers, \nservice providers, system integrators, system \nadministrators and even security specialists. Systems Security Engineering \u2014 Capability \nMaturity Model (SSE-CMM), which helps \nmeasure the process capability of an organi-\nzation that performs risk assessments [14], can \nbe an important tool. 2.2. Information Security Management System  \n\b\n[15*]\nInternational Organization of Standardization/\nInternational Electrotechnical Commission \n(ISO/IEC) 27001:2022 specifies the require-\nments for establishing, implementing, main-\ntaining \nand \ncontinually \nimproving \nan \ninformation security management system \n(ISMS) within the organizational context \n[15]. ISMS is a documented plan for man-\naging the technology-related security of an \nSoftware Security\nSoftware Security\nFundamentals\nSoftware Security\nEngineering \nand Process\nSoftware \nEngineering for \nSoftware Systems\nDomain Speci\ufb01c\nSoftware Security\nSoftware Security\nInformation \nSecurity\nCybersecurity\nSecurity \nEngineering \nand Development\nLifecycle\nCommon Criteria \nfor Information \nTechnology \nSecurity Evaluation\nSecurity\nRequirements\nSecurity Design\nSecurity Patterns\nConstruction \nfor Security\nSecurity Testing\nVulnerability\nManagement\nSoftware Security\nTools\nSecurity \nVulnerability\nChecking Tools\nPenetration\nTesting Tools\nSecurity for\nContainer \nand Cloud\nSecurity for\nIoT Software\nSecurity for\nMachine \nLearning-Based\nApplication\nSecurity \nManagement and \nOrganization\nCapability \nMaturity Model\nInformation \nSecurity\nManagement \nSystem\nAgile Practice\nfor Software Security\nFigure 13.1. The Breakdown of Topics for the Software Security KA", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 267", "position": 267, "chunk_type": "semantic", "token_estimate": 376}
{"text": "SOFTWARE SECURITY   13-3: organization. This includes documenting risks \nand taking measures to address them, aiming \nto protect the organization\u2019s data and prevent \nsecurity breaches [15]. Organization should \nuse it to continually conduct risk assess-\nments to identify security risks and vulnera-\nbilities and implement protective measures by \ndeploying an IT team to monitor these risks. An ISMS can thus also raise new or changed \nexisting software security requirements. In \naddition,  software security requirements are \nderived from laws, regulations and obligations \nfor compliance. 2.3. Agile Practice for Software Security  \n\b\n[4*,c15,c16]\nAgile teams need to understand and adopt \nsecurity practices and take more responsibility \nfor their systems\u2019 security. Security profes-\nsionals must learn to accept change, work faster \nand more iteratively, and think about security \nrisks and how to manage risks in incremental \nterms. Finally, and most important, secu-\nrity needs to become an enabler instead of a \nblocker. The keys to a successful Agile security \nprogram are the involvement of the security \nteam and developers, enablement, automation, \nand agility to keep up with Agile teams [4]. 3. Software Security Engineering and \nProcesses\n3.1. Security Engineering and Secure \nDevelopment Life Cycle (SDLC)  \n\b\n[1*, c1][16*][36]\nSoftware is only as secure as its development \nprocess. Security must be built into software \nengineering to ensure software security. The \nSDLC concept is one trend that aims to do \nthis. SDLC uses a classical spiral model that \nviews security holistically from the perspective \nof the software life cycle and ensures that secu-\nrity is inherent in software design and develop-\nment, not an afterthought later in production. The SDLC process is claimed to reduce soft-\nware maintenance costs and increase software \nreliability against security-related faults. Recently, DevSecOps (meaning the integra-\ntion of development, security and operations) \nhas emerged. Beyond SDLC, DevSecOps \nincludes an approach to culture, automation \nand platform design to make the software life \ncycle as Agile and responsible as Agile devel-\nopment and continuous integration (CI). 3.2. Common Criteria for Information \nTechnology Security Evaluation  \n\b\n[3*, c22, c25][34][35]\nSecurity evaluation establishes confidence in \nthe security functionality of IT products and \nthe assurance measures applied to them. The \nevaluation results may help consumers deter-\nmine whether IT products meet their secu-\nrity needs or standards conformity. ISO/\nIEC 15408:2022, named Common Criteria \n(CC) for Information Technology Security \nEvaluation, is useful as a guide for developing, \nevaluating and/or procuring IT products with \nsecurity functionality [34].", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 268", "position": 268, "chunk_type": "semantic", "token_estimate": 400}
{"text": "SOFTWARE SECURITY   13-3: The \nevaluation results may help consumers deter-\nmine whether IT products meet their secu-\nrity needs or standards conformity. ISO/\nIEC 15408:2022, named Common Criteria \n(CC) for Information Technology Security \nEvaluation, is useful as a guide for developing, \nevaluating and/or procuring IT products with \nsecurity functionality [34]. CC addresses the protection of assets from \nunauthorized disclosure, modification or loss \nof use. The categories of protection relating \nto these three types of security failure are \ncommonly called confidentiality, integrity and \navailability, respectively. 4. Security Engineering for Software \nSystems \b\n[1*,c1,c3][3*,c1,c3]\n4.1. Security Requirements  \n\b\n[1*,c3][2*,c2][3*,c20,c30][18]\nSecurity requirements engineering includes \nelicitation, specification, and prioritization. It \nconsiders threats, as illustrated by misuse and \nabuse cases, threat actors, security risk assess-\nments, selection and application of speci-\nfication methods, prioritization methods, \ninspections, and revisions. Selection of life-\ncycle models may impact the order of activities, \nand software product revision implies a need \nto revisit security requirements. Traceability \nof security requirements throughout the \ndevelopment process is important, and secu-\nrity teams may include specialist in security", "domains": ["Software Quality Attributes", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 268", "position": 268, "chunk_type": "semantic", "token_estimate": 174}
{"text": "13-4   SWEBOK \u00ae GUIDE V4.0: requirements. Numerous methods and tools \nexist in support of security requirements \nengineering. 4.2. Security Design  \n\b\n[1*,c4][2*,c5][3*,c20,c31][17,40]\nSecurity design concerns how to prevent \nunauthorized disclosure, creation, change, \ndeletion or denial of access to informa-\ntion and other resources. It also concerns \nhow to tolerate security-related attacks or \nviolations by limiting damage, continuing \nservice, speeding repair and recovery, and \nfailing and recovering securely. Access con-\ntrol is a fundamental concept of security. Most controls build on cryptographic algo-\nrithms and cryptographic material like keys. It is important to carefully select these and \nhow crypto material is created, distributed \nand managed. Software design security deals with the \ndesign of software modules that fit together \nto meet the security objectives specified in \nthe security requirements. To meet secu-\nrity requirements, developers conduct threat \nmodeling, illustrating how a system is being \nattacked to specify a security design for the \nmitigation. This step clarifies the details of \nsecurity considerations and develops the spe-\ncific steps for implementation. Factors con-\nsidered may include frameworks and access \nmodes that set up the overall security mon-\nitoring/enforcement strategies, as well as the \nindividual policy enforcement mechanisms. 4.3. Security Patterns \b\n[1*,c4][19, 20, 21]\nA security pattern describes a particular recur-\nring security problem that arises in a specific \ncontext and presents a well-proven generic \nsolution [21]. 4.4. Construction for Security  \n\b\n[1*,c5][3*,c20,c31][22, 23, 24]\nSoftware construction security concerns how \nto write programming code for specific sit-\nuations to address security considerations. The term software construction security can \nmean different things to different people. It \ncan mean the way a specific function is coded \nso that the code itself is secure, or it can \nmean the coding of security into software. Unfortunately, most people entangle the two \nmeanings without distinction. One reason \nfor such confusion is that it is unclear how to \nensure a specific coding is secure. For example, \nin the C programming language, the expres-\nsions \u201ci<<1\u201d (shift the binary representation of \ni\u2019s value to the left by one bit) and \u201c2*\u201d (mul-\ntiply the value of variable i by constant 2) mean \nthe same thing semantically, but do they have \nthe same security ramifications? The answer could be different for different \ncombinations of ISAs and compilers. Because \nof this lack of understanding, software con-\nstruction security \u2014 in its current state \u2014 \nmostly refers to the second aspect mentioned \nabove: the coding of security into software.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 269", "position": 269, "chunk_type": "semantic", "token_estimate": 405}
{"text": "13-4   SWEBOK \u00ae GUIDE V4.0: The answer could be different for different \ncombinations of ISAs and compilers. Because \nof this lack of understanding, software con-\nstruction security \u2014 in its current state \u2014 \nmostly refers to the second aspect mentioned \nabove: the coding of security into software. Coding of security into the software can be \nachieved by following recommended rules. A \nfew such rules follow:\n\u2022\t Structure the process so that all sec-\ntions requiring extra privileges are mod-\nules. The modules should be as small as \npossible and perform only the tasks that \nrequire those privileges. \u2022\t Ensure that any assumptions in the pro-\ngram are validated. If this is not possible, \ndocument them for the installers and \nmaintainers so they know the assump-\ntions attackers will try to invalidate. \u2022\t Ensure that the program does not \nshare objects in memory with any \nother program. \u2022\t Check every function\u2019s error status. Do \nnot recover unless neither the error\u2019s \ncause nor its effects affect any secu-\nrity considerations. The program should \nrestore the state of the software to the \nstate it had before the process began and \nthen terminate. Although there are no bulletproof ways to \nachieve secure software development, some \ngeneral guidelines exist that can be helpful.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 269", "position": 269, "chunk_type": "semantic", "token_estimate": 208}
{"text": "SOFTWARE SECURITY   13-5: These guidelines span every phase of the soft-\nware development life cycle. The Computer \nEmergency Response Team (CERT) pub-\nlishes reputable guidelines, and the following \nare its top 10 software security practices (the \ndetails can be found in [22]):\n1. Validate input. 2. Heed compiler warnings. 3. Architect and design for security policies. 4. Keep it simple. 5. Default deny. 6. Adhere to the principle of least privilege. 7. Sanitize data sent to other software. 8. Practice defense in depth. 9. Use effective quality assurance techniques. 10. Adopt a software construction secu-\nrity standard. 4.5. Security Testing  \n\b\n[1*,c5][2*,c7][3*,c24,c31][26, 27]\nSecurity testing ensures that the implemented \nsoftware meets the security requirements. It \nalso verifies that the software implementation \ncontains none of the known vulnerabilities. Whereas general software testing methods \ncan handle the former, the latter requires \nsecurity-specific testing methods. (For more \ninformation about testing, please refer to the \nSoftware Testing KA.) There are two general approaches to \nsecurity-specific testing. The first approach \nincludes detecting vulnerabilities through \nstatic analysis, which can be conducted on \nthe source code or compiled binaries. A static \nanalysis on the source code can be used to \ndetect programming language or implemen-\ntation-specific vulnerabilities, while static \nanalysis on compiled binaries can be used to \ndetect vulnerabilities that are not apparent \nin the source code due to compiler optimi-\nzations or hidden in the compiled third-\nparty components. Static analysis can be \nautomated using tools, however while auto-\nmation can play a significant role, the exper-\ntise of security professionals are required to \nproperly operate and configure the tools, and \nverify the results. The other approach to detect vulnera-\nbilities is through dynamic testing, typi-\ncally using techniques such as vulnerability \nassessment or penetration testing (also \nknown as the ethical hacking test), to detect \nvulnerabilities in software behavior. Like \nstatic analysis, there are tools that can auto-\nmate dynamic testing, such as web appli-\ncation scanners and fuzzing tools. Security \nexperts skilled in the application domain \nshould be engaged to perform these tests, \nand such tests should always be conducted \nwithin legal boundaries and with proper \nauthorization. The latter aspects are cru-\ncial to differentiate such tests from illegal \nhacking activities. 4.6. Vulnerability Management  \n\b\n[1*,c5][3*,c24][28,29, 30]\nUsing sound coding practices can help sub-\nstantially reduce software defects commonly \nintroduced during implementation [1].", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 270", "position": 270, "chunk_type": "semantic", "token_estimate": 388}
{"text": "SOFTWARE SECURITY   13-5: 4.6. Vulnerability Management  \n\b\n[1*,c5][3*,c24][28,29, 30]\nUsing sound coding practices can help sub-\nstantially reduce software defects commonly \nintroduced during implementation [1]. Such \ncommon security defects are categorized \nand shared with databases: the Common \nVulnerabilities and Exposures (CVE) [28], \nCommon Weakness Enumeration (CWE) [29], \nand Common Attack Pattern Enumeration \nand Classification (CAPEC) [30]; Common \nVulnerability Scoring System (CVSS) [41] \nexpresses characteristics and severity of soft-\nware vulnerabilities. Programmers can refer to \nthese databases for security implementation, \nand some tools are available to check common \nvulnerabilities in codes. Security maintenance \nencompasses the task to mitigate effects of vul-\nnerabilities in a system and third party com-\nponents which the system uses. The task often \ncomes with a vulnerability disclosure pro-\ncess that allows to report the identification of \nvulnerabilities. 5. Software Security Tools\n5.1. Security Vulnerability Checking Tools \n\b\n[1*,c6][25]\nSecurity vulnerability checking tools, such \nas source code analyzers and binary analysis", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 270", "position": 270, "chunk_type": "semantic", "token_estimate": 154}
{"text": "13-6   SWEBOK \u00ae GUIDE V4.0: tools, can be used to identify potential secu-\nrity vulnerabilities and issues. Source code \nanalyzers scrutinize code to detect secu-\nrity vulnerabilities, such as injection flaws, \nbuffer overflows, and insecure library use. They are useful at finding vulnerabilities \nthat can be identified through code pat-\nterns and logical flaws. Binary analysis \ntools, on the other hand, examine compiled \ncode, including third-party libraries, for \nvulnerabilities that might not be apparent \nin the source code or that arise from the \ncompilation process. While these tools sig-\nnificantly aid in detecting vulnerabilities, \nthey cannot find all vulnerabilities. For \nexample, they might not capture vulner-\nabilities that manifest in hard-to-produce \nsoftware states or that crop up in unusual \ncircumstances [1]. 5.2. Penetration Testing Tools \b\n[2*,c4]\nPenetration testing tools can be used to eval-\nuate a system\u2019s security in its operational \nenvironment. These tools perform controlled \nattacks on the system to uncover vulnerabili-\nties and security weaknesses, using techniques \nsuch as fuzzing [2], where malformed, mali-\ncious, or random data is submitted to the sys-\ntem\u2019s various entry points to detect faults. The \nuse of penetration testing tools to expose vul-\nnerabilities provide insights into how an actual \nattacker could exploit the system. 6. Domain-Specific Software Security\n6.1. Security for Container and Cloud \b\n[31]\nCloud infrastructure and services are often \ninexpensive and easy to provision, which can \nquickly lead to having many assets strewn all \nover the world and forgotten. These forgotten \nassets are like a ticking time bomb, waiting to \nexplode into a security incident [31]. One important difference with cloud envi-\nronments is that physical assets and protection \nare generally not a concern. Developers can \ngleefully outsource asset tags, anti-tailgating, \nslab-to-slab barriers, placement of data center \nwindows, cameras, and other physical secu-\nrity and physical asset tracking controls [31]. 6.2. Security for IoT Software \b\n[32,33]\nAs part of today\u2019s IoT (internet of things), \nsystems are interconnected with many \nother devices, especially back-end systems \nsuffering from all the well-known secu-\nrity flaws inherent in today\u2019s business IT. Attackers gaining access to business IT plat-\nforms, for instance, by exploiting browser \nvulnerabilities, will likely also gain access \nto weakly protected IoT industrial devices. This can cause severe damage, including \nsafety incidents. Hence, the introduction \nof a massive number of end points from the \nconsumer or industrial environment cre-\nates fertile ground for the exploitation of \nweak links.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 271", "position": 271, "chunk_type": "semantic", "token_estimate": 400}
{"text": "13-6   SWEBOK \u00ae GUIDE V4.0: This can cause severe damage, including \nsafety incidents. Hence, the introduction \nof a massive number of end points from the \nconsumer or industrial environment cre-\nates fertile ground for the exploitation of \nweak links. Hardening these end points, \nsecuring device-to-device communications, \nand ensuring device and information cred-\nibility in what until now have been closed, \nhomogeneous systems present new chal-\nlenges. Comprehensive risk and threat anal-\nysis methods, as well as management tools for \nIoT platforms, are required [33]. 6.3. Security for Machine Learning-Based \nApplication \b\n[39,c8]\nAlthough machine learning techniques are \nwidely used in many systems, machine learning \npresents a specific vulnerability. Attackers \ncan change the decisions of machine learning \nmodels. There are two kinds of attacks: model \npoisoning, which attacks training data, and \nevasion, which attacks inputs to trained \nmodels [39].", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 271", "position": 271, "chunk_type": "semantic", "token_estimate": 138}
{"text": "SOFTWARE SECURITY   13-7: MATRIX OF TOPICS VS. REFERENCE MATERIAL\nTopic\n Allen et \nal. 2008 [1*]\nMcGraw \n2006 [2*] \nBishop  \n2019 [3*]\nBell  \n2017 [4*]\n1. Software Security Fundamentals\n \n \n \n1.1. Software Security\n \n \n1.2. Information Security\n \n \n1.3. Cybersecurity\n Ch. 23\n \n2. Security Management and \nOrganization\nCh. 7\n \n \n2.1. Capability Maturity Model\nCh. 22\n2.2. Information Security \nManagement System\n2.3. Agile Practice for Software Security\nCh. 15,  \nCh. 16\n3. Software Security Engineering \nand Processes\nCh. 9\n3.1. Security Engineering and Secure \nDevelopment Life Cycle \nCh. 1\nCh. 4\n3.2. Common Criteria for Information \nTechnology Security Evaluation\nCh. 22,  \nCh. 25\n4. Security Engineering for \nSoftware Systems\nCh. 1, Ch. 15, \nCh. 1, Ch. 3\n4.1. Security Requirements\nCh. 3\nCh. 2\nCh. 20,  \nCh. 31\nCh. 5,  \nCh. 8\n4.2. Security Design\nCh. 4\nCh. 5\nCh. 20,  \nCh. 31\nCh. 8\n4.3. Security Patterns\nCh. 4\n4.4. Construction for Security\nCh. 5\nCh. 20,  \nCh. 31\n\u200b\n4.5. Security Testing\nCh. 5\nCh. 24,  \nCh. 31\nCh. 10,  \nCh. 11\n4.6. Vulnerability Management\nCh. 24\n\u200b\nCh. 6\n5. Software Security Tools\n5.1. Security Vulnerability Checking Tools\nCh. 6\nCh. 6\n5.2. Penetration Testing Tools\nCh. 4\nCh. 31\nCh. 11,  \nCh. 12\n6. Domain-Specific \nSoftware Security\n6.1. Security for Container and Cloud\n6.2. Security for IoT Software\n6.3. Security for Machine Learning-Based \nApplication", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 272", "position": 272, "chunk_type": "semantic", "token_estimate": 223}
{"text": "J. Viega, Building Secure Software: How: to Avoid Security Problems the Right Way, \nAddison-Wesley, 2011. This book introduces the definition of \nSoftware Security and the activities to develop \nand maintain secure software. It includes not \nonly the software development process but \nalso the related activities such as auditing and \nthe monitoring of service. L. Kohnfelder, Designing Secure Software: A \nGuide for Developers, No Starch Press, 2021. This book describes security activities in the \nsoftware design and implementation phases, \nincluding secure programming and web secu-\nrity. It also introduces best practices for secure \nsoftware development. C.W. Axelrod, \nEngineering \nSafe \nand \nSecure Software Systems, \nArtech \nHouse \nPublishers, 2012. This book describes engineering activities to \nmake software systems safe and secure from a \nrisk management viewpoint. It introduces risk \nassessment and mitigation methods for secu-\nrity and safety.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 273", "position": 273, "chunk_type": "semantic", "token_estimate": 135}
{"text": "[1*]\t J.H. Allen, S.J. Barnum, R.J. Ellison,: G. McGraw, and N.R. Mead, Software \nSecurity Engineering: A Guide for \nProject Managers, Addison-Wesley \nProfessional, 2008. [2*]\t G. McGraw, Software Security: \nBuilding Security In, Addison-Wesley \nProfessional, 2006. [3*]\t M. Bishop, Computer Security, \n2nd Edition, Addison-Wesley \nProfessional, 2019. [4*]\t L. Bell, M. Brunton-Spall, R. Smith, \nand J. Bird, Agile Application Security, \nO\u2019Reilly, 2017. [5]\t\nT. Hsiang-Chih Hsu, Hands-On \nSecurity in DevOps: Ensure continuous \nsecurity, deployment, and delivery with \nDevSecOps, Packt Publishing, 2018. [6]\t\nT. Hsiang-Chih Hsu, Practical Security \nAutomation and Testing: Tools and \ntechniques for automated security scan-\nning and testing in DevSecOps, Packt \nPublishing, 2019. [7]\t\nG. Wilson, DevSecOps: A leader\u2019s guide \nto producing secure software without com-\npromising flow, feedback and continuous \nimprovement, Rethink Press, 2020. [8]\t\nL. Rice, Container Security: \nFundamental Technology Concepts That \nProtect Containerized Applications, \nO\u2019Reilly & Associates Inc., 2020. [9]\t\nISO/IEC/JTC1 SC27 Standards: \nTrustworthiness, Cryptography, Data \nsecurity, Cryptography, Security eval-\nuation and testing, Security control, \nIdentity management and privacy \ntechnologies. [10*]\tISO/IEC 25010:2023 Systems and \nsoftware engineering \u2014 Systems and \nsoftware Quality Requirements and \nEvaluation (SQuaRE) \u2014 Product \nquality model. [11*]\tISO/IEC 27000:2018 Information \ntechnology \u2014 Security techniques \u2014 \nInformation security management sys-\ntems \u2014 Overview and vocabulary. [12*]\tISO/IEC 27032:2012 Information \ntechnology \u2014 Security techniques \u2014 \nGuidelines for cybersecurity. [13]\t ISO/IEC 19770-1:2017 Information \ntechnology \u2014 IT asset management", "domains": ["Software Quality Attributes", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 273", "position": 273, "chunk_type": "semantic", "token_estimate": 221}
{"text": "SOFTWARE SECURITY   13-9: \u2014 Part 1: IT asset management sys-\ntems \u2014 Requirements. [14]\t ISO/IEC 21827:2008 Information \ntechnology \u2014 Security techniques \n\u2014 Systems Security Engineering \n\u2014 Capability Maturity Model \n(SSE-CMM). [15*]\tISO/IEC 27001:2022 Information \nSecurity, Cybersecurity And Privacy \nProtection \u2014 Information Security \nManagement Systems \u2014 Requirements. [16]\t M. Howard and S. Lipner, The Security \nDevelopment Lifecycle, Microsoft \nPress, 2006. [17]\t F. Swiderski and W. Snyder, Threat \nModeling: Design for Security, Wiley, 2014. [18]\t D. Firesmith, \u201cSecurity use cases,\u201d \nJournal of Object Technology, Vol. 2, No. 1, pp. 53-64, 2003. [19]\t E. Fernandez-Buglioni, Security Patterns \nin Practice: Designing Secure Architectures \nUsing Software Patterns, Wiley, 2013. [20]\t C. Nagappan, R. Lai, and R. Steel, \nCore Security Patterns: Best Practices \nand Strategies for J2EE, Web Services, \nand Identity Management, Prentice \nHall, 2005. [21]\t M. Schumacher, E. Fernandez-\nBuglioni, D. Hybertson, F. \nBuschmann, and P. Sommerlad, \nSecurity Patterns: Integrating Security \nand Systems Engineering, Wiley, 2006. [22]\t R.C. Seacord, The CERT C Secure \nCoding Standard, Addison-Wesley \nProfessional, 2008. [23]\t R.C. Seacord, Secure Coding in C and \nC++, Addison-Wesley Professional, 2013. [24]\t D. Long, F. Mohindra, D. Seacord, \nR.C. Sutherland, and D.F. Svoboda, \nThe CERT Oracle Secure Coding \nStandard for Java, 2011. [25]\t J. Erickson, Hacking: The Art of \nExploitation, 2nd Edition, No Starch \nPress, 2008. [26]\t K. Scarfone, M. Souppaya, A. Cody, \nand A. Orebaugh, Technical Guide \nto Information Security Testing and \nAssessment, NIST SP800-115, 2008. [27]\t PCI Security Standards Council, PCI \nDSS: Payment Card Industry Data \nSecurity Standard, Version 3.2, 2017. [28]\t MITRE, \u201cCommon Vulnerabilities and \nExposures (CVE),\u201d https://cve.mitre.org/. [29] MITRE, \u201cCommon Weakness \nEnumeration (CWE),\u201d https://cwe. mitre.org/. [30]\t MITRE, \u201cCommon Attack Pattern \nEnumeration and Classification \n(CAPEC),\u201d https://capec.mitre.org/. [31]\t C. Dotson, Practical Cloud Security, \nO\u2019Reilly, 2019. [32]\t \u201cInternet of Things Security Best \nPractices,\u201d IEEE, 2017, https://\ninternetinitiative.ieee.org/resources/\nreports-presentations-publications. [33]\t \u201cIoT 2020: Smart and secure IoT plat-\nform,\u201d IEC, 2016, https://www.iec.ch \n/basecamp/iot-2020-smart-and-secure \n-iot-platform. [34]\t ISO/IEC 15408-1:2022 Information \nsecurity, cybersecurity and privacy pro-\ntection \u2014 Evaluation criteria for IT \nsecurity \u2014 Part 1: Introduction and \ngeneral model. [35]\t ISO/IEC 18045:2008 Information \ntechnology \u2014 Security techniques", "domains": ["Software Quality Attributes", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 274", "position": 274, "chunk_type": "semantic", "token_estimate": 338}
{"text": "13-10   SWEBOK \u00ae GUIDE V4.0: \u2014 Methodology for IT security \nevaluation. [36]\t DoD Enterprise DevSecOps, https://\nsoftware.af.mil/dsop/documents/. [37]\t C. Easttom, Computer Security \nFundamentals, 4th Edition, Pearson IT \nCertification, 2019. [38]\t Y. Diogenes and E. Ozkaya, \nCybersecurity \u2014 Attack and Defense \nStrategies, Second Edition, Packt \nPublishing, 2019. [39]\t C. Chio and D. Freeman, Machine \nLearning and Security: Protecting \nSystems with Data and Algorithms, \nO\u2019Reilly, 2018. [40]\t I. Sommerville, Software Engineering, \n10th ed., Addison-Wesley, 2016. [41]\t FIRST, CVSS v4.0 Specification \nDocument, https://www.first.org/cvss \n/specification-document.", "domains": ["Software Quality Attributes", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 275", "position": 275, "chunk_type": "semantic", "token_estimate": 81}
{"text": "Nondisclosure Agreement: UI/UX\nUser Interface/User Experience", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 276", "position": 276, "chunk_type": "semantic", "token_estimate": 6}
{"text": "The: Software \nEngineering \nProfessional \nPractice knowledge area (KA) is concerned \nwith the knowledge, skills, and attitudes soft-\nware engineers must possess to practice soft-\nware engineering in a professional, responsible \nand ethical manner. Because of the widespread \napplications of software products in social \nand personal life, software product quality \ncan profoundly affect personal well-being and \nsocietal harmony. Software engineers must \nhandle unique engineering problems to pro-\nduce software with known characteristics and \nreliability. This requirement calls for software \nengineers who possess the proper knowledge, \nskills, training, and experience in professional \npractice. Professional practice refers to a way of con-\nducting services to achieve certain standards or \ncriteria in both the process of performing a ser-\nvice and the end product resulting from the ser-\nvice. These standards and criteria can include \nboth technical and non-technical aspects. The concept of professional practice is espe-\ncially applicable to professions with a generally \naccepted body of knowledge; code of ethics and \nprofessional conduct with penalties for viola-\ntions; accepted processes for accreditation, cer-\ntification, qualification, and licensing; and \nprofessional societies to provide and administer \nall these. Admission to these professional soci-\neties is often predicated on a prescribed combi-\nnation of education and experience. A software engineer maintains professional \npractice by performing all work following \ngenerally accepted practices, standards, and \nguidelines set forth by the applicable pro-\nfessional society, such as the Association for \nComputing Machinery (ACM), Institute for \nElectrical and Electronics Engineers (IEEE), \nor International Federation for Information \nProcessing (IFIP), IEEE Computer Society \n(IEEE CS), International Organization for \nStandardization/International Electrotechnical \nCommission (ISO/IEC), and ISO/IEC/\nIEEE provide internationally accepted soft-\nware engineering standards. All of these", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 276", "position": 276, "chunk_type": "semantic", "token_estimate": 273}
{"text": "14-4   SWEBOK \u00ae GUIDE V4.0: should embody. The professional community \nestablishes a code of ethics and professional \nconduct. This code exists in the context of \nsocietal norms and local laws and is adjusted \nto agree with those norms and laws as needed. A code of ethics and professional conduct \ncan offer guidance in the face of conflicting \nimperatives. More than one such code serves \nthe professional engineering community. For example, in 1999, IEEE CS and ACM \nlaunched a joint Software Engineering \nEthics and Professional Practices Task \nForce to publish a code of ethics. In 2018, \nACM published its ACM Code of Ethics \nand Professional Conduct, and in 2020, \nIEEE published a revision of its Code of \nEthics which was originally approved in \n1912. Then, in 2021, IFIP published its \nCode of Ethics and Professional Conduct, \nadapted from ACM\u2019s Code of Ethics and \nProfessional Conduct. Once established, codes of ethics and pro-\nfessional conduct are enforced by the profes-\nsion, as represented by professional societies \nor by a statutory body. Violations may be acts \nof commission, such as concealing inadequate \nwork, disclosing confidential information, \nfalsifying information, or misrepresenting \nabilities. They may also occur through omis-\nsion, including failure to disclose risks or pro-\nvide important information, failure to give \nproper credit or acknowledge references, and \nfailure to represent client interests. Violations \nof a code of ethics and professional conduct \nmay result in penalties and possible expulsion \nfrom professional status. Software engineers shall commit them-\nselves to making the analysis, specification, \ndesign, development, testing, and mainte-\nnance of software a beneficial and respected \nprofession. Following their commitment to \nthe health, safety, and welfare of the public, \nsoftware engineers shall adhere to the ten \nprinciples according to IEEE Code of Ethics \nadopted by the IEEE Board of Directions, \nJune 2020. Since the code of ethics and professional \nconduct may be introduced, modified, or \nreplaced at any time, individual software \nengineers are responsible for continuing their \nstudies to stay current in their professional \npractice. 1.3. Nature\u2008and\u2008Role\u2008of\u2008Professional\u2008Societies  \n\b\n[1*, c2s3] [4*, c1s2] [5*, c35s1]\nProfessional societies comprise a mix of \npractitioners and academics. These societies \ndefine, advance, and regulate their corre-\nsponding professions. Professional societies \nhelp establish professional standards as well \nas codes of ethics and professional conduct.", "domains": ["Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 279", "position": 279, "chunk_type": "semantic", "token_estimate": 378}
{"text": "14-8   SWEBOK \u00ae GUIDE V4.0: system\u2019s security will protect the software \nand user information from accidental or \nmalicious access, use, modification, destruc-\ntion, or disclosure. Dark patterns are deceptive UI/UX inter-\nactions designed to mislead or trick users into \nmaking them do something they may not \nwant to do. These patterns do not have the \nusers\u2019 interests in mind and aim for exploit-\nability rather than usability. Creating dark \npatterns is not good ethical practice. Software \nengineers should be responsible for their \nactions and be transparent with users instead \nof manipulating them. 1.7.10. Data Privacy\nSoftware engineers should know that data \nprivacy is a key legal requirement in many \ncountries. The\u00a0 General Data Protection \nRegulation\u00a0 (GDPR), adopted on 14 April \n2016, and enforceable since 25 May 2018, \nregulates\u00a0 data protection\u00a0 and privacy in the \nEuropean Union (EU) and the\u00a0 European \nEconomic Area\u00a0(EEA). It also addresses the \ntransfer of\u00a0personal data outside the EU and \nEEA areas. The GDPR\u2019s primary aim is to \nenhance individuals\u2019 control and rights over \ntheir data and to simplify the regulatory envi-\nronment for international business. The regulation became a model for many \nnational laws outside the EU, including \nthe UK, Chile, Japan, Brazil, South Korea, \nArgentina, and Kenya. The California \nConsumer Privacy Act (CCPA), adopted \non 28 June 2018, has many similarities with \nthe GDPR. 1.8. Documentation\u2008 \n\b\n[1*, c10s5.8] [3*, c1s5] [4*] [5*, c32]\nProviding clear, thorough, and accurate \ndocumentation is the responsibility of each \nsoftware engineer. The adequacy of documen-\ntation is judged according to different criteria, \nbased on stakeholder needs. Good documen-\ntation complies with accepted standards and \nguidelines.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 283", "position": 283, "chunk_type": "semantic", "token_estimate": 268}
{"text": "14-8   SWEBOK \u00ae GUIDE V4.0: The adequacy of documen-\ntation is judged according to different criteria, \nbased on stakeholder needs. Good documen-\ntation complies with accepted standards and \nguidelines. In particular, software engineers \nshould document the following:\n\u2022\t Relevant facts\n\u2022\t Significant risks and trade-offs \n\u2022\t Warnings of undesirable or dangerous \nconsequences from the use or misuse of \nthe software\n\u2022\t Relevant information pertaining to attri-\nbute, license type, and sourcing\nSoftware engineers should avoid:\n\u2022\t Certifying or approving unacceptable \n \nproducts\n\u2022\t Disclosing confidential information\n\u2022\t Falsifying facts or data\nIn addition, software engineers and their \nmanagers should provide the following doc-\numentation for other elements of the software \ndevelopment organization to use:\n\u2022\t Software requirements specifications, soft-\nware design documents, details on the soft-\nware engineering tools used, software test \nspecifications and results, and details about \nthe adopted software engineering methods\n\u2022\t Problems encountered during the devel-\nopment process\nFor external stakeholders (customers, users, \nothers), software documentation should pro-\nvide the following:\n\u2022\t Information \nneeded \nto \ndetermine \nwhether the software is likely to meet \ncustomer and user needs\n\u2022\t Description of safe and unsafe use of \nthe software\n\u2022\t Explanation of how to protect sensitive \ninformation created by or stored using \nthe software\n\u2022\t Clear identification of warnings and crit-\nical procedures \nSoftware use may include installation, oper-\nation, administration, and performance of \nother functions by various groups of users and \nsupport personnel. If the customer will acquire \nownership of the software source code or the \nright to modify the code, the software engineer", "domains": ["Software Quality Attributes", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 283", "position": 283, "chunk_type": "semantic", "token_estimate": 255}
{"text": "SOFTWARE ENGINEERING PROFESSIONAL PRACTICE   14-9: should provide documentation of the func-\ntional specifications, the software design, the \ntest suite, and the necessary operating environ-\nment for the software. Documents should be \nkept for at least as long as the software prod-\nuct\u2019s life cycle or the time required by relevant \norganizational or regulatory requirements. 1.9. Trade-Off\u2008Analysis\u2008 \n\b\n[3*, c1s2, c10] [4*, c7s2, c13s4] [13*, \n\b\nc9s5.10]\nA software engineer often has to choose \nbetween alternative problem solutions. The \noutcome of these choices is determined by the \nsoftware engineer\u2019s professional evaluation of \neach alternative\u2019s risks, costs, and benefits in \ncooperation with stakeholders. The software \nengineer\u2019s evaluation is called trade-off analysis. Trade-off analysis notably identifies competing \nand complementary software requirements to \nprioritize the final requirements defining the \nsoftware to be constructed. (See Requirements \nNegotiation in the Software Requirements \nKA and Determination and Negotiation of \nRequirements in the Software Engineering \nManagement KA.) When an ongoing software development \nproject is late or over budget, a trade-off anal-\nysis is often conducted to decide which soft-\nware requirements can be relaxed or dropped \ngiven the effects thereof. The first step in a \ntrade-off analysis is establishing design goals \n(see Engineering Design in the Engineering \nFoundations KA) and setting the relative \nimportance of those goals. This permits the \nidentification of the solution that most nearly \nmeets those goals; this means that the way the \ngoals are stated is critically important. Design goals may include minimizing \nmonetary cost and maximizing reliability, \nperformance, or other criteria on various \ndimensions. However, it is difficult to formu-\nlate a trade-off analysis of cost against risk, \nespecially where primary production and \nsecondary risk-based costs must be weighed \nagainst each other. A software engineer must ethically con-\nduct a trade-off analysis \u2014 notably by being \nobjective and impartial when selecting cri-\nteria for comparing alternative problem solu-\ntions and assigning weights or importance \nto these criteria. In addition, any conflict of \ninterest must be disclosed upfront. 2. Group Dynamics and Psychology\nEngineering work is often conducted in \nteams. A software engineer should interact \ncooperatively and constructively with others \nto first determine and then meet needs and \nexpectations. Knowledge of group dynamics \nand psychology is an asset when interacting \nwith customers, coworkers, suppliers, and \nsubordinates to solve software engineering \nproblems. 2.1. Dynamics\u2008of\u2008Working\u2008in\u2008Teams/Groups\u2008 \n\b\n[3*, c1s6] [14*, c1s3.5, c10]\nSoftware engineers must work with others.", "domains": ["Design Patterns", "Software Quality Attributes", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 284", "position": 284, "chunk_type": "semantic", "token_estimate": 396}
{"text": "SOFTWARE ENGINEERING PROFESSIONAL PRACTICE   14-11: For a software project to succeed, team \nmembers must embrace tolerance of dif-\nferent cultural and social norms, acknowl-\nedging that not all societies have the same \nsocial expectations. The support of leader-\nship and management can facilitate tolerance \nand understanding. More frequent commu-\nnication, including face-to-face meetings, \ncan help mitigate geographical and cultural \ndivisions, promote cohesiveness, and raise \nproductivity. Also, communicating with \nteammates in their native language could be \nbeneficial. In the software industry, gender bias \nis still prevalent. Implementing broader \nrecruiting strategies, specific and measur-\nable performance evaluation criteria, and \ntransparent procedures for assigning com-\npensation can reduce gender inequality in \nthe software industry. These trends can con-\ntribute to building a diverse environment \nfor all software engineers, regardless of \ntheir gender. 3. Communication Skills \nA software engineer must communicate well, \nboth orally and in reading and writing. To \nmeet software requirements and deadlines, \nengineers must establish clear communica-\ntion with customers, supervisors, coworkers, \nand suppliers. Optimal problem-solving is \nmade possible through the ability to inves-\ntigate, comprehend and summarize infor-\nmation. Customer product acceptance and \nsafe product use depend on relevant training \nand documentation. The software engineer\u2019s \ncareer success is affected by consistently pro-\nviding oral and written communication effec-\ntively and on time.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 286", "position": 286, "chunk_type": "semantic", "token_estimate": 212}
{"text": "15-2   SWEBOK \u00ae GUIDE V4.0: whether such concerns apply to them. But eco-\nnomic decision-making is fundamental to engi-\nneering. Someone who cannot make decisions \nfrom both a technical and an economic per-\nspective cannot be considered a true engineer. Software engineering economics applies to \ndecisions across the entire software product \nlife cycle (SPLC), from the pre-project deci-\nsion to develop the software to end-of-life \ndecisions for existing software. It also applies \nto decisions at all levels of technical detail. For \nexample, all following questions involve an \neconomic perspective:\n\u2022\t can a client organization benefit from a \ndigital transformation? \u2022\t does a project proposal (a tender) align \nwith a client\u2019s business goals? \u2022\t should certain software functionality be \nbought or built? \u2022\t should certain requirements be included \nin scope or not? \u2022\t what is the most efficient, cost-effective \narchitecture and design? \u2022\t what is an optimal load-balancing strategy \nfor a cloud-based deployment that provides \nadequate response time to clients without \nincurring unnecessary operational cost? \u2022\t how much risk-based testing is enough? \u2022\t is it better to refactor, redevelop or just live \nwith code that has high technical debt? \u2022\t is it better to focus maintenance on \nadding new functionality or on fixing \nknown defects? \u2022\t would the value of early delivery of par-\ntial functionality gained by using an \nAgile process outweigh the overhead of \nrework and continuous testing inherent \nin iterative approaches? The Software Engineering Economics \nknowledge area (KA) is directly or indirectly \nrelated to all other KAs in this Guide. This KA also takes the position that the \nmore traditional, purely financial view of \nengineering economics needs to be broadened \n[2]. Value does not always derive from money \nalone; value can also derive from \u201cunquanti-\nfiables\u201d like corporate citizenship, employee \nwell-being, environmental friendliness, cus-\ntomer loyalty and so on. Therefore, software \nengineering decisions must also consider rel-\nevant unquantifiable criteria.", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 291", "position": 291, "chunk_type": "semantic", "token_estimate": 312}
{"text": "The breakdown of topics for the Software: Engineering Economics KA is shown in \nFigure 15.1. Software Engineering\nEconomics\nProposals\nCash Flow\nTime-Value\nof Money\nEquivalence\nBases for\nComparison\nAlternatives\nIntangible\nAssets\nBusiness\nModel\nProcess\nOverview\nUnderstand the\nReal Problem\nIdentify all\nReasonable\nTechnically-\nFeasible\nSolutions\nDe\ufb01ne the\nSelection\nCriteria\nEvaluate each\nAlternative\nagainst the\nSelection Criteria\nSelect the Preferred\nAlternative\nMonitor the Performance \nof the Selected Alternative\nMinimum\nAcceptable\nRate of Return\nEconomic Life\nPlanning\nHorizon\nReplacement\nDecisions\nRetirement Decisions\nAdvanced For-Pro\ufb01t\nDecision Considerations\nBene\ufb01t-Cost\nAnalysis\nCost-\nE\ufb00ectiveness\nAnalysis\n \nBreak-Even\nAnalysis\nOptimization\nAnalysis\nCompensatory\nTechniques\nNon-\nCompensatory\nTechniques\nIdentify\nProcesses and\nDe\ufb01ne \nBusiness Goals\nIdentify\nIntangible Assets\nlinked with\nBusiness Goals\nIdentify\nSoftware\nProducts that\nSupport\nIntangible Assets\nDe\ufb01ne and\nMeasure Indicators\nIntangible Asset\nCharacterization\nLink Speci\ufb01c Intangible \nAssets with the Business Model\nDecision Making\nAccounting\nCost and Costing\nFinance\nControlling\nE\ufb03ciency and\nE\ufb00ectiveness\nProductivity\nProduct or\nService\nProject\nProgram\nPortfolio\nProduct\nLifecycle\nProject\nLifecycle\nPrice and\nPricing\nPrioritization\nSoftware\nEngineering\nEconomics\nFundamentals\nTe Engineering\nDecision-Making\nProcess\nFor-Pro\ufb01t\nDecision-Making\nNonpro\ufb01t\nDecision-Making\nPresent Economy\nDecision-Making\nMultiple-\nAttribute\nDecision-Making\nIdentifying and\nCharacterizing\nIntangible Assets\nEstimation\nPractical\nConsiderations\nRelated\nConcepts\nExpert\nJudgment\nAnalogy\nDecomposition\nParametric\nMultiple\nEstimates\nBusiness Case\nMultiple-\nCurrency\nAnalysis\nSystems\nTinking\nFigure 15.1. Breakdown of Topics for the Software Engineering Economics KA", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 291", "position": 291, "chunk_type": "semantic", "token_estimate": 212}
{"text": "SOFTWARE ENGINEERING ECONOMICS   15-3: 1. Software Engineering Economics \nFundamentals\n1.1. Proposals\b\n[3*, c3pp23-24]\nSoftware engineering decisions begin with \nthe concept of a proposal \u2014 a single, separate \ncourse of action to be considered (e.g., carrying \nout a particular software development project \nor not). Another proposal could be to enhance \nan existing software component; another \nmight be to redevelop that same software \nfrom scratch. In deciding what algorithm to \nuse in implementing a certain function, each \ncandidate considered is a proposal. Every pro-\nposal represents a binary unit of choice \u2014 the \nsoftware engineer either carries out that pro-\nposal or chooses not to. Software engineering \neconomics aims to identify the proposals best \naligned with the organization\u2019s goals. 1.2. Cash Flow\b\n[3*, c3pp24-32]\nEngineers must evaluate a proposal from a \nfinancial perspective to make a meaningful \ndecision about it. The concepts of cash flow \ninstance and cash flow stream describe the \nfinancial perspective of proposals. A cash flow instance is a specific amount of \nmoney flowing into or out of the organization \nat a specific time as a direct result of carrying \nout a proposal. For example, in a proposal to \ndevelop and launch product X, the payment \nfor new computers, if needed, would be an \nexample of an outgoing cash flow instance. Money would need to be spent to carry out \nthat proposal. The sales income from product \nX in the 11th month after market launch \nwould be an example of an incoming cash \nflow instance. Money would come in because \nof carrying out the proposal. A cash flow stream is the set of cash flow \ninstances over time caused by carrying out \nthat proposal. The cash flow stream is that \nproposal\u2019s complete financial view. How \nmuch money goes out? When does it go out? How much money comes in? When does it \ncome in? If the cash flow stream for Proposal \nA is more desirable than the cash flow stream \nfor Proposal B, then \u2014 all other things being \nequal \u2014 the organization is financially better \noff carrying out Proposal A than Proposal B. Thus, the cash flow stream is an important \nelement of engineering decision-making. A cash flow diagram is a picture of a cash flow \nstream. The cash flow diagram quickly sum-\nmarizes the financial view of a proposal. Figure \n15.2 shows an example cash flow diagram. The cash flow stream is shown in two dimen-\nsions.", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 292", "position": 292, "chunk_type": "semantic", "token_estimate": 400}
{"text": "15-4   SWEBOK \u00ae GUIDE V4.0: It doesn\u2019t mean do \nnothing at all; it means \u201cdo something else, \nsomething that\u2019s not in this set of choices.\u201d \nThe do-nothing alternative should be consid-\nered in most, but not all, situations. 1.7. Intangible Assets\nIntangible assets, also known as knowl-\nedge assets, are any knowledge that lies in \nthe non-visible side of an organization but \naffects that organization\u2019s financial perfor-\nmance. According to International Valuation \nStandards (IVS) 210 \u00a7 20.1, \u201can intangible \nasset is a non-monetary asset that manifests \nitself by its economic properties. It does not \nhave physical substance but grants rights and \neconomic benefits to its owner\u201d [4]. This can include, but is not limited to, pol-\nicies, procedures, tools and specifications, \nas well as organizational culture, experience \nand know-how. Knowing the organization\u2019s intangible assets \nhelps the software engineer better understand \nhow proposals may affect or be affected by orga-\nnizational realities. Otherwise, hidden risks \nand opportunities that could influence pro-\nposals\u2019 success or failure might not be exposed. The skills needed to consider intangible \nassets are the following:\n\u2022\t intangible \nassets \nidentification \nand \nvaluation [Skills Framework for the \nInformation \nAge \n(SFIA), \ncategory \nStrategy and Architecture, subcategory \nBusiness strategy and planning];\n\u2022\t knowledge management [SFIA, category \nStrategy and Architecture, subcategory \nBusiness strategy and planning]. Identifying and characterizing intan-\ngible assets are discussed in more detail later \nin this KA.", "domains": ["Design Patterns", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 293", "position": 293, "chunk_type": "semantic", "token_estimate": 228}
{"text": "SOFTWARE ENGINEERING ECONOMICS   15-5: 1.8. Business Model \nPeter Drucker, a founder of modern manage-\nment, defines a good business model as one \nthat answers these questions [5]: \n\u2022\t \u201cWho is the customer?\u201d\n\u2022\t \u201cWhat does the customer value?\u201d\n\u2022\t \u201cHow do we make money?\u201d\n\u2022\t \u201cWhat is the underlying economic logic \nthat explains how we can deliver value to \ncustomers at an appropriate cost?\u201d\nUnderstanding the organization\u2019s business \nmodel \u2014 as well as its intangible assets \u2014 helps \nthe software engineer better understand how \nproposals may affect or be affected by orga-\nnizational realities. Analyzing the business \nmodel can help the software engineer iden-\ntify hidden risks and opportunities that could \ninfluence a proposal\u2019s success or failure [6]. 2. The Engineering Decision-Making \nProcess\n2.1. Process Overview\b\n[3*, c4pp35-36]\nFigure 15.3 provides an overview of the engi-\nneering decision-making process. The process is shown as stepwise and sequen-\ntial; however, it can be more fluid in practice. Steps can be done iteratively, can overlap and \ncan even occur in different sequences. Just be \nsure not to skip any step or execute it poorly. When the consequences of a wrong deci-\nsion are significant, such as a go/no-go deci-\nsion for a large project, more time, effort and \ncare should be spent in this process. All steps \nshould be completed thoroughly and carefully. ISO 12207 [7] and ISO 15288 [8] recommend \ntwo additional early activities, which can be \nimportant in high-consequence decisions:\n\u2022\t define the decision management strategy \n\u2014 this strategy might specify roles, \nresponsibilities, procedures and tools;\n\u2022\t identify relevant stakeholders, which might \ninclude appropriate subject matter experts. When the consequences of a wrong deci-\nsion are small, such as the consequences of \nselecting a minor algorithm or data structure, \nless time, effort and care can be spent, but the \nsame general process is followed. Each step is \ndiscussed in more detail below. 2.2. Understand the Real Problem \n\b\n[3*, c4pp37-39]\nThe best solution to a problem can come \nonly from thoroughly understanding the real \nproblem to be solved. This step\u2019s key aspects \ninclude the use of an interrogative technique \nsuch as the \u201c5 Whys\u201d technique and a con-\nsideration of the broader context surrounding \nthe problem.", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 294", "position": 294, "chunk_type": "semantic", "token_estimate": 366}
{"text": "SOFTWARE ENGINEERING ECONOMICS   15-5: Understand the Real Problem \n\b\n[3*, c4pp37-39]\nThe best solution to a problem can come \nonly from thoroughly understanding the real \nproblem to be solved. This step\u2019s key aspects \ninclude the use of an interrogative technique \nsuch as the \u201c5 Whys\u201d technique and a con-\nsideration of the broader context surrounding \nthe problem. The Empathize stage in Design \nThinking [9] (to consider intangible assets) \nand looking closely at the organization\u2019s \nIdentify all reasonable\ntechnically feasible\nsolutions\nEvaluate each\nalternative against\nthe selection criteria\nDefne the\nselection criteria\nUnderstand the\nreal problem\nSelect the\npreferred alternative\nMonitor the\nperformance of the\nselected alternative\nFigure 15.3. The Engineering Decision-Making Process", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 294", "position": 294, "chunk_type": "semantic", "token_estimate": 112}
{"text": "SOFTWARE ENGINEERING ECONOMICS   15-7: Engineering decisions are based on esti-\nmates (discussed later in this KA). The accu-\nracy of an estimate is limited in theory and in \npractice, and the degree of inaccuracy depends \non the specifics of the situation [3*, c21pp344-\n356]. If the degree of inaccuracy is high enough, \nthat inaccuracy could change the resulting \ndecision. The following techniques [3*, c23] \ncan help engineers address these situations:\n\u2022\t consider ranges of estimates;\n\u2022\t perform a sensitivity analysis;\n\u2022\t delay final decisions. In addition, two categories of techniques \naddress multiple potential outcomes from \na decision:\n\u2022\t decision-making-under-risk techniques \n[3*, c24] are used when probabilities can \nbe assigned to the different potential \noutcomes. Specific techniques include \nexpected value decision-making, expec-\ntation variance and decision-making, \nMonte Carlo analysis, decision trees, and \nthe expected value of perfect information;\n\u2022\t decision-making-under-uncertainty tech-\nniques [3*, c25] are used when probabil-\nities cannot be assigned to the different \npotential outcomes. Specific techniques \ninclude the Laplace Rule, the Maximin \nRule, the Maximax Rule, the Hurwicz \nRule and the Minimax Regret Rule. High-consequence decisions may benefit \nfrom formally recording the selected alterna-\ntive and the justification for why that alterna-\ntive was selected. 2.7. Monitor the Performance of the Selected \nAlternative\b\n[3*, c4pp42-43]\nBecause estimation is a fundamental element \nof engineering decision-making, the quality of \nthe decision depends on the quality of the esti-\nmates. Bad estimates can easily lead to bad deci-\nsions. The software engineer needs to \u201cclose the \nloop\u201d on estimates by comparing them to the \nactual outcomes. Otherwise, no one will ever \nknow if the estimates were good [3*, c21pp356-\n358]. This also helps improve estimation over \ntime. Understanding what drives differences \nbetween estimates and actual outcomes helps \nengineers refine estimation techniques to pro-\nduce more accurate estimates in the future. 3. For-Profit Decision-Making\nFor-profit decision techniques apply when the \norganization\u2019s goal is profit \u2014 which is the \ncase in most companies. Figure 15.4 shows the process for identi-\nfying the financially best alternative out of a set \nof proposals. Arranging alternatives in order of \nincreasing initial investment and then selecting \nstrictly better candidates means that, all other \nconsiderations being equal, the alternative with \nthe smaller initial investment will be chosen. The \n\u201cIs the next candidate strictly better?\u201d decision is \nmade in terms of the appropriate basis for com-\nparison: present worth, future worth, IRR, etc. 3.1.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 296", "position": 296, "chunk_type": "semantic", "token_estimate": 395}
{"text": "SOFTWARE ENGINEERING ECONOMICS   15-9: 3.5. Retirement Decisions \n\b\n[3*, c12pp178-181] [8*, c9]\nRetirement decisions are about getting out of \nan activity altogether, such as when a soft-\nware company considers not selling a software \nproduct anymore or a hardware manufacturer \nconsiders not building and selling a partic-\nular computer model any longer. Retirement \ndecisions can be preplanned or happen spon-\ntaneously (e.g., when performance targets \nare not achieved). Retirement decisions can \nbe influenced by lock-in factors such as tech-\nnology dependency and high exit costs. 3.6. Advanced For-Profit Decision \nConsiderations\b\n[3*, c13-17]\nThe above concepts and techniques are often \nsufficient to make a good for-profit decision. However, particularly when the consequences \nof a wrong decision are high, additional con-\nsiderations may need to be factored into the \ndecision analysis, including the following:\n\u2022\t inflation or deflation;\n\u2022\t depreciation;\n\u2022\t income taxes. 4. Nonprofit Decision-Making\nThe for-profit decision techniques don\u2019t apply \nwhen the organization\u2019s goal isn\u2019t profit \u2014 \nwhich is the case in government and non-\nprofit organizations. These organizations \nhave a different goal, so different decision \ntechniques are needed. The two techniques \nare benefit-cost analysis and cost-effective-\nness analysis (discussed below). 4.1. Benefit-Cost Analysis\b [3*, c18pp303-311]\nBenefit-cost analysis is one of the most \nwidely used methods for evaluating pro-\nposals in nonprofit organizations. A propos-\nal\u2019s financial benefits are divided by its costs. Any proposal with a benefit-cost ratio of \nless than 1.0 can usually be rejected without \nfurther analysis because it would cost more \nthan it would benefit the organization. Additional considerations are necessary \nwhen two or more proposals are considered \nat the same time. 4.2. Cost-Effectiveness Analysis \n\b\n[3*, c18pp311-314]\nCost-effectiveness analysis shares much of \nthe philosophy and methodology of bene-\nfit-cost analysis. There are two versions of \ncost-effectiveness analysis. The fixed-cost \nversion seeks to maximize benefit given a \nfixed upper bound on cost. The fixed-effec-\ntiveness version seeks to minimize the cost to \nachieve a fixed goal. 5. Present Economy Decision-Making\nThis subset of engineering decision-making \nis called present economy because it does not \ninvolve the time-value of money (future \neconomy). The two forms of present economy \ndecisions are presented below. 5.1. Break-Even Analysis\b\n[3*, c19]\nGiven functions describing the costs of two \nor more proposals, break-even analysis helps \nengineers choose between them by identi-\nfying points where those cost functions are \nequal. Below a break-even point, one pro-\nposal is preferred, and above that point, the \nother is preferred.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 298", "position": 298, "chunk_type": "semantic", "token_estimate": 403}
{"text": "15-10   SWEBOK \u00ae GUIDE V4.0: point where overall cost is lowest. Software\u2019s \nclassic space-time trade-off is an example of \noptimization; an algorithm that runs faster \noften uses more memory. Optimization bal-\nances the value of faster run time against the \ncost of the additional memory. 6. Multiple-Attribute Decision-Making \n\b\n[3*, c26]\nMost topics presented in this KA so far have \ndiscussed decisions based on a single cri-\nterion \u2014 money. The alternative with the \nbest present worth, the best incremental \nIRR, the best incremental benefit-cost ratio, \netc., is the one selected. Aside from tech-\nnical feasibility, money is usually the most \nimportant decision criterion, but it\u2019s cer-\ntainly not always the only one. Often, other \ncriteria, other \u201cattributes,\u201d need to be con-\nsidered that can\u2019t be cast in terms of money. Multiple-attribute decision-making tech-\nniques allow nonmonetary criteria to be fac-\ntored into the decision. A variety of techniques can be used to \naddress multiple criteria, including nonmon-\netary criteria. These techniques fall into two \ncategories. 6.1. Compensatory Techniques \n\b\n[3*, c26pp449-458]\nAlso called single-dimensioned techniques, the \ntechniques in this category collapse all criteria \ninto a single figure of merit. This category is \ncalled compensatory because, for any given \nalternative, a lower score in one criterion can \nbe compensated by \u2014 traded off against \u2014 a \nhigher score in other criteria. Compensatory \ntechniques include nondimensional scaling, \nadditive weighting and analytic hierarchy \nprocess (AHP). Gilb\u2019s Impact Estimation [11] and the \nSoftware \nEngineering \nInstitute\u2019s \n(SEI) \nArchitectural Tradeoff Analysis Method \n(ATAM) [12] are examples of compensa-\ntory \nmultiple-attribute \ndecision-making \ntechniques focused on identifying the best \nsoftware design. 6.2. Non-Compensatory Techniques \n\b\n[3*, c26pp447-449]\nAlso called fully dimensioned techniques, the \ntechniques in this category do not allow trade-\noffs among the criteria. Each criterion is \ntreated as a separate entity in the selection pro-\ncess. Non-compensatory techniques include \ndominance, satisficing and lexicography. 7. Identifying and Characterizing \nIntangible Assets\nThe intangible side of an organization is the \nvaluable knowledge residing within it. This \nincludes employees\u2019 knowledge about pro-\ncesses, structures, procedures, etc. (tacit, or \nimplicit, knowledge), as well as institutional \nknowledge recorded in various organizational \nresources (explicit knowledge). These assets \nare usually hidden, the way most of an iceberg \nis underwater.", "domains": ["Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 299", "position": 299, "chunk_type": "semantic", "token_estimate": 366}
{"text": "15-12   SWEBOK \u00ae GUIDE V4.0: identified specific intangible assets based \non their quality and impact. Specific \nintangible assets may be characterized in \nterms of their impact on business goals \nand their quality as organizational assets. There are three important characteriza-\ntion cases:\n\u2022\t case 1: specific intangible assets with both \nimpact and quality indicators (Warning, \nReplaceable, Evolving or Stable);\n\u2022\t case 2: specific intangible assets with only \nquality indicators (Acceptable Quality or \nUnacceptable Quality);\n\u2022\t case 3: specific intangible assets with only \nimpact indicators (Acceptable Impact or \nUnacceptable Impact). The three characterization cases are shown \nin Figure 15.5. The quadrants represent the \n\u201cstates\u201d constituting different levels of char-\nacterization. The lines separating the quad-\nrants are thresholds of impact and quality that \ndefine the point at which the impact or quality \nof a specific intangible asset may be considered \nacceptable or not for each organization. These \nthresholds are established for every client \norganization and specify what level of orga-\nnizational performance, quality, and impact \nthey will demand from their knowledge/\nintangible assets. Thresholds are used to deter-\nmine when quality and/or impact are accept-\nable or unacceptable. Let\u2019s look at an example \nof how to interpret Qval and Ival (both Qval \nand Ival will be explained in the following \nsections). Assuming, for example, that we are \nanalyzing the status of an intangible asset with \nboth quality and impact indicators, and that \nQval is below the quality threshold and Ival \nis below the impact threshold. In these cir-\ncumstances we would say that the status of the \nintangible asset is \u201cwarning\u201d as can be seen in \nFigure 15.5. The characterization uses information from \nstandardized-normalized indicators to assess \nthe identified intangible assets. This assess-\nment generates a descriptive value that will \ndetermine the asset\u2019s general state of health \nfrom a quantitative perspective. Quality quantitative assessment\nThe quality valuation considers only the \nindicators of the type quality of an intan-\ngible asset and calculates a general valua-\ntion of it. To evaluate the subset of quality \nindicators, given a set of q quality indica-\ntors for an intangible asset n, the valua-\ntion of the quality is given according to \nEquation 1. Q        =\nq\ni=1 X n\nn\ni\nq\n\u2211\nVal\nEquation 1. Quality Assessment for a \nKnowledge Asset\nWhere X n\ni  is each of the q normalized indica-\ntors of quality that the intangible asset n has.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 301", "position": 301, "chunk_type": "semantic", "token_estimate": 398}
{"text": "SOFTWARE ENGINEERING ECONOMICS   15-13: quality valuations (Qval and Ival), following \nthese rules, assuming that both quality and \nimpact are equally important, so KAval (the \nvaluation of the intangible asset) is given by:\nIf \n \n\u00a0Qval\nIval, then\nKAval = Qval + Ival\nIf \u00a0Qval\n\u00a0Ival, then\nKAval = Qval\n2\nIval, then\nIf \nQval\nKAval = Ival\n \nThis linear value represents an intangible \nasset\u2019s general state based on the state of its \nindicators. It uses the algebraic mean of the \nstandardized and normalized indicators to \nrepresent the assets\u2019 general state on a scale \n[-1, 1] and based on the corresponding inter-\npretation thresholds. If no threshold is explic-\nitly mentioned, the linear value is interpreted \nas follows, if the value is 0, then the intan-\ngible asset is on the target, if the value is 1, it \nmeans that the intangible asset is 100% over \nthe target and if the value is -1 then the intan-\ngible asset is -100% under the target. 7.6. Link Specific Intangible Assets with the \nBusiness Model\nVisualizing \nthe \nclient \nbusiness \nmodel, \nenriched with the intangible assets status \nallocated into that model, gives organiza-\ntional leadership a clear understanding of the \nimportant relationships among proposed soft-\nware solutions, intangible assets, the business \nmodel and the business goals. The software \nengineer can clearly show which proposed \nsolution generates the most value for the busi-\nness. An example is shown in [6]. 7.7. Decision-Making\nThe next step in the decision-making process \nis to prioritize and choose the software prod-\nucts that interest the client organization most. There is no simple rule; several criteria must \nbe considered:\n\u2022\t the intangible asset\u2019s impact on business \ngoals (defined in previous steps);\n\u2022\t the characterization reached (defined in \nprevious steps);\n\u2022\t the impact of intangibles assets status on \nthe competitors of the organization under \nimprovement;\n\u2022\t the intangible asset\u2019s impact on the busi-\nness model;\n\u2022\t cost to implement the products;\n\u2022\t time to implement the products;\n\u2022\t complexity of the products. All criteria must be considered to decide \nwhat software products should be developed \nfor the client organization, making this a \nmultiple-attribute decision. (See 6., Multiple-\nAttribute Decision-Making.) Upon considering all relevant criteria, \nthe organization can see the risks of imple-\nmenting a software solution to automate pro-\ncesses that are either not very valuable or not \nin good shape.", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 302", "position": 302, "chunk_type": "semantic", "token_estimate": 389}
{"text": "15-16   SWEBOK \u00ae GUIDE V4.0: the individual estimates are probably accu-\nrate, and any of them could be used to make \nthe decision. Divergence suggests that one or \nmore important factors might have been over-\nlooked. Finding the factors that caused the \ndivergence and reestimating to produce con-\nverging results often lead to a better estimate \nand thus a better decision. 9. Practical Considerations\n9.1. Business Case\nThe business case is the consolidated, doc-\numented \ninformation \nsummarizing \nand \nexplaining a recommended business decision \nfrom different perspectives (cost, benefit, risk \nand so on) for a decision-maker and other rel-\nevant stakeholders. It\u2019s used to assess a prod-\nuct\u2019s potential value, which can be used as a \nbasis for an investment decision. 9.2. Multiple-Currency Analysis \nWhen a decision analysis involves cross-\nborder finances, currency exchange rate varia-\ntions may need to be considered. This is often \ndone using historical data. 9.3. Systems Thinking\nThe ecosystem in which software engineers \ndevelop their professional life is complex. To \nunderstand the whole picture around a client \norganization and form a holistic view of the \nscenarios they analyze, software engineers \ncan use systems thinking methodologies. This \napproach helps the software engineer create a \ncomplete set of possible scenarios in which the \nsoftware to be provided could be useful and, \nwith this information, explain to the client \nhow the software solution can be a value pro-\nvider for the organization. Sources for system \nthinking methodologies are Understanding \nSystems \nSystems \nInnovation \n[19] \nand \nBusiness Dynamics: Systems Thinking and \nModeling for a Complex World [20]. A way \nto connect systems thinking methodologies \nwith the development of a business model to \nunderstand the pillars of the client organiza-\ntion can be reached here [21]. 10. Related Concepts \nThis topic includes concepts the software \nengineer may want to bear in mind. 10.1. Accounting\b\n[3*, c15pp234-245]\nAccounting is part of finance. It allows people \nwhose money is used to run an organization \nto know the results of their investment: Did \nthey get the profit they were expecting? In for-\nprofit organizations, this relates to the tangible \nreturn on investment (ROI), while in nonprofit \nand governmental organizations, as well as for-\nprofit organizations, it translates into sustain-\nably staying in business. Accounting\u2019s primary \nrole is to measure the organization\u2019s actual \nfinancial performance and to communicate \nfinancial information about a business entity \nto stakeholders, such as shareholders, finan-\ncial auditors and investors.", "domains": ["Design Principles", "Software Quality Attributes", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 305", "position": 305, "chunk_type": "semantic", "token_estimate": 398}
{"text": "15-16   SWEBOK \u00ae GUIDE V4.0: In for-\nprofit organizations, this relates to the tangible \nreturn on investment (ROI), while in nonprofit \nand governmental organizations, as well as for-\nprofit organizations, it translates into sustain-\nably staying in business. Accounting\u2019s primary \nrole is to measure the organization\u2019s actual \nfinancial performance and to communicate \nfinancial information about a business entity \nto stakeholders, such as shareholders, finan-\ncial auditors and investors. Communication \ngenerally takes the form of financial state-\nments showing the economic resources to be \ncontrolled. The right information \u2014 relevant \nand reliable to the user \u2014 must be presented. Information and its timing are partially gov-\nerned by risk management and governance \npolicies. Accounting systems are also a rich \nsource of historical data for estimating. Software engineers must be conscious of \nthe software\u2019s importance as a driver of busi-\nness accounts in the digital era. 10.2. Cost and Costing\b\n[3*, c15pp245-259]\nA cost is the money used to produce some-\nthing and, hence, is no longer available for \nuse. In economics, a cost is an alternative that \nis given up as a result of a decision. Sunk cost refers to unrecoverable expenses \nthat have occurred, which can cause emotional \nhurdles looking forward. From a traditional \neconomics viewpoint, sunk costs should not be \nconsidered in decision-making. Opportunity \ncost is the cost of an alternative that must be \nforgone to pursue another alternative.", "domains": ["Design Patterns", "Software Quality Attributes", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 305", "position": 305, "chunk_type": "semantic", "token_estimate": 230}
{"text": "SOFTWARE ENGINEERING ECONOMICS   15-17: Costing is part of finance and product \nmanagement. It is the process of determining \nthe cost based on expenses (e.g., production, \nsoftware engineering, distribution, rework) \nand on the target cost to be competitive and \nsuccessful in a market. The target cost can be \nbelow the actual estimated cost. The plan-\nning and controlling of these costs (called cost \nmanagement) is important and should always \nbe included in costing. An important concept in costing is the \ntotal cost of ownership (TCO). This holds \ntrue especially for software because there are \nmany not-so-obvious costs related to SPLC \nactivities after initial product development. TCO for a software product is defined as the \ntotal cost for acquiring that product, acti-\nvating it and keeping it running. These costs \ncan be grouped as direct and indirect costs. TCO is an accounting method that is crucial \nin making sound economic decisions. 10.3. Finance\nFinance is the branch of economics concerned \nwith allocating, managing, acquiring and \ninvesting resources. Finance is an element of \nevery organization, including software engi-\nneering organizations. The field of finance deals with the concepts \nof time, money, and risk, and how they are \ninterrelated. It also deals with how money is \nspent and budgeted. Corporate finance is con-\ncerned with funding an organization\u2019s activ-\nities. Generally, this involves balancing risk \nand profitability while attempting to maxi-\nmize an organization\u2019s wealth and the value \nof its stock. This applies primarily to for-profit \norganizations but also to nonprofit organiza-\ntions. The latter needs finances to ensure sus-\ntainability, if not to make a tangible profit. To \ndo this, an organization must:\n\u2022\t identify organizational goals, time hori-\nzons, risk factors, tax considerations and \nfinancial constraints;\n\u2022\t identify and implement the appropriate \nbusiness strategy, such as which port-\nfolio and investment decisions to take, \nhow to manage cash flow and where to \nget the funding;\n\u2022\t measure financial performance, such as \ncash flow and ROI, and take corrective \nactions in case of deviation from objec-\ntives and strategy. Provided that many organizations use \nsoftware development or acquisition to stay \ncompetitive, the software engineer must be \nconscious of the importance of software to \nbusiness finances. 10.4. Controlling\nControlling is the element of finance and \naccounting that involves measuring and \ncorrecting performance. It ensures that an \norganization\u2019s objectives and plans are accom-\nplished.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 306", "position": 306, "chunk_type": "semantic", "token_estimate": 389}
{"text": "SOFTWARE ENGINEERING ECONOMICS   15-17: Controlling\nControlling is the element of finance and \naccounting that involves measuring and \ncorrecting performance. It ensures that an \norganization\u2019s objectives and plans are accom-\nplished. Controlling cost is a specialized \nbranch of controlling used to detect variances \nof actual costs from planned costs. In software engineering, this concept is \nreferred to as processes and products con-\ntrol and evolution. While the organization \nis seen as an entity with its own goals, and \ncontrol of the organizational goals is seen as \nseparate, software engineers must consider \ncontrol of the organization part of their job \nby ensuring alignment of their software with \nbusiness goals. 10.5. Efficiency and Effectiveness \n\b\n[10*, c22pp422-23]\nEconomic efficiency of a process, activity or task \nis the ratio of resources consumed to resources \nexpected to be consumed. Efficiency means \n\u201cdoing things right.\u201d An efficient behavior, \nlike an effective behavior, delivers results and \nminimizes effort. Factors affecting efficiency \nin software engineering include product com-\nplexity, quality requirements, time pressure, \nprocess capability, team distribution, inter-\nruptions, feature churn, tools and program-\nming language. Effectiveness is about having impact. It is \nthe relationship between achieved objectives \nand defined objectives. Effectiveness means", "domains": ["Software Quality Attributes", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 306", "position": 306, "chunk_type": "semantic", "token_estimate": 195}
{"text": "15-18   SWEBOK \u00ae GUIDE V4.0: \u201cdoing the right things.\u201d Effectiveness looks \nonly at whether defined objectives are reached \n\u2014 not at how they are reached. 10.6. Productivity\b\n[10*, c23pp689]\nProductivity is the ratio of output to input \nfrom an economic perspective. Output is the \nvalue delivered. Input covers all resources \n(e.g., effort) spent to generate the output. Productivity combines efficiency and effec-\ntiveness from a value-oriented perspective. Maximizing productivity is about generating \nthe highest value with the lowest resource \nconsumption. The Guide to the Project Management \nBody of Knowledge [23] defines rework as \n\u201caction taken to bring a defective or noncon-\nforming component into compliance with \nrequirements or specifications.\u201d It is worth \nnoting that most software organizations are \nunaware that the single largest resource con-\nsumer is, in fact, rework. In many software \nprojects the cost of rework is higher than \nthe cost of all other project activities com-\nbined. The most effective way to increase \nproductivity can be to simply reduce rework. Reducing software project rework involves \nproactive quality improvement actions (see \nChapter 12, Software Quality KA) that either \na) identify defects earlier so those defects can \nbe  fixed at lower resource cost, b) reduce the \ndegree of defect cost growth (e.g., intention-\nally simpler code is easier to modify than \ncomplex code so actively managing and con-\ntrolling code complexity reduces the cost of \ndefect repair), and c) prevent defects in the \nfirst place by, for example, using appropriate \ntemplates and checklists in development and \nmaintenance. 10.7. Product or Service\nA product is a tangible economic good (or \noutput) created in a process that transforms \nproduct factors (or inputs) into an output. A service is an intangible resource, like con-\nsulting. When sold, a product or service is a \ndeliverable that creates both a value and an \nexperience for its consumers. A product or \nservice can be a combination of systems, solu-\ntions and materials delivered internally (e.g., \nan in-house IT solution) or externally (e.g., a \nsoftware application), either as is or as a com-\nponent for another product (e.g., embedded \nsoftware). 10.8. Project\b\n[22*, c2s2.4]\nA project is \u201ca temporary endeavor undertaken \nto create a unique product, service, or result\u201d \n[24]. In software engineering, different \nproject types are distinguished (e.g., product \ndevelopment, outsourced services, software \nmaintenance, service creation, and so on). During its life cycle, a software product may \nrequire many projects.", "domains": ["Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 307", "position": 307, "chunk_type": "semantic", "token_estimate": 395}
{"text": "15-20   SWEBOK \u00ae GUIDE V4.0: MATRIX OF TOPICS VS. REFERENCE MATERIAL \nTockey 2005 \n[3*]\nSommerville  \n2016 [10*]\nFairley 2009 \n [22*]\n1. Software Engineering Economics \nFundamentals\n1.1. Proposals\nc3pp23-24\n1.2. Cash Flow\nc3pp24-32\n1.3. Time-Value of Money\nc5-6\n1.4. Equivalence\nc7\n1.5. Bases for Comparison\nc8\n1.6. Alternatives\nc9\n1.7. Intangible Assets\n1.8. Business Model\n2. The Engineering Decision-\nMaking Process\n2.1. Process Overview\nc4pp35-36\n2.2. Understand the Real Problem\nc4pp37-39\n2.3. Identify All Reasonable Technically  \nFeasible Solutions\nc4pp40-41\n2.4. Define the Selection Criteria\nc4pp39-40, \nc26pp441-442\n2.5. Evaluate Each Alternative Against the \nSelection Criteria\nc4pp41-42\n2.6. Select the Preferred Alternative\nc4p42, \nc26pp447-458\n2.7. Monitor the Performance of the Selected  \nAlternative\nc4pp42-43\n3. For-Profit Decision-Making\n3.1. Minimum Acceptable Rate of Return \nc10pp141-143\n3.2. Economic Life\nc11pp160-164\n3.3. Planning Horizon\nc11\n3.4. Replacement Decisions\nc12pp171-178 c9\n3.5. Retirement Decisions\nc12pp178-181 c9\n3.6. Advanced For-Profit Decision Considerations\nc13-17\n4. Nonprofit Decision-Making\n4.1. Benefit-Cost Analysis\nc18pp303-311\n4.2. Cost-Effectiveness Analysis\nc18pp311-314\n5. Present Economy Decision-Making", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 309", "position": 309, "chunk_type": "semantic", "token_estimate": 159}
{"text": "Project Management Institute, A Guide to: the Project Management Body of Knowledge \n(PMBOK\u00ae Guide) [24]. The PMBOK\u00ae Guide provides guidelines for \nmanaging individual projects and defines \nproject management-related concepts. It \nalso describes the project management life \ncycle and its related processes, as well as \nthe project life cycle. It is a globally rec-\nognized guide for the project management \nprofession. Project Management Institute and IEEE \nComputer Society, Software Extension to \nthe Guide to the Project Management Body of \nKnowledge (SWX) [25]. SWX provides adaptations and extensions to \nthe generic practices of project management \ndocumented in the PMBOK\u00ae Guide for man-\naging software projects. The primary con-\ntribution of this extension to the PMBOK\u00ae \nGuide is its description of processes that are \napplicable to managing adaptive life cycle \nsoftware projects. B.W. Boehm, \nSoftware \nEngineering \nEconomics [26]. This book is classic reading on software engi-\nneering economics. It provides an overview \nof business thinking in software engineering. Although the examples and figures are dated, \nit is still worth reading. C. \nEbert \nand \nR. \nDumke, \nSoftware \nMeasurement [27]. This book provides an overview of quantita-\ntive methods in software engineering, starting \nwith measurement theory and proceeding \nto performance management and business \ndecision-making. D.J. Reifer, Making the Software Business \nCase: Improvement by the Numbers [28]. This book is classic reading on making a busi-\nness case in software and IT industries. Many \nuseful examples illustrate how the business \ncase is formulated and quantified.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 311", "position": 311, "chunk_type": "semantic", "token_estimate": 239}
{"text": "Section: Human-Computer Interface", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 314", "position": 314, "chunk_type": "semantic", "token_estimate": 3}
{"text": "Motor Industry Software: Reliability Association", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 314", "position": 314, "chunk_type": "semantic", "token_estimate": 5}
{"text": "The breakdown of topics for the Computing: Foundations knowledge area (KA) is shown \nin Figure 16.1. 1. Basic Concepts of a System or Solution \n\b\n[6*, C10]\nThe problem to be solved has to be analyzed in \ngreater detail for functional requirements, user \ninteractions, performance requirements, device \ninterfaces, security, vulnerability, durability \nand upgradability. A system is an integrated \nset of subsystems, modules and components \nthat perform specific functions independently. Delineating the problem and solution is critical. An engineered system ensures the subsys-\ntems are designed to be:\n\u2022\t Modular: Each subsystem (module) is \nuniform (similar size). \u2022\t Cohesive: Each subsystem performs one \nspecific task. Ideally, systems should be \nhighly cohesive. \u2022\t Coupled: Each subsystem functions inde-\npendently, as much as possible. Ideally, \nsystems should be loosely coupled. Computing \nFoundations\nBasic Concepts\nof a System \nor Solution\nComputer \nArchitecture\nTypes of \nComputer \nArchitecture\nMicroarchitecture \nor Computer \nOrganization\nMemory\nUnit\nInput/Output\nDevices \nControl Unit\nTypes of \nData Structures\nOperations on \nData Structures\nAlgorithms \nand Attributes \nof Algorithms\nAlgorithm \nComplexity\nMeasurement \nof Complexity\nDesigning \nAlgorithms\nSorting \nTechniques\nSearching \nTechniques\nHashing\nProgramming \nLanguage Types\nProgramming \nSyntax, Semantics, \nType Systems\nSubprograms \nand Coroutines\nObject-Oriented \nProgramming\nDistributed \nProgramming and \nParallel Programming\nDebugging\nStandards and \nGuidelines\nProcessor \nManagement\nMemory \nManagement\nDevice \nManagement\nInformation \nManagement\nNetwork \nManagement\nSchema\nData Models \nand Storage \nModels\nDatabase \nManagement \nSystems\nRelational \nDatabase \nManagement \nSystems and \nNormalization\nStructured \nQuery \nLanguage\nData Mining \nand Data \nWarehousing\nDatabase Backup \nand Recovery\nTypes of \nComputer \nNetworks\nLayered \nArchitectures \nof Networks\nOpen Systems \nInterconnection \nModel\nEncapsulation and \nDecapsulation\nApplication Layer \nProtocols\nDesign Techniques for \nReliable and Efcient \nNetworks\nInternet Protocol \nSuite\nWireless and Mobile \nNetworks\nSecurity and \nVulnerabilities\nComputer \nArchitecture and \nOrganization\nData Structures \nand Algorithms\nProgramming \nFundamentals \nand Languages\nOperating \nSystems\nDatabase\nManagement\nComputer \nNetworks and \nCommunications\nHuman Factors:\nUser and \nDeveloper\nUser Human \nFactors\nDeveloper Human \nFactors\nArti\ufb01cial \nIntelligence and \nMachine Learning\nReasoning\nLearning\nModels\nPerception and \nProblem-Solving\nNatural Language \nProcessing\nFigure 16.1. Breakdown of Topics for the Computing Foundations KA", "domains": ["Architectural Patterns and Styles", "Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 315", "position": 315, "chunk_type": "semantic", "token_estimate": 326}
{"text": "COMPUTING FOUNDATIONS   16-3: The subsystems may further be broken \ndown into modules and sub-modules that also \nexhibit these characteristics. The system may include both software and \nhardware subsystems. The hardware must \nbe designed to support the software subsys-\ntems and satisfy all user requirements, espe-\ncially user interfaces (input/output (I/O)) and \nperformance. This section focuses on designing and \nbuilding engineered software subsystems. The applications may require systems that \nare manual or fully or semiautomated; real-\ntime, online or offline; distributed or single- \nlocation, and so on. The software subsystems\u2019 architects have \nto consider appropriate technology, tools, \ndata structure, operating system, database (if \nrequired), user interfaces, programming lan-\nguages, and algorithms for computing solu-\ntions optimally among others. Software requirements, architecture, design, \nconstruction, testing, methods and models, \nquality assurance, and security are discussed in \ndetail in other chapters as independent KAs. The Computing Foundations KA focuses \non explaining the key computer science con-\ncepts a software engineer has to know well to \narchitect, design, construct, deploy and main-\ntain useful, high-quality software subsystems. 2. Computer Architecture and \nOrganization\b\n[6*, C6]\nComputer architecture refers to the com-\nponents of a computer system designed for \nspecific purposes. Computer organization \nexplains how the units within the system con-\nnect and interact to achieve those purposes. System architects must analyze the appli-\ncation for which the computer system is to \nbe designed or developed; identify the crit-\nical components, including I/O devices \nrequired (along with throughput), types and \nquantum of memory, processing power, and \ncoprocessors required; and choose or design \nappropriate computer architecture and orga-\nnization. Contingencies should be built in for \nthe resources required. This content area discusses various com-\nputer architectures and organizations a system \nor software architect needs to know. 2.1. Computer Architecture\b\n[8*, C1.1]\nArchitecture describes what the computer \nor system does, and its components, such as \nmemory, data storage devices, graphics, and \nthe computers or processor\u2019s computing power. A computing system typically has memory, I/O \ndevices and a central processing unit (CPU). These components are connected through \nphysical signal lines called a bus. Typically, three \ntypes of buses are used for specific purposes:\n\u2022\t Address bus, which addresses or accesses \na specific memory location or I/O device. \u2022\t Data bus, which stores (writes) or \nretrieves (reads) data to and from the \nmemory location.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 316", "position": 316, "chunk_type": "semantic", "token_estimate": 383}
{"text": "COMPUTING FOUNDATIONS   16-5: 2.2.4. Flynn\u2019s Architecture or Taxonomy \n\b\n[8*, C9.3]\nThe computing architectures described above \nconsider a single computer at a time. Michael \nJ. Flynn proposed concurrent computer archi-\ntectures, where multiple instruction streams \nand multiple data streams are used in the \nsystem. Software engineers need to know the \ndifferent types of Flynn\u2019s architecture, with \nexamples, including the following:\n\u2022\t Single instruction, single data stream \n(SISD) architecture. \u2022\t Single instruction, multiple data stream \n(SIMD) architecture. \u2022\t Multiple instruction, single data stream \n(MISD) architecture. \u2022\t Multiple \ninstruction, \nmultiple \ndata \nstream (MIMD) architecture. Variants of these architectures include array \nprocessing, parallel processing, and asso-\nciate processing; processing single program \nmultiple data streams, and multiple program \nmultiple data streams. Software engineers are \nexpected to know the differences among these \narchitectures, along with case studies, so that \nthey can choose the right architecture to solve \nthe problem at hand. 2.2.5. System Architecture\b\n[6*, C6]\nSystem architecture is the overall system \ndesign, \nconsidering \nhardware \narchitec-\nture, software architecture, modules, inter-\nfaces, data management, and communication \namong modules. Distributed computing has \nbecome affordable with the development of \nefficient, high-end, high-performance servers, \nstorage, network devices, software, and tools. Several reference designs or architectures are \navailable for any given application. Typical system architectures include the \nfollowing:\n\u2022\t Integrated \nsystem \narchitecture: \nComputing, I/O, data and networking \nare tightly coupled and available in \none box. This architecture is typically \nused in solutions designed for specific \napplications. \u2022\t Distributed \nsystem \narchitecture: \nComputing and storage are located in \nseparate but networked boxes. This archi-\ntecture supports scaling, provides cen-\ntralized or isolated data storage, and \nshares computation load. \u2022\t Pooled system architecture: Several com-\nputing, storage and network resources are \navailable in pools and provided depending \non demand. This architecture provides \nfor efficient use of shared resources. \u2022\t Converged system architecture: As the \nname implies, this is the convergence \nof distributed and pooled architectures. This architecture supports agility and \nscalability. Software engineers are also expected to \nknow and be able to apply various other \narchitectures, including .NET Framework \narchitecture, Unix architecture, and virtual \nmachine architecture. 2.3. Microarchitecture or Computer \nOrganization\b\n[8*, C4]\nMicroarchitecture or computer organization \nexplains how the ISA of a computer is imple-\nmented and how different components in the \nsystem function and interact with one another \nto produce the desired outcome. System architects and engineers must know \nthe various components used in the system \nalong with how they function.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 318", "position": 318, "chunk_type": "semantic", "token_estimate": 401}
{"text": "16-6   SWEBOK \u00ae GUIDE V4.0: that are high-speed memory and internal to \nthe ALU. The ALU executes the processor \ninstruction sets. All operations are typically \ncarried out on the registers. Various schemes may be implemented \nto improve the performance of the ALU, \nincluding pipeline processing and parallel \nprocessing. The latest CPUs provide multiple \ncores and multiple threads that help achieve \nmaximum throughput. Software engineers \nare expected to know the differences between \nmultiple cores and multiple threads, along with \nspecific cases illustrating the best use of these. Specific-purpose coprocessors and asso-\nciate processors are used with main processors \nto support faster processing. 2.3.2. Memory Unit\b\n[8*, C6]\nMemory units are used to store data or infor-\nmation, which is accessed by the CPU. The \ntotal amount of memory a computer can have \nis derived from the maximum number of \naddress lines supported by the CPU. Different \ntypes of memory used in the system include \nread-only memory (ROM), and read-write \nmemory or random access memory (RAM). Software engineers working on perfor-\nmance-critical applications are expected to \nknow the differences among various types \nof memory, including static RAM (SRAM), \ndynamic RAM (DRAM), asynchronous \nDRAM (ADRAM), synchronous DRAM \n(SDRAM), double-data-rate SDRAM (DDR \nSDRAM), rambus DRAM (RDRAM), and \ncache DRAM (CDRAM), along with pros, \ncons and use cases of each. 2.3.3. Input/Output Devices\b\n[8*, C7]\nAs the names imply, input devices are those \nthat provide inputs to the computer system, \nand output devices are those that deliver com-\nputer systems\u2019 output to the user. While some \ndevices are input only (keyboard, mouse, \nmicrophone, etc.) or output only (printer, \nmonitor, speakers, etc. ), a few devices serve \nas both input and output devices (e.g., touch \nscreens, hard disks, USB drives). Software engineers are expected to under-\nstand the interface of the I/O devices with the \nsystem, whether they are memory-mapped I/O \nor I/O-mapped I/O devices, and device drivers \nrequired for the users or applications to interact \nwith the devices through the operating system. 2.3.4. Control Unit\b\n[8*, C4.2]\nThe control unit synchronizes multiple com-\nponents in the computer system. Typically, \ncontrol units are part of the CPU. They inter-\npret instructions and coordinate data move-\nment among different components (memory, \nI/O devices and ALU). Control units are \nalso used to enable or disable components or \ndevices and reset devices.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 319", "position": 319, "chunk_type": "semantic", "token_estimate": 383}
{"text": "COMPUTING FOUNDATIONS   16-7: performed on data. Data structures are \ngrouped primarily based on the physical and \nlogical ordering of data items. Primarily, data is grouped into three types: \nbasic, composite or compound, and abstract. Basic or primitive data types include char-\nacter, integer, float or real, Boolean, and \npointer data. Compound data types are made of multiple \nbasic or primitive, or even multiple compound \ndata types. Some of the compound data types \ninclude sets, graphs, records and partitions. An abstract data type (ADT) is defined by \nits behavior (semantics) from the user\u2019s per-\nspective, specifically from the point of pos-\nsible values and operations. Composite or compound data types are \nfurther grouped under linear, and hierarchical \nor nonlinear data types. Linear data types include one-dimensional \nand multidimensional arrays, strings, linked \nlists (singly linked lists, doubly linked lists, \ncircular lists), stacks, queues, and hash tables. Hierarchical or nonlinear data types \ninclude trees, binary trees, n-array trees, B \ntrees, B+ trees, weighted balanced trees, red-\nblack trees, heaps, binary heaps and graphs. In the current era of free text queries or \nnatural language processing, software engi-\nneers may need to understand strings and var-\nious operations on strings, and to be able to \nanalyze skip lists. Software engineers must understand the \nnuances of various types of data and their \nsizes in memory (short integer, integer, \nlong integer, long long integer, signed and \nunsigned integer, float, double, long double, \ndouble byte character set (DBCS), Boolean, \netc. ), along with how various data types are \nrepresented and stored in memory and how \nvarious operations are performed on them. Sets, graphs, and trees are discussed in more \ndetail in the Mathematical Foundations KA. 3.2. Operations on Data Structures \n\b\n[5*, C2.1 - 2.6]\nBasic operations performed on data structures \ninclude create, read, update and delete (CRUD). Compound data types also require various ways \nof traversing data sets to identify specific data \nitems before performing the operation. It is important to ensure that any insertion \nor deletion of items in a data set or database \ndoes not alter the data set or database in a way \nthat violates any policy under which the data-\nbase was designed and built.", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 320", "position": 320, "chunk_type": "semantic", "token_estimate": 363}
{"text": "COMPUTING FOUNDATIONS   16-7: Compound data types also require various ways \nof traversing data sets to identify specific data \nitems before performing the operation. It is important to ensure that any insertion \nor deletion of items in a data set or database \ndoes not alter the data set or database in a way \nthat violates any policy under which the data-\nbase was designed and built. Additional operations performed on data \nstructures include sorting the data items in a \nspecific order, searching and locating a data \nitem, and merging two or more data sets \ninto one set without disturbing the policy \non which the data set is built. Searching \nand sorting algorithms are discussed in the \nnext section. Different data structures are created to suit \nspecific applications, such as stacks, queues, \ntrees, and graphs. Software engineers are \nencouraged to learn the traversals through non-\nlinear data structures, which include different \ntree parsers (pre-order, in-order, and post-order \ntree traversals), CRUD operations on trees, tree \nbalancing, binary search trees (BSTs), AVL \ntrees, and red-black trees, and to learn tree \nsearch algorithms (depth first, breadth first, \nshortest paths, etc.). Some of these are dis-\ncussed in the Mathematical Foundations KA. 3.3. Algorithms and Attributes of Algorithms \n\b\n[18*, C26, C27]\nAll software implements logic to perform the \nrequired function. That logic or algorithm to \nperform a specific task has to be designed or \nchosen with consideration for system per-\nformance, security, portability, maintain-\nability, scalability and simplicity, among \nother concerns. The complexity of an algorithm is deter-\nmined by measuring the computational \nresources (computing power and space) con-\nsumed by that algorithm for a given set of data. A thorough understanding of data struc-\ntures is vital for analyzing and designing good \nalgorithms. Refer to the \u201cData Structures and \nOrganization\u201d content area for more details. The attributes of algorithms are many and \ninclude functionality, correctness, robustness,", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 320", "position": 320, "chunk_type": "semantic", "token_estimate": 312}
{"text": "16-8   SWEBOK \u00ae GUIDE V4.0: modularity, maintainability, programmer- \nfriendliness (ease of integration into the project \nand ease of use), user-friendliness (i.e., how \neasily it is understood by people), need for pro-\ngrammer time, simplicity, and extensibility. A commonly emphasized attribute of algo-\nrithms is \u201cperformance\u201d or \u201cefficiency.\u201d \nThe parameters that matter for an algo-\nrithm\u2019s resource consumption include, but are \nnot limited to:\n1. Hardware. 2. Software. 3. Algorithm selection and design for a spe-\ncific problem. 4. Effective implementation. 3.4. Algorithm Complexity\b\n[5*, S1, S3, S4, \n \n\b\nS5, S6, S7, S11, S12]\nThe complexity of an algorithm is a mea-\nsure of the resources it consumes (computing \npower or memory) for a specific problem and \ngiven data set. Choosing the right data structures and \noperations on data structures and ensuring \noptimal implementation of the algorithm also \neffect the algorithm\u2019s complexity. 3.5. Measurement of Complexity\b\n[5*, S1.1, \n \n\b\nS3, S4, S5, S6, S11.1, S12.1]\nOften, the complexity of an algorithm is \ndenoted by the resources consumed in the \nworst-case scenario. The complexity of algo-\nrithms is typically measured by asymptotic \nnotations for best-case, worst-case and aver-\nage-case scenarios in terms of resource con-\nsumption for a given data set. Popular asymptotic notations for algo-\nrithms are listed in Table 16.1. Learning the computation of the listed \nnotations for different sets of input data (e.g., \nsorted, unsorted, and sorted in reverse order) \nis important. The complexity of an algorithm can be con-\nstant, linear, quadratic, cubic, exponential or \nlogarithmic. These complexities are described \nin Table 16.2. Typically, constants are not \nconsidered when computing the efficiency of \nan algorithm. 3.6. Designing Algorithms\b\n[18*, Part IV, \n \n\b\nPart VI]\nThe software engineer must consider the \nspecific application\u2019s purpose and the per-\nformance requirements in order to select an \nappropriate algorithm. In addition, the soft-\nware engineer must consider linear pro-\ngramming versus parallel programming and \nsingle- versus multi-threading. The efficiency of an algorithm is measured \nby the resources it consumes, primarily com-\nputing time and memory. A software engineer has to know a few \nstandard algorithms and relevant concepts, \nincluding the following: \nAsymptotic Notations\nDescription\nBig O\nBig O notation provides the upper bound of operations (worst-case \nscenario) for a function f(n). little-o\nLittle o notations are used to depict scenarios where the upper bound \nis not tight. Big Omega (\u03a9)\nBig \u03a9 notations are used to depict lower bounds (best-case scenarios) \nfor a function f(n).", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 321", "position": 321, "chunk_type": "semantic", "token_estimate": 403}
{"text": "16-10   SWEBOK \u00ae GUIDE V4.0: Typically, iterative methods are better than \nrecursive methods for CPU performance and \nmemory. However, recursion provides easy \nmethods for solving specific problems, such as \ntree operations. If adequate computing power \nand memory are available, the difference \nbetween recursive and iterative implementa-\ntion methods is negligible. In the case of applications where certain \nsorting algorithms work best, software engi-\nneers should learn and accommodate any \npreconditions and complexities (demand on \nmemory and computing power) involved in \nusing them. 3.8. Searching Techniques\b\n[5*, C6]\nSearching is a process of finding specific data \nitems or records in a set of data items or a \ndatabase. Search algorithms are primarily catego-\nrized into sequential search (data set is tra-\nversed sequentially until the end of the data \nset) and interval search (the search moves effi-\nciently through a sorted list, balanced tree, \netc. ), based on how data sets are organized. Depending on the type of the data item \nand the size of the data set, various search \ntechniques are used to find the desired data \nitem. Popular search algorithms include \nlinear, binary, jump, interpolation, exponen-\ntial, Fibonacci, sub-list (search a linked list in \nanother list), logarithmic, tree and hashing. 3.9. Hashing\b\n[18*, C11.2]\nHashing is one of the very important and \npopular technique in which data of arbitrary \nsize (key values) are converted into values \nof fixed size called hash values, which index \ninto a hash table so the data records can be \nlocated easily. The function used for that pur-\npose is called a hash function, and the values \nreturned are called hash values, hash codes, \ndigests, or hash keys. Different properties of hash functions, such \nas uniformity, efficiency, universality, applica-\nbility, deterministic, defined or variable range, \ndata normalization, testing, and measurement, \nmust be understood and considered when \ndesigning or choosing a hash function. Various types of hash functions are designed \nfor different types of key values, applica-\ntions, and database sizes. Hash function \ntypes include trivial hash function, division \nmethod, mid-square method, digit folding \nmethod, \nmultiplicative \nhashing, \ndouble \nhashing, open and closed hashing, rehashing, \nextendible hashing, and cryptographic and \nnoncryptographic hash functions. Software engineers are expected to learn, \nimplement and be able to compare different \ntypes of hashing algorithms, various collision \nresolution techniques, linear probing, qua-\ndratic probing, separate chaining, and open \naddressing. 4.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 323", "position": 323, "chunk_type": "semantic", "token_estimate": 388}
{"text": "COMPUTING FOUNDATIONS   16-11: Subprograms and Coroutines\b\n[4*, C6.3]\nSubprograms or functions are programs or \nbuilding blocks that perform specific (part) \nfunctions in the scope of a complete project. Subprograms provide for breaking the larger \nprogram into smaller modules. The modules \nare typically sections of code that are used \nmultiple times in multiple places. The subpro-\ngrams reduce memory space, improve read-\nability and maintainability of the program, \nand execute parts of the program with dif-\nferent values at different places and times. The subprograms have an entry point and \ntypically have multiple input parameters on \nwhich the subprogram acts and produces \noutput. The scope of input parameters is local \nto the subprogram. Subprograms that return \nvalue by their name (which can be used as a \nvariable in a statement) are called functions, \nand subprograms designed not to return any \nvalue are called procedures. By default, the scope of subprogram \nparameters is dynamic and local to the sub-\nprogram. However, if the subprograms have \nto remember their history or previous values, \nthey have to be declared static or as specified \nin the chosen programming language. Different programming languages sup-\nport one or more types of parameters\u2019 \npassing, including pass-by-value, pass-by-ref-\nerence, pass-by-name, pass-by-result and", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 324", "position": 324, "chunk_type": "semantic", "token_estimate": 203}
{"text": "16-12   SWEBOK \u00ae GUIDE V4.0: For example, a \nClass can be defined by the characteristics \nand operations of a vehicle, whereas objects \nare instances of the class vehicle such as car, \nbus or truck. The objects interact with one another using \nthe methods or operations. Important characteristics of object-ori-\nented programming (OOP) are Abstraction, \nEncapsulation, Inheritance and Polymorphism. Abstraction is a property that exposes only \nrequired or relevant information and func-\ntionality to the user, hiding the details and \nnonessentials. Thus, the implementation is \nhidden from the user of the superclass. One of the key benefits of encapsulation is \nthe ability to hide or protect data from unau-\nthorized users. The software engineer can \ngive different levels of protection to data and \nmethods by declaring them private (local to \nclass) or public (available to other classes). This also protects data from corruption, either \nintentional or accidental. Subroutine S1\nSubroutine S2\nSubroutine S3\nResume S1\nResume S3\nResume S3\nResume S2\nResume S2\nResume S1\nFigure 16.3. Example of Coroutine", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 325", "position": 325, "chunk_type": "semantic", "token_estimate": 169}
{"text": "COMPUTING FOUNDATIONS   16-13: Inheritance is an important feature of \nOOP, where a subclass or derived class \ninherits the properties of a superclass or base \nclass. Primary inheritance modes include \npublic, protected and private modes. Polymorphism is another key feature of \nOOP. Polymorphism is a provision of pro-\nviding a single interface to entities of dif-\nferent types. For example, shape could be \na base class with draw as a method, and \nobjects could be a circle, triangle or rect-\nangle. The implementation of method draw, \nthough the name is the same, differs for a \ncircle, triangle and rectangle. Polymorphism \nhas two types:\n\u2022\t Static or compile-time polymorphism: The \nmethods (functions) or operators are \noverloaded and resolved during compile \ntime. Example: The methods, though \nthey have the same name, will have dif-\nferent types or numbers of parameters. \u2022\t Dynamic or runtime polymorphism: The \noverloaded method to be executed is \nresolved at runtime. Example: When \nboth base class and derived class have the \nsame method, the base class method is \nsaid to be overridden. Popular OOP languages include C++, C#, \nCobol 2002, Java, Python, Lisp, Perl, Object \nPascal, Ruby and Smalltalk. It\u2019s important to recognize that using \nOOP requires a different mindset than using \ntraditional, procedural, or structured pro-\ngramming does. 4.5. Distributed Programming and Parallel \nProgramming\b\n[4*, C6.6]\nIn a distributed computer system, multiple \nparts of the software are run on multiple com-\nputers, connected through computer networks, \nto achieve a common goal. Writing such pro-\ngrams is called distributed programming. Parallel programming is a type of com-\nputing in which different parts of the program \nare run in parallel to achieve the same objec-\ntive or goal. Table 16.3 compares distributed \nand parallel programming. High Performance \nComputing (HPC) aims to speed-up the exe-\ncution of software, both distributed program-\nming and parallel programming are ways to \ndo this and is increasingly used together in \nhybrid software. 4.6. Debugging\b\n[6*, C2.2.2]\nPrograms, when written, are expected to \nfunction properly and generate the expected \noutput. However, programmers often face \nthree types of errors \u2014 syntax errors, runtime \nerrors, and logical errors \u2014 at different stages \nof software development. Syntax errors are deviations from the stan-\ndard format specified by programming lan-\nguages. These are explicitly identified by \ncompilers and are easy to fix.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 326", "position": 326, "chunk_type": "semantic", "token_estimate": 382}
{"text": "16-14   SWEBOK \u00ae GUIDE V4.0: An estimated 82% of vulnerabilities \nare caused by clashes between program-\nming styles.\u00a7 \nHence, quality-conscious companies often \nhave defined tools, standards and guidelines, \nwhich set rules and recommendations for \ntheir programmers and testers to follow. When software teams follow appro-\npriate coding standards, they create read-\nable, cleaner, portable, reusable, modular, \n\u00a7\t https://www.ptsecurity.com/ww-en/analytics/web-vulnerabilities-2020/\neasily maintainable, less defect-prone soft-\nware code, and project schedules become \nmore predictable. The following practices can \nhelp organizations implement such standards \nsuccessfully:\n\u2022\t Carefully choose the coding standards \nand guidelines that suit the application or \nsystem being developed. \u2022\t Consider open standards created by \nParameters\nDistributed Programming\nParallel Programming\nFunctionality\nA task is shared and executed by mul-\ntiple computers that are networked. Two or more processors on a computer \nshare and execute the task in parallel. Computers\nMultiple computers in different loca-\ntions but networked. Two computer with one or more \nprocessors or cores. Memory\nEach computer has its own memory. Computers can have shared or \ndistributed memory. Communication\nComputers communicate \nthrough networks. Processes communicate through a \nbus or inter-process communication \n(IPC) methods. Benefits\nFailure of one computer does not \naffect the functioning of the task, as \nit is transferred to another computer. Provides scalability and reliability for \nend users. As multiple processes run in parallel, \ngenerally the performance increases. Failure of one processor does not \naffect the performance of other \nprocessors or cores\nDisadvantages\nHaving multiple systems could \nbecome expensive; the cost must be \nweighed against customers\u2019 need for \napplication uptime. Network delays could affect the \noverall functioning of the task. Designing an efficient distributed \ncomputing system is relatively difficult. Using multiple processors or cores \ncould be expensive. Dependency of one process \non another process could \nintroduce latency. Example  \nApplications\nTelephone and cellular networks, \ninternet, World Wide Web networks, \ndistributed database management \nsystems, network file systems, grid \ncomputing, cloud computing. 2D and 3D simulations and rendering \nin computer graphics, scientific \ncomputing. Example  \nProgramming  \nLanguages, \nlibraries \nengines, \nframaworks \nGolang, Elixir, Scala, Fortran,  \nC and C++. Apache Hadoop, Apache Spark, \nApache Flink, Apache Beam, CUDA, \nOpenCL, OpenHMPP, MPP, \nOpenMP for C, C++ and Fortran. Table 16.3. Comparison of Distributed and Parallel Programming", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 327", "position": 327, "chunk_type": "semantic", "token_estimate": 361}
{"text": "COMPUTING FOUNDATIONS   16-15: community participation, such as Software \nEngineering Institute (SEI) Computer \nEmergency Response Team (CERT), as \nwell as closed standards created by working \ngroups such as the Motor Industry Software \nReliability Association (MISRA). \u2022\t Educate programmers to follow adopted \nstandards and guidelines. \u2022\t Use tools and periodic reviews to ensure \nadopted \nstandards \nand \nguidelines \nare followed. \u2022\t Review and revise standards and guide-\nlines from time to time, learning from \nproject execution. SC 22 is a subcommittee of the Joint \nTechnical Committee ISO/IEC JTC 1 of the \nInternational Organization for Standardization \n(ISO) and the International Electrotechnical \nCommission (IEC) for defining standards for \nprogramming languages, their environments \nand system software interfaces (ISO/IEC \nJTC 1/SC 22). Software engineers are recom-\nmended to refer these standards as well. 5. Operating Systems\b\n[19*]\nAn operating system (OS) is software that \nmanages the computer\u2019s hardware and pro-\nvides a platform for software applications. Software engineers need a good general \nunderstanding of OSs and OS objectives, ser-\nvices, and functions. Different types of OSs have been designed \nover time to support various types of systems \nor applications, including batch processing, \nmultiprogramming, \ntime-sharing, \nand \ndual-mode operation \u2014 for protecting I/O, \nmemory, CPU, kernels and micro-kernels. To choose an appropriate OS, software \nengineers have to analyze different types of \noperating systems, such as single-user, sin-\ngle-tasking, multiuser, multitasking and \nmulti-threading OSs; real-time OS (RTOS); \nnetwork OS; and distributed OS. For small \nsystems, an operating system may not be \nrequired. It is important to study examples \nof each type and compare their benefits and \nlimitations. Software engineers need to understand \noperating systems\u2019 basic structure, system \narchitecture types, design approaches, the \narchitecture of distributed OS and issues in \ndistributed OS. An operating system typically has four \nmajor components: processor management, \nmemory management, device management \nand information management. 5.1. Processor Management\b\n[19*, C2, C8]\nSoftware engineers must understand the \nconcepts of processor, process and address \nspace. They must understand booting, pro-\ncesses, cores, threads, user and kernel threads, \nfork and exec, synchronization, and hardware \nsupport for locking. They should compare and \ncontrast various CPU scheduling concepts, \nscheduling algorithms, algorithm evalua-\ntions, multiple processor scheduling and real-\ntime scheduling, concurrent programming, \ndeadlocks, critical regions, conditional crit-\nical regions, and monitors. Communication among different pro-\ncesses is important in multitasking, mul-\ntiuser OSs.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 328", "position": 328, "chunk_type": "semantic", "token_estimate": 381}
{"text": "16-16   SWEBOK \u00ae GUIDE V4.0: (SRTF), priority scheduling, round robin and \ncombined schemes). 5.2. Memory Management\b\n[19*, C3]\nA software engineer needs a very good under-\nstanding of how memory is managed in the \nsystem and of the different types of memory \nand relevant concepts \u2014 physical memory, \nvirtual memory, secondary memory, memory \nhierarchy, linking and memory allocation. Engineers must understand memory frag-\nmentation (both external fragmentation, \ninternal fragmentation), and various memory \nmanagement \nconcepts, \nincluding \nunits, \npaging, page tables, segmentation, paged \nsegmentation, virtual memory management, \ndemand paging, page replacement, thrashing \nand swapping. Memory is allocated to processes in dif-\nferent ways \u2014 for example, through contig-\nuous allocation, noncontiguous allocation, \ndynamic partitioned memory allocation, stat-\nic-swapping and overlays. An understanding of logical addresses, \npartitions, static versus dynamic memory \nallocation, free space management, and \ndefragmentation of memory blocks is also \nimportant. As the physical memory available is always \nlimited, various memory page replacement \nstrategies are designed and implemented. These \nstrategies include first-in-first-out (FIFO), \nnot-recently-used (NRU), least recently used \n(LRU), most recently used (MRU), least fre-\nquently used (LFU), most frequently used \n(MFU), longest distance first (LDF), second \nchance, and aging among others. 5.3. Device Management\b\n[19*, C5]\nA software engineer must have good knowl-\nedge of different types of I/O devices \u2014 mem-\nory-mapped and I/O-mapped devices, block \nand character devices, and buffering devices. Engineers should compare and contrast \npolled, interrupt-driven and direct memory \naccess (DMA) I/O devices, and blocking \nversus non-blocking I/O devices. Device drivers are software programs \nthat provide an interface between hardware \nand applications. Software engineers should \nunderstand device drivers, the various types \nof device drivers, device driver tables, device \ndriver functions, and interfaces for various \ntypes of hardware devices, as well as hard-\nware and software interrupts and interfaces \nby interrupts and polling. Software engineers should also understand \nthat issues with caching, scheduling, spooling \nand performance can arise for shared devices \nin multiuser, multitasking OSs and device a \nmechanism for resolving them. 5.4.", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 329", "position": 329, "chunk_type": "semantic", "token_estimate": 326}
{"text": "16-16   SWEBOK \u00ae GUIDE V4.0: Software engineers should also understand \nthat issues with caching, scheduling, spooling \nand performance can arise for shared devices \nin multiuser, multitasking OSs and device a \nmechanism for resolving them. 5.4. Information Management\b\n[19*, C4]\nSoftware engineers need to understand the \nfollowing: \n\u2022\t The concept of a process, a system pro-\ngrammer\u2019s view of processes, an operating \nsystem\u2019s view of processes, and operating \nsystem services for process management\n\u2022\t File system management, storage manage-\nment, file attributes, directory structure, \nfile system structure, mass storage struc-\nture, I/O systems, protection and security\u00a0\n\u2022\t User and operating system views of the file \nsystem and various types of file systems \u2014 \nsimple file system, symbolic file system, \nlogical file system and physical file system\nEngineers should be familiar with various \noperations including access control lists (ACLs), \naccess matrix, access control, access control ver-\nification, capabilities allocation strategy, I/O \ninitiators, device strategy, device handlers, disk \nscheduling, disk space management, existence \nand concurrency control, schemes and com-\nbined schemes, authentication schemes, direc-\ntory namespace, hierarchies, directed acyclic \ngraph (DAGs), hard and soft links. 5.5. Network Management\b\n[4*, C4.1]\nNetwork management is the process of \nadministering and managing various types of \nnetworks. This content area includes network", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 329", "position": 329, "chunk_type": "semantic", "token_estimate": 205}
{"text": "COMPUTING FOUNDATIONS   16-17: management concepts, distributed objects, \ndistributed file systems, and network archi-\ntecture, design, issues and resolutions. A network manager will need detailed \nknowledge of physical and logical time, as \nwell as internal and external synchroniza-\ntion protocols in network management such \nas Cristian\u2019s algorithm, Berkeley\u2019s algorithm, \nthe Network Time Protocol, Lamport\u2019s log-\nical clock, Vector clocks, Casual ordering of \nmessages, and global state. Other important topics include distrib-\nuted computation, termination detection, \ndistributed mutual exclusion and election, \nsimple and multicast-based mutual exclusion \nalgorithms; Centralized, Ring based, Ricart \nAgrawala\u2019s algorithm, Maekawa\u2019s algorithm, \nElection algorithms, Bully\u2019s algorithm and \nmulticast communication. In addition, software engineers should \nunderstand important principles include hard-\nware security, external security, operational \nsecurity, password protection, access control, \nsecurity kernels, and the layered approach. 6. Database Management\nA database is a collection of related data ele-\nments, collected specifically for use by one or \nmore applications and stored in an organized \nformat for easy and quick access, using one or \nmore key values. The data items or elements \nare stored in one or more databases or files, \nand the relationship among them is estab-\nlished using a database schema. Basic operations performed on the database \ninclude creating the database and its elements \n(table, index, views, functions, procedures, \netc. ), deleting or dropping items from the \ndatabase, modifying contents and structure \nof the database, and data retrieval, comment, \nand rename actions. Different types of databases include rela-\ntional databases, not only structured query \nlanguage (NoSQL) databases, columnar data-\nbases, object-oriented databases, key-value \ndatabases, document databases, hierarchical \ndatabases, graph databases, time series data-\nbases, and network databases. Understanding \nwhat type of database works best for specific \napplications and analyzing the definition, \nstructure, specific pros and cons of each type \nof database; what along with examples helps \nsoftware engineers choose the right type of \ndatabase for a given application. When selecting a database, software engi-\nneer should evaluate data models, storage \nmodels, types of databases, key values, graphs, \ncolumn family, volume of data, consistent data \naccess time, and the number of users or appli-\ncations accessing the database (traffic), etc. The learners and users of the database system \nneed to create two roles (database user and \ndatabase architect), review several case studies \nof increasing complexity, create multiple data-\nbases, and analyze the information. This process \nsignificantly helps one to understand and inter-\nnalize the database design and management. 6.1.", "domains": ["Architectural Patterns and Styles", "Design Patterns", "Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 330", "position": 330, "chunk_type": "semantic", "token_estimate": 398}
{"text": "COMPUTING FOUNDATIONS   16-17: This process \nsignificantly helps one to understand and inter-\nnalize the database design and management. 6.1. Schema\b\n[22*, C2.1.4]\nA database schema is a structure or record of \ndata items, defined in one or more database \ntables, and the relationships between them. The schema may also contain formulae to \ncheck the integrity of data items, relationships, \nindexes, functions or procedures and views. While a physical schema explains how the \ndatabase is designed at physical level (files), \nthe logical schema describes how different \ndata items are defined in one or more tables \nand interconnected. Different types of schemata used in the \nindustry include star, snowflake and fact con-\nstellation schemata. Different types of keys used \nin schemata include Primary Key, Secondary / \nAlternate Key, Foreign Key, Composite Key, \nSurrogate Key and Candidate Key. Parameters that influence the definition \nand use of schemata include overlap preserva-\ntion, extended overlap preservation, normal-\nization and minimality. 6.2. Data Models and Storage Models \n\b\n[22*, C2.3]\nA data model specifies the logical aspects of \ndata structure in a data store, and a storage", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 330", "position": 330, "chunk_type": "semantic", "token_estimate": 181}
{"text": "16-18   SWEBOK \u00ae GUIDE V4.0: model specifies the physical aspects of data \nstructure in a data store. It is difficult to \nachieve both data consistency and high avail-\nability in a database. The two primary data models used to dis-\ntinguish databases are the following:\n\u2022\t The ACID (atomicity, consistency, isola-\ntion, durability) model provides for high \ndata consistency. ACID-compliant data-\nbases are ideal for a finance-intensive \napplication. \u2022\t The BASE (basically available, soft state, \neventual consistency) model provides \nflexible methods to process data, which \nsuits NoSQL database types. Types of storage models include the \nfollowing:\ni.\t\nDAS (direct access storage): Storage \ndevices are physically or directly con-\nnected to the computer that pro-\ncesses the data. ii. NAS (network access storage): Data is \nstored in a network and accessed by mul-\ntiple computers or applications. iii. SAN (storage area network): Data is stored \nin multiple servers and efficiently provided \nto users through a computer network. 6.3. Database Management Systems \b [22*, C1.3]\nDatabase management systems (DBMSs) are \nsoftware systems that provide the necessary \ntools for maintaining data optimally, retrieving \nstored information effectively, protecting and \nsecuring stored data, and managing access for \nusers of different levels of authority. Typical DBMSs include:\n\u2022\t A database engine: This is the core of a \nDBMS. The database engine manages \nefficient storing and retrieving of data. Users with privileges can access the data-\nbase engine. \u2022\t A database manager: This program or set \nof programs performs all DBMS func-\ntionality in a database (creating, purging, \nbacking up, retrieving, maintaining, \ncloning and deleting data). It is also \nresponsible for maintaining the DBMS \nwith patches and updates. \u2022\t A runtime database manager (RDM): \nThe RDM checks for user authentica-\ntion and privileges before any operation \nis performed, provides access to a con-\ntext-based database, provides concurrent \naccess to the database by multiple users, \nand ensures data integrity. \u2022\t Database languages: These help in storing, \nretrieving, modifying and retrieving data, \ncontrolling user access (privileges), speci-\nfying schemata and views, and performing \nvarious operations. Popular database lan-\nguages include data definition language \n(DDL), database access language (DAL), \ndata manipulation language (DML), \nTransaction Control Language (TCL), \nand data control languages (DCL), \n\u2022\t A query processor: This basic and key com-\nponent of DBMS provides an effective, \nrich and English-like interface for users \nto access the database and perform var-\nious functions or operations.", "domains": ["Design Patterns", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 331", "position": 331, "chunk_type": "semantic", "token_estimate": 394}
{"text": "16-18   SWEBOK \u00ae GUIDE V4.0: \u2022\t Database languages: These help in storing, \nretrieving, modifying and retrieving data, \ncontrolling user access (privileges), speci-\nfying schemata and views, and performing \nvarious operations. Popular database lan-\nguages include data definition language \n(DDL), database access language (DAL), \ndata manipulation language (DML), \nTransaction Control Language (TCL), \nand data control languages (DCL), \n\u2022\t A query processor: This basic and key com-\nponent of DBMS provides an effective, \nrich and English-like interface for users \nto access the database and perform var-\nious functions or operations. \u2022\t Reporting: Reporting applies specified fil-\nters, extracts requested data and records \nfrom one or more database tables, and \npresents information as specified. Several free and open-source database \nmanagement systems are available. 6.4. Relational Database Management Systems \nand Normalization\b\n[22*, C4]\nConventional file system-based databases \nsuffered from data redundancy, data incon-\nsistency, data access challenges, unautho-\nrized access, lack of concurrent access, among \nother issues. A relational database management system \n(RDBMS) stores data in tables and, unlike in \na DBMS, its data tables relate to one another, \nmultiple data items can be accessed simulta-\nneously, a large amount of data is handled, \nmultiple users can access data concurrently, \ndata redundancy is significantly reduced, and", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 331", "position": 331, "chunk_type": "semantic", "token_estimate": 202}
{"text": "COMPUTING FOUNDATIONS   16-19: multiple levels of data security are supported. Computer science engineers must under-\nstand the difference between the various types \nof RDBMS, such as Objective RDBMS, Object \nOriented RDBMS, be familiar with examples, \nand know the applications they suit best. Database normalization is the process of \norganizing data in a database and removing \ndata redundancy and data inconsistency from \nthe tables. Normalization might increase \nthe number of tables and increase the query \ntime. If this occurs, then \u2014 depending on the \napplication and the requirement \u2014 de-nor-\nmalization is applied, where data redundancy \nis added for quicker data access. Different types of database normalizations \nare the following:\ni. First normal form (1 NF): Removes dupli-\ncation or redundancy. Each table cell \nhas a single value (creates more entries \nand tables). Each row has unique values. Related data is identified with a unique key. ii. Second normal form (2 NF): The table \nshould be in 1 NF; no partial dependency \n(creates separate tables with records refer-\nenced by multiple records or tables). iii. Third normal form (3 NF): The table \nshould be in 2 NF. Transitive dependen-\ncies are removed. iv. Boyce-Codd normal form (BCNF/3.5 \nNF): The table should be in 3 NF, and X \nshould be the super-key for any (X->Y). v.\t\nFourth normal form (4 NF): The table \nshould be in 3.5 NF and should not have \na multivalued dependency. vi. Fifth normal form (5 NF): The table \nshould be in 4 NF and cannot be split \ninto any more tables without losing data. vii. Sixth normal form or domain/key normal \nform (6 NF/DKNF): The table should be in \n5 NF, and every join dependency is trivial. Most databases are typically normalized \nuntil 3 NF or BCNF. An alternative normal \nform, DKNF, is defined where insertion and \ndeletion of anomalies is avoided (see [13]). Database \nengineers \nare \nencouraged \nto understand normalization forms with \nexamples and case studies and to understand \nthe challenges one would face if the database \nwere not normalized. Although normaliza-\ntion is essential and provides various benefits, \nit also increases the number of tables and pro-\ncessing time. 6.5. Structured Query Language  \n\b\n[22*, C6, C7, C8]\nStructured query language (SQL) is a stan-\ndard and popular database language for cre-\nating, updating, and deleting databases and \nfor retrieving information from databases. SQL is an inevitable part of most database \nmanagement systems.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 332", "position": 332, "chunk_type": "semantic", "token_estimate": 398}
{"text": "16-20   SWEBOK \u00ae GUIDE V4.0: Data warehousing extracts data from mul-\ntiple databases efficiently and stores it in a \ncommon database so data mining can be per-\nformed effectively on the compiled data. Data \nwarehouses are typically huge, as they store \nhistorical data records. Data mining extracts requested informa-\ntion from the data warehouse, applying var-\nious filters and conditions. Data mining \napplies pattern recognition algorithms to \nhuge data sets to generate required reports. The different types of warehouses include \nenterprise data warehouse (EDW), operational \ndata store (ODS), and data mart (DM). Many efficient tools are available to create \ndata warehouses and mine data from them. Database engineers must know different \ndata mining techniques, including associa-\ntion, clustering, classification, sequential pat-\nterns and prediction, and know how to apply \nthem for various uses and industries, such as \nhealth care, fraud detection, customer rela-\ntionship management, finance and banking, \nanomaly detection, prediction, neural net-\nworks, statistics, and data visualization. 6.7. Database Backup and Recovery\b [22*, C22]\nDatabase systems are prone to failures, and \ndata can be corrupted. It is crucial to prevent \ndata corruption and \u2014 if it does occur \u2014 to \nrecognize it immediately and recover the data. Updating the database for transactions \nmust be carried out carefully (with commits \nat specific checkpoints), and must incorporate \ntechniques such as undoing, deferred updates, \nimmediate updates, caching or buffering, and \nshadow paging. Databases must be backed up periodi-\ncally to ensure data safety. Backup techniques \ninclude Full database backup, Differential \nbackup and Transaction log backup. 7. Computer Networks and \nCommunications\b\n[4*, C4.1], [24*, C1]\nA computer network is a group of devices that \nare connected for sharing information. The \nconnected devices (nodes on the network) \ncan be located near one another, on the same \npremises, or somewhere else. Networking is \nrequired for certain benefits, including cer-\ntain modes of communication and infor-\nmation sharing; the ability to share devices \nsuch as printers, routers and video cameras; \nglobal information and data storing; security \nand policy enforcement; remote monitoring; \nshared business models; and web browsing. As we are in the internet era, computer net-\nworking is a critical element in computing, and \nthe practitioners of computer science engineering \nhave to study computer networks and commu-\nnication concepts, including examples and case \nstudies. Many computing paradigms (distrib-\nuted computing, grid computing, cloud com-\nputing, etc.) are based on networking principles.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 333", "position": 333, "chunk_type": "semantic", "token_estimate": 395}
{"text": "16-20   SWEBOK \u00ae GUIDE V4.0: Many computing paradigms (distrib-\nuted computing, grid computing, cloud com-\nputing, etc.) are based on networking principles. It is important for software engineers to \nunderstand the following: \n\u2022\t Different types of computer networks. \u2022\t Layered architectures of networks. \u2022\t Open systems interconnect (OSI) layers \n\u2022\t Encapsulation and decapsulation. \u2022\t Application layer protocols. \u2022\t Design techniques for reliable and effi-\ncient networking. \u2022\t Internet and packet delivery. \u2022\t Wireless and mobile networks. \u2022\t Security and vulnerabilities. 7.1. Types of Computer Networks \n\b\n[4*, C4.1], [24*, C1.2.1]\nDifferent types of computer networks are \ndesigned and used based on the need, such as \nthe following:\n1. Personal \narea \nnetwork \n(PAN) \n/ \nhome network. 2. Local area network (LAN). 3. Wireless local area network (WLAN). 4. Wide area network (WAN). 5. Campus area network (CAN). 6. Metropolitan area network (MAN). 7. Storage area network (SAN). 8. System-area network (SAN). 9. Enterprise private network (EPN). 10. Virtual private network (VPN).", "domains": ["Architectural Patterns and Styles", "Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 333", "position": 333, "chunk_type": "semantic", "token_estimate": 160}
{"text": "COMPUTING FOUNDATIONS   16-21: It is important to understand each of the \nabove network type as well as examples, ben-\nefits, limitations and available solutions to cir-\ncumvent challenges. 7.2. Layered Architectures of Networks \n\b\n[24*, C1.5]\nA communication system includes hardware \nand software, and these components have \nbecome complex to meet complicated use \nscenarios and user demands. To support the \nimplementation and maintenance of such sys-\ntems, ISO has developed a layered approach, \nwhere every layer has specific functionality for \nprocessing data and transferring it from one \nnode to another. Each layer is independent in its function-\nality and provides services from the lower \nlayer to the upper layer without providing \ndetails of how each layer\u2019s service is imple-\nmented. Each layer (\u201cn\u201d) on a machine com-\nmunicates with the same layer (\u201cn\u201d) on the \npeer machine. Rules used in a conversation \nare called layer-n protocol (see Figure 16.4). The basic elements of the layered approach \nare service, protocol and interface. \u2022\t Service: The set of actions a layer provides \nto the adjacent higher layer is the service. \u2022\t Protocol: The set of rules a layer uses \nto exchange information with the peer \nentity is called the protocol. The rules are \nprimarily for managing both the contents \nand order of the messages used. \u2022\t Interface: The interface provides a \nmedium for transferring the message \nfrom one layer to another layer. Software engineers are expected to under-\nstand the essential functionalities required, \nvarious modes in which the data or information \nis communicated from one layer to the other, \nand data packet formation and interpretation \nat peer levels. A useful exercise is to take exam-\nples of different protocols and analyze them. 7.3. Open Systems Interconnection Model \n\b\n[24*, C1.5]\nThe Open Systems Interconnection (OSI) \nModel was defined by the ISO. It serves as \na reference model for information exchange \nbetween applications on two systems or com-\nputers through a physical medium. Layer 5 (Application Layer)\nLayer 5 (Application Layer) \nLayer 4\nLayer 4\nLayer 3\nLayer 3\nLayer 2\nLayer 2\nLayer 1 (Physical Layer)\nLayer 1 (Physical Layer)\nLayer 5 Protocol\nLayer 4 Protocol\nLayer 3 Protocol\nLayer 2 Protocol\nLayer 1 Protocol\nFigure 16.4. Pictorial Representation of Layered Networking", "domains": ["Architectural Patterns and Styles", "Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 334", "position": 334, "chunk_type": "semantic", "token_estimate": 370}
{"text": "16-22   SWEBOK \u00ae GUIDE V4.0: OSI proposes seven (7) layers, and each \nlayer is assigned a specific task. Each layer \nindependently processes the data it receives \nfrom the upper or lower layer and passes it to \nthe lower or upper layer, as appropriate. Engineers must understand each OSI \nlayer, its functionality protocol, the input \nand output of each layer in each direction \n(from lower layer to upper layer and vice \nversa). Engineers should analyze whether \nall seven layers are required for all proto-\ncols and what is necessary to optimize for \nperformance. 1. Physical Layer (Layer 1). 2. Data Link Layer (Layer 2). 3. Network Layer (Layer 3). 4. Transport Layer (Layer 4). 5. Session Layer (Layer 5). 6. Presentation Layer (Layer 6). 7. Application Layer (Layer 7). Engineers must understand the nuances of \neach layer, with examples. 7.4. Encapsulation and Decapsulation \n\b\n[24*, C1.5.2]\nEach layer, while sending data from the \nupper layer to the lower layer, inserts \nadditional information at the beginning \n(header) and optionally at the end of the \ndata packet received from the upper layer, \ntreating the packet received from the upper \nlayer as data. This is encapsulation. The \nprotocol data unit (PDU), which is the \ndata packet containing additional informa-\ntion from all layers, is sent to the receiving \nsystem. At the receiving end, each layer \nextracts its header from the PDU, deciphers \nthe information to treat the data appropri-\nately, and sends the remaining PDU to the \nupper layer. Learning about cross-layer optimization, \nthe principles to which it must adhere, and its \napplications is important. Engineers should \nanalyze the PDU structures of each layer of \nOSI, the Internet protocol suite and the asyn-\nchronous transfer mode (ATM). 7.5. Application Layer Protocols\b\n[24*, C2]\nThe application layer, being the top most layer, \nprovides services and interfaces to interact with \nusers\u2019 application. There are two types of appli-\ncation layers in the OSI model: common appli-\ncation service element (CASE) and specific \napplication service element (SASE). Example \napplications include file transfer (FTP, TFTP, \nNFS), remote login (Telnet, Zoho Assist, \nAnydesk, TeamViewer, etc), e-mail (SMTP) \nnetworking support (DNS), network manage-\nment (SNMP, DHCP), devices (LPD), etc. Software engineers practicing in a net-\nworking domain need to understand CASE \nand SASE application services, including \nexample applications in each category. 7.6.", "domains": ["Software Quality Attributes", "Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 335", "position": 335, "chunk_type": "semantic", "token_estimate": 382}
{"text": "16-22   SWEBOK \u00ae GUIDE V4.0: Software engineers practicing in a net-\nworking domain need to understand CASE \nand SASE application services, including \nexample applications in each category. 7.6. Design Techniques for Reliable and Efficient \nNetwork\b\n[24*, C1.5]\nToday\u2019s information technology-based busi-\nnesses need around-the-clock, reliable, effi-\ncient and scalable networks and high-speed \ninternet availability. Catering to varied busi-\nness needs, the networks and their manage-\nment has become complex as well. It is critical to identify network require-\nments (both business goals and technical solu-\ntions) along with a road map (scalability). The \nfundamental design goals should include reli-\nability, security, availability and manageability. Engineers should expect threats and intrusions \nat multiple levels and design security at mul-\ntiple levels. Systems must be set up to monitor \nthe networks for both proper functioning and \nmalfunctioning; identify faults, vulnerabilities \nand hacks quickly; and fix them. Engineers must understand and learn the \nnuances of designing a network while using \nappropriate firewalls, LAN/VLANs, subnets, \nquality of service (QoS), Demilitarized Zone \n(DMZ), Spanning Tree (especially for hier-\narchical network), port or network interface \ncontroller (NIC) channel, security (both poll \nsecurity and physical security), wireless access \npoints, and wireless access controllers. Even when the design and implementation \nare well planned and executed, one has to be", "domains": ["Software Quality Attributes", "Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 335", "position": 335, "chunk_type": "semantic", "token_estimate": 211}
{"text": "COMPUTING FOUNDATIONS   16-23: \u2022\t Wireless local area networks (WLAN) . \u2022\t Wireless wide area networks (WWAN). A mobile or cellular network is a radio \nnetwork spread over a specific area of land \n(called a cell). The cells are served by base sta-\ntions, which are fixed-location transceivers. To avoid interference and ensure guaran-\nteed bandwidth, the adjacent cells use a dif-\nferent set of frequencies. These cells, when \nconnected, provide wide area radio coverage. The cell patterns take different shapes, but \nsquares, circles and hexagons are typical. Different methods of data transmission \nare used between channels, such as frequency \ndivision multiple access (FDMA), time divi-\nsion multiple access (TDMA), code division \nmultiple access (CDMA), space division mul-\ntiple access (SDMA), etc. Wireless technology has evolved over sev-\neral generations. Software Engineers are \nencouraged to learn the differences among 1G, \n2G, 3G, 4G and 5G technologies, along with \nthe core network, access system, frequency, \nbandwidth and technologies used in each. 7.9. Security and Vulnerabilities\b\n[24*, C9]\nAlthough wireless technology provides the \nease of connecting seamlessly to the network, \nit is also prone to attacks unless the network is \nsecured. Risks to unsecured wireless networks", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 336", "position": 336, "chunk_type": "semantic", "token_estimate": 193}
{"text": "16-24   SWEBOK \u00ae GUIDE V4.0: include Piggybacking, Wardriving, Evil Twins \nattacks, Wireless sniffing, Unauthorized com-\nputer access, Shoulder sniffing and Theft of \nmobile devices. Communication over the internet via \nmobile device is highly vulnerable to cyber-\nattacks. In addition to wardriving, mentioned \nabove, typical wireless and mobile device \nattacks include SMiShing, War driving, WEP \nattacks, WPA attacks, Bluejacking, Reply \nattacks, Blue snarfing, RF Jamming, etc. Many precautionary measures must be \nimplemented and strictly followed to reduce \nsuch risks. These measures include changing \ndefault passwords, changing passwords fre-\nquently, restricting access to authorized \nusers, encrypting data in the system and on \nthe network, and installing multiple levels \nof firewalls. In addition, users must protect \nand hide (not publicize) service set identifier \n(SSID), use effective antivirus software, and \nupdate and upgrade it regularly; use a virtual \nprivate networks (VPN), use file-sharing or \nsystem-sharing access with care, and disable \naccess after use; and update or upgrade the \naccess point or access controller, gateway and \nother devices with security patches when they \nbecome available. 8. User and Developer Human Factors\nThe thought processes and behaviors of soft-\nware developers typically differ from that of \nsoftware users. This content area identifies \nsalient parameters that matter for end users \nas well as the perspective of the developers. Human-computer interface (HCI) focuses \non designing and developing computer \ntechnology for users to interact with com-\nputing systems. User satisfaction is measured in terms of \nuser experience (UX). An ideal interface \nwould facilitate interaction that is as natural \nas the interaction between two human beings. 8.1. User Human Factors\b\n[3*, C8]\nUsers expect software to be robust; to have an \nintuitive graphical user interface (GUI) that \nguides the user through minimal, intelligent, \neasy-to-follow steps to achieve the end result; \nto be secure; and to provide fast, consistent \nresponses. The interface should help users use the \nsystem easily. The interface should be self-ex-\nplanatory and enable self-learning. The mes-\nsages, whether communicating results or \nerrors, should be clear and complete. The \nsystem should be able to regain its original \nstate if there are errors. The system should allow users to interrupt \nduring the processing and undo the operation, \nwherever possible. The software engineer needs to identify \nthe profile of users the system; system\u2019s func-\ntionality, input and output interfaces users \nuse (keyboard, touch pad, audio, video, etc.) to interact with the system, the system\u2019s fault \ntolerance, the system\u2019s performance parame-\nters. among others.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 337", "position": 337, "chunk_type": "semantic", "token_estimate": 403}
{"text": "16-24   SWEBOK \u00ae GUIDE V4.0: to interact with the system, the system\u2019s fault \ntolerance, the system\u2019s performance parame-\nters. among others. Typically, user interface development goes \nthrough several iterations, starting with a proto-\ntype. The user interface devices must be robust. 8.2. Developer Human Factors\b [3*, C31 - C32]\nThe software lives much longer than the time \ntaken to develop. Invariably, the software \nengineers who maintain the code are different \nfrom those who develop. Hence, the code has \nto be written with more care and for use by \nother programmer / software engineer. Meaningful and comprehensive docu-\nmentation is crucial at all stages of software \nlifecycle. Defining and adopting apt coding stan-\ndard for the project, and ensuring every team \nmember implements the same in spirit is key \nfor developing clean code that lives longer \nwith minimal maintenance. Programming style is another key ingre-\ndient of a good code. Code has to be legible, \nshould be like reading a good poem and easily \ncomprehendible. Using meaningful, consis-\ntent and detailed comments is essential to \nensure code readability. Other traits of a good software pro-\ngrammer include being a team player, enjoy", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 337", "position": 337, "chunk_type": "semantic", "token_estimate": 191}
{"text": "COMPUTING FOUNDATIONS   16-25: For example, if the premises are \u201cAll girls are \nbeautiful\u201d and \u201cMichu is a girl,\u201d then the con-\nclusion is \u201cMichu is beautiful.\u201d\nInductive Reasoning is about introducing a \nhypothesis and creating generalizations from \nthe available facts and premises. Unlike deduc-\ntive reasoning, in inductive reasoning, even if \nthe premises are certain, the conclusion would \nbe probable, depending on whether the induc-\ntive argument is strong or weak. For example, \ncheck the location of all engineers working \non a project and if they are from Bengaluru, \nIndia state \u201cAll employees working on the \ngaming project are from Bengaluru.\u201d\nAbductive Reasoning starts with an incom-\nplete set of data or information and proceeds \nto derive the most likely conclusion from the \nlatest data. For example, a doctor analyzes the \nlatest lab reports of a patient to predict the \ncourse of the disease. Common Sense Reasoning makes inferences \nabout situations based on similar past expe-\nriences. For example, if a motorcycle skids \nwhile driving on a wet road, that informa-\ntion is remembered and considered during \nfuture rides. Monotonic Reasoning occurs when the con-\nclusion remains permanent or constant after it \nis reached. For example, \u201cThe Himalayas are \none of the tallest mountain ranges.\u201d\nNon-Monotonic Reasoning (NMR) occurs \nwhen the inference changes values or direc-\ntion based on new knowledge or information. NMR is based on assumptions and deals with", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 338", "position": 338, "chunk_type": "semantic", "token_estimate": 231}
{"text": "COMPUTING FOUNDATIONS   16-27: artificial neural networks because it works \nwith limited data. Random Forest model uses multiple decision \ntrees for making a final decision. The random \nforest model is useful for solving both regres-\nsion and classification problems. AI models are key to making the most \nappropriate decisions. As different models \nsuit specific applications or domains, software \nengineers are encouraged to learn many other \nAI models as well, such as Linear Discriminant \nAnalysis, Learning Vector Quantization, \nK-nearest Neighbors (KNN), etc. 9.4. Perception and Problem-Solving\nSolving a problem efficiently and quickly is \nthe goal of AI. Problem-solving predomi-\nnantly comprises understanding user com-\nmands and executing them, as humans do. Depending on the application and problem to \nbe solved, AI systems use the relevant knowl-\nedge base and predicate logic to identify the \nmost appropriate solution. AI systems dealing with the external world, \nobtain environmental data through sensors \n(cameras; microphones; temperature, pres-\nsure and light sensors, etc. ), analyzes the data \nusing its knowledge base or inference engine, \nand acts upon it. Based on capabilities and functionality, AI \nsystems are categorized into multiple types. Type I AI systems are designed to do \nspecific tasks with intelligence. Examples \ninclude Chess games, speech and image rec-\nognition, among others. Type II AI systems analyze the current sit-\nuation or environment and do not normally \nrefer to previous decisions made in a similar \nsituation to arrive at an appropriate action. Reactive systems or reactive machines typically \nmake decisions and execute commands at that \ninstance, referring to the existing knowledge \nbase. A good example is a self-driving cars. Type III, or self-aware, AI systems have \nconsciousness and are mindful. These systems \nadopt the mind theory and predict the mood \nof the other person or entity based on the \nperson\u2019s action or type of action. For example, \nif the driver in the vehicle behind the system \nhonks, then the AI system might conclude \nthat the driver is angry or unhappy. Social and \nethical behavior is part of conscious systems. 9.5. Natural Language Processing\nNatural language processing (NLP) is a crucial \npart of AI systems, enabling users to interact \nwith the AI systems in a way that is similar to \nhow they interact with other humans. AI sys-\ntems understand human languages and exe-\ncute commands delivered in those languages.", "domains": ["Design Patterns", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 340", "position": 340, "chunk_type": "semantic", "token_estimate": 383}
{"text": "COMPUTING FOUNDATIONS   16-27: Natural Language Processing\nNatural language processing (NLP) is a crucial \npart of AI systems, enabling users to interact \nwith the AI systems in a way that is similar to \nhow they interact with other humans. AI sys-\ntems understand human languages and exe-\ncute commands delivered in those languages. AI systems that work on voice commands need \nto understand not only the human language, \nbut also the slang or pronunciation of the user. 9.6. AI and Software Engineering\nSoftware engineering and AI are mutually \nrelated to each other in basically two ways: AI \napplications in software engineering (i.e., AI \nfor SE) and software engineering for AI sys-\ntems (i.e., SE for AI). AI for SE aims to establish efficient ways \nof building high-quality software systems by \nreplicating human developers\u2019 behavior. It \nranges over almost all development stages, \nfrom resolving ambiguous requirements to \npredicting maintainability, particularly well \napplied in software quality assurance and \nanalytics, such as defect prediction, test case \ngeneration, vulnerability analysis, and pro-\ncess assessment [15]. Although human-cen-\ntric software engineering activities benefit, \nengineers should be aware of limitations and \nchallenges inherent to the nature of AI and \nML, especially the uncertain and stochastic \nbehavior and the necessity of sufficiently \nlabeled and structured datasets [15]. The development of AI systems is different \nfrom traditional software systems since the \nrules and system behavior of AI systems are \ninferred from training data rather than written \ndown as program code [16]. Thus, there is a \nneed for particular support of SE for AI, such \nas interdisciplinary collaborative teams of data \nscientists and software engineers, software", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 340", "position": 340, "chunk_type": "semantic", "token_estimate": 266}
{"text": "COMPUTING FOUNDATIONS   16-31: 7.2 Layered \nArchitecture \nof Networks\nC1.5\n7.3 Open Systems \nInterconnection  \nModel\nC1.5\n7.4 Encapsulation \nand \nDecapsulation\nC1.5.2\n7.5 Application \nLayer Protocols", "domains": ["Architectural Patterns and Styles", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 344", "position": 344, "chunk_type": "semantic", "token_estimate": 24}
{"text": "7.9 Security and: Vulnerabilities", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 344", "position": 344, "chunk_type": "semantic", "token_estimate": 4}
{"text": "[1]\t Joint Task Force on Computing: Curricula, IEEE Computer Society and \nAssociation for Computing Machinery, \nSoftware Engineering 2014: Curriculum \nGuidelines for Undergraduate Degree \nPrograms in Software Engineering, \n2014; http://sites.computer.org/ccse/\nSE2004Volume.pdf. [2*]\tG. Voland, Engineering by Design, 2nd \ned., Prentice Hall, 2003. [3*]\t S. McConnell, Code Complete, 2nd ed., \nMicrosoft Press, 2004. [4*]\t J.G. Brookshear, Computer Science: \nAn Overview, 12th ed., Addison-\nWesley, 2017. [5*]\t E. Horowitz et al., Computer \nAlgorithms, 2nd ed., Silicon Press, 2007. [6*]\t I. Sommerville, Software Engineering, \n9th ed., Addison-Wesley, 2011. [7]\t ISO/IEC/IEEE, \u201cISO/IEC/IEEE \n24765:2017 Systems and Software \nEngineering \u2014 Vocabulary,\u201d 2nd ed. 2017. [8*]\tL. Null and J. Lobur, The Essentials \nof Computer Organization and \nArchitecture, 5th ed., Jones and Bartlett \nPublishers, 2018. [9*]\tJ. Nielsen, Usability Engineering, \nMorgan Kaufmann, 1994. [10]\tISO 9241-420:2011 Ergonomics of \nHuman-System Interaction, ISO, 2011. [11*]\t\nM. Bishop, Computer Security: Art and \nScience, 2nd ed, Addison-Wesley, 2018. [12]\tR.C. Seacord, The CERT C Secure \nCoding  Standard, Addison-Wesley \nProfessional, 2016. [13]\tR. Fagin, \u201cA Normal Form for Relational \nDatabases that is based on Domains \nand Keys,\u201d ACM Transactions on \nDatabase Systems, Vol. 6, No. 3, ACM, \nSeptember 1981\n[14]\tI. Goodfellow, Y. Bengio, A. \nCourville, Deep Learning (Adaptive \nComputation and Machine Learning \nseries) Illustrated Edition, 2018. [15]\tS. Shafiq, A. Mashkoor, C. Mayr-\nDorn, A. Egyed, \u201cA Literature \nReview of Using Machine Learning \nin Software Development Life Cycle \nStages,\u201d IEEE Access, Volume 9, IEEE, \nOctober 2021. [16]\tS. Mart\u00ednez-Fern\u00e1ndez, J. Bogner, \nX. Franch, M. Oriol, J. Siebert, A. \nTrendowicz, A. M. Vollmer, \u201cSoftware \nEngineering for AI-Based Systems: A \nSurvey,\u201d ACM Transactions on Software \nEngineering and Methodology, Vol. 31, \nNo. 2, ACM, April 2022. [17]\tH. Washizaki, F. Khomh, Y. G. \nGueheneuc, H. Takeuchi, N. \nNatori, T. Doi, S. Okuda, \u201cSoftware \nEngineering Design Patterns for \nMachine Learning Applications,\u201d \nComputer, Vol. 55, No. 3, IEEE \nComputer Society, March 2022. [18]\tThomas H Cormen, Charles E \nLeiserson, Ronald L Rivest, Clifford \nStein, \u201cIntroduction to Algorithms,\u201d \nFourth Edition, 2022. [19]\tAndrew W Tanenbaum, Herbert Bos, \n\u201cModern Operating Systems,\u201d 4e, 2016. [20] https://ieeexplore.ieee.org/document \n/9779481 \n[21] Neal Ford, Mark Richards, Pramod \nSadalage and Zhamak Dehgh, Software \nArchitecture: The Hard Parts, O Reilly, \nFirst Edition \u2013 2021", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 345", "position": 345, "chunk_type": "semantic", "token_estimate": 358}
{"text": "Section: Finite-State Machine", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 347", "position": 347, "chunk_type": "semantic", "token_estimate": 3}
{"text": "17-2   SWEBOK \u00ae GUIDE V4.0: A com-\npound proposition that is neither a tautology \nnor a contradiction is a contingency. Compound propositions that always have \nthe same truth value are called logically equiv-\nalent (denoted by \u2261). Some common logical \nequivalences are the following:\n\u2022\t Identity laws: \np \u2227 T \u2261 p\t\np \u2228 F \u2261 p\n\u2022\t Domination laws: \np \u2228 T \u2261 T\t\np \u2227 F \u2261 F\n\u2022\t Idempotent laws: \np \u2228 p \u2261 p\t\np \u2227 p \u2261 p\n\u2022\t Double negation law: \n\u00ac (\u00ac p) \u2261 p \n\u2022\t Commutative laws: \np \u2228 q \u2261 q \u2228 p\t\np \u2227 q \u2261 q \u2227 p\n\u2022\t Associative laws: \n(p \u2228 q) \u2228 r \u2261 p \u2228 (q \u2228 r)\t\n(p \u2227 q) \u2227 r \n\u2261 p \u2227 (q \u2227 r)\n\u2022\t Distributive laws: \np \u2228 (q \u2227 r) \u2261 (p \u2228 q) \u2227 (p \u2228 r) \np \u2227 (q \u2228 r) \u2261 (p \u2227 q) \u2228 (p \u2227 r)\nMathematical \nFoundations\nBasic Logic\nSet, Relation, \nFunction\nFinite-State \nMachine\nNumber Teory  \nPropositional\nLogic\nPredicate\nLogic\nSet Operations\nProperties at Set\nRelations and\nFuntions\nTypes of Numbers\nDivisibility\nPrime Number\nGreatest\nCommon Divisor\nDiscrete \nProbability\nAlgebraic\nStructures\nGroup\nRing\nProof \nTechniques\nDirect Proof\nProof by\nContradiction\nProof by\nInduction\nProof by Example\nGraph and Tree\nGraph\nTree\nGrammar\nLanguage\nRecognition\nBasics of \nCounting\nNumerical\nPrecision, Accuracy \nand Error\nCalculus\nFigure 17.1. Breakdown of Topics for the Mathematical Foundations KA", "domains": ["Design Patterns", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 348", "position": 348, "chunk_type": "semantic", "token_estimate": 241}
{"text": "MATHEMATICAL FOUNDATIONS   17-5: 2.4. Proof by Example\nProof by example is only valid when the core \nof the proof is \u201cthere exists\u201d and one needs \nonly to show that at least one valid instance \ndoes exist. More generally, however, proof by \nexample has often been called Inappropriate \nGeneralization where validity is assumed to \nbe illustrated through one or a few examples \nrather than a full proof. Showing only one or a \nfew specific examples where p \u2192 q is not suf-\nficient to prove that for all cases p \u2192 q. 3. Set, Relation, Function \b\n[1*, c2]\nSet. A set is a collection of objects called ele-\nments. A set can be represented by listing its \nelements between braces (e.g., S = {1, 2, 3}). The symbol \u2208 is used to express that an ele-\nment belongs to a set or is a member of the set. Its negation is represented by \u2209 (e.g., 1 \u2208 S, \nbut 4 \u2209 S). In a more compact representation of a set \nusing set builder notation, {x | P(x)} is the set \nof all x such that P(x) for any proposition P(x) \nover any universe of discourse. Examples of \nimportant sets include the following:\n\u2022\t \u039d = {0, 1, 2, 3, \u2026} = the set of nonnega-\ntive integers. \u2022\t \u0396 = {\u2026, -3, -2, -1, 0, 1, 2, 3, \u2026} = the set \nof integers. Finite and Infinite Set. A set with a finite \nnumber of elements is called a finite set. Conversely, any set that does not have a finite \nnumber of elements in it is an infinite set. For \nexample, the set of all natural numbers is an \ninfinite set. Cardinality. The cardinality of a finite set S \nis the number of elements in S. This is repre-\nsented as |S| (e.g., if S = {1, 2, 3}, then |S| = 3). Universal Set. In general, S = {x \u2208 U | \np(x)}, where U is the universe of discourse in \nwhich the predicate P(x) must be interpreted. The universe of discourse for a given pred-\nicate is often referred to as the universal set. Alternatively, one may define a universal set \nas the set of all elements. Set Equality. Two sets are equal if and only \nif they have the same elements \u2014\n i.e., X = Y \u2261 \u2200p (p \u2208 X \u2194 p \u2208 Y). Subset.", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 351", "position": 351, "chunk_type": "semantic", "token_estimate": 399}
{"text": "MATHEMATICAL FOUNDATIONS   17-9: E = {e1, e2, e3}, and F = {(e1, (A, C)), (e2, (B, \nC)), (e3, (B, A))}. In weighted graph G = (V, E), each edge has \na weight associated with it. The weight of an \nedge typically represents the numeric value \nassociated with the relationship between the \ncorresponding two vertices. In Figure 17.12, \nthe weights for the edges e1, e2 and e3 are \ntaken to be 76, 93 and 15, respectively. If the \nvertices A, B and C represent three cities in a \nstate, the weights could be, for example, the \ndistances in kilometers between these cities. Let G = (V, E) be an undirected graph with \nedge set E. Then, for an edge e \u2208 E where e = \n{u, v}, the following expressions are often used:\n\u2022\t u, v are said to be adjacent, neighbors, or \nconnected. \u2022\t Edge e is incident with vertices u and v.\n\u2022\t Edge e connects u and v.\n\u2022\t Vertices u and v are endpoints for edge e.\nIf vertex v \u2208 V, the set of vertices in the \nundirected graph G = (V, E), then:\n\u2022\t The degree of v, deg(v), is its number of \nincident edges, except that any self-loops \nare counted twice. \u2022\t A vertex with degree 0 is called an iso-\nlated vertex. \u2022\t A vertex of degree 1 is called a pen-\ndant vertex. Let G = (V, E) be a directed graph. If e(u, \nv) is an edge of G, then the following expres-\nsions can be used to describe the graph:\n\u2022\t u is adjacent to v, and v is adjacent from u. \u2022\t e comes from u and goes to v.\n\u2022\t e connects u to v, or e goes from u to v.\n\u2022\t The initial vertex of e is u. \u2022\t The terminal vertex of e is v.\nIf vertex v is in the set of vertices for the \ndirected graph G = (V, E), then:\n\u2022\t In-degree of v, deg\u2212(v), is the number of \nedges going to v, i.e., for which v is the \nterminal vertex. \u2022\t Out-degree of v, deg+(v), is the number of \nedges coming from v, i.e., for which v is \nthe initial vertex. \u2022\t Degree of v, deg(v) = deg\u2212(v) + deg+(v), is \nthe sum of v\u2019s in-degree and out-degree.", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 355", "position": 355, "chunk_type": "semantic", "token_estimate": 387}
{"text": "17-12   SWEBOK \u00ae GUIDE V4.0: If T is a binary tree with root R and the \nremaining nodes form an ordered pair of non-\nnull left subtree TL and nonnull right subtree \nTR below R, then the preorder traversal func-\ntion PreOrder(T) is defined as:\nPreOrder(T) = R, PreOrder(TL), \nPreOrder(TR) \u2026 eqn. 1\nThe recursive process of finding the pre-\norder traversal of the subtrees continues until \nthe subtrees are found to be Null. Here, \ncommas have been used as delimiters for \nimproved readability. The postorder and in-order may be similarly \ndefined using eqn. 2 and eqn. 3, respectively. PostOrder(T) = PostOrder(TL), \nPostOrder(TR), R \u2026 eqn. 2\nInOrder(T) = InOrder(TL), R, \nInOrder(TR) \u2026 eqn. 3\nThe tree in Figure 17.19 is a binary search \ntree (BST). The pre-order, post-order and \nin-order traversal outputs for this BST are \ngiven below in their respective orders:\nPreorder output: 9, 5, 2, 1, 4, 7, 6, 8, 13, \n11, 10, 15\nPostorder output: 1, 4, 2, 6, 8, 7, 5, 10, \n11, 15, 13, 9\nIn-order output: 1, 2, 4, 5, 6, 7, 8, 9, 10, \n11, 13, 15\n5. Finite-State Machine  \b\n[1*, c13]\nA computer system may be abstracted as a \nmapping from state to state, driven by inputs. In other words, a system may be considered a \ntransition function T: S \u00d7 I \u2192 S \u00d7 O, where S \nis the set of states and I and O are the input \nand output functions. If the state set S is finite, the system is \ncalled a finite-state machine (FSM). Alternatively, a finite state machine \n(FSM) is a mathematical abstraction com-\nposed of a finite number of states and transi-\ntions between those states. For example, if the \ndomain S \u00d7 I is reasonably small, then one can \nspecify T explicitly, using diagrams similar \nto a flow graph to illustrate how logic flows \nfor different inputs. However, this is practical \nonly for machines with a very small informa-\ntion capacity. An FSM has a finite internal memory, an \ninput feature that reads symbols one at a time \nin a sequence, and an output feature. The operation of an FSM begins from a \nstart state, goes through transitions depending \non the input to different states, and can end \nin any valid state. However, only a few of the \nstates mark a successful flow of operation. These are called accept states.", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 358", "position": 358, "chunk_type": "semantic", "token_estimate": 397}
{"text": "17-12   SWEBOK \u00ae GUIDE V4.0: However, only a few of the \nstates mark a successful flow of operation. These are called accept states. The information capacity of an FSM is \nC = log |S|. Thus, if we represent a machine \nhaving an information capacity of C bits as an \nFSM, then its state transition graph will have \n|S| = 2C nodes. An FSM is formally defined as M = (S, I, \nO, f, g, s0). 9\n1\n4\n6\n8\n10\n5\n13\n15\n11\n7\n2\nFigure 17.19. A Binary Search Tree\n1, 2\n1, 2\n0, 2\n0, 3\n0, 3\n1, 3\nS\u2080\nS\u2081\nS\u2082\nFigure 17.20. Example of an FSM", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 358", "position": 358, "chunk_type": "semantic", "token_estimate": 114}
{"text": "MATHEMATICAL FOUNDATIONS   17-13: S is the state set. I is the set of input symbols. O is the set of output symbols. f is the state transition function. g is the output function. s0 is the initial state. Given an input x \u2208 I on state Sk, the FSM \ntransitions to state Sh, following state transi-\ntion function f, and produces an output y \u2208 O, \nusing the output function g.\nFigure 17.20 illustrates an FSM with S0 as \nthe start state and S1 as the final state. Here, S \n= {S0, S1, S2}; I = {0, 1}; O = {2, 3}; f(S0, 0) = S2; \nf(S0, 1) = S1; f(S1, 0) = S2; f(S1, 1) = S2; f(S2, 0) = \nS2; f(S2, 1) = S0; g(S0, 0) = 3; g(S0, 1) = 2; g(S1, \n0) = 3; g(S1, 1) = 2; g(S2, 0) = 2; g(S2, 1) = 3. The state transition and output values for dif-\nferent inputs on different states may instead be \nrepresented using a state table. The state table \nfor the FSM in Figure 17.20 is shown in Figure \n17.21. Each pair against an input symbol rep-\nresents the new state and the output symbol. Figures 17.21(a) and 17.21(b) are alternative \nrepresentations of the FSM in Figure 17.20. 6. Grammar  \b\n[1*, c13]\nThe grammar of a natural language defines \nwhether a combination of words makes a \nvalid sentence. Unlike natural languages, a \nformal language is specified by a well-defined \nset of rules for syntaxes. The valid sentences \nof a formal language can be described by a \ngrammar with the help of these rules, called \nproduction rules. A formal language is a set of finite-length \nwords or strings over some finite alphabet, \nand a grammar specifies the rules for forming \nthose words or strings. The entire set of words \nthat are valid for a grammar constitutes the \nlanguage for the grammar. Thus, the grammar \nG is any compact, precise mathematical defi-\nnition of a language L as opposed to a raw \nlisting of all legal sentences or examples of \nthose sentences in that language. A grammar implies an algorithm that can \ngenerate all legal sentences of the language. There are different types of grammars. A phrase structure grammar (PSG) \nor Type-0 grammar G = (V, T, S, P) is a \n4-tuple in which:\n\u2022\t V is the vocabulary \u2014 i.e., the set of words.", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 359", "position": 359, "chunk_type": "semantic", "token_estimate": 399}
{"text": "MATHEMATICAL FOUNDATIONS   17-13: There are different types of grammars. A phrase structure grammar (PSG) \nor Type-0 grammar G = (V, T, S, P) is a \n4-tuple in which:\n\u2022\t V is the vocabulary \u2014 i.e., the set of words. \u2022\t T \u2286 V is a set of words called terminals. \u2022\t S \u2208 N is a special word called the \nstart symbol. \u2022\t P is the set of production rules for substi-\ntuting one sentence fragment for another. There exists another set, N = V \u2212 T, of words \ncalled nonterminals. The nonterminals repre-\nsent concepts such as noun. Production rules are \napplied on strings containing nonterminals until \nno more nonterminal symbols are present in \nthe string. The start symbol S is a nonterminal. The language generated by a formal \ngrammar G, denoted by L(G), is the set of all \nstrings over the set of alphabets V that can be \ngenerated, starting with the start symbol, by \napplying production rules until all the nonter-\nminal symbols are replaced in the string. For example, let G = ({S, A, a, b}, {a, b}, S, \n{S \u2192 aA, S \u2192 b, A \u2192 aa}). Here, the set of \nterminals is N = {S, A}, where S is the start \nsymbol. The three production rules for the \ngrammar are given as P1: S \u2192 aA; P2: S \u2192 \nb; P3: A \u2192 aa. Applying the production rules in all pos-\nsible ways, the following words may be gener-\nated from the start symbol:\nCurrent \nState\nInput\nInput\nInput\nCurrent \nState\n(a)\n(b)\nOutput\n f\nState \nTrans g\n0\n1\n3\n2\n3\n2\n0\n1\n0\n1\nS\u2082,\nS\u2081,\n3\n2\nS\u2082,\nS\u2082,\n2\n3\nS\u2082,\nS\u2080,\nS\u2082\nS\u2081\nS\u2080\nS\u2082\nS\u2082\nS\u2081\nS\u2081\n3\n2\nS\u2082\nS\u2082\n2\n3\nS\u2082\nS\u2080\nS\u2080\nFigure 17.21. Tabular Representation of an FSM", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 359", "position": 359, "chunk_type": "semantic", "token_estimate": 307}
{"text": "17-16   SWEBOK \u00ae GUIDE V4.0: 1; i.e., p is prime if p > 1 \u2227 \u2203 \u00ac a, b \u2208 N: a > 1, \nb > 1, a * b = p.\nThe only positive factors of a prime p are \n1 and p itself. The numbers 2, 13, 29, 61, \netc., are prime numbers. Nonprime integers \ngreater than 1 are called composite numbers. A \ncomposite number may be composed by mul-\ntiplying two integers greater than 1. There are many interesting applications \nof prime numbers; among them is the pub-\nlic-key cryptography scheme, which involves \nthe exchange of public keys containing the \nproduct p*q of two random large primes p and \nq (a private key) that must be kept secret by a \ngiven party. 7.4. Greatest Common Divisor\nThe greatest common divisor gcd(a, b) of inte-\ngers a, b is the greatest integer d that is a \ndivisor both of a and of b \u2014 i.e., \nd = gcd (a, b) for max (d: d|a \u2227 d|b). For example, gcd(24, 36) = 12. Integers a and b are called relatively prime \nor coprime if and only if their GCD is 1. For example, neither 35 nor 6 is prime, but \nthey are coprime, as these two numbers \nhave no common factors greater than 1, so \ntheir GCD is 1. A set of integers X = {i1, i2, \u2026} is relatively \nprime if all possible pairs ih, ik, h \u2260 k drawn \nfrom the set X are relatively prime. 8. Basics of Counting \b\n[1*, c6]\nThe sum rule states that if a task t1 can be done \nin n1 ways and a second task t2 can be done in \nn2 ways, and if these tasks cannot be done at \nthe same time, then there are n1 + n2 ways to \ndo either task. \u2022\t If A and B are disjoint sets, then |A \u222a \nB|=|A| + |B|. \u2022\t In general if A1, A2, \u2026, An are disjoint \nsets, then |A1 \u222a A2 \u222a \u2026 \u222a An| = |A1| + \n|A2| + \u2026 + |An|. If 200 athletes do sprint events and 30 ath-\nletes participate in the long jump event, then \nhow many ways are there to pick one athlete \nwho is either a sprinter or a long jumper? Using the sum rule, the answer would be \n200 + 30 = 230.", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 362", "position": 362, "chunk_type": "semantic", "token_estimate": 393}
{"text": "MATHEMATICAL FOUNDATIONS   17-21: additive inverse of such a fraction is simply \n\u2212a/b, and the multiplicative inverse is b/a, pro-\nvided that a \u2260 0. 12. Engineering Calculus\nCalculus is a branch of mathematics that deals \nwith study of continuous transition, deriva-\ntives and integrals of functions using methods \noriginally based on the summation of infin-\nitesimal differences. Engineering Calculus \nfocuses on learning analytical geometry and \nvectors for engineering applications. Engineering \nCalculus \nincludes \nthe \nlearning of the following:\n\u2022\t Limits\n\u2022\t Continuity\n\u2022\t Differentiation\n\u2022\t Integration\n\u2022\t Transcendental functions\n\u2022\t Vector calculus\nLimits are the building blocks of Calculus. For a function f(x), the limit of the function \nat a point \u2018a\u2019 is the value the function achieves \nat a point \u2018a\u2019. L = lim x->a f(x) \nA function is said to be Continuous on the \ninterval [a, b] if it is continuous at each point \nin the interval. Lim  f(x) = f (a)\nx->a \nThe two major elements of calculus are differ-\nential calculus and integral calculus. \u2022\t Differential calculus analyzes the rate \nof change of one quantity in rela-\ntion to the rate of change of another. Geometrically, it is the slope of the line \ntangent to the graph of the function. The \nrate of change of x with respect to y is \nexpressed as dx/dy. \u2022\t Integral calculus analyzes such concepts as \nthe area or volume enclosed by a function. A transcendental function, in contrast to \nan algebraic function, is an analytic function \nthat does not satisfy a polynomial equation. Vector calculus deals with the differentia-\ntion and integration of vector fields in the \nthree-dimensional Euclidean space. Software engineers are encouraged to \nlearn Engineering Calculus with case studies. These concepts are required for analysing and \nextrapolating data. 13. New Advancements\n13.1. Computational Neurosciences\nComputational Neurosciences is a branch of \nNeurosciences that uses mathematical models, \ncomputer simulations and brain abstraction to \nunderstand and analyze cognitive abilities of \nthe nervous systems. This enables the learning \nof control theory, cybernetics, quantitative \npsychology, machine learning, artificial intel-\nligence, creative / imagination and connec-\ntionism among others. The central assumption of computational \nneuroscience is that the brain computes. What \ndoes that mean? Generally speaking, a com-\nputer is a dynamic system whose state vari-\nables encode information about the external \nworld. In short, computation equals coding plus \ndynamics.", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 367", "position": 367, "chunk_type": "semantic", "token_estimate": 385}
{"text": "MATHEMATICAL FOUNDATIONS   17-21: Generally speaking, a com-\nputer is a dynamic system whose state vari-\nables encode information about the external \nworld. In short, computation equals coding plus \ndynamics. Some neuroscientists study the way \nthat information is encoded in neural activity \nand other dynamic variables of the brain. Others try to characterize how these dynamic \nvariables evolve over time. The study of neural \ndynamics can be further subdivided into two \nseparate strands. One tradition, exemplified by \nthe work of Hodgkin and Huxley, focuses on the \nbiophysics of single neurons. The other focuses \non the dynamics of networks, concerning itself \nwith phenomena that emerge from the inter-\nactions between neurons. Therefore computa-\ntional neuroscience can be divided into three \nsub-specialties: neural coding, biophysics of \nneurons, and neural networks. 13.2. Genomics\nThe in-silico analysis of nucleotide sequences", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 367", "position": 367, "chunk_type": "semantic", "token_estimate": 135}
{"text": "17-22   SWEBOK \u00ae GUIDE V4.0: of chromosome(s) from a given organism is \ncalled \u201cgenome\u201d. The genome is the genetic \nmaterial of living organisms, containing \nhereditary characteristics. It is constituted by \nDNA. Genomic studies aim to understand \nhow genes and genetic information are orga-\nnized within the genome and how this orga-\nnization determines their function. Genomics deals with structure, func-\ntion, mapping, evolution and editing of \ngenomes, including sequencing and anal-\nysis of genomes. Significant research works are being under-\ntaken in the areas of preventive and thera-\npeutic healthcare, especially in the area of \ndetection, analysis and repair of genetic dis-\norders. These include genome data security, \ngenome data sharing, efficiency in genome \ndata analysis among others. Genomics encompasses a variety of tech-\nniques and approaches, including DNA \nsequencing, bioinformatic analysis, study of \ngenetic variation, computational modeling, \nand much more. The advancement of DNA sequencing \ntechnologies and bioinformatic analysis has \nsignificantly propelled progress in genomics, \nenabling detailed study of genomes across \nvarious organisms. Due to the large amount of data repre-\nsented by nucleotide sequences obtained from \ngenome sequencing, informatics is required to \nhandle these data. And the development of \nspecific software for the field relies heavily on \nSoftware Engineering. MATRIX OF TOPICS VS.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 368", "position": 368, "chunk_type": "semantic", "token_estimate": 205}
{"text": "Rosen 2018 [1*]: Cheney and \nKincaid 2020 [2*]\n1. Basic Logic\nc1\n2. Proof Techniques\nc1\n3. Set, Relation, Function\nc2\n4. Graph and Tree\nc10, c11\n5. Finite State Machine\nc13\n6. Grammar\nc13\n7. Number Theory\nc4\n8. Basics of Counting\nc6\n9. Discrete Probability\nc7\n10. Numerical Precision, \nAccuracy and Error\nc2\n11. Algebraic Structures\n12. Calculus", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 368", "position": 368, "chunk_type": "semantic", "token_estimate": 60}
{"text": "18-2   SWEBOK \u00ae GUIDE V4.0: \u2022\t Monitor the performance of the selected \nsolution \u2014 The engineering process nec-\nessarily depends on estimates, and those \nestimates can be wrong. Therefore, it is \nessential to evaluate the selected alterna-\ntive\u2019s real-world performance and, if nec-\nessary (and possible), decide whether one \nof the other alternatives might be better. Much of the rest of this KA elabo-\nrates on details of this higher-level engi-\nneering process. 2. Engineering Design\b\n[3*, c1s2-s4]\nA product\u2019s design will affect or even deter-\nmine its life cycle costs. This is true for man-\nufactured products as well as for software. Software design is guided by the features to \nbe implemented and the quality attributes to \nbe achieved. In the software engineering con-\ntext, \u201cdesign\u201d has a particular meaning; while \nthere are commonalities between engineering \ndesign as discussed in this section and soft-\nware engineering design as discussed in the \nSoftware Architecture KA and the Software \nDesign KA, there are also many differences. For example, the scope of engineering design \nis generally viewed as much broader than that \nof software design. Many disciplines involve solving problems \nfor which there is a single correct solution. In engineering, most problems have many \nsolutions, and the focus is on finding a fea-\nsible solution (among many alternatives) that \nbest meets the needs presented, economi-\ncally. In business, where the goal may be to \nfoster innovation in the marketplace, product \ndefinitions may derive from a business case. Whichever is the origin, possible solutions \nare often constrained by explicitly imposed \nlimitations such as cost, available resources, \nand the state of discipline or domain knowl-\nedge. In engineering problems, implicit con-\nstraints (such as the physical properties of \nmaterials or the laws of physics) sometimes \nrestrict the set of feasible solutions for a \ngiven problem. 2.1. Engineering Design in Engineering \nEducation\nVarious engineering education accreditation \nbodies, including the Canadian Engineering \nAccreditation Board and the Accreditation \nBoard for Engineering and Technology \n(ABET), place great value on engineering \ndesign, as evidenced by their high expecta-\ntions in this area. The Canadian Engineering Accreditation \nBoard requires specified levels of engineering \ndesign experience and coursework for engi-\nneering students and certain qualifications for \nthe faculty members who teach such course-\nwork or supervise design projects.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 370", "position": 370, "chunk_type": "semantic", "token_estimate": 377}
{"text": "18-2   SWEBOK \u00ae GUIDE V4.0: Engineering Design in Engineering \nEducation\nVarious engineering education accreditation \nbodies, including the Canadian Engineering \nAccreditation Board and the Accreditation \nBoard for Engineering and Technology \n(ABET), place great value on engineering \ndesign, as evidenced by their high expecta-\ntions in this area. The Canadian Engineering Accreditation \nBoard requires specified levels of engineering \ndesign experience and coursework for engi-\nneering students and certain qualifications for \nthe faculty members who teach such course-\nwork or supervise design projects. The organi-\nzation\u2019s accreditation criteria state: \nEngineering\nFoundations\nTe\nEngineering\nProcess\nEngineering\nDesign\nAbstraction \nand\nEncapsulation\nEmpirical\nMethods and\nExperimental\nTechniques\nStatistical\nAnalysis\nModeling,\nSimulation,\nand \nPrototyping\nEngineering\nDesign in\nEngineering\nEducation\nDesign as a\nProblem-\nSolving\nActivity\nDesigned\nExperiment\nObservational\nStudy\nRetrospective\nStudy\nLevels of\nAbstraction\nEncapsulation\nHierarchy\nAlternate\nAbstractions\nUnit of \nAnalysis\n(Sampling \nUnits),\nPopulation, \nand Sample\nCorrelation and\nRegression\nMeasurement\nLevels (Scales) of\nMeasurement\nImplications of\nMeasurement\nTeory on\nProgramming\nLanguages\nDirect and\nDerived Measures\nReliability and \nValidity\nAssessing\nReliability\nGoal-Question-\nMetric Paradigm:\nWhy Measure? Root Cause\nAnalysis\nRoot Cause\nAnalysis Techniques\nRoot Cause-\nBased\nImprovement\nIndustry 4.0 \nand Software\nEngineering\nStandards\nModeling\nSimulation\nPrototyping\nFigure 18.1. Breakdown of Topics for the Engineering Foundations KA", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 370", "position": 370, "chunk_type": "semantic", "token_estimate": 198}
{"text": "ENGINEERING FOUNDATIONS   18-3: Design: An ability to design solutions for com-\nplex, open-ended engineering problems and to \ndesign systems, components or processes that \nmeet specified needs with appropriate atten-\ntion to health and safety risks, applicable stan-\ndards, and economic, environmental, cultural, \nand societal considerations [4, p7]. Similarly, ABET defines engineering \ndesign as follows:\n\u2026 a process of devising a system, component, \nor process to meet desired needs and specifica-\ntions within constraints. It is an iterative, cre-\native, decision-making process in which the \nbasic sciences, mathematics, and engineering \nsciences are applied to convert resources into \nsolutions [5, p7]. Thus, engineering design is vital to the \ntraining and education of all engineers. The \nrest of this section focuses on various aspects \nof engineering design. 2.2. Design as a Problem-Solving Activity  \n\b\n[3*, c1s4, c2s1, c3s3] [6*, c5s1]\nEngineering design is primarily a prob-\nlem-solving activity. Finding a solution is \nparticularly challenging because design prob-\nlems tend to be open-ended and vaguely \ndefined, and there are usually several ways to \nsolve the same problem. Design is generally \nconsidered a wicked problem \u2014 a term coined \nby Horst Rittel in the 1960s when design \nmethods were a subject of intense interest. Rittel sought an alternative to the linear, step-\nby-step process many designers and design \ntheorists were exploring and argued that most \nproblems addressed by designers are wicked \nproblems. As explained by McConnell, a \nwicked problem presents a paradox: One can \ndefine it only by solving it, or by solving part \nof it. However, that solution is not the final \nsolution; a wicked problem must be solved \nonce to define it clearly and solved again to \ncreate a solution that works. This has been an \nimportant insight for software designers for \ndecades [6*, c5s1]. 3. Abstraction and Encapsulation \n\b\n[6*, c5s2-4]\nAbstraction is an indispensable technique \nassociated with problem-solving. It refers to \nboth the process and the result of generaliza-\ntion, where one reduces the information about \na concept, problem or observable phenomenon \nin order to focus on the \u201cbig picture.\u201d One of \nthe most important skills in any engineering \nundertaking is the ability to frame the levels \nof abstraction appropriately. According to Voland, \u201cThrough abstrac-\ntion, we view the problem and its possible \nsolution paths from a higher level of con-\nceptual understanding.", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 371", "position": 371, "chunk_type": "semantic", "token_estimate": 382}
{"text": "ENGINEERING FOUNDATIONS   18-3: It refers to \nboth the process and the result of generaliza-\ntion, where one reduces the information about \na concept, problem or observable phenomenon \nin order to focus on the \u201cbig picture.\u201d One of \nthe most important skills in any engineering \nundertaking is the ability to frame the levels \nof abstraction appropriately. According to Voland, \u201cThrough abstrac-\ntion, we view the problem and its possible \nsolution paths from a higher level of con-\nceptual understanding. As a result, we may \nbecome better prepared to recognize possible \nrelationships between different aspects of the \nDe\ufb01ne the\nselection criteria\nIdentify all \nreasonable technically \nfeasible solutions\nSelect the\npreferred alternative\nMonitor the\nperformance of the\nselected alternative\nEvaluate each\nalternative against\nthe selection criteria\nUnderstand the\nreal problem\nFigure 18.2. The Engineering Process", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 371", "position": 371, "chunk_type": "semantic", "token_estimate": 132}
{"text": "18-4   SWEBOK \u00ae GUIDE V4.0: problem and thereby generate more creative \ndesign solutions\u201d [2*]. This is true in computer \nscience in general (such as hardware vs. soft-\nware) and in software engineering in partic-\nular (e.g., data structure vs. data flow). Dijkstra states, \u201cThe purpose of abstracting \nis not to be vague, but to create a new \nsemantic level in which one can be absolutely \nprecise\u201d [7]. 3.1. Levels of Abstraction \nWhen abstracting, we concentrate on one \n\u201clevel\u201d of the big picture at a time, confident \nthat we can connect effectively with levels above \nand below. Although we focus on one level, \nabstraction does not mean knowing nothing \nabout the neighboring levels. Abstraction levels \ndo not necessarily correspond to discrete com-\nponents in reality or in the problem domain, \nbut to well-defined standard interfaces such \nas application programming interfaces (APIs). Standard interfaces offer advantages such as \nportability, easier software/hardware integra-\ntion and wider usage. 3.2. Encapsulation\nEncapsulation is a mechanism used to imple-\nment abstraction. When we are working with \none level of abstraction, the information con-\ncerning the levels below and above that level \nis encapsulated. This can be information about \nthe concept, problem, or observable phenom-\nenon or the permissible operations on these \nentities. Encapsulation usually means hiding \nunderlying details about the level above the \ninterface provided by the abstraction. For \nexample, hiding information about an object \nis useful because we don\u2019t need to know the \ndetails of how the object is represented or how \nthe operations on the object are implemented. 3.3. Hierarchy\nWhen we use abstraction in our problem \nformulation and solution, we might use dif-\nferent abstractions at different times \u2014 in \nother words, we work on different levels of \nabstraction as the situation requires. Usually, \nthese different levels of abstraction are orga-\nnized in a hierarchy. There are many ways to \nstructure a particular hierarchy, and the cri-\nteria used in determining the specific content \nof each layer vary depending on the individ-\nuals performing the work. Sometimes, a hierarchy of abstraction is \nsequential, meaning that each layer has one \nand only one predecessor (lower) layer and \none and only one successor (upper) layer \u2014 \nexcept the upmost layer (which has no suc-\ncessor) and the bottommost layer (which has \nno predecessor). Sometimes, however, the \nhierarchy is organized in a tree structure, \nwhich means each layer can have more than \none predecessor layer but only one successor \nlayer.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 372", "position": 372, "chunk_type": "semantic", "token_estimate": 404}
{"text": "18-4   SWEBOK \u00ae GUIDE V4.0: Sometimes, a hierarchy of abstraction is \nsequential, meaning that each layer has one \nand only one predecessor (lower) layer and \none and only one successor (upper) layer \u2014 \nexcept the upmost layer (which has no suc-\ncessor) and the bottommost layer (which has \nno predecessor). Sometimes, however, the \nhierarchy is organized in a tree structure, \nwhich means each layer can have more than \none predecessor layer but only one successor \nlayer. Occasionally, a hierarchy can have a \nmany-to-many structure, in which each layer \nhas multiple predecessors and successors. A \nhierarchy never contains a loop. A hierarchy often forms naturally in task \ndecomposition. Often, task analysis can be \ndecomposed hierarchically, starting with \nthe organization\u2019s larger tasks and goals and \nbreaking each into smaller subtasks that can \nagain be subdivided. This continuous division \nof tasks into smaller ones produces a hierar-\nchical structure of tasks and subtasks. 3.4. Alternate Abstractions\nSometimes, multiple alternate abstractions \nfor the same problem are useful to keep dif-\nferent perspectives in mind. For example, we \ncan have a class diagram, a state chart and \na sequence diagram for the same software \nat the same level of abstraction. These alter-\nnate abstractions do not form a hierarchy but \ncomplement each other, helping to illuminate \nthe problem and its solution. Though benefi-\ncial, keeping alternate abstractions in sync is \nsometimes difficult. 4. Empirical Methods and Experimental \nTechniques \b\n[8*, c1]\nThe \nengineering \nprocess \ninvolves \npro-\nposing solutions or models of solutions and", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 372", "position": 372, "chunk_type": "semantic", "token_estimate": 248}
{"text": "In testing hypotheses, we aim to maximize: the power of the test (the value of 1 \u2212 \u03b2) while \nensuring that the probability of a type I error \n(the value of \u03b1) is maintained within a partic-\nular value \u2014 typically 5%. Also note that construction of a test of a \nhypothesis includes identifying statistic(s) to \nestimate the parameter(s) and defining a crit-\nical region such that if the computed value of \nthe statistic falls within the critical region, the \nnull hypothesis is rejected. 5.2. Correlation and Regression \n\b\n[8*, c11s2, c11s8]\nA major objective of many statistical investi-\ngations is to establish relationships that make \nit possible to predict one or more variables in \nterms of others. Although it is desirable to \npredict a quantity exactly in terms of another \nquantity, that is seldom possible, and, in many \ncases, we must be satisfied with estimating \nthe average or expected values. The relationship between two variables is \nstudied using correlation and regression. Both \nthese concepts are explained briefly below. Correlation. The degree of the linear rela-\ntionship between two variables is measured \nusing the correlation coefficient. Computing the \ncorrelation coefficient is appropriate for two \nvariables that measure two different attributes \nof the same entity. The correlation coefficient \ntakes a value between \u22121 and +1. The values \n\u22121 and +1 indicate a situation where the asso-\nciation between the variables is perfect (i.e., \ngiven the value of one variable, the other can \nbe estimated with no error). A positive cor-\nrelation coefficient indicates a positive rela-\ntionship (i.e., if one variable increases, so does \nthe other). On the other hand, when the vari-\nables are negatively correlated, an increase of \none leads to a decrease in the other. Always remember that correlation does \nnot imply causation. Thus, if two variables \nare correlated, we cannot conclude that one \ncauses the other. Regression. The correlation analysis only \nmeasures the degree of relationship between \ntwo variables. The analysis to find the strength \nof the relationship between two variables is \ncalled regression analysis. This analysis uses the \ncoefficient of determination \u2014 a value between \n0 and 1. The closer the coefficient is to 1, the \nstronger the relationship between the variables. A value of 1 indicates a perfect relationship. 6. Modeling, Simulation, and Prototyping \n\b\n[3*, c6] [10*, c13s3] [11*, c5]\nModeling is part of the abstraction process used \nto represent aspects of a system.", "domains": ["Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 376", "position": 376, "chunk_type": "semantic", "token_estimate": 400}
{"text": "In testing hypotheses, we aim to maximize: 6. Modeling, Simulation, and Prototyping \n\b\n[3*, c6] [10*, c13s3] [11*, c5]\nModeling is part of the abstraction process used \nto represent aspects of a system. Simulation \nuses a model of the system to conduct designed \nexperiments to better understand the system, \nits behavior and relationships among subsys-\ntems, as well as to analyze aspects of the design. Modeling and simulation can be used to con-\nstruct theories or hypotheses about the system\u2019s \nbehavior. Engineers then use those theories to \nmake predictions about the system. Prototyping \nis another abstraction process where a partial \nrepresentation (that captures aspects of interest) \nof the product or system is built. A prototype \nmay be an initial version of the system that \nlacks the full functionality of the final version. 6.1. Modeling\nA model is always an abstraction of some real \nor imagined artifact. Engineers use models in \nmany ways as part of their problem-solving \nactivities. Some models are physical, such as", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 376", "position": 376, "chunk_type": "semantic", "token_estimate": 164}
{"text": "ENGINEERING FOUNDATIONS   18-9: a made-to-scale miniature construction of a \nbridge or building. Other models are non-\nphysical representations, such as a comput-\ner-aided design (CAD) drawing of a cog or \na mathematical model for a process. Models \nhelp engineers understand aspects of a \nproblem. They can also help engineers deter-\nmine what they know and what they don\u2019t \nknow about the problem. There are three types of models: iconic, ana-\nlogic and symbolic. An iconic model is a visually \nequivalent but incomplete two-dimensional or \nthree-dimensional representation (e.g., maps, \nglobes or built-to-scale models of structures \nsuch as bridges or highways). An iconic model \nresembles the artifact modeled. In contrast, an analogic model is a function-\nally equivalent but incomplete representation. The model behaves like the physical artifact \neven though it may not physically resemble it. Examples of analogic models include a minia-\nture airplane for wind tunnel testing or a com-\nputer simulation of a manufacturing process. Finally, a symbolic model uses a higher level \nof abstraction, modeling the process or system \nwith symbols such as equations. The engineers \ncan use the symbols to understand, describe, \nand predict the properties or behavior of the \nfinal system or product. An example is the \nequation F = ma. 6.2. Simulation \nAll simulation models are depictions of \nreality. A central issue in simulation is how to \nabstract data and create an appropriate simpli-\nfication of reality. Developing this abstraction \nis vital, as misspecification of the abstraction \nwould invalidate the results of the simulation \nexercise. Simulation can be used for a variety \nof testing purposes. Simulation is classified based on the type of \nsystem under study; simulation can be either \ncontinuous or discrete. In software engineering, \nthe emphasis is primarily on discrete simula-\ntion. Discrete simulations may model event \nscheduling or process interaction. The main \ncomponents in such a model include entities, \nactivities and events, resources, the state of \nthe system, a simulation clock, and a random \nnumber generator. The simulation generates \noutput that must be analyzed. An important problem in the development \nof a discrete simulation is that of initializa-\ntion. Before a simulation can be run, the ini-\ntial values of all the state variables must be \nprovided. As the simulation designer may not \nknow what initial values are appropriate for the \nstate variables, these values might be chosen \nsomewhat arbitrarily.", "domains": ["Design Patterns", "Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 377", "position": 377, "chunk_type": "semantic", "token_estimate": 388}
{"text": "ENGINEERING FOUNDATIONS   18-9: Before a simulation can be run, the ini-\ntial values of all the state variables must be \nprovided. As the simulation designer may not \nknow what initial values are appropriate for the \nstate variables, these values might be chosen \nsomewhat arbitrarily. For instance, it might be \ndecided that a queue should be initialized as \nempty and idle. This choice for an initial con-\ndition can have a significant but unrecognized \nimpact on the simulation outcome. 6.3. Prototyping\nConstructing a prototype of a system is \nanother abstraction process. In this case, an \ninitial version of the system is constructed, \noften while the system is designed, which \nhelps the designers determine the feasibility \nof their design. A prototype has many uses, including elic-\niting requirements, designing and refining \na user interface, and validating functional \nrequirements. The objectives and purposes \nfor building the prototype will guide its con-\nstruction and determine the level of abstrac-\ntion used. The role of prototyping is somewhat dif-\nferent for physical systems and software. With \nphysical systems, the prototype might be the \nfirst fully functional version of a system, or \nit might be a model of the system. In soft-\nware engineering, prototypes are also abstract \nmodels of part of the software. However, they \nare usually not constructed with all the archi-\ntectural, performance and other quality char-\nacteristics expected in the finished product. In either case, prototype construction must \nhave a clear purpose and be planned, mon-\nitored and controlled \u2014 it is a technique to \nstudy a specific problem within a limited con-\ntext [12*, c2s8]. In conclusion, modeling, simulation and \nprototyping are powerful techniques for \nstudying the behavior of a system from a", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 377", "position": 377, "chunk_type": "semantic", "token_estimate": 282}
{"text": "18-10   SWEBOK \u00ae GUIDE V4.0: given perspective. All can be used to perform \ndesigned experiments to study various aspects \nof the system. However, these are abstrac-\ntions and, as such, may not model all attri-\nbutes of interest. 7. Measurement \n\b\n[2*, pp442-447] [3*, c4s4] \n \n\b\n[12*, c7s5] [13*, c3s1-2]\nKnowing what to measure, how to measure \nit, what can be done with measurements and \neven why to measure is critical in engineering \nendeavors. Everyone involved in an engi-\nneering project must understand the measure-\nment methods, the measurement results and \nhow those results can and should be used. Measurements can be physical, environ-\nmental, economic, operational or another \nsort of measurement that is meaningful to \nthe project. This section explores the theory \nof measurement and how it is fundamental \nto engineering. Measurement starts as an \nabstract concept and progresses to a defini-\ntion of the measurement method and then \nto the actual application of that method to \nobtain a measurement result. Each step must \nbe understood, communicated and properly \nperformed to yield usable data. In traditional \nengineering, direct measures are often used. In software engineering, a combination of \nboth direct and derived measures (defined in \n7.3 below) is necessary [13*, p273]. The theory of measurement states that \nmeasurement is an attempt to describe an \nunderlying empirical system. Measurement \nmethods specify activities that assign a value \nor symbol to an attribute of an entity. Attributes must then be defined in terms \nof the operations used to identify and mea-\nsure them (the measurement methods). In this \napproach, a measurement method is defined \nas a precisely specified operation that yields \na symbol (called the measurement result) as \npart of the measurement of an attribute. To \nbe useful, the measurement method must be \nwell defined. Arbitrariness or vagueness in \nthe method leads to ambiguity in the mea-\nsurement results. In some cases \u2014 particularly in the physical \nworld \u2014 the attributes we wish to measure are \neasy to grasp; however, in an artificial world \nlike software engineering, defining attributes \nmight not be that simple. For example, the \nattributes of height, weight, distance, etc., are \neasily and uniformly understood (though they \nmay not be very easy to measure in all circum-\nstances). In contrast, attributes such as software \nsize and complexity require clear definitions. Operational definitions. The definition of \nattributes, to start with, is often rather abstract. Such definitions do not facilitate measure-\nments.", "domains": ["Design Patterns", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 378", "position": 378, "chunk_type": "semantic", "token_estimate": 401}
{"text": "18-14   SWEBOK \u00ae GUIDE V4.0: 7.4. Reliability and Validity\b\n[13*, c3s4-5]\nA basic question to ask when considering any \nmeasurement method is whether the proposed \nmeasurement method is truly measuring the \nconcept with good quality. Reliability and \nvalidity are the two most useful criteria for \naddressing this question. The reliability of a measurement method is the \nextent to which the application of the method \nyields consistent results. Reliability refers to \nthe consistency of the values obtained when the \nsame item is measured several times. When the \nresults agree with each other, the measurement \nmethod is said to be reliable. Reliability usually \ndepends on the operational definition. It can be \nquantified by using the variation index, which \nis computed as the ratio between the standard \ndeviation and the mean. The smaller the index, \nthe more reliable the measurement results. Validity refers to whether the measurement \nmethod measures what we intend to measure. The \nvalidity of a measurement method may be consid-\nered from three different perspectives: construct \nvalidity, criteria validity and content validity. 7.5. Assessing Reliability\b\n[13*, c3s5]\nMethods for assessing reliability include \nthe test-retest method, the alternative form \nNominal enum automobile_style = sedan, coupe, hatchback, \n\t\nminivan, suv, sports_car;\nSample A\nif( thisCarStyle >= sedan ) then \u2026 /\n/ this is not allowed\nSample B\nordinal enum CMMI_staged_level = initial, repeatable, defined, \n\t\nmanaged, optimizing;\nSample C\nif( anOrgsCMMILevel > repeatable ) then \u2026\nSample D\ninterval AirTemperatureCelsius from -120.0 to +180.0;\nAirTemperatureCelsius yesterdaysHighTemp;\nAirTemperatureCelsius todaysHighTemp;\nif( todaysHighTemp > yesterdaysHighTemp ) { \u2026 } /\n/ allowed\nif( todaysHighTemp > yesterdaysHighTemp * 2.0 ) { \u2026 } /\n/ not\nSample E\nratio TemperatureKelvin from 0.00 to 1000.00;\nTemperatureKelvin previousReading;\nTemperatureKelvin thisReading;\nif( thisReading > previousReading * 2. ) { \u2026 } /\n/ allowed\nSample F\ndouble priceOfBook;\ndouble highTemperature;\nhighTemperature = priceOfBook; /\n/ makes no sense but is allowed\nSample G\nratio Money from -10000.00 to +10000.00;\nratio TemperatureKelvin from 0.00 to 1000.00;\nMoney priceOfBook;\nTemperatureKelvin highTemperature;\ndouble highTemperature;\nhighTemperature = priceOfBook; /\n/ not allowed\nSample H\nFigure 18.3. Code Samples for Measurement Theory", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 382", "position": 382, "chunk_type": "semantic", "token_estimate": 347}
{"text": "ENGINEERING FOUNDATIONS   18-15: method, the split-halves method and the \ninternal consistency method. The easiest of \nthese is the test-retest method. In this method, \nwe apply the measurement method twice to \nthe same subjects. The correlation coefficient \nbetween the first and second set of measure-\nment results gives us the reliability of the mea-\nsurement method. 7.6. Goal-Question-Metric Paradigm:  \nWhy Measure? The final concern to discuss here regarding \nmeasurement is the importance of under-\nstanding why we measure in the first place. The Goal-Question-Metric paradigm can \nbe summarized with the simple observation \nthat a measurement should be made to sup-\nport decision-making. Some measurements \nsupport decisions in code. Other measure-\nments support decisions made by people \noutside of code (e.g., process improvement \nmeasures). The critical point is that some \ndecision should be made as a result of the \nmeasurement. Many real-world software \norganizations fall victim to a \u201cmeasurement \nfor the merely curious\u201d syndrome, where \nmetrics are gathered simply because they are \neasy to measure and interesting to look at \nwhen plotted in graphs. Those measurements \nare not used to support any decision and \nare a waste of time and energy. They should \nbe avoided. 8. Standards\b\n[3*, c9s3.2]\nMoore states that a standard can be the \nfollowing: \na. An object or measure of comparison \nthat defines or represents the magnitude \nof a unit \nb. A characterization that establishes allow-\nable tolerances for categories of items\nc.\t\nA degree or level of required excellence \nor attainment \nStandards are definitional in nature, estab-\nlished either to further understanding and \ninteraction or to acknowledge observed (or \ndesired) norms of exhibited characteristics or \nbehavior [14, p8]. Standards provide requirements, speci-\nfications or guidelines that engineers must \nobserve so that products, processes and mate-\nrials are of acceptable quality. The quali-\nties various standards dictate relate to safety, \nreliability or other product characteristics. Standards are considered critical to engineers, \nwho are expected to be familiar with and \nuse the appropriate standards for their spe-\ncific discipline. Compliance with or conformance to a \nstandard allows an organization to assure the \npublic that the organization\u2019s products meet \nthe requirements contained in that standard. Thus, standards divide organizations or their \nproducts into those that conform to the stan-\ndard and those that do not. For a standard to \nbe useful, conformance must add real or per-\nceived value to the product, process or effort.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 383", "position": 383, "chunk_type": "semantic", "token_estimate": 395}
{"text": "ENGINEERING FOUNDATIONS   18-17: evidence of the occurrence of causes and \nthe causality of effects and are thus more \nrigorous than cause-and-effect diagrams, \nFTA, and FMEA. \u2022\t A current reality tree [17] is a cause-ef-\nfect tree bound by the rules of logic \n(Categories of Legitimate Reservation). \u2022\t Human performance evaluation posits \nthat human performance depends on (1) \ninput detection, (2) input understanding, \n(3) action selection and (4) action execu-\ntion. An undesirable outcome that results \nfrom human performance can be identi-\nfied from a comprehensive list of poten-\ntial drivers, including cognitive overload, \ncognitive underload (boredom), memory \nlapse, tunnel vision or lack of a bigger \npicture, complacency, and fatigue. Additional techniques can be found in \nthe DOE-NE-STD-1004-92 Root Cause \nAnalysis Guidance Document. 9.2. Root Cause\u2013Based Improvement\nRCA is often an element in a greater pro-\ncess improvement effort. Why just identify a \nroot cause if nothing will be done about it? Why go through the effort of identifying the \nroot cause of low-importance problems? An \nexample of a systematic process for a larger \nimprovement effort incorporating RCA is \ngiven below:\n1. Select the problem to solve: Techniques \nsuch as Pareto analysis (the \u201c80/20 \nRule\u201d), frequency-severity prioritization \n(problems that happen most frequently \nand consume the most resources to rec-\ntify are the best candidates), and statis-\ntical process control are used to identify \na high-priority, undesirable outcome to \naddress. This step needs to clearly define \nthe problem and its significance. 2. Gather evidence about that problem \nand its cause(s): Consider information \nsurrounding the selected undesirable \noutcome, including statements or testi-\nmony, relevant processes or standards, \nspecifications, reports, historical trends, \nexperiments, or tests. 3. Identify the root cause using one or more \nRCA techniques presented in 9.1. Root \nCause Analysis Techniques. 4. Select corrective action(s) that (1) prevent \nrecurrence, (2) are within the organiza-\ntion\u2019s ability to control, (3) meet organi-\nzational goals and objectives, and (4) do \nnot cause other problems. More than one \ncandidate corrective action should be con-\nsidered, and the potential actions should \neliminate the cause, reduce the probability \nof the cause occurring or disconnect the \ncause from the effect. Selected correc-\ntive actions should generate the greatest \namount of control for the least cost. 5. Implement \nthe \nselected \ncorrective \naction(s). 6. Observe the selected corrective action(s) \nto ensure efficiency and effectiveness. 10. Industry 4.0 and Software Engineering\nThe manufacturing industry has always been \ncontinuously changing.", "domains": ["Design Patterns", "Software Quality Attributes", "Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 385", "position": 385, "chunk_type": "semantic", "token_estimate": 398}
{"text": "ENGINEERING FOUNDATIONS   18-17: 10. Industry 4.0 and Software Engineering\nThe manufacturing industry has always been \ncontinuously changing. Industry 4.0 is set to \nchange the manufacturing segment signifi-\ncantly, primarily focusing on custom manu-\nfacturing supported by artificial intelligence \n(AI). This offers potential benefits for cost, \nquality and efficiency. Industry 4.0\u2019s emphasis \non digitization and AI calls for building \nbespoke hardware and software and inte-\ngrating these with other standard systems. This is supported by Continuous Software \nEngineering \n(CSE), \nwhich \nhas \nbeen \naddressing continuous manufacturing prac-\ntices such as continuous planning, continuous \narchitecting/designing, \ncontinuous \ndevel-\nopment, continuous integration, continuous \ndeployments and continuous review/revision. Software is a key component in the Industry \n4.0 revolution, and engineering the software is \ncrucial to building robust and intelligent sys-\ntems. The engineering for one product affects \nothers, as more devices connect with other \ndevices, mostly wirelessly, to provide data \nand receive commands and data for further \nfunctioning.", "domains": ["Design Patterns", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 385", "position": 385, "chunk_type": "semantic", "token_estimate": 152}
{"text": "18-18   SWEBOK \u00ae GUIDE V4.0: Many technologies are used in Industry \n4.0, including the Internet of Things (IoT), \nBig data analytics, AI and machine learning, \ncybersecurity, cloud computing and Apps for \nmultiple platforms among others. Software \nplays a key role in the implementation of \nall these. Continuous \nSystems \nand \nSoftware \nEngineering for Industry 4.0 (CSSE I4.0) \nproposes how software engineering could \nbe applied in Industry 4.0. Quantum com-\nputing enables complex computations to be \nperformed faster and more cost-effectively. The size and cost of devices that host the soft-\nware are decreasing significantly, easing the \nadoption of Industry 4.0. The software will \nbe increasingly self-learning and proactive, \ndeveloping the ability to predict users\u2019 wants. MATRIX OF TOPICS VS. REFERENCE MATERIAL\nTockey 2004 [2*]\nVoland 2003 [3*]\nMcConnell 2004\n[6*]\nMontgomery and \nRunger 2018 [8*]\nNull and Lobur\n2018 [9*]\nCheney and Kincaid \n2007 [10*]\nSommerville 2018 [11*]\nFairley 2009 [12*]\nKan 2002 [13*]\n1. The \nEngineering Process\nc4\n2. Engineering Design\nc1s2-4\n2.1. Engineering Design \nin Engineering Education\n2.2. Design as a Problem-\nSolving Activity\nc1s4, \nc2s1, \nc3s3\nc5s1\n3. Abstraction and \nEncapsulation\nc5s2-4\n3.1. Levels of Abstraction\n3.2. Encapsulation\n3.3. Hierarchy\n3.4. Alternate \nAbstractions\n4. Empirical Methods \nand Experimental \nTechniques\nc1\n4.1. Designed \nExperiment\n4.2. Observational Study\n4.3. Retrospective Study\n5. Statistical Analysis\nc9s1, \nc2s1\nc11s3", "domains": ["Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 386", "position": 386, "chunk_type": "semantic", "token_estimate": 217}
{"text": "ENGINEERING FOUNDATIONS   18-19: 5.1. Unit of Analysis \n(Sampling Units), \nPopulation and Sample\nc3s5, \nc3s8, \nc4s5, \nc7s1, \nc7s3, \nc8s1, \nc9s1\n5.2. Correlation and \nRegression\nc11s2, \nc11s8\n6. Modeling, \nSimulation and \nPrototyping\nc6\nc13s3\nc5\n6.1. Modeling\n6.2. Simulation\n6.3. Prototyping\nc2s8\n7. Measurement\npp \n442-\n447\nc4s4\nc7s5\nc3s1-2\n7.1. Levels (Scales) of \nMeasurement\np442-\n447\nc7s5\nc3s2\n7.2. Implications of \nMeasurement Theory for \nProgramming Languages\n7.3. Direct and \nDerived Measures\nc7s5\n7.4. Reliability \nand Validity\nc3s4-5\n7.5. Assessing Reliability\nc3s5\n7.6. Goal-Question-\nMetric Paradigm: \nWhy Measure? 8. Standards\nc9s3.2\n9. Root Cause Analysis\nc9s3-5\nc5, c3s7,  \nc9s8\n9.1. Root Cause Analysis \nTechniques\nc4\n9.2. Root Cause-Based \nImprovement\n10. Industry 4.0 and \nSoftware Engineering", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 387", "position": 387, "chunk_type": "semantic", "token_estimate": 113}
{"text": "The SWEBOK Guide is an IEEE Computer: Society flagship and structural document for \nthe IEEE Computer Society\u2019s suite of software \nengineering products. The SWEBOK Guide is \nalso more widely recognized as a foundational \ndocument throughout the software engineering \ncommunity, notably through the official \nrecognition of the 2004 and 2014 versions \nas ISO/IEC Technical Report 19759:2005 \nand 19759:2015, respectively. The list of KAs \nand the breakdown of topics within each are \ndescribed and detailed in this SWEBOK Guide\u2019s \nintroduction. Consequently, the SWEBOK \nGuide is foundational to other initiatives within \nthe IEEE Computer Society, as follows:\n\u2022\t The list of KAs and the breakdown\nof topics within each are also adopted\nby the software engineering certifica-\ntion and associated professional devel-\nopment products offered by the IEEE\nComputer Society. (See www.computer\n.org/certification.) \u2022\t The list of KAs and the breakdown of\ntopics are also foundational to the soft-\nware engineering curriculum guide-\nlines developed or endorsed by the IEEE\nComputer Society. (See www.computer. org/portal/web/education/Curricula.) \u2022\t The Consolidated Reference List (see\nAppendix C) \u2014 meaning the list of\nRecommended References (to the level\nof section number) that accompanies the\nbreakdown of topics within each KA\n\u2014 is also adopted by the software engi-\nneering certification and associated pro-\nfessional development products offered\nby the IEEE Computer Society.", "domains": ["Design Patterns", "Design Principles"], "source": "swebok-v4.pdf", "section": "Page 389", "position": 389, "chunk_type": "semantic", "token_estimate": 214}
{"text": "Due to the structural nature of the SWEBOK: Guide and its adoption by other products, a \nbaseline was developed at the outset of the \nproject by a SWEBOK Steering Group. The \nbaseline comprises the list of KAs, including", "domains": ["Design Patterns"], "source": "swebok-v4.pdf", "section": "Page 389", "position": 389, "chunk_type": "semantic", "token_estimate": 38}
{"text": "\u2022\t KA editors are instructed to refine the: baseline breakdown of topics to reflect \nthe recent development in the target area \nfor KAs that continue to exist from the \nprevious version. \u2022\t The breakdown of topics is expected to be \n\u201creasonable,\u201d not \u201cperfect.\u201d\n\u2022\t The breakdown of topics within a KA \nmust decompose the subset of the \nSWEBOK that is \u201cgenerally recognized.\u201d \n(See below for a more detailed discussion \nof this point.) \u2022\t The breakdown of topics within a KA \nmust not presume specific application \ndomains, business needs, sizes of organi-\nzations, organizational structures, man-\nagement philosophies, software life cycle \nmodels, software technologies or soft-\nware development methods. \u2022\t The breakdown of topics must, as much \nas possible, be compatible with the var-\nious schools of thought within software \nengineering. \u2022\t The breakdown of topics within a KA \nmust be compatible with the breakdown \nof software engineering generally found \nin industry and in the software engi-\nneering literature and standards. \u2022\t The breakdown of topics is expected to be \nas inclusive as possible. \u2022\t The SWEBOK Guide adopts the position \nthat even though the following \u201cthemes\u201d \nare common across all KAs, they are also \nan integral part of all KAs and, there-\nfore, must be incorporated into the pro-\nposed breakdown of topics of each KA. These common themes are measurement, \nquality (in general) and security. \u2022\t The breakdown of topics should be at most \ntwo or three levels deep. Even though no \nupper or lower limit is imposed on the \nnumber of topics within each KA, a rea-\nsonable and manageable number of topics \nis expected to be included in each KA. Emphasis should also be put on the selection \nof the topics themselves rather than on their \norganization in an appropriate hierarchy. \u2022\t Topic names must be significant enough \nto be meaningful even when cited outside \nthe SWEBOK Guide. \u2022\t The Description of a KA will include a \nchart (in tree form) describing the knowl-\nedge breakdown. This chart will typically \nbe the first figure in the respective KA.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 390", "position": 390, "chunk_type": "semantic", "token_estimate": 341}
{"text": "KNOWLEDGE (SWEBOK): 1. Overview\nThe purpose of this appendix is to describe the \nrelationship between IEEE software engi-\nneering standards and the SWEBOK and to \nintroduce the more prominent international \nsoftware engineering standards most directly \nrelated to the SWEBOK knowledge areas \n(KA). A summary list of some useful stan-\ndards for software engineering, including all \nthose referenced in this document, is in B.9. 1.1 The SWEBOK and standards\nThe SWEBOK and other bodies of knowl-\nedge are closely related to standards for soft-\nware engineering, and standards are cited \nas resources in knowledge areas (KA) in the \nSWEBOK. Standards for software engi-\nneering extend and apply the generally accepted \nbody of knowledge that is collected in the \nSWEBOK. Conversely, standards also define \nand organize the systematic knowledge that \nis then reflected in collected bodies of knowl-\nedge. However, the SWEBOK has a different \npurpose from most software engineering stan-\ndards. The SWEBOK summarizes gener-\nally accepted concepts and experience-based \ninformation about how software engineering \nis practiced. This knowledge summary can \nbe applied in various ways: to define a curric-\nulum for educating software engineers, or for \nemployers or certification bodies determine if \na person has the knowledge and accepts the \nethical values needed to practice software \nengineering or to be certified. In contrast, a standard is a \u201cdocument, \nestablished by consensus and approved by a \nrecognized body, that provides, for common \nand repeated use, rules, guidelines or charac-\nteristics for activities or their results, aimed \nat the achievement of the optimum degree \nof order in a given context\u201d (ISO/IEC TR \n29110-1:2016). In standards, the \u201cRules, \nguidelines, or characteristics\u201d are expressed \ndifferently:\n\u2022\t requirements in normative standards, \n(stated using shall or the imperative),\n\u2022\t recommended practices (stated using \n \nshould)\n\u2022\t other guidance on possible approaches \n(stated using may)\nStandards allow for global interoperability \nfor accepted concepts, processes, people, and \nproducts. The existence of standards takes a \nvery large (possibly infinite) trade space of alter-\nnatives and normalizes that space, supporting \nmutual understanding between acquirers and \nsuppliers. In that respect, software engineering \nstandards counter the tendency of competing", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 395", "position": 395, "chunk_type": "semantic", "token_estimate": 346}
{"text": "B-2   SWEBOK \u00ae GUIDE V4.0: organizations to develop unique, proprietary \nproducts that do not interoperate outside \ntheir own suite. When standards are open, so \nthat organizations of all sizes can meet their \nrequirements, demand for trustworthy prod-\nucts and services increases to the benefit of \nmany suppliers and acquirers. Standards are voluntary; an individual or \norganization can choose to conform to their \nrequirements and follow their recommenda-\ntions. When the standard is incorporated in \ncontracts or other agreements, laws, and reg-\nulations, then compliance with the standard \nbecomes mandatory. 1.2\t Types of Standards\nStandards can be characterized by what part \nof software engineering they standardize: \nconcepts and terms, processes, products, \npeople, or assessment of capabilities. Some software engineering standards simply \npresent concepts (characteristics) and define \nterms, perhaps even establishing a schema \nof knowledge about a software engineering \ntopic. An example of this type of standard is \nISO/IEC/IEEE 24765 Systems and software \nengineering: Vocabulary, which is freely avail-\nable online at www.computer.org/sevocab.1 \nHowever, most software engineering standards \ndescribe one or more of the software engi-\nneering processes and give requirements and \nrecommendations about how to perform that \nprocess. The primary process standard in soft-\nware engineering is ISO/IEC/IEEE 12207, \nSystems and software engineering: Software life \ncycle processes. There is even a standard for how \nto describe a process: ISO/IEC/IEEE 24774, \nSystems and software engineering \u2014Life cycle \nmanagement \u2014Specification for process descrip-\ntion. It describes the purpose, outcomes, activ-\nities, tasks, and possibly the inputs, outputs, \nand other features of a process. Process stan-\ndards should not be confused with procedures \nor instructions; they do not offer detailed rec-\nipes or step-by-step instructions for doing soft-\nware engineering. 1\t http://pascal.computer.org/sev_display/index.action. A few software engineering standards have \nstandardized descriptions of products of soft-\nware engineering, such as models or informa-\ntion products like a project management plan \n(ISO/IEC/IEEE 16326). Another notable \nstandard for information products is ISO/\nIEC/IEEE 15289, Systems and software engi-\nneering\u2014Contents of life cycle information items \n(documentation). Initially, most software engi-\nneering standards were standards for a prom-\ninent information product, a plan. These \nallowed customers (acquirers of software) to \nunderstand and compare what their suppliers \nwould produce (a product). A standard for a \nplan describes what will be produced or deliv-\nered, what methods and techniques will be \nused, and what activities will be performed. In recent years, most of the standards for \nplans have been revised to become standards \nfor software engineering processes.", "domains": ["Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 396", "position": 396, "chunk_type": "semantic", "token_estimate": 405}
{"text": "APPENDIX B   B-3: Electrotechnical Commission Joint Technical \nCommittee) / SC 7 (Subcommittee), Software \nand Systems Engineering, produces standards \nthrough its membership of national standards \nbodies. JTC 1/SC 7 has a portfolio of over \ntwo hundred standards. The IEEE Computer \nSociety Systems and Software Standards \nCommittee (S2ESC) produces standards in \nworking groups of individual experts. It main-\ntains about fifty standards, of which about \n80% have been approved as ISO/IEC/IEEE \njoint standards. These are IEEE standards \nadopted by ISO/IEC JTC 1/SC 7, or stan-\ndards that are jointly developed and main-\ntained with ISO/IEC JTC 1 and designated \nas ISO/IEC/IEEE. The aim of these jointly \ndeveloped standards is to have a coordinated \ncollection of consistent standards for interna-\ntional use. For the ISO/IEC/IEEE standards \ndescribed in this appendix, the IEEE version \nand the ISO/IEC version are substantively \nidentical. The respective versions may have \ndifferent front and back matter but the tech-\nnical content is exactly the same. Standards can be purchased from the \nIEEE, ISO, and IEC websites, from national \nstandards organizations, and from commer-\ncial resellers. Academic institutions and soft-\nware engineering organizations can purchase \nor subscribe to collections of standards for \nuse by their staffs. A few standards are freely \navailable, generally those that provide intro-\nductions to concepts or terminology. In both IEEE and ISO/IEC JTC 1, stan-\ndards for systems engineering are maintained \nby the same committee as those for software \nengineering. Most of the standards apply to \nboth, especially when software is considered as \na system or as the major component of a system \nof interest. So, instead of making fine distinc-\ntions, this appendix covers both as applicable \nto software engineering. It does not mention \nolder, now stabilized standards dealing with \nthe foundations of computing or computing \nlanguages and basic programming, mathemat-\nical, or engineering concepts. ISO and IEEE have their own numbering \nsystems for their standards. When an IEEE \nstandard is adopted by ISO/IEC JTC 1, it \nis typically renumbered to a 5-digit number, \ne.g., IEEE 1062 becomes ISO/IEC/IEEE \n41062. ISO standards have long, taxonom-\nical titles with three and four levels of classi-\nfication. The first level shows the general area \n(e.g. systems and software engineering); the \nsecond level is the main title of the standard, \nand the third level provides even more detail, \nespecially for multi-part standards.", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 397", "position": 397, "chunk_type": "semantic", "token_estimate": 385}
{"text": "APPENDIX B   B-3: The first level shows the general area \n(e.g. systems and software engineering); the \nsecond level is the main title of the standard, \nand the third level provides even more detail, \nespecially for multi-part standards. To avoid \ncumbersome repetition, this appendix often \nuses a shortened title of the standard or simply \ncites it by number. The full title is given in the \nlist in B.9. All of these software engineering \nstandards are copyright protected, and IEEE \nstandard numbers are trademarked. 2. The software engineering standards \nlandscape\nFigure B.1 presents an overview of the most \nprominent software engineering standards, \nmainly from the perspective of how other \nstandards relate to the major software engi-\nneering life cycle process standard, ISO/IEC/\nIEEE 12207, software engineering processes. It is closely related to the SWEBOK in that \nboth present information related to many \nof the same software life cycle processes. Also in the upper portion of Figure B.1 are \nthe foundational standards, such as the spe-\ncialized vocabulary for systems and soft-\nware engineering (SEVOCAB, ISO/IEC/\nIEEE 24765) and a specification for how to \ndescribe processes (ISO/IEC/IEEE 24774). There are standards for how to plan for and \nmanage software engineering (ISO/IEC/\nIEEE 24748-5) and how to conduct rigorous \nreviews and audits, appropriate for critical \nsoftware like aerospace and defense systems \n(ISO/IEC/IEEE 24748-8). Using the life cycle process model of 12207 \nas described in the following section, there \nare many more specialized standards covering \nindividual processes and modern approaches to \nthe processes, such as ISO/IEC/IEEE 32675, \nDevOps, as well as IEEE 1012, Verification \nand validation, and ISO/IEC/IEEE 29119, \nsoftware testing (in multiple parts). The life \ncycle processes in 12207 generally focus on a", "domains": ["Domain-Driven Design"], "source": "swebok-v4.pdf", "section": "Page 397", "position": 397, "chunk_type": "semantic", "token_estimate": 279}
{"text": "B-4   SWEBOK \u00ae GUIDE V4.0: single system of interest (SOI) but more spe-\ncialized series focus on processes and tools for \nproduct line engineering, and for systems of \nsystems (SoS). The System of Systems stan-\ndards, ISO/IEC/IEEE 21839, 21840, and \n21841, explain how to use systems engineering \nprocesses when the system of interest (SOI) is \na constituent part of a system of systems. The life cycle process standards are intended \nto be compatible with other well-known stan-\ndards for management systems. According \nto ISO, \u201ca management system is the way in \nwhich an organization manages the interre-\nlated parts of its business in order to achieve \nits objectives.\u201d Management system standards \n(MSS) have a consistent structure and frame-\nwork of requirements, but each MSS covers \na specific aspect of managing and delivering \nengineering products and services. MSS \ntypically come in multiple parts with var-\nious guides for different aspects of their sys-\ntems. Well-known MSS related to software \nengineering include ISO 9000 for quality \nmanagement, ISO/IEC 20000 for service \nmanagement, the ISO/IEC 27000 series for \ninformation security management, the ISO/\nIEC 19770 series for managing IT assets like \nhardware and software, and the ISO/IEC \n30105 series for business process outsourcing \noperations. 3. Life cycle process standards\nISO/IEC/IEEE 12207, Software life cycle \nprocesses, \nand \nISO/IEC/IEEE \n15288, \nSystem life cycle processes, are intentionally \nharmonized for use together. As stated in \nISO/IEC/IEEE 15288:2023, \u201cthere is a con-\ntinuum of human-made systems from those \nthat use little or no software to those in which \nsoftware is the primary interest. When soft-\nware is the predominant system or element \nof interest, ISO/IEC/IEEE 12207 should \nbe used.\u201d Both standards have identical life \ncycle models (the same four process groups, as \nshown in Figure B.2) and the same processes, \nThe processes have the same names, purposes, \nand process outcomes (there are minor vari-\nations in a couple of process names) in both \nstandards. Process activities and tasks differ \nbetween these two foundational standards, as \nsome aspects of engineering for software sys-\ntems are different from systems in general. Conformance to ISO/IEC/IEEE 12207 or \nIEEE Guide to \nSW Engineering \nBody of Knowledge \n(SWEBOK)\nISO/IEC/IEEE 24765 \nVocabulary \n(SEVOCAB)\nProduct \nLines\nProcess Description\nISO/IEC/IEEE 24774\nDevOps Process View\nISO/IEC/IEEE 32675\nISO/IEC/IEEE 24748-4 SE Plans\nISO/IEC/IEEE 24748-8 \nReviews and Audits\nManagement Systems\nInformation Mgmt: \nISO/IEC/IEEE \n15289\nIndividual Processes\nVeri\ufb01cation/\nValidation", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 398", "position": 398, "chunk_type": "semantic", "token_estimate": 389}
{"text": "Software Testing: ISO/IEC/IEEE \n29119\nISO 9001 Quality\nISO/IEC 20000 Service\nISO/IEC 27000 Security\nISO/IEC 19770 IT \nAsset Mgmt. Systems of systems (SoS)\nISO/IEC/IEEE \n21839, 21840, 21841\nLife Cycle Processes\nISO/IEC/IEEE 12207\nFigure B.1. Software Engineering Standards Landscape", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 398", "position": 398, "chunk_type": "semantic", "token_estimate": 37}
{"text": "APPENDIX B   B-5: 15288 can be shown either by demonstrating \nthat all the outcomes of the process have been \nachieved, or that all the required activities \nand tasks of a process have been performed. The life cycle processes are presented in \nthe context of their use on projects, supported \nby an organization that provides continuous \nservices applicable across multiple projects. However, the processes can be applied in \nvery small entities which are essentially orga-\nnized as a single team, as well as on large pro-\ngrams and continuing efforts that do not have \na defined end point like a project. IEEE Std 12207 establishes a common \nframework for software life cycle processes, \nwith well-defined terminology that can be ref-\nerenced by the software industry. ISO/IEC \n12207 applies to the acquisition of systems \nand software products and services and to the \nsupply, development, operation, maintenance, \nand disposal of software systems and the soft-\nware portion of a system, whether performed \ninternally or externally to an organization. Those aspects of system definition and enabling \nsystems (infrastructure) needed to provide the \ncontext for software products and services are \nincluded. Selected sets of these processes can \nbe applied throughout the life cycle for man-\naging and performing the stages of a system\u2019s \nlife cycle. This is accomplished through the \ninvolvement of all interested parties, with the \ngoal of achieving customer satisfaction. Table B.1 aligns the software life cycle \nprocesses of ISO/IEC/IEEE 12207 to the \nSWEBOK KA and identifies related stan-\ndards that offer more detailed requirements \nand guidance for individual processes. The \nSWEBOK KA do not directly cover all of \nthe process groups and processes in ISO/\nIEC/IEEE 12207. The Agreement processes \n(acquisition and supply) are not included, nor \nmany of the processes in the Organizational \nProject-enabling process group, and not all \nof the Technical Management or Technical \nprocess group processes. SWEBOK KA are \nselected to cover the essential knowledge \nareas applied by individual software engineers \nworking on projects or ongoing efforts, rather \nthan those generally handled at higher levels \nin the organization or on a more general level. This version of the SWEBOK has added \nthe software security KA, which for historical \nreasons has been standardized separately from \nthe systems and software engineering stan-\ndards committees. Security is not identified as \na technical process in ISO/IEC/IEEE 12207.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 399", "position": 399, "chunk_type": "semantic", "token_estimate": 384}
{"text": "APPENDIX B   B-5: This version of the SWEBOK has added \nthe software security KA, which for historical \nreasons has been standardized separately from \nthe systems and software engineering stan-\ndards committees. Security is not identified as \na technical process in ISO/IEC/IEEE 12207. An extensive suite of security standards based \non the ISO/IEC 27001 MSS are developed in \nISO/IEC JTC 1 SC 27, Information security, \ncybersecurity, and privacy protection. Table B.1 also identifies standards that are \nintended to identify process-related functions \nwhere software tools and methods should be \napplied, or to apply the processes to product \nline engineering (see B.6). 4. Extensions and specialized applications \nof ISO/IEC/IEEE 12207\nNumerous useful standards supplement the \nrequirements of ISO/IEC/IEEE 12207 to \nhandle more rigorous or specialized situa-\ntions, or to provide more extended guidance \non its concepts and processes. Many of these \nstandards are parts of the ISO/IEC/IEEE \n24748 family. 4.1, Explanations of concepts and several processes\nISO/IEC/IEEE 24748-1, -2 and -3 are \noverall guides to the life cycle processes and \ninvaluable for understanding and applying \nsystems and software engineering concepts. Technical \nManagement\nTechnical\nOrganizational \nProject-enabling\nAgreement\nFigure B.2. Process groups of ISO/IEC/", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 399", "position": 399, "chunk_type": "semantic", "token_estimate": 189}
{"text": "6.4.12: Operation\nYes\n32675\n23531\n6.4.13\nMaintenance\nYes\n14764\n6.4.14\nDisposal\nSoftware security\nYes\nISO/IEC 27000 \nfamily, 15026 \n(Parts 1 to 4) \nSoftware Engineering \ncomputing foundations\nYes\nNumerous  \nhistoric standards\nSoftware Engineering \nMathematical \nfoundations\nYes\nNumerous his-\ntoric standards\nSoftware engineering \nFoundations\nYes\nNumerous  \nhistoric standards", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 401", "position": 401, "chunk_type": "semantic", "token_estimate": 46}
{"text": "B-8   SWEBOK \u00ae GUIDE V4.0: focus on production as a stage of interest, an \nalternate model for software life cycle stages \nis more useful: concept, development, opera-\ntions and maintenance, and retirement. Life \ncycle models are characterized by their devel-\nopment approach: sequential, incremental, or \nevolutionary. The life cycle models are com-\npared in a risk-based approach. ISO/IEC/IEEE 24748-2 is the overall \nguide to applying the systems engineering pro-\ncesses in ISO/IEC/IEEE 15288. However, \nit does not offer line-by-line expansions of \neach process, activity, and task, but presents \nan overall strategy for transitioning to use of \nstandardized life cycle processes. There is yet \nmore explanation of systems concepts, a pre-\nsentation of organizational concepts, some \ndiscussion of conformance or adaptation (tai-\nloring), of standard processes, and an intro-\nduction to model-based systems and software \nengineering (MBSSE). ISO/IEC/IEEE 24748-3, guidelines for \nthe application of software life cycle pro-\ncesses, also offers commentary on concepts of \nsoftware systems, organizations and projects, \nprocesses, life cycle states, and life cycle pro-\ncess models for software systems. It includes \nguidance for each of the processes in ISO/\nIEC/IEEE 12207, including further anal-\nysis of process purposes; outcomes and out-\nputs; activities, tasks, and approaches; closely \nrelated processes; and related standards. ISO/IEC/IEEE 32675 DevOps, (IEEE \n2675) has the informative subtitle of \n\u201cBuilding Reliable and Secure Systems, \nIncluding Application Build, Package, and \nDeployment\u201d. It defines DevOps as a \u201cset of \nprinciples and practices which enable better \ncommunication and collaboration between \nrelevant stakeholders for the purpose of spec-\nifying, developing, and operating software \nand systems products and services, and con-\ntinuous improvements in all aspects of the \nlife cycle.\u201d It expounds on the principles of \nDevOps, including business or mission first, \ncustomer focus, left shift and continuous \neverything, and systems thinking. (Left-\nshift is defined as \u201c prioritizing the involve-\nment of relevant stakeholders in applying \nquality activities, security, privacy, perfor-\nmance, verification, and validation earlier in \nthe life cycle.\u201d) IEEE 2675 emphasizes the \nleadership commitment needed for successful \napplication of DevOps. It reviews many of \nthe life cycle processes in ISO/IEC/IEEE \n12207 to analyze how they are transformed \nby DevOps, and discusses the use of DevOps \nwith agile methods. In earlier versions, both ISO/IEC/IEEE \n24748-4 and 24748-5 covered what to include \nin a management plan (Systems Engineering \nManagement Plan or Software Engineering \nManagement Plan), respectively.", "domains": ["Design Patterns", "Software Quality Attributes", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 402", "position": 402, "chunk_type": "semantic", "token_estimate": 388}
{"text": "B-8   SWEBOK \u00ae GUIDE V4.0: It reviews many of \nthe life cycle processes in ISO/IEC/IEEE \n12207 to analyze how they are transformed \nby DevOps, and discusses the use of DevOps \nwith agile methods. In earlier versions, both ISO/IEC/IEEE \n24748-4 and 24748-5 covered what to include \nin a management plan (Systems Engineering \nManagement Plan or Software Engineering \nManagement Plan), respectively. That mate-\nrial is still there, but now they also include \nguidance for systems engineers and software \nengineers, respectively, on the management \nplanning and control processes, with brief \npresentations of related processes. 4.2\t More specialized extensions\nAlthough standards are well established for \nspecialized areas of health and safety, secu-\nrity, and environmental concerns, standards \nrelating ethical values to software systems \nare relatively new. The potential for software \nsystems to cause harm through biased deci-\nsions, violations of privacy, or lack of social \nresponsibility led to the development of ISO/\nIEC/IEEE 24748-7000 (IEEE 7000). IEEE \n7000 presents a model process for incorpo-\nrating ethical values into systems design. Engineers, their managers, and other stake-\nholders benefit from well-defined processes \nfor considering ethical issues along with \nthe usual concerns of system performance \nand functionality early in the system life \ncycle. The standard requires consideration \nof values relevant to the culture where the \nsystem is to be deployed. It is applicable \nwith any life cycle model or development \nmethodology. The processes in this stan-\ndard are intended to be performed concur-\nrently with those in ISO/IEC/IEEE 12207 \n(Table B.3)\nEarlier versions of ISO/IEC/IEEE 12207 \nwere considered by some to be overly pre-\nscriptive in terms of required documentation,", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 402", "position": 402, "chunk_type": "semantic", "token_estimate": 264}
{"text": "B-10   SWEBOK \u00ae GUIDE V4.0: 7. Process assessment standards\nProcess assessment is a long-standing method \nof confirming the capabilities, quality, \nand maturity of software engineering pro-\ncesses, and encouraging process improve-\nment. Process audits look for evidence of \nperformance of activities and achievement of \noutcomes (artifacts like work products and \ninformation items). The assumption is that a \nrepeatable process with organizational sup-\nport performed by competent practitioners \nis more likely to produce acceptable soft-\nware products and services. The ISO/IEC \nTABLE B.2. STANDARDS CITED BY KNOWLEDGE AREA", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 404", "position": 404, "chunk_type": "semantic", "token_estimate": 87}
{"text": "Number: Knowledge Area \nCited standards  \n(ISO/IEC/IEEE unless otherwise designated)\nIntroduction \n24765, 12207\n1\nSoftware Requirements\n24765, 12207, ISO/IEC 25010, 29148\n2\nSoftware Architecture\n24765, 12207, 42010\n3\nSoftware Design\n12207, 24748-7000, 24765\n4\nSoftware Construction\n5\nSoftware Testing\nIEEE 1012, ISO/IEC 20246, 24765, ISO/IEC 25010, \n29119 (multiple parts), 32675 \n6\nSoftware Operations\n12207, ISO/IEC 20000, 24765, 32675\n7\nSoftware Maintenance\n12207, 14764, 15288, 32675\n8\nSoftware Configuration \nManagement\nIEEE  828, 24765, 12207\n9\nSoftware Engineering \nManagement\n12207, 32675\n10\nSoftware \nEngineering Process\n12207, 24748-1, 24748-3, 24765, 24774, ISO/IEC \n25000, 29110, 33001, 32675\n11\nSoftware Engineering \nModels and Methods\n12\nSoftware Quality\nIEEE 730, IEEE 982.1, IEEE 1012, IEEE 1228, IEEE \n1633, ISO 9001, 12207, 15026-1, 15288, 20000, 20246, \n24765, 25010, 27001, 33061, 90003,  IEC 60300\n13\nSoftware Security\nISO/IEC 15408-1, ISO/IEC 18045, ISO/IEC 19770-1, \nISO/IEC 21827, 25010, ISO/IEC 27000, ISO/IEC \n27001, ISO/IEC 27032\n14\nSoftware Engineering \nProfessional Practice \nISO/IEC 24773-1, ISO/IEC 24773-4\n15\nSoftware \nEngineering Economics\n12207, 15288\n16\nComputing Foundations\n12207, 24765\n17\nMathematical \nFoundations\n18\nEngineering Foundations\n24765", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 404", "position": 404, "chunk_type": "semantic", "token_estimate": 170}
{"text": "Standard for Software Safety Plans: \u2022\t IEEE 1633-2016 IEEE Recommended \nPractice on Software Reliability\n\u2022\t ISO 9000:2015 Quality management \nsystems \u2014 Fundamentals and vocabulary\n\u2022\t ISO 9001:2015 Quality management \nsystems \u2014 Requirements\n\u2022\t ISO/IEC/IEEE 12207:2017 Systems \nand software engineering: Software \nengineering processes\n\u2022\t ISO/IEC 14143 Information technolo-\ngy--Software measurement--Functional \nsize measurement (multiple parts)\n\u2022\t ISO/IEC/IEEE 14764-2021 Software \nEngineering - Software Life Cycle \nProcesses - Maintenance\n\u2022\t ISO/IEC/IEEE 15026-1-2019 Systems \nand Software Engineering\u2014Systems and \nSoftware Assurance\u2014 Part 1: Concepts \nand Vocabulary\n\u2022\t ISO/IEC/IEEE 15026- 2:2021 Systems \nand \nSoftware \nEngineering\u2014Systems \nand \nSoftware \nAssurance\u2014Part \n2: \nAssurance Case\n\u2022\t ISO/IEC 15026-3: 2023 Systems and \nSoftware \nEngineering\u2014Systems \nand \nSoftware Assurance\u2014Part 3: System \nIntegrity Levels\n\u2022\t ISO/IEC/IEEE 15026-4:2021, Systems \nand Software Engineering\u2014Systems and \nSoftware Assurance\u2014Part 4: Assurance \nin the Life Cycle\n\u2022\t ISO/IEC/IEEE 15288:2023 Standard \nfor Systems and Software Engineering\u2014\nSystem Life Cycle Processes\n\u2022\t ISO/IEC/IEEE 15289:2019 Systems \nand Software Engineering\u2014 Content \nof Life-Cycle Information Products \n(Documentation)\n\u2022\t ISO/IEC \n15408-1:2022 \nInformation \nsecurity, \ncybersecurity \nand \nprivacy \nprotection \u2014 Evaluation criteria for \nIT security \u2014 Part 1: Introduction and \ngeneral model\n\u2022\t ISO/IEC/IEEE 15939:2017 Systems \nand \nSoftware \nEngineering\u2014\nMeasurement Process\n\u2022\t ISO/IEC/IEEE 16085:2021 Systems \nand Software Engineering\u2014Software \nLife Cycle Processes\u2014 Risk Management\n\u2022\t ISO/IEC/IEEE 16326:2019 Systems \nand Software Engineering\u2014Life Cycle \nProcesses\u2014Project Management\n\u2022\t ISO/IEC 16350:2015 Information tech-\nnology \u2014 Systems and software engi-\nneering \u2014 Application management\n\u2022\t ISO/IEC 18045:2022 Information secu-\nrity, cybersecurity and privacy protection \n\u2014 Evaluation criteria for IT security \u2014 \nMethodology for IT security evaluation\n\u2022\t ISO/IEC \n19761:2011 \nSoftware \nEngineering\u2014COSMIC: A Functional \nSize Measurement Method\n\u2022\t ISO/IEC \n19770-1:2017 \nInformation \ntechnology \u2014 IT asset management \u2014 \nPart 1: IT asset management systems \n\u2014 Requirements\n\u2022\t ISO/IEC \n19770-2:2015 \nInformation \ntechnology \u2014 IT asset management \u2014 \nPart 2: Software identification tag\n\u2022\t ISO/IEC \n19770-3:2016 \nInformation \ntechnology \u2014 IT asset management \u2014 \nPart 3: Entitlement schema\n\u2022\t ISO/IEC \n19770-4:2017 \nInformation \ntechnology \u2014 IT asset management \u2014 \nPart 4: Resource utilization measurement\n\u2022\t ISO/IEC \n19770-5:2015 \nInformation \ntechnology \u2014 IT asset management \u2014 \nPart 5: Overview and vocabulary\n\u2022\t ISO/IEC \n19770-8:2020 \nInformation \ntechnology \u2014 IT asset management \n\u2014 Part 8: Guidelines for mapping of \nindustry practices to/from the ISO/IEC \n19770 family of standards\n\u2022\t ISO/IEC 19770-11:2021 Information \ntechnology \u2014 IT asset management \u2014 \nPart 11: Requirements for bodies pro-\nviding audit and certification of IT asset \nmanagement systems\n\u2022\t ISO/IEC \n20000-1:2018 \nInformation", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 406", "position": 406, "chunk_type": "semantic", "token_estimate": 382}
{"text": "APPENDIX B   B-13: Technology\u2014Service \nManagement\u2014\nPart 1: Service management system \nrequirements\n\u2022\t ISO/IEC 20246:2017 Software and sys-\ntems engineering -- Work product reviews\n\u2022\t ISO/IEC 20741:2017 Systems and soft-\nware engineering \u2014 Guideline for the \nevaluation and selection of software engi-\nneering tools\n\u2022\t ISO/IEC 20926:2009 Software and \nSystems \nEngineering\u2014Software \nMeasurement\u2014IFPUG Functional Size \nMeasurement Method SW Requirements\n\u2022\t ISO/IEC \n20968:2002 \nSoftware \nEngineering\u2014Mk II Function Point \nAnalysis\u2014Counting Practices Manual \nSW Requirements\n\u2022\t ISO/IEC 21827:2008 Information tech-\nnology \u2014 Security techniques \u2014 systems \nsecurity engineering \u2014 capability matu-\nrity model\u00ae (SSE-CMM\u00ae)\n\u2022\t ISO/IEC/IEEE 21839:2019 Systems \nand software engineering \u2014 system of \nsystems (SoS) considerations in life cycle \nstages of a system\n\u2022\t ISO/IEC/IEEE 21840:2019 Systems \nand software engineering \u2014 Guidelines \nfor the utilization of ISO/IEC/IEEE \n15288 in the context of system of \nsystems (SoS)\n\u2022\t ISO/IEC/IEEE 21841:2019 Systems \nand software engineering \u2014 Taxonomy \nof systems of systems\n\u2022\t ISO/IEC/IEEE 23026:2023 Systems \nand software engineering \u2014 Engineering \nand management of websites for systems, \nsoftware, and services information\n\u2022\t ISO/IEC 23396:2020 Systems and soft-\nware engineering \u2014 Capabilities of \nreview tools\n\u2022\t ISO/IEC 23531:2020 Systems and soft-\nware engineering \u2014 Capabilities of issue \nmanagement tools\n\u2022\t ISO/IEC 24570:2018 Software engi-\nneering -- NESMA functional size \nmeasurement method --Definitions and \ncounting guidelines for the application of \nfunction point analysis\n\u2022\t ISO/IEC/IEEE 24641:2023 Systems \nand Software engineering \u2014 Methods \nand tools for model-based systems and \nsoftware engineering\n\u2022\t ISO/IEC/IEEE 24748-1:2024 Systems \nand software engineering \u2014 Life cycle \nmanagement \u2014 Part 1: Guidelines for \nlife cycle management\n\u2022\t ISO/IEC/IEEE 24748-2:2024 Systems \nand software engineering \u2014 Life cycle \nmanagement \u2014 Part 2: Guidelines for \nthe application of ISO/IEC/IEEE 15288 \n(system life cycle processes)\n\u2022\t ISO/IEC/IEEE 24748-3:2020 Systems \nand software engineering \u2014 Life cycle \nmanagement \u2014 Part 3: Guidelines for \nthe application of ISO/IEC/IEEE 12207 \n(software life cycle processes)\n\u2022\t ISO/IEC/IEEE 24748-4:2016 Systems \nand software engineering \u2014 Life cycle \nmanagement \u2014 Part 4: Systems engi-\nneering planning\n\u2022\t ISO/IEC/IEEE 24748-5:2017 Systems \nand software engineering \u2014 Life cycle \nmanagement \u2014 Part 5: Software devel-\nopment planning\n\u2022\t ISO/IEC/IEEE 24748-6:2023, Systems \nand Software Engineering \u2014 Life Cycle \nManagement \u2014 Part 6: Systems and \nSoftware Integration\n\u2022\t ISO/IEC/IEEE 24748-7:2019 Systems \nand software engineering \u2014 Life cycle \nmanagement \u2014 Part 7: Application \n \nof systems engineering on defense \n \nprograms\n\u2022\t ISO/IEC/IEEE 24748-8:2019 Systems \nand software engineering \u2014 Life cycle \nmanagement \u2014 Part 8: Technical reviews \nand audits on defense programs\n\u2022\t ISO/IEC/IEEE 24748-9:2023 Systems \nand software engineering, prevention and \ncontrol systems\n\u2022\t ISO/IEC/IEEE \n24748-7000:2022 \n(IEEE 7000:2021) Model Process for \nAddressing Ethical Concerns during \nSystem Design\n\u2022\t ISO/IEC/IEEE 24765:2017 Systems \nand Software Engineering \u2014 Vocabulary, \navailable at www.computer.org/sevocab\n\u2022\t ISO/IEC 24773-1:2019 Software and", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 407", "position": 407, "chunk_type": "semantic", "token_estimate": 438}
{"text": "B-14   SWEBOK \u00ae GUIDE V4.0: systems engineering \u2014 Certification of \nsoftware and systems engineering profes-\nsionals \u2014 Part 1: General requirements\n\u2022\t ISO/IEC 24773-4:2023 Software and \nsystems engineering \u2014 Certification of \nsoftware and systems engineering profes-\nsionals \u2014 Part 4: Software engineering\n\u2022\t ISO/IEC/IEEE 24774:2021 Systems \nand software engineering \u2014 Life cycle \nmanagement \u2014 Specification for process \ndescription\n\u2022\t ISO/IEC 25000:2014 Systems and soft-\nware engineering \u2014 Systems and software \nQuality Requirements and Evaluation \n(SQuaRE) \u2014 Guide to SQuaRE\n\u2022\t ISO/IEC 25001:2014 Systems and soft-\nware engineering \u2014 Systems and software \nQuality Requirements and Evaluation \n(SQuaRE) \u2014 planning and management\n\u2022\t ISO/IEC \n25010:2023 \nSystems \nand \nsoftware engineering \u2014 Systems and \nsoftware Quality Requirements and \nEvaluation (SQuaRE) \u2014 System and \nsoftware quality models\n\u2022\t ISO/IEC 25012:2008 Software engi-\nneering \u2014 Software product Quality \nRequirements and Evaluation (SQuaRE) \n\u2014 Data quality model\n\u2022\t ISO/IEC \n25020:2019 \nSystems \nand \nsoftware engineering \u2014 Systems and \nsoftware Quality Requirements and \nEvaluation (SQuaRE) \u2014 Quality mea-\nsurement framework\n\u2022\t ISO/IEC \n25021:2012 \nSystems \nand \nsoftware engineering \u2014 Systems and \nsoftware Quality Requirements and \nEvaluation (SQuaRE) \u2014 Quality mea-\nsure elements\n\u2022\t ISO/IEC \n25022:2016 \nSystems \nand \nsoftware engineering \u2014 Systems and \nsoftware quality requirements and eval-\nuation (SQuaRE) \u2014 Measurement of \nquality in use\n\u2022\t ISO/IEC \n25023:2016 \nSystems \nand \nsoftware engineering \u2014 Systems and \nsoftware Quality Requirements and \nEvaluation (SQuaRE) \u2014 Measurement \nof system and software product quality\n\u2022\t ISO/IEC \n25024:2015 \nSystems \nand \nsoftware engineering \u2014 Systems and \nsoftware Quality Requirements and \nEvaluation (SQuaRE) \u2014 Measurement \nof data quality\n\u2022\t ISO/IEC \n25030:2019 \nSystems \nand \nsoftware engineering \u2014 Systems and \nsoftware quality requirements and eval-\nuation (SQuaRE) \u2014 Quality require-\nments framework\n\u2022\t ISO/IEC 25040:2011 Systems and soft-\nware engineering \u2014 Systems and software \nQuality Requirements and Evaluation \n(SQuaRE) \u2014 Evaluation process\n\u2022\t ISO/IEC \n25041:2012 \nSystems \nand \nsoftware engineering \u2014 Systems and \nsoftware Quality Requirements and \nEvaluation (SQuaRE) \u2014 Evaluation \nguide for developers, acquirers and inde-\npendent evaluators\n\u2022\t ISO/IEC \n25045:2010 \nSystems \nand \nsoftware engineering \u2014 Systems and \nsoftware Quality Requirements and \nEvaluation (SQuaRE) \u2014 Evaluation \nmodule for recoverability\n\u2022\t ISO/IEC 25051:2014 Software engi-\nneering \u2014 Systems and software Quality \nRequirements and Evaluation (SQuaRE) \n\u2014 Requirements for quality of Ready \nto Use Software Product (RUSP) and \ninstructions for testing\n\u2022\t ISO/IEC \n25062 \nSoftware \nProduct \nQuality Requirements and Evaluation \n(SQuaRE)\u2014Common Industry Format \n(CIF) for Usability\n\u2022\t ISO/IEC 26442:2019 Software and sys-\ntems engineering--Tools and methods for \nproduct line architecture design\n\u2022\t ISO/IEC/IEEE 26511:2018 Systems and \nsoftware engineering \u2014 Requirements \nfor managers of information for users of \nsystems, software, and services\n\u2022\t ISO/IEC/IEEE 26512:2018 Systems and \nsoftware engineering \u2014 Requirements \nfor acquirers and suppliers of informa-\ntion for users\n\u2022\t ISO/IEC/IEEE 26513:2017 Systems and \nsoftware engineering \u2014 Requirements \nfor testers and reviewers of informa-\ntion for users", "domains": ["Domain-Driven Design", "Code Organization"], "source": "swebok-v4.pdf", "section": "Page 408", "position": 408, "chunk_type": "semantic", "token_estimate": 455}
{"text": "APPENDIX B   B-15: \u2022\t ISO/IEC \n26514:2021 \nSystems \nand \nSoftware \nEngineering--Design \nand \ndevelopment of information for users\n\u2022\t ISO/IEC/IEEE 26515:2018 Systems and \nsoftware engineering \u2014 Developing infor-\nmation for users in an agile environment\n\u2022\t ISO/IEC/IEEE 26531:2023 Systems \nand software engineering \u2014 Content \nmanagement for product life-cycle, user \nand service management documentation\n\u2022\t ISO/IEC 26550:2015 Software and sys-\ntems engineering \u2014 Reference model for \nproduct line engineering and management\n\u2022\t ISO/IEC 26551:2016 Software and sys-\ntems engineering \u2014 Tools and methods \nfor product line requirements engineering\n\u2022\t ISO/IEC 26552:2019 Software and sys-\ntems engineering \u2014 Tools and methods \nfor product line architecture design\n\u2022\t ISO/IEC 26553:2018 Information tech-\nnology \u2014 Software and systems engi-\nneering \u2014 Tools and methods for product \nline realization\n\u2022\t ISO/IEC 26554:2018 Information tech-\nnology \u2014 Software and systems engi-\nneering \u2014 Tools and methods for product \nline testing\n\u2022\t ISO/IEC 26555:2015 Software and sys-\ntems engineering \u2014 Tools and methods \nfor product line technical management\n\u2022\t ISO/IEC 26556:2018 Information tech-\nnology \u2014 Software and systems engi-\nneering \u2014 Tools and methods for product \nline organizational management\n\u2022\t ISO/IEC 26557:2016 Software and sys-\ntems engineering \u2014 Methods and tools \nfor variability mechanisms in software \nand systems product line\n\u2022\t ISO/IEC 26558:2017 Software and sys-\ntems engineering \u2014 Methods and tools \nfor variability modelling in software and \nsystems product line\n\u2022\t ISO/IEC 26559:2017 Software and sys-\ntems engineering \u2014 Methods and tools \nfor variability traceability in software and \nsystems product line\n\u2022\t ISO/IEC 26560:2019 Software and sys-\ntems engineering \u2014 Tools and methods \nfor product line product management\n\u2022\t ISO/IEC 26561:2019 Software and sys-\ntems engineering \u2014 Methods and tools \nfor product line technical probe\n\u2022\t ISO/IEC 26562:2019 Software and sys-\ntems engineering \u2014 Methods and tools \nfor product line transition management\n\u2022\t ISO/IEC 26580:2021 Software and sys-\ntems engineering \u2014 Methods and tools \nfor the feature-based approach to software \nand systems product line engineering\n\u2022\t ISO/IEC \n27000:2018 \nInformation \ntechnology \u2014 Security techniques \u2014 \nInformation security management sys-\ntems \u2014 Overview and vocabulary\n\u2022\t ISO/IEC 27001:2022 Information secu-\nrity, cybersecurity and privacy protection \n\u2014 Information security management \nsystems \u2014 Requirements\n\u2022\t ISO/IEC \n27032:2012 \nInformation \ntechnology \u2014 Security techniques \u2014 \nGuidelines for cybersecurity\n\u2022\t ISO/IEC TR 29110-1:2016 Systems and \nsoftware engineering \u2014 Lifecycle pro-\nfiles for Very Small Entities (VSEs) \u2014 \nPart 1: Overview\n\u2022\t ISO/IEC \n29110-2-1:2015 \nSoftware \nengineering \u2014 Lifecycle profiles for \nVery Small Entities (VSEs) \u2014 Part 2-1: \nFramework and taxonomy\n\u2022\t ISO/IEC TR 29110-5-3:2018 Systems \nand software engineering \u2014 Lifecycle \nprofiles for Very Small Entities (VSEs) \n\u2014 Part 5-3: Service delivery guidelines\n\u2022\t ISO/IEC/IEEE 29119-1: 2022 Software \nand systems engineering --Software \ntesting --Part 1: Concepts and definitions\n\u2022\t ISO/IEC/IEEE 29119-2: 2021 Software \nand systems engineering --Software \ntesting --Part 2: Test processes\n\u2022\t ISO/IEC/IEEE 29119-3: 2021 Software \nand systems engineering -- Software \ntesting --Part 3: Test documentation\n\u2022\t ISO/IEC/IEEE 29119-4 Software and \nsystems engineering--Software testing--\nPart 4: Test techniques\n\u2022\t ISO/IEC/IEEE 29119-5: 2016 Software \nand systems engineering -- Software \ntesting -- Part 5: Keyword-Driven Testing\n\u2022\t ISO/IEC TR 29119-6:2021 Software", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 409", "position": 409, "chunk_type": "semantic", "token_estimate": 503}
{"text": "B-16   SWEBOK \u00ae GUIDE V4.0: and systems engineering \u2014 Software \ntesting \u2014 Part 6: Guidelines for the use \nof ISO/IEC/IEEE 29119 (all parts) in \nagile projects\n\u2022\t ISO/IEC TR 29119-11:2020 Software \nand systems engineering \u2014 Software \ntesting \u2014 Part 11: Guidelines on the \ntesting of AI-based systems\n\u2022\t ISO/IEC/IEEE 29148:2018. Systems \nand Software Engineering\u2014Life Cycle \nProcesses\u2014Requirements \nEngineering \nSW Requirements\n\u2022\t ISO/IEC 30130:2016 Software engi-\nneering \u2014 Capabilities of software \ntesting tools\n\u2022\t ISO/IEC \n33001:2015 \nInformation \ntechnology \u2014 Process assessment \u2014 \nConcepts and terminology\n\u2022\t ISO/IEC \n33002:2015 \nInformation \ntechnology \u2014 Process assessment \u2014 \nRequirements for performing process \nassessment\n\u2022\t ISO/IEC \n33003:2015 \nInformation \ntechnology \u2014 Process assessment \u2014 \nRequirements for process measurement \nframeworks\n\u2022\t ISO/IEC \n33004:2015 \nInformation \ntechnology \u2014 Process assessment \u2014 \nRequirements for process reference, pro-\ncess assessment and maturity models\n\u2022\t ISO/IEC TR 33014:2013 Information \ntechnology \u2014 Process assessment \u2014 \nGuide for process improvement\n\u2022\t ISO/IEC 33020:2019 Information tech-\nnology \u2014 Process assessment \u2014 Process \nmeasurement framework for assessment \nof process capability\n\u2022\t ISO/IEC TS 33061:2021 Information \ntechnology \u2014 Process assessment \u2014 \nProcess assessment model for software \nlife cycle processes\n\u2022\t ISO/IEC 33063:2015 Information tech-\nnology \u2014 Process assessment \u2014 Process \nassessment model for software testing\n\u2022\t ISO/IEC/IEEE 32430 Software engi-\nneering \n\u2014 \nStandard \nfor \nsoftware \nnon-functional size measurements\n\u2022\t ISO/IEC/IEEE \n32675:2021 \n(IEEE \n2675:2021) DevOps: Building Reliable \nand Secure Systems Including Application \nBuild, Package, and Deployment\n\u2022\t ISO/IEC 38500:2008 Corporate gover-\nnance of information technology\n\u2022\t ISO/IEC/IEEE 41062:2023 Software \nengineering \u2014 Recommended practice \nfor software acquisition\n\u2022\t ISO/IEC/IEEE 42010:2022 Software, \nsystems and enterprise \u2014 Architecture \ndescription\n\u2022\t ISO/IEC/IEEE 42020:2019: Software, \nsystems and enterprise \u2014 Architec\u00ad\nture processes\n\u2022\t ISO/IEC/IEEE 42030: 2019 Software, \nsystems, and enterprise \u2014 Architecture \nevaluation framework\n\u2022\t IEC 60300-1:2014 Dependability man-\nagement - Part 1: Guidance for manage-\nment and application. \u2022\t IEC/IEEE 82079-1 2019 Preparation0 \nof Information for Use (Instructions for \nUse) of Products - Part 1: Principles and \nGeneral Requirements\n\u2022\t ISO/IEC/IEEE 90003:2018 Software \nengineering \u2014 Guidelines for the \napplication of ISO 9001:2015 to com-\nputer software", "domains": ["Code Organization"], "source": "swebok-v4.pdf", "section": "Page 410", "position": 410, "chunk_type": "semantic", "token_estimate": 332}
{"text": "Appendix C: The Consolidated Reference List identi-\nfies all recommended reference materials \n(to the level of section number) that accom-\npany the breakdown of topics within each \nknowledge area (KA). This Consolidated \nReference List is adopted by the software \nengineering certification and associated pro-\nfessional development products offered by \nthe IEEE Computer Society. KA Editors \nused the references allocated to their KA \nby the Consolidated Reference List as their \nRecommended References. Collectively this Consolidated Reference \n \nList is\n\u2022\t Complete: Covering the entire scope of \nthe SWEBOK Guide. \u2022\t Sufficient: Providing enough informa-\ntion to describe \u201cgenerally accepted\u201d \nknowledge. \u2022\t Consistent: Not providing contradictory \nknowledge nor conflicting practices. \u2022\t Credible: Recognized as providing expert \ntreatment. \u2022\t Current: Treating the subject in a manner \nthat is commensurate with currently gen-\nerally accepted knowledge. \u2022\t Succinct: As short as possible (both in \nnumber of reference items and in total page \ncount) without failing other objectives. In total, there are 37 reference mate-\nrials below. \u2022\t J.H. Allen et al., Software Security \nEngineering: A Guide for Project \nManagers, Addison-Wesley, 2008. \u2022\t M. Bishop, Computer Security: Art \nand Science, 2nd Edition, Addison-\nWesley, 2018. \u2022\t B. Boehm and R. Turner, Balancing \nAgility and Discipline: A Guide for the \nPerplexed, Addison-Wesley, 2003. \u2022\t F. Bott et al., Professional Issues in \nSoftware Engineering, 3rd ed., Taylor & \nFrancis, 2000. \u2022\t J.G. Brookshear, Computer Science: \nAn Overview, 12th ed., Addison-\nWesley, 2017. \u2022\t D. Budgen, Software Design, 3rd ed., \nCRC Press, 2021. \u2022\t E.W. Cheney \nand \nD.R. Kincaid, \nNumerical Mathematics and Computing, \n6th ed., Brooks/Cole, 2007. \u2022\t P. Clements et al., Documenting Software \nArchitectures: Views and Beyond, 2nd \ned., Pearson Education, 2010. \u2022\t R.E. Fairley, Managing and Leading \nSoftware Projects, Wiley-IEEE Computer \nSociety Press, 2009. \u2022\t C.Y Laporte, A.April, Software Quality \nAssurance, IEEE Computer Society \nPress, 1st ed., 2018. \u2022\t E. Gamma et al., Design Patterns: \nElements of Reusable Object-Oriented \nSoftware, \n1st \ned., \nAddison-Wesley \nProfessional, 1994. \u2022\t P. Grubb and A.A. Takang, Software \nMaintenance: Concepts and Practice, 2nd \ned., World Scientific Publishing, 2003. \u2022\t A.M.J. Hass, Configuration Management \nPrinciples and Practices, 1st ed., Addison- \nWesley, 2003. \u2022\t S.H. Kan, Metrics and Models in \nSoftware Quality Engineering, 2nd ed., \nAddison-Wesley, 2002. \u2022\t S. McConnell, Code Complete, 2nd ed., \nMicrosoft Press, 2004. \u2022\t J. McGarry et al., Practical Software \nMeasurement: \nObjective \nInformation", "domains": ["Design Principles", "Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 411", "position": 411, "chunk_type": "semantic", "token_estimate": 382}
{"text": "Foundation: for \nModel-\nDriven Architecture, 1st ed., Addison-\nWesley, 2002. \u2022\t S. Naik and P. Tripathy, Software \nTesting and Quality Assurance: Theory \nand Practice, Wiley-Spektrum, 2008. \u2022\t J. Nielsen, Usability Engineering, 1st ed., \nMorgan Kaufmann, 1993. \u2022\t L. Null and J. Lobur, The Essentials \nof \nComputer \nOrganization \nand \nArchitecture, 2nd ed., Jones and Bartlett \nPublishers, 2006. \u2022\t M. Page-Jones, Fundamentals of Object-\nOriented Design in UML, 1st ed., \nAddison-Wesley, 1999. \u2022\t A. Silberschatz, P.B. Galvin, and G. \nGagne, Operating System Concepts, 8th \ned., Wiley, 2008. \u2022\t I. Sommerville, Software Engineering, \n10th ed., Addison-Wesley, 2016. \u2022\t S. \nTockey, \nReturn \non \nSoftware: \nMaximizing \nthe \nReturn \non \nYour \nSoftware Investment, 1st ed., Addison-\nWesley, 2004. \u2022\t G. Voland, Engineering by Design, 2nd \ned., Prentice Hall, 2003. \u2022\t K.E. Wiegers, Software Requirements, \n3rd ed., Microsoft Press, 2013. \u2022\t J.M. Wing, \u201cA Specifier\u2019s Introduction to \nFormal Methods,\u201d Computer, vol. 23, no. 9, 1990, pp. 8, 10\u201323. \u2022\t G. Kim, J. Humble, P. Debois, J. Willis \nand J. Allspaw, The DevOps handbook: \nHow to create world-class agility, reli-\nability, & security in technology organi-\nzations, 2nd ed., IT Revolution, 2021. \u2022\t G. Booch, J. Rumbaugh and I. Jacobson, \nThe \nUnified \nModeling \nLanguage \nUser Guide, 2nd edition, Addison-\nWesley, 2005. \u2022\t N. Rozanski and E. Woods, Software \nSystems Architecture: Working with \nStakeholders Using Viewpoints and \nPerspectives, 2nd edition, Addison-\nWesley, 2011. \u2022\t D. Farley, Modern Software Engineering: \nDoing What Works to Build Better \nSoftware \nFaster. Addison-Wesley \nProfessional, 2022. \u2022\t J. Shore and S. Warden, The Art of Agile \nDevelopment,  O\u2019Reilly Media, 2nd \nEdition, 2021. \u2022\t Project Management Institute and Agile \nAlliance, Agile Practice Guide, Project \nManagement Institute, 2017. \u2022\t D. C. Montgomery and G. C. Runger, \nApplied \nStatistics \nand \nProbability \nfor Engineers, 7th ed. Hoboken, NJ: \nWiley, 2018. \u2022\t K. Rosen, Discrete Mathematics and \nits Applications, 8th ed., McGraw-\nHill, 2018. \u2022\t E.W. Cheney and D.R. Kincaid, Numerical \nMathematics and Computing, 7th ed., \nAddison Wesley, 2020. \u2022\t L. Null and J. Lobur, The Essentials of \nComputer Organization and Architecture, \n5th ed. Sudbury, MA: Jones and Bartlett \nPublishers, 2018.", "domains": ["Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 412", "position": 412, "chunk_type": "semantic", "token_estimate": 341}
{"text": "The Guide to the Software Engineering Body of: Knowledge (SWEBOK Guide), published by the IEEE \nComputer Society, represents the current state \nof generally accepted knowledge and promotes a \nconsistent view of software engineering worldwide. Guide Version 4 reflects changes since the publication \nof Guide V3 in 2014, including modern development \npractices, new techniques, and the advancement of \nstandards, such as areas and descriptions related to \nagile and DevOps, architecture, operations, security, \nand AI. IEEE Computer Society is the largest computer \nscience and technology community dedicated to \nengaging engineers, scientists, academia, and industry \nprofessionals from across the globe, driving continued \nadvancements.", "domains": ["Design Patterns", "Software Quality Attributes"], "source": "swebok-v4.pdf", "section": "Page 413", "position": 413, "chunk_type": "semantic", "token_estimate": 100}
