{"text": "EDITOR\nHironori Washizaki \nWaseda University, IEEE Computer Society 2024 \nPresident-Elect, 2025 President\nGuide to the \nSoftware \nEngineering \nBody of \nKnowledge\nv4.0\n", "page": 1, "type": "text", "section": "Page 1"}
{"text": "A PROJECT OF THE IEEE COMPUTER SOCIETY\nGuide to the \nSoftware \nEngineering \nBody of \nKnowledge\nv4.0\n", "page": 2, "type": "text", "section": "Page 2"}
{"text": "EDITOR\nHironori Washizaki, Waseda University\n(IEEE Computer Society 2024 President-Elect, 2025 President)\nGuide to the \nSoftware \nEngineering \nBody of \nKnowledge\nv4.0\n", "page": 4, "type": "text", "section": "Page 4"}
{"text": "iv   SWEBOK \u00ae GUIDE V4.0\nCopyright and Reprint Permissions. Educational or personal use of this material is permitted \nwithout fee provided such copies 1) are not made for profit or in lieu of purchasing copies for \nclasses, and that this notice and a full citation to the original work appear on the first page \nof the copy and 2) do not imply IEEE endorsement of any third-party products or services. \nPermission to reprint/republish this material for commercial, advertising or promotional \npurposes or for creating new collective works for resale or redistribution must be obtained from \nIEEE by writing to the IEEE Intellectual Property Rights Office, 445 Hoes Lane, Piscataway, \nNJ 08854-4141 or pubs-permissions@ieee.org. \nReference to any specific commercial products, process, or service does not imply endorsement by \nIEEE. Products, services, and company names mentioned in this document may be the trademarks \nof their respective owners. Mention in this document does not constitute an endorsement. The \nviews and opinions expressed in this work do not necessarily reflect those of IEEE. \nIEEE makes this document available on an \u201cas is\u201d basis and makes no warranty, express or \nimplied, as to the accuracy, capability, efficiency merchantability, or functioning of this document. \nIn no event will IEEE be liable for any general, consequential, indirect, incidental, exemplary, or \nspecial damages, even if IEEE has been advised of the possibility of such damages.\nCopyright \u00a9 2014\u20132024 IEEE. All rights reserved.\nDigital copies of SWEBOK Guide V4.0 may be downloaded free of charge for personal and \nacademic use via www.swebok.org.\nIEEE COMPUTER SOCIETY STAFF FOR THIS PUBLICATION\nMelissa A. Russell, Executive Director\nEric Berkowitz, Director of Membership\nMichelle Phon, Professional Education & Certification Program Coordinator  \nJennie Zhu-Mai, Creative Design Manager\nIEEE Computer Society Products and Services. The world-renowned IEEE Computer Society \npublishes, promotes, and distributes a wide variety of authoritative computer science and \nengineering journals, magazines, conference proceedings, and professional education products. \nVisit the Computer Society at www.computer.org for more information.\n", "page": 5, "type": "text", "section": "Page 5"}
{"text": "v \nTable of \nContents\nForeword\b\nxxv \n\t\nForeword to the 2014 Edition \b\nxxvi\nForeword to the 2004 Edition\b\nxxvii\nEditor\b\nxxix\nKnowledge Area Editors\b\nxxix\nContributing Editors\b\nxxx\nSteering Group\b\nxxxi\nKnowledge Area Editors of Previous SWEBOK Versions\b\nxxxi\nReview Team\b\nxxxiii\nAcknowledgements\b\nxxxiv\nIEEE Computer Society Presidents\b\nxxxiv\nProfessional and Educational Activities Board, 2024 Membership\b\nxxxiv\nMotions Regarding the Approval of SWEBOK Guide V4.0\b\nxxxv\nMotions Regarding the Approval of SWEBOK Guide V3.0\b\nxxxv\nMotions Regarding the Approval of SWEBOK Guide 2004 Version\b\nxxxvi\nIntroduction to the Guide\b\nxxxvii\nCHAPTER 01 \nSoftware Requirements\b\n1-1\nIntroduction\b\n1-1\n1.\t Software Requirements Fundamentals\b\n1-2\n1.1.\t\nDefinition of a Software Requirement \b\n1-2\n1.2.\t\nCategories of Software Requirements\b\n1-3\n1.3.\t\nSoftware Product Requirements and Software  \nProject Requirements\b\n1-3\n1.4.\t\nFunctional Requirements\b\n1-4\n1.5.\t\nNonfunctional Requirements \b\n1-4\n1.6.\t\nTechnology Constraints\b\n1-4\n1.7.\t\nQuality of Service Constraints\b\n1-4\n1.8.\t\nWhy Categorize Requirements This Way?\b\n1-5\n1.9.\t\nSystem Requirements and Software Requirements\b\n1-5\n1.10.\t Derived Requirements\b\n1-6\n1.11.\t Software Requirements Activities\b\n1-6\n2.\t Requirements Elicitation\b\n1-6\n2.1.\t\nRequirements Sources\b\n1-6\n2.2.\t\nCommon Requirements Elicitation Techniques \b\n1-7\n3.\t Requirements Analysis\b\n1-8\n3.1.\t\nBasic Requirements Analysis \b\n1-8\n3.2.\t\nEconomics of Quality of Service Constraints\b\n1-8\n3.3.\t\nFormal Analysis \b\n1-9\n", "page": 6, "type": "text", "section": "Page 6"}
{"text": "vi   SWEBOK \u00ae GUIDE V4.0\n3.4.\t\nAddressing Conflict in Requirements\b\n1-10\n4.\t Requirements Specification\b\n1-10\n4.1.\t\nUnstructured Natural Language Requirements Specification\b\n1-11\n4.2.\t\nStructured Natural Language Requirements Specification\b\n1-12\n4.3.\t\nAcceptance Criteria-Based Requirements Specification\b\n1-12\n4.4.\t\nModel-Based Requirements Specification\b\n1-14\n4.5.\t\nAdditional Attributes of Requirement\b\n1-14\n4.6.\t\nIncremental and Comprehensive Requirements Specification\b\n1-15\n5.\t\nRequirements Validation\b\n1-15\n5.1.\t\nRequirements Reviews\b\n1-15\n5.2.\t\nSimulation and Execution\b\n1-16\n5.3.\t\nPrototyping\b\n1-16\n6.\t Requirements Management Activities\b\n1-16\n6.1.\t\nRequirements Scrubbing\b\n1-16\n6.2.\t\nRequirements Change Control \b\n1-17\n6.3.\t\nScope Matching\b\n1-17\n7.\t\nPractical Considerations\b\n1-17\n7.1.\t\nIterative Nature of the Requirements Process \b\n1-17\n7.2.\t\nRequirements Prioritization\b\n1-17\n7.3.\t\nRequirements Tracing \b\n1-18\n7.4.\t\nRequirements Stability and Volatility\b\n1-19\n7.5.\t\nMeasuring Requirements\b\n1-19\n7.6.\t\nRequirements Process Quality and Improvement \b\n1-19\n8.\t Software Requirements Tools\b\n1-20\n8.1.\t\nRequirements Management Tools \b\n1-20\n8.2.\t\nRequirements Modeling Tools\b\n1-20\n8.3.\t\nFunctional Test Case Generation Tools\b\n1-20\nMatrix of Topics vs. Reference Material\b\n1-21\nFurther Readings\b\n1-22\nReferences\b\n1-23\nCHAPTER 02 \nSoftware Architecture\b\n2-1\nIntroduction\b\n2-1\n1.\t Software Architecture Fundamentals\b\n2-1\n1.1.\t\nThe Senses of \u201cArchitecture\u201d\b\n2-1\n1.2.\t\nStakeholders and Concerns\b\n2-3\n1.3.\t\nUses of Architecture\b\n2-4\n2.\t Software Architecture Description\b\n2-4\n2.1.\t\nArchitecture Views and Viewpoints\b\n2-5\n2.2.\t\nArchitecture Patterns, Styles and Reference Architectures\b\n2-6\n2.3.\t\nArchitecture Description Languages and Architecture Frameworks\b\n2-7\n2.4.\t\nArchitecture as Significant Decisions\b\n2-7\n3.\t Software Architecture Process\b\n2-8\n3.1.\t\nArchitecture in Context\b\n2-8\n3.1.1.\t Relation of Architecture to Design\b\n2-9\n", "page": 7, "type": "text", "section": "Page 7"}
{"text": "TABLE OF CONTENTS   vii\n3.2.\t\nArchitectural Design\b\n2-9\n3.2.1.\tArchitecture Analysis\b\n2-9\n3.2.2.\tArchitecture Synthesis\b\n2-9\n3.2.3.\tArchitecture Evaluation\b\n2-10\n3.3.\t\nArchitecture Practices, Methods, and Tactics\b\n2-10\n3.4.\t\nArchitecting in the Large\b\n2-10\n4.\t\nSoftware Architecture Evaluation\b\n2-10\n4.1.\t\nGoodness in Architecture\b\n2-10\n4.2.\t\nReasoning about Architectures\b\n2-11\n4.3.\t\nArchitecture Reviews\b\n2-11\n4.4.\t\nArchitecture Metrics\b\n2-11\nMatrix of Topics vs. Reference Material\b\n2-12\nFurther Readings\b\n2-13\nReferences\b\n2-14\nCHAPTER 03 \nSoftware Design\b\n3-1\nIntroduction\b\n3-1\n1.\t\nSoftware Design Fundamentals\b\n3-2\n1.1.\t\nDesign Thinking\b\n3-2\n1.2.\t\nContext of Software Design\b\n3-2\n1.3.\t\nKey Issues in Software Design\b\n3-3\n1.4.\t\nSoftware Design Principles\b\n3-3\n2.\t\nSoftware Design Processes\b\n3-5\n2.1.\t\nHigh-Level Design\b\n3-6\n2.2.\t\nDetailed Design\b\n3-6\n3.\t\nSoftware Design Qualities\b\n3-6\n3.1.\t\nConcurrency\b\n3-6\n3.2.\t\nControl and Event Handling\b\n3-6\n3.3.\t\nData Persistence\b\n3-7\n3.4.\t\nDistribution of Components\b\n3-7\n3.5.\t\nErrors and Exception Handling, Fault Tolerance\b\n3-7\n3.6.\t\nIntegration and Interoperability\b\n3-7\n3.7.\t\nAssurance, Security, and Safety\b\n3-7\n3.8.\t\nVariability\b\n3-7\n4.\t\nRecording Software Designs\b\n3-7\n4.1.\t\nModel-Based Design\b\n3-8\n4.2.\t\nStructural Design Descriptions\b\n3-8\n4.3.\t\nBehavioral Design Descriptions\b\n3-9\n4.4.\t\nDesign Patterns and Styles\b\n3-10\n4.5.\t\nSpecialized and Domain-Specific Languages\b\n3-10\n4.6.\t\nDesign Rationale\b\n3-11\n5.\t\nSoftware Design Strategies and Methods\b\n3-11\n5.1.\t\nGeneral Strategies\b\n3-11\n5.2.\t\nFunction-Oriented (or Structured) Design\b\n3-11\n5.3.\t\nData-Centered Design\b\n3-11\n", "page": 8, "type": "text", "section": "Page 8"}
{"text": "viii   SWEBOK \u00ae GUIDE V4.0\n5.4.\t\nObject-Oriented Design\b\n3-11\n5.5.\t\nUser-Centered Design\b\n3-12\n5.6.\t\nComponent-Based Design (CBD)\b\n3-12\n5.7.\t\nEvent-Driven Design\b\n3-12\n5.8.\t\nAspect-Oriented Design (AOD)\b\n3-12\n5.9.\t\nConstraint-Based Design\b\n3-12\n5.10.\t Domain-Driven Design\b\n3-13\n5.11.\t Other Methods\b\n3-13\n6.\t Software Design Quality Analysis and Evaluation\b\n3-13\n6.1.\t\nDesign Reviews and Audits\b\n3-13\n6.2.\t\nQuality Attributes\b\n3-13\n6.3.\t\nQuality Analysis and Evaluation Techniques\b\n3-13\n6.4.\t\nMeasures and Metrics\b\n3-14\n6.5.\t\nVerification, Validation, and Certification\b\n3-14\nMatrix of Topics vs. Reference Material\b\n3-14\nFurther Readings\b\n3-16\nReferences\b\n3-16\nCHAPTER 04 \nSoftware Construction\b\n4-1\nIntroduction\b\n4-1\n1.\t Software Construction Fundamentals\b\n4-2\n1.1.\t\nMinimizing Complexity\b\n4-2\n1.2.\t\nAnticipating and Embracing Change\b\n4-2\n1.3.\t\nConstructing for Verification\b\n4-4\n1.4.\t\nReusing Assets \b\n4-4\n1.5.\t\nApplying Standards in Construction \b\n4-4\n2.\t Managing Construction\b\n4-4\n2.1.\t\nConstruction in Life Cycle Models\b\n4-4\n2.2.\t\nConstruction Planning \b\n4-5\n2.3.\t\nConstruction Measurement \b\n4-5\n2.4.\t\nManaging Dependencies \b\n4-5\n3.\t Practical Considerations\b\n4-6\n3.1.\t\nConstruction Design\b\n4-6\n3.2.\t\nConstruction Languages \b\n4-6\n3.3.\t\nCoding \b\n4-7\n3.4.\t\nConstruction Testing \b\n4-7\n3.5.\t\nReuse in Construction \b\n4-7\n3.6.\t\nConstruction Quality \b\n4-8\n3.7.\t\nIntegration\b\n4-9\n3.8.\t\nCross-Platform Development and Migration \b\n4-9\n4.\t\nConstruction Technologies\b\n4-10\n4.1.\t\nAPI Design and Use \b\n4-10\n4.2.\t\nObject-Oriented Runtime Issues \b\n4-10\n4.3.\t\nParameterization, Templates, and Generics \b\n4-10\n4.4.\t\nAssertions, Design by Contract, and Defensive Programming \b\n4-10\n4.5.\t\nError Handling, Exception Handling, and Fault Tolerance \b\n4-11\n", "page": 9, "type": "text", "section": "Page 9"}
{"text": "TABLE OF CONTENTS   ix\n4.6.\t\nExecutable Models \b\n4-11\n4.7.\t\nState-Based and Table-Driven Construction Techniques \b\n4-11\n4.8.\t\nRuntime Configuration and Internationalization\b\n4-12\n4.9.\t\nGrammar-Based Input Processing\b\n4-12\n4.10.\t Concurrency Primitives \b\n4-12\n4.11.\t Middleware\b\n4-12\n4.12.\t Construction Methods for Distributed and Cloud-Based Software\b\n4-13\n4.13.\t Constructing Heterogeneous Systems\b\n4-13\n4.14.\t Performance Analysis and Tuning\b\n4-13\n4.15.\t Platform Standards\b\n4-13\n4.16.\t Test-First Programming\b\n4-14\n4.17.\t Feedback Loop for Construction\b\n4-14\n5.\t\nSoftware Construction Tools\b\n4-14\n5.1.\t\nDevelopment Environments \b\n4-14\n5.2.\t\nVisual Programming and Low-Code/Zero-Code Platforms\b\n4-14\n5.3.\t\nUnit Testing Tools\b\n4-15\n5.4.\t\nProfiling, Performance Analysis, and Slicing Tools \b\n4-15\nMatrix of Topics vs. Reference Material\b\n4-15\nFurther Readings\b\n4-18\nReferences\b\n4-18\b\nCHAPTER 05 \nSoftware Testing\b\n5-1\nIntroduction\b\n5-1\n1.\t Software Testing Fundamentals\b\n5-3\n1.1.\t\nFaults vs. Failures\b\n5-3\n1.2.\t\nKey Issues\b\n5-4\n1.2.1.\t Test Case Creation \b\n5-4\n1.2.2.\tTest Selection and Adequacy Criteria\b\n5-4\n1.2.3.\tPrioritization/Minimization\b\n5-4\n1.2.4.\tPurpose of Testing\b\n5-4\n1.2.5.\tAssessment and Certification \b\n5-4\n1.2.6.\tTesting for Quality Assurance/Improvement \b\n5-4\n1.2.7.\t The Oracle Problem \b\n5-4\n1.2.8.\tTheoretical and Practical Limitations \b\n5-5\n1.2.9.\t The Problem of Infeasible Paths \b\n5-5\n1.2.10.\tTestability \b\n5-5\n1.2.11.\tTest Execution and Automation\b\n5-5\n1.2.12.\t\nScalability \b\n5-5\n1.2.13.\tTest Effectiveness\b\n5-5\n1.2.14.\tControllability, Replication, and Generalization\b\n5-5\n1.2.15.\tOff-Line vs. Online Testing\b\n5-6\n1.3.\t\nRelationship of Testing to Other Activities\b\n5-6\n2.\t Test Levels\b\n5-6\n2.1.\t\nThe Target of the Test \b\n5-6\n2.1.1.\t Unit Testing \b\n5-6\n2.1.2.\tIntegration Testing \b\n5-7\n", "page": 10, "type": "text", "section": "Page 10"}
{"text": "x   SWEBOK \u00ae GUIDE V4.0\n2.1.3.\tSystem Testing\b\n5-7\n2.1.4.\t Acceptance Testing \b\n5-7\n2.2.\t\nObjectives of Testing \b\n5-7\n2.2.1.\tConformance Testing\b\n5-7\n2.2.2. \t\nCompliance Testing\b\n5-8\n2.2.3.\tInstallation Testing \b\n5-8\n2.2.4.\tAlpha and Beta Testing \b\n5-8\n2.2.5.\tRegression Testing \b\n5-8\n2.2.6.\tPrioritization Testing \b\n5-8\n2.2.7.\t Non-functional Testing \b\n5-8\n2.2.8.\tSecurity Testing\b\n5-9\n2.2.9. Privacy Testing \b\n5-9\n2.2.10. Interface and Application Program Interface (API) Testing\b\n5-10\n2.2.11. Configuration Testing \b\n5-10\n2.2.12. Usability and Human-Computer Interaction Testing\b\n5-10\n3.\t Test Techniques \b\n5-10\n3.1.\t\nSpecification-Based Techniques\b\n5-10\n3.1.1.\t Equivalence Partitioning\b\n5-11\n3.1.2.\tBoundary-Value Analysis\b\n5-11\n3.1.3.\t Syntax Testing\b\n5-11\n3.1.4.\t Combinatorial Test Techniques \b\n5-11\n3.1.5.\t Decision Table\b\n5-11\n3.1.6.\t Cause-Effect Graphing\b\n5-11\n3.1.7.\t State Transition Testing \b\n5-12\n3.1.8.\t Scenario-Based Testing \b\n5-12\n3.1.9.\t Random Testing\b\n5-12\n3.1.10.\tEvidence-Based \b\n5-12\n3.1.11.\tForcing Exception \b\n5-12\n3.2.\t\nStructure-Based Test Techniques\b\n5-13\n3.2.1.\tControl Flow Testing\b\n5-13\n3.2.2.\tData Flow Testing \b\n5-13\n3.2.3.\tReference Models for Structure-Based Test Techniques \b\n5-13\n3.3.\t\nExperience-Based Techniques\b\n5-13\n3.3.1.\t Error Guessing\b\n5-13\n3.3.2.\tExploratory Testing\b\n5-13\n3.3.3.\tFurther Experience-Based Techniques \b\n5-14\n3.4.\t\nFault-Based and Mutation Techniques \b\n5-14\n3.5.\t\nUsage-Based Techniques \b\n5-15\n3.5.1.\t Operational Profile \b\n5-15\n3.5.2.\tUser Observation Heuristics\b\n5-15\n3.6.\t\nTechniques Based on the Nature of the Application\b\n5-15\n3.7.\t\nSelecting and Combining Techniques \b\n5-16\n3.7.1.\t Combining Functional and Structural\b\n5-16\n3.7.2.\t Deterministic vs. Random \b\n5-16\n3.8.\t\nTechniques Based on Derived Knowledge \b\n5-16\n4.\t Test-Related Measures\b\n5-16\n4.1.\t\nEvaluation of the SUT \b\n5-17\n4.1.1.\t SUT Measurements that Aid in Planning and Designing Tests \b\n5-17\n", "page": 11, "type": "text", "section": "Page 11"}
{"text": "TABLE OF CONTENTS   xi\n4.1.2.\tFault Types, Classification and Statistics\b\n5-17\n4.1.3.\t Fault Density \b\n5-17\n4.1.4.\t Life Test, Reliability Evaluation \b\n5-17\n4.1.5.\t Reliability Growth Models \b\n5-17\n4.2.\t\nEvaluation of the Tests Performed \b\n5-18\n4.2.1.\tFault Injection\b\n5-18\n4.2.2.\tMutation Score \b\n5-18\n4.2.3.\tComparison and Relative Effectiveness of Different Techniques \b\n5-18\n5.\t\nTest Process \b\n5-18\n5.1.\t\nPractical Considerations \b\n5-19\n5.1.1.\t Attitudes/Egoless Programming \b\n5-19\n5.1.2.\t Test Guides and Organizational Process \b\n5-19\n5.1.3.\t Test Management and Dynamic Test Processes\b\n5-19\n5.1.4.\t Test Documentation\b\n5-19\n5.1.5.\t Test Team \b\n5-20\n5.1.6.\t Test Process Measures \b\n5-20\n5.1.7. \tTest Monitoring and Control \b\n5-20\n5.1.8.\t Test Completion\b\n5-20\n5.1.9.\t Test Reusability\b\n5-21\n5.2.\t\nTest Sub-Processes and Activities\b\n5-21\n5.2.1.\t Test Planning Process \b\n5-21\n5.2.2.\tTest Design and Implementation\b\n5-21\n5.2.3.\tTest Environment Set-up and Maintenance \b\n5-21\n5.2.4.\tControlled Experiments and Test Execution \b\n5-22\n5.2.5.\tTest Incident Reporting\b\n5-22\n5.3.\t\nStaffing \b\n5-22\n6.\t Software Testing in the Development Processes and the Application Domains\b\n5-23\n6.1.\t\nTesting Inside Software Development Processes \b\n5-23\n6.1.1.\t Testing in Traditional Processes \b\n5-23\n6.1.2.\tTesting in Line with Shift-Left Movement\b\n5-23\n6.2.\t\nTesting in the Application Domains\b\n5-24\n7.\t\nTesting of and Testing Through Emerging Technologies \b\n5-26\n7.1.\t\nTesting of Emerging Technologies\b\n5-26\n7.2.\t\nTesting Through Emerging Technologies\b\n5-27\n8.\t Software Testing Tools \b\n5-29\n8.1.\t\nTesting Tool Support and Selection\b\n5-29\n8.2.\t\nCategories of Tools \b\n5-29\nMatrix of Topics vs. Reference Material\b\n5-31\nReferences\b\n5-34\nCHAPTER 06 \nSoftware Engineering Operations\b\n6-1\nIntroduction\b\n6-1\n1.\t Software Engineering Operations Fundamentals\b\n6-3\n1.1.\t\nDefinition of Software Engineering Operations\b\n6-3\n1.2.\t\nSoftware Engineering Operations Processes\b\n6-4\n", "page": 12, "type": "text", "section": "Page 12"}
{"text": "xii   SWEBOK \u00ae GUIDE V4.0\n1.3.\t\nSoftware Installation \b\n6-5\n1.4.\t\nScripting and Automating\b\n6-5\n1.5.\t\nEffective Testing and Troubleshooting\b\n6-5\n1.6.\t\nPerformance, Reliability and Load Balancing\b\n6-6\n2.\t Software Engineering Operations Planning\b\n6-6\n2.1.\t\nOperations Plan and Supplier Management\b\n6-6\n2.1.1.\t Operations Plan\b\n6-6\n2.1.2.\tSupplier Management\b\n6-7\n2.2.\t\nDevelopment and Operational Environments\b\n6-7\n2.3.\t\nSoftware Availability, Continuity, and Service Levels\b\n6-8\n2.4.\t\nSoftware Capacity Management\b\n6-8\n2.5.\t\nSoftware Backup, Disaster Recovery, and Failover\b\n6-8\n2.6.\t\nSoftware and Data Safety, Security, Integrity, Protection, and Controls\b\n6-9\n3.\t Software Engineering Operations Delivery\b\n6-9\n3.1.\t\nOperational Testing, Verification, and Acceptance\b\n6-9\n3.2.\t\nDeployment/Release Engineering\b\n6-10\n3.3.\t\nRollback and Data Migration\b\n6-10\n3.4.\t\nChange Management\b\n6-11\n3.5.\t\nProblem Management\b\n6-11\n4.\t Software Engineering Operations Control\b\n6-11\n4.1.\t\nIncident Management\b\n6-11\n4.2.\t\nMonitor, Measure, Track, and Review\b\n6-11\n4.3.\t\nOperations Support\b\n6-12\n4.4.\t\nOperations Service Reporting\b\n6-12\n5.\t\nPractical Considerations\b\n6-12\n5.1.\t\nIncident and Problem Prevention\b\n6-12\n5.2.\t\nOperational Risk Management\b\n6-12\n5.3.\t\nAutomating Software Engineering Operations\b\n6-12\n5.4.\t\nSoftware Engineering Operations for Small Organizations\b\n6-13\n6.\t Software Engineering Operations Tools\b\n6-13\n6.1.\t\nContainers and Virtualization\b\n6-13\n6.2.\t\nDeployment\b\n6-13\n6.3.\t\nAutomated Test\b\n6-14\n6.4.\t\nMonitoring and Telemetry\b\n6-14\nMatrix of Topics vs. Reference Material\b\n6-14\nReferences \b\n6-15\nCHAPTER 07 \nSoftware Maintenance\b\n7-1\nIntroduction\b\n7-1\n1.\t Software Maintenance Fundamentals\b\n7-2\n1.1.\t\nDefinitions and Terminology\b\n7-2\n1.2.\t\nNature of Software Maintenance\b\n7-2\n1.3.\t\nNeed for Software Maintenance\b\n7-3\n1.4.\t\nMajority of Maintenance Costs\b\n7-3\n1.5.\t\nEvolution of Software\b\n7-3\n", "page": 13, "type": "text", "section": "Page 13"}
{"text": "TABLE OF CONTENTS   xiii\n1.6.\t\nCategories of Software Maintenance\b\n7-4\n2.\t Key Issues in Software Maintenance\b\n7-5\n2.1.\t\nTechnical Issues\b\n7-5\n2.1.1\t Limited Understanding\b\n7-5\n2.1.2\t Testing\b\n7-5\n2.1.3\t Impact Analysis\b\n7-6\n2.1.4\t Maintainability\b\n7-6\n2.2.\t\nManagement Issues\b\n7-7\n2.2.1.\tAlignment with Organizational Objectives\b\n7-7\n2.2.2.\tStaffing\b\n7-7\n2.2.3.\tProcess\b\n7-8\n2.2.4.\tSupplier Management\b\n7-8\n2.2.5.\tOrganizational Aspects of Maintenance\b\n7-8\n2.3.\t\nSoftware Maintenance Costs \b\n7-9\n2.3.1. \tTechnical Debt Cost Estimation\b\n7-9\n2.3.2. \t\nMaintenance Cost Estimation\b\n7-9\n2.4.\t\nSoftware Maintenance Measurement\b\n7-10\n3.\t Software Maintenance Processes\b\n7-11\n3.1.\t\nSoftware Maintenance Processes\b\n7-11\n3.2.\t\nSoftware Maintenance Activities and Tasks\b\n7-11\n3.2.1.\tSupporting and Monitoring Activities\b\n7-12\n3.2.2.\tPlanning Activities\b\n7-12\n3.2.3.\tConfiguration Management\b\n7-13\n3.2.4.\tSoftware Quality\b\n7-13\n4.\t Software Maintenance Techniques\b\n7-13\n4.1.\t\nProgram Comprehension\b\n7-13\n4.2.\t\nSoftware Reengineering\b\n7-13\n4.3.\t\nReverse Engineering\b\n7-14\n4.4.\t\nContinuous Integration, Delivery, Testing, and Deployment\b\n7-14\n4.5.\t\nVisualizing Maintenance\b\n7-15\n5.\t\nSoftware Maintenance Tools\b\n7-15\nMatrix of Topics vs. Reference Material\b\n7-16\nFurther Readings\b\n7-17\nReferences \b\n7-17\nCHAPTER 08 \nSoftware Configuration Management\b\n8-1\nIntroduction\b\n8-1\n1.\t Management of the SCM Process\b\n8-2\n1.1.\t\nOrganizational Context for SCM\b\n8-2\n1.2.\t\nConstraints and Guidance for the SCM Process\b\n8-3\n1.3.\t\nPlanning for SCM \b\n8-3\n1.3.1.\t SCM Organization and Responsibilities\b\n8-4\n1.3.2.\tSCM Resources and Schedules\b\n8-4\n1.3.3.\tTool Selection and Implementation\b\n8-4\n1.3.4.\tVendor/Subcontractor Control\b\n8-5\n", "page": 14, "type": "text", "section": "Page 14"}
{"text": "xiv   SWEBOK \u00ae GUIDE V4.0\n1.3.5.\t Interface Control\b\n8-5\n1.4.\t\nSCM Plan\b\n8-5\n1.5.\t\nMonitoring of Software Configuration Management \b\n8-5\n1.5.1\t SCM Measures and Measurement \b\n8-6\n1.5.2\t In-Process Audits of SCM\b\n8-6\n2.\t Software Configuration Identification\b\n8-6\n2.1.\t\nIdentifying Items to Be Controlled\b\n8-6\n2.1.1\t Software Configuration\b\n8-6\n2.1.2\t Software Configuration Item\b\n8-6\n2.2.\t\nConfiguration Item Identifiers and Attributes\b\n8-7\n2.3.\t\nBaseline Identification\b\n8-7\n2.4.\t\nBaseline Attributes\b\n8-7\n2.5.\t\nRelationships Scheme Definition\b\n8-7\n2.6.\t\nSoftware Libraries \b\n8-8\n3.\t Software Configuration Change Control \b\n8-9\n3.1.\t\nRequesting, Evaluating, and Approving Software Changes \b\n8-9\n3.1.1\t Software Configuration Control Board\b\n8-10\n3.1.2\t Software Change Request Process\b\n8-10\n3.1.3\t Software Change Request Forms Definition\b\n8-10\n3.2.\t\nImplementing Software Changes\b\n8-10\n3.3.\t\nDeviations and Waivers\b\n8-11\n4.\t Software Configuration Status Accounting\b\n8-11\n4.1.\t\nSoftware Configuration Status Information\b\n8-11\n4.2.\t\nSoftware Configuration Status Reporting\b\n8-11\n5.\t\nSoftware Configuration Auditing\b\n8-12\n5.1.\t\nSoftware Functional Configuration Audit \b\n8-12\n5.2.\t\nSoftware Physical Configuration Audit \b\n8-12\n5.3.\t\nIn-Process Audits of a Software Baseline\b\n8-12\n6.\t Software Release Management and Delivery\b\n8-13\n6.1.\t\nSoftware Building\b\n8-13\n6.2.\t\nSoftware Release Management\b\n8-13\n7.\t\nSoftware Configuration Management Tools\b\n8-14\nMatrix of Topics vs. Reference Material\b\n8-15\nFurther Readings\b\n8-16\nReferences \b\n8-17\nCHAPTER 09\nSoftware Engineering Management\b\n9-1\nIntroduction\b\n9-1\n1.\t Initiation and Scope Definition\b\n9-6\n1.1.\t\nDetermination and Negotiation of Requirements\b\n9-6\n1.2.\t\nFeasibility Analysis\b\n9-6\n1.3.\t\nProcess for the Review and Revision of Requirements\b\n9-7\n2.\t Software Project Planning\b\n9-7\n2.1.\t\nProcess Planning\b\n9-8\n2.2.\t\nDetermine Deliverables\b\n9-8\n", "page": 15, "type": "text", "section": "Page 15"}
{"text": "TABLE OF CONTENTS   xv\n2.3.\t\nEffort, Schedule, and Cost Estimation\b\n9-8\n2.4.\t\nResource Allocation \b\n9-9\n2.5.\t\nRisk Management \b\n9-9\n2.6.\t\nQuality Management \b\n9-9\n2.7.\t\nPlan Management \b\n9-10\n3.\t\nSoftware Project Execution\b\n9-11\n3.1.\t\nImplementation of Plans \b\n9-11\n3.2.\t\nSoftware Acquisition and Supplier Contract Management \b\n9-11\n3.3.\t\nImplementation of Measurement Process \b\n9-12\n3.4.\t\nMonitor Process \b\n9-12\n3.5.\t\nControl Process \b\n9-12\n3.6.\t\nReporting\b\n9-13\n4.\t\nSoftware Review and Evaluation\b\n9-13\n4.1.\t\nDetermining Satisfaction of Requirements \b\n9-13\n4.2.\t\nReviewing and Evaluating Performance \b\n9-13\n5.\t\nClosure\b\n9-13\n5.1.\t\nDetermining Closure \b\n9-13\n5.2.\t\nClosure Activities \b\n9-14\n6.\t\nSoftware Engineering Measurement\b\n9-14\n6.1.\t\nEstablish and Sustain Measurement Commitment \b\n9-14\n6.2.\t\nPlan the Measurement Process\b\n9-15\n6.3.\t\nPerform the Measurement Process\b\n9-15\n6.4.\t\nEvaluate Measurement \b\n9-16\n7.\t\nSoftware Engineering Management Tools\b\n9-16\nMatrix of Topics vs. Reference Material\b\n9-17\nFurther Readings\b\n9-18\nReferences\b\n9-18\nCHAPTER 10 \nSoftware Engineering Process\b\n10-1\nIntroduction\b\n10-1\n1.\t\nSoftware Engineering Process Fundamentals\b\n10-1\n1.1.\t\nIntroduction \b\n10-1\n1.2.\t\nSoftware Engineering Process Definition\b\n10-3\n2.\t\nLife Cycles\b\n10-3\n2.1.\t\nLife Cycle Definition, Process Categories, and Terminology\b\n10-3\n2.2.\t\nRationale for Life Cycles\b\n10-4\n2.3.\t\nThe Concepts of Process Models and Life Cycle Models\b\n10-5\n2.4.\t\nSome Paradigms for Development Life Cycle Models\b\n10-5\n2.5.\t\nDevelopment Life Cycle Models and Their Engineering Dimension\b\n10-6\n2.6.\t\nThe Management of SLCPs\b\n10-7\n2.7.\t\nSoftware Engineering Process Management\b\n10-8\n2.8.\t\nSoftware Life Cycle Adaptation\b\n10-8\n2.9.\t\nPractical Considerations\b\n10-8\n2.10.\t Software Process Infrastructure, Tools, Methods\b\n10-9\n2.11.\t Software Engineering Process Monitoring and  \n", "page": 16, "type": "text", "section": "Page 16"}
{"text": "xvi   SWEBOK \u00ae GUIDE V4.0\nits Relationship with the Software Product\b\n10-9\n3.\t Software Process Assessment and Improvement\b\n10-9\n3.1.\t\nOverview of Software Process Assessment and Improvement\b\n10-9\n3.2.\t\nGoal-Question-Metric (GQM)\b\n10-10\n3.3.\t\nFramework-Based Methods\b\n10-10\n3.4.\t\nProcess Assessment and Improvement in Agile\b\n10-10\nMatrix of Topics vs. Reference Material\b\n10-10\nReferences\b\n10-11\nCHAPTER 11 \nSoftware Engineering Models and Methods\b\n11-1\nIntroduction\b\n11-1\n1.\t Modeling\b\n11-1\n1.1.\t\nModeling Principles\b\n11-2\n1.2.\t\nProperties and Expression of Models \b\n11-3\n1.3.\t\nSyntax, Semantics, and Pragmatics \b\n11-3\n1.4.\t\nPreconditions, Postconditions, and Invariants \b\n11-4\n2.\t Types of Models\b\n11-4\n2.1.\t\nStructural Modeling\b\n11-5\n2.2.\t\nBehavioral Modeling\b\n11-5\n3.\t Analysis of Models\b\n11-5\n3.1.\t\nAnalyzing for Completeness \b\n11-6\n3.2.\t\nAnalyzing for Consistency \b\n11-6\n3.3.\t\nAnalyzing for Correctness \b\n11-6\n3.4.\t\nAnalyzing for Traceability \b\n11.6\n3.5.\t\nAnalyzing for Interaction \b\n11-6\n4.\t Software Engineering Methods\b\n11-7\n4.1.\t\nHeuristic Methods \b\n11-7\n4.2.\t\nFormal Methods \b\n11-8\n4.3.\t\nPrototyping Methods \b\n11-9\n4.4.\t\nAgile Methods\b\n11-10\nMatrix of Topics vs. Reference Material\b\n11-11\nReferences\b\n11-12\nCHAPTER 12\nSoftware Quality\b\n12-1\nIntroduction\b\n12-1\n1.\t Software Quality Fundamentals\b\n12-3\n1.1.\t\nSoftware Engineering Culture and Ethics\b\n12-3\n1.2.\t\nValue and Costs of Quality\b\n12-4\n1.3.\t\nStandards, Models, and Certifications\b\n12-4\n1.4.\t\nSoftware Dependability and Integrity Levels\b\n12-5\n1.4.1\t Dependability\b\n12-5\n1.4.2. Integrity Levels of Software\b\n12-6\n", "page": 17, "type": "text", "section": "Page 17"}
{"text": "TABLE OF CONTENTS   xvii\n2.\t Software Quality Management Process\b\n12-6\n2.1.\t\nSoftware Quality Improvement \b\n12-7\n2.2.\t\nPlan Quality Management\b\n12-7\n2.3.\t\nEvaluate Quality Management\b\n12-8\n2.3.1\t Software Quality Measurement\b\n12-8\n2.4.\t\nPerform Corrective and Preventive Actions \b\n12-9\n2.4.1. Defect Characterization \b\n12-9\n3.\t Software Quality Assurance Process\b\n12-10\n3.1.\t\nPrepare for Quality Assurance \b\n12-10\n3.2.\t\nPerform Process Assurance \b\n12-10\n3.3.\t\nPerform Product Assurance\b\n12-11\n3.4.\t\nV&V and Testing\b\n12-12\n3.4.1\t Static Analysis Techniques\b\n12-13\n3.4.2. Dynamic Analysis Techniques\b\n12-13\n3.4.3. Formal Analysis Techniques\b\n12-13\n3.4.4. Software Quality Control and Testing\b\n12-13\n3.4.5. Technical Reviews and Audits\b\n12-14\n4.\t Software Quality Tools\b\n12-15\nMatrix of Topics vs. Reference Material\b\n12-15\nFurther Readings\b\n12-16\nReferences\b\n12-17\nCHAPTER 13\nSoftware Security\b\n13-1\nIntroduction\b\n13-1\n1.\t Software Security Fundamentals\b\n13-1\n1.1.\t\nSoftware Security\b\n13-1\n1.2.\t\nInformation Security\b\n13-1\n1.3.\t\nCybersecurity \b\n13-2\n2.\t Security Management and Organization \b\n13-2\n2.1.\t\nCapability Maturity Model \b\n13-2\n2.2.\t\nInformation Security Management System\b\n13-2\n2.3.\t\nAgile Practice for Software Security\b\n13-3\n3.\t Software Security Engineering and Processes\b\n13-3\n3.1.\t\nSecurity Engineering and Secure Development Life Cycle (SDLC) \b\n13-3\n3.2.\t\nCommon Criteria for Information Technology Security Evaluation \b\n13-3\n4.\t Security Engineering for Software Systems\b\n13-3\n4.1.\t\nSecurity Requirements \b\n13-3\n4.2.\t\nSecurity Design\b\n13-4\n4.3.\t\nSecurity Patterns\b\n13-4\n4.4.\t\nConstruction for Security \b\n13-4\n4.5.\t\nSecurity Testing \b\n13-5\n4.6.\t\nVulnerability Management \b\n13-5\n5.\t\nSoftware Security Tools\b\n13-5\n5.1.\t\nSecurity Vulnerability Checking Tools \b\n13-5\n5.2.\t\nPenetration Testing Tools\b\n13-6\n", "page": 18, "type": "text", "section": "Page 18"}
{"text": "xviii   SWEBOK \u00ae GUIDE V4.0\n6.\t Domain-Specific Software Security\b\n13-6\n6.1.\t\nSecurity for Container and Cloud\b\n13-6\n6.2.\t\nSecurity for IoT Software\b\n13-6\n6.3.\t\nSecurity for Machine Learning-Based Application\b\n13-6\nMatrix of Topics vs. Reference Material\b\n13-7\nFurther Readings\b\n13-8\nReferences\b\n13-8\nCHAPTER 14\nSoftware Engineering Professional Practice\b\n14-1\nIntroduction\b\n14-1\n1.\t Professionalism\b\n14-2\n1.1.\t\nAccreditation, Certification and Qualification, and Licensing\b\n14-2\n1.1.1. Accreditation\b\n14-2\n1.1.2. Certification and Qualification\b\n14-3\n1.1.3. Licensing\b\n14-3\n1.2.\t\nCodes\u2008of\u2008Ethics\u2008and\u2008Professional\u2008Conduct\b\n14-3\n1.3.\t\nNature\u2008and\u2008Role\u2008of\u2008Professional\u2008Societies\b\n14-4\n1.4.\t\nNature and Role of Software Engineering Standards \b\n14-4\n1.5.\t\nEconomic\u2008Impact\u2008of\u2008Software \b\n14-5\n1.6.\t\nEmployment\u2008Contracts \b\n14-5\n1.7.\t\nLegal Issues\b\n14-6\n1.7.1.\t Standards\b\n14-6\n1.7.2.\t Trademarks\b\n14-6\n1.7.3.\t Patents\b\n14-6\n1.7.4.\t Copyrights\b\n14-6\n1.7.5.\t Trade\u2008Secrets\b\n14-6\n1.7.6.\t Professional\u2008Liability\b\n14-7\n1.7.7.\t Legal\u2008Requirements\b\n14-7\n1.7.8.\t Trade\u2008Compliance\b\n14-7\n1.7.9.\t Cybercrime\b\n14-7\n1.7.10.\t\nData Privacy\b\n14-8\n1.8.\t\nDocumentation\b\n14-8\n1.9.\t\nTrade-Off\u2008Analysis\b\n14-9\n2.\t Group Dynamics and Psychology\b\n14-9\n2.1.\t\nDynamics\u2008of\u2008Working\u2008in\u2008Teams/Groups\u2008\b\n14-9\n2.2.\t\nIndividual\u2008Cognition\b\n14-10\n2.3.\t\nDealing\u2008with\u2008Problem\u2008Complexity\b\n14-10\n2.4.\t\nInteracting\u2008with\u2008Stakeholders\b\n14-10\n2.5.\t\nDealing\u2008with\u2008Uncertainty\u2008and\u2008Ambiguity\b\n14-11\n2.6.\t\nDealing\u2008with\u2008Equity, Diversity, and Inclusivity\b\n14-11\n3.\t Communication Skills\b\n14-11\n3.1.\t\nReading,\u2008Understanding, and\u2008Summarizing\b\n14-12\n3.2.\t\nWriting\b\n14-12\n3.3.\t\nTeam\u2008and\u2008Group\u2008Communication\b\n14-12\n3.4.\t\nPresentation\u2008Skills\b\n14-12\n", "page": 19, "type": "text", "section": "Page 19"}
{"text": "TABLE OF CONTENTS   xix\nMatrix of Topics vs. Reference Material\b\n14-13\nFurther Readings\b\n14-14\nReferences\b\n14-14\nCHAPTER 15\nSoftware Engineering Economics\b\n15-1\nIntroduction\b\n15-1\n1.\t Software Engineering Economics Fundamentals\b\n15-3\n1.1.\t\nProposals\b\n15-3\n1.2.\t\nCash Flow\b\n15-3\n1.3.\t\nTime-Value of Money\b\n15-3\n1.4.\t\nEquivalence\b\n15-4\n1.5.\t\nBases for Comparison\b\n15-4\n1.6.\t\nAlternatives\b\n15-4\n1.7.\t\nIntangible Assets\b\n15-4\n1.8.\t\nBusiness Model\b\n15-5\n2.\t The Engineering Decision-Making Process\b\n15-5\n2.1.\t\nProcess Overview\b\n15-5\n2.2.\t\nUnderstand the Real Problem\b\n15-5\n2.3.\t\nIdentify All Reasonable Technically Feasible Solutions\b\n15-6\n2.4.\t\nDefine the Selection Criteria\b\n15-6\n2.5.\t\nEvaluate Each Alternative Against the Selection Criteria\b\n15-6\n2.6.\t\nSelect the Preferred Alternative\b\n15-6\n2.7.\t\nMonitor the Performance of the Selected Alternative\b\n15-7\n3.\t For-Profit Decision-Making\b\n15-7\n3.1.\t\nMinimum Acceptable Rate of Return\b\n15-7\n3.2.\t\nEconomic Life\b\n15-7\n3.3.\t\nPlanning Horizon\b\n15-8\n3.4.\t\nReplacement Decisions\b\n15-8\n3.5.\t\nRetirement Decisions\b\n15-9\n3.6.\t\nAdvanced For-Profit Decision Considerations\b\n15-9\n4.\t Nonprofit Decision-Making\b\n15-9\n4.1.\t\nBenefit-Cost Analysis\b\n15-9\n4.2.\t\nCost-Effectiveness Analysis\b\n15-9\n5.\t\nPresent Economy Decision-Making\b\n15-9\n5.1.\t\nBreak-Even Analysis\b\n15-9\n5.2.\t\nOptimization Analysis\b\n15-9\n6.\t Multiple-Attribute Decision-Making\b\n15-10\n6.1.\t\nCompensatory Techniques\b\n15-10\n6.2.\t\nNon-Compensatory Techniques\b\n15-10\n7.\t\nIdentifying and Characterizing Intangible Assets\b\n15-10\n7.1.\t\nIdentify Processes and Define Business Goals\b\n15-10\n7.2.\t\nIdentify Intangible Assets Linked with Business Goal\b\n15-11\n7.3.\t\nIdentify Software Products That Support Intangible Assets\b\n15-11\n7.4.\t\nDefine and Measure Indicators\b\n15-11\n7.5.\t\nIntangible Asset Characterization\b\n15-11\n", "page": 20, "type": "text", "section": "Page 20"}
{"text": "xx   SWEBOK \u00ae GUIDE V4.0\n7.6.\t\nLink Specific Intangible Assets with the Business Model\b\n15-13\n7.7.\t\nDecision-Making\b\n15-13\n8.\t Estimation\b\n15-13\n8.1.\t\nExpert Judgment\b\n15-14\n8.2.\t\nAnalogy\b\n15-15\n8.3.\t\nDecomposition\b\n15-15\n8.4.\t\nParametric\b\n15-15\n8.5.\t\nMultiple Estimates\b\n15-15\n9.\t\nPractical Considerations\b\n15-16\n9.1.\t\nBusiness Case\b\n15-16\n9.2.\t\nMultiple-Currency Analysis \b\n15-16\n9.3.\t\nSystems Thinking\b\n15-16\n10.\t Related Concepts \b\n15-16\n10.1.\t Accounting\b\n15-16\n10.2.\t Cost and Costing\b\n15-16\n10.3.\t Finance\b\n15-17\n10.4.\t Controlling\b\n15-17\n10.5.\t Efficiency and Effectiveness\b\n15-17\n10.6.\t Productivity\b\n15-18\n10.7.\t Product or Service\b\n15-18\n10.8.\t Project\b\n15-18\n10.9.\t Program\b\n15-18\n10.10.\tPortfolio\b\n15-18\n10.11.\tProduct Life Cycle\b\n15-19\n10.12.\tProject Life Cycle\b\n15-19\n10.13.\tPrice and Pricing\b\n15-19\n10.14.\tPrioritization\b\n15-19\nMatrix of Topics vs. Reference Material\b\n15-20\nFurther Readings\b\n15-22\nReferences\b\n15-22\nCHAPTER 16\nComputing Foundations\b\n16-1\nIntroduction\b\n16-2\n1.\t Basic Concepts of a System or Solution\b\n16-2\n2.\t Computer Architecture and Organization\b\n16-3\n2.1.\t\nComputer Architecture\b\n16-3\n2.2.\t\nTypes of Computer Architectures\b\n16-3\n2.2.1.\tVon Neumann Architecture\b\n16-3\n2.2.2.\tHarvard Architecture\b\n16-4\n2.2.3.\tInstruction Set Architecture\b\n16-4\n2.2.4.\tFlynn\u2019s Architecture or Taxonomy\b\n16-5\n2.2.5.\tSystem Architecture\b\n16-5\n2.3.\t\nMicroarchitecture or Computer Organization\b\n16-5\n2.3.1.\tArithmetic Logic Unit \b\n16-5\n2.3.2.\tMemory Unit\b\n16-6\n", "page": 21, "type": "text", "section": "Page 21"}
{"text": "TABLE OF CONTENTS   xxi\n2.3.3.\tInput/Output Devices\b\n16-6\n2.3.4.\tControl Unit\b\n16-6\n3.\t Data Structures and Algorithms\b\n16-6\n3.1.\t\nTypes of Data Structures\b\n16-6\n3.2.\t\nOperations on Data Structures\b\n16-7\n3.3.\t\nAlgorithms and Attributes of Algorithms\b\n16-7\n3.4.\t\nAlgorithm Complexity\b\n16-8\n3.5.\t\nMeasurement of Complexity\b\n16-8\n3.6.\t\nDesigning Algorithms\b\n16-8\n3.7.\t\nSorting Techniques\b\n16-9\n3.8.\t\nSearching Techniques\b\n16-10\n3.9.\t\nHashing\b\n16-10\n4.\t Programming Fundamentals and Languages\b\n16-10\n4.1.\t\nProgramming Language Types\b\n16-10\n4.2.\t\nProgramming Syntax, Semantics, Type Systems\b\n16-11\n4.3.\t\nSubprograms and Coroutines\b\n16-11\n4.4.\t\nObject-Oriented Programming \b\n16-12\n4.5.\t\nDistributed Programming and Parallel Programming\b\n16-13\n4.6.\t\nDebugging\b\n16-13\n4.7.\t\nStandards and Guidelines\b\n16-13\n5.\t\nOperating Systems\b\n16-15\n5.1.\t\nProcessor Management\b\n16-15\n5.2.\t\nMemory Management\b\n16-16\n5.3.\t\nDevice Management\b\n16-16\n5.4.\t\nInformation Management\b\n16-16\n5.5.\t\nNetwork Management\b\n16-16\n6.\t Database Management\b\n16-17\n6.1.\t\nSchema\b\n16-17\n6.2.\t\nData Models and Storage Models\b\n16-17\n6.3.\t\nDatabase Management Systems \b\n16-18\n6.4.\t\nRelational Database Management Systems and Normalization\b\n16-18\n6.5.\t\nStructured Query Language \b\n16-19\n6.6.\t\nData Mining and Data Warehousing\b\n16-19\n6.7.\t\nDatabase Backup and Recovery\b\n16-20\n7.\t\nComputer Networks and Communications\b\n16-20\n7.1.\t\nTypes of Computer Networks\b\n16-20\n7.2.\t\nLayered Architectures of Networks\b\n16-21\n7.3.\t\nOpen Systems Interconnection Model\b\n16-21\n7.4.\t\nEncapsulation and Decapsulation\b\n16-22\n7.5.\t\nApplication Layer Protocols\b\n16-22\n7.6.\t\nDesign Techniques for Reliable and Efficient Network\b\n16-22\n7.7.\t\nInternet Protocol Suite\b\n16-23\n7.8.\t\nWireless and Mobile Networks\b\n16-23\n7.9.\t\nSecurity and Vulnerabilities\b\n16-23\n8.\t User and Developer Human Factors\b\n16-24\n8.1.\t\nUser Human Factors\b\n16-24\n8.2.\t\nDeveloper Human Factors\b\n16-24\n9.\t\nArtificial Intelligence and Machine Learning\b\n16-25\n", "page": 22, "type": "text", "section": "Page 22"}
{"text": "xxii   SWEBOK \u00ae GUIDE V4.0\n9.1.\t\nReasoning\b\n16-25\n9.2.\t\nLearning\b\n16-26\n9.3.\t\nModels\b\n16-26\n9.4.\t\nPerception and Problem-Solving\b\n16-27\n9.5.\t\nNatural Language Processing\b\n16-27\n9.6.\t\nAI and Software Engineering\b\n16-27\nMatrix of Topics vs. Reference Material\b\n16-28\nReferences\b\n16-32\nCHAPTER 17\nMathematical Foundations\b\n17-1\nIntroduction\b\n17-1\n1.\t Basic Logic\b\n17-1\n1.1.\t\nPropositional Logic\b\n17-1\n1.2.\t\nPredicate Logic\b\n17-3\n2.\t Proof Techniques\b\n17-3\n2.1.\t\nDirect Proof\b\n17-4\n2.2.\t\nProof by Contradiction\b\n17-4\n2.3.\t\nProof by Induction\b\n17-4\n2.4.\t\nProof by Example\b\n17-5\n3.\t Set, Relation, Function\b\n17-5\n3.1.\t\nSet Operations\b\n17-6\n3.2.\t\nProperties of Sets\b\n17-6\n3.3.\t\nRelation and Function\b\n17-7\n4.\t Graph and Tree\b\n17-8\n4.1.\t\nGraph\b\n17-8\n4.2.\t\nTree\b\n17-10\n5.\t\nFinite-State Machine\b\n17-12\n6.\t Grammar  \b\n17-13\n6.1.\t\nLanguage Recognition \b\n17-14\n7.\t\nNumber Theory  \b\n17-14\n7.1.\t\nTypes of Numbers\b\n17-15\n7.2.\t\nDivisibility\b\n17-15\n7.3.\t\nPrime Number\b\n17-15\n7.4.\t\nGreatest Common Divisor\b\n17-16\n8.\t Basics of Counting\b\n17-16\n9.\t\nDiscrete Probability\b\n17-17\n10.\t Numerical Precision, Accuracy, and Error\b\n17-18\n11.\t Algebraic Structures\b\n17-19\n11.1.\t Group\b\n17-19\n11.2.\t Ring\b\n17-20\n12.\t Engineering Calculus\b\n17-21\n13.\t New Advancements\b\n17-21\n13.1.\t Computational Neurosciences\b\n17-21\n13.2.\t Genomics\b\n17-21\nMatrix of Topics vs. Reference Material\b\n17-22\nReferences\b\n17-22\n", "page": 23, "type": "text", "section": "Page 23"}
{"text": "TABLE OF CONTENTS   xxiii\nCHAPTER 18\nEngineering Foundations\b\n18-1\nIntroduction\b\n18-1\n1.\t The Engineering Process\b\n18-1\n2.\t Engineering Design\b\n18-2\n2.1.\t\nEngineering Design in Engineering Education\b\n18-2\n2.2.\t\nDesign as a Problem-Solving Activity\b\n18-3\n3.\t Abstraction and Encapsulation\b\n18-3\n3.1.\t\nLevels of Abstraction \b\n18-4\n3.2.\t\nEncapsulation\b\n18-4\n3.3.\t\nHierarchy\b\n18-4\n3.4.\t\nAlternate Abstractions\b\n18-4\n4.\t Empirical Methods and Experimental Techniques \b\n18-4\n4.1.\t\nDesigned Experiment\b\n18-5\n4.2.\t\nObservational Study\b\n18-5\n4.3.\t\nRetrospective Study\b\n18-5\n5.\t\nStatistical Analysis \b\n18-5\n5.1.\t\nUnit of Analysis (Sampling Units), Population, and Sample\b\n18-5\n5.2.\t\nCorrelation and Regression\b\n18-8\n6.\t Modeling, Simulation, and Prototyping\b\n18-8\n6.1.\t\nModeling\b\n18-8\n6.2.\t\nSimulation \b\n18-9\n6.3.\t\nPrototyping\b\n18-9\n7.\t\nMeasurement\b\n18-10\n7.1.\t\nLevels (Scales) of Measurement\b\n18-10\n7.2.\t\nImplications of Measurement Theory for Programming Languages\b\n18-12\n7.3.\t\nDirect and Derived Measures\b\n18-13\n7.4.\t\nReliability and Validity\b\n18-14\n7.5.\t\nAssessing Reliability\b\n18-14\n7.6.\t\nGoal-Question-Metric Paradigm: Why Measure?\b\n18-15\n8.\t Standards\b\n18-15\n9.\t\nRoot Cause Analysis\b\n18-16\n9.1.\t\nRoot Cause Analysis Techniques\b\n18-16\n9.2.\t\nRoot Cause\u2013Based Improvement\b\n18-17\n10.\t Industry 4.0 and Software Engineering\b\n18-17\nMatrix of Topics vs. Reference Material\b\n18-18\nFurther Readings\b\n18-19\nReferences\b\n18-20\nAPPENDIX A\nKnowledge Area Description Specifications\b\nA-1\nIntroduction\b\nA-1\nThe Swebok Guide is a Foundational Document for the IEEE Computer Society  \nSuite of Software Engineering Products\b\nA-1\n", "page": 24, "type": "text", "section": "Page 24"}
{"text": "xxiv   SWEBOK \u00ae GUIDE V4.0\nBaseline and Change Control\b\nA-1\nCriteria and Requirements for the Breakdown of Topics Within a Knowledge Area\b\nA-2\nCriteria and Requirements for Describing Topics\b\nA-2\nCriteria and Requirements for Reference Material\b\nA-2\nCommon Structure\b\nA-4\nWhat Do We Mean by \u201cGenerally Recognized Knowledge\u201d?\b\nA-4\nLength of KA Description\b\nA-5\nImportant Related Documents\b\nA-5\nOther Detailed Guidelines\b\nA-6\nEditing \b\nA-6\nRelease of Copyright\b\nA-6\nReferences\b\nA-6\nAPPENDIX B\nIEEE and ISO/IEC Standards Supporting the Software \nEngineering Body of Knowledge (SWEBOK)\b\nB-1\n1.\t Overview\b\nB-1\n1.1.\t\nThe SWEBOK and standards\b\nB-1\n1.2.\t\nTypes of Standards\b\nB-2\n1.3.\t\nSources of Software Engineering Standards\b\nB-2\n2.\t The software engineering standards landscape\b\nB-3\n3.\t Life cycle process standards\b\nB-4\n4.\t Extensions and specialized applications of ISO/IEC/IEEE 12207\b\nB-5\n4.1.\t\nExplanations of concepts and several processes\b\nB-5\n4.2.\t\nMore specialized extensions\b\nB-8\n4.3.\t\nSoS standards\b\nB-9\n5.\t\nSingle Process Standards\b\nB-9\n6.\t Standards for product line, methods, and tools\b\nB-9\n7.\t\nProcess assessment standards\b\nB-10\n8.\t Professional Skills and Knowledge Standards\b\nB-11\n9.\t\nSelected Software Engineering Standards\b\nB-11\nAPPENDIX C\nConsolidated Reference List\b\nC-1\nConsolidated Reference List\b\nC-1\n", "page": 25, "type": "text", "section": "Page 25"}
{"text": "FOREWORD \nThe Guide to the Software Engineering Body of Knowledge (SWEBOK Guide), published by the \nIEEE Computer Society (IEEE CS), represents the current state of generally accepted, con-\nsensus-based knowledge emanating from the interplay between software engineering theory \nand practice. Its objectives include the provision of guidance for learners, researchers, and prac-\ntitioners to identify and share a common understanding of \u201cgenerally accepted knowledge\u201d in \nsoftware engineering, defining the boundary between software engineering and related disci-\nplines, and providing a foundation for certifications and educational curricula.\nThe origins of the Guide go back to the early 2000s. Much like the software engineering dis-\ncipline, the Guide has continued to evolve over the last 20 years to reflect society\u2019s industrial, \neducational, social, technical, and technological changes. Publication of the 2014 version of the \nGuide (SWEBOK Guide V3) was a significant milestone in establishing software engineering as \na recognized engineering discipline. \nThe goal of developing this update (SWEBOK Guide V4) to the Guide is to improve the \nGuide\u2019s currency, readability, consistency, and usability. The Guide consists of 18 knowledge \nareas (KAs) followed by several appendixes. A KA is an identified area of software engineering \ndefined by its knowledge requirements and described in terms of its component processes, prac-\ntices, inputs, outputs, tools, and techniques. Three appendixes provide, respectively, the speci-\nfications for the KA descriptions, an annotated set of relevant standards for each KA, and a list \nof references cited in the Guide. \nAll KAs have been updated to reflect changes in software engineering since the publication \nof Guide V3, including modern development practices, new techniques, and the advancement \nof standards. One significant change is that Agile and DevOps have been incorporated into \nalmost all KAs because these models have been widely accepted since the previous publication \nof the Guide. Agile models typically involve frequent demonstrations of working software to \na customer in short, iterative cycles. Agile practices exist across KAs. Furthermore, emerging \nplatforms and technologies, including artificial intelligence (AI), machine learning (ML), and \nthe internet of things (IoT), have been incorporated into the foundation KAs.\nTo reflect areas that are becoming particularly important in modern software engineering, \nthe following KAs have been added: the Software Architecture KA, Software Security KA, \nand Software Engineering Operations KA.\nThis Guide, written under the auspices of the Professional and Educational Activities Board \nof the IEEE Computer Society, represents the next step in the evolution of the software engi-\nneering profession.\nSteve McConnell\nChief Executive Officer, Construx Software\nHironori Washizaki\nPresident-Elect 2024, President 2025, IEEE Computer Society\n  xxv\n", "page": 26, "type": "text", "section": "Page 26"}
{"text": "xxvi   SWEBOK \u00ae GUIDE V4.0\nFOREWORD TO THE 2014 EDITION\nEvery profession is based on a body of knowledge, although that knowledge is not always \ndefined in a concise manner. In cases where no formality exists, the body of knowledge is \u201cgen-\nerally recognized\u201d by practitioners and may be codified in a variety of ways for a variety of dif-\nferent uses. But in many cases, a guide to a body of knowledge is formally documented, usually \nin a form that permits it to be used for such purposes as development and accreditation of aca-\ndemic and training programs, certification of specialists, or professional licensing. Generally, \na professional society or similar body maintains stewardship of the formal definition of a body \nof knowledge.\nDuring the past forty-five years, software engineering has evolved from a conference catch-\nphrase into an engineering profession, characterized by 1) a professional society, 2) standards \nthat specify generally accepted professional practices, 3) a code of ethics, 4) conference proceed-\nings, 5) textbooks, 6) curriculum guidelines and curricula, 7) accreditation criteria and accred-\nited degree programs, 8) certification and licensing, and 9) this Guide to the Body of Knowledge.\nIn this Guide\u2008to\u2008the\u2008Software\u2008Engineering\u2008Body\u2008of\u2008Knowledge, the IEEE Computer Society \npresents a revised and updated version of the body of knowledge formerly documented as \nSWEBOK 2004; this revised and updated version is denoted SWEBOK Guide V3. This work is \nin partial fulfillment of the Society\u2019s responsibility to promote the advancement of both theory \nand practice for the profession of software engineering.\nIt should be noted that this Guide does not present the entire body of knowledge for soft-\nware engineering but rather serves as a guide to the body of knowledge that has been devel-\noped over more than four decades. The software engineering body of knowledge is constantly \nevolving. Nevertheless, this Guide constitutes a valuable characterization of the software engi-\nneering profession.\nIn 1958, John Tukey, the world-renowned statistician, coined the term software. The term \nsoftware engineering was used in the title of a NATO conference held in Germany in 1968. The \nIEEE Computer Society first published its Transactions\u2008on\u2008Software\u2008Engineering in 1972, and \na committee for developing software engineering standards was established within the IEEE \nComputer Society in 1976.\nIn 1990, planning was begun for an international standard to provide an overall view of \nsoftware engineering. The standard was completed in 1995 with designation ISO/IEC 12207 \nand given the title of Standard\u2008for\u2008Software\u2008Life\u2008Cycle\u2008Processes. The IEEE version of 12207 \nwas published in 1996 and provided a major foundation for the body of knowledge captured \nin SWEBOK 2004. The current version of 12207 is designated as ISO/IEC 12207:2008 and \nIEEE 12207-2008; it provides the basis for this SWEBOK Guide V3. \nThis Guide\u2008to\u2008the\u2008Software\u2008Engineering\u2008Body\u2008of\u2008Knowledge is presented to you, the reader, as a \nmechanism for acquiring the knowledge you need in your lifelong career development as a soft-\nware engineering professional.\nDick Fairley, Chair \nSoftware\u2008and\u2008Systems\u2008Engineering\u2008Committee\nIEEE\u2008Computer\u2008Society\nDon Shafer, Vice President\nProfessional\u2008Activities\u2008Board IEEE\u2008Computer\u2008Society\n", "page": 27, "type": "text", "section": "Page 27"}
{"text": "FOREWORD TO THE 2004 EDITION\nIn this Guide, the IEEE Computer Society establishes for the first time a baseline for the body \nof knowledge for the field of software engineering, and the work partially fulfills the Society\u2019s \nresponsibility to promote the advancement of both theory and practice in this field. In so doing, \nthe Society has been guided by the experience of disciplines with longer histories but was not \nbound either by their problems or their solutions.\nIt should be noted that the Guide does not purport to define the body of knowledge but \nrather to serve as a compendium and guide to the body of knowledge that has been developing \nand evolving over the past four decades. Furthermore, this body of knowledge is not static. The \nGuide must, necessarily, develop and evolve as software engineering matures. It nevertheless \nconstitutes a valuable element of the software engineering infrastructure.\nIn 1958, John Tukey, the world-renowned statistician, coined the term software. The term \nsoftware\u2008engineering\u2008was used in the title of a NATO conference held in Germany in 1968. \nThe IEEE Computer Society first published its Transactions\u2008on\u2008Software\u2008Engineering\u2008in 1972. \nThe committee established within the IEEE Computer Society for developing software engi-\nneering standards was founded in 1976.\nThe first holistic view of software engineering to emerge from the IEEE Computer Society \nresulted from an effort led by Fletcher Buckley to develop IEEE standard 730 for software \nquality assurance, which was completed in 1979. The purpose of IEEE Std. 730 was to provide \nuniform, minimum acceptable requirements for preparation and content of software quality \nassurance plans. This standard was influential in completing the developing standards in the \nfollowing topics: configuration management, software testing, software requirements, software \ndesign, and software verification and validation.\nDuring the period 1981\u20131985, the IEEE Computer Society held a series of workshops con-\ncerning the application of software engineering standards. These workshops involved practi-\ntioners sharing their experiences with existing standards. The workshops also held sessions on \nplanning for future standards, including one involving measures and metrics for software engi-\nneering products and processes. The planning also resulted in IEEE Std. 1002, Taxonomy\u2008of\u2008\nSoftware\u2008Engineering\u2008Standards (1986), which provided a new, holistic view of software engi-\nneering. The standard describes the form and content of a software engineering standards tax-\nonomy. It explains the various types of software engineering standards, their functional and \nexternal relationships, and the role of various functions participating in the software life cycle.\nIn 1990, planning for an international standard with an overall view was begun. The plan-\nning focused on reconciling the software process views from IEEE Std. 1074 and the revised \nUS DoD standard 2167A. The revision was eventually published as DoD Std. 498. The inter-\nnational standard was completed in 1995 with designation, ISO/IEC 12207, and given the title \nof Standard\u2008for\u2008Software\u2008Life\u2008Cycle\u2008Processes. Std. ISO/ IEC 12207 provided a major point of \ndeparture for the body of knowledge captured in this book.\nIt was the IEEE Computer Society Board of Governors\u2019 approval of the motion put forward \nin May 1993 by Fletcher Buckley which resulted in the writing of this book. The Association \nfor Computing Machinery (ACM) Council approved a related motion in August 1993. The two \nmotions led to a joint committee under the leadership of Mario Barbacci and Stuart Zweben \nwho served as cochairs. The mission statement of the joint committee was \u201cTo establish the \nappropriate set(s) of criteria and norms for professional practice of software engineering upon \nwhich industrial decisions, professional certification, and educational curricula can be based.\u201d \nThe steering committee organized task forces in the following areas: \n  xxvii\n", "page": 28, "type": "text", "section": "Page 28"}
{"text": "xxviii   SWEBOK \u00ae GUIDE V4.0\n1.\t\nDefine Required Body of Knowledge and Recommended Practices.\n2.\t\nDefine Ethics and Professional Standards.\n3.\t\nDefine Educational Curricula for undergraduate, graduate, and continuing education.\nThis book supplies the first component: required body of knowledge and recommended \npractices.\nThe code of ethics and professional practice for software engineering was completed in 1998 \nand approved by both the ACM Council and the IEEE Computer Society Board of Governors. \nIt has been adopted by numerous corporations and other organizations and is included in sev-\neral recent textbooks.\nThe educational curriculum for undergraduates is being completed by a joint effort of the \nIEEE Computer Society and the ACM and is expected to be completed in 2004.\nEvery profession is based on a body of knowledge and recommended practices, although \nthey are not always defined in a precise manner. In many cases, these are formally documented, \nusually in a form that permits them to be used for such purposes as accreditation of academic \nprograms, development of education and training programs, certification of specialists, or pro-\nfessional licensing. Generally, a professional society or related body maintains custody of such \na formal definition. In cases where no such formality exists, the body of knowledge and recom-\nmended practices are \u201cgenerally recognized\u201d by practitioners and may be codified in a variety \nof ways for different uses.\nIt is hoped that readers will find this book useful in guiding them toward the knowledge and \nresources they need in their lifelong career development as software engineering professionals.\nThe book is dedicated to Fletcher Buckley in recognition of his commitment to promoting \nsoftware engineering as a professional discipline and his excellence as a software engineering \npractitioner in radar applications. \nLeonard L. Tripp, IEEE Fellow 2003\nChair,\u2008Professional\u2008Practices\u2008Committee,\u2008IEEE\u2008\nComputer\u2008Society\u2008(2001\u20132003)\nChair,\u2008Joint\u2008IEEE\u2008Computer\u2008Society\u2008and\u2008ACM\u2008\nSteering\u2008Committee\u2008for\u2008the\u2008Establishment\u2008of \nSoftware\u2008Engineering\u2008as\u2008a\u2008Profession\u2008(1998\u20131999)\nChair,\u2008Software\u2008Engineering\u2008Standards\u2008\u2008Committee,\u2008\nIEEE\u2008Computer\u2008Society\u2008(1992\u20131998)\n", "page": 29, "type": "text", "section": "Page 29"}
{"text": "EDITOR\nHironori Washizaki, Waseda University / National Institute of Informatics / eXmotion / \nUniversity of Human Environments, Japan, washizaki@waseda.jp\nKNOWLEDGE AREA EDITORS\nSoftware Requirements\nSteve Tockey, Construx Software, USA.\nSoftware Architecture\nRich Hilliard, USA.\nSoftware Design\nRich Hilliard, USA.\nSoftware Construction\nXin Peng, Software School, Fudan University, China.\nSteve Schwarm, Synopsys - Black Duck Software, USA.\nSoftware Testing\nEda Marchetti, ISTI-CNR, Italy.\nSaid Daoudagh, ISTI-CNR, Italy.\nSoftware Engineering Operations\nFrancis Bordeleau, \u00c9cole de technologie sup\u00e9rieure (\u00c9TS), Canada.\nAlain April, \u00c9cole de technologie sup\u00e9rieure (\u00c9TS), Canada.\nSoftware Maintenance\nAli Ouni, \u00c9cole de technologie sup\u00e9rieure (\u00c9TS), Canada\nAlain April, \u00c9cole de technologie sup\u00e9rieure (\u00c9TS), Canada\nPeter Leather, Exceptional Performance, UK.\nSoftware Configuration Management\nMaria Isabel S\u00e1nchez Segura, Universidad Carlos III de Madrid, Spain. \nBob Aiello, CM Best Practices, USA.\nSoftware Engineering Management\nKenneth E. Nidiffer, George Mason University, USA.\nSoftware Engineering Process\nJuan Garbajosa, Universidad Polit\u00e9cnica de Madrid, Spain.\nSoftware Engineering Models and Methods\nHironori Washizaki, Waseda University, Japan.\nAkinori Ihara, Wakayama University, Japan.\nShinpei Ogata, Shinshu University, Japan.\n  xxix\n", "page": 30, "type": "text", "section": "Page 30"}
{"text": "xxx   SWEBOK \u00ae GUIDE V4.0\nSoftware Quality\nAlain April, \u00c9cole de technologie sup\u00e9rieure (\u00c9TS), Canada.\nSteve Tockey, Construx Software, USA. \nSteve Schwarm, Synopsys - Black Duck Software, USA.\nSoftware Security\nNobukazu Yoshioka, Waseda University, Japan.\nSeiji Munetoh, IBM Research, Japan.\nSoftware Engineering Professional Practice\nKatsuhisa Shintani, Waseda University, Japan.\nEiji Hayashiguchi, Waseda University, Japan.\nSoftware Engineering Economics\nMaria Isabel S\u00e1nchez Segura, Universidad Carlos III de Madrid, Spain.\nSteve Tockey, Construx Software, USA.\nComputing Foundations\nYatheendranath TJ, DhiiHii Labs Private Limited, India.\nMathematical Foundations\nYatheendranath TJ, DhiiHii Labs Private Limited, India.\nSteve Tockey, Construx Software, USA.\nEngineering Foundations\nYatheendranath TJ, DhiiHii Labs Private Limited, India.\nSteve Tockey, Construx Software, USA.\nAppendix A: Knowledge Area Description Specifications\nJuan Garbajosa, Universidad Polit\u00e9cnica de Madrid, Spain. \nHironori Washizaki, Waseda University, Japan.\nAppendix B: IEEE and ISO/IEC Standards Supporting SWEBOK\nAnnette Reilly, USA.\nAppendix C: Consolidated Reference List\nHironori Washizaki, Waseda University, Japan.\nCONTRIBUTING EDITORS\nThe following persons contributed to editing the SWEBOK Guide V4:\nMichelle Phon\nEric Berkowitz\n", "page": 31, "type": "text", "section": "Page 31"}
{"text": "STEERING GROUP\nThe following experts served on the SWEBOK Guide V4 Steering Group that guided the initial \narchitecture of the Guide at the beginning of the project:\nHironori Washizaki\nYatheendranath TJ\nRich Hilliard\nKenneth Nidiffer\nPete Brink\nV.S. Mani\nHari Prasad Devarapalli\nAnnette Reilly\nNarendra S Chowdhury\nDharanipragada Janakiram\nJuan Garbajosa\nMaria Isabel S\u00e1nchez Segura\nPeter Leather\nAndy Chen\nSteve Schwarm\nKNOWLEDGE AREA EDITORS OF PREVIOUS SWEBOK VERSIONS\nThe following persons served as Knowledge Area Editors for either the Trial version published \nin 2001, the 2004 version, and/or the 2014 version (SWEBOK V3). The affiliations listed are as \nthey belonged to when each person served as a knowledge area editor.\nSoftware Requirements\nPeter Sawyer, Computing Department, Lancaster University, UK\nGerald Kotonya, Computing Department, Lancaster University, UK\nSoftware Design\nGuy Tremblay, D\u00e9partement d\u2019informatique, UQAM, Canada\nYanchun Sun, School of Electronics Engineering and Computer Science, Peking University, China\nSoftware Construction\nSteve McConnell, Construx Software, USA\nTerry Bollinger, the MITRE Corporation, USA\nPhilippe Gabrini, D\u00e9partement d\u2019informatique, UQAM, Canada\nLouis Martin, D\u00e9partement d\u2019informatique, UQAM, Canada\nXin Peng, Software School, Fudan University, China\nSoftware Testing\nAntonia Bertolino, ISTI-CNR, Italy\nEda Marchetti, ISTI-CNR, Italy\nSoftware Maintenance\nThomas M. Pigoski, Techsoft Inc., USA\nAlain April, \u00c9cole de technologie sup\u00e9rieure, Canada\nMira Kajko-Mattsson, School of Information and Communication Technology,  KTH Royal \nInstitute of Technology\nSoftware Configuration Management\nJohn A. Scott, Lawrence Livermore National Laboratory, USA David Nisse, USA\nRoger Champagne, \u00c9cole de technologie sup\u00e9rieure (\u00c9TS), Canada\nAlain April, \u00c9cole de technologie sup\u00e9rieure (\u00c9TS), Canada\n  xxxi\n", "page": 32, "type": "text", "section": "Page 32"}
{"text": "xxxii   SWEBOK \u00ae GUIDE V4.0\nSoftware Engineering Management\nDennis Frailey, Raytheon Company, USA\nStephen G. MacDonell, Auckland University of Technology, New Zealand\nAndrew R. Gray, University of Otago, New Zealand \nJames McDonald, Department of Computer Science and Software Engineering, Monmouth \nUniversity, USA\nSoftware Engineering Process\nKhaled El Emam, served while at the Canadian National Research Council, Canada\nAnnette Reilly, Lockheed Martin Information Systems & Global Solutions, USA\nRichard E. Fairley, Software and Systems Engineering Associates (S2EA), USA\nSoftware Engineering Tools and Methods\nDavid Carrington, School of Information Technology and Electrical Engineering,  \nThe University of Queensland, Australia\nMichael F. Siok, Lockheed Martin Aeronautics Company, USA\nSoftware Quality\nAlain April, \u00c9cole de technologie sup\u00e9rieure, Canada\nDolores Wallace, retired from the National Institute of Standards and Technology, USA \nLarry Reeker, NIST, USA\nJ. David Blaine, USA\nDurba Biswas, Tata Consultancy Services, India\nSoftware Engineering Professional Practice\nAura Sheffield, USA\nHengming Zou, Shanghai Jiao Tong University, China\nSoftware Engineering Economics\nChristof Ebert, Vector Consulting Services, Germany\nComputing Foundations\nHengming Zou, Shanghai Jiao Tong University, China\nMathematical Foundations\nNabendu Chaki, University of Calcutta, India\nEngineering Foundations\nAmitava Bandyopadhayay, Indian Statistical Institute, India \nMary Jane Willshire, Software and Systems Engineering Associates (S2EA), USA\nAppendix B: IEEE and ISO/IEC Standards Supporting SWEBOK \nJames W. Moore, USA\nReferences Editor\nMarc Bouisset, D\u00e9partement d\u2019informatique, UQAM\u2003\n", "page": 33, "type": "text", "section": "Page 33"}
{"text": "REVIEW TEAM\nThe people listed below participated in the public review process of SWEBOK Guide V4. \nMembership of the IEEE Computer Society was not a requirement to participate in this review \nprocess, and membership information was not requested from reviewers. Over 1300 individual \ncomments were collected and duly adjudicated.\nAakashjit Bhattacharya\nAdil Aliyev\nAlaa Mahjoub\nAlberto C\u00f3rdoba Izaguirre\nAng Boon Chong\nAntonio Navarro\nArjun Remadevi Somanathan\nAtilla Elci\nBeatri Beltr\u00e1n Mart\u00ednez\nBiswaranjan Senapati\nBrandon Thorin Klein\nBrian Kirkpatrick\nCarol Woody\nChandraSR K\nChristof Ebert\nClaude Laporte\nClive Boughton\nDale Dzielski\nDaniel Medeiros Rocha\nDavid Budgen\nDavid Mack Endres\nDmytro Lenda\nDuncan Hall\nEd Zuk\nEka Arriyanti\nElena Williams\nEmmanuelle Wintergerst\nErnesto Cuadros-Vargas\nFabr\u00edcio Laguna\nFabricio Lantieri\nFedor Dzerzhinskiy\nFernando Pinciroli\nFrancisco Vald\u00e9s-Souto\nGabriel Tamura\nGavin Howard\nGopal T V\nGraham Lee\nHector Teran\nHelmut Neukirchen\nHernan Guarda\nHiroyuki Sato\nHossein Saiedian\nIan Hirst\nIrina Marudina\nJack McKenzie\nJack Pope\nJames C Davis\nJames Purtilo\nJason Adcock\nJavier Gonzalez Huerta\nJoanna Isabelle Olszewska\nJoanna Leng\nJoao Marcelo Borovina Josko\nJon D Hagar\nJonathan Oliver\nJoshua Cook\nJuris Borzovs\nKarol Szkudlarek\nKiyoshi Endo\nKiyoshi Honda\nKonstantinos Domdouzis\nKun Hsiang Wu\nLolita Narag\nMagesh Kasthuri\nMaher Ben Abdessalem\nManu Mitra\nMarc Blumberg\nMarcia Ito\nMaria-Isabel Sanchez-Segura\nMartin Kropp\nMasahiko Ishikawa\nMatteo Gro\u00dfe-Kampmann\nMicheal Tuape\nMirna Mu\u00f1oz\nMohammad Samarah\nMuthu Ramachandran\nMyneni Madhu Bala\nNancy Mead\nNandakumar Ramanathan\nNauman Ahmad\nNenad Medvidovi\u0107\nNicolae Giurescu\nNorha Villegas\nOmar\nOscar A. Schivo\nPankaj Kamthan\nPaola Britos\nPeter Schoo\nPhillip A. Laplante\nPieter Botman\nPiotr Karocki\nPrashant Verma\nQusay F. Hassan\nRadoslav Rakovic\nRavindra Joshi\nRen-Her Hwang\nRobert Lemay\nRodrigo Martins Pagliares\nRupesh Sreeraman\nSamuel J. Crawford\nSaurabh Kumar\nShailendra Suryawanshi\nShelly Sachdeva\nSheydi Anel Zamudio L\u00f3pez\nSravan Kumar Reddy \nKamidi Raja\nStefan Malich\nStefano Pietroiusti\n  xxxiii\n", "page": 34, "type": "text", "section": "Page 34"}
{"text": "xxxiv   SWEBOK \u00ae GUIDE V4.0\nSteffen Becker\nSteve France\nSudheer Kumar \nReddy Gowrigari\nSusanne M\u00fcller\nSushil Birla\nSyed Mohamed Thameem \nNizamudeen\nT V Gopal\nTakehisa Okazaki\nTarig Ahmed Khalid\nTateki Sano\nTetsu Nagata\nThomas M. Prinz\nTim Bond\nTrent Leopold\nTyler Thomas Procko\nVivek Dave\nVivienne Bi\u010dak\nWalter Green\nWeihan Goh\nWeijia Yang\nWilliam Uemura\nYarlagadda Padma Sai\nYasuko Okazaki\nYuseon Yu\nZheng Wang\nACKNOWLEDGEMENTS \nFunding for the development of SWEBOK Guide V4 has been provided by the IEEE Computer \nSociety. The editors and coeditors appreciate the important work performed by the KA editors \nand the contributing editors, as well as by the members of the Steering Group. The editorial \nteam must also acknowledge the indispensable contribution of reviewers. \nFinally, there are surely other people who have contributed to this Guide, either directly or \nindirectly, whose names we have inadvertently omitted. To those people, we offer our tacit \nappreciation and apologize for having omitted explicit recognition. \nIEEE COMPUTER SOCIETY PRESIDENTS\nLeila De Floriani, 2020 President\nForrest Shull, 2021 President\nWilliam \u201cBill\u201d Gropp, 2022 President\nNita Patel, 2023 President\nJyotika Athavale, 2024 President\nHironori Washizaki, 2025 President\nPROFESSIONAL AND EDUCATIONAL ACTIVITIES BOARD,  \n2024 MEMBERSHIP\nCyril Onwubiko, Chair\nDeborah Silver\nHironori Washizaki\nRajendra Raj\nErnesto Cuadros-Vargas\nSao-Jie Chen\nAkinori Ihara\nKiyoshi Honda\nAndrew Seely\nMegha Ben\nKwabena Boateng\nEric Berkowitz\nMichelle Phon\n", "page": 35, "type": "text", "section": "Page 35"}
{"text": "TABLE OF CONTENTS   xxxv\nMOTIONS REGARDING THE APPROVAL OF SWEBOK GUIDE V4.0\nThe following motion was unanimously adopted by the Professional and Educational \nActivities Board of the IEEE Computer Society in September 2024: \nThe Professional Activities Board of the IEEE Computer Society finds that the Guide to the Software \nEngineering Body of Knowledge Version 4.0 has been successfully completed; and endorses the Guide \nto the Software Engineering Body of Knowledge Version 4.0 and commends it to the IEEE Computer \nSociety Board of Governors for their approval.\nThe following motion was adopted by the IEEE Computer Society Board of Governors in \nOctober 2024:\nMOVED, that the Board of Governors of the IEEE Computer Society approves Version 4.0 of the \nGuide to the Software Engineering Body of Knowledge and authorizes the Chair of the Professional \nActivities Board to proceed with printing.\nMOTIONS REGARDING THE APPROVAL OF SWEBOK GUIDE V3.0\nThe SWEBOK Guide V3.0 was submitted to ballot by verified IEEE Computer Society mem-\nbers in November 2013 with the following question: \u201cDo you approve this manuscript of the \nSWEBOK Guide V3.0 to move forward to formatting and publication?\u201d The results of this \nballot were 259 Yes votes and 5 No votes.\nThe following motion was unanimously adopted by the Professional Activities Board of the \nIEEE Computer Society in December 2013: \nThe Professional Activities Board of the IEEE Computer Society finds that the Guide to the Software \nEngineering Body of Knowledge Version 3.0 has been successfully completed; and endorses the Guide \nto the Software Engineering Body of Knowledge Version 3.0 and commends it to the IEEE Computer \nSociety Board of Governors for their approval.\nThe following motion was adopted by the IEEE Computer Society Board of Governors in \nDecember 2013:\nMOVED, that the Board of Governors of the IEEE Computer Society approves Version 3.0 of the \nGuide to the Software Engineering Body of Knowledge and authorizes the Chair of the Professional \nActivities Board to proceed with printing.\nPlease also note that The SWEBOK Guide V3.0 was submitted by the IEEE Computer Society to \nISO/IEC without any change and was recognized as Technical Report ISO/IEC TR 19759:2015.\n", "page": 36, "type": "text", "section": "Page 36"}
{"text": "xxxvi   SWEBOK \u00ae GUIDE V4.0\nMOTIONS REGARDING THE APPROVAL OF SWEBOK GUIDE 2004 VERSION\nThe following motion was unanimously adopted by the Industrial Advisory Board of the \nSWEBOK Guide project in February 2004:\nThe Industrial Advisory Board finds that the Software Engineering Body of Knowledge project \ninitiated in 1998 has been successfully completed; and endorses the 2004 Version of the Guide to the \nSWEBOK and commends it to the IEEE Computer Society Board of Governors for their approval.\nThe following motion was adopted by the IEEE Computer Society Board of Governors in \nFebruary 2004:\nMOVED, that the Board of Governors of the IEEE Computer Society approves the 2004 Edition \nof the Guide to the Software Engineering Body of Knowledge and authorizes the Chair of the \nProfessional Practices Committee to proceed with printing.\nPlease also note that the 2004 edition of the Guide to the Software Engineering Body of Knowledge \nwas submitted by the IEEE Computer Society to ISO/IEC without any change and was recog-\nnized as Technical Report ISO/IEC TR 19759:2005.\n", "page": 37, "type": "text", "section": "Page 37"}
{"text": "xxxvii \nIntroduction to the Guide\nACRONYMS\nKA\nKnowledge Area\nSWEBOK\nSoftware Engineering Body \nof Knowledge\nPublication of the 2014 version of the Guide \nto the Software Engineering Body of Knowledge \n(SWEBOK Guide V3) was a major milestone in \nestablishing software engineering as a recog-\nnized engineering discipline. The goal of devel-\noping this update (Version 4) to the SWEBOK \nGuide is to improve the Guide\u2019s currency, read-\nability, consistency and usability. The content \nof the Guide consists of 18 knowledge areas \n(KAs) followed by several appendixes. A KA is \nan identified area of software engineering and \nis described in terms of its generally accepted \nknowledge, such as its component processes, \npractices, inputs, outputs, tools and tech-\nniques. Three appendixes provide, respectively, \nthe specifications for the KA descriptions, an \nannotated set of relevant standards for each \nKA, and a list of references cited in the Guide. \nAll KAs have been updated to reflect \nchanges in software engineering since the \npublication of the Guide V3, including modern \ndevelopment practices, new techniques, and \nthe advancement of standards. One signifi-\ncant change is that Agile and DevOps have \nbeen incorporated into almost all KAs because \nthese models have been widely accepted since \nthe previous publication of the Guide. Agile \nmodels typically involve frequent demonstra-\ntions of working software to a customer in \nshort, iterative cycles. Agile practices exist \nacross KAs. Furthermore, emerging plat-\nforms and technologies, including artificial \n1\t\n http://pascal.computer.org/sev_display/index.action.\nintelligence (AI), machine learning (ML) and \nthe internet of things (IoT), have been incor-\nporated into the foundation KAs.\nTo reflect areas that are becoming partic-\nularly important in modern software engi-\nneering, the following KAs have been added: \nthe Software Architecture KA, Software \nSecurity KA and Software Engineering \nOperations KA.\nThis Guide, written under the auspices of \nthe Professional and Educational Activities \nBoard of the IEEE Computer Society, rep-\nresents a next step in the evolution of the soft-\nware engineering profession.\n1.\t What Is Software Engineering?\nISO/IEC/IEEE Systems and Software \nEngineering \nVocabulary \n(SEVOCAB)1 \ndefines software as \u201ccomputer programs, pro-\ncedures and possibly associated documenta-\ntion and data pertaining to the operation of a \ncomputer system\u201d.1 And software engineering \nis defined as \u201cthe application of a systematic, \ndisciplined, quantifiable approach to the devel-\nopment, operation, and maintenance of soft-\nware; that is, the application of engineering \nto software\u201d [1]. Historically, software engi-\nneering has been defined in various ways, \nsuch as \u201cthe practical application of scientific \nknowledge to the design and construction of \ncomputer programs and the associated docu-\nmentation required to develop, operate, and \nmaintain them\u201d [2] and \u201cthe technological and \nmanagerial discipline concerned with system-\natic production and maintenance of software \nproducts that are developed and modified on \ntime and within cost estimates\u201d [3]. Although \n", "page": 38, "type": "text", "section": "Page 38"}
{"text": "xxxviii   SWEBOK \u00ae GUIDE V4.0\nthese definitions differ in detail, they have an \nessential commonality in that they both deal \nwith software development and maintenance. \nFurthermore, the application of scientific \nknowledge (mentioned in the first definition) \ncan be described as a technological discipline \n(a phrase used in the second definition). As \n\u201cscientific\u201d implies a systematic and quan-\ntifiable approach, the initial definition also \nexpresses an idea common in past definitions \nof the discipline.\nSoftware engineering occupies a position \nbetween the mathematical and physical disci-\nplines of computer science and technology on \nthe one hand and the work of applying those \nfindings to solve the problems of particular \napplication domains on the other [3]. Science \nis about discovering new things. On the other \nhand, engineering is about applying that \nknowledge to solve real-world problems with \nlimited resources cost-effectively. As such, \nthe engineering discipline of a given scientific \nfield requires skills and knowledge about rel-\nevant \u201cpractice.\u201d Further, as engineering con-\ncerns cost-effective solutions to real-world \nproblems, all engineering disciplines involve \nengineering economics, which is the analysis \nof theoretically possible solutions to identify \nthe most cost-effective one. In essence, this \nGuide distills the relevant theory of computer \nscience and engineering into the three foun-\ndation KAs, while the remaining KAs cat-\nalog the practice and engineering economics \nof software engineering.\nSoftware engineering techniques can be \nviewed as specializations of techniques of more \ngeneral disciplines, such as project manage-\nment, systems engineering and quality man-\nagement [3]. Furthermore, a software project \nmust implement requirements imposed by \ncross-cutting disciplines such as dependability \nand safety. Software engineering and com-\nputer science are related but distinct in the \nsame way chemical engineering and chemistry \nare related but distinct. Scientific disciplines, \nsuch as computer science and chemistry, aim to \nextend human knowledge. Effective require-\nments elicitation techniques, design princi-\nples like cohesion and coupling, appropriate \nbranch-merge strategies, conducting a proper \npeer review, and assessing the cost of quality \nare a few examples of critical software engi-\nneering practices that are of little or no concern \nto computer science. In engineering, science \nand practice are applied to generate poten-\ntial solutions to the real-world problem, and \nengineering economics is used to identify the \nmost cost-effective one. In the same way that \nit would not make sense to send a chemist to \nsolve a chemical engineering problem, it does \nnot make sense to send a computer scientist to \nsolve a software engineering problem.\nIn addition to computer science, software \nengineering is related to several other disci-\nplines and professional areas, such as indus-\ntrial engineering, dependability engineering, \nand safety and security engineering.\u00a0\n2.\t What Are the Objectives of the  \nSWEBOK Guide?\nThe Guide should not be confused with the \nbody of knowledge itself, which exists in the \npublished literature. The Guide\u2019s purpose is \nto describe the generally accepted portion of \nthe body of knowledge, organize that portion, \nand provide topical access to it. \nThe SWEBOK Guide was established with \nthe following five objectives:\n1.\t To promote a consistent view of software \nengineering worldwide\n2.\t To specify the scope and clarify the place \nof software engineering with respect to \nother disciplines, such as computer sci-\nence, project management, computer \nengineering and mathematics\n3.\t To characterize the contents of the soft-\nware engineering discipline\n4.\t To provide topical access to the Software \nEngineering Body of Knowledge\n5.\t\nTo provide a foundation for curriculum \ndevelopment and for individual certifica-\ntion and licensing materials\nThe first objective, to promote a consis-\ntent worldwide view of software engineering, \nwas supported by a development process that \n", "page": 39, "type": "text", "section": "Page 39"}
{"text": "INTRODUCTION TO THE GUIDE   xxxix\nengaged about 130+ reviewers from various \ncountries. More information regarding the \ndevelopment process can be found at www.\nswebok.org. Professional and learned soci-\neties and public agencies involved in soft-\nware engineering were contacted, made \naware of this project to update the SWEBOK \nGuide, and invited to participate in the review \nprocess. Associate editors were recruited \nfrom America, Asia, Europe, and Oceania. \nPresentations on the project were made at var-\nious international venues.\nThe second objective, to specify the scope \nof software engineering, underlies the fun-\ndamental organization of the Guide. Material \nthat falls within this discipline is organized \ninto the 18 KAs listed in Table I.1. Each KA \nis treated as a chapter in this Guide. Among \nthem, Chapters 1-15 are regarded as the soft-\nware engineering KAs, while Chapters 16-18 \naddress foundation KAs.\nTABLE I.1. THE 18 SWEBOK KAS\n1.\t Software Requirements\n2.\t Software Architecture\n3.\t Software Design\n4.\t Software Construction\n5.\t Software Testing\n6.\t Software Engineering Operations\n7.\t Software Maintenance\n8.\t Software Configuration Management\n9.\t Software Engineering Management\n10.\t Software Engineering Process\n11.\t Software Engineering Models \nand Methods\n12.\tSoftware Quality\n13.\t Software Security\n14.\t Software Engineering \nProfessional Practice\n15.\t Software Engineering Economics\n16.\t Computing Foundations \n17.\t Mathematical Foundations\n18.\t Engineering Foundations\nIn specifying the scope of the discipline, \nit is also important to identify disciplines \nthat intersect with software engineering. To \nthis end, the SWEBOK V4 Guide continues \nto recognize eleven related disciplines, listed \nin Table I.2. Software engineers should, of \ncourse, be knowledgeable about these dis-\nciplines (and KA descriptions in this Guide \nmight refer to them). However, characterizing \nthe knowledge of related disciplines is not an \nobjective of the SWEBOK Guide.\nTABLE I.2. RELATED DISCIPLINES\nBusiness Analysis\nComputer Engineering\nComputer Science\nCybersecurity \nData Science\nGeneral Management\nInformation Systems and Technology\nMathematics\nProject Management\nQuality Management\nSystems Engineering\nThe relevant elements of computer science, \nmathematics, and engineering foundations \nare presented in the Computing Foundations \nKA,  Mathematical Foundations KA, and \nEngineering Foundations KA of the Guide \n(Chapters 16, 17 and 18).\nHIERARCHICAL ORGANIZATION\nThe organization of the KA chapters supports \nthe third project objective \u2014 to characterize \nthe contents of software engineering. The \ndetailed specifications provided by the proj-\nect\u2019s editorial team to the associate editors \nregarding the contents of the KA descriptions \ncan be found in Appendix A.\nThe Guide uses a hierarchical organiza-\ntional structure to decompose each KA into \na set of topics with recognizable labels. Each \n", "page": 40, "type": "text", "section": "Page 40"}
{"text": "xl   SWEBOK \u00ae GUIDE V4.0\nKA provides a two- or three-level break-\ndown, which provides a reasonable way to \nfind topics of interest. The Guide treats the \nselected topics in a way that is compatible \nwith major schools of thought and sepa-\nrates the topics into subtopics that are gen-\nerally found in industry and in software \nengineering literature and standards. The \nbreakdowns are not designed for particular \napplication domains, business uses, manage-\nment philosophies, development methods and \nso forth. Each topic description is meant only \nto give the reader a general understanding \nof the topic and to enable the reader to find \nreference material. The body of knowledge \nis found in the reference materials, not in \nthe Guide.\nSoftware plays a core role in various appli-\ncation and technological domains, such as \nautomotive, legal, health care, and finance. \nDifferences in application domains and busi-\nness models (e.g., custom applications, and \nopen source applications) and system types \n(e.g., enterprise and cloud systems, embedded \nand IoT systems, and AI/ML-based sys-\ntems) may influence what practices are \nadopted. Major special techniques and prac-\ntices specific to certain system types are \nalso discussed in some KAs, especially the \nSoftware Requirements KA, the Software \nTesting KA, the Software Quality KA, the \nSoftware Security KA and the Computing \nFoundations KA.\nREFERENCE MATERIAL AND \nMATRIX\nTo provide topical access to the knowledge \n\u2014 the fourth project objective \u2014 the Guide \nidentifies authoritative reference material for \neach KA. In addition, Appendix C provides \na Consolidated Reference List for the entire \nGuide. Each KA includes relevant references \nfrom the Consolidated Reference List as well \nas a matrix connecting the reference materials \nto the topics covered. \n2\t\nA Guide to the Project Management Body of Knowledge, 7th ed., Project Management Institute, 2021, www.pmi.org. \nPlease note that the Guide does not attempt \nto be comprehensive in its citations. Much \nsuitable and excellent material is not refer-\nenced. However, the material included in the \nConsolidated Reference List provides further \ninformation about the topics described.\nDEPTH OF TREATMENT\nTo achieve the Guide\u2019s fifth objective \u2014 to \nprovide a foundation for curriculum devel-\nopment, certification and licensing \u2014 the \ncriterion of generally accepted knowledge has \nbeen applied. This is distinct from advanced \nand research knowledge (on the grounds of \nmaturity) and from specialized knowledge \n(on the grounds of generality of applica-\ntion). The equivalent term generally recog-\nnized comes from the Project Management \nInstitute:2 \n\u201cGenerally recognized means the knowl-\nedge and practices described are applicable to \nmost projects most of the time, and there is \nconsensus about their value and usefulness.\u201d\nHowever, the terms generally accepted and \ngenerally recognized do not imply that the desig-\nnated knowledge should be uniformly applied \nto all software engineering endeavors \u2014 each \nproject\u2019s needs determine what knowledge to \napply, and how. However, competent, capable \nsoftware engineers should be equipped with \nthis knowledge for potential application. \nTherefore, appropriate selection of generally \naccepted knowledge should be included in the \nstudy material for the software engineering \nprofessional certification and licensing exam-\ninations that graduates take after gaining four \nyears of work experience.  \nSTRUCTURE OF THE KA \nDESCRIPTIONS\nEach chapter provides a description of one of \nthe KAs. These descriptions are structured \nas follows. \n", "page": 41, "type": "text", "section": "Page 41"}
{"text": "INTRODUCTION TO THE GUIDE   xli\nThe introduction briefly defines the KA \nand presents an overview of its scope and its \nrelationship with other KAs.\nThe breakdown of topics in each KA consti-\ntutes the core of the KA description, showing \nthe decomposition of the KA into subareas, \ntopics and subtopics. For each topic or sub-\ntopic, a short description is given, along with \none or more references. \nThese reference materials were selected as \nthe best available presentation of knowledge \nrelated to the topic. A matrix links the topics \nto the reference materials. \nThe last part of each KA description is the \nlist of recommended references and suggested \nfurther reading. Relevant standards for each \nKA are presented in Appendix B of the Guide.\nAPPENDIX A. KA DESCRIPTION \nSPECIFICATIONS\nAppendix A describes the specifications \nprovided by the editorial team to the asso-\nciate editors for the content, recommended \nreferences, format and style of the KA \ndescriptions.\nAPPENDIX B. IEEE AND ISO/IEC \nSTANDARDS\nAppendix B presents an annotated list of the \nrelevant standards, mostly from the IEEE \nand the ISO, for each of the SWEBOK \nGuide\u2019s KAs.\nAPPENDIX C. CONSOLIDATED \nREFERENCE LIST\nAppendix C contains the consolidated list of \nrecommended references cited in the KAs. \nThese references are marked with an asterisk\n(*) in the text. \nREFERENCES\n[1] \t ISO/IEC/IEEE, \u201cISO/IEC/IEEE \n24765:2017 Systems and Software \nEngineering \u2014 Vocabulary,\u201d \n2nd ed. 2017.\n[2]\t Barry W. Boehm, \u201cSoftware \nEngineering,\u201d IEEE Transactions on \nComputers, Vol. C-25, No. 12, 1976.\n[3] \t James W. Moore, \u201cSoftware \nEngineering Standards: A User\u2019s Road \nMap,\u201d IEEE Computer Society, 1998.\n", "page": 42, "type": "text", "section": "Page 42"}
{"text": "1-1 \nCHAPTER 01\nSoftware Requirements\nACRONYMS\nATDD\nAcceptance Test Driven \nDevelopment\nBDD\nBehavior Driven \nDevelopment\nCIA\nConfidentiality, Integrity, \nand Availability\nFSM\nFunctional Size \nMeasurement\nINCOSE\nInternational Council on \nSystems Engineering\nJAD\nJoint Application \nDevelopment\nJRP\nJoint Requirements Planning\nSME\nSubject Matter Expert\nSysML\nSystems Modeling Language\nTDD\nTest Driven Development\nUML\nUnified Modeling Language\nINTRODUCTION\nSoftware requirements should be viewed from \ntwo perspectives. The first is as an expres-\nsion of the needs and constraints on a soft-\nware product or project that contribute to the \nsolution of a real-world problem. The second \nis that of the activities necessary to develop \nand maintain the requirements for a software \nproduct and for the project that constructs \nit. Both perspectives are presented in this \nknowledge area (KA).\nIf a team does a poor job of determining the \nrequirements, the project, the product or both \nare likely to suffer from added costs, delays, \ncancellations and defects. One reason is that \neach software product requirement generally \nleads to many design decisions. Each design \ndecision generally leads to many code-level \ndecisions. Each decision can involve several \ntest decisions, as well. In other words, deter-\nmining the requirements correctly is high-\nstakes work. If not detected and repaired \nearly, missing, misinterpreted and incorrect \nrequirements can induce exponentially cas-\ncading rework to correct them.\nReal-world software projects tend to \nsuffer from two primary requirements-re-\nlated problems:\n1.\t incompleteness: \nstakeholder \nrequire-\nments, and necessary detail, exist that are \nnot revealed  and communicated to the \nsoftware engineers;\n2.\t ambiguity: requirements are communi-\ncated in a way that is open to multiple \ninterpretations, with only one possible \ninterpretation being correct.\nBeyond the obvious short-term role \nrequirements play in initial software con-\nstruction, they also play a less recognized \nbut still important role in long-term mainte-\nnance. Upon receiving software without any \nsupporting documentation, a software engi-\nneer has several means to determine what that \ncode does, such as execute it, step through \nit with a debugger, hand-execute it, stati-\ncally analyze it, and so on. The challenge is \ndetermining what that code is intended to do. \nWhat is generally referred to as a bug \u2014 but \nis better called a defect \u2014 is simply an observ-\nable difference between what the software is \nintended to do and what it does. The role of \nrequirements documentation throughout the \nservice life of the software is to capture and \n", "page": 43, "type": "text", "section": "Page 43"}
{"text": "1-2   SWEBOK \u00ae GUIDE V4.0\ncommunicate intent for software engineers \nwho maintain the code but might not have \nbeen its original authors.\nThe Software Requirements KA concerns \ndeveloping software requirements and man-\naging those requirements over the software\u2019s \nservice life. This KA provides an under-\nstanding that software requirements:\n\u2022\t are not necessarily a discrete front-end \nactivity of the software development life \ncycle but rather a process initiated at a \nproject\u2019s beginning that often continues \nto be refined throughout the software\u2019s \nentire service life;\n\u2022\t need to be tailored to the organization \nand project context.\nThe term requirements engineering is often \nused to denote the systematic handling of \nrequirements. For consistency, the term engi-\nneering will not be used in this KA other than \nfor software engineering per se. \nThe Software Requirements KA is most \nclosely related to the Software Architecture, \nSoftware Design, Software Construction, \nSoftware Testing, and Software Maintenance \nKAs, as well as to the models topic in the \nSoftware Engineering Models and Methods \nKA, in that there can be high value in speci-\nfying requirements in model form.\nThis KA is also related to the Software \nLife Cycles topic in the Software Engineering \nProcess KA, in that this KA\u2019s focus is on what \nand how requirements work can and should \nbe done, whereas the project\u2019s life cycle deter-\nmines when that work is done. For example, \nin a waterfall life cycle, all requirements work \nis essentially done in a discrete Requirements \nphase and is expected to be substantially com-\nplete before any architecture, design and con-\nstruction work occurs in subsequent phases. \nUnder some iterative life cycles, initial, high-\nlevel requirements work is done during an \nInception phase, and further detailing is done \nduring one or more Elaboration phases. In an \nAgile life cycle, requirements work is done \nincrementally, just in time, as each additional \nelement of functionality is constructed.\nThe whats and hows of software require-\nments work on a project should be determined \nby the nature of the software constructed, not \nby the life cycle under which it is constructed. \nInsofar as requirements documentation cap-\ntures and communicates the software\u2019s intent, \ndownstream maintainers should not be able \nto discern the life cycle used in earlier devel-\nopment from the form of those require-\nments alone.\nThis KA is also related, but somewhat \nless so, to the Software Configuration \nManagement, \nSoftware \nEngineering \nManagement and Software Quality KAs. \nSoftware CM approaches can be applied to \ntrace and manage requirements; software \nquality looks at how well formed the require-\nments are, and engineering management can \nuse the status of requirements to evaluate the \ncompletion of the project.\nBREAKDOWN OF TOPICS FOR \nSOFTWARE REQUIREMENTS\nThe topic breakdown for the Software \nRequirements KA is shown in Figure 1.1.\n1.\t Software Requirements Fundamentals\n1.1.\t Definition of a Software Requirement  \n\b\n[1*, c1pp5-6] [2*, c4p102]\nFormally, a software requirement has been \ndefined as [28]:\n\u2022\t a condition or capability needed by a user \nto solve a problem or achieve an objective;\n\u2022\t a condition or capability that must be \nmet or possessed by a system or system \ncomponent to satisfy a contract, stan-\ndard, specification or other formally \nimposed document;\n\u2022\t a documented representation or capa-\nbility as in (1) or (2) above.\nThis formal definition is extended in this \nKA to include expressions of a software proj-\nect\u2019s needs and constraints.\n", "page": 44, "type": "text", "section": "Page 44"}
{"text": "SOFTWARE REQUIREMENTS   1-3\nAt its most basic, a software requirement \nis a property that must be exhibited to solve a \nreal-world problem. It might aim to automate \nall or part of a task supporting an organiza-\ntion\u2019s business policies and processes, correct \nexisting software\u2019s shortcomings, or control a \ndevice \u2014 just a few of the many problems for \nwhich software solutions are possible. \nBusiness policies and processes, as well as \ndevice functions, are often very complex. By \nextension, software requirements are often a \ncomplex combination of requirements from \nvarious stakeholders at different organiza-\ntional levels who are involved or connected \nwith some aspect of the environment in which \nthe software will operate.\nClients, customers and users usually impose \nrequirements. However, other third parties, \nlike regulatory authorities and, in some cases, \nthe software organization or the project itself, \nmight also impose requirements. (See also [5, \nc1] [6, c1] [9, c4].)\n1.2.\t Categories of Software Requirements  \n\b\n[1*, c1pp7-12] [2*, s4.1]\nFigure 1.2 shows the categories of software \nrequirements defined in this KA and the \nrelationships among those categories. (See \nalso [5, c1] [6, c1] [9, c4].) Each category is \nfurther described below.\n1.3.\t Software Product Requirements and \nSoftware Project Requirements  \n\b\n[1*, c1pp14-15]\nSoftware product requirements specify the \nsoftware\u2019s expected form, fit or function. \nSoftware project requirements \u2014 also called \nprocess requirements or, sometimes business \nrequirements\u2014 constrain the project that \nconstructs the software. Project require-\nments often constrain cost, schedule and/or \nstaffing but can also constrain other aspects \nof a software project, such as testing envi-\nronments, data migration, user training, \nand maintenance. Software project require-\nments can be captured in a project charter \nor other high-level project initiation doc-\nument. They are most relevant to how \nthe project is managed (see the Software \nEngineering Management KA) or what \nlife cycle process should be used (see the \nSoftware Engineering Process KA). This \nKA does not discuss software project \nrequirements further.\nSoftware\nRequirements\nSoftware\nRequirements\nFundamentals\nDe\ufb01nition of a\nSoftware\nRequirement\nCategories of\nSoftware\nRequirements\nSoftware Product\nRequirements and\nSoftware Project\nRequirements\nFunctional\nRequirements\nNonfunctional\nRequirements\nTechnology\nConstraints\nQuality of Service\nConstraints\nWhy Categorize\nRequirements Tis Way?\nSystem Requirements\nand Software Requirements\nDerived\nRequirements\nSoftware Requirements\nActivities\nRequirements\nSources\nCommon\nRequirements\nElicitation\nTechniques\nBasic\nRequirements\nAnalysis\nEconomics of\nQuality of Service\nConstraints\nFormal\nAnalysis\nAddressing\nCon\ufb02ict in\nRequirements\nUnstructured\nNatural\nLanguage\nRequirements\nSpeci\ufb01cation\nStructured\nNatural\nLanguage\nRequirements\nSpeci\ufb01cation\nAcceptance\nCriteria-based\nRequirements\nSpeci\ufb01cation\nModel-Based\nRequirements\nSpeci\ufb01cation\nAdditional\nAttributes of\nRequirements\nIncremental and\nComprehensive\nRequirements\nSpeci\ufb01cation\nRequirements\nReviews\nSimulation and\nExecution\nPrototyping\nRequirements\nScrubbing\nRequirements\nChange\nControl\nScope\nMatching\nIterative Nature\nof the\nRequirements\nProcess\nRequirements\nPrioritization\nRequirements\nTracing\nRequirements\nStability and\nVolatility\nMeasuring\nRequirements\nRequirements\nProcess Quality\nand Improvement\nRequirements\nElicitation\nRequirements\nAnalysis\nRequirements\nSpeci\ufb01cation\nRequirements\nValidation\nRequirements\nManagement\nActivities\nPractical\nConsiderations\nSoftware\nRequirements\nTools\nRequirements\nManagement\nTools\nRequirements\nModeling\nTools\nFunctional\nTest Case\nGeneration\nTools\nFigure 1.1. Breakdown of Topics for the Software Requirements KA\n", "page": 45, "type": "text", "section": "Page 45"}
{"text": "1-4   SWEBOK \u00ae GUIDE V4.0\n1.4.\t Functional Requirements  \n\b\n[1*, c1p9] [2*, s4.1.1]\nFunctional requirements specify observable \nbehaviors that the software is to provide \u2014 \npolicies to be enforced and processes to be \ncarried out. Example policies in banking soft-\nware might be \u201can account shall always have \nat least one customer as its owner,\u201d and \u201cthe \nbalance of an account shall never be negative.\u201d \nExample processes could specify the meanings \nof depositing money into an account, with-\ndrawing money from an account and trans-\nferring money from one account to another.\nEven highly technical (nonbusiness-ori-\nented) software, such as software that imple-\nments the transmission control protocol/\ninternet protocol (TCP/IP) network com-\nmunications protocol, has policies and pro-\ncesses: \u201ca Port shall be able to exist with zero, \none, or many associated Connections, but a \nConnection shall exist on exactly one associ-\nated Port,\u201d \u201cacceptable states of a Connection \nshall be \u2018listen,\u2019 \u2018syn sent,\u2019 \u2018established,\u2019 \n\u2018closing,\u2019 . . . ,\u201d and \u201cif the time-to-live of a \nSegment reaches zero, that Segment shall be \ndeleted.\u201d (See [5, c1] [6, c10] [9, c4].)\n1.5.\t Nonfunctional Requirements  \n\b\n[1*, c1pp10-11] [2*, s4.1.2]\nNonfunctional requirements in some way con-\nstrain the technologies to be used in the \nimplementation: \nWhat \ncomputing \nplat-\nform(s)? What database engine(s)? How accu-\nrate do results need to be? How quickly must \nresults be presented? How many records of a \ncertain type need to be stored? Some non-\nfunctional requirements might relate to the \noperation of the software. (See the Operation \nand Maintenance KA.) (See also [5, c1] [6, \nc11] [9, c4].)\nThe nonfunctional requirements can be \nfurther divided into technology constraints \nand quality of service constraints. They have \nessential relationships among themselves, \nwhich affect them positively or negatively \nand require that, whenever a nonfunctional \nrequirement is modified, the impact it may \ncause on others should be considered.\n1.6.\t Technology Constraints\nThese requirements mandate \u2014 or prohibit \u2014 \nuse of specific, named automation technolo-\ngies or defined infrastructures. Examples are \nrequirements to use specific computing plat-\nforms (e.g., Windows\u2122, MacOS\u2122, Android \nOS\u2122, \niOS\u2122), \nprogramming \nlanguages \n(e.g., Java, C++, C#, Python), compatibility \nwith specific web browsers (e.g., Chrome\u2122, \nSafari\u2122, Edge\u2122), given database engines (e.g., \nOracle\u2122, SQL Server\u2122, MySQL\u2122), and gen-\neral technologies (e.g., reduced instruction set \ncomputer (RISC), Relational Database). A \nrequirement prohibiting use of pointers would \nbe another example. (See also [9, c4].)\n1.7.\t Quality of Service Constraints\nThese requirements do not constrain the use \nof specific, named technologies. Instead, \nthese specify acceptable performance levels an \nautomated solution must exhibit. Examples \nare response time, throughput, accuracy, \nreliability and scalability. ISO/IEC 25010: \n\u201cSystem and software engineering \u2013 Systems \nand software Quality Requirements and \nEvaluation (SQuaRE) \u2013 System and software \nquality models\u201d [27] contains a large list of \nthe kinds of quality characteristics that can be \nrelevant for software. (See also [9, c4].) Safety \nSoftware\nRequirements\nSoftware Project\nRequirements\nFunctional\nRequirements\nNonfunctional\nRequirements\nTechnology\nConstraints\nQuality of Service\nConstraints\nSoftware Product\nRequirements\nFigure 1.2. Categories of Software Requirements\n", "page": 46, "type": "text", "section": "Page 46"}
{"text": "SOFTWARE REQUIREMENTS   1-5\nand security are also a particularly important \ntopic where requirements tend to be over-\nlooked. (See the Security KA for details on \nthe kinds of specific security requirements \nthat should be considered.) (See also [2*, c13].)\n1.8.\t Why Categorize Requirements This Way?\nCategorizing requirements this way is useful \nfor the following reasons:\n\u2022\t requirements in one category tend to \ncome from different sources than other \ncategories;\n\u2022\t elicitation \ntechniques \noften \nvary \nby source;\n\u2022\t analysis techniques vary by category;\n\u2022\t specification techniques vary by category;\n\u2022\t validation authorities vary by category;\n\u2022\t the different categories affect the resulting \nsoftware in different ways.\nIn addition, organizing the requirements \nin these categories is beneficial in the fol-\nlowing ways:\n\u2022\t complexity can be better managed because \ndifferent areas can be addressed sepa-\nrately; software engineers can deal with \npolicy and process complexities without \nworrying about automation technology \nissues at the same time (and vice versa). \nOne large problem becomes two smaller \nones. This is classic divide and conquer \ncomplexity management;\n\u2022\t distinct areas of expertise can be iso-\nlated; stakeholders, not software engi-\nneers, are the experts in the policies and \nprocesses to be automated. Software \nengineers, not stakeholders, are the \ntechnology experts. When a business \nexpert is given interspersed functional \nand nonfunctional requirements for \nreview or validation, they might give \nup because they don\u2019t understand \u2014 or \neven care about \u2014 the technology issues. \nThe relevant requirements reviewer can \nfocus on just the subset of requirements \nrelevant to them.\nThe Perfect Technology Filter originally \ndescribed in [18, c1-4] but also explained in \n[8] and [9, c4] helps separate functional from \nnonfunctional requirements. Simply put, \nfunctional requirements are those that would \nstill need to be stated even if a computer with \ninfinite speed, unlimited memory, zero cost, \nno failures, etc., existed on which to construct \nthe software. All other software product \nrequirements are constraints on automation \ntechnologies and are therefore nonfunctional.\nLarge systems often span more than one \nsubject matter area, or domain. As explained \nin [9, c6], recursive design shows how non-\nfunctional requirements in a parent domain \ncan become, or can induce, functional require-\nments in a child domain. For example, a non-\nfunctional requirement about user security \nin a parent banking domain can become or \ncan induce functional requirements in a child \nsecurity domain. Similarly, cross-cutting non-\nfunctional requirements about auditing and \ntransaction management in a parent banking \ndomain can become or induce functional \nrequirements in a child auditing domain and a \nchild transaction domain. Decomposing large \nsystems into a set of related domains signifi-\ncantly reduces complexity.\n1.9.\t System Requirements and Software \nRequirements\nThe International Council on Systems \nEngineering (INCOSE) defines a system as \n\u201can interacting combination of elements to \naccomplish a defined objective. These include \nhardware, software, firmware, people, infor-\nmation, techniques, facilities, services, and \nother support elements\u201d [24].\nIn some cases, it is either useful or manda-\ntory to distinguish system requirements from \nsoftware requirements. System requirements \napply to larger systems \u2014 for example, an \nautonomous vehicle. Software requirements \napply only to an element of software in that \nlarger system. Some software requirements \nmay be derived from system requirements. \n(See also [5, c1].) In other cases, the software is \nitself the system of interest, and hardware and \n", "page": 47, "type": "text", "section": "Page 47"}
{"text": "1-6   SWEBOK \u00ae GUIDE V4.0\nsupport system are regarded as the platform \nor infrastructure, so that the system require-\nments are mostly software requirements.\n1.10.\t\n  Derived Requirements\nIn practice, requirements can be context-sensi-\ntive and can depend on perspective. An external \nstakeholder can impose a scope requirement, \nand this would be a requirement for the entire \nproject \u2014 even if that project involves hun-\ndreds of software engineers. An architect\u2019s \ndecision to use a pipes-and-filters architecture \nstyle would not be a requirement from the per-\nspective of the overall project stakeholders, \nbut a design decision. But that same decision, \nwhen seen from the perspective of a sub-team \nresponsible for constructing a particular filter, \nwould be considered a requirement.\nThe aerospace industry has long used the \nterm derived requirement to mean a require-\nment that was not made by a stakeholder \nexternal to the overall project but that was \nimposed inside the larger development team. \nThe architect\u2019s pipes-and-filters decision fits \nthis definition. That choice would be seen as \na design decision from the point of view of \nexternal stakeholders, but as a requirement for \nthe sub-teams responsible for developing each \nfilter. (See also [9, c4].)\n1.11.\t\n  Software Requirements Activities  \n\b\n[1*, c1pp15-18] [2*, s4.2]\nFigure 1.3 shows the requirements develop-\nment and management activities.\nRequirements development, as a whole, \ncan be thought of as \u201creaching an agreement \non what software is to be constructed.\u201d In \ncontrast, requirements management can be \nconsidered \u201cmaintaining that agreement over \ntime.\u201d Each activity is presented in this KA. \nRequirements development activities are pre-\nsented as separate topics, with requirements \nmanagement presented as a single topic. (See \nalso [5, c1] [6, 2].)\n2.\t Requirements Elicitation  \n\b\n[1*, c6-7] [2*, s4.3]\nThe goal of requirements elicitation is to sur-\nface candidate requirements. It is also called \nrequirements capture, requirements discovery or \nrequirements acquisition. As stated earlier, one \nproblem in requirements work on real-world \nsoftware projects is incompleteness. This \ncan be the result of inadequate elicitation. \nAlthough there is no guarantee that a set of \nrequirements is complete, well-executed elic-\nitation helps minimize incompleteness. (See \nalso [5, c2-3] [6, c3-7].)\n2.1.\t Requirements Sources  \n\b\n[1*, c6] [2*, s4.3]\nRequirements come \u2014 can be elicited \u2014 from \nmany different sources. All potential require-\nments sources should be identified and eval-\nuated. A stakeholder can be defined as any \nperson, group or organization that: \n\u2022\t is actively involved in the project;\n\u2022\t is affected by the project\u2019s outcome;\n\u2022\t can influence the project\u2019s outcome.\nTypical stakeholders for software projects \ninclude but are not limited to the following:\n\u2022\t clients \u2014 those who pay for the software \nto be constructed (e.g., organizational \nmanagement);\n\u2022\t customers \u2014 those who decide whether a \nsoftware product will be put into service;\n\u2022\t users \u2014 those who interact directly or \nindirectly with the software; users can \nRequirements\nRequirements\nDevelopment\nElicitation\nAnalysis\nSpeci\ufb01cation\nValidation\nScrubbing\nChange Control\nScope Matching\nRequirements\nManagement\nFigure 1.3. Software Requirements Activities\n", "page": 48, "type": "text", "section": "Page 48"}
{"text": "SOFTWARE REQUIREMENTS   1-7\noften be further broken down into dis-\ntinct user classes that vary in frequency \nof use, tasks performed, skill and knowl-\nedge level, privilege level, and so on;\n\u2022\t subject matter experts (SMEs);\n\u2022\t operations staff;\n\u2022\t first-level product support staff;\n\u2022\t relevant professional bodies;\n\u2022\t regulatory agencies;\n\u2022\t special interest groups;\n\u2022\t people who can be negatively affected if \nthe project is successful;\n\u2022\t developers.\nStakeholder classes are groups of stake-\nholders that have similar perspectives and \nneeds. Working on a software project in terms \nof stakeholder classes rather than with indi-\nvidual stakeholders can produce important, \nadditional insight.\nMany projects benefit from performing \na stakeholder analysis to identify as many \nimportant stakeholder classes as possible. This \nreduces the possibility that the requirements \nare biased toward better-represented stake-\nholders and away from less well-represented \nstakeholders. The stakeholder analysis can \nalso inform negotiation and conflict resolu-\ntion when requirements from one stakeholder \nclass conflict with requirements from another. \n(See also [5, c3] [6, c3].)\nRequirements are not limited to only \ncoming from people. Other, non-person \nrequirements sources can include:\n\u2022\t documentation such as requirements for \nprevious versions, mission statements, \nconcept of operations;\n\u2022\t other systems;\n\u2022\t larger business context including organi-\nzational policies and processes;\n\u2022\t computing environment.\n2.2.\t Common Requirements Elicitation \nTechniques \b\n[1*, c7] [2*, s4.3]\nA wide variety of techniques can be used to \nelicit requirements from stakeholders. Some \ntechniques work better with certain stake-\nholder classes than others. Common stake-\nholder elicitation techniques include the \nfollowing:\n\u2022\t interviews;\n\u2022\t meetings, \npossibly \nincluding \nbrainstorming;\n\u2022\t joint application development (JAD) \n[13], joint requirements planning (JRP) \n[14] and other facilitated workshops;\n\u2022\t protocol analysis;\n\u2022\t focus groups;\n\u2022\t questionnaires and market surveys;\n\u2022\t exploratory \nprototyping, \nincluding \nlow-fidelity and high-fidelity user inter-\nface prototyping [1*, c15];\n\u2022\t user story mapping.\nElicitation can be difficult, and the software \nengineer needs to know that (for example) users \nmight have difficulty describing their tasks, \nleave important information unstated or be \nunwilling or unable to cooperate. Elicitation \nis not a passive activity. Even if cooperative \nand articulate stakeholders are available, the \nsoftware engineer must work hard to elicit \nthe right information. Many product require-\nments are tacit or can be found only in infor-\nmation that has yet to be collected.\nRequirements can also be elicited from \nsources other than stakeholders. Such sources \nand techniques include the following:\n\u2022\t previous versions of the system;\n\u2022\t defect tracking database for previous ver-\nsions of the system;\n\u2022\t systems that interface with the system \nunder development;\n\u2022\t competitive benchmarking;\n\u2022\t literature search;\n\u2022\t quality function deployment (QFD)\u2019s \nHouse of Quality [15];\n\u2022\t observation, where the software engineer \nstudies the work and the environment \nwhere the work is being done;\n\u2022\t apprenticing, where the software engi-\nneer learns by doing the work;\n\u2022\t usage scenario descriptions;\n", "page": 49, "type": "text", "section": "Page 49"}
{"text": "1-8   SWEBOK \u00ae GUIDE V4.0\n\u2022\t decomposition (e.g., capabilities into \nepics into features into stories);\n\u2022\t task analysis [16];\n\u2022\t design thinking (empathize, define, \nideate, prototype, test) [17];\n\u2022\t ISO/IEC 25010: \u201cSystem and software \nengineering \u2013 Systems and software \nQuality Requirements and Evaluation \n(SQuaRE) \u2013 System and software quality \nmodels\u201d [27];\n\u2022\t security requirements, as discussed in the \nSecurity KA;\n\u2022\t applicable standards and regulations.\n(See also [5, c3] [6, c4-7].)\n3.\t Requirements Analysis [1*, c8-9]\nRequirements are unlikely to be elicited in \ntheir final form. Further investigation is usu-\nally needed to reveal the full, true require-\nments suggested by the originally elicited \ninformation. Requirements analysis helps \nsoftware developers understand the meaning \nand implications of candidate requirements, \nboth individually and in the context of the \noverall set of requirements.\n3.1.\t Basic Requirements Analysis  \n\b\n[1*, c8-9]\nThe following list of desirable properties of \nrequirements can guide basic requirements \nanalysis. The software engineer seeks to \nestablish any of these properties that do not \nhold yet. Each requirement should:\n\u2022\t be \nunambiguous \n(interpretable \nin \nonly one way);\n\u2022\t be testable (quantified), meaning that \ncompliance or noncompliance can be \nclearly demonstrated;\n\u2022\t be binding, meaning that clients are \nwilling to pay for it and unwilling not \nto have it;\n\u2022\t atomic, represent a single decision\n\u2022\t represent true, actual stakeholder needs;\n\u2022\t use stakeholder vocabulary;\n\u2022\t be acceptable to all stakeholders.\nThe overall collection of requirements \nshould be:\n\u2022\t complete  \u2014 The requirements adequately \naddress boundary conditions, exception \nconditions and security needs;\n\u2022\t concise \u2014 No extraneous content in the \nrequirements\n\u2022\t internally consistent \u2014 No requirement \nconflicts with any other;\n\u2022\t externally consistent \u2014 No requirement \nconflicts with any source material;\n\u2022\t feasible \u2014 A viable, cost-effective solu-\ntion can be created within cost, schedule, \nstaffing, and other constraints.\nIn some cases, an elicited statement rep-\nresents a solution to be implemented rather \nthan the true problem to be solved. This \nrisks implementing a suboptimal solution. \nThe 5-whys technique (e.g., [3*, c4]) involves \nrepeatedly asking, \u201cWhy is this the require-\nment?\u201d to converge on the true problem. \nRepetition stops when the answer is, \u201cIf that \nisn\u2019t done, then the stakeholder\u2019s problem has \nnot been solved.\u201d Often, the true problem is \nreached in two or three cycles, but the tech-\nnique is called 5-whys to incentivize engineers \nto push it as far as possible.\n3.2.\t Economics of Quality of Service Constraints \n\b\n[3*]\nQuality of service constraints can be partic-\nularly challenging. This is generally because \nengineers do not consider them from an eco-\nnomic perspective [9, c4]. Figure 1.4 illus-\ntrates the economic perspective of a typical \nquality of service constraint, such as capacity, \nthroughput and reliability, where value \nincreases with performance level. This curve is \nmirrored vertically for quality of service con-\nstraints whose value decreases as performance \nlevel increases (response time and mean time \nto repair would be examples).\n Over the relevant range of performance \nlevels, the stakeholders have a corresponding \nvalue if the system performs at that level. The \nvalue curve has two important points:\n", "page": 50, "type": "text", "section": "Page 50"}
{"text": "SOFTWARE REQUIREMENTS   1-9\n1.\t Perfection point \u2014 This is the most \nfavorable level of performance, beyond \nwhich there is no additional benefit. Even \nif the system can perform better than the \nperfection point, the customer cannot use \nthat capacity. For example, a social media \nsystem that supports more members than \nthe world population would have this \nexcess capacity.\n2.\t Fail point \u2014 This is the least favorable \nlevel of performance, beyond which there \nis no further reduction in benefit. For \nexample, the social media system might \nneed to support at least a minimum \nmarket share to be viable as a platform.\nA quantified requirement point, even if \nstated explicitly, is usually arbitrary. It is \noften based on what a client feels justified \nrequesting, given what they are paying for \nthe software. Even if the software engineers \ncannot construct a system that fully achieves \nthe stated requirement point, the software \ntypically still has value; it just has less value \nthan the client expected. Further, the ability \nto exceed the requirement point can signifi-\ncantly increase value in some cases.\nThe cost to achieve a given performance \nlevel is usually a step function. First, for a \ngiven investment level, there is some max-\nimum achievable performance level. Then, \nadditional investment is needed, and that \nfurther investment enables performance up \nto a new, more favorable maximum. Figure \n1.5 illustrates the most cost-effective perfor-\nmance level \u2014 the performance level with \nthe maximum positive difference between the \nvalue at that performance level and the cost to \nachieve it.\n(See the Software Engineering Economics \nKA or [3*] for more information on per-\nforming economic analyses such as this.)\nThe software engineer should pay particular \nattention to positive and negative relation-\nships between quality of service constraints \n(e.g., Figure 14-1 in [1*, c14]). Some quality of \nservice constraints are mutually supporting; \nimproving one\u2019s performance level will auto-\nmatically improve the other\u2019s performance \nlevel. For example, the more modifiable code \nis, the more reliable it tends to be, as both \nmodifiability and reliability are, to a degree, \na consequence of how clean the code is. On \nthe other hand, the higher the code\u2019s speed, \nthe less modifiable it might be, because high \nspeed is often achieved through optimizations \nthat make the code more complex.\n3.3.\t Formal Analysis  \n\b\n[2*, s12.3.2-12.3.3]\nFormal analysis has shown benefits in some \napplication domains, particularly high-integ-\nrity systems (e.g., [5, c6]). The formal expres-\nsion of requirements depends on the use of a \nspecification language with formally defined \nsemantics. Formality has two benefits. First, \nformal requirements are precise and concise, \nValue\nLevel of Performance\nFail\nPerfection\nFigure 1.4. Value as a Function of Level of \nPerformance\n$\nValue\nCost to\ndeliver\nMost cost-e\ufb00ective\nlevel of performance\nLevel of performance\nFigure 1.5. Most Cost-Effective Level of \nPerformance\n", "page": 51, "type": "text", "section": "Page 51"}
{"text": "1-10   SWEBOK \u00ae GUIDE V4.0\nwhich (in principle) will reduce the possibility \nfor misinterpretation. Second, formal require-\nments can be reasoned over, permitting \ndesired properties of the specified software to \nbe proved. This permits static validation that \nthe software specified by the requirements \ndoes have the properties (e.g., absence of \ndeadlock) that the customer, users and soft-\nware engineer expect it to have.\nThis topic is related to Formal Methods \nin the Software Engineering Models and \nMethods KA.\n3.4.\t Addressing Conflict in Requirements\nWhen a project has more \u2014 and more diverse \n\u2014 stakeholders, conflicts among the require-\nments are more likely. One particularly \nimportant aspect of requirements analysis \nis identifying and managing such conflicts \n(e.g., [6, c17]). Once conflicting requirements \nhave been identified, the engineer may con-\nsider two different approaches to managing \nthat conflict (and possibly other approaches \nas well) and determine the most appropriate \ncourse of action.\nOne approach is to negotiate a resolution \namong the conflicting stakeholders. In most \ncases, it is unwise for the software engineer \nto make a unilateral decision, so it becomes \nnecessary to consult with the stakeholders to \nreach a consensus resolution. It is often also \nimportant, for contractual reasons, that such \ndecisions be traceable back to the customer. A \nspecific example is project scope management \u2014 \nnamely, balancing what\u2019s desired in the stated \nsoftware product requirements with what can \nbe accomplished given the project require-\nments of cost, schedule, staffing and other \nproject-level constraints. There are many \nuseful sources for information on negotiation \nand conflict resolution [25].\nAnother approach is to apply product family \ndevelopment (e.g., [20]). This involves sepa-\nrating requirements into two categories. The \nfirst category contains the invariant require-\nments. These are requirements that all stake-\nholders agree on. The second category contains \nthe variant requirements, where conflict exists. \nThe software engineer can focus on under-\nstanding the range of variations needed to \nsatisfy all stakeholders. The software can be \ndesigned using design to invariants to accom-\nmodate the invariant requirements and design \nfor change to incorporate customization points \nto configure an instance of the system to best \nfit relevant stakeholders. In a simple example, \nsome users of a weather application require \ntemperatures displayed in degrees Celsius \nwhile others require degrees Fahrenheit.\n4.\t Requirements Specification  \n\b\n[1*, c10-14, c20-26] [2*, s4.4, c5]\nRequirements specification concerns recording \nthe requirements so they can be both remem-\nbered and communicated. Requirements \nspecification might be the most contentious \ntopic in this KA. Debate centers on ques-\ntions such as:\n\u2022\t should \nrequirements \nbe \nwritten \ndown at all?\n\u2022\t if requirements are written down, what \nform should they take?\n\u2022\t if requirements are written down, should \nthey also be maintained over time?\nThere are no standard answers to these \nquestions; the answer to each can depend on \nfactors such as the following:\n\u2022\t the software engineer\u2019s familiarity with \nthe business domain;\n\u2022\t precedent for this kind of software;\n\u2022\t degree of risk (e.g., probability, severity) \nof incorrect requirements;\n\u2022\t staff turnover anticipated during the ser-\nvice life of the software;\n\u2022\t geographic distribution of the develop-\nment team members;\n\u2022\t stakeholder involvement over the course \nof the project;\n\u2022\t whether the use of a third-party service, \npackaged solution or open source library \nis anticipated;\n\u2022\t whether any design or construction will \nbe outsourced;\n", "page": 52, "type": "text", "section": "Page 52"}
{"text": "SOFTWARE REQUIREMENTS   1-11\n\u2022\t the \ndegree \nof \nrequirements-based \ntesting expected;\n\u2022\t effort needed to use a candidate specifica-\ntion technique;\n\u2022\t accuracy needed from the require-\nments-based estimates;\n\u2022\t extent of requirements tracing neces-\nsary, if any;\n\u2022\t contractual impositions of requirements \nspecification content and format.\nAs stated in this KA\u2019s introduction, the \nwhats and hows of software requirements \nwork on a project should be determined by \nthe nature of the software constructed, not \nby the life cycle under which it is constructed. \nDownstream maintainers should not be able \nto discern the life cycle used in earlier devel-\nopment from the form of those requirements \nalone. The chosen life cycle\u2019s effect should be \nlimited to the completeness of the require-\nments at any point in the project. Under a \nwaterfall life cycle, the requirements are \nexpected to be completely specified at the end \nof the Requirements phase. Under an Agile \nlife cycle, the requirements are expected to \nchange, grow, or be eliminated continuously \nand not be complete until the project\u2019s end.\nSome organizations have a culture of docu-\nmenting requirements; some do not. Dynamic \nstartup projects are often driven by a strong \nproduct vision and limited resources; their \nteams might view requirements documen-\ntation as unnecessary overhead. But as these \nproducts evolve and mature, software engi-\nneers often recognize that they need to recover \nthe requirements that motivated product fea-\ntures in order to assess the impact of proposed \nchanges. Hence, requirements documentation \nand change management become important \nto long-term success. A project\u2019s approach to \nrequirements in general, and to requirements \nspecification in particular, may evolve over \nthe service life of that software.\nThe most basic recommendation for \nrequirements documentation is to base deci-\nsions on an audience analysis. Who are the \ndifferent consumers who will need informa-\ntion from a requirements specification? What \ninformation will they need? How can that \ninformation be packaged and presented so \nthat each consumer can get the information \nthey need with the least effort?\nThere is a degree of overlap and dependency \nbetween requirements analysis and specifica-\ntion. Use of certain requirements specifica-\ntion techniques \u2014 particularly model-based \nrequirements specifications \u2014 permit and \nencourage requirements analysis that can go \nbeyond what has already been presented.\nDocumented software requirements should \nbe subject to the same configuration man-\nagement practices as the other deliverables \nof the software life cycle processes. (See the \nConfiguration Management KA for a detailed \ndiscussion.) In addition, when practical, the \nindividual requirements are also subject to \nconfiguration management and traceability, \nwhich is generally supported by a requirements \nmanagement tool. (See Topic 8, Software \nRequirements Tools.)\nThere are several general categories of \nrequirements specification techniques, each \nof which is discussed below. The requirements \nspecification for a given project may also use \nvarious techniques. ISO/IEC/IEEE 29148 \n[26], as well as [1*, c10-14], [5, c4], [6, c16], \nand many others offer templates for require-\nments documentation.\n4.1.\t Unstructured Natural Language \nRequirements Specification \n \b\n[1*, c11] [2*, s4.4.1]\nNatural language requirements specifications \nexpress requirements in common, ordinary lan-\nguage. Natural language requirements specifi-\ncations can be unstructured or structured.\nA typical unstructured natural language \nrequirements specification is a collection of \nstatements in natural language, such as, \u201cThe \nsystem shall . . . .\u201d For example, business rules \nare statements that define or constrain some \naspect of the structure or the behavior of the \nbusiness to be automated. \u201cA student cannot \nregister in next semester\u2019s courses if there \nremain any unpaid tuition fees\u201d is an example \nof a business rule that serves as a requirement \n", "page": 53, "type": "text", "section": "Page 53"}
{"text": "1-12   SWEBOK \u00ae GUIDE V4.0\nfor a university\u2019s course-registration software. \nSome projects can publish a user manual as \na satisfactory requirements specification, \nalthough there are limits to how effective this \ncan be. (See also [5, c4] [26].)\n4.2.\t Structured Natural Language Requirements \nSpecification \b\n[1*, c8] [2*, s4.4.2]\nStructured natural language requirements \nspecifications impose constraints on how the \nrequirements are expressed; the goal is to \nincrease precision and conciseness.\nThe simplest example might be the \nactor-action format. The actor is the entity \nresponsible for carrying out the action, and \naction is what needs to happen. A trig-\ngering event might precede the actor, and \nthe action might be followed by an optional \ncondition or qualification. The statement \n\u201cWhen an order is shipped, the system shall \ncreate an Invoice unless the Order Terms \nare \u2018Prepaid\u2019\u201d uses actor-action format. \nThe triggering event is \u201cWhen an order is \nshipped.\u201d The actor is \u201cthe system.\u201d The \naction is \u201ccreate an Invoice.\u201d The condition/\nqualification is \u201cexcept the Order Terms are \n\u2018Prepaid\u2019.\u201d \nAnother example is a use case specifica-\ntion template, as shown in Figure 1.6. (See \n[11] for guidelines on writing good use case \nspecifications.)\nThe user story format, \u201cAs a <user> I want \n<capability> so that <benefit>\u201d as well as deci-\nsion tables are other examples. (See also [5, \nc4] [6, c12, c16] [7, c2-5].)\n4.3.\t Acceptance Criteria-Based Requirements \nSpecification\nThis general approach includes two specific \nvariants: acceptance test driven  develop-\nment (ATDD) and behavior driven develop-\nment (BDD).\nATDD [2*, s3.2.3, s8.2] is a part of the \nlarger test  driven development (TDD) \napproach. (See the Software Testing KA.). \nThe main idea of TDD is that test cases pre-\ncede construction. Therefore, no new produc-\ntion code is written and no existing code is \nmodified unless at least one test case fails, \neither at the unit test level or at the acceptance \ntest level. The ATDD process has three steps:\n1.\t A unit of functionality (e.g., a user story) \nis selected for implementation.\n2.\t One or more software engineers, one or \nmore business domain experts, and pos-\nsibly one or more QA/test professionals \nmeet \u2014 before any production design or \nUse case #66  \nUse case name: Reserve \ufb02ight(s)\nTriggering event(s)  \nCustomer requests reservation(s) on \ufb02ight(s)\nParameters  \nPassenger, itinerary, fare class, payment method(s)\nRequires  \nLegal itinerary, fare class restrictions met\nGuarantees  \nSeat(s) reserved for passenger on itinerary \ufb02ight(s)\nNormal course  \nNon-FF passenger, all domestic itinerary, Economy fare class, credit/debit card\nAlternative course(s)  \nIs FF passenger: [None, Silver, Gold, Platinum, Elite]\n \nItinerary: [all international, mixed domestic + international] \n \nFare class: [Basic economy, Premium Economy, Business, First] \n \nPayment method: [Voucher, FF miles]\nExceptions  \nC/D card declined, voucher doesn\u2019t exist, voucher expired, FF account doesn\u2019t exist,\n \ninsu\ufb03cient miles in FF account\nFigure 1.6. Example of Structured Natural Language Specification for a Single Use Case\n", "page": 54, "type": "text", "section": "Page 54"}
{"text": "SOFTWARE REQUIREMENTS   1-13\nconstruction work is done \u2014 to agree on \na set of test cases that must pass to show \nthat the unit of functionality has been \ncorrectly implemented.\n3.\t At least one of those acceptance test cases \nmust fail on the existing software. The \nexistence of at least one failing test case \ngives the software engineer(s) permis-\nsion to create or modify production code \nto pass all of the agreed-upon test cases. \nThis step might require several iterations. \nThe code may also be refactored during \nthis step.\nWhen all acceptance test cases have passed, \nand presumably all unit and integration test \ncases as well, then the unit of functionality is \ndeemed to have been completely and correctly \nimplemented. The ATDD process returns to \nstep 1, where a new unit of functionality is \nselected, and the cycle repeats.\nATDD might seem to be a testing tech-\nnique rather than a requirements specifica-\ntion technique. On the other hand, a test case \nhas the general form of \u201cWhen given input \nthat looks like X, we expect the software to \nproduce results that look like Y.\u201d The key is \nthe underlined phrase, \u201cwe expect the soft-\nware to produce.\u201d If we simply modify that \nphrase to say, \u201cthe software shall produce,\u201d \nas in \u201cWhen given input that looks like X, \nthe software shall produce results that look \nlike Y,\u201d what first looked like a test case now \nlooks like a requirement. Technically, one \nacceptance test case can encompass more \nthan one single requirement, but the gen-\neral idea holds that the ATDD test cases are \nessentially precise, unambiguous statements \nof requirements.\nThe BDD approach [19] is slightly more \nstructured, and business domain experts typ-\nically prefer it over ATDD because it is less \ntechnical in appearance. In BDD, the unit \nof functionality is described as a user story, \nin a form such as this: \u201cAs a <user> I want \n<capability> so that <benefit>.\u201d This leads to \nthe identification and specification of a set of \n\u201cscenarios\u201d in this form: \u201cGiven <some con-\ntext> [and <possibly more context>], when \n<stimulus> then <outcome> [and <possibly \nmore outcomes>].\u201d\nIf the story is \u201cAs a bank customer, I want \nto withdraw cash from the automated teller \nmachine (ATM) so that I can get money \nwithout going to the bank,\u201d one scenario could \nbe that \u201cthe account has a sufficient balance.\u201d \nThis scenario could be detailed as \u201cGiven the \naccount balance is $500, and the customer\u2019s \nbank card is valid, and the automated teller \nmachine contains enough money in its cash \nbox, when the Account Holder requests $100, \nthen the ATM should dispense $100 and the \naccount balance should be $400, and the cus-\ntomer\u2019s bank card should be returned.\u201d\nAnother scenario could be that \u201cthe \naccount has an insufficient balance\u201d and \ncould be detailed as \u201cGiven the account bal-\nance is $50, and the customer\u2019s bank card is \nvalid, and the automated teller machine con-\ntains enough money in its cash box, when \nthe Account Holder requests $100, then the \nATM should not dispense any money, and the \nATM should say there is an insufficient bal-\nance, the balance should remain at $50, and \nthe customer\u2019s bank card should be returned.\u201d\nThe goal of BDD is to have a comprehensive \nset of scenarios for each unit of functionality. \nIn the withdrawing cash situation, additional \nscenarios for \u201cThe Bank Customer\u2019s bank card \nhas been disabled\u201d and \u201cThe ATM does not \ncontain enough money in its cash box\u201d would \nbe necessary.\nThe acceptance test cases are obvious from \nthe BDD scenarios.\nAcceptance criteria-based requirements \nspecification directly addresses the require-\nments ambiguity problem. Natural languages \nare inherently ambiguous, but test case lan-\nguage is not. In acceptance-based criteria \nrequirements specification, the requirements \nare written using test case language, which is \nvery precise. On the other hand, this does not \ninherently solve the incompleteness problem. \nHowever, combining ATDD or BDD with \nappropriate functional test coverage cri-\nteria, such as Domain Testing, Boundary \nValue Analysis and Pairwise Testing (see \nthe Software Testing KA), can reduce the \n", "page": 55, "type": "text", "section": "Page 55"}
{"text": "1-14   SWEBOK \u00ae GUIDE V4.0\nlikelihood of requirements incompleteness. \n(See also [9, c1, c12].)\n4.4.\t Model-Based Requirements Specification  \n\b\n[1*, c12] [2*, c5] [4*]\nAnother approach to avoiding the inherent \nambiguity of natural languages is to use mod-\neling languages such as selected elements of \nthe unified modeling language\u2122 (UML) or \nsystems modeling language\u2122 (SysML). Much \nlike the blueprints used in building construc-\ntion, these modeling languages can be used \nin a computing technology-free manner to \nprecisely and concisely specify functional \nrequirements [9, c1-2]. This topic is closely \nrelated to the Software Engineering Models \nand Methods KA. Requirements models fall \ninto two general categories:\n1.\t Structural models for specifying poli-\ncies to be enforced: These are logical class \nmodels as described in, for example, [9, \nc8]. They are also called conceptual data \nmodels, logical data models and enti-\nty-relationship diagrams.\n2.\t Behavioral models for specifying pro-\ncesses to be carried out: These models \ninclude use case modeling as described in \n[9, c7], interaction diagrams as described \nin [9, c9] and state modeling as described \nin [9, c10]. Other examples are UML \nactivity diagrams and data-flow mod-\neling, as described in [1*, c12-13], [8], \n[10] and [18].\nModel-based \nrequirements \nspecifica-\ntions vary in the degree of model formality. \nConsider the following: \n1.\t Agile modeling (see, for example, [10]) \nis the least formal. Agile models can be \nlittle more than rough sketches whose \ngoal is to communicate important infor-\nmation rather than demonstrate proper \nuse of modeling notations. In this type \nof modeling, the effect of the communi-\ncation is considered more important than \nthe form of the communication.\n2.\t Semiformal modeling, for example [9, \nc6-12], provides a definition of the mod-\neling language semantics ([9, Appendix \nL]), but that definition has not been \nformally proved to be complete and \nconsistent.\n3.\t Formal modeling, for example, Z, the \nVienna development method (VDM), \nspecification and description language \n(SDL) and [5, c7] have very precisely \ndefined semantics that allow specifica-\ntions to be mechanically analyzed for the \npresence or absence of specific properties \nto help avoid critical reasoning errors. \nThe term correctness by construction has \nbeen used for development in this con-\ntext. (See the Formal Methods section in \nthe Software Engineering Models and \nMethods KA.)\nGenerally, the more formal a requirements \nmodel is, the less ambiguous it is, so soft-\nware engineers are less likely to misinterpret \nthe requirements. More formal requirements \nmodels can also be:\n\u2022\t more concise and compact;\n\u2022\t easier to translate into code, possibly \nmechanically;\n\u2022\t used as a basis for deriving acceptance \ntest cases.\nOne important message in [4*] is that while \nformal modeling languages are stronger than \nsemiformal and Agile modeling, formal nota-\ntions can burden both the model creator and \nhuman readers. Wing\u2019s compromise is to use \nformally defined underpinnings (e.g., in Z) \nfor surface syntaxes that are easier to read and \nwrite (e.g., UML statecharts).\n4.5.\t Additional Attributes of Requirements  \n\b\n[1*, c27pp462-463]\nOver and above the basic requirements \nstatements already described, documenting \nadditional attributes for some or all require-\nments can be useful. This supplemental \ndetail can help software engineers better \n", "page": 56, "type": "text", "section": "Page 56"}
{"text": "SOFTWARE REQUIREMENTS   1-15\ninterpret and manage the requirements [6, \nc16]. Possible additional attributes include \nthe following:\n\u2022\t tag to support requirements tracing;\n\u2022\t description (additional details about the \nrequirement);\n\u2022\t rationale \n(why \nthe \nrequirement \nis \nimportant);\n\u2022\t source (role or name of the stakeholder \nwho imposed this requirement);\n\u2022\t use case or relevant triggering event;\n\u2022\t type (classification or category of the \nrequirement \u2014 e.g., functional, quality \nof service);\n\u2022\t dependencies;\n\u2022\t conflicts;\n\u2022\t acceptance criteria;\n\u2022\t priority (see Requirements Prioritization \nlater in this KA);\n\u2022\t stability (see Requirements Stability and \nVolatility later in this KA);\n\u2022\t whether the requirement is common or a \nvariant for product family development \n(e.g., [20]);\n\u2022\t supporting materials;\n\u2022\t the requirement\u2019s change history.\nGilb\u2019s Planguage (short for Planning \nLanguage) [7] recommends attributes such as \nscale, meter, minimum, target, outstanding, \npast, trend and record.\n4.6.\t Incremental and Comprehensive \nRequirements Specification\nProjects that explicitly document require-\nments take one of two approaches. One can \nbe called incremental specification. In this \napproach, a version of the requirements speci-\nfication contains only the differences \u2014 addi-\ntions, modifications and deletions \u2014 from \nthe previous version. An advantage of this \napproach is that it can produce a smaller \nvolume of written specifications.\nThe other approach can be called compre-\nhensive specification. In this approach, each \nversion\u2019s requirements specification con-\ntains all requirements, not just changes from \nthe previous version. An advantage of this \napproach is that a reader can understand all \nrequirements in a single document instead of \nhaving to keep track of cumulative additions, \nmodifications and deletions across a series of \nspecifications.\nSome organizations combine these two \napproaches, producing intermediate releases \n(e.g., x.1, x.2 and x.3) that are specified incre-\nmentally and major releases (e.g., 1.0, 2.0 and \n3.0) that are specified comprehensively. The \nreader never needs to go any further back \nthan the requirements specifications for the \nlast major release to obtain the complete set \nof specifications.\n5.\t Requirements Validation  \n\b\n[1*, c17] [2*, s4.5]\nRequirements validation concerns gaining \nconfidence that the requirements represent \nthe stakeholders\u2019 true needs as they are cur-\nrently understood (and possibly documented). \nKey questions include the following:\n\u2022\t do these represent all requirements rele-\nvant at this time?\n\u2022\t are any stated requirements not represen-\ntative of stakeholder needs?\n\u2022\t are \nthese \nrequirements \nappropri-\nately stated?\n\u2022\t are the requirements understandable, \nconsistent and complete?\n\u2022\t does the requirements documentation \nconform to relevant standards?\nThree methods for requirements validation \ntend to be used: requirements reviews, sim-\nulation and execution, and prototyping. (See \nalso [5, c5] [6, c17] [9, c12].)\n5.1.\t Requirements Reviews  \n\b\n[1*, c17pp332-342] [2*, c4p130]\nThe most common way to validate is by \nreviewing or inspecting a requirements docu-\nment. One or more reviewers are asked to look \nfor errors, omissions, invalid assumptions, \nlack of clarity and deviation from accepted \n", "page": 57, "type": "text", "section": "Page 57"}
{"text": "1-16   SWEBOK \u00ae GUIDE V4.0\npractice. Review from multiple perspectives \nis preferred:\n\u2022\t clients, customers and users check that \ntheir wants and needs are completely and \naccurately represented;\n\u2022\t other software engineers with expertise \nin requirements specification check that \nthe document is clear and conforms to \napplicable standards;\n\u2022\t software engineers who will do architec-\nture, design or construction of the soft-\nware that satisfies these requirements \ncheck that the document is sufficient to \nsupport their work.\nProviding checklists, quality criteria or \na \u201cdefinition of done\u201d to the reviewers can \nguide them to focus on specific aspects of the \nrequirements specification. (See Reviews and \nAudits in the Software Quality KA.)\n5.2.\t Simulation and Execution\nNontechnical stakeholders might not want to \nspend time reviewing a specification in detail. \nSome specifications can be subjected to sim-\nulation or actual execution in place of or in \naddition to human review. To the extent that \nthe requirements are formally specified (e.g., \nin a model-based specification), software \nengineers can hand interpret that specifica-\ntion and \u201cexecute\u201d the specification. Given \na sufficient set of demonstration scenarios, \nstakeholders can be convinced that the spec-\nification defines their policies and processes \ncompletely and accurately. (See [9, c12].)\n5.3.\t Prototyping  \n\b\n[1*, c17p342] [2*, c4p130]\nIf the requirements specification is not in \na form that allows direct simulation or exe-\ncution, an alternative is to have a software \nengineer build a prototype that concretely \ndemonstrates some important dimension of \nan implementation. This demonstrates the \nsoftware engineer\u2019s interpretation of those \nrequirements.\nPrototypes can help expose software engi-\nneers\u2019 assumptions and, where needed, give \nuseful feedback on why they are wrong. For \nexample, a user interface\u2019s dynamic behavior \nmight be better understood through an ani-\nmated prototype than through textual \ndescription or graphical models. However, a \ndanger of prototyping is that cosmetic issues \nor quality problems with the prototype can \ndistract the reviewers\u2019 attention from the core \nunderlying functionality. Prototypes can also \nbe costly to develop. However, if a prototype \nhelps engineers avoid the waste caused by \ntrying to satisfy erroneous requirements, its \ncost can be more easily justified.\n6.\t Requirements Management Activities \n\b\n[1*, c27-28] [2*, s4.6]\nRequirements development, as a whole, can be \nthought of as \u201creaching an agreement on what \nsoftware is to be constructed.\u201d (See Figure \n1.3.) In contrast, requirements management \ncan be thought of as \u201cmaintaining that agree-\nment over time.\u201d This topic examines require-\nments management. (See also [5, c9].)\n6.1.\t Requirements Scrubbing\nThe goal of requirements scrubbing [22, c14, \nc32] is to find the smallest set of simply stated \nrequirements that will meet stakeholder needs. \nDoing so will reduce the size and complexity of \nthe solution, thus minimizing the effort, cost \nand schedule to deliver it. Requirements scrub-\nbing involves eliminating requirements that:\n\u2022\t are out of scope;\n\u2022\t would not yield an adequate return on \ninvestment;\n\u2022\t are not that important.\nAnother important part of the process \nis to simplify unnecessarily complicated \nrequirements.\nIn waterfall and other plan-based life cycles, \nrequirements scrubbing can be coordi-\nnated with requirements reviews for valida-\ntion; scrubbing should occur just before the \n", "page": 58, "type": "text", "section": "Page 58"}
{"text": "SOFTWARE REQUIREMENTS   1-17\nvalidation review. In Agile life cycles, scrub-\nbing happens implicitly in iteration planning; \nonly the highest-priority requirements are \nbrought into a sprint (iteration).\n6.2.\t Requirements Change Control  \n\b\n[1*, c28] [2*, s4.6]\nChange control is central to managing \nrequirements. This topic is closely linked to the \nSoftware Configuration Management KA. \n(Refer to that chapter for more information.)\nProjects using waterfall or other plan-based \nlife cycles should have an explicit require-\nments change control process that includes:\n\u2022\t a means to request changes to previously \nagreed-upon requirements;\n\u2022\t an optional impact analysis stage to more \nthoroughly examine benefits and costs of \na requested change;\n\u2022\t a responsible person or group who \ndecides to accept, reject, or defer each \nrequested change;\n\u2022\t a means to notify all affected stakeholders \nof that decision;\n\u2022\t a means to track accepted changes \nto closure.\nAll stakeholders must understand and agree \nthat accepting a change means accepting its \nimpact on schedule, resources and/or com-\nmensurate change in scope elsewhere in the \nproject. Ideally the change in scope should be \nobjectively quantifiable, i.e., in terms of  func-\ntional size  units.\nIn contrast, requirements change manage-\nment happens implicitly in Agile life cycles. \nIn these life cycles, any request to change pre-\nviously agreed-upon requirements becomes \njust another item on the product backlog. A \nrequest will only become \u201caccepted\u201d when it \nis prioritized highly enough to make it into an \niteration (a sprint). (See also [5, c9] [22, c17].)\n6.3.\t Scope Matching\nScope matching [22, c14] involves ensuring \nthat the scope of requirements to architect, \ndesign and construct does not exceed any \ncost, schedule or staffing constraints on the \nproject. When requirements scope exceeds \nthe cost, schedule or staffing constraints, \nthen either that scope must be reduced (pre-\nsumably by removing a sufficient number of \nthe lowest-priority requirements), capacity \nmust be increased (by extending the schedule \nor increasing the budget and/or staffing), or \nsome appropriate combination thereof must be \nnegotiated. Where possible, scope matching \nshould be quantitative instead of qualitative, \ni.e., in terms of functional size units.\nIn waterfall and other plan-based life cycles, \nscope matching can be coordinated with \nrequirements validation; the scope matching \nshould occur just before the validation review. \nIn Agile life cycles, as long as some variant of \nvelocity-based sprint planning is done, then the \nonly work allowed into a sprint/iteration will \nbe the work that can reasonably be expected \nto be completed during that sprint/iteration.\n7.\t Practical Considerations\n7.1.\t Iterative Nature of the Requirements \nProcess \b\n[2*, s4.2]\nRequirements for typical software not only \nhave wide breadth; they must also have \nsignificant depth. The tension created by \nsimultaneous breadth-wise and depth-wise \nrequirements in real-world projects often \nprompts teams to perform requirements activ-\nities iteratively. At some points, elicitation \nand analysis favor expanding the breadth of \nrequirements knowledge, while at other points, \nexpanding the depth is called for. In practice, \nit is highly unlikely that all requirements work \ncan be done in a single pass through the sub-\nject matter. (See also [6, c2, c9].)\n7.2.\t Requirements Prioritization \b\n[1*, c16]\nPrioritizing requirements is useful throughout \na software project because it helps focus soft-\nware engineers on delivering the most valuable \nfunctionality soonest. It also helps support \nintelligent \ntrade-off \ndecisions \ninvolving \n", "page": 59, "type": "text", "section": "Page 59"}
{"text": "1-18   SWEBOK \u00ae GUIDE V4.0\nconflict resolution and scope matching. \nPrioritized requirements also help in mainte-\nnance beyond the initial development project \nitself. Defects raised against higher-priority \nrequirements should probably be repaired \nbefore defects raised against lower-pri-\nority ones.\nA variety of prioritization schemes are \navailable. Answering a few key questions can \nhelp engineers choose the best approach. The \nfirst question is \u201cWhat factors are relevant in \ndetermining the priority of one requirement \nover another?\u201d The following factors might be \nrelevant to a project:\n\u2022\t value; desirability; client, customer and \nuser satisfaction;\n\u2022\t undesirability; client, customer and user \ndissatisfaction (Kano model, below);\n\u2022\t cost to deliver;\n\u2022\t cost to maintain over the software\u2019s ser-\nvice life; \n\u2022\t technical risk of implementation;\n\u2022\t risk that users will not use it even if \nimplemented.\nThe Kano model, which underlies [6, c17], \nshows that considering only value, desir-\nability or satisfaction can lead to erroneous \npriorities. A better understanding of priorities \ncomes from considering how unhappy stake-\nholders would be if that requirement were \nnot satisfied. For example, consider a project \nto develop an email client. Two candidate \nrequirements might relate to:\n1.\t Having an effective spam filter\n2.\t Handling attachments on emails\nPrioritization must weigh both the satis-\nfaction users will experience from having cer-\ntain features and the dissatisfaction they will \nexperience if they lack certain features. For \nexample, users are more likely to be happy \nwith an effective spam filter than with the \nability to handle attachments, so the spam \nfilter would be given a higher priority based on \nthe satisfaction criterion. On the other hand, \nthe inability to handle attachments would \nmake many users extremely unhappy \u2014 much \nmore so than not having an effective spam \nfilter. When considering happiness, or satis-\nfaction, from implementing features combined \nwith unhappiness (or dissatisfaction) from not \nimplementing certain features, developers \nwould generally give handling attachments a \nhigher priority than the effective spam filter.\nThe second key question is \u201cHow can we \nconvert the set of relevant factors into an \nexpression of priority?\u201d The formula\nCost\nPriority  = (Value * (1-Risk))\nis just one example of an objective function to \ndo so. The choice of measurement schemes for \nthe relevant factors can impose constraints \non the objective function. (See Measurement \nTheory in Computing Foundations).\nOnce the priority of the requirements has \nbeen determined, those priorities must be \nspecified in a way that can be communicated \nto all stakeholders. Several ways to do this are \npossible, including the following:\n\u2022\t enumerated scale (e.g., must have, should \nhave, nice to have);\n\u2022\t numerical scale (e.g., 1 . . . 10);\n\u2022\t Lists that sort the requirements in \ndecreasing priority order.\nEffective requirement prioritization focuses \non finding groups of requirements with sim-\nilar priorities rather than creating overly rig-\norous measurement scales or debating small \ndifferences.\n7.3.\t Requirements Tracing \b\n[1*, c29]\nRequirements tracing can serve two poten-\ntially useful purposes. One is to serve as an \naccounting exercise that documents consis-\ntency between pairs of related project work \nproducts. An important question might be \n\u201cFor each identified software requirement, \nare there identified design elements intended \nto satisfy it?\u201d If no identified design elements \ncan be found, then either that requirement \nis not satisfied in that design or the design is \n", "page": 60, "type": "text", "section": "Page 60"}
{"text": "SOFTWARE REQUIREMENTS   1-19\ncorrect and one or more stated requirements \ncan be deleted. Similarly, \u201cFor each identified \ndesign element, are there identified require-\nments that cause it to exist?\u201d If no identified \nrequirements can be found, then either that \ndesign element is unnecessary or the stated \nrequirements are incomplete.\nThe other purpose is to assist in impact \nanalysis of a proposed requirement change. \nIf a particular system requirement were to \nchange, for example, that system requirement \ncould be traced to its linked software require-\nments. Not all linked software requirements \nwould need to change. But each software \nrequirement that would be affected could be \ntraced to its linked design elements. Again, \nnot all linked design elements would need \nto change. But each design element affected \ncould be traced to the linked code. The \naffected software requirements, design ele-\nments and code units could also be traced to \ntheir linked test cases for further impact anal-\nysis. This helps establish a \u201cfootprint\u201d for the \nvolume of work needed to incorporate that \nchange to the system requirement.\nSoftware requirements can be traced back \nto source documentation such as system \nrequirements, standards documents and other \nrelevant specifications. Software requirements \ncan also be traced forward to design elements \nand requirements-based test cases. Finally, \nsoftware requirements can also be traced for-\nward to sections in a user manual describing \nthe implemented functionality. (See also [23].)\n7.4.\t Requirements Stability and Volatility  \n\b\n[2*, s4.6]\nSome requirements are very stable; they will \nprobably never change over the software\u2019s ser-\nvice life. Some requirements are less stable; \nthey might change over the service life but \nmight not change during the development \nproject. For example, in a banking applica-\ntion, requirements for functions to calculate \nand credit interest to customers\u2019 accounts \nare likely to be more stable than require-\nments to support different tax-free accounts. \nThe former reflects a banking domain\u2019s \nfundamental feature (that accounts can earn \ninterest). At the same time, the latter may \nbe rendered obsolete by a change in govern-\nment legislation. Finally, some requirements \ncan be very unstable; they can change during \nthe project \u2014 possibly more than once. It is \nuseful to assess the likelihood that a require-\nment will change in a given time. Identifying \npotentially volatile requirements helps the \nsoftware engineer establish a design more tol-\nerant of change, (e.g., [20]). (See also [9, c4].)\n7.5.\t Measuring Requirements \n \b\n[1*, c19]\nAs a practical matter, it may be useful to have \nsome concept of the volume of the require-\nments for a particular software product. \nThis number is useful in evaluating the size \nof a new development project or the size of \na change in requirements and in estimating \nthe cost of development or maintenance tasks \n(e.g., [9, c23]), or simply for use as the denom-\ninator in other measurements. Functional size \nmeasurement (FSM) is a technique for evalu-\nating the size of a body of functional require-\nments. Story points can also be considered a \nmeasure of requirements size. \nAdditional information on size measure-\nment and standards can be found in the \nSoftware Engineering Process KA. \nMany quality indicators have been devel-\noped that can be used to relate the quality of \nsoftware requirements specification to other \nproject variables such as cost, acceptance, \nperformance, schedule and reproducibility. \nQuality indicators for individual software \nrequirements and a requirements specifica-\ntion document as a whole can be derived from \nthe desirable properties discussed in Section \n3.1, Basic Requirements Analysis, earlier \nin this KA.\n7.6.\t Requirements Process Quality and \nImprovement \b\n[1*, c31]\nThis topic concerns assessing the quality and \nimprovement of the requirements process. Its \npurpose is to emphasize the key role of the \n", "page": 61, "type": "text", "section": "Page 61"}
{"text": "1-20   SWEBOK \u00ae GUIDE V4.0\nrequirements process in a software product\u2019s \ncost and timeliness and in customer satisfac-\ntion. Furthermore, it helps align the require-\nments process with quality standards and \nprocess improvement models for software and \nsystems. Process quality and improvement are \nclosely related to both the Software Quality \nKA and Software Engineering Process KA, \ncomprising the following:\n\u2022\t requirements process coverage by process \nimprovement standards and models;\n\u2022\t requirements \nprocess \nmeasures \nand \nbenchmarking;\n\u2022\t improvement \nplanning \nand \nimplementation;\n\u2022\t security/CIA (confidentiality, integrity, \nand availability) improvement/planning \nand implementation.\n8.\t Software Requirements Tools [1*, c30]\nTools that help software engineers deal with \nsoftware requirements fall broadly into three \ncategories: requirements management tools, \nrequirements modeling tools and functional \ntest case generation tools, as discussed below.\n8.1.\t Requirements Management Tools  \n\b\n[1*, c30pp506-510]\nRequirements management tools support var-\nious activities, including storing requirements \nattributes, tracing, document generation and \nchange control. Indeed, tracing and change \ncontrol might only be practical when sup-\nported by a tool. Because requirements man-\nagement is fundamental to good requirements \npractice, many organizations have invested \nin tools. However, many more manage their \nrequirements in more ad hoc and generally \nless satisfactory ways (e.g., spreadsheets). (See \nalso [5, c8].)\n8.2.\t Requirements Modeling Tools  \n\b\n[1*, c30p506] [2*, s12.3.3]\nAt a minimum, a requirements modeling tools \nsupport visually creating, modifying and \npublishing model-based requirements speci-\nfications. Some tools extend that by also pro-\nviding static analysis (e.g., syntax correctness, \ncompleteness and consistency). Formal anal-\nysis requires tool support to be practicable for \nanything other than trivial systems, and tools \ngenerally fall into two categories: theorem \nprovers or model checkers. In neither case \ncan proof be fully automated, and the com-\npetence in formal reasoning needed to use the \ntools restricts the wider formal analysis. Some \ntools also dynamically execute a specification \n(simulation).\n8.3.\t Functional Test Case Generation Tools\nThe more formally defined a requirements \nspecification language is, the more likely it \nis that functional test cases can be at least \npartially derived mechanically. For example, \nconverting BDD scenarios into test cases is \nnot difficult. Another example involves state \nmodels. Positive test cases can be derived \nfor each defined transition in that kind of \nmodel. Negative test cases can be derived \nfrom the state and event combinations that \ndo not appear. (See Section 8.2, Testing \nTools in the Testing KA, for more informa-\ntion.) A process for deriving test cases from \nUML requirements models can be found \nin [9, c12].\nIn the most general case, such tools can \nonly generate test case inputs. Determining \nan expected result is not always possible, \nadditional business domain expertise might \nbe necessary.\n", "page": 62, "type": "text", "section": "Page 62"}
{"text": "SOFTWARE REQUIREMENTS   1-21\nMATRIX OF TOPICS VS. REFERENCE MATERIAL\nWiegers  \n2013\n[1*]\nSommerville  \n2018  \n[2*]\nTockey  \n2005 \n[3*\nWing  \n1990  \n[4*]\n1. \tSoftware Requirements Fundamentals\n1.1. Definition of a Software Requirement\nc1pp5-6\nc4p102\n1.2. Categories of Software Requirements\nc1pp7-12\ns4.1\n1.3. Software Product Requirements and \nSoftware Project Requirements\nc1pp14-15\n1.4. Functional Requirements\nc1p9\ns4.1.1\n1.5. Nonfunctional Requirements\nc1pp10-11\ns4.1.2\n1.6. Technology Constraints\n1.7. Quality of Service Constraints\n1.8. Why Categorize Requirements This Way?\n1.9. System Requirements and Software \nRequirements\n1.10. Derived Requirements\n1.11. Software Requirements Activities\nc1pp15-18\ns4.2\n2.\t Requirements Elicitation\n2.1. Requirements Sources\nc6\ns4.3\n2.2. Common Requirements Elicitation \nTechniques\nc7\ns4.3\n3.\t Requirements Analysis\n3.1. Basic Requirements Analysis\nc8-9\n3.2. Economics of Quality of Service \nConstraints\nc1-27\n3.3. Formal Analysis\ns12.3.2-12.3.3\n3.4. Addressing Conflict in Requirements\n4.\t Requirements Specification\n4.1. Unstructured Natural Language \nRequirements Specification\nc11\ns4.4.1\n4.2. Structured Natural Language \nRequirements Specification\nc8\ns4.4.2\n4.3. Acceptance Criteria-Based Requirements \nSpecification\ns3.2.3, s8.2\n4.4. Model-Based Requirements Specification\nc12\nc5\npp8-11\n4.5. Additional Attributes of Requirements\nc27pp462-463\n4.6. Incremental and Comprehensive \nRequirements Specification\n5. \tRequirements Validation\n5.1. Requirements Reviews\nc17pp332-342\nc4p130\n5.2. Simulation and Execution\n5.3. Prototyping\nc17p342\nc4p130\n", "page": 63, "type": "text", "section": "Page 63"}
{"text": "1-22   SWEBOK \u00ae GUIDE V4.0\n6.\t Requirements Management Activities\n6.1. Requirements Scrubbing\n6.2. Requirements Change Control\nc28\ns4.6\n6.3. Scope Matching\n7.\t Practical Considerations\n7.1. Iterative Nature of the Requirements \nProcess\ns4.2\n7.2. Requirements Prioritization\nc16\n7.3. Requirements Tracing\nc29\n7.4. Requirements Stability and Volatility\ns4.6\n7.5. Measuring Requirements\nc19\n7.6. Requirements Process Quality and \nImprovement\nc31\n8.\t Software Requirements Tools\n8.1. Requirements Management Tools\nc30pp506-510\n8.2. Requirements Modeling Tools\nc30p506\ns12.3.3\n8.3. Functional Test Case Generation Tools\nFURTHER READINGS\nIIBA, A Guide to the Business Analysis Body of \nKnowledge\u00ae (BABOK\u00ae Guide) v3 [30] \nThe BABOK Guide is the reference body of \nknowledge for the Business Analysis commu-\nnity and provides a comprehensive descrip-\ntion of that discipline. While broader than \njust requirements and just for software, a very \nlarge portion of the BABOK Guide content \nis relevant to software requirements.\nP. LaPlante, Requirements Engineering for \nSoftware and Systems [5].\nThis book is one potential alternative to [1*], \noffering a comprehensive discussion of soft-\nware requirements.\nS. Robertson and J. Robertson, Mastering the \nRequirements Process: Getting Requirements \nRight [6].\nThis book is another potential alternative to \n[1*], offering a comprehensive discussion of \nsoftware requirements.\nT. Gilb, Competitive Engineering: A Handbook \nfor \nSystems \nEngineering, \nRequirements \nEngineering, and Software Engineering Using \nPlanguage [7].\nThis book presents a unique perspective on \nrequirements, emphasizing requirements pre-\ncision and completeness along with a strong \nbusiness value-driven motivation.\nK. Wiegers, Software Development Pearls: Lessons \nfrom Fifty Years of Software Experience [21].\nThis book is a compendium of important \nbut often unrecognized key success factors \nbased on Dr. Wiegers\u2019 extensive real-world \nexperience. Chapter 2 is specific to software \nrequirements.\nR. Fisher and W. Ury, Getting to Yes [25].\nThis book is a classic reference on principled \nnegotiation and conflict resolution that serves \nas one good basis for addressing inevitable \n", "page": 64, "type": "text", "section": "Page 64"}
{"text": "SOFTWARE REQUIREMENTS   1-23\nconflict in software requirements when there \nare multiple stakeholders. \nN. Ahmad, Effects of Electronic Communication \non the Elicitation of Tacit Knowledge in \nInterview Techniques for Small Software \nDevelopments [29].\nThis doctoral thesis shows how using four \ndifferent types of electronic communication \ntools to discuss interview agenda details with \ninterviewees before conducting semi-struc-\ntured interviews for requirements elicita-\ntion improved elicitation of tacit (hidden) \nknowledge.\nREFERENCES\n[1*]\tK. E. Wiegers and J. Beatty, Software \nRequirements, 3rd ed., Redmond, WA: \nMicrosoft Press, 2013.\n[2*]\tI. Sommerville, Software Engineering, 10th \ned., New York: Addison-Wesley, 2018.\n[3*]\tS. Tockey, Return on Software: \nMaximizing the Return on Your Software \nInvestment, Boston, MA: Addison-\nWesley, 2005.\n[4*]\tJ. M. Wing, \u201cA Specifier\u2019s Introduction \nto Formal Methods,\u201d Computer, vol. 23, \nno. 9, 1990, pp. 8, 10-23.\n[5]\t P. Laplante and M. Kassab, Requirements \nEngineering for Software and Systems, 4th \ned., Boca Raton, FL: CRC Press, 2022.\n[6]\t S. Robertson and J. Robertson, \nMastering the Requirements Process: \nGetting Requirements Right, Upper \nSaddle River, NJ: Addison-\nWesley, 2013.\n[7]\t T. Gilb, Competitive Engineering: A \nHandbook for Systems Engineering, \nRequirements Engineering, and \nSoftware Engineering Using Planguage, \nOxford, UK: Elsevier Butterworth-\nHeinemann, 2005.\n[8]\t E. Yourdon, Modern Structured Analysis, \nEnglewood Cliffs, NJ: Prentice-\nHall, 1989.\n[9]\t S. Tockey, How to Engineer Software, \nHoboken, NJ: Wiley, 2019.\n[10]\tS. Ambler, Agile Modeling: Effective \nPractices for eXtreme Programming \nand the Unified Process, Hoboken, NJ: \nWiley, 2002.\n[11]\tA. Cockburn, Writing Effective \nUse Cases, Upper Saddle River, NJ: \nAddison-Wesley, 2000.\n[12]\tL. Constantine and L. Lockwood, \nSoftware for Use, Reading, MA: \nAddison-Wesley, 2000.\n[13]\tJ. Wood and D. Silver, Joint Application \nDevelopment, New York, NY: \nWiley, 1995.\n[14]\tE. Gottesdiener, Requirements by \nCollaboration, Boston, MA: Addison-\nWesley, 2002.\n[15]\tJ. Terninko, Step by Step QFD, 2nd ed., \nBoca Raton, FL: CRC Press, 1997.\n[16]\tG. Salvendy, Handbook of Human Factors, \n4th ed., Hoboken, NJ: Wiley, 2012.\n[17]\tT. Brown and B. Katz, Change by \nDesign: How Design Thinking Transforms \nOrganizations and Inspires Innovation, \nRevised and updated ed., New York, \nNY: Harper Collins, 2019.\n[18]\tS. McMenamin and J. Palmer, Essential \nSystems Analysis, New York, NY: \nYourdon Press, 1984.\n[19]\tJ. Smart, BDD in Action: Behavior-\nDriven Development for the Whole \n", "page": 65, "type": "text", "section": "Page 65"}
{"text": "1-24   SWEBOK \u00ae GUIDE V4.0\nSoftware Lifecycle, Shelter Island, NY: \nManning Publications, 2015.\n[20]\tD. Weiss and C. Lai, Software Product-\nLine Engineering: A Family-Based \nSoftware Development Process, Reading, \nMA: Addison-Wesley, 1999.\n[21]\tK. Wiegers, Software Development \nPearls: Lessons from Fifty Years of \nSoftware Experience, Boston, MA: \nAddison-Wesley Professional, 2021.\n[22]\tS. McConnell, Rapid Development, \nRedmond, WA: Microsoft Press, 1996.\n[23]\tO. Gotel and C. W. Finkelstein, \u201cAn \nAnalysis of the Requirements Traceability \nProblem,\u201d presented at the Proceedings \nof the 1st International Conference on \nRequirements Engineering, 1994.\n[24]\tINCOSE, Systems Engineering \nHandbook: A Guide for System Life Cycle \nProcesses and Activities, 3.2.2 ed., San \nDiego, US: International Council on \nSystems Engineering, 2012.\n[25]\t\nR. Fisher and W. Ury, Getting to Yes, 3rd \ned., New York, NY: Penguin, 2011.\n[26]\tISO/IEC/IEEE 29148 \u201cSystems \nand software engineering \u2013 Life \ncycle processes \u2013 Requirements engi-\nneering,\u201d International Standards \nOrganization, 2018.\n[27]\tISO/IEC 25010: \u201cSystem and software \nengineering \u2013 Systems and software \nQuality Requirements and Evaluation \n(SQuaRE) \u2013 System and software \nquality models,\u201d International Standards \nOrganization, 2011.\n[28]\tISO/IEC/IEEE, \u201cISO/IEC/IEEE \n24765:2017 Systems and Software \nEngineering \u2014 Vocabulary,\u201d \n2nd ed. 2017.\n[29]\tN. Ahmad, Effects of Electronic \nCommunication on the Elicitation \nof Tacit Knowledge in Interview \nTechniques for Small Software \nDevelopments, doctoral thesis, \nUniversity of Huddersfield, 2021.\n[30]\tIIBA, A Guide to the Business Analysis \nBody of Knowledge\u00ae (BABOK\u00ae \nGuide) v3, International Institute of \nBusiness Analysis, Toronto, Ontario, \nCanada, 2015.\n", "page": 66, "type": "text", "section": "Page 66"}
{"text": "2-1 \nCHAPTER 02\nSoftware Architecture\nACRONYMS\nAD\nArchitecture Description\nADL\nArchitecture Description Language\nAPI\nApplication Programming Interface\nASR\nArchitecturally Significant \nRequirement\nATAM\nArchitectural Tradeoff Analysis  \nMethod\nIDL\nInterface Description Language\nMVC\nModel View Controller\nQAW\nQuality AttributeWorkshop\nRA\nReference Architecture\nREST\nRepresentational State Transfer\nSAAM\nSoftware Architecture Analysis \nMethod\nUML\nUnified Modeling Language\nINTRODUCTION\nThis chapter considers software architecture \nfrom several perspectives: concepts; repre-\nsentation and work products; context, process \nand methods; and analysis and evaluation.\nIn contrast to the previous edition, this edi-\ntion creates a software architecture knowledge \narea (KA), separate from the Software Design \nKA, because of the significant interest and \ngrowth of the discipline since the 1990s. \nBREAKDOWN OF TOPICS FOR \nSOFTWARE ARCHITECTURE\nThe breakdown of topics for the Software \nArchitecture KA is shown in Figure 2.1.\n1.\t Software Architecture Fundamentals \n\b\n[2*c1-2, 38*c2, 41*c1-3, 29*, 34]\n1.1.\t The Senses of \u201cArchitecture\u201d\b\n[2*c1, 29*]\nSoftware engineering and related disciplines \nuse many senses of \u201carchitecture\u201d. First, \n\u201carchitecture\u201d often refers to a discipline: the \nart and science of constructing things \u2014 in \nthis case, software-intensive systems. The dis-\ncipline involves concepts, principles, processes \nand methods the community has discovered \nand adopted. \nSecond, \u201carchitecture\u201d refers to the various \nprocesses through which that discipline is \nrealized. Software architecture is also consid-\nered part of Software Design; generally con-\nsidered a multistage process, divided into the \nfollowing stages: \n\u2022\t  Architectural design stage \n\u2022\t  High-level design stage \n\u2022\t  Detailed design stage\nSoftware design is the focus of Chapter 3. \nThis chapter focuses on architecting and archi-\ntectural design.\nThird, \u201carchitecture\u201d refers to the out-\ncome of applying architectural design disci-\npline and processes to devise architectures \nfor software systems. Architectures as out-\ncomes are expressed in architecture descrip-\ntions. This is discussed in topic Software \nArchitecture Description. The concept of \narchitecture has evolved, and many defi-\nnitions are in use today. One early defini-\ntion of architecture, from 1990, emphasized \nsoftware structure:\nArchitecture. The organizational struc-\nture of a system or component. [from: IEEE \n", "page": 67, "type": "text", "section": "Page 67"}
{"text": "2-2   SWEBOK \u00ae GUIDE V4.0\nStd 610.12\u20131990, IEEE Glossary of Software \nEngineering Terminology] \nThis definition did not do justice to evolving \nthinking about architecture; e.g., this definition \ndoes not allow us to distinguish the detailed \ndesign of a module from its Makefile. Either \nexample reflects an organizational structure of \nthe software system or component but should \nnot be considered architecture. Moreover, \nemphasis on the structure was often limited to \nthe code\u2019s structure and failed to encompass all \nthe structures of the software system:\nThe software architecture of a system is the \nset of structures needed to reason about the \nsystem. These structures comprise software ele-\nments, relations among them, and properties \nof both. [2*]\nDuring the mid-1990s, however, software \narchitecture emerged as a broader discipline \ninvolving a more generic study of software \nstructures and architectures. Many software \nsystem structures are not directly reflected \nin the code structure. Both types of struc-\nture have implications for the system as a \nwhole: What behaviors is the system capable \nof? What interactions does it have with other \nsystems? How are properties like safety and \nsecurity handled? The recognition that soft-\nware contains many different structures has \nprompted discussion of a number of inter-\nesting concepts about software architecture \n(and software design more generally) leading \nto current definitions such as: \narchitecture (of a system). fundamental con-\ncepts or properties of a system in its environ-\nment embodied in its elements, relationships, \nand in the principles of its design and evo-\nlution [23]\nKey ideas in that definition are the fol-\nlowing: (1)\u00a0 Architecture is about what is \nfundamental to a software system; not every \nelement, interconnection, or interface is con-\nsidered fundamental. (2)\u00a0 Architecture con-\nsiders a system in its environment. Much like \nbuilding architecture, software architec-\nture is outward-looking; it considers a sys-\ntem\u2019s context beyond its boundaries including \nthe people, organizations, software, hard-\nware and other devices with which the system \nmust interact.\nSoftware\nArchitecture\nTe Senses of\n\u201carchitecture\u201d\nArchitecture\nViews and \nViewpoints\nArchitecture\nin Context\nGoodness in\nArchitecture\nReasoning \nabout\nArchitectures\nArchitecture\nReviews\nArchitecture\nMetrics\nArchitectural\nDesign\nArchitecture\nMethods and \nTactics\nArchitecture\nin the Large\nArchitecture\nStyles and \nPatterns\nArchitecture\nDescription\nLanguages and\nArchitecture\nFramework\nArchitecture \nas Signifcant \nDecisions \nStakeholders \nand Concerns\nUses of \nArchitecture\nSoftware\nArchitecture\nDescription\nSoftware\nArchitecture\nFundamentals\nSoftware\nArchitecture\nProcess\nSoftware\nArchitecture\nEvaluation\nFigure 2.1. Breakdown of Topics for the Software Architecture KA\n", "page": 68, "type": "text", "section": "Page 68"}
{"text": "SOFTWARE ARCHITECTURE   2-3\n1.2.\t Stakeholders and Concerns \n\b\n[2*c3-14, 38*c8-9, 41*c3, 12, 23, 24]\nA software system has many stakeholders with \nvarying roles and interests relative to that \nsystem. These varying interests are termed con-\ncerns, following Dijkstra\u2019s separation of concerns: \nLet me try to explain to you, what to my taste \nis characteristic for all intelligent thinking. \nIt is, that one is willing to study in depth an \naspect of one\u2019s subject matter in isolation for \nthe sake of its own consistency, all the time \nknowing that one is occupying oneself only \nwith one of the aspects. We know that a pro-\ngram must be correct and we can study it from \nthat viewpoint only; we also know that it \nshould be efficient and we can study its effi-\nciency on another day, so to speak. In another \nmood we may ask ourselves whether, and if so: \nwhy, the program is desirable. But nothing is \ngained \u2014 on the contrary! \u2014 by tackling these \nvarious aspects simultaneously. It is what I \nsometimes have called \u201cthe separation of con-\ncerns\u201d, which, even if not perfectly possible, is \nyet the only available technique for effective \nordering of one\u2019s thoughts, that I know of. This \nis what I mean by \u201c[focusing] one\u2019s attention \nupon some aspect\u201d: it does not mean ignoring \nthe other aspects, it is just doing justice to the \nfact that from this aspect\u2019s point of view, the \nother is irrelevant. It is being one- and multi-\nple-track-minded simultaneously. [12]\nWhat is fundamental about a system varies \naccording to stakeholders\u2019 concerns and roles. \nThe software structures, therefore, also vary \nwith stakeholder roles and concerns. (See also \ntopic Design Methods in Software Design KA.)\nA software system\u2019s customer is most inter-\nested in when the system will be ready and \nhow much it will cost to build and operate. \nUsers are most interested in what it does and \nhow to use it. Designers and programmers \nbuilding the system have their own concerns, \nsuch as whether an algorithm will meet the \nsystem requirements. Those responsible for \nensuring the system is safe to operate have dif-\nferent concerns.\nConcerns encompass a broad range of \nissues, possibly pertaining to any influence on \na system in its environment, including devel-\nopmental, technological, business, opera-\ntional, organizational, political, economic, \nlegal, regulatory, ecological and social influ-\nences. Like software requirements, they may \nbe classified as functional, non-functional \nor constraint. (See Software Requirements \nKA.) Concerns manifest in various familiar \nforms, including requirements, quality attri-\nbutes or \u201cilities\u201d, emergent properties (which \nmay be either desired or prohibited) and var-\nious kinds of constraints (as listed above). \nSee Software Quality KA. Topic 2, Software \nArchitecture Description, shows how concerns \nshape architecture and the work products \ndescribing those architectures. Example \nof concerns are depicted in Figure 2.2. \nConcerns are not static; concerns evolve over \nthe life cycle of a system and as technolo-\ngies, policies and other influences evolve. \nFor example, due to increased awareness of \nclimate change, there is growing interest in \nconcerns such as energy efficiency, and sus-\ntainability [24].\nFigure 2.2. Examples of Architectural Concerns\naffordability, agility, assurance, autonomy, \navailability, behavior, business goals and \nstrategies, complexity, compliance with regu-\nlation, concurrency, control, cost, data acces-\nsibility, deployability, disposability, energy \nefficiency, evolvability, extensibility, feasi-\nbility, flexibility, functionality, information \nassurance, \ninter-process \ncommunication, \ninteroperability, known limitations, main-\ntainability, modifiability, modularity, open-\nness, performance, privacy, quality of service, \nreliability, resource utilization, reusability, \nsafety, scalability, schedule, security, system \nmodes, software structure, subsystem inte-\ngration, sustainability, system features, test-\nability, usability, usage, user experience\n", "page": 69, "type": "text", "section": "Page 69"}
{"text": "2-4   SWEBOK \u00ae GUIDE V4.0\n1.3.\t Uses of Architecture \n\b\n[2*c24, 38*c30, 23, 11, 28]\nA principal use of a software system\u2019s archi-\ntecture is to give those working with it a \nshared understanding of the system to guide \nits design and construction. An architec-\nture also serves as a preliminary conception \nof the software system that provides a basis \nto analyze and evaluate alternatives. A third \ncommon usage is to enable reverse engi-\nneering (or reverse architecting) by helping \nthose working with it to understand an \nexisting software system before undertaking \nmaintenance, enhancement or modification. \nTo support these uses, the architecture should \nbe documented (see topic Software Architecture \nDescription).\nConway\u2019s Law posits that \u201corganizations \nwhich design systems . . . are constrained to \nproduce designs which are copies of the com-\nmunication structures of these organiza-\ntions\u201d [11]. Empirical studies have observed \nthat the architectures of these systems often \nmirror the communications structures of \nthose organizations [28]. Depending on the \nsoftware system and the organization, this \ncan be a strength or a weakness. The archi-\ntecture can enhance communication within a \nlarge team or compromise it. Each part of the \norganization can base its planning, costing \nand scheduling activities upon its knowledge \nof the architecture. Creating a well-planned \nand documented architecture is one approach \nto increasing the applicability and reusability \nof software designs and components. The \narchitecture forms the basis for design fam-\nilies of programs or software product lines. \nThis can be done by identifying commonali-\nties among members of such families and by \ndesigning reusable and customizable com-\nponents to account for the variability among \nfamily members. \n2.\t Software Architecture Description \n\b\n[2*c22, 38*, 40*c6, 41*c6-7, 9,23,25]\nIn topic 1, Software Architecture Fundamentals, \na software architecture was defined as the \nfundamental concepts or properties of a soft-\nware system in its environment. But each \nstakeholder can have a different notion of \nwhat is fundamental to that software system, \ngiven their perspective. Having a mental \nmodel of a system\u2019s architecture is perhaps \nfine for small systems and for individuals \nworking alone. However, for large, complex \nsystems developed and operated by teams, a \ntangible representation is invaluable, espe-\ncially as the conception of the system evolves, \nand as people join or leave the team. Having a \nconcrete representation as a work product can \nalso serve as a basis to analyze the architec-\nture, organize its design and guide its imple-\nmentation. These work products are called \narchitecture descriptions (ADs).\nADs document an architecture for a soft-\nware system. It is targeted to those stake-\nholders of the system who have concerns about \nthe software system which are answered by \nthe architecture. As noted in topic 1, Software \nArchitecture Fundamentals, a primary audi-\nence comprises the designers, engineers and \nprogrammers whose concerns pertain to con-\nstructing the system. For these stakeholders, \nADs serve as a blueprint to guide the con-\nstruction of the software system. For others, \nthe AD is a basis for their work\u2014for example, \ntesting and quality assurance, certification, \ndeployment, operation, and maintenance and \nfuture evolution. \nHistorically, ADs used text and informal \ndiagrams \nto \nconvey \nthe \narchitecture. \nHowever, the diversity of stakeholder audi-\nences and their different concerns have led to \na diversity of representations of the architec-\nture. Notations should be chosen based on the \nneed, purpose and the utility of those choices \n(such as understandability, familiarity) for \nthe stakeholders who need that information. \nOften, these representations are specialized \nbased upon existing practices of the com-\nmunities or disciplines involved to effectively \naddress this variety of stakeholders and con-\ncerns (see Software Design KA and Software \nEngineering Models and Methods KA). \nThese various representations are called archi-\ntecture views. \n", "page": 70, "type": "text", "section": "Page 70"}
{"text": "SOFTWARE ARCHITECTURE   2-5\n2.1.\t Architecture Views and Viewpoints \b\n[6*c7, 38*c3,c15-23, 40*c6.2, 23]\nAn architecture view represents one or more \naspects of an architecture to address one or \nmore concerns [38*]. Views address distinct \nconcerns \u2014 for example, a logical view (depicts \nhow the system will satisfy the functional \nrequirements); a process view (depicts how the \nsystem will use concurrency); a physical view \n(depicts how the system is to be deployed and \ndistributed) and a development view (depicts \nhow the top-level design is broken down \ninto implementation units, the dependencies \namong those units and how the implementa-\ntion is to be constructed). Separating concerns \nby view allows interested stakeholders to focus \non a few things at a time and offers a means of \nmanaging the architecture\u2019s understandability \nand overall complexity. \nArchitecture practice has evolved from the \nuse of text and informal diagrams to the use \nof more rigorous representations. Each archi-\ntecture view depicts architectural elements of \nthe system using well-defined conventions, \nnotations and models [38*]. The conventions \nfor each view are documented as an architec-\nture viewpoint [23]. Viewpoints guide the cre-\nation, interpretation and uses of architecture \nviews. Each viewpoint links stakeholder audi-\nence concerns with a set of conventions. In \nmodel-based architecting, each view can be \nmachine-checked against its viewpoint.\nCommon viewpoints include the module \nviewpoint, used to express a software system\u2019s \nimplementation in terms of its modules and \ntheir organization [2*]; the component and \nconnector viewpoint, used to express the soft-\nware\u2019s large-scale runtime organization and \ninteractions [2*]; the logical viewpoint, used \nto express fundamental concepts of the soft-\nware\u2019s domain and capability [25]; the sce-\nnarios/use cases viewpoint, used to express \nhow users interact with the system [25]; the \ninformation viewpoint, used to express a sys-\ntem\u2019s key information elements and how they \nare accessed and stored [38*]; and the deploy-\nment viewpoint, used to express how a system \nis configured and deployed for operation [38*]. \nOther documented viewpoints include view-\npoints for availability, behavior, communi-\ncations, exception handling, performance, \nreliability, safety and security.\nEach viewpoint provides a vocabulary or \nlanguage for talking about a set of concerns \nand the mechanisms for addressing them. \nThe viewpoint language gives stakeholders \na shared means of expression. Viewpoints \nneed not be limited to one software system \nbut are reusable by an organization or appli-\ncation community for many similar systems. \nWhen generic representations such as Unified \nModeling Language (UML) are used, they \ncan be specialized to the system, its domain \nor the organizations involved. (See section \n2.3 Architecture Description Languages and \nArchitecture Frameworks.)\nBeyond specifying forms of representation, \nan architecture viewpoint can capture the \nways of working within a discipline or com-\nmunity of practice. For example, a software \nreliability viewpoint captures existing prac-\ntices from the software reliability community \nfor identifying and analyzing reliability issues, \nformulating alternatives and synthesizing \nand representing solutions. Like engineering \nhandbooks, general-purpose and special-\nized viewpoints provide a means to document \nrepeatable or reusable approaches to recurring \nsoftware issues. Clements et al. have intro-\nduced viewtypes which establish a 3-way cat-\negorization of viewpoints. These categories are \nmodule, component and connector, and allo-\ncation viewtypes [9].\nArchitecture descriptions frequently use \nmultiple architecture views to represent the \ndiverse structures needed to address different \nstakeholders\u2019 various concerns. There are two \ncommon approaches to the construction of \nviews: the synthetic approach and the projective \napproach. In the synthetic approach, architects \nconstruct views of the system-of-interest and \nintegrate these views within an architecture \ndescription using correspondence rules. In \nthe projective approach, an architect derives \neach view through some routine, possibly \nmechanical, procedure of extraction from a \nsingle unified model (or \u201cuber model\u201d) [23]. \n", "page": 71, "type": "text", "section": "Page 71"}
{"text": "2-6   SWEBOK \u00ae GUIDE V4.0\nA consequence of introducing multiple views \ninto an AD is a potential mismatch between \nthe views. Are they consistent? Are they \ndescribing the same system? This has been \ncalled the multiple views problem [39]. The \nprojective approach limits possible inconsis-\ntencies, since views are derived from a single \n(presumably consistent) model, but at the cost \nof expressiveness: the underlying model may \nnot be capable of capturing arbitrary concerns. \nUnder the synthetic approach, architects inte-\ngrate views into a whole, using linkages or \nother forms of traceability to cross-refer-\nence view elements to achieve consistency \n[23,25]. Viewpoints often include rules for \nestablishing consistency or other relationships \namong views.\n2.2.\t Architecture Patterns, Styles and Reference \nArchitectures\b\n[6*c6,38*c11, 40*c6.3, \n \n\b\n41*c11, 7, 9, 10c2, 13, 17, 18, 19, 37\nInspired by its use in the long history of the \narchitecture of buildings, an architectural style \nis a particular manner of construction yielding \na software system\u2019s characteristic features. An \narchitectural style often expresses a software \nsystem\u2019s large-scale organization. In contrast, \nan architectural pattern expresses a common \nsolution to a recurring problem within the \ncontext of a software system\u2014it need not \napply to the whole system. Design patterns \nare discussed in section 4.4 of Software \nDesign KA.\nVarious architectural styles and patterns \nhave been documented [7,39]: \n\u2022\t General structures (e.g., layered, call-\nand-return, pipes and filters, blackboard, \nservices and microservices) \n\u2022\t Distributed systems (e.g., client-server, \nn-tier, \nbroker, \npublish-subscribe, \npoint-to- \npoint, representational state transfer \n \n(REST)) \n\u2022\t Method-driven (e.g., object-oriented, \nevent-driven, data flow)\n\u2022\t User-computer interaction (e.g., model- \nview-controller, presentation-abstraction- \ncontrol) \n\u2022\t Adaptive systems (e.g., microkernel, \nreflection and meta-level architectures) \n\u2022\t Virtual machines (e.g., interpreters, rule-\nbased, process control) \nPattern catalogs (or systems of patterns) are \nused to express architectural styles and solu-\ntions through coordinated sets of patterns. \nExamples of pattern catalogs are [7], [19] for \nn-tier architectures, [13] for service-oriented \narchitecture and [37] for microservice architec-\ntures. Pattern catalogs are not limited to archi-\ntecture styles and can be focused on addressing \nspecific concerns, such as security [17].\nThere is no strict dividing line between \narchitectural styles and patterns. Both pat-\nterns and styles provide solutions to specific \nproblems in given contexts. An architectural \nstyle expresses the global aspects of a system \nor subsystem by defining its  major parts of \nthat (sub)system and how they interact [7,38*]. \nAn architectural style can be expressed as an \narchitectural pattern [7]. Architectural pat-\nterns exist at varying scales and could apply \nonce to a single element of a system or be \napplied repeatedly throughout a system.\nIn relation to architecture viewpoints, \nwhich provide the languages for talking about \nvarious aspects of software systems, a uni-\nfying notion is that both patterns and styles are \nidioms in those languages for expressing partic-\nular aspects of architectures (and designs, see \nsection 4.4 Design Patterns in Software Design \nKA). An architectural pattern or style uses a \nvocabulary, drawn from the viewpoint\u2019s lan-\nguage, in a specified way, to talk about view \nelements, including element and relation types \nand their instances, and constraints on com-\nbining them [23,39]. In this way, viewpoints, \npatterns and styles are mechanisms for codi-\nfying recommended practices to facilitate reuse.\nA reference architecture (RA) is an architec-\nture constraining or guiding other architec-\ntures. Documented as a reference architecture \ndescription, an RA provides a common basis \nfor the \u00a0development of architectures for indi-\nvidual systems, product lines or families of \nsystems and application domains. Reference \narchitectures \ncapture \ncommonalities \nto \n", "page": 72, "type": "text", "section": "Page 72"}
{"text": "SOFTWARE ARCHITECTURE   2-7\npromote ease of development, integration \nand interoperability and other kinds of stan-\ndardization. Reference architectures have \nbeen developed and used in many domains \nincluding automotive systems, healthcare, \nInternet of Things, cloud computing, avionics, \nmanufacturing and telecommunications.\n2.3.\t Architecture Description Languages and \nArchitecture Frameworks\b\n[2*c22, \b\n41*c6-7, 23,30]\nAn architecture description language (ADL) \nis a domain-specific language for expressing \nsoftware architectures. ADLs arose from \nmodule interconnection languages [36] for \nprogramming in the large. Some ADLs target \na single application domain or architectural \nstyle (such as MetaH for avionics systems in \nan event-driven style), others are wide spec-\ntrum to frame concerns across the enterprise \n(such as ArchiMate\u2122). UML has frequently \nbeen used as an ADL due to its widespread \nuse in software design activities [41*]. ADLs \noften provide capabilities beyond descrip-\ntion to enable architecture analysis or code \ngeneration.\nAn architecture framework captures the \n\u201cconventions, principles and practices for the \ndescription of architectures established within \na specific domain of application and/or com-\nmunity of stakeholders\u201d [23]. Frameworks \ncodify recommended practices within a spe-\ncific domain and are implemented as an inter-\nlocking set of viewpoints or ADLs. Examples \nare AUTOSAR for the automotive industry, \nOMG\u2019s Unified Architecture Framework \n(UAF\u00ae) and ISO Reference Model for Open \nDistributed Processing.\n2.4.\t Architecture as Significant Decisions \b\n[38*c8, 40*c6.1, 1, 23, 26]\nArchitectural design is a creative process. \nDuring this activity, architects make many \ndecisions that profoundly affect the archi-\ntecture, the downstream development pro-\ncess and the software system. Many factors \naffect decision-making, including prominent \nconcerns of stakeholders for the software \nsystem, its requirements, and the available \nresources during development and throughout \nthe life cycle. The impact on quality attributes \nand trade-offs among competing quality attri-\nbutes are often the basis for design decisions.\nThe architectural design activity creates \na network of decisions as its outcome, with \nsome decisions deriving from prior decisions. \nDecision analysis provides one approach to \narchitecture evaluation. Decisions can be \nexplicitly documented, along with an explana-\ntion of the rationale for each nontrivial deci-\nsion. Decision analysis provides one approach \nto architecture evaluation. (See topic 4, \nSoftware Architecture Evaluation.)\nArchitecture rationale captures why an archi-\ntectural decision was made. This includes \nassumptions made before the decision, alter-\nnatives considered, and trade-offs or criteria \nused to select an approach and reject others. \nRecording rejected decisions and the rea-\nsons for their rejection can also be useful. In \nthe future, this could either prevent a soft-\nware project from making a poor decision\u2014\none rejected earlier for forgotten reasons\u2014or \nallow the development to recognize that rel-\nevant conditions have changed and that they \ncan revisit the decision. \nArchitectural technical debt has been intro-\nduced to reflect that today\u2019s decisions for \nan architecture may have significant con-\nsequences later in the software system\u2019s life \ncycle. Decisions deferred can compromise \nits maintainability or the future evolvability, \nand that debt will have to be paid\u2014typ-\nically by others, not necessarily by those \nwho caused the debt. Such debt has an eco-\nnomic impact on the system\u2019s future devel-\nopment and operations. For example, when \na software project has limited time, it may \ndevelop an initial design with little concern \nfor modularity for its first release. The lack \nof modularity can adversely affect the devel-\nopment time for subsequent releases, impact \ndevelopers, and perhaps compromise future \nmaintainability of the system. Additional \nfunctionality can be added later only by doing \nextensive refactoring which impacts future \n", "page": 73, "type": "text", "section": "Page 73"}
{"text": "2-8   SWEBOK \u00ae GUIDE V4.0\ntimelines and introduces additional defects. \n[26]. Architectural technical debt can be ana-\nlyzed and managed, like other concerns, using \nmodels and viewpoints [27]. \n3.\t Software Architecture Process \n\b\n[38*c7, 41*c4, 14,42]\nThis section outlines a general model of an \narchitectural design process. It is used to \ndemonstrate how architectural design fits into \nthe general context of software engineering \nprocesses (see Software Engineering Process \nKA) and as a framework for understanding the \nmany architecture methods currently in use. It \nalso recognizes that architectural design can \ntake place in a variety of contexts.\n3.1.\t Architecture in Context\b\n[41*c2, 29*]\nArchitecture occurs in several contexts. In \nthe traditional life cycle, there is an architec-\ntural design stage driven by software system \nrequirements (see Software Requirements \nKA). Some requirements will be architectural \ndrivers, influencing major decisions about the \narchitecture, while other requirements are \ndeferred to subsequent stages of the software \nprocess, such as design or construction.\nIn product line or product family settings, \na product line/family architecture is devel-\noped against a basic set of needs, requirements \nand other factors. That architecture will be the \nstarting point for one or more product instances \ndeveloped against specific product require-\nments, building upon the product baseline.\nIn agile approaches, there is not usually an \narchitecture design stage. The only architec-\nture description might be the code itself. In \nsome agile practices, the software architecture \nis said to \u201cemerge\u201d from coding the system \nbased on user stories through a rapid series of \ndevelopment cycles. Although this approach \nhas had some success with user-centric \ninformation systems, it is difficult to ensure \nan adequate architecture emerges for other \nclasses of applications, such as embedded and \ncyber-physical systems, when critical archi-\ntectural properties might not be articulated \nby any user stories.\nIn enterprise and system-of-systems con-\ntexts, as in product lines and families, the \nFigure 2.3. A general model of architectural design\n", "page": 74, "type": "text", "section": "Page 74"}
{"text": "SOFTWARE ARCHITECTURE   2-9\noverarching architecture (of the enterprise, \nsystem or product line/family) provides pri-\nmary requirements and guidance on the form \nand constraints upon the software architec-\nture. This baseline can be enforced through \nspecifications, additional requirements, appli-\ncation programming interfaces (APIs) or con-\nformance suites.\n3.1.1.\t Relation of Architecture to Design\nDesign and architecture are often blurred. It \nhas been said that architecture is the set of \ndecisions that one cannot trust to  designers. \nIn fact, architecture emerged out of software \ndesign as the discipline matured, largely since \nthe 1990s. There are various contrasts: design \noften focuses on an established set of require-\nments, whereas architecture often must shape \nthe requirements through negotiation with \nstakeholders and requirements analysis. In \naddition, architecture often must recognize \nand address a wider range of concerns that \nmay or may not end up as requirements on the \nsoftware system of interest.\n3.2.\t Architectural Design\b\n[2*c20, 20]\nArchitectural design is the application of \ndesign principles and methods within a \nprocess to create and document a software \narchitecture. There are many architecture \nmethods for carrying out this activity. This \nsection describes a general model of architec-\ntural design underlying various architecture \nmethods based upon [20].\nArchitectural design involves identifying a \nsystem\u2019s major components; their responsibil-\nities, properties, and interfaces; and the rela-\ntionships and interactions among them and \nwith the environment. In architectural design, \nfundamentals of the system are decided, but \nother aspects, such as the internal details of \nmajor components are deferred.\nTypical concerns in architectural design \ninclude the following:\n\u2022\t Overall architecture styles and com-\nputing paradigms\n\u2022\t Large-scale refinement of the system into \nkey components\n\u2022\t Communication and interaction among \ncomponents\n\u2022\t Allocation of concerns and design \nresponsibilities to components\n\u2022\t Component interfaces\n\u2022\t Understanding and analysis of scaling \nand performance properties, resource \nconsumption properties, and reliability \nproperties\n\u2022\t Large-scale/system-wide approaches to \ndominating concerns (such as safety and \nsecurity, where applicable)\nAn overview of architectural design is pre-\nsented in Figure 2.3.\nArchitectural design is iterative, com-\nprising three major activities: analysis, syn-\nthesis and evaluation. Often, all three major \nactivities are performed concurrently at var-\nious levels of granularity.\n3.2.1.\t Architecture Analysis\nArchitecture analysis gathers and formulates \narchitecturally significant requirements (ASRs), \ndefined as any \u2018\u2018requirement upon a software \nsystem which influences its architecture\u2019\u2019 [31]. \nArchitecture analysis is based on identified \nconcerns and on understanding the software\u2019s \ncontext, including known requirements, \nstakeholder needs and the environment\u2019s con-\nstraints. ASRs reflect the design problems \nthe architecture must solve. Often the com-\nbination of initial requirements and known \nconstraints cannot be satisfied without conse-\nquences to cost, schedule, etc. In such cases, \nnegotiation is used to modify incoming needs, \nrequirements and expectations to make solu-\ntions possible. Architecture analysis produces \nASRs, initial system-wide decisions and any \noverarching system principles derived from \nthe context (see Architecture in Context).\n3.2.2.\t Architecture Synthesis\nArchitecture synthesis develops candidate \nsolutions in response to the outcomes of \n", "page": 75, "type": "text", "section": "Page 75"}
{"text": "2-10   SWEBOK \u00ae GUIDE V4.0\narchitecture analysis. Synthesis proceeds by \nworking out detailed solutions to design prob-\nlems identified by ASRs, and makes trade-\noffs to accommodate interactions between \nthose solutions. These outcomes feedback to \narchitecture analysis resulting in elaborated \nASRs, principles and decisions which then \nlead to further detailed solution elements.\n3.2.3.\t Architecture Evaluation\nArchitecture evaluation validates whether the \nchosen solutions satisfy ASRs and when and \nwhere rework is needed. Architecture evalua-\ntion methods are discussed in topic 4 Software \nArchitecture Evaluation.\n3.3.\t Architecture Practices, Methods, and Tactics \n\b\n[2*c19-23, 38*c9-14, 5, 8, 14, 15, \n \n\b\n16, 21, 25, 35]\nThere are a number of documented architec-\nture methods (see Further Readings for a list).\n3.4.\t Architecting in the Large\b\n[29*]\nArchitectural design denotes a specific stage \nof the life cycle, but is only one part of soft-\nware architecting. Software architecting does \nnot occur in a vacuum, as noted in section 3.1 \nArchitecture in Context, but in an environment \nthat often includes other architectures. For \nexample, an application architecture should \nconform to an enterprise architecture; to \u201cplay \nwell\u201d in a system of systems, the architecture of \neach constituent system should conform to the \nsystem of systems architecture. In such cases, \nthese relations need to be reflected as ASRs on \nthe software being architected. Many software \narchitecting activities and principles are not \nlimited to software but equally apply to systems \nand enterprise architecting [29]. Weinreich \nand Buchgeher have extended Hofmeister \net al.\u2019s model used in section 3.2 Architectural \nDesign to include these activities [42]:\n\u2022\t architecture implementation: \noverseeing \nimplementation and certifying that imple-\nmentations conform to the architecture\n\u2022\t architecture maintenance: managing and \nextending the architecture following its \nimplementation\n\u2022\t architecture management: managing an \norganization\u2019s portfolio of interrelated \narchitectures\n\u2022\t architecture \nknowledge \nmanagement: \nextracting, maintaining, sharing and \nexploiting reusable architecture assets, \nincluding decisions, lessons learned, \nspecifications and documentation across \nthe organization\n4.\t Software Architecture Evaluation \n\b\n[2*c21, 38*c14, 41*c8, 10, 31, 33]\n4.1.\t \u201cGoodness\u201d in Architecture \n\b\n[2*c2, 3, 10, 31]\nArchitecture analysis takes place throughout \nthe process of creating and sustaining an \narchitecture. Architecture evaluation is typ-\nically undertaken by third parties at deter-\nmined milestones as a form of assessment.\nGiven the multi-concern, multi-disci-\nplinary nature of software architecture, there \nare many aspects to what makes an architecture \n\u201cgood.\u201d The Roman architect Vitruvius posited \nthat all buildings should have the attributes of \nfirmitas,\u00a0utilitas and venustas (translated from \nLatin as strength, utility and beauty). \nOf a software system and its architecture, \none can ask:\n\u2022\t Is it robust over its lifetime and possible \nevolution?\n\u2022\t Is it fit for its intended use? \n\u2022\t Is it feasible and cost-effective to construct \nsoftware systems using this architecture? \n\u2022\t Is it, if not beautiful, then at least clear \nand understandable to those who must \nconstruct, use and maintain the software? \nEach architecture concern may be a basis \nfor evaluation. Evaluation is conducted against \nrequirements (when available) or against need, \nexpectations and norms (in other situations). \nA \u201cgood\u201d architecture should address not only \nthe distinct concerns of its stakeholders, but \n", "page": 76, "type": "text", "section": "Page 76"}
{"text": "SOFTWARE ARCHITECTURE   2-11\nalso the consequences of their interactions. \nFor example, a secure architecture may be \nexcessively costly to build and verify; an easy-\nto-build architecture may not be maintainable \nover the system\u2019s lifetime if it cannot incorpo-\nrate new technologies. \nThe Architecture Tradeoff Analysis Method \n(ATAM) [10] provides a methodical approach \nto evaluating software architectures based on \nquality attributes in a utility tree (provide illus-\ntration) and scenarios illustrating the quali-\nties. Analysis of tradeoffs among competing \nquality requirements and their architectural \napproaches are the key to the architecture \nevaluation. Clements, et al. describe several \nmethods for evaluation including ATAM, \nSoftware Architecture Analysis Method \n(SAAM), and Quality Attribute Workshops \n(QAW) [10]. The SARA Report defines a \ngeneral framework for software architecture \nevaluation [31].\n4.2.\t Reasoning about Architectures \n\b\n[38*c10, 3, 10, 31]\nEach architecture concern has a distinct basis \nfor evaluation. Evaluation is most effective \nwhen it is based upon robust, existing archi-\ntecture descriptions. ADs can be queried, \nexamined and analyzed. For example, eval-\nuation of functionality or behavior benefits \nfrom having an explicit architecture view \nor other representation of that aspect of the \nsystem to study. Specialized concerns such as \nreliability, safety and security often rely on \nspecialized representations from the respec-\ntive discipline.\nOften architecture documentation is unfin-\nished, incomplete, out of date or nonexistent. \nIn such cases, the evaluation effort must rely \non the knowledge of participants as a primary \ninformation source. \nUse cases are frequently used to check \nan architecture\u2019s completeness and consis-\ntency (see Software Engineering Models and \nMethods KA) by comparing the steps in the \nuse case to the software architecture elements \nthat would be involved in carrying out those \nsteps [23].\nFor a general framework for reasoning \nabout various concerns, see Bass et al. [3].\n4.3.\t Architecture Reviews\b\n[2*c21, 1, 31]\nArchitecture reviews are an effective approach \nto assess an architecture\u2019s status and quality \nand identify risks by assessing one or more \narchitecture concerns [1]. Many reviews are \ninformal or expertise-based, and some are \nmore structured, organized around a checklist \nof topics to cover. Parnas and Weiss proposed \nan effective approach to conducting reviews, \ncalled active reviews [33], where instead of \nchecklists, each evaluation item entails a \nspecific activity by a reviewer to obtain the \nneeded information.\nMany organizations have institution-\nalized architecture review practices. For \nexample, an industry group developed a \nframework for defining, conducting and \ndocumenting architecture reviews and their \noutcomes [31].\n4.4.\t Architecture Metrics\b\n[2*c23]\nAn architecture metric is a quantitative mea-\nsure of a characteristic of an architecture. \nVarious architecture metrics have been \ndefined. Many of these originated as design or \ncode metrics that have been \u201clifted\u201d to apply \nto architecture. Metrics include component \ndependency, cyclicity and cyclomatic com-\nplexity, internal module complexity, module \ncoupling and cohesion, levels of nesting, and \ncompliance with the use of patterns, styles \nand (required) APIs.\nIn continuous development paradigms \n(such as DevOps), other metrics have evolved \nthat focus not on the architecture directly but \non the responsiveness of the process, such as \nmetrics for lead time for changes, deployment \nfrequency, mean time to restore service, and \nchange failure rate\u2014as indicative of the state \nof the architecture.\n", "page": 77, "type": "text", "section": "Page 77"}
{"text": "2-12   SWEBOK \u00ae GUIDE V4.0\nMATRIX OF TOPICS VS. REFERENCE MATERIAL\ncX refers to chapter X\nBass \net al. [2*]\nBudgen \n \n[6*]\nRozanski \n \nWoods  \n[38*]\nSommerville \n \n[40*]\nTaylor  \net al. \n[41*]\nSee also\nSoftware \nArchitecture \nFundamentals\nc1-2\nc2\nc1-3\n[29*,34]\nThe senses of \n\u201carchitecture\u201d\nc1\n[29*]\nStakeholders \nand Concerns\nc3-14\nc8-9\nc3\n[12,23,24]\nUses of Architecture\nc24\nc30\n[23,11,28]\nSoftware \nArchitecture \nDescription\nc22\nall\nc6\nc6-7\n[9,23,25]\nArchitecture Views \nand Viewpoints\nc7\nc3,c15-23\nc6.2\n[23]\nArchitectural Styles \nand Patterns\nc6\nc11\nc6.3\nc11\n[7,9,10c2,13, \n17,18,19,37]\nArchitecture \nDescription \nLanguages and \nArchitecture \nFrameworks\nc22\nc6-7\n[23,30]\nArchitecture as \nSignificant Decisions\nc8\nc6.1\n[1,23,26]\nArchitecture  \nProcesses\nc7\nc4\n[14,42]\nArchitecture \nin Context\nc2\n[29*]\nArchitectural Design\nc20\n[20]\nArchitecture \nMethods and Tactics\nc19-23\nc9-14\n[5,8,14,15,16,\n21,25,35] \nArchitecting \nin the Large\n[29*]\nArchitecture \nEvaluation\nc21\nc14\nc8\n[10,31,33]\n\u201cGoodness\u201d in \nArchitecture\nc2\n[3,10,31]\nReasoning about \nArchitectures\nc10\n[3,10,31]\nArchitecture Reviews\nc21\n[1,31]\nArchitecture Metrics\nc23\n", "page": 78, "type": "text", "section": "Page 78"}
{"text": "SOFTWARE ARCHITECTURE   2-13\nFURTHER READINGS\nPerry and Wolf, Foundations for the study of \nsoftware architecture [34]\nPerry and Wolf\u2019s Foundations circulated infor-\nmally for several years before its publication in \n1992. It has indeed served as a foundation the \nevolution of the discipline of software archi-\ntecture, introducing a number of ideas that are \nfundamental to the field, including architec-\nture as a discipline; distinguishing architecture \nand design; elements of software architectures; \nmultiple views; architecture styles and types; \nand analogies with other fields.\nBass et al., Software Architecture in Practice [2*]\nThis book introduces concepts and recom-\nmended practices of software architecture, \nmeaning how software is structured and how \nthe software\u2019s components interact. The book \naddresses several quality concerns in detail, \nincluding: availability, deployability, energy \nefficiency, modifiability, performance, test-\nability and usability. The authors offer recom-\nmended practices focusing on architectural \ndesign, architecture description, architecture \nevaluation and managing architecture tech-\nnical debt. They also emphasize the impor-\ntance of the business context in which large \nsoftware is designed. In doing so, they present \nsoftware architecture in a real-world setting, \nreflecting both the opportunities and con-\nstraints that organizations encounter. \nKruchten, \nThe \n4+1 \nView \nModel \nof \nArchitecture [25]. \nThis seminal paper organizes an approach \nto architecture description using five archi-\ntecture viewpoints. The first four are used to \nproduce the logical view, the development \nview, the process view, and the physical view. \nThese are integrated through selected use \ncases or scenarios to illustrate the architec-\nture. Hence, the model results in 4+1 views. \nThe views are used to describe the software as \nenvisioned by different stakeholders\u2014such as \nend-users, developers, and project managers. \nRozanski and Woods, Software Systems \nArchitecture [38*]\nThis is a handbook for the software sys-\ntems architect. It develops key concepts of \nstakeholder, concern, architecture descrip-\ntion, architecture viewpoint and architecture \nview, architecture patterns and styles, with \nexamples. It provides an end-to-end archi-\ntecting process. The authors provide a cat-\nalog of ready-to-use, practical viewpoints for \nthe architect to employ that are applicable to \na wide range of systems. The book is filled \nwith guidance for applying these concepts \nand methods.\nR.N. Taylor, N. Medvidovi\u0107, E. Dashofy, \nSoftware Architecture: Foundations, Theory, and \nPractice [41*]\nThis is a comprehensive textbook on many \naspects of software architecture, including \nkey ideas; software architecture in the con-\ntext of software engineering; the design pro-\ncess; architecture modeling, analysis and \nvisualization; and chapters on several con-\ncerns including implementation, deployment, \nadaptation, non-functional properties, trust \nand security.\nP. Clements et al. Documenting Software \nArchitecture: Views and Beyond, 2nd edition [9].\nThis book provides detailed guidance on cap-\nturing software architectures, using guidance \nand examples to express an architecture so \nthat stakeholders can build, use, and main-\ntain that system. The book introduces a \n3-way categorization of views and therefore \nviewpoints: into module, component and \nconnector and allocation called viewtypes, \nproviding numerous examples of each.\nBrown, Software Architecture for Developers [5]\nBrown provides an overview of software \narchitecture topics from the perspective of a \n", "page": 79, "type": "text", "section": "Page 79"}
{"text": "2-14   SWEBOK \u00ae GUIDE V4.0\ndeveloper. He discusses common architec-\nture drivers including architecture principles, \nquality concerns, constraints and functional \nrequirements. He has an in-depth discussion \nof the role of the architect in a development \nsetting and requisite knowledge and skills for \narchitects. He focuses on the practical issues \nof architecture in the delivery process and \non managing risk. An appendix provides a \ncase study.\nFairbanks, Just Enough Software Architecture: \nA risk-driven approach [16]\nFairbanks offers a risk-driven approach to \narchitecting within the context of develop-\nment: do just enough software architecture \nto mitigate the identified risks where those \nrisks could result from a small solution space, \nfrom extremely demanding quality require-\nments or from possible high-risk failures. \nThe risk-driven approach is harmonious \nwith low-ceremony and agile approaches. \nArchitecting, as argued by Fairbanks, is \nnot just for architects\u2014but is relevant to all \ndevelopers.\nErder, Pureur and Woods, Continuous \nArchitecture in Practice: Software Architecture in \nthe Age of Agility and DevOps. [15]\nThis book shows how \u201cclassical\u201d thinking \nabout software architecture has evolved \nin the present day in the contexts of agile, \ncloud-based and DevOps approaches to \nsoftware development by providing prac-\ntical guidance on a range of quality and \ncross-cutting concerns including security, \nresilience, scalability and integration of \nemerging technologies. \nREFERENCES\n[1]\t M. Ali Babar, and I. Gorton, \u201cSoftware \nArchitecture Review: The State of the \nPractice\u201d, IEEE Computer, July 2009.\n[2]\t * L. Bass, P. Clements, and R. Kazman, \nSoftware Architecture in Practice, 4th edi-\ntion, 2021.\n[3]\t L. Bass, J. Ivers, M.H. Klein, and \nP. Merson, Reasoning Frameworks, \nCMU/SEI-2005-TR-007, 2005.\n[4]\t * F. Brooks, The Design of Design, \nAddison-Wesley, 2010.\n[5]\t S. Brown, Software Architecture for \nDevelopers, 2018, http://leanpub.com/\nsoftware-architecture-for-developers \n[6]\t * D. Budgen, Software Design: Creating \nSolutions for Ill-Structured Problems, \n3rd Edition, CRC Press, 2021.\n[7]\t F. Buschmann, R. Meunier, H. \nRohnert, P. Sommerlad, and M. Stal, \nPattern Oriented Software Architecture, \nJohn Wiley & Sons, 1996.\n[8]\t H. Cervantes, R Kazman, Designing \nSoftware Architectures: A Practical \nApproach, 2nd ed., Addison-Wesley, 2024.\n[9]\t P. Clements et al., Documenting Software \nArchitecture: Views and Beyond, 2nd edi-\ntion Addison-Wesley, 2011.\n[10]\tP. Clements, R. Kazman, M. Klein, \nEvaluating Software Architectures, \nAddison-Wesley, 2001\n[11]\tM.E. Conway, \u201cHow Do Committees \nInvent?\u201d Datamation, 14(4), 28-31, 1968.\n[12]\tE.W. Dijkstra, \u201cOn the role of scientific \nthought\u201d, 1974, available at http://www.\ncs.utexas.edu/users/EWD/transcrip-\ntions/EWD04xx/EWD447.html.\n[13]\tT. Earl, SOA Design Patterns, \nPrentice-Hall, 2009\n[14]\tP. Eeles, and P. Cripps, The Process \nof Software Architecting, Addison \nWesley, 2010. \n", "page": 80, "type": "text", "section": "Page 80"}
{"text": "SOFTWARE ARCHITECTURE   2-15\n[15]\tM. Erder, P. Pureur and E. Woods, \nContinuous Architecture in Practice: \nSoftware Architecture in the Age of Agility \nand DevOps, Addison-Wesley, 2021.\n[16]\tG. Fairbanks, Just Enough Software \nArchitecture: A Risk-Driven Approach, \nMarshall & Brainerd, 2010.\n[17]\tE. Fernandez-Buglioni, Security \nPatterns in Practice: Designing Secure \nArchitectures Using Software Patterns, \nWiley, 2013.\n[18]\tR.T. Fielding and R.N. Taylor, \nPrincipled design of the modern web \narchitecture, ACM Transactions on \nInternet Technology, 2(2), 115\u2013150, 2002.\n[19]\tM. Fowler, D. Rice, M. Foemmel, \nE. Hieatt, R. Mee and R. Stafford, \nPatterns of Enterprise Application \nArchitecture, Addison-Wesley, 2003.\n[20]\tC. Hofmeister, P.B. Kruchten, R.L. \nNord, H. Obbink, A. Ran, and P. \nAmerica, \u201cA general model of soft-\nware architecture design derived \nfrom five industrial approaches\u201d, The \nJournal of Systems and Software, 80, \n106\u2013126, 2007.\n[21]\tC. Hofmeister, R.L. Nord, and D. Soni, \nApplied Software Architecture, Addison- \nWesley, 2000. \n[22]\tISO/IEC/IEEE, \u201cISO/IEC/IEEE \n24765:2017 Systems and Software \nEngineering \u2014 Vocabulary,\u201d 2nd ed. 2017.\n[23]\tISO/IEC/IEEE 42010:2011, \nSystems and software engineering \u2014 \nArchitecture description.\n[24]\tR. Kazman, S. Haziyev, A. Yakuba, \nand D.A. Tamburri, Managing Energy \nConsumption as an Architectural \nQuality Attribute, IEEE Software, \n35(5), 102\u2013107, 2018\n[25]\tP.B. Kruchten, The \u201c4+1\u201d View Model of \nArchitecture, IEEE Software 12(6), 1995. \n[26]\tP.B. Kruchten, R.L. Nord, and \nI. Ozkaya, Managing Technical \nDebt: Reducing Friction in Software \nDevelopment. Addison-Wesley, 2019.\n[27]\tZ. Li, P. Liang and P. Avgeriou, \nArchitecture viewpoints for documenting \narchitectural technical debt. Software \nQuality Assurance, Elsevier, 2016.\n[28]\tAlan MacCormack, John Rusnak & \nCarliss Baldwin, Exploring the Duality \nbetween Product and Organizational \nArchitectures: A Test of the \n\u2018Mirroring\u2019 Hypothesis. Research Policy, \n41:1309\u20131324, 2012\n[29]\t* M.W. Maier and E. Rechtin, The Art \nof Systems Architecting, 3rd edition, CRC \nPress, 2021.\n[30]\tN. Medvidovi\u0107, D.S. Rosenblum, D.F. \nRedmiles and J.E. Robbins, Modeling \nsoftware architectures in the Unified \nModeling Language, ACM Transactions \non Software Engineering and Methodology, \n11(1), 2\u201357, 2002\n[31]\tH. Obbink et al., Report on Software \nArchitecture Review and Assessment \n(SARA), version 1.0, available at https://\nphilippe.kruchten.com/architecture/\nSARAv1.pdf, 2002. \n[32]\tD.L. Parnas, \u201cOn the criteria to be used \nin decomposing systems into modules\u201d, \nCommunications of the ACM 15(12), \n1053-1058, 1972. \n[33]\tD.L. Parnas and D.M. Weiss, \n\u201cActive Design Reviews: Principles \nand Practices\u201d, Proceedings of 8th \nInternational Conference on Software \nEngineering, 215-222, 1985.\n[34]\tD. Perry, A. Wolf, Foundations for the \n", "page": 81, "type": "text", "section": "Page 81"}
{"text": "2-16   SWEBOK \u00ae GUIDE V4.0\nstudy of software architecture, ACM \nSIGSOFT Software Engineering Notes, \n17(4), 40\u201352, 1992\n[35]\tE. Poort, H. van Vliet, RCDA: \nArchitecting as a Risk- and Cost \nManagement Discipline, Journal of \nSystems and Software, https://www \n.cs.vu.nl/~hans/publications/y2012 \n/JSS-RCDA.pdf, 2012\n[36]\tR. Prieto-Diaz and J.M. Neighbors, \n\u201cModule Interconnection Languages\u201d, \nJournal of Systems and Software, 6(4), \n307\u2013334, 1986.\n[37]\tC. Richardson, Microservices Patterns, \nManning Publications, 2019\n[38]\t*N. Rozanski and E. Woods, Software \nSystems Architecture: Working with \nStakeholders Using Viewpoints and \nPerspectives, 2nd edition, Addison-\nWesley, 2011.\n[39]\tM. Shaw and D. Garlan, Software \nArchitecture: Perspectives on an Emerging \nDiscipline, Prentice Hall, 1996.\n[40]\t*I. Sommerville, Software Engineering, \n10th edition, 2016.\n[41]\tR.N. Taylor, N. Medvidovi\u0107, E. Dashofy, \nSoftware Architecture: Foundations, Theory, \nand Practice, Wiley, 2009\n[42]\tR. Weinreich and G. Buchgeher, \nTowards supporting the software archi-\ntecture life cycle, The Journal of Systems \nand Software, 85, 546\u2013561, 2012.\n", "page": 82, "type": "text", "section": "Page 82"}
{"text": "3-1 \nCHAPTER 03\nSoftware Design\nACRONYMS\nAPI\nApplication Programming  \nInterface\nAOD\nAspect-Oriented Design\nCBD\nComponent-Based Design\nCRC\nClass Responsibility Collaborator \n(Or Collaboration)\nDFD\nData Flow Diagram\nDSL\nDomain-Specific Language\nERD\nEntity Relationship Diagram\nFOSS\nFree And Open Source Software\nIDL\nInterface Description Language\nMBD\nModel-Based Design\nMDD\nModel-Driven Design\nOO\nObject-Oriented\nPDL\nProgram Design Language\nSDD\nSoftware Design Description\nSoC\nSeparation of Concerns\nUML\nUnified Modeling Language\nINTRODUCTION\nThis chapter considers software design from \nseveral perspectives\u2014focusing on basic con-\ncepts, context and processes, software design \nqualities and strategies, and recording and \nevaluating designs.\nDesign is used in distinct but closely related \nways to refer to (1)\u00a0the discipline (\u201cuse of sci-\nentific principles, technical information, and \nimagination in the definition of a software \nsystem to perform [prespecified] functions \nwith maximum economy and efficiency\u201d) \n[11]; (2)\u00a0 the processes for performing within \nthat discipline; (3)\u00a0the result of applying that \ndiscipline; and (4)\u00a0the stage in the life cycle \nof a software system during which those pro-\ncesses yield those results. \nA software design description (SDD) docu-\nments the result of software design. It is a \u201crep-\nresentation of software created to facilitate \nanalysis, planning, implementation, and deci-\nsion-making. The software design description \nis used as a medium for communicating soft-\nware design information and can be thought of \nas a blueprint or model of the system\u201d [11]. \nThe SDD, which may take many forms, \nencompasses the refinement of that software \ninto components, the organization of those \ncomponents, and the definition of interfaces \namong them and between the software and \nthe outside world\u2014to a level of detail that \nenables their construction. \nSoftware design, viewed as a life cycle \nactivity, is the application of software engi-\nneering discipline in which software require-\nments are analyzed to define the software\u2019s \nexternal characteristics and internal structure \nas the basis for the software\u2019s construction.\nSoftware design takes place in three stages:\n\u2022\t architectural design of the software system\n\u2022\t high-level or external-facing design of \nthe system and its components \n\u2022\t detailed or internal-facing design\nArchitectural design is a part of architecting, \ndiscussed in the Software Architecture KA.\nBREAKDOWN OF TOPICS FOR \nSOFTWARE DESIGN\nThe breakdown of topics for the Software \nDesign KA is shown in Fig. 3.1.\n", "page": 83, "type": "text", "section": "Page 83"}
{"text": "3-2   SWEBOK \u00ae GUIDE V4.0\n1.\t Software Design Fundamentals\b [3*][4*]\nThe concepts, notions and terminology intro-\nduced here form a basis for understanding the \nrole and scope of software design. \n1.1.\t Design Thinking\b\n[3* c1, c2, c3] \n \n\b\n[4* c1, c2] [20]\nDesign is all around us, in the things and \norganizations that have been created to meet \na need or solve a problem. \nIn a general sense, design can be viewed as \na form of problem-solving. For example, the \nconcept of a wicked problem\u2014a problem with \nno definitive solution\u2014is interesting in terms \nof understanding the limits of design. Many \nother notions and concepts help us understand \ndesign in its general sense: goals, constraints, \nalternatives, representations and solutions. \n(See also Design as a Problem-Solving Activity \nin Engineering Foundations KA.)\nDesign thinking comprises two essentials: \n(1)\u00a0 understanding the need or problem and \n(2)\u00a0 devising a solution. Ross, Goodenough \nand Irvine offer an elaboration of design \nthinking appropriate to software:\nThis process consists of five basic steps: (1) crys-\ntallize a purpose or objective; (2) formulate a \nconcept for how the purpose can be achieved; \n(3) devise a mechanism that implements the con-\nceptual structure; (4) introduce a notation for \nexpressing the capabilities of the mechanism \nand invoking its use; (5)\u00a0describe the usage of the \nnotation in a specific problem context to invoke \nthe mechanism so the purpose is achieved. [20]\nThis is particularly appropriate because \nmuch of software design consists of cre-\nating the necessary vocabulary to express a \nproblem, express its solution and implement \nthat solution. The steps emphasize the lin-\nguistic nature of software design problem \nsolving. This is a recurring pattern we see \nthroughout high-level design, detailed design \nand architecting (see Architecting in the Large \nin Software Architecture KA). Therefore, \nSoftware Design is a practical process of \ntransforming a problem statement into a solu-\ntion statement. Software design shares com-\nmonalities with other kinds of design. Design \ncan be further understood via design theory [8]. \n1.2.\t Context of Software Design\b\n[4* c13, c14] \n\b\n[21* c19, c20]\nSoftware design is an important part of the \nsoftware development process. To understand \nthe role of software design is to see how it fits \nSoftware\nDesign\nSoftware\nDesign\nFundamentals\nDesign\nTinking\nContext of\nSoftware\nDesign\nKey Issues \nin Software \nDesign\nSoftware\nDesign\nPrinciples\nHigh-Level\nDesign\nDetailed\nDesign\nConcurrency\nControl and Event\nHandling\nData Persistence\nDistribution of\nComponents\nErrors and Exception\nHandling\nIntegration and\nInteroperability\nAssurance, Security, \nSafety\nVariability\nModel-Based\nDesign\nStructural \nDesign Description\nBehavioral\nDesign Description\nDesign Patterns\nSpecialized\nDomain-Speci\ufb01c\nLanguages\nDesign\nRationale\nGeneral Strategies\nFunction-Oriented\nData-Centered\nObject-Oriented\nUser-Centered\nComponent-Based\nEvent-Driven\nAspect-Oriented\nConstraint-Based\nDomain-Driven Design\nOther Methods\nDesign Reviews \nand Audits\nQuality Attributes\nQuality Analysis \nand Evaluation \nTechniques\nMeasures and \nMetrics\nVeri\ufb01cation, \nValidation and\nCerti\ufb01cation\nSoftware\nDesign\nProcesses\nSoftware\nDesign\nQualities\nRecording\nSoftware\nDesign\nSoftware Design\nStrategies and \nMethods\nSoftware Design\nAnalysis and \nEvaluations\nFigure 3.1. Breakdown of topics for the Software Design KA\n", "page": 84, "type": "text", "section": "Page 84"}
{"text": "SOFTWARE DESIGN   3-3\ninto the software development life cycle (see \nSoftware Process KA). To understand that \ncontext, it is important to understand the \nmajor characteristics and roles of software \nrequirements, software construction, software \ntesting, and software maintenance. The con-\ntext varies with many factors, including degree \nof formality and stage of the life cycle.\nSoftware design is the transformation of \ncustomer and other requirements, needs, and \nconcerns into implementable design specifica-\ntions. Its contexts include the following:\n\u2022\t Software Design\u2019s relationship with soft-\nware requirements: The requirements \nestablish a set of problems that the soft-\nware design must solve.\n\u2022\t Software Design\u2019s relationship with soft-\nware architecture: In cases where an \narchitecture has been established, that \narchitecture constrains the design by \ncapturing fundamental aspects of the \nsystem: such as its major components and \ntheir interconnections, application pro-\ngramming interfaces (APIs), styles and \npatterns to be used, and architectural \nprinciples to be observed and enforced.\n\u2022\t Software Design\u2019s relationship with soft-\nware construction: The software design \nmust provide a guide to implementors on \nbuilding the system.\n\u2022\t Software Design\u2019s relationship with soft-\nware testing: Software design provides a \nfoundation for an overall testing strategy \nand test cases that ensure that the design \nis properly implemented and operates \nas intended.\n1.3.\t Key Issues in Software Design\b\n[2, 12]\nMany key issues must be dealt with when \ndesigning software. Some are quality con-\ncerns that all software must address (per-\nformance, security, reliability, usability, \nmaintainability, etc.). Another important \nissue is how to refine, organize, intercon-\nnect and package software components. \nThese issues are so fundamental that all \ndesign approaches address them in one \nway or another. (See topic Stakeholders and \nConcerns in Software Architecture KA, sec-\ntion 1.4 Software Design Principles, and topic \n5 Software Design Strategies and Methods.) \nIn contrast, other issues \u201cdeal with some \naspect of software\u2019s behavior that is not in the \napplication domain, but which addresses some \nof the supporting domains\u201d [2]. Such issues, \nwhich often crosscut the system\u2019s function-\nality, are referred to as aspects, which \u201ctend not \nto be units of software\u2019s functional decompo-\nsition, but rather to be properties that affect \nthe performance or semantics of the compo-\nnents in systemic ways\u201d [12]. \n1.4.\t Software Design Principles\b [5, 10, 17, 20]\nA principle is \u201ca fundamental truth or proposi-\ntion that serves as\u00a0the foundation for a system \nof belief or behavior or for a chain of rea-\nsoning.\u201d [Oxford English Dictionary] \nDesign principles provide direction or guid-\nance for making decisions during design. \nSome principles originated during the early \ndays of software engineering, others even pre-\ndate the discipline, deriving from best prac-\ntices in engineering unrelated to software. \n(See Engineering Foundations KA.) Decision \nmaking can also be assisted by quantita-\ntive methods, such as discussed in Software \nEngineering Economics KA. Software design \nprinciples are key notions that provide the basis \nfor many different software design concepts, \napproaches and methods. The principles listed \nbelow apply to any of the three stages of design. \nMany of these principles are interrelated. \nWhether alone or used in combination with \nother principles, they are reflected elsewhere \nin software design to produce many concepts \nand constructs found in design capture, strat-\negies and methods. This is itself an application \nof the design thinking process above. Software \ndesign principles include the following:\n\u2022\t Abstraction is \u201ca view of an object that \nfocuses on the information relevant to \na particular purpose and ignores the \nremainder of the information\u201d [11].\u201cThe \nabstraction principle . . . helps to identify \n", "page": 85, "type": "text", "section": "Page 85"}
{"text": "3-4   SWEBOK \u00ae GUIDE V4.0\nessential properties common to super-\nficially different entities\u201d [20]. (See also \ntopic Abstraction in the Computing \nFoundations KA.)\n\u2022\t Separation of concerns (SoC). A design con-\ncern is an \u201carea of interest with respect to \na software design\u201d [11] that is relevant \nto one or more of its stakeholders. By \nidentifying and separating concerns, the \ndesigner can focus on each concern for the \nsystem in isolation about which Dijkstra \nsaid \u201ceven if not perfectly possible, [SoC] \nis yet the only available technique for \neffective ordering of one\u2019s thoughts \u201d [5] \n(See also topic Stakeholders and Concerns \nin Software Architecture KA.)\n\u2022\t Modularization (or refinement or decompo-\nsition) structures large software as com-\nprising smaller components or units. Each \ncomponent is named and has well-de-\nfined interfaces for its interactions with \nother components. Smaller components \nare easier to understand and, therefore, to \nmaintain. There are numerous modular-\nization strategies. (See topic 5 Software \nDesign Strategies and Methods.) \n\t Traditionally, the goal is to place distinct \nfunctionalities and responsibilities in dif-\nferent components. David Parnas advo-\ncated that each module in a system should \nhave a single responsibility [17]. One way \nto think of modularization is as a special \ncase of more general strategies, such as sep-\naration of concerns or divide and conquer. \n(see topic Problem-Solving Techniques in \nComputing Foundations).\n\u2022\t Encapsulation (or information hiding) \nbuilds upon the principles of abstraction \nand modularization so that nonessential \ninformation is less accessible, allowing \nusers of the module to focus on the essen-\ntial elements at the interface. \n\u2022\t Separation of interface and implementa-\ntion is an application of encapsulation \nthat involves defining a component by \nspecifying its public interfaces, which \nare known to and accessible to clients; \nisolating the use of a component from \nthe details of how that component is \nbuilt. (See Encapsulation (or information \nhiding) above.)\n\u2022\t Coupling is defined as \u201ca measure of the \ninterdependence among modules in a \ncomputer program\u201d [11]. Most design \nmethods advocate that modules should \nbe loosely or weakly coupled.\n\u2022\t Cohesion (or localization) is defined as \u201ca \nmeasure of the strength of association \nof the elements within a module\u201d\u00a0 [11]. \nCohesion highlights organizing a mod-\nule\u2019s constituents based on their relat-\nedness. Most design methods advocate \nthat modules should maximize their \ncohesion/locality. \n\u2022\t Uniformity is a principle of consistency \nacross software components\u2014common \nsolutions should be produced to address \ncommon or recurring problems. These \ninclude naming schemes, notations and \nsyntax, interfaces that define access to \nservices and mechanisms, and ordering \nof elements and parameters. This can be \nachieved through conventions such as \nrules, formats and styles.\n\u2022\t Completeness (or sufficiency) means ensuring \nthat a software component captures the \nimportant characteristics of an abstrac-\ntion and leaves nothing out. Completeness \ntakes various forms, perhaps the most \nimportant of which is design completeness \nagainst requirements: a design should be \nsufficient for designers to demonstrate how \nrequirements will be met and how subse-\nquent work will satisfy those requirements. \nDesign should be complete with respect to \nthe modes and states of the software. \n\u2022\t Verifiability means that information \nneeded to verify the design against its \nrequirements and other constraints is \navailable. This is relevant for any software \nbut is of particular importance for high-as-\nsurance software, such as software where \nsecurity, reliability or safety-critical con-\ncerns are present. An SDD should be \nsufficient as a basis for verifying a design. \n(See Software Testing KA and Software \nQuality KA.).)\n\u2022\t Other design principles. Recently, with the \n", "page": 86, "type": "text", "section": "Page 86"}
{"text": "SOFTWARE DESIGN   3-5\nincreased appearance of autonomous sys-\ntems, the use of machine learning and \nartificial intelligence, and, generally, \nsystems with widening social impacts, \napproaches to Ethically Aligned Design \nhave been developed to address concerns \nincluding universal human values, polit-\nical self-determination, and data agency \nand technical dependability [9]. The gen-\neral principles of Ethically Aligned Design \nare human rights, well-being, data agency, \neffectiveness, transparency, accountability, \nawareness of misuse, and competence.\n2.\t Software Design Processes \n\b\n[4* c3] [21* c2, c7] [10]\nSoftware design is generally considered a mul-\ntistage process or activity. Software design \ncan be divided into the following stages or \nphases. When necessary, we distinguish the \nphase from the general activity:\n\u2022\t Architectural design stage\n\u2022\t High-level design stage\n\u2022\t Detailed design stage\nThe architectural design stage addresses \nthe fundamentals of the system as a whole and \nin relation to its environment (see Software \nArchitecture KA).\nThe \nhigh-level \ndesign \nstage \nis \nout-\nward-facing\u2014developing the top-level struc-\nture and organization of the software, \nidentifying its various components and how \nthat software system and its components \ninteract with the environment and its elements.\nThe detailed design stage is inward-\nfacing\u2014specifying each component in suffi-\ncient detail to facilitate its construction and \nto meet its outside obligations, including how \nsoftware components are further refined into \nmodules and units.\nEach stage reflects the basic pattern out-\nlined in section 1.1 Design Thinking. \nNot all stages are found in every soft-\nware process. However, when present, each \nstage creates an obligation upon the next \nstage regarding the software which is under \ndevelopment. \nAlthough software developers generally \nfollow similar guidelines for what happens \nin each stage, there are no strict bound-\naries between stages regarding what must be \ndone and when. For example, for many soft-\nware systems, the choice of an algorithm to \nsort data will be deferred to programmers, \nwithin the constraints and guidance provided \nby the system\u2019s requirements, its architecture \ndescription or design specifications. However, \nfor another software system, the existence of \na suitable algorithm could be architecturally \nsignificant and must be determined early in \nthe life cycle. Without that algorithm, there \nis no possibility of constructing the software \nto meet its requirements.\nSome rules of thumb for each stage include \nthe following:\n\u2022\t The architectural design stage defines \na computational model, the major com-\nputational elements, and the important \nprotocols and relationships among them. \nThis stage develops strategies to address \ncrosscutting concerns, such as perfor-\nmance, reliability, security and safety, \nand articulation of crosscutting deci-\nsions, including system-wide styles (e.g., \na transactional n-tier style versus a pipes \nand filters style, together with the ratio-\nnale for such decisions).\n\u2022\t The high-level design stage includes \nidentification of the primary computa-\ntional elements and significant relation-\nships among them, with a focus on each \nmajor component\u2019s existence, role and \ninterfaces. That definition should be suf-\nficiently detailed to allow designers or \nprogrammers of client components to \ncorrectly and efficiently access each ser-\nvice\u2019s capabilities\u2014without having to \nread its code. \n\u2022\t The detailed design stage defines each \nmodule\u2019s internal structure, focusing on \ndetailing and justifying choices of algo-\nrithms, data access and data representa-\ntion. The detailed design specifications \nshould be sufficient to allow programmers \n", "page": 87, "type": "text", "section": "Page 87"}
{"text": "3-6   SWEBOK \u00ae GUIDE V4.0\nto code each module during construction \n(see Software Construction KA). The \ncode is a representation of the solution that \nis sufficiently detailed and complete that a \ncompiler (or interpreter) can execute it.\n2.1.\t High-Level Design\b\n[3* c5] [4* c6] [10]\nHigh-level design specifies the interaction of \na system\u2019s major components with one another \nand with the environment, including users, \ndevices and other systems. High-level design \naddresses the following:\n\u2022\t External events and messages to which \nthe system must respond\n\u2022\t Events and messages which the system \nmust produce\n\u2022\t Specification of the data formats and pro-\ntocols for events and messages\n\u2022\t Specification of the ordering and timing \nrelationships between input events and \nmessages, and output events and messages\n\u2022\t Tracing and analysis of end-to-end trans-\nactions and event threads\n\u2022\t Data persistence (how data is stored \nand managed)\nHigh-level design is undertaken within \nthe envelope established by the system\u2019s soft-\nware architecture (if any). Each of the above \nmay be guided or constrained by architecture \ndirectives. For example, event signaling and \nmessaging will use the protocols and modes \nof interaction established by the architecture. \nData formats and protocols will use data and \ncommunication standards specified by the \narchitecture. Absent an explicit architecture \ndesign stage, some of these directives will be \nestablished by the software requirements or \ndecided during high-level design.\n2.2.\t Detailed Design\b\n[10]\nThe detailed design stage proceeds within the \nconstraints established by the high-level design. \nIt specifies major system components\u2019 internal \ncharacteristics, internal modules and their \ninterconnections to other modules, services \nand processes they provide, computing proper-\nties, algorithms, and data access rules and data \nstructures. This includes the following:\n\u2022\t Refinement of major system components \ninto modules or program units, including \nopportunities for using off-the-shelf com-\nponents and application frameworks\n\u2022\t Allocation of design responsibilities to \nmodules and program units\n\u2022\t Interactions among modules\n\u2022\t Scope and visibility among components, \nmodules and program units \n\u2022\t Component modes, component states \nand transitions among them\n\u2022\t Data and control interdependencies\n\u2022\t Data \norganization, \npackaging \nand \nimplementation\n\u2022\t User interfaces\n\u2022\t Requisite algorithms and data structures\n3.\t Software Design Qualities\b\n[4* c4] [20]\nSoftware requirements and architecture direc-\ntives are intended to guide software toward \ncertain characteristics or design qualities. \nDesign qualities are an important subclass of \nconcerns (see topic Stakeholders and Concerns \nin Software Architecture KA). One role of \ndesign principles (see section 1.4 Software \nDesign Principles) is to help software achieve \nthese qualities. Among the characteristics of \ninterest to designers are the following:\n3.1.\t Concurrency\b\n[21* c17]\nDesign for concurrency concerns how software \nis refined into concurrent units such as pro-\ncesses, tasks, and threads and the consequences \nof those decisions with respect to efficiency, \natomicity, synchronization and scheduling. \n3.2.\t Control and Event Handling\b\n[21* c21]\nEvent handling is concerned with how to \norganize control flow as well as how to handle \nreactive and temporal events through var-\nious mechanisms including synchronization, \nimplicit invocation and callbacks. \n", "page": 88, "type": "text", "section": "Page 88"}
{"text": "SOFTWARE DESIGN   3-7\n3.3.\t Data Persistence\b\n[21* c6, c16]\nData persistence concerns the storage and \nmanagement of data throughout the system.\n3.4.\t Distribution of Components\b\n[21* c17]\nDistribution concerns how software com-\nponents are distributed across hardware \n(including computers, networks and other \ndevices) and how those components commu-\nnicate while meeting performance, reliability, \nscalability, availability, monitorability, busi-\nness continuity and other expectations. \n3.5.\t Errors and Exception Handling, Fault \nTolerance\b\n[21* c11]\nThis concern pertains to how to prevent, \navoid, mitigate, tolerate and process errors \nand exceptional conditions. \n3.6.\t Integration and Interoperability \n\b\n[4* c11, c14, c16]\nThis issue arises at the enterprise or sys-\ntem-of-systems level or for any complex \nsoftware when heterogeneous systems or \napplications need to interwork through \nexchanges of data or accessing one another\u2019s \nservices. Within a software system, the issue \narises when components are designed using \ndifferent frameworks, libraries or protocols.\n3.7.\t Assurance, Security, and Safety \n\b\n[21* c10\u2013c14]\nHigh assurance spans a number of software \nqualities, including security and safety con-\ncerns, pertaining to whether the software \nbehaves as intended in critical situations, such \nas in the face of hazards. Security becomes a \nkey concern for distributed applications where \ncomponents communicate using different pro-\ntocols and media. Design for security concerns \nhow to prevent unauthorized disclosure, cre-\nation, change, deletion, or denial of access to \ninformation and other resources in the face of \nattacks upon the system or violations of system \npolicies to limit damage; provide continuity of \nservice; and assist repair and recovery. Design \nfor safety pertains to managing the software\u2019s \nbehavior in circumstances which might lead to \nharm to or loss of human life or damage to \nproperty or the environment.\n3.8.\t Variability\b\n[6]\nVariability concerns permissible variations in \na software system. It is a fundamental aspect \nof most software [6]. It is the ability to create \nsoftware system variants for different market \nsegments or contexts of use.\nInterest in variability first arose in software \nproduct lines and system families, to accom-\nmodate and manage deployment of multiple \nvariants such as for different organizations \nor markets. (See appendix B 6, Standards for \nproduct line, methods and tools). It is also \nrelevant to software ecosystems and con-\ntext-aware software. (See also 3.5 Reuse in \nConstruction, Software Construction KA.)\nFeature models are used to gather require-\nments and dependencies into bundles. (See \nFeature-Driven Development, under topic \n4.1 Agile Methods in Software Engineering \nModels and Methods KA)\n4.\t Recording Software Designs \n\b\n[4* c7, c8] [1]\nThe outcome of design processes is accumu-\nlated knowledge and work products recording \nthat knowledge. Work products of software \ndesign capture (1)\u00a0aspects of the problems to \nbe solved, using the vocabulary of the domain; \n(2)\u00a0a solution vocabulary for solving the design \nproblems (see section 1.1 Design Thinking); \n(3)\u00a0the major decisions that have been taken; \nand (4)\u00a0explanations of the rationale for each \nnontrivial decision. Recording the rationale \nfor important decisions enhances the software \nproduct\u2019s long-term maintainability when \nmodifications or enhancements are consid-\nered (see section 4.6 Design Rationale). These \nwork products, often termed design descrip-\ntions or design specifications, can take the form \nof texts, diagrams, models and prototypes \n", "page": 89, "type": "text", "section": "Page 89"}
{"text": "3-8   SWEBOK \u00ae GUIDE V4.0\nthat comprise the blueprints of the software \nto be implemented.\nA fundamental aspect of software design \nis communication about the design among \ndesigners, and to customers, implementers and \nother stakeholders. This is the case whether \nthe software is developed using agile, tradi-\ntional or formal methods. The communication \nwill vary depending upon the target audi-\nence, the level of detail being communicated, \nand relevance to the concerns of the stake-\nholders. For example, when using traditional \nor formal methods, the design often evolves \nthrough a progression of design descriptions, \nwhile in agile approaches the evolving design \nmay be implicit in the minds of developers \nand only explicit as code. While the latter \napproach supports the agility of developers, \nother stakeholders, such as those concerned \nwith requirements, certification, testing and \nquality assurance may need explicit design \ninformation to do their work. Therefore, \nprojects should make conscious decisions \nabout which design specifications are needed \nbased upon stakeholder audience, subject and \nintended usage.\nDesigners can analyze and evaluate these \nwork products to determine whether the \ndesign can meet the requirements and con-\nstraints on the software. Software design also \nexamines and evaluates alternative solutions \nand trade-offs. In addition to using them \nas inputs and as the starting point for con-\nstruction and testing, stakeholders can use \nthe design work products to plan subsequent \nactivities, such as system verification and \nvalidation.\nAs design concepts evolve, so do their rep-\nresentations (see section 1.1 Design Thinking); \npart of the design process involves creating \nappropriate vocabularies for problems and \nsolutions. An informal sketch may be most \nappropriate for the early stages. It is useful \nto distinguish in-process (\u201cworking\u201d) spec-\nifications from final design products. The \nformer are produced by the design team for the \ndesign team; the latter may be produced for \nknown stakeholders or even for an unknown \nfuture audience.\nMany notations exist to represent software \ndesign artifacts. Software design is often car-\nried out using multiple types of notation. Two \nbroad areas of concern are software struc-\ntures and software behaviors. Some are used \nto describe a design\u2019s structural organization, \nothers to represent the software\u2019s intended \nbehavior. Below, they are categorized as nota-\ntions for structural and behavioral concerns \n(see section 4.2 Structural Design Descriptions \nand section 4.3 Behavioral Design Descriptions, \nrespectively). Certain notations are used \nmostly during architectural design and others \nmainly during detailed design; some are useful \nthroughout all stages of software design. Some \nnotations are closely tied to the context of spe-\ncific design methods (see Software Design \nStrategies and Methods KA).\nThe Unified Modeling Language (UML) is \na widely used family of notations addressing \nboth structural and behavioral concerns and \nis used in all design stages, from architectural \nthrough detailed design [1].\n4.1.\t Model-Based Design\b\n[4* c7.3] [21* c5.5] \nOver the history of software engineering, \nincluding architecture and design, there \nhas been an evolution from document-based \nartifacts to model-based artifacts. Model-\nBased Design (MBD) is an approach to \nrecording designs where models play an \nimportant role.\nThis trend reflects the limitations of docu-\nment-based artifacts and the increased capa-\nbilities of automated tools. Document-based \nartifacts use natural language and informal \ndiagrams to convey designers\u2019 intentions, \nwhich might introduce ambiguity and \nincompleteness. Even when documents use \nwell-defined formats, relevant information \nmight be spread across documents, making \nunderstandability and analysis difficult. \nWith MBD, appropriate tooling can gather \nand organize relevant information for use by \ndesigners and other stakeholders in an acces-\nsible form.\nModern tools have accelerated the trend \nfrom document to model-based artifacts. \n", "page": 90, "type": "text", "section": "Page 90"}
{"text": "SOFTWARE DESIGN   3-9\nTooling enables animation or simulation of \nvarious software aspects, analyses of what-if \nscenarios and trade-offs, and rapid proto-\ntyping. Tooling also facilitates continuous \ntesting and integration approaches, enhanced \nand interactive traceability, and knowledge \ncapture and management, which are ineffi-\ncient or even infeasible with document-based \napproaches.\nModel-driven development (MDD) is a \ndevelopment paradigm that uses models as \nthe development process\u2019 primary artifacts (see \nSoftware Engineering Models and Methods KA). \n4.2.\t Structural Design Descriptions \n\b\n[4* c7, c10] [7* c4] [21* c5.3]\nThe following types of notation, most of which \nare graphical, are used to represent the struc-\ntural aspects of a software design\u2014that is, \nthey are used to describe the major compo-\nnents and how they are interconnected (static \nview) and the allocation of responsibilities to \ncomponents and modules: \n\u2022\t Class and object diagrams are used to rep-\nresent a set of classes and objects and their \ninterrelationships. \n\u2022\t Component diagrams are used to rep-\nresent a set of components (replaceable \nelements of a system that conform to \nand provide the realization of a set of \ninterfaces) and their interconnections. \nComponent models evolved from ear-\nlier module interconnection languages \ninto the package systems of program-\nming languages like Ada and Java and \nthe sophisticated module systems of cur-\nrent functional language systems such as \nHaskell and Coq.\n\u2022\t Class responsibility collaborator cards \n(CRCs) are used to denote the names of \ncomponents (classes), their responsibil-\nities and the components they interact \nwith to meet those responsibilities. \n\u2022\t Deployment diagrams are used to repre-\nsent a set of physical nodes and their inter-\nconnections to model the physical aspects \nof software as deployed on hardware. \n\u2022\t Entity relationship diagrams (ERDs) are \nused to represent conceptual, logical and \nphysical models of data as stored in infor-\nmation repositories or as a part of inter-\nface descriptions. \n\u2022\t Interface description languages (IDLs) \nare programming-like languages used to \ndefine the interfaces (names and types \nof exported operations) of software \ncomponents. \n\u2022\t Structure charts are used to describe the \ncalling structure of programs (that is, they \nshow which modules call, and are called \nby, which other modules). \n4.3.\t Behavioral Design Descriptions \n\b\n[4* c9, c10] [7* c5] [21* c5.4]\nThe following notations and languages, some \ngraphical and some textual, are used to describe \nthe dynamic behavior of software systems and \ntheir components. Many of these notations \nare useful mostly, but not exclusively, during \ndetailed design. Moreover, behavioral descrip-\ntions can include rationale for design decisions \n(see section 4.6 Design Rationale). \n\u2022\t Activity diagrams are used to show flow \nof a computation from activity to activity. \nThey also can represent concurrent activ-\nities, their inputs and outputs and oppor-\ntunities for concurrency.\n\u2022\t Interaction diagrams characterize the \ninteraction among a group of objects. \nThere are two major kinds of interaction \ndiagrams: communication (or collabora-\ntion) diagrams and sequence diagrams. \nCommunication diagrams show inter-\nactions among objects with an emphasis \non their links and the messages they \nexchange on those links. Sequence dia-\ngrams show interactions among objects, \nwith an emphasis on the temporal ordering \nof messages passed among those objects.\n\u2022\t Data flow diagrams (DFDs) are used to \nshow data flow among computing ele-\nments. A DFD provides \u201ca description \nbased on modeling the flow of infor-\nmation around a network of operational \n", "page": 91, "type": "text", "section": "Page 91"}
{"text": "3-10   SWEBOK \u00ae GUIDE V4.0\nelements, with each element making use \nof or modifying the information flowing \ninto that element\u201d [4]. DFDs have other \nuses, such as security analysis, as they \nidentify possible paths for attack and dis-\nclosure of confidential information. \n\u2022\t Decision tables and diagrams are used to\nrepresent complex combinations of con-\nditions and actions.\n\u2022\t Flowcharts are used to represent the flow\nof control and the sequence of associ-\nated actions.\n\u2022\t State (transition) diagrams and statecharts \nare used to show transitions from state to\nstate and how a component\u2019s behavior\nchanges based on its current state and\nresponse to input events.\n\u2022\t Formal specification languages are predomi-\nnantly textual languages founded upon basic\nnotions from mathematics (for example,\ntype, set, sequence, logical proposition) to\nrigorously and abstractly define software\ncomponent interfaces and behavior, often in\nterms of pre- and post-conditions, invariants, \ntype checking, and computational models\n(see section Formal Methods in Software\nEngineering Models and Methods KA).\n\u2022\t Pseudocode and program design lan-\nguages (PDLs) are structured, program-\nming language-like notations used to\ndescribe a procedure\u2019s processing behavior,\ngenerally at the detailed design stage. The\nuse of these languages is less common\ntoday but is still found in the documenta-\ntion of algorithms.\n4.4.\t Design Patterns and Styles \b\n[3* c12] [4* c15] [7* c1, c2] [21* 7.2]\nSuccinctly described, a pattern is \u201ca common \nsolution to a common problem in a given context\u201d \n[7]. Design patterns include the following: \n\u2022\t Creational patterns (e.g., builder, factory,\nprototype, singleton)\n\u2022\t Structural patterns (e.g., adapter, bridge,\ncomposite, \ndecorator, \nfac\u0327ade, \nfly-\nweight, proxy)\n\u2022\t Behavioral patterns (e.g., command,\ninterpreter, iterator, mediator, memento, \nobserver, peer-to-peer, publish-subscribe, \nstate, strategy, template, visitor) \nDesign patterns can be used to reflect idioms \nthat have proven useful in solving particular \ndesign problems in the past, establish a solution \nvocabulary, and document and explain design \ndecisions. They arise at all stages of design, \nincluding architectural design. Often architec-\ntural styles can be viewed as patterns \u201cin the \nlarge,\u201d describing common solutions to archi-\ntecture-level problems that pervade the soft-\nware. (See also topic 2.2 Architecture Styles and \nPatterns, Software Architecture KA).\n4.5.\t Specialized and Domain-Specific \nLanguages\b\n[21* c15]\nNot every design representation falls easily \ninto the structure/behavior dichotomy. For \nexample, user interface design mixes the \nstructural layout of what a user might see with \nthe behavioral logic of sequencing screens \nbased upon user actions. Specialized concerns \nsuch as safety and reliability often have their \nown forms of representation that have evolved \namong specialists in those communities [21].\nA recent trend has been the maturing of \ndomain-specific languages (DSLs) and widely \navailable tools to develop them. In this \napproach, part of the design process is codifying \nconcepts and constructs of a specific application \ndomain to create a computer language for that \ndomain so that representing the design using \nthese constructs leads to an animated or exe-\ncutable implementation. DSLs blur the lines \namong modeling languages, design languages \nand programming languages in this approach. \nThere are DSLs and supporting tools for \ndomains such as simulation; real-time, reactive \nand distributed systems; game development; \nuser interfaces; test development; and language \nprocessing tools. The growth of DSLs has been \nfacilitated by increasingly powerful gram-\nmar-driven tools that, given a language defi-\nnition, can generate a graphical user interface, \nsyntax checkers, code generators, compilers \nand linkers for the specialized language.\n", "page": 92, "type": "text", "section": "Page 92"}
{"text": "SOFTWARE DESIGN   3-11\n4.6.\t Design Rationale\b\n[3* c16] [4* c12] \n\b\n[21* c6.1]\nA useful design outcome is insight into and \nexplicit documentation of the major decisions \ntaken, along with an explanation of the ratio-\nnale for each decision. Design rationale cap-\ntures why a design decision was made. This \nincludes prior assumptions made, alternatives \nconsidered, and trade-offs and criteria ana-\nlyzed to select one approach and reject others. \nAlthough the reasons for decisions are likely \nto be obvious to the current design team, they \ncan be less obvious to those who modify or main-\ntain the system after deployment. Recording the \nrationale enhances the software product\u2019s long-\nterm maintainability. Continuing to capture \nthe rationale for changes during maintenance \nalso contributes to the software\u2019s viability.\nIt can also be useful to capture rejected deci-\nsions and the reasons for rejection. Capturing \nthese rationales can enable a team to revisit \na previously rejected decision when assump-\ntions, requirements or constraints change. The \nimportance of rationale is visible, for example, \nin free and open-source software (FOSS) \nprojects, which often involve large, distributed \nteams of developers with frequent turnover.\nDesign rationale may be captured as part \nof a software design description or as a com-\npanion artifact. Often rationale is captured in \ntext, but other forms of representation can also \nbe used, such as graphs that portray a design \nas an interconnected network of decisions.\n5.\t Software Design Strategies and Methods \n\b\n[21* c3]\nVarious strategies and methods exist to struc-\nture and guide the design process; many of \nthese evolved from programming styles or \nparadigms. In addition to embodying one or \nmore general strategies, most design methods \nfocus on making one or more design concepts \n(whether objects, methods or events) promi-\nnent as organizing themes for the software. \nThese themes then guide the designers as to \nwhat to focus on first, how to proceed, and \nhow to structure modules. \n5.1.\t General Strategies\b\n[4* c13]\nSome often-cited examples of general strategies \nuseful in the design process include divide-and-\nconquer and stepwise refinement strategies; top-\ndown vs. bottom-up strategies; strategies using \nheuristics, patterns and pattern languages; and \niterative and incremental approaches. \n5.2.\t Function-Oriented (or Structured)  \nDesign\b\n[4* c9]\nThis is one of the classical software design \nmethods. It focuses on refinement (or decom-\nposition) to identify major software func-\ntions, elaborating them in a top-down manner. \nStructured design often follows structured anal-\nysis, producing DFDs and associated process \ndescriptions. Various tools enable the automated \ntranslation of DFDs into high-level designs.\n5.3.\t Data-Centered Design\b\n[4* c9]\nData-centered design starts from the data \nstructures a program manipulates rather than \nfrom the functions it performs. The software \ndesigner specifies the input and output data \nstructures and then develops program units \nthat transform inputs into outputs. Various \nheuristics have been proposed to deal with spe-\ncial cases, such as cases where there is a mis-\nmatch between the input and output structures. \n5.4.\t Object-Oriented Design\b\n[4* c10]\nNumerous software design methods based \non objects have been proposed. The field \nhas evolved from the early object-oriented \ndesign of the mid-1980s (where nouns depict \nobjects; verbs depict methods; and adjec-\ntives depict attributes), where inheritance \nand polymorphism play key roles, to the field \nof component-based design (CBD), where \nmetainformation can be defined and accessed \n(through reflection, for example). Although \nOOD\u2019s roots stem from the concept of data \nabstraction, responsibility-driven design has \nbeen proposed as an alternative underlying \nprinciple of OOD. Often design strategies \n", "page": 93, "type": "text", "section": "Page 93"}
{"text": "3-12   SWEBOK \u00ae GUIDE V4.0\nare provided with mnemonics such as SOLID \n(Single-responsibility, Open\u2013closed, Liskov \nsubstitution, \nInterface \nsegregation, \nand \nDependency inversion) principles of class \ndesign and SOFA (Short, One thing, Few \narguments and Abstraction level consistency) \nprinciples for method design.\n5.5.\t User-Centered Design\b\n[3* c9] [16]\nUser-centered design is more than a design \nmethod; it is a multidisciplinary approach \nemphasizing a deep understanding of users \nand their needs as the basis for designing user \nexperiences within the context of their orga-\nnization and the tasks to be accomplished. It \ninvolves gathering user requirements, creating \na user flow of tasks and decisions, creating \nprototypes or mockups representative of user \ninterfaces, and evaluating the design solution \nagainst original requirements [16].\n5.6.\t Component-Based Design (CBD) \n\b\n[4* c11, c16] [21* c16]\nCBD decomposes a software system into one \nor more standalone components that com-\nmunicate only on well-defined interfaces and \nconform to a system-wide standard com-\nponent model. A software component is an \nindependent unit, having well-defined inter-\nfaces and dependencies that can be composed \nand deployed independently. CBD addresses \nissues related to providing, developing and \nintegrating such components to improve \nreuse. CBD often emphasizes common APIs \nfor all components and specialized APIs for \nspecific services or responsibilities.\n5.7.\t Event-Driven Design\b\n[14, 15]\nEvent-driven design is an approach where a \nsystem or component invokes its operations in \nreaction to events (indirect invocation) [15]. \nPublish/subscribe messaging (broadcasting) \nis often used as means of transporting events \nvia the network to all interested subscribers. \nPublish/subscribe keeps the producers and \nconsumers decoupled using a message broker \nwith channels called topics. This differs from \nPoint-to-point messaging where senders and \nreceivers need to know each other to deliver \nand receive a message. Different types of \nevent processing exist, i.e. simple event pro-\ncessing, event stream processing and complex \nevent processing. Message-based systems \nfrequently incorporate identifiable senders \nand receivers within the design. Event-\ndriven systems may not identify senders and \nreceivers explicitly\u2014instead each module \nproduces events while listening for any events \nthey care about or need to respond to [14]. \n\u201cAnonymous\u201d asynchronous message and \nevent processing are good strategies for scal-\nable systems. \n5.8.\t Aspect-Oriented Design (AOD)\b\n[12]\nAOD is a method by which software is con-\nstructed using aspects to implement the cross-\ncutting concerns and extensions identified in \nsoftware requirements [12]. AOD evolved \nfrom object-oriented design and program-\nming practices. Although it has yet to become \na widespread design or programming para-\ndigm, the aspect-oriented perspective is fre-\nquently used in application frameworks and \nsoftware libraries where parameters of the \nframework or library can be configured with \naspect declarations. \n5.9.\t Constraint-Based Design\b\n[3* c11]\nConstraints\u2019 role in the design process is to \nlimit the size of a design space to exclude infea-\nsible or unacceptable alternatives. Constraints \naccelerate design because they force a few early \ndecisions. The constraints can reflect limits \nimposed on the hardware, software, data, \noperational procedures, interfaces or anything \nthat affects the software. The constrained \ndesign space can then be explored with search \nor backtracking methods. Constraint-based \ndesign approaches are used in user interface \ndesign, gaming and other applications. In \ngeneral, constraint satisfaction problems can \nbe computationally intractable; however, var-\nious kinds of constraint-based programming \n", "page": 94, "type": "text", "section": "Page 94"}
{"text": "SOFTWARE DESIGN   3-13\ncan be used to approximate or solve con-\nstraint problems.\n5.10.\t\n Domain-Driven Design\b\n[14]\nDomain-driven design is a method in which \nthe designer uses a domain-specific language \nshared with analysts and other stakeholders to \ndescribe the target software system. Through \nthis shared language, objects, roles, events, \nand activities specified in the software require-\nments can be expressed in the software design \ndescriptions. (See the Requirements KA).\n5.11.\t\n Other Methods\b\n[21* c18\u2013c21]\nOther approaches to design exist (see Software \nEngineering Models and Methods KA). \nFor example, iterative and adaptive methods \nimplement software increments and reduce \nthe emphasis on rigorous software require-\nments and design. \nService-oriented methods builds distrib-\nuted software using web services executed on \ndistributed computers. Software systems are \noften constructed using services from different \nproviders interconnect with standard proto-\ncols (e.g., HTTP, HTTPS, SOAP) designed \nto support service communication and service \ninformation exchange. \n6.\t Software Design Quality Analysis and \nEvaluation\b\n[4* c7] [21* c24]\n6.1.\t Design Reviews and Audits\b\n[4* c5.3]\nDesign reviews are intended as compre-\nhensive examinations of a design to assess \nconcerns such as status or degree of com-\npletion, coverage of requirements, open or \nunresolved issues and potential problems. A \ndesign review can be undertaken at any stage \nof design. Design reviews can be conducted \nby the design team, by an independent third \nparty or other stakeholder. A design audit is \nmore narrowly focused on a set list of char-\nacteristics (e.g., a functional audit). (See also \nsection 2.3 Reviews and Audits in Software \nQuality KA).\n6.2.\t Quality Attributes\b\n[21* c24]\nVarious attributes contribute to the quality of \na software design, including various \u201cilities\u201d \n(modularity, maintainability, portability, test-\nability, usability) and \u201cnesses\u201d (correctness, \nrobustness). Qualities are a major subset of \nconcerns (see topic Stakeholders and Concerns \nin Software Architecture KA). Some qualities \ncan be observed at runtime (e.g., performance, \nsecurity, availability, functionality, usability); \nothers cannot (e.g., modifiability, portability, \nreusability, testability); some (e.g., concep-\ntual integrity, correctness, completeness) are \nobservable in the design of the software.\n6.3.\t Quality Analysis and Evaluation \nTechniques\b\n[21* c24]\nVarious tools and techniques can help in ana-\nlyzing and evaluating software design quality. \n(See also topic Software Quality Tools in \nSoftware Quality KA.)\n\u2022\t Software design reviews include informal \nand rigorous techniques to determine \nsoftware qualities based on SDDs and \nother design artifacts for example, archi-\ntecture reviews, design reviews and \ninspections; scenario-based techniques; \nrequirements tracing. \n\u2022\t Static analysis: formal or semiformal static \n(nonexecutable) analysis that can be used \nto evaluate a design (for example, fault-\ntree analysis or automated cross-checking). \nDesign vulnerability analysis (for example, \nstatic analysis for security weaknesses) \ncan be performed if security is a concern. \nFormal design analysis uses mathemat-\nical models that allow designers to predict \nthe behavior and validate the performance \nof the software instead of having to rely \nentirely on testing. Formal design anal-\nysis can be used to detect residual speci-\nfication and design errors (perhaps caused \nby imprecision, ambiguity, and sometimes \nother kinds of mistakes). (See also Software \nEngineering Models and Methods KA.) \n\u2022\t Simulation and prototyping: dynamic \n", "page": 95, "type": "text", "section": "Page 95"}
{"text": "3-14   SWEBOK \u00ae GUIDE V4.0\ntechniques to evaluate a design (for \nexample, performance simulation or fea-\nsibility prototypes). \n6.4.\t Measures and Metrics \n\b\n[4* c5, c17] [21* c24.5]\nMeasures can be used to assess or to quanti-\ntatively estimate various aspects of a software \ndesign; for example, size, structure, or quality. \nMost measures that have been proposed are \nbased upon the approach used for producing \nthe design (see topic 5 Software Design \nStrategies and Methods). These measures are \nclassified in two broad categories: \n\u2022\t Function-based (structured) design mea-\nsures: measures obtained by analyzing \nfunctional decomposition; generally rep-\nresented using a structure chart (or hierar-\nchical diagram) on which various measures \ncan be calculated. \n\u2022\t Object-oriented design measures: the \ndesign structure is typically represented \nas a class diagram, on which various mea-\nsures can be computed. Measures on \nthe properties of the internal content of \neach class can also be calculated. Object-\noriented measures also consider the com-\nplexity of the code based on the lines of \ncode per method or the number of mes-\nsages sent.\n6.5.\t Verification, Validation, and Certification \n\b\n[21* c7, c8]\nSystematic analysis or evaluation of the design \nplays an important role in each of these \nthree areas:\n\u2022\t verification: to confirm that the design \nsatisfies stated requirements;\n\u2022\t validation: to establish that the design will \nallow the system to meet the expectations \nof its stakeholders, including customers, \nusers, operators and maintainers;\n\u2022\t certification: third-party attestation of \nconformity of design to its overall spec-\nification and intended usage.\n(See also section 2.2 Verification and \nValidation in Software Quality KA.)\nMATRIX OF TOPICS VS. REFERENCE MATERIAL\nIn table below, cX means chapter X\n1. Software Design \nFundamentals\nBrooks  \n[3*]\nBudgen  \n[4*]\nGamma et al. \n \n[7*]\nSommerville \n \n[21*]\nSee also\n1.1 Design Thinking\nc1, c2, c3\nc1, c2\n[20]\n1.2  Context of Software Design\nc13, c14\nc19, c20\n1.3 Key Issues in Software Design\n[2, 12]\n1.4 Software Design Principles\n[5, 10,  \n17, 20]\n2. Software Design Processes\nc3\nc2, c7\n[10]\n2.1 High-level Design\nc5\nc6\n[10]\n2.2 Detailed Design\n[10]\n3. Software Design Qualities\nc4\n[20]\n3.1 Concurrency\nc17\n3.2 Control and \nHandling of Events\nc21\n3.3 Data Persistence\nc6, c16\n", "page": 96, "type": "text", "section": "Page 96"}
{"text": "SOFTWARE DESIGN   3-15\n3.4 Distribution of Components\nc17\n3.5 Errors and Exception \nHandling, Fault Tolerance\nc11\n3.6 Integration and \nInteroperability\nc11, c14,  \nc16\n3.7 Assurance, Security and Safety\nc10\u2013c14\n3.8 Variability\n[6]\n4. Recording \nSoftware Designs\nc7, c8\n[1]\n4.1 Model-based Design\nc7.3\nc5.5\n4.2 Structural Design \nDescriptions\nc7, c10\nc4\nc5.3\n4.3 Behavioral Design \nDescriptions\nc9, c10\nc5\nc5.4\n4.4 Design Patterns and Styles\nc12\nc15\nc1, c2\nc7.2\n[7]\n4.5 Specialized and Domain-\nSpecific Languages\nc15\n4.6 Design Rationale\nc16\nc12\nc6.1\n5. Software Design Strategies \nand Methods\nc3\n5.1 General Strategies\nc13\n5.2 Function-Oriented (or \nStructured) Design\nc9\n5.3 Data-Centered Design\nc9\n5.4 Object-Oriented Design\nc10\n5.5 User-Centered Design\nc9\n[16]\n5.6 Component-Based \nDesign (CBD)\nc11, c16\nc16\n5.7 Event-Driven Design\n[14, 15]\n5.8 Aspect-Oriented Design (AOD)\n[12]\n5.9 Constraint-Based Design\nc11\n5.10 Domain-Driven Design\n[13]\n5.11 Other Methods\nc18\u2013c21\n6. Software Design Quality \nAnalysis and Evaluation\nc17\nc24\n6.1 Design Reviews and Audits\nc5.3\n6.2 Quality Attributes\nc24\n6.3 Quality Analysis and \nEvaluation Techniques\nc24\n6.4 Measures and Metrics\nc5, c17\nc24.5\n6.5 Verification, Validation and \nCertification\nc7,c8\n", "page": 97, "type": "text", "section": "Page 97"}
{"text": "3-16   SWEBOK \u00ae GUIDE V4.0\nFURTHER READINGS\nBrooks, The Design of Design [3*]\nBrooks, one of the pioneers of software engi-\nneering, provides a collection of essays and \ncase studies on all aspects of software design.\nREFERENCES\n[1]\t *G. Booch, J. Rumbaugh, and I. \nJacobson, The Unified Modeling Language \nUser Guide, 2nd edition, Addison-\nWesley, 2005. \n[2]\t J. Bosch, Design and Use of Software \nArchitectures: Adopting and Evolving \na Product-Line Approach, ACM \nPress, 2000.\n[3]\t *F. Brooks, The Design of Design, \nAddison-Wesley, 2010.\n[4]\t *D. Budgen, Software Design: Creating \nSolutions for Ill-Structured Problems, 3rd \nEdition CRC Press, 2021.\n[5]\t E.W. Dijkstra, On the Role of Scientific \nThought. 1974. http://www.cs.utexas \n.edu/users/EWD/transcriptions/\nEWD04xx/EWD447.html.\n[6]\t M. Galster, D. Weyns, D. Tofan, B. \nMichalik, and P. Avgeriou, Variability \nin Software Systems\u2014A Systematic \nLiterature Review, IEEE Transactions on \nSoftware Engineering, 40(3), 2014.\n[7]\t *E. Gamma et al., Design Patterns: \nElements of Reusable Object-Oriented \nSoftware, 1st ed, Addison-Wesley, 1994.\n[8]\t S. Gregor and D. Jones, The Anatomy \nof a Design Theory, Association for \nInformation Systems, 2007.\n[9]\t IEEE Std 7000\u2122-2021, IEEE Standard \nModel Process for Addressing Ethical \nConcerns during System Design. \n[10]\tISO/IEC/IEEE 12207, Systems and \nSoftware Engineering \u2014 Software Life \nCycle Processes.\n[11]\tISO/IEC/IEEE, \u201cISO/IEC/IEEE \n24765:2017 Systems and Software \nEngineering \u2014 Vocabulary,\u201d \n2nd ed. 2017.\n[12]\tG. Kiczales et al., Aspect-Oriented \nProgramming, Proc. 11th European Conf. \nObject-Oriented Programming (ECOOP \n97), Springer, 1997. \n[13]\tT. Kosar, S. Bohra, M. Mernik, \nDomain-Specific Languages: A \nSystematic Mapping Study, Information \nand Software Technology, 71, 77-91, 2016.\n[14]\tD. Luckham, The Power of Events: an \nIntroduction to Complex Event Processing, \nAddison-Wesley, 2002.\n[15]\tG. M\u00fchl, L. Fiege, and P. Pietzuch, \nDistributed Event-Based Systems, Spring-\nVerlag, 2006.\n[16]\tJ. Nielsen, Usability Engineering, Morgan \nKaufman, 1994.\n[17]\tD.L. Parnas, On the Criteria To Be \nUsed In Decomposing Systems Into \nModules, Communications of the ACM \n15(12), 1053\u20131058, 1972. \n[18]\tD.L. Parnas and P.C. Clements, A \nRational Design Process: How and Why \nto fake it, IEEE Transactions on Software \nEngineering 12(2), 251\u2013 257, 1986. \n[19]\tD.L. Parnas and D.M. Weiss, Active \nDesign Reviews: Principles and \nPractices, Journal of Systems & Software \n7, 259\u2013265, 1987 \n[20]\tD.T. Ross, J.B. Goodenough, and \nA. Irvine, Software Engineering: \n", "page": 98, "type": "text", "section": "Page 98"}
{"text": "SOFTWARE DESIGN   3-17\nProcess, Principles, and Goals, IEEE \nComputer, May 1975.\n[21]\t*I. Sommerville, Software Engineering, \n10th edition, Pearson, 2016.\n", "page": 99, "type": "text", "section": "Page 99"}
{"text": "4-1 \nCHAPTER 04\nSoftware Construction\nACRONYMS\nAPI\nApplication \nProgramming Interface\nASIC\nApplication-Specific \nIntegrated Circuit\nBaaS\nBackend As A Service\nCI\nContinuous Integration\nCOTS\nCommercial Off-The-Shelf\nCSS\nCascading Style Sheets\nDSL\nDomain-Specific Language\nDSP\nDigital Signal Processor\nESB\nEnterprise Service Bus\nFPGA\nField Programmable \nGate Array\nGPU\nGraphic Processing Unit\nGUI\nGraphical User Interface\nHTML5\nHypertext Markup \nLanguage Version 5\nIDE\nIntegrated Development \nEnvironment\nIEEE\nInstitute Of Electrical And \nElectronics Engineers\nISO\nInternational Organization \nFor Standardization\nJEE\nJakarta Enterprise Edition\nKA\nKnowledge Area\nMDA\nModel-Driven Architecture\nNPM\nNode Package Manager\nOMG\nObject Management Group\nPIM\nPlatform Independent Model\nPOSIX\nPortable Operating \nSystem Interface\nPSM\nPlatform-Specific Model\nSDK\nSoftware Development Kit\nTDD\nTest-Driven Development\nUML\nUnified Modeling Language\nWYSIWYG\nWhat You See Is \nWhat You Get\nINTRODUCTION\nSoftware construction refers to the detailed cre-\nation and maintenance of software through \ncoding, verification, unit testing, integration \ntesting and debugging.\nThe software construction knowledge area \n(KA) is linked to all the other KAs, but it is \nmost strongly linked to the Software Design \nand Software Testing KAs because the soft-\nware construction process involves signifi-\ncant design and testing. The process uses the \ndesign output and provides an input to testing \n(\u201cdesign\u201d and \u201ctesting\u201d in this case referring \nto the activities, not the KAs). Boundaries \namong design, construction and testing (if \nany) vary depending on the software life cycle \nprocesses used in a project.\nAlthough some detailed design might be \nperformed before construction, much design \nwork is performed during construction. Thus, \nthe Software Construction KA is closely \nlinked to the Software Design KA.\nAlso, throughout construction, software \nengineers both unit-test and integration-test \ntheir work. Thus, the Software Construction \nKA is closely linked to the Software Testing \nKA as well.\n", "page": 100, "type": "text", "section": "Page 100"}
{"text": "4-2   SWEBOK \u00ae GUIDE V4.0\nThe Software Construction KA is also \nrelated to configuration management, quality, \nproject management and computing, and thus \nto the relevant KAs. \nFirst, software construction typically pro-\nduces the highest number of configuration \nitems that need to be managed in a software \nproject (e.g., source files, documentation, test \ncases). Thus, the Software Construction KA is \nclosely linked to the Software Configuration \nManagement KA.\nSecond, while quality is important in all the \nKAs, code is a software project\u2019s ultimate deliv-\nerable, and code is produced during construc-\ntion. Thus, the Software Quality KA is closely \nlinked to the Software Construction KA.\nThird, while project management involves \nvarious software development tasks, soft-\nware construction typically produces the most \ndeliverables of a software project. Thus, the \nSoftware Construction KA is closely linked to \nthe Software Engineering Management KA.\nFourth, since software construction requires \nknowledge of algorithms and coding practices, \nthis KA is closely related to the Computing \nFoundations KA, which concerns the com-\nputer science foundations supporting software \nproduct design and construction.\nBREAKDOWN OF TOPICS FOR \nSOFTWARE COSTRUCTION\nThe breakdown of topics for the Software \nArchitecture KA is shown in Figure 4-1.\n1.\t Software Construction Fundamentals\nSoftware construction fundamentals include \nthe following:\n\u2022\t Minimizing complexity\n\u2022\t Anticipating and embracing change\n\u2022\t Constructing for verification\n\u2022\t Reusing assets\n\u2022\t Applying standards in construction\nThe first four concepts apply to design as \nwell as to construction. The following sections \ndefine these concepts and describe how they \napply to construction.\n1.1.\t Minimizing Complexity \b\n[1, c2, c3, \n\b\nc7-9, c24, c27, c28, c3, 1, c32, c34]\nMost people have limited ability to hold \ncomplex structures and information in their \nworking memories, especially over long \nperiods. This greatly influences how people \nconvey intent to computers and drives one \nof the key goals in software construction \u2014 \nto minimize complexity. The need to reduce \ncomplexity applies to essentially every aspect \nof software construction and is particularly \ncritical to testing software constructions.\nSeveral types of complexity can affect \nsoftware construction. Tools can be used to \nmanage different aspects of the complexity \nof software components and their construc-\ntion. For example, cyclomatic complexity is a \nstatic analysis measure of how difficult code is \nto test and understand. The tool, developed by \nThomas J. McCabe, Sr., in 1976, calculates the \nnumber of linearly independent paths through \na program\u2019s source code. Ideally, there should \nbe at least that number of test cases. Other \nexamples are tools like Make, which can build \nan application, or integrated development \nenvironments (IDEs) for entering, editing and \ncompiling code. These tools help manage the \ncomplexity of the construction process.\nIn software construction, reduced com-\nplexity is achieved by creating simple and \nreadable code rather than clever code. This is \naccomplished by using standards (see section \n3.1.5, Standards in Construction), modular \ndesign (see section 3.1, Construction Design) \nand numerous other specific techniques (see \nsection 3.3, Coding). Construction-focused \nquality techniques also support this (see sec-\ntion 3.6, Construction Quality).\n1.2.\t Anticipating and Embracing Change \n[1-c3-c5, c24, c31, \n \nc32, c34, 2-c1, c3, c9, 3-c1]\nMost software changes over time, and \nanticipating change drives many aspects \n", "page": 101, "type": "text", "section": "Page 101"}
{"text": "SOFTWARE CONSTRUCTION   4-3\nof software construction; changes in the \nenvironments in which software oper-\nates also affect software in diverse ways. \nAnticipating change helps software engi-\nneers build extensible software, enhancing \na software product without disrupting the \nunderlying structure. Anticipating change \nis supported by many specific techniques \n(see section 3.3, Coding).\nMoreover, today\u2019s business environments \nrequire many organizations to deliver and \ndeploy software more frequently, faster and \nmore reliably. Anticipating specific, nec-\nessary changes can be difficult, so soft-\nware engineers should be careful to build \nflexibility and adaptability into the soft-\nware to incorporate changes with less diffi-\nculty. These software teams should embrace \nchange by adopting agile development, \npracticing DevOps, and by adopting con-\ntinuous delivery and deployment practices. \nSuch practices align the software develop-\nment process and management with an evo-\nlutionary environment.\nSoftware\nConstruction\nSoftware\nConstruction\nFundamentals\nMinimizing\nComplexity\nAnticipating and \nEmbracing Change\nConstruction for \nVerifcation\nReusing Assets\nApplying Standards \nin Construction\nConstruction in \nLife Cycle Models\nConstruction \nPlanning\nConstruction \nMeasurements\nManaging\nDependencies\nConstruction \nDesign\nConstruction \nLanguages\nCoding\nConstruction \nTesting\nReuse in\nConstruction\nConstruction \nQuality\nIntegration\nCross-Platform\nDevelopment \nand Migration \nAPI Design \nand Use\nObject-Oriented \nRuntime Issues\nParameterization,\nTemplates and\nGenerics\nAssertions,\nDesign by Contract \nand Defensive \nProgramming\nError Handling,\nException Handling\nand Fault Tolerance\nExecutable Models\nState-Based and \nTable-Driven \nConstruction Techniques\nRuntime Confguration and\nInternationalization\nGrammar-Based\nInput Processing\nConcurrency Primitives\nMiddleware\nConstruction Methods\nfor Distribution and\nCloud-Based Software\nConstructing\nHeterogeneous Systems\nPerformance Analysis\nand Tuning\nPlatform Standards\nTest-First Programming\nFeedback Loop \nfor Construction\nDevelopment\nEnvironments\nVisual Programming\nand Low-Code/\nZero-Code Platforms\nUnit Testing Tools\nProofng, Performance\nAnalysis and Slicing Tools\nManaging\nConstruction\nPractical\nConsiderations\nConstruction\nTechnologies\nSoftware\nConstruction\nTools\nFigure 4.1. Breakdown of Topics for the Software Construction KA\n", "page": 102, "type": "text", "section": "Page 102"}
{"text": "4-4   SWEBOK \u00ae GUIDE V4.0\n1.3.\t Constructing for Verification \b\n[1-c8, \n\b\nc20-c23, c31, c34]\nConstructing for verification builds software in \nsuch a way that faults can be readily found by \nthe software engineers writing the software as \nwell as by the testers and users during inde-\npendent testing and operational activities. \nSpecific techniques that support constructing \nfor verification include following coding \nstandards to support code reviews and unit \ntesting, organizing code to support automated \ntesting, restricting the use of complex or dif-\nficult-to-understand language structures, and \nrecording software behaviors with logs.\n1.4.\t Reusing Assets \b\n[2-c15]\nReuse means using existing assets to solve dif-\nferent problems. In software construction, \ntypical assets that are reused include frame-\nworks, libraries, modules, components, source \ncode and commercial off-the-shelf (COTS) \nassets. Reuse has two closely related facets: \nconstruction for reuse and construction with reuse. \nThe former means creating reusable software \nassets, whereas the latter means reusing soft-\nware assets to construct a new solution. Reuse \noften transcends project boundaries, which \nmeans reused assets can be constructed in \nother projects or organizations.\n1.5.\t Applying Standards in Construction \b [1-c4]\nApplying external or internal development \nstandards during construction helps achieve \na project\u2019s efficiency, quality and cost objec-\ntives. Specifically, the choices of allowable \nprogramming language subsets and usage \nstandards are important aids in achieving \nhigher security.\nStandards that directly affect construction \nissues include the following:\n\u2022\t Communication methods (e.g., standards \nfor document formats and content)\n\u2022\t Programming languages (e.g., standards \nfor languages like Java and C++)\n\u2022\t Coding \nstandards \n(e.g., \nstandards \nfor naming conventions, layout and \nindentation)\n\u2022\t Exception handling policies (e.g., stan-\ndards for the information included in \nexceptions and the way how exceptions \nare handled after catching)\n\u2022\t Platforms (e.g., interface standards for \noperating system calls)\n\u2022\t Tools (e.g., diagrammatic standards \nfor notations like UML - Unified \nModeling Language)\nUse of external standards: Construction \ndepends on external standards for construction \nlanguages, construction tools, technical inter-\nfaces and interactions between the Software \nConstruction KA and other KAs. Standards \ncome from numerous sources, including \nhardware and software interface specifica-\ntions (e.g., OMG - Object Management \nGroup) \nand \ninternational \norganizations \n(e.g., IEEE - the Institute of Electrical and \nElectronics Engineers, ISO - the International \nOrganization for Standardization).\nUse of internal standards: Standards may \nalso be created on an organizational basis at the \ncorporate level or for use on specific projects. \nThese standards support coordinating group \nactivities, minimizing complexity, anticipating \nchange and constructing for verification.\n2.\t Managing Construction\n2.1.\t Construction in Life Cycle Models  \n\b\n[1-c2, c3, c27, c29, 2-c3, c7, 3-c1]\nNumerous models have been created to \ndevelop software; some emphasize construc-\ntion more than others.\nSome models are more linear from the \nconstruction viewpoint, such as the water-\nfall and staged-delivery life cycle models. \nThese models treat construction as an activity \nthat occurs only after the completion of sig-\nnificant prerequisite work, including detailed \nrequirements work, extensive design work and \ndetailed planning. The more linear approaches \nemphasize the activities that precede con-\nstruction (requirements and design) and create \n", "page": 103, "type": "text", "section": "Page 103"}
{"text": "SOFTWARE CONSTRUCTION   4-5\nmore distinct separations between activities. \nIn these models, construction\u2019s main emphasis \nmight be coding.\nOther models, such as evolutionary proto-\ntyping and agile development, are more iter-\native. These approaches treat construction as \nan activity that occurs concurrently with or \noverlaps other software development activi-\nties (including requirements, design and plan-\nning). These approaches mix design, coding \nand testing activities, and they often treat the \ncombination of activities as construction (see \nthe Software Engineering Management and \nSoftware Process KAs). \nThe practices of continuous delivery and \ndeployment further mix coding, testing, \ndelivery and deployment activities. In these \npractices, software updates made during con-\nstruction activities are continuously delivered \nand deployed into the production environ-\nment. The whole process is fully automated \nby a deployment pipeline that consists of var-\nious testing and deployment activities.\nConsequently, what is considered construc-\ntion depends on the life cycle model used. \nIn general, software construction is mostly \ncoding and debugging, but it also involves \nconstruction planning, detailed design, unit \ntesting, integration testing and other activities.\n2.2.\t Construction Planning \b\n[1-c3, c4, \n \n\b\nc21, c27-c29]\nThe choice of construction method is a key \naspect of the construction planning activity. \nThis choice affects the extent to which con-\nstruction prerequisites are performed, the \norder in which they are performed and the \ndegree to which they should be completed \nbefore construction work begins.\nThe approach to construction affects the \nproject team\u2019s ability to reduce complexity, \nanticipate change and construct for verifica-\ntion. Each objective may also be addressed at \nthe process, requirements and design levels, \nbut the choice of construction method will \ninfluence them.\nConstruction planning also defines the \norder in which components are created and \nintegrated, the integration strategy (for \nexample, phased or incremental integration), \nthe software quality management processes, \nthe allocation of task assignments to specific \nsoftware engineers, and other tasks, according \nto the chosen method.\n2.3.\t Construction Measurement \b\n[1-c25, c28]\nNumerous construction activities and arti-\nfacts can be measured, including code devel-\noped, modified, reused, and destroyed; code \ncomplexity; code inspection statistics; fault-fix \nand fault-find rates; effort; and scheduling. \nThese measurements can be useful for man-\naging construction, ensuring quality during \nconstruction and improving the construc-\ntion process, among other uses (see the \nSoftware Engineering Process KA for more \non measurement).\n2.4.\t Managing Dependencies \b\n[2-c25]\nSoftware products often heavily rely on depen-\ndencies, including internal and external (com-\nmercial or open-source) dependencies, which \nallow developers to reuse common functional-\nities instead of reinventing the wheel and sub-\nstantially improve developers\u2019 productivity. In \naddition, package managers (e.g., Maven in \nJava and NPM in JavaScript) are widely used to \nautomate the process of installing, upgrading, \nconfiguring and removing dependencies. \nThe direct and indirect dependencies of \nsoftware products constitute a dependency \nsupply chain network. Any dependency in the \nsupply chain network can introduce poten-\ntial risk to software products and should be \nmanaged by developers or tools. Unnecessary \ndependencies should be avoided to improve \nbuild efficiency. License conflicts between \ndependencies and software products should \nbe avoided to reduce legal risk. Propagation \nof dependencies\u2019 defects or vulnerabilities into \nsoftware products should be avoided to improve \nthe quality of software products. Regulations \nand monitoring mechanisms should be devel-\noped to prevent developers from introducing \nuntrusted external dependencies.\n", "page": 104, "type": "text", "section": "Page 104"}
{"text": "4-6   SWEBOK \u00ae GUIDE V4.0\n3.\t Practical Considerations\nConstruction is an activity in which the soft-\nware engineer often has to deal with some-\ntimes chaotic, changing and even conflicting \nreal-world constraints. Because of real-world \nconstraints, practical considerations drive \nconstruction more than some other KAs, and \nsoftware engineering is perhaps most craft-\nlike in the construction activities compared \nwith other activities.\n3.1.\t Construction Design\b [1-c3, c5, c24, 2-c7]\nSome projects allocate considerable design \nactivity to construction, whereas others allo-\ncate design to a phase explicitly focused on \ndesign. Regardless of the exact allocation, \nsome detailed design work occurs at the con-\nstruction level, and that design work is dic-\ntated by constraints imposed by the real-world \nproblem the software addresses.\nJust as construction workers building a \nphysical structure must make small modifi-\ncations for unanticipated gaps in the builder\u2019s \nplans, software construction workers must \nmake small or large modifications to flesh out \nsoftware design details during construction.\nThe details of the design activity at the \nconstruction level are essentially the same as \ndescribed in the Software Design KA, but \nthey are applied at a smaller scale to algo-\nrithms, data structures and interfaces.\n3.2.\t Construction Languages \b\n[1-c4]\nConstruction languages include all forms \nof communication by which a human can \nspecify an executable solution to a problem. \nConsequently, construction languages and \ntheir implementations (e.g., compilers) can \naffect software quality attributes such as per-\nformance, reliability and portability. As a \nresult, they can seriously contribute to secu-\nrity vulnerabilities.\nThe simplest construction language is a \nconfiguration language, in which software \nengineers choose from a limited set of pre-\ndefined options to create new or custom \nsoftware installations. The text-based config-\nuration files used in both the Windows and \nUnix operating systems are examples of this, \nand some program generators\u2019 menu-style \nselection lists constitute another example of a \nconfiguration language.\nToolkit languages are used to build appli-\ncations from elements in toolkits (integrated \nsets of application-specific reusable parts); \nthey are more complex than configuration \nlanguages. Toolkit languages may be explic-\nitly defined as application programming lan-\nguages, or the applications might be implied \nby a toolkit\u2019s set of interfaces.\nScripting languages are commonly used \napplication programming languages. In some \nscripting languages, scripts are called batch \nfiles or macros.\nProgramming languages are the most flex-\nible construction languages. They also contain \nthe least amount of information about specific \napplication areas and development processes. \nTherefore, they require the most training and \nskill to use effectively. The choice of program-\nming language can greatly affect the like-\nlihood of vulnerabilities being introduced \nduring coding (e.g., unsafe use of C and C++ \nlibrary functions is questionable from a secu-\nrity viewpoint).\nThree general notations are used for pro-\ngramming languages:\n\u2022\t Linguistic (e.g., C/C++, Java)\n\u2022\t Formal (e.g., Event-B)\n\u2022\t Visual (e.g., MATLAB)\nLinguistic notations are distinguished in \nparticular by the use of textual strings to rep-\nresent complex software constructions. The \ncombination of textual strings in patterns may \nhave a sentence-like syntax. Properly used, \neach string should have a strong semantic \nconnotation providing an immediate intui-\ntive understanding of what happens when the \nsoftware construction is executed.\nFormal notations rely less on intuitive, \neveryday meanings of words and text strings \nand more on definitions backed by precise, \nunambiguous and formal (or mathematical) \n", "page": 105, "type": "text", "section": "Page 105"}
{"text": "SOFTWARE CONSTRUCTION   4-7\ndefinitions. Formal construction notations \nand methods are at the semantic base of most \nsystem programming notations, where accu-\nracy, time behavior and testability are more \nimportant than ease of mapping into natural \nlanguage. Formal constructions also use pre-\ncisely defined ways of combining symbols that \navoid the ambiguity of many natural language \nconstructions.\nVisual notations rely much less on the \ntextual notations of linguistic and formal \nconstruction and more on direct visual inter-\npretation and placement of visual entities that \nrepresent the underlying software. Visual \nconstruction is somewhat limited by the dif-\nficulty of making \u201ccomplex\u201d statements using \nonly the arrangement of icons on a display. \nHowever, these icons can be powerful tools \nin cases where the primary programming task \nis to build and \u201cadjust\u201d a visual interface to a \nprogram, the detailed behavior of which has \nan underlying definition.\nNowadays, \ndomain-specific \nlanguages \n(DSLs) are widely used to build domain-spe-\ncific applications. Unlike a general-pur-\npose programming language, such as C/C++ \nor Java, a DSL is designed for the applica-\ntion construction of a particular domain. \nTherefore, a DSL usually can be defined \nbased on a higher level of abstraction of the \ntarget domain and can be optimized for a \nspecific class of problems. Furthermore, A \nDSL usually can be expressed by visual nota-\ntions defined by domain-specific concepts \nand rules.\n3.3.\t Coding \b\n[1-c5-c19, c25-c26]\nThe following considerations apply to the \nsoftware construction coding activity:\n\u2022\t Techniques for creating understandable \nsource code, including naming conven-\ntions and source code layout\n\u2022\t Use of classes, enumerated types, vari-\nables, named constants and other sim-\nilar entities\n\u2022\t Use of control structures \n\u2022\t Handling of error conditions \u2014 both \nanticipated and exceptional (e.g., input \nof bad data)\n\u2022\t Prevention \nof \ncode-level \nsecurity \nbreaches (e.g., buffer overflows or array \nindex bounds)\n\u2022\t Resource use through use of exclusion \nmechanisms and discipline in accessing \nserially reusable resources, including \nthreads and database locks\n\u2022\t Source code organization into state-\nments, routines, classes, packages or \nother structures\n\u2022\t Code documentation\n\u2022\t Code tuning\n3.4.\t Construction Testing \b\n[1-c22, c23, 2-c8]\nConstruction involves two forms of testing, \nwhich are often performed by the software \nengineer who wrote the code: unit testing and \nintegration testing.\nConstruction testing aims to reduce the gap \nbetween when faults are inserted into the code \nand when those faults are detected, thereby \nreducing the cost incurred to fix them. In \nsome instances, test cases are written after the \ncode has been written. In other instances, test \ncases might be created before code is written.\nConstruction testing typically involves a \nsubset of the various types of testing, described \nin the Software Testing KA. For instance, \nconstruction testing does not typically include \nsystem testing, alpha testing, beta testing, \nstress testing, configuration testing, usability \ntesting, or other more specialized testing.\nTwo standards have been published on \nconstruction testing: IEEE Standard 829-\n1998, \u201cIEEE Standard for Software Test \nDocumentation,\u201d \nand \nIEEE \nStandard \n1008-1987, \u201cIEEE Standard for Software \nUnit Testing.\u201d\nSee sections 2.1.1 and 2.1.2 in the Software \nTesting KA for more specialized refer-\nence material.\n3.5.\t Reuse in Construction \b\n[2-c15, c16]\nReuse in construction includes both construc-\ntion for reuse and construction with reuse. \n", "page": 106, "type": "text", "section": "Page 106"}
{"text": "4-8   SWEBOK \u00ae GUIDE V4.0\nConstruction for reuse creates software \nwith the potential to be reused in the future \nfor the present project or for other projects \nwith a broad-based, multisystem perspec-\ntive. Construction for reuse is usually based \non variability analysis and design. To avoid \nthe problem of code clones, developers should \nencapsulate reusable code fragments into \nwell-structured libraries or components.\nThe tasks related to software construc-\ntion for reuse during coding and testing are \nas follows:\n\u2022\t Variability implementation with mech-\nanisms such as parameterization, condi-\ntional compilation and design patterns\n\u2022\t Variability \nencapsulation \nto \nmake \nthe software assets easy to configure \nand customize\n\u2022\t Testing the variability provided by the \nreusable software assets\n\u2022\t Description and publication of reusable \nsoftware assets\nConstruction with reuse means creating \nnew software by reusing existing software \nassets. The most popular reuse method is \nto reuse code from the libraries provided by \nthe language, platform, tools or an organi-\nzational repository. Aside from these, many \napplications developed today use open-source \nlibraries. In addition, reused and off-the-\nshelf software often have the same (or better) \nquality requirements as newly developed soft-\nware (e.g., security level requirements).\nThe tasks related to software construc-\ntion with reuse during coding and testing are \nas follows:\n\u2022\t Selecting reusable units, databases, test \nprocedures or test data\n\u2022\t Evaluating code or test reusability\n\u2022\t Integrating reusable software assets into \nthe current software\n\u2022\t Reporting reuse information on new \ncode, test procedures or test data\nThe forms of reusable software assets are \nnot limited to software artifacts that must be \nlocally integrated. Nowadays, cloud services \nthat provide various services through online \ninterfaces such as RESTful application pro-\ngramming interfaces (APIs) are widely used in \napplications. In the new cloud service model \nBaaS (backend as a service), applications del-\negate their backend implementations to cloud \nservice providers \u2014 for example, utilities such \nas authentication, messaging and storage are \nusually provided by cloud providers.\nReuse is best practiced systematically, \naccording to a well-defined, repeatable pro-\ncess. Systematic reuse can enable signifi-\ncant software productivity, quality and cost \nimprovements. Systematic reuse is supported \nby methodologies such as software product \nline engineering and various software frame-\nworks and platforms. Widely used frameworks \nsuch as Spring provide reusable infrastruc-\ntures for enterprise applications so soft-\nware teams can focus on application-specific \nbusiness logic. Commercial platforms pro-\nvide various reusable frameworks, libraries, \ncomponents and tools to support application \ndevelopment to build their ecosystems.\n3.6.\t Construction Quality \b\n[1-c8, c20-c25, \n\b\n2-c8, c24]\nIn addition to faults occurring during require-\nments and design activities, faults introduced \nduring construction can cause serious quality \nproblems (e.g., security vulnerabilities). These \ninclude not only faults in security function-\nality but also faults elsewhere that allow \nbypassing of the security functionality or \ncreate other security weaknesses or violations.\nNumerous techniques exist to ensure the \nquality of code as it is constructed. The pri-\nmary techniques used to ensure construction \nquality are the following:\n\u2022\t Unit testing and integration testing (see \nsection 3.4, Construction Testing)\n\u2022\t Test-first development (see section 6.1.2 \nin the Software Testing KA)\n\u2022\t Use \nof \nassertions \nand \ndefensive \nprogramming\n\u2022\t Debugging\n", "page": 107, "type": "text", "section": "Page 107"}
{"text": "SOFTWARE CONSTRUCTION   4-9\n\u2022\t Inspections\n\u2022\t Technical reviews, including securi-\nty-oriented reviews (see section 2.3 in the \nSoftware Quality KA)\n\u2022\t Static analysis (see section 2.2.1 of the \nSoftware Quality KA)\nThe specific technique or techniques \nselected depend on the software constructed \nand on the skill set of the software engi-\nneers performing the construction activities. \nProgrammers should know good practices and \ncommon vulnerabilities (e.g., from widely rec-\nognized lists about common vulnerabilities). \nAutomated static code analysis for security \nweaknesses is available for several common \nprogramming languages and can be used in \nsecurity-critical projects.\nConstruction quality activities are dif-\nferentiated from other quality activities by \ntheir focus. These activities focus on arti-\nfacts that are closely related to code \u2014 such \nas detailed design \u2014 as opposed to other \nartifacts that are less directly connected to \nthe code, such as requirements, high-level \ndesigns and plans.\n3.7.\t Integration \b\n[1-c29, 2-c8, 3-c11]\nDuring construction, a key activity is inte-\ngrating individually constructed routines, \nclasses, components and subsystems into a \nsingle system. In addition, a particular soft-\nware system may need to be integrated with \nother software or hardware systems.\nConcerns related to construction integra-\ntion include planning the sequence in which \ncomponents are integrated, identifying what \nhardware is needed, creating scaffolding to \nsupport interim versions of the software, \ndetermining the degree of testing and quality \nwork performed on components before they \nare integrated, and determining points in the \nproject at which interim versions of the soft-\nware are tested. \t\nPrograms can be integrated by means \nof either the phased or the incremental \napproach. Phased integration, also called \nbig bang integration, entails delaying the \nintegration of component software parts until \nall parts intended for release in a version are \ncomplete. Incremental integration is thought \nto offer many advantages over the traditional \nphased integration (e.g., easier error loca-\ntion, improved progress monitoring, earlier \nproduct delivery and improved customer rela-\ntions). In incremental integration, the devel-\nopers write and test a program in small pieces \nand then combine the pieces one at a time. \nAdditional test infrastructure, including, for \nexample, stubs, drivers and mock objects, is \nusually needed to enable incremental integra-\ntion. In addition, by building and integrating \none unit at a time (e.g., a class or compo-\nnent), the construction process can provide \nearly feedback to developers and customers. \nOther advantages of incremental integration \ninclude easier error location, improved prog-\nress monitoring and more fully tested units, \namong others.\nNowadays, continuous integration (CI) has \nbeen widely adopted in practice. A software \nteam using CI integrates its work frequently, \nleading to multiple integrations per day. CI \nis usually automated by a pipeline that builds \nand tests each integration to detect errors and \nprovide fast feedback.\n3.8.\t Cross-Platform Development and \nMigration \b\n[4-c]\nSome applications, such as mobile applica-\ntions, heavily rely on specific platforms (e.g., \nApple, Android), which usually include \noperating systems, development frameworks \nand APIs. To support multiple platforms, \nthe developers need to develop and build an \napplication separately for each target plat-\nform using the corresponding program lan-\nguage and software development kit (SDK). \nHowever, multi-platform development in this \nway requires more time and cost and might \ncause different user experiences between dif-\nferent implementations.\nCross-platform development allows the \ndevelopers to develop an application using a \nuniversal language and export it to various \nplatforms. This usually can be done in two \n", "page": 108, "type": "text", "section": "Page 108"}
{"text": "4-10   SWEBOK \u00ae GUIDE V4.0\nways for mobile applications. One way is to \ngenerate native applications using specific \ntools that can compile the universal language \ninto platform-specific formats. The other is \nto develop hybrid applications that combine \nweb applications developed using languages \nlike hypertext markup language version 5 \n(HTML5) and cascading style sheets (CSS) \nand native containers or wrappers for various \noperations systems.\nFor applications that are not developed in \nthis way, developers may consider migrating \nthe applications from one platform to another. \nThe migration usually involves translation of \ndifferent programming languages and plat-\nform-specific APIs and can be partially auto-\nmated by tools.\n4.\t Construction Technologies\n4.1.\t API Design and Use \b\n[5-c7]\nAn API is a set of signatures that are exported \nand available to the users of a library or a \nframework to write their applications. Besides \nsignatures, an API should always include \nstatements about the program\u2019s effects and/or \nbehaviors (i.e., its semantics).\nAPI design should make the API easy to \nlearn and memorize, lead to readable code, be \ndifficult to misuse, be easy to extend, be com-\nplete, and maintain backward compatibility. \nAs the APIs usually outlast their implemen-\ntations for a widely used library or framework, \nan API should be straightforward and stable, \nto facilitate client application development \nand maintenance.\nAPI use involves selecting, learning, \ntesting, integrating and possibly extending \nAPIs provided by a library or framework (see \nsection 3.5, Reuse in Construction).\nFor online interfaces such as RESTful \nAPIs, open standers such as OpenAPI play \nan important role. OpenAPI defines a stan-\ndard, language-agnostic interface to HTTP \nAPIs and supports the automatic generation \nof server-side and client-side code, covering \npopular languages such as Java, JavaScript, \nPython, etc.. At the same time, API-first \napproach has been widely used, which \nemphasizes designing and building the APIs \nof an application first. In practice, API-first \napproach is usually accomplished by using an \nAPI description language to establish a con-\ntract for how the API is supposed to behave.\n4.2.\t Object-Oriented Runtime Issues \b [1-c6, c7]\nObject-oriented languages support run-\ntime mechanisms, including polymorphism \nand reflection. These runtime mechanisms \nincrease the flexibility and adaptability of \nobject-oriented programs. \nPolymorphism is a language\u2019s ability to \nsupport general operations without knowing \nuntil runtime what kind of concrete objects \nthe software will include. Because the pro-\ngram does not know the types of the objects \nin advance, the exact behavior is determined \nat runtime (called dynamic binding).\nReflection is a program\u2019s ability to observe \nand modify its structure and behavior at run-\ntime. For example, reflection allows inspection \nof classes, interfaces, fields and methods at \nruntime without knowing their names at com-\npile time. It also allows instantiation of new \nobjects at runtime and invocation of methods \nusing parameterized class and method names.\n4.3.\t Parameterization, Templates, and Generics \n\b\n[6-c1]\nParameterized types, also known as generics \n(Ada, Java, Eiffel) and templates (C++), enable \na type or class definition without specifying \nall the other types used. The unspecified types \nare supplied as parameters at the point of use. \nParameterized types provide a third way \n(besides class inheritance and object compo-\nsition) to compose behaviors in object-ori-\nented software.\n4.4.\t Assertions, Design by Contract, and \nDefensive Programming \b\n[1-c8, c9]\nAn assertion is an executable predicate placed \nin a program \u2014 usually a routine or macro \n\u2014 that allows runtime checks of the program. \n", "page": 109, "type": "text", "section": "Page 109"}
{"text": "SOFTWARE CONSTRUCTION   4-11\nAssertions are especially useful in high-reli-\nability programs. They enable programmers to \nmore quickly flush out mismatched interface \nassumptions, errors that creep in when code is \nmodified, and other problems. Assertions are \ntypically compiled into the code at develop-\nment time and are later compiled out of the \ncode so they don\u2019t degrade the performance.\nDesign by contract is a development approach \nin which preconditions and postconditions are \nincluded for each routine. When precondi-\ntions and postconditions are used, each rou-\ntine or class is said to form a contract with \nthe rest of the program. A contract precisely \nspecifies the semantics of a routine and thus \nhelps clarify its behavior. Design by contract \nis thought to improve the quality of software \nconstruction.\nDefensive programming means to protect a \nroutine from being broken by invalid inputs. \nCommon ways to handle invalid inputs \ninclude checking the values of all the input \nparameters and deciding how to handle bad \ninputs. Assertions are often used in defensive \nprogramming to check input values.\n4.5.\t Error Handling, Exception Handling, and \nFault Tolerance \b\n[1-c8, c9]\nHow errors are handled affects software\u2019s \nability to meet requirements related to correct-\nness, robustness and other nonfunctional attri-\nbutes. Assertions are sometimes used to check \nfor errors. Other error-handling techniques \u2014 \nsuch as returning a neutral value, substituting \nthe next piece of valid data, logging a warning \nmessage, returning an error code or shutting \ndown the software \u2014 are also used.\nExceptions are used to detect and process \nerrors or exceptional events. The basic struc-\nture of an exception is as follows: A routine \nuses throw to throw a detected exception, \nand an exception-handling block will catch \nthe exception in a try-catch block. The try-\ncatch block may process the erroneous condi-\ntion or return control to the calling routine. \nException-handling policies should be care-\nfully designed following common principles, \nsuch as including in the exception message \nall information that led to the exception, \navoiding empty catch blocks, knowing the \nexceptions the library code throws, perhaps \nbuilding a centralized exception reporter, \nand standardizing the program\u2019s use of \nexceptions.\nFault tolerance is a collection of techniques \nthat increase software reliability by detecting \nerrors and then recovering from them or con-\ntaining their effects if recovery is not possible. \nThe most common fault tolerance strate-\ngies include backing up and retrying, using \nauxiliary code and voting algorithms, and \nreplacing an erroneous value with a phony \nvalue that will have a benign effect.\n4.6.\t Executable Models \b\n[7]\nExecutable models abstract away the details of \nspecific programming languages and deci-\nsions about the software\u2019s organization. \nDifferent from traditional software models, \na specification built in an executable mod-\neling language like xUML (executable UML) \ncan be deployed in various software environ-\nments without change. Furthermore, an exe-\ncutable-model compiler (transformer) can \nturn an executable model into an implemen-\ntation using a set of decisions about the target \nhardware and software environment. Thus, \nconstructing executable models is a way of \nconstructing executable software.\nExecutable models are one foundation \nsupporting the model-driven architecture \n(MDA) initiative of the OMG. An executable \nmodel is a way to specify a platform-indepen-\ndent model (PIM); a PIM is a model of a \nsolution to a problem that does not rely on any \nimplementation technologies. Then a plat-\nform-specific model (PSM), which is a model \nthat contains the details of the implementa-\ntion, can be produced by weaving together the \nPIM and the platform on which it relies.\n4.7.\t State-Based and Table-Driven \nConstruction Techniques \b\n[1-c18]\nState-based programming, or automata-based \nprogramming, is a programming technology \n", "page": 110, "type": "text", "section": "Page 110"}
{"text": "4-12   SWEBOK \u00ae GUIDE V4.0\nthat uses finite-state machines to describe \nprogram behaviors. A state machine\u2019s transi-\ntion graphs are used in all stages of software \ndevelopment (specification, implementation, \ndebugging and documentation). The main \nidea is to construct computer programs in the \nsame way technological processes are auto-\nmated. State-based programming is usually \ncombined with object-oriented programming, \nforming a new composite approach called \nstate-based, object-oriented programming.\nA table-driven method is a schema that \nuses tables to display information rather \nthan convey information with logic state-\nments (such as if and case). When used in \nappropriate \ncircumstances, \ntable-driven \ncode is simpler than complicated logic and \neasier to modify. When using table-driven \nmethods, the programmer addresses two \nissues: what information to store in the table \nor tables and how to efficiently access infor-\nmation in the table.\n4.8.\t Runtime Configuration and \nInternationalization \b\n[1-c3, c10]\nTo achieve more flexibility, a program is \noften constructed to support its variables\u2019 late \nbinding time. For example, runtime configu-\nration binds variable values and program set-\ntings when the program is running, usually by \nupdating and reading configuration files in a \njust-in-time mode.\nInternationalization is the technical activity \nof preparing a program, usually interactive \nsoftware, to support multiple locales. The cor-\nresponding activity, localization, modifies a \nprogram to support a specific local language. \nInteractive software may contain dozens or \nhundreds of prompts, status displays, help \nmessages, error messages and so on. The \ndesign and construction processes should \naccommodate string and character set issues, \nincluding which character set is used, what \nkinds of strings are used, how to maintain the \nstrings without changing the code and how to \ntranslate the strings into different languages \nwith minimal impact on the processing code \nand the user interface.\n4.9.\t Grammar-Based Input Processing \b\n[1, 8]\nGrammar-based input processing \ninvolves \nsyntax analysis, or parsing, of the input token \nstream. It involves the creation of a data struc-\nture (called a parse tree or syntax tree) repre-\nsenting the input data. The inorder traversal \nof the parse tree usually gives the expres-\nsion just parsed. Next, the parser checks the \nsymbol table for programmer-defined vari-\nables that populate the tree. After building \nthe parse tree, the program uses it as an input \nto the computational processes.\n4.10.\t\nConcurrency Primitives \b\n[9-c6]\nA synchronization primitive is a programming \nabstraction provided by a programming lan-\nguage or the operating system that facilitates \nconcurrency and synchronization. Well-\nknown concurrency primitives include sema-\nphores, monitors and mutexes.\nA semaphore is a protected variable or \nabstract data type that provides a simple \nbut useful abstraction for controlling access \nto a common resource by multiple processes \nor threads in a concurrent programming \nenvironment.\nA monitor is an abstract data type that pres-\nents a set of programmer-defined operations \nexecuted with mutual exclusion. A monitor \ncontains the declaration of shared variables \nand procedures or functions that operate on \nthose variables. The monitor construct ensures \nthat only one process at a time is active in \nthe monitor.\nA mutex (mutual exclusion) is a synchro-\nnization primitive that grants exclusive access \nto a shared resource by only one process or \nthread at a time.\n4.11.\t\nMiddleware \b\n[5-c1, 8-c8]\nMiddleware is a broad classification for soft-\nware that provides services above the operating \nsystem layer yet below the application pro-\ngram layer. Middleware can provide runtime \ncontainers for software components to provide \nmessage passing, persistence and a transparent \n", "page": 111, "type": "text", "section": "Page 111"}
{"text": "SOFTWARE CONSTRUCTION   4-13\nlocation across a network. Middleware can \nbe viewed as a connector between the com-\nponents using the middleware. Modern mes-\nsage-oriented middleware usually provides an \nenterprise service bus (ESB) that supports ser-\nvice-oriented interaction and communication \namong multiple software applications.\n4.12.\t\nConstruction Methods for Distributed and \nCloud-Based Software \b\n[2-c17, c18, 9-c2]\nA distributed system is a collection of physically \nseparate, possibly heterogeneous computer \nsystems networked to provide the users with \naccess to the resources the system maintains. \nThe construction of distributed software is \ndistinguished from traditional software con-\nstruction by issues such as parallelism, com-\nmunication and fault tolerance.\nDistributed programming typically falls \ninto several basic architectural categories: \nclient-server, three-tier architecture, n-tier \narchitecture, distributed objects, loose cou-\npling or tight coupling (see section 5.6 in the \nComputing Foundations KA and section 2.2 \nin the Software Architecture KA).\nNowadays, more applications are migrated \nto the cloud. Cloud-based software often adopts \nmicroservice architecture and container-based \ndeployment. In addition to traditional dis-\ntributed software issues, cloud-based soft-\nware developers also need to consider cloud \ninfrastructure issues such as use of an API \ngateway, service registration and discovery.\nDistributed systems based on n-tier/ser-\nvice-oriented architectures usually rely on \nACID distributed transactions for the imple-\nmentation of transactions involving multiple \ndistributed components. In contrast, cloud-\nbased microservices cannot enforce distributed \ntransactions consistency, and use some form of \nSAGA-based eventual consistency, initially \nintended for long-running transactions.\n4.13.\t\nConstructing Heterogeneous Systems \b [8-c9]\nHeterogeneous systems consist of various special-\nized computational units of different types, \nsuch as Graphic Processing Units (GPUs) and \nDigital Signal Processors (DSPs), micro-\ncontrollers and peripheral processors. These \ncomputational units are independently con-\ntrolled and communicate with one another. \nEmbedded systems are typically heteroge-\nneous systems.\nThe design of heterogeneous systems \nmay require combining several specifica-\ntion languages to design different system \nparts (hardware/software codesign). The \nkey issues include multilanguage validation, \nco-simulation and interfacing.\nDuring \nthe \nhardware/software \ncode-\nsign, software and virtual hardware develop-\nment proceed concurrently through stepwise \ndecomposition. The hardware part is usually \nsimulated in field programmable gate arrays \n(FPGAs) or application-specific integrated \ncircuits (ASICs). The software part is trans-\nlated into a low-level programming language.\n4.14.\tPerformance Analysis and Tuning  \n\b\n[1-c25, c26]\nCode efficiency \u2014 determined by architec-\nture, detailed design decisions, and data struc-\nture and algorithm selection \u2014 influences \nexecution speed and size. Performance analysis \ninvestigates a program\u2019s behavior using infor-\nmation gathered as the program executes to \nidentify possible hot spots in the program to \nbe improved.\nCode tuning, which improves performance \nat the code level, modifies correct code to \nmake it run more efficiently. Code tuning \nusually involves only small changes that affect \na single class, a single routine or, more com-\nmonly, a few lines of code. A rich set of code \ntuning techniques is available, including those \nfor tuning logic expressions, loops, data trans-\nformations, expressions and routines. Using a \nlow-level language is another common tech-\nnique for improving hot spots in a program.\n4.15.\t\nPlatform Standards \b\n[4-c, 8-c10, 9-c1]\nPlatform standards enable programmers to \ndevelop portable applications that can be exe-\ncuted in compatible environments without \n", "page": 112, "type": "text", "section": "Page 112"}
{"text": "4-14   SWEBOK \u00ae GUIDE V4.0\nchanges. Platform standards usually involve \nstandard services and APIs that compat-\nible platform implementations must use. \nTypical examples of platform standards are \nJakarta Enterprise Edition (JEE); the por-\ntable operating system interface (POSIX) \nstandard for operating systems, which rep-\nresents a set of standards implemented pri-\nmarily for Unix-based operating systems; \nand HTML5, which defines the standards \nfor developing web applications that can \nrun on different environments (e.g., Apple \niOS, Android).\n4.16.\tTest-First Programming \b\n[1-c22, 2-c8]\nTest-first programming (also known as TDD - \nTest-Driven Development) is a popular devel-\nopment style in which test cases are written \nbefore any code. These test cases, when applied \nto the current code base, will fail. Code is then \nwritten that will allow the test cases to pass. \nAt that time, the new code and associated \nparts of the project can be refactored and opti-\nmized. Test-first programming can usually \ndetect defects earlier and correct them more \neasily than traditional programming styles. \nFurthermore, writing test cases first forces \nprogrammers to think about requirements and \ndesign before coding, thus exposing require-\nments and design problems sooner.\n4.17.\tFeedback Loop for Construction \n \b\n[3-c3, c16]\nEarly and continuous feedback for the \nconstruction activity is one of the most \nimportant advantages of agile development \nand DevOps. Agile development provides \nearly feedback for construction through fre-\nquent iterations in the development process. \nDevOps provides even faster feedback from \nthe operation, allowing the developers to \nlearn how well their code performs in pro-\nduction environments. This fast feedback is \nachieved through techniques and practices \nin the DevOps pipeline, such as automated \nbuilding and testing, canary release, and \nA/B testing.\n5.\t  Software Construction Tools\n5.1.\t Development Environments \b\n[1-c30]\nA development environment, or integrated \ndevelopment environment (IDE), provides \ncomprehensive facilities to programmers for \nsoftware construction by integrating a set of \ndevelopment tools. The programmers\u2019 choice \nof development environment can affect soft-\nware construction efficiency and quality.\nBesides basic code editing functions, \nmodern IDEs often offer other features, like \ncompilation and error detection within the \neditor, integration with source code control, \nbuild/test/debugging tools, compressed or \noutline views of programs, automated code \ntransforms, and support for refactoring.\nNowadays, cloud-based development envi-\nronments are available in public or private \ncloud services. These environments can pro-\nvide all the features of modern IDEs and \neven more (e.g., containerized building and \ndeployment), powered by the cloud.\nMoreover, modern IDEs are often equipped \nwith AI-assisted programming which is \nboosted by the recent advances in Large \nLanguage Models (LLMs). With the support \na programmer can define a function in pseudo-\ncode comments or outline its implementa-\ntion as a prompt for an LLM to generate or \ncomplete the code. The programmer lets the \nLLM complete many of the details, but still \nreviews the generated code and integrates it \ninto their project.\n5.2.\t Visual Programming and Low-Code/Zero-\nCode Platforms \b\n[1-c30]\nVisual programming allows users to create pro-\ngrams by manipulating visual program ele-\nments graphically. As a visual programming \ntool, a GUI (graphical user interface) builder \nenables the developer to create and main-\ntain GUIs in a WYSIWYG (what you see \nis what you get) mode. A GUI builder usu-\nally includes a visual editor that enables the \ndeveloper to design forms and windows and \nmanage the layout of the widgets with drag, \n", "page": 113, "type": "text", "section": "Page 113"}
{"text": "SOFTWARE CONSTRUCTION   4-15\ndrop and parameter setting features. Some \nGUI builders can automatically generate the \nsource code corresponding to the visual GUI \ndesign. Because GUI applications usually \nfollow the event-driven style (in which events \nand event handling determine the program \nflow), GUI builder tools usually provide code \ngeneration assistants, which automate the \nmost repetitive tasks required for event han-\ndling. The supporting code connects widgets \nwith the outgoing and incoming events that \ntrigger the functions providing the application \nlogic. Some modern IDEs provide integrated \nGUI builders or GUI builder plug-ins. There \nare also many stand-alone GUI builders.\nVisual programming and other rapid appli-\ncation development tools have evolved into \nlow-code/zero-code platforms. These platforms \nallow developers to build complete applica-\ntions visually through a drag-and-drop inter-\nface and with minimal hand-coding. They \nare usually based on the principles of mod-\nel-driven design, visual programming and \ncode generation. The difference between low-\ncode development and zero-code development \nlies in hand-coding; the former requires a \nlittle hand-coding, whereas the latter requires \npractically none.\n5.3.\t Unit Testing Tools \b\n[1-c22, 2-c8]\nUnit testing verifies the functioning of soft-\nware modules in isolation from other sepa-\nrately testable software elements (for example, \nclasses, routines, components). Unit testing \nis often automated. Developers can use unit \ntesting tools and frameworks to extend and \ncreate an automated testing environment. For \nexample, the developer can code criteria into \nthe test with unit testing tools and frame-\nworks to verify the unit\u2019s correctness under \nvarious data sets. Each test is implemented \nas an object, and a test runner runs the tests. \nFailed test cases will be automatically flagged \nand reported during the test execution.\n5.4.\t Profiling, Performance Analysis,  \nand Slicing Tools \b\n[1-c25, c26]\nPerformance analysis tools are usually used to \nsupport code tuning. The most common per-\nformance analysis tools are profiling tools. An \nexecution profiling tool monitors the code \nwhile it runs and records how often each \nstatement is executed or how much time the \nprogram spends on each statement or exe-\ncution path. Profiling the code while it runs \ngives insight into how the program works, \nwhere the hot spots are and where the devel-\nopers should focus the code tuning efforts.\nProgram slicing involves computing the set \nof program statements (i.e., the program slice) \nthat might affect the values of specified vari-\nables at some point of interest, which is called \na slicing criterion. Program slicing can be used \nfor locating error sources, program under-\nstanding and optimization analysis. Program \nslicing tools compute program slices for var-\nious programming languages using static or \ndynamic analysis methods.\nMATRIX OF TOPICS VS. REFERENCE MATERIAL\nMcConnell,  \n2004 [1]\nSommerville,  \n2016 [2] \nKim et al.,   \n2021 [3]\nHeitk\u00f6tter  \net al., 2013 [4]\nClements  \net al., 2010 [5]\nGamma et al.  \n1994 [6]\nMellor and Balcer,  \n2002 [7]\nNull and Lobur,  \n2006 [8]\nSilberschatz  \net al., 2008 [9]\n1. Software Construction \nFundamentals\n", "page": 114, "type": "text", "section": "Page 114"}
{"text": "4-16   SWEBOK \u00ae GUIDE V4.0\n1.1. Minimizing \nComplexity\nc2, c3, c7-c9, \nc24, c27, c28, \nc31, c32, c34\n1.2. Anticipating and \nEmbracing Change\nc3-c5, c24, \nc31, c32, c34\nc1, c3, \n \nc9\nc1\n1.3. Constructing for \nVerification\nc8, c20-c23,  \nc31, c34\n1.4. Reuse\nc15\n1.5. Standards in \nConstruction \nc4\n2. Managing Construction\n2.1. Construction in Life \nCycle Models\nc2, c3, c27,  \nc29\nc3, \nc7\nc1\n2.2. Construction  \nPlanning\nc3, c4, c21,  \nc27-c29\n2.3. Construction \nMeasurement\nc25, c28\n2.4. Managing \nDependencies\nc25\n3. Practical \nConsiderations\n3.1. Construction Design\nc3, c5, c24\nc7\n3.2. Construction  \nLanguages\nc4\n3.3. Coding\nc5-c19,  \nc25-c26\n3.4. Construction Testing\nc22, c23\nc8\n3.5. Reuse in Construction\nc15, \nc16\n3.6. Construction Quality\nc8, c20-c25\nc8, \nc24\n3.7. Integration\nc29\nc8\nc11\n3.8. Cross-Platform \nDevelopment \nand Migration\nc\n4. Construction \nTechnologies\n4.1. API Design and Use\nc7\n4.2. Object-Oriented \nRuntime Issues\nc6, c7\n", "page": 115, "type": "text", "section": "Page 115"}
{"text": "SOFTWARE CONSTRUCTION   4-17\n4.3. Parameterization, \nTemplates and Generics\nc1\n4.4. Assertions, Design by \nContract and Defensive \nProgramming\nc8, c9\n4.5. Error Handling, \nException Handling and \nFault Tolerance\nc3, c8\n4.6. Executable Models\n4.7. State-Based and \nTable-Driven Construction \nTechniques\nc18\n4.8. Runtime \nConfiguration and \nInternationalization\nc3, c10\n4.9. Grammar-Based Input \nProcessing\nc5\nc8\n4.10. Concurrency \nPrimitives\nc6\n4.11. Middleware\nc1\nc8\n4.12. Construction \nMethods for Distributed \nand Cloud-Based Software\nc17, \nc18\nc2\n4.13. Constructing \nHeterogeneous Systems\nc9\n4.14. Performance Analysis \nand Tuning\nc25, c26\n4.15. Platform Standards\nc\nc10\nc1\n4.16. Test-First \nProgramming\nc22\nc8\n4.17. Feedback Loop for \nConstruction\nc3, \nc16\n5. Software \nConstruction Tools\n5.1. Development \nEnvironments\nc30\n5.2. Visual Programming \nand Low-Code/Zero-\nCode Platforms\nc30\n5.3. Unit Testing Tools\nc22\nc8\n5.4. Profiling, Performance \nAnalysis and Slicing Tools\nc25, c26\n", "page": 116, "type": "text", "section": "Page 116"}
{"text": "4-18   SWEBOK \u00ae GUIDE V4.0\nFURTHER READINGS\nIEEE Std. 1517-1999: IEEE Standard for \nInformation Technology--Software Life Cycle \nProcesses--Reuse Processes, IEEE, 1999 [8].\nThis standard specifies the processes, activi-\nties, and tasks to be applied during each phase \nof the software life cycle to enable a soft-\nware product to be constructed from reusable \nassets. It covers the concept of reuse-based \ndevelopment and the processes of construc-\ntion for reuse and construction with reuse.\nISO/IEC \n12207:2008: \nInformation \nTechnology--Software Life Cycle Processes, ISO/\nIEC, 2008 [9].\nThis standard defines a series of software \ndevelopment processes, including software \nconstruction process, software integration \nprocess, and software reuse process.\nMartin Fowler, Kent Beck. Refactoring: \nImproving the Design of Existing Code \n(2nd Edition),  Addison-Wesley Signature \nSeries (Fowler).\nRobert C. Martin.Clean Code: A Handbook \nof Agile Software Craftsmanship, Pearson \nEducation, Inc.\nREFERENCES\n[1]\t S. McConnell, Code Complete, 2nd edition, \nRedmond, WA: Microsoft Press, 2004.\n[2]\t I. Sommerville, Software Engineering, \n10th edition, Addison-Wesley, 2016.\n[3]\t G. Kim et al., The DevOps Handbook: \nHow to Create World-Class Agility, \nReliability & Security in Technology \nOrganizations, 2nd edition, IT \nRevolution, 2021.\n[4]\t H. Heitk\u00f6tter, S. Hanschke, and T.A. \nMajchrzak, Evaluating Cross-Platform \nDevelopment Approaches for Mobile \nApplications, 2013, in Cordeiro, J., \nKrempels, K.H. (eds.), Web Information \nSystems and Technologies. WEBIST \n2012. Lecture Notes in Business \nInformation Processing, vol. 140, \nSpringer, Berlin, Heidelberg.\n[5]\t P. Clements et al., Documenting Software \nArchitectures: Views and Beyond, 2nd edi-\ntion, Boston: Pearson Education, 2010.\n[6]\t E. Gamma et al., Design Patterns: \nElements of Reusable Object-Oriented \nSoftware, 1st edition, Reading, MA: \nAddison-Wesley Professional, 1994.\n[7]\t S.J. Mellor and M.J. Balcer, Executable \nUML: A Foundation for Model-Driven \nArchitecture, 1st edition, Boston: \nAddison-Wesley, 2002.\n[8]\t L. Null and J. Lobur, The Essentials of \nComputer Organization and Architecture, \n2nd edition, Sudbury, MA: Jones and \nBartlett Publishers, 2006.\n[9]\t A. Silberschatz et al., Operating System \nConcepts, 8th edition, Hoboken, NJ: \nWiley, 2008.\n", "page": 117, "type": "text", "section": "Page 117"}
{"text": "5-1 \nCHAPTER 05\nSoftware Testing\nACRONYMS\nAI\nArtificial Intelligence\nAPI\nApplication Program Interface \nARINC\nAeronautical Radio Incorporated\nATDD\nAcceptance Test-Driven \nDevelopment\nCMMI\nCapability Maturity Model \nIntegration \nCSS\nCascading Style Sheets \nDICOM\nDigital Imaging and \nCommunications in Medicine\nDL\nDeep Learning \nDU\nDefinition and Use\nEBSE\nEvidence-Based Software \nEngineering \nECS\nEcosystem\nETSI\nEuropean Telecommunications \nStandards Institute \nFHIR\nFast Healthcare Interoperability \nResources \nGDPR\nGeneral Data Protection \nRegulation \nGPS\nGlobal Positioning System\nGUI\nGraphical User Interface \nHIL\nHardware-In-the-Loop \nHIPAA\nHealth Insurance Portability and \nAccountability Act \nHL7\nHealth Level Seven \nIoT\nInternet of Things \nKPI\nKey Performance Indicator\nMC/DC\nModified Condition \nDecision Coverage\nML\nMachine Learning \nMTTR\nMean Time to Recovery \nOAT\nOrthogonal Array Testing\nODC\nOrthogonal Defect Classification\nSoS\nSystem of Systems\nSPI\nSoftware Process Improvement \nSPICE\nSoftware Process Improvement \nand Capability Determination \nSUT\nSystem Under Test\nTDD\nTest-Driven Development\nTMMi\nTest Maturity Model integration\nUI\nUser Interface\nUP\nUnified Process\nINTRODUCTION \nSoftware testing consists of the dynamic vali-\ndation that a system under test (SUT) provides \nexpected behaviors on a finite set of test cases \nsuitably selected from the usually infinite exe-\ncution domain. \nIn the above statement, italicized words \ncorrespond to key issues in the Software \nTesting knowledge area (KA). Those terms \nare discussed below.\n\u2022\t System Under Test: This term can refer to \nthe tested object, which could be a pro-\ngram, a software product, an applica-\ntion, a service-oriented application (e.g., \nweb services, microservices), middleware \n(HW/SW), a services composition, a \nsystem, a System of Systems (SoS), or an \nEcosystem (ECS).\n\u2022\t Test Case: A test case is the specification \nof all the entities that are essential for the \nexecution, such as input values, execution \n", "page": 118, "type": "text", "section": "Page 118"}
{"text": "5-2   SWEBOK \u00ae GUIDE V4.0\nand timing conditions, testing procedure, \nand the expected outcomes (e.g., pro-\nduced values, state changes, output mes-\nsages). Input values alone are not always \nsufficient to specify the test cases because \nthe SUT might react to the same input \nwith different behaviors, depending, for \ninstance, on the SUT state or environ-\nmental conditions. A set of test cases is \nusually called a test suite.\n\u2022\t Dynamic: Dynamic validation requires \nexecuting the SUT on a test suite. Static \ntechniques complement dynamic testing, \nand they are covered in the Software \nQuality KA.1 \n\u2022\t Finite: Even in a simple SUT, executing \nall the possible test cases (i.e., exhaus-\ntive testing) could require months or \nyears. Consequently, in practice, testing \ntargets a subset of all possible test cases \ndetermined by different criteria. Testing \nalways implies a trade-off between lim-\nited resources and schedules on the one \nhand and inherently unlimited test \nrequirements on the other.\n\u2022\t Selected: Identifying the most suitable \nselection criteria under given conditions \nis a complex problem. Different tech-\nniques can be considered and combined \nto tackle that problem, such as risk anal-\nysis, software requirements, cost reduc-\ntion, \nquality \nattributes \nsatisfaction, \nprioritization, and fault detection. The \nmany proposed test techniques differ in \nhow the test suite is selected, and soft-\nware engineers must be aware that dif-\nferent selection criteria might yield vastly \ndifferent degrees of effectiveness. \n\u2022\t Expected: For each executed test case, it \nmust be possible, although it might not \nbe easy, to decide whether the observed \nSUT outcomes match the expected ones. \nIndeed, the observed behavior may be \nchecked against user needs (commonly \nreferred to as testing for validation), against \na specification (testing for verification), or, \n1\t\n It is worth noting that terminology is not uniform among different communities, and some use the \nterm testing to refer to static techniques as well.\nperhaps, against the foreseen behavior \nfrom implicit requirements or expectations. \n(See Section 4.3, Acceptance Criteria-\nBased Requirements Specification, in the \nSoftware Requirements KA.) \nAs reflected in this discussion, software \ntesting is a pervasive and holistic activity \ninvolving all the steps of any process devel-\nopment life cycle (e.g., traditional or shift-left \ndevelopment). The remainder of this chapter \npresents the basics of software testing and its \nchallenges, issues, and commonly accepted \npractices and solutions. \nBREAKDOWN OF TOPICS FOR \nSOFTWARE TESTING \nFigure 5.1 shows the breakdown of topics \nfor the Software Testing KA. The Matrix \nof Topics vs. Reference Material provides \na more detailed breakdown at the end of \nthis KA. The first topic, Software Testing \nFundamentals, covers the basic definitions in \nsoftware testing, the basic terminology and \nkey issues, and software testing\u2019s relationship \nwith other activities.\nThe second topic, Test Levels, contains \ntwo (orthogonal) subtopics. The first subtopic, \nThe Target of the Test, lists the levels into \nwhich the testing of large software is tradi-\ntionally subdivided, and the second subtopic, \nObjectives of Testing, discusses testing for \nspecific conditions or properties. Not all types \nof testing apply to every software product, nor \nhas every possible type been listed. The Target \nof the Test and Objectives of Testing together \ndetermine how the test suite is identified, both \nregarding its consistency (How much testing \nis enough for achieving the stated objective?) \nand its composition (Which test cases should \nbe selected for achieving the stated objec-\ntive?). (However, usually, \u201cfor achieving the \nstated objective\u201d remains implicit, and only \nthe first part of the two questions above is \n", "page": 119, "type": "text", "section": "Page 119"}
{"text": "SOFTWARE TESTING   5-3\nposed.) Criteria for addressing the first ques-\ntion are test adequacy criteria, whereas those \nused for addressing the second question are \nthe test selection criteria.\nSeveral Test Techniques have been devel-\noped in the past few decades, and new ones \nare still being proposed. Therefore, the third \ntopic covers generally accepted and standard-\nized techniques.\nTest-Related Measures are dealt with in \nthe fourth topic, while the issues relative to \nthe Test Process are covered in the fifth. \nSoftware Testing in the Development \nProcesses and the Application Domains is \ndescribed in the sixth topic, and Testing of \nand Testing Through Emerging Technologies \nare described in the seventh topic. Finally, \nSoftware Testing Tools are presented in \ntopic eight.\n1.\t Software Testing Fundamentals\n[1*, c1, c2; 2*, c8; 14*, c7]\nThis section provides an overview of the main \ntesting issues and the relationship of testing \nto the other activities. Most of the testing \nterms used here are also defined. A more \ncomprehensive overview of the testing and \ntesting-related terminology can be found in \nthe cited references.\n1.1 Faults vs. Failures \n[1*, c1s5; 2*, c1; 14*, c1s3]\nMany terms are used in the software engi-\nneering literature to describe a malfunction: \nnotably fault (see, for comparison, defect in \nSection 3.2, Defect Characterization, in the \nSoftware Quality KA), failure and error. It is \nessential to distinguish between the cause of a \nmalfunction (for which the term fault is used \nhere) and an undesired effect observed in the \nsystem\u2019s delivered service (a failure). Indeed, \nthere might well be faults in the software that \nnever manifest as failures. (See Theoretical \nand Practical Limitations of Testing in \nSection 1.2.8.) Thus, testing can reveal fail-\nures, but the faults causing them are what can \nand must be removed. However, a failure\u2019s \ncause cannot always be unequivocally iden-\ntified. No theoretical criteria exist to defin-\nitively determine, in general, the fault that \ncaused an observed failure. The fault might \nhave to be modified to remove the failure, but \nSoftware\nTesting\nSoftware\nTesting\nFundamentals\nSoftware Testing\nin the Development \nProcesses and the \nApplication Domains\nFaults vs. \nFailures\nKey Issues\nRelationship \nof Testing to \nother Activities\nTe Target \nof the Test\nObjectives of \nTesting\nSpeci\ufb01cation-\nBased\nTechniques\nStructure-\nBased Test \nTechniques\nExperience-Based\nTechniques\nFault-Based \nand Mutation \nTechniques\nTechniques Based \non the Nature of \nthe Application\nSelecting and \nCombining \nTechniques\nTechniques \nBased on Derived \nKnowledge\nEvaluation of \nthe SUT\nEvaluation of the \nTest Performed\nPractical \nConsiderations\nTest Sub-\nProcesses\n and Activities\nSta\ufb03ng\nTesting Inside \nSoftware\nDevelopment \nProcess\nTesting in the\nApplication \nDomains\nTest Levels\nTest Techniques\nTest-Related\nMeasures\nTest Process\nTesting of and \nTesting Trough\nEmerging \nTechnologies\nTesting of \nEmerging \nTechnologies\nTesting Trough\nEmerging \nTechnologies\nSoftware \nTesting\nTools\nTesting Tool\nSupport and \nSelection\nCategories \nof Tools\nFigure 5.1. Breakdown of Topics for the Software Testing KA\n", "page": 120, "type": "text", "section": "Page 120"}
{"text": "5-4   SWEBOK \u00ae GUIDE V4.0\nother modifications might also work. To avoid \nambiguity, we could refer to failure-causing \ninputs instead of faults \u2014 those sets of inputs \nthat cause a failure to appear.\n1.2. Key Issues\nThis subsection provides an overview of the \nmain testing issues. \n1.2.1. Test Case Creation \n[1*, c12s1, c12s3, 2*, c8]\nTest case creation or generation creates the test \nsuite useful for testing the SUT for specific \npurposes (e.g., adequacy, accuracy, or assess-\nment). Because test case generation is among \nthe most important and intensive software \ntesting activities, it is usually supported by \napproaches, techniques, and tools to automate \nthe process. \n1.2.2. Test Selection and Adequacy Criteria\n[1*, c1s14, c6s6, c12s7, 2*, c8] \nA test selection criterion is a means of \nselecting test cases or determining that a \ntest suite is sufficient for a specified purpose. \nTest case selection aims to reduce the car-\ndinality of the test suites while keeping the \nsame effectiveness in terms of coverage or \nfault detection rate. Test adequacy criteria \ncan be used to decide when sufficient testing \nis accomplished.\n1.2.3 Prioritization/Minimization\n[4, part 2, part 3, c5]\nSuitable strategies for test case selection or \nprioritization can be adopted to improve \ntesting efficacy. Test case prioritization aims \nto define a test execution order according to \nsome criteria (e.g., coverage, fault detection \nrate, similarity, and risk), so those tests with a \nhigher priority are executed before those with \na lower priority. Test case minimization usu-\nally aims to reduce a test suite by removing \nredundant test cases according to some crite-\nrion or purpose.\n1.2.4. Purpose of Testing\n[1*, c13s11, c11s4, 2*, c8]\nDifferent well-defined purposes can guide \ntesting activity; it is only by considering a \nspecific purpose that a test suite can be gen-\nerated (selected), executed, and evaluated (see \nSection 2 for more details).\n1.2.5. Assessment and Certification \n[4, part 1, c5; 2*, c7, c25; 8]\nTesting needs to focus on specific (mandatory) \nprescriptions, such as requirements, laws, and \nstandards. Test cases should be generated and \nexecuted to provide evidence useful for eval-\nuating and/or certifying adherence to the \nselected prescriptions. Usually, assessment and \ncertification of the test results include verifying \nthat the test cases have been derived and gen-\nerated using baseline requirements, adopting \na configuration control process, and using \nrepeatable processes. \n1.2.6. Testing for Quality Assurance/ \n\t Improvement \n[1*, c16s2; 4, part 1, c5; 9]\nTesting has many aspects, including quality \nimprovement and assurance. These charac-\nteristics involve planned and systematic sup-\nporting processes and activities leveraging \nconfidence that the SUT fulfills established \ntechnical or quality requirements. Thus, \nquality improvement and assurance involve \ndefining methods, tools, skills, and prac-\ntices to achieve the specific quality level and \nobjectives. The list of the main quality char-\nacteristics that testing can measure or assess \nis reported in ISO/IEC 25010:2011 [9]. (See \nalso Section 1.3.2, Software Product Quality, \nin the Software Quality KA.)\n1.2.7. The Oracle Problem \n[1*, c1s9, c9s7]\nAn important testing component is the \noracle. Indeed, a test is meaningful only if \nit is possible to decide its observed outcome. \n", "page": 121, "type": "text", "section": "Page 121"}
{"text": "SOFTWARE TESTING   5-5\nAn oracle can be any human or mechanical \nagent that decides whether the SUT behaved \ncorrectly in each test and according to the \nexpected outcomes. Consequently, the oracle \nprovides a \u201cpass\u201d or \u201cfail\u201d verdict. The oracle \ncannot always decide; in these cases, the test \noutput is classified as inconclusive. There are \nmany kinds of oracles \u2014 for example, unam-\nbiguous requirements specifications, behav-\nioral models, and code annotations. The \nautomation of oracles can be difficult and \nexpensive.\n1.2.8. Theoretical and Practical Limitations \n[1*, c2s7]\nTesting theory warns against ascribing unjus-\ntified confidence to a series of successful tests. \nUnfortunately, most established results of \nthe testing theory are negative results in that \nthey state what is not achieved as opposed \nto what is achieved. The most famous quo-\ntation on this point is the Dijkstra aphorism \nthat \u201cprogram testing can be used to show \nthe presence of bugs, but never to show their \nabsence\u201d [3]. The obvious reason for this is \nthat complete testing is not feasible in real-\nistic software.\n1.2.9. The Problem of Infeasible Paths \n[1*, c4s7]\nInfeasible paths are control flow paths that \ncannot be exercised by any input data (i.e., test \ncases). Managing (i.e., identifying, solving  or \nremoving) the infeasible paths can help reduce \nthe time and resources devoted to testing. \nThey are a significant problem in path-based \ntesting, particularly in the automated deri-\nvation of test cases to exercise control flow \npaths. Additionally, the detection of infeasible \npaths can also play a role in reducing security \nvulnerabilities.\n1.2.10. Testability \n[1*, c17s2]\nThe term software testability has two related \nbut different meanings. On the one hand, it \nrefers to the ease with which a given test cov-\nerage criterion can be satisfied; on the other \nhand, it is defined as the likelihood, possibly \nmeasured statistically, that a test suite will \nexpose a failure if the software is faulty. Both \nmeanings are important.\n1.2.11 Test Execution and Automation \n[4, part 1, c4]\nAn important challenge of testing is to \nimprove attainable automation, either \nby developing advanced techniques for \ngenerating the test inputs or, beyond \ntest generation, by finding innovative sup-\nport procedures to (fully) automate the dif-\nferent testing activities \u2014 for instance, to \nincrease the number of test cases generated \nor executed.\n1.2.12. Scalability \n[1*, c8s7] \nScalability is the software\u2019s ability to increase \nand scale up on its nonfunctional require-\nments, such as load, number of transactions, \nand volume of data. Scalability is also con-\nnected to the complexity of the platform and \nenvironment in which the program runs, such \nas distributed, wireless networks and virtual-\nized environments, large-scale clusters, and \nmobile clouds.\n1.2.13 Test Effectiveness\n[1* c1s1; 2* c8s1; 8]\nEvaluating the SUT, measuring a testing \ntechnique\u2019s efficacy, and judging whether \ntesting can be stopped are important evi-\ndences for software testing, and they may \nrequire defining and selecting the proper test \neffectiveness measures. \n1.2.14 Controllability, Replication, and  \n\t Generalization \n[1* c12s12; 4, part 2, c7]\nSpecific aspects of testing include the \nfollowing: \n", "page": 122, "type": "text", "section": "Page 122"}
{"text": "5-6   SWEBOK \u00ae GUIDE V4.0\n\u2022\t Controllability refers to the transition \nof testing activities from the laboratory \n(i.e., controlled conditions) to reality (i.e., \nuncontrolled conditions). \n\u2022\t Replication refers to the ability for dif-\nferent people to perform the same \ntesting activities. The purpose is to verify \nwhether a given testing theory works, at \nleast in the laboratory. \n\u2022\t The generalization of testing is connected \nto external validity \u2014 i.e., the extent to \nwhich the test approach can be applied \nto broader settings or target populations. \nThe generalizability of the software testing \ncan be important for managing the testing \nactivities (in terms of cost and effort) and \nincreasing confidence in the test results. \n1.2.15. Offline vs. Online Testing\n[10, c3]\nThe testing process can be executed in two \nsettings: offline and online. Usually, the \nSUT is validated in an environment without \nexternal interaction in offline testing, whereas \nthe SUT interacts with the real application \nenvironment in online testing. The test cases \nare either manually or automatically derived \nin both cases, and the expected outcomes are \nused to assess the SUT.\n1.3. Relationship of Testing to Other Activities\nSoftware testing is related to but different \nfrom static software quality management \ntechniques, proofs of correctness, debugging, \nand program construction. However, it is \ninformative to consider testing from the view-\npoint of software quality analysts and certi-\nfiers. For further discussion, see the following:\n\u2022\t Testing vs. Static Software Quality \nManagement Techniques: See Section \n2.2.1, Static Analysis Techniques, in the \nSoftware Quality KA. \n\u2022\t Testing \nvs. \nQuality \nImprovement/\nAssurance: See Section 1.3.2, Software \nProduct \nQuality, \nin \nthe \nSoftware \nQuality KA.\n\u2022\t Testing vs. Correctness Proofs and \nFormal Verification: See the Software \nEngineering Models and Methods KA.\n\u2022\t Testing vs. Debugging: See Construction \nTesting in the Software Construction KA \nand Debugging Tools and Techniques in \nthe Computing Foundations KA.\n\u2022\t Testing vs. Program Construction: See \nConstruction Testing in the Software \nConstruction KA. \n\u2022\t Testing vs. Security: See the new KA: \nSoftware Security.\n\u2022\t Testing vs. Effort Estimation: See the \nSoftware Engineering Management KA. \n\u2022\t Testing vs. Legal Issues: See the Software \nEngineering Professional Practice KA.\n2.\t Test Levels\n[1*, c1s13; 2*, c8s1]\nSoftware testing is usually performed at dif-\nferent levels throughout development and \nmaintenance. Levels can be distinguished \nbased on the object of testing, the target, or \non the purpose or objective (of the test level). \n2.1. The Target of the Test \n[1*, c1s13, 2*, c8s1]\nThe target of the test can vary depending \non the SUT, the conditions of the environ-\nment, and the budget/time devoted to the \ntesting activity. Four test stages can be distin-\nguished: unit, integration, system, and accep-\ntance. These four test stages do not imply \nany development process, nor is any one of \nthem assumed to be more important than the \nother three. \n2.1.1. Unit Testing \n[1*, c3, 2*, c8] \nUnit testing verifies the functioning in isola-\ntion of SUT elements that are separately test-\nable. Depending on the context, these could \nbe the individual subprograms or components, \na subsystem, or a composition of SUT com-\nponents. Typically, but not always, the person \nwho wrote the code conducts the unit testing. \n", "page": 123, "type": "text", "section": "Page 123"}
{"text": "SOFTWARE TESTING   5-7\n2.1.2. Integration Testing \n[1*, c7, 2*, c8]\nIntegration testing verifies the interac-\ntions among SUT elements (for instance, \ncomponents, modules, or subsystems). \nIntegration strategies involve the incre-\nmental (and systematic) integration of the \nSUT elements considering either identified \nfunctional threads or architecture specifica-\ntions. Typical integration testing strategies \nare top-down, bottom-up, mixed (or sand-\nwiched), and the big bang. They focus on \ndifferent perspectives of the level at which \nSUT elements are integrated. Integration \ntesting is a continuous activity that can \nbe performed at each development stage. \nIt may target different aspects, such as \ninteroperability (e.g., compatibility or con-\nfiguration) of the SUT elements or with \nthe external environment. External inter-\nfaces to other applications, utilities, hard-\nware devices or operating environments can \nalso be considered.\n2.1.3. System Testing \n[1*, c8, 2*, c8]\nSystem testing concerns testing the behavior \nof the SUT (according to the definition of \nSection 1). Effective unit and integration \ntesting should have identified many SUT \ndefects. In addition, system testing is usu-\nally considered appropriate for assessing \nnon-functional system requirements, such as \nsecurity, privacy, speed, accuracy, and reli-\nability. (See Functional and Non-Functional \nRequirements in the Software Requirements \nKA and Software Quality Requirements in \nthe Software Quality KA.)\n2.1.4. Acceptance Testing \n[1*, c1s7, 2*, c8s4]\nAcceptance testing targets the deployment of a \nSUT. Its main goal is to verify that the SUT \nsatisfies the requirements and the end-users\u2019 \nexpectations. Generally, it is run by or with \nthe end-users to perform those functions and \ntasks for which the software was built. For \nexample, this testing activity could target \nusability testing or operational acceptance. \nDefining acceptance tests before imple-\nmenting the corresponding functionality is \na key activity of the acceptance test-driven \ndevelopment (ATDD). (See the Software \nRequirements KA, Section 4.3.) \n2.2. Objectives of Testing \n[1*, c1s7]\nTesting is conducted considering specific \nobjectives, which are stated (more or less) \nexplicitly and with varying degrees of preci-\nsion. Stating the testing objectives in precise, \nquantitative terms supports measurement and \ncontrol of the test process.\nTesting can be aimed at verifying dif-\nferent properties. For example, test cases \ncan be designed to check that the functional \nspecifications are correctly implemented, \nwhich is variously referred to in the liter-\nature as conformance testing, correctness \ntesting or functional testing. However, sev-\neral other non-functional properties may \nbe tested as well, including performance, \nreliability, and usability. (See Models and \nQuality Characteristics in the Software \nQuality KA.)\nOther important testing objectives include \nbut are not limited to reliability measure-\nments, identification of security and pri-\nvacy vulnerabilities, and usability evaluation; \ndifferent approaches would be necessary \ndepending on the objective. Note that, in \ngeneral, the test objectives vary with the test \ntarget; different purposes are addressed at dif-\nferent levels of testing.\nThe subtopics listed below are those most \ncited in the literature.\n2.2.1. Conformance Testing\n[1*, c10s4]\nConformance testing aims to verify that the \nSUT conforms to standards, rules, specifi-\ncations, requirements, design, processes, or \npractices. \n", "page": 124, "type": "text", "section": "Page 124"}
{"text": "5-8   SWEBOK \u00ae GUIDE V4.0\n2.2.2 Compliance Testing\n[1*, c12s3]\nCompliance testing aims to demonstrate the \nSUT\u2019s adherence to a law or regulation. \nUsually, compliance testing is forced by an \nexternal regulatory body.\n2.2.3. Installation Testing \n[1*, c12s2]\nOften, after system and acceptance testing is \ncompleted, and the SUT has been installed in \nthe target environment, the SUT is verified. \nInstallation testing can be viewed as system \ntesting conducted in the operational environ-\nment of hardware configurations and other \noperational constraints. Installation proce-\ndures may also be verified.\n2.2.4. Alpha and Beta Testing \n[1*, c13s7, c16s6, 2*, c8s4]\nBefore the SUT is released, it is sometimes \ngiven to a small, selected group of potential \nusers for trial use (alpha testing) and/or to a \nlarger set of representative users (beta testing). \nThese users report problems with the product. \nAlpha testing and beta testing are often \nuncontrolled and are not always referred to in \na test plan.\n2.2.5. Regression Testing \n[1*, c8s11, c13s3; 4, part 1, c5]\nAccording to the definition reported in [5], \nregression testing is the \u201cselective retesting of \na SUT to verify that modifications have not \ncaused unintended effects and that the SUT \nstill complies with its specified requirements.\u201d \nIn practice, the approach is designed to show \nthat the SUT still passes previously passed tests \nin a test suite (in fact, it is sometimes referred \nto as non-regression testing). In some cases, a \ntrade-off must be made between the assur-\nance given by regression testing every time a \nchange is made and the resources required to \nperform the regression tests. This can be quite \ntime-consuming because of the many tests \nthat might be executed. Regression testing \ncan be conducted at each test level described \nin Section 2.1. It may involve functional and \nnon-functional testing, such as reliability, \naccessibility, usability, maintainability, con-\nversion, migration, and compatibility testing.\nRegression testing may involve selection \n(see Section 1.2.2) and minimization (see \nSection 1.2.3) of test cases, as well as the \nadoption of prioritization approaches (see \nSection 2.2.6) to existing test suites.\nRegression testing is a fundamental activity \nof Agile, DevOps, test-driven development \n(TDD), and Continuous Development. It is \nusually performed after integration testing and \nbefore deployment to production or operation. \n2.2.6. Prioritization Testing \n[1*, c12s7]\nTest case prioritization aims to schedule test \ncases to increase the rate and likelihood of \nfault detection, the coverage of code under \ntest, and the SUT\u2019s reliability. Typically, pri-\noritization testing relies on heuristics, and \nits performance might vary according to the \nSUT, the environment, and the available test \ncases. Among the different prioritization \nproposals, similarity-based prioritization is \none of the most commonly adopted. In this \napproach to prioritization, test cases are pri-\noritized starting from those most dissimilar \naccording to a predefined distance function.\n2.2.7. Non-functional Testing \n[2*, c8]\nNon-Functional testing targets the validation \nof non-functional aspects (such as perfor-\nmance, usability, or reliability), and it is per-\nformed at all test levels. At the state of the \npractice, there are hundreds of non-functional \ntesting techniques that include but are not \nlimited to the following: \n\u2022\t Performance \nTesting \n[4, \npart \n1]: \nPerformance testing verifies that the \nsoftware meets the specified performance \nrequirements and assesses performance \n", "page": 125, "type": "text", "section": "Page 125"}
{"text": "SOFTWARE TESTING   5-9\ncharacteristics \n(e.g., \ncapacity \nand \nresponse time).\n\u2022\t Load Testing [4, part 1]: Load testing \nfocuses on validating the SUT\u2019s behavior \nunder load pressure conditions to dis-\ncover problems (e.g., deadlocks, racing, \nbuffer overflows and memory leaks) or \nreliability, stability, or robustness viola-\ntions. It aims to assess the rate at which \ndifferent service requests are submitted \nto the SUT.\n\u2022\t Stress Testing [1*, c8s8]: Stress testing \naims to push the SUT beyond its capa-\nbilities by generating a load greater than \nwhat the system is expected to handle.\n\u2022\t Volume Testing [4, part 1]: Volume \ntesting targets the assessment of the \nSUT\u2019s internal storage limitations and its \nability to exchange data and information.\n\u2022\t Failover Testing [1*, c17s2; 2*, c8]: \nFailover testing validates the SUT\u2019s \nability to manage heavy loads or unex-\npected failure to continue typical opera-\ntions (e.g., by allocating extra resources). \nFailover testing is also connected with \nrecoverability validation.\n\u2022\t Reliability Testing [1*, c15; 2*, c11]: \nReliability testing evaluates the SUT\u2019s \nreliability by identifying and correcting \nfaults. Reliability testing observes the \nSUT in operation or exercises the SUT \nby using test cases according to statis-\ntical models (operational profiles) of the \ndifferent users\u2019 behaviors. Usually, reli-\nability is assessed through reliability \ngrowth models. The continuous devel-\nopment processes (such as DevOps) are \ncurrently facilitating the adoption of reli-\nability testing in the various iterations for \nimproving final SUT quality.\n\u2022\t Compatibility Testing [4, part 1; 10, c3]: \nCompatibility testing is used to verify \nwhether the software can collaborate with \ndifferent hardware and software facilities \nor with different versions or releases.\n\u2022\t Scalability Testing [1*, c8s7; 2* c17]: \nScalability testing assesses the soft-\nware\u2019s ability to scale up non-functional \nrequirements such as load, number of \ntransactions, volume of data. It could \nintegrate or extend load, elasticity and \nstress testing.\n\u2022\t Elasticity Testing [17]: Elasticity testing \nassesses the ability of the SUT (such as \ncloud and distributed systems) to rap-\nidly expand or shrink compute, memory, \nand storage resources without compro-\nmising the capacity to meet peak utili-\nzation. Some elasticity testing objectives \nare to control behaviors, to identify the \nresources to be (un)allocated, and to coor-\ndinate events in parallel.\n\u2022\t Infrastructure Testing [8, annex H]: \nInfrastructure testing tests and validates \ninfrastructure components to reduce the \nchances of downtime and improve the \nperformance of the IT infrastructure.\n\u2022\t Back-to-Back Testing [5]: ISO/IEC/\nIEEE 24765 defines back-to-back testing \nas \u201ctesting in which two or more vari-\nants of a program are executed with \nthe same inputs, the outputs are com-\npared, and errors are analyzed in case of \ndiscrepancies.\u201d\n\u2022\t Recovery Testing [1*, c14s2]: Recovery \ntesting is aimed at verifying software \nrestart capabilities after a system crash or \nother disaster.\n2.2.8. Security Testing \n[2*, c13; 4, part 4, annex A]\nSecurity testing focuses on validating that \nthe SUT is protected from external attacks. \nMore precisely, it verifies the confidenti-\nality, integrity, and availability of the sys-\ntems and their data. Usually, security testing \nincludes validation against misuse and abuse \nof the software or system (negative testing). \n(See Security Testing in the Software \nSecurity KA.)\n2.2.9. Privacy Testing \n[2*, c13, c14]\nPrivacy testing is devoted to assessing the \nsecurity and privacy of users\u2019 personal \ndata to prevent local attacks. It specifically \n", "page": 126, "type": "text", "section": "Page 126"}
{"text": "5-10   SWEBOK \u00ae GUIDE V4.0\nassesses privacy and information-sharing \npolicies, as well as the validation of decen-\ntralized management of users\u2019 social profiles \nand data storage solutions. (See Legal Issue \nin the Software Engineering Professional \nPractice KA.)\n2.2.10. Interface and Application Program  \n\t Interface (API) Testing \n[2*, c8s1; 14*, c7s12; 4, part 5, c4, c7]\nInterface defects are common in complex sys-\ntems. Interface testing aims to verify whether \nthe components\u2019 interface provide the correct \nexchange of data and control information. \nUsually, the test cases are generated from the \ninterface specification. A specific interface \ntesting objective is to simulate the use of APIs \nby end-user applications. That involves gen-\nerating parameters of the API calls, setting \nconditions of the external environment, and \ndefining internal data that affect the API. \n2.2.11. Configuration Testing \n[1*, c8s5]\nWhere the SUT is built to serve different \nusers, configuration testing verifies the software \nunder specified configurations.\n2.2.12. Usability and Human-Computer  \n\t Interaction Testing \n[2* c8s4; 19*, c6; 4, part 4, annex A]\nThe main task of usability and human-com-\nputer interaction testing is to evaluate how \neasy it is for end-users to learn to use the \nsoftware. It might involve testing the soft-\nware functions that support user tasks, the \ndocumentation that aids users, and the sys-\ntem\u2019s ability to recover from user errors. \n(See User-Centered Design in the Software \nDesign KA.)\n3.\t Test Techniques \n[1*, c1s15; 4, part 4]\nOver the years, different testing techniques \nhave been developed to increase the SUT\u2019s \noverall quality [4, part 4]. These techniques \nattempt to propose systematic procedures and \napproaches for generating or selecting the \nmost suitable test suites for detecting as many \nfailures as possible.\nTesting techniques can be classified by \nconsidering different key aspects such as \nspecification, structure, and experience [4, \npart 4]. Additional classification sources can \nbe the faults to be discovered, the predicted \nuse, the models, the nature of the applica-\ntion, or the derived knowledge. For instance, \nmodel-based testing [7; 4, part 1] refers to all \nthe testing techniques that use the concept \nof a model representing behavioral specifi-\ncation, the SUT\u2019s structure, or the available \nknowledge and experience. However, classi-\nfication overlapping is possible, and one cate-\ngory might deal with combining two or more \ntechniques.\nAlternative classifications that rely on \nthe degree of information about the SUT \nare available in the literature. Indeed, in \nthe specification-based techniques, also \nknown as black-box techniques, the gen-\neration of test cases is based only on the \nSUT\u2019s input/output behavior, whereas in \nthe structure-based, also called white-box \n(or glass-box or clear-box), techniques, the \ntest cases are generated using the infor-\nmation about how the SUT has been \ndesigned or coded.\nAs some testing techniques are used \nmore than others, the remainder of the sec-\ntion presents the standard testing techniques \nand those commonly adopted at the state of \nthe practice.\n3.1. Specification-Based Techniques\n[1*, c6s2; 4, part 4]\nThe underlying idea of specification-based tech-\nniques (sometimes also called domain testing \ntechniques) is to select a few test cases from \nthe input domain that can detect specific cat-\negories of faults (also called domain errors). \nThese techniques check whether the SUT \ncan manage inputs within a certain range and \nreturn the required output.\n", "page": 127, "type": "text", "section": "Page 127"}
{"text": "SOFTWARE TESTING   5-11\n3.1.1. Equivalence Partitioning \n[1*, c9s4]\nEquivalence partitioning involves partitioning \nthe input domain into a collection of subsets \n(or equivalence classes) based on a specified \ncriterion or relation. This criterion or rela-\ntion may be different computational results, a \nrelation based on control flow or data flow, or \na distinction made between valid inputs that \nare accepted and processed by the SUT and \ninvalid inputs, such as out-of-range values, \nthat are not accepted and should generate \nan error message or initiate error processing. \nA representative test suite (sometimes con-\ntaining only one test case) is usually taken \nfrom each equivalence class.\n3.1.2. Bounday Value Analysis \n[1*, c9s5; 4, part 4]\nTest cases are chosen on or near the bound-\naries of the input domain of variables, with the \nunderlying rationale that many faults tend to \nconcentrate near the extreme values of inputs. \nAn extension of this technique is robustness \ntesting, wherein test cases are also chosen out-\nside the input domain of variables to test pro-\ngram robustness in processing unexpected or \nerroneous inputs. \n3.1.3. Syntax Testing\n[1*, c10s11, 2*, c5; 4, part 4] \nThe Syntax Testing techniques, also known \nas formal specification-based techniques, \nrely on the SUT specifications in a formal \nlanguage. (See Formal Methods in the \nSoftware Engineering Models and Methods \nKA.) This representation permits automatic \nderivation of functional test cases and, at the \nsame time, provides an oracle for checking \ntest results. \n3.1.4. Combinatorial Test Techniques \n[1*, c9s3; 4, part 4]\nThe Combinatorial Test Techniques system-\natically derive the test cases that cover specific \nparameters of values or conditions. According \nto [4, part 4], the commonly used combina-\ntorial test techniques are All combinations \nTesting, Pair-Wise Testing, Each Choice \nTesting, and Base Choice Testing. All combi-\nnations testing focuses on all the possible input \ncombinations, whereas its subset, also called \nt-wise testing, considers every possible combi-\nnation of t input. In this case, more than one \npair is derived (i.e., by including higher-level \ncombinations). Pair-wise testing is a specific \ncombinatorial testing technique where test \ncases are derived by combining values of every \npair of an input set. These techniques are also \nknown as orthogonal array testing (OAT). \n3.1.5. Decision Table\n[1*, c9s6; 1*, c13s6; 4, part 4]\nDecision tables (or trees) represent logical rela-\ntionships between conditions (roughly, inputs) \nand actions (roughly, outputs). Usually, they \nare widely adopted for knowledge representa-\ntion (e.g., machine learning (ML)). Test cases \nare systematically derived by considering \nevery possible combination of conditions \nand their corresponding resultant actions. \nA related technique is cause-effect graphing. \nCurrently, shift-left development processes \nare taking advantage of this kind of testing \ntechnique because these techniques are useful \nfor documenting the test results and factors \nthat can affect them.\n3.1.6. Cause-Effect Graphing\n[1*, c1s6; 4, part 3, part 4]\nCause-effect graphing techniques rely on log-\nical networks that map a set of causes to a \nset of effects by systematically exploring the \npossible combinations of input conditions. \nThey identify the effects and link the effects \nto their causes through model graphs. Cause-\neffect graphing techniques are used in testing \nbecause they allow specification analysis, the \nidentification of the relevant input conditions \nor causes, the consequent transformations, \nand the output conditions.\n", "page": 128, "type": "text", "section": "Page 128"}
{"text": "5-12   SWEBOK \u00ae GUIDE V4.0\n3.1.7. State Transition Testing \n[1*, c10; 4, part 4]\nTechniques based on Finite-State Machines \n(State Transition Testing techniques in [4, \npart 4]) focus on representing the SUT with \na finite-state machine. In this case, the test \nsuite is derived to cover the states and tran-\nsitions according to a specific coverage level. \n3.1.8. Scenario-Based Testing \n[2*, c8s3, c19s3; 4, part 4; 7]\nA model in this context is an abstract (formal) \nrepresentation of the SUT or its software \nrequirements. (See Modeling in the Software \nEngineering Models and Methods KA.) \nScenario-based testing is used to validate require-\nments, check their consistency, and generate \ntest cases focused on the SUT\u2019s behavioral \naspects. (See Types of Models in the Software \nEngineering Models and Methods KA.) The \nkey components of scenario-based testing are \nthe notation used to represent the model of the \nsoftware or its requirements, workflow models \nor similar models, the test strategy or algorithm \nused for test case generation, the supporting \ninfrastructure for the test execution, and the \nevaluation of test results compared to expected \nresults. Because of the complexity of the tech-\nniques, scenario-based testing approaches are \noften used with test automation harnesses. \nAmong scenario-based testing, workflow \nmodels can also be used to graphically represent \nthe sequence of activities performed by humans \nand/or software applications. In this case, each \nsequence of actions constitutes one workflow \n(also called a scenario). Usually, it is important \nto ensure that both typical and alternate work-\nflows are also tested. For example, business \nprocess testing is part of this scenario-based \ntechnique. In this case, the special focus is on \nthe roles in a workflow specification. \n3.1.9. Random Testing \n[1*, c9s7; 4, part 4]\nIn this approach, test cases are generated \npurely at random. This testing falls under \nthe heading of input domain testing because \nthe input domain must be known to be able \nto pick random points within it. Random \ntesting provides a relatively simple approach \nto test automation. Enhanced forms of \nrandom testing (such as adaptive random \ntesting) have been proposed in which other \ninput selection criteria direct the random \ninput sampling.\nCurrently, under the name of fuzz testing, \nthe random selection of invalid and unex-\npected inputs and data is extensively used in \ncybersecurity to find hackable software bugs, \ncoding errors, and security loopholes. (See \nalso Sections 2.2.8 and 8.2.)\n3.1.10. Evidence-Based \b\n[10, c6s2]\nEvidence-based software engineering (EBSE), \nwhich follows a rigorous research approach, \nis the best solution for a practical problem. \nEBSE includes the following phases: \n\u2022\t Identifying the evidence and forming \na question\n\u2022\t Tracking down the best evidence to \nanswer the question\n\u2022\t Critically analyzing the evidence in light \nof the problem that the evidence should \nhelp solve.\n\u2022\t EBSE principles can also be applied to \nthe testing process. For that purpose, the \nwidely used approaches that allow iden-\ntifying and aggregating evidence are \nsystematic mapping studies and system-\natic reviews.\n3.1.11. Forcing Exception \n[5] \nTest cases are specifically conceived for \nchecking whether the SUT can manage a \npredefined set of exceptions/errors, such as \ndata exception, operation exception, overflow \nexception, protection exception or underflow \nexception. Testing techniques usually focus \non negative test scenarios (i.e., test cases \nthat are able to force the generation of error \nmessages).\n", "page": 129, "type": "text", "section": "Page 129"}
{"text": "SOFTWARE TESTING   5-13\n3.2. Structure-Based Test Techniques\n[4, part 4] \nStructure-Based Test Techniques (sometimes \ncalled code-based test techniques) focus on \nthe code and its structure. Structure-Based \nTest Techniques can be performed at dif-\nferent levels (such as code development, code \ninspection, or unit testing) and can include \nstatic testing (such as code inspection, code \nwalkthrough, and code review), dynamic \ntesting (like statement coverage, branch cov-\nerage, and path coverage), or code complexity \nmeasurement (e.g., using techniques like cyc-\nlomatic complexity [12]). \n3.2.1. Control Flow Testing \n[1*, c4; 4, part 4]\nControl flow testing covers all the statements, \nbranches, decisions, branch conditions, mod-\nified condition decision coverage (MC/DC), \nblocks of statements, or specific combinations \nof statements in a SUT. The strongest of the \ncontrol flow-based criteria is path testing, \nwhich aims to execute all entry-to-exit con-\ntrol flow paths in a SUT\u2019s control flow graph. \nBecause exhaustive path testing is generally \nnot feasible because of loops, other less strin-\ngent criteria focus on coverage of paths that \nlimit loop iterations, such as statement cov-\nerage, branch coverage, and condition/decision \ntesting. The adequacy of such tests is measured \nin percentages; for example, when all branches \nhave been executed at least once by the tests, \n100% branch coverage has been achieved.\n3.2.2. Data Flow Testing \n[1*, c5; 4, part 4]\nIn data flow testing, the control flow graph is \nannotated with information about how the \nvariables are defined, used, and killed (unde-\nfined). Commonly adopted data flow testing \ntechniques are All-Definitions Testing, All-\nC-Uses Testing, All-P-Uses Testing, All-\nUses Testing and All-DU-Paths Testing. The \nstrongest data flow testing criterion is the All-\nDU-Paths Testing, where all definition and \nuse (DU) paths need to be covered [4, part \n4]. This is because it requires executing, for \neach variable, every control flow path segment \nfrom a definition of that variable to the use \nof that definition. However, weaker strategies \nsuch as all-definitions and all-uses are used to \nreduce the number of paths required.\n3.2.3. Reference Models for Structure-Based Test  \n\t Techniques \n[1*, c4]\nAlthough not a technique, a SUT\u2019s control \nstructure can be graphically represented using \na flow graph to visualize structure-based test \ntechniques. A flow graph is a directed graph, \nthe nodes and arcs of which correspond to \nprogram elements. (See Graphs and Trees \nin the Mathematical Foundations KA.) For \ninstance, nodes may represent statements or \nuninterrupted sequences of statements, and \narcs may represent the transfer of control \nbetween nodes.\n3.3. Experience-Based Techniques\n[4, part 1, part 4]\nThe generation of the most suitable test suite \nmay depend on different factors, such as human \nknowledge of the SUT and its context and the \ntester\u2019s experience and intuition. In the fol-\nlowing section, the commonly adopted experi-\nence-based techniques are briefly introduced.\n3.3.1. Error Guessing \n[1*, c9s8; 4, part 4]\nIn error guessing, software engineers design \ntest cases specifically to anticipate the most \nplausible faults in each SUT. Good sources of \ninformation are the history of faults discov-\nered in earlier projects and the software engi-\nneer\u2019s expertise.\n3.3.2. Exploratory Testing\n[4, part 1]\nExploratory testing is defined as simultaneous \nlearning, test design and test execution. The \n", "page": 130, "type": "text", "section": "Page 130"}
{"text": "5-14   SWEBOK \u00ae GUIDE V4.0\ntest cases are not defined in advance but are \ndynamically designed, executed, and modi-\nfied according to the collected evidence and \ntest results, such as observed product behavior, \npeculiarities of the SUT, the domain and the \nenvironment, the failure process, the types of \npossible faults and failures, and the risk asso-\nciated with a particular product. Usually, the \nintuition, knowledge, and expertise of the \npersonnel in charge of performing the explor-\natory testing can affect the testing effective-\nness. Exploratory testing is widely used in \nshift-left development (such as Agile). (See \nSection 5.4.2.) \n3.3.3. Further Experience-Based Techniques \n[4, part 4; 13]\nAt the state of the practice, experience-based \ntechniques may include further approaches \nsuch as Ad Hoc-based, knowledge-based and \nML-based testing techniques. \nAd Hoc testing is a widely used technique in \nwhich test cases are derived by relying on the \nsoftware engineer\u2019s skill, intuition, and expe-\nrience with similar programs. It can be useful \nfor identifying test cases that are not easily gen-\nerated by more formalized techniques. Typical \nAd Hoc methodologies are the following: \n\u2022\t Monkey testing runs randomly generated \ntest cases to simulate rundom activities \nand cause the program to stop.\n\u2022\t Pair (Buddy) testing involves two indi-\nviduals. One generates and runs the test \ncases; the other observes and analyzes \nthe testing process. Pair testing allows \nfor generating test cases with broader and \nbetter test coverage.\n\u2022\t Gamification aims to convert testing \ntasks to components of gameplay. By \napplying specific techniques (such as \nengaging practitioners or crowdsourcing \ncomplex testing tasks), gamification can \nsubstantially improve software testing \npractice and, consequently, SUT quality.\n\u2022\t Quick testing, in which a very small test \nsuite is selected and executed to swiftly \nidentify critical issues in the SUT.  It aims \nto enhances the probability of detecting \nfaults early in the development process.\n\u2022\t Smoke testing (also known as Build \nVerification Testing) ensures that the \nSUT\u2019s core functionalities behave prop-\nerly. It also guarantees that the SUT is \noperational before the planned testing \nbegins. In addition, smoke testing pre-\nvents failures because of the test envi-\nronment (e.g., because artifacts or \npackages are not properly built). Smoke \ntesting is also considered a special case of \nquick testing.\nKnowledge-based testing and ML-based \ntesting exploit (formal or informal) knowl-\nedge about the SUT or derive it from obser-\nvations of SUT executions for defining its \nbehavioral models (such as ontologies or \ndecision tables) (see Section 3.6.1), rules, \nand non-functional properties. In addition, \nKnowledge-based testing and ML-based \ntesting specify the testing needs and iden-\ntify test objectives for which test cases are \ngenerated.\n3.4. Fault-Based and Mutation Techniques \n[1*, c1s14, 1* c3s5; 5]\nWith different degrees of formalization, fault-\nbased testing techniques devise test cases spe-\ncifically to reveal likely or predefined fault \ncategories. A fault model can be introduced \nthat classifies the different faults to better \nfocus the test case generation or selection. In \nthis context, a variety of platforms and devel-\nopment processes (e.g., waterfall, spiral and \nAgile) consider the orthogonal defect clas-\nsification (ODC) a valid methodology for \ncollecting semantic information about the \ndifferent defects and reducing the time and \neffort of the root cause analysis.\nMutation Testing was originally conceived as \na technique to evaluate test suites (see Section \n4.2, Evaluation of the Tests Performed) in \nwhich a mutant is a slightly modified ver-\nsion of the SUT (also called gold), differing \nfrom it by a small syntactic change. Every \ntest case exercises both the gold version and \n", "page": 131, "type": "text", "section": "Page 131"}
{"text": "SOFTWARE TESTING   5-15\nall generated mutants. If a test case succeeds \nin identifying the difference between the \ngold version and a mutant, the latter is said \nto be \u201ckilled.\u201d The underlying assumption of \nmutation testing, the coupling effect, is that \nmore complex but real faults will be found \nby looking for simple syntactic faults. For \nthe technique to be effective, many mutants \nmust be automatically generated and executed \nsystematically [6]. Mutation testing is also a \ntesting criterion in itself. Test cases are ran-\ndomly generated until enough mutants have \nbeen killed, or tests are specifically designed \nto kill surviving mutants. In the latter case, \nmutation testing can also be categorized as a \nstructure-based technique. Mutation testing \nhas been used effectively for generating fuzz \ntesting. A more recent application of the \nmutation process is metamorphic testing, a \ntechnique that has become increasingly pop-\nular in addressing some ML systems\u2019 testing \nchallenges. In this case, the modifications \n(called also morph) are applied to the inputs \nso a relationship can connect the previous \ninput (and its output) to the new morphed \ninput (and its output).\n3.5. Usage-Based Techniques \n[1*, c15s5]\nUsage-based techniques usually rely on a usage \nmodel or profiles. In this case, the testing \nenvironment needs to represent the actual \noperational environment, and the sequence of \ntest case execution should reproduce the SUT \nusage by the target stakeholder. Statistical \nsampling is used for simulating the execu-\ntion of many test cases. Thus, sometimes, the \nterm random testing is also associated with \nthese techniques. Usage-based statistical \ntesting is applied more during the acceptance \ntesting stage.\n3.5.1. Operational Profile \n[1*, c15s5, 2*, c11]\nTesting based on operational profiles aims at \ngenerating test cases that might estimate the \nreliability of the SUT or part of it. Therefore, \nthe goal is to infer from the observed test \nresults the future reliability of the software \n(when it is in use). Because the established \nreliability strictly depends on the operating \nprofile, the main difficulty (and cost) in using \nthis testing approach comes from the opera-\ntional profile derivation. Therefore, one pos-\nsible solution is to assign to the input the \nprobabilities or profiles according to their fre-\nquency of occurrence in actual operation.\n3.5.2. User Observation Heuristics\n[19*, c5, c7; 4, part 4, annex A]\nSpecialized heuristics, also called usability \ninspection methods, are applied to systemat-\nically observe system use under controlled \nconditions to determine how well people can \nuse the system and its interfaces. Usability \nheuristics include cognitive walkthroughs, \nclaims analysis, field observations, thinking \naloud, and even indirect approaches such as \nuser questionnaires and interviews. \n3.6. Techniques Based on the Nature of the \nApplication\n[2* c16, c17, c18, c20, c21; 14*, c4s8; 8] \nThe above techniques apply to all kinds of \nsoftware. Additional test derivation and exe-\ncution techniques are based on the nature of \nthe software being tested. Examples are the \nfollowing: \n\u2022\t Object-oriented software \n\u2022\t Component-based software\n\u2022\t Web-based software\n\u2022\t Concurrent programs \n\u2022\t Protocol-based software\n\u2022\t Communication systems\n\u2022\t Real-time systems \n\u2022\t Safety-critical systems\n\u2022\t Service-oriented software \n\u2022\t Open-source software \n\u2022\t Embedded software \n\u2022\t Cloud-based software\n\u2022\t Blockchain-based software\n\u2022\t Big data-based software\n\u2022\t AI/ML/DL-based software\n", "page": 132, "type": "text", "section": "Page 132"}
{"text": "5-16   SWEBOK \u00ae GUIDE V4.0\n\u2022\t Mobile apps\n\u2022\t Security and privacy-preserving software\nIn some cases, standards such as ISO/\nIEC/IEEE 29119 [4, part 4, part 5] pro-\nvide examples and support for specifying test \ncases, automating their execution, and main-\ntaining the test suites, such as the case of the \nKeyword-Driven Testing [4, part 5].\n3.7. Selecting and Combining Techniques \n[14*, c7s12; 10; 4, part 5] \nCombining different testing techniques has \nalways been a well-grounded means to assure \nthe required level of SUT quality. Currently, \nespecially in shift-left developments, method-\nologies for adaptive combinations of testing \ntechniques are part of the state of the prac-\ntice. The goal is to improve the effectiveness of \ntesting processes by learning from experience \nand, at the same time, adapting the technique \nselection to the current testing session. \n3.7.1. Combining Functional and Structural\n[1*, c9; 4, part 5]\nScenario-based and structure-based test \ntechniques are often contrasted as functional \nvs. structural testing. These two approaches \nto test case selection are nowadays seen as \ncomplements, as they use different sources of \ninformation and have been shown to high-\nlight different problems. Depending on the \ndifferent organizational constraints, such \nas budgetary considerations, they could \nbe combined.\n3.7.2. Deterministic vs. Random \n[1*, c9s6]\nTest cases can be selected in a determin-\nistic way, according to many techniques, or \nrandomly drawn from some distribution of \ninputs, such as is usually done in reliability \ntesting. Several analytical and empirical com-\nparisons have been conducted to analyze the \nconditions that make one approach more \neffective than the other.\n3.8. Techniques Based on Derived Knowledge \n[2*, c19, c20; 14*, c7] \nTesting techniques can integrate evidence and \nknowledge from different research areas and \ncontexts. For this, approaches and methodol-\nogies are used to support testing activity and \nimprove its effectiveness. Currently, innova-\ntive approaches include using digital twins or \nsimulation methodologies and frameworks, \nexploiting ML and gamification facilities, \nand using (simulated) neuronal networks.\n4.\t Test-Related Measures\n[2*, c24s5; 14*, c10; 4, part 4]\nTesting techniques are like tools that help in \nachieving specific test objectives. To evaluate \nwhether a test objective is reached, well-de-\nfined measures are needed. Measurement is \nusually considered fundamental to quality \nanalysis. Measurement may also be used to \noptimize test planning and execution. Test \nmanagement can use several different process \nmeasures to monitor progress. (See Software \nEngineering Measurement in the Software \nEngineering Management KA for informa-\ntion on measurement programs. See Software \nMeasurement in the Software Engineering \nProcess KA for information on measures.)\nAccording to the definition in [4, part 4], \ntesting techniques can be classified according \nto the degree of coverage they can achieve. \nCoverage may vary from 0% to 100%, \nexcluding possible infeasible tests (i.e., tests \nthat cannot be executed). Thus, for each spec-\nification-based, structure-based, and expe-\nrience-based test technique, the associated \ncoverage measures and the procedure for \nevaluating that coverage must be determined. \nExamples of coverage measures could be the \npercentage of branches covered in the pro-\ngram flow graph or the percentage of func-\ntional requirements exercised among those \nlisted in the specifications document.\nIt is important to consider that moni-\ntoring facilities can dynamically compute the \nratio between covered elements, and the total \nnumber may also be considered. Additionally, \n", "page": 133, "type": "text", "section": "Page 133"}
{"text": "SOFTWARE TESTING   5-17\nespecially in the case of structure-based \ntesting techniques, appropriate instrumenta-\ntion of the SUT may also be necessary.\nHowever, the proposed set of testing mea-\nsures can also be classified from different \nviewpoints \u2014 from the point of view of those \nproviding and allowing an evaluation of the \nSUT based on the observed test outputs and \nof those that evaluate the thoroughness or \neffectiveness of the executed test suites. \n4.1. Evaluation of the SUT \n[2*, c24s5]\nUsually, indicators (i.e., measurable infor-\nmation) can be used to determine whether a \nSUT is performing as expected and achieving \nits expected outcomes. The indicators, some-\ntimes known as key performance indica-\ntors (KPIs), are strongly connected with the \nadopted evaluation measures, methods, data \nanalysis and reporting.\n4.1.1. SUT Measurements That Aid in Planning  \n\t and Designing Tests \n[14*, c10; 10, c6; 4, part 1, part 4] \nAll the testing measures proposed in [4, \npart 4] can be used for planning and guiding \ntesting activities. Additionally, in the shift-\nleft development process, specific measures, \nsuch as deployment frequency, lead time, \nmean time to recovery (MTTR), and change \nfailure rate, are also commonly adopted \nto plan and manage the testing activities \nand results. \n4.1.2. Fault Types, Classification and Statistics\n [1* c13s4, c13s5, c13s6]\nThe testing literature is rich in classifica-\ntions and taxonomies of faults that can be \ngeneric or specific to a context or quality \nattributes (such as the usability defect clas-\nsification, the taxonomy of HW/SW security \nand privacy vulnerabilities and attacks, and \nthe classification of cybersecurity risks). To \nmake testing more effective, it is important \nto know which types of faults may be found \nin the SUT and the relative frequency with \nwhich these faults have occurred in the past. \nThis information can be useful in making \nquality predictions and in process improve-\nment (See Characterization in the Software \nQuality KA).\n4.1.3. Fault Density \n[1*, c13s4; 14*, c10s1]\nTraditionally, a SUT can be evaluated \nby counting discovered faults as the ratio \nbetween the number of faults found and the \nSUT size. Because of the semantics-based \ndefinition of faults, additional measurements \ncan be considered, such as fault depth (the \nminimal number of fault removals needed to \nmake a SUT correct) and fault multiplicity \n(the number of atomic changes needed to \nrepair a single fault). \n4.1.4. Life Test, Reliability Evaluation \n[1*, c15, 2*, c11; 14*, c1s3]\nA statistical estimate of software reliability, \nwhich can be obtained by observing reli-\nability achieved, can be used to evaluate a \nSUT and decide whether testing can be \nstopped or the SUT is mature enough to be \na candidate for the next shift-left develop-\nment release. Reliability evaluation is taking \na pivotal role in the Cloud (and fog) con-\ntexts [18].\nOn the one hand, validation and veri-\nfication proposals are focusing on main-\ntaining the high level of reliability and \navailability required by the cloud (fog) ser-\nvices. On the other, testing activities are \nexploiting the computational power of the \ncloud (fog) environment to speed up the \nreliability evaluation and drastically reduce \nits costs.\n4.1.5. Reliability Growth Models \n[1*, c15, 2* c11s5]\nReliability growth models predict reli-\nability based on observed failures. They \nassume, in general, that when the faults \n", "page": 134, "type": "text", "section": "Page 134"}
{"text": "5-18   SWEBOK \u00ae GUIDE V4.0\nthat caused the observed failures have been \nfixed (although some models also accept \nimperfect fixes), the product\u2019s reliability \nwill increase. There are many published \nreliability growth models. Notably, these \nmodels are divided into failure-count and \ntime-between-failure models.\n4.2. Evaluation of the Tests Performed \n[4, part 4, c6]\nThe behavior of SUT is generally verified \nby executing test suites, which are pivotal \nin finding defects. Therefore, from both the \nresearchers\u2019 and practitioners\u2019 perspectives, a \nfundamental part of software testing is com-\nparing test suites. Usually, evaluating the test \nsuites means comparing techniques for test \ncase generation that produce the test cases. \nDifferent criteria are used for that purpose, \nsuch as coverage criteria or mutation anal-\nysis criteria.\n4.2.1. Fault Injection\n[1*, c2s5]\nIn fault injection, some faults are artificially \nintroduced into the SUT before testing. \nWhen a test suite is executed, some of these \ninjected faults are revealed, as are, possibly, \nsome faults that were already there. In theory, \ndepending on which and how many artificial \nfaults are discovered, the testing effectiveness \ncan be evaluated, and the remaining number \nof genuine faults can be estimated. In prac-\ntice, statisticians question the distribution \nand representativeness of injected faults rel-\native to genuine faults and the small sample \nsize on which any extrapolations are based. \nSome also argue that this technique should \nbe used with great care because inserting \nfaults into the SUT incurs the obvious risk of \nleaving them there.\n4.2.2. Mutation Score \n[1*, c3s5; 6] \nIn mutation testing, the test suite effective-\nness measure is calculated as the ratio of killed \nmutants to the number of generated mutants. \nThe higher the test suite effectiveness value, \nthe better, since it indicates a stronger ability \nto discover the most real injected faults. \n4.2.3. Comparison and Relative Effectiveness of  \n\t Different Techniques \n[1*, c1s7; 5; 9] \nRelative effectiveness compares different \ntesting techniques against a specific property, \nsuch as the number of tests needed to find the \nfirst failure, the ratio of the number of faults \nfound through testing to all the faults found \nduring and after testing, and how much reli-\nability was improved. Several studies have \nalready been conducted to compare dif-\nferent techniques analytically and empirically \naccording to each notion of property (or effec-\ntiveness) defined.\n5.\t Test Process \n[4, part 1, part 2, part 3; 2* c8] \nTesting concepts, strategies, techniques and \nmeasures need to be integrated into a defined \nand controlled test planning process to test \noutput evaluation. The test process supports \ntesting and provides guidelines to those respon-\nsible for different testing activities to ensure \nthe test objectives are met cost-effectively.\nAs described in [4, part 2], the test pro-\ncess is a multi-layered process activity that \nincludes the test specification at the organi-\nzational, management and dynamic levels. \nThe organizational test process defines the \nsteps for creating and maintaining test speci-\nfications, such as organizational test policies, \nstrategies, processes, procedures, and other \nassets [4, part 2].\nThe test management process defines the \nsteps necessary for management: planning, \nmonitoring and control, and completion.\nFinally, the dynamic test process speci-\nfies the steps for design and implementation, \nenvironment setup and maintenance, execu-\ntion, and test incident reporting.\nIn the remainder of this section, some \npractical considerations about the test process \n", "page": 135, "type": "text", "section": "Page 135"}
{"text": "SOFTWARE TESTING   5-19\nspecification, management, and execution, as \nwell as a summary of the test sub-processes \nand activities included in the organizational, \nmanagement and dynamic levels as in [4, part \n2], are provided.\n5.1. Practical Considerations \n[4, part 1]\nTesting processes should allow the automation \nof different testing phases and should rely on \nthe controllability, traceability, replicability, \nand risk/cost estimation of the performed \nactivities. In the remainder of this section, \ncommonly applied test steps are described, \ncompatible with and applicable to all life cycle \nmodels. (See Software Life Cycles in the \nSoftware Engineering Process KA.)\n5.1.1. Attitudes/Egoless Programming \n[1*, c16; 2*, c3]\nAn important element of successful testing \nis a collaborative attitude toward testing and \nquality assurance (QA) activities. Managers \nhave a key role in fostering a favorable recep-\ntion toward failure discovery and correction \nduring software development and mainte-\nnance. For instance, in shift-left change in \ndevelopment, such as Agile, communication \nand collaboration among testers and devel-\nopers are considered vital for achieving suc-\ncessful testing results. \n5.1.2. Test Guides and Organizational Process \n[1*, c12s1, 2* c8; 4, part 2, part 3; \n14*, c7s3]\nVarious aims can guide the testing phases. For \nexample, risk-based testing uses the product \nrisks to prioritize and focus the test strategy, \nand scenario-based testing defines test cases \nbased on specified software scenarios and \nbacklog lists. Usually, the organization of \nthe test process includes defining test policies \n(i.e., specifying the purpose, goals, and overall \nscope of testing) and test strategies (i.e., spec-\nifying the guidelines about how testing will \nbe carried out). For instance, in shift-left \ndevelopments, a test strategy should include \nat least the following data: the purposes (e.g., \ndefined through user stories), the objectives \n(e.g., a test suite), the scope (the SUT), and \nthe environment and methods (e.g., how, and \nwhere the test suite is run).\n5.1.3. Test Management and Dynamic Test  \n\t Processes\n[1*, c12; 4, part 2, part 3, 14*, c7s3]\nTest activities conducted at different levels (see \nSection 2, Test Levels) should be organized \n\u2014 with people, tools, policies, and measures \n\u2014 into a well-defined process integral to the \nlife cycle. Test process management includes \ndifferent subprocesses such as planning, mon-\nitoring, control, and completion, whereas the \nDynamic test process includes test design and \nimplementation, test environment set-up and \nmaintenance, test execution, and test incident \nreporting.\n5.1.4. Test Documentation\n[1*, c8s12; 14*, c7s8; 4, part 3] \nAccording to [4, part 3], documentation is \nintegral to the formalization of the test pro-\ncess. Test documents can be classified into \nthree hierarchical categories: organizational \ntest documentation, test management docu-\nmentation and dynamic test documentation. \nOrganizational test documentation includes \nthe information necessary for documenting \nthe test policy and the organizational test \nstrategies. Test management documentation \nincludes the test plan, test status report and \ntest completion report. Finally, dynamic test \ndocumentation includes the following docu-\nments: test specification (test design specifica-\ntion, test case specification and test procedure \nspecification), test data requirements, test \nenvironment requirements, test data readiness \nreport, test environment readiness report, and \ntest execution documentation (such as actual \nresults, test results, test execution log and \nincident report).\nTest documentation should be produced \nand continuously updated with the same \n", "page": 136, "type": "text", "section": "Page 136"}
{"text": "5-20   SWEBOK \u00ae GUIDE V4.0\nquality as other software engineering doc-\numentation. Test documentation should \nalso be under the control of software con-\nfiguration management. (See the Software \nConfiguration Management KA.) \n5.1.5. Test Team \n[1*, c16; 2* c23s5; 4, part 2, part 3]\nFormalizing the testing process may also \ninvolve formalizing the testing team\u2019s orga-\nnization. Considerations of cost, schedule, \nmaturity levels of the involved organizations \nand criticality of the application can guide the \ndecision. The testing team can be composed of \nmembers involved (or not) in the SUT devel-\nopment (i.e., having or not having an unbi-\nased, independent perspective) or internal \n(or external) personnel. Nowadays, shift-left \ndevelopment does not strongly distinguish \namong testing team members because the test \nsuite is defined and updated according to the \nSUT development and delivered code. \n5.1.6. Test Process Measures \n[1*, c18s3, 14*, c10; 4, part 1, part \n2, part 3] \nManagers use several measures for the \nresources spent on testing, as well as for the \nrelative fault-finding effectiveness of the var-\nious test phases, to control and improve the \ntesting process, as well as to provide informa-\ntion for managing process risks. Therefore, \nmonitor and control testing must define \nrequired data and information and state how \nto obtain them. The test measures may cover \nthe number of specified, executed, passed, \nand failed test cases, among other elements. \nThese measures can also be combined with \nspecific process metrics such as residual risk, \ncumulative defects open and closed, test case \nprogress, and defect detection percentage. \nEvaluation of test phase reports can be com-\nbined with root-cause analysis to evaluate \ntest process effectiveness in finding faults as \nearly as possible. Such an evaluation can be \nassociated with risk analysis. Moreover, the \nresources deemed worth spending on testing \nshould be commensurate with the applica-\ntion\u2019s use and criticality. Different techniques \nhave different costs and yield different confi-\ndence levels in product reliability.\n5.1.7. Test Monitoring and Control \n[4, part 1, part 2] \nMonitoring and Control comprise an important \nsub-process of the test management process as \nin [4, part 2], useful for collecting data and \ninformation required during test management \nand assessment. Usually, monitoring and con-\ntrol activities are executed in parallel with \nthe test execution, and sometimes, data col-\nlected might prompt revision of overall pro-\ncess planning. Monitoring assures that testing \nprocess activities comply with a specific test \nplan to trace the requirements satisfaction \nand mitigate the identified risks satisfactorily. \nDuring test monitoring and control, specific \ndocumentation (test reports) can regularly be \nproduced to help assess and document the \ntest activity.\n5.1.8. Test Completion \n[14*, c7s11; 4, part 3]\nA decision must be made about how much \ntesting is enough and when a test stage can \nbe completed. Therefore, the purpose of Test \nCompletion, a sub-process of the test manage-\nment process as in [4, part 2], is to ensure that \ntest requirements are satisfied and verified, \ntest reports are completed, and test results \nare communicated to relevant stakeholders. \nThoroughness measures, such as achieved code \ncoverage or functional coverage, and estimates \nof fault density or operational reliability, pro-\nvide useful support but are not sufficient in \nthemselves. The decision also involves consid-\nerations about the costs and risks incurred by \npossible remaining failures, as opposed to the \ncosts incurred by continuing to test (See Test \nSelection and Adequacy Criteria in Section \n1.2, Key Issues.) As for the other activities, in \nthis stage, specific documentation is produced \n(e.g., test completion report) and communi-\ncated to the relevant stakeholders.\n", "page": 137, "type": "text", "section": "Page 137"}
{"text": "SOFTWARE TESTING   5-21\n5.1.9. Test Reusability\n[14*, c3; 9]\nIt is necessary to add complexity and time \nfor test planning and design to achieve reus-\nability of the testing artifacts, such as the \ntest case or execution environment, which \nis desired when test development is costly, \ntime-consuming, and complex.\nTest reusability collects and classifies the \ntesting knowledge (test cases and test results) \nto make this information searchable and \nusable for creating new tests or re-executing \nan existing one. Suitable knowledge-based \nrepositories should be configured and man-\naged to test reusability so changes to soft-\nware requirements or design can be reflected \nin changes to the tests.\nCurrently, the reusability of test cases is \npivotal in feature-based or product-line devel-\nopment and regression testing. Test reus-\nability also relates to maintainability because \nreusability can reduce the cost and effort \ninvolved and improve a test\u2019s effectiveness. \n5.2. Test Sub-Processes and Activities\n[1*, c1s12; 1*, c12s9; 4, part 2]\nIn the remainder of this section, the main \ntesting activities and sub-processes are briefly \nintroduced. \n5.2.1. Test Planning Process \n[1*, c12s1, c12s8; 11; 4, part 2] \nLike all other aspects of project manage-\nment, testing activities must be planned. \nAccording to [4, part 2], key aspects of test \nplanning include identification and coor-\ndination of personnel, identification of \nthe test objective and completion criteria, \ndefinition of test facilities and equipment, \ncreation and maintenance of all test-re-\nlated documentation, and risk planning and \nmanagement for possible undesirable out-\ncomes. These activities can be organized at \nthree different levels: (1) process manage-\nment (i.e., identification of test policies, \nstrategies, processes, and procedures), (2) \norganizational management (i.e., definition \nof the test phase, test type and test objective), \nand (3) design and implementation (i.e., defi-\nnition of the test environment, the test execu-\ntion process and monitoring, the completion \nprocess, and reporting).\n5.2.2. Test Design and Implementation\n[1*, c12s1, c12s3; 11]\nGeneration of test cases is based on the \nlevel of testing to be performed and the \nchosen testing techniques. According to \nthe dynamic test process, as described in [4, \npart 2], preconditions of the test case gener-\nation are the identification of test objectives \nand the selection of the appropriate testing/\ndemonstration techniques. Test generation \nfocuses on implementing and executing test \ncases. It often relates to tooling (i.e., using \nspecific software, also called a test cases gen-\nerator). This software accepts inputs (such \nas source code, test criteria, specifications, \nor data structure definitions) and uses them \nto generate the test suites. Sometimes, a \ntest case generator can determine expected \nresults by using a specific oracle facility. This \ncontributes to the full test automation of the \noverall testing process. \n5.2.3. Test Environment Set-up and  \n\t Maintenance \n[1*, c12s6; 2* c8s1; 14* c13s2; 4, part 2; 11]\nAccording to the dynamic test process, as \ndescribed in [4, part 2], test environment \ndevelopment and setup involve identifying the \ntesting infrastructure. This includes selecting \nor developing the facilities, hardware, soft-\nware, firmware, and procedures to conduct \nthe testing activity. The testing environment \ncan be simulated, controlled, and executed \nin vitro or in vivo. Developing the test envi-\nronment also involves setting up monitoring \nand logging facilities useful for documenting \nthe testing activities and assessing the result \nobtained. The testing environment should \nbe compatible with the other software engi-\nneering tools used. \n", "page": 138, "type": "text", "section": "Page 138"}
{"text": "5-22   SWEBOK \u00ae GUIDE V4.0\n5.2.4. Controlled Experiments and Test  \n\t Execution \n[1*, c12s7, 14* c4s7, 14* c5s6; 4, part 2]\nExecution of tests should embody a basic \nprinciple of scientific controlled experimenta-\ntion \u2014 everything done during testing should \nbe performed and documented specifically \nand clearly enough that another person could \nreplicate the results. Hence, testing should \nbe performed following documented proce-\ndures using a clearly defined version of the \nSUT. Especially during acceptance testing, \ncontrolled experiments like A/B testing can \nalso be performed to statistically evaluate \nuser preferences between different versions \nof the SUT. \n5.2.5. Test Incident Reporting\n[1*, c13s4, c13s9, c13s11; 2*, c8s3; 14*, \nc7s8; 4, part 3; 12]\nAccording to the dynamic test process, as \ndescribed in [4, part 2], testing incidents \nand reporting focus on the well-defined \ntest data collection process (i.e., identifying \nwhen a test was conducted, who performed \nthe test, what software configuration was \nused, and other relevant identification infor-\nmation). This process and the collected evi-\ndence can be leveraged for accountability \npurposes. Test reporting can involve suitable \naudit systems to identify unexpected or incor-\nrect test results and record them in a problem \nreporting system. These data form the basis \nfor later debugging and fixing the problems \nobserved as failures during testing. Also, \nanomalies not classified as faults could be \ndocumented if they later become more serious \nthan first thought. Test reports are also inputs \nto the change management request process. \n(See Software Configuration Control in the \nSoftware Configuration Management KA.) \nHence, the Test Incident Reporting pro-\ncess focuses on identifying the relevant \nstakeholders\u2019 incidents that could be used to \ndetermine what aspects of software testing \nand other processes need improvement and \nhow effective previous approaches have been.\nPart of the incident reporting is also eval-\nuating test results to determine whether the \ntesting has been successful. In most cases, \n\u201csuccessful\u201d means that the software per-\nformed as expected and did not have any \nmajor unexpected outcomes. Not all unex-\npected outcomes are necessarily faults; some-\ntimes they are determined to be simply noise. \nBefore a fault can be removed, an analysis and \ndebugging effort is needed to isolate, identify, \nand describe it. When test results are particu-\nlarly important, a formal review board may be \nconvened to evaluate them.\n5.3. Staffing \n[1*, c16; 4, part 3]\nAccording to [4, part 3], staffing includes \ndefining roles, activities, and responsibilities, \nspecifying hiring needs, and defining training \nneeds. Staffing affects project risk because the \nteam\u2019s expertise might undermine the ability \nto discover faults, to address changing require-\nments, to meet deadlines, and increase/reduce \nmaintenance costs. \nThe roles, activities and responsibilities \ndefinition establishes the following roles and \nresponsibilities: the activity leader and sup-\nporting personnel, the test-related roles and \ntheir corresponding responsibilities, and the \nperson responsible for providing the test item(s). \nDepending on the development lifecycle \nadopted, typical testing roles include but are \nnot limited to scrum master/test lead, QA/\ntest analyst, test designer, test security/perfor-\nmance engineer and consultant, test environ-\nment expert, test executor and test automation \nconsultant or architect.\nHiring needs require the identification of \nspecific requirements for which additional \ntesting personnel are needed to complete the \ntesting process (as well as when that personnel \nis needed and the desired skills). Depending \non the business needs, staffing could take \ndifferent forms, from internal transfers to \nexternal hires or even consultants and/or out-\nsourced resources.\nFinally, the training needs specification \nincludes the definition of the required skill \n", "page": 139, "type": "text", "section": "Page 139"}
{"text": "SOFTWARE TESTING   5-23\nlevel. It also includes the specification of the \ntraining activities (such as classroom training, \nself-paced training, computer-based training, \nor mentoring) useful for providing the neces-\nsary skills to the selected staff.\n6.\t Software Testing in the Development \nProcesses and the Application Domains\n[2*, c8, c15; 14*, c4s8, c7]\nWhatever development process is adopted, \ntesting remains a fundamental activity. \nHowever, specific testing activities or termi-\nnologies could be used in some cases, such as \nthe adopted development life cycle and/or the \napplication domain \n6.1.  Testing Inside Software Development \nProcesses \n[2*, c8; 14*, c7] \nIn the remainder of this section, peculiarities \nof testing inside the different development \nprocesses are provided.\n6.1.1. Testing in Traditional Processes \n[1* c18; 14*, c7] \nThere are a variety of traditional processes, \nessentially based on the SUT development \nprinciples, that can be adopted within the \norganization. Sequential, V, spiral model and \niterative are just some of the processes com-\nmonly applied. (Software Life Cycles in the \nSoftware Engineering Process KA provides \na detailed description of each.) However, in \nall these processes, testing is just one per-\nceived activity; it is sometimes performed at \nthe end of the process, with a tangible risk \nof SUT development failure in case of devi-\nation of the end-user needs or assessment \nissues. During recent years, to evaluate and \ncontrol the overall quality of the SUT, initia-\ntives such as test maturity model integration \n(TMMi) and software process improvement \n(SPI) have been established. As a result, dif-\nferent existing frameworks have been updated \nor improved for the purpose, such as soft-\nware process improvement and capability \ndetermination (SPICE), capability maturity \nmodel integration (CMMI), and unified pro-\ncess (UP). \nFor instance, CMMI is one of the most \nreferenced models; it can guide key SUT \nstakeholders in gaining control of their devel-\nopment and maintenance processes. It is, in \nfact, a well-defined set of best practices in \nsoftware testing that improves SUT quality \nby increasing customer satisfaction.\nPresented in the early 2000s, the UP model \ncan be seen as a predecessor of the shift-left \nmovement. UP encourages testing early by \noffering several mechanisms to integrate \ntesting more closely with the software devel-\nopment effort, making testing a distinct disci-\npline. Furthermore, UP promotes an iterative \ndevelopment approach for continuously ver-\nifying quality. It also enables use cases and \nrisk to drive SUT development and allows \nstrategic change management. Indeed, UP \ngroups the SUT increments and SUT itera-\ntions into four phases: inception, elaboration, \nconstruction, and transition.\nNowadays, UP can be considered both \nIterative and Agile \u2014 Iterative because all \nthe core activities are repeated throughout the \nSUT development project, and Agile because \nthe defined phases of the chosen lifecycle can \nbe repeated until the SUT meets require-\nments (both functional and non-functional), \nachieves the defined objectives, and guaran-\ntees the target quality.\n6.1.2. Testing in Line with Shift-Left Movement\n[2*, c3, c8s2; 4, part 1; 10, c3, c5]\nThe shift-left testing movement promotes the \nadoption of testing in the early stages of soft-\nware development to detect and remove faults \nas early as possible to increase overall SUT \nquality and reduce the cost and risks of testing \nactivities. \nCurrently, \ndifferent \ndevelop-\nment life cycles, such as Agile, DevOps and \nTDD, belong to the shift-left movement. (See \nAgile Methods in the Software Engineering \nProcess KA.)\nIn shift-left-based development, different \ntesting aspects should be considered:\n", "page": 140, "type": "text", "section": "Page 140"}
{"text": "5-24   SWEBOK \u00ae GUIDE V4.0\nA.\t The internal code quality: Regression, \nprioritization, security, and privacy could \nbe the primary objectives of the internal \ncode quality (Section 2.2). Usually, unit \ntesting and integration testing are the \ntargeted levels (Section 2.1), whereas \nstructure-based is the main testing tech-\nnique (Section 3.2).\nB.\t Business needs: Compliance and confor-\nmance, usability, security, and privacy are \njust a subset of the possible objectives of \nthe business needs aspect (Section 2.2). \nConcerning this aspect, testing focuses \nmore on the system and acceptance test \nlevels and on end-user expectations, as \nwell as usage-based (Section 3.5) and sce-\nnario-based techniques (Section 3.1.8).\nC.\t Perceived quality: Alpha, beta, instal-\nlation, usability, security, and privacy \ncould be the primary objectives of the \ninternal perceived quality (Section 2.2). \nPerceived quality usually focuses on the \nacceptance test level and is achieved \nby applying techniques based on soft-\nware engineering\u2019s intuition and experi-\nence (Section 3.3) and usage-based and \nfault-based techniques, such as mutation \ntesting (Section 3.4).\nD.\t Quality assurance: Performance installa-\ntions, security, and privacy conformance \nand compliance are some main objectives of \nquality assurance (Section 2.2). This aspect \nmay involve all testing levels, and the selec-\ntion of the testing technique depends on \nthe objective and the level chosen.\nHere, some examples of testing inside the \ndifferent shift-left movements implementa-\ntion are provided:\n\u2022\t In Agile process development, testing \nactivities involve all stakeholders (such as \ncustomers and team personnel) and target \nthe identification of where improvements \ncould be made in future interactions. \nManaging the risk of regression defects, \nmeeting changing requirements, and \nmanaging their impact on test artifacts \nare also objectives of the Agile testing \nprocess. Typically, test automation is used \nto manage the regression risk, and explor-\natory testing may be used to manage a \nlack of detailed requirements.\n\u2022\t In TDD, the test cases mainly target \nthe software requirements specifications \nand acceptance, and they are generated \nin advance of the code being written. \nThe tests are based on the user stories \nand implemented using automated com-\nponent testing tools. Indeed, TDD is a \npractice that requires defining and main-\ntaining unit tests and can help clarify the \nuser needs and software requirements \nspecifications.\n\u2022\t In testing automated builds and contin-\nuous integration (for instance, DevOps), \nthe SUT is continuously developed, inte-\ngrated, delivered and monitored. In this \nprocess, regression testing is continuously \nperformed to timely identify and cor-\nrect development and integration issues. \nAdditionally, quick testing techniques, \nsuch as smoke testing, are commonly \nused during continuous integration to \nguarantee that the SUT is testable before \nit is released to the operational stage.\n6.2. Testing in the Application Domains\n[2*, c15; 14*, c4s8]\nUsually, an application domain is strictly con-\nnected to a certain reality. Therefore, testing \napproaches could be tailored to the needs of \nthe domain and customized to the adopted \ntechnologies.\nBelow, we provide an overview of dif-\nferent aspects and solutions for software \ntesting applied within several domain-spe-\ncific environments:\n\u2022\t Automotive domain testing: Due to the \ncomplexity of automotive systems, this \ntesting involves aspects of almost every \nsoftware component and its interaction \nwith hardware. Security testing, simula-\ntion testing, reliability/life cycle testing, \nintegrated systems testing, data acquisi-\ntion and signal analysis testing, quality \n", "page": 141, "type": "text", "section": "Page 141"}
{"text": "SOFTWARE TESTING   5-25\ntesting and inspection, and stress/strain \ntesting are just some of the various testing \nperformed in this domain. Several sup-\nporting standards are currently available \nto guide and manage automotive testing \naccording to the peculiarity, the compo-\nnent, or the quality aspect that should \nbe assessed. Autosar2 and Automotive \nSPICE3 are examples.\n\u2022\t Internet of things (IoT) domain testing: \nThis testing involves application develop-\nment, device management, system man-\nagement, heterogeneity management, \ndata management, and tools for anal-\nysis, deployment, monitoring, visualiza-\ntion and research. Additionally, security, \nprivacy, communications and user/com-\nponent interaction should be considered \nin the quality assessment. For example, \nguidelines and specific conformance test \nsuites for cybersecurity assessment of the \nIoT SUT are detailed in the European \nTelecommunications Standards Institute \n(ETSI) standards.4 \n\u2022\t Legal domain testing: One of the most \nimportant aspects in the legal domain \nis the management of highly sensitive \nusers; therefore, security, privacy and \ntrust are the most common areas of focus \nfor testing. Additionally, because of the \ncopious data collected and exchanged, \nperformance testing of the data reposi-\ntory, testing to show accurate commu-\nnication and integration testing, as well \nas consistency and compliance testing, \nshould also be done. Finally, because the \nlegal domain is characterized by specific \nnomenclature and jargon, involving legal \ndomain experts in test case generation \nis common practice to ensure a focus on \ndesired characteristics and quality.\n2\t\n https://www.autosar.org/\n3\t\n https://www.automotivespice.com/\n4\t\n https://www.etsi.org/\n5\t\n https://www.w3.org/2013/07/webmobile-ig-charter.html\n6\t\n www.astm.org.\n7\t\nhttps://www.hl7.org/\n8\t\nhttp://fhir.org/\n\u2022\t Mobile domain testing: This testing is \nusually for usability, functional, con-\nfiguration and consistency assessment. \nMobile-specific aspects such as screen \nresolution, global positioning system \n(GPS), operating systems, and device \nmanufacturers should also be consid-\nered during testing activity. Finally, the \ntype of mobile applications (native or web \napps) and their interactions need to be \ntested. For example, the W3C Web and \nMobile Interest Group5 provides facil-\nities, guidelines and ad hoc test suites \nuseful for developing and testing web-\nbased content, applications and services. \n\u2022\t Avionics domain testing6: Usually, avi-\nonics systems include several indepen-\ndent or loosely coupled components and \ncommercial off-the-shelf products. Those \nforces testing to include very general \nprocesses and approaches applicable at \nboth the system and the process levels. \nFunctional and non-functional, integra-\ntion, communication operational, stress, \nsafety, and security testing are exam-\nples of possible approaches. As in other \ndomains, supporting standards such \nas Aeronautical Radio Incorporated \n(ARINC) \nStandards \nand \nASTM \nF3153-15 can be used for reference.\n\u2022\t Healthcare domain testing: Healthcare \ndomain testing should ensure quality \nin areas such as secure and reliable data \nexchange, stable performance, privacy, \nand safety. Interoperability, usability, per-\nformance and compliance with industry \nregulations, as well as security and safety \nstandards (such as the Health Level Seven \n(HL7),7 Fast Healthcare Interoperability \nResources (FHIR),8 Digital Imaging \nand \nCommunications \nin \nMedicine \n", "page": 142, "type": "text", "section": "Page 142"}
{"text": "5-26   SWEBOK \u00ae GUIDE V4.0\n(DICOM),9 Health Insurance Portability \nand Accountability Act (HIPAA),10 and \nthe General Data Protection Regulation \n(GDPR)11) should also be considered.\n\u2022\t Embedded domain testing: Because soft-\nware and hardware are tightly coupled \nin embedded systems, testing activity \nshould assess functional and non-func-\ntional attributes of both software and \nhardware. \n\u2022\t Graphical user interface (GUI) testing: \nGUI testing involves assessing the UI \n(user interface) (i.e., the elements of the \nuser objects that we can see). Thus, GUI \ntesting targets the design pattern, images, \nalignment, spellings, and the overall look \nand feel of the UI. Testing approaches \nbased on finite-state machines, goal-\ndriven approaches, approaches based on \nabstractions and model-based approaches \ncan be considered. \n\u2022\t Gaming: Gaming applications and soft-\nware are currently a very active sector of \nsoftware production, causing increased \ndemand for new approaches and ways \nto ensure their quality and security. \nAmong the specific testing techniques, \nplaytesting is one of the most adopted. \nIn this case, real gamers repeat quality \ncontrol methods at many points of the \ngame execution or design process. GUI \ntesting, \nfunctionality \ntesting, \nsecu-\nrity testing, console testing, compliance \ntesting and performance testing can also \nbe considered.\n\u2022\t Real-time domain testing: Real-time \ntesting usually focuses on assessing \ntiming constraints and deterministic \nbehavior. Usually, unit, integration and \nsystem testing approaches can be adopted. \nCommunication, interaction and behav-\nioral testing can also be performed.\n\u2022\t Service oriented architecture (SOA) \ntesting: This testing focuses mainly \non \ncorrectly \nimplementing \nbusiness \n9\t\nhttps://www.dicomstandard.org/\n10\t https://www.hhs.gov/hipaa/.\n11\t  https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:32016R0679.\nprocesses and involves unit and integra-\ntion testing approaches. Structure-based, \nspecification-based and security testing \ncan be applied. The testing activity might \nvary according to the environment, orga-\nnization and set of requirements that \nshould be satisfied.\n\u2022\t Finance domain testing: This testing \ncovers a wide range of aspects, from man-\naging financial requirements to assessing \nfinancial applications and software pro-\ngrams. As in other domains, domain-spe-\ncific knowledge (such as that held by, for \nexample, banks, credit unions, insurance \ncompanies, credit card companies, con-\nsumer finance businesses, investment funds \nand stock brokerages) could be necessary \nto apply the testing process effectively and \nefficiently. Customer satisfaction, usability, \nsecurity, privacy, third-party component \nand apps integrations, real-time issues, \nand performance are some of the most \nimportant challenges in this domain.\n7.\t Testing of and Testing Through \nEmerging Technologies \nIn recent decades, software development was \ndriven by emerging trends such as the wide-\nspread diffusion of mobile technology, cloud \ninfrastructures adoption, big data analysis \nand the software as a service paradigm, which \nhighlighted new constraints and challenges \nfor testing.\n7.1. Testing of Emerging Technologies\n\u2022\t Testing artificial intelligence (AI), ML/\ndeep learning (DL) [13]: AI, ML and \nDL are successfully being applied in \npractice. Sooner or later, most business \napplications will have some form of AI, \nML or DL. Because of their peculiarities, \ntesting such applications is challenging \nand might be very expensive. AI, ML or \n", "page": 143, "type": "text", "section": "Page 143"}
{"text": "SOFTWARE TESTING   5-27\nDL testing refers to any activity designed \nto reveal AI, ML or DL bugs. \no\t Three main aspects should be consid-\nered in defining bugs and testing in \nthis scenario: the required conditions \n(correctness, robustness, security, and \nprivacy); the AI, ML or DL items \n(e.g., a bug might exist in the data, \nthe learning program, or the frame-\nwork used); and the involved testing \nactivities (test case generation, test \noracle identification and definition, \nand test case adequacy criteria).\no\t In all these applications, a prototype \nmodel is first generated based on his-\ntorical data. Then, offline testing, \nsuch as cross-validation, is con-\nducted to verify that the generated \nmodel satisfies the required condi-\ntions. Usually, after deployment, the \nmodel is used for prediction purposes \nby generating new data. Finally, the \ngenerated data is analyzed through \nonline testing to evaluate how the \nmodel interacts with user behaviors.\n\u2022\t Testing blockchain [15]: The commonly \nused testing techniques for validating \nblockchains and related applications such \nas smart contracts are stress testing, pen-\netration testing and property testing. \nHowever, depending on the specific situa-\ntion, different aspects should be considered \nduring the testing of a blockchain-based \nSUT, such as the following:\n\u2022\t Platform type: The level of validation \ndepends on the type of platform used for \nimplementation \u2014 public or private. The \nlatter requires a much greater testing effort.\n\u2022\t Connection with other applications: \nIntegration testing should be performed \nto check consistency when the blockchain \nworks with various applications.\n\u2022\t Performance: Performance testing should \nbe conducted when performance issues \nare a concern. Specific strategies to handle \nmany transactions should be conceived \nto guarantee a satisfactory performance \nlevel. Qualitative and quantitative met-\nrics, such as average transaction valida-\ntion latency and security, should also be \nconsidered.\n\u2022\t Testing the cloud [1*, c10s10, 2*, c18]: \nTesting the cloud validates the quality of \napplications and infrastructures deployed \nin the cloud by considering both func-\ntional and non-functional properties. The \nfocus is to identify problems posed by \nsystems residing in the cloud. Therefore, \ntesting activities use techniques to val-\nidate \ncloud-based \nservices\u2019 \nperfor-\nmance, scalability, elasticity and security. \nMoreover, testing should also focus on \ncompatibility and interoperability among \nheterogeneous cloud resources when dif-\nferent deployment models are used (e.g., \nprivate, public or hybrid).\n\u2022\t Testing concurrent and distributed appli-\ncations [1*, c10s10, 2*, c17]: One main \naspect of testing dynamic, complex, dis-\ntributed or concurrent applications is \ndealing with multiple operating systems \nand updates, multiple browser platforms \nand versions, different types of hardware, \nand many users. For such testing, it\u2019s dif-\nficult to use testing approaches based on \nthe classical hierarchy between compo-\nnents or systems; instead, solutions based \non input/output, dependency threads, \nor dynamic relations often work better. \nAdditionally, the possibility of continuous \nintegration and deployment of the dif-\nferent components forces the testing pro-\ncess to include approaches for managing \ncontinuous test operation, injection, mon-\nitoring and reporting according to the \ntime, bandwidth usage, throughput, and \nadaptability constraints. Finally, there is \nstill the need for solutions that allow the \nreusability of testing knowledge, archi-\ntectures, and code to make the testing \nactivity more effective and less expensive.\n7.2. Testing Through Emerging Technologies\n\u2022\t Testing through ML [13]: AI, ML or DL \ntechniques are successfully used to reduce \n", "page": 144, "type": "text", "section": "Page 144"}
{"text": "5-28   SWEBOK \u00ae GUIDE V4.0\nthe effort involved in several activities in \nsoftware engineering (such as behavior \nextraction, testing or bug fixing). These \ntechniques aid both researchers and \npractitioners in adopting and identi-\nfying appropriate methods for their \ndesired applications. There is a growing \ninterest in adopting ML techniques in \nsoftware testing because most software \ntesting issues are being formulated as \nML learning problems. Indeed, AI, ML \nor DL is intensively used in almost all \nsoftware, such as test case design, the \noracle problem, test case evaluation, test \ncase prioritization and refinement, and \nmutation testing automation. Indeed, \nthey can reduce maintenance efforts \nand improve the overall SUT quality \nbecause of their ability to analyze large \namounts of data for classifying, triaging \nand prioritizing bugs more efficiently. \nFrom a DevOps perspective, AI, ML \nand DL solutions can be used in SUT \nautomation authoring and execution \nphases of test cases, as well as in the \npost-execution test analysis that identi-\nfies trends, patterns and impact on SUT \ntesting activity.\n\u2022\t Testing \nthrough \nblockchain \n[15]: \nTesting becomes complicated when dif-\nferent teams, domain experts and users \nneed to work together in collaborative, \nlarge-scale systems and complex soft-\nware systems to achieve a common goal. \nThis is mainly because of the time con-\nstraint, data sharing policies, acceptance \ncriteria and trusted coordination among \nthe teams involved in the testing process. \nBlockchain technologies can be exploited \nto improve software testing efficiency \nand avoid using centralized authority to \nmanage different testing activities. This \ncan help ensure distributed data man-\nagement, tamper resistance, auditability, \nand automatic requirement compli-\nance to improve the quality of software \ntesting and development. Blockchain-\nbased approaches for trusted test case \nrepository management and to support \ntest-based software and security testing \nare also considered.\n\u2022\t Testing through the cloud [17]: Testing \nthrough the cloud refers to SUT testing \nperformed by leveraging scalable cloud \ntechnologies. Usually, the cloud is used \nfor testing purposes wherever large-scale \nsimulations and elastic resources are nec-\nessary. Indeed, this can affect cost reduc-\ntion, development, and maintenance of \nthe testing infrastructure (scaffolding), \nand online validation of systems, such as \nML-based SUT. A particular situation is \nthe testing of the cloud through the cloud \nitself. This is an example of the inter-\nsection between testing of and testing \nthrough emerging technologies. The \napplications and infrastructures deployed \nin the cloud can be tested, exploiting the \ncloud\u2019s bandwidth.\n\u2022\t Testing through simulation [1*, c3s9]: \nSimulation is an important technology \nfor testing activity because it represents \na valid means for evaluating SUT execu-\ntion under critical situations or disasters \nor assessing specific behaviors or recov-\nering activities. The complexity of the \ntesting approach might vary according to \nthe complexity of the simulation system \nadopted and might involve closed-loop \ntesting; assessing the devices, communi-\ncations, and interface; and use of real-time \ndata (e.g., voltage, current and breaker \nstatus). Simulation testing can be applied \nto each development level and might \ninvolve mathematical, formal represen-\ntation of the real system, environment, \nnetwork conditions and control devices. \nSimulation testing is currently adopted in \nmany application domains. Especially in \nthe automotive and embedded domain, \namong the different proposals, one of the \nemerging solutions for simulation testing \nis hardware-in-the-loop (HIL) simula-\ntion testing. In this case, real signals sent \nto the SUT to simulate reality and to test \nand design the iteration are continuously \nperformed while the real-world system is \nbeing used. \n", "page": 145, "type": "text", "section": "Page 145"}
{"text": "SOFTWARE TESTING   5-29\n\u2022\t Testing through crowdsourcing [16]: \nCrowdsourced testing (also known as \ncrowdtesting) is an emerging approach for \ninvolving users and experts in the testing \nactivity. Thus, crowdsourcing uses repre-\nsent the dispersed, temporary workforce \nof multiple individual testers. Testing \nthrough crowdsourcing is mainly used \nfor testing mobile applications because it \nensures technology diversity and custom-\ner-centric validation. However, crowd-\ntesting is not a substitute for in-house \nSUT validation. It represents a valid \nmeans of detecting failures and issues \nbecause it involves many individuals (tes-\nters) in different locations, who are using \ndifferent technologies in different condi-\ntions and who have different skills and \nknowledge.\n8.\t Software Testing Tools \n[1*, c12s11, 14*, c7]\nSeveral testing tools focus on the SUT pecu-\nliarities and needs. This section describes the \nmain issues and challenges concerning testing \ntools and provides an overview of their cur-\nrently identified categories.\n8.1. Testing Tool Support and Selection\n[1*, c12s11, 14*, c7]\nTesting involves many labor-intensive tasks \nsince it involves running numerous pro-\ngram executions and handling a considerable \namount of information. Appropriate tools \ncan alleviate the burden of tedious clerical \noperations and make them less error-prone. \nSophisticated tools can support test design \nand generation, making them more effective.\nGuidance to managers and testers on \nselecting testing tools that will be most \nuseful to their organization and processes is \nan important topic, as tool selection greatly \naffects testing efficiency and effectiveness. \nTool selection depends on diverse factors, \nsuch as development choices, evaluation \nobjectives and execution facilities. In general, \nthere might not be a unique tool to satisfy spe-\ncific needs, so a suite of selected tools could be \nappropriate.\n8.2. Categories of Tools \n[1*, c1, c3, c4, c7, c8, c9, c12]\nSeveral classifications of testing tools mainly \ndescribe their functionalities, such as the \nfollowing:\n\u2022\t Test harnesses (drivers, stubs) [1*, c3s9] \nprovide a controlled environment in \nwhich tests can be launched and the test \noutputs can be logged. Drivers and stubs \nare provided to execute parts of a SUT to \nsimulate calling and called modules.\n\u2022\t Test generators [1*, c12s11] assist in gen-\nerating test cases. That generation can be \nrandom, path-based, model-based or a \nmix thereof.\n\u2022\t Capture/replay tools [1*, c12s11] automat-\nically re-execute or replay previously exe-\ncuted tests that have recorded inputs and \noutputs (e.g., screens).\n\u2022\t Oracle/file comparators/assertion checking \ntools [1*, c9s7] assist in deciding whether a \ntest outcome is successful.\n\u2022\t Coverage analyzers and instrumenters [1*, \nc4] work together. Coverage analyzers \nassess which and how many entities of \nthe program flow graph have been exer-\ncised among all those required by the \nselected test coverage criterion. The anal-\nysis can be done through SUT instru-\nmenters that insert recording probes into \nthe code. \n\u2022\t Tracers [1*, c1s7] record the history of a \nprogram\u2019s execution paths.\n\u2022\t Regression testing tools [1*, c12s16] support \nthe re-execution of a test suite after a sec-\ntion of software has been modified. They \ncan also help select a test subset according \nto the change made.\n\u2022\t Reliability evaluation tools [1*, c8] support \ntest results analysis and graphical visual-\nization to assess reliability-related mea-\nsures according to selected models. \n\u2022\t Injection-based tools [1*, c3, c7s7] focus on \n", "page": 146, "type": "text", "section": "Page 146"}
{"text": "5-30   SWEBOK \u00ae GUIDE V4.0\nintroducing or reproducing specific prob-\nlems to confirm that the SUT behaves \nsuitably under the corresponding con-\ndition. That can involve managing some \ninput or triggering of events. Usually, \ntwo categories of injection-based tools \nare considered: attack injection and fault \ninjection.\n\u2022\t Simulation-based tools [1*, c3s9] verify and \nvalidate selected properties. Usually, they \nexploit specific models to enable the auto-\nmated execution of scenarios to assess \nwhether the SUT operates as expected or \nto predict how the SUT would respond to \ndefined inputs. Typical simulation-based \ntools are classified into tools for verifi-\ncation, tools for collaboration, tools for \noptimization, tools for testing automated \nsystems and tools for evaluating software \nconcepts. \n\u2022\t Security testing tools [1*, c8s3, c12s11] \nfocus on specific security vulnerabilities. \nAmong these are tools for attack injec-\ntion, penetration testing and fuzz testing.\n\u2022\t Test management tools [1*, c12s11] include \nall the supporting tools that assure effi-\ncient and effective test management and \ndata collection.\n\u2022\t Cross-browser testing tools [1*, c8s3] enable \nthe tester to quickly build and run user \ninterface test cases across desktop, mobile \nand web applications to check whether \nthe SUT looks and works as expected on \nevery device and browser.\n\u2022\t Load testing tools [1*, c3] collect valuable \ndata and evidence for SUT performance \nevaluations.\n\u2022\t Defect tracking tools [1*, c3] help keep \ntrack of detected faults during the SUT \ndevelopment projects. These tools behave \nas tracking systems and usually allow end \nusers to enter fault reports directly.\n\u2022\t Mobile testing tools [1*, c8s3] support the \nimplementation and testing of mobile \napps by allowing several repeated UI tests \nover the application platform, develop-\nment on real mobile devices or emulators, \ntesting of the mobile apps on real-time \nimplementations and collection of data \nfor specific QA measures.\n\u2022\t API testing tools [1*, c7s2] check whether \nthe applications meet functionality, per-\nformance, reliability, and security expec-\ntations throughout the automation of \nspecific API tests.\n\u2022\t CSS validator tools [1*, c7s2] validate cas-\ncading style sheets (CSS) code and dis-\ncover errors, issues and warnings that can \nbe fixed. The CSS Validation Service, \nprovided by W3C for free, is one of the \nmost used validators in practice that helps \nboth web designers and web developers \ncheck CSS.\n\u2022\t Web application testing tools [1*, c8s3], also \nreferred to as web testing tools, support \nvalidating the functionality and the per-\nformance of web-based SUTs before their \ndeployment into production. These tools \nprovide relevant insight and data for dif-\nferent stakeholders, such as developers, \nservers, and infrastructure administra-\ntors. From a DevOps perspective, these \ntools address issues, or bugs before SUTs \nare available to end users.\n", "page": 147, "type": "text", "section": "Page 147"}
{"text": "SOFTWARE TESTING   5-31\nMATRIX OF TOPICS VS. REFERENCE MATERIAL\n1*\n2*\n14*\n19*\n1. Software Testing Fundamentals\nc1, c2\nc8\nc7\n1.1. Faults vs. Failures\nc1s5\nc1\nc1s3\n1.2. Key Issues\n1.2.1. Test Case Creation\nc12s1, c12s3\nc8\n1.2.2. Test Selection and Adequacy Criteria\nc1s14, \nc6s6, c12s7\nc8\n1.2.3. Prioritization/Minimization\n1.2.4. Purpose of Testing\nc13s11, c11s4\nc8\n1.2.5. Assessment and Certification\nc7, c25\n1.2.6. Testing for Quality \nImprovement/Assurance\nc16s2\n1.2.7. The Oracle Problem\nc1s9, c9s7\n1.2.8. Theoretical and Practical Limitations\nc2s7\n1.2.9. The Problem of Infeasible Paths\nc4s7\n1.2.10. Testability\nc17s2\n1.2.11. Test Execution and Automation\n1.2.12. Scalability\nc8s7\n1.2.13. Test Effectiveness\nc1s1\nc8s1\n1.2.14. Controllability, Replication and \nGeneralization\nc12s12\n1.2.15. Offline vs. Online Testing\n1.3. Relationship of Testing to Other Activities\n2. Test Levels\nc1s13\nc8s1\n2.1. The Target of the Test\nc1s13\nc8s1\n2.1.1. Unit Testing\nc3\nc8\n2.1.2. Integration Testing \nc7\nc8\n2.1.3. System Testing\nc8\nc8\n2.1.4. Acceptance Testing\nc1s7\nc8s4\n2.2. Objectives of Testing\nc1s7\n2.2.1. Conformance Testing\nc10s4\n2.2.2. Compliance Testing\nc12s3\n2.2.3. Installation Testing\nc12s2\n2.2.4. Alpha and Beta Testing\nc13s7, c16s6\nc8s4\n2.2.5. Regression Testing\nc8s11, c13s3\n2.2.6. Prioritization Testing\nc12s7\n2.2.7. Non-functional testing\nc8s7, c8s8, \nc14s2, \nc15, c17s2\nc8, c 11, c17\n", "page": 148, "type": "text", "section": "Page 148"}
{"text": "5-32   SWEBOK \u00ae GUIDE V4.0\n2.2.8. Security Testing\nc13\n2.2.9. Privacy Testing\nc13, c14\n2.2.10. Interface and API Testing\nc8s1\nc7s12\n2.2.11. Configuration Testing\nc8s5\n2.2.12. Usability and Human-Computer \nInteraction Testing\nc8s4\nc6\n3. Test Techniques\nc1s15\n3.1. Specification-Based Techniques\nc6s2\n3.1.1. Equivalence Partitioning\nc9s4\n3.1.2. Boundary Value Analysis\nc9s5\n3.1.3. Syntax Testing\nc10s11\nc5\n3.1.4. Combinatorial Test Techniques\nc9s3\n3.1.5. Decision Table\nc9s6, c13s6 \n3.1.6. Cause-Effect Graphing\nc1s6\n3.1.7. State Transition Testing\nc10\n3.1.8. Scenario Testing\nc8s3.2, c19s3.1\n3.1.9. Random Testing\nc9s7\n3.1.10. Evidence-Based\n3.1.11. Forcing Exception\n3.2. Structure-Based Test Techniques\n3.2.1. Control Flow Testing\nc4\n3.2.2. Data Flow Testing\nc5\n3.2.3. Reference Models for Structure-Based \nTest Techniques\nc4\n3.3. Experience-Based Techniques\n3.3.1. Error Guessing\nc9s8\n3.3.2. Exploratory Testing\n3.3.3. Further Experience-Based Techniques\n3.4. Fault-Based and Mutation Techniques\nc1s14, c3s5\n3.5. Usage-Based Techniques\nc15s5\n3.5.1. Operational Profile \nc15s5\nc11\n3.5.2. User Observation Heuristics\nc5, c7\n3.6. Techniques Based on the Nature of the \nApplication\nc16, c17, \nc18, c20, c21\nc4s8\n3.7. Selecting and Combining Techniques\nc7s12\n3.7.1. Combining Functional and Structural\nc9\n3.7.2. Deterministic vs. Random\nc9s6\n3.8. Techniques Based on Derived Knowledge\nc19, c20\nc7\n4. Test-Related Measures\nc24s5\nc10\n4.1. Evaluation of the SUT\nc24s5\n", "page": 149, "type": "text", "section": "Page 149"}
{"text": "SOFTWARE TESTING   5-33\n4.1.1. SUT Measurements That Aid in Planning \nand Designing Tests\nc10\n4.1.2. Fault Types, Classification and Statistics\nc13s4, \nc13s5, c13s6\n4.1.3. Fault Density\nc13s4\nc10s1\n4.1.4. Life Test, Reliability Evaluation\nc15\nc11\nc1s3\n4.1.5. Reliability Growth Models\nc15\nc11s5\n4.2. Evaluation of the Tests Performed\n4.2.1. Fault Injection\nc2s5\n4.2.2. Mutation Score\nc3s5\n4.2.3. Comparison and Relative Effectiveness of \nDifferent Techniques\nc1s7\n5. Test Process\nc8\n5.1. Practical Considerations\n5.1.1. Attitudes/Egoless Programming\nc16\nc3\n5.1.2. Test Guides and Organizational Process\nc12s1\nc8\nc7s3\n5.1.3. Test Management and Dynamic \nTest Processes\nc12\nc7s3\n5.1.4. Test Documentation\nc8s12\nc7s8\n5.1.5. Test Team\nc16\nc23s5\n5.1.6. Test Process Measures\nc18s3\nc10\n5.1.7. Test Monitoring and Control\n5.1.8. Test Completion\nc7s11\n5.1.9. Test Reusability\nc3\n5.2. Test Sub-Processes and Activities\nc12s9, c1s12\n5.2.1. Test Planning Process\nc12s1, c12s8\n5.2.2. Test Design and Implementation\nc12s1, c12s3\n5.2.3. Test Environment Set-up  \nand Maintenance\nc12s6\nc8s1\nc13s2\n5.2.4. Controlled Experiments and \nTest Execution\nc12s7\nc4s7,  \nc5s6\n5.2.5. Test Incident Reporting\nc13s4, \nc13s9, c13s11\nc8s3\nc7s8\n5.3. Staffing\nc16\n6. Software Testing in the Development \nProcesses and the Application Domains\nc8, c15\nc4s8, \nc7\n6.1. Testing Inside Software \nDevelopment Processes\nc8\nc7\n6.1.1. Testing in Traditional Processes\nc18\nc7\n6.1.2. Testing in Line with Shift-\nLeft  Movement\nc3, c8s2\n", "page": 150, "type": "text", "section": "Page 150"}
{"text": "5-34   SWEBOK \u00ae GUIDE V4.0\n6.2. Testing in the Application Domains\nc15\nc4s8\n7. Testing of and Testing Through Emerging \nTechnologies\n7.1. Testing of Emerging Technologies\nc10s10\nc17, c18\n7.2. Testing Through Emerging Technologies\nc3s9\n8. Software Testing Tools\nc12s11\nc7\n8.1. Testing Tool Support and Selection\nc12s11\nc7\n8.2. Categories of Tools\nc1, c3, c4, c7, \nc8, c9, c12\nREFERENCES\n[1*]\tS. Naik and P. Tripathy, Software \nTesting and Quality Assurance: Theory and \nPractice, ed: Wiley, 2008, p. 648.\n[2*]\tI. Sommerville, Software Engineering, \n10th ed., Addison-Wesley, 2016. \n[3]\t E.W. Dijkstra, Notes on Structured \nProgramming, Technological University, \nEindhoven, 1970.\n[4]\t ISO/IEC/IEEE 29119 \u2014 System \nand software engineering \u2014 Software \ntesting, ed. 2021.\n[5]\t ISO/IEC/IEEE, \u201cISO/IEC/IEEE \n24765:2017 Systems and Software \nEngineering \u2014 Vocabulary,\u201d \n2nd ed. 2017.\n[6]\t M. Papadakis, M. Kintis, J. Zhang, \nY. Jia, Y. Le Traon, and M. Harman, \nChapter Six \u2014 Mutation Testing \nAdvances: An Analysis and Survey, \nAdv. Comput. 112, 2019: 275-378. \n[7]\t M. Utting, B. Legeard, F. Bouquet, E. \nFourneret, F. Peureux, and A. Vernotte, \nRecent advances in model-based testing, \nAdvances in Computers, 101, 2016, \npp. 53-120. \n[8]\t IEEE Std 1012-2016, IEEE Standard \nfor System, Software, and Hardware \nVerification, and Validation, ed. 2016.\n[9]\t ISO/IEC 25010:2011, Systems and \nsoftware engineering \u2014 Systems \nand Software Quality Requirements \nand Evaluation (SQuaRE) \u2014 \nSystem and Software Quality \nModels, ed. 2011.\n[10]\tISO/IEC/IEEE 32675:2022 \nInformation technology \u2014 DevOps \u2014 \nBuilding reliable and secure systems \nincluding application build, package and \ndeployment.\n[11]\tSoftware Engineering Competency \nModel (SWECOM), v1.0, 2014.\n[12]\tISO/IEC 20246:2017, \u201cSoftware and \nsystems engineering \u2014 Work product \nreviews\u201d, ed, 2017, 42p\n[13]\tV. Riccio, G. Jahangirova, A. Stocco, \net al., Testing machine learning \nbased systems: A systematic mapping, \nEmpir Software Eng, 25, 2020, pp. \n5193-5254.\n[14*]\tC.Y. Laporte, and A. April, Software \nQuality Assurance, IEEE Computer \nSociety Press, 1st ed., 2018.\n[15]\tS. Demi, R. Colomo-Palacios, and \nM. S\u00e1nchez-Gord\u00f3n, Software \nEngineering Applications Enabled by \n", "page": 151, "type": "text", "section": "Page 151"}
{"text": "SOFTWARE TESTING   5-35\nBlockchain Technology: A Systematic \nMapping Study, Applied Sciences, 11(7), \n2021, pp. 2960.\n[16]\tK. Mao, L. Capra, M. Harman, and \nY. Jia. A survey of the use of crowd-\nsourcing in software engineering, \nJournal of Systems and Software, 126, \n2017, pp. 57-84.\n[17]\tA. Bertolino, G.D. Angelis, M. \nGallego, B. Garc\u00eda, F. Gort\u00e1zar, F. \nLonetti, and E. Marchetti, A system-\natic review on cloud testing, ACM \nComputing Surveys (CSUR), 52(5), \n2019, pp. 1-42.\n[18]\tR. Achary and P. Raj, Cloud Reliability \nEngineering: Technologies and Tools, CRC \nPress, 2021.\n[19*]\tJ. Nielsen, Usability Engineering, 1st \ned., Boston: Morgan Kaufmann, 1993.\n", "page": 152, "type": "text", "section": "Page 152"}
{"text": "6-1 \nCHAPTER 06\nSoftware Engineering \nOperations\nACRONYMS\nAPI\nApplication \nProgramming Interface\nATDD\nAcceptance Test Driven \nDevelopment\nCD\nContinuous Delivery\nCI\nContinuous Integration\nCPU\nCentral Processing Unit\nCONOPS\nConcepts of Operations\nDBMS\nDatabase Management System\nIaC\nInfrastructure as-Code\nIaaS\nInfrastructure as a Service\nIT\nInformation technology\nITIL\nIT Infrastructure Library\nKA\nKnowledge Area\nKPI\nKey Performance indicator\nMR\nModification request\nMVP\nMinimum Viable Product \nPaaS\nPlatform as a Service\nPR\nProblem Report\nQA\nQuality Assurance\nSaaS\nSoftware as a Service\nSLAs\nService-Level Agreements\nSRE\nSite Reliability Engineering\nTDD\nTest Driven Development\nINTRODUCTION\nSoftware engineering operations refers to the \nset of activities and tasks necessary to deploy, \noperate and support a software application \nor system while preserving its integrity and \nstability. These activities include the deploy-\nment and configuration of the software in the \ntargeted operational environments and the \nmonitoring and management of the applica-\ntion while it is in use (until it is retired). Once \nthe application is operational, software engi-\nneering operations must manage any defects \nthat are uncovered, any changes made to \nthe system software environment and hard-\nware equipment over time, and any new user \nrequirements that surface. \nSoftware engineering operations is an inte-\ngral part of system and software life cycle \nprocesses [3]. The Software Engineering \nOperations Knowledge Area (KA) is related \nto all other aspects of software engineering. \nTherefore, this KA description is linked to \nall other software engineering KAs of the \nSWEBOK Guide, particularly the Software \nConstruction KA, which discusses preparing \nthe software for deployment, including inte-\ngrating, building, packaging and testing. \nSpecialized software and information tech-\nnology (IT) operations engineers have tradi-\ntionally provided and managed IT operations \nservices. Best practices in software engi-\nneering operations were initially published \nby the IT infrastructure library (ITIL) and \nwere quickly accepted by the industry. These \npractices were summarized and published in \nthe Institute of Electrical and Electronics \nEngineers 20000 standard [1]. \nHistorically, operations and computing cen-\nters were often located in organizational silos \nseparate from software development activities. \nProgressive organizations now co-locate soft-\nware development, software maintenance and \nsome software engineering operations activ-\nities (often provided as a service and often \ncoined DevOps). Benefits of this approach \nare the elimination of the organizational silos \nthat separated these software activities and the \n", "page": 153, "type": "text", "section": "Page 153"}
{"text": "6-2   SWEBOK \u00ae GUIDE V4.0\nsharing of common processes and tools. The \nrising popularity and growing acceptance of \nDevOps practices [2*] and related standards \n[4], including an ever-evolving set of tools, \nreflect this trend. DevOps aims at automating \nand continuously evolving software engi-\nneering activities to ensure high-quality soft-\nware and to satisfy users who demand quicker \nturnaround from software engineers. \nIn this context, the role of software engi-\nneers involved in software engineering oper-\nations has significantly evolved over the \npast decade with the emergence of practices \nlike infrastructure as code (IaC), Platform-\nas-Code (PaC), Agile infrastructure, soft-\nware-defined \narchitectures/systems, \nand \nthe availability of infrastructure as a ser-\nvice (IaaS) and platform as a service (PaaS) \nsolutions. Tasks traditionally performed by \nIT infrastructure engineers are increasingly \nautomated and made available as a service, \nenabling application developers to perform \nsoftware engineering operations tasks inde-\npendently as part of their daily project activ-\nities. For example, application developers in \nmany organizations can now directly use IaaS \nand PaaS to deploy applications in produc-\ntion environments and to monitor different \naspects of those applications without directly \ninvolving operations engineers.\nHaving end-to-end resources and desired \nstate configuration managed like code, using \npractices such as IaC and PaC, provides value \nin the form of 1) improved repeatability, 2) \nconsistency/standardization, 3) known secu-\nrity policies , 4) self-documentation (transpar-\nency), 5) single source of truth, 6) configuration \ncontrol, and 7) scalability. From an engi-\nneering perspective, the important point is \nthat nearly anything that impacts a software \nproduct directly or indirectly should be con-\nsidered for representation as code.\nTo perform software engineering operations \ntasks, some organizations use the the concept \nof Platform Engineering and Site Reliability \nEngineering (SRE) [6] to increase produc-\ntivity and software quality. The role of platform \nengineering is to build and manage self-service \nplatform capabilities that can be used by soft-\nware engineers to develop, deploy, and operate \nsoftware applications. On the other hand, \nthe role of SRE is to monitor, automate, and \nimprove software operations with respect to \nnon-functional aspects, including availability, \nperformance, latency, and security. SRE is also \nresponsible for change management, emer-\ngency response, capacity planning, and overall \nefficiency of software systems.\nAlthough many organizations still use \nconventional IT operations management \nSoftware Engineering\nOperations\nSoftware\nEngineering\nOperations\nFundamentals\nSoftware\nEngineering\nOperations\nPlanning\nSoftware\nEngineering\nOperations\nDelivery\nSoftware\nEngineering\nOperations\nControl\nSoftware\nEngineering\nOperations\nTools\nDefnition of\nSoftware Engineering\nOperations\nSoftware Engineering\nOperations Processes\nSoftware Installation\nScripting and\nAutomating\nEfective Testing and \nTroubleshooting\nPerformance, Reliability \nand Load Balancing\nOperations Plan and\nSupplier Management\nDevelopment \nand Operational \nEnvironment\nSoftware Availability, \nContinuity and \nService Levels\nSoftware Capacity\nManagement\nSoftware and Data \nSafety, Security, \nIntegrity, Protection \nand Controls\nDeployment/Release\nEngineering\nRollback and\nData Migration\nChange Management\nProblem\nManagement\nIncident \nManagement \nMonitor, Measure \nTrack and Review\nOperations \nSupport\nOperations Service \nReporting\nIncident and \nProblem Prevention\nOperational Risk \nManagement\nAutomated \nSoftware\nEngineering \nOperations\nSoftware Engineering\nOperations for\nVery Small Entities\nContainers \nand Incident\nVisualization\nDeployment\nAutomated Tests\nMonitoring and \nTelemetry\nPractical\nConsiderations\nFigure 6.1. Breakdown of Topics for the Software Engineering Operations KA.\n", "page": 154, "type": "text", "section": "Page 154"}
{"text": "SOFTWARE ENGINEERING OPERATIONS   6-3\nprocesses, this KA focuses mainly on the role \nof software engineers in operations in the \nemerging contexts of DevOps, IaC, PaC, and \nAgile infrastructure practices. \nIn this context, we identify two main soft-\nware engineering roles related to operations: \nOperations engineer, who is responsible for \ndeveloping operations services made available \nas a service and accessible through an appli-\ncation programming interface (API), and \nsoftware engineer, who can use the resulting \noperations services (available as a service) to \nindependently deploy and manage applica-\ntions without directly involving IT operations \nspecialists. \nBREAKDOWN OF TOPICS FOR \nSOFTWARE ENGINEERING \nOPERATIONS \nThe breakdown of topics for the Software \nEngineering Operations KA is shown in \nFigure 6.1.\n1.\t Software Engineering Operations \nFundamentals\nThis first section introduces the concepts and \nterminology that form an underlying basis for \nunderstanding the role and scope of software \nengineering operations.\n1.1.\t Definition of Software Engineering \nOperations\b\n[1, c3s3.3][3, c6s6.4.12]\nIn this Guide, the term software engineering \noperations refers to the knowledge, skills, pro-\ncesses and tools used by software engineers or \ntheir organization to ensure that a software \nproduct, including IT infrastructure, system \nsoftware, and application software, operates \nwell during development, maintenance and in \nreal conditions of operations. \nIn ISO/IEC/IEEE 12207 [3], an operator \nis defined as an \u201cindividual or organization \nthat performs the operations of a system.\u201d The \nSWEBOK Guide modifies that definition for \nthe term operations engineer, which refers to \na software engineer who executes software \nengineering operations processes. In this role, \nan operations engineer works closely with soft-\nware engineers to develop and offer operations \nservices such as the following: \n\u2022\t Provisioning, deploying and config-\nuring, and supporting containers and vir-\ntual servers,\n\u2022\t Designing and offering on-demand ser-\nvices (e.g., environment on demand, ver-\nsioning, continuous integration (CI) and \ntesting, deployment, and surveillance) for \nuse by software engineering,\n\u2022\t Monitoring and troubleshooting system \nand application software incidents by \nrunning diagnostics, documenting prob-\nlems and resolutions, prioritizing prob-\nlems, and assessing impact of issues,\n\u2022\t Performing, automating and imple-\nmenting \nappropriate \nprocesses \nfor \nsecurity, data protection and failover \nprocedures,\n\u2022\t Overseeing \ncapacity, \nstorage \nplan-\nning and database management system \n(DBMS) performance,\n\u2022\t Providing documentation and technical \nspecifications to IT staff for planning and \nimplementing new or upgraded IT infra-\nstructure and system software.\nISO/IEC/IEEE 20000-1 describes the \nneed to develop and enhance the profes-\nsional competencies of operations engineers. \nTo achieve this goal, software organizations \nshould address the following:\n\u2022\t Staff recruitment: To validate job appli-\ncants\u2019 \nqualifications/competencies, \nincluding their professional certifications, \nand to identify their strengths, weak-\nnesses and potential capabilities against \nthe operations engineer job description, \ncore technologies and computer languages \nmastered and overall experience,\n\u2022\t Resource planning: To staff new or \nexpanded engineering operations services, \nplan the use of new technology, plan the \nassignment of service management staff\n \n", "page": 155, "type": "text", "section": "Page 155"}
{"text": "6-4   SWEBOK \u00ae GUIDE V4.0\nto development project teams, develop \nsuccession planning and other staffing \ngaps created by staff turnover,\n\u2022\t Resource training and development: \nTo identify training and development \nrequirements and create a training and \ndevelopment plan that meets them; also, \nto provide timely, effective delivery of \noperations services. Operations engineers \nshould be trained in the relevant aspects \nof service management (e.g., via training \ncourses, \nself-study, \nmentoring \nand \non-the-job training), and their teamwork \nand leadership skills should be developed. \nA chronological training record should \nbe maintained for each individual, with \ndescriptions of the training provided.\n1.2.\t Software Engineering Operations Processes \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n\b\n[2*, s1][3, c6s6.4.12]\nISO/IEC/IEEE 20000-1 is the reference stan-\ndard that presents an overview of operations pro-\ncesses. It specifies requirements for the design, \ntransition, delivery and improvement of opera-\ntions services. The ISO/IEC/IEEE 20000-1 \ndescribes five main operations process groups: \nservice delivery processes, release processes, \ncontrol processes, resolution processes and rela-\ntionship processes. These operations processes \nare further categorized as technical processes \nin ISO/IEC/IEEE 12207 [3]. Operations pro-\ncesses, from the perspective of a software engi-\nneer, contain the activities and tasks necessary \nto deploy, configure, operate and support an \nexisting software system or product while pre-\nserving its integrity. This international standard \ndescribes four main operations process activi-\nties: 1) prepare for the operation: that requires \nto define an operation strategy; 2) perform the \noperation: which consist of operating and mon-\nitoring; 3) manage the results of operation: \nwhere anomalies are recorded and addressed; \nand finally 4) support the customer: which \nmeans to give assistance and consultation to any \nuser of the operations services. \nFinally, ISO/IEC/IEEE 32675 [4] intro-\nduces a number of software engineering \noperations activities using an Agile and a \nminimum viable product (MVP) perspec-\ntive. This standard recognizes the influence \nof DevOps as a set of principles and practices \nthat enable better communication and collab-\noration between relevant stakeholders for the \n\u2022 Operations Plan and Supplier Management\n\u2022 Development and Operational Environment\n\u2022 Software CM, Build, Package and Deployment\n\u2022 Software Availability, Continuity and Service Levels\n\u2022 Software Capacity Management\n\u2022 Software Backup, Disaster Recovery and Failover\n\u2022 Software and Data Safety, Security, Integrity, Protection and Controls\n\u2022 Operational Testing, Veri\ufb01cation and Acceptance\n\u2022 Development/Release Engineering\n\u2022 Rollback and Data Migration \n\u2022 Problem Resolution\n\u2022 Incident and Change Management\n\u2022 Monitor, Measure, Track and Review\n\u2022 Service Support and Operations Service Desk\n\u2022 Service Reporting\nOperations Planning\nProcesses\nOperations Delivery\nProcesses\nOperations Control\nProcesses\nFigure 6.2. Software Engineering Operations Processes and Activities\n", "page": 156, "type": "text", "section": "Page 156"}
{"text": "SOFTWARE ENGINEERING OPERATIONS   6-5\npurpose of specifying, developing, continu-\nously improving, and operating software and \nsystem products and services. These processes \nand activities are the responsibility of opera-\ntions engineers. \nFor the purpose of the SWEBOK Guide, \nengineering operations activities can be \ngrouped into three main operations processes \n(see Figure 6.2) that each contain a number of \noperations activities, which are described in \nthe following sections of this chapter:\n\u2022\t Operations Planning (section 2),\n\u2022\t Operations Delivery (section 3), \n\u2022\t Operations Control (section 4).\nEach software engineering operations pro-\ncess includes activities performed during the \npre delivery and post delivery stages of a soft-\nware project. Software engineering opera-\ntions planning activities occur during the pre \ndelivery stage. These activities are covered in \nthis chapter.\n1.3.\t Software Installation  \n\b\n[1, c3, c6s2][2*, c3s3.1]\nBefore a software application or update can \nbe made available to the users (i.e. released \nin production), the operations engineer must \ninstall the software as part of its deployment. \nTo install the software, the engineer might \nhave to uninstall previous versions, configure \nthe software for its target destination, and \ncreate the necessary directories, registry files \nand environment variables on the target des-\ntination. This is often done using a scripting \nlanguage. The installation of the software to \nthe appropriate locations is typically done \nelectronically, but in the case of embedded \nsystems, it might require the use of a phys-\nical medium. Once the software is installed, \na verification step is conducted to ensure that \nthe operation succeeded.\n1.4.\t Scripting and Automating\b\n[2*, c9]\nAs part of software engineering operations, \nrepetitive tasks are automated  to reduce \ndelays, increase quality, and ensure a con-\nsistent and stable operational environment. \nThis is typically achieved using scripting \nlanguages, which are basic programming \nlanguages. Automating operations enables \na quicker reaction in case of a failure and, \ntherefore, results in  less downtime and fewer \nsevere incidents, as alerts are sent immedi-\nately. Automating such tasks is also a good \nway to ensure standardization of operations in \nan organization. It also constitutes the basis \nfor the development of operations made avail-\nable as a service. Refer to section 6 for further \ndiscussion on operations tools.\n1.5.\t Ef\ufefffective Testing and  \nTroubleshooting\b\n[2*, c3]\nSoftware engineering operations is respon-\nsible for ensuring the stability of the system. \nFor this purpose, software must be thor-\noughly tested before it is released (deployed \nin production and made available to users). \nBecause manual testing is inefficient, error-\nprone and non-scalable, testing must be auto-\nmated as much as possible throughout the \nentire software process. Also, because the \ntime available for testing is limited, regres-\nsion testing and test coverage strategies (the \nselective retesting of a software application, \nor component, to verify that the software \nto be deployed will not cause unintended \neffects) play an important role in software \nengineering operations. \nWhen errors are found (in production after \nthe software is released or during internal \ntesting phases), software engineers and soft-\nware operations engineers need to troubleshoot \nhardware and software incidents by running \ndiagnostics, documenting problems and res-\nolutions, prioritizing problems, and assessing \nthe impact of the issues. The cost \u2014 in both \ntime and money \u2014 of repeating full testing \non a major piece of software is significant. \nTo ensure that the requested problem reports \n(PRs) are valid, the operations engineer should \nreplicate and verify problems by running the \nappropriate tests. Testing certain aspects of \nthe software in production can be particularly \n", "page": 157, "type": "text", "section": "Page 157"}
{"text": "6-6   SWEBOK \u00ae GUIDE V4.0\nchallenging. For example, when software per-\nforms critical functions, bringing it off-line to \ntest might be difficult. Generally, testing the \nsoftware in the production system context is \nchallenging (sometimes impossible) and could \nrequire the use of testing techniques such as \ncanary testing and dark launches. The Software \nTesting KA provides additional information \nand references on testing.\n1.6.\t Performance, Reliability and  \nLoad Balancing\b\n[1, c6s6.2]\nSoftware operations engineers plan for per-\nformance, reliability and load balancing early \nin software projects to ensure they meet the \nproject requirements. (See section 1.2 to 1.7 \nof the Software Requirements KA). A cur-\nrent trend is for software engineers to design \nand use infrastructure/operations services to \nadjust dynamically (e.g. scalability) the infra-\nstructure according to the demand. Using \nDevOps practices enables operations engi-\nneers to anticipate these needs early and pro-\nvide infrastructure services that software \nengineers can use and test during the devel-\nopment stages of a project. \n2.\t Software Engineering Operations \nPlanning\nThis topic introduces some of the generally \naccepted techniques used in software engi-\nneering operations planning. Operations \nengineers must deal with a number of key \nissues to ensure software operates effectively. \nOperations engineers should document their \nsoftware engineering operations steps and \ntools, using any type, form or medium suit-\nable for the purpose (e.g., Wikis, documents, \nand more). The following topics are typically \nconsidered suitable as evidence of well docu-\nmented operations:\n\u2022\t Policies and plans,\n\u2022\t Service documentation,\n\u2022\t Procedures,\n\u2022\t Processes, and\n\u2022\t Process control records.\n2.1.\t Operations Plan and Supplier Management\n\b\n[1, c4s4.1][3, c6s6.1]\nSoftware engineering operations planning \nshould comprise part of the process of trans-\nlating project requirements and the needs of \nthe developers and maintainers into services, \nand it should provide a road map for directing \nprogress. This process often involves the prod-\nucts and services of suppliers that must be \nwell coordinated to ensure quality service. \nISO/IEC/IEEE 20000-1 describes planning \nactivities, as well as ISO/IEC/IEEE 12207, \nwhich lists the activities operations engineers \nconsiders from human, technical and system \nperspectives.\n2.1.1.\t\nOperations Plan \n\b\n[1, c4s4.1][3,c6s6.4.12.3a]\nWhereas software development typically \nlasts from some months to a few years, the \noperations phase usually lasts many years. \nTherefore, estimating resources is a key ele-\nment of operations planning. Software engi-\nneering operations planning should begin \nwith the decision to develop a new software \nproduct and should consider its maintenance \nand operations requirements early. A concept \ndocument should be developed, followed by an \noperations and maintenance plan [1,c7s2], and \nboth should address the following:\n\u2022\t Scope of the operations and software \nmaintenance,\n\u2022\t Adaptation of the software engineering \noperations process and tools,\n\u2022\t Identification of the software engineering \noperations organization,\n\u2022\t Estimate of software engineering opera-\ntions and maintenance costs.\nThe next planning step suggest to develop \na software engineering operations plan, or \nconcept of operations (CONOPS). This plan \nshould be prepared during software develop-\nment and should specify how users will request \nsoftware modifications and report problems or \nissues when the software will be operational. \n", "page": 158, "type": "text", "section": "Page 158"}
{"text": "SOFTWARE ENGINEERING OPERATIONS   6-7\nSoftware engineering operations planning is \naddressed in ISO/IEC/IEEE 12207 [3] and \nISO/IEC/IEEE 32675 [4]. The standards pro-\nvide guidelines for planning, implementing, \nmaintaining, automating and supporting pro-\nduction software. Finally, at the highest plan-\nning level, the operations organization must \nconduct business planning activities (e.g., bud-\ngetary, financial and human resources), just as \nall the other divisions of the organization (refer \nto the Software Engineering Management \nKA). ISO/IEC/IEEE 20000-1 recommends \nthat the operations plan address issues associ-\nated with a number of planning perspectives, \nincluding the following:\n\u2022\t The roles and responsibilities for imple-\nmenting, operating and maintaining the \nnew or changed service,\n\u2022\t Activities to be performed by customers \nand suppliers,\n\u2022\t Changes to the existing service manage-\nment framework and services,\n\u2022\t Communication to the relevant parties,\n\u2022\t New or changed contracts and agreements \nto align with changes in business needs,\n\u2022\t Staffing and recruitment requirements,\n\u2022\t Skills and training requirements (e.g., \nusers, technical support),\n\u2022\t Processes, measures, methods and tools \nto be used in connection with the new or \nchanged service,\n\u2022\t Capacity management,\n\u2022\t Financial management,\n\u2022\t Budgets and timescales,\n\u2022\t Service acceptance criteria, and\n\u2022\t The expected outcomes from operating \nthe new service, expressed in measur-\nable terms.\nThis plan ensures that an operational \nstrategy is defined, conditions for correct oper-\nations are identified and evaluated, the soft-\nware is tested at scale to operate in its intended \nenvironment, and surveillance is provided \nto ensure responsiveness and availability of \nthe software by ensuring constant support. \nAt the individual request level (e.g., problem \nreport (PR) or modification request (MR)) \nneed planning. Once individual requests are \nreceived and validated, the release or version \nplanning activity requires that operations \nengineers perform the following tasks:\n\u2022\t Identify the target availability dates of \nindividual requests,\n\u2022\t Agree on the content of subsequent \nreleases or versions,\n\u2022\t Identify potential conflicts and develop \nalternatives,\n\u2022\t Assess the risk of a given release and \ndevelop a rollback and data migration plan \n(see section 3.3) in case problems arise,\n\u2022\t Inform all stakeholders.\n2.1.2.\t\nSupplier Management \n\b\n[1, c7s3][3, c6s6.1]\nSupplier management ensures that the orga-\nnization\u2019s suppliers and their performance are \nmanaged appropriately to support the seam-\nless provision of quality products and services. \nISO/IEC/IEEE 12207 lists the activities that \nthe operations engineer will perform to estab-\nlish an agreement to acquire suppliers\u2019 products \nand/or services. From an operations engineer\u2019s \nperspective, the nature of the relationship \nwith suppliers and the approach should be \ndetermined by the nature of the products and \nservices needed in a project. Managing sup-\npliers of services related to operational soft-\nware includes managing out-sourced services \nand cloud services, like IaaS and PaaS. \n2.2.\t Development and Operational \nEnvironments\b\n[2*, c9]\nThe overall software process requires the use \nof different environments at different stages. \nThese are typically defined as the development \nenvironment, the testing or quality assurance \n(QA) environment, the preproduction envi-\nronment, and the production environment. \nTo build quality into the product and reduce \nthe risks associated with the release of soft-\nware in the production environment (whether \nthe release is associated with new function-\nality or software defects), engineers must \n", "page": 159, "type": "text", "section": "Page 159"}
{"text": "6-8   SWEBOK \u00ae GUIDE V4.0\nensure that the different environments are all \ncoherent and synchronized with the produc-\ntion environment. \nFor this reason, DevOps recommends that \nthe creation of all the different environments \nbe automated and built from a single code \nrepository. In mature DevOps organizations, \nthe creation of the different environments is \ncompletely automated and made available as \na service. Also, all environments need to be \nbuilt from the same code source (single source \nof truth) to ensure that all the environments \nare synchronized with the production envi-\nronment in which the software is released. \nThis leads to the concept of infrastructure as \ncode (IaC).\n2.3.\t Software Availability, Continuity, and \nService Levels\b\n[1, c6s6.3]\nService availability and continuity must be \nmanaged to ensure that customer commitments \nare met. Because service availability and conti-\nnuity are defined as nonfunctional requirements \nearly in a project (see the Software Quality \nKA), operations engineers will ensure that \nthe proper infrastructure is planned, designed, \nimplemented and tested. Software availability \nis measured and recorded, and unplanned \nnonavailability is investigated and appropriate \nactions taken. Service reports produce avail-\nability and continuity indicators of operations \nservices against service-level targets. \nThe service-level management process moni-\ntors the agreed software level of service, including \nworkload characteristics, performance and \navailability trend information and customer \nsatisfaction analysis. Defining, agreeing to and \ndocumenting service-level agreements (SLAs) \ncan help clarify the full range of operations \nservices obligations provided. The Software \nMaintenance KA provides additional infor-\nmation and references about SLA\u2019s.\n2.4.\t  Software Capacity Management \n\b\n[1, c6s6.5]\nISO/IEC/IEEE 20000-1 describes the need \nto ensure that the software product has the \ncapacity, at all times, to meet current and \nfuture agreed-upon demands created by the \ncustomer\u2019s business needs. The current and \nexpected business requirements for services \nshould be understood in terms of what the \nbusiness needs in order to deliver its prod-\nucts or services to its customers. Business pre-\ndictions and workload estimates should be \ntranslated into specific requirements and doc-\numented. The reaction to variations in work-\nload or environment should be predictable; \ndata on current and previous components, as \nwell as resource utilization at an appropriate \nlevel, should be captured and analyzed to sup-\nport the process.\nCapacity management is the focal point \nfor all performance and capacity issues. The \nprocess should directly support the develop-\nment of new and changed services by sizing \nand modeling these services. A capacity plan \ndocumenting the actual performance of the \ninfrastructure and the expected requirements \nshould be produced at a suitable frequency (at \nleast annually), considering the rate of change \nin services and service volumes, informa-\ntion in the change management reports, and \nchanging customer business requirements. \nThe capacity plan should document costed \noptions for meeting business requirements \nand recommend solutions to ensure achieve-\nment of the agreed-upon service-level targets \nas defined in the SLA. The technical infra-\nstructure and its current and projected capac-\nities should be well understood to ensure \noptimal software operations.\n2.5.\t  Software Backup, Disaster Recovery, and \nFailover\b\n[1, c6s6.3.4]\nISO/IEC/IEEE 20000-1 also proposes that \nthe following should be quickly available \nfollowing a major service failure or disaster \nto ensure continuity planning and testing: \nbackups of data, documents and software, \nand any equipment or staff necessary for ser-\nvice restoration. Backup and data recovery \nare important activities; successful recovery \nis especially vital. The need for successful \nrecovery should influence which backup and \n", "page": 160, "type": "text", "section": "Page 160"}
{"text": "SOFTWARE ENGINEERING OPERATIONS   6-9\nrecovery methods are used (full or incre-\nmental), how frequently restore points are \nestablished, where they are stored, and how \nlong they are retained. \nPreparedness and regular test of backup, \ndisaster recovery, and failover should be con-\nstantly rehearsed as changes to the produc-\ntion environment are made. This is another \nessential activity that is triggered when outage \nassessments are done. Testing disaster recovery \nrequires stopping the service, identifying the \ncheckpoint state and triggering the failover \nprocess. Software engineers should under-\nstand that failure is inevitable and that auto-\nmated failover daemons can reduce recovery \ntime drastically. To achieve this, software \napplications should include failure-handling \nlogic; this must be planned during develop-\nment. DevOps can help organizations that \nwant to reduce failovers and disasters by auto-\nmating and launching tests as often as possible \nto ensure readiness in case of a failure or cata-\nstrophic event.\n2.6.\t  Software and Data Safety, Security, \nIntegrity, Protection, and Controls \n\b\n[1, c6.s6.6]\nThe need to manage information secu-\nrity effectively within all service activities is \ndescribed in ISO/IEC/IEEE 20000-1. This \nis done by conducting a software risk assess-\nment on the security and availability of infor-\nmation. Operations engineers should strive to \nenforce the following controls:\na.\tSenior management should define their \ninformation security policy, communi-\ncate it to staff and customers, and act to \nensure its effective implementation,\nb.\tInformation security management roles \nand responsibilities should be defined \nand allocated to post holders,\nc.\tA representative of the management team \nshould be assigned the role of monitoring \nand maintaining the effectiveness of the \ninformation security policy,\nd.\tStaff with significant security roles should \nreceive information security training,\ne.\tAll staff should be made aware of the \ninformation security policy,\nf.\t Expert help on risk assessment and con-\ntrol implementation should be available,\ng.\tChanges should not compromise the \neffective operation of controls, and\n\u2022\t Information security incidents should \nbe reported following incident manage-\nment procedures, and a response should \nbe initiated.\nIn line with the evolution of DevOps, \nDevSecOps is promoting the integration \nof security early and throughout the soft-\nware process, which includes the integra-\ntion of different security mechanisms and \ntools at the operations level. The goal is to \nautomate the detection and correction of \nsecurity issues as early as possible in the \noverall process.\n3.\t Software Engineering Operations \nDelivery\nThis topic introduces some of the gener-\nally accepted processes used during software \nengineering operations  delivery (ISO/IEC/\nIEEE 20000-1): SLA, service reporting, \nservice continuity, availability management, \nbudgeting and accounting for IT services, \ncapacity management, and information secu-\nrity management. \n3.1.\t  Operational Testing, Verification, and \nAcceptance\b\n[2*,c10] [3, c6s6.3.5.3d]\nSoftware engineers plan and execute soft-\nware verification as early as possible, using \ntest-driven development (TDD) and accep-\ntance test-driven development (ATDD) \ntechniques and tools that ensure that opera-\ntional testing is ongoing during the develop-\nment of the software, not only at the end of \na project. DevOps plays an important role in \ndeveloping and automating software testing \nservices and integrating different tools to \nboost software productivity and quality. \n(See TDD and ATDD in the Software \nTesting KA.)\n", "page": 161, "type": "text", "section": "Page 161"}
{"text": "6-10   SWEBOK \u00ae GUIDE V4.0\n3.2.\t  Deployment/Release Engineering \n\b\n[2*,c12][3,c6s6.3.5.3d]\nA software operations engineer\u2019s main \nresponsibility relates to the deployment and \nrelease of software to ensure its continued \nperformance. As defined in [2*], \u201cdeploy-\nment is the installation of a specified ver-\nsion of software to a given environment (e.g., \ndeploying code into an integration test envi-\nronment or deploying code in production),\u201d \nwhereas \u201crelease is when we make a feature \n(or set of features) available to all our cus-\ntomers or a segment of customers (e.g., we \nenable the feature to be used by 5% of our \ncustomer base).\u201d Release processes include all \nthe activities related to release management. \nISO/IEC/IEEE 12207 [3] lists release con-\ntrol activities and explains the need to iden-\ntify and record release requests, identify the \nsoftware system elements in a release fol-\nlowed by approval, and track the releases in \ntheir specified environments. \nDevOps advocates integrating develop-\nment and operations in the same team to \nimprove software engineering operations \nefficiency. In traditional software processes, \nwhen an application is ready for deployment, \nit is transferred from a development team to \nan operations team that is responsible for \ndeployment, which is mostly done manually. \nThis results in processes that are inefficient \nfrom both a time and a quality perspective. \nTo improve the efficiency of the deployment \nprocess, DevOps calls for automating the \ndifferent deployment steps, including pack-\naging the code, generating configuration \nfiles, restarting the servers, configuring the \nservers and databases, installing the soft-\nware on the different servers, launching the \nexecution of the application, and executing \nsmoke testing. \nDifferent \nrelease \nengineering \nstrate-\ngies can be used to reduce the risks asso-\nciated \nwith \nsoftware \nreleases. \nThese \nstrategies can be grouped into two main cat-\negories: environment-based release strate-\ngies and application-based release strategies. \nEnvironment-based release strategies use a \nstaging environment to support the release \nof a new version of an application. In other \nwords, the basic strategy involves deploying \nthe new version of the application to a staging \nenvironment. Application-based release strat-\negies are based on the use of toggles (e.g., fea-\nture toggles) that make it possible to enable \nor disable specific sections of the code (e.g., a \nfeature) using configuration parameters.\nDeployment and release are supported \nby automation techniques and tools. The \ncanary release testing technique is a partial \nand time-limited deployment of a change in \na service and an evaluation of that change. \nThis evaluation helps the operations engi-\nneer decide whether to proceed with a \ncomplete deployment. Similarly, tools that \nmanage the installation of new software typ-\nically observe the newly started server for a \nwhile, ensuring that the server doesn\u2019t crash \nor otherwise misbehave. The same tech-\nnique is useful for observing recent changes; \nif they do not pass the validation period, \nthey can be automatically rolled back. The \nSoftware Configuration Management KA \nprovides more information about the release \nprocesses. Once the application platform is \ndeployed in the targeted production envi-\nronment, the decision to make it available \nto the users (release it) becomes a busi-\nness decision.\n3.3.\t Rollback and Data Migration \n\b\n[2*, c12][3, c6s6.4.10.3]\nRollback and data migration are terms used to \ndescribe the process of returning software and \nits database to a state where they work prop-\nerly. Software engineers ensure that when \na new version of the software and its data-\nbases have been modified and deployed to \nproduction, they can easily and quickly be \nrolled back in case the new version is causing \ndefects or product degradation in production. \nThis means a planned and rehearsed rollback \nis done before a new version of the software \nis deployed in production. DevOps processes \nautomate this process to make it faster; in \nfact, the automated surveillance can trigger \n", "page": 162, "type": "text", "section": "Page 162"}
{"text": "SOFTWARE ENGINEERING OPERATIONS   6-11\nrollback and data migration to a previous state \nso quickly that the end user doesn\u2019t notice that \nthere was a problem. Both release strategy \ncategories (described in section 3.2) \u2014 envi-\nronment-based release and application-based \nrelease \u2014 can be used to support rollback.\n3.4.\t Change Management \b\n[1, c9s9.2]\nThis operations process ensures that all \nchanges are assessed, approved, implemented \nand reviewed in a controlled manner. All \nchange requests are recorded and classified \n(e.g., emergency, urgent, major and minor). \nThis process assesses the risk of a change \nand the need for a rollback strategy in case \nof failure. Large systems might require that a \nchange schedule be planned with the product \nmanager and end users. \nWhereas in traditional software delivery \nprocesses (or software life cycle models), all \nchanges are delivered as part of new soft-\nware releases (containing multiple changes \nrelated to different aspects of the application \nor system) issued at fixed time intervals (e.g., \nevery three months), DevOps aims to deliver \nsmall units of change (a single new function-\nality or service, or defect fix, rather than a \nnew version of an application containing mul-\ntiple changes) on demand and independently \nfrom each other. For this purpose, software \napplications (or services) must be archi-\ntected to enable small, independent software \ndeployments.\n3.5.\t Problem Management\b\n[1, c8s8.3]\nThe objective of this operations process is to \nminimize disruption to the business through \nthe identification and analysis of the cause \nof software and system incidents and prob-\nlems. This approach may require the involve-\nment of a multidisciplinary team, whose \nsoftware engineers and operations engineers \ninvestigate, for example, recurring produc-\ntion problems that might have an underlying \ncause in software infrastructure and system \ncomponents. This might require monitoring, \nlogging and profiling the software and its \ninfrastructure behavior.\n4.\t Software Engineering Operations \nControl\nThis topic introduces some generally accepted \ntechniques used in software engineering \noperations control.\n4.1.\t Incident Management\b\n[1, c8s8.2] \nIncident management is the process of \nrecording, prioritizing and assessing the busi-\nness impact, resolution, escalation and closure \nof software incidents. The modern DevOps \napproach automates software surveillance using \nalerts and logs to prevent minor incidents from \nbecoming major incidents. When an inci-\ndent occurs, proper analysis and/or post mor-\ntems must be conducted to find the source of \nthe incident and appropriate solutions must be \nimplemented to prevent similar incidents to \nhappen again in the future.\n4.2.\t Monitor, Measure, Track, and Review   \n\b\n[2*, c14-15]\nSoftware \nengineering \noperations \nactivi-\nties monitor capacity, continuity and avail-\nability. In a DevOps mindset, hope should \nnot be a strategy; instead, engineers should be \ninformed about system quality and operational \nhealth with evidence, such as the following \nkey performance indicators (KPI), which are \navailable to stakeholders in real time:\n\u2022\t Production system\u2019s monitoring and \nproduct telemetry,\n\u2022\t Actionable \nverification \nand \nvalida-\ntion results before and after release to \nproduction,\n\u2022\t End-user activity and resource use,\n\u2022\t Impact analysis results,\n\u2022\t Inter- and intra-related dependencies \nrequired for system operation,\n\u2022\t Configuration changes unrelated to \napproved deployment tasks, and\n\u2022\t Security and resilience performance \ncapability.\n", "page": 163, "type": "text", "section": "Page 163"}
{"text": "6-12   SWEBOK \u00ae GUIDE V4.0\n4.3.\t Operations Support\b\n[1, c6, c14s5]\nISO/IEC/IEEE 12207 [3], \u201cISO/IEC/\nIEEE 20000-1 [1] and ISO/IEC/IEEE \n32675 [4] identify the primary software \nengineering operations activities that sup-\nport the operations processes \u2014 activi-\nties that operate the software product in its \nintended environment \u2014 and the primary \nactivities that provide support to the cus-\ntomers of the software products. Operations \nsupport activities are initiated at the plan-\nning stage of the project and are then exe-\ncuted, which often requires techniques and \ntools to proactively monitor the product \nand services and react quickly to events \nand incidents. Support activities are often \ndescribed in SLAs.\n4.4.\t  Operations Service Reporting   \n\b\n[1,c6s6.2]\nService reporting aims to produce agreed-\nupon, timely, reliable and accurate informa-\ntion for decision-making. Each service report \nhelps demonstrate how an operations ser-\nvice has performed and whether it has met \nsome stated and agreed-upon end-user objec-\ntive. Typical service reports address perfor-\nmance against service-level targets, as well \nas security breaches, the volume of transac-\ntions and resource use, incidents and failures, \ntrend information, and satisfaction analysis. \nOperations engineers need to establish auto-\nmated systems and tools for measurement to \ndo the following:\n\u2022\t Determine whether measures are already \navailable or additional instrumentation \nfor collection, analysis and reporting \nis needed,\n\u2022\t Select or develop a framework and tools to \nallow coordination of measurement col-\nlection for analysis, reporting and control.\n5.\t Practical Considerations\nThis topic introduces practical considerations \nfor software engineering operations.\n5.1.\t Incident and Problem Prevention \n\b\n[2*, c7]\nThe overall operations process needs to be \nautomated as much as possible to prevent inci-\ndents and problems, and automated testing \nneeds to be integrated throughout the process. \nAlso, product telemetry should be imple-\nmented with proper analytics techniques to \ndetect problems as early as possible to prevent \nincidents. For this purpose, data collected \nat all layers of the product stack (including \napplication layer, operating system layer and \ninfrastructure layer) must be collected and \nanalyzed. Using product telemetry not only \nallows engineers to detect potential issues but \nalso provides the foundation for identifying \nthe source of the problem.\n5.2.\t  Operational Risk Management \n\b\n[3, c6s6.4.12.3c4]\nOperations engineers must manage a number \nof risks. IEEE 2675 [4] defines continuous \nrisk management as a continuous process that \ncan be automated to monitor operations con-\nstantly for risks that can affect software avail-\nability, scalability and security. Operations \nengineers can take measures to automate \nthe alerts. To decide what events will trigger \nan alert, they need to talk with product \nowners and software engineers to establish \nan agreed-upon level of risk tolerance. Other \nperspectives are to choose the deployment \nprocess that is appropriate for the risk profile \nof a given service and the risks of exposing \nprivate data.\n5.3.\t Automating Software Engineering \nOperations\b\n[2*, c8]\nAutomation has taken an important place in \nrecent years in modern operations. Software \nengineers achieve the best results when cou-\npling applications and operations automation. \nAlthough automation primarily focuses on \nmanaging the life cycle of a system or infra-\nstructure (e.g., user account creation, envi-\nronments and server provisioning, runtime \n", "page": 164, "type": "text", "section": "Page 164"}
{"text": "SOFTWARE ENGINEERING OPERATIONS   6-13\nconfig changes), it can also be useful in other \nuse cases where services can be developed \nto help software engineers deploy, test and \ndebug during development. Trends in oper-\nations automation aim to reduce complexity, \naccelerate provisioning of infrastructure, \noffer operations services scripts to developers, \ndefine applications, automate deployment \nand test workflows.\n5.4.\t Software Engineering Operations for Small \nOrganizations\nVery small organizations (organizations of up \nto 25 people) have difficulty applying stan-\ndards developed by and for large organiza-\ntions, as their requirements can overwhelm \nthe capabilities of small organizations. This \nis where the ISO/IEC 29110 series of stan-\ndards is useful, as it provides standards and \nguidelines adapted to very small organizations \nto ensure the quality of their software engi-\nneering operations [7]. Software engineers \nshould be aware that operations processes can \nbe adapted to small organizations and that the \nISO/IEC CD 29110-5-5 is currently under \ndevelopment for this purpose.\n6.\t Software Engineering Operations Tools \n\b\n[1, c5s5g][2*, c12] \nThis topic encompasses tools that are par-\nticularly important in software engineering \noperations for maximizing the efficient use \nof personnel. Automating development, \nmaintenance and operations-related tasks \nsaves engineering resources and improves \nquality and turnaround. When imple-\nmented appropriately, such automated tasks \nare generally faster, easier and more reliable \nthan they would be if they were attempted \nmanually by software engineers and oper-\nations engineers. DevOps supports such \nautomation for integrating, building, pack-\naging, configuring, and deploying reliable \nand secure systems. It combines devel-\nopment, \nmaintenance, \nand \noperations \nresources and procedures to perform CI, \ndelivery, testing and deployment. \nContinuous delivery (CD) is a software \nengineering practice that uses automated \ntools to provide frequent releases of new sys-\ntems (including software) to staging or var-\nious test environments. CD continuously \nassembles the latest code and configuration \nfrom the head into release candidates.\nContinuous testing is a software testing \npractice that involves testing the software at \nevery stage of the software development life \ncycle. Continuous testing aims to evaluate the \nquality of software at every step of the CD \nprocess by testing early and often. Continuous \ntesting involves various stakeholders, such as \ndevelopers, DevOps personnel, and QA and \nend-users.\nContinuous deployment (aka CD) is an auto-\nmated process of deploying changes to pro-\nduction by verifying intended features and \nvalidations to reduce risk. Jez Humble and \nDavid Farley [8] pointed out that \u201c[t]he biggest \nrisk to any software effort is that you end up \nbuilding something that isn\u2019t useful. The ear-\nlier and more frequently you get working soft-\nware in front of real users, the quicker you get \nfeedback to find out how valuable it really is.\u201d\n6.1.\t Containers and Virtualization \t\nDifferent container/virtualization technol-\nogies and management tools (also called \norchestrators) are available to operations \nengineers to improve the scalability of appli-\ncations and standardize software deployment \nacross multiple computer and server suppliers. \n[4, c6,s6.4.12] Operations engineers use their \nknowledge of the size and complexity of each \nproject to identify the best tool for flexibility, \nsecurity and monitoring.\n6.2.\t Deployment\b\n[2*, c12] \nDifferent technologies and tools can be used \nto manage software deployments in different \nenvironments. [4, c5s5.1] Also, different tools \nare usually combined to cover the different \nphases and aspects of software deployment, \nranging from the specification of deployment \nand configuration using descriptor files to the \n", "page": 165, "type": "text", "section": "Page 165"}
{"text": "6-14   SWEBOK \u00ae GUIDE V4.0\nautomated deployment and management of \nproduction environment resources.\n6.3.\t Automated Test \b\n[2*, c10]\nTo enable fast and constant feedback to the \ndevelopers, testing must be automated as \nmuch as possible throughout the entire soft-\nware delivery process, including throughout \ndevelopment and operations. For this pur-\npose, a testing strategy covering the different \ntypes of test (unit test, integration test, system \ntest, user acceptance test) must be defined, and \ntools to support and automate the different \ntesting phases must be selected. The automa-\ntion of testing is critical to provide continuous \nfeedback to software engineers developing \ncode and thereby to improve software quality.\n6.4.\t Monitoring and Telemetry\b\n[2*, c14-15]\nMonitoring and telemetry are key aspects \nof software engineering operations. They \ncollect data at all layers of the software system \n(including application, operating system and \nserver) and extract information that can be \nused to analyze and monitor different aspects \nof the system to detect issues and follow \nthe evolution of various properties. James \nTurnbull [9] describes a general monitoring \nframework architecture used by engineering \noperations in many technology organizations. \nImplementing monitoring solutions requires \ncombining different techniques and tools to \ncollect data at different layers. This includes \nlogs at the application level, execution traces \nat the operating system level and resource \nuse information (like CPU and memory use) \nat the server level. Then, based on the col-\nlected data, different analytics techniques \n(e.g., statistical analysis and machine learning \ntechniques) can be used to extract relevant \ninformation. Finally, dashboards can be used \nto visualize the extracted information; dif-\nferent dashboards can be developed to display \nrelevant information to different stakeholders. \nMATRIX OF TOPICS VS. REFERENCE MATERIAL\nISO 20000-1  \n[1] \nThe DevOps  \nHandbook [2*]\nISO 12207 [3]\n1. Software Engineering Operations \nFundamentals\n1.1. Definition of Software Engineering \nOperations \nc3s3.3\nc6s6.4.12\n1.2. Software Engineering \nOperations Processes\ns1\nc6 s6.4.12\n1.3. Software Installation\nc3, c6s2\nc3s3.1\n1.4. Scripting and Automating\nc9\n1.5. Effective Testing and Troubleshooting\nc3\n1.6. Performance, Reliability and \nLoad Balancing\nc6s6.2\n2. Software Engineering \nOperations Planning\n2.1. Operations Plan and Supplier \nManagement\nc4s4.1\nc6s6.1\n2.2. Development and Operational \nEnvironments\nc9\n", "page": 166, "type": "text", "section": "Page 166"}
{"text": "SOFTWARE ENGINEERING OPERATIONS   6-15\n2.3. Software Availability, Continuity \nand Service Levels\nc6s6.3\n2.4. Software Capacity Management\nc6s6.5\n2.5. Software Backup, Disaster Recovery \nand Failover\nc6s6.3.4\n2.6. Software and Data Safety, Security, \nIntegrity, Protection and Controls\nc6s6.6\n3. Software Engineering \nOperations Delivery\n3.1. Operational Testing, Verification and \nAcceptance\nc10\nc6s6.3.5.3d\n3.2. Deployment/Release Engineering\nc12\n3.3. Rollback and\nData Migration\n3.4. Change Management\nc9s9.2\n3.5. Problem Management\nc8s8.3\n4. Software Engineering \nOperations Control\n4.1. Incident Management\nc8s8.2\n4.2. Monitor, Measure, Track and Review \nc14-15\n4.3. Operations Support\nc6, c14s5\n4.4. Operations Service Reporting\nc6s6.2\n5. Practical Considerations \n5.1. Incident and Problem Prevention\nc7\n5.2. Operational Risk Management\nc6s6.4.12.3c4\n5.3. Automating Software Engineering \nOperations\nc8\n5.4. Software Engineering Operations for \nSmall Organizations\n6. Software Engineering \nOperations Tools\nc5s5g\nc12\n6.1. Containers and Virtualization\n6.2. Deployment\nc12\n6.3. Automated Test\nc10\n6.4. Monitoring and Telemetry\nc14-15\nREFERENCES \n[1]\t IEEE standard, ISO/IEC/IEEE 20000-\n1:2013, Information technology \u2014 Service \nmanagement \u2014 Part 1: Service management \nsystems requirements, ed. IEEE, 2013.\n[2*]\tG. Kim, J. Humble, J. Debois, J. \nWillis, and N. Forsgren, The DevOps \n", "page": 167, "type": "text", "section": "Page 167"}
{"text": "6-16   SWEBOK \u00ae GUIDE V4.0\nHandbook: How to create world-class \nagility, reliability and security in tech-\nnology organizations, 2nd ed., IT \nRevolution Press, 2021.\n[3]\t IEEE standard, ISO/IEC/IEEE \n12207:2017, Systems and software \nengineering \u2014 Software Life Cycle \nProcesses, ed. IEEE, 2017.\n[4]\t IEEE standard, ISO/IEC/IEEE \n32675:2022, Information Technology \n\u2014 DevOps: Building Reliable and \nSecure Systems Including Application \nBuild, Package and Deployment, ed. \nIEEE, 2022.\n[5]\t ISO/IEC/IEEE, \u201cISO/IEC/IEEE \n24765:2017 Systems and Software \nEngineering \u2014 Vocabulary,\u201d 2nd ed. 2017\n[6]\t B. Beyer, C. Jones, J. Petoff, and N.R. \nMurphy, Site Reliability Engineering \u2014 \nHow Google Runs Production Systems, \nO\u2019Reilly Media, 2016. \n[7] \tISO/IEC CD 29110-5-5:2023, Systems \nand software engineering \u2014 Lifecycle \nprofiles for Very Small Entities (VSEs), \nPart 5-5: Agile/DevOps guidelines.\n[8] \tJ. Humble and D. Farley. Continuous \ndelivery: reliable software releases through \nbuild, test, and deployment automation. \nPearson Education, 2010.\n[9] \t J. Turnbull, The Art of Monitoring. James \nTurnbull, 2014.\n", "page": 168, "type": "text", "section": "Page 168"}
{"text": "7-1 \nCHAPTER 07\nSoftware Maintenance\nACRONYMS\nAPI\nApplication Programming Interface\nCI\nContinuous Integration\nIEC\nThe International Electrotechnical \nCommission\nIEEE\nThe Institute of Electrical and \nElectronics Engineers\nISO\nInternational Organization for \nStandardization\nKA\nKnowledge Area\nLOC\nLines of Code\nMR\nModification Request\nPR\nProblem Report\nSCM\nSoftware Configuration \nManagement\nSEE\nSoftware Engineering Environment\nSLA\nService-Level Agreement\nSLI\nService-Level Indicators\nSLO\nService-Level Objectives\nSQA\nSoftware Quality Assurance\nV&V \nVerification and Validation\nXaaS\nAnything as a Service\nINTRODUCTION\nSuccessful software development efforts \nresult in the delivery of a software product \nthat satisfies user requirements. As those \nrequirements and other factors change, the \nsoftware product must evolve: Once the soft-\nware is in operation, defects are uncovered, \noperating environments change, and new \nuser requirements surface. The maintenance \nphase of the life cycle begins after a warranty \nperiod or after post-implementation support \ndelivery, but maintenance activities occur \nmuch earlier. \nSoftware maintenance is an integral part \nof a software life cycle. However, it has not \nreceived the same degree of attention as \nthe other software engineering activities. \nHistorically, software development has had \na much higher profile than software mainte-\nnance. This is now changing as organizations \nstrive to optimize their software engineering \ninvestment by ensuring continuous develop-\nment, maintenance and operation, progres-\nsively eliminating the organizational silos \namong these areas. The growing acceptance \nof DevOps practices and tools have drawn \nfurther attention to the need to continuously \nevolve software while ensuring its smooth \noperation to satisfy users, who are demanding \nquicker turnaround from software engineers \nthan in the past. \nIn this SWEBOK Guide, software main-\ntenance is defined as the totality of activi-\nties required to provide cost-effective support \nfor software in operation. Activities to sup-\nport software operation and maintenance are \nperformed during the pre delivery stage and \nduring the post delivery stage. Pre delivery \nactivities include planning for post delivery \noperations, maintainability and determining \nthe logistics support needed for the tran-\nsition from development to maintenance. \nPostdelivery activities include software sur-\nveillance, modification, training, and oper-\nating or interfacing with a help desk.\nThe Software Maintenance knowledge area \n(KA) is related to all other aspects of software \nengineering. Therefore, this KA description is \nlinked to all other software engineering KAs \nin the Guide. \n", "page": 169, "type": "text", "section": "Page 169"}
{"text": "7-2   SWEBOK \u00ae GUIDE V4.0\nBREAKDOWN OF TOPICS FOR \nSOFTWARE MAINTENANCE \nThe breakdown of topics for the Software \nMaintenance KA is shown in Figure 7.1.\n1.\t Software Maintenance Fundamentals\nThis section introduces the concepts and ter-\nminology that form a basis for understanding \nthe role and scope of software maintenance. \nAmong these concepts are the different cat-\negories of software maintenance. Learning \nabout these categories is critical to under-\nstanding what this knowledge area encom-\npasses and why it is so important.\n1.1.\t Definitions and Terminology \n\b\n[1, s3.1][2*, c1s1.2, c2s2,2] \nThe purpose of software maintenance is \ndefined in the international standard for soft-\nware maintenance: ISO/IEC/IEEE 14764 \n[1]. In the context of software engineering, \nsoftware maintenance is essentially one of \nmany technical processes. The objective of \nsoftware maintenance is to modify existing \nsoftware while preserving its integrity. The \ninternational standard also emphasizes the \nimportance of performing some maintenance \nactivities before final delivery of the software \n(pre delivery activities). Software mainte-\nnance shares knowledge and tools with soft-\nware development and software operation and \nalso has its own processes and  techniques.\n1.2.\t  Nature of Software Maintenance \n\b\n[2*, c1s1.3]\nSoftware maintenance sustains the soft-\nware product throughout its life cycle (from \ndevelopment through operations). The soft-\nware is monitored for capacity, continuity \nand \navailability. \nModification \nrequests \n(MRs) and incidents or problems reports \n(PRs) are logged and tracked, the impact of \nproposed changes is determined, code and \nother software artifacts are modified, testing \nis conducted, and a new version of the soft-\nware product is released into operation. \nAlso, training and daily ongoing support \nare provided to users. A software maintainer \nis defined as a role or an organization that \nperforms software maintenance activities. \nSoftware\nMaintenance\nDe\ufb01nitions and \nTerminology\nTechnical Issues\nManagement \nIssuess\nSoftware \nMaintenance\nCost\nSoftware \nMaintenance\nMeasurements\nNature of\nSoftware \nMaintenance\nNeed of\nSoftware \nMaintenance\nCategories of\nSoftware \nMaintenance\nEvolution of\nSoftware\nKey Issues in\nSoftware\nMaintenance\nSoftware\nMaintenance\nFundamentals\nSoftware\nMaintenance\nProcesses\nSoftware\nMaintenance\nProcesses\nProgram\nComprehension\nSoftware\nReengineering\nReverse\nEngineering\nCI/CD, Testing\nand Deployment\nSoftware\nMaintenance\nActivities \nand Tasks\nSoftware\nMaintenance\nTechniques\nSoftware\nMaintenance\nTools\nFigure 7.1. Breakdown of Topics for the Software Maintenance KA\n", "page": 170, "type": "text", "section": "Page 170"}
{"text": "SOFTWARE MAINTENANCE   7-3\nIn this KA, the term sometimes refers to \nindividuals who perform those activities, to \ncontrast their role with the software devel-\noper\u2019s role.\nMaintainers can learn from the developers\u2019 \nand operators\u2019 knowledge of the software. \nEarly contact with the developers and early \ninvolvement by the maintainers can reduce \nthe overall maintenance costs and efforts. An \nadditional challenge is created when main-\ntainers join the project after the initial devel-\nopers have left or are no longer available. \nMaintainers must understand and use soft-\nware artifacts from development (e.g., code, \ntests or documentation), support them imme-\ndiately, and progressively evolve and maintain \nthem over time.\n1.3.\t Need for Software Maintenance  \n\b\n[2*, c1s1.5]\nSoftware maintenance is needed to ensure that \nthe software continues to satisfy user require-\nments throughout its life span. Maintenance \nis necessary regardless of the type of software \nlife cycle model used to develop it (e.g., water-\nfall or Agile). Software products change as a \nresult of both corrective and non-corrective \nactions. Software maintenance is typically \nperformed to do the following:\n\u2022\t Correct faults and latent defects\n\u2022\t Improve the design or performance of \noperational software\n\u2022\t Implement enhancements\n\u2022\t Help users understand the software\u2019s \nfunctionality\n\u2022\t Adapt to changes in interfaced systems or \ninfrastructure\n\u2022\t Prevent security threats\n\u2022\t Remediate technical obsolescence of \nsystem or software elements\n\u2022\t Retire the software\n1.4.\t Majority of Maintenance Costs \n\b\n[2*, c4s4.3, c5s5.2]\nIt is generally accepted that the relative cost \nof error fixing increases in later phases of \nthe software life cycle. Maintenance also \nuses a significant portion of the total finan-\ncial resources attributed throughout the life \nof a software. A common perception of soft-\nware maintenance is that it merely fixes faults. \nHowever, studies and surveys over the years \nhave indicated that most software mainte-\nnance \u2014 over 80% \u2014 is used for enhancing \nand adapting the software [3]. Grouping \nenhancements and corrections together in \nmanagement reports contributes to a mis-\nconception that corrections cost more than \nthey really do. Understanding the categories \nof software maintenance helps us understand \nthe structure of software maintenance costs \n\u2014 that is, where most of that spending goes \n[7]. Also, understanding the factors that affect \nthe maintainability of software can help orga-\nnizations contain costs. Environmental fac-\ntors that affect software maintenance costs \ninclude the following:\n\u2022\t Operating environment (hardware and \nsoftware).\n\u2022\t Organizational \nenvironment \n(poli-\ncies, competition, process, product and \npersonnel).\n1.5.\t Evolution of Software  \n\b\n[2*, c3s3.5]\nSoftware maintenance as an activity that \nsupports the evolution of software was first \naddressed in the late 1960s. Research, by \nLehman and others [8], over a period of twenty \nyears led to the formulation of eight laws of \nsoftware evolution: \n\u2022\t Continuing Change \u2014 Software must be \ncontinually adapted, or it becomes pro-\ngressively less satisfactory.\n\u2022\t Increasing Complexity \u2014 As software \nevolves, its complexity increases unless \nwork is done to maintain or reduce that \ncomplexity.\n\u2022\t Self-Regulation \u2014 The program evolu-\ntion process is self regulating with close \nto normal distribution of measures of \nproduct and process attributes.\n", "page": 171, "type": "text", "section": "Page 171"}
{"text": "7-4   SWEBOK \u00ae GUIDE V4.0\n\u2022\t Invariant Work Rate \u2014 The average \neffective global activity rate in an evolving \nsoftware package is invariant over the \nproduct\u2019s lifetime.\n\u2022\t Conservation of Familiarity \u2014 As soft-\nware evolves, all associated with it (e.g., \ndevelopers, sales personnel and users) \nmust maintain mastery of its content and \nbehavior to achieve satisfactory evolution. \nExcessive growth diminishes that mas-\ntery. Hence, average incremental growth \nremains invariant as the system evolves.\n\u2022\t Continuing Growth \u2014 Functional con-\ntent of a program must be continually \nincreased to maintain user satisfaction \nover its lifetime.\n\u2022\t Declining Quality \u2014 The quality of soft-\nware will appear to be declining unless it \nis rigorously maintained and adapted to \nchanges in the operational environment.\n\u2022\t Feedback System \u2014 Software evolution \nprocesses constitute multilevel, multi-\nloop, multi-agent feedback systems and \nmust be treated as such to achieve sig-\nnificant improvement over any rea-\nsonable base.\nKey findings of Lehman\u2019s research include \na proposal that maintenance is evolutionary \ndevelopment and that maintenance decisions \nare aided by an understanding of what hap-\npens to software over time. Another way to \nthink of maintenance is as continued devel-\nopment that accommodates extra inputs (or \nconstraints) \u2014 in other words, large software \nprograms are never complete and continue \nto evolve. As they evolve, they grow more \ncomplex unless action is taken to reduce that \ncomplexity. \n1.6.\t Categories of Software Maintenance \n\b\n[1, s3.1.8][2*, c1s1.8, c3s3.3]\nFive categories (types) of software mainte-\nnance have been standardized to classify a \nmaintenance request: corrective, preventive, \nadaptive, additive and perfective. ISO/IEC/\nIEEE 14764 [1], regroups these maintenance \ncategories as either corrections or enhance-\nments, as shown in Figure 7.2. \nISO/IEC/IEEE 14764 [1] also defines a \nsixth category \u2014 emergency maintenance: \n\u2022\t Corrective maintenance: Reactive modi-\nfication (or repairs) of a software product \nperformed after delivery to correct dis-\ncovered problems.\n\u2022\t Preventive maintenance: Modification of \na software product after delivery to cor-\nrect latent faults in the software product \nbefore they occur in the live system. \n\u2022\t Adaptive maintenance: Modification of a \nsoftware product performed after delivery \nto keep a software product usable in an \nevolving environment. Adaptive mainte-\nnance provides enhancements necessary \nto accommodate changes in the environ-\nment in which a software product operates \n(e.g., an upgrade to the operating system \nresults in changes to the applications).\n\u2022\t Additive \nmaintenance: \nModification \nof a software product performed after \ndelivery to add functionality or features \nto enhance the usage of the product. \nModi\ufb01cation Request\nCorrection\nCorrective\nPreventive\nAdaptive\nAdditive\nPerfective\nEnhancement\nFigure 7.2. Software Maintenance Categories\n", "page": 172, "type": "text", "section": "Page 172"}
{"text": "SOFTWARE MAINTENANCE   7-5\nAdditive maintenance differs from per-\nfective maintenance in that a) it provides \nadditional new functions or features to \nimprove software usability, performance, \nmaintainability or other software quality \nattributes, and b) it adds functionality or \nfeatures with relatively large additions \nor changes for improving software attri-\nbutes after delivery.\n\u2022\t Perfective maintenance: Modification of \na software product after delivery to pro-\nvide enhancements for users, improve-\nment of program documentation, and \nrecoding to improve software perfor-\nmance, maintainability, or other software \nattributes.\n\u2022\t Emergency maintenance: Unscheduled \nmodification performed to temporarily \nkeep a system operational, pending cor-\nrective maintenance.\n2.\t Key Issues in Software Maintenance\nA number of key issues must be dealt with to \nensure the effective maintenance of software. \nSoftware maintenance provides unique tech-\nnical and management challenges for soft-\nware engineers (e.g.,the challenge of finding \na fault in large complex software developed by \nsomeone else.)\nSimilarly, in an Agile setting, maintainers \nand developers are constantly striving to make \nsure that clients see the value at the end of \neach iteration so maintenance activities have \nto compete with the development of new fea-\ntures for client approval; Planning for a future \nrelease, which often includes coding the next \nrelease while sending out emergency patches \nfor the current release, also creates a challenge \nin balancing maintenance and development \nwork. The following section presents tech-\nnical and management issues related to soft-\nware maintenance. They are grouped under \nthe following topics:\n\u2022\t Technical issues.\n\u2022\t Management issues.\n\u2022\t Software maintenance costs.\n\u2022\t Software maintenance measurement.\n2.1.\t Technical Issues\n2.1.1\t\nLimited Understanding \n\b\n[2*, c6s6.9]\nLimited understanding describes a software \nengineer\u2019s initial comprehension of software \nsomeone else developed. This is reflected in \nhow quickly a software engineer can under-\nstand where to change or correct the soft-\nware. Research suggests a significant portion \nof total maintenance effort is devoted to \nunderstanding the software to be modified. \nConsequently, the topic of software compre-\nhension is of great interest to software engi-\nneers. A number of comprehension factors \nhave been identified: 1) domain knowledge; 2) \nprogramming practices (e.g., implementation \nissues); 3) documentation; and 4) organisation \nand presentation issues. Comprehension is \nmore difficult in text-oriented representation \n(e.g., in source code), where it is often difficult \nto trace the evolution of software through its \nreleases or versions if changes are not docu-\nmented and the developers are not available \nto explain them. Thus, software engineers \nmay initially have a limited understanding \nof the software, and much work must be \ndone to remedy this. Various techniques can \nhelp engineers understand existing software, \nsuch as visualization and reverse engineering \nusing tool-based graphical representations \nof the code.\n2.1.2\t\nTesting \n\b\n[1, s6.2][2*, c9, c13s13.4.4] \nTest planning and activities occur during MRs \nand PRs processing. The cost of repeating full \ntesting on a major piece of software is signifi-\ncant, in both time and effort. To ensure a soft-\nware modification is validated, the maintainer \nshould replicate or verify changes by planning \nand executing the appropriate tests \u2014 for \nexample, regression testing is important in \nmaintenance. Regression testing is the selec-\ntive retesting of software or a component to \nverify that the modifications have not caused \nunintended effects. Another challenge is \n", "page": 173, "type": "text", "section": "Page 173"}
{"text": "7-6   SWEBOK \u00ae GUIDE V4.0\nfinding the time to conduct as much testing \nas possible. Coordinating tests can be chal-\nlenging for maintenance team members who \nare simultaneously working on different prob-\nlems. Bringing software offline to test it can \nbe difficult if the software performs critical \nfunctions. The Software Testing KA pro-\nvides additional information and references \non software testing and its subtopic on regres-\nsion testing.\n2.1.3\t\nImpact Analysis \n\b\n[1, s5.1.6][2*, c13s13.3] \nImpact analysis assesses the detailed effects \nof proposed changes on existing software. \nSoftware engineers should strive to con-\nduct the analysis as cost-effectively as pos-\nsible. Maintainers need detailed knowledge \nof the software\u2019s structure and content. They \nuse that knowledge to perform the impact \nanalysis, which identifies all systems and \nsoftware products that would be affected by \na software change request and develops an \nestimate of the resources needed to accom-\nplish the change. The analysis also deter-\nmines the risks involved in making the \nchange. The change request (originating \nfrom an MR or a PR), must first be analyzed \nand translated into software terms. Impact \nanalysis is performed after a change request \nenters the software configuration man-\nagement (SCM) process. ISO/IEC/IEEE \n14764 [1] states that the impact analysis \ntasks do the following:\n\u2022\t Develop \nan \nidentification \nscheme \nfor MRs/PRs.\n\u2022\t Develop a scheme for categorizing and \nprioritizing MRs/PRs.\n\u2022\t Determine the procedures for an operator \nto submit an MR/PR.\n\u2022\t Identify the information needs and issues \nthat must be tracked and reported to the \nusers and identify the measures that pro-\nvide feedback on those information needs \nand issues.\n\u2022\t Determine how temporary work-arounds \nwill be provided to the operators.\n\u2022\t Track \nthe \nwork-around(s) \nthrough \nto removal.\n\u2022\t Determine what follow-up feedback will \nbe provided to the users.\nSoftware maintainers often use the severity \nof a PR as a guide when deciding how and \nwhen to fix the problem. The maintainer con-\nducts an impact analysis that identifies the \naffected components, develops several poten-\ntial solutions, and, finally, recommends a \ncourse of action.\nImpact analyses of proposed maintenance \nchanges often consider various factors such as \nthe maintenance category, the size of the mod-\nification, the cost involved, the testing needed \nto make the modification, and any impacts on \nperformance, safety and security. Designing \nsoftware with maintainability in mind greatly \nfacilitates impact analysis. More information \ncan be found in the Software Configuration \nManagement KA.\n2.1.4\t\nMaintainability \n\b\n[1, s8.8][2*, c12s12.5.5]\nISO/IEC/IEEE 14764 [1] defines main-\ntainability as the capability of the software \nproduct to be modified. Modifications can \ninclude corrections, improvements or adap-\ntation of the software to changes in environ-\nment, as well as changes in requirements and \nfunctional specifications.\nAs an important software quality char-\nacteristic, maintainability should be speci-\nfied, reviewed and controlled during software \ndevelopment activities in order to reduce \nmaintenance costs. When these activities are \ncarried out successfully, the software\u2019s main-\ntainability will benefit. Maintainability is \noften difficult to achieve because it is often not \na primary focus during software development. \nThe developers are typically more focused on \nother activities and might not pay enough \nattention to maintainability requirements. \nThis can result in bad architecturing, missing \nsoftware documentation or test environments, \nwhich is a leading cause of difficulties in pro-\ngram comprehension and subsequent impact \n", "page": 174, "type": "text", "section": "Page 174"}
{"text": "SOFTWARE MAINTENANCE   7-7\nanalysis during maintenance. The presence of \nsystematic and mature software development \nprocesses, techniques and tools helps enhance \nthe maintainability of software. The Software \nQuality KA provides additional information \nand references on software maintainability.\nCompromised software maintainability \ntypically increases the burden on software \nengineers who maintain the software in the \nfuture; in other words, it creates technical \ndebt. Technical debt often accumulates when \nthe need to quickly address corrective, emer-\ngency, and additive maintenance tasks, con-\nstrained by limited time and understanding \nof the software, leads to compromises. These \nimmediate but potentially under-considered \nsolutions, often not peer-reviewed, contribute \nto the accumulation of technical debt. This \npractice generally creates a technical debt that \nwill take additional time and effort to address \nduring maintenance. Specifically, software \nengineers must investigate three areas in \ndepth when addressing technical debt:\n1.\t Code quality versus relevance: Not all \ntechnical debt is urgent.\n2.\t Alignment with organizational objec-\ntives: The software architecture should \nreflect the organization\u2019s goals. \n3.\t Process loss: Ensure complementary \nskills of software engineers involved.\t\n2.2.\t Management Issues\n2.2.1.\t\nAlignment with Organizational \nObjectives \n\b\n[1, s9.1.8][2*, c2s2.3.1.2, c3s3.4]\nThis section describes how to optimizse soft-\nware maintenance activities and economics \nto be aligned with  organizational objectives \nand the priorities of the business, customers \nand users.\nIn many organizations, initial software \ndevelopment is project-based, with a defined \ntime scale and budget. The main goal is to \ndeliver a product that meets user needs on \ntime and within budget. In contrast, soft-\nware maintenance aims to extend the life of \nsoftware and keep it operational for as long \nas possible. In addition, it may be driven by \nthe need to meet user demand for software \nupdates and enhancements. \nIn both cases, the economics of software \nmaintenance is not as visible as those of soft-\nware development. At the organizational \nlevel, it may be seen as an activity that con-\nsumes significant resources with no clear, \nquantifiable benefit for the organization. As \na consequence, adding new features is often \ngiven higher priority than other maintenance \nactivities (such as refactoring, security or per-\nformance improvement) to meet the goals \nand objectives of software customers, as well \nas with constraints such as time and budget. \nHowever, such organizational objectives and \nconstraints must be balanced with software \nmaintainability and engineering standards to \navoid code decay and technical debt.\nApplying product management approaches \nto the management of software development \nand maintenance can help organizations:\n\u2022\t Understand the total cost of operational \nsoftware over its full life cycle.\n\u2022\t Compare the costs and benefits of devel-\noping new software versus enhancing \nexisting software.\n\u2022\t Resolve staffing and skills issues, as the \nsame team can be responsible for mainte-\nnance and development.\n\u2022\t Focus more on maintainability require-\nments from the start, as the same team \nhas responsibility for both development \nand maintenance.\n2.2.2.\t\nStaffing\b\n[1*, s6.4.13.3c] \n\b\n[2*, c2s2.3.1.5, c10s10.4]\nAlthough maintenance work is sometimes \nperceived as less engaging, this view overlooks \nthe critical importance of software main-\ntainers. Given that maintenance constitutes a \nsignificant portion of software lifecycle activi-\nties, recognizing and valuing the contribution \nof maintainers is essential to boosting morale, \nperformance, and reducing staff turnover. \n", "page": 175, "type": "text", "section": "Page 175"}
{"text": "7-8   SWEBOK \u00ae GUIDE V4.0\nOrganizations need to design development \nand maintenance teams and roles carefully \nand provide professional development oppor-\ntunities for their staff. \n2.2.3.\t\nProcess\b\n[1*, s6][2*, c5] \nThe software life cycle process is a set of \nactivities, methods, practices and transforma-\ntions that people use to develop and maintain \nsoftware and its associated products. At the \nprocess level, software maintenance activ-\nities share much in common with software \ndevelopment (e.g., SCM is a crucial activity \nin both). Maintenance also requires several \nactivities not found in software development. \n(Refer to section 3.2.)\n2.2.4.\t\nSupplier Management \n\b\n[1*, s6.1.2, s8.3, s8.8.2]\nSupplier management ensures that the orga-\nnization\u2019s suppliers and their performance are \nmanaged appropriately to support the seam-\nless provision of quality products and services \nwhen maintenance is contracted to suppliers. \nThe nature of the organization\u2019s relation-\nship with suppliers and its approach to sup-\nplier management should be determined by \nthe nature of these products and services. \nContractors can be hired to conduct main-\ntenance tasks and outsourcing or offshoring \nsoftware maintenance is a major industry. \nOutsourcing maintenance means substituting \ninternal capability with an external supplier\u2019s \ncapability. Approaches to contracting mainte-\nnance include the following:\n\u2022\t Single source or partnership: A single sup-\nplier provides all services, or an external \nservice integrator manages the organiza-\ntion\u2019s relationship with all suppliers. \n\u2022\t Multi-sourcing: Products and services \nare provided by more than one inde-\npendent supplier. These are combined \ninto a single (software-enabled) service. \nMulti-sourcing in software services is \nincreasingly common, enabled by the \ngrowth of \u201canything as a service\u201d (XaaS), \napplication \nprogramming \ninterfaces \n(APIs), and data sources. \nMany organizations outsource entire port-\nfolios of software. Typically, these portfolios \ninclude software that is not mission-critical, as \norganizations do not want to lose control of \nthe software used in their core business. One \nmajor challenge for outsourcers is determining \nthe scope of the maintenance services required, \nthe terms of a service-level agreement (SLA), \nand the contractual details. Outsourcers need \nto invest in good communication infrastruc-\nture and an efficient help desk staffed with \npeople who can communicate effectively with \ncustomers and users [3]. Outsourcing requires \na significant initial investment and the setup \nand review of software maintenance processes \nthat require automation. \n2.2.5.\t\nOrganizational Aspects of Maintenance  \n\b\n[1, s9.1.8][2*, c10]\nOrganizational \naspects \nof \nmaintenance \ninclude determining which teams will be \nresponsible for software maintenance. When \nusing Agile life cycle models, the developer \nalso conducts maintenance tasks, acting as \nboth developer and maintainer. Other organi-\nzations prefer that the team that develops the \nsoftware does not necessarily maintain it once \nit is operational. In deciding where the soft-\nware maintenance function will be located, \nsoftware engineering organizations must con-\nsider each alternative\u2019s advantages and disad-\nvantages. There are a number of disadvantages \nto having the developer also maintain the \nsoftware after it has been put into production, \nsuch as the risk that new development will be \ndisrupted when the developers need to attend \nto failures and the potential loss of knowledge \nwhen developers leave the organization, since \nfewer individuals are familiar with the soft-\nware; this could also lead to lower-quality doc-\numentation, as fewer individuals are involved. \nHowever, having a separate maintenance \nfunction also has its challenges, as many soft-\nware engineers do not like limiting their work \nto maintenance and may be more likely to \n", "page": 176, "type": "text", "section": "Page 176"}
{"text": "SOFTWARE MAINTENANCE   7-9\nleave for more interesting work. In addition, a \nhandoff process must be put in place between \ndevelopers and maintainers, which sometimes \nleads to friction between teams [3]. \nThe introduction of product manage-\nment processes has encouraged a single-team \napproach, particularly for developing and \nmaintaining software that needs to respond \nrapidly to changes in customer and user needs. \nBecause there are many pros and cons to each \noption, the decision should be made on a case-\nby-case basis. What is important is that the \norganization delegates the maintenance tasks \nto an experienced group or person and keeps \nquality documentation on maintenance tasks \nand all changes made to the software, regard-\nless of the organization\u2019s structure. \n2.3.\t  Software Maintenance Costs \nSoftware engineers must understand the dif-\nferent categories of software maintenance \ndescribed  in 1.6. Presenting costs trends by \ncategories of Maintenance can show cus-\ntomers where maintenance effort is spent for \neach system supported [7]. The data about \nmaintenance effort by category can be also \nused to accurately estimate the cost of software \nmaintenance. Cost estimation is an important \naspect of planning software maintenance.\n2.3.1. \t\nTechnical Debt Cost Estimation \n\b\n[1, s6.1.7, s8.8.3.6][2*, c12.12.5]\nTechnical debt generally makes code more \nexpensive to maintain than it has to be. \nTechnical debt represents the effort required \nto fix problems that remain in the code when \nan application is initially released by the devel-\nopment team. Several techniques and indica-\ntors can help engineers measure technical debt, \nincluding, size, complexity and the number of \nengineering flaws and violations of good archi-\ntectural design and coding practices in the \nsource code. ISO/IEC/IEEE 14764 provides \nsuggestions for improving maintainability, \nincluding: ensuring legibility, pursuing struc-\ntured code, reducing code complexity, provide \naccurate code comments, using identation and \nwhite space, eliminating language weaknesses \nand compiler dependent constructs, facilitate \nerror-tracing, ensure traceability of code to \ndesign, conduct inspections and code reviews. \nA software product needs to evolve, by adding \nnew features and capabilities, and its codebase \nmust remain maintainable, easily understood, \nand easy to further evolve. A common barrier \nto addressing technical debt \u2014 or, indeed, of \nimplementing any potential enhancement \u2014 \nis the uncertain reward for doing so. That\u2019s \nwhy it\u2019s so important for organizations to \ndetermine the following:\n\u2022\t The quality of their current software. \n\u2022\t The current cost of their technical debt. \n\u2022\t The potential savings from investing in \nquality enhancement.\n\u2022\t The impact of current quality issues on \ntheir business.\nFurthermore, technical debt is only one factor \nof several contributing to excess unplanned \nwork; team or process issues may also need to \nbe understood and addressed. Modern tooling \ncan help detect such issues, which means tech-\nnical debt should not be handled in isolation \nbut through an examination of its root causes.\n2.3.2. \t\nMaintenance Cost Estimation  \n\b\n[1, s6.2.2, s9.1.4, s9.1.9-10] \n\b\n[2*, c12s12.5.6]\nAn estimate of software maintenance costs \nshould be prepared early in the software plan-\nning process [1, c6s1.4]. The costs should be a \nfunction of the scope of maintenance activi-\nties. ISO/IEC/IEEE 14764 [1, c7s2.4] iden-\ntified various factors that should be included, \nsuch as the following:\n\u2022\t Travel to user locations.\n\u2022\t Training for maintainers as well as users.\n\u2022\t Cost and annual maintenance for the \nsoftware engineering environment (SEE) \nand software testing.\n\u2022\t Personnel costs (e.g., salaries, benefits).\n\u2022\t Other resource costs, such as consumables.\n\u2022\t Software license maintenance costs.\n", "page": 177, "type": "text", "section": "Page 177"}
{"text": "7-10   SWEBOK \u00ae GUIDE V4.0\n\u2022\t Product changes, program management.\n\u2022\t Field service engineers.\n\u2022\t Renting facilities for maintenance.\nMoreover, as the maintenance and devel-\nopment efforts progress, the estimates should \nbe amended. Historical measurement data \nshould be used as inputs to estimate main-\ntenance costs. Additionally, cost estimates \nare also required during impact analysis of \nindividual MR or PR. The cost estimating \nmethod (e.g., parametric model, comparison \nto analog systems, use of empirical and his-\ntorical data) should be described. Estimates of \nindividual MRs or PRs typically include the \nestimated effort associated with executing a \nchange, resource estimates and an estimated \ntimeline for implementing the change. \n2.4.\t Software Maintenance Measurement \n\b\n[1, s6.1.7][2*, c12]\nMeasurable software maintenance artifacts \ninclude maintenance processes, resources and \nproducts [2*, c12s12.3.1]. Measures include \nsize, complexity, quality, understandability, \nmaintainability and effort. One useful measure \nis the amount of effort (in terms of resources) \nexpended for corrective, preventive, adaptive, \nadditive and perfective maintenance. \nComplexity and technical debt measures \nof software can also be obtained using avail-\nable tools. These measures constitute a good \nstarting point for the measurement of soft-\nware quality. Maintainers should determine \nwhich measures are appropriate for a spe-\ncific organization based on that organiza-\ntion\u2019s needs. Software measurement programs \nare discussed in the Software Engineering \nManagement KA.\nThe software quality model described in \nthe Software Quality KA describes software \nproduct and process measures specific to soft-\nware maintenance. Measurable characteristics \nof maintainability include the following:\n\u2022\t Modularity measures the degree to which \na system or software is composed of com-\nponents that are independent, such that \na change to one component has minimal \nimpact on other components.\n\u2022\t Reusability measures how well a compo-\nnent can be reused.\n\u2022\t Analyzability measures the effort or \nresources the maintainer must expend \neither to diagnose deficiencies or causes \nof failure or to identify components to \nbe modified.\n\u2022\t Modifiability measures the maintain-\ner\u2019s effort associated with implementing \na specified modification without intro-\nducing defects or degrading existing \nproduct quality.\n\u2022\t Testability measures the effort main-\ntainers and users expend to test the mod-\nified software.\n\u2022\t Supportability measures the ease with \nwhich support can be provided for the \nsoftware, encompassing the availability \nand accessibility of documentation, tools, \nand assistance for addressing issues, \nfacilitating effective maintenance and \ntroubleshooting.\nOther measures that software maintainers \nuse include the following:\n\u2022\t Reliability: The degree to which a system \nor software performs specific functions \nunder specified conditions for a spec-\nified period, including the following \ncharacteristics:\no\tMaturity: How well a system or soft-\nware can meet the need for reliability.\no\tAvailability: Whether a system or soft-\nware is operational and accessible.\no\tFault tolerance: How well a system or \nsoftware operates despite hardware or \nsoftware faults.\no\tRecoverability: How well a system or \nsoftware can recover data during an \ninterruption or failure.\n\u2022\t Size of the software (e.g., functional \nsize, LOC).\n\u2022\t Number of maintenance requests, by \ntime period.\n", "page": 178, "type": "text", "section": "Page 178"}
{"text": "SOFTWARE MAINTENANCE   7-11\n\u2022\t Effort per maintenance request.\n\u2022\t Software characteristics (e.g., platform, \nhardware, \nprogramming \nlanguage, \nframeworks).\nMaintenance measures may be collected, \nanalyzed and trended by category to facil-\nitate improvement and to provide insight \ninto where maintenance costs are expended. \nThe degree of software maintenance effort \nexpended for different applications, listed \nby category, is valuable business informa-\ntion for users and their organizations. It \ncan also enable the organization to make an \ninternal comparison of software maintenance \nprofiles [7].\n3.\t Software Maintenance Processes\nIn addition to standard software engineering \nprocesses and activities described in ISO/\nIEC/IEEE 14764 [1], a number of activities \nare unique to maintainers (refer to section 3.2).\n3.1.\t Software Maintenance Processes \n\b\n[1, s5.2][2*, c5] \nMaintenance processes provide needed activ-\nities and detailed inputs and outputs to those \nactivities, as described in ISO/IEC/IEEE \n14764 [1]. Maintenance is one of the technical \nlife cycle processes presented in ISO/IEC/\nIEEE 12207 [10]. Figure 7.3 shows how main-\ntenance processes connect to other software \nengineering processes, which interact to sup-\nport operational software. The software main-\ntenance processes includes the following:\n\u2022\t Prepare for maintenance. \n\u2022\t Perform maintenance.\n\u2022\t Perform logistics support.\n\u2022\t Manage results of maintenance and \nlogistics.\nRecently, Agile methodologies, which pro-\nmote lightweight processes, have also been \nadapted to maintenance. This requirement \nhas emerged from the ever-increasing demand \nfor fast turnaround of maintenance services. \nImprovement to the software maintenance \nprocesses is supported by software mainte-\nnance maturity models [3].\n3.2.\t Software Maintenance Activities and Tasks \n\b\n[1, s6.1][2*, c6, c7] \nThe maintenance process contains the activi-\nties and tasks necessary to operate and modify \nan existing software system while preserving \nits integrity. These activities and tasks are the \nresponsibility of the operator and the main-\ntainer. As already noted, many maintenance \nactivities are similar to those of software \ndevelopment. Maintainers perform anal-\nysis, design, coding, testing and documenta-\ntion. They must track requirements in their \nactivities \u2014 just as in development \u2014 and \nupdate documentation as baselines change. \nSoftware Maintenance Process\nPrepare for \nMaintenance\nPerform\nLogistic\nSupport\nManage Results \nof  Maintenance \nand Logistics\nDisposal\nTransition\nOperation\nDevelopment\nPerform \nMaintenance\nFigure 7.3. Software Maintenance Processes (ISO/IEC/IEEE 14764) [1]\n", "page": 179, "type": "text", "section": "Page 179"}
{"text": "7-12   SWEBOK \u00ae GUIDE V4.0\nISO/IEC/IEEE 14764 recommends that \nwhen a maintainer uses a development pro-\ncess, the process must be tailored to meet spe-\ncific needs. \nHowever, there are a number of processes, \nactivities and practices that are specialized to \nsoftware maintenance:\n\u2022\t Program understanding: This comprises \nthe activities needed to obtain a general \nknowledge of what a software product \ndoes and how the parts work together.\n\u2022\t Transition: This is a controlled and coor-\ndinated sequence of activities during \nwhich software is transferred progres-\nsively from the developer to the opera-\ntions and maintenance team.\n\u2022\t MR acceptance/rejection: Modifications \nrequesting work greater than the agreed \nsize, level of effort, or level of complexity \nmay be rejected by maintainers and \nrerouted to a developer. \n\u2022\t Maintenance help desk: The help desk \nis an end-user and maintenance-coordi-\nnated support function that triggers the \nassessment, prioritization and costing of \nMRs and incidents. \n\u2022\t Impact analysis: The impact analysis \nidentifies areas impacted by a poten-\ntial change.\n\u2022\t Maintenance \nservice-level \nindicators \n(SLIs), service-level objectives (SLOs), \nSLAs, and maintenance software and \nhardware licenses and contracts: These \nare contractual agreements that describe \nthe services and quality objectives of \nthird parties.\n3.2.1.\t\nSupporting and Monitoring Activities  \n\b\n[s6.4.13.3d5, s6.1.8][2*, c3s3.4]\nMaintainers may also perform ongoing sup-\nport activities, such as documentation, SCM, \nverification and validation (V&V), problem \nresolution, software quality assurance (SQA), \nreviews, vulnerability assessments, and audits. \nAnother important management of mainte-\nnance results activity is that of monitoring \ncustomer satisfaction.\n3.2.2.\t\nPlanning Activities \n\b\n[1, s6.1.3, s8.7.2][2*, c10]\nAn important activity for software main-\ntenance is planning, and this process must \naddress the issues associated with a number \nof planning perspectives, including the \nfollowing:\n\u2022\t Business planning (organizational level)\n\u2022\t Maintenance planning (transition level).\n\u2022\t Release/version planning (software level).\n\u2022\t MR planning (at individual request level).\nAt the individual request level, planning is \ncarried out during the impact analysis. (See \nsection 2.1.3, Impact Analysis.) The release/\nversion planning activity requires that the \nmaintainer do the following:\n\u2022\t Collect the dates of availability of indi-\nvidual requests.\n\u2022\t Agree with users on the content of sub-\nsequent releases/versions.\n\u2022\t Identify potential conflicts and develop \nalternatives.\n\u2022\t Assess the risk of a given release \nand develop a back-out plan in case \nproblems arise\n\u2022\t Inform all stakeholders.\nWhereas software development projects \nhave a typical duration of months to a few \nyears, the maintenance phase usually lasts until \nthe software is retired by the disposal process. \nEstimating resources is a key element of main-\ntenance planning. Software maintenance plan-\nning should begin with the decision to develop \na new software product and should consider \nquality objectives. A concept document should \nbe developed, followed by a maintenance plan, \nand these should address the following:\n\u2022\t Scope of software maintenance.\n\u2022\t Adaptation of the software maintenance \nprocesses and tools.\n\u2022\t Identification of the software mainte-\nnance organization.\n\u2022\t Estimate of software maintenance costs.\n", "page": 180, "type": "text", "section": "Page 180"}
{"text": "SOFTWARE MAINTENANCE   7-13\nA software maintenance plan should be \nprepared during software development and \nshould specify how users will request mod-\nifications and report problems or issues. \nSoftware maintenance planning is addressed \nin ISO/IEC/IEEE 14764 [1]. Finally, at the \nhighest level of management, the maintenance \norganization must conduct software mainte-\nnance business planning activities (e.g., com-\nmunications, budgetary, financial and human \nresources activities). [2*, c10]\n3.2.3.\t\nConfiguration Management \n\b\n[1, s6.1.3c, s6.4.13.3d4][2*, c11s11.3] \nISO/IEC/IEEE 14764 [1] describes SCM \nas an enabling system or service to support \nthe maintenance process. SCM procedures \nshould provide for the verification, valida-\ntion and audit of each step required to iden-\ntify, authorize, implement and release the \nsoftware product and its IT assets under-\ngoing change. \nIt is not sufficient to track MRs or PRs \nonly. Any change made to the software \nproduct and its underlying infrastructure \nmust be controlled. This control is established \nby implementing and enforcing an approved \nSCM process. The SCM KA discusses SCM \nin more detail as well as the process by which \nchange requests are submitted, evaluated and \napproved. SCM for software maintenance \ndiffers from SCM for software development \nin the number of small changes that must be \ncontrolled in the operational environment. \nThe SCM process is implemented by devel-\noping and following an SCM plan and oper-\nating procedures. Maintainers participate in \nconfiguration control boards to determine \nthe content of the next release or version in \nproduction.\n3.2.4.\t\nSoftware Quality \n\b\n[1, s6.1.6, s8.7.2][2*, c13s13.4]\nIt is not sufficient to simply hope that soft-\nware maintenance will produce higher quality \nsoftware. Maintainers should have an effec-\ntive quality program. They must implement \nprocesses to support the continuous improve-\nment of software maintenance processes. The \nactivities and techniques for SQA, V&V, \nreviews, and audits must be selected in con-\ncert with all the other processes to achieve \nthe desired level of quality. It is also recom-\nmended that both software operations and \nmaintenance adapt and use the output of the \nsoftware development process, its techniques \nand deliverables (e.g., test tools and documen-\ntation), and test results. More details about \nsoftware quality can be found in the Software \nQuality KA.\n4.\t Software Maintenance Techniques\nThis topic introduces generally accepted tech-\nniques used in software maintenance.\n4.1.\t Program Comprehension \n\b\n[2*, c6, c14s14.5]\nMaintainers spend considerable time reading \nand understanding programs in order to \nimplement changes. Code browsers are key \ntools for program comprehension and are used \nto organize and present source code. Clear \nand concise documentation also aids program \ncomprehension.\n4.2.\t  Software Reengineering \n\b\n [2*, c7]\nSoftware reengineering refers to the examina-\ntion and alteration of software to reconstitute \nit in a new form. It includes the subsequent \nimplementation of the new form. It is often \nundertaken not to improve maintainability \nbut to replace aging legacy software. \nRefactoring is a reengineering technique \nthat aims to reorganize a program without \nchanging its behavior. Refactoring seeks to \nimprove the internal structure and the main-\ntainability of software. Refactoring tech-\nniques can be used during maintenance \nactivities to reduce the technical debt of the \ncodebase before and after code changes.\nIn the context of Agile software develop-\nment, the incremental nature of continuous \n", "page": 181, "type": "text", "section": "Page 181"}
{"text": "7-14   SWEBOK \u00ae GUIDE V4.0\nintegration (CI) often requires the code to \nbe continuously refactored to augment its \nquality and reliability. Hence, continuous \nrefactoring supports the volatile software \nlife cycle by providing better ways to reduce \nand manage the growing complexity of soft-\nware systems while improving developer \nproductivity.\n4.3.\t Reverse Engineering \n\b\n[2*, c7, c14s14.5]\nReverse engineering is the process of ana-\nlyzing software to identify the software\u2019s \ncomponents and their interrelationships \nand creating representations of the soft-\nware in another form or at higher levels of \nabstraction. Reverse engineering is passive; \nit does not change the software or result in \nnew software. Reverse engineering efforts \ntypically produce graphical representations \nof different software artifacts, such as call \ngraphs and control flow graphs from source \ncode. Types of reverse engineering include \nthe following:\n\u2022\t Re-documentation.\n\u2022\t Design recovery. \n\u2022\t Data reverse engineering \u2014 recovering \nlogical schemata from physical databases.\nTools are key for reverse engineering and \nrelated tasks such as re-documentation and \ndesign recovery. Software visualization is \na common reverse engineering technique \nthat helps maintainers explore, analyze and \nunderstand the structure of software systems \nas well as their evolution. Software visual-\nization comprises visually encoding and ana-\nlyzing software systems, including software \nmaintenance practices, evolution, structure \nand software runtime behavior using infor-\nmation visualization, computer graphics and \nhuman-computer \ninteraction. \nGenerally, \nsoftware visualization tools are accompanied \nby various quality assurance features, such \nas quality metrics calculation, technical debt \nestimation, and bad design and coding prac-\ntices (code smells) detection. \n4.4.\t Continuous Integration, Delivery, Testing \nand Deployment\b\n[1, s6.4.13.3 Note 1]\nAutomating \ndevelopment, \noperation \nand \nmaintenance-related tasks saves engineering \nresources. When implemented appropriately, \nsuch automated tasks are generally faster, easier \nand more reliable than they would be if per-\nformed manually. ISO14764 states that auto-\nmation includes distribution and installation of \nsoftware.[1, s6.4.13.3 Note 1]. DevOps supports \nsuch automation while building, packaging and \ndeploying reliable and secure systems. DevOps \ncombines development, operations, and main-\ntenance resources and procedures to perform \nCI, delivery, testing and deployment. [9]\nCI is a software engineering practice that \ncontinually merges artifacts, including source \ncode updates from all members of a team, into \na shared mainline for evolving and testing the \ndeveloped system. With CI, the members of \na team can integrate their changes frequently, \nand each integration can be verified by an \nautomated build (including testing) to detect \nintegration errors as quickly as possible. The \nfundamental goal of CI is to automatically \ncatch problematic changes as early as pos-\nsible. CI helps guarantee the working state of \na software system at various points from build \nto release, thereby improving confidence and \nquality in software products and improving \nproductivity in teams. Specifically, CI auto-\nmates the build and release processes with \ncontinuous build, continuous delivery, contin-\nuous testing and continuous deployment. [6, \nc23, c24].\nContinuous delivery is a software engi-\nneering practice that enables frequent releases \nof new systems (including software) to staging \nor various test environments through the use \nof automated tools. Continuous delivery con-\ntinuously assembles the latest code and config-\nuration to create release candidates. \nContinuous testing is a software testing prac-\ntice that involves testing the software at every \nstage of the software development life cycle. \nThe goal of continuous testing is to evaluate \nthe quality of software at every step of the \ncontinuous delivery process by testing early \n", "page": 182, "type": "text", "section": "Page 182"}
{"text": "SOFTWARE MAINTENANCE   7-15\nand often. Continuous testing involves var-\nious stakeholders such as developers, main-\ntainers, DevOps, SQA, and operational \nsystems teams.\nContinuous deployment is an automated pro-\ncess of deploying changes to production by \nverifying intended features and validations to \nreduce risk. As Martin Fowler, in the book \nContinuous Delivery, pointed out, \u201cThe biggest \nrisk to any software effort is that you end up \nbuilding something that isn\u2019t useful. The ear-\nlier and more frequently you get working soft-\nware in front of real users, the quicker you get \nfeedback to find out how valuable it really is.\u201d\n4.5.\t Visualizing Maintenance\nMaintaining a clear understanding of soft-\nware systems\u2019 evolving structures and depen-\ndencies presents a challenge. Visualization is \na valuable supporter in software maintenance \nmanagement, offering a visual representation \nof the software\u2019s components and helping it \nmake informed decisions. With the increasing \nsize and complexity of software systems, visual \nrepresentations can support software mainte-\nnance by enabling dependency analysis, tracing \na software evolution history, visualizing soft-\nware runtime dynamics, and providing com-\nplementary \ndocumentation. \nVisualization \nrepresents an active research area that syner-\ngizes computational capabilities with human \npattern detection abilities. It produces visual \nrepresentations designed to enhance the main-\ntenance team\u2019s cognitive performance when \nfaced with complex data analysis.\n5.\t Software Maintenance Tools \n\b\n [1, c6s4][2*, c14] \nThis topic encompasses tools that are par-\nticularly important in software maintenance \nwhere existing software is being modified. \nMaintenance tools are interrelated with \ndevelopment and operations tools. Together, \nthey are part of the SEE. The following are \nexamples of maintenance tools:\n\u2022\t Configuration management, code ver-\nsioning and code review tools,\n\u2022\t software testing tools,\n\u2022\t Software quality assessment tools (to \nassess technical debt and code quality). \n\u2022\t Program slicers, which select only the \nparts of a program affected by a change.\n\u2022\t Static analyzers, which allow gen-\neral viewing and summaries of pro-\ngram content.\n\u2022\t Dynamic analyzers, which allow the \nmaintainer to trace the execution path of \na program.\n\u2022\t Data flow analyzers, which allow the \nmaintainer to track all possible data flows \nof a program.\n\u2022\t Cross-referencers, which generate indexes \nof program components.\n\u2022\t Dependency analyzers, which help main-\ntainers analyze and understand the inter-\nrelationships among components of \na program.\n\u2022\t Remote Access tools, enabling main-\ntainers to diagnose and modify user sys-\ntems remotely, crucial for real-time issue \nresolution and seamless modifications \nacross environments.\nReverse engineering tools support the pro-\ncess by working backward from an existing \nproduct to create artifacts such as specifica-\ntion and design descriptions, which can then \nbe transformed to generate a new product \nfrom an old one. Maintainers also use soft-\nware tests, SCM, software documentation \nand software measurement tools.\n", "page": 183, "type": "text", "section": "Page 183"}
{"text": "7-16   SWEBOK \u00ae GUIDE V4.0\nMATRIX OF TOPICS VS. REFERENCE MATERIAL\nISO/IEC/IEEE \n14764 2022 [1] \nGrubb and \nTakang 2003 [2*]\n1. Software Maintenance Fundamentals\n1.1. Definitions and Terminology\ns3.1\nc1s1.2, c2s2.2\n1.2. Nature of Software Maintenance\nc1s1.3\n1.3. Need for Software Maintenance\nc1s1.5\n1.4. Majority of Maintenance Costs\nc4s4.3, c5s5.2\n1.5. Evolution of Software\nc3s3.5\n1.6. Categories of Software Maintenance \ns3.1.8\nc1s1.8, c3s3.3\n2. Key Issues in Software Maintenance\n2.1. Technical Issues\n2.1.1. Limited Understanding\nc6s6.9\n2.1.2. Testing\ns6.2\nc9, c13s13.4.4\n2.1.3. Impact Analysis\ns5.1.6\nc13s13.3\n2.1.4. Maintainability\ns8.8\nc12s12.5.5\n2.2. Management Issues\n2.2.1. Alignment with Organizational Objectives\ns9.1.8\nc2s2.3.1.2, c3s3.4\n2.2.2. Staffing\ns6.4.13.3c\nc2s2.3.1.5, c10s10.4\n2.2.3. Process\ns6\nc5\n2.2.4. Supplier Management\ns6.1.2, s8.3, s8.8.2\n2.2.5. Organizational Aspects of Maintenance\ns9.1.8\nc10\n2.3. Maintenance Costs \n2.3.1. Technical Debt Cost Estimation\ns6.1.7, s8.8.3.6\nc12s12.5\n2.3.2. Maintenance Costs Estimation \ns6.2.2, \ns9.1.4, s9.1.9-10\nc12s12.5.6\n2.4. Software Maintenance Measurement\ns6.1.7\nc12\n3. Software Maintenance Process\n3.1. Software Maintenance Processes \ns5.2\nc5\n3.2. Software Maintenance Activities and Tasks\ns6.1\nc6, c7\n3.2.1. Supporting and Monitoring Activities\ns6.4.13.3d5, s6.1.8\nc3s3.4\n3.2.2. Planning Activities\ns6.1.3, s8.7.2\nc10\n3.2.3. Software Configuration Management\ns6.1.3c, s6.4.13.3d4\nc11s11.3\n3.2.4. Software Quality\ns6.1.6, s8.7.2\nc13s13.4\n4. Software Maintenance Techniques \n4.1. Program Comprehension\nc6,c14s14.5\n4.2. Software Reengineering\nc7\n4.3. Reverse Engineering\nc7, c14s14.5\n", "page": 184, "type": "text", "section": "Page 184"}
{"text": "SOFTWARE MAINTENANCE   7-17\n4.4. Continuous Integration, Delivery, Testing and \nDeployment\ns6.4.13.3 Note 1\n4.5. Visualizing Maintenance\n5. Software Maintenance Tools \ns4\nc14\nFURTHER READINGS\nA. April and A. Abran, Software Maintenance \nManagement: Evaluation and Continuous \nImprovement [3].\nThis book explores the domain of contin-\nuous software maintenance processes. It \nprovides road maps for improving soft-\nware maintenance processes in organiza-\ntions. It describes software maintenance \npractices organized by maturity levels, \nwhich allow for benchmarking and con-\ntinuous improvement. Goals for each key \npractice area are provided, and the pro-\ncess model presented is fully aligned with \nthe architecture and framework of inter-\nnational standards ISO12207, ISO14764 \nand ISO15504, as well as  models such as \nITIL and CoBIT.\nIEEE std 2675-2021, IEEE Standard for \nDevOps: Building Reliable and Secure Systems \nIncluding Application Build, Package and \nDeployment [5].\nTechnical principles and processes to build, \npackage, and deploy systems and applica-\ntions in a reliable and secure way are speci-\nfied. Establishing effective compliance and \ninformation technology (IT) controls is the \nfocus. DevOps principles presented include \nmission first, customer focus, shift-left, con-\ntinuous everything, and systems thinking. \nHow stakeholders, including developers and \noperations staff, can collaborate and commu-\nnicate effectively is described. The process \noutcomes and activities herein are aligned \nwith the process model specified in ISO/\nIEC/IEEE 12207:2017 and ISO/IEC/IEEE \n15288:2015.\nREFERENCES \n[1]\t IEEE standard, ISO/IEC/IEEE \n14764 IEEE Std. 14764:2022, Software \nEngineering \u2014 Software Life Cycle \nProcesses \u2014 Maintenance, third ed: \n2022 01, 39p.\n[2*]\tP. Grubb and A.A. Takang, Software \nMaintenance: Concepts and Practice, 2nd \ned. River Edge, NJ: World Scientific \nPublishing, 2003.\n[3]\t A. April and A. Abran, Software \nMaintenance Management: Evaluation \nand Continuous Improvement. Wiley-\nIEEE Computer Society Press, 2008.\n[4]\t C. Seybold and R. Keller, Aligning \nSoftware Maintenance to the Offshore \nReality, 12th European Conference \non Software Maintenance and \nReengineering. April 1-4, 2008, \nAthens, Greece, DOI:10.1109/\nCSMR.2008.4493298.\n[5]\t IEEE standard, IEEE Std. 2675-\n2021, IEEE Standard for DevOps: \nBuilding Reliable and Secure Systems \nIncluding Application Build, Package and \nDeployment, ed: IEEE. 2021.\n[6] \t W. Titus, T. Manshreck, and H. \nWright. Software engineering at Google: \nLessons learned from programming over \ntime. O\u2019Reilly Media, 2020.\n[7]\t A. Abran and H. Nguyenkim, \nMeasurement of the maintenance pro-\ncess from a demand-based perspec-\ntive, Journal of Software Maintenance: \n", "page": 185, "type": "text", "section": "Page 185"}
{"text": "7-18   SWEBOK \u00ae GUIDE V4.0\nResearch and Practice, Vol. 5 Issue 2: \n63-90, 1993.\n[8]\t \u201cLaws of software evolution revisited.\u201d \nEuropean workshop on software process \ntechnology. Berlin, Heidelberg: Springer \nBerlin Heidelberg, 1996\u201d\n[9]\t J. Humble and D. Fairley, Continuous \nDelivery: Reliable Software Releases \nthrough Build, Test, and Deployment \nAutomation, Addison-Wesley, 2010.\n[10]\tISO/IEC/IEEE 12207:2017 Systems \nand software engineering \u2014 Software life \ncycle processes, 2017.\n", "page": 186, "type": "text", "section": "Page 186"}
{"text": "8-1 \nCHAPTER 08\nSoftware Configuration \nManagement\nACRONYMS\nCCB\nConfiguration Control Board\nCI \nConfiguration Item\nCM\nConfiguration Management\nFCA\nFunctional Configuration Audit\nPCA\nPhysical Configuration Audit\nQA\nQuality Assurance\nSCCB\nSoftware Configuration \nControl Board\nSCI\nSoftware Configuration Item\nSCM\nSoftware Configuration Management\nSCMP\nSoftware Configuration \nManagement Plan\nSCR\nSoftware Change Request\nSCSA\nSoftware Configuration Status \nAccounting\nCMMI\nSoftware Engineering Institute\u2019s \nCapability Maturity Model \nIntegration\nSLCP\nSoftware Life Cycle Process\nSQA\nSoftware Quality Assurance\nV&V\nVerification And Validation\nKA\nKnowledge Area\nMBX\nModel Based Experience\nSBOM\nSoftware Bill Of Materials\nCR\nChange Request\nVDD\nVersion Description Document\nCMDB\nConfiguration \nManagement Database\nINTRODUCTION\nSoftware configuration management (SCM) \nis formally defined as \u201cthe process of applying \nconfiguration management [CM] throughout \nthe software life cycle to ensure the com-\npleteness and correctness of CIs [configura-\ntion items],\u201d with CM defined as \u201ca discipline \napplying technical and administrative direc-\ntion and surveillance to identify and document \nthe functional and physical characteristics of \na configuration item, control changes to those \ncharacteristics, record and report change pro-\ncessing and implementation status, and verify \ncompliance with specified requirements\u201d [1]. \nSCM is a software life cycle process (SLCP) \nthat supports project management, devel-\nopment and maintenance activities, quality \nassurance (QA) activities, and the customers \nand users of the end product. \nThe concepts of CM apply to all items \ncontrolled, although some differences exist \nbetween implementing hardware CM and \nimplementing software CM. CM applies \nequally to iterative and incremental software \ndevelopment methodology.\nSCM is closely related to software quality \nassurance (SQA). As defined in the Software \nQuality knowledge area (KA), SQA processes \nensure that the software products and pro-\ncesses in the project life cycle conform to their \nspecified requirements by requiring software \nengineers to plan, enact and perform a set of \nactivities that demonstrate that those specifica-\ntions are built into the software. SCM activi-\nties support these SQA goals through software \nconfiguration activities (presented later in this \nchapter). The configuration audit activity can be \ndescribed as a review of CIs and is closely related \nto the reviews defined in the quality plan. \nThe SCM activities should operationalize \nSCM process management and planning, soft-\nware configuration identification, software con-\nfiguration change control, software configuration \n", "page": 187, "type": "text", "section": "Page 187"}
{"text": "8-2   SWEBOK \u00ae GUIDE V4.0\nstatus accounting (SCSA), software configura-\ntion auditing, and software release management \nand delivery. This operationalization:\n1.\t Determines what is expected to be under \ncontrol during project development\n2.\t Identifies and records who developed what \nCI as well as when and where it is allocated\n3.\t Allows controlled changes\n4.\t Tracks \nCIs\u2019 \nrelationships \nto \nshow \nhow changes that affect one CI might \naffect other CIs\n5.\t\nKeeps CI versions under control\n6.\t Ensures that the quality of the CIs delivered \nmeets the requirements for intended use\nThe SCM KA is related to all other KAs \nbecause SCM\u2019s object is the artifact produced \nand used throughout the software engi-\nneering process.\nBREAKDOWN OF TOPICS FOR \nSOFTWARE CONFIGURATION \nMANAGEMENT\nFigure 8.1 shows the breakdown of topics for \nthe SCM KA.\n1.\t Management of the SCM Process  \n\b\n[2*, c6, c7]\nSCM controls the evolution and integrity of \na product by identifying its elements (known \nas CIs); managing and controlling change; \nand verifying, recording and reporting on \nconfiguration information. From the soft-\nware engineer\u2019s perspective, SCM facilitates \ndevelopment and change implementation \nactivities. Successful SCM implementation \nrequires careful planning and management, \nwhich requires a strong understanding of \nthe organizational context for, and the con-\nstraints placed on, the design and imple-\nmentation of the SCM process. The SCM \nplan can be developed once for the organi-\nzation and then adjusted as needed for indi-\nvidual projects.\n1.1\t Organizational Context for SCM  \n\b\n[2*, c6, ann. D] [3*, Introduction] \n \n\b\n[4*, c25]\nTo plan an SCM process for a project, it is \nnecessary to understand the organizational \ncontext and the relationships among orga-\nnizational elements. SCM interacts not just \nSoftware Con\ufb01guration \nManagement\nOrganizational\nContext for SCM\nConstraints and\nGuidance for the\nSCM Process\nPlanning for SCM\nIdentifying Items\nto be Controlled\nRequesting, Evaluating\nand Approving\nSoftware Changes\nSoftware\nCon\ufb01guration Status\nInformation\nSoftware\nCon\ufb01guration Status\nReporting\nSoftware Functional\nCon\ufb01guration Audit\nSoftware Physical\nCon\ufb01guration Audit\nIn-process Audits\nof a Software\nBaseline\nSoftware Building\nSoftware Release\nManagement\nImplementing\nSoftware Changes\nDeviations and\nWaivers\nSoftware\nCon\ufb01guration\nControl Board\nSoftware Change\nRequest Process\nSoftware Change\nRequest Forms\nDe\ufb01nition\nCon\ufb01guration \nItem Identi\ufb01ers \nand Attributes\nBaselines \nIdenti\ufb01cation\nBaseline Attributes\nRelationships Scheme\nDe\ufb01nition\nSoftware Libraries\nSoftware\nCon\ufb01guration\nSoftware\nCon\ufb01guration\nItem\nSCM Organization\nand Responsibilities\nSCM Resources \nand Schedules\nTool Selection and\nImplementation\nVendor/\nSubcontractor\nControl\nInterface Control\nSCM Plan\nSurveillance of\nSoftware Con\ufb01guration\nManagement SCM \nMeasures and Measurement\nIn-Process Audits of SCM\nManagement of\nthe SCM Process\nSoftware\nCon\ufb01guration\nIdenti\ufb01cation\nSoftware\nCon\ufb01guration\nChange Control\nSoftware\nCon\ufb01guration\nStatus Accounting\nSoftware\nCon\ufb01guration\nAuditing\nSoftware Release\nManagement\n and Delivery\nSoftware\nCon\ufb01guration\nManagement Tools\nFigure 8.1. Breakdown of Topics for the Software Configuration Management KA.\n", "page": 188, "type": "text", "section": "Page 188"}
{"text": "SOFTWARE CONFIGURATION MANAGEMENT   8-3\nwith the particular project but also with sev-\neral other areas of the organization. \nThe organizational elements responsible \nfor software engineering supporting pro-\ncesses might be structured in various ways. \nThe overall responsibility for SCM often \nrests with a distinct part of the organization \nor with a designated individual. However, \nresponsibility for certain SCM tasks might \nbe assigned to other parts of the organization \n(such as the development division). \nSoftware is frequently developed as part \nof a larger system containing hardware and \nfirmware elements. In this case, SCM activ-\nities take place in parallel with hardware and \nfirmware CM activities and must be con-\nsistent with system-level CM. Note that \nfirmware contains hardware and software; \ntherefore, both hardware and software CM \nconcepts apply.\nSCM might interface with an organiza-\ntion\u2019s QA activity on issues such as records \nmanagement and nonconforming items. \nRegarding the former, project records subject \nto provisions of the organization\u2019s QA pro-\ngram might also be under SCM control. The \nQA team is usually responsible for managing \nnonconforming items. However, SCM might \nassist with tracking and reporting on software \nconfiguration items (SCIs) in this category.\nPerhaps the closest relationship is with \nthe software development and maintenance \norganizations. It is within this context that \nmany of the software configuration control \ntasks are conducted. Frequently, the same \ntools support development, maintenance, and \nSCM purposes.\n1.2\t Constraints and Guidance for the  \nSCM Process  \n\b\n[2*, c6, ann. D, ann. E] [3*, \n \n\b\nc2, c5] [5, c19s2.2] \nConstraints affecting, and guidance for, \nthe SCM process come from many sources. \nPolicies and procedures set forth at corporate \nor other organizational levels might influence \nor prescribe the design and implementation of \nthe SCM process for a project. In addition, \nthe contract between the acquirer and the \nsupplier might contain provisions affecting \nthe SCM process (e.g., certain configura-\ntion audits might be required, or the contract \nmight specify that certain items be placed \nunder CM). When the software to be devel-\noped could affect public safety, external regu-\nlatory bodies may impose constraints. Finally, \nthe SLCP chosen for a software project and \nthe level of formalism selected for imple-\nmentation will also affect SLCP design and \nimplementation. \nSoftware engineers can also find guid-\nance for designing and implementing an \nSCM process in \u201cbest practice,\u201d as reflected \nin the software engineering standards issued \nby the various standards organizations. (See \nAppendix B for more information about these \nstandards.)\n1.3\t Planning for SCM  \n\b\n[2*, c6, ann. D, ann. E] [3*, c23] \n \n\b\n[4*, c25]\nSCM process planning for a project should \nbe consistent with the organizational context, \napplicable constraints, commonly accepted \nguidance and the nature of the project (e.g., \nsize, safety criticality and security). The major \nactivities covered in the plan are software con-\nfiguration identification, software configura-\ntion control, SCSA, software configuration \nauditing, and software release management \nand delivery. In addition, issues such as orga-\nnization and responsibilities, resources and \nschedules, tool selection and implementa-\ntion, vendor and subcontractor control, and \ninterface control are typically considered. The \nplanning activity\u2019s results are recorded in an \nSCM plan (SCMP), which is subject to SQA \nreview and audit.\nBranching and merging strategies should \nbe carefully planned and communicated \nbecause they affect many SCM activities. \nSCM defines a branch as a set of evolving \nsource file versions [1]. Merging consists of \ncombining different changes to the same file \n[1]. This typically occurs when more than \none person changes a CI. There are many \n", "page": 189, "type": "text", "section": "Page 189"}
{"text": "8-4   SWEBOK \u00ae GUIDE V4.0\nbranching and merging strategies in common \nuse. (See the Further Readings section for \nadditional discussion.)\nThe software development life cycle model \nchosen (see Software Life Cycle Models in \nthe Software Engineering Process KA) also \naffects SCM activities, and SCM planning \nshould consider this. For instance, many soft-\nware development approaches use continuous \nintegration, which is characterized by fre-\nquent build-test-deploy cycles. Clearly, SCM \nactivities must be planned accordingly. \n1.3.1\t SCM Organization and Responsibilities \n\b [2*, ann. Ds5-6] [3*, c10-11] [4*, c25] \nOrganizational roles must be clearly identi-\nfied to prevent confusion about who will per-\nform specific SCM activities or tasks. These \nresponsibilities must also be assigned to orga-\nnizational entities; this can be made clear by \nthe responsible individual\u2019s title or by des-\nignating the organizational division or sec-\ntion in addition to the individual responsible \nwithin that section. The overall authority and \nreporting channels for SCM should also be \nidentified, although this might be accom-\nplished at the project management or the QA \nplanning stage.\n1.3.2\t SCM Resources and Schedules \n\b\n[2*, ann. Ds8] [3*, c23]\nPlanning for SCM identifies the resources \n\u2014 including staff and tools \u2014 involved in \ncarrying out SCM activities and tasks. It \nalso identifies the necessary sequences of \nSCM tasks and establishes each task\u2019s place \nin the project schedule and its position rela-\ntive to milestones established at the project \nmanagement planning stage. Any training \nrequirements for implementing the plans and \ntraining new staff members are also specified.\n1.3.3\t Tool Selection and Implementation \n\b\n[3*, c26s2, c26s6]\nAs in any area of software engineering, the \nselection and implementation of SCM tools \nshould be carefully planned. The following \nquestions should be considered:\n\u2022\t Organization: What motivates tool acqui-\nsition from an organizational perspective?\n\u2022\t Tools: Can we use commercial tools, or \ndo we need to develop our own tools spe-\ncifically for this project?\n\u2022\t Environment: What constraints are \nimposed by the organization and its tech-\nnical context?\n\u2022\t Legacy: How will projects use (or not \nuse) the new tools?\n\u2022\t Financing: Who will pay for the tools\u2019 \nacquisition, maintenance, training and \ncustomization?\n\u2022\t Scope: How will the new tools be deployed \n\u2014 for instance, through the entire orga-\nnization or only on specific projects?\n\u2022\t Ownership: Who is responsible for intro-\nducing new tools?\n\u2022\t Future: What is the plan for the tools\u2019 use \nin the future?\n\u2022\t Change: How adaptable are the tools?\n\u2022\t Branching and merging: Are the tools\u2019 \ncapabilities compatible with planned \nbranching and merging strategies?\n\u2022\t Integration: Do the various SCM tools \nintegrate among themselves? Do they \nintegrate with other tools in use in the \norganization?\n\u2022\t Migration: Can the repository maintained \nby the version control tool be ported to \nanother version control tool while main-\ntaining the complete history of the CIs \nit contains?\nSCM requires a set of tools instead of \na single tool. Such tool sets are sometimes \ncalled workbenches. As part of the tool selec-\ntion planning effort, the team must determine \nwhether the SCM workbench will be open \n(tools from different suppliers will be used in \ndifferent SCM process activities) or integrated \n(elements of the workbench are designed to \nwork together).\nOrganization size and the type of projects \ninvolved may also affect tool selection. (See \nSCM Tools, section 7 of this document) \n", "page": 190, "type": "text", "section": "Page 190"}
{"text": "SOFTWARE CONFIGURATION MANAGEMENT   8-5\n1.3.4\t Vendor/Subcontractor Control  \n\b\n[2*, c13] [3*, c13s9-c14s2] \nA software project might acquire or use pur-\nchased software products, such as compilers or \nother tools. SCM planning considers whether \nand how these items will be managed with \nconfiguration control (e.g., integrated into the \nproject libraries) and how changes or updates \nwill be evaluated and managed.\nSimilar considerations apply to subcon-\ntracted software. When a project uses subcon-\ntracted software, both the SCM requirements \nto be imposed on the subcontractor\u2019s SCM \nprocess and the means for monitoring compli-\nance need to be established. The latter includes \ndetermining what SCM information must be \navailable for effective compliance monitoring.\n1.3.5\t Interface Control  \n\b\n[2*, c12] [3*, c23s4]\nWhen a software item interfaces with another \nsoftware or with a hardware item, a change \nto either item can affect the other. Planning \nfor the SCM process considers how the inter-\nfacing items will be identified and how changes \nto the items will be managed and communi-\ncated. The SCM role may be part of a larger, \nsystem-level process for interface specification \nand control involving interface specifications, \ninterface control plans and interface control \ndocuments. In this case, SCM planning for \ninterface control takes place within the con-\ntext of the system-level process.\n1.4\t SCM Plan \n\b\n[2*, ann. D] [3*, c23]\nThe results of SCM planning for a given \nproject are recorded in an SCMP, a \u201cliving \ndocument\u201d that serves as a reference for the \nSCM process. The SCMP is maintained \n(updated and approved) as necessary during \nthe software life cycle. For teams to implement \nan SCMP, they\u2019ll typically need to develop a \nnumber of more detailed, subordinate pro-\ncedures to define how specific requirements \nwill be met  during day-to-day activities (e.g., \nwhich branching strategies will be used, how \nfrequently builds will occur, how often auto-\nmated tests of all kinds will be run).\nGuidance on creating and maintaining an \nSCMP, based on the information produced \nby the planning activity, is available from a \nnumber of sources, such as [2*]. This refer-\nence provides requirements for information to \nbe contained in an SCMP. An SCMP should \ninclude the following sections: \n\u2022\t Introduction (purpose, scope, terms used)\n\u2022\t SCM Management (organization, respon-\nsibilities, authorities, applicable policies, \ndirectives, procedures)\n\u2022\t SCM Activities (configuration identifi-\ncation, configuration control, etc.)\n\u2022\t SCM Schedules (coordination with other \nproject activities)\n\u2022\t SCM Resources (tools, physical resources \nand human resources)\n\u2022\t SCMP Maintenance\n1.5\t Monitoring of Software Configuration \nManagement  \n\b\n[3*, c11s3]\nAfter the SCM process has been imple-\nmented, some surveillance may be necessary \nto ensure that the SCMP provisions are prop-\nerly carried out. The plan is likely to include \nspecific SQA requirements to ensure com-\npliance with specified SCM processes and \nprocedures. The person responsible for SCM \nensures that those with the assigned respon-\nsibility perform the defined SCM tasks cor-\nrectly. As part of a compliance auditing \nactivity, the SQA authority might also per-\nform this surveillance.\nUsing integrated SCM tools with pro-\ncess control capability can make the surveil-\nlance task easier. Some tools facilitate process \ncompliance while providing flexibility for \nthe software engineer to adapt procedures. \nOther tools enforce a specific process, leaving \nthe software engineer with less flexibility. \nSurveillance requirements and the level of \nflexibility provided to the software engineer \nare important considerations in tool selection.\n", "page": 191, "type": "text", "section": "Page 191"}
{"text": "8-6   SWEBOK \u00ae GUIDE V4.0\n1.5.1\t SCM Measures and Measurement  \n\b\n[3*, c9s2, c25s2-s3]\nSCM measures can be designed to provide \nspecific information on the evolving product, \nbut they can also provide insight into how \nwell the SCM process functions and iden-\ntify opportunities for process improvement. \nSCM process measurements enable teams to \nmonitor the effectiveness of SCM activities \non an ongoing basis. These measurements \nare useful in characterizing the current \nstate of the process and providing a basis for \ncomparison over time. Measurement anal-\nysis may produce insights that lead to pro-\ncess changes and corresponding updates \nto the SCMP.\nSoftware libraries and the various SCM \ntool capabilities enable teams to extract useful \ninformation about SCM process characteris-\ntics (as well as project and management infor-\nmation). For example, information about the \ntime required to accomplish various types of \nchanges would be useful in evaluating criteria \nfor determining what levels of authority are \noptimal for authorizing certain changes and \nin estimating the resources needed to make \nfuture changes.\nCare must be taken to keep the surveillance \nfocused on the insights that can be gained from \nthe measurements, not on the measurements \nthemselves. Software process and product \nmeasurement is further discussed in the \nSoftware Engineering Process KA. Software \nmeasurement programs are described in the \nSoftware Engineering Management KA.\n1.5.2\t In-Process Audits of SCM\n[3*, c1s1]\nAudits can be carried out during the software \nengineering process to investigate the status \nof specific configuration elements or to assess \nthe SCM process implementation. In-process \nSCM auditing provides a more formal mech-\nanism for monitoring selected aspects of the \nprocess and may be coordinated with the \nSQA function. (See Software Configuration \nAuditing.)\n2.\t Software Configuration Identification \n\b\n[2*, c8]\nSoftware configuration identification identi-\nfies items to be controlled, establishes iden-\ntification schemes for the items and their \nversions, and establishes the tools and tech-\nniques to be used in acquiring and managing \ncontrolled items. These activities provide the \nbasis for other SCM activities.\n2.1\t Identifying Items to Be Controlled  \n\b\n[2*, c8s2.2]\nA first step in controlling change is identi-\nfying the software items to be controlled. This \ninvolves understanding the software configu-\nration within the context of the system con-\nfiguration, selecting SCIs and developing a \nstrategy for labeling software items.\n2.1.1.\t\nSoftware Configuration\nSoftware configuration is the functional and \nphysical characteristics of hardware or soft-\nware as set forth in technical documentation \nor achieved in a product. It can be viewed as \npart of an overall system configuration.\n2.1.2\t\nSoftware Configuration Item  \n\b\n[2*, c8s2.1] [3*, c9]\nA CI is an item or aggregation of hardware, \nsoftware or both, designed to be managed as \na single entity. An SCI is a software entity \nthat has been established as a CI [1]. The \nSCM controls various items in addition to \nthe code itself. Software items with potential \nto become SCIs include plans, specifications \nand design documentation, testing materials, \nsoftware tools, source and executable code, \ncode libraries, data and data dictionaries, and \ndocumentation for installation, maintenance, \noperations and software use. \nSelecting SCIs is an important process in \nwhich a balance must be achieved between \nproviding adequate visibility for project con-\ntrol purposes and providing a manageable \nnumber of controlled items. \n", "page": 192, "type": "text", "section": "Page 192"}
{"text": "SOFTWARE CONFIGURATION MANAGEMENT   8-7\n2.2\t Configuration Item Identifiers and \nAttributes \n\b\n[2*, c8s2.3, c8s2.4] [3*, c9]\nStatus accounting activity (explained later) \ngathers information about CIs while they \nare developed. The CIs\u2019 scheme is defined \nin order to establish what information must \nbe gathered and tracked for each CI. Unique \nidentifiers and versions are tracked.\nAn example scheme may include the \nfollowing: \nCI name\nCI unique identifier\nCI description\nCI date(s) \nCI type\nCI owner\nThe CI\u2019s unique Identifier can use sig-\nnificant or nonsignificant codification. An \nexample of significant codification could be \nXX-YY, where XX is the iteration abbrevia-\ntion (in case of using an iterative development \nmethod) and YY is the CI abbreviation.\n2.3\t Baseline Identification \n\b\n[2*, c8s2.5.4, c8s2.5.5, c8s2.5.6]\nA software baseline is a formally approved \nversion of a CI (regardless of media type) that \nis formally designated and fixed at a specific \ntime during the CI\u2019s life cycle. The term also \nrefers to a particular version of an agreed-\nupon SCI. The baseline can be changed only \nthrough formal change control procedures. \nA baseline, with all approved changes to the \nbaseline, represents the current approved con-\nfiguration. A baseline consists of one or more \nrelated CIs.\n2.4\t Baseline Attributes \n\b\n[2*, c8s2.5.4]\nBaseline attributes are used in the status \naccounting activity and specify information \nabout the baseline established.\nExample baseline attributes may include \nthe following:\nBaseline name\nBaseline unique identifier\nBaseline description\nBaseline date of creation\nBaseline CIs\n2.5\t Relationships Scheme Definition \n\b\n[3*, c7s4]\nRelationships \nprovide \nthe \nconnections \nrequired to create and sustain structure. The \nability to communicate intent and manage the \nresults are significantly enhanced when effec-\ntive relationships (structuring) are in place \n(e.g., model-based experience (MBX) plat-\nforms). Relationship information exchange \nand interoperability are needed to support \nthe applicable relationship types. The status \naccounting activity is responsible for gathering \ninformation about relationships among CIs.\nCommon types of relationships can be \ndescribed according to the following schemes: \nDependencies: CI-1 and CI-2 depend mutu-\nally on each other.\nExample: CI-1 depends on C1-2, and vice \nversa, for instance a class model depends on a \nsequence diagram, because any change on any \nof both types of models, affect the other. \nCI-1 Code\nCI-2 Code\nDate\nDerivation: One CI derives from another, \ntypically in a sequential relationship, not \nbecause of a lack of resources to handle both \nCIs but because of a constraint that requires \nthat, for instance, CI-1 is completed before \nCI-2 is developed. \nExample: CI-1 derives from CI-2. \nCI-1 Code\nCI-2 Code\nDate\nSuccession: Software items evolve as a soft-\nware project proceeds. A software item ver-\nsion is an identified instance of an item. It \ncan be thought of as a state of an evolving \nitem. This is what the succession relationship \n", "page": 193, "type": "text", "section": "Page 193"}
{"text": "8-8   SWEBOK \u00ae GUIDE V4.0\nreflects, and it is reflexive in that each CI has \nthis relationship with itself. The first succes-\nsion comes up the first time a CI is created. \nEach time it is changed, a new succession \ncomes up, and tracking these successions is \nthe way to track CI versions. \nExample: CI versions along a timeline.\nCI Code\nCurrent Version\nNext Version\nDate\nVariants are program versions resulting \nfrom engineered alternative options. This \ntype of relationship is not as common as the \ntype of relationships described above because \nit is more expensive to maintain. \nThe decision on what relationships to track \nthroughout the project is important because \ntracking some relationships can require extra \nwork. On the other hand, tracking such rela-\ntionships can facilitate decisions on change \nrequests (CRs) for a CI.\nRelationships between CIs can be tracked \nin a Software Bill of Materials (SBOM). \nAn SBOM is a formal record containing \nthe details and supply chain relationships \nof the CIs used in building software. CIs \nin an SBOM are frequently referred to as \ncomponents. Components can be source code, \nlibraries, modules and other artifacts; they \ncan be open source or proprietary, free or \npaid; and the data can be widely available or \naccess-restricted. \nA simple example of the relationships \namong three CIs in an SBOM, called CI-1, \nCI-2 and CI-3, is illustrated in Figure 8.2.\n2.6\t Software Libraries  \n\b\n[2*, c8s2.5] [3*, c1s3]\nA software library is a controlled collection of \nsource code, scripts, object code, documen-\ntation and related artifacts. Requirements \nand test cases are stored in a repository and \nshould be linked with the code baselines \ndeveloped. Source code is stored in a version \ncontrol system, which provides traceability \nand security for the baselines developed. \nMultiple development streams are supported \nin version control systems linked to the binary \nobjects (e.g., object code) derived during the \nbuild process. These binary objects are typi-\ncally stored in a repository that should con-\ntain cryptographic hashes used to perform the \nphysical configuration audit (PCA). \nSuccessions Records: According to the scheme de\ufb01ned for succession relationships, the next table gives the date when each CI was \ncreated (three \ufb01rst rows), and the fourth row indicates a change made on the CI-1 on 10/05/2021, where the current version was 1 \nand created new version is 2.\nDerivation Record: According to the scheme de\ufb01ned for derivation, CI-3 derives from CI-1 and \nthis relationship came up the day CI-3 was created.\nDependency Record: According to the scheme de\ufb01ned for dependencies CI-1 and CI-2 have a \ndependency relationship created the day CI-2 was developed.\nCI-1 \n\u2013 \n1 \n10/01/2021\nCI-2 \n\u2013 \n1 \n10/04/2021\nCI-3 \n\u2013 \n1 \n10/03/2021\nCI-1 \n1 \n2 \n10/05/2021\nCI-1 \nCI-2 \n10/04/2021\nCI-3 \nCI-1 \n10/03/2021\nCI-1\nCI-2\nCI-3\nsuccession\nsuccession\nsuccession\ndependency\nderivation\nFigure 8.2. Example of reported relationships\n", "page": 194, "type": "text", "section": "Page 194"}
{"text": "SOFTWARE CONFIGURATION MANAGEMENT   8-9\nThe definitive media library  contains the \nrelease baseline(s) of the artifacts that can \nbe deployed to the test, stage and produc-\ntion systems. \nThe release management process depends \non these software libraries to manage the arti-\nfacts deployed. In terms of access control and \nthe backup facilities, security is a key aspect of \nlibrary management.\n3.\t Software Configuration Change Control  \n\b\n[2*, c9] [3*,c8] [4*, c25s3] [5, c11.s3.3]\nSoftware configuration change control is con-\ncerned with changes required to CIs during \nthe software life cycle. It covers the pro-\ncess for determining what changes to make, \nthe authority for approving certain changes, \nsupport for implementing those changes, \nand the concept of formal deviations from \nproject requirements as well as waivers of \nthem. Information derived from these activ-\nities is useful in measuring change traffic and \nbreakage, as well as aspects of rework.\nGiven that change to CIs can follow spe-\ncific rules depending on the industrial sector, \narea, company, etc., it is very important to \nidentify those rules in the context of the \nsoftware project for which the SCM pro-\ncess is being developed and to adhere strictly \nto those rules. The rest of this section can \nbe useful when no specific rules regarding \nchange control exist in the company or the \nindustrial sector where the software project \nunder development is allocated.\n3.1\t Requesting, Evaluating, and Approving \nSoftware Changes  \n\b\n[2*, c9s2.4] [3*, c11s1] [4*, c25s3]\nThe first step in managing changes to con-\ntrolled items is determining what changes to \nmake. The software change request (SCR) \nprocess (Figure 8.3) provides formal pro-\ncedures for submitting and recording CRs; \nevaluating the potential cost and impact of a \nproposed change; and accepting, modifying, \ndeferring or rejecting the proposed change. \nA CR is a request to expand or reduce the \nproject scope; modify policies, processes, \nplans or procedures; modify costs or budgets; \nmodify implemented code; or revise schedules \n[1]. Requests for changes to SCIs may be orig-\ninated by anyone at any point in the software \nlife cycle and may include a suggested solution \nand requested priority. One source of a CR is \nthe initiation of corrective action in response \nto problem reports. Regardless of the source, \nthe type of change (e.g., defect or enhance-\nment) is usually recorded on the SCR.\n\u201cEmergency Path\u201d\nusually also exists\nChanges can be\nimplemented with \nchange process\nperformed afterward\nIncomplete\nComplete\nApproved\nRejected\nInform\nRequester\nAssign\nto Software\nEngineer\nSchedule, \nDesign, Test,\nComplete Change\nCCB\nReview\nPreliminary\nInvestigation\nNeed for\nChange\nChange\nidentifed for\ncontrolled item\nSCR Generated\nor Upgraded\nSCR\nEvaluated\nFigure 8.3. Flow of a Change Control Process\n", "page": 195, "type": "text", "section": "Page 195"}
{"text": "8-10   SWEBOK \u00ae GUIDE V4.0\nRecording of the SCR enables the software \nengineers to track defects and collect change \nactivity measurements by change type. Once \nan SCR is received, a technical evaluation \n(also known as an impact analysis) is per-\nformed to determine the extent of the modifi-\ncations necessary should the CR be accepted. \nA good understanding of the relationships \namong software (and, possibly, hardware) \nitems is important for this task. The infor-\nmation recorded about the CIs\u2019 relationships \ncould be useful for making decisions affecting \nany CI, given the potential impact on other \nCIs. Finally, an established authority \u2014 com-\nmensurate with the affected baseline, the SCI \ninvolved and the nature of the change \u2014 will \nevaluate the CR\u2019s technical and managerial \naspects and accept, modify, reject or defer the \nproposed change. \n3.1.1\t\nSoftware Configuration Control Board  \n\b\n[2*, c9s2.2] [3*, c11s1] [4*, c25s3]\nThe authority for accepting or rejecting pro-\nposed changes rests with an entity known as a \nconfiguration control board (CCB). In smaller \nprojects, this authority may reside with the \nleader or an assigned individual rather than \na multi-person board. There can be multiple \nlevels of change authority depending on a \nvariety of criteria \u2014 such as the criticality of \nthe item involved, the nature of the change \n(e.g., impact on budget and schedule), or \nwhere the project is in the life cycle. The com-\nposition of the CCBs used for a system varies \ndepending on these criteria (but an SCM rep-\nresentative is always present). All stakeholders \nappropriate to the CCB level are represented. \nWhen a CCB\u2019s scope of authority is limited \nto software, the board is known as a Software \nConfiguration \nControl \nBoard \n(SCCB). \nThe CCB\u2019s activities are subject to software \nquality audits or reviews.\n3.1.2\t Software Change Request Process  \n\b\n[3*, c1s4, c8s4] [4*, c25s3]\nAn effective SCR process requires the use \nof supporting tools and procedures for \noriginating CRs, enforcing the change process \nflow, capturing CCB decisions and reporting \nchange process information. Linking this tool \ncapability with the problem-reporting system \ncan facilitate the problem resolution tracking \nand how quickly solutions are developed. \n3.1.3\t Software Change Request Forms \nDefinition \n\b\n[2*, c9s2.3, c9s2.5] \n \n\b\n[3*, c8s4] [4*, c25s3]\nA CR application must include the following:\n\u2022\t A CR form, which must describe the \nrequest and give the rationale for it\n\u2022\t A change certification form (necessary if \nthe CR is granted)\nThese forms can be managed through the \ncorresponding supporting tool, but humans \nare responsible for designing the forms. \n3.2\t Implementing Software Changes  \n\b\n[4*, c25s3]\nApproved SCRs are implemented using the \ndefined software procedures per the applicable \nschedule requirements. Because a number of \napproved SCRs might be implemented simul-\ntaneously, a means for tracking which SCRs \nare incorporated into particular software ver-\nsions and baselines must be provided. At the \nend of the change process, completed changes \nmay undergo configuration audits and soft-\nware quality verification, which includes \nensuring that only approved changes have \nbeen made. The SCR process typically docu-\nments the change\u2019s SCM and other approval \ninformation. \nChanges may be supported by source code \nversion control tools. These tools allow a team \nof software engineers, or a single software \nengineer, to track and document changes to \nthe source code. These tools provide a single \nrepository for storing the source code, so they \ncan prevent more than one software engineer \nfrom editing the same module at the same \ntime, and they record all changes made to the \n", "page": 196, "type": "text", "section": "Page 196"}
{"text": "SOFTWARE CONFIGURATION MANAGEMENT   8-11\nsource code. Software engineers check mod-\nules out of the repository, make changes, doc-\nument the changes, and then save the edited \nmodules in the repository. If needed, changes \ncan also be discarded, restoring a previous \nbaseline. More powerful tools can support \nparallel development and geographically dis-\ntributed environments. These tools may mani-\nfest as separate, specialized applications under \nan independent SCM group\u2019s control. They \nmay also appear as an integrated part of the \nsoftware engineering environment. Finally, \nthey may be as elementary as a rudimentary \nchange control system that is provided with \nan operating system.\n3.3\t Deviations and Waivers  \n\b\n[1, c3]\nThe constraints imposed on a software engi-\nneering effort or the specifications produced \nduring the development activities might con-\ntain provisions that those working on the \nproject find cannot be satisfied at the desig-\nnated point in the life cycle. A deviation is \na written authorization granted before the \nmanufacture of an item to depart from a par-\nticular performance or design requirement for \na specific number of units or a specific period \nof time. A waiver is a written authorization \nto allow a CI or other designated item in \nresponse to an issue found during production \nor after the project is submitted for inspection \nto depart from specified requirements when \nthe CI or project is nevertheless considered \nsuitable for use, either as it is or after rework \nvia an approved method. In these cases, a \nformal process is used to gain approval for \ndeviations from or waivers of the provisions. \n4.\t Software Configuration Status \nAccounting \n\b\n[2*, c10] [3*, c9] [5, c11s3.4]\nSCSA is an activity of CM consisting of \nrecording and reporting information needed to \nmanage a configuration effectively regarding \nCIs, baselines and relationships among CIs. \nThis activity must be done by following the \nlogical schemes defined in the activity config-\nuration identification for CIs, baselines and \nrelationships for gathering information.\n4.1\t Software Configuration Status Information \n\b\n[2*, c10s2.1]\nThe SCSA activity designs and operates a \nsystem for capturing, verifying, validating \nand reporting necessary information as the \nlife cycle proceeds. As in any information \nsystem, the configuration status information \nto be managed for the evolving configurations \nmust be identified, collected and maintained. \nIn addition, the information itself should be \nsecured where relevant. SCSA information \nand measurements are needed to support the \nSCM process and to meet the configuration \nstatus reporting needs of management, soft-\nware engineering, security, performance and \nother related activities. \nThe types of information available include \nbut are not limited to the following:\n\u2022\t Ongoing and approved configuration \nidentification\n\u2022\t Current implementation status of changes\n\u2022\t Impacted CIs and related systems\n\u2022\t Deviations and waivers\n\u2022\t Verification \nand \nvalidation \n(V&V) \nactivities\nAutomated tools support SCSA as tasks \nare performed, and reporting is available in a \nuser-friendly format. \n4.2\t Software Configuration Status Reporting \n\b\n[2*, c10s2.4] [3*, c1s5, c9s1]\nReported information can be used by var-\nious organizational and project elements \u2014 \nincluding the development team, operations, \nsecurity, the maintenance team, project man-\nagement, software quality activities teams \nand others. Reporting can take many forms: \nautomated reports, ad hoc queries to answer \nspecific questions, and regular production of \npredesigned reports, including those devel-\noped to meet security, legal or regulatory \n", "page": 197, "type": "text", "section": "Page 197"}
{"text": "8-12   SWEBOK \u00ae GUIDE V4.0\nrequirements. In other words, information \nproduced by the SCSA activity throughout \nthe life cycle can be used to satisfy QA and \nsecurity and to provide evidence of compli-\nance with regulations, governance require-\nments, etc.\nIn addition to reporting the configura-\ntion\u2019s current status, the information obtained \nby the SCSA can serve as a basis for various \nmeasurements. \nModern SCM includes a wider scope of \ninformation, including but not limited to the \nfollowing: \n\u2022\t Indicators of integrity (e.g., MAC \n(Message Authentication Code) SHA1 \n(Secure \nHash \nAlgorithm), \nMD5 \n(Message Digest))\n\u2022\t Indicators of security status (e.g., gover-\nnance risk and compliance) \n\u2022\t Evidence of V&V activities (e.g., require-\nments completion)\n\u2022\t Baseline status\n\u2022\t The number of CRs per SCI \n\u2022\t The \naverage \ntime \nneeded \nto \nimplement a CR \n5.\t Software Configuration Auditing \n\b\n[2*, c11] [5, c11s3.5]\nA software audit is an independent examina-\ntion of a work product or set of work prod-\nucts to assess technical, security, legal and \nregulatory compliance with specifications, \nstandards, contractual agreements or other \ncriteria [1]. Audits are conducted according \nto a well-defined process comprising various \nauditor roles and responsibilities. Because \nof this complexity, each audit must be care-\nfully planned. An audit can require a number \nof individuals to perform various tasks over a \nfairly short time. Tools to support the plan-\nning and conduct of an audit can greatly facil-\nitate the process.\nSoftware configuration auditing deter-\nmines the extent to which an item satis-\nfies requirements for functional and physical \ncharacteristics. Informal audits can be con-\nducted at key points in the life cycle. Two \ntypes of formal audits might be required by \nthe governing contract (e.g., a contract cov-\nering critical software): the functional config-\nuration audit (FCA) and the PCA. Successful \ncompletion of these audits can be a prerequi-\nsite for establishing the product baseline. \n5.1\t Software Functional Configuration Audit  \n\b\n[2*, c11s2.1]\nThe software FCA ensures that the audited \nsoftware item is consistent with its governing \nspecifications. The software V&V activities\u2019 \noutput (see Verification and Validation in \nthe Software Quality KA) is a key input to \nthis audit.\n5.2\t Software Physical Configuration Audit  \n\b\n[2*, c11s2.2]\nThe software PCA ensures that the design \nand reference documentation are consistent \nwith the as-built software product.\n5.3\t In-Process Audits of a Software Baseline \n\b\n[2*, c11s2.3]\nAudits can be carried out during the develop-\nment process to investigate the status of specific \nconfiguration elements. In-process audits can \nbe applied to all baseline items to ensure that \nperformance is consistent with specifications \nor that evolving documentation continues to be \nconsistent with the developing baseline item. \nThis task applies to every single CI to be \napproved as part of a baseline. The audit \nconsists of reviewing the CI to determine \nwhether it satisfies requirements. How to con-\nduct the review and the expected result must \nbe described in the quality plan or if there is \nno quality plan, defined for the software con-\nfiguration auditing activity. \nContinuous reviews of CIs identified in \nthe configuration identification activities help \nverify conformance to governance and regula-\ntory requirements. \nConfiguration auditing reviews take place \nthroughout project development, whenever a \nCI must be reviewed.\n", "page": 198, "type": "text", "section": "Page 198"}
{"text": "SOFTWARE CONFIGURATION MANAGEMENT   8-13\n6.\t Software Release Management and \nDelivery \n\b\n[2*, c14] [3*, c8s2] [4*, c25s4]\nIn this context, release refers to distrib-\nuting software and related artifacts outside \nthe development activity, including internal \nreleases and distribution to customers. When \ndifferent versions of a software item are avail-\nable for delivery (such as versions for different \nplatforms or versions with varying capabili-\nties), re-creating specific versions and pack-\naging the correct materials for version delivery \nare frequently necessary. The software library \nis a key element in accomplishing release and \ndelivery tasks.\n6.1\t Software Building\b\n[4*, c25s2]\nSoftware building constructs the correct ver-\nsions of SCIs, using the appropriate config-\nuration data, into a software package for \ndelivery to a customer or other recipient such \nas a team performing testing. For systems \nwith hardware or firmware, the executable \nprogram is delivered to the system-building \nactivity. Build instructions help ensure that \nthe proper build steps are taken in the cor-\nrect sequence. In addition to building soft-\nware for new releases, SCM must usually \nbe able to reproduce previous releases for \nrecovery, testing, maintenance or additional \nrelease purposes.\nSoftware is built using supporting tools, \nsuch as compilers. For example, if it is nec-\nessary to rebuild an exact copy of a previously \nbuilt SCI, supporting tools and associated \nbuild instructions must be under SCM con-\ntrol to ensure the availability of the correct \nversions of the tools. \nTool capability is useful for selecting the \ncorrect versions of software items for a target \nenvironment and automating the process \nof building the software from the selected \nversion and configuration data. This tool \ncapability is necessary for projects with \nparallel or distributed development envi-\nronments. Most software engineering envi-\nronments provide this capability. However, \nthese tools vary in complexity; some require \nthe software engineer to learn a special-\nized scripting language, while others use a \nmore graphics-oriented approach that hides \nmuch of the complexity of an \u201cintelligent\u201d \nbuild facility.\nThe build process and products are often \nsubject to software quality verification. \nOutputs of the build process might be needed \nfor future reference. They may become records \nof quality, security, or compliance with orga-\nnizational or regulatory requirements. The \nSBOM listing the artifacts included in the \nbuild is an important CM output.\nIn \ncontinuous \nintegration, \nsoftware \nbuilding is performed automatically when \nchanges to CIs are committed to a source \ncontrol repository. Tools running on a local \nor cloud-based server monitor the project\u2019s \nsource control system and initiate a pipeline of \nsteps to be undertaken every time a change is \ncommitted to a particular branch or area of the \nsource code repository. The tool is configured \nto retrieve a fresh copy of the complete source \ncode for the project and execute the necessary \ncommands to compile and link the code. This \nconfiguration is often combined with steps to \nvalidate coding standards via automated static \nanalysis, execute unit tests and determine \ncode coverage metrics, or extract documenta-\ntion from the source code.  The resulting arti-\nfacts are then deployed through the Release \nManagement process.\n6.2\t Software Release Management \n\b\n[4*, c25s2]\nSoftware release management encompasses \nthe identification, packaging and delivery of \nthe elements of a product (e.g., an execut-\nable program, documentation, release notes, \nor configuration data). Given that product \nchanges can occur continually, one concern \nfor release management is determining when \nto issue a release. The severity of the prob-\nlems addressed by the release and measure-\nments of the fault densities of prior releases \naffect this decision. The packaging task iden-\ntifies which product items are to be delivered \n", "page": 199, "type": "text", "section": "Page 199"}
{"text": "8-14   SWEBOK \u00ae GUIDE V4.0\nand then selects the correct variants of those \nitems, given the product\u2019s intended applica-\ntion. The information documenting the phys-\nical contents of a release is known as a version \ndescription document (VDD). The release \nnotes describe new capabilities, known prob-\nlems and platform requirements necessary for \nproper product operation. The package to be \nreleased also contains installation or upgrade \ninstructions. The latter can be complicated \nbecause some users might have versions that \nare several releases old. In some cases, release \nmanagement might be necessary to track the \nproduct\u2019s distribution to various customers \nor target systems (e.g., when the supplier \nwas required to notify a customer of newly \nreported problems). Finally, a mechanism to \nhelp ensure the released item\u2019s integrity can \nbe implemented (e.g., by including a digital \nsignature).\n A tool capability is needed for supporting \nthese release management functions. For \nexample, a connection with the tool capa-\nbility supporting the CR process is useful to \nmap release contents to the SCRs that have \nbeen received. This tool capability might also \nmaintain information on various target plat-\nforms and customer environments.\nIn continuous delivery, a pipeline is estab-\nlished to build software continuously, as \ndescribed in the previous section. The resulting \nartifacts from the build process include exe-\ncutable code and libraries, which can then be \ncombined into an installation package and \ndeployed into an environment for verification \nor production use. \n7.\t Software Configuration Management \nTools \n\b\n[3*, c26s1]\nMany tools can assist with CM at many levels. \nThe scope of these tools varies depending on \nwho uses the tools. CM is most effective when \nintegrated with other processes and by exten-\nsion with other existing tools. The selection of \nCM tool can be made depending on the scope \nthat the tool is going to have.\nOverview of tools:\n\u2022\t The configuration management system \n(CMS) provides enabling technology and \nlogic to facilitate CM activities. \n\u2022\t Version control stores the source code, \nconfiguration files and related artifacts.\n\u2022\t Build automation (pipeline) is established \nto enable continuous delivery.\n\u2022\t A repository stores binaries that are cre-\nated during the build process to extract \nthe latest build artifacts and redeploy \nthem as required \u2014 used in the release \nverification process.\n\u2022\t Configuration \nmanagement \ndatabase \n(CMDB) or similar persistence store.\n\u2022\t Change control tools.\n\u2022\t Release/deployment tools.\nThe CMS supports the unique identifica-\ntion of artifacts. Both individual artifacts and \ncollections are specified in CM systems and \nrelated repositories. Structuring creates a log-\nical relationship between artifacts. Validation \nand release establish the artifacts\u2019 integ-\nrity, as part of the release management pro-\ncess. Baselines are identified where stability is \nintended. For example, interface management \nis identified and controlled, making it part of \nthe baseline process. Change management, \nincluding variants and nonconformances, \nis reviewed and approved, and its imple-\nmentation is planned. Verification and audit \nactivities are performed as part of the identi-\nfication, change and release management pro-\ncess. Status and performance accounting are \nrecorded as events occur and are made avail-\nable through the CMS.\nIndividual support tools are typically suffi-\ncient for small organizations or development \ngroups that do not issue variants of their soft-\nware products or face other complex SCM \nrequirements. The following are examples of \nthese tools:\n\u2022\t Version control tools: These tools track, \ndocument and store individual CIs such as \nsource code and external documentation.\n\u2022\t Build handling tools: In their simplest \nform, such tools compile and link an exe-\ncutable version of the software. More \n", "page": 200, "type": "text", "section": "Page 200"}
{"text": "SOFTWARE CONFIGURATION MANAGEMENT   8-15\nadvanced building tools extract the latest \nversion from the version control soft-\nware, perform quality checks, run regres-\nsion tests, and produce various forms of \nreports, among other tasks.\n\u2022\t Change control tools: These tools pri-\nmarily support the control of CRs and \nevent notifications (e.g., CR status \nchanges, milestones reached).\nProject-related support tools mainly sup-\nport workspace management for develop-\nment teams and integrators. In addition, \nthey can support distributed development \nenvironments. Such tools are appropriate for \nmedium-to-large organizations that use vari-\nants of their software products and parallel \ndevelopment and do not have certification \nrequirements.\nCompanywide-process support tools \ncan \nautomate portions of a companywide pro-\ncess, providing support for workflow man-\nagement, roles and responsibilities. They can \nhandle many items, large volumes of data, and \nnumerous life cycles. In addition, such tools \nadd to project-related support by supporting a \nmore formal development process, including \ncertification requirements.\nMATRIX OF TOPICS VS. REFERENCE MATERIAL\nTopic\nIEEE 828-2012\n[2*]\nHass 2003 \n[3*]\nSommerville 2016\n[4*]\n1. Management of the SCM Process\nc6, c7\n1.1. Organizational Context for SCM\nc6, ann.D \nIntroduction\nc25\n1.2. Constraints and Guidance for the SCM Process\nc6, ann.D,  \nann.E\nc2,c5\n1.3. Planning for SCM\nc6, ann.D,  \nann.E\nc23\nc25\n1.3.1. SCM Organization and Responsibilities\nann.Ds5-6\nc10-11\nc25\n1.3.2. SCM Resources and Schedules\nann.Ds8\nc23\n1.3.3. Tool Selection and Implementation\nc26s2, s6\n1.3.4. Vendor/Subcontractor Control\nc13\nc13s9-c14s2\n1.3.5. Interface Control\nc12\nc23s4\n1.4. SCM Plan\nann.D\nc23\n1.5. Surveillance of Software Configuration \nManagement\nc11s3\n1.5.1. SCM Measures and Measurement\nc9s2; c25s2-s3\n1.5.2. In-Process Audits of SCM\nc1s1\n2. Software Configuration Identification\nc8\n2.1. Identifying Items to Be Controlled\nc8s2.2\nc1s2\n2.1.1. Software Configuration\n", "page": 201, "type": "text", "section": "Page 201"}
{"text": "8-16   SWEBOK \u00ae GUIDE V4.0\n2.1.2. Software Configuration Item\nc8s2.1\nc9\n2.2. Configuration Item Identifiers and Attributes\nc8s2.3 c8s2.4\nc9\n2.3. Baseline Identification\nc8s2.5.4\nc8s2.5.5 c8s2.5.6\n2.4. Baseline Attributes\nc8s2.5.4\n2.5. Relationships Scheme Definition\nc7s4\n2.6. Software Libraries\nc8s2.5\nc1s3\n3. Software Configuration Change Control\nc9\nc8\nc25s3\n3.1. Requesting, Evaluating and Approving \nSoftware Changes\nc9s2.4\nc11s1\nc25s3\n3.1.1. Software Configuration Control Board\nc9s2.2\nc11s1\nc25s3\n3.1.2. Software Change Request Process\nc1s4, c8s4\nc25s3\n3.1.3. Software Change Request Forms Definition\nc9s2.3 c9s2.5\nc8s4\nc25s3\n3.2. Implementing Software Changes\nc25s3\n3.3. Deviations and Waivers\n4. Software Configuration Status Accounting\nc10\nc9\n4.1. Software Configuration Status Information\nc10s2.1\n4.2. Software Configuration Status Reporting\nc10s2.4\nc1s5; c9s1\n5. Software Configuration Auditing\nc11\n5.1. Software Functional Configuration Audit\nc11s2.1\n5.2. Software Physical Configuration Audit\nc11s2.2\n5.3. In-Process Audits of a Software Baseline\nc11s2.3\n6. Software Release Management \nand Delivery\nc14\nc8s2\nc25s4\n6.1. Software Building\nc25s2\n6.2. Software Release Management\nc25s2\n7. Software Configuration Management Tools\nc26s1\nFURTHER READINGS\nS.P. Berczuk and B. Appleton, Software \nConfiguration Management Patterns: Effective \nTeamwork, Practical Integration [6].\nThis book expresses useful SCM practices \nand strategies as patterns. The patterns can be \nimplemented using various tools, but they are \nexpressed in a tool-agnostic fashion.\nCMMI for Development, Version 2.0 - 2.1, pp. \n66\u201380 [7].\nThis model presents a collection of best prac-\ntices to help software development organi-\nzations improve their processes. At maturity \nlevel 2, it suggests CM activities.\nB. Aiello and L. A. Sachs, Configuration man-\nagement best practices: Practical methods that \n", "page": 202, "type": "text", "section": "Page 202"}
{"text": "SOFTWARE CONFIGURATION MANAGEMENT   8-17\nwork in the real world (1st edition), 2011 [8].\nThis book presents the seven types of change \ncontrol (Chapter 4, Section 3).\nREFERENCES \n[1]\t ISO/IEC/IEEE, \u201cISO/IEC/IEEE \n24765:2017 Systems and Software \nEngineering \u2014 Vocabulary,\u201d \n2nd ed. 2017.\n[2*]\tIEEE. IEEE Standard 828-\n2012, Standard for Configuration \nManagement in Systems and Software \nEngineering, 2012.\n[3*]\tA.M.J. Hass. Configuration Management \nPrinciples and Practices, 1st ed. Boston: \nAddison-Wesley, 2003.\n[4*]\tI. Sommerville, Software Engineering, \n10th ed. Global ed. Pearson, 2016.\n[5]\t J.W. Moore, The Road Map to Software \nEngineering: A Standards-Based Guide, \n1st ed. Hoboken, NJ: Wiley-IEEE \nComputer Society Press, 2006.\n[6]\t S.P. Berczuk and B. Appleton, \nSoftware Configuration Management \nPatterns: Effective Teamwork, \nPractical Integration: Addison-Wesley \nProfessional, 2003.\n[7]\t CMMI for development, Version 2.0, \nCMMI Institute, 2018.\n[8]\t B. Aiello and L.A. Sachs, Configuration \nmanagement best practices: Practical \nmethods that work in the real world (1st \nedition), 2011.\n", "page": 203, "type": "text", "section": "Page 203"}
{"text": "9-1 \nCHAPTER 09\nSoftware Engineering \nManagement\nACRONYMS\nPMBOK\u00ae \n \nGuide \nGuide to the Project Management \nBody of Knowledge\nSDLC\nSoftware development life cycle\nSEM\nSoftware engineering \nmanagement\nSQA\nSoftware quality assurance\nSWX\nSoftware Extension to the \nPMBOK\u00ae Guide \nWBS\nWork breakdown structure\nPSM\nPractical Software and Systems \nMeasurement\nMBSE\nModel-Based System Engineering\nINTRODUCTION\nSoftware engineering management (SEM) \ncan be defined as a collection of work activi-\nties involved with planning, estimating, mea-\nsuring, controlling, coordinating, leading and \nmanaging risk factors for a software project to \nhelp ensure that software products and soft-\nware engineering services are delivered effi-\nciently, effectively and to the stakeholders\u2019 \nbenefit [3]. Although project management \nand measurement management are often \nseen as separate areas, and each possesses \nmany unique attributes, the close relationship \nbetween the two has led to their combined \ntreatment in this knowledge area (KA). \nIn one sense, it should be possible to \nmanage a software engineering project in the \nsame way other complex endeavors are man-\naged, using models, technical processes and \nproblem-solving styles as other engineering \nprojects do. However, software engineers use \ndifferent process models, technical processes, \nand problem-solving styles than other engi-\nneers, making these choices based on their \neducation and experience and on the differ-\nences between physical and software attri-\nbutes. Software system elements are logical \nconstructions expressed in algorithmic form, \nwhile physical system elements are realized \nin mechanical, electrical, chemical, biological \nand other physical media. Software is intan-\ngible because it has no physical properties and \nis malleable because of the relative ease with \nwhich code can be modified. Obtaining the \ndesired effect by modifying software code \nmight not be easy, but code modifications, \nper se, are straightforward compared with the \nmodification of physical elements that have \nalready been constructed [12].\nAs software and software-embedded sys-\ntems become bigger, more complex, and more \nintertwined, software engineering manage-\nment and engineering roles are evolving in \nresponse [10], because skilled individuals \nmust actively develop and maintain these sys-\ntems. Consider the following: hardware is \ndifferent from software (and not all software \nis the same). Hardware can be developed, \nprocured, and maintained in a linear fashion. \nSoftware is an enduring capability that must \nbe supported and continuously improved \nthroughout its life cycle [13]. Furthermore, \nthe malleable nature of software allows iter-\nation among and interleaving of the develop-\nment phases (to a much greater degree than is \npossible when developing physical artifacts).\nSoftware is made by people and for people, \nso digital talent matters. Software projects \nare increasingly important, and their ongoing \nsuccess largely depends on people with the \nright skills, knowledge and abilities. This fact \n", "page": 204, "type": "text", "section": "Page 204"}
{"text": "9-2   SWEBOK \u00ae GUIDE V4.0\nis essentially actual and necessary but not suf-\nficient. Other human factors may affect the \nproject\u2019s success. During the software devel-\nopment lifecycle, it is impossible to separate \nthe human factors from the technical ones. \nTherefore, people management activities, \nsuch as team and teamwork, leadership, com-\nmunication, and coordination activities, are \nimportant to project success.\nSoftware reuse can be a key factor in main-\ntaining and improving productivity and \ncompetitiveness.\nFactors such as cultural differences and \ndiverse attitudes may affect the develop-\nment team. A significant number of software \nprojects failed due to social issues. A \u201chigh \nquality\u201d developer can produce inappro-\npriate or poor quality products that require \nrework if presented with poor requirements or \ncommunication.\nOther issues can complicate effective man-\nagement of software projects and software life \ncycle processes, including the following:\n\u2022\t Clients often do not know what is needed \nor what is feasible.\n\u2022\t Increased understanding and changing \nconditions will likely generate new or \nchanged software requirements.\n\u2022\t Clients often do not appreciate the com-\nplexities inherent in software engi-\nneering, \nparticularly \nregarding \nthe \nimpact of changing requirements.\n\u2022\t As a result of changing requirements and \nsoftware malleability, software is often \nbuilt iteratively rather than as a linear \nsequence of phases.\n\u2022\t Software is nominally an enduring capa-\nbility that must be supported and contin-\nuously improved throughout its lifecycle. \n\u2022\t Software construction differs from hard-\nware implementation in that design is \nusually part of software construction, \nwhereas in hardware-oriented systems, \ndesign precedes hardware implementa-\ntion to \u201cget it right\u201d prior to procurement \nor fabrication of hardware [12].\n\u2022\t Software engineering necessarily incorpo-\nrates creativity and discipline. Maintaining \nan appropriate balance between the two is \nsometimes difficult [5].\n\u2022\t The development of software capabilities \noften involves a high degree of novelty \nand complexity.\n\u2022\t Typically, the underlying technology has \na high rate of change.\n\u2022\t Computer software has become a key \ncomponent of most modern systems. \nSoftware has been elevated to a highly \nprominent role because of its flexibility \nand relatively low replication cost com-\npared with hardware.\n\u2022\t A significant number of software projects \nfailed due to human issues. Physical mea-\nsurement units such as the length and \nweight measures are challenging to apply \nto the software. This difficulty impacts \nhow to plan, monitor, and control soft-\nware development projects. \n\u2022\t Software rework to remove faults and \nrespond to change. \n\u2022\t Speed and cycle time are important met-\nrics for managing software. Software \ncapabilities \nare \noften \ndelivered \nat \nincreasing speed to satisfy business and \nmission needs [13].\nSEM activities occur on three levels: orga-\nnizational and infrastructure management, \nproject management, and management of the \nmeasurement program. The last two are cov-\nered in detail in this KA description. This fact \ndoes not diminish the importance of organiza-\ntional and infrastructure management issues \nbut rather points out that software organiza-\ntional engineering managers should be con-\nversant with the project management and \nsoftware measurement knowledge described \nin this KA. They should also possess some \ntarget domain knowledge. Likewise, it also \nhelps for managers of complex projects and \nprograms where software is part of the system \narchitecture to know what issues software \nengineering processes (versus other types of \nengineering processes) introduce into project \nmanagement and project measurement. \nOther aspects of organizational man-\nagement affect software engineering \u2014 for \n", "page": 205, "type": "text", "section": "Page 205"}
{"text": "SOFTWARE ENGINEERING MANAGEMENT   9-3\nexample, organizational policies and proce-\ndures that provide the framework for software \nengineering projects. These policies and pro-\ncedures might need to be adjusted for effec-\ntive software development and maintenance \nrequirements. In addition, several policies \nspecific to software engineering might need \nto be in place or established for the effective \nmanagement of software engineering at the \norganizational level. For example, policies are \nusually necessary to establish specific organi-\nzation-wide processes or procedures for soft-\nware engineering tasks such as software design, \nsoftware construction, estimating, monitoring \nand reporting. Such policies are important for \neffective long-term management of software \nengineering projects across an organization \n(e.g., one such policy could establish a con-\nsistent basis for analyzing past project perfor-\nmance and implementing improvements).\nAnother important aspect of organiza-\ntional management is the use of personnel \nmanagement policies and procedures for \nhiring, training and mentoring \u2014 not only \nfor a project\u2019s success, but also for the orga-\nnization\u2019s long-term success. Given the pro-\njected scarcity of skilled software engineers, \nit is important to provide an environment that \nattracts and retains good talent. Software \nengineering personnel can present unique \ntraining or personnel management chal-\nlenges (e.g., maintaining currency in a context \nwhere the underlying technology undergoes \nrapid and continuous change) as part of career \ndevelopment. \nCommunication management is also often \nmentioned as an overlooked but important \naspect of success in a field where a pre-\ncise understanding of user needs, software \nrequirements and software designs is nec-\nessary. \nFurthermore, \nportfolio \nmanage-\nment is desirable, which provides an overall \nview of software under development in var-\nious projects and programs (integrated proj-\nects) of planned software, and of software \nalready in use in an organization. Also, soft-\nware reuse can be a key factor in maintaining \nand improving productivity and competitive-\nness. Effective reuse requires a strategic vision \nthat reflects the advantages and disadvantages \nof reuse. \nSoftware engineers should have a sound \nunderstanding of the aspects of management \nthat are unique to software projects, and they \nshould also have some knowledge of the more \ngeneral aspects of management discussed \nin this KA (even in the first few years after \ngraduation).\nCertain attributes of organizational cul-\nture and behavior, as well as management of \nfunctional areas of the enterprise outside the \nimmediate software engineering realm, can \ninfluence an organization\u2019s software engi-\nneering processes, albeit indirectly. Software \nprojects are often targeted at changing the \nway people work \u2014 but culture change is dif-\nficult, complicated and unlikely to succeed \nwithout a significant effort. For this reason, \nleadership is an important attribute for pro-\ngram managers, as they often need to lead \nthe charge for digital transformation. They \nmight need to galvanize their teams and other \nstakeholders to bring their very best to every \nproject pursuing major change.\nExtensive information concerning project \nmanagement can be found in the Guide to \nthe Project Management Body of Knowledge \n(PMBOK\u00ae Guide fifth edition) and the Software \nExtension to the PMBOK\u00ae Guide (SWX) [1, \n2]. Each of these guides includes 10 project \nmanagement KAs: project integration man-\nagement, project scope management, project \ntime/schedule management, project cost man-\nagement, project quality management, project \nresource/human management, project com-\nmunications management, project risk man-\nagement, project procurement management \nand project stakeholder management. Each \nKA has direct relevance to this SEM KA. \nAdditional information is also provided in this \nKA\u2019s references and list of Further Readings.\nThis SEM KA discusses the software \nproject management processes shown as the \nfirst five topics in Figure 9-1 (Initiation and \nScope Definition, Software Project Planning, \nSoftware Project Enactment, Review and \nEvaluation, Closure), as well as Software \nEngineering Measurement (the sixth topic \n", "page": 206, "type": "text", "section": "Page 206"}
{"text": "9-4   SWEBOK \u00ae GUIDE V4.0\nshown in the figure) and Software Engineering \nManagement Tools (the seventh topic). \nUnfortunately, a common perception of \nthe software industry is that software prod-\nucts often are delivered late, are over budget, \nare of poor quality and have incomplete \nfunctionality. Measurement-informed man-\nagement \u2014 a basic principle of any true engi-\nneering discipline (see Measurement in the \nEngineering Foundations KA) \u2014 can help \nimprove perception and reality. In essence, \nmanagement without measurement (qualita-\ntive and quantitative) suggests a lack of disci-\npline, and measurement without management \nsuggests a lack of purpose or context. To be \neffective, software engineers must use both \nmeasurement and management.\nThe following working definitions are \nadopted here:\n\u2022\t Management is a system of processes and \ncontrols required to achieve the strategic \nobjectives set by the organization. \n\u2022\t Measurement refers to the assignment \nof values and labels to software engi-\nneering work products, processes and \nresources, plus the models derived from \nthem, whether these models are devel-\noped using statistical or other techniques \n[3*, c7, c8].\nThe software engineering project manage-\nment sections in this KA use the Software \nEngineering Measurement section extensively.\nThis KA is closely related to others in the \nSWEBOK Guide; reading the following KA \ndescriptions will be particularly helpful in \nunderstanding this one: \n\u2022\t The Engineering Foundations KA describes \nsome general measurement concepts that \ndirectly apply to the Software Engineering \nMeasurement section of this KA. In addi-\ntion, the concepts and techniques pre-\nsented in the Statistical Analysis section of \nthe Engineering Foundations KA apply \ndirectly to many topics in this KA.\n\u2022\t The Software Requirements KA describes \nactivities that should be performed \nduring the project\u2019s Initiation and Scope \nDefinition phase.\n\u2022\t The Software Configuration Management \nKA deals with the identification, control, \nstatus accounting and auditing of soft-\nware configurations, along with software \nrelease management and delivery and \nsoftware configuration management tools. \n\u2022\t The Software Engineering Process KA \ndescribes software life cycle models and \nthe relationships between processes and \nwork products.\nSoftware Engineering \nManagement\nInitiation \nand Scope \nDe\ufb01nition\nSoftware \nEngineering\nMeasurement\nDetermination \nand Negotiation \nof Requirements\nFeasibility\nAnalysis\nProcess for the\nReview and \nRevision of\nRequirements\nProcess\nPlanning\nDetermine\nDeliverables\nE\ufb00ort, \nSchedule,\nand Cost \nEstimation\nImplementation\nof Plans\nSoftware \nAcquisition \nand Supplier \nContract\nManagement\nImplementation \nof Measurement\nProcess\nMonitor Process\nControl Process\nReporting\nDetermine\nSatisfaction of\nRequirements\nReviewing\nand Evaluating\nPerformance\nDetermine\nClosure\nClosure\nActivities\nEstablish \nand Sustain\nMeasurement\nCommitment\nPlan the \nMeasurement\nProcess\nPerform the \nMeasurement\nProcess\nEvaluate\nMeasurement\nSoftware \nProject \nPlanning\nSoftware \nProject \nEnactment\nSoftware\nReview and \nEvaluation\nClosure\nSoftware \nEngineering\nManagement \nTools\nFigure 9.1. Breakdown of Topics for the Software Engineering Management KA\n", "page": 207, "type": "text", "section": "Page 207"}
{"text": "SOFTWARE ENGINEERING MANAGEMENT   9-5\n\u2022\t The Software Quality KA emphasizes \nquality as a management goal and as an aim \nof many software engineering activities.\n\u2022\t The Software Engineering Economics \nKA discusses how to make software-re-\nlated decisions in a business context. \nBREAKDOWN OF TOPICS FOR \nSOFTWARE ENGINEERING \nMANAGEMENT \nBecause most software development life cycle \n(SDLC) models require similar activities that \nmay be executed in different ways, the topic \nbreakdown, shown in Figure 9-1, is activi-\nty-based. The top-level elements shown in \nthe figure are activities that are usually per-\nformed when a software development project \nis being managed, regardless of which SDLC \nmodel is being used (see Software Life Cycle \nModels in the Software Engineering Process \nKA). This breakdown does not recommend \na specific life cycle model. However, it is \nimportant to note the choice of the SDLC \ncan have a impact on program activities to \naccommodate changing requirements.\nDelivery speed, continuous adaptation and \nfrequent modular upgrades to deliver new \ncapabilities are often key business differenti-\nators and project management imperative [11, \n13]. These imperatives should be balanced \nwith risk management activities.\nSeveral software life cycle process models \nhave been and are being developed to shorten \ndevelopment cycles in response to changing \nbusiness needs, specifically, changing soft-\nware requirements. Most of these pro-\ncesses involve Agile SDLC approaches [14]. \nThe Agile approach assumes that teams can \ndevelop \nhigh-quality, \nadaptive \nsoftware \nusing continuous design improvement prin-\nciples and testing based on rapid feedback \nand change. In comparison, the traditional \napproach assumes that software-intensive sys-\ntems are fully specifiable and predictable and \ncan be built through meticulous and exten-\nsive planning. The management style asso-\nciated with the Agile approach emphasizes \nleadership and collaboration at the team level, \nwhereas the management style of the highly \npredictive approach is more formal (top-\ndown). Many Agile approaches integrate dif-\nferent management approaches. \nFor example, Dev/Sec/Ops is a culture \nand an Agile approach to modern software \ndelivery that aligns development (Dev), secu-\nrity (Sec) and operations (Ops) groups into an \nintegrated team focused on continuous, incre-\nmental delivery of capabilities. The main char-\nacteristic of Dev/Sec/Ops is that this approach \nautomates, continuously monitors and applies \nsecurity at all phases of the software life cycle: \nplan, develop, build, test, release, deliver, \ndeploy, operate and monitor. In Dev/Sec/\nOps, testing and security are shifted to the \nleft through automated unit, functional, inte-\ngration and security testing. This is a key \nDev/Sec/Ops differentiator; security/quality \nassurance (QA) and other nonfunctional \nand functional capabilities are tested and \nbuilt simultaneously [11, 14]. Whereas Dev/\nSec/Ops encompasses the culture and pro-\ncesses that enable rapid, continual delivery \nof cyber-resilient systems, complex soft-\nware-embedded systems can have additional \ndemands that must also be integrated into \nthe Dev/Sec/Ops culture and processes, such \nas safety. Elevating these demands to be on \npar with Dev/Sec/Ops highlights the impor-\ntance of incorporating quality into all program \naspects. The complexity of the end-to-end \nDevSecOps tools and of using emerging tech-\nnologies such as artificial intelligence (AI) and \nmachine learning (ML) to leverage those tools \nadds another dimension [15]. For example, \nAgile and DevOps approaches are reasonably \nwell-established, but in case of AI-based soft-\nware, new SLDCs maybe required to manage \nthe complexity brought by AI to the software.\nIt is important to understand the differ-\nence between phases and activities and why \nan activities breakdown is used. The Project \nManagement Institute (PMI) describes a \nphase this way:  \u201cThe completion and approval \nof one or more deliverables characterizes a \nproject phase.\u201d A deliverable is a measurable, \nverifiable work product such as a specification, \n", "page": 208, "type": "text", "section": "Page 208"}
{"text": "9-6   SWEBOK \u00ae GUIDE V4.0\nfeasibility study report, detailed design docu-\nment or working prototype. Some deliverables \ncorrespond to part of the project management \nprocess, whereas others are the end products \nor components of the end products for which \nthe project was conceived. The deliverables, \nand hence the phases, are part of a generally \nsequential process designed to ensure proper \ncontrol of the project and to attain the desired \nproduct or service, which is the project\u2019s objec-\ntive. From a project management perspective, \nphases help accomplish project objectives and \nmaintain control over the project. \nThe activity-based breakdown in Figure \n9-1 shows what happens but does not imply \nwhen, how or how many times each activity \noccurs. The seven topics are the following:\n\u2022\t Initiation and Scope Definition, which \ndeals with the decision to embark on a \nsoftware engineering project\n\u2022\t Software \nProject \nPlanning, \nwhich \naddresses the activities undertaken to pre-\npare for a successful software engineering \nproject from the management perspective\n\u2022\t Software Project Enactment, which deals \nwith generally accepted SEM activities \nthat occur during a software engineering \nproject\u2019s execution\n\u2022\t Review and Evaluation, which deals with \nensuring that technical, schedule, cost \nand quality engineering activities are \nsatisfactory \n\u2022\t Closure, which addresses the activities \naccomplished to complete a project\n\u2022\t Software \nEngineering \nMeasurement, \nwhich deals with the effective develop-\nment and implementation of measure-\nment programs in software engineering \norganizations\n\u2022\t Software \nEngineering \nManagement \nTools, which describes the selection and \nuse of tools for managing a software \nengineering project\n1.\t\nInitiation and Scope Definition \nProject initiation focuses on reviewing the \nsoftware requirements and determining the \nneed, scope, feasibility, and authorization for \na software project Once project feasibility has \nbeen established, the remaining tasks in this \nsection are specifying the software require-\nments and selecting the processes for require-\nments revision and review. \n1.1.\t Determination and Negotiation of \nRequirements \b\n[3*, c3]\nDetermining and negotiating the project \nrequirements are the overarching goals of \nthe tasks undertaken during this phase (see \nthe Software Architecture KA and Software \nRequirements KA). Activities should include \nsoftware requirements review (e.g., elicita-\ntion, analysis, specification, and validation). \nMethods and techniques should be selected \nand applied considering the various stake-\nholder perspectives. Requirements provide the \nbasis for all that follows on a software project \nand are captured in a Project Charter or other \nhigh-level project initiation document. \n1.2.\t Feasibility Analysis \b\n[4*, c5]\nThe purpose of the feasibility analysis is to \ndevelop a clear description of project objec-\ntives and to evaluate alternative approaches to \ndetermine whether the proposed project solu-\ntion is the best approach, given the constraints \nof technology, resources, finances and changes \nto ethical, environmental, and socio-technical \nconsiderations. An initial project and product \nscope statement, project deliverables, project \nduration constraints, and an estimation of \nresources needed should be prepared.\nResources (which can be internal or external \nto the organization) include infrastructure, \nsupport, and people with the necessary core \ncompetencies. The feasibility analysis often \nrequires estimations of effort and cost based \non appropriate methods. (See Section 2.3, \nEffort, Schedule and Cost Estimation.) \nAn initial work breakdown structure \n(WBS) and context diagram may be devel-\noped during the project\u2019s Initiation and Scope \nDefinition phase activities. Breaking work \ninto smaller tasks is a common productivity \n", "page": 209, "type": "text", "section": "Page 209"}
{"text": "SOFTWARE ENGINEERING MANAGEMENT   9-7\ntechnique that makes the work more man-\nageable and approachable. As the project \ntool that uses this technique,\u00a0 WBS\u00a0 is an \nimportant project management document. \nWhile a WBS can be used to organize cost \nand schedule tracking, the WBS does not \nitself include cost and schedule baselines. \nSchedules are developed as part of the next \nactivity, project planning (section 2).\nAn engineering context diagram defines \nthe boundary between the system (or a part \nof the system) and its environment, showing \nthe entities interacting with it. This document \nis important in defining management and \ntechnical interfaces and trade-offs that must \nbe considered [1]. While engineers are devel-\noping the WBS, they should consider all con-\nfiguration items as tasks to have under control.\n1.3.\t Process for the Review and Revision of \nRequirements \b\n[3*, c3]\nGiven the inevitability of change, stake-\nholders should agree on how requirements \nand scope will be reviewed and revised (e.g., \nchange management and trade-off proce-\ndures, iterative cycle retrospectives). (See \nthe Requirements KA.)  This indicates that \nscope and requirements will not be \u201cset in \nstone\u201d but can and should be revisited at \npredetermined points as the project unfolds \n(for example, at the time when backlog pri-\norities are created or at milestone reviews). \nIf changes are accepted, then forward or \nbackward traceability analysis and risk anal-\nysis should be used to ascertain the impact \nof those changes. For example, backward \ntraceability may link the test script to its \nassociated requirement and design. This \nlink helps monitor the status of require-\nments satisfaction and helps make deci-\nsions to stop testing. It also helps in making \ntradeoffs \nregarding \nrequirements \nand \ndesign. (See Section 2.5, Risk Management, \nand Software Configuration Control in the \nSoftware Configuration Management KA.) \nA managed-change approach can also form \nthe basis for evaluating success during closure \nof an incremental cycle or an entire project, \nbased on changes that occurred along the way. \n(See Topic 5, Closure).\n2.\t\nSoftware Project Planning\nA key step in software project planning should \nbe selecting an appropriate SDLC model and, \nperhaps, tailoring it based on project scope, \nsoftware requirements and a risk assess-\nment. The SWX [2] states that project life \ncycles occupy a continuum from predictive to \nadaptive. Factors that characterize the posi-\ntions of software project life cycles within \nthe continuum include (but are not limited \nto) the various ways requirements and plans \nare handled, how risk and cost are managed, \nand key stakeholder involvement. Highly pre-\ndictive software project life cycles emphasize \nrequirements specification and detailed plan-\nning during the project\u2019s initiation and plan-\nning phases. Detailed plans based on a known \narchitecture, requirements and constraints are \nused to reduce risk and cost. Milestones are \nplanned, versus continuous key stakeholder \ninvolvement. Highly adaptive software project \nlife cycles, on the other hand, are character-\nized by progressive requirements specification \nbased on short iterative development cycles. \nRisk and cost are reduced by progressive evo-\nlution of initial plans, and key stakeholders \nare continuously involved [2].\nOther factors to consider include the \nnature of the application domain, func-\ntional and technical complexity, and software \nquality requirements. (See Software Quality \nRequirements in the Software Quality KA.) \nIn all SDLCs, risk assessment should be \nan element of initial project planning, and \nthe \u201crisk profile\u201d of the project should be dis-\ncussed and accepted by all relevant stake-\nholders. \nSoftware \nquality \nmanagement \nprocesses (see Software Quality Management \nProcesses in the Software Quality KA) \nshould be planned along with project plan-\nning.  This planning should establish proce-\ndures and responsibilities for software quality \nassurance (SQA), verification and valida-\ntion, reviews, and audits. (See the Software \nQuality KA.) Processes and responsibilities \n", "page": 210, "type": "text", "section": "Page 210"}
{"text": "9-8   SWEBOK \u00ae GUIDE V4.0\nfor ongoing review and revision of the project \nplan and related plans should also be clearly \nstated and agreed upon.\n2.1.\t Process Planning \n \b\n[3*, c3, c4, c5], [5*, c1]\nSDLC models span a continuum from pre-\ndictive to adaptive. (See Software Life Cycle \nModels in the Software Engineering Process \nKA.) Predictive SDLCs are characterized by \nthe development of detailed software archi-\ntecture and software requirements, detailed \nproject planning, and minimal planning \nfor iteration among development phases. \nAdaptive SDLCs are designed to accommo-\ndate emergent software requirements and \niterative adjustment of plans. A highly pre-\ndictive SDLC executes the first five pro-\ncesses listed in Figure 9-1 in a linear sequence \nwith revisions to earlier phases only as nec-\nessary. Adaptive SDLCs are characterized \nby iterative development cycles. SDLCs in \nthe midrange of the SDLC continuum pro-\nduce increments of functionality on either a \npreplanned schedule (on the predictive side \nof the continuum) or as the products of fre-\nquently updated development cycles (on the \nadaptive side of the continuum).\nWell-known SDLCs include the water-\nfall, incremental and spiral models, plus var-\nious Agile software development approaches \n[2, 11] [3*, c2]. \nRelevant methods (see the Software \nEngineering Models and Methods KA) and \ntools should be selected as part of planning. \nAutomated tools that will be used throughout \nthe project should also be planned for and \nacquired. Tools might include those for \nproject scheduling, software requirements, \nsoftware design, software construction, soft-\nware maintenance, software configuration \nmanagement, software engineering process \nand software quality, among others. Many of \nthese tools should be selected based primarily \non the technical considerations discussed in \nother KAs, but some of those concerns are \nclosely related to the management consider-\nations discussed in this chapter. \n2.2. Determine Deliverables \n\b\n[3*, c4, c5, c6]\nEach project activity\u2019s work product(s) (e.g., \nsoftware architecture design documents, \ninspection reports, tested software) should be \nidentified and characterized. Opportunities to \nreuse software components from previous proj-\nects or to use off-the-shelf software products \nshould be evaluated. Software procurement \nand use of third parties to develop delivera-\nbles should be planned and suppliers selected. \n(See Section 3.2, Software Acquisition and \nSupplier Contract Management.) \n2.3. Effort, Schedule, and Cost Estimation\nThe topic of estimation in general is addressed \nin the Software Engineering Economics KA. \nQuestions like \u201cWhat is estimation?\u201d and \n\u201cWhy do we estimate?\u201d are addressed there. \nThis section addresses management-specific \nestimation topics.\nEstimating costs for software projects is an \nerror-prone process. The effort required for any \ngiven software project depends almost entirely \non human elements: individuals\u2019 experience \nand capabilities, team members\u2019 interactions, \nand the culture of the software development \nenvironment. Dynamic environmental factors, \nsuch as rapid technology evolution, changing \nand emergent requirements, and the intangible \nnature of the product, also significantly affect \ncost management. Estimating costs when this \nmuch variability exists is difficult even when \nsignificant historical data exists. Software \nproject managers should use multiple estima-\ntion approaches and then reconcile the differ-\nences among the estimates [3, 10, 11].\nWhen data is available, the estimated range \nof effort required for a project, or parts of a \nproject, can be determined using a calibrated \nestimation model based on historical size and \neffort data. It is best to also use bottom-up \nestimation techniques based on estimates \nfrom those who will accomplish the work and \nhistorical data based on similar projects [2]. \nTask dependencies can be established, and \npotential opportunities for completing tasks \n", "page": 211, "type": "text", "section": "Page 211"}
{"text": "SOFTWARE ENGINEERING MANAGEMENT   9-9\nconcurrently and sequentially can be identi-\nfied and documented, using a Gantt chart, \nfor example. In predictive SDLC projects, \nthe expected schedule of tasks, with projected \nstart times, durations and end times, is typ-\nically produced during planning. In adaptive \nSDLC projects, an overall estimate of effort \nand schedule is typically developed from the \ninitial understanding of the requirements, or, \nalternatively, constraints on overall effort and \nschedule may be specified and used to deter-\nmine an initial estimate of the number of iter-\native cycles and estimates of effort and other \nresources allocated to each cycle. \nResource \nrequirements \n(for \nexample, \npeople and tools needed) can usually be \ntranslated into cost estimates. The estima-\ntion of effort, schedule and cost is an itera-\ntive activity that should be negotiated and \nrevised among affected stakeholders until \nconsensus is reached on resources and time \navailable for project completion. Program \nmanagers often use a model that links four \nassociation role types: responsible, account-\nable, consulted, and informed (i.e., RACI) to \nfacilitate this process.\u00a0 Responsible\u00a0 roles pro-\nduce deliverables;\u00a0 accountable\u00a0 roles check \nthe deliverables;\u00a0 consulted\u00a0 roles advise on \ntasks; and\u00a0 informed\u00a0 roles are kept informed \nthroughout these processes.  Project managers \nshould constantly monitor stakeholder require-\nments and changes as they evolve to analyze \ntheir impact on the project cost and schedule. \nThis is usually more important in Agile soft-\nware development projects, where stakeholder \nrequirements are dynamic because changes \nmight occur rapidly as the project progresses.\n2.4. Resource Allocation \b\n[3*, c5, c10, c11]\nEquipment, facilities and people should be \nallocated to the identified tasks, including \nallocating responsibilities for completing var-\nious project elements and the overall project. \nA matrix that shows who is responsible for, \naccountable for, consulted about and informed \nabout each task can be used. Resource allo-\ncation is based on and constrained by the \navailability of resources and their optimal \nuse, and by issues relating to personnel (e.g., \nproductivity of individuals and teams, team \ndynamics, and team structures). \n2.5. Risk Management \b\n[3*, c9] [5*, c5]\nRisk and uncertainty are related but distinct \nconcepts. Uncertainty results from a lack of \ninformation. Risk is effect of uncertainty on \nobjectives that has negative (threats) or positive \n(opportunities) consequences on objectives.\nRisk management entails identifying risk \nfactors, analyzing probability and potential \nimpact of each risk factor, prioritizing risk \nfactors, and developing risk mitigation strat-\negies to reduce the probability of a negative \nevent and to minimize the negative impact if \na risk factor becomes a problem. Risk man-\nagement data can be used to represent the \nproject risk profile; this data is often part of \na risk register. A risk register is a document \nused as a risk management tool. It can be used \nto fulfill regulatory compliance, serving as a \nrepository for all risks identified and for addi-\ntional information about each risk [2]. Risk \nassessment methods (e.g., expert judgment, \nhistorical data, decision trees and process \nsimulations) can sometimes be used to iden-\ntify and evaluate risk factors. \nProject abandonment conditions can also \nbe determined with all relevant stakeholders. \nSoftware-unique aspects of risk, such as soft-\nware engineers\u2019 tendency to add unneeded \nfeatures or the risks related to software\u2019s \nintangible nature, can influence risk man-\nagement for software projects. Particular \nattention should be paid to managing risks \nrelated to software quality requirements such \nas safety or security [11]. (See the Software \nQuality KA.) Risk management should be \ndone not only at the beginning of a project, \nbut also at periodic intervals throughout the \nproject life cycle.\n2.6. Quality Management  \n\b\n[3*, c4] [4*, c2]\nAccording to the PMBOK\u00ae Guide, Project \nquality management includes the performing \n", "page": 212, "type": "text", "section": "Page 212"}
{"text": "9-10   SWEBOK \u00ae GUIDE V4.0\norganization\u2019s processes and activities that \ndetermine quality policies, objectives and \nresponsibilities so the project will satisfy \nthe needs for which it was undertaken. This \nsection discusses additional considerations \nfor managing software project quality [1]. \nSoftware quality requirements for a soft-\nware project and the associated work prod-\nucts should be identified, perhaps both \nquantitatively and qualitatively. Quality \nattributes of software include but are not \nlimited to safety, security, reliability, avail-\nability, performance, ease of use and ease of \nmodification. SWX Section 1.9 lists quality \nattributes that are important for software \nusers (e.g., efficiency, safety, security, reli-\nability, availability) and quality attributes \nthat are important to software developers \nand maintainers (e.g., maintainability is \nimportant to those who provide sustain-\nment services) [1]. ISO/IEC 25000 series \nof standards provides extensive lists of \nsoftware quality attributes that align with \ndifferent stakeholder needs [2]. This align-\nment is consistent with ISO/IEC/IEEE \n15939 and practical software and systems \nmeasurement (PSM) [2, 9.11].\nLarge portions of system functionality \nare shifting from hardware to software to \ncapitalize on the increased flexibility and \nspeed of component delivery that soft-\nware can provide. However, with these \nbenefits come other challenges \u2014 for \nexample, the need for increased man-\nagement of software quality require-\nments (e.g., cybersecurity) throughout \nthe SDLC [11]. Thresholds for acceptable \nquality measurements should be set for \neach software quality requirement based \non stakeholder needs and expectations. \nProcedures concerned with ongoing SQA \nand quality improvement throughout \nthe development process and with veri-\nfying and validating the deliverable soft-\nware product should also be specified \nduring quality planning (e.g., technical \nreviews and inspections or demonstra-\ntions of completed functionality). (See \nthe Software Quality KA.) \n2.7. Plan Management \b\n[3*, c4]\nExcept for older predictive programs, doc-\numenting and managing formal plans are \nbecoming less emphasized in managing most \nsoftware projects. (e.g., documentation plans \nare rarely used, especially when Model-Based \nSystems Engineering (MBSE) is used for \nproduct data). The said, where they are used, \nplans should be developed and managed for \nsoftware projects when change is expected. \nThe magnitude of the planning effort and the \nplan\u2019s content should be determined partly \nby the risk of not developing the plan. The \nmanagement of the project plan should itself \nbe planned. Plans and processes selected for \nsoftware development should be systemat-\nically monitored, reviewed, reported and, \nwhen appropriate, revised. Plans associated \nwith supporting processes (e.g., documenta-\ntion, software configuration management, \nand problem resolution) also should be man-\naged. Reporting, monitoring and controlling \na project should fit within the selected SDLC \nand the realities of the project. Plans should \naccount for the various artifacts that will be \nused to manage the project.\nProject managers of predictive life cycle \nsoftware projects put substantial effort into \nup-front development of the project plan and \nintegration of subsidiary plans developed \nby support personnel from other organiza-\ntional units (e.g., estimation specialists in the \nProject Management Office (PMO)). \nIn other types of programs (e.g., adap-\ntive programs) where formal plans are not \nusually used, the emphasis should be on \nselecting and retaining project information \nuseful in project control and future projects, \nand establishing strategy, policies, and pro-\ncedures. For example, in adaptive programs, \nmanagers will usually spend less effort up \nfront on developing detailed scope, cost and \nschedule plans. But significant effort is typ-\nically spent defining monitor and control \nprocesses, such as requirements traceability, \nto ensure coordination among the project \nmembers or teams as the emerging plans are \nimplemented [2]. \n", "page": 213, "type": "text", "section": "Page 213"}
{"text": "SOFTWARE ENGINEERING MANAGEMENT   9-11\n3.\t\nSoftware Project Execution\nDuring software project enactment (also \nknown as project execution), plans are imple-\nmented, and the processes embodied in the \nplans are enacted. Throughout, there should \nbe a focus on adherence to the selected SDLC \nprocesses, with an overriding expectation that \nadherence will satisfy stakeholder require-\nments and achieve the project\u2019s objectives. \nFundamental to enactment are the ongoing \nmanagement activities of monitoring, con-\ntrolling and reporting.\n3.1.\t  Implementation of Plans \b\n[4*, c2]\nProject activities should follow the project plan \nand supporting plans. Project activities use \nresources (personnel, technology and funding) \nand generate work products (software design, \nsoftware code and software test cases).\n3.2.\t  Software Acquisition and Supplier \nContract Management \b\n[3*, c3, c4]\nSoftware acquisition and supplier contract \nmanagement concern issues involved in con-\ntracting with customers of the software \ndevelopment organization who acquire the \ndeliverable work products and with suppliers \nwho supply products or services to the soft-\nware engineering organization. \nSoftware acquisition is common practice \nin software development projects, with inte-\ngrated development environments (IDEs) \nand package libraries allowing software \nengineers to acquire third-party libraries \nwith minimal steps, facilitating the assess-\nment of risk, legality and suitability. \nHowever, software is no longer exclusively \nacquired as a shrink-wrapped product via \na complex supply chain process and pur-\nchasing route. The ease of acquiring soft-\nware has resulted in a common attack \nsurface and led to security vulnerabilities. \nOrganizations should consider introducing \ntechnical or procedural controls to minimize \nrisk potentially exposed by unfiltered access \nto external library repositories.\nThe different software acquisition classes \ninclude commercial off-the-shelf (COTS) \nsoftware \u2014 an existing product acquired \u201cas \nis\u201d from another software vendor, with appli-\ncable license terms; software developed exclu-\nsively for the organization by another party \n\u2014 typically contracted and sometimes a cus-\ntomization of COTS software; open source \nsoftware \u2014 nominally free, although the orga-\nnization may purchase enhanced support or \nmaintenance and must review the license for \nrestrictions on use; customer loaned software \n\u2014 typically to provide simulation or integra-\ntion with another system element; software as \na service (SaaS) \u2014 which might include soft-\nware the organization rents to fulfill a partic-\nular need (for example, a cloud-based hosting, \nsource control or development environment).\nSoftware projects typically use different \nacquisition approaches to obtain the necessary \nsoftware components. However, regardless of \nhow the software components are obtained, \nthe following activities should be performed: \nverifying that each component is complete, \ncorrect and consistent concerning the archi-\ntectural design and software requirements for \nthat component; integrating the components; \nverifying that the integrated components are \ncorrect, complete and consistent concerning \nthe architectural design and the software \nrequirements; and validating that the inte-\ngrated components will satisfy their intended \npurpose when used in their intended oper-\nating environment.\nDifferent \nacquisition \napproaches \n(for \nobtaining software components) require dif-\nferent approaches to managing the project. \nFor example, custom development requires \ndetailed planning for the numbers and skills \nof the software developers, organizing the \ndevelopment team(s), allocating requirements \nto the teams, specifying project metrics to be \ncollected, monitoring progress, and applying \ncorrective actions when actual progress does \nnot agree with planned progress. Licensing \ncomponents involves evaluating candidate \ncomponents; selecting appropriate compo-\nnents; and negotiating terms, conditions, and \ndelivery dates for the selected components. \n", "page": 214, "type": "text", "section": "Page 214"}
{"text": "9-12   SWEBOK \u00ae GUIDE V4.0\nThis might involve selecting appropriate \ncontracts, such as fixed price, time-and-mate-\nrials, cost plus fixed fee, and cost-plus incentive \nfee. Agreements with customers and suppliers \ntypically specify the scope of work and the \ndeliverables. The agreements can also include \nspecial clauses, such as clauses establishing \npenalties for late delivery or no delivery, and \nintellectual property agreements that specify \nwhat the suppliers are providing and what \nthe acquirer is paying for, plus what will be \ndelivered to and owned by the acquirer. For \nsoftware developed by suppliers (both those \ninternal to and those external to the software \ndevelopment organization), agreements com-\nmonly establish software quality requirements.\nIn software contracting with suppliers, \ndata set acquisition is usually important. It \nincludes the process of obtaining specific \ndatasets from external vendors or partners \nas part of a software development project or \nservice agreement. This can occur in various \nscenarios, such as: date licensing agreements, \ndata provisioning, custom data acquisition \nand data integration services.\nAfter the agreement has been put in place, \nexecuting the project in compliance with \nthe terms of the agreement should be man-\naged. (See Chapter 12, Software Extension \nto the PMBOK\u00ae Guide (SWX), Software \nProcurement Management, for more infor-\nmation on this topic [2].) \n3.3.\t  Implementation of Measurement Process \n\b\n[3*, c7]\nThe measurement process should be enacted \nduring the software project to ensure that \nrelevant and useful data is collected. (See \nSections 6.2, Plan the Measurement Process, \nand 6.3, Perform the Measurement Process.)\n3.4.\t  Monitor Process \b\n[3*, c8]\nAdherence to the scope, project plan and \nrelated plans should be assessed continually \nand at predetermined intervals. Outputs and \ncompletion criteria for each task should also \nbe assessed. Deliverables should be evaluated \nfor their required characteristics (for example, \nvia inspections or by demonstrating working \nfunctionality). Effort expenditure, schedule \nadherence, costs to date, and resource use \nshould be analyzed. The project risk pro-\nfile (see Section 2.5, Risk Management) \nshould be revisited, and adherence to soft-\nware quality requirements should be evalu-\nated (see Software Quality Requirements in \nthe Software Quality KA). \nMeasurement data should be analyzed. \n(See Statistical Analysis in the Engineering \nFoundations KA.) Variance analysis should \nbe conducted to determine deviation of actual \nfrom expected outcomes and values. This anal-\nysis might examine cost overruns, schedule \nslippage or other measures. Outlier identifica-\ntion and analysis of quality and other measure-\nment data should be performed (e.g., defect \nanalysis). (See Software Quality Measurement \nin the Software Quality KA.) Risk exposures \nshould be recalculated. (See Section 2.5, Risk \nManagement.) These activities can enable \nproblem detection and exception identification \nbased on thresholds that have been exceeded. \nOutcomes should be reported as necessary \nor when thresholds have been exceeded. For \nexample, the timely identification, mitigation, \nand resolution of software security vulnerabil-\nities and weaknesses that exceed expectations \ncan affect the system\u2019s security posture [11].\n3.5.\t  Control Process \b\n[3*, c7, c8]\nProject monitoring activities provide the basis \nfor making decisions. Where appropriate, and \nwhen the probability and impact of risk fac-\ntors are understood, changes can be made to \nthe project. This may take the form of cor-\nrective action (e.g., retesting certain software \ncomponents). It might involve incorporating \nadditional actions (e.g., deciding to use pro-\ntotyping to assist in software requirements \nvalidation; see Prototyping in the Software \nRequirements KA). It might also entail \nrevising the project plan and other project \ndocuments (e.g., the software requirements \nspecification) to accommodate unanticipated \nevents and their implications.\n", "page": 215, "type": "text", "section": "Page 215"}
{"text": "SOFTWARE ENGINEERING MANAGEMENT   9-13\nIn some instances, the control process \nmight lead to abandonment of the project. \nIn all cases, the software development team \nshould adhere to software configuration con-\ntrol and software configuration management \nprocedures. (See the Software Configuration \nManagement KA.) Decisions should be doc-\numented and communicated to all relevant \nparties, plans should be revisited and revised \nwhen necessary, and relevant data should \nbe recorded. (See Section 6.3, Perform the \nMeasurement Process.) \n3.6.\t  Reporting \b\n[3*, c11]\nProgress to date should be reported at spec-\nified and agreed-upon times both within the \norganization (e.g., to a project steering com-\nmittee) and to external stakeholders (e.g., cli-\nents or users). Reports should focus on the \ninformation needs of the target audience \nas opposed to the detailed status reporting \nwithin the project team. \n4.\t\nSoftware Review and Evaluation\nAt prespecified times and as needed, overall \nprogress toward the stated objectives and \nsatisfaction of stakeholder (user and cus-\ntomer) requirements should be evaluated. \nSimilarly, assessments of the effectiveness of \nthe software process, the personnel involved, \nand the tools and methods used should also \nbe undertaken regularly and as circum-\nstances demand.\n4.1.\t  Determining Satisfaction of Requirements \n\b\n[4*, c8]\nAchieving stakeholder satisfaction is a prin-\ncipal goal of the software engineering man-\nager. Progress toward this goal should be \nassessed periodically. Progress should be \nassessed upon achieving a major project \nmilestone (e.g., completing software design \narchitecture or completing a software tech-\nnical review) or upon completion of an iter-\native development cycle that results in a \nproduct increment. Variances from software \nrequirements should be identified, and appro-\npriate actions should be taken.\nAs in the control process activity above (see \nSection 3.5, Control Process), software con-\nfiguration control and software configuration \nmanagement procedures should be followed \n(see the Software Configuration Management \nKA). Decisions should be documented and \ncommunicated to all relevant parties; plans \nshould be revisited and revised as neces-\nsary; and relevant data should be recorded \n(see Section 6.3, Perform the Measurement \nProcess). \n4.2.\t  Reviewing and Evaluating Performance \n\b\n[3*, c8, c10]\nPeriodic performance reviews for project per-\nsonnel can provide insight into the likelihood \nof adherence to plans and processes and pos-\nsible areas of difficulty (e.g., team member \nconflicts). The various project methods, tools \nand techniques should be evaluated for effec-\ntiveness and appropriateness. The project\u2019s \nprocess should also be systematically and \nperiodically assessed for relevance, utility and \nefficacy. Where appropriate, project changes \nshould be made and managed. \n5.\t\nClosure\nAn entire project, a major project phase or \nan iterative development cycle reaches clo-\nsure when all the plans and processes have \nbeen enacted and completed. The criteria for \nproject, phase or iteration success should then \nbe evaluated. Once closure has been estab-\nlished, archival, retrospective and process \nimprovement activities can be performed.\n5.1.\t  Determining Closure \b\n[1, s3.7, s4.6]\nClosure occurs when the specified tasks for \na project, a phase or an iteration have been \ncompleted and satisfactory achievement of \nthe completion criteria has been confirmed. \nSoftware requirements can be confirmed as \nsatisfied or not, and the degree of achieving \nthe objectives can be determined. Closure \n", "page": 216, "type": "text", "section": "Page 216"}
{"text": "9-14   SWEBOK \u00ae GUIDE V4.0\nprocesses should involve relevant stake-\nholders and document relevant stakeholders\u2019 \nacceptance; any known problems should be \ndocumented. \n5.2.\t  Closure Activities \b\n[2, s3.7, s4.8]\nAfter closure has been confirmed, project \nmaterials should be archived in accordance \nwith stakeholder agreed-upon rules for \narchival methods, location and duration \u2014 \npossibly including destruction of sensitive \ninformation, software and the medium on \nwhich copies are resident. For example, these \nrules could require that during closure, all data \nis removed and destroyed from any devices \nthat contain relevant information before \nphysical disposal of the devices (e.g., the hard \ndrives of personal computers, servers, main-\nframes, personal digital assistants (PDAs), \nrouters, firewalls, switches, tapes, diskettes, \nCDs, DVDs, cell phones, printers, universal \nserial bus (USB) data storage devices). \nThe organization\u2019s measurement database \nshould be updated with relevant project data. \nA project, phase or iteration retrospective \nanalysis should be undertaken so that issues, \nproblems, risks and opportunities encoun-\ntered can be analyzed. (See Topic 4, Review \nand Evaluation.) Lessons learned should be \ndrawn from the project and fed into organiza-\ntional learning and improvement endeavors. \n6.\t\nSoftware Engineering Measurement \nThe importance of software engineering mea-\nsurement for good management and engi-\nneering practices is widely acknowledged. \n(See Measurement in the Engineering \nFoundations KA.) Effective software engi-\nneering measurement has become one of \nthe cornerstones of organizational maturity. \nMeasurement can be applied to organiza-\ntions, projects, processes and work products. \nThis section focuses on applying measure-\nment at the levels of projects, processes and \nwork products.\n1\t  These two chapters can be downloaded free of charge from http://www.psmsc.com/PSMBook.asp.\nThis \nsection \nfollows \nISO/IEC/IEEE \n15939 standard [6], which describes a pro-\ncess to define the activities and tasks neces-\nsary to implement a software measurement \nprocess. The standard also includes a mea-\nsurement information model. This model in \nthe PSM Continuous Iterative Development \nMeasurement Framework report is also elab-\norated for SDLC approaches [9].\n6.1.\t  Establish and Sustain Measurement \nCommitment \b\n[7*, c1, c2]1\n\u2022\t Establish measurement requirements. \nEach measurement endeavor should be \nguided by organizational objectives and \ndriven by a set of measurement require-\nments established by the organization \nand the project (e.g., an organizational \nobjective might be first to market).\n\u2022\t Establish the scope of measurement. \nThe project team should establish the \norganizational unit to which each mea-\nsurement requirement is to be applied. \nThis might be a functional area, a \nsingle project, a single site or an entire \nenterprise. The temporal scope of the \nmeasurement effort should also be con-\nsidered because the time series of some \nmeasurements might be required (e.g., \nto calibrate estimation models). (See \nSection 2.3, Effort, Schedule and Cost \nEstimation.) \n\u2022\t Establish the team\u2019s commitment to \nmeasurement. The commitment should \nbe formally established, communicated \nand supported by resources.\n\u2022\t Commit measurement resources. An \norganization\u2019s commitment to mea-\nsurement is an essential factor for suc-\ncess, as evidenced by the assignment of \nresources for implementing the mea-\nsurement process. Assigning resources \nincludes allocation of responsibility for \nthe various tasks of the measurement \nprocess (such as analyst and librarian). \nAdequate funding, training, tools and \n", "page": 217, "type": "text", "section": "Page 217"}
{"text": "SOFTWARE ENGINEERING MANAGEMENT   9-15\nsupport to conduct the process should \nalso be allocated. \n6.2.\t  Plan the Measurement Process  \n\b\n[7*, c1, c2]1\n\u2022\t Characterize the organizational unit. The \norganizational unit provides the context \nfor measurement, so the organizational \ncontext should be explicit, including the \norganization\u2019s constraints on the mea-\nsurement process. The characterization \ncan be stated in terms of organizational \nprocesses, application domains, tech-\nnology, organizational interfaces and \norganizational structure.\n\u2022\t  Identify information needs. Information \nneeds are based on the organizational \nunit\u2019s goals, constraints, risks, and prob-\nlems and may be derived from business, \norganizational, regulatory and/or product \nobjectives. Stakeholders should identify, \nprioritize, document, communicate and \nreview these needs. \n\u2022\t Select measures. Select candidate mea-\nsures, with clear links to the information \nneeds. Select measures based on the pri-\norities of the information needs and other \ncriteria such as cost of collection; degree \nof process disruption during collection; \nease of obtaining accurate, consistent \ndata; and ease of analysis and reporting. \nInternal \nquality \ncharacteristics \n(see \nModels and Quality Characteristics in \nthe Software Quality KA) are often not \ncontained in the contractually binding \nsoftware requirements. Therefore, con-\nsider measuring the software\u2019s internal \nquality to provide an early indicator of \npotential issues that might affect external \nstakeholders.\n\u2022\t Define data collection, analysis and \nreporting procedures. This encompasses \ncollection procedures and schedules, \nstorage, verification, analysis, reporting \nand data configuration management.\n\u2022\t Select criteria for evaluating the infor-\nmation products. The organizational \nunit\u2019s technical and business objectives \ninfluence evaluation criteria. Information \nproducts include those associated with \nthe product produced and those associ-\nated with the processes used to manage \nand measure the project.\n\u2022\t Provide resources for measurement tasks. \nThe appropriate stakeholders should \nreview and approve the measurement \nplan to include all data collection pro-\ncedures; storage, analysis, and reporting \nprocedures; evaluation criteria; sched-\nules; and responsibilities. Criteria for \nreviewing these artifacts should be estab-\nlished at the organizational unit level or \nhigher and should be used as the basis for \nthese reviews. Such criteria should con-\nsider experience, resource availability and \npotential disruptions to projects when \nchanges from current practices are pro-\nposed. Approval demonstrates commit-\nment to the measurement process.\no\tIdentify resources to be made avail-\nable for implementing the planned and \napproved measurement tasks. Resource \navailability may be staged in cases where \nchanges are piloted before widespread \ndeployment. Consider the resources \nnecessary for successful deployment of \nnew procedures or measures.\no\tAcquire and deploy supporting tech-\nnologies. This includes evaluating \navailable \nsupporting \ntechnologies, \nselecting the most appropriate tech-\nnologies, acquiring those technologies \nand deploying those technologies.\n6.3.\t  Perform the Measurement Process  \n\b\n[7*, c1, c2]\nIntegrate measurement procedures with rel-\nevant software processes. The measurement \nprocedures, such as data collection, should \nbe integrated into the software processes they \nmeasure. This might involve changing current \nsoftware processes to accommodate data col-\nlection or generation activities. It might also \ninvolve analyzing current software processes \nto minimize additional effort and evaluating \n", "page": 218, "type": "text", "section": "Page 218"}
{"text": "9-16   SWEBOK \u00ae GUIDE V4.0\nthe effect on employees to ensure acceptance \nof the measurement procedures. Consider \nmorale issues and other human factors. In \naddition, communicate the measurement pro-\ncedures to those providing the data. Training \nand support might also be needed. Data anal-\nysis and reporting procedures are typically \nintegrated similarly into organizational and \nproject processes.\nCollect data. Measurement data should be \ncollected and analyzed. Data should be col-\nlected, verified and stored. Collection can \nsometimes be automated by using SEM \ntools (see Topic 7, Software Engineering \nManagement Tools) to analyze data and \ndevelop reports. Data may be aggregated, \ntransformed or recorded as part of the analysis, \nusing a degree of rigor appropriate to the nature \nof the data and the information needs. This \nanalysis typically produces graphs, numbers or \nother indicators that inform conclusions and \nrecommendations to present to stakeholders. \n(See Statistical Analysis in the Engineering \nFoundations KA.) The results and conclusions \nare reviewed using the organization\u2019s formal \nor informal process. Data providers and mea-\nsurement users should participate in reviewing \nthe data to ensure it is meaningful and accurate \nand can result in reasonable actions.\nCommunicate results. Document and \ncommunicate information products to users \nand stakeholders.\n6.4.\t  Evaluate Measurement \b\n[7*, c1, c2]\nEvaluate information products and the mea-\nsurement process against specified evalua-\ntion criteria, and determine the strengths \nand weaknesses of the information products \nor process. An internal process or an external \naudit can be used to perform the evaluation, \nincluding feedback from measurement users. \nRecord lessons learned in an appropriate \ndatabase. \nIdentify potential improvements. Such \nimprovements might be changes in the format \nof indicators, changes in units measured or \nreclassification of measurement categories. \nDetermine potential improvements\u2019 costs \nand benefits, and report appropriate improve-\nment actions. \nCommunicate proposed improvements to \nthe measurement process owner and stake-\nholders for review and approval. Also, com-\nmunicate the lack of potential improvements \nif the analysis fails to identify any.\n7.\t\n Software Engineering Management \nTools \b\n[3*, c5, c6, c7]\nSEM tools are often used to provide visibility \nand control of SEM processes. Some tools are \nautomated, whereas others are manually imple-\nmented. In addition, there has been a recent \ntrend toward using integrated suites of software \nengineering tools throughout a project to plan, \ncollect and record, monitor and control, and \nreport project and product information. Tools \ncan be divided into the following categories: \nProject planning and tracking tools. Project \nplanning and tracking tools can be used to \nestimate project effort and cost and to prepare \nproject schedules. For example, some proj-\nects use automated estimation tools that use \na software product\u2019s estimated size and other \ncharacteristics as input and then estimate \nthe required total effort, schedule and cost. \nPlanning tools also include automated sched-\nuling tools that analyze the WBS tasks, their \nestimated durations, their precedence rela-\ntionships and the resources assigned to each \ntask to produce a Gantt chart. \nTracking tools can be used to track project \nmilestones, regularly scheduled project status \nmeetings, scheduled iteration cycles, product \ndemonstrations and action items.\nRisk management tools. Risk management \ntools (see Section 2.5, Risk Management) \ncan be used to track risk identification, anal-\nysis and monitoring. These tools include sim-\nulation or decision trees to analyze the effect \nof costs versus payoffs and subjective esti-\nmates of the probabilities of risk events. For \nexample, Monte Carlo simulation tools can \nbe used to produce probability distributions \nof effort, schedule and risk by algorithmi-\ncally combining multiple input probability \ndistributions.\n", "page": 219, "type": "text", "section": "Page 219"}
{"text": "SOFTWARE ENGINEERING MANAGEMENT   9-17\nCommunication tools. Communication tools \ncan help provide timely and consistent infor-\nmation to relevant stakeholders involved in \na project. Examples of such tools are email \nnotifications and broadcasts to team mem-\nbers and stakeholders; regular communica-\ntions of meeting minutes; and charts showing \nprogress, backlogs, and maintenance request \nresolutions. \nMeasurement tools. Measurement tools sup-\nport activities related to the software mea-\nsurement program. (See Topic 6, Software \nEngineering Measurement.) There are few \ncompletely automated tools in this cate-\ngory. Measurement tools to gather, analyze \nand report project measurement data may be \nbased on spreadsheets developed by project \nteam members or organizational employees.\nMATRIX OF TOPICS VS. REFERENCE MATERIAL\nFairley 2009 \n[3*]\nSommerville \n2011 [4*]\nBoehm and \nTurner 2003 [5*]\nMcGarry et \nal. 2001 [7*]\n1. Initiation and Scope \nDefinition\n1.1. Determination and \nNegotiation of Requirements\nc3\n1.2. Feasibility Analysis\nc4\n1.3. Process for the Review and \nRevision of Requirements\nc3\n2. Software \nProject Planning\n2.1. Process Planning\nc2, c3, c4, c5\nc1\n2.2. Determine Deliverables\nc4, c5, c6\n2.3. Effort, Schedule and Cost \nEstimation\nc6\n2.4. Resource Allocation\nc5, c10, c11\n2.5. Risk Management\nc9 \nc5\n2.6. Quality Management\nc4\nc24\n2.7. Plan Management\nc4\n3. Software \nProject Enactment\n3.1. Implementation of Plans\nc2\n3.2. Software Acquisition and \nSupplier Contract Management\nc3, c4\n3.3. Implementation of \nMeasurement Process\nc7\n3.4. Monitor Process \nc8\n3.5. Control Process\nc7, c8\n3.6. Reporting\nc11\n4. Review and Evaluation\n4.1. Determining Satisfaction \nof Requirements\n", "page": 220, "type": "text", "section": "Page 220"}
{"text": "9-18   SWEBOK \u00ae GUIDE V4.0\n4.2. Reviewing and \nEvaluating Performance\nc8, c10\n5. Closure\n5.1. Determining Closure\n5.2. Closure Activities\n6. Software Engineering \nMeasurement\n6.1. Establish and Sustain \nMeasurement Commitment\nc1, c2\n6.2. Plan the \nMeasurement Process\nc1, c2\n6.3. Perform the \nMeasurement Process\nc1, c2\n6.4. Evaluate Measurement\nc1, c2\n7. Software Engineering \nManagement Tools\nc5, c6, c7\nFURTHER READINGS\nA Guide to the Project Management Body of \nKnowledge (PMBOK\u00ae Guide) [1].\nThe PMBOK\u00ae Guide provides guidelines for \nmanaging individual projects and defines \nproject management-related concepts. It also \ndescribes the project management life cycle \nand its related processes, and the project life \ncycle. It is a globally recognized guide for the \nproject management profession.\nSoftware Extension to the Project Management \nBody of Knowledge (PMBOK\u00ae) Guide [2].\nSWX provides adaptations of and extensions \nto the generic practices of project manage-\nment documented in the PMBOK\u00ae Guide for \nmanaging software projects. The primary con-\ntribution of this extension to the PMBOK\u00ae \nGuide is a description of processes for man-\naging adaptive life cycle software projects.\nIEEE Standard Adoption of ISO/IEC 15939 [6].\nThis international standard identifies a pro-\ncess that supports defining suitable measures \nto address specific information needs. It iden-\ntifies the activities and tasks necessary to suc-\ncessfully identify, define, select, apply and \nimprove measurement within an overall project \nor organizational measurement structure.\nJ. McDonald, Managing the Development of \nSoftware Intensive Systems, Wiley, 2010 [8].\nThis textbook introduces project management \nfor beginning software and hardware devel-\nopers, plus unique advanced material for expe-\nrienced project managers. Case studies are \nincluded for planning and managing verifica-\ntion and validation for large software projects \nand complex software and hardware systems, \nas well as inspection results and testing met-\nrics to monitor project status.\nREFERENCES\n[1]\t Project Management Institute, A \nGuide to the Project Management Body \nof Knowledge (PMBOK\u00ae Guide), 6th \ned., Newton Square, PA: Project \nManagement Institute, 2017.\n", "page": 221, "type": "text", "section": "Page 221"}
{"text": "SOFTWARE ENGINEERING MANAGEMENT   9-19\n[2]\t Software Extension to the Project \nManagement Body of Knowledge \n(PMBOK\u00ae Guide), Fifth Edition, \nProject Management Institute, 2013.\n[3*]\tR. E. Fairley, Managing and Leading \nSoftware Projects. Hoboken, NJ: Wiley \nIEEE Computer Society Press, 2009.\n[4*]\tI. Sommerville, Software Engineering, \n10th ed., New York: Addison-\nWesley, 2015.\n[5*]\tB. Boehm and R. Turner, Balancing \nAgility and Discipline: A Guide for \nthe Perplexed. Boston: Addison-\nWesley, 2003.\n[6]\t IEEE, IEEE Standard Adoption of ISO/\nIEC 15939: 2007 Systems and Software \nEngineering Measurement Process, ed: \nIEEE, 2017.\n[7*]\tJ. McGarry et al., Practical Software \nMeasurement: Objective Information \nfor Decision Makers, Addison-Wesley \nProfessional, 2001.\n[8]\t J. McDonald, Managing the \nDevelopment of Software-Intensive \nSystems. Hoboken, NJ: John Wiley and \nSons, Inc., 2010.\n[9] \t Practical Software and Systems \nMeasurement Continuous Iterative \nDevelopment Measurement Framework \nParts 1-3: Concepts, Definitions, \nPrinciples, and Measures, Version 2.1,  \n15 April 2021. \n[10]\tS. Sheard, M. Bouyaud, M. Osaisai, \nJ. Siviy, and K. Nidiffer, \u201cBook Club\u201d \nGuides a Working Group to Create \nINCOSE System-Software Interface \nProducts, INSIGHT, Volume 24, \nIssue 2, 2021.\n[11]\tK. Nidiffer, C. Woody, and T.A. \nChick, Program Manager\u2019s Guidebook \nfor Software Assurance, Special Report, \nCMU/SEI-2018-SR-025, Software \nSolutions and CERT Divisions, \nSoftware Engineering Institute/\nCarnegie Mellon University, \nAugust 2018.\n[12]\tR.E. Fairley, Systems Engineering of \nSoftware-Enabled Systems, ISBN 978-1-\n119-53501-0, 2019. \n[13]\tDefense Innovation Board, Software Is \nNever Done: Refactoring the Acquisition \nCode for Competitive Advantage Defense, \nv3.3, March 12, 2019.\n[14]\t\u201cDevOps: Building Reliable and Secure \nSystems Including Application Build, \nPackage, and Deployment,\u201d IEEE \nStandard, 2675-2021, 2021.\n[15]\tM. Chemuturi and T. Cagley, Mastering \nSoftware Project Management: Best \nPractices, Tools and Techniques, J. Ross \nPublishing, July 2010.\n", "page": 222, "type": "text", "section": "Page 222"}
{"text": "10-1 \nCHAPTER 10\nSoftware Engineering Process\nACRONYMS\nBPMN\nBusiness Process Modeling Notation\nCASE\nComputer-Aided Software \nEngineering\nCMM\nCapability Maturity Model\nCMMI\nCapability Maturity Model \nIntegration\nGQM\nGoal-Question-Metric\nIDEF0\nIntegration Definition\nKA\nKnowledge Area\nPDCA\nPlan-Do-Check-Act\nSLCM\nSoftware Life Cycle Model\nSLCP\nSoftware Life Cycle Process\nUML\nUnified Modeling Language\nINTRODUCTION TO THE KA \nThis chapter considers the software engi-\nneering process from several perspectives: \nconcepts, life cycles, and software engi-\nneering process assessment. The software \nengineering community has been very \nactive concerning the standardization of \nmany of the aspects of the software engi-\nneering process.\nBREAKDOWN OF TOPICS FOR \nTHE SOFTWARE ENGINEERING \nPROCESS KA\nThe topic breakdown for the Software \nEngineering Process KA is shown in \nFigure 10.1.\n1.\t Software Engineering Process \nFundamentals\n1.1 Introduction \b\n[1*,c5],[13]\nSoftware engineering processes involve work \nactivities software engineers conduct to build \nand operate software. When the discipline \nof software engineering emerged, scientists, \nengineers and technicians had to look at \nexisting disciplines to understand the scope \nof the software engineering process. An engi-\nneering process consists of a set of interrelated \nactivities that transform one or more inputs \ninto outputs while consuming resources to \naccomplish the transformation. As part of \nengineering, software engineering uses pro-\ncesses similar to those of other types of engi-\nneering. As engineers create devices or other \nproducts, they progress through various steps, \nexpending significant design effort, relying \non a vast trove of knowledge as they do so, at \nthe time that they gain knowledge, i.e. learn, \nabout the process they are performing and the \nproduct they are creating.\nBeginning in the 1960s and continuing in \nthe 1970s, engineering design and manufac-\nturing provided a baseline \u2014 a foundation \u2014 \nfor what would later become a new discipline. \nIn those years, it was agreed that the process \nof building software would be decomposed \ninto processes that could include design and \nmanufacturing, and later, operations. Some \nof the processes needed to construct software \nsystems fit into the design class, and others fit \ninto the manufacturing class. Today, the soft-\nware engineering community is still learning \nand, therefore, still improving the soft-\nware engineering process. Currently, a wide \nconsensus exists concerning that building \n", "page": 223, "type": "text", "section": "Page 223"}
{"text": "10-2   SWEBOK \u00ae GUIDE V4.0\nsoftware systems requires lots of design and \nlearning effort focused on the product under \nconstruction, and on the process. As it will \nbe discussed below, no ideal process, or set of \nprocesses exists:  software processes must be \nselected, adapted, and applied as appropriate \nfor each project and each organizational con-\ntext. It is essential that the software engi-\nneering process management is supported by \nempirical measurement.\nThe concept of a project emerges as an \n\u201cendeavor with defined start and finish cri-\nteria undertaken to create a product or service \nin accordance with specified resources and \nrequirements\u201d [1] or a \u201ctemporary endeavor \nundertaken to create a unique product, ser-\nvice, or result\u201d [13]. It is a concept of the man-\nagement discipline linked to clear objectives \nand bound by a limited time frame, as dis-\ncussed in knowledge area (KA) 9, Software \nEngineering Management. Software engi-\nneering processes are usually performed in the \ncontext of projects.\nMany of the processes of the more con-\nventional engineering disciplines (e.g., elec-\ntrical or chemical) include design and \nmanufacturing, where manufacturing pro-\nduces multiple units of a system (e.g., a chem-\nical reactor). This is not the case for software \nsystems, though manufacturing is useful to \ndescribe the need to build the many software \nunits that comprise a software system. In \nelectrical or chemical engineering, the oper-\nation of the engineering systems transforms \n(raw) materials, energy and physical entities \ninto other forms of material or energy. For the \nsoftware engineering discipline, an analogy \nfor this operation could be the execution of \na software unit (the output from a software \nengineering set of processes) that transforms \none kind of data into another. \nIn the rest of the section, the term process \nwill denote work activities, not the execution \nof software. \nThe Software Engineering Process KA \nis closely related to most of the SWEBOK \nSoftware Engineering \nProcess\nSoftware Engineering \nProcess Fundamentals\nIntroduction\nSoftware Engineering \nProcess De\ufb01nition\nLife Cycle De\ufb01nition, Process \nCathegories and Terminology\nRationale for Life Cycles\nTe Concepts of Process \nModels and Life Cycle Models\nSome Paradigm for Development \nLife Cycle Models\nDevelopment Life Cycle \nModels and Teir Engineering \nDimension\nTe Management of SLCPs\nSoftware Engineering Process\nManagement\nSoftware Life Cycle Adaptation\nPractical Considerations\nSoftware Process Infrastructure, \nTools, Methods\nSoftware Engineering Process \nMonitoring and the Relation \nto the Software Product\nOverview of Sotware Process\nAssesment and Improvement\nGlobal-Question-Metric (GQM)\nFramework-Based-Method\nProcess Assesment and \nImprovement in Agile\nLife Cycles\nSoftware Process Assesment \nand Improvement\nFigure 10.1. Breakdown of Topics for the Software Engineering Process KA\n", "page": 224, "type": "text", "section": "Page 224"}
{"text": "SOFTWARE ENGINEERING PROCESS   10-3\nKAs \nand \nthe \nSoftware \nEngineering \nManagement, Software Engineering Models \nand Methods, Software Quality, Software \nArchitecture, and Software Testing KAs. The \nMeasurement and Root Cause Analysis sec-\ntions in the Engineering Foundations KA is \nalso closely related.\n1.2 Software Engineering Process Definition \n\b\n[1*,c5][2] [7][14][20]\nA process is a \u201cset of interrelated or interacting \nactivities that transforms inputs into outputs\u201d, \nwhere activity is a \u201cset of cohesive tasks of a pro-\ncess,\u201d and a task is a \u201crequired, recommended, \nor permissible action, intended to contribute to \nthe achievement of one or more outcomes of \na process\u201d [1]. According to [2], a process is a \n\u201cpredetermined course of events defined by its \npurpose or by its effect, achieved under given \nconditions.\u201d A third definition, following [7], is \na \u201csystem of activities, which use resources to \ntransform inputs into outputs.\u201d And a fourth \none is a \u201cset of interrelated or interacting activ-\nities which transforms inputs into outputs to \ndeliver an intended result\u201d [20]. That is, the \ndescription of a process includes required inputs, \ntransforming activities, and the outputs gener-\nated. These definitions address any processes \nthat are applied to the software part of software \nsystems. Software systems also include hard-\nware, and they also involve people and manual \nprocedures. The output of one process can be \nan input to another process.  Processes may \ninclude controls (e.g. directives and constraints) \nand enabling mechanisms (e.g. tools, technolo-\ngies or resources such as workforce and infra-\nstructure)  associated with the processes [14].\n2.\t Life Cycles1\n2.1.\t Life Cycle Definition, Process Categories, \nand Terminology \n\b\n[1*,c5-6][3*,c2][8*,c1-3][13]\nA life cycle, according to [1], is the \u201cevolution \nof a system, product, service, project or other \n1\t  Lifecycle, life-cycle and life cycle are different spellings. Merriam-Webster prefers the spelling \u201clife cycle\u201d.\nhuman-made entity from conception through \nretirement.\u201d In software engineering, life \ncycles help convey information about software \nsystems, the \u201csystem[s] for which software is \nof primary importance to the stakeholders\u201d \n[1]. The concept of life cycles was put in place \nbecause simply identifying and defining the \nprocesses required to produce software did \nnot adequately describe all the complexity \nof software systems. It was also necessary to \ndefine life cycles, which include a number of \nprocesses and constraints [8].\nIn software engineering, development refers \nto a crucial stage of a system, product, ser-\nvice or project life cycle: that of building (or \nchanging) a software system according to \nthe stakeholders\u2019 needs. From a production/\nindustrial management perspective, software \nsystems are referred to as products. In this \ncontext, the term software product development \nlifecycle makes sense. \nProduct life cycle can be defined as the \n\u201cseries of phases that represent the evolution \nof a product, from concept through delivery, \ngrowth, maturity, to retirement\u201d [13]. This \ndefinition is not specific to software sys-\ntems but applies to all products more gener-\nally. Likewise, the life cycle concept, which is \nlinked to the product concept, is not specific \nto software engineering.\nSoftware systems contain software units \nthat are an \u201catomic-level software component \nof the software architecture that can be sub-\njected to stand-alone testing.\u201d (See the Testing \nKA.) The life cycle of a software system (and \nkeep in mind that software engineering uses \nan interdisciplinary approach) comprises all \nthe processes, activities and tasks from the \nideation of the software system to the retire-\nment of the system, including production, \noperation and evolution, as well as acquisi-\ntion, when needed, and supply. Likewise, we \ncan look at the life cycle of an element of a \nsoftware system (a software unit). A soft-\nware system life cycle will consider both the \nbusiness and the technical needs of the stake-\nholders and the system\u2019s ability to produce, \n", "page": 225, "type": "text", "section": "Page 225"}
{"text": "10-4   SWEBOK \u00ae GUIDE V4.0\nas the outcome of the different software life \ncycle processes (SLCPs) performed by a team, \na product that meets the stakeholders\u2019 needs, \nwith the required quality level for its users and \nfor all the different stakeholders. \nThe following paragraphs enumerate the \nprocess categories, as enumerated in [1]. \nThese process categories reflect the multiple \nperspectives involved in producing a soft-\nware system: (1) technical processes including \nengineering practices to build, make, evolve, \noperate and retire software products; (2) \ntechnical management processes that cover \nplanning and control, as well as configura-\ntion management, risk management, infor-\nmation management and quality assurance; \n(3) organizational project-enabling processes \nthat support life cycle model and infrastruc-\nture management, portfolio management, \nand human resources, knowledge and quality \nmanagement; and finally (4) agreement pro-\ncesses, which are essential to support collec-\ntive decision-making, as well as acquisition \nand supply processes.\nA breakdown of these processes is \nas follows:\n1.\t Technical processes\na)\t Business or mission analysis process\nb)\t Stakeholder needs and requirements \ndefinition process\nc)\t System/software requirements defini-\ntion process\nd)\t Architecture definition process\ne)\t Design definition process\nf)\t System analysis process\ng)\t Implementation process\nh)\t Integration process\ni)\t Verification process\nj)\t Transition process\nk)\t Validation process\nl)\t Operation process\nm)\tMaintenance process\nn)\t Disposal process\n2.\t Technical management processes\na)\t Project planning process\nb)\t Project assessment and control process\nc)\t Decision management process\nd)\t Risk management process\ne)\t Configuration management process\nf)\t Information management process\ng)\t Measurement process\nh)\t Quality assurance process\n3.\t\nOrganizational project-enabling processes\na)\t Life cycle model management process\nb)\t Infrastructure management process\nc) Portfolio management process\nd)\t Human resource management process\ne)\t Quality management process\nf)\t Knowledge management process\n4.\t Agreement processes \na)\t Acquisition process\nb)\t Supply processes\n2.2. Rationale for Life Cycles\b\n[8*,c2-3][12]\nCreating, operating and retiring software \nproducts require a number of processes, with \ntheir activities and tasks, and a number of \nconstraints. As noted above, software systems \ninvolve people and manual procedures, as well \nas software and hardware. Defining software \nprocesses, following [12], requires specifying \ninputs and outputs. Inputs from processes \nare, very often, outputs from other processes. \nTherefore, life cycle processes are interre-\nlated processes; that is, each individual pro-\ncess (its inputs and outputs) may depend on \nother processes. The interrelated nature of the \nprocesses involved make the overall software \nengineering process highly complex. \nT\ufeffhe specification of life cycles is a pow-\nerful tool for implementing an engineering \napproach to the creation, operation and \nretirement of software systems. A life cycle \nshould be defined following engineering prin-\nciples that guide engineering as a discipline \n[8]. The specification of a life cycle includes \nthe specification of every process and the \nassociated constraints. The process specifica-\ntion should be useful to humans so that they \ncan communicate with one another using this \nspecification. The specification should be easy \nto understand and correct because life cycle \nspecifications are the basis for technical and \n", "page": 226, "type": "text", "section": "Page 226"}
{"text": "SOFTWARE ENGINEERING PROCESS   10-5\nengineering management, including coordina-\ntion and agreement, measurement, assessment \nand improvement, and quality management.\n2.3.\t The Concepts of Process Models and Life \nCycle Models\b\n[3*,c2][10*,c2][c2]\nSection 2.1 provides a number of software life \ncycle definitions. In reference [2], a new defi-\nnition introduces the concept of a standard as a \ncommonly accepted guiding document, stating \nthat a \u201cproject-specific sequence of activities \u2026 \nis created by mapping the activities of a stan-\ndard onto a selected software life cycle model \n(SLCM).\u201d That is, a life cycle is created in con-\nformance with the life cycle model. \nExamples of well-known life cycle models \nfor product development are, among others, \nthe waterfall model, the V-model, the incre-\nmental model, the spiral model and the Agile \nmodel [2,3, 10]. \n2.4.\t Some Paradigms for Development Life \nCycle Models\b\n[3*,c2-3][8*,c2-3] \n\b\n[9*,c1][10*,c1][2][11][12]\nEach software system has its own features \nreflecting the stakeholders\u2019 needs, both busi-\nness and technical. A suitable life cycle will \nconsider all these needs. As explained in \nSection 2.3, a software life cycle will be \ndefined in conformance with (partially or fully \nconforming to) an SLCM. Some authors use \nthe term \u201cdevelopment\u201d to refer to SLCM, \ne.g. \u201citerative development\u201d instead of \u201citera-\ntive (software) life cycle model\u201d. Types of life \ncycles are described below. \nPredictive life cycles are \u201ca form of project \nlife cycle in which the project scope, time, and \ncost are determined in the early phase of the life \ncycle\u201d [13]. Predictive life cycles assume that the \nset of requirements that will be implemented is \na closed set that will not undergo substantive \nchange unless a force majeure occurs. \nAn iterative life cycle is \u201ca project life cycle \nwhere the project scope is generally deter-\nmined early in the project life cycle, but \ntime and cost estimates are routinely mod-\nified as the project team understanding of \nthe product increases. Iterations develop the \nproduct through a series of repeated cycles, \nwhile increments successively add to the func-\ntionality of the product\u201d [3, 8, 13]. The itera-\ntions duration is defined for each project. The \nmethod chosen (see KA 11) would prescribe \nthe role and size of iterations. \nIn an evolutionary life cycle, a product \nor service changes over its lifetime. It may \nhappen because requirements and customer \nneeds change, but it also may happen because \nrequirements are introduced into the product \nin successive steps and not as a complete and \natomic set [3, 8]. \u201cSuccessive steps\u201d is a syn-\nonym for \u201citerations.\u201d\nAn incremental life cycle is \u201can adaptive \nproject life cycle in which the deliverable is \nproduced through a series of iterations that \nsuccessively add functionality within a prede-\ntermined time frame. The deliverable contains \nthe necessary and sufficient capability to be \nconsidered complete only after the final itera-\ntion\u201d [3, 8, 13]. Incremental life cycles are not \nalways predictive, but they can be. Incremental \ndevelopment is a \u201csoftware development tech-\nnique in which requirements definition, \ndesign, implementation, and testing occur in \nan overlapping, iterative (rather than sequen-\ntial) manner, resulting in incremental com-\npletion of the overall software product\u201d [2]. \nContinuous development refers to software \nengineering practices that allow for frequent \nreleases of new systems (including soft-\nware) to staging or various test environments \nthrough the use of automated tools [8, 9, 11].\nA life cycle can enforce a rule that the \nrequirements \nspecifications \ncannot \nbe \nchanged once the requirements process has \nbeen finalized and the customer has agreed to \nthe specifications. This happens, for example, \nin predictive life cycles. On the other hand, \nwhen the life cycle does not preclude changes \nin the requirements specifications, even after \nthe customer has agreed to them and signed \noff on them, and in practice, allows them \nto change at any point [upon negotiation of \ninterested parts], then the life cycle is said to \nbe open to change. Being open to change is one \nof the claims of Agile development [9, 10].\n", "page": 227, "type": "text", "section": "Page 227"}
{"text": "10-6   SWEBOK \u00ae GUIDE V4.0\n2.5.\t Development Life Cycle Models and Their \nEngineering Dimension\b\n[3*,c2][8*,c2-3]\n\b\n[9*,c1][10*,c1][2] [11] [16] \n \n\b\n[17] [18] [19][25][26][27]\nSeveral life cycle models have become well \nknown with the development of software \nengineering since its inception. One model, \nwhich became popular early in the history of \nthe discipline, is the waterfall model [3], that \nfalls into the category of predictive, described \npreviously. The waterfall model approach for \nproduct development uses a number of phases, \nincluding requirements, preliminary design, \ndetailed design, coding and testing. It imple-\nments a very strict process, in which one phase \ncannot be started until the previous one is fin-\nished. The waterfall model was useful because \nit introduced a systematization in the develop-\nment of software systems and, therefore, what \ncould be referred to as an engineering approach \nto software product development. Many vari-\nants or extensions, such as the V-model [3], \nwith many different names and nuances, have \nbeen introduced in the history of software \nengineering. The waterfall model was an early \nattempt to address the so-called software crisis \n[3]. The waterfall model is document-driven. \nReference [2] defines the waterfall model as \nthe \u201cmodel of the software development pro-\ncess in which the constituent activities, typ-\nically a concept phase, requirements phase, \ndesign phase, implementation phase, test \nphase, and installation and checkout phase, \nare performed in that order, possibly with \noverlap but with little or no iteration.\u201d\nThe waterfall model is clearly an example \nof a predictive life cycle. Some other para-\ndigms, such as the incremental life cycle, also \nattempted to address the \u201csoftware crisis.\u201d In \nthis model (see Section 2.4), different phases \noccur in an overlapping rather than sequential \nmanner. An incremental life cycle can also be \na predictive life cycle. This would mean that \nthe requirements are defined and closed before \nany other development phase is started. The \nspiral model, introduced by Boehm, is evolu-\ntionary and risk-driven, as opposed to docu-\nment- or code-driven [3]. Reference [2] defines \nthe spiral model as a \u201cmodel of the software \ndevelopment process in which the constit-\nuent activities, typically requirements anal-\nysis, preliminary and detailed design, coding, \nintegration, and testing, are performed itera-\ntively until the software is complete.\u201d Another \npopular model is rapid prototyping, a \u201ctype \nof prototyping in which emphasis is placed \non developing prototypes early in the devel-\nopment process to permit early feedback and \nanalysis in support of the development process\u201d \n[2]. The unified process, also known as  unified \nsoftware development process, is an iterative \nand incremental software development pro-\ncess framework [25]. From the unified process, \nthe rational unified process (RUP\u00ae) is docu-\nmented in [26], and the OpenUP, managed by \nthe Eclipse Foundation [27].\nThe Agile Manifesto [16] effected a disrup-\ntion in the software engineering community \nby creating an abrupt change of mindset. The \ndifference was that Agile Manifesto signato-\nries claimed that the process should be open to \nchange \u2014 requirements could be modified at \nany stage of the development process if users\u2019 \nneeds changed. Communication and mutual \ntrust between team/customer were essential. \nSignatories claimed that team communication, \noften face-to-face, and communication with \nthe customer were key. Nevertheless, the Agile \nManifesto does not say that documents (e.g. \nto define requirements) are not needed, docu-\nments are needed [9, 10]. Signatories also advo-\ncated for small software incremental deliveries, \nas opposed to projects that applied the waterfall \nmodel with a single software delivery at the end \nof the project after months or years of working. \nAgile makes a clear distinction between, on \nthe one side, values and principles (e.g., always \ndelivering value to the customer or a commit-\nment to technical excellence) and, on the other, \npractices (peer programming, sprint planning \nor retrospective). The Agile mindset [10] is dif-\nferent from the predictive mindset. The Agile \nmindset is based on a number of values and \nprinciples (e.g., the importance of communi-\ncation, being open to change or commitment \nto technical excellence and always delivering \nvalue to the customer); this focus differentiates \n", "page": 228, "type": "text", "section": "Page 228"}
{"text": "SOFTWARE ENGINEERING PROCESS   10-7\nAgile from the predictive mindset, which is \nmore focused on committing to the implemen-\ntation of the requirements specifications. Agile \n \nhelps address complexity [8, 10].\nSeveral misconceptions arose around Agile, \nand some still remain. One is that Agile is a \nmethod in itself, which it is not. Another is \nthat Agile is \u201cfaster\u201d than waterfall because \nyou need not produce any document. A third \none is that Agile has a  limited or unstructured \nset of methods/practices; a chart that enumer-\nates several commonly used Agile methods \nand practices can be found, for example, in \n[18]. Several Agile methods became popular, \nlike Extreme Programming for product devel-\nopment, Scrum for project management and \nothers. Even considering the ever rising pop-\nularity of the Agile life cycle model to address \ncomplex projects, scaling up Agile for large \nprojects and portfolios is still challenging. The \nperception today is that the Agile Manifesto \nmeant a significant disruption; nevertheless, \nit is already 20 years old, and some authors \nthink that some of its principles might need \nbe updated, informed by the experience devel-\nopers have obtained in the past 20 years [17].\nThe application of Agile practices has tran-\nscended the software engineering process, and \nthe terms business agility and Agile organiza-\ntions are now very common [19]. From a soft-\nware engineering point of view, Agile created \nan opportunity for the industry to achieve a \nreengineering and a better alignment of soft-\nware engineering processes and business stra-\ntegic processes in organizations. The use of \nan Agile approach by business processes is a \ncommon scenario; this is reflected in the prin-\nciples of DevOps [11], for example, explained \nlater in this section, and process assessment \nand improvement in Section 3.\nThe need to provide more frequent releases, \nthe fact that users\u2019 needs and technological life \ncycles change more frequently, together with \nthe required alignment of the organizations\u2019 \nstrategic plans with the organizations\u2019 IT opera-\ntions, has led to the creation of DevOps, defined \nas a \u201cset of principles and practices which \nenable better communication and collaboration \nbetween relevant stakeholders for the purpose of \nspecifying, developing, and operating software \nand systems products and services, and con-\ntinuous improvements in all aspects of the life \ncycle\u201d [11]. The ability to provide more releases \nmore frequently, once adequate process manage-\nment has been defined, has become an advan-\ntage that makes companies more competitive.\nIn the history of software engineering, \nthere has been a lot of controversy over soft-\nware life cycle models \u2014 for example, as \nseen in debate over the merits of the water-\nfall model versus the Agile model of software \ndevelopment (See Section 2). This contro-\nversy should be understood from a historical \nperspective; new approaches have been dis-\nruptive or considered disruptive, and there \nhas been a lack of empirical measures to sup-\nport evidence-based discussions about soft-\nware engineering. This situation has been \nchanging slowly but steadily. Using empirical \nmeasures as the basis for making decisions is \nan essential element of software engineering \n[4, 8]. See also KA 9, Software Engineering \nManagement., and KA 12, Software Quality.\n2.6. The Management of SLCPs\b\n[14]\nThe life cycle for any software system contains \na number of stages. According to [14], these \nstages are the following:\n1.\t Concept: At this stage, stakeholders\u2019 \nneeds will be identified, concepts will be \nexplored, and solutions will be proposed.\n2.\t Development: At this stage, require-\nments representing the users\u2019 needs will \nbe refined, solutions will be created, sys-\ntems built, and all undergo the needed \nverification and validation processes.\n3.\t Production: This stage will have a dif-\nferent scope depending on the character-\nistics of the software system under focus. \nGenerally speaking, it will include the \nproduction and testing of the system.\n4.\t Utilization: At this stage, the system \noperates to satisfy users\u2019 needs.\n5.\t\nSupport: At this stage, developers pro-\nvide the required actions to achieve a sat-\nisfactory operation.\n", "page": 229, "type": "text", "section": "Page 229"}
{"text": "10-8   SWEBOK \u00ae GUIDE V4.0\n6.\t Retirement: At this stage, the team fol-\nlows established procedures to dispose of \nthe system.\nThe stages are not supposed to be sequen-\ntial, by any means. Actually, the specifica-\ntion of the life cycle for a software system will \ninclude the transitions between these stages. \nIt should be clear that these stages have been \nidentified for a general life cycle. Specific life \ncycles will have specific stages, meaningful \nto a particular project\u2019s stakeholders; these \nstages will fit into these general stages.\n2.7. Software Engineering Process Management \n\b\n[1*,c5][2]\nProcess management is defined as \u201cdirection, \ncontrol, and coordination of work performed \nto develop a product or perform a service\u201d \n[2]. Several management levels govern the \nsoftware engineering process, as explained \nin reference [1], see also KA 9, Software \nEngineering Management. The lowest level is \nthe technical processes; the second is the tech-\nnical management level, which will include \nproject management processes. The third level \nis the (executive) management level, focused \non organizational enabling processes, such \nas knowledge management, life cycle model \nmanagement, or portfolio management. \n2.8. Software Life Cycle Adaptation \n\b\n[5] [14] [23][29]\nEach software system has its differential char-\nacteristics. These differential characteristics, \ntogether with the stakeholders\u2019 needs, lead to \nspecific life cycles. This adaptation will include \nidentifying all the relevant characteristics, \nselecting the appropriate standards or docu-\nments internal to an organization, selecting a \ndevelopment strategy/life cycle model, stages, \nand processes, and documenting the decisions \nand rationale. The adaptation will not require \nkeeping the names provided in Section 2, \nor including them all [5, 14, 23]. The ISO/\nIEC 29110 series, Systems and Software \nEngineering Standards and Guides for Very \nSmall Entities (VSEs) [29], is an example of \na series derived from ISO/IEC/IEEE 12207. \n2.9. Practical Considerations\b\n[8*,c2-3]\nDefining a life cycle process includes the spec-\nification of the four categories presented in \nSection 2. This means addressing technical \nprocesses (definition of the processes that will \nbe required), organizational processes (this \nincludes human resources, among other pro-\ncesses), technical management processes (how \nprocesses are related, how they are monitored \nand managed), and agreement processes.\nThe discipline of software engineering has \nbeen evolving since its conception for several \nreasons. The community has never stopped \nlearning, while the complexity of the prod-\nucts has been ever-increasing. Defining a \nsoftware life cycle for the development of a \nproduct requires considering the characteris-\ntics of the product (e.g., stakeholders\u2019 needs, \nproduct size or complexity) and others external \nto the product, such as the stakeholders\u2019 char-\nacteristics. Something that the community has \nlearned is that estimations and measurements \nare essential. Wrong or uncertain estimations \nin the context of a life cycle will lead to failure. \nAccurate estimations are not easy to produce. [8]\nA current trend in software engineering \nis a focus on continuous delivery, supported \nby realistic process and product estimations \nand measurements. A helpful lesson engi-\nneers have learned is that working with large \nprocesses without producing any delivera-\nbles along the way increases uncertainty. (See \nDevOps in Section 2.5.) The Agile mindset \nhas contributed to this and has helped engi-\nneers recognize the importance of communi-\ncation in the process. [8]\nWhen a project process is defined in confor-\nmity with a life cycle, it is important to make \nsure that it will be possible to have metrics/\nmeasure definitions that will result in realistic \nprocess (and product) estimations and mea-\nsurements throughout project definition and \nexecution, and to define the level of precision \nand uncertainty; project process (and product) \nmeasurements should always provide accurate \n", "page": 230, "type": "text", "section": "Page 230"}
{"text": "SOFTWARE ENGINEERING PROCESS   10-9\ninformation about what is happening (the \nstatus of the process and the product) while the \nlife cycle process is executed. If we are uncer-\ntain about the accuracy of estimations and \nmeasurements, the project might not be suc-\ncessful. In this case, a reflection should take \nplace on the overall approach. Historically, \na lot of polemics have grown about the pre-\ndictive life cycle versus the Agile life cycle. \nIn software engineering, discussions should \nalways be supported by realistic process and \nproduct estimations and measurements, which \ncan accurately reduce the level of uncertainty. \n2.10.\tSoftware Process Infrastructure, Tools, \nMethods\b\n[3*,c2][8*,c2-3][2]\nSeveral notations have been used for defining \nsoftware processes, including natural language, \nspecifying textual lists of constituent activi-\nties and tasks, data-flow diagrams, state charts, \nintegration definition (IDEF0), Petri nets, and \nunified modeling language (UML) activity dia-\ngrams, and business process modeling notation \n(BPMN) [2, 3]. Software process infrastructure \nincludes tools to support the definition of these \nprocesses (e.g., a BPMN toolkit) but mainly to \nsupport all specific processes (testing or con-\nfiguration management). Process definitions \nwill often include methods and formalism (e.g., \nRational Unified Process or extreme program-\nming) [3]. Tools will, ideally, have to support \nthese methods and, as important, be integrated \nwith them. Therefore, it is not enough that a \ntool supports testing. Once a code unit has been \nsuccessfully tested, for example, this becomes \nuseful information that should be recorded so \nthat the rest of the team can be aware of this \nfact. This means that the configuration man-\nagement tool and the testing tool will have to be \nintegrated [3, 8]. The term software engineering \nenvironment, representing a set of integrated \ntools, is sometimes used. The term CASE (com-\nputer-aided software engineering) was popular \nin the 1980s and 1990s. Somehow, the power \ntools of the 1980s and 1990s were oversold as a \ncure for the software crisis. In any case, today, \nthe automation of some processes (e.g., config-\nuration management, or at least version control; \ntesting; ticket management) is seen as essential \nfor the implementation of successful life cycles. \nYou can also read KA 11, Software Engineering \nModels and Methods.\n2.11.\tSoftware Engineering Process Monitoring \nand its Relationship with the Software \nProduct\b\n[1*,c5-6][3*,c2][4*c4-10]\n\b\n[8*c2-3]\nDevelopers must monitor the software engi-\nneering process execution, assess whether the \nprocess objectives are met, and assess risks. \nThis process monitoring is part of software \nengineering process assessment (see Section \n3) and part of the Software Engineering \nManagement KA [1, 3, 4, 8]. \nEmpirical methods support process assess-\nment and improvement as well as product \nassessment and improvement. The goal of pro-\ncess execution is to obtain products that meet \nstakeholders\u2019 needs. While this area is focused \non the software engineering process, process \nmonitoring requires assessing both process and \nproduct, using a joint, more holistic approach.\n3.\t Software Process Assessment and \nImprovement\n3.1.\t Overview of Software Process Assessment \nand Improvement\b\n[4*,c4][15][24]\nThe idea that any executed process can be \nimproved was present in the classic Shewhart-\nDeming plan-do-check-act (PDCA) par-\nadigm [15, 24], which was already being \ndiscussed and applied in the 1950s, and its \nfoundations can be found centuries earlier. \nFor the software engineering process, several \napproaches have been developed. \nThe PDCA paradigm is an opportunity to \nmeet a widely recognized need \u2014 the need \nfor empirical evidence to make decisions. \nSuch decisions include choosing a life cycle, \ndeciding how to assess a process or deciding \nhow to improve a process, among others. \nGetting empirical evidence across the execu-\ntion of a software engineering process is essen-\ntial for the success of the process execution. [4]\n", "page": 231, "type": "text", "section": "Page 231"}
{"text": "10-10   SWEBOK \u00ae GUIDE V4.0\n3.2. Goal-Question-Metric (GQM)\b\n[21]\nThe GQM approach [21] is based on Basili\u2019s \nQuality Improvement Paradigm. Both are \nbased on setting goals that can be measured, \nchanging something, and then evaluating the \neffect of the change. When the evaluation is \npositive, an improvement has occurred. \n3.3 Framework-Based Methods \n\b\n[4*,c4-10][6][22]\nSome assessment methods are based on frame-\nworks that use a process reference model and \nan assessment reference model \u2014 for example, \nCMM\u00ae (capability maturity model), CMMI\u00ae \n[4, 22], and the ISO/IEC 33000 [4, 6] series, \nalso known as SPICE. \nThe ISO/IEC 33000 framework includes \na process reference framework and a pro-\ncess assessment model. The ISO/IEC 33000 \nframework revises the ISO/IEC 15504 series \nof International Standards, providing a \nframework for the assessment of (1) the pro-\ncess quality characteristics, one of which is \nprocess capability, together with (2) organi-\nzational maturity. This framework covers pro-\ncesses for the development, maintenance and \nuse of systems across the information tech-\nnology domain, as well as processes for the \ndesign, transition, delivery and improvement \nof services. The concept of seeking continuous \nimprovement underlies the assessment.\nThis series has developed several groups of \nstandards addressing, as well as core elements, \nbasic requirements for performing process \nassessments, process models and the process \nmeasurement framework; guidance on how \nto perform assessments; measurement frame-\nworks for the assessment of process capability \nand organizational maturity; process refer-\nence models for special cases such as safety or \nhigh maturity; process assessment models for \nSLCPs, system life cycle process IT service \nmanagement, safety and high maturity; and \norganizational maturity models.\nThe process reference model is defined as a \n\u201cmodel comprising definitions of processes in \na domain of application described in terms of \nprocess purpose and outcomes, together with \nan architecture describing the relationships \nbetween the processes.\u201d The process assess-\nment model is defined as a \u201cmodel suitable for \nthe purpose of assessing a specified process \nquality characteristic, based on one or more \nprocess reference models.\u201d [6]\n3.4. Process assessment and improvement in Agile \n\b\n[9*,c11][28]\nAgile methods (e.g., the scrum project man-\nagement method) introduce what they call \nretrospectives at the end of each iteration. The \nobjective of the retrospective is to analyze \nwhat went well and what did not go well, to \nunderstand why, and to set a number of actions \nfor learning and improvement. In the end, the \nteam is in a continuous learning loop [9]. This \npractice, with different names and scopes was \nnot new in software engineering [28].\nMATRIX OF TOPICS VS. REFERENCE MATERIAL\nISO/IEC/I  \nEEE 12207 [1*]\nSommerville  \n[3*]\nLaporte \net al. [4*]\nFarley [8*]\nShore et al [9*]\nPMI [10*]\nOthers\n1. Software Engineering Process \nFundamentals\n1.1 Introduction\nc5\n[13]\n1.2 Software Engineering Process \nDefinition\nc5\n[2] [7][14][20]\n", "page": 232, "type": "text", "section": "Page 232"}
{"text": "SOFTWARE ENGINEERING PROCESS   10-11\n2. Life Cycles\n2.1 Life cycle definition, process \ncategories and terminology\nc5-6\nc2\nc1-3\n[13]\n2.2 Rationale for life cycles\nc2-3\n[12]\n2.3 The concept of process models and \nlife cycles models\nc2\nc2 \n[2]\n2.4 Some paradigms for \ndevelopment life cycle models\nc2-3\nc2-3\nc1\nc1\n[2] [11] [13]\n2.5 Development life cycle models \nand their engineering dimension\nc2\nc2-3\nc1\nc1\n[2] [11] [16] \n[17] [18] [19] \n[25] [26] [27]\n2.6 The management of SLCPs\n[14]\n2.7 Software engineering process \nmanagement\nc5\n[2]\n2.8 Software life cycle adaptation\n[5] [14] [23] [29]\n2.9 Practical considerations\n2.10 Software process infrastructure, \ntools, methods\nc2\nc2-3\n[2]\n2.11 Software engineering process \nmonitoring\nc5-6\nc2\nc4-10\nc2-3\n3. Software Process Assessment \nand Improvement\nc4-10\n3.1 Overview of software process \nassessment and improvement\nc4\n[15] [24]\n3.2 Goal-question metric (GQM)\n[21]\n3.3 Framework-based methods\nc4-10\n[6] [22]\n3.4 Process Assessment and \nimprovement in Agile\nc11\n[28]\nREFERENCES\n[1]\t ISO/IEC/IEEE 12207:2017 Systems \nand software engineering \u2014 Software \nlife cycle processes.\n[2]\t ISO/IEC/IEEE, \u201cISO/IEC/IEEE \n24765:2017 Systems and Software \nEngineering \u2014 Vocabulary,\u201d 2nd ed. 2017.\n[3]\t I. Sommerville, Software Engineering. \n10th ed. 2016.\n[4]\t C. Y. Laporte and A. April, Software \nQuality Assurance, IEEE Computer \nSociety Press, 1st ed., 2018.\n[5]\t Project Management Institute, Software \nExtension to the PMBOK\u00ae Guide \u2014 \nFifth Edition, 2013.\n[6]\t ISO/IEC 33001:2015 Information \ntechnology \u2014 Process assessment \u2014 \nConcepts and terminology.\n[7]\t ISO/IEC 25000:2014 Systems and \nsoftware engineering \u2014 Systems and \nsoftware product quality requirements \nand evaluation (SQuaRE) \u2014 Guide \nto SQuaRE.\n[8] \tD. Farley, Modern Software Engineering: \nDoing What Works to Build Better \n", "page": 233, "type": "text", "section": "Page 233"}
{"text": "10-12   SWEBOK \u00ae GUIDE V4.0\nSoftware Faster. Addison-Wesley \nProfessional, December 2021.\n[9]\t J. Shore and S. Warden, The Art of Agile \nDevelopment, O\u2019Reilly Media, 2nd ed. \nOctober 2021.\n[10] \tProject Management Institute, Agile \nPractice Guide. Project Management \nInstitute and Agile Alliance. \nSeptember 2017.\n[11]\tISO/IEC/IEEE Std 32675:2022 \nInformation technology \u2014 DevOps \u2014 \nBuilding reliable and secure systems \nincluding application build, package and \ndeployment.\n[12]\tISO/IEC/IEEE 24774:2021 Systems \nand software engineering \u2014 Life cycle \nmanagement \u2014 Specification for pro-\ncess description.\n[13]\tProject Management Institute, A \nGuide to the Project Management Body \nof Knowledge (PMBOK\u00ae Guide) \u2014 \nSixth Edition.\n[14]\tISO/IEC/IEEE 24748-1:2018(E) \nSystems and software engineering \n\u2014 Life cycle management \u2014 Part 1: \nGuidelines for life cycle management.\n[15]\tW.A. Shewhart and W.E. Deming, \nStatistical Method from the Viewpoint \nof Quality Control. Dover, New \nYork, 1986.\n[16]\t\u201cThe Agile Manifesto.\u201d https://\nagilemanifesto.org. [Accessed \nMarch 5, 2022].\n[17]\tS. McConnell, More Effective Agile: A \nRoadmap for Software Leaders, 2019.\n[18]\t\u201cSubway Map to Agile Practices.\u201d Agile \nAlliance. https://www.agilealliance.org \n/agile101/subway-map-to-agile \n-practices/. [Accessed March 5, 2022].\n[19]\tJ. Eckstein and J. Buck, Company-wide \nAgility with Beyond Budgeting, Open \nSpace & Sociocracy: Survive & Thrive on \nDisruption, 2021.\n[20]\tISO/IEC TR 29110-5-3:2018 Systems \nand software engineering \u2014 Lifecycle \nprofiles for very small entities (VSEs) \u2014 \nPart 5-3: Service delivery guidelines.\n[21]\tN. Fenton and J. Bieman, Software \nMetrics, 3rd ed. CRC Press, 2014.\n[22]\tCMMI Institute \u2014 CMMI V2.0. \nhttps://cmmiinstitute.com/cmmi.\n[Accessed 5 March 2022].\n[23]\tISO/IEC/IEEE 24748-3:2020. Part 3: \nGuidelines for the application of ISO/\nIEC/IEEE 12207 (software life cycle \nprocesses).\n[24]\tD.R. Kiran, Total Quality manage-\nment. Elsevier, 2017.\n[25]\t\nJ. Rumbaugh, G. Booch, I. Jacobson. \nThe Unified Software Development \nProcess, 1999\n[26]\tP. Kruchten. The Rational Unified \nProcess: An Introduction. 3rd Ed. 2004\n[27]\tThe Eclipse Foundation https://www.\neclipse.org/org/foundation/ [Accessed \n25 April 2024].\n[28]\tT. Dings\u00f8yr, Postmortem reviews: pur-\npose and approaches in software engi-\nneering, Information and Software \nTechnology, Volume 47, Issue 5, 2005, \nPages 293-303.\n[29]\tISO/IEC TR 29110-1:2016 Systems \nand software engineering Lifecycle pro-\nfiles for Very Small Entities (VSEs) \nPart 1: Overview\n", "page": 234, "type": "text", "section": "Page 234"}
{"text": "11-1 \nCHAPTER 11\nSoftware Engineering Models \nand Methods\nACRONYMS\n3GL\n3rd Generation Language    \nBNF\nBackus-Naur Form\nFDD\nFeature-Driven Development\nIDE\nIntegrated Development \nEnvironment\nPBI\nProduct Backlog Item\nRAD\nRapid Application Development\nUML\nUnified Modeling Language\nXP\neXtreme Programming\nINTRODUCTION\nSoftware engineering models and methods \nimpose structure on software engineering to \nmake it systematic, repeatable and ultimately \nmore success-oriented. Models provide an \napproach to problem-solving, a notation and \nprocedures for model construction and anal-\nysis. Methods provide an approach to the sys-\ntematic specification, design, construction, \ntesting and verification of the end-item soft-\nware and associated work products.\nSoftware engineering models and methods \nvary widely in scope \u2014 from addressing a \nsingle software life cycle phase to covering the \ncomplete software life cycle. This knowledge \narea (KA) focuses on models and methods \nthat encompass multiple software life cycle \nphases regardless of the type of life cycle pro-\ncess models such as iterative models and agile \nones, since other KAs cover methods specific \nto single life cycle phases.\nBREAKDOWN OF TOPICS FOR \nSOFTWARE ENGINEERING \nMODELS AND METHODS\nThis chapter on software engineering models \nand methods is divided into four main \ntopic areas: \n1.\t Modeling discusses the general practice of \nmodeling and presents topics in modeling \nprinciples, properties and expression of \nmodels, modeling syntax, semantics, \nand pragmatics, as well as preconditions, \npostconditions, and invariants.\n2.\t Types of Models briefly discusses models \nand aggregation of submodels and pro-\nvides general characteristics of model \ntypes commonly found in the software \nengineering practice.\n3.\t Analysis of Models presents common anal-\nysis techniques used in modeling to verify \ncompleteness, consistency, correctness, \ntraceability and interaction.\n4.\t Software Engineering Methods presents \na summary of commonly used software \nengineering methods. The discussion \nguides the reader through a summary of \nheuristic methods, formal methods, pro-\ntotyping and Agile methods.\nThe breakdown of topics for the Software \nEngineering Models and Methods KA is \nshown in Figure 11.1.\n1. Modeling\nModeling of software is becoming a pervasive \ntechnique to help software engineers under-\nstand, engineer and communicate aspects \nof the software to appropriate stakeholders. \n", "page": 235, "type": "text", "section": "Page 235"}
{"text": "11-2   SWEBOK \u00ae GUIDE V4.0\nStakeholders are those people or parties with a \nstated or implied interest in the software (e.g., \nusers, buyers, suppliers, architects, certifying \nauthorities, evaluators, developers, software \nengineers). \nAlthough there are many modeling lan-\nguages, notations, techniques and tools in \nthe literature and in practice, some general, \nunifying concepts apply to them all. The fol-\nlowing sections provide background on these \ngeneral concepts.\n1.1. Modeling Principles \n \b\n[1*, c2s2, c5s1, c5s2, 2*, c2s2, 3*, c5s0]\nModeling provides the software engineer \nwith an organized and systematic approach \nfor representing significant aspects of the \nsoftware under study, facilitating deci-\nsion-making about the software or elements, \nand communicating those significant deci-\nsions to others in the stakeholder commu-\nnities. Three general principles guide such \nmodeling activities:\n\u2022\t Model the essentials: Good models do not \nusually represent every aspect or fea-\nture of the software under every possible \ncondition. Modeling typically involves \nonly those aspects or features that pose \nspecific questions, abstracting away any \nnonessential information. This approach \nkeeps models manageable and useful.\n\u2022\t Provide perspective: Modeling provides \nviews of the software under study using \ndefined rules for expressing the model \nwithin each view. This perspective-driven \napproach provides dimensionality to the \nmodel (e.g., providing a structural view, \na behavioral view, a temporal view, an \norganizational view and/or other views \nif relevant). Organizing information into \nviews focuses the software modeling \nefforts on specific concerns relevant to \nthat view using the appropriate notation, \nvocabulary, methods and tools.\n\u2022\t Enable effective communications: Modeling \nuses the application domain vocabulary \nof the software, a modeling language \nand semantic expression (in other words, \nmeaning within context). When used \nrigorously and systematically, mod-\neling results in a reporting approach \nthat facilitates effective communica-\ntion of software information to project \nstakeholders. \nSoftware\nEngineering Models\nand Methods\nModeling\nTypes of Models\nAnalysis of\nModels \nSoftware\nEngineering\nMethods  \nModeling\nPrinciples\nProperties and\nExpression of\nModels\nSyntax,\nSemantics and\nPragmatics\nPreconditions,\nPostconditions\nand Invariants     \nBehavioral\nModeling\nStructure\nModeling\nAnalyzing for\nCompleteness\nAnalyzing for\nConsistency\nAnalyzing for\nCorrectness\nAnalyzing for\nTraceability\nAnalyzing for\nInteraction\nHeuristic\nMethods\nFormal\nMethods\nPrototyping\nMethods\nAgile\nMethods\nFigure 11.1. Breakdown of Topics for the Software Engineering Models and Methods KA\n", "page": 236, "type": "text", "section": "Page 236"}
{"text": "SOFTWARE ENGINEERING MODELS AND METHODS   11-3\nA model is an abstraction or simplification \nof a system. A consequence of using abstrac-\ntion is that, because no single abstraction \ncompletely describes a software component, \nthe software model comprises an aggregation \nof abstractions, which, when taken together, \ndescribe selected aspects, perspectives or \nviews \u2014 only those that are needed to make \ninformed decisions and respond to the reasons \nfor creating the model in the first place. This \nsimplification points to assumptions about the \ncontext within which the model is placed that \nshould also be captured in the model. Then, \nwhen the model is reused, these assumptions \ncan be validated first to establish the rele-\nvancy of the reused model within its new use \nand context.\n1.2. Properties and Expression of Models  \n\b\n[1*, c5s2, c5s3, 3*, c4s1.1p7, c4s6p3, \n \n\b\nc5s0p3]\nProperties of models are those distinguishing \nfeatures of a particular model that charac-\nterize its completeness, consistency and cor-\nrectness within the chosen modeling notation \nand tooling. Properties of models include the \nfollowing:\n\u2022\t Completeness \u2014 the degree to which all \nrequirements have been implemented and \nverified within the model\n\u2022\t Consistency \u2014 the degree to which the \nmodel contains no conflicting require-\nments, assertions, constraints, functions \nor component descriptions\n\u2022\t Correctness \u2014 the degree to which the \nmodel satisfies its requirements and \ndesign specifications and is free of defects\nModels are constructed to represent objects \nneeded for target domains and their behaviors \nto answer specific questions about how the \nsoftware is expected to operate. Interrogating \nthe models \u2014 through exploration, simula-\ntion or review \u2014 might expose areas of uncer-\ntainty within the model and the software to \nwhich the model refers. These uncertain-\nties or unanswered questions regarding the \nrequirements, design and/or implementation \ncan then be handled appropriately.\nThe primary expression element of a model \nis an entity. An entity may represent concrete \nartifacts (e.g., processors, sensors or robots) \nor abstract artifacts (e.g., software modules \nor communication protocols). Model entities \nare connected to other entities using relations \n(lines or textual operators on target entities). \nExpression of model entities may be accom-\nplished using textual or graphical modeling \nlanguages; both modeling language types con-\nnect model entities through specific language \nconstructs. The meaning of an entity may \nbe represented by its shape, its textual attri-\nbutes or both. Generally, textual information \nadheres to language-specific syntactic struc-\nture. The precise meanings related to the mod-\neling of context, structure or behavior using \nthese entities and relations are dependent on \nthe modeling language used, the design rigor \napplied to the modeling effort, the specific \nview being constructed and the entity to which \nthe specific notation element may be attached. \nMultiple views of the model may be required to \ncapture the needed semantics of the software.\nWhen using automation-supported models, \nmodels may be checked for completeness and \nconsistency. The usefulness of these checks \ndepends greatly on the level of semantic and \nsyntactic rigor applied to the modeling effort \nand on explicit tool support. Correctness can \nbe checked through model simulation, execu-\ntion or review.\n1.3. Syntax, Semantics, and Pragmatics  \n\b\n[2*, c2s2.2.2p6, 3*, c5s0]\nModels can be surprisingly deceptive. The fact \nthat a model is an abstraction with missing \ninformation can give people the illusion that \nthey completely understand the software after \nstudying a single model. A complete model \n(\u201ccomplete\u201d being relative to the modeling \neffort) may be a union of multiple submodels \nand any special function models. Examination \nof and decision-making regarding a single \nmodel within this collection of submodels \nmay be problematic.\n", "page": 237, "type": "text", "section": "Page 237"}
{"text": "11-4   SWEBOK \u00ae GUIDE V4.0\nUnderstanding the precise meanings of \nmodeling constructs can also be difficult. \nSyntactic and semantic rules define modeling \nlanguages. For textual languages, syntax is \ndefined using a notation grammar that defines \nvalid language constructs (e.g., Backus-Naur \nform (BNF)). For graphical languages, syntax \nis defined using graphical models called meta-\nmodels. As with BNF, metamodels define a \ngraphical modeling language\u2019s valid syntac-\ntical constructs. In addition, the metamodel \ndefines how these constructs can be composed \nto produce valid models.\nSemantics for modeling languages specify \nthe meaning attached to the entities and \nrelations captured within the model. For \nexample, a simple diagram of two boxes con-\nnected by a line is open to various interpre-\ntations. Knowing that the diagram on which \nthe boxes are placed and connected is an \nobject diagram or an activity diagram can \nassist in interpreting this model. \nAs a practical matter, the semantics of \na specific software model are usually fairly \nclear due to the model\u2019s use of a modeling \nlanguage, the way that modeling language \nexpresses entities and relations within that \nmodel, the experience and skill of the mod-\nelers, and the context within which the mod-\neling has been undertaken and represented. \nMeaning is communicated through the model \neven in the presence of incomplete informa-\ntion through abstraction. Pragmatics explains \nhow meaning is embodied in the model and \nits context and how it is communicated effec-\ntively to other software engineers.\nHowever, there are still instances where \ncaution is needed regarding modeling and \nsemantics. For example, any model parts \nimported from another model or library must \nbe examined for semantic assumptions that \nconflict with the new modeling environ-\nment; these conflicts might not be obvious. \nThe model should be checked for documented \nassumptions. Although the imported mod-\neling syntax might be the same, it might mean \nsomething quite different in the new environ-\nment, which is a different context. Also, con-\nsider that as software matures and changes \nare made, semantic discord can be intro-\nduced, leading to errors. With many soft-\nware engineers working on part of a model \nover time, and with tool updates and perhaps \nnew requirements, there are opportunities for \nportions of the model to represent something \ndifferent from the original author\u2019s intent and \ninitial model context.\n1.4. Preconditions, Postconditions, and Invariants \n\b\n[2*, c4s4, 4*, c10s4p2, c10s5p2p4]\nWhen modeling functions or methods, \nthe software engineer typically starts with \nassumptions about the software\u2019s state before, \nduring and after the function or method exe-\ncutes. These assumptions are essential to the \ncorrect operation of the function or method \nand are grouped, for discussion, as a set of \npreconditions, postconditions and invariants. \n\u2022\t Preconditions are conditions that must be \nsatisfied before execution of the function \nor method. If these preconditions do not \nhold before execution of the function or \nmethod, the function or method might \nproduce erroneous results.\n\u2022\t Postconditions are conditions guaranteed \nto be true after the function or method \nhas executed successfully. Typically, the \npostconditions represent how the soft-\nware\u2019s state has changed, how parameters \npassed to the function or method have \nchanged, how data values have changed, \nor how the return value has been affected.\n\u2022\t Invariants are conditions within the oper-\national environment that persist (in other \nwords, do not change) before and after \nexecution of the function or method. \nThese invariants are relevant and neces-\nsary to the software and to the correct \noperation of the function or method.\n2. Types of Models\nA typical model consists of an aggregation \nof submodels. Each submodel is a partial \ndescription and is created for a specific pur-\npose. A submodel may comprise one or more \n", "page": 238, "type": "text", "section": "Page 238"}
{"text": "SOFTWARE ENGINEERING MODELS AND METHODS   11-5\ndiagrams. The collection of submodels may \nuse multiple modeling languages or a single \nmodeling language. The unified modeling \nlanguage (UML) recognizes a rich collec-\ntion of modeling diagrams. These diagrams, \nalong with the modeling language constructs, \nare used in two common model types: struc-\ntural models and behavioral models. (See \nSection 1.1.) Depending on modeling lan-\nguages, there can be other types of models. \nFor instance, the systems modeling language \n(SysML) provides two other types of models: \nrequirements models and parametric models.\n2.1. Structural Modeling \n\b\n[1*, c7s2.2, c7s2.5, c7s3.1, c7s3.2, 3*, c5s3, \n\b\nc8s1, 4*, c4, 17]\nStructural models illustrate the software\u2019s \nphysical or logical composition of software \nfrom its various component parts. Structural \nmodeling establishes the defined boundary \nbetween the software being implemented or \nmodeled and the environment in which it is to \noperate. Some common structural constructs \nused in structural modeling are composition, \ndecomposition, generalization, and special-\nization of entities; identification of relevant \nrelations and cardinality between entities; and \nthe definition of process or functional inter-\nfaces. Structure diagrams provided by the \nUML for structural modeling include class, \ncomponent, object, deployment, and pack-\naging diagrams.\n Information modeling is a kind of struc-\ntural modeling and focuses on data and \nother information. An information model is \nan abstract representation that identifies and \ndefines a set of concepts, properties, relations \nand constraints on data entities. The semantic \nor conceptual information model is often used \nto provide some formalism and context to the \nsoftware as viewed from the problem perspec-\ntive, without concern for how this model is \nmapped to the implementation of the software. \nThe semantic or conceptual information model \nis an abstraction and, as such, includes only the \nconcepts, properties, relations and constraints \nneeded to conceptualize a real-world view of \nthe information. Subsequent transformations \nof the semantic or conceptual information \nmodel become logical and then physical data \nmodels as implemented in the software.\n2.2. Behavioral Modeling  \n\b\n[1*, c7s2.1, c7s2.3, c7s2.4, 2*, c9s2, 3*, \n\b\n c5s4, 8, c1s5.4]\nBehavioral models identify and define soft-\nware functions. Behavioral models generally \ntake three basic forms: state machines, con-\ntrol-flow models and data-flow models. State \nmachines provide a model that represents \nthe software as a collection of defined states, \nevents and transitions. The software tran-\nsitions from one state to the next through a \nguarded or unguarded triggering event that \noccurs in the modeled environment. Control-\nflow models depict how a sequence of events \ncauses processes to be activated or deacti-\nvated. Data-flow models represent data-flow \nbehavior as a sequence of steps where data \nmoves through processes toward data stores \nor data sinks. These models are described in \nthe way of event-triggered, time concepts \n(i.e., logical, physical, discrete, continuous, \nrelative, or absolute time), or combinations \nthereof. Behavioral diagrams provided by the \nUML for behavioral modeling include use \ncase, activity, state machine, and interaction \n(sequence, communication, timing, and inter-\naction overview) diagrams.\n3. Analysis of Models\nThe development of models allows the soft-\nware engineer to study, reason about and \nunderstand software structure, function, \noperational use and assembly considerations. \nAnalysis of constructed models is needed to \nensure that the models are complete, con-\nsistent and correct enough to serve their \nintended purpose for the stakeholders.\nThe following sections briefly describe the \nanalysis techniques generally used to ensure \nthat the software engineer and other relevant \nstakeholders gain appropriate value from the \ndevelopment and use of models.\n", "page": 239, "type": "text", "section": "Page 239"}
{"text": "11-6   SWEBOK \u00ae GUIDE V4.0\n3.1. Analyzing for Completeness  \n\b\n[3*, c4s1.1p7, c4s6, 5*, pp8-11]\nTo ensure software fully meets the needs of \nthe stakeholders, completeness \u2014 from the \nrequirements elicitation process to code imple-\nmentation \u2014 is critical. Completeness is the \ndegree to which all specified requirements have \nbeen implemented and verified. Engineers can \ncheck models for completeness with a modeling \ntool that uses structural analysis and state-\nspace reachability analysis (which ensure some \nset of correct inputs reach all paths in the state \nmodels). Models may also be checked manually \nfor completeness by using inspections or other \nreview techniques. (See the Software Quality \nKA.) Errors and warnings generated by these \nanalysis tools and found by inspection or review \nindicate that corrective actions are probably \nneeded to ensure model completeness.\n3.2. Analyzing for Consistency  \n\b\n[3*, c4s1.1p7, c4s6, 5*, pp8-11]\nConsistency is the degree to which models \ncontain no conflicting requirements, asser-\ntions, constraints, functions or component \ndescriptions. Typically, consistency checking \nis accomplished with the modeling tool using \nan automated analysis function. Models may \nalso be checked manually for consistency \nusing inspections or other review techniques. \n(See the Software Quality KA.) As with com-\npleteness, errors and warnings generated by \nthese analysis tools and found by inspection or \nreview indicate the need for corrective action.\n3.3. Analyzing for Correctness \b\n[5*, pp8-11]\nCorrectness is the degree to which a model \nsatisfies its software requirements and soft-\nware design specifications, is free of defects, \nand ultimately meets the stakeholders\u2019 needs. \nAnalyzing for correctness includes verifying \nthe model\u2019s syntactic correctness (that is, cor-\nrect use of the modeling language grammar \nand constructs) and semantic correctness (that \nis, use of the modeling language constructs to \ncorrectly represent the meaning of that which \nis being modeled). To analyze a model for syn-\ntactic and semantic correctness, one analyzes it \n\u2014 either automatically (e.g., using the modeling \ntool to check for model syntactic correctness) \nor manually (using inspections or other review \ntechniques) \u2014 searching for possible defects \nand then removing or repairing the confirmed \ndefects before the software is released for use.\n3.4. Analyzing for Traceability  \n\b\n[3*, c4s7.1, c4s7.2]\nDeveloping software typically involves using, \ncreating and modifying many work products \nsuch as planning documents, process specifica-\ntions, software requirements, diagrams, designs \nand pseudo-code, handwritten and tool-gen-\nerated code, manual and automated test cases \nand reports, and files and data. These work \nproducts may share various dependency rela-\ntionships (e.g., uses, implements and tests). As \nsoftware is developed, managed, maintained or \nextended, these traceability relationships must \nbe mapped and controlled to demonstrate the \nsoftware requirements\u2019 consistency with the \nsoftware model (see Requirements Tracing in \nthe Software Requirements KA) and the many \nwork products. Use of traceability typically \nimproves the management of software work \nproducts and software process quality and \nassures stakeholders that all requirements are \nsatisfied. Traceability enables change analysis \nonce the software is developed and released \nbecause relationships to software work prod-\nucts can easily be traversed to assess change \nimpact. Modeling tools typically help automat-\nically or manually specify and manage trace-\nability links among requirements, design, code \nand/or test entities that might be represented in \nthe models and other software work products. \n(For more information on traceability, see the \nSoftware Configuration Management KA.)\n3.5. Analyzing for Interaction  \n\b\n[2*, c10, c11, 3*, c29s1.1, c29s5, 4*, c5]\nInteraction analysis focuses on the communica-\ntions or control-flow relations between entities \nused to accomplish a specific task or function \n", "page": 240, "type": "text", "section": "Page 240"}
{"text": "SOFTWARE ENGINEERING MODELS AND METHODS   11-7\nwithin the software model. This analysis \nexamines the dynamic behavior of the inter-\nactions among the software model\u2019s different \nparts, including other software layers (such as \nthe operating system, middleware and appli-\ncations). Examining interactions between the \ncomputer software application and the user \ninterface software might also be important \nfor some software applications. Some soft-\nware modeling environments provide simula-\ntion facilities to study aspects of the dynamic \nbehavior of modeled software. Stepping \nthrough the simulation allows the software \nengineer to review the interaction design and \nverify that the software\u2019s different parts work \ntogether to provide the intended functions.\n4. Software Engineering Methods\nSoftware engineering methods provide an \norganized and systematic approach to devel-\noping software for a target computer. There \nare numerous methods from which to choose, \nand the software engineer needs to choose an \nappropriate method or methods for the soft-\nware development task at hand. This choice \ncan dramatically affect the success of the \nproject. When software engineers, working \nwith people who have the right skill sets and \nthe right tools, use these software engineering \nmethods, they can visualize the software\u2019s \ndetails and ultimately transform the represen-\ntation into a working set of code and data.\nSelected software engineering methods \nare discussed below. The topic areas are orga-\nnized into discussions of Heuristic Methods, \nFormal Methods, Prototyping Methods and \nAgile Methods.\n4.1. Heuristic Methods \b\n[1*, c13, c15, c16, 3*, \nc2s2.2, c7s1, c5, 8, \b\npp.xiii-xvii  9, c2s2, 11, \n\b\nc1, 12, c1s1, 19, pp.220-242]\nHeuristic methods are experience-based soft-\nware engineering methods that are fairly widely \npracticed in the software industry. This topic \narea contains five broad discussion categories: \nstructured analysis and design methods, data \nmodeling methods, object-oriented analysis \nand design methods, aspect-oriented develop-\nment methods, and model-driven and mod-\nel-based development methods.\n\u2022\t Structured analysis and design methods: \nThese methods develop the software \nmodel primarily from a functional or \nbehavioral viewpoint. It starts from a \nhigh-level view of the software (including \ndata and control elements). It then pro-\ngressively decomposes or refines the \nmodel components through increasingly \ndetailed designs. The detailed designs \neventually converge to specific software \ndetails or specifications that must be \ncoded (by hand, automatically generated \nor both), built, tested and verified.\n\u2022\t Data modeling methods: The data model \nis constructed from the viewpoint of the \ndata or information used. Data tables and \nrelationships define the data models. This \ndata modeling method is used primarily \nto define and analyze data requirements \nsupporting database designs or data \nrepositories typically found in business \nsoftware, where data is actively managed \nas a business systems resource or asset. \n\u2022\t Object-oriented analysis and design methods: \nThe object-oriented model is represented as \na collection of objects that encapsulate data \nand relationships and interact with other \nobjects through methods. Objects may be \nreal-world items or virtual items. These \nmethods build models using diagrams to \nconstitute selected views of the software. \nProgressive refinement of the models leads \nto a detailed design. The detailed design \nis then either evolved through succes-\nsive iterations or transformed (using some \nmechanism) into the implementation view \nof the model, where the code and pack-\naging for eventual software product release \nand deployment are expressed. Popular \nobject-oriented approaches include Unified \nProcess (UP) and specific implementa-\ntions of UP, such as Rational Unified \nProcess (RUP). (See Software Design KA, \nModel-Based Requirements and Software \nRequirements KA.)\n", "page": 241, "type": "text", "section": "Page 241"}
{"text": "11-8   SWEBOK \u00ae GUIDE V4.0\n\u2022\t Aspect-Oriented Development Methods: The \naspect-oriented approach aims to separate \ncrosscutting concerns from non-crosscut-\nting ones in the system and keeps them \nencapsulated throughout the entire life \ncycle to solve their scattering and tangling \nproblem. Aspect is the unit of modularity \nto encapsulate crosscutting concerns. At \nthe software level, there is a \u201cweaver\u201d \nthat is in charge of joining the portions \nof functionality (advices) encapsulated \nin the incumbencies at certain points of \nbase behavior (join points), according to \nwell-defined predicates (pointcuts).\n\u2022\t Model-Driven \nand \nModel-Based \nDevelopment Methods: \nModel-Driven \nDevelopment (MDD) is an approach \nusing models as primary artifacts of \nthe development process. In MDD, usu-\nally the implementation or other models \nare (semi)automatically transformed from \nthe models. Model-Based Development \n(MBD) uses models to analyze the system, \nwhere models are not necessarily the pri-\nmary artifacts. Some literature refers to \nMBD as the acronym for Model-Based \nDesign. Model-Based Design is a mod-\nel-centric approach to developing con-\ntrol, signal processing, communications, \nand other dynamic systems, focusing \non executable specification and simula-\ntion. See Software Design KA. Model-\nDriven Requirements and Model-Based \nRequirements apply the same mentality to \nspecification of software requirements, see \nthe Software Requirements KA for more \ninformation on this topic. MDD/MBD is a \nprerequisite to Model-Based Architecture, \nsee the Software Architecture KA. \nSometimes, test cases are generated from \nmodels, see the Software Testing KA.\n4.2. Formal Methods  \n\b[1*, c18, 3*, c27, 5*, pp8-24, 10, pp.xi-xiv]\nFormal methods are software engineering \nmethods that apply rigorous, mathemati-\ncally based notation and language to specify, \ndevelop and verify the software. Through \nuse of a specification language, the software \nmodel can be systematically checked for con-\nsistency (or lack of ambiguity), complete-\nness, and correctness, either automatically \nor semiautomatically. This topic is related to \nthe Formal Analysis section in the Software \nRequirements KA. \nThis section addresses specification lan-\nguages, program refinement and derivation, \nformal verification, logical inference, and \nlightweight formal methods.\n\u2022\t Specification languages: Specification lan-\nguages provide the mathematical basis \nfor a formal method. Specification lan-\nguages are formal, higher-level computer \nlanguages (not a classic 3rd-generation \nlanguage (3GL) programming language) \nused during the software specification, \nrequirements analysis and/or design stages \nto describe specific input/output behavior. \nSpecification languages are not directly \nexecutable languages. Instead, they typ-\nically comprise a notation and syntax, \nsemantics for the use of the notation, and \na set of allowed relations for objects. \n\u2022\t Program \nrefinement \nand \nderivation: \nProgram refinement creates a lower-level \n(or more detailed) specification using a \nseries of transformations. Through suc-\ncessive transformations, the software \nengineer derives an executable represen-\ntation of a program. Specifications may \nbe refined, adding details until the model \ncan be formulated in a 3GL program-\nming language or in an executable por-\ntion of the chosen specification language. \nThis specification refinement is made \npossible by defining specifications with \nprecise semantic properties. For example, \nthe specifications must set out not only \nthe relationships between entities but \nalso the exact runtime meanings of those \nrelationships and operations.\n\u2022\t Formal verification: Model checking is a \nformal verification method. It typically \ninvolves performing a state-space explo-\nration or reachability analysis to demon-\nstrate that the represented software design \n", "page": 242, "type": "text", "section": "Page 242"}
{"text": "SOFTWARE ENGINEERING MODELS AND METHODS   11-9\nhas or preserves certain model properties \nof interest. An example of model checking \nis an analysis that verifies correct program \nbehavior under all possible interleaving of \nevent or message arrivals. Formal verifica-\ntion requires a rigorously specified model \nof the software and its operational envi-\nronment. This model often takes the form \nof a finite-state machine or other formally \ndefined automaton.\n\u2022\t Logical inference: Logical inference is a \nmethod of designing software that spec-\nifies preconditions and postconditions \naround each significant design block. \nUsing mathematical logic, it develops the \nproof that those preconditions and post-\nconditions must hold under all inputs. \nThis allows the software engineer to pre-\ndict software behavior without having \nto execute the software. Some inte-\ngrated development environments (IDEs) \ninclude ways to represent these proofs and \nthe design or code.\n\u2022\t Lightweight Formal Methods: Lightweight \nformal \nmethods \nare \nlightweight \napproaches \nthat \nbalance \npractical \nusability and rigorous verification. For \ninstance, Alloy takes from formal specifi-\ncation the idea of a precise and expressive \nnotation based on a tiny core of simple and \nrobust concepts, but it replaces conven-\ntional analysis based on theorem proving \nwith a fully automatic analysis that gives \nimmediate feedback. Unlike theorem \nproving, this analysis is not \u201ccomplete\u201d: it \nexamines only a finite space of cases.\n4.3. Prototyping Methods  \n\b\n[1*, c12s2, 3*, c2s3.1, 6*, c7s3p5]\nSoftware prototyping is an activity that gen-\nerally creates incomplete or minimally func-\ntional versions of a software application, \nusually for trying out specific new features; \nsoliciting feedback on software requirements \nor user interfaces; further exploring software \nrequirements, software design, or imple-\nmentation options; or gaining some other \nuseful insight into the software. The software \nengineer selects a prototyping method to \nfirst understand the least understood soft-\nware aspects or components. This approach \ncontrasts with other software engineering \nmethods that usually begin development with \nthe best-understood portions first. Typically, \nthe prototype does not become the final soft-\nware product without extensive development \nrework or refactoring.\nThis section briefly discusses prototyping \nstyles, targets and evaluation techniques.\n\u2022\t Prototyping style: \nPrototyping \nstyles \ndescribe the various approaches to devel-\noping prototypes. A prototype can be \ndeveloped as throwaway code or a paper \nproduct, as an evolution of a working \ndesign, or as an executable specification. \nDifferent prototyping life cycle processes \nare typically used for each style. The style \nchosen is based on the type of results the \nproject needs, the quality of the results \nneeded and the results\u2019 urgency.\n\u2022\t Prototyping target: The prototyping target \nis the specific product served by the pro-\ntotyping effort. Examples of prototyping \ntargets are a requirements specification, \nan architectural design element or com-\nponent, an algorithm, and a human-ma-\nchine user interface.\n\u2022\t Prototyping evaluation techniques: The \nsoftware engineer or other project stake-\nholders may use or evaluate the prototype \nin many ways, driven primarily by the \nunderlying reasons that led to prototype \ndevelopment. Prototypes may be evalu-\nated or tested against the implemented \nsoftware or target requirements (e.g., a \nrequirements prototype). The prototype \nmight also serve as a model for future \nsoftware development (e.g., as in a user \ninterface specification).\n4.4. Agile Methods  \n\b\n[3*, c3, 6*, c7s3p7, 7*, c6, App. A, \n \n\b\n13, 14, 15, 16, 18]\nAgile methods were developed in the 1990s to \nreduce the apparent large overhead associated \n", "page": 243, "type": "text", "section": "Page 243"}
{"text": "11-10   SWEBOK \u00ae GUIDE V4.0\nwith heavyweight, plan-based methods used \nin large-scale software development projects. \nAgile methods are considered lightweight \nbecause of their short, iterative development \ncycles, self-organizing teams, simpler designs, \ncode refactoring, test-driven development, \nfrequent customer involvement and emphasis \non creating a demonstrable working product \nwith each development cycle. Agile methods \ncan be seen as an application of the Deming \nimprovement cycle of Plan-Do-Check-Act \n(PDCA) to software engineering. For \nexample, EVO, which is one of the earliest \nagile methods, is known as a practical way to \nimplement the PDCA cycle incrementally.\nMany Agile methods are available in the lit-\nerature. Some more popular approaches, dis-\ncussed here briefly, include rapid application \ndevelopment (RAD), eXtreme programming \n(XP), Scrum, feature-driven development \n(FDD), and Lean software development.\n\u2022\t RAD: RAD methods are used primarily \nin data-intensive, business systems appli-\ncation development. RAD is enabled \nby special-purpose database develop-\nment tools used by software engineers to \nquickly develop, test and deploy new or \nmodified business applications.\n\u2022\t XP: This approach uses stories or sce-\nnarios for requirements, develops tests \nfirst, has direct customer involvement on \nthe team (typically defining acceptance \ntests), uses pair programming, and pro-\nvides continuous code refactoring and \nintegration. Stories are decomposed into \ntasks, prioritized, estimated, developed \nand tested. Each software increment is \ntested with automated and manual tests. \nAn increment may be released frequently, \nsuch as every couple of weeks.\n\u2022\t Scrum: This Agile approach is more \nproject management-friendly than the \nothers. The Scrum master manages the \nactivities within the project increment. \nEach increment is called a sprint and lasts \nno more than 30 days. The product owner \ndetermines which items go into the \nproduct backlog and developed a product \nbacklog item (PBI) list. The tasks from \nthis list are identified, defined, priori-\ntized and estimated. A working version of \nthe software is tested and released in each \nincrement. Daily Scrum meetings ensure \nwork is managed according to the plan.\n\u2022\t FDD: This is a model-driven, short, iter-\native software development approach \nusing a five-phase process: (1) develop a \nproduct model to scope the breadth of \nthe domain, (2) create the list of needs \nor features, (3) build the feature develop-\nment plan, (4) develop designs for itera-\ntion-specific features, and (5) code, test, \nand then integrate the features. FDD is \nsimilar to an incremental software devel-\nopment approach. It is similar to XP, \nexcept that code ownership is assigned \nto individuals rather than to the team. \nIn addition, FDD emphasizes an overall \narchitectural approach to the software, \nwhich promotes building features cor-\nrectly the first time rather than rely on \ncontinual refactoring.\n\u2022\t Lean: This is an application of lean man-\nufacturing principles adapted from the \nToyota Production System to software \ndevelopment. The approach adopts the \nstrategy of making a Minimum Viable \nProduct, in which a team releases the \nsimplest version of its product. The team \nlearns feedback from users and iterates \nbased on the feedback. The concept of \nLean is to optimize the entire develop-\nment process, rather than optimizing the \nindividual development process. By over-\nlooking the entire value flow, including \ndesign, manufacturing, sales, and ser-\nvice delivery, this approach optimizes \nthe flow to quickly deliver the service to \nusers. Kanban is also lightweight process \nthat applies many of the Lean. However, \nthey are some fundamental differences \nbecause Kanban supports managing \nworkflow and visualization.\nThere are many more variations of Agile \nmethods in the literature and in practice. \nThere will always be a place for heavyweight, \n", "page": 244, "type": "text", "section": "Page 244"}
{"text": "SOFTWARE ENGINEERING MODELS AND METHODS   11-11\nplan-based software engineering methods as \nwell as places where Agile methods shine. In \naddition, new methods are arising from com-\nbinations of Agile and plan-based methods: \nPractitioners are defining these new methods \nto balance features from heavyweight and \nlightweight methods based primarily on \norganizational business needs. These busi-\nness needs, as typically identified by project \nstakeholders, should and do drive the choice \nof software engineering method.\nLarge-scale and enterprise agile approaches \nreflect recent efforts to manage many agile \nteams and apply agile principles and practices \nacross the enterprise while keeping promises \nof agile development methodologies (see agile \nmodels in Software Engineering Process KA).\nAgile methodology leads to shorter release \ncycles. Then, Release engineering contributes \nlightweight release cycle.  Release engineering \nis a sub-discipline in software engineering \nconcerned with the compilation, assembly, \nand delivery of source code into finished prod-\nucts or other software components. The trend \ncycle in Agile would be Integration, Building, \nand Testing that Release Engineering focuses \non. DevOps is often conflated with agile \nand continuous deployment approaches of \nsoftware development. To avoid conflating, \nrelease management acts as a method for \nfilling the collaboration gap between devel-\nopment and operations. Release managers \nneed to monitor the development process and \nthe promotion schedule for each release. The \nkey to managing software releases in DevOps \nthat keeps pace with deployment schedules is \nthrough automated management tools such as \na continuous integration (CI) system.\nMATRIX OF TOPICS VS. REFERENCE MATERIAL\nBudgen 2021 [1*]\nMellor and Balcer 2002 [2*]\nSommerville 2011 [3*]\nPage-Jones 1999 [4*]\nWing 1990 [5*]\nBrookshear 2008 [6*]{Brookshear, 2008, \nComputer Science: An Overview}\nBoehm and Turner 2003 [7*]\n1. Modeling\n1.1. Modeling  \nPrinciples\nc3s3, c3s5, \nc4s2, c7s1,  \nc7s2\nc2s2\nc5s0\n1.2. Properties  \nand Expression  \nof Models\nc7s2, c7s3\nc4s1.1p7,  \nc4s6p3,  \nc5s0p3\n1.3. Syntax,  \nSemantics and \nPragmatics\nc2s2.2.2p6\nc5s0\n1.4. Preconditions, \nPostconditions and \nInvariants\nc4s4\nc10s4p2,  \nc10s5p2p4\n", "page": 245, "type": "text", "section": "Page 245"}
{"text": "11-12   SWEBOK \u00ae GUIDE V4.0\n2. Types of  \nModels\n2.1. Structural  \nModeling\nc9s5, c10s5\nc8s1, c5s3\nc4\n2.2. Behavioral  \nModeling\nc9s3, c10s6\nc9s2\nc5s4\n3. Analysis  \nof Models\n3.1. Analyzing for \nCompleteness\nc4s1.1p7,  \nc4s6\npp8-11\n3.2. Analyzing for \nConsistency\nc4s1.1p7,  \nc4s6\npp8-11\n3.3. Analyzing for \nCorrectness \npp8-11\n3.4. Traceability\nc4s7.1, c4s7.2\n3.5. Interaction  \nAnalysis\nc10, c11\nc29s1.1,  \nc29s5\nc5\n4. Software \nEngineering  \nMethods\n4.1. Heuristic  \nMethods\nc13\nc2s2.2, \nc7s1, c5s4.1\n4.2. Formal  \nMethods\nc18s2\nc27\npp8-24\n4.3. Prototyping  \nMethods\nc14s1, c14s2,  \nc14s3\nc2s3.1\nc7s3p5\n4.4. Agile  \nMethods\nc14s5, c14s6\nc3\nc7s3p7\nc6,  \napp. \nA\nREFERENCES \n[1*]\tD Budgen, Software Design: Creating \nSolutions for Ill-Structured Problems, 3rd \nEdition, CRC Press, 2021.\n[2*]\tS.J. Mellor and M.J. Balcer, Executable \nUML: A Foundation for Model-Driven \nArchitecture, 1st ed. Boston: Addison-\nWesley, 2002.\n[3*]\tI. Sommerville, Software Engineering, 9th \ned. New York: Addison-Wesley, 2011.\n[4*]\tM. Page-Jones, Fundamentals of Object-\nOriented Design in UML, 1st ed. \nReading, MA: Addison-Wesley, 1999.\n[5*]\tJ.M. Wing, \u201cA Specifier\u2019s Introduction \nto Formal Methods,\u201d Computer, vol. 23, \npp. 8, 10-23, 1990.\n[6*]\tJ.G. Brookshear, Computer Science: An \nOverview, 10th ed. Boston: Addison-\nWesley, 2008.\n[7*]\tB. Boehm and R. Turner, Balancing \nAgility and Discipline: A Guide for \nthe Perplexed. Boston: Addison-\nWesley, 2003.\n[8]\t B. Selic and S. Gerard, Modeling and \nAnalysis of Real-Time and Embedded \n", "page": 246, "type": "text", "section": "Page 246"}
{"text": "SOFTWARE ENGINEERING MODELS AND METHODS   11-13\nSystems with UML and MARTE: \nDeveloping Cyber-Physical Systems, \nMorgan Kaufmann, 2013.\n[9]\t M. Brambilla, J. Cabot, and M. \nWimmer, Model-Driven Software \nEngineering in Practice, Morgan & \nClaypool Publishers, 2017.\n[10]\tD. Jackson, Software Abstractions, \nrevised edition, The MIT Press, 2016.\n[11]\tR. Aarenstrup, Managing Model-\nBased Design, CreateSpace Independent \nPublishing Platform, 2015.\n[12]\tC. Larman, Applying UML and \nPatterns: An Introduction to Object-\noriented Analysis and Design and Iterative \nDevelopment, Germany: Prentice Hall \nPTR, 2005.\n[13]\tM. Poppendieck and T. Poppendieck, \nLean Software Development: An \nAgile Toolkit, Addison-Wesley \nProfessional, 2003.\n[14]\tT. Ohno, Toyota Production System: \nBeyond Large-Scale Production, Taylor & \nFrancis Distribution, 2021\n[15]\tD.J. Anderson, Kanban: Successful \nEvolutionary Change for Your Technology \nBusiness, Blue Hole Press; Blue Book ed. \nedition, 2010.\n[16]\tJ. Goodpasture, Project management the \nagile way: Making it work in the enter-\nprise, J. Ross Publishing, 2010.\n[17]\tISO/IEC 19505-1:2012, Information \ntechnology \u2014 Object Management \nGroup Unified Modeling Language \n(OMG UML) \u2014 Part 1: Infrastructure.\n[18]\tISO/IEC/IEEE 32675:2022, \nInformation technology \u2014 DevOps \u2014 \nBuilding reliable and secure systems \nincluding application build, package and \ndeployment.\n[19]\tG. Kiczales, J. Lamping, A. Mendhekar, \nC. Maeda, C. Lopes, J. M. Loingtier, \nand J. Irwin, Aspect-oriented pro-\ngramming, ECOOP\u201997, LNCS, Vol. \n1241, 1997.\n", "page": 247, "type": "text", "section": "Page 247"}
{"text": "12-1 \nCHAPTER 12\nSoftware Quality\nACRONYMS\nCI/CD\nContinuous Integration/\nContinuous Delivery\nCoSQ\nCost of Software Quality\nCOTS\nCommercial Off-The-Shelf\nFMEA\nFailure Mode and Effects Analysis\nFTA\nFault Tree Analysis\nIV&V\nIndependent Verification and \nValidation\nPDCA\nPlan-Do-Check-Act\nPSP\nPersonal Software Process\nQFD\nQuality Function Deployment\nRCA\nRoot Cause Analysis\nSCM\nSoftware Configuration \nManagement\nSQA\nSoftware Quality Assurance\nSQAP\nSoftware Quality Assurance Plan\nSQC\nSoftware Quality Control\nSQM\nSoftware Quality Management\nV&V\nVerification and Validation\nINTRODUCTION\nWhat is software quality, and why is it so \nimportant that it is included in many knowl-\nedge areas (KAs) of the SWEBOK Guide? One \nreason is that the term software quality is over-\nloaded. Software quality may refer to the desir-\nable characteristics of software products, to the \nextent to which a particular software product \nhas those characteristics (software product \nquality), and to the processes, tools and tech-\nniques used to achieve those characteristics \n(software process quality). Over the years, \nauthors and organizations have defined the term \nquality differently. Phil Crosby defined quality \nas \u201cconformance to requirements\u201d [2]. Watts \nHumphrey referred to it as \u201cachieving excellent \nlevels of \u201cfitness for use\u201d [3]. Meanwhile, IBM \ncoined the phrase \u201cmarket-driven quality,\u201d \nwhere the \u201ccustomer is the final arbiter\u201d [4]. \nFinally, fitness for purpose is also a term that \nrefers to software qualit. Fitness for purpose is \nthe suitability of a product, system, or service \nfor use by the intended users, for the intended \nuse, in the intended situations, and intended \nenvironmental conditions.\nMore recently, software (product) quality \nhas been defined as the \u201ccapability of a soft-\nware product to satisfy stated and implied \nneeds under specified conditions\u201d [4] and as \n\u201cthe degree to which a software product meets \nestablished requirements; however, quality \ndepends upon the degree to which those \nestablished requirements accurately represent \nstakeholder needs, wants, and expectations\u201d \n[6]. Both definitions embrace the premise of \nconformance to requirements. Neither refers \nto different types of requirements (require-\nments categorized according to functionality, \nreliability, performance, dependability, or any \nother characteristic). Significantly, however, \nthese definitions emphasize that quality is an \nimportant characteristic of requirements.\nThese definitions also illustrate another \nreason for the recurring discussions about soft-\nware quality throughout the SWEBOK Guide \n\u2014 the often-unclear distinction between \nsoftware quality and software quality require-\nments (\u201cthe -ilities\u201d is a common shorthand \nfor these terms). Software quality require-\nments (Quality of Service Constraints in the \nSoftware Requirements KA) are attributes of \n(or constraints on) functional requirements \n(what the system does). Software requirements \n", "page": 248, "type": "text", "section": "Page 248"}
{"text": "12-2   SWEBOK \u00ae GUIDE V4.0\nmay also specify resource use, a communi-\ncation protocol, or many other characteris-\ntics (Technology Constraints in the Software \nRequirements KA). This KA attempts to \nclarify requirements by using software quality \nin the broadest sense from the definitions \nabove and by using software quality require-\nments as constraints on functional require-\nments. Software product quality is achieved \nby conforming to all requirements regard-\nless of specified characteristics or grouping or \nnaming of requirements.\nSoftware quality is also discussed in many \nother SWEBOK Guide Knowledge Areas \nbecause it is a basic concept of a software engi-\nneering effort. The primary goal for all engineered \nproducts is to deliver maximum stakeholder \nvalue while balancing the constraints of develop-\nment, maintenance, and operational cost, some-\ntimes characterized as fitness for use. Stakeholder \nvalue is expressed in requirements. For software \nproducts, stakeholders could value price (what \nthey pay for the product), lead time (how fast \nthey get the product), and software quality. (See \nthe Software Requirements KA for a broader \ndiscussion of this.)\nThe software process quality aspect, \nwhich is implied by the above, must be made \nexplicit. The quality of a software process can \nbe also observed in process characteristics \nsuch as efficiency, effectiveness, usability, and \nlearnability. Defects in that process will likely \nshow up as defects in the resulting software \nproduct, as well.\nFinally, the Agile and DevOps move-\nments aim at improving the software pro-\ncess and product quality through compliance \nby promoting quick iteration feedback loops \nand eliminating organizational silos by col-\nlocating users and software engineers. Other \npractices like pair programming and the auto-\nmation of development, testing, and oper-\nations services also bring value, improve \nefficiency, and can detect defects early. (Refer \nto the Process KA for Agile life cycles and the \nSoftware Operations KA for more informa-\ntion on DevOps processes.)\nThis KA provides an overview of practices, \ntools, and techniques for understanding soft-\nware quality and planning and appraising \nthe state of software quality during develop-\nment, maintenance and operation, from both \na software product perspective and a software \nprocess perspective. Cited references provide \nadditional details.\nBREAKDOWN OF TOPICS FOR \nSOFTWARE QUALITY\nThe breakdown of topics for the Software \nQuality KA is presented in Figure 12.1.\nSoftware Quality\nSoftware Quality\nFundamentals\nSoftware Quality\nManagement Process\nSoftware Quality\nAssurance Process\nSoftware Quality\nTools\nSoftware \nEngineering Culture \nand Ethics\nValue and Cost \nof Quality\nStandards, Models \nand Certi\ufb01cations\nSoftware \nDependability and \nIntegrity Levels\nSoftware Quality\nImprovement\nPlan Quality\nManagement\nEvaluate Quality\nManagement\nPerform corrective \nand Preventive Action\nPrepare for Quality\nAssurance\nPerform Process\nAssurance\nPerform Product\nAssurance\nFigure 12.1. Breakdown of Topics for Software Quality\n", "page": 249, "type": "text", "section": "Page 249"}
{"text": "SOFTWARE QUALITY   12-3\n1.\t Software Quality Fundamentals\nAgreeing on what constitutes software quality \nfor all stakeholders and communicating that \nagreement to software engineers requires \nthat the many aspects of quality be formally \ndefined and communicated. The main chal-\nlenges the software engineer faces to ensure \nquality include the following:\n\u2022\t Difficulty in clearly defining requirements;\n\u2022\t Maintaining effective communication \nwith the client/user;\n\u2022\t Deviations from specifications;\n\u2022\t Architecture and design errors;\n\u2022\t Coding errors;\n\u2022\t Noncompliance with current processes/\nprocedures;\n\u2022\t Inadequate work product reviews and tests;\n\u2022\t Documentation errors.\nSoftware quality is defined as \u201cconfor-\nmance to established requirements; the capa-\nbility of a software product to satisfy stated \nand implied needs when under specified con-\nditions\u201d [6]. It is further defined \u201cby the degree \nto which a software product meets established \nrequirements; however, quality depends upon \nthe degree to which those established require-\nments accurately represent stakeholder needs, \nwants, and expectations\u201d [6]. Quality often \nmeans the absence of defects. The word defect \nis overloaded with too many meanings, as \nengineers and others use the word to refer \nto all different types of anomalies. However, \ndifferent engineering cultures and standards \noften understand \u201cdefect\u201d and other terms \nas having more specific meanings. To avoid \nconfusion, software engineers should use the \nmeaning provided by their standards [14]:\n\u2022\t Error: \u201cA human action that produces an \nincorrect result.\u201d Also called human error;\n\u2022\t Defect: (synonym of a fault) An \u201cimper-\nfection or deficiency in a work product \nwhere that work product does not meet its \nrequirements or specifications and needs \nto be either repaired or replaced.\u201d A defect \nis inserted when a person developing the \nsoftware makes an error. It hides in the \nsoftware until (and if) it is discovered;\n\u2022\t Failure: The \u201ctermination of the ability of \na system to perform a required function \nor its inability to perform within previ-\nously specified limits; an externally visible \ndeviation from the system\u2019s specification \nevent in which a system or system compo-\nnent does not perform a required function \nwithin specified limits.\u201d A failure is pro-\nduced when the software executes a defect.\nA software engineer should understand \nsoftware quality concepts, characteristics, and \nvalues and their application to the many devel-\nopment, maintenance, and operation activi-\nties. An important concept is that the software \nrequirements are expected to define the required \nsoftware quality attributes. Furthermore, soft-\nware requirements influence the measurement \nmethods and acceptance criteria for assessing \nhow the software and related work products \nachieve the desired quality levels. Another \nimportant concept is that software quality \nshould be planned early and assessed at many \nmilestones during the software life cycle. \nFinally, how to adapt software quality assur-\nance (SQA) activities to accommodate different \nlife cycles, for example Agile software develop-\nment is presented in detail in the Institute of \nElectrical and Electronics Engineers (IEEE) \nStandard 730:2014 [6].\n1.1.\t Software Engineering Culture and Ethics  \n\b\n[1*, c1s1.6; c2s3] [5*]\nAn organization\u2019s culture affects how soft-\nware engineers influence software quality. \nAs Iberle explains [19], software engineering \npractices vary depending on the business \nmodel (e.g., custom, mass-market, commer-\ncial, firmware) and the industry where the \nsoftware engineers work. Software engineers \nare expected to share a commitment to soft-\nware quality in the context of their industry \nand as part of their culture. A healthy soft-\nware engineering culture includes many char-\nacteristics, such as the understanding that \ntrade-offs among cost, schedule and quality \n", "page": 250, "type": "text", "section": "Page 250"}
{"text": "12-4   SWEBOK \u00ae GUIDE V4.0\nare a basic tenet of any product\u2019s engineering. \nA strong software engineering ethic assumes \nthat engineers accurately report information, \nconditions and outcomes related to quality. \nEthics also play a significant role in soft-\nware quality in the professional culture of \nengineering, and in the attitudes of software \nengineers. The IEEE Computer Society and \nthe Association for Computing Machinery \n(ACM) have developed a code of ethics and \nprofessional practice. (See Codes of Ethics \nand Professional Conduct in the Software \nEngineering Professional Practice KA.)\n1.2.\t Value and Costs of Quality \b\n[1*, c2s2.2]\nOne major factor driving resistance to imple-\nmenting SQA is its perceived high cost. \nHowever, not implementing basic SQA activ-\nities can be costly as well. Software engineers \nshould inform their administration of the risks \nthey take when they are not fully committed to \nquality. This can be done by explaining the cost \nof software quality concepts to management. \nCost of software quality (CoSQ ) is defined as \nthe sum of the following project costs:\n\u2022\t Implementation cost of planning and \nconstruction activities (e.g., planning, \ndesigning, development);\n\u2022\t Prevention cost of activities (process \nimprovement, tools, training);\n\u2022\t Appraisal costs activities for defect detec-\ntion (e.g., reviews, audits, testing);\n\u2022\t Nonconformance \nand \nrework \ncosts \n(internal failure cost and external \nfailure cost).\nThe CoSQ can be broken down into two \ntop-level categories: conformance cost and non-\nconformance cost. Conformance cost is the total \nof all investments in error and defect detec-\ntion (appraisal) and prevention activities. \nAppraisal costs arise from project activities \nthat are intended to find errors and defects. \nThese include testing (as detailed in the \nSoftware Testing KA) and reviews and audits \n(as detailed later in this KA). Appraisal costs \nextend to subcontracted software suppliers, if \nany. Prevention costs include investments in \nsoftware process improvement (SPI) efforts, \nquality infrastructure, quality tools, work \nproduct templates and training. These costs \nmight not be specific to a project; they often \nspan the larger organization. \nNonconformance cost is the total of all \nspending dealing with errors and defects that \nhave been detected. Pre-delivery costs are \nthose incurred to repair errors and defects \nfound during appraisal activities and discov-\nered before the software product is delivered \nto the customer. Post-Delivery costs include \nthose incurred responding to software fail-\nures discovered after delivery to the customer. \nExternal costs include the rework needed to \nrepair and test an updated release. External \ncosts include rework and repair of the unin-\ntended and uncompensated side effects or \nconsequences of defects. However, the finan-\ncial impact on the customer who encounters a \nfailure is just as important. For example, the \ncustomer\u2019s lost productivity, lost data, and \npotential loss of reputation in the market-\nplace must be acknowledged and accounted \nfor. Beyond the impact on the customer, low-\nquality software can also impact the public and \nthe environment.  Software engineers should \nseek the optimal CoSQ \u2014 the minimal total \ncost for a specified quality level. \n1.3.\t Standards, Models, and Certifications  \n\b\n[1*, c4] [7, c24s24.2]\nSound use of software engineering software \nstandards and software process assessment \nand improvement improves software quality. \nOne of the key general software engineering \nstandards is ISO/IEC/IEEE 12207:2017, \nwhich describes the software life cycle pro-\ncesses. Foremost, software engineers should \nknow the key software engineering stan-\ndards that apply to their specific industry. As \nIberle discussed [19], the practices software \nengineers use vary greatly depending on the \nindustry, business model and organizational \nculture where they work. For example, IEEE \n1228:1994 Standard for Software Safety Plans \nand IEEE 1633:2016 Recommended Practice \n", "page": 251, "type": "text", "section": "Page 251"}
{"text": "SOFTWARE QUALITY   12-5\non Software Reliability target industries \nwhere safety and reliability are important.\nThe Plan-Do-Check-Act (PDCA) para-\ndigms differ from standards in that it often \nproposes \u201cbest practices\u201d for software engi-\nneers from a specific perspective. (Refer to the \nSoftware Engineering Process KA for more \ninformation about the PDCA paradigm for \nsoftware.) \nOther industry \u201cbest practices\u201d models such \nas the Control Objectives for Information and \nRelated Technologies (COBIT) for informa-\ntion technology governance [27], the Project \nManagement Body of Knowledge (PMBOK\u00ae) \nfor project management [25], the Business \nAnalysis Body of Knowledge (BABOK\u00ae) [28], \nthe Capability Maturity Model Integration \n(CMMI) [29] and The Open Group \nArchitecture Framework (TOGAF) propose \nsoftware related practices that can improve the \nquality of software processes and products [30]. \nSoftware organizations can also consider the \npossible advantages of obtaining registrations \nor certifications (e.g., ISO 9001 for quality \n[10], ISO 27001 for security [31], (e.g., ISO \n9001 for quality [10], ISO 27001 for security \n[31] and ISO 20000 for operations [32]), and \nsoftware engineers can also obtain Scrum and \nScaled Agile Framework\u00ae (SAFe\u00ae) certifica-\ntions for Agile processes [22]. The use of these \nmodels and certifications have been shown \nto augment stakeholders\u2019 confidence that the \nsoftware engineers\u2019 knowledge and skills are \nup to date and recognized internationally. \n1.4.\t Software Dependability and Integrity \nLevels \b\n[1*, c4s4.8, c7s7.3.3] [11]\nSoftware-intensive and safety-critical sys-\ntems are those in which a system failure could \nharm human life, other living things, physical \nstructures, or the environment. The software \nin these systems is considered safety-critical \nand requires the use of systematic methods \nand tools to ensure its high level of quality. \nA growing number of industries are using \nincreasing numbers of safety-critical soft-\nware, including transportation systems, chem-\nical and nuclear plants, and medical devices. \nSoftware failure in these systems could have \ncatastrophic effects. Engineers use industry \nstandards, such as software considerations in \nairborne systems and equipment certification \nDO-178C [8] and railway applications EN \n50128 [18], and emerging processes, tools, \nand techniques to develop safety-critical soft-\nware more safely. These standards, tools and \ntechniques reduce the risk of injecting faults \ninto the software and thus improve software \navailability, reliability, and maintainability. \nSoftware engineers and their managers must \nunderstand the threats and issues and develop \nthe skills needed to anticipate and prevent \naccidents before they occur [15].\nSafety-critical software can be catego-\nrized as direct or indirect. Direct software is \nembedded in a safety-critical system, such as \nan aircraft\u2019s flight control computer. Indirect \nsoftware includes software applications used \nto develop safety-critical software. Indirect \nsoftware is included in software engineering \nenvironments and software test environments.\nThree \ncomplementary \ntechniques \nfor \nreducing failure risk are avoidance, detec-\ntion and removal, and damage limitation. \nThese techniques impact software functional \nrequirements, performance requirements and \ndevelopment processes. Increasing risk implies \nincreasing SQA and more rigorous review \ntechniques such as inspections [16]. Higher risk \nlevels might necessitate more thorough inspec-\ntions of requirements, design, and code, or the \nuse of more formal verification and valida-\ntion techniques. Another technique for man-\naging and controlling software risk is building \nassurance cases. An assurance case is a reasoned, \nauditable artifact created to support the con-\ntention that its claim or claims are satisfied. \nIt contains the following relationships: one or \nmore claims about properties, arguments that \nlogically link the evidence and any assump-\ntions to the claims, and a body of evidence and \nassumptions supporting these arguments [9].\n1.4.1.\t Dependability \b\n[7, c10] \nIn cases where system failure may have severe \nconsequences, overall dependability (e.g., \n", "page": 252, "type": "text", "section": "Page 252"}
{"text": "12-6   SWEBOK \u00ae GUIDE V4.0\nhardware, software, and human or oper-\national dependability) is the main quality \nrequirement, aside from basic software func-\ntionality, for the following reasons: System \nfailures affect many people; users often reject \nsystems that are unreliable, unsafe, or inse-\ncure; system failure costs could be important; \nand undependable systems might cause infor-\nmation loss. Many standards address dif-\nferent perspectives of dependability, such as \nreliability and availability. System and soft-\nware dependability regroups several related \nquality characteristics: availability, reliability, \nmaintainability and supportability, safety and \nsecurity [21]. When developing dependable \nsoftware, engineers can apply tools and tech-\nniques to reduce the risk of injecting faults into \nthe intermediate deliverables or the final soft-\nware product. They can use static, dynamic, or \nformal methods for verification and validation \n(V&V), and testing processes, as well as other \nspecialized techniques, methods, and tools to \nidentify defects that affect dependability as \nearly as possible in the software life cycle [7*, \nc10.5]. Additionally, they may have to incor-\nporate specific mechanisms into the software \nto guard against external attacks and to tol-\nerate faults during its operation.\n1.4.2.\t Integrity Levels of Software  \n\b\n[1*, c4s4.8, c7s7.3.2] [11]\nDefining integrity levels is a method of risk \nmanagement. An integrity level is \u201ca value rep-\nresenting project-unique characteristics (e.g., \ncomplexity, criticality, risk, safety level, secu-\nrity level, desired performance, and reliability) \nthat define the importance of the system, \nsoftware, or hardware to the user\u201d [11]. The \ncharacteristics used to determine software \nintegrity level vary depending on the intended \napplication and use of the system. The soft-\nware is a part of the system, and its integrity \nlevel is determined as a part of that system.\nThe assigned software integrity levels \nmight change as the software evolves. Design, \ncoding, procedural and technology features \nimplemented in the system or software can \nraise or lower the assigned software integrity \nlevels. The software integrity levels estab-\nlished for a project result from agreements \namong the acquirer, supplier, developer, and \nindependent assurance authorities. A software \nintegrity level scheme is used to determine soft-\nware integrity levels [11].\nSoftware engineers should know that in \ncertain safety-critical industries, such as \navionics, railways, nuclear power, medical \ndevices and many others, industry-specific \nguidance can require a certain level of inde-\npendence for software quality activities and \ncan assign minimum V&V techniques to \nbe used by integrity level (example of such \ntechniques are: usability analysis, algorithm \nanalysis, boundary value analysis, data flow \nanalysis, walk-through review [11][26]).\n2.\t Software Quality Management Process\n\u201cSoftware quality management\u201d (SQM) is \nconcerned with coordinating activities to \ndirect and control an organization with regard \nto software quality\u201d [6]. The purpose of the \nQuality Management process is to assure that \nproducts, services, and implementations of \nthe quality management process meet orga-\nnizational and project quality objectives and \nachieve customer satisfaction.  \nSoftware engineers can learn about the \nSQM process in the many software engi-\nneering standards, models, and certifications \navailable and used widely in the industry. \nAn important concept of SQM is the design \nand upkeeping of a Quality Management \nSystem (QMS). As proposed by ISO90003 \n[26] which interprets ISO9001 concepts for \nthe software industry.\nQMS defines processes, process owners, \nrequirements for the processes, measurements \nof the processes and their outputs, and feed-\nback channels throughout the whole software \nlife cycle. A QMS comprises many key activ-\nities: SQA, V&V, reviews and audits, soft-\nware configuration management (SCM), and \nrequires policies, procedures, and processes \nto ensure that everyone involved understands \nwhat is expected in terms of software pro-\ncess and product quality. For a QMS to be \n", "page": 253, "type": "text", "section": "Page 253"}
{"text": "SOFTWARE QUALITY   12-7\neffective, management support is impera-\ntive. Management support implies that proj-\nects are trained to the QMS requirement and \nhave enough resources to achieve the quality \ngoal defined for it. Management sponsorship \nshould be solicited frequently during soft-\nware project review to ensure software quality \nactivities are executed and nonconformities \naddressed.\nFor a software project, software quality \nprocesses consist of tasks and techniques to \nindicate how software plans (e.g., software \nmanagement, development, quality manage-\nment or configuration management plans) are \nimplemented and how well the intermediate \nand final products meet their specified require-\nments. Results from these tasks are assem-\nbled in reports for management. SQM process \nmanagement is tasked with ensuring that the \nreport results are accurate and acted upon.\nRisk management can also play an \nimportant role in delivering quality software. \nIncorporating disciplined risk analysis and \nmanagement techniques into the software \nlife cycle processes can help improve product \nquality. (See the Software Engineering \nManagement KA for related material on risk \nmanagement.)\n2.1.\t Software Quality Improvement  \n\b\n[1*, s9.9 and c9] [2] [3]\nSoftware quality improvement (SQI) is done \nusing many different approaches within the \nsoftware industry, including software process \nimprovement (SPI), Six Sigma, Lean, and \nKaizen just to name a few. For example, the \nSPI activities seek to improve process effec-\ntiveness, efficiency, and other characteristics \nto improve software quality. For example, \nalthough SPI could be included in any of the \nfirst three categories, many organizations \norganize SPI into a separate category that \nmight span many projects. \nSoftware product quality can be improved \nusing Lean principles as well as an iterative \nprocess of continual improvement, which \nincludes management control, coordination of \nactivities, and feedback from many concurrent \nprocesses: (1) the process of improving the \nsoftware life cycle processes; (2) the pro-\ncess of fault/defect categorization, detection, \nremoval, and prevention; and (3) a personal \nimprovement process. \nThe theory and concepts behind quality \nimprovement \u2014 such as building quality \nthrough the prevention and early detection of \ndefects, continual improvement, and stake-\nholder focus \u2014 are also pertinent to software \nengineering. These concepts are based on the \nwork of experts in quality who have stated \nthat a product\u2019s quality is directly linked to \nthe quality of the process used to create it. \nImprovement models such as the Plan-Do-\nCheck-Act (PDCA) improvement cycle, evo-\nlutionary delivery, Kaizen, and techniques \nlike quality function deployment (QFD) offer \nways to specify quality objectives and deter-\nmine whether they are met. \nFinally, since software engineering is a \ncomplex process, it cannot be reduced to a \ncookbook of procedures. To complement the \nprocess and tools improvement movement, \nHumphrey proposed the personal software \nprocess (PSP) for software engineers to also \nassess their skills and knowledge constantly \nand continually improve them as well. \n2.2.\t Plan Quality Management\b\n[1*, c13]\nSoftware quality planning includes determining \nwhich quality standards and models are to be \nused, defining specific quality goals, estimating \nthe effort to be used to achieve each goal; and \ndeciding at what milestone the software quality \nactivity should take place. In some cases, soft-\nware quality planning also includes defining \nthe software quality processes to be used.\nFirst, the software organization must \ncommit to quality by establishing their quality \nmanagement system (QMS) which includes \nquality management policies, objectives, and \nprocedures. This requires that the respon-\nsibility and authority for implementing the \nQMS are assigned and that they are indepen-\ndent of current project management teams.\nAn approved organizational policy, about \nsoftware quality, helps in guiding projects \n", "page": 254, "type": "text", "section": "Page 254"}
{"text": "12-8   SWEBOK \u00ae GUIDE V4.0\nand products development decisions as well \nas behavior of personnel. Software engineers \nshould promote the use of graphically repre-\nsented processes and procedures that imple-\nment the quality policy and explain the roles, \nactivities to be executed and the expected \nresults of key software engineering activi-\nties. Consequently, for a QMS to be used \nin improvement its processes should be doc-\numented with its user in mind and iden-\ntify where quality controls are to be verified. \nFinally, procedures explain in detail what \nsteps are taken to execute a specific activity. \n2.3.\t Evaluate Quality Management\nOnce the QMS is in place, the ISO/IEC \nTechnical Specification TS 33061:2021 [23] \nStandard defines a process assessment model \nfor software life cycle processes using five pro-\ncess capabilities levels (from level 0: incomplete \nto level 5: optimizing process). Additionally, \nsoftware engineers can assess the maturity of \ntheir QMS activities in their software projects \nusing the IEEE 730:2014 Standard guidance \n[6]. Management sponsorship supports pro-\ncess and product evaluations. The evaluation \nfindings feed into an improvement program \nfor identifying detailed actions and improve-\nment projects to be addressed in a feasible \ntime frame. Periodically, the software engi-\nneers will gather and analyze quality assur-\nance evaluation results. This can be achieved \nby looking at quality measures and defect \ncharacterization produced by the projects.\n2.3.1.\t Software Quality Measurement  \n\b\n[1*, c10] [7, c24s24.5]\nSoftware quality measurements are used \nto support decision-making. With the \nincreasing sophistication of software, quality \nquestions go beyond whether the software \nworks to how well it achieves measurable \nquality goals. Quantifying some attribute \nof software can help engineers evaluate its \nquality or the quality of its process. (Process \nmeasurement is described in detail in the \nProcess KA.) \nSoftware quality measurement helps engi-\nneers \nmake \ndeterminations \nabout \nsoft-\nware quality (because models of software \nproduct quality include measures to deter-\nmine the degree to which the software product \nachieves quality goals); managerial questions \nabout effort, cost, and schedule; when to stop \ntesting and release a product (see Test-Related \nMeasures\u00a0 in the Software Testing KA); and \nthe efficacy of process improvement efforts.\nThe CoSQ assurance activities are an issue \nfrequently raised in deciding how a project \nor a software development and maintenance \norganization should be organized. Often, \ngeneric models of cost are used; these models \nare based on when a defect is found and how \nmuch effort it takes to fix the defect rela-\ntive to finding the defect earlier in develop-\nment. Software quality measurement data \ncollected internally may offer a better picture \nof cost within the project or organization. \nAlthough the software quality measurement \ndata may be useful by itself (e.g., the number \nof defective requirements or the proportion \nof defective requirements), mathematical \nand graphical techniques can help project \nstakeholders interpret the measures. (See \nthe Engineering Mathematical Foundations \nKA.) These techniques include the following:\n\u2022\t Descriptive statistics-based analysis (e.g., \nPareto analysis, run charts, scatter plots, \nnormal distribution);\n\u2022\t Statistical tests (e.g., the binomial test, \nchi-squared test);\n\u2022\t Trend analysis (e.g., control charts; see \nThe Quality Toolbox in Further Readings);\n\u2022\t Prediction (e.g., reliability models).\nDescriptive statistics-based techniques and \ntests often provide a snapshot of the more \ntroublesome areas of the software product \nunder examination. The resulting charts and \ngraphs are visualization aids decision-makers \ncan use to focus resources and conduct process \nimprovements where they seem most needed. \nResults from trend analysis may indicate that \na schedule is slipping or that certain classes \nof faults may become more likely unless some \n", "page": 255, "type": "text", "section": "Page 255"}
{"text": "SOFTWARE QUALITY   12-9\ncorrective action is taken in development. The \npredictive techniques help estimate testing \neffort and schedule and predict failures. (More \ndiscussion on measurement in general appears \nin the Software Engineering Process and \nSoftware Engineering Management KAs. \nMore specific information on testing mea-\nsurement is presented in the Software Testing \nKA.) Software quality measurement also \nincludes measuring defect occurrences and \napplying statistical methods to understand \nwhat types of defects occur most frequently. \nThree widely used software quality measure-\nments are error density (number of errors per \nunit size of documents/software), defect den-\nsity (number of defects found divided by the \nsize of the software), and failure rate (mean \ntime to failure). Reliability models are built \nfrom failure data collected during software \ntesting or from software in service and thus \ncan be used to estimate the probability of \nfuture failures and assist in decisions about \nwhen to stop testing. This information can \nbe used in SPI to determine methods to pre-\nvent, reduce or eliminate defect recurrence. \nThe information also helps engineers under-\nstand trends, how well detection and contain-\nment techniques are working, and how well \nthe development and maintenance processes \nare progressing. They can use these measure-\nment methods to develop defect profiles for \na specific application domain. Then, for the \nnext software project within that organi-\nzation, the profiles can be used to guide the \nSQM processes \u2014 that is, to focus effort \non where problems are most likely to occur. \nSimilarly, benchmarks, or defect counts typ-\nical of that domain, may help engineers deter-\nmine when the product is ready for delivery. \n(Discussion about using measurement data to \nimprove development and maintenance pro-\ncesses appears in the Software Engineering \nManagement and Software Engineering \nProcess KAs.)\n2.4.\t Perform Corrective and Preventive Actions \nIt is important that when quality manage-\nment objectives are not met, corrective actions \nbe documented and submitted so that the \nQMS be improved to prevent problem from \nreoccurring in future software projects. This \nrequires that project participants have a way \nof reporting software engineering process \nand tools problems to an independent orga-\nnization that will document and monitor the \nprogress of the corrective actions and inform \nthe relevant stakeholders.  \n2.4.1.\t Defect Characterization \b\n[1*, c1s3]\nTo help in the elimination of the cause or \ncauses of an existing nonconformity or unde-\nsirable situation to prevent recurrence, soft-\nware engineers can use software quality \ncontrol (SQC) techniques to find errors, \ndefects, and failures in their processes and \nproducts. When tracking errors, defects and \nfailures, the software engineer is interested in \nthe number and types of incidents. Numbers \nalone, without classification, might be insuf-\nficient to help in identifying the underlying \ncauses and thus to prevent them in the future. \nTherefore, software engineers should establish \na meaningful defect classification taxonomy to \ndescribe and categorize such anomalies. One \nprobable action resulting from peer reviews \nand testing findings is to remove these errors \nand defects early from the work product under \nexamination. \nOther SQM activities attempt to eliminate \ntheir causes (e.g., root cause analysis (RCA)). \nRCA activities include analyzing and sum-\nmarizing the findings to find root causes and \nusing measurement techniques to improve the \nsoftware engineering processes, techniques \nand tools. (Process improvement is pri-\nmarily discussed in the Software Engineering \nProcess KA. RCA is further discussed in the \nEngineering Foundations KA.)\nData on errors and defects found during \nSQA and control techniques may be lost \nunless they are recorded. For some techniques \n(e.g., peer reviews and inspections), software \nengineers are present to record such data and \nto address issues and make decisions. In addi-\ntion, when automated tools are used (see Topic \n4, Software Quality Tools), the tool output \n", "page": 256, "type": "text", "section": "Page 256"}
{"text": "12-10   SWEBOK \u00ae GUIDE V4.0\nmay provide defect trends reports that can be \nprovided to the organization\u2019s management. \n3.\t Software Quality Assurance Process\n3.1.\t Prepare for Quality Assurance  \n\b\n[1*, c1s1.5, c4s4.6]  [6]\nSoftware quality assurance (SQA) is defined as \n\u201ca set of activities that define and assess the \nadequacy of software processes to provide evi-\ndence that establishes confidence that the soft-\nware processes are appropriate for and produce \nsoftware products of suitable quality for their \nintended purposes.\u201d To correct a common \nmisunderstanding, SQA is not only testing of \na software. A key attribute of SQA, in critical \nsystems, is the objectivity of the SQA function \nconcerning the quality of a software product. \nIn this case, the SQA function might also be \norganizationally independent of the project; \nthat is, free from technical, managerial, and \nfinancial pressures [6]. SQA has two aspects: \nproduct assurance and process assurance, \nwhich are introduced in Section 2.3. \nThe software quality plan (in some industry \nsectors, it is termed the software quality \nassurance plan (SQAP)) defines the activities \nand tasks used to ensure that software devel-\noped for a specific product satisfies the proj-\nect\u2019s established requirements and user needs \nwithin project cost and schedule constraints \nand is commensurate with project risks. The \nSQAP first ensures that quality targets are \nclearly defined and understood.\nThe SQAP\u2019s quality activities and tasks \nare specified, along with their costs, resource \nrequirements, objectives, and schedule in \nrelation to related objectives, in the software \nengineering management, software develop-\nment and software maintenance plans. The \nSQAP identifies documents, standards, prac-\ntices, and conventions governing the project \nand how these items are checked and mon-\nitored to ensure adequacy and compliance. \nThe SQAP also identifies measures; statistical \ntechniques; procedures for problem reporting \nand corrective action; resources such as tools, \ntechniques, and methodologies; security for \nphysical media; training; and SQA reporting \nand documentation. Moreover, the SQAP \naddresses the SQA activities of any other type \nof activity described in the software plans \u2014 \nsuch as procurement of supplier software for \nthe project, commercial off-the-shelf (COTS) \nsoftware installation and service after soft-\nware delivery. It can also contain acceptance \ncriteria and reporting and management activ-\nities that are critical to software quality. The \nSQA plan should not conflict with the soft-\nware configuration management plan or any \nother relevant project plannning artifact. \nMore over they should be considered com-\nplimentary activities (for process SQAP the \nSCM Process Audit and the Testing activities \nfor SCM Functional Audit).\nSoftware quality encompasses several per-\nspectives: the software process quality, the \nsoftware end-product quality and the soft-\nware work products (also called intermediary \nproducts) quality. The next sections cover each \nperspective of software quality knowledge a \nsoftware engineer must have.\n3.2.\t Perform Process Assurance  \n\b\n[1*, c3s3.2\u2013s3.3, c4s4.6.1.3, c8, c9] [7, c25]\nCrosby [2] and Humphrey [3] have demon-\nstrated that software quality management \n(SQM) and software engineering process \nquality have a direct effect on the quality of the \nfinal software product. (Models and criteria \nthat evaluate and improve the capabilities of \nsoftware organizations are primarily project \norganization and management considerations \nand, as such, are covered in the Software \nEngineering Management and Software \nEngineering Process KAs.) International \nOrganization for Standardization (ISO) 9001 \n[10] proposes another process quality perspec-\ntive, where a management system that over-\nsees the processes\u2019 actors, activities, controls, \ninput, and outputs ensures the quality of out-\nputs (e.g., work products and final product). A \nmanagement system is defined as a \u201cset of inter-\nrelated or interacting elements of an organi-\nzation to establish policies and objectives, \nand processes to achieve those objectives\u201d \n", "page": 257, "type": "text", "section": "Page 257"}
{"text": "SOFTWARE QUALITY   12-11\n[10]. This perspective requires software engi-\nneering organizations to take the time to \ndescribe their policies, processes, and proce-\ndures with enough detail that software engi-\nneer roles and responsibilities are clear during \nlife cycle activities (as detailed in the Software \nEngineering Process KA).\nSQA activities, listed in the IEEE 730:2014 \nStandard [6], describe the many quality assur-\nance activities that should be conducted early \nin a software project\u2019s life cycle to ensure \nquality. Software engineers should be aware \nof the need to plan and execute SQA activ-\nities at certain project milestones and keep \nrecords of their execution. These activities \nconsist of document and code reviews as well \nas verification and validation (V&V) activi-\nties, including testing (as detailed in Section \n3.4 of this KA), which evaluate the output of \na process\u2019s compliance with its requirements \nand specifications.\nFinally, \nsoftware \nconfiguration \nman-\nagement (SCM) is an important activity to \nensure the quality of work products and soft-\nware. Configuration management is defined as \nthe \u201cdiscipline applying technical and admin-\nistrative direction and surveillance to:\n\u2022\t identify and document the functional \nand physical characteristics of a config-\nuration item;\n\u2022\t control changes to those characteristics;\n\u2022\t record and report change processing and \nimplementation status;\n\u2022\t verify \ncompliance \nwith \nspecified \nrequirements.\u201d \nSoftware engineers should identify which \nwork products and software artifacts require \nconfiguration management. In addition, they \nshould be familiar with source code ver-\nsioning processes, which involve keeping \ntrack of baselined and incremental versions of \nthe software and ensuring that changes dif-\nferent developers make do not interfere with \none another, and they should know how to \noperate the version control tool kit. (Refer \nto the Software Configuration Management \nKA for more information about this process.)\n3.3.\t Perform Product Assurance  \n\b\n[1*, s3.2\u2013s3.3] [7, c4, s4.6.1.2] \nFirst, the software engineer must determine \nthe real purpose of the software to be designed \nand constructed. Stakeholder requirements are \nparamount here. They include quality require-\nments (called Quality of Service Constraints in \nthe Software Requirements KA) and func-\ntional requirements. Thus, software engineers \nare responsible for eliciting quality require-\nments that might not be explicit at the outset \nand for understanding their importance and \nthe difficulty in defining them, measuring \nthem, and establishing them for final accep-\ntance. Software engineers should understand \nhow to define quality requirements as well as \ntheir quality targets to ensure they can effec-\ntively be measured at the acceptance stage \nof the project. During the project planning, \nsoftware engineers must keep these quality \nrequirements in mind. They must also antici-\npate potential additional development costs if \nattributes such as safety, security and depend-\nability are important.\nAn international standard on what con-\nstitutes a software product\u2019s many measur-\nable quality characteristics was reached and \nis described in ISO/IEC 25010:2011 [4]. This \nstandard proposes several software product \nquality models, consisting of characteristics \nand sub-characteristics, for software product \nquality and software quality in use. Another \nis IEEE 982.1:2005 Standard Dictionary \nof Measures to Produce Reliable Software. \nThese software characteristics are commonly \ncalled product quality requirements, which are \nnonfunctional software requirements [7*, \nc4,s4.6.1.2]. Software engineers should know \nthe many software characteristics that can be \nplanned, implemented, and measured during \nsoftware construction (e.g., functional suit-\nability, performance efficiency, compatibility, \nusability, reliability, security, maintainability, \nand portability). Software engineers should \nalso know that certain quality characteris-\ntics have conflicting impacts. For example, \ntrying to augment the security characteristic \nby encrypting data might adversely affect the \n", "page": 258, "type": "text", "section": "Page 258"}
{"text": "12-12   SWEBOK \u00ae GUIDE V4.0\nperformance characteristic. This international \nstandard also proposes a general data quality \nmodel that focuses on data quality as part of \na computer system and defines quality char-\nacteristics for target data used by humans \nand systems.\nAnother software product quality perspec-\ntive is the quality of work products. The term \nwork product means any artifact resulting from \na process used to create the final software \nproduct. Work products include system/sub-\nsystem specifications, software requirements \nspecifications for a system\u2019s software compo-\nnents, software design descriptions, source \ncode, software test documentation and test \nreports. Sound engineering practice requires \nthat intermediate work products relevant to \nquality be evaluated using work product reviews \nand inspections (discussed later in this chapter) \nthroughout the software engineering process.\n3.4.\t V&V and Testing \b\n[1*, c7] [11]\nVerification ensures that the product is built \ncorrectly in that the output products of a life \ncycle phase meet the specifications imposed \non them in previous phases. Verification is \ndefined as \u201cthe process of evaluating a system \nor component to determine whether the prod-\nucts of a given development phase satisfy the \nconditions imposed at the start of that phase\u201d \n[11]. Alternatively, validation ensures that the \nright product is built \u2014 the product fulfills its \nspecific intended purpose. It is defined as \u201cthe \nprocess of evaluating a system or component \nduring or at the end of the development pro-\ncess to determine whether it satisfies specified \nrequirements.\u201d\nThe purpose of V&V is to help the devel-\nopment organization build quality into the \nsoftware throughout the development life \ncycle. V&V includes software testing tasks. \nSoftware testing is a necessary activity to \nensure product quality. However, in most \ncases, software testing is insufficient to \nestablish confidence that the software fits \nits intended use. V&V tasks listed in IEEE \nStandard 1012:2016 [11] objectively assess \nproducts and processes throughout the life \ncycle. This assessment demonstrates whether \nthe requirements are correct, complete, accu-\nrate, consistent, and testable. The verifica-\ntion process and the validation process should \nbegin early in development or maintenance. \nThis prevents defects late in the life cycle, \nwhich would incur rework and significantly \nincrease costs. Software engineers should \nidentify the product integrity level and ensure \nthe minimum V&V tasks are assigned for key \nproduct features concerning both the product\u2019s \nimmediate predecessor and the planned spec-\nifications. Optional V&V tasks are also listed \nand can improve software product quality. \nKeeping a record of the traceability among \nsoftware work products can help augment \nthe quality of the V&V activities. Traceability \nis defined as the \u201cability to trace the history, \napplication or location of an object\u201d [14]. \nEarly planning of V&V activities ensures \nthat each resource, role, and responsibility \nis clearly assigned. The resulting V&V plan \ndocuments the various resources and their \nroles and SQA activities, as well as the \ntechniques and tools to be used. Software \nengineers should choose and apply the \nproper V&V task depending on the soft-\nware integrity level. (Refer to Section 1.4.2) \nV&V can also be executed by an indepen-\ndent organization for very critical software. \nIndependent verification and validation \n(IV&V) are defined as \u201cV&V performed by \nan organization that is technically, mana-\ngerially, and financially independent of the \ndevelopment organization\u201d [11].\nSoftware V&V tasks can be sorted into \nstatic, dynamic and formal tasks [20]. \nDynamic techniques involve executing the \nsoftware; static techniques involve analyzing \ndocuments and source code but not executing \nthe software; formal techniques use mathe-\nmatics and formal specification languages.\nIt should be noted that there are no strong \nboundaries between \"Static analysis tech-\nniques\", \"Dynamic analysis techniques\" and \n\"Formal analysis techniques\". For example, \nstatic and dynamic analysis techniques usu-\nally have a strong formal background such as \ndata-flow analysis or model checking.\n", "page": 259, "type": "text", "section": "Page 259"}
{"text": "SOFTWARE QUALITY   12-13\n3.4.1.\t Static Analysis Techniques\nStatic analysis techniques directly ana-\nlyze a work product\u2019s content and structure \n(including requirements, interface specifica-\ntions, designs, and models) without executing \nthe software. The only way to detect non-ex-\necutable code is through static analysis as no \ndynamic test can verify that. Static techniques \ncan be executed manually or with the help of a \ntool. Tools and techniques for statically exam-\nining software work can help software engi-\nneers in this task. For example, code reading, \npeer review of a work product, and static anal-\nysis of source code control flow are considered \nstatic techniques because they do not involve \nexecuting the software code.\nWe will see, in section 3.4.5 that review \nand audit processes are consideredstatic anal-\nysis activities, meaning that no software or \nmodels are executed. Instead, they examine \nsoftware engineering artifacts (also called \nintermediary or work products) concerning \nstandards established by the organization or \nproject for those artifacts.\n3.4.2.\t Dynamic Analysis Techniques\nDynamic analysis techniques involve exe-\ncuting or simulating the software code, looking \nfor errors and defects. Different dynamic \ntechniques are performed throughout soft-\nware development, maintenance, and opera-\ntion. Generally, these are testing techniques, \nbut simulation, model analysis and model \nchecking are considered dynamic analysis \ntechniques. (See the Software Engineering \nModels and Methods KA.) \u201cIn addition, black \nbox testing is considered a dynamic analysis \ntechnique, as the software engineer analyzes \nthe output received following the entry of \ninputs.\u201d (See the Software Testing KA.)\n3.4.3.\t Formal Analysis Techniques\n\b\n[7*, c10s10.5]\nFormal analysis techniques (also called formal \nmethods) are \u201cmathematical approaches to \nsoftware development where you define a \nformal model of the software. You may then \nformally analyze this model to search for \nerrors and inconsistencies\u201d [7*, c10s10.5]. \nSometimes, the software requirements may \nbe written using a more formal specification \nlanguage known as formal methods. They are \nnotably used to verify software requirements \nand designs. They have mostly been used to \nverify crucial parts of critical systems, such \nas specific security and safety requirements. \n(See also Formal Methods in the Software \nEngineering Models and Methods KA.) \nDifferent groups may perform testing during \nsoftware development, including groups \nindependent of the development team. The \nSoftware Testing KA is devoted entirely to \nthis subject.\n3.4.4.\t Software Quality Control and Testing  \n\b\n[1*, c7s7.10]\nTesting is considered an important product \nquality control activity part of a soft-\nware development project\u2019s V&V processes. \nQuality Control is \u201ca set of activities that \nmeasure, evaluate and report on the quality \nof software project artifacts throughout the \nproject life cycle\u201d [25]. Software testing is an \nimportant quality control activity to ensure \nsoftware quality. Software testing is one of \nmany verification activities that confirm that \nsoftware development output meets input \nrequirements. IEEE 730:2014 [6] lists the \nmany testing and retesting activities software \nengineers should plan, execute, and record. It \nalso recommends that testing completion cri-\nteria be set. Software engineers should plan \nthe testing activities, including levels, tech-\nniques, measures, and tools. Software quality \nengineering team, for critical systems, should \nparticularly be involved in qualifying software \nproducts prior to its delivery (i) either for fur-\nther integration or (ii) for operations in target \ncomputing environment; as an independent \ntest and evaluation activity, without involving \ndevelopment team members in the process. \n(Refer to the Testing KA for details about the \nknowledge software engineers should have \nabout software testing.)\n", "page": 260, "type": "text", "section": "Page 260"}
{"text": "12-14   SWEBOK \u00ae GUIDE V4.0\n3.4.5.\t Technical Reviews and Audits  \n\b\n[1*, c5, c6] [23, s4, s5]\nWe have seen SQC techniques for assessing \nthe quality of the software in section 2.4.1. \nFor the other artefacts, product quality con-\ntrol is assessed using reviews and inspections \nof these work products. These SQC activities \nare planned and executed during develop-\nment, maintenance, and operations activities \n[17]. Peer reviews are defined as \u201cthe review \nof work products performed by peers during \ndevelopment of the work products to identify \ndefects for removal\u201d [14]. For example, during \nsoftware development, a code review (often \ndone by using a pull request technique/tool) \noccurs when a peer reviews the code, often at \nthe software developer\u2019s request, before it can \nbe merged into a project. \nReviews are valuable because they can iden-\ntify issues early in development or even before \na component is designed. Fixing a defect in a \ncomponent that has been coded is much more \nexpensive than catching it beforehand. \nDifferent types of work product reviews (e.g., \nformal, and informal) are distinguished by pur-\npose, level of independence, tools and tech-\nniques used, roles involved, and by the subject \nof the activity. Reviews play important roles in \nsoftware quality, in SCM, and in the sharing \nof knowledge among colleagues. However, \nthese different roles share a single purpose \u2014 \nto ensure the quality of the delivered products. \nReviews should be part of the software engi-\nneering culture and should be planned, exe-\ncuted, and documented during the software life \ncycle. In Agile life cycles, pair programming \ninvites continuous reviews. Different review \ntypes for work products are described in the \nISO/IEC 20246:2017 Standard [12]: \n\u2022\t Ad hoc reviews \u2014 unstructured reviews \nwhere each reviewer is expected to find as \nmany defects as possible of any type; \n\u2022\t Checklist-based reviews \u2014 system-\natic reviews identifying issues based on \nchecklists; \n\u2022\t Scenario-based reviews \u2014 reviews where \nreviewers are provided with structured \nguidelines on how to read through the \nwork product under review; \n\u2022\t Perspective-based reviews \u2014 reviews \nwhere reviewers take on different stake-\nholder viewpoints and review the work \nproduct from that stakeholder\u2019s view-\npoint; and \n\u2022\t Role-based reviews \u2014 reviews in which \nthe reviewer evaluates the work product \nfrom the perspective of various stake-\nholder roles, which might differ from \ntheir daily role. \nAudits are more formal activities that are \noften mandated to be performed by third \nparties to ensure independence. In mature \norganizations, technical reviews and audits \nare fully integrated with the overall project \nplans. Therefore, technical reviews and audits \nshould be planned, approved, and conducted. \nAlthough a project audit often addresses the \nwhole project\u2019s current state, technical reviews \ncan also be more focused and address a spe-\ncific project phase [24]. System requirements \nreviews help ensure that the level of under-\nstanding of top-level system requirements is \nadequate to support further requirements anal-\nysis and design activities and that the system \ncan proceed into initial system design with \nacceptable risk; System functional or pre-\nliminary design reviews help ensure that the \nsystem under review can proceed into prelimi-\nnary or detailed design with acceptable risk and \nthat all system requirements and functional \nperformance requirements derived from the \napproved preliminary system specification are \ndefined and consistent with the project budget, \nprogram schedule, risk, and other program and \nsystem constraints; Preliminary design reviews \nhelp ensure that the preliminary design for \nthe system under review is sufficiently mature \nand ready to proceed into detailed design and \ncan meet the stated performance requirements \nwithin program budget, schedule, risk and \nother program and system constraints; Test \nreadiness reviews assess test objectives, test \nmethods and procedures, test scope, safety, \nreadiness for the project test and evaluation, \nand whether test resources have been properly \n", "page": 261, "type": "text", "section": "Page 261"}
{"text": "SOFTWARE QUALITY   12-15\nidentified and obtained; Production readi-\nness reviews ascertain that the system design \nis ready for production and that the project has \naccomplished adequate production planning \nfor entering production.\n4.\t Software Quality Tools  \n\b\n[1*, c3s3.2.3, c7s7.8.1, c7s7.11]\nSoftware tools improve software quality. \nSimple tools can be forms and checklists (e.g., \na requirements traceability matrix or a code \nreview checklist). But automated tools can also \nbe of great help to improve software efficiency \nand quality. Examples of automated tools are \ntools that allow code versioning/branching (e.g., \nGit) and pull requests for code review. DevOps \ntools in services/scripts like on-demand envi-\nronments, continuous integration/continuous \ndelivery (CI/CD), code quality assessment, and \nautomated testing are important contributors to \nsoftware quality. (See the Software Operations \nKA discussion about tools.) \nT\ufeffhese tools are known as static and dynamic \nanalysis tools. Static analysis tools input source \ncode, perform syntactical and semantic anal-\nysis without executing the code, and present \nresults to users. There is a large variety in the \ndepth, thoroughness and scope of static anal-\nysis tools that can be applied to artifacts, \nincluding models, and source code. (See the \nSoftware Construction, Software Testing, \nand Software Maintenance KAs for descrip-\ntions of dynamic analysis tools.) Categories of \nstatic analysis tools include the following: \n\u2022\t Tools that facilitate and partially auto-\nmate reviews and inspections of docu-\nments and code. These tools can route \nwork to different participants to partially \nautomate and control the review process. \nIn addition, they allow users to enter \ndefects found during inspections and \nreviews for later removal; \n\u2022\t Tools that help organizations perform \nsoftware safety hazard analysis. These \ntools provide, for example, automated sup-\nport for failure mode and effects analysis \n(FMEA) and fault tree analysis (FTA); \n\u2022\t Tools that support tracking of software \nproblems. These tools enable entry of \nanomalies discovered during software \ntesting and subsequent analysis, disposi-\ntion, and resolution. Some tools include \nsupport for workflow and for tracking \nproblem resolution status; and \n\u2022\t Tools that analyze data captured from \nsoftware engineering environments and \nsoftware test environments and pro-\nduce visual displays of quantified data \nin graphs, charts, and tables. These tools \nsometimes include the functionality to \nperform statistical analysis on data sets \n(to discern trends and make forecasts). \nSome of these tools provide defect injec-\ntion and removal rates, defect densities, \nyields, and distribution of defect injection \nand removal for each life cycle phase.\nMATRIX OF TOPICS VS. REFERENCE MATERIAL\nTopic\nLaporte and \nApril 2018 [1*]\nSommerville \n2016 [7*] \nIEEE Software \nCode of \nEthics [5*] \nWiegers \n2013 [13*]\n1. Software Quality Fundamentals\n \n \n1.1. Software Engineering Culture \nand Ethics\nCh. 1s1.6, Ch. 2s3\nX \n1.2. Value and Cost of Quality\nCh. 2s2.2\n \n", "page": 262, "type": "text", "section": "Page 262"}
{"text": "12-16   SWEBOK \u00ae GUIDE V4.0\n1.3. Standards, Models and \nCertifications\nCh. 4\nCh. 24s24.2\n \n1.4. Software Dependability and \nIntegrity Levels\nCh. 4s4.8\nCh. 7s7.2-7.3\nCh. 10\n \n2. Software Quality \nManagement Process\n \n \n2.1. Software Quality Improvement\nCh. 9s9.9 \n \n2.2. Plan Quality Management\n \n2.3. Evaluate Quality Management\nCh. 10\nCh. 24s24.5\n2.4. Perform Corrective and \nPreventive Actions\nCh. 1,s3\n \n3. Software Quality \nAssurance Process\n \n \n3.1. Prepare for Quality Assurance\nCh. 1s1.5, Ch. 4s4.6\n \nCh. 14\n3.2. Perform Process Assurance\nCh. 3s3.2-s3.3\nCh. 8, Ch. 9, \nCh. 4s4.6.1.3\nCh. 25\n \n3.3. Perform Product Assurance\nCh. 3s3.2-3.3\nCh. 7, Ch. 5, \nCh. 4s4.6.1.2\nCh. 4s4.1.2\n \n3.4. Verification & Validation  \nand Tests\nCh. 5, Ch. 6, Ch. 7\nCh. 10s10.5\n4. Software Quality Tools\nCh. 3s3.2.3, Ch. \n7s7.8.1, Ch. 7s7.11 \nX\nFURTHER READINGS\nIEEE 730-2014, \u201cIEEE Standard for Software \nQuality Assurance Processes,\u201d 2014 [6]. \nRequirements for initiating, planning, con-\ntrolling, and executing the Software Quality \nAssurance processes of a software develop-\nment or maintenance project are established \nin this standard. \nIEEE Std 1012-2016, \u201cIEEE Standard for \nSystem, Software, and Hardware Verification \nand Validation,\u201d 2016 [11].\nVerification and validation (V&V) pro-\ncesses are used to determine whether the \ndevelopment products of a given activity \nconform to that activity\u2019s requirements and \nwhether the product satisfies its intended \nuse and user needs. V&V life cycle process \nrequirements are specified for different integ-\nrity levels. \nISO/IEC Std 20246-2017, \u201cSoftware and \nSystems Engineering \u2014 Work Product \nReviews,\u201d 2017 [12]. \nThis international standard establishes a \ngeneric framework for work product reviews \nthat can be referenced and used by all orga-\nnizations involved in the management, devel-\nopment, testing and maintenance of systems \nand software. \n", "page": 263, "type": "text", "section": "Page 263"}
{"text": "SOFTWARE QUALITY   12-17\nN. Leveson, Safeware: System Safety and \nComputers [15]. \nThis book describes the importance of soft-\nware safety practices and how these practices \ncan be incorporated into software develop-\nment projects.\nT. Gilb and D. Graham, Software Inspection [16]. \nThis book introduces measurement and sta-\ntistical sampling for reviews and defects. It \npresents techniques that produce quanti-\nfied results for reducing defects, improving \nproductivity, tracking projects and creating \ndocumentation.\nK. E. Wiegers, Peer Reviews in Software: A \nPractical Guide [17*]. \nThis book provides clear, succinct expla-\nnations of different peer review methods \ndistinguished by level of formality and effec-\ntiveness. It provides pragmatic guidance for \nimplementing the methods and for deter-\nmining which methods are appropriate for \ngiven circumstances.\nREFERENCES\n[1*]\t C.Y. Laporte and A. April, Software \nQuality Assurance, IEEE Press, 2018.\n[2]\t P.B. Crosby, Quality Is Free, McGraw-\nHill, 1979.\n[3]\t W. Humphrey, Managing the Software \nProcess, Addison-Wesley, 1989.\n[4]\t ISO/IEC, \u201cISO/IEC 25010:2011 \nSystems and Software Engineering \n\u2014 Systems and Software Quality \nRequirements and Evaluation \n(SQuaRE) \u2014 Systems and Software \nQuality Models,\u201d ed., 2011.\n[5*]\t IEEE CS/ACM Joint Task Force on \nSoftware Engineering Ethics and \nProfessional Practices, \u201cSoftware \nEngineering Code of Ethics and \nProfessional Practice https://www \n.computer.org/education/code-of \n-ethics. \n[6]\t IEEE, \u201cIEEE 730 Standard for \nSoftware Quality Assurance \nProcesses,\u201d ed., IEEE, 2014.\n[7*]\t I. Sommerville, Software Engineering, \n10th ed., New York: Addison-\nWesley, 2016.\n[8]\t RTCA, \u201cDO-178C, Software \nConsiderations in Airborne Systems \nand Equipment Certification,\u201d ed.,  \n5 January 2012. Also known as \nED-12C in EUROCAE.\n[9]\t ISO/IEC, \u201cISO/IEC 15026-1:2019 \nSystems and Software Engineering \u2014 \nSystems and Software Assurance \u2014 \nPart 1: Concepts and Vocabulary,\u201d ed., \nISO/IEC, 2019.\n[10]\t \u201cISO 9001:2015 Quality Management \nSystems \u2014 Requirements,\u201d ed., \nISO, 2015.\n[11]\t IEEE, \u201cIEEE Std. 1012:2016, \nStandard for System and Software \nVerification and Validation,\u201d \nIEEE, 2016.\n[12]\t ISO/IEC 20246:2017, \u201cSoftware and \nsystems engineering \u2014 Work product \nreviews,\u201d ed., 2017.\n[13*]\tK.E. Wiegers, Software Requirements, \n3rd ed., Redmond, WA: Microsoft \nPress, 2013.\n[14]\t ISO/IEC/IEEE, \u201cISO/IEC/IEEE \n24765:2017 Systems and Software \nEngineering \u2014 Vocabulary,\u201d \n2nd ed. 2017.\n[15]\t N. Leveson, Safeware: System Safety \n", "page": 264, "type": "text", "section": "Page 264"}
{"text": "12-18   SWEBOK \u00ae GUIDE V4.0\nand Computers, Addison-Wesley \nProfessional, 1995.\n[16]\t T. Gilb and D. Graham, Software \nInspection, Addison-Wesley \nProfessional, 1993.\n[17*]\tK. Wiegers, Peer Reviews in Software: \nA Practical Guide, Addison-Wesley \nProfessional, 2001.\n[18]\t BS EN 50128:2011+A2:2020, \n\u201cStandard for Railway Applications \n\u2013 Communications, Signaling and \nProcessing Systems \u2013 Software for \nRailway Control and Protection \nSystems,\u201d British-Adopted European \nStandard, 10 August 2020.\n[19]\t K. Iberle, They don\u2019t care about quality, \nproceedings of STAR East, Orlando, \nUnited States, 2013, available at \nhttps://kiberle.com/publications/. \n[20]\t D. Wallace, L. M. Ippolito, and \nB.B. Cuthill, Reference Information \nfor the Software Verification and \nValidation Process, National Institute \nof Standards and Technology \n(NIST), U.D. Department of \nCommerce, Special Publication \n500-234, 1996.\n[21]\t IEC 60300-1:2014, \u201cDependability \nManagement \u2014 Part 1: Guidance for \nManagement and Application,\u201d version \n3, 25 September 2014.\n[22]\t D. Leffingwell, Safe 4.5 Reference \nGuide: Scaled Agile Framework For \nLean Enterprises, 2nd ed., New-York, \nAddison-Wesley, 2018.\n[23]\t ISO/IEC TS 33061:2021, \n\u201cInformation technology \u2014 Process \nassessment \u2014 Process Assessment \nModel for Software Life Cycle \nProcesses,\u201d 2021-04.\n[24]\t IEEE Std 15288.2:2014, \u201cIEEE \nStandard for Technical Reviews and \nAudits on Defense Programs.\u201d\n[25]\t A guide to the Project management \nBody of Knowledge, 7th edition, PMI, \n2021, 368p.\n[26]\t ISO/IEC/IEEE 90003:2018, \n\u201cGuidelines for the application of \nISO 9001:2015 to computer soft-\nware\u201d, 2018-11.\n[27]\t COBIT, \u201cControl Objectives for \nInformation Technology\u201d, version \n2019, ISACA and the IT Governance \nInstitute.\n[28]\t BABOK, \u201cA guide to the Business \nAnalysis Body of Knowledge\u201d, version \n3, International Institute of Business \nAnalysis, 04-2015.\n[29]\t CMMI, \u201cCapability Maturity Model \nIntegration\u201d, version 10, ISACA, 2023.\n[30]\t TOGAF, \u201cOpen Group Architecture \nFramework\u201d, version 10, 04-2022.\n[31]\t ISO/IEC 27001:2022, \u201cInformation \nsecurity, cybersecurity, and pri-\nvacy protection  Information \nsecurity \u2014management systems \u2014 \nRequirements\u201d, 10-2022.\n", "page": 265, "type": "text", "section": "Page 265"}
{"text": "13-1 \nCHAPTER 13\nSoftware Security\nACRONYMS\nCC\nCommon Criteria\nSDLC\nSecure Development Life Cycle\nINTRODUCTION\nSecurity has become a significant issue in soft-\nware development because of potential misuse \nand increasing malicious activity targeting \ncomputer systems. In addition to the usual \ncorrectness and reliability concerns, software \ndevelopers must pay attention to the security \nof the software they develop. Secure software \ndevelopment builds security by following \na set of established and/or recommended \nrules and practices. Secure software mainte-\nnance complements secure software develop-\nment by ensuring that no security problems \nare introduced during software maintenance \nand that identified vulnerabilities, which are \nerrors that attackers can exploit, can be han-\ndled during the software life cycle. Security \nvulnerabilities are not only introduced at the \ndevelopment, but also by third party compo-\nnents such as libraries, COTS, or OS.\nBREAKDOWN OF TOPICS FOR \nSOFTWARE SECURITY\nThe breakdown of topics for the Software \nSecurity knowledge area (KA) is shown in \nFigure 13.1.\n1.\t Software Security Fundamentals \b [37, 9]\nA generally accepted belief about software \nsecurity is that it is much better to design \nsecurity into software than to patch it in after \nthe software is developed. To design secu-\nrity into software, one must consider every \ndevelopment life cycle stage. Secure software \ndevelopment involves software requirements \nsecurity, software design security, software \nconstruction security and software testing \nsecurity. In addition, security must be consid-\nered during software maintenance, as secu-\nrity faults and loopholes can be and often are \nintroduced during maintenance.\n1.1.\t Software Security \b\n[10*]\nSecurity is a product quality characteristic \nrepresenting the degree to which a product or \nsystem protects information and data so that \npersons or other products or systems have data \naccess appropriate to their types and levels of \nauthorization [10]. (For more information \nabout product quality, refer to the Software \nQuality KA.)\n1.2.\t Information Security \b\n[11*]\nInformation security preserves confidenti-\nality, integrity and availability of informa-\ntion. Other properties, such as authenticity, \naccountability, non-repudiation and reliability \ncan also be involved [11]. Confidentiality is \nthe property of ensuring that information is \nnot disclosed to unauthorized individuals, \nentities or processes. Integrity is the property \nof accuracy and completeness. Availability \nis the property of being accessible and \nusable on demand by an authorized entity. \nSoftware engineers should define the secu-\nrity properties of their software and maintain \nthem throughout the software development \nlife cycle.\n", "page": 266, "type": "text", "section": "Page 266"}
{"text": "13-2   SWEBOK \u00ae GUIDE V4.0\n1.3.\t Cybersecurity \b\n[12*][38]\nCybersecurity is safeguarding of people, \nsociety, organizations and nations from cyber \nrisks. Safeguarding means to keep cyber risk \nat a tolerable level.\nGenerally, cybersecurity addresses secu-\nrity issues in cyberspace, including the \nfollowing:\n\u2022\t Social engineering attacks\n\u2022\t Hacking\n\u2022\t The proliferation of malicious soft-\nware (malware)\n\u2022\t Spyware\n\u2022\t Other potentially unwanted software [12]\nSoftware engineers should consider the \nmitigation of such threats as part of software \ndevelopment.\n2.\t Security Management and Organization \n\b\n[1*, c7][13]\nSecurity governance and management are \nmost effective when they are systematic; in \nother words, when they are woven into the \nculture and fabric of organizational behaviors \nand actions. Project managers need to elevate \nsoftware security from a stand-alone tech-\nnical concern to an enterprise issue [1].\n2.1.\t Capability Maturity Model  \n\b\n[3*, c22][14]\nMany organizations practice security engi-\nneering in the development of computer pro-\ngrams, including operating systems, functions \nthat manage and enforce security, packaged \nsoftware products, middleware, and applica-\ntions. Therefore, a diverse array of individuals \nmust know how to apply appropriate methods \nand practices, including product developers, \nservice providers, system integrators, system \nadministrators and even security specialists. \nSystems Security Engineering \u2014 Capability \nMaturity Model (SSE-CMM), which helps \nmeasure the process capability of an organi-\nzation that performs risk assessments [14], can \nbe an important tool.\n2.2.\t Information Security Management System  \n\b\n[15*]\nInternational Organization of Standardization/\nInternational Electrotechnical Commission \n(ISO/IEC) 27001:2022 specifies the require-\nments for establishing, implementing, main-\ntaining \nand \ncontinually \nimproving \nan \ninformation security management system \n(ISMS) within the organizational context \n[15]. ISMS is a documented plan for man-\naging the technology-related security of an \nSoftware Security\nSoftware Security\nFundamentals\nSoftware Security\nEngineering \nand Process\nSoftware \nEngineering for \nSoftware Systems\nDomain Speci\ufb01c\nSoftware Security\nSoftware Security\nInformation \nSecurity\nCybersecurity\nSecurity \nEngineering \nand Development\nLifecycle\nCommon Criteria \nfor Information \nTechnology \nSecurity Evaluation\nSecurity\nRequirements\nSecurity Design\nSecurity Patterns\nConstruction \nfor Security\nSecurity Testing\nVulnerability\nManagement\nSoftware Security\nTools\nSecurity \nVulnerability\nChecking Tools\nPenetration\nTesting Tools\nSecurity for\nContainer \nand Cloud\nSecurity for\nIoT Software\nSecurity for\nMachine \nLearning-Based\nApplication\nSecurity \nManagement and \nOrganization\nCapability \nMaturity Model\nInformation \nSecurity\nManagement \nSystem\nAgile Practice\nfor Software Security\nFigure 13.1. The Breakdown of Topics for the Software Security KA\n", "page": 267, "type": "text", "section": "Page 267"}
{"text": "SOFTWARE SECURITY   13-3\norganization. This includes documenting risks \nand taking measures to address them, aiming \nto protect the organization\u2019s data and prevent \nsecurity breaches [15]. Organization should \nuse it to continually conduct risk assess-\nments to identify security risks and vulnera-\nbilities and implement protective measures by \ndeploying an IT team to monitor these risks. \nAn ISMS can thus also raise new or changed \nexisting software security requirements. In \naddition,  software security requirements are \nderived from laws, regulations and obligations \nfor compliance.\n2.3.\t Agile Practice for Software Security  \n\b\n[4*,c15,c16]\nAgile teams need to understand and adopt \nsecurity practices and take more responsibility \nfor their systems\u2019 security. Security profes-\nsionals must learn to accept change, work faster \nand more iteratively, and think about security \nrisks and how to manage risks in incremental \nterms. Finally, and most important, secu-\nrity needs to become an enabler instead of a \nblocker. The keys to a successful Agile security \nprogram are the involvement of the security \nteam and developers, enablement, automation, \nand agility to keep up with Agile teams [4].\n3.\t Software Security Engineering and \nProcesses\n3.1.\t Security Engineering and Secure \nDevelopment Life Cycle (SDLC)  \n\b\n[1*, c1][16*][36]\nSoftware is only as secure as its development \nprocess. Security must be built into software \nengineering to ensure software security. The \nSDLC concept is one trend that aims to do \nthis. SDLC uses a classical spiral model that \nviews security holistically from the perspective \nof the software life cycle and ensures that secu-\nrity is inherent in software design and develop-\nment, not an afterthought later in production. \nThe SDLC process is claimed to reduce soft-\nware maintenance costs and increase software \nreliability against security-related faults.\nRecently, DevSecOps (meaning the integra-\ntion of development, security and operations) \nhas emerged. Beyond SDLC, DevSecOps \nincludes an approach to culture, automation \nand platform design to make the software life \ncycle as Agile and responsible as Agile devel-\nopment and continuous integration (CI).\n3.2.\t Common Criteria for Information \nTechnology Security Evaluation  \n\b\n[3*, c22, c25][34][35]\nSecurity evaluation establishes confidence in \nthe security functionality of IT products and \nthe assurance measures applied to them. The \nevaluation results may help consumers deter-\nmine whether IT products meet their secu-\nrity needs or standards conformity. ISO/\nIEC 15408:2022, named Common Criteria \n(CC) for Information Technology Security \nEvaluation, is useful as a guide for developing, \nevaluating and/or procuring IT products with \nsecurity functionality [34].\nCC addresses the protection of assets from \nunauthorized disclosure, modification or loss \nof use. The categories of protection relating \nto these three types of security failure are \ncommonly called confidentiality, integrity and \navailability, respectively.\n4.\t Security Engineering for Software \nSystems \b\n[1*,c1,c3][3*,c1,c3]\n4.1.\t Security Requirements  \n\b\n[1*,c3][2*,c2][3*,c20,c30][18]\nSecurity requirements engineering includes \nelicitation, specification, and prioritization.  It \nconsiders threats, as illustrated by misuse and \nabuse cases, threat actors, security risk assess-\nments, selection and application of speci-\nfication methods, prioritization methods, \ninspections, and revisions.  Selection of life-\ncycle models may impact the order of activities, \nand software product revision implies a need \nto revisit security requirements.  Traceability \nof security requirements throughout the \ndevelopment process is important, and secu-\nrity teams may include specialist in security \n", "page": 268, "type": "text", "section": "Page 268"}
{"text": "13-4   SWEBOK \u00ae GUIDE V4.0\nrequirements.  Numerous methods and tools \nexist in support of security requirements \nengineering.\n4.2.\t Security Design  \n\b\n[1*,c4][2*,c5][3*,c20,c31][17,40]\nSecurity design concerns how to prevent \nunauthorized disclosure, creation, change, \ndeletion or denial of access to informa-\ntion and other resources. It also concerns \nhow to tolerate security-related attacks or \nviolations by limiting damage, continuing \nservice, speeding repair and recovery, and \nfailing and recovering securely. Access con-\ntrol is a fundamental concept of security. \nMost controls build on cryptographic algo-\nrithms and cryptographic material like keys. \nIt is important to carefully select these and \nhow crypto material is created, distributed \nand managed.\nSoftware design security deals with the \ndesign of software modules that fit together \nto meet the security objectives specified in \nthe security requirements. To meet secu-\nrity requirements, developers conduct threat \nmodeling, illustrating how a system is being \nattacked to specify a security design for the \nmitigation. This step clarifies the details of \nsecurity considerations and develops the spe-\ncific steps for implementation. Factors con-\nsidered may include frameworks and access \nmodes that set up the overall security mon-\nitoring/enforcement strategies, as well as the \nindividual policy enforcement mechanisms.\n4.3.\t Security Patterns \b\n[1*,c4][19, 20, 21]\nA security pattern describes a particular recur-\nring security problem that arises in a specific \ncontext and presents a well-proven generic \nsolution [21].\n4.4.\t Construction for Security  \n\b\n[1*,c5][3*,c20,c31][22, 23, 24]\nSoftware construction security concerns how \nto write programming code for specific sit-\nuations to address security considerations. \nThe term software construction security can \nmean different things to different people. It \ncan mean the way a specific function is coded \nso that the code itself is secure, or it can \nmean the coding of security into software. \nUnfortunately, most people entangle the two \nmeanings without distinction. One reason \nfor such confusion is that it is unclear how to \nensure a specific coding is secure. For example, \nin the C programming language, the expres-\nsions \u201ci<<1\u201d (shift the binary representation of \ni\u2019s value to the left by one bit) and \u201c2*\u201d (mul-\ntiply the value of variable i by constant 2) mean \nthe same thing semantically, but do they have \nthe same security ramifications?\nThe answer could be different for different \ncombinations of ISAs and compilers. Because \nof this lack of understanding, software con-\nstruction security \u2014 in its current state \u2014 \nmostly refers to the second aspect mentioned \nabove: the coding of security into software. \nCoding of security into the software can be \nachieved by following recommended rules. A \nfew such rules follow:\n\u2022\t Structure the process so that all sec-\ntions requiring extra privileges are mod-\nules. The modules should be as small as \npossible and perform only the tasks that \nrequire those privileges.\n\u2022\t Ensure that any assumptions in the pro-\ngram are validated. If this is not possible, \ndocument them for the installers and \nmaintainers so they know the assump-\ntions attackers will try to invalidate.\n\u2022\t Ensure that the program does not \nshare objects in memory with any \nother program.\n\u2022\t Check every function\u2019s error status. Do \nnot recover unless neither the error\u2019s \ncause nor its effects affect any secu-\nrity considerations. The program should \nrestore the state of the software to the \nstate it had before the process began and \nthen terminate.\nAlthough there are no bulletproof ways to \nachieve secure software development, some \ngeneral guidelines exist that can be helpful. \n", "page": 269, "type": "text", "section": "Page 269"}
{"text": "SOFTWARE SECURITY   13-5\nThese guidelines span every phase of the soft-\nware development life cycle. The Computer \nEmergency Response Team (CERT) pub-\nlishes reputable guidelines, and the following \nare its top 10 software security practices (the \ndetails can be found in [22]):\n1.\t  Validate input.\n2.\t  Heed compiler warnings.\n3.\t  Architect and design for security policies.\n4.\t  Keep it simple.\n5.\t\n Default deny.\n6.\t Adhere to the principle of least privilege.\n7.\t\nSanitize data sent to other software.\n8.\t Practice defense in depth.\n9.\t\nUse effective quality assurance techniques.\n10.\t Adopt a software construction secu-\nrity standard.\n4.5.\t Security Testing  \n\b\n[1*,c5][2*,c7][3*,c24,c31][26, 27]\nSecurity testing ensures that the implemented \nsoftware meets the security requirements. It \nalso verifies that the software implementation \ncontains none of the known vulnerabilities. \nWhereas general software testing methods \ncan handle the former, the latter requires \nsecurity-specific testing methods. (For more \ninformation about testing, please refer to the \nSoftware Testing KA.) \nThere are two general approaches to \nsecurity-specific testing. The first approach \nincludes detecting vulnerabilities through \nstatic analysis, which can be conducted on \nthe source code or compiled binaries. A static \nanalysis on the source code can be used to \ndetect programming language or implemen-\ntation-specific vulnerabilities, while static \nanalysis on compiled binaries can be used to \ndetect vulnerabilities that are not apparent \nin the source code due to compiler optimi-\nzations or hidden in the compiled third-\nparty components. Static analysis can be \nautomated using tools, however while auto-\nmation can play a significant role, the exper-\ntise of security professionals are required to \nproperly operate and configure the tools, and \nverify the results.\nThe other approach to detect vulnera-\nbilities is through dynamic testing, typi-\ncally using techniques such as vulnerability \nassessment or penetration testing (also \nknown as the ethical hacking test), to detect \nvulnerabilities in software behavior. Like \nstatic analysis, there are tools that can auto-\nmate dynamic testing, such as web appli-\ncation scanners and fuzzing tools. Security \nexperts skilled in the application domain \nshould be engaged to perform these tests, \nand such tests should always be conducted \nwithin legal boundaries and with proper \nauthorization. The latter aspects are cru-\ncial to differentiate such tests from illegal \nhacking activities.\n4.6.\t Vulnerability Management  \n\b\n[1*,c5][3*,c24][28,29, 30]\nUsing sound coding practices can help sub-\nstantially reduce software defects commonly \nintroduced during implementation [1]. Such \ncommon security defects are categorized \nand shared with databases: the Common \nVulnerabilities and Exposures (CVE) [28], \nCommon Weakness Enumeration (CWE) [29], \nand Common Attack Pattern Enumeration \nand Classification (CAPEC) [30]; Common \nVulnerability Scoring System (CVSS) [41] \nexpresses characteristics and severity of soft-\nware vulnerabilities. Programmers can refer to \nthese databases for security implementation, \nand some tools are available to check common \nvulnerabilities in codes. Security maintenance \nencompasses the task to mitigate effects of vul-\nnerabilities in a system and third party com-\nponents which the system uses. The task often \ncomes with a vulnerability disclosure pro-\ncess that allows to report the identification of \nvulnerabilities.\n5.\t Software Security Tools\n5.1.\t Security Vulnerability Checking Tools \n\b\n[1*,c6][25]\nSecurity vulnerability checking tools, such \nas source code analyzers and binary analysis \n", "page": 270, "type": "text", "section": "Page 270"}
{"text": "13-6   SWEBOK \u00ae GUIDE V4.0\ntools, can be used to identify potential secu-\nrity vulnerabilities and issues. Source code \nanalyzers scrutinize code to detect secu-\nrity vulnerabilities, such as injection flaws, \nbuffer overflows, and insecure library use. \nThey are useful at finding vulnerabilities \nthat can be identified through code pat-\nterns and logical flaws. Binary analysis \ntools, on the other hand, examine compiled \ncode, including third-party libraries, for \nvulnerabilities that might not be apparent \nin the source code or that arise from the \ncompilation process. While these tools sig-\nnificantly aid in detecting vulnerabilities, \nthey cannot find all vulnerabilities. For \nexample, they might not capture vulner-\nabilities that manifest in hard-to-produce \nsoftware states or that crop up in unusual \ncircumstances [1].\n5.2.\t Penetration Testing Tools \b\n[2*,c4]\nPenetration testing tools can be used to eval-\nuate a system\u2019s security in its operational \nenvironment. These tools perform controlled \nattacks on the system to uncover vulnerabili-\nties and security weaknesses, using techniques \nsuch as fuzzing [2], where malformed, mali-\ncious, or random data is submitted to the sys-\ntem\u2019s various entry points to detect faults. The \nuse of penetration testing tools to expose vul-\nnerabilities provide insights into how an actual \nattacker could exploit the system.\n6.\t Domain-Specific Software Security\n6.1.\t Security for Container and Cloud \b\n[31]\nCloud infrastructure and services are often \ninexpensive and easy to provision, which can \nquickly lead to having many assets strewn all \nover the world and forgotten. These forgotten \nassets are like a ticking time bomb, waiting to \nexplode into a security incident [31].\nOne important difference with cloud envi-\nronments is that physical assets and protection \nare generally not a concern. Developers can \ngleefully outsource asset tags, anti-tailgating, \nslab-to-slab barriers, placement of data center \nwindows, cameras, and other physical secu-\nrity and physical asset tracking controls [31].\n6.2.\t Security for IoT Software \b\n[32,33]\nAs part of today\u2019s IoT (internet of things), \nsystems are interconnected with many \nother devices, especially back-end systems \nsuffering from all the well-known secu-\nrity flaws inherent in today\u2019s business IT. \nAttackers gaining access to business IT plat-\nforms, for instance, by exploiting browser \nvulnerabilities, will likely also gain access \nto weakly protected IoT industrial devices. \nThis can cause severe damage, including \nsafety incidents. Hence, the introduction \nof a massive number of end points from the \nconsumer or industrial environment cre-\nates fertile ground for the exploitation of \nweak links. Hardening these end points, \nsecuring device-to-device communications, \nand ensuring device and information cred-\nibility in what until now have been closed, \nhomogeneous systems present new chal-\nlenges. Comprehensive risk and threat anal-\nysis methods, as well as management tools for \nIoT platforms, are required [33].\n6.3.\t Security for Machine Learning-Based \nApplication \b\n[39,c8]\nAlthough machine learning techniques are \nwidely used in many systems, machine learning \npresents a specific vulnerability. Attackers \ncan change the decisions of machine learning \nmodels. There are two kinds of attacks: model \npoisoning, which attacks training data, and \nevasion, which attacks inputs to trained \nmodels [39].\n", "page": 271, "type": "text", "section": "Page 271"}
{"text": "SOFTWARE SECURITY   13-7\nMATRIX OF TOPICS VS. REFERENCE MATERIAL\nTopic\n Allen et \nal. 2008 [1*]\nMcGraw \n2006 [2*] \nBishop  \n2019 [3*]\nBell  \n2017 [4*]\n1. Software Security Fundamentals\n \n \n \n1.1. Software Security\n \n \n1.2. Information Security\n \n \n1.3. Cybersecurity\n Ch. 23\n \n2. Security Management and \nOrganization\nCh. 7\n \n \n2.1. Capability Maturity Model\nCh. 22\n2.2. Information Security \nManagement System\n2.3. Agile Practice for Software Security\nCh. 15,  \nCh. 16\n3. Software Security Engineering \nand Processes\nCh. 9\n3.1. Security Engineering and Secure \nDevelopment Life Cycle \nCh. 1\nCh. 4\n3.2. Common Criteria for Information \nTechnology Security Evaluation\nCh. 22,  \nCh. 25\n4. Security Engineering for \nSoftware Systems\nCh. 1, Ch. 15, \nCh. 1, Ch. 3\n4.1. Security Requirements\nCh. 3\nCh. 2\nCh. 20,  \nCh. 31\nCh. 5,  \nCh. 8\n4.2. Security Design\nCh. 4\nCh. 5\nCh. 20,  \nCh. 31\nCh. 8\n4.3. Security Patterns\nCh. 4\n4.4. Construction for Security\nCh. 5\nCh. 20,  \nCh. 31\n\u200b\n4.5. Security Testing\nCh. 5\nCh. 24,  \nCh. 31\nCh. 10,  \nCh. 11\n4.6. Vulnerability Management\nCh. 24\n\u200b\nCh. 6\n5. Software Security Tools\n5.1. Security Vulnerability Checking Tools\nCh. 6\nCh. 6\n5.2. Penetration Testing Tools\nCh. 4\nCh. 31\nCh. 11,  \nCh. 12\n6. Domain-Specific \nSoftware Security\n6.1. Security for Container and Cloud\n6.2. Security for IoT Software\n6.3. Security for Machine Learning-Based \nApplication\n", "page": 272, "type": "text", "section": "Page 272"}
{"text": "13-8   SWEBOK \u00ae GUIDE V4.0\nFURTHER READINGS\nJ. Viega, Building Secure Software: How \nto Avoid Security Problems the Right Way, \nAddison-Wesley, 2011.\nThis book introduces the definition of \nSoftware Security and the activities to develop \nand maintain secure software. It includes not \nonly the software development process but \nalso the related activities such as auditing and \nthe monitoring of service.\nL. Kohnfelder, Designing Secure Software: A \nGuide for Developers, No Starch Press, 2021.\nThis book describes security activities in the \nsoftware design and implementation phases, \nincluding secure programming and web secu-\nrity. It also introduces best practices for secure \nsoftware development.\nC.W. \nAxelrod, \nEngineering \nSafe \nand \nSecure Software Systems, \nArtech \nHouse \nPublishers, 2012.\nThis book describes engineering activities to \nmake software systems safe and secure from a \nrisk management viewpoint. It introduces risk \nassessment and mitigation methods for secu-\nrity and safety.\nREFERENCES\n[1*]\t J.H. Allen, S.J. Barnum, R.J. Ellison, \nG. McGraw, and N.R. Mead, Software \nSecurity Engineering: A Guide for \nProject Managers, Addison-Wesley \nProfessional, 2008.\n[2*]\t G. McGraw, Software Security: \nBuilding Security In, Addison-Wesley \nProfessional, 2006.\n[3*]\t M. Bishop, Computer Security, \n2nd Edition, Addison-Wesley \nProfessional, 2019.\n[4*]\t L. Bell, M. Brunton-Spall, R. Smith, \nand J. Bird, Agile Application Security, \nO\u2019Reilly, 2017.\n[5]\t\nT. Hsiang-Chih Hsu, Hands-On \nSecurity in DevOps: Ensure continuous \nsecurity, deployment, and delivery with \nDevSecOps, Packt Publishing, 2018.\n[6]\t\nT. Hsiang-Chih Hsu, Practical Security \nAutomation and Testing: Tools and \ntechniques for automated security scan-\nning and testing in DevSecOps, Packt \nPublishing, 2019.\n[7]\t\nG. Wilson, DevSecOps: A leader\u2019s guide \nto producing secure software without com-\npromising flow, feedback and continuous \nimprovement, Rethink Press, 2020.\n[8]\t\nL. Rice, Container Security: \nFundamental Technology Concepts That \nProtect Containerized Applications, \nO\u2019Reilly & Associates Inc., 2020.\n[9]\t\nISO/IEC/JTC1 SC27 Standards: \nTrustworthiness, Cryptography, Data \nsecurity, Cryptography, Security eval-\nuation and testing, Security control, \nIdentity management and privacy \ntechnologies.\n[10*]\tISO/IEC 25010:2023 Systems and \nsoftware engineering \u2014 Systems and \nsoftware Quality Requirements and \nEvaluation (SQuaRE) \u2014 Product \nquality model.\n[11*]\tISO/IEC 27000:2018 Information \ntechnology \u2014 Security techniques \u2014 \nInformation security management sys-\ntems \u2014 Overview and vocabulary.\n[12*]\tISO/IEC 27032:2012 Information \ntechnology \u2014 Security techniques \u2014 \nGuidelines for cybersecurity.\n[13]\t ISO/IEC 19770-1:2017 Information \ntechnology \u2014 IT asset management \n", "page": 273, "type": "text", "section": "Page 273"}
{"text": "SOFTWARE SECURITY   13-9\n\u2014 Part 1: IT asset management sys-\ntems \u2014 Requirements.\n[14]\t ISO/IEC 21827:2008 Information \ntechnology \u2014 Security techniques \n\u2014 Systems Security Engineering \n\u2014 Capability Maturity Model \n(SSE-CMM).\n[15*]\tISO/IEC 27001:2022 Information \nSecurity, Cybersecurity And Privacy \nProtection \u2014 Information Security \nManagement Systems \u2014 Requirements.\n[16]\t M. Howard and S. Lipner, The Security \nDevelopment Lifecycle, Microsoft \nPress, 2006.\n[17]\t F. Swiderski and W. Snyder, Threat \nModeling: Design for Security, Wiley, 2014.\n[18]\t D. Firesmith, \u201cSecurity use cases,\u201d \nJournal of Object Technology, Vol. 2, No. \n1, pp. 53-64, 2003.\n[19]\t E. Fernandez-Buglioni, Security Patterns \nin Practice: Designing Secure Architectures \nUsing Software Patterns, Wiley, 2013.\n[20]\t C. Nagappan, R. Lai, and R. Steel, \nCore Security Patterns: Best Practices \nand Strategies for J2EE, Web Services, \nand Identity Management, Prentice \nHall, 2005.\n[21]\t M. Schumacher, E. Fernandez-\nBuglioni, D. Hybertson, F. \nBuschmann, and P. Sommerlad, \nSecurity Patterns: Integrating Security \nand Systems Engineering, Wiley, 2006.\n[22]\t R.C. Seacord, The CERT C Secure \nCoding Standard, Addison-Wesley \nProfessional, 2008.\n[23]\t R.C. Seacord, Secure Coding in C and \nC++, Addison-Wesley Professional, 2013.\n[24]\t D. Long, F. Mohindra, D. Seacord, \nR.C. Sutherland, and D.F. Svoboda, \nThe CERT Oracle Secure Coding \nStandard for Java, 2011.\n[25]\t J. Erickson, Hacking: The Art of \nExploitation, 2nd Edition, No Starch \nPress, 2008.\n[26]\t K. Scarfone, M. Souppaya, A. Cody, \nand A. Orebaugh, Technical Guide \nto Information Security Testing and \nAssessment, NIST SP800-115, 2008.\n[27]\t PCI Security Standards Council, PCI \nDSS: Payment Card Industry Data \nSecurity Standard, Version 3.2, 2017.\n[28]\t MITRE, \u201cCommon Vulnerabilities and \nExposures (CVE),\u201d https://cve.mitre.org/.\n[29] MITRE, \u201cCommon Weakness \nEnumeration (CWE),\u201d https://cwe.\nmitre.org/.\n[30]\t MITRE, \u201cCommon Attack Pattern \nEnumeration and Classification \n(CAPEC),\u201d https://capec.mitre.org/.\n[31]\t C. Dotson, Practical Cloud Security, \nO\u2019Reilly, 2019.\n[32]\t \u201cInternet of Things Security Best \nPractices,\u201d IEEE, 2017, https://\ninternetinitiative.ieee.org/resources/\nreports-presentations-publications.\n[33]\t \u201cIoT 2020: Smart and secure IoT plat-\nform,\u201d IEC, 2016, https://www.iec.ch \n/basecamp/iot-2020-smart-and-secure \n-iot-platform.\n[34]\t ISO/IEC 15408-1:2022 Information \nsecurity, cybersecurity and privacy pro-\ntection \u2014 Evaluation criteria for IT \nsecurity \u2014 Part 1: Introduction and \ngeneral model.\n[35]\t ISO/IEC 18045:2008 Information \ntechnology \u2014 Security techniques \n", "page": 274, "type": "text", "section": "Page 274"}
{"text": "13-10   SWEBOK \u00ae GUIDE V4.0\n\u2014 Methodology for IT security \nevaluation.\n[36]\t DoD Enterprise DevSecOps, https://\nsoftware.af.mil/dsop/documents/.\n[37]\t C. Easttom, Computer Security \nFundamentals, 4th Edition, Pearson IT \nCertification, 2019.\n[38]\t Y. Diogenes and E. Ozkaya, \nCybersecurity \u2014 Attack and Defense \nStrategies, Second Edition, Packt \nPublishing, 2019.\n[39]\t C. Chio and D. Freeman, Machine \nLearning and Security: Protecting \nSystems with Data and Algorithms, \nO\u2019Reilly, 2018.\n[40]\t I. Sommerville, Software Engineering, \n10th ed., Addison-Wesley, 2016.\n[41]\t FIRST, CVSS v4.0 Specification \nDocument, https://www.first.org/cvss \n/specification-document.\n", "page": 275, "type": "text", "section": "Page 275"}
{"text": "14-1 \nCHAPTER 14\nSoftware Engineering \nProfessional Practice\nACRONYMS\nACM\nAssociation for Computing \nMachinery\nCCPA\nThe California Consumer \nPrivacy Act\nEEA\nEuropean Economic Area\nENAEE\nEuropean Network \nfor Accreditation of \nEngineering Education\nEU\nEuropean Union\nGDPR\nThe General Data Protection \nRegulation\nIEA\nInternational \nEngineering Alliance\nIEC\nInternational Electrotechnical \nCommission\nIEEE CS\nIEEE Computer Society\nIFIP\nInternational Federation for \nInformation Processing\nIP\nIntellectual Property\nISO\nInternational Organization for \nStandardization\nNDA\nNondisclosure Agreement\nUI/UX\nUser Interface/User Experience\nWIPO\nWorld Intellectual Property \nOrganization\nWTO\nWorld Trade Organization\nINTRODUCTION\nThe \nSoftware \nEngineering \nProfessional \nPractice knowledge area (KA) is concerned \nwith the knowledge, skills, and attitudes soft-\nware engineers must possess to practice soft-\nware engineering in a professional, responsible \nand ethical manner. Because of the widespread \napplications of software products in social \nand personal life, software product quality \ncan profoundly affect personal well-being and \nsocietal harmony. Software engineers must \nhandle unique engineering problems to pro-\nduce software with known characteristics and \nreliability. This requirement calls for software \nengineers who possess the proper knowledge, \nskills, training, and experience in professional \npractice. \nProfessional practice refers to a way of con-\nducting services to achieve certain standards or \ncriteria in both the process of performing a ser-\nvice and the end product resulting from the ser-\nvice. These standards and criteria can include \nboth technical and non-technical aspects. \nThe concept of professional practice is espe-\ncially applicable to professions with a generally \naccepted body of knowledge; code of ethics and \nprofessional conduct with penalties for viola-\ntions; accepted processes for accreditation, cer-\ntification, qualification, and licensing; and \nprofessional societies to provide and administer \nall these. Admission to these professional soci-\neties is often predicated on a prescribed combi-\nnation of education and experience.\nA software engineer maintains professional \npractice by performing all work following \ngenerally accepted practices, standards, and \nguidelines set forth by the applicable pro-\nfessional society, such as the Association for \nComputing Machinery (ACM), Institute for \nElectrical and Electronics Engineers (IEEE), \nor International Federation for Information \nProcessing (IFIP), IEEE Computer Society \n(IEEE CS), International Organization for \nStandardization/International Electrotechnical \nCommission (ISO/IEC), and ISO/IEC/\nIEEE provide internationally accepted soft-\nware engineering standards. All of these \n", "page": 276, "type": "text", "section": "Page 276"}
{"text": "14-2   SWEBOK \u00ae GUIDE V4.0\nstandards and guidelines comprise the foun-\ndation of the professional practice of software \nengineering. \nBREAKDOWN OF TOPICS FOR \nSOFTWARE ENGINEERING \nPROFESSIONAL PRACTICE\nThe \nSoftware \nEngineering \nProfessional \nPractice KA\u2019s breakdown of topics is shown \nin Figure 14.1.\nThe subareas presented in this KA are pro-\nfessionalism, group dynamics and psychology, \nand communication skills.\n1.\t Professionalism\nA software engineer displays professionalism \nnotably by adhering to a code of ethics and \nprofessional conduct and to standards and \npractices established by the engineer\u2019s profes-\nsional community.\nOne or more professional societies often \nrepresent a professional community, and this \nis the case for the engineering community. \nThose societies publish codes of ethics and \nprofessional conduct as well as criteria for \nadmittance to the community. Those criteria \nform the basis for accreditation and licensing \nactivities and may determine engineering \ncompetence or negligence.\nAs software is used more widely and deeply \nin society, stakeholders\u2019 requirements have \nlikewise become wider and deeper. And as \nsoftware has become socially vital, software \nengineers have worked to base the user inter-\nface/user experience (UI/UX) on socially \ninclusive concepts. \n1.1.\t Accreditation,\u2008Certification and \nQualification,\u2008and\u2008Licensing  \n\b\n[1*, cls4-s5, cls10] [2] [4*, c12s10] \n \n\b\n[6] [7] [8] [9] \n1.1.1. Accreditation\u2008\nAccreditation certifies an organization\u2019s com-\npetency, authority, or credibility. Accredited \nschools or programs have shown that they \nadhere to particular standards and maintain \ncertain qualities. In many countries, the basic \nmeans by which engineers acquire knowledge \nis by completing an accredited course of study. \nOften, the accreditation process is indepen-\ndent of the government and is performed by \nSoftware Engineering\nProfessional Practice\nProfessionalism\nGroup Dynamics \nand Psychology\nCommunication \nSkills\nAccreditation Certi\ufb01cation and\nQuali\ufb01cation, and Licensing\nCode of Ethics and Professional \nConduct\nNature and Role of Professional \nSocieties\nNature and Role of Software \nEngineering Standards\nEconomic Impact of Software\nEmployment Contracts\nLegal Issues\nDocumentation\nTrade-o\ufb00 Analysis\nDynamics of Working in \nTeams/Groups\nIndividual Cognition\nDealing with Problem Complexity\nInteracting with Stakeholders\nDealing with Uncertainty and \nAmbiguity\nDealing with Equity, Diversity\nand Inclusivity\nReading, Understanding, \nand Summarizing\nWriting\nTeam and Group\nCommunication\nPresentation Skills\nFigure 14.1. Breakdown of Topics for the Software Engineering Professional Practice KA\n", "page": 277, "type": "text", "section": "Page 277"}
{"text": "SOFTWARE ENGINEERING PROFESSIONAL PRACTICE   14-3\nprivate membership associations. There are \ntwo major global accreditation organizations. \nOne is the International Engineering Alliance \n(IEA), of which the Washington Accord \nis a constituent. The other is the European \nNetwork for Accreditation of Engineering \nEducation (ENAEE), which administers \nEUR-ACE\u00ae, the label awarded to engineering \ndegree programs at the bachelor\u2019s and master\u2019s \nlevels, listed by the European Commission. \nAlthough the accreditation process might \ndiffer for each country and jurisdiction, the gen-\neral meaning is the same. Accreditation of an \ninstitution\u2019s course of study means \u201cthe accred-\nitation body recognizes an educational institu-\ntion as maintaining standards that qualify the \ngraduates for admission to higher or more spe-\ncialized institutions or professional practice.\u201d \n1.1.2. Certification and Qualification\nISO/IEC 24773-1 Software and Systems \nEngineering \u2014 Certification of Software and \nSystems Engineering Professionals \u2014 Part \n1: General Requirements define certification \nand qualification [8] defines certification and \nqualification. ISO/IEC 24773-4 Software \nand Systems Engineering \u2014 Certification \nof Software and Systems Engineering \nProfessionals \u2014 Part 4: Software engineering \n[9] elaborates requirements and recommen-\ndations for certification schemes based on \nISO/IEC 24773-1, which are specific to the \ndomain of software engineering. Certification \ncontains recertification. Qualification is sim-\nilar to certification but does not require \nre-qualification. Certification refers to the \nconfirmation of a person\u2019s particular char-\nacteristics. A common type of certification \nis professional certification, which certifies a \nperson as being able to complete an activity in \na certain discipline at a stated level of compe-\ntency. Professional certification can verify the \nholder\u2019s ability to meet professional standards \nand to apply professional judgment in solving \nor addressing problems. Professional certifi-\ncation can also verify prescribed knowledge, \nmastery of best practices and proven method-\nologies, and professional experience. \nAn engineer usually obtains certifica-\ntion by passing an examination in addition \nto meeting other experience-based criteria. \nNongovernmental organizations, such as pro-\nfessional societies, often administer these \nexaminations. In software engineering, certi-\nfication testifies to one\u2019s capability as a soft-\nware engineer. \nThe qualification and certification programs \nare designed to confirm a software\u00a0engineer\u2019s \nknowledge of standard software engineering \npractices and to advance the engineer\u2019s career. \nA lack of qualification or\u00a0 certification does \nnot exclude the individual\u00a0 from working as \na software engineer.\u00a0Qualification or certifi-\ncation in software\u00a0 engineering is voluntary. \nMost software engineers are not qualified or \ncertified under any program\n1.1.3. Licensing\nLicensing authorizes a person to perform cer-\ntain activities and take responsibility for \nresultant engineering products. The noun \nlicense refers to both that authorization and \nthe document recording that authorization. \nGovernmental authorities or statutory bodies \nusually issue licenses.\nObtaining a license to practice requires an \nindividual to meet a certain standard at a cer-\ntain ability to practice or operate. Sometimes an \nentry-level requirement sets the minimum skills \nand capabilities to practice, and as the profes-\nsional moves through their career, the required \nskills and capabilities change and evolve.\nEngineers are licensed to protect the public \nfrom unqualified individuals. In some coun-\ntries, no one can practice as a professional \nengineer unless licensed; further, no company \nmay offer \u201cengineering services\u201d unless at \nleast one licensed engineer is employed there. \n1.2. \tCodes\u2008of\u2008Ethics\u2008and\u2008Professional\u2008Conduct \n\b [1*, cls7-cls9, c10s2, Appendix] [3*, c8] \n \n\b\n[4*, cls2] [5*, c33][10] [11] [13*] \nCodes of ethics and professional conduct \ndescribe the values and behavior that an \nengineer\u2019s professional practice and decisions \n", "page": 278, "type": "text", "section": "Page 278"}
{"text": "14-4   SWEBOK \u00ae GUIDE V4.0\nshould embody. The professional community \nestablishes a code of ethics and professional \nconduct. This code exists in the context of \nsocietal norms and local laws and is adjusted \nto agree with those norms and laws as needed. \nA code of ethics and professional conduct \ncan offer guidance in the face of conflicting \nimperatives. More than one such code serves \nthe professional engineering community. \nFor example, in 1999, IEEE CS and ACM \nlaunched a joint Software Engineering \nEthics and Professional Practices Task \nForce to publish a code of ethics. In 2018, \nACM published its ACM Code of Ethics \nand Professional Conduct, and in 2020, \nIEEE published a revision of its Code of \nEthics which was originally approved in \n1912. Then, in 2021, IFIP published its \nCode of Ethics and Professional Conduct, \nadapted from ACM\u2019s Code of Ethics and \nProfessional Conduct. \nOnce established, codes of ethics and pro-\nfessional conduct are enforced by the profes-\nsion, as represented by professional societies \nor by a statutory body. Violations may be acts \nof commission, such as concealing inadequate \nwork, disclosing confidential information, \nfalsifying information, or misrepresenting \nabilities. They may also occur through omis-\nsion, including failure to disclose risks or pro-\nvide important information, failure to give \nproper credit or acknowledge references, and \nfailure to represent client interests. Violations \nof a code of ethics and professional conduct \nmay result in penalties and possible expulsion \nfrom professional status. \nSoftware engineers shall commit them-\nselves to making the analysis, specification, \ndesign, development, testing, and mainte-\nnance of software a beneficial and respected \nprofession. Following their commitment to \nthe health, safety, and welfare of the public, \nsoftware engineers shall adhere to the ten \nprinciples according to IEEE Code of Ethics \nadopted by the IEEE Board of Directions, \nJune 2020. \nSince the code of ethics and professional \nconduct may be introduced, modified, or \nreplaced at any time, individual software \nengineers are responsible for continuing their \nstudies to stay current in their professional \npractice. \n1.3.\t Nature\u2008and\u2008Role\u2008of\u2008Professional\u2008Societies  \n\b\n[1*, c2s3] [4*, c1s2] [5*, c35s1]\nProfessional societies comprise a mix of \npractitioners and academics. These societies \ndefine, advance, and regulate their corre-\nsponding professions. Professional societies \nhelp establish professional standards as well \nas codes of ethics and professional conduct. \nThey also engage in related activities, which \ninclude the following:\n\u2022\t Establishing and promulgating a body of \ngenerally accepted knowledge\n\u2022\t Providing the basis for licensing, certi-\nfying, and accrediting \n\u2022\t Dispensing disciplinary actions\n\u2022\t Advancing the profession through confer-\nences, training, publications, and standards\nParticipation in professional societies \nassists individual engineers in maintaining \nand sharpening their professional knowledge \nand relevancy and in expanding and main-\ntaining their professional network.\n1.4.\t Nature and Role of Software Engineering \nStandards  \n\b\n[1*, c10s2] [2] [4*] [5*, c32s6]\nSoftware engineering standards cover a \nremarkable variety of topics. They provide \nguidelines for the practice of software engi-\nneering and for processes to be used during \nthe development, maintenance, and sup-\nport of software. By establishing a common \nbody of knowledge and experience, soft-\nware engineering standards establish a basis \non which further guidelines may be devel-\noped. Appendix B of this Guide presents \nIEEE, ISO/IEC, and ISO/IEC/IEEE soft-\nware engineering standards that support this \nGuide\u2019s KAs. \nStandards are valuable sources of infor-\nmation \nabout \nrequirements \nand \nother \n", "page": 279, "type": "text", "section": "Page 279"}
{"text": "SOFTWARE ENGINEERING PROFESSIONAL PRACTICE   14-5\nguidance that can support software engi-\nneers in everyday activities. Adherence to \nstandards promotes discipline by enumer-\nating minimal characteristics of products and \npractices. That discipline helps mitigate sub-\nconscious assumptions or overconfidence in a \ndesign. For these reasons, organizations per-\nforming software engineering activities often \ninclude conformance to standards as part of \ntheir organizational policies.\n1.5.\t Economic\u2008Impact\u2008of\u2008Software  \n\b\n[3*, c1s1, c10s8] [4*, c1s1] [13*]\nThe software has economic effects at the \nindividual, business, and societal levels. For \nexample, software \u201csuccess\u201d may be deter-\nmined by a product\u2019s suitability for a recog-\nnized problem and by its effectiveness when \napplied to that problem. At the individual \nlevel, an engineer\u2019s continuing employment \nmay depend on their ability and willingness \nto interpret and execute tasks in meeting cus-\ntomers\u2019 or employers\u2019 needs and expectations. \nThe customer\u2019s or the employer\u2019s financial sit-\nuation may be positively or negatively affected \nby software purchases.\nAt the business level, software properly \napplied to a problem can eliminate months of \nwork and translate to elevated profits or more \neffective organizations. Organizations that \nacquire or provide successful software may \nbecome a boon to the society in which they \noperate by providing both employment and \nimproved services. However, the software\u2019s \ndevelopment or acquisition costs can be con-\nsiderable, like those of any major acquisition.\nAt the societal level, direct impacts of soft-\nware success or failure include the avoidance \nor experience of accidents, interruptions, and \nloss of service. Indirect impacts include the \nsuccess or failure of the organization that \nacquired or produced the software, increased \nor decreased societal productivity, harmo-\nnious or disruptive social order, and even the \nsaving or loss of property or life. In addition, \nas digitalization progresses, easier and faster \naccess to the information needed may bring \nhigher social value.\n1.6. \tEmployment\u2008Contracts  \n\b\n[1*, c6, c7] [10] [11] [12]\nSoftware engineering services may be pro-\nvided under a variety of client-engineer rela-\ntionships. For example, the work may be done \nthrough a company-to-customer supplier \narrangement, an engineer-to-customer con-\nsultancy arrangement, a direct-hire, or even \nthrough volunteering. In these situations, the \ncustomer and supplier agree that a product or \nservice will be provided in return for some con-\nsideration. Here, we are most concerned with \nengineer-to-customer arrangements and their \nattendant agreements or contracts, whether \nthey are of the direct-hire or consultant variety, \nand the issues they typically address.\nA common concern in software engineering \ncontracts is confidentiality. Employers derive \ncommercial advantage from intellectual prop-\nerty (IP), so they strive to protect that prop-\nerty from disclosure. Therefore, software \nengineers are often required to sign nondis-\nclosure agreements (NDA) or IP agreements \nas a precondition to working. These agree-\nments typically apply to information the \nsoftware engineer could gain only through \nassociation with the customer. The terms of \nthese agreements may extend past the associ-\nation\u2019s termination.\nAnother concern is IP ownership. Rights \nto software engineering assets \u2014 products, \ninnovations, inventions, discoveries, and ideas \n\u2014 may reside with the employer or customer, \nunder explicit contract terms or relevant laws, \nif those assets are obtained during the software \nengineer\u2019s relationship with that employer or \ncustomer. Contracts differ in the ownership \nof assets created using non-employer-owned \nequipment or information.\nFinally, contracts can also specify, among \nother elements: \n\u2022\t The location at which work is performed\n\u2022\t Standards to which that work will be held\n\u2022\t The system configuration used for \ndevelopment\n\u2022\t Limitations of the software engineer\u2019s \nand employer\u2019s liability\n", "page": 280, "type": "text", "section": "Page 280"}
{"text": "14-6   SWEBOK \u00ae GUIDE V4.0\n\u2022\t A communication matrix and/or esca-\nlation plan\n\u2022\t Administrative details such as rates, fre-\nquency of compensation, working hours, \nand working conditions\n1.7.\t Legal\u2008Issues\u2008\b\n[1*, c6, c11] [2] \n \n\b\n[3*, c5s3\u2013c5s4] [4*, c12s3, c13s2]\nLegal issues surrounding software engi-\nneering professional practice include mat-\nters related to standards, trademarks, patents, \ncopyrights, trade secrets, professional lia-\nbility, legal requirements, trade compliance, \ncybercrime, and data privacy. It is there-\nfore beneficial to know these issues and \ntheir applicability. In addition, legal issues \nare jurisdictionally based, so software engi-\nneers must consult attorneys who specialize \nin the type and jurisdiction of any identified \nlegal issues.\n1.7.1.\u2008Standards\nAdherence to standards provides a defense \nfrom legal action or allegations of malpractice. \n1.7.2.\u2008Trademarks\nA trademark relates to any word, name, symbol, \nor device used in business transactions. It is \nused \u201cto indicate the source or origin of the \ngoods.\u201d Trademark protection protects names, \nlogos, images, and packaging. However, if a \nname, image, or other trademarked asset \nbecomes a generic term, trademark protection \nis nullified.\nThe \nWorld \nIntellectual \nProperty \nOrganization (WIPO) is the authority \nthat frames the rules and regulations on \ntrademarks. WIPO is the United Nations \nagency dedicated to protecting the use of \nIP as a means of stimulating innovation and \ncreativity. \n1.7.3.\u2008Patents\nPatents protect an inventor\u2019s right to manu-\nfacture and sell an idea. A patent consists of \nexclusive rights granted by a sovereign gov-\nernment to an individual, group of individ-\nuals, or organization for a limited period. \nPatents are an old form of idea-ownership \nprotection and date to the 15th century.\nApplication for a patent entail keeping and \nproducing careful records of the process that \nled to the invention. In addition, patent attor-\nneys help write patent disclosure claims in a \nmanner most likely to protect the software \nengineer\u2019s rights. Note that if inventions are \nmade during a software engineering contract, \nownership may belong to the employer or cus-\ntomer or be jointly held rather than belong to \nthe software engineer.\nRules vary concerning what is and what \nis not patentable. In many countries, soft-\nware code is not patentable, but software \nalgorithms may be. Existing and filed patent \napplications can be found at WIPO. \n1.7.4.\u2008Copyrights\nMost governments give exclusive rights of an \noriginal work to its creator, usually for a lim-\nited time, enacted as copyright. Copyrights \nprotect the way an idea is presented \u2014 not \nthe idea itself. For example, they may pro-\ntect the particular wording of an account of \na historical event, whereas the event itself is \nnot protected. Copyrights are long-term and \nrenewable. As a form of IP, they date to the \n17th century.\n1.7.5.\u2008Trade\u2008Secrets\nIn many countries, an intellectual asset such as \na formula, algorithm, process, design, method, \npattern, instrument, or compilation of informa-\ntion may be considered a trade secret, provided \nthe asset is not generally known and may pro-\nvide a business with some economic advan-\ntage. The \u201ctrade secret\u201d designation provides \nlegal protection if the asset is stolen. This pro-\ntection is not subject to a time limit. However, \nif another party derives or discovers the same \nasset legally, then the asset is no longer pro-\ntected and the other party will also possess all \nrights to use it.\n", "page": 281, "type": "text", "section": "Page 281"}
{"text": "SOFTWARE ENGINEERING PROFESSIONAL PRACTICE   14-7\n1.7.6.\u2008Professional\u2008Liability\nIt is common for software engineers to be \nconcerned with professional liability mat-\nters. As engineers provide services to a client \nor employer, it is crucial that they adhere to \nstandards and generally accepted practices \nto protect themselves against allegations of \nor proceedings related to malpractice, negli-\ngence, or incompetence.\nFor engineers (including software engi-\nneers), professional liability is related to product \nliability. Under the laws and rules of their juris-\ndiction, engineers may be held accountable for \nfailing to fully and conscientiously follow rec-\nommended practice; this is known as negligence. \nThey may also be subject to laws governing \nstrict liability and implied or express warranty, \nwhere, by selling the product, the engineer is \nheld to warrant that the product is both suit-\nable and safe for use. In some countries (e.g., \nin the US), privity (a doctrine under which one \ncan sue only the person selling the product) is \nno longer a defense against liability actions.\nLegal suits for liability can be brought under \ntort law in the US, allowing anyone who is \nharmed to recover their loss even if no guaran-\ntees were made. Because it is difficult to mea-\nsure the suitability or safety of software, failure \nto take due care can be used to prove negligence \non the part of software engineers. Engineers \ncan defend themselves against such an allega-\ntion by showing that they followed standards \nand generally accepted practices in developing \nthe product to be ready to consult with attor-\nneys regarding the standard of care in any rel-\nevant jurisdiction to manage risks associated \nwith product liability or professional liability.\n1.7.7.\u2008Legal\u2008Requirements\nSoftware engineers must operate within local, \nnational and international legal frameworks. \nTherefore, software engineers must know the \nlegal requirements for the following:\n\u2022\t Registration and licensing, including \nexamination, education, experience, and \ntraining requirements\n\u2022\t Contractual agreements\n\u2022\t Noncontractual legalities, such as those \ngoverning liability\nBasic information on the international \nlegal framework can be accessed from the \nWorld Trade Organization (WTO). \n1.7.8.\u2008Trade\u2008Compliance\nAll software professionals must be aware of \nlegal restrictions on the import, export, or \nre-export of goods, services, and technology \nin the jurisdictions in which they work. Such \nrules often concern export controls and classi-\nfication; transfer of goods; acquisition of nec-\nessary governmental licenses for foreign use \nof hardware and software; services and tech-\nnology by sanctioned nations, enterprises, or \nindividual entities; and import restrictions \nand duties. Trade experts should be consulted \nfor detailed compliance guidance.\n1.7.9.\u2008Cybercrime\nCybercrime refers to any crime that involves a \ncomputer, computer software, computer net-\nworks, or embedded software controlling a \nsystem. The computer or software may have \nbeen used in the commission of a crime or \nhave been the target of the crime. This cat-\negory of crime includes fraud, unauthorized \naccess, spam, obscene or offensive content, \nthreats, harassment, theft of sensitive per-\nsonal data or trade secrets, and use of one \ncomputer to damage or infiltrate other com-\nputers and automated system controls.\nComputer and software users commit \nfraud by altering electronic data to facilitate \nillegal activity. Forms of unauthorized access \ninclude hacking, eavesdropping, and using \ncomputer systems in a way that is concealed \nfrom their owners. Many countries have laws \nthat specifically cover cybercrimes, but many \ndo not have effective statutes, making cyber-\ncrime difficult to prosecute in some cases. \nThe software engineer has a professional \nobligation to consider the threat of cyber-\ncrime and to consider how the software \n", "page": 282, "type": "text", "section": "Page 282"}
{"text": "14-8   SWEBOK \u00ae GUIDE V4.0\nsystem\u2019s security will protect the software \nand user information from accidental or \nmalicious access, use, modification, destruc-\ntion, or disclosure.\nDark patterns are deceptive UI/UX inter-\nactions designed to mislead or trick users into \nmaking them do something they may not \nwant to do. These patterns do not have the \nusers\u2019 interests in mind and aim for exploit-\nability rather than usability. Creating dark \npatterns is not good ethical practice. Software \nengineers should be responsible for their \nactions and be transparent with users instead \nof manipulating them.\n1.7.10. Data Privacy\nSoftware engineers should know that data \nprivacy is a key legal requirement in many \ncountries. The\u00a0 General Data Protection \nRegulation\u00a0 (GDPR), adopted on 14 April \n2016, and enforceable since 25 May 2018, \nregulates\u00a0 data protection\u00a0 and privacy in the \nEuropean Union (EU) and the\u00a0 European \nEconomic Area\u00a0(EEA). It also addresses the \ntransfer of\u00a0personal data outside the EU and \nEEA areas. The GDPR\u2019s primary aim is to \nenhance individuals\u2019 control and rights over \ntheir data and to simplify the regulatory envi-\nronment for international business.\nThe regulation became a model for many \nnational laws outside the EU, including \nthe UK, Chile, Japan, Brazil, South Korea, \nArgentina, and Kenya. The California \nConsumer Privacy Act (CCPA), adopted \non 28 June 2018, has many similarities with \nthe GDPR. \n1.8.\u2008Documentation\u2008 \n\b\n[1*, c10s5.8] [3*, c1s5] [4*] [5*, c32]\nProviding clear, thorough, and accurate \ndocumentation is the responsibility of each \nsoftware engineer. The adequacy of documen-\ntation is judged according to different criteria, \nbased on stakeholder needs. Good documen-\ntation complies with accepted standards and \nguidelines. In particular, software engineers \nshould document the following:\n\u2022\t Relevant facts\n\u2022\t Significant risks and trade-offs \n\u2022\t Warnings of undesirable or dangerous \nconsequences from the use or misuse of \nthe software\n\u2022\t Relevant information pertaining to attri-\nbute, license type, and sourcing\nSoftware engineers should avoid:\n\u2022\t Certifying or approving unacceptable \n \nproducts\n\u2022\t Disclosing confidential information\n\u2022\t Falsifying facts or data\nIn addition, software engineers and their \nmanagers should provide the following doc-\numentation for other elements of the software \ndevelopment organization to use:\n\u2022\t Software requirements specifications, soft-\nware design documents, details on the soft-\nware engineering tools used, software test \nspecifications and results, and details about \nthe adopted software engineering methods\n\u2022\t Problems encountered during the devel-\nopment process\nFor external stakeholders (customers, users, \nothers), software documentation should pro-\nvide the following:\n\u2022\t Information \nneeded \nto \ndetermine \nwhether the software is likely to meet \ncustomer and user needs\n\u2022\t Description of safe and unsafe use of \nthe software\n\u2022\t Explanation of how to protect sensitive \ninformation created by or stored using \nthe software\n\u2022\t Clear identification of warnings and crit-\nical procedures \nSoftware use may include installation, oper-\nation, administration, and performance of \nother functions by various groups of users and \nsupport personnel. If the customer will acquire \nownership of the software source code or the \nright to modify the code, the software engineer \n", "page": 283, "type": "text", "section": "Page 283"}
{"text": "SOFTWARE ENGINEERING PROFESSIONAL PRACTICE   14-9\nshould provide documentation of the func-\ntional specifications, the software design, the \ntest suite, and the necessary operating environ-\nment for the software. Documents should be \nkept for at least as long as the software prod-\nuct\u2019s life cycle or the time required by relevant \norganizational or regulatory requirements.\n1.9.\u2008Trade-Off\u2008Analysis\u2008 \n\b\n[3*, c1s2, c10] [4*, c7s2, c13s4] [13*, \n\b\nc9s5.10]\nA software engineer often has to choose \nbetween alternative problem solutions. The \noutcome of these choices is determined by the \nsoftware engineer\u2019s professional evaluation of \neach alternative\u2019s risks, costs, and benefits in \ncooperation with stakeholders. The software \nengineer\u2019s evaluation is called trade-off analysis. \nTrade-off analysis notably identifies competing \nand complementary software requirements to \nprioritize the final requirements defining the \nsoftware to be constructed. (See Requirements \nNegotiation in the Software Requirements \nKA and Determination and Negotiation of \nRequirements in the Software Engineering \nManagement KA.)\n When an ongoing software development \nproject is late or over budget, a trade-off anal-\nysis is often conducted to decide which soft-\nware requirements can be relaxed or dropped \ngiven the effects thereof. The first step in a \ntrade-off analysis is establishing design goals \n(see Engineering Design in the Engineering \nFoundations KA) and setting the relative \nimportance of those goals. This permits the \nidentification of the solution that most nearly \nmeets those goals; this means that the way the \ngoals are stated is critically important.\nDesign goals may include minimizing \nmonetary cost and maximizing reliability, \nperformance, or other criteria on various \ndimensions. However, it is difficult to formu-\nlate a trade-off analysis of cost against risk, \nespecially where primary production and \nsecondary risk-based costs must be weighed \nagainst each other. \nA software engineer must ethically con-\nduct a trade-off analysis \u2014 notably by being \nobjective and impartial when selecting cri-\nteria for comparing alternative problem solu-\ntions and assigning weights or importance \nto these criteria. In addition, any conflict of \ninterest must be disclosed upfront.\n2.\t Group Dynamics and Psychology\nEngineering work is often conducted in \nteams. A software engineer should interact \ncooperatively and constructively with others \nto first determine and then meet needs and \nexpectations. Knowledge of group dynamics \nand psychology is an asset when interacting \nwith customers, coworkers, suppliers, and \nsubordinates to solve software engineering \nproblems. \n2.1. \tDynamics\u2008of\u2008Working\u2008in\u2008Teams/Groups\u2008 \n\b\n[3*, c1s6] [14*, c1s3.5, c10]\nSoftware engineers must work with others. \nOn the one hand, they work internally in engi-\nneering teams; on the other hand, they work \nwith customers, members of the public, reg-\nulators, and other stakeholders. Performing \nteams \u2014 those who demonstrate a consistent \nquality of work and progress toward goals \u2014 \nare cohesive and possess a cooperative, honest \nand focused atmosphere. Individual and \nteam goals are aligned so the members natu-\nrally commit to and feel ownership of shared \noutcomes. \nTeam members facilitate this atmosphere \nby being intellectually honest, using group \nthinking, admitting ignorance, and acknowl-\nedging mistakes. They share responsibility, \nrewards, and workload fairly. They commu-\nnicate clearly and directly to one another and \nin documents and source code so information \nis accessible to everyone. Peer reviews about \nwork products are framed in a constructive \nand nonpersonal way. (See Reviews and Audits \nin the Software Quality KA.) This allows all \nthe members to pursue a continuous improve-\nment and growth cycle without personal risk. \nMembers of cohesive teams demonstrate \nrespect for one another and their leader.\n One point to emphasize is that software \n", "page": 284, "type": "text", "section": "Page 284"}
{"text": "14-10   SWEBOK \u00ae GUIDE V4.0\nengineers must be able to work in multidisci-\nplinary environments and varied application \ndomains. Because software is everywhere, \nfrom phones to cars, it affects people\u2019s lives \nfar beyond the more traditional concept of \nsoftware made for information management \nin a business environment. \n2.2.\t Individual\u2008Cognition \n\b\n[3*, c1s6.5] [5*, c33]\nEngineers want to solve problems. Every \nengineer strives to solve problems effectively \nand efficiently. However, the limits and pro-\ncesses of individual cognition affect prob-\nlem-solving. Individual cognition plays a \nprominent role in problem-solving in soft-\nware engineering, in part because of the \nhighly abstract nature of software itself.\nAn individual\u2019s (in particular, a software \nengineer\u2019s) ability to decompose a problem \nand creatively develop a solution can be inhib-\nited by the following:\n\u2022\t The need for more knowledge\n\u2022\t Subconscious assumptions\n\u2022\t The volume of data\n\u2022\t Fear of failure or the consequence of failure \n\u2022\t Culture, either of the application domain \nor the organization\n\u2022\t Lack of ability to express the problem \n\u2022\t Perceived working atmosphere\n\u2022\t The individual\u2019s emotional status\nThe effects of these inhibiting factors \ncan be reduced by cultivating good prob-\nlem-solving habits that minimize the impact \nof misleading assumptions. The ability to \nfocus is crucial, as is intellectual humility. \nBoth allow a software engineer to suspend \npersonal considerations and consult with \nothers freely, which is especially important \nwhen working in teams.\nEngineers use basic methods to facili-\ntate problem-solving. (See Problem-Solving \nTechniques in the Computing Foundations \nKA.) Breaking down problems and solving \nthem one piece at a time reduces cognitive \noverload. By taking advantage of professional \ncuriosity and pursuing continuous professional \ndevelopment, engineers gain skills and knowl-\nedge. Reading, networking, and experimenting \nwith new tools, techniques and methods are all \nvalid means of professional development. \n2.3. Dealing\u2008with\u2008Problem\u2008Complexity\u2008 \n\b\n[3*, c3s2] [4*, c1s1, c20s1-s5] [5*, c33]\nMany, if not most, software engineering prob-\nlems are too complex and difficult to address \nas a whole or to be tackled by individual soft-\nware engineers. When such circumstances \narise, engineers typically use teamwork \nand problem decomposition. (See Problem-\nSolving Techniques in the Computing \nFoundations KA.) \nTeams work together to deal with large, \ncomplex problems by sharing burdens and \ndrawing on one another\u2019s knowledge and cre-\nativity. When software engineers work in \nteams, individual engineers\u2019 different views \nand abilities complement one another and \nhelp build a solution otherwise difficult to \ncome by. Some teamwork examples in soft-\nware engineering are pair programming (see \nAgile Methods in the Software Engineering \nModels and Methods KA) and code review \n(see Reviews and Audits in the Software \nQuality KA).\n2.4. \tInteracting\u2008with\u2008Stakeholders \b\n[4*]\nThe success of a software engineering endeavor \ndepends on positive interactions with stake-\nholders. Stakeholders should provide support, \ninformation, and feedback at all stages of the \nsoftware life cycle. For example, during the \nearly stages, it is critical to identify all stake-\nholders and discover how the product will \naffect them to properly capture a sufficient \ndefinition of stakeholder requirements.\n In Agile software development, the involve-\nment of stakeholders is even more essential \nthan in other types of development. First, \nduring development, stakeholders may pro-\nvide feedback on specifications or early ver-\nsions of the software, changes of priority, \nand clarification of detailed or new software \n", "page": 285, "type": "text", "section": "Page 285"}
{"text": "SOFTWARE ENGINEERING PROFESSIONAL PRACTICE   14-11\nrequirements. Last, during software mainte-\nnance and until the end of product life, stake-\nholders can provide feedback on evolving or \nnew requirements and problem reports so \nthe software can be extended and improved. \nClearly, regular stakeholder involvement will \nlead to a better application. It is vital to main-\ntain open and productive communication \nwith stakeholders during the software prod-\nuct\u2019s life cycle. \n2.5. \tDealing\u2008with\u2008Uncertainty\u2008and\u2008Ambiguity\u2008 \n\b [4*, c4s1, c4s4, c11s5, c24s5] [14*, c9s4]\nAs with engineers in other fields, software \nengineers must often deal with and resolve \nuncertainty and ambiguities while providing \nservices and developing products. The soft-\nware engineer must reduce or eliminate any \nlack of clarity that is an obstacle to per-\nforming work.\nOften, uncertainty reflects a lack of knowl-\nedge. If that is the case, investigating the \nissue by reading formal sources such as text-\nbooks and professional journals, interviewing \nstakeholders, or consulting with teammates \nand peers can likely solve the problem.\nWhen uncertainty or ambiguity cannot be \novercome easily, software engineers or organi-\nzations may regard it as a project risk. When \nthis is the case, work estimates or pricing are \nadjusted to mitigate the anticipated cost of \naddressing it. (See Risk Management in the \nSoftware Engineering Management KA.)\n2.6. \tDealing\u2008with\u2008Equity, Diversity, and \nInclusivity\u2008\b\n[4*] [14*, c10s7]\nThe equity, diversity, and inclusivity environ-\nment can affect a group\u2019s dynamics. This is \nespecially true when the group is geograph-\nically separated or communication is infre-\nquent because such separation elevates the \nimportance of each contact. Intercultural \ncommunication is even more difficult if the \ndifference in time zones makes oral commu-\nnication less frequent. \nMulticultural environments are preva-\nlent in software engineering, perhaps more \nthan in other engineering fields, because of \nthe strong trend of international outsourcing \nand the easy shipment of software compo-\nnents instantaneously around the globe. For \nexample, it is common for a software project \nto be divided into pieces across national and \ncultural borders. It is also common for a soft-\nware project team to consist of people from \ndiverse cultural backgrounds. \nFor a software project to succeed, team \nmembers must embrace tolerance of dif-\nferent cultural and social norms, acknowl-\nedging that not all societies have the same \nsocial expectations. The support of leader-\nship and management can facilitate tolerance \nand understanding. More frequent commu-\nnication, including face-to-face meetings, \ncan help mitigate geographical and cultural \ndivisions, promote cohesiveness, and raise \nproductivity. Also, communicating with \nteammates in their native language could be \nbeneficial. \nIn the software industry, gender bias \nis still prevalent. Implementing broader \nrecruiting strategies, specific and measur-\nable performance evaluation criteria, and \ntransparent procedures for assigning com-\npensation can reduce gender inequality in \nthe software industry. These trends can con-\ntribute to building a diverse environment \nfor all software engineers, regardless of \ntheir gender. \n3.\t Communication Skills \nA software engineer must communicate well, \nboth orally and in reading and writing. To \nmeet software requirements and deadlines, \nengineers must establish clear communica-\ntion with customers, supervisors, coworkers, \nand suppliers. Optimal problem-solving is \nmade possible through the ability to inves-\ntigate, comprehend and summarize infor-\nmation. Customer product acceptance and \nsafe product use depend on relevant training \nand documentation. The software engineer\u2019s \ncareer success is affected by consistently pro-\nviding oral and written communication effec-\ntively and on time. \n", "page": 286, "type": "text", "section": "Page 286"}
{"text": "14-12   SWEBOK \u00ae GUIDE V4.0\n3.1. \tReading,\u2008Understanding, \nand\u2008Summarizing \b\n[4*, c4s5] [5*, c33s3] \nSoftware engineers must be able to read and \nunderstand technical material. Technical mate-\nrial includes reference books, manuals, research \npapers, online sources and program source code.\nReading is not only a primary way of \nimproving skills but also a way of gathering \ninformation for completing engineering goals. \nA software engineer sifts through accumu-\nlated information, focusing on the pieces that \nwill be most helpful. Customers may request \nthat a software engineer summarize the results \nof such information-gathering for them, sim-\nplifying or explaining it so that they can make \nthe final choice among competing solutions.\nReading and comprehending source code \nare also components of information-gathering \nand problem-solving. For example, when \nengineers modify, extend or rewrite software, \nthey must understand both its implementa-\ntion, directly derived from the presented code, \nand its design, which must often be inferred. \n3.2. \tWriting\u2008\b\n[3*, c1s5] [4*, c4s2-s3]\nSoftware engineers can produce written \nproducts requested by customers or required \nby generally accepted practice. These written \nproducts may include source code, software \nproject plans, software requirement docu-\nments, risk analyses, software design doc-\numents, software test plans, user manuals, \ntechnical reports and evaluations, justifica-\ntions, diagrams and charts, and so forth. \nClear, concise writing is important because \nwriting is often the primary method of com-\nmunication among relevant parties. In all \ncases, written software engineering products \nmust be accessible, understandable, and rele-\nvant to their intended audience.\n3.3. \tTeam\u2008and\u2008Group\u2008Communication\u2008 \n\b\n[3*, c1s6.8] [4*, c22s3] [5*, c27s1] \n \n\b\n[14*, c10s4]\nEffective communication among team and \ngroup members is essential to a collaborative \nsoftware engineering effort. Stakeholders \nmust be consulted; decisions must be made, \nand plans must be generated. The greater \nthe number of team and group members, the \ngreater the need to communicate.\nHowever, the number of communication \npaths grows quadratically with the addition \nof each team member. Furthermore, team \nmembers are unlikely to communicate with \nanyone perceived to be removed from them by \nmore than two degrees (levels). This problem \ncan be more serious when software engi-\nneering endeavors or organizations are spread \nacross national and continental borders.\n Some communication can be accom-\nplished in writing. Software documentation \nis a common substitute for direct interaction. \nEmail is another, but although it is useful, it \nis not always enough. Also, if one receives too \nmany messages, it becomes difficult to identify \nthe important information. Increasingly, orga-\nnizations are using enterprise collaboration \ntools to share information. In addition, elec-\ntronic information stores, accessible to all team \nmembers for organizational policies, stan-\ndards, common engineering procedures, and \nproject-specific information, can be beneficial. \nSome software engineering teams focus \non face-to-face interaction and promote such \ninteraction through office space arrange-\nments. Although private offices improve indi-\nvidual productivity, other arrangements, such \nas co-locating team members in physical or \nvirtual spaces and providing communal work \nareas, can boost collaborative efforts. \n3.4. \tPresentation\u2008Skills\u2008 \n\b\n[3*, c1s5] [4*, c22] [14*, c10s7\u2013c10s8]\nSoftware engineers rely on their presenta-\ntion skills during software life cycle pro-\ncesses. For example, software engineers may \nwalk customers and teammates through \nsoftware requirements during the phase \nand conduct formal requirements reviews. \n(See Requirement Reviews in the Software \nRequirements KA.) During and after soft-\nware design, software construction, and soft-\nware maintenance, software engineers lead \n", "page": 287, "type": "text", "section": "Page 287"}
{"text": "SOFTWARE ENGINEERING PROFESSIONAL PRACTICE   14-13\nreviews, product walkthroughs (see Review \nand Audits in the Software Quality KA), and \ntraining. These require the ability to present \ntechnical information to groups and solicit \nideas or feedback.\n Therefore, the software engineer\u2019s ability \nto convey concepts effectively in a presentation \ninfluences product acceptance, management, \nand customer support. It also influences the \nability of stakeholders to comprehend and \nassist in the product effort. This knowledge \nneeds to be archived in slides, knowledge \nwrite-ups, technical white papers, and other \nmaterial used for knowledge creation.\nMATRIX OF TOPICS VS. REFERENCE MATERIAL\n1. Professionalism\nBott et al.  \n2000 [1*]\nVoland,  \n2003 [3*]\nSommerville, \n2016 [4*]\nMcConnel,  \n2004 [5*]\nTockey, \n2004 [13*]\nFairley, \n2009 [14*]\n1.1. Accreditation,\nCertification and \nQualification, and Licensing\nc1s5,\nc1s10\nc12s10\n1.2. Codes of Ethics and \nProfessional Conduct\nc1s7-s9,  \nc10s2, App\nc1s2\n1.3. Nature and Role of \nProfessional Societies\nc2s3\nc1s2\nc35s1\n1.4. Nature and Role of \nSoftware Engineering \nStandards \nc10s2,\n*\nc32s6\n1.5. Economic Impact \nof Software\nc1s1,\nc10s8\nc1s1\n*\n1.6. Employment Contracts\nc6, c7\n*\n1.7. Legal Issues\nc6, c11\nc5s3-\ns4,\nc12s3,\nc13s2\n1.8. Documentation\nc10s5\nc1s5\n*\nc32\n1.9. Trade-Off Analysis\nc1s2,\nc10\nc7s2,\nc13s4\nc9s5-10\n2. Group Dynamics and \nPsychology\n2.1. Dynamics of Working in \nTeams/Groups\nc1s6\nc1s3-5,\nc10\n2.2. Individual Cognition\nc1s6\nc33\n2.3. Dealing with Problem \nComplexity\nc3s2\nc1s1,\nc20s1-s5\n2.4. Interacting with \nStakeholders\n*\n2.5. Dealing with \nUncertainty and Ambiguity\nc4s1,c4s4,\nc11s5c24s5\nc9s4\n", "page": 288, "type": "text", "section": "Page 288"}
{"text": "14-14   SWEBOK \u00ae GUIDE V4.0\n2.6. Dealing with Equity, \nDiversity, and Inclusivity\n*\nc10s7\n3. Communication Skills\n3.1. Reading, Understanding, \nand Summarizing\nc4s5\nc33s3\n3.2. Writing\nc1s5\nc4s2-s3\n3.3. Team and Group \nCommunication\nc1s6\nc22s3\nc27s1\nc10s4\n3.4. Presentation Skills\nc1s5\nc22\nc10s7-s8\nFURTHER READINGS \nG.M. Weinberg, The Psychology of Computer \nProgramming [15]. \nThis was the first major book to address pro-\ngramming as an individual and team effort; it \nhas become a classic in the field.\nKinney and Lange, P.A., Intellectual\u2008Property\u2008\nLaw\u2008for\u2008Business\u2008Lawyers [16]. \nThis book covers IP laws in the US. It not only \ntalks about what the IP law is; it also explains \nwhy it looks the way it does.\nREFERENCES\n[1*] \t F. Bott et al., Professional Issues in \nSoftware Engineering, 3rd ed., Taylor & \nFrancis, 2000.\n[2] \t Appendix B of this Guide.\n[3*]\t G. Voland, Engineering by Design, 2nd \ned., Prentice-Hall, 2003.\n[4*]\t I. Sommerville, Software Engineering, \n10th ed., Addison-Wesley, 2016.\n[5*]\t S. McConnell, Code Complete, 2nd ed., \nMicrosoft Press, 2004.\n[6]\t 25 Years Washington Accord, \nIEC, 2014.\n[7]\t EUR-ACE, 2017.\n[8]\t ISO/IEC 24773-1, Software and \nSystems Engineering \u2013 Certification \nof Software and System Engineering \nProfessionals \u2014 Part 1: General \nRequirements.\n[9]\t\nISO/IEC 24773-4 Software and Systems \nEngineering \u2014 Certification of Software \nand Systems Engineering Professionals \n\u2014 Part 4: Software engineering. \n[10]\t ACM Code of Ethics and Professional \nConduct, 2018.\n[11]\t IEEE Code of Ethics, 2020.\n[12]\t IFIP Code of Ethics and Professional \nConduct, 2021.\n[13*]\tS. Tockey, Return on Software: \nMaximizing the Return on Your Software \nInvestment, Addison-Wesley, 2004.\n[14*]\tR. E. Fairley, Managing and Leading \nSoftware Projects, Wiley-IEEE \nComputer Society Press, 2009.\n[15]\t G. M. Weinberg, The Psychology \nof Computer Programming: Silver \nAnniversary Edition, Dorset \nHouse, 1998.\n[16]\t Kinney and Lange, P.A., Intellectual \nProperty Law for Business Lawyers, \nThomson West, 2013.\n", "page": 289, "type": "text", "section": "Page 289"}
{"text": "15-1 \nCHAPTER 15\nSoftware Engineering \nEconomics\nACRONYMS\nIRR\nInternal Rate of Return\nMARR\nMinimum Acceptable \nRate of Return\nSDLC\nSoftware Development Life Cycle\nSPLC\nSoftware Product Life Cycle\nROI\nReturn on Investment\nSEI\nSoftware Engineering Institute\nTCO\nTotal Cost of Ownership\nINTRODUCTION\nSoftware is ubiquitous and has become essen-\ntial for many organizations. It serves organiza-\ntions in the following ways:\n\u2022\t as a lever to reach an organization\u2019s busi-\nness or strategic goals;\n\u2022\t as a catalyst of organizational know-how \nto improve value.\nBoth aspects lead directly to critical soft-\nware engineering demands:\n\u2022\t increased productivity;\n\u2022\t reduced rework\n\u2022\t reduced development time\n\u2022\t shorter maintenance turnaround\n\u2022\t long-term sustainability;\n\u2022\t innovation;\n\u2022\t competitiveness;\n\u2022\t alignment with organizational goals.\nSoftware engineering economics helps soft-\nware engineers work in ways that satisfy these \ncritical demands. The Introduction to SWEBOK \nGuide explains that engineering economics is a \nkey element of all recognized engineering dis-\nciplines. Economics is the science of choice, \nnot the science of money. Engineering eco-\nnomics is the applied microeconomics branch \nof economics. It asks the fundamental ques-\ntion, \u201cIs it in the best interest of this enterprise \nto invest its limited resources in this technical \nendeavor, or would the same investment pro-\nduce a higher return elsewhere?\u201d Paraphrasing \nthe definition in [1], engineering is \u201cfinding the \nbalance between what is technically feasible \nand what is economically acceptable.\u201d\nSoftware engineering must be value-based. \nNeutral \u2014 or worse, negative \u2014 value from \nan organization\u2019s investment in software is not \nsustainable. Software engineering economics \naligns software technical decisions with the \norganization\u2019s business goals.\n\u201cThe organization\u201d will at least include the \norganization where the software engineer is \nemployed. However, when the software engi-\nneer is involved in work for any third party, \nsuch as through an external digital transfor-\nmation contract or other \u201cworks for hire\u201d situ-\nation, the business goals of that third party are \nalso relevant.\nIn all types of organizations \u2014 for-profit, \nnonprofit and government \u2014 a value-based \napproach translates into long-term sustainability. \nIn for-profit organizations this means achieving a \ntangible return on the software investment. In \nnonprofit organizations, this means achieving \nthe maximum benefit for the least cost.\nSoftware technical decisions, like an orga-\nnization\u2019s decision to use a preexisting library \nor to develop its own, may appear easy from a \npurely technical perspective. However, they can \nhave serious implications for the business via-\nbility of a software project as well as the product \nitself. Most software practitioners wonder \n", "page": 290, "type": "text", "section": "Page 290"}
{"text": "15-2   SWEBOK \u00ae GUIDE V4.0\nwhether such concerns apply to them. But eco-\nnomic decision-making is fundamental to engi-\nneering. Someone who cannot make decisions \nfrom both a technical and an economic per-\nspective cannot be considered a true engineer.\nSoftware engineering economics applies to \ndecisions across the entire software product \nlife cycle (SPLC), from the pre-project deci-\nsion to develop the software to end-of-life \ndecisions for existing software. It also applies \nto decisions at all levels of technical detail. For \nexample, all following questions involve an \neconomic perspective:\n\u2022\t can a client organization benefit from a \ndigital transformation?\n\u2022\t does a project proposal (a tender) align \nwith a client\u2019s business goals?\n\u2022\t should certain software functionality be \nbought or built?\n\u2022\t should certain requirements be included \nin scope or not?\n\u2022\t what is the most efficient, cost-effective \narchitecture and design?\n\u2022\t what is an optimal load-balancing strategy \nfor a cloud-based deployment that provides \nadequate response time to clients without \nincurring unnecessary operational cost?\n\u2022\t how much risk-based testing is enough?\n\u2022\t is it better to refactor, redevelop or just live \nwith code that has high technical debt?\n\u2022\t is it better to focus maintenance on \nadding new functionality or on fixing \nknown defects?\n\u2022\t would the value of early delivery of par-\ntial functionality gained by using an \nAgile process outweigh the overhead of \nrework and continuous testing inherent \nin iterative approaches?\nThe Software Engineering Economics \nknowledge area (KA) is directly or indirectly \nrelated to all other KAs in this Guide.\nThis KA also takes the position that the \nmore traditional, purely financial view of \nengineering economics needs to be broadened \n[2]. Value does not always derive from money \nalone; value can also derive from \u201cunquanti-\nfiables\u201d like corporate citizenship, employee \nwell-being, environmental friendliness, cus-\ntomer loyalty and so on. Therefore, software \nengineering decisions must also consider rel-\nevant unquantifiable criteria.\nBREAKDOWN OF TOPICS FOR \nSOFTWARE ENGINEERING \nECONOMICS\nThe breakdown of topics for the Software \nEngineering Economics KA is shown in \nFigure 15.1. \nSoftware Engineering\nEconomics\nProposals\nCash Flow\nTime-Value\nof Money\nEquivalence\nBases for\nComparison\nAlternatives\nIntangible\nAssets\nBusiness\nModel\nProcess\nOverview\nUnderstand the\nReal Problem\nIdentify all\nReasonable\nTechnically-\nFeasible\nSolutions\nDe\ufb01ne the\nSelection\nCriteria\nEvaluate each\nAlternative\nagainst the\nSelection Criteria\nSelect the Preferred\nAlternative\nMonitor the Performance \nof the Selected Alternative\nMinimum\nAcceptable\nRate of Return\nEconomic Life\nPlanning\nHorizon\nReplacement\nDecisions\nRetirement Decisions\nAdvanced For-Pro\ufb01t\nDecision Considerations\nBene\ufb01t-Cost\nAnalysis\nCost-\nE\ufb00ectiveness\nAnalysis\n \nBreak-Even\nAnalysis\nOptimization\nAnalysis\nCompensatory\nTechniques\nNon-\nCompensatory\nTechniques\nIdentify\nProcesses and\nDe\ufb01ne \nBusiness Goals\nIdentify\nIntangible Assets\nlinked with\nBusiness Goals\nIdentify\nSoftware\nProducts that\nSupport\nIntangible Assets\nDe\ufb01ne and\nMeasure Indicators\nIntangible Asset\nCharacterization\nLink Speci\ufb01c Intangible \nAssets with the Business Model\nDecision Making\nAccounting\nCost and Costing\nFinance\nControlling\nE\ufb03ciency and\nE\ufb00ectiveness\nProductivity\nProduct or\nService\nProject\nProgram\nPortfolio\nProduct\nLifecycle\nProject\nLifecycle\nPrice and\nPricing\nPrioritization\nSoftware\nEngineering\nEconomics\nFundamentals\nTe Engineering\nDecision-Making\nProcess\nFor-Pro\ufb01t\nDecision-Making\nNonpro\ufb01t\nDecision-Making\nPresent Economy\nDecision-Making\nMultiple-\nAttribute\nDecision-Making\nIdentifying and\nCharacterizing\nIntangible Assets\nEstimation\nPractical\nConsiderations\nRelated\nConcepts\nExpert\nJudgment\nAnalogy\nDecomposition\nParametric\nMultiple\nEstimates\nBusiness Case\nMultiple-\nCurrency\nAnalysis\nSystems\nTinking\nFigure 15.1. Breakdown of Topics for the Software Engineering Economics KA\n", "page": 291, "type": "text", "section": "Page 291"}
{"text": "SOFTWARE ENGINEERING ECONOMICS   15-3\n1.\t Software Engineering Economics \nFundamentals\n1.1. Proposals\b\n[3*, c3pp23-24]\nSoftware engineering decisions begin with \nthe concept of a proposal \u2014 a single, separate \ncourse of action to be considered (e.g., carrying \nout a particular software development project \nor not). Another proposal could be to enhance \nan existing software component; another \nmight be to redevelop that same software \nfrom scratch. In deciding what algorithm to \nuse in implementing a certain function, each \ncandidate considered is a proposal. Every pro-\nposal represents a binary unit of choice \u2014 the \nsoftware engineer either carries out that pro-\nposal or chooses not to. Software engineering \neconomics aims to identify the proposals best \naligned with the organization\u2019s goals.\n1.2. Cash Flow\b\n[3*, c3pp24-32]\nEngineers must evaluate a proposal from a \nfinancial perspective to make a meaningful \ndecision about it. The concepts of cash flow \ninstance and cash flow stream describe the \nfinancial perspective of proposals.\nA cash flow instance is a specific amount of \nmoney flowing into or out of the organization \nat a specific time as a direct result of carrying \nout a proposal. For example, in a proposal to \ndevelop and launch product X, the payment \nfor new computers, if needed, would be an \nexample of an outgoing cash flow instance. \nMoney would need to be spent to carry out \nthat proposal. The sales income from product \nX in the 11th month after market launch \nwould be an example of an incoming cash \nflow instance. Money would come in because \nof carrying out the proposal. \nA cash flow stream is the set of cash flow \ninstances over time caused by carrying out \nthat proposal. The cash flow stream is that \nproposal\u2019s complete financial view. How \nmuch money goes out? When does it go out? \nHow much money comes in? When does it \ncome in? If the cash flow stream for Proposal \nA is more desirable than the cash flow stream \nfor Proposal B, then \u2014 all other things being \nequal \u2014 the organization is financially better \noff carrying out Proposal A than Proposal B. \nThus, the cash flow stream is an important \nelement of engineering decision-making.\nA cash flow diagram is a picture of a cash flow \nstream. The cash flow diagram quickly sum-\nmarizes the financial view of a proposal. Figure \n15.2 shows an example cash flow diagram.\nThe cash flow stream is shown in two dimen-\nsions. Time runs from left to right and amounts \nof money run up and down. The horizontal \naxis is divided into units representing years, \nmonths, weeks, etc., as appropriate for the pro-\nposal. Each net cash flow instance is drawn at a \nleft-to-right position relative to its timing. The \namount of the cash flow instance is shown as \nan upward or downward arrow. Upward arrows \nindicate that money is coming in (income), \nwhereas downward arrows indicate that money \nis spent (expense). The arrow\u2019s length is usually \nproportional to the net amount.\n1.3. Time-Value of Money\b\n[3*, c5-6]\nOne of the most fundamental concepts in \neconomics \u2014 and therefore, in business deci-\nsions \u2014 is that money has time-value: Its \nvalue changes over time. A specific amount \nof money right now almost always has a value \n0\n1\n2\n3\n4\n$2900\n5\n6\n7\n-$10,000\n-$850\n$8150\n$650\n$5900\n$3650\n$1400\nFigure 15.2. A Cash Flow Diagram\n", "page": 292, "type": "text", "section": "Page 292"}
{"text": "15-4   SWEBOK \u00ae GUIDE V4.0\ndifferent from the same amount at some other \ntime. This concept has been around since the \nearliest recorded human history and is com-\nmonly expressed as interest.\n1.4. Equivalence\b\n[3*, c7]\nDue to the time-value of money, two or more \ncash flows are equivalent only when they equal \nthe same amount of money at the same time. \nTherefore, comparing cash flows makes sense \nonly when they are expressed in the same time \nframe. Then, lack of equivalence between the \ntwo cash flows can be determined accurately \nand can serve as the basis for choice. The pro-\nposal with the highest value in the same time \nframe is the most financially desirable.\n1.5. Bases for Comparison\b\n[3*, c8]\nA basis for comparison is a shared frame of ref-\nerence for comparing two or more cash flow \nstreams. It uses equivalence to meaningfully \ncompare two or more proposals. Several bases \nfor comparison exist, including the following:\n\u2022\t present worth;\n\u2022\t future worth;\n\u2022\t annual equivalent;\n\u2022\t internal rate of return (IRR);\n\u2022\t discounted payback period.\n1.6. Alternatives\b\n[3*, c9]\nOften, an organization could carry out more \nthan one proposal if it wanted to. But there \nmight be important relationships between \nproposals that need to be considered. Maybe \nProposal Y can only be carried out if Proposal \nX is also carried out. Or maybe Proposal P \ncannot be carried out if Proposal Q is car-\nried out, nor could Q be carried out if P were. \nDecisions are easier when there are mutually \nexclusive paths \u2014 A, or B, or C, or another \nproject, and no others. This topic explains how \nto turn any set of proposals, with their inter-\nrelationships, into a set of mutually exclu-\nsive alternatives. The cash flow stream for any \nalternative is the sum of the cash flow streams \nfor all the proposals it contains. The choice \ncan then be made among these alternatives.\nOne special case is known as the do-nothing \nalternative. Sometimes the best course of \naction is not to carry out any of the proposals \nbeing considered. The do-nothing alterna-\ntive represents that case. It doesn\u2019t mean do \nnothing at all; it means \u201cdo something else, \nsomething that\u2019s not in this set of choices.\u201d \nThe do-nothing alternative should be consid-\nered in most, but not all, situations.\n1.7. Intangible Assets\nIntangible assets, also known as knowl-\nedge assets, are any knowledge that lies in \nthe non-visible side of an organization but \naffects that organization\u2019s financial perfor-\nmance. According to International Valuation \nStandards (IVS) 210 \u00a7 20.1, \u201can intangible \nasset is a non-monetary asset that manifests \nitself by its economic properties. It does not \nhave physical substance but grants rights and \neconomic benefits to its owner\u201d [4].\nThis can include, but is not limited to, pol-\nicies, procedures, tools and specifications, \nas well as organizational culture, experience \nand know-how.\nKnowing the organization\u2019s intangible assets \nhelps the software engineer better understand \nhow proposals may affect or be affected by orga-\nnizational realities. Otherwise, hidden risks \nand opportunities that could influence pro-\nposals\u2019 success or failure might not be exposed.\nThe skills needed to consider intangible \nassets are the following:\n\u2022\t intangible \nassets \nidentification \nand \nvaluation [Skills Framework for the \nInformation \nAge \n(SFIA), \ncategory \nStrategy and Architecture, subcategory \nBusiness strategy and planning];\n\u2022\t knowledge management [SFIA, category \nStrategy and Architecture, subcategory \nBusiness strategy and planning].\nIdentifying and characterizing intan-\ngible assets are discussed in more detail later \nin this KA.\n", "page": 293, "type": "text", "section": "Page 293"}
{"text": "SOFTWARE ENGINEERING ECONOMICS   15-5\n1.8. Business Model \nPeter Drucker, a founder of modern manage-\nment, defines a good business model as one \nthat answers these questions [5]: \n\u2022\t \u201cWho is the customer?\u201d\n\u2022\t \u201cWhat does the customer value?\u201d\n\u2022\t \u201cHow do we make money?\u201d\n\u2022\t \u201cWhat is the underlying economic logic \nthat explains how we can deliver value to \ncustomers at an appropriate cost?\u201d\nUnderstanding the organization\u2019s business \nmodel \u2014 as well as its intangible assets \u2014 helps \nthe software engineer better understand how \nproposals may affect or be affected by orga-\nnizational realities. Analyzing the business \nmodel can help the software engineer iden-\ntify hidden risks and opportunities that could \ninfluence a proposal\u2019s success or failure [6].\n2.\t  The Engineering Decision-Making \nProcess\n2.1. Process Overview\b\n[3*, c4pp35-36]\nFigure 15.3 provides an overview of the engi-\nneering decision-making process.\nThe process is shown as stepwise and sequen-\ntial; however, it can be more fluid in practice. \nSteps can be done iteratively, can overlap and \ncan even occur in different sequences. Just be \nsure not to skip any step or execute it poorly.\nWhen the consequences of a wrong deci-\nsion are significant, such as a go/no-go deci-\nsion for a large project, more time, effort and \ncare should be spent in this process. All steps \nshould be completed thoroughly and carefully. \nISO 12207 [7] and ISO 15288 [8] recommend \ntwo additional early activities, which can be \nimportant in high-consequence decisions:\n\u2022\t define the decision management strategy \n\u2014 this strategy might specify roles, \nresponsibilities, procedures and tools;\n\u2022\t identify relevant stakeholders, which might \ninclude appropriate subject matter experts.\nWhen the consequences of a wrong deci-\nsion are small, such as the consequences of \nselecting a minor algorithm or data structure, \nless time, effort and care can be spent, but the \nsame general process is followed. Each step is \ndiscussed in more detail below.\n2.2. Understand the Real Problem \n\b\n[3*, c4pp37-39]\nThe best solution to a problem can come \nonly from thoroughly understanding the real \nproblem to be solved. This step\u2019s key aspects \ninclude the use of an interrogative technique \nsuch as the \u201c5 Whys\u201d technique and a con-\nsideration of the broader context surrounding \nthe problem. The Empathize stage in Design \nThinking [9] (to consider intangible assets) \nand looking closely at the organization\u2019s \nIdentify all reasonable\ntechnically feasible\nsolutions\nEvaluate each\nalternative against\nthe selection criteria\nDefne the\nselection criteria\nUnderstand the\nreal problem\nSelect the\npreferred alternative\nMonitor the\nperformance of the\nselected alternative\nFigure 15.3. The Engineering Decision-Making Process\n", "page": 294, "type": "text", "section": "Page 294"}
{"text": "15-6   SWEBOK \u00ae GUIDE V4.0\nbusiness model are examples of considering \nthat broader context.\n2.3. Identify All Reasonable Technically Feasible \nSolutions\b\n[3*, c4pp40-41]\nThe goal of engineering decision-making is \nto find the best solution. However, the best \nsolution must first be identified as a candidate \nbefore it can be selected as the best. If the \nbest solution is not among the set of solutions \nbeing considered, it cannot be selected. The \nimportance of creative thinking in this step \ncannot be overstated when the consequences \nof a wrong decision are high.\nFor some potential solutions, or candidates, \nprototyping is a useful way to verify technical \nfeasibility. Peer review can also help verify \ntechnical feasibility and possibly spur the \nidentification of even more candidates.\nOn the one hand, adding candidates \nincreases the probability that the best one is in \nthe set. On the other hand, each adds cost to \nthe decision-making process. Software engi-\nneers must use their best judgment in deciding \nwhen they have enough candidates. These \ncandidates are the \u201cproposals\u201d as defined in \nthe Fundamentals topic, Section 1.\n2.4. Define the Selection Criteria \n\b\n[3*, c4pp39-40, c26pp441-442]\nEngineering decisions almost always consider \nthe financial perspective. However, other \ndecision criteria can also be relevant; when \nthis is the case, the decision is a multiple-at-\ntribute decision. For example, an environmen-\ntally conscious organization may choose a less \neconomical solution if it is more eco-friendly. \nIn many cases, the greater the consequences \nof a wrong decision, the more selection cri-\nteria need to be considered.\nAs much as possible, each criterion should \nbe expressed objectively. Ideally, those objec-\ntive terms will be expressed as a monetary value \n\u2014 but not necessarily. What is the \u201cvalue\u201d of a \nclean river? It might not make sense to value a \nriver by multiplying the price per kilogram of \nfish by an estimate of the number of fish in the \nriver. Decision criteria that can\u2019t be expressed \nobjectively are called \u201cunquantifiables,\u201d \u201cirre-\nducibles\u201d or \u201cintangibles.\u201d\nDefining the decision criteria can be a sub-\njective task. Too many criteria could make the \nanalysis unwieldy. On the other hand, too few \ncriteria might not differentiate well between \nproposals and could thus lead to a suboptimal \nchoice. The potential for a better decision \nprovided by including more criteria must be \nbalanced against the extra effort required to \nanalyze the criteria.\nTo the extent that money is a selection crite-\nrion, the context of the decision will constrain \nthe decision-maker to a for-profit, nonprofit or \npresent economy decision analysis, as explained \nin topics 3, 4 and 5, later in this KA.\n2.5. Evaluate Each Alternative Against the \nSelection Criteria\b\n[3*, c4pp41-42]\nEach alternative is evaluated against each \nselection criterion. When a selection crite-\nrion involves money, each alternative must \nbe judged from the same viewpoint. Use the \nsame basis for comparison (present worth, \nfuture worth, IRR, etc., in for-profit deci-\nsions; benefit-cost ratio or cost-effectiveness in \nnonprofit decisions, etc.), the same planning \nhorizon, and consider the same kinds of costs \nand incomes. An example decision might be \nbuying and adapting an off-the-shelf software \nproduct versus building a custom application \nfrom scratch. Considering costs for a longer \ntime frame for one proposal than for the other \nwill make the one using the shorter time frame \nseem like the better choice even though it \nmight not be better over the same time frame.\n2.6. Select the Preferred Alternative \n\b\n[3*, c4p42, c26pp447-458]\nIf the only selection criterion is money, the \nalternative with the highest present worth, \nfuture worth, etc., will be chosen. When \nthere are multiple criteria, a variety of tech-\nniques can be used to evaluate the criteria \ntogether. Multiple-attribute decision-making \nis detailed later in this KA.\n", "page": 295, "type": "text", "section": "Page 295"}
{"text": "SOFTWARE ENGINEERING ECONOMICS   15-7\nEngineering decisions are based on esti-\nmates (discussed later in this KA). The accu-\nracy of an estimate is limited in theory and in \npractice, and the degree of inaccuracy depends \non the specifics of the situation [3*, c21pp344-\n356]. If the degree of inaccuracy is high enough, \nthat inaccuracy could change the resulting \ndecision. The following techniques [3*, c23] \ncan help engineers address these situations:\n\u2022\t consider ranges of estimates;\n\u2022\t perform a sensitivity analysis;\n\u2022\t delay final decisions.\nIn addition, two categories of techniques \naddress multiple potential outcomes from \na decision:\n\u2022\t decision-making-under-risk techniques \n[3*, c24] are used when probabilities can \nbe assigned to the different potential \noutcomes. Specific techniques include \nexpected value decision-making, expec-\ntation variance and decision-making, \nMonte Carlo analysis, decision trees, and \nthe expected value of perfect information;\n\u2022\t decision-making-under-uncertainty tech-\nniques [3*, c25] are used when probabil-\nities cannot be assigned to the different \npotential outcomes. Specific techniques \ninclude the Laplace Rule, the Maximin \nRule, the Maximax Rule, the Hurwicz \nRule and the Minimax Regret Rule.\nHigh-consequence decisions may benefit \nfrom formally recording the selected alterna-\ntive and the justification for why that alterna-\ntive was selected.\n2.7. Monitor the Performance of the Selected \nAlternative\b\n[3*, c4pp42-43]\nBecause estimation is a fundamental element \nof engineering decision-making, the quality of \nthe decision depends on the quality of the esti-\nmates. Bad estimates can easily lead to bad deci-\nsions. The software engineer needs to \u201cclose the \nloop\u201d on estimates by comparing them to the \nactual outcomes. Otherwise, no one will ever \nknow if the estimates were good [3*, c21pp356-\n358]. This also helps improve estimation over \ntime. Understanding what drives differences \nbetween estimates and actual outcomes helps \nengineers refine estimation techniques to pro-\nduce more accurate estimates in the future.\n3.\t  For-Profit Decision-Making\nFor-profit decision techniques apply when the \norganization\u2019s goal is profit \u2014 which is the \ncase in most companies.\nFigure 15.4 shows the process for identi-\nfying the financially best alternative out of a set \nof proposals. Arranging alternatives in order of \nincreasing initial investment and then selecting \nstrictly better candidates means that, all other \nconsiderations being equal, the alternative with \nthe smaller initial investment will be chosen. The \n\u201cIs the next candidate strictly better?\u201d decision is \nmade in terms of the appropriate basis for com-\nparison: present worth, future worth, IRR, etc.\n3.1. Minimum Acceptable Rate of Return \n\b\n[3*, c10pp141-143]\nThe minimum acceptable rate of return (MARR) \nis the lowest IRR the organization would \nconsider a good investment. Generally, it \nwould not be wise to invest in an activity \nwith a return of 10% when another activity \nreturns 20%. The MARR is a statement that \nthe organization is confident it can achieve \nat least that rate of return. The MARR rep-\nresents the organization\u2019s opportunity cost \nfor investments. By investing in some alter-\nnative, the organization explicitly decides not \nto invest that same money somewhere else. If \nthe organization is already confident it can \nachieve a known rate of return, alternatives \nshould be chosen only if their rate of return is \nat least that high. A simple way to account for \nthat opportunity cost is to use the MARR as \nthe interest rate in the basis for comparison. \n3.2. Economic Life\b\n[3*, c11pp160-164]\nWhen an organization invests in a partic-\nular alternative, money is tied up in that \n", "page": 296, "type": "text", "section": "Page 296"}
{"text": "15-8   SWEBOK \u00ae GUIDE V4.0\nalternative \u2014 so-called frozen assets. The eco-\nnomic impact of frozen assets typically starts \nhigh and decreases over time. On the other \nhand, operating and maintenance costs tend \nto start low and increase over time. An alter-\nnative\u2019s total cost is the sum of those two \ncosts. At first, frozen asset costs dominate; \nlater, operating and maintenance costs dom-\ninate. At some point, the sum of the two costs \nis minimized; this is the economic life or min-\nimum cost lifetime.\n3.3. Planning Horizon\b\n[3*, c11]\nTo properly compare a proposal with a four-\nyear life to a proposal with a six-year life, the \neconomic effects of either cutting the six-year \nproposal by two years or investing the profits \nfrom the four-year proposal for another two \nyears need to be addressed. The planning \nhorizon, sometimes known as the study period, \nis the consistent time frame over which all \nproposals in the same decision are considered. \nAspects such as economic life and the time \nframe over which reasonable estimates can be \nmade need to be factored into establishing a \nplanning horizon. Once the planning horizon \nis established, several techniques are available \nfor putting proposals with different life spans \ninto that planning horizon.\n3.4. Replacement Decisions \n\b\n[3*, c12pp171-178] [8*, c9]\nA replacement decision happens when an \norganization already has a particular asset and \nis considering replacing it with a different asset \n(e.g., deciding between maintaining and sup-\nporting legacy software or redeveloping it from \nthe ground up). Replacement decisions use the \nsame for-profit decision process, but there are \ntwo additional important considerations: sunk \ncost and salvage value. Replacement does not \nnecessarily need to involve an entire asset. \nTo the extent that an asset can be replaced in \nsmaller increments, the decision-maker can \nconsider incremental replacement options \namong the various economic alternatives.\nStart\nStop\nIs the next\ncandidate strictly\nbetter than the\ncurrent best?\nCompare the next candidate\nto the current best\nAre there\nmore alternatives\nto compare?\nArrange the alternatives\nin order of increasing\ninitial investment\nAssume the frst alternative\nis the current best\nMake that next candidate\nthe new current best\nTe current best is\nthe best overall\nYes\nYes\nNo\nNo\nFigure 15.4. The For-Profit Decision-Making Process\n", "page": 297, "type": "text", "section": "Page 297"}
{"text": "SOFTWARE ENGINEERING ECONOMICS   15-9\n3.5. Retirement Decisions \n\b\n[3*, c12pp178-181] [8*, c9]\nRetirement decisions are about getting out of \nan activity altogether, such as when a soft-\nware company considers not selling a software \nproduct anymore or a hardware manufacturer \nconsiders not building and selling a partic-\nular computer model any longer. Retirement \ndecisions can be preplanned or happen spon-\ntaneously (e.g., when performance targets \nare not achieved). Retirement decisions can \nbe influenced by lock-in factors such as tech-\nnology dependency and high exit costs.\n3.6. Advanced For-Profit Decision \nConsiderations\b\n[3*, c13-17]\nThe above concepts and techniques are often \nsufficient to make a good for-profit decision. \nHowever, particularly when the consequences \nof a wrong decision are high, additional con-\nsiderations may need to be factored into the \ndecision analysis, including the following:\n\u2022\t inflation or deflation;\n\u2022\t depreciation;\n\u2022\t income taxes.\n4.\t  Nonprofit Decision-Making\nThe for-profit decision techniques don\u2019t apply \nwhen the organization\u2019s goal isn\u2019t profit \u2014 \nwhich is the case in government and non-\nprofit organizations. These organizations \nhave a different goal, so different decision \ntechniques are needed. The two techniques \nare benefit-cost analysis and cost-effective-\nness analysis (discussed below).\n4.1. Benefit-Cost Analysis\b [3*, c18pp303-311]\nBenefit-cost analysis is one of the most \nwidely used methods for evaluating pro-\nposals in nonprofit organizations. A propos-\nal\u2019s financial benefits are divided by its costs. \nAny proposal with a benefit-cost ratio of \nless than 1.0 can usually be rejected without \nfurther analysis because it would cost more \nthan it would benefit the organization. \nAdditional considerations are necessary \nwhen two or more proposals are considered \nat the same time.\n4.2. Cost-Effectiveness Analysis \n\b\n[3*, c18pp311-314]\nCost-effectiveness analysis shares much of \nthe philosophy and methodology of bene-\nfit-cost analysis. There are two versions of \ncost-effectiveness analysis. The fixed-cost \nversion seeks to maximize benefit given a \nfixed upper bound on cost. The fixed-effec-\ntiveness version seeks to minimize the cost to \nachieve a fixed goal.\n5.\t  Present Economy Decision-Making\nThis subset of engineering decision-making \nis called present economy because it does not \ninvolve the time-value of money (future \neconomy). The two forms of present economy \ndecisions are presented below.\n5.1. Break-Even Analysis\b\n[3*, c19]\nGiven functions describing the costs of two \nor more proposals, break-even analysis helps \nengineers choose between them by identi-\nfying points where those cost functions are \nequal. Below a break-even point, one pro-\nposal is preferred, and above that point, the \nother is preferred. For example, consider a \nchoice between two cloud service providers. \nOne provider has a lower fixed cost per \nmonth with a higher incremental fee for use, \nwhereas the other has a higher fixed monthly \ncost with a lower incremental fee for use. \nBreak-even analysis identifies the use level \nwhere the costs are the same. The organi-\nzation\u2019s expected use level can be compared \nto the break-even point to identify the low-\ner-cost provider.\n5.2. Optimization Analysis\b\n[3*, c20]\nOptimization analysis studies one or more \ncost functions over a range of values to find the \n", "page": 298, "type": "text", "section": "Page 298"}
{"text": "15-10   SWEBOK \u00ae GUIDE V4.0\npoint where overall cost is lowest. Software\u2019s \nclassic space-time trade-off is an example of \noptimization; an algorithm that runs faster \noften uses more memory. Optimization bal-\nances the value of faster run time against the \ncost of the additional memory. \n6.\t  Multiple-Attribute Decision-Making \n\b\n[3*, c26]\nMost topics presented in this KA so far have \ndiscussed decisions based on a single cri-\nterion \u2014 money. The alternative with the \nbest present worth, the best incremental \nIRR, the best incremental benefit-cost ratio, \netc., is the one selected. Aside from tech-\nnical feasibility, money is usually the most \nimportant decision criterion, but it\u2019s cer-\ntainly not always the only one. Often, other \ncriteria, other \u201cattributes,\u201d need to be con-\nsidered that can\u2019t be cast in terms of money. \nMultiple-attribute decision-making tech-\nniques allow nonmonetary criteria to be fac-\ntored into the decision.\nA variety of techniques can be used to \naddress multiple criteria, including nonmon-\netary criteria. These techniques fall into two \ncategories.\n6.1. Compensatory Techniques \n\b\n[3*, c26pp449-458]\nAlso called single-dimensioned techniques, the \ntechniques in this category collapse all criteria \ninto a single figure of merit. This category is \ncalled compensatory because, for any given \nalternative, a lower score in one criterion can \nbe compensated by \u2014 traded off against \u2014 a \nhigher score in other criteria. Compensatory \ntechniques include nondimensional scaling, \nadditive weighting and analytic hierarchy \nprocess (AHP).\nGilb\u2019s Impact Estimation [11] and the \nSoftware \nEngineering \nInstitute\u2019s \n(SEI) \nArchitectural Tradeoff Analysis Method \n(ATAM) [12] are examples of compensa-\ntory \nmultiple-attribute \ndecision-making \ntechniques focused on identifying the best \nsoftware design.\n6.2. Non-Compensatory Techniques \n\b\n[3*, c26pp447-449]\nAlso called fully dimensioned techniques, the \ntechniques in this category do not allow trade-\noffs among the criteria. Each criterion is \ntreated as a separate entity in the selection pro-\ncess. Non-compensatory techniques include \ndominance, satisficing and lexicography.\n7.\t  Identifying and Characterizing \nIntangible Assets\nThe intangible side of an organization is the \nvaluable knowledge residing within it. This \nincludes employees\u2019 knowledge about pro-\ncesses, structures, procedures, etc. (tacit, or \nimplicit, knowledge), as well as institutional \nknowledge recorded in various organizational \nresources (explicit knowledge). These assets \nare usually hidden, the way most of an iceberg \nis underwater. The intangible assets must be \nexplicitly considered in many decisions, par-\nticularly when the consequences of a wrong \ndecision are high for the client, no matter if \nthe client is internal or external to the orga-\nnization for which the software project is \nbeing done.\nIf these assets are not adequately consid-\nered, software engineers risk developing a \nsoftware solution that does not fit the client \norganization. Only when the intangible \nassets are explicitly considered will the risk \nof a poorly fitting software solution be min-\nimized. The Strategic Intangible Process \nAssets Characterization (SIPAC) method \n[13] has been used to good effect to accom-\nplish this. SIPAC steps are outlined in the \nfollowing subsections.\n7.1. Identify Processes and Define Business Goals\nStart by understanding the organization\u2019s \nbusiness processes and business goals. If the \norganization has well-documented processes, \nthese should be used; otherwise, a deliberate \nsurvey will be necessary.\nBusiness goals can include, but are not lim-\nited to, the following:\n", "page": 299, "type": "text", "section": "Page 299"}
{"text": "SOFTWARE ENGINEERING ECONOMICS   15-11\n1.\t maintaining growth and continuity of \nthe organization;\n2.\t meeting financial objectives;\n3.\t meeting responsibility to employees;\n4.\t meeting responsibility to society;\n5.\t\nmanaging market position.\n7.2. Identify Intangible Assets Linked with \nBusiness Goals\nThe next step is to comprehensively iden-\ntify the intangible assets. Common examples \nare policies, documented business processes, \nchecklists, lessons learned, templates, stan-\ndards, procedures, plans and training mate-\nrials. Organizations develop or acquire these \nassets to meet their business goals. The assets \nrepresent investments that provide business \nvalue. One effective approach to identifying \nan organization\u2019s intangible assets is to start \nwith a taxonomy such as described in the fol-\nlowing reference [14]. The goal is to identify as \nmany intangible assets as possible that serve \nas a lever to achieve the business goals iden-\ntified in the previous step. In practice, this \ncan be an iterative process where reviewing \nthe already-identified assets reveals the exis-\ntence of others. A practical way to do it is by \nfocusing iteratively on the 11 generic intan-\ngible assets (GIAs) described in [6].\nPossible GIAs represent all potential parts \nof any business that can be involved in a dig-\nital transformation. Focusing on one or more \nof them allows the software engineer to better \nunderstand and frame the project\u2019s impact. \nFocusing iteratively on the 11 GIAs, the soft-\nware engineer will select the type of GIA to \nbe considered and, with this, elicit the specific \nintangible assets associated with each GIA.\nIn addition to identifying specific intan-\ngible assets, a qualitative relative \u201cimportance\u201d \nmust be added to each one as it is identified. \nThe importance is a value between 1 and 5 (1 \nfor lower importance and 5 for higher impor-\ntance), depending on how well the asset sup-\nports achieving the business objectives. The \nintangible assets with the highest importance \nare likely the most suitable target for the client \norganization.\n7.3. Identify Software Products That Support \nIntangible Assets \nSoftware products that support specific intan-\ngible assets will be part of the digital transfor-\nmation proposal to be presented to the client \nto help them decide what digital transforma-\ntion to implement.\nTo identify products related to specific \nintangible assets, the software engineer can \nchoose from the following:\n\u2022\t discovering them all at a single time by \nusing the methodology of Osterwalder \n[13], which promotes innovation by gen-\nerating a value map with the stakeholders\u2019 \nemerging needs, mapping the products to \nthe specific intangible assets;\n\u2022\t listing them if they are known and then \nmapping them to specific intangible assets;\n\u2022\t iteratively working with the individual \nintangible assets by (1) selecting a spe-\ncific intangible asset and (2) identifying \nthe products, continuing until all specific \nintangible assets have been analyzed.\nA single product can support more than one \nspecific intangible asset, and each specific intan-\ngible asset can be supported by many products.\n7.4. Define and Measure Indicators\nThis step defines and measures the indica-\ntors that will be used to characterize how the \nintangible assets (through the software prod-\nucts that support those intangible assets) help \nmeet business goals through describing, imple-\nmenting or improving the identified products. \nQuality indicators assess specific intangible \nasset characteristics or features. Impact indi-\ncators assess how much the specific intangible \nassets contribute to processes or business goals.\nIndicators must be normalized and stan-\ndardized to operate correctly. \n7.5. Intangible Asset Characterization\nBased on the information gathered, the soft-\nware engineer determines the value of the \n", "page": 300, "type": "text", "section": "Page 300"}
{"text": "15-12   SWEBOK \u00ae GUIDE V4.0\nidentified specific intangible assets based \non their quality and impact. Specific \nintangible assets may be characterized in \nterms of their impact on business goals \nand their quality as organizational assets. \nThere are three important characteriza-\ntion cases:\n\u2022\t case 1: specific intangible assets with both \nimpact and quality indicators (Warning, \nReplaceable, Evolving or Stable);\n\u2022\t case 2: specific intangible assets with only \nquality indicators (Acceptable Quality or \nUnacceptable Quality);\n\u2022\t case 3: specific intangible assets with only \nimpact indicators (Acceptable Impact or \nUnacceptable Impact).\nThe three characterization cases are shown \nin Figure 15.5. The quadrants represent the \n\u201cstates\u201d constituting different levels of char-\nacterization. The lines separating the quad-\nrants are thresholds of impact and quality that \ndefine the point at which the impact or quality \nof a specific intangible asset may be considered \nacceptable or not for each organization. These \nthresholds are established for every client \norganization and specify what level of orga-\nnizational performance, quality, and impact \nthey will demand from their knowledge/\nintangible assets. Thresholds are used to deter-\nmine when quality and/or impact are accept-\nable or unacceptable. Let\u2019s look at an example \nof how to interpret Qval and Ival (both Qval \nand Ival will be explained in the following \nsections). Assuming, for example, that we are \nanalyzing the status of an intangible asset with \nboth quality and impact indicators, and that \nQval is below the quality threshold and Ival \nis below the impact threshold. In these cir-\ncumstances we would say that the status of the \nintangible asset is \u201cwarning\u201d as can be seen in \nFigure 15.5.\nThe characterization uses information from \nstandardized-normalized indicators to assess \nthe identified intangible assets. This assess-\nment generates a descriptive value that will \ndetermine the asset\u2019s general state of health \nfrom a quantitative perspective. \nQuality quantitative assessment\nThe quality valuation considers only the \nindicators of the type quality of an intan-\ngible asset and calculates a general valua-\ntion of it. To evaluate the subset of quality \nindicators, given a set of q quality indica-\ntors for an intangible asset n, the valua-\ntion of the quality is given according to \nEquation 1.\nQ        =\nq\ni=1 X n\nn\ni\nq\n\u2211\nVal\nEquation 1. Quality Assessment for a \nKnowledge Asset\nWhere X n\ni  is each of the q normalized indica-\ntors of quality that the intangible asset n has.\nAbove, Qval is the average of the normal-\nized values of the quality indicators of a cor-\nresponding specific intangible asset.\nImpact quantitative assessment\nAn intangible asset\u2019s impact valuation is an \nassessment that considers only the normal-\nized indicators that are classified as \u201cimpact\u201d \nindicators. To evaluate the subset of impact \nindicators, given a set of p normalized impact \nindicators for an intangible asset n, the valua-\ntion is given as stated in Equation 2:\n \nI n\nVal = \u2211\np\ni = \n1Z n\ni\np\nEquation 2. Impact Assessment for a Specific \nIntangible Asset\nWhere Zn\ni  is each of the p normalized indica-\ntors of impact that the knowledge asset n has.\nWhere Ival is the average of the normal-\nized values of the impact indicators of a corre-\nsponding knowledge asset.\nLinear value calculation\nFinally, the linear value of an intangible asset \ncharacterization is given by the impact and \n", "page": 301, "type": "text", "section": "Page 301"}
{"text": "SOFTWARE ENGINEERING ECONOMICS   15-13\nquality valuations (Qval and Ival), following \nthese rules, assuming that both quality and \nimpact are equally important, so KAval (the \nvaluation of the intangible asset) is given by:\nIf \n \n\u00a0Qval\nIval, then\nKAval = Qval + Ival\nIf \u00a0Qval\n\u00a0Ival, then\nKAval = Qval\n2\nIval, then\nIf \nQval\nKAval = Ival\n \nThis linear value represents an intangible \nasset\u2019s general state based on the state of its \nindicators. It uses the algebraic mean of the \nstandardized and normalized indicators to \nrepresent the assets\u2019 general state on a scale \n[-1, 1] and based on the corresponding inter-\npretation thresholds. If no threshold is explic-\nitly mentioned, the linear value is interpreted \nas follows, if the value is 0, then the intan-\ngible asset is on the target, if the value is 1, it \nmeans that the intangible asset is 100% over \nthe target and if the value is -1 then the intan-\ngible asset is -100% under the target.\n7.6. Link Specific Intangible Assets with the \nBusiness Model\nVisualizing \nthe \nclient \nbusiness \nmodel, \nenriched with the intangible assets status \nallocated into that model, gives organiza-\ntional leadership a clear understanding of the \nimportant relationships among proposed soft-\nware solutions, intangible assets, the business \nmodel and the business goals. The software \nengineer can clearly show which proposed \nsolution generates the most value for the busi-\nness. An example is shown in [6].\n7.7. Decision-Making\nThe next step in the decision-making process \nis to prioritize and choose the software prod-\nucts that interest the client organization most. \nThere is no simple rule; several criteria must \nbe considered:\n\u2022\t the intangible asset\u2019s impact on business \ngoals (defined in previous steps);\n\u2022\t the characterization reached (defined in \nprevious steps);\n\u2022\t the impact of intangibles assets status on \nthe competitors of the organization under \nimprovement;\n\u2022\t the intangible asset\u2019s impact on the busi-\nness model;\n\u2022\t cost to implement the products;\n\u2022\t time to implement the products;\n\u2022\t complexity of the products.\nAll criteria must be considered to decide \nwhat software products should be developed \nfor the client organization, making this a \nmultiple-attribute decision. (See 6., Multiple-\nAttribute Decision-Making.)\nUpon considering all relevant criteria, \nthe organization can see the risks of imple-\nmenting a software solution to automate pro-\ncesses that are either not very valuable or not \nin good shape. Instead, the software engi-\nneer can offer, in a transparent way, proposals \nthat better satisfy the organization\u2019s busi-\nness needs.\nThis approach can be useful whenever an \nengineering decision needs to be made, but it \nis particularly critical in the pre-project stage \nwhen there is a need to present the client \norganization with proposals that are best for \nbusiness value.\n8.\t  Estimation\b\n[3*, c21-26]\nAn estimate analytically predicts some quan-\ntity, like a project\u2019s size, cost or schedule. \nMany other quantities are also estimated in \nsoftware engineering, such as the average \nnumber of active client sessions a cloud ser-\nvice needs to support, the number of times a \nfunction will be called during execution of a \nsection of code, or the number of delivered \ndefects in a software product.\nSoftware engineers do not estimate purely \nfor the sake of estimating. Software engi-\nneers estimate to make decisions when critical \nquantities are unknown. For example, a deci-\nsion to buy a functionality or build it within \n", "page": 302, "type": "text", "section": "Page 302"}
{"text": "15-14   SWEBOK \u00ae GUIDE V4.0\nthe organization would certainly be based on \nthe cost of building it. But the actual cost of \nbuilding it cannot be precisely known until \nthe organization does build it. Key informa-\ntion needed to make engineering decisions is \nusually not known when those decisions need \nto be made. Instead, decisions are based on \nestimates. Behind every estimate is one or \nmore decisions.\nGiven that estimates are predictions, there \nis a nonzero probability that the actual out-\ncome will differ from the estimate. All esti-\nmates are inherently uncertain. Sometimes, \nthe uncertainty is large, and sometimes it is \nsmall. But it is always there. Fortunately, esti-\nmates need not be perfect; they need only to \nbe good enough to lead the decision-maker to \nmake the right decision.\nThe Software Engineering Code of Ethics \nand Professional Practice [16] states, \u201c3.09. \nEnsure realistic quantitative estimates of cost, \nscheduling, personnel, quality and outcomes \non any project on which they work or propose \nto work and provide an uncertainty assess-\nment of these estimates\u201d (underlining added \nfor emphasis). (See [3*, c21pp358-361].)\nEstimation is covered extensively in [17], \n[18] and [3*]. Several general techniques exist, \nand each is overviewed here. All specific esti-\nmation techniques use one or a combination \nof these general techniques.\n8.1. Expert Judgment\b\n[3*, c22pp367-369]\nIn expert judgment estimation, the estimate \nis based purely on the estimator\u2019s professional \nopinion. It is the simplest technique and is \nalways available, and it is particularly useful \nwhen the other techniques aren\u2019t available. The \ndownside is that this technique produces the \nleast accurate estimates. Multiple expert judg-\nment estimates can be fed into group estimation \nprocesses like Wide Band Delphi and Planning \nPoker to produce more accurate estimates.\nCase 2:\nOnly Quality Indicators\nAcceptable\nQuality\nUnacceptable\nQuality\nWarning\nEvolving\nUnacceptable\nImpact\nAcceptable\nImpact\nCase 3:\nOnly Impact\nIndicators\nReplaceable\nStable\nQuality\nTreshold\nCase 1:\nQuality and Impact Indicators\nImpact Treshold\nFigure 15.5. Extended Characterization of Specific Intangible Assets\n", "page": 303, "type": "text", "section": "Page 303"}
{"text": "SOFTWARE ENGINEERING ECONOMICS   15-15\n8.2. Analogy\b\n[3*, c22pp369-371]\nEstimation by analogy assumes that if the \nthing estimated is similar to something \nalready known, then the estimate for the \nnew thing can be based on the actual result \nfor the similar thing, with allowances for rel-\nevant differences. The steps in estimation by \nanalogy are as follows:\n1.\t Understand the thing to be estimated.\n2.\t Find a suitable analogy for which actual \nresults are known.\n3.\t List differences between the thing being \nestimated and the analogy that could sig-\nnificantly affect the outcome.\n4.\t Estimate the magnitude of each identi-\nfied difference.\n5.\t\nBuild the estimate from the analogy\u2019s \nactual result and adjustments for the \nidentified differences.\nEstimation by analogy produces more \naccurate results than expert judgment, and it \nis still relatively quick and easy. On the other \nhand, an appropriate analogy for which accu-\nrate results are known must be available for \nthis approach to work.\n8.3. Decomposition\b\n[3*, c22pp371-374]\nSometimes called bottom-up estimation, the \nsteps in estimation by decomposition are:\n1.\t Break the thing to be estimated into suc-\ncessively smaller pieces until the smallest \npieces can be reasonably estimated.\n2.\t Estimate those smallest pieces.\n3.\t Add up the estimates for the smallest \npieces to build the estimate for the whole.\n4.\t\nIf the estimates for the smallest pieces don\u2019t \ninclude allowances for significant cross-cut-\nting factors, then find a way to address \nthose factors. For example, when estimating \na software project from its design, the esti-\nmates for the design elements may not \ninclude allowances for requirements work, \nintegration work, testing work and user \ndocumentation work.\nEstimation by decomposition assumes \nthat overestimates of lowest-level pieces will \ncancel out corresponding underestimates of \nother pieces and lead to a more accurate esti-\nmate of the whole. The primary disadvantages \nare the following:\n\u2022\t  it can be a lot more work than any other \ntechnique;\n\u2022\t  if the bottom-level estimates are biased \neither high or low, the canceling effect \ndoesn\u2019t happen.\n8.4. Parametric\b\n[3*, c22pp374-377]\nAlso called estimation by statistical methods, \nparametric estimation takes advantage of a \nknown, mathematical relationship between \nthe thing being estimated and one or more \nobservable factors about that thing, like cal-\nculating the cost to build a building as a func-\ntion of its floor space. The estimation model is \nan equation: First, count the observable fac-\ntors, and then plug them into the equation to \nget the resulting estimate.\nParametric estimates are typically the most \naccurate, the most defendable and the easiest \nto use, provided the equation has been devel-\noped and validated. The disadvantage is that \ndeveloping and validating such an equation \nrequires an adequate base of accurate histor-\nical data along with some nontrivial mathe-\nmatics and statistics.\n8.5. Multiple Estimates \n\b\n[3*, c22pp377-379]\nWhen the consequences of a wrong decision \nare small, it can be acceptable to base the deci-\nsion on a single estimate from a single estimator \nusing a single estimation technique. However, \nwhen the consequences of a wrong decision are \nsignificant, investing extra effort in developing \nmore than one estimate can be worthwhile.\nTo use this approach, engineers estimate the \nsame thing using different techniques, pos-\nsibly by different estimators. Then, they look \nfor convergence or divergence among those \nmultiple estimates. Convergence suggests \n", "page": 304, "type": "text", "section": "Page 304"}
{"text": "15-16   SWEBOK \u00ae GUIDE V4.0\nthe individual estimates are probably accu-\nrate, and any of them could be used to make \nthe decision. Divergence suggests that one or \nmore important factors might have been over-\nlooked. Finding the factors that caused the \ndivergence and reestimating to produce con-\nverging results often lead to a better estimate \nand thus a better decision.\n9.\t  Practical Considerations\n9.1. Business Case\nThe business case is the consolidated, doc-\numented \ninformation \nsummarizing \nand \nexplaining a recommended business decision \nfrom different perspectives (cost, benefit, risk \nand so on) for a decision-maker and other rel-\nevant stakeholders. It\u2019s used to assess a prod-\nuct\u2019s potential value, which can be used as a \nbasis for an investment decision.\n9.2. Multiple-Currency Analysis \nWhen a decision analysis involves cross-\nborder finances, currency exchange rate varia-\ntions may need to be considered. This is often \ndone using historical data.\n9.3. Systems Thinking\nThe ecosystem in which software engineers \ndevelop their professional life is complex. To \nunderstand the whole picture around a client \norganization and form a holistic view of the \nscenarios they analyze, software engineers \ncan use systems thinking methodologies. This \napproach helps the software engineer create a \ncomplete set of possible scenarios in which the \nsoftware to be provided could be useful and, \nwith this information, explain to the client \nhow the software solution can be a value pro-\nvider for the organization. Sources for system \nthinking methodologies are Understanding \nSystems \nSystems \nInnovation \n[19] \nand \nBusiness Dynamics: Systems Thinking and \nModeling for a Complex World [20]. A way \nto connect systems thinking methodologies \nwith the development of a business model to \nunderstand the pillars of the client organiza-\ntion can be reached here [21].\n10.\t Related Concepts \nThis topic includes concepts the software \nengineer may want to bear in mind.\n10.1. Accounting\b\n[3*, c15pp234-245]\nAccounting is part of finance. It allows people \nwhose money is used to run an organization \nto know the results of their investment: Did \nthey get the profit they were expecting? In for-\nprofit organizations, this relates to the tangible \nreturn on investment (ROI), while in nonprofit \nand governmental organizations, as well as for-\nprofit organizations, it translates into sustain-\nably staying in business. Accounting\u2019s primary \nrole is to measure the organization\u2019s actual \nfinancial performance and to communicate \nfinancial information about a business entity \nto stakeholders, such as shareholders, finan-\ncial auditors and investors. Communication \ngenerally takes the form of financial state-\nments showing the economic resources to be \ncontrolled. The right information \u2014 relevant \nand reliable to the user \u2014 must be presented. \nInformation and its timing are partially gov-\nerned by risk management and governance \npolicies. Accounting systems are also a rich \nsource of historical data for estimating.\nSoftware engineers must be conscious of \nthe software\u2019s importance as a driver of busi-\nness accounts in the digital era.\n10.2. Cost and Costing\b\n[3*, c15pp245-259]\nA cost is the money used to produce some-\nthing and, hence, is no longer available for \nuse. In economics, a cost is an alternative that \nis given up as a result of a decision. \nSunk cost refers to unrecoverable expenses \nthat have occurred, which can cause emotional \nhurdles looking forward. From a traditional \neconomics viewpoint, sunk costs should not be \nconsidered in decision-making. Opportunity \ncost is the cost of an alternative that must be \nforgone to pursue another alternative.\n", "page": 305, "type": "text", "section": "Page 305"}
{"text": "SOFTWARE ENGINEERING ECONOMICS   15-17\nCosting is part of finance and product \nmanagement. It is the process of determining \nthe cost based on expenses (e.g., production, \nsoftware engineering, distribution, rework) \nand on the target cost to be competitive and \nsuccessful in a market. The target cost can be \nbelow the actual estimated cost. The plan-\nning and controlling of these costs (called cost \nmanagement) is important and should always \nbe included in costing. \nAn important concept in costing is the \ntotal cost of ownership (TCO). This holds \ntrue especially for software because there are \nmany not-so-obvious costs related to SPLC \nactivities after initial product development. \nTCO for a software product is defined as the \ntotal cost for acquiring that product, acti-\nvating it and keeping it running. These costs \ncan be grouped as direct and indirect costs. \nTCO is an accounting method that is crucial \nin making sound economic decisions. \n10.3. Finance\nFinance is the branch of economics concerned \nwith allocating, managing, acquiring and \ninvesting resources. Finance is an element of \nevery organization, including software engi-\nneering organizations.\nThe field of finance deals with the concepts \nof time, money, and risk, and how they are \ninterrelated. It also deals with how money is \nspent and budgeted. Corporate finance is con-\ncerned with funding an organization\u2019s activ-\nities. Generally, this involves balancing risk \nand profitability while attempting to maxi-\nmize an organization\u2019s wealth and the value \nof its stock. This applies primarily to for-profit \norganizations but also to nonprofit organiza-\ntions. The latter needs finances to ensure sus-\ntainability, if not to make a tangible profit. To \ndo this, an organization must:\n\u2022\t identify organizational goals, time hori-\nzons, risk factors, tax considerations and \nfinancial constraints;\n\u2022\t identify and implement the appropriate \nbusiness strategy, such as which port-\nfolio and investment decisions to take, \nhow to manage cash flow and where to \nget the funding;\n\u2022\t measure financial performance, such as \ncash flow and ROI, and take corrective \nactions in case of deviation from objec-\ntives and strategy.\nProvided that many organizations use \nsoftware development or acquisition to stay \ncompetitive, the software engineer must be \nconscious of the importance of software to \nbusiness finances.\n10.4. Controlling\nControlling is the element of finance and \naccounting that involves measuring and \ncorrecting performance. It ensures that an \norganization\u2019s objectives and plans are accom-\nplished. Controlling cost is a specialized \nbranch of controlling used to detect variances \nof actual costs from planned costs.\nIn software engineering, this concept is \nreferred to as processes and products con-\ntrol and evolution. While the organization \nis seen as an entity with its own goals, and \ncontrol of the organizational goals is seen as \nseparate, software engineers must consider \ncontrol of the organization part of their job \nby ensuring alignment of their software with \nbusiness goals.\n10.5. Efficiency and Effectiveness \n\b\n[10*, c22pp422-23]\nEconomic efficiency of a process, activity or task \nis the ratio of resources consumed to resources \nexpected to be consumed. Efficiency means \n\u201cdoing things right.\u201d An efficient behavior, \nlike an effective behavior, delivers results and \nminimizes effort. Factors affecting efficiency \nin software engineering include product com-\nplexity, quality requirements, time pressure, \nprocess capability, team distribution, inter-\nruptions, feature churn, tools and program-\nming language. \nEffectiveness is about having impact. It is \nthe relationship between achieved objectives \nand defined objectives. Effectiveness means \n", "page": 306, "type": "text", "section": "Page 306"}
{"text": "15-18   SWEBOK \u00ae GUIDE V4.0\n\u201cdoing the right things.\u201d Effectiveness looks \nonly at whether defined objectives are reached \n\u2014 not at how they are reached.\n10.6. Productivity\b\n[10*, c23pp689]\nProductivity is the ratio of output to input \nfrom an economic perspective. Output is the \nvalue delivered. Input covers all resources \n(e.g., effort) spent to generate the output. \nProductivity combines efficiency and effec-\ntiveness from a value-oriented perspective. \nMaximizing productivity is about generating \nthe highest value with the lowest resource \nconsumption.\nThe Guide to the Project Management \nBody of Knowledge [23] defines rework as \n\u201caction taken to bring a defective or noncon-\nforming component into compliance with \nrequirements or specifications.\u201d It is worth \nnoting that most software organizations are \nunaware that the single largest resource con-\nsumer is, in fact, rework.  In many software \nprojects the cost of rework is higher than \nthe cost of all other project activities com-\nbined. The most effective way to increase \nproductivity can be to simply reduce rework. \nReducing software project rework involves \nproactive quality improvement actions (see \nChapter 12, Software Quality KA) that either \na) identify defects earlier so those defects can \nbe  fixed at lower resource cost, b) reduce the \ndegree of defect cost growth (e.g., intention-\nally simpler code is easier to modify than \ncomplex code so actively managing and con-\ntrolling code complexity reduces the cost of \ndefect repair), and c) prevent defects in the \nfirst place by, for example, using appropriate \ntemplates and checklists in development and \nmaintenance.\n10.7. Product or Service\nA product is a tangible economic good (or \noutput) created in a process that transforms \nproduct factors (or inputs) into an output. \nA service is an intangible resource, like con-\nsulting. When sold, a product or service is a \ndeliverable that creates both a value and an \nexperience for its consumers. A product or \nservice can be a combination of systems, solu-\ntions and materials delivered internally (e.g., \nan in-house IT solution) or externally (e.g., a \nsoftware application), either as is or as a com-\nponent for another product (e.g., embedded \nsoftware). \n10.8. Project\b\n[22*, c2s2.4]\nA project is \u201ca temporary endeavor undertaken \nto create a unique product, service, or result\u201d \n[24]. In software engineering, different \nproject types are distinguished (e.g., product \ndevelopment, outsourced services, software \nmaintenance, service creation, and so on). \nDuring its life cycle, a software product may \nrequire many projects. For example, during \nthe product conception phase, a project might \nbe conducted to determine customer need and \nmarket requirements; during maintenance, \na project might be conducted to produce the \nnext version of a product.\n10.9. Program\nA program is \u201ca group of related projects, sub-\nprograms, and program activities managed \nin a coordinated way to obtain benefits not \navailable from managing them individually\u201d \n[24]. Programs are often used to identify and \nmanage different deliveries to a single cus-\ntomer or market over a time horizon of sev-\neral years. \n10.10. Portfolio\nPortfolios are \u201cprojects, programs, sub-portfo-\nlios, and operations managed as a group to \nachieve strategic objectives\u201d [24]. Portfolios \nare used to group and then manage simul-\ntaneously all assets within a business line \nor organization. Having an entire portfolio \nto consider helps ensure that the broader \nimpacts of decisions are considered, such as \nthe decision to allocate resources to a specific \nproject, which means that the same resources \nwill not be available for the other projects in \nthe portfolio.\n", "page": 307, "type": "text", "section": "Page 307"}
{"text": "SOFTWARE ENGINEERING ECONOMICS   15-19\n10.11. Product Life Cycle\nAn SPLC includes all activities needed to \ndefine, build, operate, maintain and retire a \nsoftware product or service and its variants. \nThe SPLC activities of \u201coperate,\u201d \u201cmain-\ntain\u201d and \u201cretire\u201d occur in a much longer \ntime frame than initial software develop-\nment (the software development life cycle \n(SDLC)). (See Software Life Cycle Models \nin the Software Engineering Process KA.) \nAlso, the operate-maintain-retire activi-\nties of an SPLC consume more total effort \nand other resources than the SDLC activi-\nties. (See Majority of Maintenance Costs in \nthe Software Maintenance KA.) The value \ncontributed by a software product or associ-\nated services can be objectively determined \nduring the \u201coperate and maintain\u201d time \nframe. Software engineering economics \nshould be concerned with all SPLC activ-\nities, including activities that take place \nafter the initial product release.\n10.12. Project Life Cycle\nProject life cycle activities typically involve \nfive process groups: Initiating, Planning, \nExecuting, Monitoring and controlling, \nand Closing [23]. (See the Software \nEngineering Management KA.) The activ-\nities within a software project life cycle \nare often interleaved, overlapped and iter-\nated in various ways [20*, c2] [25]. (See \nthe Software Engineering Process KA.) \nFor instance, Agile product development \nwithin an SPLC involves multiple itera-\ntions that produce increments of deliver-\nable software. An SPLC should include \nrisk management and synchronization \nwith different suppliers (if any) while pro-\nviding auditable decision-making informa-\ntion (e.g., to comply with product liability \nneeds or governance regulations). The soft-\nware project life cycle and the SPLC are \ninterrelated; an SPLC may include sev-\neral SDLCs.\n10.13. Price and Pricing\b\n[10*, c23s23.1]\nA price is what is paid in exchange for a good or \nservice. Price is a fundamental aspect of finan-\ncial modeling and is one of the four Ps of the \nmarketing mix. The other three Ps are product, \npromotion and place. Price is the only reve-\nnue-generating element among the four Ps; the \nrest are costs.\nPricing is an element of finance and mar-\nketing. It determines what a company will \nreceive in exchange for its products. Pricing \nfactors include manufacturing cost, market \nplacement, competition, market condition and \nproduct quality. Pricing applies prices to prod-\nucts and services based on factors such as fixed \namount, quantity break, promotion or sales \ncampaign, specific vendor quote, shipment or \ninvoice date, combination of multiple orders, \nservice offerings, and many others. The con-\nsumer\u2019s needs can be converted into demand \nonly if the consumer has the willingness and \ncapacity to buy the product. Thus, pricing is \ncrucial in marketing. Pricing is initially done \nduring the project initiation phase and is a part \nof the \u201cgo\u201d decision-making process.\n10.14. Prioritization\nPrioritization involves ranking alternatives \nbased on common criteria to deliver the best \nvalue. For example, in software engineering \nprojects, software requirements are often pri-\noritized to deliver the most value to the client \nwithin the constraints of schedule, budget, \nresources, and technology, or to allow the team \nto build the product in increments, where the \nfirst increments provide the highest value to \nthe customer. (See Requirements Prioritization \nin the Software Requirements KA and \nSoftware Life Cycle Models in the Software \nEngineering Process KA.) Prioritizing alter-\nnatives is at least implicit in the discussion \nin 2.6., Select the Preferred Alternative, but \nis explicit when a compensatory technique is \nused, as described in 7.6., Multiple-Attribute \nDecision-Making.\n", "page": 308, "type": "text", "section": "Page 308"}
{"text": "15-20   SWEBOK \u00ae GUIDE V4.0\nMATRIX OF TOPICS VS. REFERENCE MATERIAL \nTockey 2005 \n[3*]\nSommerville  \n2016 [10*]\nFairley 2009 \n [22*]\n1. Software Engineering Economics \nFundamentals\n1.1. Proposals\nc3pp23-24\n1.2. Cash Flow\nc3pp24-32\n1.3. Time-Value of Money\nc5-6\n1.4. Equivalence\nc7\n1.5. Bases for Comparison\nc8\n1.6. Alternatives\nc9\n1.7. Intangible Assets\n1.8. Business Model\n2. The Engineering Decision-\nMaking Process\n2.1. Process Overview\nc4pp35-36\n2.2. Understand the Real Problem\nc4pp37-39\n2.3. Identify All Reasonable Technically  \nFeasible Solutions\nc4pp40-41\n2.4. Define the Selection Criteria\nc4pp39-40, \nc26pp441-442\n2.5. Evaluate Each Alternative Against the \nSelection Criteria\nc4pp41-42\n2.6. Select the Preferred Alternative\nc4p42, \nc26pp447-458\n2.7. Monitor the Performance of the Selected  \nAlternative\nc4pp42-43\n3. For-Profit Decision-Making\n3.1. Minimum Acceptable Rate of Return \nc10pp141-143\n3.2. Economic Life\nc11pp160-164\n3.3. Planning Horizon\nc11\n3.4. Replacement Decisions\nc12pp171-178 c9\n3.5. Retirement Decisions\nc12pp178-181 c9\n3.6. Advanced For-Profit Decision Considerations\nc13-17\n4. Nonprofit Decision-Making\n4.1. Benefit-Cost Analysis\nc18pp303-311\n4.2. Cost-Effectiveness Analysis\nc18pp311-314\n5. Present Economy Decision-Making\n", "page": 309, "type": "text", "section": "Page 309"}
{"text": "SOFTWARE ENGINEERING ECONOMICS   15-21\n5.1. Break-Even Analysis\nc19\n5.2. Optimization Analysis\nc20\n6. Multiple-Attribute Decision-Making\n6.1. Compensatory Techniques\nc26pp449-458\n6.2. Non-Compensatory Techniques\nc26pp447-449\n7. Identifying and Characterizing \nIntangible Assets\n7.1. Identify Processes and Define Business Goals\n7.2. Identify Intangible Assets Linked with \nBusiness Goals\n7.3. Identify Software Products That Support \nIntangible Assets\n7.4. Define and Measure Indicators\n7.5. Intangible Asset Characterization\n7.6. Link Specific Intangible Assets with the \nBusiness Model\n7.7. Decision-Making\n8. Estimation\n8.1. Expert Judgment\nc22pp367-369\n8.2. Analogy\nc22pp369-371\n8.3. Decomposition\nc22pp371-374\n8.4. Parametric\nc22pp374-377\n8.5. Multiple Estimates\nc22pp377-379\n9. Practical Considerations\n9.1. Business Case\n9.2. Multiple-Currency Analysis\n9.3. Systems Thinking\n10. Related Concepts\n10.1. Accounting\nc15pp234-245\n10.2. Cost and Costing\nc15pp245-259\n10.3. Finance\n10.4. Controlling\n10.5. Efficiency and Effectiveness\nc22pp422-23\n10.6. Productivity\nc23pp689\n10.7. Product or Service\n10.8. Project\nc2s2.4\n", "page": 310, "type": "text", "section": "Page 310"}
{"text": "15-22   SWEBOK \u00ae GUIDE V4.0\n10.9. Program\n10.10. Portfolio\n10.11. Product Life Cycle\n10.12. Project Life Cycle\n10.13. Price and Pricing\nc23s23.1\n10.14. Prioritization\nFURTHER READINGS\nProject Management Institute, A Guide to \nthe Project Management Body of Knowledge \n(PMBOK\u00ae Guide) [24].\nThe PMBOK\u00ae Guide provides guidelines for \nmanaging individual projects and defines \nproject management-related concepts. It \nalso describes the project management life \ncycle and its related processes, as well as \nthe project life cycle. It is a globally rec-\nognized guide for the project management \nprofession.\nProject Management Institute and IEEE \nComputer Society, Software Extension to \nthe Guide to the Project Management Body of \nKnowledge (SWX) [25].\nSWX provides adaptations and extensions to \nthe generic practices of project management \ndocumented in the PMBOK\u00ae Guide for man-\naging software projects. The primary con-\ntribution of this extension to the PMBOK\u00ae \nGuide is its description of processes that are \napplicable to managing adaptive life cycle \nsoftware projects.\nB.W. \nBoehm, \nSoftware \nEngineering \nEconomics [26]. \nThis book is classic reading on software engi-\nneering economics. It provides an overview \nof business thinking in software engineering. \nAlthough the examples and figures are dated, \nit is still worth reading.\nC. \nEbert \nand \nR. \nDumke, \nSoftware \nMeasurement [27]. \nThis book provides an overview of quantita-\ntive methods in software engineering, starting \nwith measurement theory and proceeding \nto performance management and business \ndecision-making.\nD.J. Reifer, Making the Software Business \nCase: Improvement by the Numbers [28]. \nThis book is classic reading on making a busi-\nness case in software and IT industries. Many \nuseful examples illustrate how the business \ncase is formulated and quantified. \nREFERENCES\n[1]\t E. DeGarmo et al., Engineering \nEconomy, 9th ed., Englewood Cliffs, \nNJ: Prentice Hall, 1993.\n[2]\t P. Rodriguez, C. Urquhart, and E. \nMendes. \u201cA Theory of Value for Value-\nbased Feature Selection in Software \nEngineering,\u201d IEEE Transactions on \nSoftware Engineering, 1, 2020.\n[3*]\t S. Tockey, Return on Software: \nMaximizing the Return on Your Software \nInvestment, Boston, MA: Addison-\nWesley, 2005.\n[4]\t International Valuation Standards (IVS), \n", "page": 311, "type": "text", "section": "Page 311"}
{"text": "SOFTWARE ENGINEERING ECONOMICS   15-23\n2019, Norwich: Page Bros, ISBN: \n978-0-9931513-3-3-0.\n[5]\t K. Voigt, O. Buliga, and K. Michl, \nBusiness Model Pioneers: How \nInnovators Successfully Implement \nNew Business Models, 2017.\n[6]\t M.-I. Sanchez-Segura, G.-L. Dugarte-\nPe\u00f1a, A. Amescua-Seco, and F. \nMedina-Dom\u00ednguez, \u201cExploring  \nHow The Intangible Side of an \nOrganization Impacts its Business  \nModel,\u201d Kybernetes, Vol. 50 No. 10,  \npp. 2790-2822. 2021. https://doi.org \n/10.1108/K-05-2020-0302.\n[7]\t ISO/IEC/IEEE International \nStandard \u2013 Systems And Software \nEngineering \u2013 Software Life Cycle \nProcesses \u2013 Part 2: Relation and \nMapping Between ISO/IEC/IEEE \n12207:2017 and ISO/IEC 12207:2008. \nIEEE, 2020, pp. 1-278, doi: 10.1109/\nIEEESTD.2020.9238529.\n[8*]\t ISO/IEC/IEEE 15288 First edi-\ntion 2015-05-15: ISO/IEC/IEEE \nInternational Standard \u2013 Systems and \nSoftware Engineering \u2013 System Life \nCycle Processes, IEEE.\n[9]\t T. Brown and B. Katz, Change by \nDesign: How Design Thinking Transforms \nOrganizations and Inspires Innovation, \nRevised and updated ed., New York, \nNY: Harper Collins, 2019.\n[10*]\t\nI. Sommerville, Software Engineering, \n10th ed., New York: Addison-\nWesley, 2016.\n[11]\t T. Gilb, Competitive Engineering: A \nHandbook for Systems Engineering, \nRequirements Engineering, and \nSoftware Engineering Using Planguage, \nOxford, UK: Elsevier Butterworth-\nHeinemann, 2005.\n[12]\tR. Kazman, M. Klein, and P. \nClements, \u201cATAMSM: Method for \nArchitecture Evaluation,\u201d CMU/SEI-\n2000-TR-004, Software Engineering \nInstitute, August 2000.\n[13]\tM.I. Sanchez-Segura, A. Ruiz-\nRobles, F. Medina-Dom\u00ednguez, \nand G.L. Dugarte-Pe\u00f1a. \u201cStrategic \nCharacterization of Process Assets \nBased on Asset Quality and Business \nImpact,\u201d Industrial Management and Data \nSystems, 117(8), 1720-1734. https://doi.\norg/10.1108/IMDS-10-2016-0422, 2017.\n[14]\t M.I. Sanchez-Segura, A. Ruiz Robles, \nF. Medina-Dom\u00ednguez. \u201cUncovering \nHidden Process Assets: A Case Study.\u201d \nInformation Systems Frontiers, https://\nwww.springerprofessional.de/en \n/uncovering-hidden-process-assets-a \n-case-study/11724394, 2016.\n[15]\tA. Osterwalder, Y. Pigneur, G. \nBernarda, A. Smith, and T. Papadakos, \nValue Proposition Design, Wiley, 2015.\n[16]\t D. Gotterbarn, K. Miller, and S. \nRogerson, \u201cSoftware Engineering  \nCode of Ethics,\u201d Commun. \nACM 40, 11, 110-118, doi: \n10.1145/265684.265699, 1997.\n[17]\t S. McConnell, Software Estimation \nDemystifying the Black Art, 1st ed., \nMicrosoft Press, 2009.\n[18]\t R.D. Stutzke, Estimating Software-\nIntensive Systems Projects, Products, and \nProcesses, 1st ed., Addison-Wesley, 2005.\n[19]\t M. Ben-Eli, Understanding Systems. \nSystems Innovation, http://bit.ly/2X-\nNlh3D, 2019.\n[20]\tJ. Sterman, Business Dynamics: Systems \nThinking and Modeling for a Complex \nWorld, McGraw-Hill, 2000.\n", "page": 312, "type": "text", "section": "Page 312"}
{"text": "15-24   SWEBOK \u00ae GUIDE V4.0\n[21]\t S. Pereira, G. Medina, et al., \u201cSystem \nThinking and Business Model Canvas \nfor Collaborative Business Models \nDesign,\u201d IFIP Advances in Information \nand Communication Technology, Vol. \n488, pp. 461-468, 2016.\n[22*]\tR.E. Fairley, Managing and Leading \nSoftware Projects, Wiley-IEEE \nComputer Society Press, 2009.\n[23]\tProject Management Institute, A \nGuide to the Project Management Body \nof Knowledge (PMBOK\u00ae Guide), 7th \ned., Newton Square, PA: Project \nManagement Institute, 2021.\n[24]\tProject Management Institute, Inc., \nPMI Lexicon of Project Management \nTerm, 2012.\n[25]\tProject Management Institute and \nIEEE Computer Society, Software \nExtension to the PMBOK\u00ae Guide Fifth \nEdition, ed: Project Management \nInstitute, 2013.\n[26] B.W. Boehm, Software Engineering \nEconomics, Prentice-Hall, 1981.\n[27] C. Ebert and R. Dumke, Software \nMeasurement, Springer, 2007.\n[28] D.J. Reifer, Making the Software Business \nCase: Improvement by the Numbers, \nAddison-Wesley, 2002.\n", "page": 313, "type": "text", "section": "Page 313"}
{"text": "16-1 \nCHAPTER 16\nComputing Foundations\nACRONYMS\nADT\nAbstract Data Type\nAI\nArtificial Intelligence\nANSI\nAmerican National Standards \nInstitute \nAVL Tree\nAdelson-Velskii and Landis Tree\nBCNF\nBoyce-Codd Normal Form \nBST\nBinary Search Tree\nCASE\nCommon Application \nService Element \nCDRAM\nCache DRAM\nCERT\nComputer Engineering \nResponse Team\nCISC\nComplex Instruction \nSet Computer\nCRUD\nCreate, Read, Update, Delete\nCUDA\nCompute Unified Device \nArchitecture\nDAG\nDirected Acyclic Graph\nDAL\nDatabase Access Language\nDAS\nDirect Access Storage\nDBCS\nDouble Byte Character Set\nDCL\nData Control Language\nDDL\nData Definition Language\nDDR \nSDRAM\nDouble Data Rate SDRAM\nDKNF\nDomain/Key Normal Form \nDMA\nDirect Memory Access\nDML\nData Manipulation Language\nEDW\nEnterprise Data Warehouse\nFCFS\nFirst Come, First Served \nFIFO\nFirst In, First Out\nFPU\nFloating Point Unit\nHCI\nHuman-Computer Interface\nHMPP\nHybrid Multicore Parallel \nProgramming\nHTTP\nHyper Text Transfer Protocol\nIPC\nInter-Process Communication\nISA\nInstruction Set Architecture\nMIMD\nMultiple Instruction, Multiple \nData Stream \nMISD\nMultiple Instruction, Single \nData Stream \nMISRA\nMotor Industry Software \nReliability Association\nML\nMachine Learning\nNAS\nNetwork Access Storage\nOSI\nOpen Systems Interconnection\nPDU\nProtocol Data Unit\nRDBMS\nRelational DBMS\nRDM\nRuntime Database Manager\nRDRAM\nRambus DRAM\nRISC\nReduced Instruction \nSet Computer\nRTOS\nReal Time Operating System\nSAN\nStorage Area Network\nSASE\nSpecific Application \nService Element \nSDRAM\nSynchronous DRAM\nSEI\nSoftware Engineering Institute\nSIMD\nSingle Instruction, Multiple \nData Stream \nSISD\nSingle Instruction, Single \nData Stream \nSQL\nStructured Query Language\nSRTF\nShortest Remaining Time First\n", "page": 314, "type": "text", "section": "Page 314"}
{"text": "16-2   SWEBOK \u00ae GUIDE V4.0\nINTRODUCTION\nSoftware engineers must understand and inter-\nnalize the differences between their role and \nthat of a computer programmer. A typical pro-\ngrammer converts a given algorithm into a set \nof computer instructions, compiles the code, \ncreates links with relevant libraries, binds, \nloads the program into the desired system, \nexecutes the program, and generates output.\nOn the other hand, a software engineer \nstudies the requirements, architects and designs \nmajor system blocks, and identifies optimal \nalgorithms, communication mechanisms, per-\nformance criteria, test and acceptance plans, \nmaintenance methodologies, engineering pro-\ncesses and methods appropriate to the applica-\ntions and so on.\nThe \nkey \npurpose \nof \nthe \nSoftware \nEngineering Body of Knowledge (SWEBOK) \nGuide is to identify the areas of knowledge \nthat professional software engineers must \nknow, according to practicing subject matter \nexperts worldwide.\nSoftware engineers are expected to have \ndeep and broad knowledge of various con-\ncepts of computer science and be able to apply \nthem. These concepts form the foundations of \ncomputing.\nBREAKDOWN OF TOPICS FOR \nCOMPUTING FOUNDATIONS\nThe breakdown of topics for the Computing \nFoundations knowledge area (KA) is shown \nin Figure 16.1.\n1.\t Basic Concepts of a System or Solution \n\b\n[6*, C10]\nThe problem to be solved has to be analyzed in \ngreater detail for functional requirements, user \ninteractions, performance requirements, device \ninterfaces, security, vulnerability, durability \nand upgradability. A system is an integrated \nset of subsystems, modules and components \nthat perform specific functions independently. \nDelineating the problem and solution is critical.\nAn engineered system ensures the subsys-\ntems are designed to be:\n\u2022\t Modular: Each subsystem (module) is \nuniform (similar size).\n\u2022\t Cohesive: Each subsystem performs one \nspecific task. Ideally, systems should be \nhighly cohesive.\n\u2022\t Coupled: Each subsystem functions inde-\npendently, as much as possible. Ideally, \nsystems should be loosely coupled.\nComputing \nFoundations\nBasic Concepts\nof a System \nor Solution\nComputer \nArchitecture\nTypes of \nComputer \nArchitecture\nMicroarchitecture \nor Computer \nOrganization\nMemory\nUnit\nInput/Output\nDevices \nControl Unit\nTypes of \nData Structures\nOperations on \nData Structures\nAlgorithms \nand Attributes \nof Algorithms\nAlgorithm \nComplexity\nMeasurement \nof Complexity\nDesigning \nAlgorithms\nSorting \nTechniques\nSearching \nTechniques\nHashing\nProgramming \nLanguage Types\nProgramming \nSyntax, Semantics, \nType Systems\nSubprograms \nand Coroutines\nObject-Oriented \nProgramming\nDistributed \nProgramming and \nParallel Programming\nDebugging\nStandards and \nGuidelines\nProcessor \nManagement\nMemory \nManagement\nDevice \nManagement\nInformation \nManagement\nNetwork \nManagement\nSchema\nData Models \nand Storage \nModels\nDatabase \nManagement \nSystems\nRelational \nDatabase \nManagement \nSystems and \nNormalization\nStructured \nQuery \nLanguage\nData Mining \nand Data \nWarehousing\nDatabase Backup \nand Recovery\nTypes of \nComputer \nNetworks\nLayered \nArchitectures \nof Networks\nOpen Systems \nInterconnection \nModel\nEncapsulation and \nDecapsulation\nApplication Layer \nProtocols\nDesign Techniques for \nReliable and Efcient \nNetworks\nInternet Protocol \nSuite\nWireless and Mobile \nNetworks\nSecurity and \nVulnerabilities\nComputer \nArchitecture and \nOrganization\nData Structures \nand Algorithms\nProgramming \nFundamentals \nand Languages\nOperating \nSystems\nDatabase\nManagement\nComputer \nNetworks and \nCommunications\nHuman Factors:\nUser and \nDeveloper\nUser Human \nFactors\nDeveloper Human \nFactors\nArti\ufb01cial \nIntelligence and \nMachine Learning\nReasoning\nLearning\nModels\nPerception and \nProblem-Solving\nNatural Language \nProcessing\nFigure 16.1. Breakdown of Topics for the Computing Foundations KA\n", "page": 315, "type": "text", "section": "Page 315"}
{"text": "COMPUTING FOUNDATIONS   16-3\nThe subsystems may further be broken \ndown into modules and sub-modules that also \nexhibit these characteristics.\nThe system may include both software and \nhardware subsystems. The hardware must \nbe designed to support the software subsys-\ntems and satisfy all user requirements, espe-\ncially user interfaces (input/output (I/O)) and \nperformance. \nThis section focuses on designing and \nbuilding engineered software subsystems. \nThe applications may require systems that \nare manual or fully or semiautomated; real-\ntime, online or offline; distributed or single- \nlocation, and so on. \nThe software subsystems\u2019 architects have \nto consider appropriate technology, tools, \ndata structure, operating system, database (if \nrequired), user interfaces, programming lan-\nguages, and algorithms for computing solu-\ntions optimally among others.\nSoftware requirements, architecture, design, \nconstruction, testing, methods and models, \nquality assurance, and security are discussed in \ndetail in other chapters as independent KAs.\nThe Computing Foundations KA focuses \non explaining the key computer science con-\ncepts a software engineer has to know well to \narchitect, design, construct, deploy and main-\ntain useful, high-quality software subsystems.\n2.\t Computer Architecture and \nOrganization\b\n[6*, C6]\nComputer architecture refers to the com-\nponents of a computer system designed for \nspecific purposes. Computer organization \nexplains how the units within the system con-\nnect and interact to achieve those purposes. \nSystem architects must analyze the appli-\ncation for which the computer system is to \nbe designed or developed; identify the crit-\nical components, including I/O devices \nrequired (along with throughput), types and \nquantum of memory, processing power, and \ncoprocessors required; and choose or design \nappropriate computer architecture and orga-\nnization. Contingencies should be built in for \nthe resources required.\nThis content area discusses various com-\nputer architectures and organizations a system \nor software architect needs to know.\n2.1.\t Computer Architecture\b\n[8*, C1.1]\nArchitecture describes what the computer \nor system does, and its components, such as \nmemory, data storage devices, graphics, and \nthe computers or processor\u2019s computing power. \nA computing system typically has memory, I/O \ndevices and a central processing unit (CPU). \nThese components are connected through \nphysical signal lines called a bus. Typically, three \ntypes of buses are used for specific purposes:\n\u2022\t Address bus, which addresses or accesses \na specific memory location or I/O device.\n\u2022\t Data bus, which stores (writes) or \nretrieves (reads) data to and from the \nmemory location.\n\u2022\t Control bus, which provides control sig-\nnals from the CPU to I/O devices (read \nor write, enable or disable, interrupt, \nstatus, reset, etc.).\nSoftware engineers are expected to know \nthe details of the functioning and timing \nof different types of buses \u2014 first-gener-\nation, second-generation and third-gen-\neration buses; internal and external buses; \nserial and parallel buses; simplex, full-duplex \nand half-duplex buses; Mil-Std-1553Bbus, \nWishbone buses, etc.\n2.2.\t Types of Computer Architectures \n\b\n[8*, C4.14, C5]\n2.2.1.\t Von Neumann Architecture\b\n[8*, C1.9]\nJohn von Neumann designed a computer \nsystem architecture with five essential com-\nponents as shown in Figure 16.2:\n\u2022\t Arithmetic logic unit (ALU) that per-\nforms arithmetic and logic computation.\n\u2022\t Memory where the program and data are \nloaded and executed (program and data \nreside in the same memory space).\n", "page": 316, "type": "text", "section": "Page 316"}
{"text": "16-4   SWEBOK \u00ae GUIDE V4.0\n\u2022\t Input devices (e.g., keyboard, mouse, \nserial port, hard disk) that allow the user \nto provide inputs and control commands.\n\u2022\t Output devices (e.g., monitor, printer) \nthat transmit or communicate the com-\nputed results.\n\u2022\t The control unit synchronizes all devices, \nmemory and ALU.\n2.2.2.\t Harvard Architecture\b\n[20*]\nThe Harvard architecture provides separate \nmemory blocks for code (program or instruc-\ntions) and data. As the code and data memory \nblocks are different, the contents of address \n0000 in the code block and the contents of \naddress 0000 in the data block are different. The \nCPU reads instructions from the code addresses \nand reads data from the data addresses. \nThe system design and implementation in \nthe original Harvard architecture were rela-\ntively complex. The modified Harvard architec-\nture provides one memory block but partitions \nit into code and data sections. Data memory \nsections are read/write capable, and code \nmemory sections are read-only (thus protects \ncode from getting corrupted at runtime). I/O \noperations can be performed simultaneously. \n2.2.3.\t Instruction Set Architecture\b [8*, C4.8.3]\nAn instruction set architecture (ISA) is an \nabstract model of how a CPU executes the \ninstruction sets defined for the system. An \nISA defines registers (address, data, flags), data \ntypes, instructions specific to the computer \nor system, memory (internal and external) \naddressing schemes, and I/O handling models. \nA reduced instruction set computer (RISC) \narchitecture and a complex instruction set \ncomputer (CISC) architecture are the two \nprimary types of ISAs. \nIn RISC, the instructions perform single \ntasks such as reading from memory or I/O, \nperforming arithmetic or logical computa-\ntion, and storing data into memory or I/O. \nThe computer system is simple but requires \nmore instructions to execute a task. It requires \nfewer clock cycles per instruction, and instruc-\ntion sizes tend to be fixed. As the instruction \nset is small (fewer instructions), it is easier to \nbuild a compiler, and the program can be rel-\natively large. RISC architectures are typically \ndesigned for general-purpose processors. \nThe instructions are relatively more pow-\nerful in CISC and can perform multiple tasks \nsuch as reading data from memory + per-\nforming arithmetic operation + storing the \nresult in memory. Here, fewer instructions are \nrequired to perform a task, but the instruc-\ntions take more clock cycles to complete. \nInstruction sizes vary widely depending on \noperations with registers, memory and I/O. \nPrograms are relatively small. CISCs are typ-\nically designed for specific purposes such as \ndigital signal processing (DSP) and graphics.\nMemory\nInput Devices\nALU\nOutput Devices\nControl Unit\nFigure 16.2. Computer Architecture\n", "page": 317, "type": "text", "section": "Page 317"}
{"text": "COMPUTING FOUNDATIONS   16-5\n2.2.4.\t Flynn\u2019s Architecture or Taxonomy \n\b\n[8*, C9.3]\nThe computing architectures described above \nconsider a single computer at a time. Michael \nJ. Flynn proposed concurrent computer archi-\ntectures, where multiple instruction streams \nand multiple data streams are used in the \nsystem. Software engineers need to know the \ndifferent types of Flynn\u2019s architecture, with \nexamples, including the following:\n\u2022\t Single instruction, single data stream \n(SISD) architecture.\n\u2022\t Single instruction, multiple data stream \n(SIMD) architecture.\n\u2022\t Multiple instruction, single data stream \n(MISD) architecture.\n\u2022\t Multiple \ninstruction, \nmultiple \ndata \nstream (MIMD) architecture.\nVariants of these architectures include array \nprocessing, parallel processing, and asso-\nciate processing; processing single program \nmultiple data streams, and multiple program \nmultiple data streams. Software engineers are \nexpected to know the differences among these \narchitectures, along with case studies, so that \nthey can choose the right architecture to solve \nthe problem at hand.\n2.2.5.\t System Architecture\b\n[6*, C6]\nSystem architecture is the overall system \ndesign, \nconsidering \nhardware \narchitec-\nture, software architecture, modules, inter-\nfaces, data management, and communication \namong modules. Distributed computing has \nbecome affordable with the development of \nefficient, high-end, high-performance servers, \nstorage, network devices, software, and tools. \nSeveral reference designs or architectures are \navailable for any given application.\nTypical system architectures include the \nfollowing:\n\u2022\t Integrated \nsystem \narchitecture: \nComputing, I/O, data and networking \nare tightly coupled and available in \none box. This architecture is typically \nused in solutions designed for specific \napplications.\n\u2022\t Distributed \nsystem \narchitecture: \nComputing and storage are located in \nseparate but networked boxes. This archi-\ntecture supports scaling, provides cen-\ntralized or isolated data storage, and \nshares computation load.\n\u2022\t Pooled system architecture: Several com-\nputing, storage and network resources are \navailable in pools and provided depending \non demand. This architecture provides \nfor efficient use of shared resources. \n\u2022\t Converged system architecture: As the \nname implies, this is the convergence \nof distributed and pooled architectures. \nThis architecture supports agility and \nscalability.\nSoftware engineers are also expected to \nknow and be able to apply various other \narchitectures, including .NET Framework \narchitecture, Unix architecture, and virtual \nmachine architecture.\n2.3.\t Microarchitecture or Computer \nOrganization\b\n[8*, C4]\nMicroarchitecture or computer organization \nexplains how the ISA of a computer is imple-\nmented and how different components in the \nsystem function and interact with one another \nto produce the desired outcome.\nSystem architects and engineers must know \nthe various components used in the system \nalong with how they function. Some of these \ncomponents are discussed below.\n2.3.1.\t Arithmetic Logic Unit\b\n[8*, C1.2]\nThe ALU performs all arithmetic computa-\ntions and logical operations. The CPU typ-\nically has an ALU, processor, memory, and \ncontrol unit. High-end CPUs may also have \nother functionality-specific processing units, \nsuch as a floating-point unit (FPU), to per-\nform computations involving floating point or \nreal numbers (fractions). ALUs have registers \n", "page": 318, "type": "text", "section": "Page 318"}
{"text": "16-6   SWEBOK \u00ae GUIDE V4.0\nthat are high-speed memory and internal to \nthe ALU. The ALU executes the processor \ninstruction sets. All operations are typically \ncarried out on the registers.\nVarious schemes may be implemented \nto improve the performance of the ALU, \nincluding pipeline processing and parallel \nprocessing. The latest CPUs provide multiple \ncores and multiple threads that help achieve \nmaximum throughput. Software engineers \nare expected to know the differences between \nmultiple cores and multiple threads, along with \nspecific cases illustrating the best use of these. \nSpecific-purpose coprocessors and asso-\nciate processors are used with main processors \nto support faster processing.\n2.3.2.\t Memory Unit\b\n[8*, C6]\nMemory units are used to store data or infor-\nmation, which is accessed by the CPU. The \ntotal amount of memory a computer can have \nis derived from the maximum number of \naddress lines supported by the CPU. Different \ntypes of memory used in the system include \nread-only memory (ROM), and read-write \nmemory or random access memory (RAM).\nSoftware engineers working on perfor-\nmance-critical applications are expected to \nknow the differences among various types \nof memory, including static RAM (SRAM), \ndynamic RAM (DRAM), asynchronous \nDRAM (ADRAM), synchronous DRAM \n(SDRAM), double-data-rate SDRAM (DDR \nSDRAM), rambus DRAM (RDRAM), and \ncache DRAM (CDRAM), along with pros, \ncons and use cases of each.\n2.3.3.\t Input/Output Devices\b\n[8*, C7]\nAs the names imply, input devices are those \nthat provide inputs to the computer system, \nand output devices are those that deliver com-\nputer systems\u2019 output to the user. While some \ndevices are input only (keyboard, mouse, \nmicrophone, etc.) or output only (printer, \nmonitor, speakers, etc.), a few devices serve \nas both input and output devices (e.g., touch \nscreens, hard disks, USB drives).\nSoftware engineers are expected to under-\nstand the interface of the I/O devices with the \nsystem, whether they are memory-mapped I/O \nor I/O-mapped I/O devices, and device drivers \nrequired for the users or applications to interact \nwith the devices through the operating system.\n2.3.4.\t Control Unit\b\n[8*, C4.2]\nThe control unit synchronizes multiple com-\nponents in the computer system. Typically, \ncontrol units are part of the CPU. They inter-\npret instructions and coordinate data move-\nment among different components (memory, \nI/O devices and ALU). Control units are \nalso used to enable or disable components or \ndevices and reset devices.\nSoftware engineers are expected to be \naware of the different types of control units, \nincluding hardware control units and micro \nprogrammable control units (single-level and \ntwo-level control stores), along with the bene-\nfits and challenges of each.\n3.\t Data Structures and Algorithms \n\b\n[8*, C2]   [18*, C10 Part V]\nData structures are fundamental to computer \nscience and software engineering. Every pro-\ngram uses data \u2014 receives input (data), per-\nforms specific functions on the data and \nproduces output. Data structures is about rep-\nresenting different types of data effectively, \nperforming various operations on the data pro-\nficiently, and storing and retrieving data effi-\nciently. Software engineers must internalize \ndata structures, the selection of data structures, \nand operations on them specific to applications.\u00a0\nIn this chapter, different types of data \nstructures and various operations on them are \ndiscussed. \n3.1.\t Types of Data Structures\b\n[18*, C10], \n\b\n[5*, C2.1 - 2.6]\nData type is an attribute of data. Various data \ntypes are identified and defined based on dif-\nferent characteristics of data, the need for \ngrouping data items and various operations \n", "page": 319, "type": "text", "section": "Page 319"}
{"text": "COMPUTING FOUNDATIONS   16-7\nperformed on data. Data structures are \ngrouped primarily based on the physical and \nlogical ordering of data items. \nPrimarily, data is grouped into three types: \nbasic, composite or compound, and abstract. \nBasic or primitive data types include char-\nacter, integer, float or real, Boolean, and \npointer data. \nCompound data types are made of multiple \nbasic or primitive, or even multiple compound \ndata types. Some of the compound data types \ninclude sets, graphs, records and partitions.\nAn abstract data type (ADT) is defined by \nits behavior (semantics) from the user\u2019s per-\nspective, specifically from the point of pos-\nsible values and operations.\nComposite or compound data types are \nfurther grouped under linear, and hierarchical \nor nonlinear data types.\nLinear data types include one-dimensional \nand multidimensional arrays, strings, linked \nlists (singly linked lists, doubly linked lists, \ncircular lists), stacks, queues, and hash tables.\nHierarchical or nonlinear data types \ninclude trees, binary trees, n-array trees, B \ntrees, B+ trees, weighted balanced trees, red-\nblack trees, heaps, binary heaps and graphs.\nIn the current era of free text queries or \nnatural language processing, software engi-\nneers may need to understand strings and var-\nious operations on strings, and to be able to \nanalyze skip lists.\nSoftware engineers must understand the \nnuances of various types of data and their \nsizes in memory (short integer, integer, \nlong integer, long long integer, signed and \nunsigned integer, float, double, long double, \ndouble byte character set (DBCS), Boolean, \netc.), along with how various data types are \nrepresented and stored in memory and how \nvarious operations are performed on them. \nSets, graphs, and trees are discussed in more \ndetail in the Mathematical Foundations KA.\n3.2.\t Operations on Data Structures \n\b\n[5*, C2.1 - 2.6]\nBasic operations performed on data structures \ninclude create, read, update and delete (CRUD). \nCompound data types also require various ways \nof traversing data sets to identify specific data \nitems before performing the operation.\nIt is important to ensure that any insertion \nor deletion of items in a data set or database \ndoes not alter the data set or database in a way \nthat violates any policy under which the data-\nbase was designed and built.\nAdditional operations performed on data \nstructures include sorting the data items in a \nspecific order, searching and locating a data \nitem, and merging two or more data sets \ninto one set without disturbing the policy \non which the data set is built.\u00a0 Searching \nand sorting algorithms are discussed in the \nnext section.\nDifferent data structures are created to suit \nspecific applications, such as stacks, queues, \ntrees, and graphs. Software engineers are \nencouraged to learn the traversals through non-\nlinear data structures, which include different \ntree parsers (pre-order, in-order, and post-order \ntree traversals), CRUD operations on trees, tree \nbalancing, binary search trees (BSTs), AVL \ntrees, and red-black trees, and to learn tree \nsearch algorithms (depth first, breadth first, \nshortest paths, etc.). Some of these are dis-\ncussed in the Mathematical Foundations KA.\n3.3.\t Algorithms and Attributes of Algorithms \n\b\n[18*, C26, C27]\nAll software implements logic to perform the \nrequired function. That logic or algorithm to \nperform a specific task has to be designed or \nchosen with consideration for system per-\nformance, security, portability, maintain-\nability, scalability and simplicity, among \nother concerns.\nThe complexity of an algorithm is deter-\nmined by measuring the computational \nresources (computing power and space) con-\nsumed by that algorithm for a given set of data. \nA thorough understanding of data struc-\ntures is vital for analyzing and designing good \nalgorithms. Refer to the \u201cData Structures and \nOrganization\u201d content area for more details.\nThe attributes of algorithms are many and \ninclude functionality, correctness, robustness, \n", "page": 320, "type": "text", "section": "Page 320"}
{"text": "16-8   SWEBOK \u00ae GUIDE V4.0\nmodularity, maintainability, programmer- \nfriendliness (ease of integration into the project \nand ease of use), user-friendliness (i.e., how \neasily it is understood by people), need for pro-\ngrammer time, simplicity, and extensibility. \nA commonly emphasized attribute of algo-\nrithms is \u201cperformance\u201d or \u201cefficiency.\u201d \nThe parameters that matter for an algo-\nrithm\u2019s resource consumption include, but are \nnot limited to:\n1.\t Hardware. \n2.\t Software. \n3.\t Algorithm selection and design for a spe-\ncific problem. \n4.\t Effective implementation.\n3.4.\t Algorithm Complexity\b\n[5*, S1, S3, S4, \n \n\b\nS5, S6, S7, S11, S12]\nThe complexity of an algorithm is a mea-\nsure of the resources it consumes (computing \npower or memory) for a specific problem and \ngiven data set. \nChoosing the right data structures and \noperations on data structures and ensuring \noptimal implementation of the algorithm also \neffect the algorithm\u2019s complexity.\n3.5.\t Measurement of Complexity\b\n[5*, S1.1, \n \n\b\nS3, S4, S5, S6, S11.1, S12.1]\nOften, the complexity of an algorithm is \ndenoted by the resources consumed in the \nworst-case scenario. The complexity of algo-\nrithms is typically measured by asymptotic \nnotations for best-case, worst-case and aver-\nage-case scenarios in terms of resource con-\nsumption for a given data set.\u00a0\nPopular asymptotic notations for algo-\nrithms are listed in Table 16.1. \nLearning the computation of the listed \nnotations for different sets of input data (e.g., \nsorted, unsorted, and sorted in reverse order) \nis important.\nThe complexity of an algorithm can be con-\nstant, linear, quadratic, cubic, exponential or \nlogarithmic. These complexities are described \nin Table 16.2. Typically, constants are not \nconsidered when computing the efficiency of \nan algorithm.\n3.6.\t Designing Algorithms\b\n[18*, Part IV, \n \n\b\nPart VI]\nThe software engineer must consider the \nspecific application\u2019s purpose and the per-\nformance requirements in order to select an \nappropriate algorithm. In addition, the soft-\nware engineer must consider linear pro-\ngramming versus parallel programming and \nsingle- versus multi-threading.\nThe efficiency of an algorithm is measured \nby the resources it consumes, primarily com-\nputing time and memory. \nA software engineer has to know a few \nstandard algorithms and relevant concepts, \nincluding the following: \nAsymptotic Notations\nDescription\nBig O\nBig O notation provides the upper bound of operations (worst-case \nscenario) for a function f(n).\nlittle-o\nLittle o notations are used to depict scenarios where the upper bound \nis not tight.\nBig Omega (\u03a9)\nBig \u03a9 notations are used to depict lower bounds (best-case scenarios) \nfor a function f(n). \nlittle-omega (\u03c9)\nLittle omega (\u03c9) notations are used to depict loosely bound best-case \nscenarios of an algorithm.\nTheta (\u0398)\nTheta notation bounds the function from above and below (provides \naverage-case complexity of an algorithm).\nTable 16.1. Asymptotic Notations of Algorithms\n", "page": 321, "type": "text", "section": "Page 321"}
{"text": "COMPUTING FOUNDATIONS   16-9\n\u2022\t Common types of algorithms: Brute \nforce algorithm, Recursive algorithm, \nDivide & Conquer algorithm, Dynamic \nprogramming \nalgorithms, \nGreedy \nalgorithm, \nBacktracking \nalgorithms, \nRandomized algorithms.\n\u2022\t Randomized approximation algorithms, \nrandomized rounding, approximation \nalgorithms, P and NP complexity class \nalgorithms, Cook\u2019s theorem, reductions \nand completeness algorithms.\n\u2022\t Multiple comparison operations per-\nformed simultaneously in a network \nmodel of computation. Popular sorting \nnetwork algorithms include comparison \nnetworks, zero-one principle, merging \nnetwork and bitonic sorter.\n\u2022\t Optimized algorithms for performing \nseveral operations on a matrix, such as \nmatrix \nmultiplication, \ntransposition, \nmatrix inversion, median, and finding \ndeterminants.\n\u2022\t Cryptographic complexity and algo-\nrithms: secret key (symmetric) encryp-\ntion algorithms, public key (asymmetric) \nencryption \nalgorithms \nand \nhash \nfunctions.\n\u2022\t One-way functions, class UP, space com-\nplexity, deterministic and nondeterministic \nspace complexity classes, the reachability \nmethod, and Savitch\u2019s theorem.\n\u2022\t Graph representations, graph algorithms, \nbreadth-first and depth-first search, \ntopological sort, minimum spanning \ntree, Kruskal and Prim algorithms, and \nsingle-source shortest paths (Bellman-\nFord and Dijkstra algorithms).\n\u2022\t Complexity of randomized computa-\ntion, interactive proofs, complexity of \ncounting, Boolean circuit complexity.\nOf particular importance in many soft-\nware systems are algorithms for sorting and \nsearching, these are discussed in more detail.\n3.7.\t Sorting Techniques\b\n[18*, C6-C9]\nSorting is the process of arranging data items \nin a specific order.\u00a0\nPopular sorting algorithms include Linear \nsort, Bubble sort, Quick sort, Merge sort, \nRadix sort, Heap sort, Bucket sort, Pigeonhole \nsort, Bitonic sort, Tree sort, Cartesian Tree \nsort, 3-Way Quick sort,3-Way Merge sort, \nand Sorting Singly / Doubly linked lists.\nEach sorting algorithm has its benefits and \nshortfalls. Selection of an appropriate algo-\nrithm depends on the size of input data, the \ntype of data (linear or nonlinear), and the type \nof data set (completely unsorted, partially \nsorted, etc.). The algorithms are implemented \nin both iterative and recursive methods. \nComplexity\nNotation\nDescription\nConstant\nO(1)\nRegardless of the data size, the algorithm takes a constant \nnumber of steps to perform the operation.\nLinear\nO(n)\nThe number of operations is linearly proportional (steps are a \nconstant multiple of the data set size n).\nQuadratic\nO(n2)\nThe algorithm takes the order of n2 steps for performing the \noperation on the data set of size n.\nCubic\nO(n3)\nThe algorithm takes the order of n3 steps for performing the \noperation on a data set size of n.\nExponential\nO(nk)\nO(2n)\nO(n!)\nThe algorithm has an order of exponential dependability for \nperforming the operation on a data set of size n.\nLogarithmic\nO(log (n))\nO(N*log (n))\nThe algorithm takes the order of log (n) steps (base of log is \ntypically 2).\nTable 16.2. List of Algorithmic Complexities\n", "page": 322, "type": "text", "section": "Page 322"}
{"text": "16-10   SWEBOK \u00ae GUIDE V4.0\nTypically, iterative methods are better than \nrecursive methods for CPU performance and \nmemory. However, recursion provides easy \nmethods for solving specific problems, such as \ntree operations. If adequate computing power \nand memory are available, the difference \nbetween recursive and iterative implementa-\ntion methods is negligible. \nIn the case of applications where certain \nsorting algorithms work best, software engi-\nneers should learn and accommodate any \npreconditions and complexities (demand on \nmemory and computing power) involved in \nusing them.\n3.8.\t Searching Techniques\b\n[5*, C6]\nSearching is a process of finding specific data \nitems or records in a set of data items or a \ndatabase.\u00a0\nSearch algorithms are primarily catego-\nrized into sequential search (data set is tra-\nversed sequentially until the end of the data \nset) and interval search (the search moves effi-\nciently through a sorted list, balanced tree, \netc.), based on how data sets are organized.\nDepending on the type of the data item \nand the size of the data set, various search \ntechniques are used to find the desired data \nitem. Popular search algorithms include \nlinear, binary, jump, interpolation, exponen-\ntial, Fibonacci, sub-list (search a linked list in \nanother list), logarithmic, tree and hashing.\n3.9.\t Hashing\b\n[18*, C11.2]\nHashing is one of the very important and \npopular technique in which data of arbitrary \nsize (key values) are converted into values \nof fixed size called hash values, which index \ninto a hash table so the data records can be \nlocated easily. The function used for that pur-\npose is called a hash function, and the values \nreturned are called hash values, hash codes, \ndigests, or hash keys.\nDifferent properties of hash functions, such \nas uniformity, efficiency, universality, applica-\nbility, deterministic, defined or variable range, \ndata normalization, testing, and measurement, \nmust be understood and considered when \ndesigning or choosing a hash function.\nVarious types of hash functions are designed \nfor different types of key values, applica-\ntions, and database sizes. Hash function \ntypes include trivial hash function, division \nmethod, mid-square method, digit folding \nmethod, \nmultiplicative \nhashing, \ndouble \nhashing, open and closed hashing, rehashing, \nextendible hashing, and cryptographic and \nnoncryptographic hash functions.\nSoftware engineers are expected to learn, \nimplement and be able to compare different \ntypes of hashing algorithms, various collision \nresolution techniques, linear probing, qua-\ndratic probing, separate chaining, and open \naddressing.\n4.\t Programming Fundamentals and \nLanguages\b\n[4*, C6]\nComputer programs are sequential steps or \ninstructions that work on provided inputs and \ngenerate desired or specific outputs. \nSoftware engineers must carefully consider \nvarious aspects before selecting a program-\nming language to solve a specific problem.\n4.1.\t Programming Language Types\b [8*, C8.4.4]\nDepending on the hardware, operating \nsystem, and application various types of \nprogramming languages are developed and \nused. Basic types of programming languages \ninclude microprogramming, machine lan-\nguages, assembly programming and high-\nlevel programming. \nMicroprogramming is executed within the \nmicrocontroller or microprocessor chips to \nexecute the assembly language instructions. \nAssembly language programs use the mne-\nmonic specified by the microcontroller or \nmicroprocessor. Typically, the microcon-\ntrollers or microprocessors are designed to \naddress specific applications (DSP processors, \ngraphics chips, I/O controllers, mathematical \ncoprocessors, generic processors, etc.). \nHigh-level languages enable programs to \nbe written in instructions similar to English, \n", "page": 323, "type": "text", "section": "Page 323"}
{"text": "COMPUTING FOUNDATIONS   16-11\nwhich makes it easy for the developer and \nmaintainer to write and maintain the pro-\ngrams. Various types of high-level program-\nming languages include the following: \n\u2022\t Functional programming languages.\n\u2022\t Procedural programming languages. \n\u2022\t Object-oriented programming languages\n\u2022\t Scripting languages.\n\u2022\t Logic programming languages.\nA programming language can support more \nthan one programming paradigms Software \nengineers need to study multiple program-\nming languages to choose the right one for a \nspecific application.\nMany programming languages, such as C, \nC++ and Java, use compilers to build execut-\nables, whereas other programming languages, \nsuch as JavaScript, Ruby and Python, use \ninterpreters. \n4.2.\t Programming Syntax, Semantics, Type \nSystems\b\n[8*, C8.4.4]\nThe syntax of a programming language is its \ngrammar \u2014 the various constructs the pro-\ngramming language uses. A compiler or inter-\npreter checks the syntax of all declarations, \nstatements (algorithmic statements, condi-\ntional or logical statements, control statements, \nloops, special language-specific statements, \nmicros, etc.), and functions or procedures, and \ncreates notifications of any errors.\nSemantics refers to the meaning or inter-\npretation of the statement. The meaning could \nvary at runtime, depending on runtime values.\nA type system assigns a type to a data item \nor to constructs of a program, such as variables, \nexpressions and functions. In static typing, \nthe type is fixed; it is defined during program \ncreation and checked at compilation time. \nLanguages such as C, C++ and Java support \nstatic typing. In dynamic typing, the type of a \nvariable can change at runtime depending on \nthe context and hence is checked at runtime. \nDynamic typing languages include Python, \nPerl, PHP and Ruby. Dynamic typing is also \ncalled polymorphic typing.\nSoftware engineers are expected to know \nhow high-level programming languages are \ntranslated into machine languages, to be \nfamiliar with the various types of compilers, \nand to know the differences among compilers, \ninterpreters, cross-compilers, assemblers and \ncross-assemblers. Software engineers are \nencouraged to learn about compiler phases, \nincluding preprocessing, lexical analysis, \nsyntax analysis, intermediate code generation, \noptimization, code generator, linkers, loaders \nand debuggers. \nTokens, grammars, syntax trees, parse \ntrees and weights to various operators (prece-\ndence) in arithmetic and logical equations are \nimportant to analyze and understand. \n4.3.\t Subprograms and Coroutines\b\n[4*, C6.3]\nSubprograms or functions are programs or \nbuilding blocks that perform specific (part) \nfunctions in the scope of a complete project. \nSubprograms provide for breaking the larger \nprogram into smaller modules. The modules \nare typically sections of code that are used \nmultiple times in multiple places. The subpro-\ngrams reduce memory space, improve read-\nability and maintainability of the program, \nand execute parts of the program with dif-\nferent values at different places and times.\nThe subprograms have an entry point and \ntypically have multiple input parameters on \nwhich the subprogram acts and produces \noutput. The scope of input parameters is local \nto the subprogram. Subprograms that return \nvalue by their name (which can be used as a \nvariable in a statement) are called functions, \nand subprograms designed not to return any \nvalue are called procedures.\nBy default, the scope of subprogram \nparameters is dynamic and local to the sub-\nprogram. However, if the subprograms have \nto remember their history or previous values, \nthey have to be declared static or as specified \nin the chosen programming language.\nDifferent programming languages sup-\nport one or more types of parameters\u2019 \npassing, including pass-by-value, pass-by-ref-\nerence, pass-by-name, pass-by-result and \n", "page": 324, "type": "text", "section": "Page 324"}
{"text": "16-12   SWEBOK \u00ae GUIDE V4.0\npass-by-result-value. \nSoftware \nengineers \nshould know the differences among these \ntypes and use them appropriately.\nMany high-end languages support the \nnesting of subroutines and recursions, where a \nsubroutine calls itself. Different types of recur-\nsions include cyclic or direct recursion (subrou-\ntine calls itself) and acyclic or indirect recursion \n(subroutine A calls subroutine B, which in turn \ncalls subroutine A). It is important to establish \nthe exit criteria in recursive subprograms.\nSoftware engineers are encouraged to \nunderstand, using case studies, how the sub-\nprogram return address and parameters are \nstored in memory (runtime stack), how they \nare used in the subprogram and for returning \nto the called subprogram, and the scope of \nvariables (global and local).\nA subprogram with multiple entry points, \nwhere the previous exit point is remembered \nfor resumption at a later point, is called a \nCoroutine. A Coroutine call is typically \ncalled a resume call. The first resume call enters \nthe subroutine from the beginning, and sub-\nsequent resume calls enter the subroutine at \nthe point where it was exited last. \nHigh-end \nlanguages \nthat \nsupport \nCoroutines \ninclude \nC++20, \nC#, \nJava, \nJavaScript, Kotlin, Perl, .NET Framework, \nPython, Ruby and many assembly languages.\nSoftware engineers are encouraged to \nunderstand specific applications where corou-\ntines are useful and to use the coroutines. It \nis an interesting exercise to implement corou-\ntines in C, as C does not support corou-\ntines natively.\nFigure 16.3 depicts the functioning or con-\ntrol flow of coroutines.\n4.4.\t Object-Oriented Programming\b [4*, C6.5] \nAs the name suggests, object-oriented pro-\ngramming languages are based on objects. \nThe objects typically have both data and \nfunctions that operate on that data. The data \nof an object is typically called the object\u2019s \nattributes or properties, and the code or func-\ntions that work on the attributes are called \noperations externally (by the client or user) \nand called methods internally (referring to \nhow the operation is implemented by the \ndeveloper). \nA Class is a programmer-defined proto-\ntype that defines the attributes and methods. \nObjects are actual instances of a Class. \nThere could be multiple Objects of a Class \nwith varied characteristics. For example, a \nClass can be defined by the characteristics \nand operations of a vehicle, whereas objects \nare instances of the class vehicle such as car, \nbus or truck.\nThe objects interact with one another using \nthe methods or operations. \nImportant characteristics of object-ori-\nented programming (OOP) are Abstraction, \nEncapsulation, Inheritance and Polymorphism. \nAbstraction is a property that exposes only \nrequired or relevant information and func-\ntionality to the user, hiding the details and \nnonessentials. Thus, the implementation is \nhidden from the user of the superclass.\nOne of the key benefits of encapsulation is \nthe ability to hide or protect data from unau-\nthorized users. The software engineer can \ngive different levels of protection to data and \nmethods by declaring them private (local to \nclass) or public (available to other classes). \nThis also protects data from corruption, either \nintentional or accidental.\nSubroutine S1\nSubroutine S2\nSubroutine S3\nResume S1\nResume S3\nResume S3\nResume S2\nResume S2\nResume S1\nFigure 16.3. Example of Coroutine\n", "page": 325, "type": "text", "section": "Page 325"}
{"text": "COMPUTING FOUNDATIONS   16-13\nInheritance is an important feature of \nOOP, where a subclass or derived class \ninherits the properties of a superclass or base \nclass. Primary inheritance modes include \npublic, protected and private modes.\nPolymorphism is another key feature of \nOOP. Polymorphism is a provision of pro-\nviding a single interface to entities of dif-\nferent types. For example, shape could be \na base class with draw as a method, and \nobjects could be a circle, triangle or rect-\nangle. The implementation of method draw, \nthough the name is the same, differs for a \ncircle, triangle and rectangle. Polymorphism \nhas two types:\n\u2022\t Static or compile-time polymorphism: The \nmethods (functions) or operators are \noverloaded and resolved during compile \ntime. Example: The methods, though \nthey have the same name, will have dif-\nferent types or numbers of parameters.\n\u2022\t Dynamic or runtime polymorphism: The \noverloaded method to be executed is \nresolved at runtime. Example: When \nboth base class and derived class have the \nsame method, the base class method is \nsaid to be overridden.\nPopular OOP languages include C++, C#, \nCobol 2002, Java, Python, Lisp, Perl, Object \nPascal, Ruby and Smalltalk.\nIt\u2019s important to recognize that using \nOOP requires a different mindset than using \ntraditional, procedural, or structured pro-\ngramming does.\n4.5.\t Distributed Programming and Parallel \nProgramming\b\n[4*, C6.6]\nIn a distributed computer system, multiple \nparts of the software are run on multiple com-\nputers, connected through computer networks, \nto achieve a common goal. Writing such pro-\ngrams is called distributed programming.\nParallel programming is a type of com-\nputing in which different parts of the program \nare run in parallel to achieve the same objec-\ntive or goal. Table 16.3 compares distributed \nand parallel programming. High Performance \nComputing (HPC) aims to speed-up the exe-\ncution of software, both distributed program-\nming and parallel programming are ways to \ndo this and is increasingly used together in \nhybrid software.\n4.6.\t Debugging\b\n[6*, C2.2.2]\nPrograms, when written, are expected to \nfunction properly and generate the expected \noutput. However, programmers often face \nthree types of errors \u2014 syntax errors, runtime \nerrors, and logical errors \u2014 at different stages \nof software development. \nSyntax errors are deviations from the stan-\ndard format specified by programming lan-\nguages. These are explicitly identified by \ncompilers and are easy to fix. \nRuntime errors surface when a program \nruns into an unexpected condition or situation \nsuch as dividing by zero, memory overflow, or \naddressing a wrong or unauthorized memory \nlocation or device, or when a program tries to \nperform an illegitimate or unauthorized oper-\nation or tries to access a library, for example. \nThe programs must be thoroughly tested for \nvarious types of inputs (valid data sets, invalid \ndata sets and boundary value data sets) and \nconditions to identify these errors. Once iden-\ntified, runtime errors are easy to fix. \nLogical errors are slipups in implementing \nthe logic to achieve the desired output. These \nerrors must be traced and resolved with various \ndata for each functionality. Several sophisti-\ncated high-end debuggers help trace each vari-\nable or data item and support setting various \ntypes of break points.\n4.7.\t Standards and Guidelines\b\n[3*, C28.5, \n\b\nC31.5]\nAs the computing system or application \nbecomes bigger and complex, more program-\nmers are involved. Their individual program-\nming styles affect the project schedules and \nmake system integration difficult, so systems \nbecome defect-prone, and maintenance and \nenhancement become challenging. \n", "page": 326, "type": "text", "section": "Page 326"}
{"text": "16-14   SWEBOK \u00ae GUIDE V4.0\nAn estimated 82% of vulnerabilities \nare caused by clashes between program-\nming styles.\u00a7 \nHence, quality-conscious companies often \nhave defined tools, standards and guidelines, \nwhich set rules and recommendations for \ntheir programmers and testers to follow. \nWhen software teams follow appro-\npriate coding standards, they create read-\nable, cleaner, portable, reusable, modular, \n\u00a7\t https://www.ptsecurity.com/ww-en/analytics/web-vulnerabilities-2020/\neasily maintainable, less defect-prone soft-\nware code, and project schedules become \nmore predictable. The following practices can \nhelp organizations implement such standards \nsuccessfully:\n\u2022\t Carefully choose the coding standards \nand guidelines that suit the application or \nsystem being developed.\n\u2022\t Consider open standards created by \nParameters\nDistributed Programming\nParallel Programming\nFunctionality\nA task is shared and executed by mul-\ntiple computers that are networked.\nTwo or more processors on a computer \nshare and execute the task in parallel.\nComputers\nMultiple computers in different loca-\ntions but networked.\nTwo computer with one or more \nprocessors or cores.\nMemory\nEach computer has its own memory.\nComputers can have shared or \ndistributed memory.\nCommunication\nComputers communicate \nthrough networks.\nProcesses communicate through a \nbus or inter-process communication \n(IPC) methods.\nBenefits\nFailure of one computer does not \naffect the functioning of the task, as \nit is transferred to another computer.\nProvides scalability and reliability for \nend users.\nAs multiple processes run in parallel, \ngenerally the performance increases. \nFailure of one processor does not \naffect the performance of other \nprocessors or cores\nDisadvantages\nHaving multiple systems could \nbecome expensive; the cost must be \nweighed against customers\u2019 need for \napplication uptime.\nNetwork delays could affect the \noverall functioning of the task.\nDesigning an efficient distributed \ncomputing system is relatively difficult.\nUsing multiple processors or cores \ncould be expensive.\nDependency of one process \non another process could \nintroduce latency.\nExample  \nApplications\nTelephone and cellular networks, \ninternet, World Wide Web networks, \ndistributed database management \nsystems, network file systems, grid \ncomputing, cloud computing.\n2D and 3D simulations and rendering \nin computer graphics, scientific \ncomputing.\nExample  \nProgramming  \nLanguages, \nlibraries \nengines, \nframaworks \nGolang, Elixir, Scala, Fortran,  \nC and C++.\nApache Hadoop, Apache Spark, \nApache Flink, Apache Beam, CUDA, \nOpenCL, OpenHMPP, MPP, \nOpenMP for C, C++ and Fortran.\nTable 16.3. Comparison of Distributed and Parallel Programming\n", "page": 327, "type": "text", "section": "Page 327"}
{"text": "COMPUTING FOUNDATIONS   16-15\ncommunity participation, such as Software \nEngineering Institute (SEI) Computer \nEmergency Response Team (CERT), as \nwell as closed standards created by working \ngroups such as the Motor Industry Software \nReliability Association (MISRA).\n\u2022\t Educate programmers to follow adopted \nstandards and guidelines. \n\u2022\t Use tools and periodic reviews to ensure \nadopted \nstandards \nand \nguidelines \nare followed.\n\u2022\t Review and revise standards and guide-\nlines from time to time, learning from \nproject execution.\nSC 22 is a subcommittee of the Joint \nTechnical Committee ISO/IEC JTC 1 of the \nInternational Organization for Standardization \n(ISO) and the International Electrotechnical \nCommission (IEC) for defining standards for \nprogramming languages, their environments \nand system software interfaces (ISO/IEC \nJTC 1/SC 22).  Software engineers are recom-\nmended to refer these standards as well.\n5.\t Operating Systems\b\n[19*]\nAn operating system (OS) is software that \nmanages the computer\u2019s hardware and pro-\nvides a platform for software applications. \nSoftware engineers need a good general \nunderstanding of OSs and OS objectives, ser-\nvices, and functions.\nDifferent types of OSs have been designed \nover time to support various types of systems \nor applications, including batch processing, \nmultiprogramming, \ntime-sharing, \nand \ndual-mode operation \u2014 for protecting I/O, \nmemory, CPU, kernels and micro-kernels.\nTo choose an appropriate OS, software \nengineers have to analyze different types of \noperating systems, such as single-user, sin-\ngle-tasking, multiuser, multitasking and \nmulti-threading OSs; real-time OS (RTOS); \nnetwork OS; and distributed OS. For small \nsystems, an operating system may not be \nrequired. It is important to study examples \nof each type and compare their benefits and \nlimitations.\u00a0\nSoftware engineers need to understand \noperating systems\u2019 basic structure, system \narchitecture types, design approaches, the \narchitecture of distributed OS and issues in \ndistributed OS.\nAn operating system typically has four \nmajor components: processor management, \nmemory management, device management \nand information management. \n5.1.\t Processor Management\b\n[19*, C2, C8]\nSoftware engineers must understand the \nconcepts of processor, process and address \nspace.\u00a0 They must understand booting, pro-\ncesses, cores, threads, user and kernel threads, \nfork and exec, synchronization, and hardware \nsupport for locking. They should compare and \ncontrast various CPU scheduling concepts, \nscheduling algorithms, algorithm evalua-\ntions, multiple processor scheduling and real-\ntime scheduling, concurrent programming, \ndeadlocks, critical regions, conditional crit-\nical regions, and monitors.\nCommunication among different pro-\ncesses is important in multitasking, mul-\ntiuser OSs. A software engineer must have a \ndeep understanding of inter-process commu-\nnication (IPC), and types of IPCs, including \nmessages, pipes, shared memory, semaphores, \nmodularization and process synchronization.\u00a0\nVarious types of locks are used to ensure \nproper synchronization of data among pro-\ncesses, including semaphores, binary sema-\nphores, counting semaphores and mutex locks. \nDeep understanding of common challenges \nof IPCs, deadlocks, deadlock scenarios, and \ndeadlock characterization; prevention, avoid-\nance, detection and recovery of deadlocks; \nand precedence graphs is critical and to be \ninternalized with the help of case studies.\nSoftware engineers are required to study, \nwith examples, concurrent languages, pro-\ncesses and scheduling, job and process con-\ncepts, and various types of scheduling: \nCPU-I/O interleaving, non-preemption, con-\ntext switching, and scheduling algorithms \n(first come, first served (FCFS), shortest \njob first (SJF), shortest remaining time first \n", "page": 328, "type": "text", "section": "Page 328"}
{"text": "16-16   SWEBOK \u00ae GUIDE V4.0\n(SRTF), priority scheduling, round robin and \ncombined schemes).\n5.2.\t Memory Management\b\n[19*, C3]\nA software engineer needs a very good under-\nstanding of how memory is managed in the \nsystem and of the different types of memory \nand relevant concepts \u2014 physical memory, \nvirtual memory, secondary memory, memory \nhierarchy, linking and memory allocation.\nEngineers must understand memory frag-\nmentation (both external fragmentation, \ninternal fragmentation), and various memory \nmanagement \nconcepts, \nincluding \nunits, \npaging, page tables, segmentation, paged \nsegmentation, virtual memory management, \ndemand paging, page replacement, thrashing \nand swapping.\nMemory is allocated to processes in dif-\nferent ways \u2014 for example, through contig-\nuous allocation, noncontiguous allocation, \ndynamic partitioned memory allocation, stat-\nic-swapping and overlays.\nAn understanding of logical addresses, \npartitions, static versus dynamic memory \nallocation, free space management, and \ndefragmentation of memory blocks is also \nimportant. \nAs the physical memory available is always \nlimited, various memory page replacement \nstrategies are designed and implemented. These \nstrategies include first-in-first-out (FIFO), \nnot-recently-used (NRU), least recently used \n(LRU), most recently used (MRU), least fre-\nquently used (LFU), most frequently used \n(MFU), longest distance first (LDF), second \nchance, and aging among others.\n5.3.\t Device Management\b\n[19*, C5]\nA software engineer must have good knowl-\nedge of different types of I/O devices \u2014 mem-\nory-mapped and I/O-mapped devices, block \nand character devices, and buffering devices. \nEngineers should compare and contrast \npolled, interrupt-driven and direct memory \naccess (DMA) I/O devices, and blocking \nversus non-blocking I/O devices.\u00a0\nDevice drivers are software programs \nthat provide an interface between hardware \nand applications. Software engineers should \nunderstand device drivers, the various types \nof device drivers, device driver tables, device \ndriver functions, and interfaces for various \ntypes of hardware devices, as well as hard-\nware and software interrupts and interfaces \nby interrupts and polling.\u00a0\nSoftware engineers should also understand \nthat issues with caching, scheduling, spooling \nand performance can arise for shared devices \nin multiuser, multitasking OSs and device a \nmechanism for resolving them.\n5.4.\t Information Management\b\n[19*, C4]\nSoftware engineers need to understand the \nfollowing: \n\u2022\t The concept of a process, a system pro-\ngrammer\u2019s view of processes, an operating \nsystem\u2019s view of processes, and operating \nsystem services for process management\n\u2022\t File system management, storage manage-\nment, file attributes, directory structure, \nfile system structure, mass storage struc-\nture, I/O systems, protection and security\u00a0\n\u2022\t User and operating system views of the file \nsystem and various types of file systems \u2014 \nsimple file system, symbolic file system, \nlogical file system and physical file system\nEngineers should be familiar with various \noperations including access control lists (ACLs), \naccess matrix, access control, access control ver-\nification, capabilities allocation strategy, I/O \ninitiators, device strategy, device handlers, disk \nscheduling, disk space management, existence \nand concurrency control, schemes and com-\nbined schemes, authentication schemes, direc-\ntory namespace, hierarchies, directed acyclic \ngraph (DAGs), hard and soft links.\n5.5.\t Network Management\b\n[4*, C4.1]\nNetwork management is the process of \nadministering and managing various types of \nnetworks. This content area includes network \n", "page": 329, "type": "text", "section": "Page 329"}
{"text": "COMPUTING FOUNDATIONS   16-17\nmanagement concepts, distributed objects, \ndistributed file systems, and network archi-\ntecture, design, issues and resolutions.\nA network manager will need detailed \nknowledge of physical and logical time, as \nwell as internal and external synchroniza-\ntion protocols in network management such \nas Cristian\u2019s algorithm, Berkeley\u2019s algorithm, \nthe Network Time Protocol, Lamport\u2019s log-\nical clock, Vector clocks, Casual ordering of \nmessages, and global state.\nOther important topics include distrib-\nuted computation, termination detection, \ndistributed mutual exclusion and election, \nsimple and multicast-based mutual exclusion \nalgorithms; Centralized, Ring based, Ricart \nAgrawala\u2019s algorithm, Maekawa\u2019s algorithm, \nElection algorithms, Bully\u2019s algorithm and \nmulticast communication.\nIn addition, software engineers should \nunderstand important principles include hard-\nware security, external security, operational \nsecurity, password protection, access control, \nsecurity kernels, and the layered approach.\n6.\t Database Management\nA database is a collection of related data ele-\nments, collected specifically for use by one or \nmore applications and stored in an organized \nformat for easy and quick access, using one or \nmore key values. The data items or elements \nare stored in one or more databases or files, \nand the relationship among them is estab-\nlished using a database schema.\nBasic operations performed on the database \ninclude creating the database and its elements \n(table, index, views, functions, procedures, \netc.), deleting or dropping items from the \ndatabase, modifying contents and structure \nof the database, and data retrieval, comment, \nand rename actions.\nDifferent types of databases include rela-\ntional databases, not only structured query \nlanguage (NoSQL) databases, columnar data-\nbases, object-oriented databases, key-value \ndatabases, document databases, hierarchical \ndatabases, graph databases, time series data-\nbases, and network databases. Understanding \nwhat type of database works best for specific \napplications and analyzing the definition, \nstructure, specific pros and cons of each type \nof database; what along with examples helps \nsoftware engineers choose the right type of \ndatabase for a given application. \nWhen selecting a database, software engi-\nneer should evaluate data models, storage \nmodels, types of databases, key values, graphs, \ncolumn family, volume of data, consistent data \naccess time, and the number of users or appli-\ncations accessing the database (traffic), etc.\nThe learners and users of the database system \nneed to create two roles (database user and \ndatabase architect), review several case studies \nof increasing complexity, create multiple data-\nbases, and analyze the information. This process \nsignificantly helps one to understand and inter-\nnalize the database design and management.\n6.1.\t Schema\b\n[22*, C2.1.4]\nA database schema is a structure or record of \ndata items, defined in one or more database \ntables, and the relationships between them. \nThe schema may also contain formulae to \ncheck the integrity of data items, relationships, \nindexes, functions or procedures and views. \nWhile a physical schema explains how the \ndatabase is designed at physical level (files), \nthe logical schema describes how different \ndata items are defined in one or more tables \nand interconnected.\nDifferent types of schemata used in the \nindustry include star, snowflake and fact con-\nstellation schemata. Different types of keys used \nin schemata include Primary Key, Secondary / \nAlternate Key, Foreign Key, Composite Key, \nSurrogate Key and Candidate Key. \nParameters that influence the definition \nand use of schemata include overlap preserva-\ntion, extended overlap preservation, normal-\nization and minimality.\n6.2.\t Data Models and Storage Models \n\b\n[22*, C2.3]\nA data model specifies the logical aspects of \ndata structure in a data store, and a storage \n", "page": 330, "type": "text", "section": "Page 330"}
{"text": "16-18   SWEBOK \u00ae GUIDE V4.0\nmodel specifies the physical aspects of data \nstructure in a data store. It is difficult to \nachieve both data consistency and high avail-\nability in a database.\nThe two primary data models used to dis-\ntinguish databases are the following:\n\u2022\t The ACID (atomicity, consistency, isola-\ntion, durability) model provides for high \ndata consistency. ACID-compliant data-\nbases are ideal for a finance-intensive \napplication.\n\u2022\t The BASE (basically available, soft state, \neventual consistency) model provides \nflexible methods to process data, which \nsuits NoSQL database types.\nTypes of storage models include the \nfollowing:\ni.\t\nDAS (direct access storage): Storage \ndevices are physically or directly con-\nnected to the computer that pro-\ncesses the data.\nii.\t NAS (network access storage): Data is \nstored in a network and accessed by mul-\ntiple computers or applications.\niii.\t SAN (storage area network): Data is stored \nin multiple servers and efficiently provided \nto users through a computer network. \n6.3.\t Database Management Systems \b [22*, C1.3]\nDatabase management systems (DBMSs) are \nsoftware systems that provide the necessary \ntools for maintaining data optimally, retrieving \nstored information effectively, protecting and \nsecuring stored data, and managing access for \nusers of different levels of authority.\nTypical DBMSs include:\n\u2022\t A database engine: This is the core of a \nDBMS. The database engine manages \nefficient storing and retrieving of data. \nUsers with privileges can access the data-\nbase engine.\n\u2022\t A database manager: This program or set \nof programs performs all DBMS func-\ntionality in a database (creating, purging, \nbacking up, retrieving, maintaining, \ncloning and deleting data). It is also \nresponsible for maintaining the DBMS \nwith patches and updates.\n\u2022\t A runtime database manager (RDM): \nThe RDM checks for user authentica-\ntion and privileges before any operation \nis performed, provides access to a con-\ntext-based database, provides concurrent \naccess to the database by multiple users, \nand ensures data integrity.\n\u2022\t Database languages: These help in storing, \nretrieving, modifying and retrieving data, \ncontrolling user access (privileges), speci-\nfying schemata and views, and performing \nvarious operations. Popular database lan-\nguages include data definition language \n(DDL), database access language (DAL), \ndata manipulation language (DML), \nTransaction Control Language (TCL), \nand data control languages (DCL), \n\u2022\t A query processor: This basic and key com-\nponent of DBMS provides an effective, \nrich and English-like interface for users \nto access the database and perform var-\nious functions or operations.\n\u2022\t Reporting: Reporting applies specified fil-\nters, extracts requested data and records \nfrom one or more database tables, and \npresents information as specified.\nSeveral free and open-source database \nmanagement systems are available. \n6.4.\t Relational Database Management Systems \nand Normalization\b\n[22*, C4]\nConventional file system-based databases \nsuffered from data redundancy, data incon-\nsistency, data access challenges, unautho-\nrized access, lack of concurrent access, among \nother issues. \nA relational database management system \n(RDBMS) stores data in tables and, unlike in \na DBMS, its data tables relate to one another, \nmultiple data items can be accessed simulta-\nneously, a large amount of data is handled, \nmultiple users can access data concurrently, \ndata redundancy is significantly reduced, and \n", "page": 331, "type": "text", "section": "Page 331"}
{"text": "COMPUTING FOUNDATIONS   16-19\nmultiple levels of data security are supported.\nComputer science engineers must under-\nstand the difference between the various types \nof RDBMS, such as Objective RDBMS, Object \nOriented RDBMS, be familiar with examples, \nand know the applications they suit best.\nDatabase normalization is the process of \norganizing data in a database and removing \ndata redundancy and data inconsistency from \nthe tables. Normalization might increase \nthe number of tables and increase the query \ntime. If this occurs, then \u2014 depending on the \napplication and the requirement \u2014 de-nor-\nmalization is applied, where data redundancy \nis added for quicker data access. \nDifferent types of database normalizations \nare the following:\ni.\t\nFirst normal form (1 NF): Removes dupli-\ncation or redundancy. Each table cell \nhas a single value (creates more entries \nand tables). Each row has unique values. \nRelated data is identified with a unique key.\nii.\t Second normal form (2 NF): The table \nshould be in 1 NF; no partial dependency \n(creates separate tables with records refer-\nenced by multiple records or tables).\niii.\t Third normal form (3 NF): The table \nshould be in 2 NF. Transitive dependen-\ncies are removed.\niv.\t Boyce-Codd normal form (BCNF/3.5 \nNF): The table should be in 3 NF, and X \nshould be the super-key for any (X->Y).\nv.\t\nFourth normal form (4 NF): The table \nshould be in 3.5 NF and should not have \na multivalued dependency.\nvi.\t Fifth normal form (5 NF): The table \nshould be in 4 NF and cannot be split \ninto any more tables without losing data.\nvii.\t Sixth normal form or domain/key normal \nform (6 NF/DKNF): The table should be in \n5 NF, and every join dependency is trivial.\nMost databases are typically normalized \nuntil 3 NF or BCNF. An alternative normal \nform, DKNF, is defined where insertion and \ndeletion of anomalies is avoided (see [13]). \nDatabase \nengineers \nare \nencouraged \nto understand normalization forms with \nexamples and case studies and to understand \nthe challenges one would face if the database \nwere not normalized. Although normaliza-\ntion is essential and provides various benefits, \nit also increases the number of tables and pro-\ncessing time. \n6.5.\t Structured Query Language  \n\b\n[22*, C6, C7, C8]\nStructured query language (SQL) is a stan-\ndard and popular database language for cre-\nating, updating, and deleting databases and \nfor retrieving information from databases. \nSQL is an inevitable part of most database \nmanagement systems. \nTypical SQL syntax has several language \nconstructs or elements, including clauses, \nexpressions, predicates, queries and statements. \nAll operations on a database, including cre-\nating, updating, deleting and viewing tables; \nperforming different normalizations; purging \ndata; and searching through the database \nbased on various combinations of parameters \nor filters, can be performed using SQL.\nMost databases support SQL (except \nNoSQL databases), and the SQL syntax and \nlibrary of functions supported vary across \ndatabase providers (much like programming \nlanguages \u2014 though different languages sup-\nport similar features, the syntaxes vary). \nDatabase engineers also have to decide \nwhether \nto \nuse \nstatic/embedded \nSQL, \ndynamic SQL or a combination of the two, \nafter weighing the pros and cons of each option \nfor the particular application. They should \nalso know the differences between simple and \ncomplex views and use them appropriately.\nSQL is standardized and adopted by the \nAmerican National Standards Institute (ANSI) \nand ISO. The standards are revised from time to \ntime; the first SQL standard was SQL-86, issued \nin 1986, and the most recent is SQL:2019. \n6.6.\t Data Mining and Data Warehousing \n\b\n[22*, C34]\nDatabases are designed to store transactions \nand retrieve them efficiently. \n", "page": 332, "type": "text", "section": "Page 332"}
{"text": "16-20   SWEBOK \u00ae GUIDE V4.0\nData warehousing extracts data from mul-\ntiple databases efficiently and stores it in a \ncommon database so data mining can be per-\nformed effectively on the compiled data. Data \nwarehouses are typically huge, as they store \nhistorical data records.\nData mining extracts requested informa-\ntion from the data warehouse, applying var-\nious filters and conditions. Data mining \napplies pattern recognition algorithms to \nhuge data sets to generate required reports. \nThe different types of warehouses include \nenterprise data warehouse (EDW), operational \ndata store (ODS), and data mart (DM).\nMany efficient tools are available to create \ndata warehouses and mine data from them.\nDatabase engineers must know different \ndata mining techniques, including associa-\ntion, clustering, classification, sequential pat-\nterns and prediction, and know how to apply \nthem for various uses and industries, such as \nhealth care, fraud detection, customer rela-\ntionship management, finance and banking, \nanomaly detection, prediction, neural net-\nworks, statistics, and data visualization.\n6.7.\t Database Backup and Recovery\b [22*, C22]\nDatabase systems are prone to failures, and \ndata can be corrupted. It is crucial to prevent \ndata corruption and \u2014 if it does occur \u2014 to \nrecognize it immediately and recover the data.\nUpdating the database for transactions \nmust be carried out carefully (with commits \nat specific checkpoints), and must incorporate \ntechniques such as undoing, deferred updates, \nimmediate updates, caching or buffering, and \nshadow paging. \nDatabases must be backed up periodi-\ncally to ensure data safety. Backup techniques \ninclude Full database backup, Differential \nbackup and Transaction log backup. \n7.\t Computer Networks and \nCommunications\b\n[4*, C4.1], [24*, C1]\nA computer network is a group of devices that \nare connected for sharing information. The \nconnected devices (nodes on the network) \ncan be located near one another, on the same \npremises, or somewhere else. Networking is \nrequired for certain benefits, including cer-\ntain modes of communication and infor-\nmation sharing; the ability to share devices \nsuch as printers, routers and video cameras; \nglobal information and data storing; security \nand policy enforcement; remote monitoring; \nshared business models; and web browsing. \nAs we are in the internet era, computer net-\nworking is a critical element in computing, and \nthe practitioners of computer science engineering \nhave to study computer networks and commu-\nnication concepts, including examples and case \nstudies. Many computing paradigms (distrib-\nuted computing, grid computing, cloud com-\nputing, etc.) are based on networking principles. \nIt is important for software engineers to \nunderstand the following: \n\u2022\t Different types of computer networks.\n\u2022\t Layered architectures of networks.\n\u2022\t Open systems interconnect (OSI) layers \n\u2022\t Encapsulation and decapsulation.\n\u2022\t Application layer protocols.\n\u2022\t Design techniques for reliable and effi-\ncient networking.\n\u2022\t Internet and packet delivery.\n\u2022\t Wireless and mobile networks.\n\u2022\t Security and vulnerabilities.\n7.1.\t Types of Computer Networks \n\b\n[4*, C4.1], [24*, C1.2.1]\nDifferent types of computer networks are \ndesigned and used based on the need, such as \nthe following:\n1.\t Personal \narea \nnetwork \n(PAN) \n/ \nhome network.\n2.\t Local area network (LAN).\n3.\t Wireless local area network (WLAN).\n4.\t Wide area network (WAN).\n5.\t\nCampus area network (CAN).\n6.\t Metropolitan area network (MAN).\n7.\t\nStorage area network (SAN).\n8.\t System-area network (SAN).\n9.\t\nEnterprise private network (EPN).\n10.\t Virtual private network (VPN).\n", "page": 333, "type": "text", "section": "Page 333"}
{"text": "COMPUTING FOUNDATIONS   16-21\nIt is important to understand each of the \nabove network type as well as examples, ben-\nefits, limitations and available solutions to cir-\ncumvent challenges.\n7.2.\t Layered Architectures of Networks \n\b\n[24*, C1.5]\nA communication system includes hardware \nand software, and these components have \nbecome complex to meet complicated use \nscenarios and user demands. To support the \nimplementation and maintenance of such sys-\ntems, ISO has developed a layered approach, \nwhere every layer has specific functionality for \nprocessing data and transferring it from one \nnode to another.\nEach layer is independent in its function-\nality and provides services from the lower \nlayer to the upper layer without providing \ndetails of how each layer\u2019s service is imple-\nmented. Each layer (\u201cn\u201d) on a machine com-\nmunicates with the same layer (\u201cn\u201d) on the \npeer machine. Rules used in a conversation \nare called layer-n protocol (see Figure 16.4).\nThe basic elements of the layered approach \nare service, protocol and interface. \n\u2022\t Service: The set of actions a layer provides \nto the adjacent higher layer is the service.\n\u2022\t Protocol: The set of rules a layer uses \nto exchange information with the peer \nentity is called the protocol. The rules are \nprimarily for managing both the contents \nand order of the messages used.\n\u2022\t Interface: The interface provides a \nmedium for transferring the message \nfrom one layer to another layer.\nSoftware engineers are expected to under-\nstand the essential functionalities required, \nvarious modes in which the data or information \nis communicated from one layer to the other, \nand data packet formation and interpretation \nat peer levels. A useful exercise is to take exam-\nples of different protocols and analyze them.\n7.3.\t Open Systems Interconnection Model \n\b\n[24*, C1.5]\nThe Open Systems Interconnection (OSI) \nModel was defined by the ISO. It serves as \na reference model for information exchange \nbetween applications on two systems or com-\nputers through a physical medium. \n  \n \nLayer 5 (Application Layer)\nLayer 5 (Application Layer) \nLayer 4\nLayer 4\nLayer 3\nLayer 3\nLayer 2\nLayer 2\nLayer 1 (Physical Layer)\nLayer 1 (Physical Layer)\nLayer 5 Protocol\nLayer 4 Protocol\nLayer 3 Protocol\nLayer 2 Protocol\nLayer 1 Protocol\nFigure 16.4. Pictorial Representation of Layered Networking\n", "page": 334, "type": "text", "section": "Page 334"}
{"text": "16-22   SWEBOK \u00ae GUIDE V4.0\nOSI proposes seven (7) layers, and each \nlayer is assigned a specific task. Each layer \nindependently processes the data it receives \nfrom the upper or lower layer and passes it to \nthe lower or upper layer, as appropriate.\nEngineers must understand each OSI \nlayer, its functionality protocol, the input \nand output of each layer in each direction \n(from lower layer to upper layer and vice \nversa). Engineers should analyze whether \nall seven layers are required for all proto-\ncols and what is necessary to optimize for \nperformance.\n1.\t Physical Layer (Layer 1).\n2.\t Data Link Layer (Layer 2).\n3.\t Network Layer (Layer 3).\n4.\t Transport Layer (Layer 4).\n5.\t\nSession Layer (Layer 5).\n6.\t Presentation Layer (Layer 6).\n7.\t\nApplication Layer (Layer 7).\nEngineers must understand the nuances of \neach layer, with examples. \n7.4.\t Encapsulation and Decapsulation \n\b\n[24*, C1.5.2]\nEach layer, while sending data from the \nupper layer to the lower layer, inserts \nadditional information at the beginning \n(header) and optionally at the end of the \ndata packet received from the upper layer, \ntreating the packet received from the upper \nlayer as data. This is encapsulation. The \nprotocol data unit (PDU), which is the \ndata packet containing additional informa-\ntion from all layers, is sent to the receiving \nsystem. At the receiving end, each layer \nextracts its header from the PDU, deciphers \nthe information to treat the data appropri-\nately, and sends the remaining PDU to the \nupper layer. \nLearning about cross-layer optimization, \nthe principles to which it must adhere, and its \napplications is important. Engineers should \nanalyze the PDU structures of each layer of \nOSI, the Internet protocol suite and the asyn-\nchronous transfer mode (ATM).\n7.5.\t Application Layer Protocols\b\n[24*, C2]\nThe application layer, being the top most layer, \nprovides services and interfaces to interact with \nusers\u2019 application. There are two types of appli-\ncation layers in the OSI model: common appli-\ncation service element (CASE) and specific \napplication service element (SASE). Example \napplications include file transfer (FTP, TFTP, \nNFS), remote login (Telnet, Zoho Assist, \nAnydesk, TeamViewer, etc), e-mail (SMTP) \nnetworking support (DNS), network manage-\nment (SNMP, DHCP), devices (LPD), etc. \nSoftware engineers practicing in a net-\nworking domain need to understand CASE \nand SASE application services, including \nexample applications in each category.\n7.6.\t Design Techniques for Reliable and Efficient \nNetwork\b\n[24*, C1.5]\nToday\u2019s information technology-based busi-\nnesses need around-the-clock, reliable, effi-\ncient and scalable networks and high-speed \ninternet availability. Catering to varied busi-\nness needs, the networks and their manage-\nment has become complex as well. \nIt is critical to identify network require-\nments (both business goals and technical solu-\ntions) along with a road map (scalability). The \nfundamental design goals should include reli-\nability, security, availability and manageability. \nEngineers should expect threats and intrusions \nat multiple levels and design security at mul-\ntiple levels. Systems must be set up to monitor \nthe networks for both proper functioning and \nmalfunctioning; identify faults, vulnerabilities \nand hacks quickly; and fix them. \nEngineers must understand and learn the \nnuances of designing a network while using \nappropriate firewalls, LAN/VLANs, subnets, \nquality of service (QoS), Demilitarized Zone \n(DMZ), Spanning Tree (especially for hier-\narchical network), port or network interface \ncontroller (NIC) channel, security (both poll \nsecurity and physical security), wireless access \npoints, and wireless access controllers.\nEven when the design and implementation \nare well planned and executed, one has to be \n", "page": 335, "type": "text", "section": "Page 335"}
{"text": "COMPUTING FOUNDATIONS   16-23\nconstantly vigilant for attacks and continuously \nupgrade to better systems, devices and tools.\n7.7.\t Internet Protocol Suite\b\n[24*, C3]\nData is transmitted in packets from one com-\nputer to another, either in the same network \nor in a different one. The Internet Protocol \nsuite, or TCP/IP, defines data communi-\ncation between two computers connected \nvia the internet. The top three layers of the \nOSI model (Application, Presentation and \nSession layers) are merged into the applica-\ntion layer, and the network layer is revised \nspecifically for internet functioning. Internet \nProtocol is the fulcrum of today\u2019s internet or \nnetwork layer. \nMultiple variations of Internet Protocols \nare designed and used for different purposes. \nThe protocols include TCP/IP (Transmission \nControl Protocol/Internet Protocol), UDP/IP \n(User Datagram protocol / Internet Protocol), \nSMTP (Simple Mail Transfer Protocol), PPP \n(Point to Point Protocol), FTP File Transfer \nProtocol, SFTP (Secure FTP), HTTP \n(Hyper Text Transfer Protocol), HTTPS \n(HTTP Secure), Telnet (Terminal Network), \nPoP3 (Post office Protocol 3), VOIP (Voice \nover Internet Protocol), SLIP (Serial Line \nInternet Protocol). It is important to know \nthe differences between these along with use \ncases (applications where each type is used or \nwhere it works best). \nMobile Internet Protocol is a communi-\ncations protocol that conforms to an IETF \n(Internet Engineering Task Force) standard \nand allows users to move their mobile devices \n(laptops, mobile phones, etc.) seamlessly from \none network to the other without changing \nthe IP address.\nInternet Protocol Version 4 (IPV4) uses a \n32-bit IP address, whereas IPV6 uses 128-bit \nIP addresses. \nPrivate IP addresses are translated into \npublic IP addresses using either NAT (net-\nwork address translation) or PAT (port \naddress translation). Both use IPV4, but PAT \nuses port numbers. Different technologies \nused to communicate between IPV4 and IPV6 \ndevices include dual-stack routers, tunneling \nand NAT protocol translators.\nProfessional computer network architects \nand programmers need to understand IPV6 \naddressing, routing, transitioning to IPV6 from \nIPV4, dual-dress stacks, tunneling and NAT64. \n7.8.\t Wireless and Mobile Networks\b\n[c24*, C7]\nWireless networks provide the ability for \ndevices to connect and communicate without \nthe hassle of wires and cables. They also pro-\nvide flexibility and ease of using the devices. \nDifferent wireless technologies are used for \ndifferent applications: \n\u2022\t Wireless personal area networks (WPAN). \n\u2022\t Wireless local area networks (WLAN) .\n\u2022\t Wireless wide area networks (WWAN). \nA mobile or cellular network is a radio \nnetwork spread over a specific area of land \n(called a cell). The cells are served by base sta-\ntions, which are fixed-location transceivers. \nTo avoid interference and ensure guaran-\nteed bandwidth, the adjacent cells use a dif-\nferent set of frequencies. These cells, when \nconnected, provide wide area radio coverage. \nThe cell patterns take different shapes, but \nsquares, circles and hexagons are typical. \nDifferent methods of data transmission \nare used between channels, such as frequency \ndivision multiple access (FDMA), time divi-\nsion multiple access (TDMA), code division \nmultiple access (CDMA), space division mul-\ntiple access (SDMA), etc. \nWireless technology has evolved over sev-\neral generations. Software Engineers are \nencouraged to learn the differences among 1G, \n2G, 3G, 4G and 5G technologies, along with \nthe core network, access system, frequency, \nbandwidth and technologies used in each.\n7.9.\t Security and Vulnerabilities\b\n[24*, C9]\nAlthough wireless technology provides the \nease of connecting seamlessly to the network, \nit is also prone to attacks unless the network is \nsecured. Risks to unsecured wireless networks \n", "page": 336, "type": "text", "section": "Page 336"}
{"text": "16-24   SWEBOK \u00ae GUIDE V4.0\ninclude Piggybacking, Wardriving, Evil Twins \nattacks, Wireless sniffing, Unauthorized com-\nputer access, Shoulder sniffing and Theft of \nmobile devices.\nCommunication over the internet via \nmobile device is highly vulnerable to cyber-\nattacks. In addition to wardriving, mentioned \nabove, typical wireless and mobile device \nattacks include SMiShing, War driving, WEP \nattacks, WPA attacks, Bluejacking, Reply \nattacks, Blue snarfing, RF Jamming, etc.\nMany precautionary measures must be \nimplemented and strictly followed to reduce \nsuch risks. These measures include changing \ndefault passwords, changing passwords fre-\nquently, restricting access to authorized \nusers, encrypting data in the system and on \nthe network, and installing multiple levels \nof firewalls. In addition, users must protect \nand hide (not publicize) service set identifier \n(SSID), use effective antivirus software, and \nupdate and upgrade it regularly; use a virtual \nprivate networks (VPN), use file-sharing or \nsystem-sharing access with care, and disable \naccess after use; and update or upgrade the \naccess point or access controller, gateway and \nother devices with security patches when they \nbecome available. \n8.\t User and Developer Human Factors\nThe thought processes and behaviors of soft-\nware developers typically differ from that of \nsoftware users. This content area identifies \nsalient parameters that matter for end users \nas well as the perspective of the developers. \nHuman-computer interface (HCI) focuses \non designing and developing computer \ntechnology for users to interact with com-\nputing systems.\nUser satisfaction is measured in terms of \nuser experience (UX). An ideal interface \nwould facilitate interaction that is as natural \nas the interaction between two human beings.\n8.1.\t User Human Factors\b\n[3*, C8]\nUsers expect software to be robust; to have an \nintuitive graphical user interface (GUI) that \nguides the user through minimal, intelligent, \neasy-to-follow steps to achieve the end result; \nto be secure; and to provide fast, consistent \nresponses.\nThe interface should help users use the \nsystem easily. The interface should be self-ex-\nplanatory and enable self-learning. The mes-\nsages, whether communicating results or \nerrors, should be clear and complete. The \nsystem should be able to regain its original \nstate if there are errors. \nThe system should allow users to interrupt \nduring the processing and undo the operation, \nwherever possible. \nThe software engineer needs to identify \nthe profile of users the system; system\u2019s func-\ntionality, input and output interfaces users \nuse (keyboard, touch pad, audio, video, etc.) \nto interact with the system, the system\u2019s fault \ntolerance, the system\u2019s performance parame-\nters. among others.\nTypically, user interface development goes \nthrough several iterations, starting with a proto-\ntype. The user interface devices must be robust.\n8.2.\t Developer Human Factors\b [3*, C31 - C32]\nThe software lives much longer than the time \ntaken to develop.  Invariably, the software \nengineers who maintain the code are different \nfrom those who develop.  Hence, the code has \nto be written with more care and for use by \nother programmer / software engineer.\nMeaningful and comprehensive docu-\nmentation is crucial at all stages of software \nlifecycle.  \nDefining and adopting apt coding stan-\ndard for the project, and ensuring every team \nmember implements the same in spirit is key \nfor developing clean code that lives longer \nwith minimal maintenance.\nProgramming style is another key ingre-\ndient of a good code.  Code has to be legible, \nshould be like reading a good poem and easily \ncomprehendible.  Using meaningful, consis-\ntent and detailed comments is essential to \nensure code readability. \nOther traits of a good software pro-\ngrammer include being a team player, enjoy \n", "page": 337, "type": "text", "section": "Page 337"}
{"text": "COMPUTING FOUNDATIONS   16-25\nsolving puzzles creatively, be agile, be struc-\ntured / modular among others.\nGood coding standards include defining \nnaming conventions for various types of vari-\nables, functions/procedures, comment struc-\nture/styles, indentation styles, structuring the \ncode into paragraphs (of related functions), etc.\n\u201cCode is read many more times than it is \nwritten. Consider\u00a0whether write-time conve-\nnience is a false economy\u201d \u2014 Steve McConnell\n\u201cClean\u00a0code always looks like it was written \nby someone who cares\u201d \u2014 Robert (Uncle \nBob) Martin\n9.\t Artificial Intelligence and Machine \nLearning\b\n[17*]\nIntelligence is the ability to acquire and cor-\nrelate information and knowledge to make a \ncorrect decision for a specific task. Artificial \nintelligence (AI) enables computer systems \nto become intelligent, like human beings. \nMachine learning (ML) enables computer sys-\ntems to learn from experiences and to use the \nknowledge gained to make smart decisions \n\u2014 to become artificially intelligent. Deep \nlearning uses artificial neural network models \nfor learning and making predictions.\nEveryone expects all systems they use to \nbe smart, reliable, consistent, secure and \nfault-tolerant \u2014 and to get better every day. \nAI and ML work toward enabling systems to \naccomplish all this.\nAn ideal AI system would be one that a \nhuman could not identify it as a computer; \nhumans would not be able to distinguish the \ncomputer from a human being.\nSeveral tools have been developed and are \navailable for creating AI systems. Using proven \ntools helps engineers build a stable system faster.\n9.1.\t Reasoning\nReasoning means analyzing sets of informa-\ntion available for a given situation and deter-\nmining the cause of the situation. Reaching \nthis conclusion is an important ability of AI, \nas the conclusion informs AI\u2019s decision about \nwhat to do next. \nDifferent types of reasoning used in AI \ninclude the following:\nDeductive Reasoning is a standard and stra-\ntegic approach to mapping available facts, \ninformation and knowledge to arrive at a con-\nclusion. In this approach, available facts and \ninformation are considered to be authentic. \nFor example, if the premises are \u201cAll girls are \nbeautiful\u201d and \u201cMichu is a girl,\u201d then the con-\nclusion is \u201cMichu is beautiful.\u201d\nInductive Reasoning is about introducing a \nhypothesis and creating generalizations from \nthe available facts and premises. Unlike deduc-\ntive reasoning, in inductive reasoning, even if \nthe premises are certain, the conclusion would \nbe probable, depending on whether the induc-\ntive argument is strong or weak. For example, \ncheck the location of all engineers working \non a project and if they are from Bengaluru, \nIndia state \u201cAll employees working on the \ngaming project are from Bengaluru.\u201d\nAbductive Reasoning starts with an incom-\nplete set of data or information and proceeds \nto derive the most likely conclusion from the \nlatest data. For example, a doctor analyzes the \nlatest lab reports of a patient to predict the \ncourse of the disease. \nCommon Sense Reasoning makes inferences \nabout situations based on similar past expe-\nriences. For example, if a motorcycle skids \nwhile driving on a wet road, that informa-\ntion is remembered and considered during \nfuture rides.\nMonotonic Reasoning occurs when the con-\nclusion remains permanent or constant after it \nis reached. For example, \u201cThe Himalayas are \none of the tallest mountain ranges.\u201d\nNon-Monotonic Reasoning (NMR) occurs \nwhen the inference changes values or direc-\ntion based on new knowledge or information. \nNMR is based on assumptions and deals with \n", "page": 338, "type": "text", "section": "Page 338"}
{"text": "16-26   SWEBOK \u00ae GUIDE V4.0\nincomplete or not-known facts. For example, \nthe rule is \u201cBirds fly\u201d. But a few birds do not \nfly including penguins.  \nSoftware engineers are encouraged to learn \nother reasoning methods, such as metalevel \nreasoning, procedural numeric reasoning, and \nformal reasoning, as well.\n9.2.\t Learning\nWe learn from our observations, experiments \nand experiences. Enabling computers to \nlearn and to remember what they\u2019ve learned \nfor future use is critical for building AI sys-\ntems. An AI system learns when observations \nand outcomes of experiments (signals) are \nfed back into the system. Different types of \nlearning include the following:\nSupervised Learning, the computer system \ntrains by receiving labeled (i.e., training) data. \nSubsequently, when any input is provided, \nthe system compares it with the data it was \ntrained on and generates output. Naturally, \nthe more training data, the better the out-\ncome. Supervised learning uses multiple \nlearning techniques, including the classifica-\ntion technique and the regression technique. \nSupervised learning may not be able to handle \ncomplex tasks.\nUnsupervised Learning, labeled or training \ndata is not provided to the system. The system \nhas to figure out common patterns from the \ninput given and make inferences. The data is \nanalyzed in real time. \nSemi-supervised Learning, the system is \ntrained with partly labeled and partly unla-\nbeled data. This type of learning has been \nshown to be effective.\nReinforcement Learning is based on inter-\nactions with the environment. In this type \nof learning, the system receives feedback \n(an error message or a reward) and learns \nfrom that feedback. No data is provided to \nthe system (neither labeled nor unlabeled). \nVarious algorithms are produced in reinforced \nlearning. This is a trial-and-error method \nfor learning.\nSoftware engineers working on AI are \nexpected to know various other learning \ntechniques as well, including dimension-\nality reduction learning, self-learning, feature \nlearning, sparse learning, anomaly detection \nand robot learning, along with the key differ-\nences between the methods and the applica-\ntions where each method works well.\n9.3.\t Models\nAI models are inference engines or tools \n(algorithms) that can arrive at the best deci-\nsions based on relevant data.\nDifferent models are created to enable effi-\ncient ML, with or without training data. \nModels used in ML include the following:\nLinear Regression model is based on super-\nvised learning, where the relationship between \ninput and output variables is determined and \nused. This model is commonly used in health \ncare and banking applications.\nLogistic Regression model is a statistical \nmodel primarily used for classifying dependent \nvariables from given independent variables. \nArtificial Neural Networks are inspired by \nbiological neural networks in a brain. The sys-\ntems are designed to learn naturally from the \ninputs without specific rules. \nDecision Tree model is used where past deci-\nsions are used to arrive at a decision. The name \n\u201ctree\u201d is used because the data is stored in the \nform of a tree. \nNa\u00efve Bayes model works on the assumption \nthat the presence of a feature does not depend \non the presence of any other feature. Spam \nfiltering is one of the applications that suits \nthis model.\nSupport Vector Machine (SVM), is a super-\nvised ML algorithm used to analyze a limited \nquantum of data. SVM is typically faster than \n", "page": 339, "type": "text", "section": "Page 339"}
{"text": "COMPUTING FOUNDATIONS   16-27\nartificial neural networks because it works \nwith limited data.\nRandom Forest model uses multiple decision \ntrees for making a final decision. The random \nforest model is useful for solving both regres-\nsion and classification problems.\nAI models are key to making the most \nappropriate decisions. As different models \nsuit specific applications or domains, software \nengineers are encouraged to learn many other \nAI models as well, such as Linear Discriminant \nAnalysis, Learning Vector Quantization, \nK-nearest Neighbors (KNN), etc.\n9.4.\t Perception and Problem-Solving\nSolving a problem efficiently and quickly is \nthe goal of AI. Problem-solving predomi-\nnantly comprises understanding user com-\nmands and executing them, as humans do. \nDepending on the application and problem to \nbe solved, AI systems use the relevant knowl-\nedge base and predicate logic to identify the \nmost appropriate solution. \nAI systems dealing with the external world, \nobtain environmental data through sensors \n(cameras; microphones; temperature, pres-\nsure and light sensors, etc.), analyzes the data \nusing its knowledge base or inference engine, \nand acts upon it.\nBased on capabilities and functionality, AI \nsystems are categorized into multiple types. \nType I AI systems are designed to do \nspecific tasks with intelligence.  Examples \ninclude Chess games, speech and image rec-\nognition, among others.\nType II AI systems analyze the current sit-\nuation or environment and do not normally \nrefer to previous decisions made in a similar \nsituation to arrive at an appropriate action. \n \nReactive systems or reactive machines typically \nmake decisions and execute commands at that \ninstance, referring to the existing knowledge \nbase. A good example is a self-driving cars.\nType III, or self-aware, AI systems have \nconsciousness and are mindful. These systems \nadopt the mind theory and predict the mood \nof the other person or entity based on the \nperson\u2019s action or type of action. For example, \nif the driver in the vehicle behind the system \nhonks, then the AI system might conclude \nthat the driver is angry or unhappy. Social and \nethical behavior is part of conscious systems.\n9.5.\t Natural Language Processing\nNatural language processing (NLP) is a crucial \npart of AI systems, enabling users to interact \nwith the AI systems in a way that is similar to \nhow they interact with other humans. AI sys-\ntems understand human languages and exe-\ncute commands delivered in those languages. \nAI systems that work on voice commands need \nto understand not only the human language, \nbut also the slang or pronunciation of the user. \n9.6.\t AI and Software Engineering\nSoftware engineering and AI are mutually \nrelated to each other in basically two ways: AI \napplications in software engineering (i.e., AI \nfor SE) and software engineering for AI sys-\ntems (i.e., SE for AI). \nAI for SE aims to establish efficient ways \nof building high-quality software systems by \nreplicating human developers\u2019 behavior. It \nranges over almost all development stages, \nfrom resolving ambiguous requirements to \npredicting maintainability, particularly well \napplied in software quality assurance and \nanalytics, such as defect prediction, test case \ngeneration, vulnerability analysis, and pro-\ncess assessment [15]. Although human-cen-\ntric software engineering activities benefit, \nengineers should be aware of limitations and \nchallenges inherent to the nature of AI and \nML, especially the uncertain and stochastic \nbehavior and the necessity of sufficiently \nlabeled and structured datasets [15].\nThe development of AI systems is different \nfrom traditional software systems since the \nrules and system behavior of AI systems are \ninferred from training data rather than written \ndown as program code [16]. Thus, there is a \nneed for particular support of SE for AI, such \nas interdisciplinary collaborative teams of data \nscientists and software engineers, software \n", "page": 340, "type": "text", "section": "Page 340"}
{"text": "16-28   SWEBOK \u00ae GUIDE V4.0\nevolution focusing on large and changing \ndatasets, and ethics and equity requirements \nengineering [16]. Recommended software \nengineering practices for AI are often formal-\nized as patterns, such as ML software design \npatterns [17].\nMATRIX OF TOPICS VS. REFERENCE MATERIAL\nTopics\nTanenbaum, Bos [19*]\nCLRS [18*]\nH.Washizaki [17*]\nHorowitz et al. 2007 [5*]\nS McConnell [3*]\nSommerville 2011 [6*]\nL. Null and J. Lobur [8*]\nArticles and Journals\nJ.G. Brookshear [4*]\nThomas Connolly,  \nCarolyn Begg [22]\nKurose & Ross [24]\n1. Basic \nConcept of \na System \nor Solution\nC10\n2. Computer \nArchitecture \nand \nOrganization\n2.1 Computer \nArchitecture\nC1.1\n2.2 Types of \nComputer \nArchitecture\nC4.14, \nC5\n2.2.1 Von \nNeumann \nArchitecture\nC1.9\n2.2.2 Harward \nArchitecture\n[20]\n2.2.3 Instruction \nSet Architecture\nC4.8.3\n2.2.4 Flynn\u2019s \nArchitecture \nor Taxonomy\nC9.3\n2.2.5 System \nArchitecture\nC6\nC6\n2.3 Micro \nArchitecture \nor Computer \nOrganization\nC4\n2.3.1 Arithmetic \nLogic Unit\nC1.2\n2.3.2 \nMemory Unit\nC6\n2.3.3 Input / \nOutput Unit\nC7\n", "page": 341, "type": "text", "section": "Page 341"}
{"text": "COMPUTING FOUNDATIONS   16-29\n2.3.4 \nControl Unit\nC4.2\n3. Data \nStructures and \nAlgorithms\nc10,  \nPart \nV\nC2\n3.1 Types of Data \nStructures\nc10\nS2.1-2.6\n3.2 Operations on \nData Structures\nS2.1-2.6\n3.3 Algorithms \nand Attributes of \nAlgorithms\nc26, \nc27\n3.4 Algorithm \nComplexity\ns1.1\u20131.3, \ns3.3\u20133.6, \ns4.1\u20134.8, \ns5.1\u20135.7, \ns6.1\u20136.3, \n7.6, s11.1, \ns12.1\n3.5 Measurement \nof Complexity\ns1.1\u2013s3.3\u2013 \n3.6, \ns4.1\u20134.8, \ns5.1\u20135.7, \ns6.1\u20136.3, \ns7.1\u20137.6, \ns11.1,  \ns12.1\n3.6 Designing \nAlgorithms\nPart \nIV,  \nPart \nVII\n3.7 Sorting \nTechniques\nc6, \nc7,  \nc8,  \nc9\n3.8 Searching \nTechniques\nC6\n3.9 Hashing\nc11.2\n4. \nProgramming \nFundamentals \nand Languages\nC6\n4.1 Programming \nLanguage Types\nC8.4.4\n4.2 Programming \nSyntax, Semantics, \nType Systems\nC8.4.4\n4.3 Subprograms \nand Coroutines\nC6.3\n", "page": 342, "type": "text", "section": "Page 342"}
{"text": "16-30   SWEBOK \u00ae GUIDE V4.0\n4.4 Object-\nOriented \nProgramming\nC6.5\n4.5 Distributed \nProgramming \nand Parallel \nProgramming\nC6.6\n4.6 Debugging\nC2.2.2\n4.7 Standards \nand Guidelines\nC28.5, \n \nC31.5\n5. Operating  \nSystems\n5.1 Processor \nManagement\nc2, \nc8\n5.2 Memory \nManagement\nc3\n5.3 Device \nManagement\nc5\n5.4 Information \nManagement\nc4\n5.5 Network \nManagement\nC4.1\n6. Database \nManagement\n6.1 Schema\nC2.1.4\n6.2 Data \nModels and \nStorage Models\nC2.3\n6.3 Database \nManagement  \nSystems\nC1.3\n6.4 Relational \nDatabase \nManagement \nSystems and \nNormalization\nC4\n6.5 Structured \nQuery Language\nC6,  \nC7,  \nC8\n6.6 Data Mining \nand Data \nWarehousing\nC34\n6.7 Database \nBackup \nand Recovery\nC22\n7. Computer \nNetworks and  \nCommunications\nC4.1\nC1\n7.1 Types \nof Computer  \nNetworks\nC4.1\nC1.2.1\n", "page": 343, "type": "text", "section": "Page 343"}
{"text": "COMPUTING FOUNDATIONS   16-31\n7.2 Layered \nArchitecture \nof Networks\nC1.5\n7.3 Open Systems \nInterconnection  \nModel\nC1.5\n7.4 Encapsulation \nand \nDecapsulation\nC1.5.2\n7.5 Application \nLayer Protocols\nC2\n7.6 Design \nTechniques for \nReliable and \nEfficient Network\nC1.5\n7.7 Internet \nProtocol Suite\nC3\n7.8 Wireless and \nMobile Networks\nC7\n7.9 Security and \nVulnerabilities\nC8\n8. User and \nDeveloper \nHuman Factors\n8.1 User \nHuman Factors\nc8\n8.2. Developer \nHuman Factors\nc31-\nc32\n9. Artificial \nIntelligence \nand Machine\nLearning\nC1\n9.1 Reasoning\n9.2 Learning\n9.3 Models\n9.4 Perception \nand \nProblem-Solving\n9.5 Natural \nLanguage \nProcessing\n9.6 AI and \nSoftware \nEngineering\n", "page": 344, "type": "text", "section": "Page 344"}
{"text": "16-32   SWEBOK \u00ae GUIDE V4.0\nREFERENCES\n[1]\t Joint Task Force on Computing \nCurricula, IEEE Computer Society and \nAssociation for Computing Machinery, \nSoftware Engineering 2014: Curriculum \nGuidelines for Undergraduate Degree \nPrograms in Software Engineering, \n2014; http://sites.computer.org/ccse/\nSE2004Volume.pdf.\n[2*]\tG. Voland, Engineering by Design, 2nd \ned., Prentice Hall, 2003.\n[3*]\t S. McConnell, Code Complete, 2nd ed., \nMicrosoft Press, 2004.\n[4*]\t J.G. Brookshear, Computer Science: \nAn Overview, 12th ed., Addison-\nWesley, 2017.\n[5*]\t E. Horowitz et al., Computer \nAlgorithms, 2nd ed., Silicon Press, 2007.\n[6*]\t I. Sommerville, Software Engineering, \n9th ed., Addison-Wesley, 2011.\n[7]\t ISO/IEC/IEEE, \u201cISO/IEC/IEEE \n24765:2017 Systems and Software \nEngineering \u2014 Vocabulary,\u201d 2nd ed. 2017.\n[8*]\tL. Null and J. Lobur, The Essentials \nof Computer Organization and \nArchitecture, 5th ed., Jones and Bartlett \nPublishers, 2018.\n[9*]\tJ. Nielsen, Usability Engineering, \nMorgan Kaufmann, 1994.\n[10]\tISO 9241-420:2011 Ergonomics of \nHuman-System Interaction, ISO, 2011.\n[11*]\t\nM. Bishop, Computer Security: Art and \nScience, 2nd ed, Addison-Wesley, 2018.\n[12]\tR.C. Seacord, The CERT C Secure \nCoding  Standard, Addison-Wesley \nProfessional, 2016.\n[13]\tR. Fagin, \u201cA Normal Form for Relational \nDatabases that is based on Domains \nand Keys,\u201d ACM Transactions on \nDatabase Systems, Vol. 6, No. 3, ACM, \nSeptember 1981\n[14]\tI. Goodfellow, Y. Bengio, A. \nCourville, Deep Learning (Adaptive \nComputation and Machine Learning \nseries) Illustrated Edition, 2018.\n[15]\tS. Shafiq, A. Mashkoor, C. Mayr-\nDorn, A. Egyed, \u201cA Literature \nReview of Using Machine Learning \nin Software Development Life Cycle \nStages,\u201d IEEE Access, Volume 9, IEEE, \nOctober 2021.\n[16]\tS. Mart\u00ednez-Fern\u00e1ndez, J. Bogner, \nX. Franch, M. Oriol, J. Siebert, A. \nTrendowicz, A. M. Vollmer, \u201cSoftware \nEngineering for AI-Based Systems: A \nSurvey,\u201d ACM Transactions on Software \nEngineering and Methodology, Vol. 31, \nNo. 2, ACM, April 2022.\n[17]\tH. Washizaki, F. Khomh, Y. G. \nGueheneuc, H. Takeuchi, N. \nNatori, T. Doi, S. Okuda, \u201cSoftware \nEngineering Design Patterns for \nMachine Learning Applications,\u201d \nComputer, Vol. 55, No. 3, IEEE \nComputer Society, March 2022.\n[18]\tThomas H Cormen, Charles E \nLeiserson, Ronald L Rivest, Clifford \nStein, \u201cIntroduction to Algorithms,\u201d \nFourth Edition, 2022.\n[19]\tAndrew W Tanenbaum, Herbert Bos, \n\u201cModern Operating Systems,\u201d 4e, 2016.\n[20] https://ieeexplore.ieee.org/document \n/9779481 \n[21] Neal Ford, Mark Richards, Pramod \nSadalage and Zhamak Dehgh, Software \nArchitecture: The Hard Parts, O Reilly, \nFirst Edition \u2013 2021\n", "page": 345, "type": "text", "section": "Page 345"}
{"text": "COMPUTING FOUNDATIONS   16-33\n[22] Thomas Connolly, Carolyn Begg, \nDatabase Systems - A Practical Approach to \nDesign, Implementation and Management, \n6th Edition \u2013 Pearson\n[23] Michael J. Hernandez, Database \nDesign For Mere Mortals, 4th Edition, \nAddison-Wesley\n[24] James F Kurose, Keith W Ross, \nComputer Networking - A Top-Down \nApproach, 7th Edition, Pearson\n", "page": 346, "type": "text", "section": "Page 346"}
{"text": "17-1 \nCHAPTER 17\nMathematical Foundations\nACRONYMS\nBST\nBinary Search Tree\nCFG\nContext-Free Grammar\nCSG\nContext-Sensitive Grammar\nFSM\nFinite-State Machine\nGCD\nGreatest Common Divisor\nIH\nInduction Hypothesis\nLHS\nLeft-Hand Side\nPSG\nPhrase Structure Grammar\nRHS\nRight-Hand Side\nINTRODUCTION\nSoftware engineers can write code only for \nsomething that follows well-understood, \nunambiguous \nlogic. \nThe \nMathematical \nFoundations Knowledge Area (KA) helps \nsoftware engineers comprehend this logic, \nwhich they translate into source code. The \nmathematics in this KA differs greatly from \ntypical arithmetic, which deals with num-\nbers. This KA focuses on logic and reasoning, \nwhich are the essence of the mathematics a \nsoftware engineer must address.\nMathematics, in a sense, is the study of \nformal systems. The word formal is associated \nwith preciseness, so there can be no ambig-\nuous or erroneous interpretation of the facts. \nMathematics is therefore the study of all cer-\ntain truths about any concept. This concept can \nbe about numbers, symbols, images, sounds or \nvideo \u2014 almost anything. In short, numbers \nand numeric equations aren\u2019t the only subjects \nof preciseness. On the contrary, a software \nengineer must have a precise abstraction on \ncomplex, diverse application domains.\nThe Mathematical Foundations KA covers \nbasic techniques to identify a set of rules for \nreasoning in the context of the system under \nstudy. Anything you can deduce following \nthese rules is an absolute certainty within \nthe context of that system. This KA defines \nand discusses techniques that can represent \nand take forward a software engineer\u2019s rea-\nsoning and judgment in a precise (and there-\nfore mathematical) manner. The language and \nmethods of logic discussed allow software \nengineers to describe mathematical proofs to \ninfer conclusively the absolute truth of cer-\ntain concepts beyond just numbers. This KA\u2019s \nobjective is to help software engineers develop \nthe skill to identify and describe such logic \nand verify that the logic in the code is con-\nsistent with abstractions. The emphasis is on \nhelping software engineers understand the \nbasic concepts rather than on developing their \narithmetic abilities.\nBREAKDOWN OF TOPICS FOR \nMATHEMATICAL FOUNDATIONS\nThe breakdown of topics for the Mathematical \nFoundations KA is shown in Figure 17.1.\n1.\t Basic Logic\b\n[1*, c1]\n1.1.\t Propositional Logic\nA proposition is a statement that is either \ntrue or false, but not both. Consider declar-\native sentences for which it is meaningful to \nassign either of the two status values: true \n", "page": 347, "type": "text", "section": "Page 347"}
{"text": "17-2   SWEBOK \u00ae GUIDE V4.0\nor false. The following are some examples of \npropositions:\n\u2022\t The sun is a star.\n\u2022\t Elephants are mammals.\n\u2022\t 2 + 3 = 5.\nHowever, a + 3 = b is not a proposition, as \nit is neither true nor false. Whether it is true \ndepends on the values of the variables a and b. \nThe Law of Excluded Middle: For every \nproposition p, either p is true, or p is false.\nThe Law of Contradiction: For every propo-\nsition p, it is not the case that p is both true \nand false.\nPropositional logic is the area of logic that \ndeals with propositions. A truth table displays \nthe relationships between the truth values of \npropositions.\nA Boolean variable is a variable whose value \nis either true or false. Computer bit operations \ncorrespond to logical operations of Boolean \nvariables.\nThe basic logical operators include negation \n(not, \u00ac p), conjunction (and, p \u2227 q), disjunc-\ntion (or, p \u2228 q), exclusion (p \u2295 q), and impli-\ncation (p \u2192 q). Compound propositions may \nbe formed using various logical operators.\nA compound proposition that is always \ntrue is a tautology. A compound proposition \nthat is always false is a contradiction. A com-\npound proposition that is neither a tautology \nnor a contradiction is a contingency.\nCompound propositions that always have \nthe same truth value are called logically equiv-\nalent (denoted by \u2261). Some common logical \nequivalences are the following:\n\u2022\t Identity laws: \np \u2227 T \u2261 p\t\np \u2228 F \u2261 p\n\u2022\t Domination laws: \np \u2228 T \u2261 T\t\np \u2227 F \u2261 F\n\u2022\t Idempotent laws: \np \u2228 p \u2261 p\t\np \u2227 p \u2261 p\n\u2022\t Double negation law: \n\u00ac (\u00ac p) \u2261 p \n\u2022\t Commutative laws: \np \u2228 q \u2261 q \u2228 p\t\np \u2227 q \u2261 q \u2227 p\n\u2022\t Associative laws: \n(p \u2228 q) \u2228 r \u2261 p \u2228 (q \u2228 r)\t\n(p \u2227 q) \u2227 r \n\u2261 p \u2227 (q \u2227 r)\n\u2022\t Distributive laws: \np \u2228 (q \u2227 r) \u2261 (p \u2228 q) \u2227 (p \u2228 r) \np \u2227 (q \u2228 r) \u2261 (p \u2227 q) \u2228 (p \u2227 r)\nMathematical \nFoundations\nBasic Logic\nSet, Relation, \nFunction\nFinite-State \nMachine\nNumber Teory  \nPropositional\nLogic\nPredicate\nLogic\nSet Operations\nProperties at Set\nRelations and\nFuntions\nTypes of Numbers\nDivisibility\nPrime Number\nGreatest\nCommon Divisor\nDiscrete \nProbability\nAlgebraic\nStructures\nGroup\nRing\nProof \nTechniques\nDirect Proof\nProof by\nContradiction\nProof by\nInduction\nProof by Example\nGraph and Tree\nGraph\nTree\nGrammar\nLanguage\nRecognition\nBasics of \nCounting\nNumerical\nPrecision, Accuracy \nand Error\nCalculus\nFigure 17.1. Breakdown of Topics for the Mathematical Foundations KA\n", "page": 348, "type": "text", "section": "Page 348"}
{"text": "MATHEMATICAL FOUNDATIONS   17-3\n\u2022\t De Morgan\u2019s laws: \n\u00ac (p \u2227 q) \u2261 \u00ac p \u2228 \u00ac q \n\u00ac (p \u2228 q) \u2261 \u00ac p \u2227 \u00ac q\n1.2.\t Predicate Logic \nA predicate is a verb phrase template that \ndescribes a property of objects or a relation-\nship among objects represented by the vari-\nables. For example, in the sentence The flower \nis Red, the template is Red is a predicate. It \ndescribes a property of the flower. The same \npredicate may be used in other sentences. \nPredicates are often given a name (e.g., Red \nor simply R) that can represent the predicate (in \nthis case, Red or R can represent the predicate is \nred). Assuming R is the name for the predicate \nis red, sentences that assert an object is the color \nred can be represented as R(x), where x rep-\nresents an arbitrary object. R(x) reads as x is red.\nQuantifiers allow statements about entire \ncollections of objects so that enumerating \neach object by name is not necessary.\n\u2022\t The universal quantifier \u2200x asserts that a \nsentence is true for all values of variable \nx (e.g., \u2200x Tiger(x) \u2192 Mammal(x) means \nall tigers are mammals).\n\u2022\t The existential quantifier \u2203x asserts that \na sentence is true for at least one value \nof variable x (e.g., \u2203x Tiger(x) \u2192 Man-\neater(x) means there exists at least one \ntiger that is a man-eater).\nThus, while universal quantification uses \nimplication, existential quantification natu-\nrally uses conjunction.\nA variable x introduced into a logical \nexpression by a quantifier is bound to the \nclosest enclosing quantifier. Similarly, in a \nblock-structured \nprogramming \nlanguage, \na variable in a logical expression refers to \nthe closest quantifier within whose scope \nit appears. For example, in \u2203x (Cat(x) \u2227 \u2200x \n(Black(x))), x in Black(x) is universally quan-\ntified. Therefore, the expression implies that \ncats exist and everything is black. \nA variable is a free variable if it is not bound \nto a quantifier.\nPropositional logic falls short in repre-\nsenting many assertions used in mathematics, \ncomputer science and, therefore, software \nengineering. It also fails to compare equiva-\nlence and other relationships between prop-\nositions. For example, the assertion \u201ca is \ngreater than 1\u201d is not a proposition because \none cannot infer whether it is true or false \nwithout knowing the value of a. Thus, propo-\nsitional logic cannot deal with such sentences. \nHowever, such assertions appear quite often \nin mathematics, and we want to infer infor-\nmation from those assertions. Also, prop-\nositional logic cannot capture the pattern \ninvolved in the following two logical equiva-\nlences: \u201cNot all men are smokers\u201d and \u201cSome men \ndon\u2019t smoke.\u201d Each of these two propositions is \ntreated independently in propositional logic. \nThere is no mechanism in propositional logic \nto determine whether the two are equivalent. \nHence, propositional logic treats each equiva-\nlent proposition individually rather than apply \na general formula that covers all equivalences \ncollectively. \nPredicate logic addresses these issues. In \na sense, predicate logic (also known as first-\norder logic or predicate calculus) extends \npropositional logic to formulas involving \nterms and predicates.\n2.\t Proof Techniques  \b\n[1*, c1]\nA proof is an argument that rigorously estab-\nlishes the truth of a statement. Proofs can \nthemselves be represented formally as discrete \nstructures.\nStatements used in a proof include axioms \nand postulates that are essentially the under-\nlying assumptions about mathematical struc-\ntures, the hypotheses of the theorem to be \nproved and previously proved theorems.\n\u2022\t A theorem is a statement that can be \nshown to be true.\n\u2022\t A lemma is a simple theorem used in \nproving other theorems.\n\u2022\t A corollary is a proposition that can be \nestablished directly from a theorem that \nhas been proved.\n", "page": 349, "type": "text", "section": "Page 349"}
{"text": "17-4   SWEBOK \u00ae GUIDE V4.0\n\u2022\t A conjecture is a statement whose truth \nvalue is unknown.\nWhen a conjecture\u2019s proof is found, that \nconjecture becomes a theorem. Many times, \nconjectures are shown to be false and, hence, \nare not theorems.\n2.1.\t Direct Proof\nDirect proof is a technique to establish that \nthe implication p \u2192 q is true by showing that \nq must be true when p is true. For example, \nto show that if n is odd, then n2 \u2212 1 is even, \nsuppose n is odd for some integer k \u2014 i.e., n \n= 2k + 1: \n\u2234 n2 = (2k + 1)2 = 4k2 + 4k + 1\nAs the first two terms of the Right-Hand \nSide (RHS) are even numbers irrespective \nof the value of k, the Left-Hand Side (LHS) \n(n2) is an odd number. Therefore, n2 \u2212 1 is \neven. Direct proof can also be called Proof by \nDeduction.\n2.2.\t Proof by Contradiction\nA proposition p is true by contradiction if \nproved based on the truth of the implica-\ntion \u00ac p \u2192 q, where q is a contradiction. For \nexample, to show that the sum of 2x + 1 and \n2y \u2212 1 is even, assume that the sum of 2x + \n1 and 2y \u2212 1 is odd. In other words, 2(x + y), \nwhich is a multiple of 2, is odd. This is a con-\ntradiction. Hence, the sum of 2x + 1 and 2y \n\u2212 1 is even. \nAn inference rule is a pattern establishing \nthat if a set of premises are all true, then it \ncan be deduced that a certain conclusion \nstatement is true. The reference rules of addi-\ntion, simplification and conjunction need to \nbe studied.\nA closely related approach, Proof by \nContrapositive, takes the opposite approach by \nassuming the conclusion is false and proving \nthat the hypothesis is also false. If it can be \nshown that\u00a0 \u00ac q \u2192 \u00ac p is true, then p \u2192 q \nmust also be true.\n2.3.\t Proof by Induction\nProof by induction is done in two parts. \nFirst, the proposition is established to be \ntrue for a base case \u2014 typically for the posi-\ntive integer 1. Then, in the second part, it is \nestablished that if the proposition holds for \nan arbitrary positive integer k, then it must \nalso hold for the next greater integer, k + 1. \nIn other words, proof by induction is based \non the rule of inference that tells us that the \ntruth of an infinite sequence of propositions \nP(n), \u2200n \u2208 [1, \u2026, \u221e] is established if first \nP(1) is true, and, second \u2200k \u2208 [2, \u2026, n] if \nP(k) \u2192 P(k + 1). \nFor a proof by induction, it is not assumed \nthat P(k) is true for all positive integers \nk. Proving a theorem or proposition only \nrequires us to establish that if it is assumed \nP(k) is true for any arbitrary positive integer \nk, then P(k + 1) is also true. An in-depth dis-\ncussion of the correctness of induction as a \nvalid proof technique is beyond the scope of \nthis KA. The following proposition is proved \nusing induction:\nProposition: The sum of the first n positive \nodd integers P(n) is n2.\nBasis Step: The proposition is true for n = \n1 as P(1) = 12 = 1. The basis step is complete.\nInductive Step: The induction hypothesis \n(IH) is that the proposition is true for n = k, k \nbeing an arbitrary positive integer k. \n\u2234 1 + 3 + 5 + \u2026 + (2k \u2212 1) = k2\nNow, it\u2019s to be shown that P(k) \u2192 P(k + 1).\nP(k + 1) = 1 + 3 + 5 + \u2026 + (2k \u2212 1) + (2k + 1)\n\t\n= P(k) + (2k + 1)\n\t\n= k2 + (2k + 1) [using IH]\n\t\n= k2 + 2k + 1\n\t\n= (k + 1)2 \nThus, it is shown that if the proposition is \ntrue for n = k, then it is also true for n = k + 1.\nThe basis step together with the inductive \nstep of the proof show that P(1) is true and the \nconditional statement P(k) \u2192 P(k + 1) is true \nfor all positive integers k. Hence, the proposi-\ntion is proved.\n", "page": 350, "type": "text", "section": "Page 350"}
{"text": "MATHEMATICAL FOUNDATIONS   17-5\n2.4.\t Proof by Example\nProof by example is only valid when the core \nof the proof is \u201cthere exists\u201d and one needs \nonly to show that at least one valid instance \ndoes exist. More generally, however, proof by \nexample has often been called Inappropriate \nGeneralization where validity is assumed to \nbe illustrated through one or a few examples \nrather than a full proof. Showing only one or a \nfew specific examples where p \u2192 q is not suf-\nficient to prove that for all cases p \u2192 q.\n3.\t Set, Relation, Function \b\n[1*, c2]\nSet. A set is a collection of objects called ele-\nments. A set can be represented by listing its \nelements between braces (e.g., S = {1, 2, 3}).\nThe symbol \u2208 is used to express that an ele-\nment belongs to a set or is a member of the set. \nIts negation is represented by \u2209 (e.g., 1 \u2208 S, \nbut 4 \u2209 S).\nIn a more compact representation of a set \nusing set builder notation, {x | P(x)} is the set \nof all x such that P(x) for any proposition P(x) \nover any universe of discourse. Examples of \nimportant sets include the following:\n\u2022\t \u039d = {0, 1, 2, 3, \u2026} = the set of nonnega-\ntive integers.\n\u2022\t \u0396 = {\u2026, -3, -2, -1, 0, 1, 2, 3, \u2026} = the set \nof integers.\nFinite and Infinite Set. A set with a finite \nnumber of elements is called a finite set. \nConversely, any set that does not have a finite \nnumber of elements in it is an infinite set. For \nexample, the set of all natural numbers is an \ninfinite set. \nCardinality. The cardinality of a finite set S \nis the number of elements in S. This is repre-\nsented as |S| (e.g., if S = {1, 2, 3}, then |S| = 3).\nUniversal Set. In general, S = {x \u2208 U | \np(x)}, where U is the universe of discourse in \nwhich the predicate P(x) must be interpreted. \nThe universe of discourse for a given pred-\nicate is often referred to as the universal set. \nAlternatively, one may define a universal set \nas the set of all elements.\nSet Equality. Two sets are equal if and only \nif they have the same elements \u2014\n i.e., X = Y \u2261 \u2200p (p \u2208 X \u2194 p \u2208 Y).\nSubset. X is a subset of set Y, or X is con-\ntained in Y, if all elements of X are included \nin Y. This is denoted by X \u2286 Y. In other words, \nX \u2286 Y if and only if \u2200p(p \u2208 X \u2192 p \u2208 Y) If X \n= {1, 2, 3} and Y = {1, 2, 3, 4, 5}, then X \u2286 Y.\nIf X is not a subset of Y, it is denoted as X  Y.\nProper Subset. X is a proper subset of Y \n(denoted by X \u2282 Y) if X is a subset of Y but \nnot equal to Y \u2014 i.e., there is some element in \nY that is not in X.\nIn other words, X \u2282 Y if (X \u2286 Y) \u2227 (X \u2260 Y). \nIf X = {1, 2, 3}, Y = {1, 2, 3, 4}, and Z = {1, 2, \n3}, then X \u2282 Y, but X is not a proper subset of \nZ. Sets X and Z are equal sets.\nIf X is not a proper subset of Y, it is \ndenoted as X \u2284 Y.\nSuperset. If X is a subset of Y, then Y is \ncalled a superset of X. This is denoted by Y \u2287 \nX \u2014 i.e., Y \u2287 X if and only if X \u2286 Y. If X = {1, \n2, 3} and Y = {1, 2, 3, 4, 5}, then Y \u2287 X.\nEmpty Set. A set with no elements is called \nan empty set. An empty set, denoted by \u03c6, is \nalso referred to as a null or void set.\nPower Set. The set of all subsets of a set X \nU\nX\nFigure 17.2. Venn Diagram for Set X\nU\nX \u2229 Y\nX\nY\nFigure 17.3. Intersection of Sets X and Y\n", "page": 351, "type": "text", "section": "Page 351"}
{"text": "17-6   SWEBOK \u00ae GUIDE V4.0\nis called the power set of X. It is represented \nas \u2118(X). If X = {a, b, c}, then \u2118(X) = {\u03c6, {a}, \n{b}, {c}, {a, b}, {a, c}, {b, c}, {a, b, c}}. If |X| = n, \nthen |\u2118 (X)| = 2n.\nVenn Diagrams. Venn diagrams are graphic \nrepresentations of sets as enclosed areas in the \nplane. For example, in Figure 17.2, the rect-\nangle represents the universal set, and the \nshaded region represents a set X.\n3.1.\t Set Operations\nIntersection. The intersection of two sets, X \nand Y, denoted by X \u2229 Y, is the set of common \nelements in both X and Y. In other words, X \n\u2229 Y = {p | (p \u2208 X) \u2227 (p \u2208 Y)}. For example, {1, \n2, 3} \u2229 {3, 4, 6} = {3}.\nIf X \u2229 Y = \u03c6, then the two sets X and Y are \nsaid to be disjoint.\nA Venn diagram for set intersection is \nshown in Figure 17.3. The common portion \nof the two sets represents the set intersection.\nUnion. The union of two sets, X and Y, \ndenoted by X \u222a Y, is the set of all elements in \nX, in Y or in both. In other words, X \u222a Y = {p \n| (p \u2208 X) \u2228 (p \u2208 Y)}. For example, {1, 2, 3} \u222a \n{3, 4, 6} = {1, 2, 3, 4, 6}.\nIt may be noted that |X \u222a Y| = |X| + |Y| \n\u2212 |X \u2229 Y|.\nA Venn diagram illustrating the union of \ntwo sets is represented by the shaded region \nin Figure 17.4.\nComplement Set. The set of elements in the \nuniversal set that do not belong to a given set \nX is called its complement set X\u2019. In other \nwords, X\u2019 ={p | (p \u2208 U) \u2227 (p \u2209 X)}.\nThe shaded portion of the Venn diagram in \nFigure 17.5 represents the complement set of X.\nSet Difference or Relative Complement. The \nset of elements that belong to set X but not \nto set Y builds the set difference of Y from X. \nThis is represented by X \u2212 Y. In other words, \nX \u2212 Y = {p | (p \u2208 X) \u2227 (p \u2209 Y)}. For example, \n{1, 2, 3} \u2212 {3, 4, 6} = {1, 2}.\nIt may be proved that X \u2212 Y = X \u2229 Y\u2019.\nSet difference X \u2013 Y is illustrated by \nthe shaded region in Figure 17.6 using a \nVenn diagram.\nCartesian Product. An ordinary pair {p, q} \nis a set with two elements. In a set, the order \nof the elements is irrelevant, so {p, q} = {q, p}. \nIn an ordered pair (p, q), the order of occur-\nrences of the elements is relevant. Thus, (p, q) \n\u2260 (q, p) unless p = q. In general, (p, q) = (s, t) if \nand only if p = s and q = t.\nGiven two sets, X and Y, their Cartesian \nproduct X \u00d7 Y is the set of all ordered pairs (p, \nq) such that p \u2208 X and q \u2208 Y. In other words, X \n\u00d7 Y = {(p, q) | (p \u2208 X) \u2227 (q \u2208 Y)}. For example, \n{a, b} \u00d7 {1, 2} = {(a, 1), (a, 2), (b, 1), (b, 2)}.\n3.2.\t Properties of Sets\nSome of the important properties and laws of \nsets are mentioned below:\nU\nX \u222a Y\nX\nY\nFigure 17.4. Union of Sets X and Y\nU\nX \u2013 Y\nX\nY\nFigure 17.6. Venn Diagram for X \u2212 Y\nU\nX\nFigure 17.5. Venn Diagram for \nComplement Set of X\n", "page": 352, "type": "text", "section": "Page 352"}
{"text": "MATHEMATICAL FOUNDATIONS   17-7\n\u2022\t Associative Laws:\n\u2022\t X \u222a (Y \u222a Z) = (X \u222a Y) \u222a Z\n\u2022\t X \u2229 (Y \u2229 Z) = (X \u2229 Y) \u2229 Z\n\u2022\t Commutative Laws:\n\u2022\t X \u222a Y = Y \u222a X\t\nX \u2229 Y = Y \u2229 X\n\u2022\t Distributive Laws:\n\u2022\t X \u222a (Y \u2229 Z) = (X \u222a Y) \u2229 (X \u222a Z)\n\u2022\t X \u2229 (Y \u222a Z) = (X \u2229 Y) \u222a (X \u2229 Z)\n\u2022\t Identity Laws:\n\u2022\t X \u222a \u03c6 = X\t\nX \u2229 U = X\n\u2022\t Complement Laws:\n\u2022\t X \u222a X\u2019 = U\t\nX \u2229 X\u2019 = \u03c6\n\u2022\t Idempotent Laws:\n\u2022\t X \u222a X = X\t\nX \u2229 X = X\n\u2022\t Bound Laws:\n\u2022\t X \u222a U = U\t\nX \u2229 \u03c6 = \u03c6\n\u2022\t Absorption Laws:\n\u2022\t X \u222a (X \u2229 Y) = X\t\nX \u2229 (X \u222a Y) = X\n\u2022\t De Morgan\u2019s Laws:\n\u2022\t (X \u222a Y)\u2019 = X\u2019 \u2229 Y\u2019\t\n(X \u2229 Y)\u2019 = X\u2019 \u222a Y\u2019\n3.3.\t Relation and Function\nA relation is an association between two sets of \ninformation. Consider a set of residents of a city \nand their phone numbers. The pairing of names \nwith corresponding phone numbers is a rela-\ntion. This pairing is ordered for the entire rela-\ntion. For each pair, either the name comes first, \nfollowed by the phone number, or the reverse. \nThe set from which the first element is drawn \nis called the domain set, and the other set is \ncalled the range set. The domain is what you \nstart with, and the range is what you end with.\nA function is a well-behaved relation. A \nrelation R(X, Y) is well-behaved if every ele-\nment of the domain set X corresponds to a \nsingle element of the range set Y. Consider \ndomain set X as a set of people and range set \nY as their phone numbers. If a person may \nhave more than one phone number, then this \nrelation is not a function. However, if we \ndraw a relation between the names of resi-\ndents and their dates of birth with the name \nset as domain, then this becomes a well-be-\nhaved relation and hence a function. This \nmeans that while all functions are relations, \nnot all relations are functions. In the case of \na function given an x, there is one and exactly \none y for each ordered pair (x, y).\nFor example, consider the following two \nrelations:\nA: {(3, \u20139), (5, 8), (7, \u20136), (3, 9), (6, 3)}\nB: {(5, 8), (7, 8), (3, 8), (6, 8)}\nAre these functions as well?\nIn relation A, the domain is all x-values \u2014 \ni.e., {3, 5, 6, 7} \u2014 and the range is all y-values \n\u2014 i.e., {\u20139, \u20136, 3, 8, 9}.\nRelation A is not a function, as there are \ntwo different range values, \u20139 and 9, for the \nsame x-value, 3.\nIn relation B, the domain is the same as \nfor A \u2014 i.e., {3, 5, 6, 7}. However, the range \nis a single element \u2014 {8}. This qualifies as a \nfunction even if all x-values are mapped to the \nsame y-value. Here, each x-value is distinct, \nso the relation is well-behaved and is therefore \na function. Therefore, Relation B may be rep-\nresented by the equation y = 8.\nWhether a relation may be characterized as \na function can be verified using the vertical \nline test presented below:\nGiven the graph of a relation, if one can \ndraw a vertical line that crosses the graph in \nmore than one place, then that relation is not \na function.\nY\nL1\nL2\nX\nFigure 17.7. Vertical Line Test for Function\n", "page": 353, "type": "text", "section": "Page 353"}
{"text": "17-8   SWEBOK \u00ae GUIDE V4.0\nIn Figure 17.7, both lines L1 and L2 cut the \ngraph for the relation three times. This signi-\nfies that for each of these x-values (with L1 \nrepresenting one x-value and L2 representing \nanother), there are three different y-values. \nThus, the relation is not a function. Of course, \neither L1 or L2 alone would be enough to \nprove that the relation is not a function.\n4.\t Graph and Tree \b\n[1*, c10, c11]\n4.1.\t Graph\nIn a graph G = (V, E), V is the set of vertices \n(nodes) and E is the set of edges. Edges are \nalso called arcs or links.\nF is a function that maps the set of edges E \nto a set of ordered or unordered pairs of ele-\nments V. In Figure 17.8, G = (V, E) where V \n= {A, B, C}, E = {e1, e2, e3}, and F = {(e1, (A, \nC)), (e2, (C, B)), (e3, (B, A))}.\nThe simple graph in Figure 17.8 consists \nof a set of vertices or nodes and a set of edges \nconnecting unordered pairs. The edges in \nsimple graphs are undirected. Such graphs \nare also called undirected graphs. In Figure \n17.8, (e1, (A, C)) may be replaced by (e1, (C, \nA)), as the pair between vertices A and C \nis unordered. This is true for the other two \nedges as well.\nIn a multigraph, more than one edge may \nconnect the same two vertices. Two or more \nconnecting edges between the same pair of \nvertices may reflect multiple associations \nbetween the same two vertices. Such edges \nare called parallel or multiple edges. In Figure \n17.9, the edges e3 and e4 both connect A and \nB. Figure 17.9 is a multigraph where edges e3 \nand e4 are multiple edges.\nIn a pseudograph, edges connecting a node to \nitself are allowed. Such edges are called loops.\nIn Figure 17.10, the edge e4 both starts and \nends at B. Figure 17.10 is a pseudograph in \nwhich e4 is a loop.\nA directed graph G = (V, E) consists of a \nset of vertices V and a set of edges E that are \nordered pairs of elements of V. A directed \ngraph may contain loops. In Figure 17.11, G = \n(V, E) is a directed graph where V = {A, B, C}, \nA\nB\nC\ne2\ne1\ne3\nFigure 17.8. Example of a Graph\nA\nB\nC\ne2\ne4\ne1\ne3\nFigure 17.9. Example of a Multigraph\nA\nB\nC\ne2\ne4\ne1\ne3\nFigure 17.10. Example of a Pseudograph\nA\nB\nC\ne2\ne1\ne3\nFigure 17.11. Example of a Directed Graph\nA\nB\nC\ne2\n93\ne1\n76\n15\ne3\nFigure 17.12. Example of a Weighted Graph\n", "page": 354, "type": "text", "section": "Page 354"}
{"text": "MATHEMATICAL FOUNDATIONS   17-9\nE = {e1, e2, e3}, and F = {(e1, (A, C)), (e2, (B, \nC)), (e3, (B, A))}.\nIn weighted graph G = (V, E), each edge has \na weight associated with it. The weight of an \nedge typically represents the numeric value \nassociated with the relationship between the \ncorresponding two vertices. In Figure 17.12, \nthe weights for the edges e1, e2 and e3 are \ntaken to be 76, 93 and 15, respectively. If the \nvertices A, B and C represent three cities in a \nstate, the weights could be, for example, the \ndistances in kilometers between these cities.\nLet G = (V, E) be an undirected graph with \nedge set E. Then, for an edge e \u2208 E where e = \n{u, v}, the following expressions are often used:\n\u2022\t u, v are said to be adjacent, neighbors, or \nconnected.\n\u2022\t Edge e is incident with vertices u and v.\n\u2022\t Edge e connects u and v.\n\u2022\t Vertices u and v are endpoints for edge e.\nIf vertex v \u2208 V, the set of vertices in the \nundirected graph G = (V, E), then:\n\u2022\t The degree of v, deg(v), is its number of \nincident edges, except that any self-loops \nare counted twice.\n\u2022\t A vertex with degree 0 is called an iso-\nlated vertex.\n\u2022\t A vertex of degree 1 is called a pen-\ndant vertex.\nLet G = (V, E) be a directed graph. If e(u, \nv) is an edge of G, then the following expres-\nsions can be used to describe the graph:\n\u2022\t u is adjacent to v, and v is adjacent from u.\n\u2022\t e comes from u and goes to v.\n\u2022\t e connects u to v, or e goes from u to v.\n\u2022\t The initial vertex of e is u.\n\u2022\t The terminal vertex of e is v.\nIf vertex v is in the set of vertices for the \ndirected graph G = (V, E), then:\n\u2022\t In-degree of v, deg\u2212(v), is the number of \nedges going to v, i.e., for which v is the \nterminal vertex.\n\u2022\t Out-degree of v, deg+(v), is the number of \nedges coming from v, i.e., for which v is \nthe initial vertex.\n\u2022\t Degree of v, deg(v) = deg\u2212(v) + deg+(v), is \nthe sum of v\u2019s in-degree and out-degree. \n\u2022\t A loop at a vertex contributes 1 to both \nthe in-degree and the out-degree of \nthis vertex.\nAccording to the definitions above, the \ndegree of a node is unchanged whether we \nconsider its edges to be directed or undirected.\nIn an undirected graph, a path of length n \nfrom u to v is a sequence of n adjacent edges \nfrom vertex u to vertex v.\n\u2022\t A path is a circuit if u = v.\n\u2022\t A path traverses the vertices along it. \n\u2022\t A path is simple if it contains no edge \nmore than once.\nA cycle on n vertices Cn for any n \u2265 3 is a \nsimple graph where V = {v1, v2, \u2026, vn} and E = \n{{v1, v2}, {v2, v3}, \u2026, {vn\u22121, vn}, {vn, v1}}.\nFor example, Figure 17.13 illustrates two \ncycles of lengths 3 and 4.\nAn adjacency list is a table with one row \nper vertex, listing its adjacent vertices. The \nFigure 17.13. Example of Cycles C3 and C4\nA\nB\nC\ne2\ne1\ne3\nA\nB\nD\nC\ne1\ne3\ne4\ne2\nFigure 17.14. Adjacency List for the Graph in \nFigure 17.10\nVertex \nAdjacent Nodes\nA\nB, C\nB\nA, B, C\nC\nA, B\n", "page": 355, "type": "text", "section": "Page 355"}
{"text": "17-10   SWEBOK \u00ae GUIDE V4.0\nadjacency list for a directed graph maintains \na listing of the terminal nodes for each vertex. \nFigure 17.14 illustrates the adjacency lists \nfor the pseudograph in Figure 17.10 and the \ndirected graph in Figure 17.11. As the out-de-\ngree of vertex C in Figure 17.11 is 0, there is \nno entry against C in the adjacency list.\nDifferent representations for a graph \u2014 \ne.g., adjacency matrix, incidence matrix and \nadjacency lists \u2014 need to be studied.\n4.2.\t Tree\nA tree T(N, E) is a hierarchical data struc-\nture of n = |N| nodes with a specially desig-\nnated root node R while the remaining n \u2212 1 \nnodes form subtrees under the root node R. \nThe number of edges |E| in a tree are always \nequal to |N| \u2212 1.\nThe subtree at node X is the subgraph of \nthe tree consisting of node X, its descendants \nand all edges incident to those descendants. \nAs an alternative to this recursive definition, a \ntree may be defined as a connected undirected \ngraph with no simple circuits.\nHowever, a tree is strictly hierarchical, \nwhereas a graph is flat. In a tree, an ordered \npair is built between two nodes as parent and \nchild. Each child node in a tree is associ-\nated with only one parent node, whereas this \nrestriction is meaningless for a graph, where \nno parent-child association exists. \nAn undirected graph is a tree if and only if \nthere is a unique simple path between any two \nof its vertices.\nFigure 17.15 presents a tree T(N, E) with a \nset of nodes N = {A, B, C, D, E, F, G, H, I, J, \nK}. The edge set E is {(A, B), (A, C), (A, D), (B, \nE), (B, F), (B, G), (C, H), (C, I), (D, J), (D, K)}.\nThe parent of a non-root node v is the \nunique node u with a directed edge from u to \nv. Each node in the tree has a unique parent \nnode except for the tree\u2019s root node. While root \nnodes can serve as parent nodes, they have no \nparent nodes themselves. In Figure 17.15, root \nnode A is the parent node for nodes B, C and \nD. Similarly, B is the parent of E, F and G, and \nso on. The root node A has no parent.\nA node that has children is called an internal \nnode. For example, in Figure 17.15, node A \nand node B are examples of internal nodes. \nThe degree of a node in a tree is the same as \nits number of children. For example, in Figure \n17.15, root node A and its child B are both of \ndegree 3. Nodes C and D have degree 2.\nA node\u2019s distance from the root node in \nnumber of hops is called its level. Nodes in \na tree are at different levels. The root node is \nat level 0. Alternately, a node X\u2019s level is the \nunique path\u2019s length from the tree\u2019s root to \nnode X. Root node A is at level 0 in Figure \n17.15. Nodes B, C and D are at level 1. The \nremaining nodes in Figure 17.15 are at level 2.\nA tree\u2019s height is the maximum of the levels \nof tree nodes. For example, in Figure 17.15, \nthe tree\u2019s height is 2.\nA node is called a leaf if it has no chil-\ndren, and the degree of a leaf node is 0. For \nexample, in Figure 17.15, nodes E through K \nare leaf nodes with degree 0. \nThe ancestors or predecessors of a non-root \nnode X are all the nodes in the path from the \nroot to node X. For example, in Figure 17.15, \nnodes A and D form the set of ancestors for J. \nA node X\u2019s successors or descendants are \nall the nodes that have X as their ancestor. For \na tree with n nodes, all remaining n \u2212 1 nodes \nare successors of the root node. In Figure \n17.15, node B has successors in E, F, and G.\nIf node X is an ancestor of node Y, then node Y \nis a successor of X.\nTwo or more nodes sharing the same parent \nnode are called sibling nodes. For example, \nin Figure 17.15, nodes E and G are siblings. \nHowever, nodes E and J, though at the same \nlevel, are not sibling nodes. \nA\nB\nC\nD\nE\nF\nG\nI\nH\nJ\nK\nFigure 17.15. Example of a Tree\n", "page": 356, "type": "text", "section": "Page 356"}
{"text": "MATHEMATICAL FOUNDATIONS   17-11\nTwo sibling nodes are at the same level, but two \nnodes at the same level are not necessarily siblings.\nA tree is called an ordered tree if the rela-\ntive position of occurrences of children nodes \nis significant. For example, a family tree is an \nordered tree if, as a rule, the name of an elder \nsibling always appears before (on the left of) \nthe younger sibling.\nIn an unordered tree, the relative position \nof occurrences between the siblings has no \nsignificance and may be altered arbitrarily.\nA binary tree is formed with 0 or more \nnodes where there is a root node R and all the \nremaining nodes form a pair of ordered sub-\ntrees under the root node. In a binary tree, \nno internal node can have more than two \nchildren. In addition to this criterion for \nthe degree of internal nodes, a binary tree \nis always ordered. If the positions of the left \nand right subtrees for any node in the tree are \nswapped, then a new tree is created.\nIn Figure 17.16, the two binary trees are \ndifferent, as the positions of occurrences of A\u2019s \nchildren differ in the two trees.\nAccording to [1*], a binary tree is called \na full binary tree if every internal node has \nexactly two children. For example, the binary \ntree in Figure 17.17 is a full binary tree, as \nboth internal nodes A and B are of degree 2. \nA full binary tree that meets the definition \nabove is also called a strictly binary tree.\nBoth binary trees in Figure 17.18 are com-\nplete binary trees. The tree in Figure 17.18(a) \nis a complete and full binary tree. A complete \nbinary tree has all its levels filled, except pos-\nsibly the last one. If a complete binary tree\u2019s \nlast level is not full, nodes occur from the left-\nmost positions available.\nInterestingly, following the definitions \nabove, the tree in Figure 17.18(b) is a complete \nbut not full binary tree, as node B has only one \nchild in D. On the contrary, the tree in Figure \n17.17 is a full but not complete binary tree, \nas B\u2019s children occur in the tree, whereas the \nchildren of C do not appear in the last level.\nA binary tree of height H is balanced if all \nleaf nodes occur at levels H or H \u2212 1. All three \nbinary trees in Figures 17.17 and 17.18 are \nbalanced binary trees.\nThere are at most 2H leaves in a binary tree \nof height H. In other words, if a binary tree \nwith L leaves is full and balanced, then its \nheight is H =|log2L|. This is true for the two \ntrees in Figures 17.17 and 17.18(a), as both \ntrees are full and balanced. However, the tree \nin Figure 17.18(b) is not a full binary tree. \nA binary search tree (BST) is a special kind \nof binary tree in which each node contains a \ndistinct key value, and the key value of each \nnode in the tree is less than every key value \nin its right subtree and greater than every key \nvalue in its left subtree.\nA traversal algorithm is a procedure for sys-\ntematically visiting every node of a binary tree. \nTree traversals may be defined recursively.\nA\nB\nC\nA\nC\nB\nFigure 17.16. Examples of Binary Trees\nA\nC\nB\nD\nE\nFigure 17.17. Example of a Full Binary Tree\nA\nA\n(a)\n(b)\nC\nB\nC\nB\nD\nE\nD\nG\nF\nFigure 17.18. Example of Complete Binary Trees\n", "page": 357, "type": "text", "section": "Page 357"}
{"text": "17-12   SWEBOK \u00ae GUIDE V4.0\nIf T is a binary tree with root R and the \nremaining nodes form an ordered pair of non-\nnull left subtree TL and nonnull right subtree \nTR below R, then the preorder traversal func-\ntion PreOrder(T) is defined as:\nPreOrder(T) = R, PreOrder(TL), \nPreOrder(TR) \u2026 eqn. 1\nThe recursive process of finding the pre-\norder traversal of the subtrees continues until \nthe subtrees are found to be Null. Here, \ncommas have been used as delimiters for \nimproved readability.\nThe postorder and in-order may be similarly \ndefined using eqn. 2 and eqn. 3, respectively.\nPostOrder(T) = PostOrder(TL), \nPostOrder(TR), R \u2026 eqn. 2\nInOrder(T) = InOrder(TL), R, \nInOrder(TR) \u2026 eqn. 3\nThe tree in Figure 17.19 is a binary search \ntree (BST). The pre-order, post-order and \nin-order traversal outputs for this BST are \ngiven below in their respective orders:\nPreorder output: 9, 5, 2, 1, 4, 7, 6, 8, 13, \n11, 10, 15\nPostorder output: 1, 4, 2, 6, 8, 7, 5, 10, \n11, 15, 13, 9\nIn-order output: 1, 2, 4, 5, 6, 7, 8, 9, 10, \n11, 13, 15\n5.\t Finite-State Machine  \b\n[1*, c13]\nA computer system may be abstracted as a \nmapping from state to state, driven by inputs. \nIn other words, a system may be considered a \ntransition function T: S \u00d7 I \u2192 S \u00d7 O, where S \nis the set of states and I and O are the input \nand output functions.\nIf the state set S is finite, the system is \ncalled a finite-state machine (FSM).\nAlternatively, a finite state machine \n(FSM) is a mathematical abstraction com-\nposed of a finite number of states and transi-\ntions between those states. For example, if the \ndomain S \u00d7 I is reasonably small, then one can \nspecify T explicitly, using diagrams similar \nto a flow graph to illustrate how logic flows \nfor different inputs. However, this is practical \nonly for machines with a very small informa-\ntion capacity.\nAn FSM has a finite internal memory, an \ninput feature that reads symbols one at a time \nin a sequence, and an output feature. \nThe operation of an FSM begins from a \nstart state, goes through transitions depending \non the input to different states, and can end \nin any valid state. However, only a few of the \nstates mark a successful flow of operation. \nThese are called accept states.\nThe information capacity of an FSM is \nC = log |S|. Thus, if we represent a machine \nhaving an information capacity of C bits as an \nFSM, then its state transition graph will have \n|S| = 2C nodes.\nAn FSM is formally defined as M = (S, I, \nO, f, g, s0).\n9\n1\n4\n6\n8\n10\n5\n13\n15\n11\n7\n2\nFigure 17.19. A Binary Search Tree\n1, 2\n1, 2\n0, 2\n0, 3\n0, 3\n1, 3\nS\u2080\nS\u2081\nS\u2082\nFigure 17.20. Example of an FSM\n", "page": 358, "type": "text", "section": "Page 358"}
{"text": "MATHEMATICAL FOUNDATIONS   17-13\nS is the state set.\nI is the set of input symbols.\nO is the set of output symbols.\nf is the state transition function.\ng is the output function.\ns0 is the initial state.\nGiven an input x \u2208 I on state Sk, the FSM \ntransitions to state Sh, following state transi-\ntion function f, and produces an output y \u2208 O, \nusing the output function g.\nFigure 17.20 illustrates an FSM with S0 as \nthe start state and S1 as the final state. Here, S \n= {S0, S1, S2}; I = {0, 1}; O = {2, 3}; f(S0, 0) = S2; \nf(S0, 1) = S1; f(S1, 0) = S2; f(S1, 1) = S2; f(S2, 0) = \nS2; f(S2, 1) = S0; g(S0, 0) = 3; g(S0, 1) = 2; g(S1, \n0) = 3; g(S1, 1) = 2; g(S2, 0) = 2; g(S2, 1) = 3.\nThe state transition and output values for dif-\nferent inputs on different states may instead be \nrepresented using a state table. The state table \nfor the FSM in Figure 17.20 is shown in Figure \n17.21. Each pair against an input symbol rep-\nresents the new state and the output symbol. \nFigures 17.21(a) and 17.21(b) are alternative \nrepresentations of the FSM in Figure 17.20.\n6.\t Grammar  \b\n[1*, c13]\nThe grammar of a natural language defines \nwhether a combination of words makes a \nvalid sentence. Unlike natural languages, a \nformal language is specified by a well-defined \nset of rules for syntaxes. The valid sentences \nof a formal language can be described by a \ngrammar with the help of these rules, called \nproduction rules.\nA formal language is a set of finite-length \nwords or strings over some finite alphabet, \nand a grammar specifies the rules for forming \nthose words or strings. The entire set of words \nthat are valid for a grammar constitutes the \nlanguage for the grammar. Thus, the grammar \nG is any compact, precise mathematical defi-\nnition of a language L as opposed to a raw \nlisting of all legal sentences or examples of \nthose sentences in that language.\nA grammar implies an algorithm that can \ngenerate all legal sentences of the language. \nThere are different types of grammars.\nA phrase structure grammar (PSG) \nor Type-0 grammar G = (V, T, S, P) is a \n4-tuple in which:\n\u2022\t V is the vocabulary \u2014 i.e., the set of words.\n\u2022\t T \u2286 V is a set of words called terminals. \n\u2022\t S \u2208 N is a special word called the \nstart symbol.\n\u2022\t P is the set of production rules for substi-\ntuting one sentence fragment for another.\nThere exists another set, N = V \u2212 T, of words \ncalled nonterminals. The nonterminals repre-\nsent concepts such as noun. Production rules are \napplied on strings containing nonterminals until \nno more nonterminal symbols are present in \nthe string. The start symbol S is a nonterminal.\nThe language generated by a formal \ngrammar G, denoted by L(G), is the set of all \nstrings over the set of alphabets V that can be \ngenerated, starting with the start symbol, by \napplying production rules until all the nonter-\nminal symbols are replaced in the string.\nFor example, let G = ({S, A, a, b}, {a, b}, S, \n{S \u2192 aA, S \u2192 b, A \u2192 aa}). Here, the set of \nterminals is N = {S, A}, where S is the start \nsymbol. The three production rules for the \ngrammar are given as P1: S \u2192 aA; P2: S \u2192 \nb; P3: A \u2192 aa. \nApplying the production rules in all pos-\nsible ways, the following words may be gener-\nated from the start symbol:\nCurrent \nState\nInput\nInput\nInput\nCurrent \nState\n(a)\n(b)\nOutput\n f\nState \nTrans g\n0\n1\n3\n2\n3\n2\n0\n1\n0\n1\nS\u2082,\nS\u2081,\n3\n2\nS\u2082,\nS\u2082,\n2\n3\nS\u2082,\nS\u2080,\nS\u2082\nS\u2081\nS\u2080\nS\u2082\nS\u2082\nS\u2081\nS\u2081\n3\n2\nS\u2082\nS\u2082\n2\n3\nS\u2082\nS\u2080\nS\u2080\nFigure 17.21. Tabular Representation of an FSM\n", "page": 359, "type": "text", "section": "Page 359"}
{"text": "17-14   SWEBOK \u00ae GUIDE V4.0\nS \t\n\u2192 aA\t\n(using P1 on start symbol)\n\t\n\u2192 aaa\t (using P3)\nS \t\n\u2192 b \t\n(using P2 on start symbol)\nNothing else can be derived from G. Thus, \nthe language of the grammar G consists of \nonly two words: L(G) = {aaa, b}.\n6.1.\t Language Recognition \nFormal grammars can be classified according \nto the types of productions they allow. The \nChomsky hierarchy (introduced by Noam \nChomsky in 1956) describes such a classifi-\ncation scheme. \nFrom Figure 17.22, we can infer the fol-\nlowing about different grammars:\n1.\t Every regular grammar is a context-free \ngrammar (CFG).\n2.\t Every \nCFG \nis \na \ncontext-sensitive \ngrammar (CSG).\n3.\t Every CSG is a phrase structure \ngrammar (PSG).\nContext-Sensitive Grammar (CSG): All \nfragments in the RHS are either longer than \nthe corresponding fragments in the LHS or \nempty; in other words, if b \u2192 a, then |b| < |a| \nor a = \u03c6. A formal language is context-sensi-\ntive if a CSG generates it.\nContext-Free Grammar (CFG): All frag-\nments in the LHS are of length 1; in other \nwords, if A \u2192 a, then |A| = 1 for all A \u2208 N. \nThe term context-free derives from the fact \nthat A can always be replaced by a, regardless \nof the context in which it occurs. A formal \nlanguage is context-free if a CFG generates \nit. Context-free languages are the theoret-\nical basis for the syntax of most programming \nlanguages.\nRegular Grammar: All fragments in the \nRHS are either single terminals or a pair \nbuilt by a terminal and a nonterminal; if A \u2192 \na, then either a \u2208 T, a = cD, or a = Dc for c \n\u2208 T, D \u2208 N.\nIf a = cD, the grammar is called a right \nlinear grammar. On the other hand, if a = Dc, \nthe grammar is called a left linear grammar. \nBoth the right linear and left linear grammars \nare regular or Type-3 grammars. \nThe language L(G) generated by a regular \ngrammar G is called a regular language.\nA regular expression A is a string (or pat-\ntern) formed from the following pieces of \ninformation: a \u2208 \u03a3, the set of alphabets, \u03b5, 0, \nand the operations OR (+), PRODUCT (\u2022), \nand CONCATENATION (*). The language \nof G, L(G) is equal to all those strings that \nmatch G, L(G) = {x \u2208 \u03a3*|x matches G}.\nFor any a \u2208 \u03a3, L(a) = a; L(\u03b5) = {\u03b5}; L(0) = 0.\n+\t functions as an or, L(A + B) = \nL(A) \u222a L(B).\n\u2022\t creates a product structure, L(AB) = \nL(A) \u2022 L(B).\n*\t denotes concatenation, L(A*) = {x1x2 \n\u2026 xn | xi \u2208 L(A) and n \u2265 0}.\nFor example, the regular expression (ab)* \nmatches the set of strings: {\u03b5, ab, abab, ababab, \nabababab, \u2026}. The regular expression (aa)* \nmatches the set of strings on one letter \u2018a\u2019 with \neven length. The regular expression (aaa)* + \n(aaaaa)* matches the set of strings of length \nequal to a multiple of 3 or 5.\n7.\t Number Theory  \b\n[1*, c4]\nNumber theory is one of the oldest branches \nof pure mathematics and one of the largest. \nIt concerns questions about numbers, usu-\nally meaning whole numbers, and fractional \nType 0: PSG\nType 1: CSG\nType 2: CFG\nType 3:\nRegular Grammar\nFigure 17.22. Chomsky Hierarchy of Grammars\n", "page": 360, "type": "text", "section": "Page 360"}
{"text": "MATHEMATICAL FOUNDATIONS   17-15\nor rational numbers. The different types of \nnumbers include integer, real number, natural \nnumber, complex number and rational number.\n7.1.\t Types of Numbers\nNatural Numbers: This group of numbers \nstarts at 1 and continues with 2, 3, 4, 5 and \nso on. Zero is not in this group. There are no \nnegative or fractional numbers in the group of \nnatural numbers. The common mathematical \nsymbol for the set of all natural numbers is N.\nWhole Numbers: This group has all natural \nnumbers plus the number 0.\nUnfortunately, not everyone accepts the \nabove definitions of natural and whole num-\nbers. There seems to be no general agreement \nabout whether to include 0 in the set of nat-\nural numbers. Many mathematicians consider \nthat, in Europe, the sequence of natural num-\nbers traditionally started with 1 (0 was not \neven considered a number by the Greeks). In \nthe 19th century, set theoreticians and other \nmathematicians started the convention of \nincluding 0 in the set of natural numbers.\nIntegers: This group includes all the whole \nnumbers and their negatives. The common \nmathematical symbol for the set of all integers \nis Z \u2014 i.e., Z = {\u2026, \u22123, \u22122, \u22121, 0, 1, 2, 3, \u2026}.\nRational Numbers: These numbers can \nbe expressed as a ratio of two integers. The \ncommon symbol for the set of all rational \nnumbers is Q.\nRational numbers may be classified into \nthree types based on how the decimals act: (1) \ndecimals do not exist (e.g., 15); or (2) deci-\nmals do exist, and they terminate (e.g., 15.6); \n(3) decimals do exist, and they repeat with a \npattern, as in 1.666... (which is 5/3). \nIrrational Numbers: These numbers cannot \nbe expressed as an integer divided by an \ninteger. These numbers have decimals that \nnever terminate and never repeat with a pat-\ntern (e.g., PI or \u221a2).\nReal Numbers: This group comprises all \nrational and irrational numbers. The numbers \nalgebra uses are real numbers. The common \nmathematical symbol for the set of all real \nnumbers is R.\nImaginary Numbers: These are all based \non the imaginary number i. This imaginary \nnumber is equal to the square root of \u22121. Any \nreal number multiple of i is an imaginary \nnumber (e.g., i, 5i, 3.2i, \u22122.6i).\nComplex Numbers: A complex number \nis a combination of a real number and an \nimaginary number in the form a + bi. The \nreal part is a, and b is called the imaginary \npart. The common mathematical symbol \nfor the set of all complex numbers is C. For \nexample, 2 + 3i, 3 \u2212 5i, 7.3 + 0i, and 0 + 5i \nare complex numbers, but the latter two are \nequivalent to real numbers. 7.3 + 0i is the \nsame as the real number 7.3. Similarly, 0 + \n5i is same as the imaginary number 5i. All \nreal numbers are complex numbers with 0 \nfor the imaginary part, and all imaginary \nnumbers are complex numbers with 0 for \nthe real part.\n7.2.\t Divisibility\nElementary number theory involves divisi-\nbility among integers. Let a, b \u2208 Z with a \n\u2260 0. The expression a|b says that a divides b \nif \u2203c \u2208 Z, and the expression b = ac means \nthat there is an integer c such that c times \na equals b. For example, 3|\u221212 is true, but \n3|7 is false.\nIf a divides b, then we say that a is a factor of \nb or a is a divisor of b, and b is a multiple of a.\nb is even if and only if 2|b. \nLet a, d \u2208 Z with d > 1. Then a mod d \ndenotes the remainder r from the division \nalgorithm with dividend a and divisor d, i.e., \nthe remainder when a is divided by d. We can \ncompute (a mod d) by a \u2212 d* \u23a3a/d\u23a6, where \u23a3a/d\u23a6 \nrepresents the floor of the real number.\nLet Z+ = {n \u2208 Z | n > 0} and a, b \u2208 Z, m \u2208 \nZ+. Then a is congruent to b modulo m, written \nas a \u2261 b (mod m), if and only if m | a \u2212 b.\nAlternately, a is congruent to b modulo m if \nand only if (a \u2212 b) mod m = 0.\n7.3.\t Prime Number\nAn integer p > 1 is prime if and only if it is not \nthe product of any two integers greater than \n", "page": 361, "type": "text", "section": "Page 361"}
{"text": "17-16   SWEBOK \u00ae GUIDE V4.0\n1; i.e., p is prime if p > 1 \u2227 \u2203 \u00ac a, b \u2208 N: a > 1, \nb > 1, a * b = p.\nThe only positive factors of a prime p are \n1 and p itself. The numbers 2, 13, 29, 61, \netc., are prime numbers. Nonprime integers \ngreater than 1 are called composite numbers. A \ncomposite number may be composed by mul-\ntiplying two integers greater than 1.\nThere are many interesting applications \nof prime numbers; among them is the pub-\nlic-key cryptography scheme, which involves \nthe exchange of public keys containing the \nproduct p*q of two random large primes p and \nq (a private key) that must be kept secret by a \ngiven party.\n7.4.\t Greatest Common Divisor\nThe greatest common divisor gcd(a, b) of inte-\ngers a, b is the greatest integer d that is a \ndivisor both of a and of b \u2014 i.e., \nd = gcd (a, b) for max (d: d|a \u2227 d|b).\nFor example, gcd(24, 36) = 12.\nIntegers a and b are called relatively prime \nor coprime if and only if their GCD is 1. \nFor example, neither 35 nor 6 is prime, but \nthey are coprime, as these two numbers \nhave no common factors greater than 1, so \ntheir GCD is 1.\nA set of integers X = {i1, i2, \u2026} is relatively \nprime if all possible pairs ih, ik, h \u2260 k drawn \nfrom the set X are relatively prime.\n8.\t Basics of Counting \b\n[1*, c6]\nThe sum rule states that if a task t1 can be done \nin n1 ways and a second task t2 can be done in \nn2 ways, and if these tasks cannot be done at \nthe same time, then there are n1 + n2 ways to \ndo either task.\n\u2022\t If A and B are disjoint sets, then |A \u222a \nB|=|A| + |B|.\n\u2022\t In general if A1, A2, \u2026, An are disjoint \nsets, then |A1 \u222a A2 \u222a \u2026 \u222a An| = |A1| + \n|A2| + \u2026 + |An|.\nIf 200 athletes do sprint events and 30 ath-\nletes participate in the long jump event, then \nhow many ways are there to pick one athlete \nwho is either a sprinter or a long jumper?\nUsing the sum rule, the answer would be \n200 + 30 = 230.\nThe product rule states that if a task t1 can \nbe done in n1 ways and a second task t2 can be \ndone in n2 ways after the first task has been \ndone, then there are n1 * n2 ways to perform \nthe procedure.\n\u2022\t If A and B are disjoint sets, then |A \u00d7 B| \n= |A| * |B|.\n\u2022\t In general, if A1, A2, \u2026, An are disjoint \nsets, then |A1 \u00d7 A2 \u00d7 \u2026 \u00d7 An| = |A1| * \n|A2| * \u2026. * |An|.\nIf 200 athletes do sprint events and 30 ath-\nletes participate in the long jump event, then \nhow many ways are there to pick two ath-\nletes so that one is a sprinter and the other is \na long jumper?\nUsing the product rule, the answer would \nbe 200 * 30 = 6,000.\nThe principle of inclusion-exclusion states that \nif a task t1 can be done in n1 ways and a second \ntask t2 can be done in n2 ways at the same time \nwith t1, then to find the total number of ways \nthe two tasks can be done, one must subtract the \nnumber of ways to do both tasks from n1 + n2.\n\u2022\t If A and B are not disjoint, |A \u222a B| = |A| \n+ |B| \u2212 |A \u2229 B|.\nIn other words, the principle of inclu-\nsion-exclusion aims to ensure that the objects \nin the intersection of two sets are not counted \nmore than once.\nRecursion is the general term for defining \nan object in terms of itself. There are recur-\nsive algorithms, recursively defined functions, \nrelations, sets, etc.\nA recursive function is a function that calls \nitself. For example, we can define f(n) = 3 * f(n \n\u2212 1) for all n \u2208 N and n \u2260 0 and f(0) = 5.\nAn algorithm is recursive if it solves a \nproblem by reducing it to an instance of the \nsame problem with a smaller input.\n", "page": 362, "type": "text", "section": "Page 362"}
{"text": "MATHEMATICAL FOUNDATIONS   17-17\nA phenomenon is said to be random if indi-\nvidual outcomes are uncertain but the long-\nterm pattern of many individual outcomes is \npredictable.\nThe probability of any outcome for a \nrandom phenomenon is the proportion of \ntimes the outcome would occur in a very long \nseries of repetitions.\nThe probability P(A) of any event A satis-\nfies 0 \u2264 P(A) \u2264 1. Any probability is a number \nbetween 0 and 1. If S is the sample space in \na probability model, then P(S) = 1. All pos-\nsible outcomes together must have a proba-\nbility of 1.\nTwo events are disjoint if they have no out-\ncomes in common and so can never occur \ntogether. If A and B are two disjoint events, \nP(A or B) = P(A) + P(B). This is known as the \naddition rule for disjoint events.\nIf two events have no outcomes in common, \nthe probability that one or the other occurs is \nthe sum of their individual probabilities.\nPermutation is an arrangement of objects \nin which the order matters without repeti-\ntion. For example, one can choose r objects in \na particular order from a total of n objects by \nusing nPr ways, where npr = n! / (n \u2212 r)!. Various \nnotations, such as nPr and P(n, r), are used to \nrepresent the number of permutations of a set \nof n objects taken r at a time.\nCombination is a selection of objects in \nwhich the order does not matter without rep-\netition. This is different from a permutation \nbecause the order does not matter. If only the \norder is changed (and not the members), no \nnew combination is formed. One can choose \nr objects in any order from a total of n objects \nusing nCr ways, where nCr = n! / [r! * (n \u2212 r)!].\n9.\t Discrete Probability \b\n[1*, c7]\nProbability is the mathematical description of \nrandomness. Basic definitions of probability \nand randomness are provided in the previous \nsection. Here, we start with the concepts \nbehind probability distribution and discrete \nprobability.\nA probability model is a mathemat-\nical description of a random phenomenon \nconsisting of two parts: a sample space S and \na way of assigning probabilities to events. The \nsample space defines the set of all possible \noutcomes, whereas an event is a subset of a \nsample space representing a possible outcome \nor a set of outcomes.\nA random variable is a function or rule that \nassigns a number to each outcome. Basically, \nit is a symbol that represents the outcome of \nan experiment. For example, X could be the \nnumber of heads when the experiment is flip-\nping a coin n times. Similarly, S could be \nthe speed of a passing car as measured on a \nradar detector.\nThe values for a random variable could \nbe discrete or continuous, depending on the \nexperiment. A discrete random variable can \nhold all possible values (i.e., can represent \nall possible outcomes) without missing any, \nalthough it might take an infinite amount \nof time. A continuous random variable is \nused to measure an uncountable number \nof values even when an infinite amount of \ntime is given.\nFor example, if random variable X rep-\nresents an outcome that is a real number \nbetween 1 and 100, then X may have an \ninfinite number of values. Therefore, one can \nnever list all possible outcomes for X, even if \nan infinite amount of time is allowed. Here, \nX is a continuous random variable. On the \nother hand, for the same interval of 1 to 100, \nanother random variable Y can be used to list \nall integer values in the range. Here, Y is a dis-\ncrete random variable.\nAn uppercase letter, say X, will represent \nthe name of the random variable. Its lowercase \ncounterpart, x, will represent the value of the \nrandom variable.\nThe probability that the random variable X \nwill equal x is: \nP(X = x) or, more simply, P(x).\nA \nProbability \nDistribution \n(Density) \nFunction (PDF) is a table, formula or graph \nthat describes the values of a random vari-\nable and the probabilities associated with \nthese values. Probabilities associated with \n", "page": 363, "type": "text", "section": "Page 363"}
{"text": "17-18   SWEBOK \u00ae GUIDE V4.0\ndiscrete random variables have the following \nproperties:\n\u2022\t 0 \u2264 P(x) \u2264 1 for all x\n\u2022\t  \n\u03a3P(x) = 1\nA discrete probability distribution can be rep-\nresented as a discrete random variable.\nThe mean \u03bc of a probability distribution model \nis the sum of the product terms for individual \nevents and their outcome probability. In other \nwords, for the possible outcomes x1, x2, \u2026, \nxn in a sample space S if pk is the probability \nof outcome xk, the mean of this probability \nwould be \u03bc = x1p1 + x2p2 + \u2026 + xnpn. The mean \nof the probability density for the distribution \nin Figure 17.23 would be the following:\n\t 1 * (1/6) + 2 * (1/6) + 3 * (1/6) + 4 * (1/6) + 5 * \n \n\t \t (1/6) + 6 * (1/6) \n\t = 21 * (1/6) = 3.5\nHere, the sample space refers to the set of \nall possible outcomes.\nThe variance \u03c32 of a discrete probability model \nis \u03c32 = (x1 \u2013 \u03bc)2p1 + (x2 \u2013 \u03bc)2p2 + \u2026 + (xk \u2013 \u03bc)2pk. \nThe standard deviation, \u03c3, is the square root of \nthe variance. For the probability distribution \nin Figure 17.23, the variation \u03c32 would be the \nfollowing:\n\t \u03c32 = [(1 \u2013 3.5)2 * (1/6) + (2 \u2013 3.5)2 * (1/6) \n \n\t \t + (3 \u2013 3.5)2 * (1/6) + (4 - 3.5)2 * (1/6) + (5 \n \n\t \t \u2013 3.5)2 * (1/6) + (6 \u2013 3.5)2 * (1/6)]\n\t = (6.25 + 2.25 + 0.25 + 0.5 + 2.25 \n \n\t \t + 6.25) * (1/6) \n\t = 17.5 * (1/6) \n\t = 2.90\n\u2234 standard deviation s = 1.70\nThese numbers aim to derive the average \nvalue from repeated experiments. This is based \non the most important principle in probability \n\u2014 i.e., the average value from repeated exper-\niments is likely to be close to the expected \nvalue of one experiment. Moreover, the \naverage value is more likely to be closer to the \nexpected value of any one experiment as the \nnumber of experiments increases.\n10.\tNumerical Precision, Accuracy, and Error \n\b\n[2*, c1]\nThe main goal of numerical analysis is to \ndevelop efficient algorithms for computing \nprecise numerical values of functions, as well \nas finding solutions to algebraic and differen-\ntial equations, optimization problems, etc.\nDigital computers can store finite num-\nbers only. A digital computer cannot repre-\nsent any infinitely large number \u2014 be it an \ninteger, rational number, or any real or com-\nplex number [see section 7, Number Theory]. \nThe mathematics of approximation is critical \nfor working with numbers in the finite range \na computer can handle.\nEach number in a computer is assigned a \nlocation (e.g., an address or register) and con-\nsists of a quantity of binary digits, or bits. A \nk-bit location can store any of N = 2k different \nnumbers. A 32-bit location can store any of \nN = 232 \u2248 4.3 \u00d7 109 different numbers, while \na 64-bit location can store any of N = 264 \u2248 \n1.84 \u00d7 1019 different numbers. The question \nis how to distribute those numbers for max-\nimum efficiency and accuracy in practical \ncomputations.\nOne choice is to distribute the numbers \nevenly, leading to fixed-point arithmetic. In \nthis system, the first bit represents the sign, \nand the remaining bits represent magnitude. \nThe decimal point \u2014 more appropriately, the \nbinary point (the transition between whole \nand fractional values) \u2014 can be anywhere. \nInteger numbers are represented by placing \nthe binary point immediately to the right of \nthe least significant bit, and integer num-\nbers between \u22122k\u22121\u22121 and 2k\u22121 can be stored. \nPlacing the binary point to the left of the least \nX\n1\n2\n3\n4\n5\n6\nP(x)\n1/6\n1/6\n1/6\n1/6\n1/6\n1/6\nFigure 17.23. A Discrete Probability Function for a \nRolling Die\n", "page": 364, "type": "text", "section": "Page 364"}
{"text": "MATHEMATICAL FOUNDATIONS   17-19\nsignificant bit allows non-integer values to be \nrepresented.\nAnother choice is to space the numbers \nclosely together, say with a uniform gap of \n2\u2212n, and thereby distribute the total N num-\nbers uniformly over the interval \u22122\u2212n\u22121N < x \u2264 \n2\u2212n\u22121N. Real numbers lying between the gaps \nare represented by either rounding (meaning \nthe closest exact representative) or chopping \n(meaning the exact representative immediately \nbelow \u2014 or above, if negative \u2014 the number). \nNumbers outside the range must be rep-\nresented by the largest (or largest negative) \nnumber that can be represented. This becomes a \nsymbol for overflow, which occurs when a com-\nputation produces a value outside the range.\nWhen processing speed is a significant bot-\ntleneck, fixed-point representations can be an \nattractive and faster alternative to the more \ncumbersome floating-point arithmetic most \ncommonly used in practice.\nAccuracy and precision are important \nterms in numerical analysis. \nAccuracy is the closeness with which a mea-\nsured or computed value agrees with the \ntrue value.\nPrecision, on the other hand, is the close-\nness with which two or more measured or \ncomputed values for the same thing agree. In \nother words, precision is the closeness with \nwhich a number represents an exact value.\nLet x be a real number, and let x* be an \napproximation. The absolute error in the approx-\nimation x* \u2248 x is defined as | x* \u2212 x |. The relative \nerror is defined as the ratio of the absolute error \nto the size of x \u2014 i.e., |x* \u2212 x| / | x | \u2014 which \nassumes x \u2260 0; otherwise, relative error is not \ndefined. For example, 1,000,000 is an approx-\nimation of 1,000,001 with an absolute error of \n1 and a relative error of 10\u22126, whereas 10 is an \napproximation of 11 with an absolute error of \n1 and a relative error of 0.1. Typically, relative \nerror is more intuitive and the preferred deter-\nminer of the size of the error. The present con-\nvention is that errors are always \u2265 0 and are = 0 \nif and only if the approximation is exact.\nAn approximation x* has k significant dec-\nimal digits if its relative error is < 5 \u00d7 10\u2212\nk\u22121. This means that the first k digits of x* \nfollowing its first nonzero digit are the same \nas those of x.\nSignificant digits are the digits of a number \nthat are known to be correct. In a measure-\nment, one uncertain digit is included. For \nexample, measurement of length with a ruler \nof 15.5 mm with \u00b10.5 mm maximum allow-\nable error has two significant digits, whereas a \nmeasurement of the same length using a cal-\niper and recorded as 15.47 mm with \u00b10.01 \nmm maximum allowable error has three sig-\nnificant digits.\n11.\tAlgebraic Structures\nThis section introduces a few representa-\ntions used in higher algebra. An algebraic \nstructure consists of one or two sets closed \nunder some operations and satisfying several \naxioms, including none. For example, group, \nmonoid, ring and lattice are examples of alge-\nbraic structures. Group, monoid and ring are \ndefined in this section. \n11.1.\t\nGroup\nA set S closed under a binary operation \u2022 \nforms a group if the binary operation satisfies \nthe following four criteria:\n\u2022\t Associative: \u2200a, b, c \u2208 S, the equation (a \u2022 \nb) \u2022 c = a \u2022 (b \u2022 c) holds.\n\u2022\t Identity: There exists an identity element \nI \u2208 S such that for all a \u2208 S, I \u2022 a = a \u2022 I = a.\n\u2022\t Inverse: Every element a \u2208 S has an \ninverse a\u2032 \u2208 S with respect to the binary \noperation, i.e., a \u2022 a\u2032 = I; for example, \nthe set of integers Z with respect to the \naddition operation is a group. The iden-\ntity element of the set is 0 for the addi-\ntion operation. In \u2200x \u2208 Z, the inverse of x \nwould be \u2013x, which is also included in Z.\n\u2022\t Closure property: \u2200a, b \u2208 S, the result of \nthe operation a \u2022 b \u2208 S.\nA group that is commutative i.e., a \u2022 b = b \u2022 \na is known as a commutative or Abelian group. \nThe set of natural numbers N (with the \noperation of addition) is not a group because \n", "page": 365, "type": "text", "section": "Page 365"}
{"text": "17-20   SWEBOK \u00ae GUIDE V4.0\nthere is no inverse for any x > 0 in the set of \nnatural numbers. (The third criterion, the \ninverse criterion, is violated.) However, the set \nof natural numbers has some structure.\nSets with an associative operation (the first \ncriterion) are called semigroups; if they also have \nan identity element (the second criterion), they \nare called monoids. The set of natural numbers \nunder addition is an example of a monoid, a \nstructure that is not quite a group because it \nis missing the requirement that every element \nhave an inverse under the operation.\nA monoid is a set S that is closed under a \nsingle associative binary operation \u2022 and has \nan identity element I \u2208 S such that for all a \u2208 \nS, I \u2022 a = a \u2022 I = a. A monoid must contain at \nleast one element. The set of natural numbers \nN forms a commutative monoid under addi-\ntion with identity element 0. The same set of \nnatural numbers N also forms a monoid under \nmultiplication with identity element 1. The \nset of positive integers P forms a commuta-\ntive monoid under multiplication with iden-\ntity element 1.\nIt may be noted that, unlike those in a \ngroup, elements of a monoid need not have \ninverses. A monoid can also be considered a \nsemigroup with an identity element. \nA subgroup is a group H contained within \na bigger group, G, such that the identity ele-\nment of G is contained in H, and whenever \nh1 and h2 are contained in H, so are h1 \u2022 h2 \nand h1\n\u22121. Thus, the elements of H, equipped \nwith the group operation on G restricted to \nH, form a group.\nGiven any subset S of a group G, the sub-\ngroup generated by S consists of products \nof elements of S and their inverses. It is the \nsmallest subgroup of G containing S. For \nexample, let G be the Abelian group whose \nelements are G = {0, 2, 4, 6, 1, 3, 5, 7} and \nwhose group operation is addition modulo 8. \nThis group has a pair of nontrivial subgroups: \nJ = {0, 4} and H = {0, 2, 4, 6}, where J is also a \nsubgroup of H. \nIn group theory, a cyclic group is a group \nthat can be generated by a single element, \nin the sense that the group has an element a \n(called the generator of the group) such that, \nwhen this element is written multiplicatively, \nevery element of the group is a power of a.\nA group G is cyclic if G = {an for any \ninteger n}. \nSince any group generated by an element in \na group is a subgroup of that group, showing \nthat the only subgroup of a group G that con-\ntains a is G itself suffices to show that G is \ncyclic. For example, the group G = {0, 2, 4, 6, \n1, 3, 5, 7}, with respect to addition modulo 8 \noperation, is cyclic. The subgroups J = {0, 4} \nand H = {0, 2, 4, 6} are also cyclic.\n11.2.\t\nRing\nIf we take an Abelian group and define a \nsecond operation on it, a new structure is \nfound that is different from just a group. If \nthis second operation is associative and is dis-\ntributive over the first, then we have a ring. \nA ring is a triple of the form (S, +, \u2022), where \n(S, +) is an Abelian group, (S, \u2022) is a semigroup \nand \u2022 is distributive over +; i.e., \u2200 a, b, c \u2208 S, \nthe equation a \u2022 (b + c) = (a \u2022 b) + (a \u2022 c) holds. \nFurther, if \u2022 is commutative, then the ring is \nsaid to be commutative. If there is an identity \nelement for the \u2022 operation, then the ring is \nsaid to have an identity.\nAs an example, (Z, +, *), i.e., the set of \nintegers Z with the usual addition and mul-\ntiplication operations, is a ring. As (Z, *) is \ncommutative, this ring is a commutative \nor Abelian ring. The ring has 1 as its iden-\ntity element.\nNote that the second operation may not \nhave an identity element, nor do we need to \nfind an inverse for every element with respect \nto this second operation. As for what distrib-\nutive means, intuitively, it is what we do in \nelementary mathematics when we perform \nthe following operation: a * (b + c) = (a * b) \n+ (a * c).\nA field is a ring for which the elements of \nthe set, excluding 0, form an Abelian group \nwith the second operation. A simple example \nof a field is the field of rational numbers (R, \n+, *) with the usual addition and multiplica-\ntion operations. The numbers are of the form \na/b \u2208 R, where a, b are integers and b \u2260 0. The \n", "page": 366, "type": "text", "section": "Page 366"}
{"text": "MATHEMATICAL FOUNDATIONS   17-21\nadditive inverse of such a fraction is simply \n\u2212a/b, and the multiplicative inverse is b/a, pro-\nvided that a \u2260 0.\n12.\tEngineering Calculus\nCalculus is a branch of mathematics that deals \nwith study of continuous transition, deriva-\ntives and integrals of functions using methods \noriginally based on the summation of infin-\nitesimal differences. Engineering Calculus \nfocuses on learning analytical geometry and \nvectors for engineering applications.  \nEngineering \nCalculus \nincludes \nthe \nlearning of the following:\n\u2022\t Limits\n\u2022\t Continuity\n\u2022\t Differentiation\n\u2022\t Integration\n\u2022\t Transcendental functions\n\u2022\t Vector calculus\nLimits are the building blocks of Calculus. \n \nFor a function f(x), the limit of the function \nat a point \u2018a\u2019 is the value the function achieves \nat a point \u2018a\u2019.\nL = lim x->a f(x) \nA function is said to be Continuous on the \ninterval [a, b] if it is continuous at each point \nin the interval.\nLim  f(x) = f (a)\nx->a \nThe two major elements of calculus are differ-\nential calculus and integral calculus.\n\u2022\t Differential calculus analyzes the rate \nof change of one quantity in rela-\ntion to the rate of change of another. \nGeometrically, it is the slope of the line \ntangent to the graph of the function. The \nrate of change of x with respect to y is \nexpressed as dx/dy.\n\u2022\t Integral calculus analyzes such concepts as \nthe area or volume enclosed by a function.\nA transcendental function, in contrast to \nan algebraic function, is an analytic function \nthat does not satisfy a polynomial equation.\nVector calculus deals with the differentia-\ntion and integration of vector fields in the \nthree-dimensional Euclidean space.\nSoftware engineers are encouraged to \nlearn Engineering Calculus with case studies. \nThese concepts are required for analysing and \nextrapolating data. \n13.\tNew Advancements\n13.1.\t\nComputational Neurosciences\nComputational Neurosciences is a branch of \nNeurosciences that uses mathematical models, \ncomputer simulations and brain abstraction to \nunderstand and analyze cognitive abilities of \nthe nervous systems. This enables the learning \nof control theory, cybernetics, quantitative \npsychology, machine learning, artificial intel-\nligence, creative / imagination and connec-\ntionism among others.\nThe central assumption of computational \nneuroscience is that the brain computes. What \ndoes that mean? Generally speaking, a com-\nputer is a dynamic system whose state vari-\nables encode information about the external \nworld. In short, computation equals coding plus \ndynamics. Some neuroscientists study the way \nthat information is encoded in neural activity \nand other dynamic variables of the brain. \nOthers try to characterize how these dynamic \nvariables evolve over time. The study of neural \ndynamics can be further subdivided into two \nseparate strands. One tradition, exemplified by \nthe work of Hodgkin and Huxley, focuses on the \nbiophysics of single neurons. The other focuses \non the dynamics of networks, concerning itself \nwith phenomena that emerge from the inter-\nactions between neurons. Therefore computa-\ntional neuroscience can be divided into three \nsub-specialties: neural coding, biophysics of \nneurons, and neural networks.\n13.2.\t\nGenomics\nThe in-silico analysis of nucleotide sequences \n", "page": 367, "type": "text", "section": "Page 367"}
{"text": "17-22   SWEBOK \u00ae GUIDE V4.0\nof chromosome(s) from a given organism is \ncalled \u201cgenome\u201d. The genome is the genetic \nmaterial of living organisms, containing \nhereditary characteristics. It is constituted by \nDNA. Genomic studies aim to understand \nhow genes and genetic information are orga-\nnized within the genome and how this orga-\nnization determines their function.\nGenomics deals with structure, func-\ntion, mapping, evolution and editing of \ngenomes, including sequencing and anal-\nysis of genomes.\nSignificant research works are being under-\ntaken in the areas of preventive and thera-\npeutic healthcare, especially in the area of \ndetection, analysis and repair of genetic dis-\norders.  These include genome data security, \ngenome data sharing, efficiency in genome \ndata analysis among others.\nGenomics encompasses a variety of tech-\nniques and approaches, including DNA \nsequencing, bioinformatic analysis, study of \ngenetic variation, computational modeling, \nand much more. \nThe advancement of DNA sequencing \ntechnologies and bioinformatic analysis has \nsignificantly propelled progress in genomics, \nenabling detailed study of genomes across \nvarious organisms.\nDue to the large amount of data repre-\nsented by nucleotide sequences obtained from \ngenome sequencing, informatics is required to \nhandle these data. And the development of \nspecific software for the field relies heavily on \nSoftware Engineering.\nMATRIX OF TOPICS VS.  \nREFERENCE MATERIAL\nRosen 2018 [1*]\nCheney and \nKincaid 2020 [2*]\n1.\t Basic Logic\nc1\n2.\t Proof Techniques\nc1\n3.\t Set, Relation, Function\nc2\n4.\t Graph and Tree\nc10, c11\n5.\t Finite State Machine\nc13\n6.\t Grammar\nc13\n7.\t Number Theory\nc4\n8.\t Basics of Counting\nc6\n9.\t Discrete Probability\nc7\n10.\tNumerical Precision, \nAccuracy and Error\nc2\n11.\tAlgebraic Structures\n12.\tCalculus\nREFERENCES\n[1*] K. Rosen, Discrete Mathematics and Its \nApplications, 8th ed., McGraw-Hill, 2018.\n[2*] E.W. Cheney and D.R. Kincaid, \nNumerical Mathematics and Computing, \n7th ed., Addison Wesley, 2020.\n", "page": 368, "type": "text", "section": "Page 368"}
{"text": "18-1 \nCHAPTER 18\nEngineering Foundations\nACRONYMS\nCAD\nComputer-Aided Design\nCMMI\nCapability Maturity Model Integration\nPDF\nProbability Density Function\nPMF\nProbability Mass Function\nRCA\nRoot Cause Analysis\nSDLC\nSoftware Development Life Cycle\nINTRODUCTION\nThe Institute of Electrical and Electronics \nEngineers (IEEE) defines engineering as \u201cthe \napplication of a systematic, disciplined, quanti-\nfiable approach to structures, machines, prod-\nucts, systems or processes\u201d [1]. As the theory and \nthe practice of software engineering mature, it is \nincreasingly apparent that software engineering \nas a discipline is based on skills and knowledge \nthat are common to all engineering disciplines. \nThis knowledge area (KA) explores engineering \nfoundations pertinent to other engineering dis-\nciplines that also apply to software engineering. \nThe focus is on covering topics that support \nother KAs while minimizing duplication of \ncontent covered elsewhere in this Guide. \nBREAKDOWN OF TOPICS FOR \nENGINEERING FOUNDATIONS\nThe breakdown of topics for the Engineering \nFoundations KA is shown in Figure 18.1.\n1.\t The Engineering Process\b\n[2*, c4]\nThe engineering process, which is common to \nall engineering disciplines, is discussed more \nfully in the Software Engineering Economics \nKA. (Refer to that chapter for more informa-\ntion.) A brief, high-level summary is included \nhere. Figure 18.2 shows the process flow.\nThe engineering process is necessarily iter-\native; knowledge gained at any point may be \nrelevant to earlier steps, triggering iteration. \nThese steps are briefly defined below:\n\u2022\t Understand \nthe \nreal \nproblem \n\u2014 \nEngineering begins when a need is recog-\nnized and no existing solution meets that \nneed. However, the problem that needs \nto be solved is not always the problem \nengineers are asked to solve. Use root \ncause analysis techniques (discussed later \nin this KA) to discover the underlying \nproblem needing a solution.\n\u2022\t Define \nthe \nselection \ncriteria \n\u2014 \nEngineering decisions must consider \nvarious factors; for example, they must \nconsider financial criteria, as discussed \nin the Software Engineering Economics \nKA. Be sure to identify all relevant selec-\ntion criteria.\n\u2022\t Identify all reasonable, technically fea-\nsible solutions \u2014 The best solution is \nrarely the first solution that comes to \nmind. Therefore, consider multiple tech-\nnically feasible solutions to ensure that \nthe optimal solution is among the set \nconsidered.\n\u2022\t Evaluate each solution against the selec-\ntion criteria \u2014 Determine how well each \ntechnically feasible solution satisfies the \nneed while meeting the various criteria \n(for example, financial criteria).\n\u2022\t Select the preferred option \u2014 Identify \nwhich technically feasible solution best \nsatisfies the selection criteria.\n", "page": 369, "type": "text", "section": "Page 369"}
{"text": "18-2   SWEBOK \u00ae GUIDE V4.0\n\u2022\t Monitor the performance of the selected \nsolution \u2014 The engineering process nec-\nessarily depends on estimates, and those \nestimates can be wrong. Therefore, it is \nessential to evaluate the selected alterna-\ntive\u2019s real-world performance and, if nec-\nessary (and possible), decide whether one \nof the other alternatives might be better.\nMuch of the rest of this KA elabo-\nrates on details of this higher-level engi-\nneering process.\n2.\t Engineering Design\b\n[3*, c1s2-s4]\nA product\u2019s design will affect or even deter-\nmine its life cycle costs. This is true for man-\nufactured products as well as for software. \nSoftware design is guided by the features to \nbe implemented and the quality attributes to \nbe achieved. In the software engineering con-\ntext, \u201cdesign\u201d has a particular meaning; while \nthere are commonalities between engineering \ndesign as discussed in this section and soft-\nware engineering design as discussed in the \nSoftware Architecture KA and the Software \nDesign KA, there are also many differences. \nFor example, the scope of engineering design \nis generally viewed as much broader than that \nof software design.\nMany disciplines involve solving problems \nfor which there is a single correct solution. \nIn engineering, most problems have many \nsolutions, and the focus is on finding a fea-\nsible solution (among many alternatives) that \nbest meets the needs presented, economi-\ncally. In business, where the goal may be to \nfoster innovation in the marketplace, product \ndefinitions may derive from a business case. \nWhichever is the origin, possible solutions \nare often constrained by explicitly imposed \nlimitations such as cost, available resources, \nand the state of discipline or domain knowl-\nedge. In engineering problems, implicit con-\nstraints (such as the physical properties of \nmaterials or the laws of physics) sometimes \nrestrict the set of feasible solutions for a \ngiven problem.\n2.1.\t Engineering Design in Engineering \nEducation\nVarious engineering education accreditation \nbodies, including the Canadian Engineering \nAccreditation Board and the Accreditation \nBoard for Engineering and Technology \n(ABET), place great value on engineering \ndesign, as evidenced by their high expecta-\ntions in this area. \nThe Canadian Engineering Accreditation \nBoard requires specified levels of engineering \ndesign experience and coursework for engi-\nneering students and certain qualifications for \nthe faculty members who teach such course-\nwork or supervise design projects. The organi-\nzation\u2019s accreditation criteria state: \nEngineering\nFoundations\nTe\nEngineering\nProcess\nEngineering\nDesign\nAbstraction \nand\nEncapsulation\nEmpirical\nMethods and\nExperimental\nTechniques\nStatistical\nAnalysis\nModeling,\nSimulation,\nand \nPrototyping\nEngineering\nDesign in\nEngineering\nEducation\nDesign as a\nProblem-\nSolving\nActivity\nDesigned\nExperiment\nObservational\nStudy\nRetrospective\nStudy\nLevels of\nAbstraction\nEncapsulation\nHierarchy\nAlternate\nAbstractions\nUnit of \nAnalysis\n(Sampling \nUnits),\nPopulation, \nand Sample\nCorrelation and\nRegression\nMeasurement\nLevels (Scales) of\nMeasurement\nImplications of\nMeasurement\nTeory on\nProgramming\nLanguages\nDirect and\nDerived Measures\nReliability and \nValidity\nAssessing\nReliability\nGoal-Question-\nMetric Paradigm:\nWhy Measure?\nRoot Cause\nAnalysis\nRoot Cause\nAnalysis Techniques\nRoot Cause-\nBased\nImprovement\nIndustry 4.0 \nand Software\nEngineering\nStandards\nModeling\nSimulation\nPrototyping\nFigure 18.1. Breakdown of Topics for the Engineering Foundations KA\n", "page": 370, "type": "text", "section": "Page 370"}
{"text": "ENGINEERING FOUNDATIONS   18-3\nDesign: An ability to design solutions for com-\nplex, open-ended engineering problems and to \ndesign systems, components or processes that \nmeet specified needs with appropriate atten-\ntion to health and safety risks, applicable stan-\ndards, and economic, environmental, cultural, \nand societal considerations [4, p7].\nSimilarly, ABET defines engineering \ndesign as follows:\n\u2026 a process of devising a system, component, \nor process to meet desired needs and specifica-\ntions within constraints. It is an iterative, cre-\native, decision-making process in which the \nbasic sciences, mathematics, and engineering \nsciences are applied to convert resources into \nsolutions [5, p7].\nThus, engineering design is vital to the \ntraining and education of all engineers. The \nrest of this section focuses on various aspects \nof engineering design.\n2.2.\t Design as a Problem-Solving Activity  \n\b\n[3*, c1s4, c2s1, c3s3] [6*, c5s1]\nEngineering design is primarily a prob-\nlem-solving activity. Finding a solution is \nparticularly challenging because design prob-\nlems tend to be open-ended and vaguely \ndefined, and there are usually several ways to \nsolve the same problem. Design is generally \nconsidered a wicked problem \u2014 a term coined \nby Horst Rittel in the 1960s when design \nmethods were a subject of intense interest. \nRittel sought an alternative to the linear, step-\nby-step process many designers and design \ntheorists were exploring and argued that most \nproblems addressed by designers are wicked \nproblems. As explained by McConnell, a \nwicked problem presents a paradox: One can \ndefine it only by solving it, or by solving part \nof it. However, that solution is not the final \nsolution; a wicked problem must be solved \nonce to define it clearly and solved again to \ncreate a solution that works. This has been an \nimportant insight for software designers for \ndecades [6*, c5s1].\n3.\t Abstraction and Encapsulation \n\b\n[6*, c5s2-4]\nAbstraction is an indispensable technique \nassociated with problem-solving. It refers to \nboth the process and the result of generaliza-\ntion, where one reduces the information about \na concept, problem or observable phenomenon \nin order to focus on the \u201cbig picture.\u201d One of \nthe most important skills in any engineering \nundertaking is the ability to frame the levels \nof abstraction appropriately.\nAccording to Voland, \u201cThrough abstrac-\ntion, we view the problem and its possible \nsolution paths from a higher level of con-\nceptual understanding. As a result, we may \nbecome better prepared to recognize possible \nrelationships between different aspects of the \nDe\ufb01ne the\nselection criteria\nIdentify all \nreasonable technically \nfeasible solutions\nSelect the\npreferred alternative\nMonitor the\nperformance of the\nselected alternative\nEvaluate each\nalternative against\nthe selection criteria\nUnderstand the\nreal problem\nFigure 18.2. The Engineering Process\n", "page": 371, "type": "text", "section": "Page 371"}
{"text": "18-4   SWEBOK \u00ae GUIDE V4.0\nproblem and thereby generate more creative \ndesign solutions\u201d [2*]. This is true in computer \nscience in general (such as hardware vs. soft-\nware) and in software engineering in partic-\nular (e.g., data structure vs. data flow).\nDijkstra states, \u201cThe purpose of abstracting \nis not to be vague, but to create a new \nsemantic level in which one can be absolutely \nprecise\u201d [7].\n3.1.\t Levels of Abstraction \nWhen abstracting, we concentrate on one \n\u201clevel\u201d of the big picture at a time, confident \nthat we can connect effectively with levels above \nand below. Although we focus on one level, \nabstraction does not mean knowing nothing \nabout the neighboring levels. Abstraction levels \ndo not necessarily correspond to discrete com-\nponents in reality or in the problem domain, \nbut to well-defined standard interfaces such \nas application programming interfaces (APIs). \nStandard interfaces offer advantages such as \nportability, easier software/hardware integra-\ntion and wider usage.\n3.2.\t Encapsulation\nEncapsulation is a mechanism used to imple-\nment abstraction. When we are working with \none level of abstraction, the information con-\ncerning the levels below and above that level \nis encapsulated. This can be information about \nthe concept, problem, or observable phenom-\nenon or the permissible operations on these \nentities. Encapsulation usually means hiding \nunderlying details about the level above the \ninterface provided by the abstraction. For \nexample, hiding information about an object \nis useful because we don\u2019t need to know the \ndetails of how the object is represented or how \nthe operations on the object are implemented.\n3.3.\t Hierarchy\nWhen we use abstraction in our problem \nformulation and solution, we might use dif-\nferent abstractions at different times \u2014 in \nother words, we work on different levels of \nabstraction as the situation requires. Usually, \nthese different levels of abstraction are orga-\nnized in a hierarchy. There are many ways to \nstructure a particular hierarchy, and the cri-\nteria used in determining the specific content \nof each layer vary depending on the individ-\nuals performing the work.\nSometimes, a hierarchy of abstraction is \nsequential, meaning that each layer has one \nand only one predecessor (lower) layer and \none and only one successor (upper) layer \u2014 \nexcept the upmost layer (which has no suc-\ncessor) and the bottommost layer (which has \nno predecessor). Sometimes, however, the \nhierarchy is organized in a tree structure, \nwhich means each layer can have more than \none predecessor layer but only one successor \nlayer. Occasionally, a hierarchy can have a \nmany-to-many structure, in which each layer \nhas multiple predecessors and successors. A \nhierarchy never contains a loop.\nA hierarchy often forms naturally in task \ndecomposition. Often, task analysis can be \ndecomposed hierarchically, starting with \nthe organization\u2019s larger tasks and goals and \nbreaking each into smaller subtasks that can \nagain be subdivided. This continuous division \nof tasks into smaller ones produces a hierar-\nchical structure of tasks and subtasks.\n3.4.\t Alternate Abstractions\nSometimes, multiple alternate abstractions \nfor the same problem are useful to keep dif-\nferent perspectives in mind. For example, we \ncan have a class diagram, a state chart and \na sequence diagram for the same software \nat the same level of abstraction. These alter-\nnate abstractions do not form a hierarchy but \ncomplement each other, helping to illuminate \nthe problem and its solution. Though benefi-\ncial, keeping alternate abstractions in sync is \nsometimes difficult.\n4.\t Empirical Methods and Experimental \nTechniques \b\n[8*, c1]\nThe \nengineering \nprocess \ninvolves \npro-\nposing solutions or models of solutions and \n", "page": 372, "type": "text", "section": "Page 372"}
{"text": "ENGINEERING FOUNDATIONS   18-5\nconducting experiments or tests to study those \nproposed solutions or models. Thus, engineers \nmust understand how to create an experiment \nand analyze the results to evaluate proposed \nsolutions. Empirical methods and experi-\nmental techniques help the engineer describe \nand understand variability in their observa-\ntions, identify the sources of that variability, \nand make decisions.\nThree types of empirical studies commonly \nused in engineering efforts are designed \nexperiments, observational studies and ret-\nrospective studies. Brief descriptions of the \ncommonly used methods are given below.\n4.1.\t Designed Experiment\nA designed or controlled experiment tests a \nhypothesis by manipulating one or more inde-\npendent variables to measure their effect on \none or more dependent variables. A precon-\ndition for conducting this experiment is the \nexistence of a clear hypothesis. Therefore, \nengineers need to understand how to formu-\nlate clear hypotheses.\nDesigned experiments allow engineers \nto determine precisely how the variables are \nrelated and, specifically, whether a cause-ef-\nfect relationship exists between them. Each \ncombination of values of the independent vari-\nables is a treatment. The simplest experiments \nhave just two treatments, representing two \nlevels of a single independent variable (e.g., \nusing a tool vs. not using a tool). More com-\nplex experimental designs arise when more \nthan two levels, more than one independent \nvariable, or any dependent variables are used.\n4.2.\t Observational Study\nAn observational or case study is an empirical \ninquiry that makes observations of processes \nor phenomena within a real-world context. \nWhile an experiment deliberately ignores con-\ntext, an observational or case study includes \ncontext. A case study is most useful when it \nfocuses on how and why questions, on when the \nbehavior of those involved cannot be manipu-\nlated, and on when contextual conditions are \nrelevant and the boundaries between the phe-\nnomena and context are unclear.\n4.3.\t Retrospective Study\nRetrospective studies involve the analysis of \nhistorical data, and thus are also known as \nhistorical studies. This type of study uses data \n(regarding some phenomenon) archived over \ntime. This archived data is then analyzed to \nfind relationships between variables, to pre-\ndict future events or to identify trends. One \nlimitation is that the quality of the analysis \ndepends on the quality of the archived data, \nand historical data may be incomplete, incon-\nsistently measured or incorrect.\n5.\t Statistical Analysis  \n\b\n[8*, c9s1, c2s1] [9*, c11s3] \nEngineers must understand how product and \nprocess characteristics vary. Engineers often \nencounter situations where the relationship \nbetween different variables must be studied. \nMost studies use samples, but the results need \nto be understood with respect to the full pop-\nulation. Therefore, engineers must understand \nstatistical techniques for collecting and inter-\npreting reliable data (sampling and analysis) \nto arrive at results that can be generalized. \nThese techniques are discussed below.\n5.1.\t Unit of Analysis (Sampling Units), \nPopulation, and Sample\nUnit of analysis. In any empirical study, the \nresearchers must make observations based \non chosen units called the units of anal-\nysis or sampling units. These units must be \nclearly identified and be appropriate for the \nanalysis. For example, in a study of the per-\nceived usability of a software product, the user \nor the software function might be the unit \nof analysis.\nPopulation. The set of all respondents or \nitems (possible sampling units) forms the \npopulation. For example, for a study of the \nperceived usability of a software product, the \nset of all possible users forms the population.\n", "page": 373, "type": "text", "section": "Page 373"}
{"text": "18-6   SWEBOK \u00ae GUIDE V4.0\nIn defining the population, care must be \ntaken to differentiate the study and target \npopulations. The population being studied \nand the population for which the results are \ngeneralized will differ if the study involves a \nsample. For example, when the study popu-\nlation consists only of past observations but \ngeneralizations are required for the future, \nthe study population and the target popula-\ntion are not the same.\nSample. A sample is a subset of the pop-\nulation. The most crucial issue in selecting \na sample is its representativeness, including \nsize. The samples must be drawn in a way that \nensures draws are independent, and the rules \nof drawing samples must be predefined so the \nprobability of selecting a particular sampling \nunit is known beforehand. This method of \nselecting samples is called probability sampling. \nRandom variable. In statistical termi-\nnology, the process of making observations \nor measurements on the sampling units is \nreferred to as conducting the experiment. For \nexample, if the experiment is to toss a coin 10 \ntimes and count the number of times the coin \nlands on heads, every 10 tosses of the coin \nis a sampling unit and the number of heads \nfor a given sample is the observation or out-\ncome for the experiment. The outcome of an \nexperiment is obtained in terms of real num-\nbers and defines the random variable being \nstudied. The attribute of the items being mea-\nsured at the outcome of the experiment rep-\nresents the random variable being studied; the \nobservation obtained from a particular sam-\npling unit is a particular realization of the \nrandom variable. In the example of the coin \ntoss, the random variable is the number of \nheads observed for each experiment. \nThe set of possible values of a random vari-\nable may be finite or infinite but countable \n(e.g., the set of all integers or the set of all odd \nnumbers). In such a case, the random variable \nis called a discrete random variable. In other \ncases, the random variable under consider-\nation may take values on a continuous scale \nand is called a continuous random variable.\nEvent. A subset of possible values of a \nrandom variable is called an event. Suppose \nX denotes some random variable; then, for \nexample, we may define different events such \nas X \u2265 x or X < x and so on.\nDistribution of a random variable. A random \nvariable\u2019s range and pattern of variation are \ngiven by its distribution. When the distribu-\ntion of a random variable is known, it is pos-\nsible to compute the probability of any event. \nSome distributions occur commonly and are \nused to model many random variables occur-\nring in practice in the context of engineering. \nA few of the more commonly occurring dis-\ntributions are described below:\n\u2022\t Binomial distribution is used to model \nrandom variables that count the number \nof successes in n trials carried out inde-\npendently of each other, where each trial \nresults in success or failure. We assume \nthat the chance of a successful trial \nremains constant [8*, c3s5].\n\u2022\t Poisson distribution is used to model the \ncount of occurrences of some event over \ntime or space [8*, c3s8].\n\u2022\t Normal distribution is used to model con-\ntinuous or discrete random variables \nby taking a very large number of values \n[8*, c4s5].\nConcept of parameters. Parameters charac-\nterize a statistical distribution. For example, \nthe proportion of successes in any given trial is \nthe only parameter characterizing a binomial \ndistribution. Similarly, the Poisson distribu-\ntion is characterized by a rate of occurrence. \nA normal distribution is characterized by two \nparameters: its mean and standard deviation.\nOnce the values of the parameters are \nknown, the distribution of the random vari-\nable is revealed and the chance (probability) \nof any event can be computed. The proba-\nbilities for a discrete random variable can be \ncomputed through the probability mass func-\ntion (PMF). The PMF is defined at discrete \npoints and gives the point mass \u2014 i.e., the \nprobability that the random variable takes \nthat particular value. Likewise, for a contin-\nuous random variable, we have the probability \ndensity function (PDF). The PDF needs to be \n", "page": 374, "type": "text", "section": "Page 374"}
{"text": "ENGINEERING FOUNDATIONS   18-7\nintegrated over a range to obtain the proba-\nbility that the continuous random variable lies \nbetween certain values. Thus, if the PMF or \nPDF is known, the chances of the random \nvariable taking a certain set of values may be \ncomputed theoretically.\nConcept of estimation [8*, c7s1, c7s3]. The \ntrue values of the parameters of a distribution \nare usually unknown and need to be estimated \nfrom the sample observations. The estimates \nare functions of the sample values and are \ncalled statistics. For example, the sample mean \nis a statistic and may be used to estimate the \npopulation mean. Similarly, the rate of occur-\nrence of defects estimated from the sample \n(rate of defects per line of code) is a statistic and \nserves as the estimate of the population rate \nof defects per line of code. The statistic used \nto estimate a population parameter is often \nreferred to as the estimator of the parameter.\nThe results of the estimators themselves \nare random. If we take a different sample, we \nwill likely get a different population param-\neter estimate. In the theory of estimation, \nwe need to understand different properties \nof estimators \u2014 particularly, how much the \nestimates can vary across samples and how to \nchoose between different ways to obtain the \nestimates. For example, if we wish to estimate \nthe mean of a population, we might use as our \nestimator a sample mean, a sample median, a \nsample mode or the midrange of the sample. \nEach of these estimators has different statis-\ntical properties that might impact the stan-\ndard error of the estimate.\nTypes of estimates [8*, c7s3, c8s1]. There are \ntwo types of estimates: point estimates and \ninterval estimates. When we use the value of \na statistic to estimate a population parameter, \nwe get a point estimate. As the name indi-\ncates, a point estimate gives a point value of \nthe parameter estimated.\nAlthough point estimates are often used, \nthey leave room for many questions. For \ninstance, they do not tell us anything about the \npossible error size or the estimate\u2019s statistical \nproperties. Thus, we might need to supple-\nment a point estimate with information about \nthe sample size and the estimate\u2019s variance. \nAlternatively, we might use an interval esti-\nmate. An interval estimate is a random interval \nwhose lower and upper limits are functions of \nthe sample observations and the sample size. \nThe limits are computed based on assumptions \nregarding the sampling distribution of the \npoint estimate on which the limits are based. \nProperties of estimators. Various statistical \nproperties of estimators are used to deter-\nmine the appropriateness of an estimator in a \ngiven situation. The most important proper-\nties are efficiency, consistency with respect to \nthe population, and lack of bias.\nTests of hypotheses [8*, c9s1]. A hypothesis \nis a statement about the possible values of a \nparameter. For example, suppose someone \nclaims that a new method of software devel-\nopment reduces the occurrence of defects. The \nhypothesis is that the rate of occurrence of \ndefects has been reduced. When we test the \nhypothesis, we decide \u2014 based on sample \nobservations \u2014 whether it should be accepted \nor rejected.\nTo test hypotheses, the null and alterna-\ntive hypotheses are formed. The null hypoth-\nesis is the hypothesis of no change, denoted as \nH0. The alternative hypothesis is written as H1. \nThe alternative hypothesis may be one-sided \nor two-sided. For example, if we have the null \nhypothesis that the population mean is not less \nthan some given value, the alternative hypoth-\nesis would be that it is less than that value, and \nwe would have a one-sided test. However, if \nwe have the null hypothesis that the popula-\ntion mean is equal to some given value, the \nalternative hypothesis would be that it is not \nequal, and we would have a two-sided test \n(because the true value could be either less \nthan or greater than the given value).\nThe first step in testing a hypothesis is to \ncompute a statistic. In addition, a region is \ndefined such that if the computed value of \nthe statistic falls within that region, the null \nhypothesis is rejected. This region is called \nthe critical region (also known as the confidence \ninterval). In tests of hypotheses, we need to \naccept or reject the null hypothesis based on \nthe evidence obtained. In general, the alter-\nnative hypothesis is the hypothesis of interest. \n", "page": 375, "type": "text", "section": "Page 375"}
{"text": "18-8   SWEBOK \u00ae GUIDE V4.0\nIf the computed value of the statistic does not \nfall inside the critical region, then we cannot \nreject the null hypothesis. This indicates that \nthere is insufficient evidence to believe that \nthe alternative hypothesis is true.\nAs the decision is based on sample obser-\nvations, errors are possible; the types of such \nerrors are summarized in the following table.\nNature\nStatistical decision\nAccept H0\nReject H0\nH0 is  \ntrue\nOK\nType I error \n(probability = \u03b1)\nH0 is  \nfalse\nType II error \n(probability = \u03b2)\nOK\nIn testing hypotheses, we aim to maximize \nthe power of the test (the value of 1 \u2212 \u03b2) while \nensuring that the probability of a type I error \n(the value of \u03b1) is maintained within a partic-\nular value \u2014 typically 5%. \nAlso note that construction of a test of a \nhypothesis includes identifying statistic(s) to \nestimate the parameter(s) and defining a crit-\nical region such that if the computed value of \nthe statistic falls within the critical region, the \nnull hypothesis is rejected.\n5.2.\t Correlation and Regression \n\b\n[8*, c11s2, c11s8]\nA major objective of many statistical investi-\ngations is to establish relationships that make \nit possible to predict one or more variables in \nterms of others. Although it is desirable to \npredict a quantity exactly in terms of another \nquantity, that is seldom possible, and, in many \ncases, we must be satisfied with estimating \nthe average or expected values. \nThe relationship between two variables is \nstudied using correlation and regression. Both \nthese concepts are explained briefly below.\nCorrelation. The degree of the linear rela-\ntionship between two variables is measured \nusing the correlation coefficient. Computing the \ncorrelation coefficient is appropriate for two \nvariables that measure two different attributes \nof the same entity. The correlation coefficient \ntakes a value between \u22121 and +1. The values \n\u22121 and +1 indicate a situation where the asso-\nciation between the variables is perfect (i.e., \ngiven the value of one variable, the other can \nbe estimated with no error). A positive cor-\nrelation coefficient indicates a positive rela-\ntionship (i.e., if one variable increases, so does \nthe other). On the other hand, when the vari-\nables are negatively correlated, an increase of \none leads to a decrease in the other.\nAlways remember that correlation does \nnot imply causation. Thus, if two variables \nare correlated, we cannot conclude that one \ncauses the other.\nRegression. The correlation analysis only \nmeasures the degree of relationship between \ntwo variables. The analysis to find the strength \nof the relationship between two variables is \ncalled regression analysis. This analysis uses the \ncoefficient of determination \u2014 a value between \n0 and 1. The closer the coefficient is to 1, the \nstronger the relationship between the variables. \nA value of 1 indicates a perfect relationship.\n6.\t Modeling, Simulation, and Prototyping \n\b\n[3*, c6] [10*, c13s3] [11*, c5]\nModeling is part of the abstraction process used \nto represent aspects of a system. Simulation \nuses a model of the system to conduct designed \nexperiments to better understand the system, \nits behavior and relationships among subsys-\ntems, as well as to analyze aspects of the design. \nModeling and simulation can be used to con-\nstruct theories or hypotheses about the system\u2019s \nbehavior. Engineers then use those theories to \nmake predictions about the system. Prototyping \nis another abstraction process where a partial \nrepresentation (that captures aspects of interest) \nof the product or system is built. A prototype \nmay be an initial version of the system that \nlacks the full functionality of the final version. \n6.1.\t Modeling\nA model is always an abstraction of some real \nor imagined artifact. Engineers use models in \nmany ways as part of their problem-solving \nactivities. Some models are physical, such as \n", "page": 376, "type": "text", "section": "Page 376"}
{"text": "ENGINEERING FOUNDATIONS   18-9\na made-to-scale miniature construction of a \nbridge or building. Other models are non-\nphysical representations, such as a comput-\ner-aided design (CAD) drawing of a cog or \na mathematical model for a process. Models \nhelp engineers understand aspects of a \nproblem. They can also help engineers deter-\nmine what they know and what they don\u2019t \nknow about the problem.\nThere are three types of models: iconic, ana-\nlogic and symbolic. An iconic model is a visually \nequivalent but incomplete two-dimensional or \nthree-dimensional representation (e.g., maps, \nglobes or built-to-scale models of structures \nsuch as bridges or highways). An iconic model \nresembles the artifact modeled. \nIn contrast, an analogic model is a function-\nally equivalent but incomplete representation. \nThe model behaves like the physical artifact \neven though it may not physically resemble it. \nExamples of analogic models include a minia-\nture airplane for wind tunnel testing or a com-\nputer simulation of a manufacturing process.\nFinally, a symbolic model uses a higher level \nof abstraction, modeling the process or system \nwith symbols such as equations. The engineers \ncan use the symbols to understand, describe, \nand predict the properties or behavior of the \nfinal system or product. An example is the \nequation F = ma. \n6.2.\t Simulation \nAll simulation models are depictions of \nreality. A central issue in simulation is how to \nabstract data and create an appropriate simpli-\nfication of reality. Developing this abstraction \nis vital, as misspecification of the abstraction \nwould invalidate the results of the simulation \nexercise. Simulation can be used for a variety \nof testing purposes.\nSimulation is classified based on the type of \nsystem under study; simulation can be either \ncontinuous or discrete. In software engineering, \nthe emphasis is primarily on discrete simula-\ntion. Discrete simulations may model event \nscheduling or process interaction. The main \ncomponents in such a model include entities, \nactivities and events, resources, the state of \nthe system, a simulation clock, and a random \nnumber generator. The simulation generates \noutput that must be analyzed.\nAn important problem in the development \nof a discrete simulation is that of initializa-\ntion. Before a simulation can be run, the ini-\ntial values of all the state variables must be \nprovided. As the simulation designer may not \nknow what initial values are appropriate for the \nstate variables, these values might be chosen \nsomewhat arbitrarily. For instance, it might be \ndecided that a queue should be initialized as \nempty and idle. This choice for an initial con-\ndition can have a significant but unrecognized \nimpact on the simulation outcome.\n6.3.\t Prototyping\nConstructing a prototype of a system is \nanother abstraction process. In this case, an \ninitial version of the system is constructed, \noften while the system is designed, which \nhelps the designers determine the feasibility \nof their design.\nA prototype has many uses, including elic-\niting requirements, designing and refining \na user interface, and validating functional \nrequirements. The objectives and purposes \nfor building the prototype will guide its con-\nstruction and determine the level of abstrac-\ntion used. \nThe role of prototyping is somewhat dif-\nferent for physical systems and software. With \nphysical systems, the prototype might be the \nfirst fully functional version of a system, or \nit might be a model of the system. In soft-\nware engineering, prototypes are also abstract \nmodels of part of the software. However, they \nare usually not constructed with all the archi-\ntectural, performance and other quality char-\nacteristics expected in the finished product. \nIn either case, prototype construction must \nhave a clear purpose and be planned, mon-\nitored and controlled \u2014 it is a technique to \nstudy a specific problem within a limited con-\ntext [12*, c2s8]. \nIn conclusion, modeling, simulation and \nprototyping are powerful techniques for \nstudying the behavior of a system from a \n", "page": 377, "type": "text", "section": "Page 377"}
{"text": "18-10   SWEBOK \u00ae GUIDE V4.0\ngiven perspective. All can be used to perform \ndesigned experiments to study various aspects \nof the system. However, these are abstrac-\ntions and, as such, may not model all attri-\nbutes of interest.\n7.\t Measurement \n\b\n[2*, pp442-447] [3*, c4s4] \n \n\b\n[12*, c7s5] [13*, c3s1-2]\nKnowing what to measure, how to measure \nit, what can be done with measurements and \neven why to measure is critical in engineering \nendeavors. Everyone involved in an engi-\nneering project must understand the measure-\nment methods, the measurement results and \nhow those results can and should be used.\nMeasurements can be physical, environ-\nmental, economic, operational or another \nsort of measurement that is meaningful to \nthe project. This section explores the theory \nof measurement and how it is fundamental \nto engineering. Measurement starts as an \nabstract concept and progresses to a defini-\ntion of the measurement method and then \nto the actual application of that method to \nobtain a measurement result. Each step must \nbe understood, communicated and properly \nperformed to yield usable data. In traditional \nengineering, direct measures are often used. \nIn software engineering, a combination of \nboth direct and derived measures (defined in \n7.3 below) is necessary [13*, p273].\nThe theory of measurement states that \nmeasurement is an attempt to describe an \nunderlying empirical system. Measurement \nmethods specify activities that assign a value \nor symbol to an attribute of an entity.\nAttributes must then be defined in terms \nof the operations used to identify and mea-\nsure them (the measurement methods). In this \napproach, a measurement method is defined \nas a precisely specified operation that yields \na symbol (called the measurement result) as \npart of the measurement of an attribute. To \nbe useful, the measurement method must be \nwell defined. Arbitrariness or vagueness in \nthe method leads to ambiguity in the mea-\nsurement results.\nIn some cases \u2014 particularly in the physical \nworld \u2014 the attributes we wish to measure are \neasy to grasp; however, in an artificial world \nlike software engineering, defining attributes \nmight not be that simple. For example, the \nattributes of height, weight, distance, etc., are \neasily and uniformly understood (though they \nmay not be very easy to measure in all circum-\nstances). In contrast, attributes such as software \nsize and complexity require clear definitions.\nOperational definitions. The definition of \nattributes, to start with, is often rather abstract. \nSuch definitions do not facilitate measure-\nments. For example, we might define a circle \nas a line forming a closed loop such that the \ndistance between any point on this line and \na fixed interior point called the center is con-\nstant. We might further say that the fixed \ndistance from the center to any point on the \nclosed loop is the circle\u2019s radius. Though the \nconcept has been defined, no means of mea-\nsuring the radius has been proposed. The oper-\national definition specifies the exact steps or \nmethod used to carry out a specific measure-\nment. This can also be called the measurement \nmethod; sometimes, a measurement procedure \nmight be required to be even more precise.\nThe importance of operational definitions \ncan hardly be overstated. Take the case of \nthe apparently simple measurement of a per-\nson\u2019s height. Unless we specify various factors \n\u2014for example, the time the height is mea-\nsured (because the height of individuals varies \nthroughout the day), how the variability cre-\nated by hair is handled, whether the measure-\nment is taken when the person is wearing shoes \nor not, the accuracy expected (to the nearest \ninch, 1/2 inch, centimeter, etc.) \u2014 then even \nthis simple measurement will produce sub-\nstantial variation. Therefore, engineers must \nappreciate the need to define measurements \nfrom an operational perspective.\n7.1.\t Levels (Scales) of Measurement \n\b\n[2*, pp442-447] [12*, c7s5] [13*, c3s2]\nOnce the operational definitions have been \ndetermined, actual measurements can be \ntaken. Measurement may be carried out in \n", "page": 378, "type": "text", "section": "Page 378"}
{"text": "ENGINEERING FOUNDATIONS   18-11\nfour different scale types: nominal, ordinal, \ninterval, and ratio. Brief descriptions of each \nare given below:\nNominal scale: This is the lowest level of \nmeasurement and represents the most unre-\nstricted assignment of symbols, which are \nonly labels. Nominal scales involve classifi-\ncation where measured entities are put into \none of the mutually exclusive and collectively \nexhaustive categories (classes). Examples of \nnominal scales are the following:\n\u2022\t Job titles in an organization\n\u2022\t Automobile styles (sedan, coupe, hatch-\nback, minivan, etc.)\n\u2022\t Software development life cycle (SDLC) \nmodels (waterfall, iterative, Agile, etc.)\nIn nominal scales, no relationship among \nsymbols may be inferred. The only valid types \nof manipulation of measures in a nominal \nscale are the following:\n\u2022\t Determining whether two entities have \nthe same or different symbol (e.g., \u201cIs \nyour job title the same as or different \nfrom my job title?\u201d)\n\u2022\t Counting the number of entities having \nthe same symbol (e.g., \u201cHow many \nemployees have the job title Software \nEngineer Level 2 in this organization?\u201d)\nStatistical analyses may be carried out to \nunderstand how entities belonging to dif-\nferent classes perform with respect to some \nother variable.\nOrdinal scale: Ordinal scales extend nominal \nscales by requiring a strict ordering relationship \namong the symbols. Ordinal scales are neces-\nsarily transitive (if A > B and B > C, then A > \nC). The following are examples of ordinal scales:\n\u2022\t Finish order in a race (1st, 2nd, 3rd)\n\u2022\t Probabilities \nexpressed \nusing \nterms \n(remote, \nunlikely, \neven, \nprobable, \nalmost certain)\n\u2022\t Severities expressed using terms (neg-\nligible, \nmarginal, \nserious, \ncritical, \ncatastrophic)\n\u2022\t Level of agreement expressed using terms \n(strongly agree, somewhat agree, neutral, \nsomewhat disagree, strongly disagree)\n\u2022\t Capability Maturity Model Integration \n(CMMI) staged maturity levels\nAll manipulations of values on nom-\ninal scales are valid on ordinal scales, while \nordinal scales also support more-than and \nless-than comparisons. For example:\n\u2022\t Did you finish that race before, tied with \nor after me?\n\u2022\t Is Event X the same, more or less prob-\nable than Event Y?\n\u2022\t Is Event X the same, more or less severe \nthan Event Y?\n\u2022\t Is the CMMI staged maturity level of \nOrganization A the same, higher or lower \nthan that of Organization B?\nWhen an ordinal scale uses numbers as \nsymbols \u2014 like the CMMI staged maturity \nlevels 1, 2, 3, 4 and 5 \u2014 those numbers cannot \nbe manipulated arithmetically. We cannot say \nthat the difference between CMMI staged \nmaturity level 5 and level 4 (5 \u2212 4) compares in \nany meaningful way to the difference between \nlevel 3 and level 2 (3 \u2212 2). Neither can we say \nthat CMMI staged maturity level 4 is twice as \ngood as level 2. Ordinal scales that use numbers \nas symbols are commonly misused in exactly \nthis way \u2014 for example, to present mean and \nstandard deviation (e.g., \u201cThe average software \norganization worldwide has a CMMI staged \nmaturity level of 1.763.\u201d). Such misuse can \neasily lead to erroneous conclusions [13*, p274]. \n(We can compute the median on an ordinal \nscale, as this only involves counting.) Using \nnonnumerical symbols, such as initial, repeat-\nable, defined, managed, and optimizing (for \nCMMI staged maturity levels), is preferred \nbecause it helps prevent such mistreatment. \nProperly chosen labels also better communi-\ncate the meaning of each label.\nInterval scale: Interval scales extend ordinal \nscales by requiring that the difference between \nany pair of adjacent values is constant. The \nfollowing are examples of interval scales:\n", "page": 379, "type": "text", "section": "Page 379"}
{"text": "18-12   SWEBOK \u00ae GUIDE V4.0\n\u2022\t Temperatures \nexpressed \nin \ndegrees \nCelsius and Fahrenheit: The difference \nbetween \u22129\u00b0C and \u22128\u00b0C is the same as \nthat between 26\u00b0C and 27\u00b0C. The differ-\nence between \u22129\u00b0F and \u22128\u00b0F is the same \nas the difference between 26\u00b0F and 27\u00b0F.\n\u2022\t Calendar dates: The difference between \nany two consecutive dates is always one \nday: 24 hours.\n\u2022\t Shoe sizes in North America: The differ-\nence between size 3 and size 4 is the same \nas the difference between a size 10 and size \n11 \u2014 one-third of an inch, or 8.467 mm.\nAll manipulations of values on ordinal \nscales are valid on interval scales, while \ninterval scales also support addition and sub-\ntraction. For example:\n\u2022\t The difference between \u22129\u00b0C and 0\u00b0C is \nthe same as that between 0\u00b0C and 9\u00b0C. \nThe difference between \u221250\u00b0F and 0\u00b0F is \nthe same as that between 25\u00b0F and 75\u00b0F.\n\u2022\t The length of time between May 6 \nand May 9 is the same as that between \nNovember 8 and November 11.\nInterval scales support most statistical \nanalyses, like mean, standard deviation, cor-\nrelation and regression. Any manipulation \ninvolving multiplication or division of values, \non the other hand, is meaningless because 0 on \nan interval scale, if it even exists, does not rep-\nresent the absence of the measured quantity. \nA 0 point on an interval scale is arbitrary with \nrespect to the attribute measured. Consider \nthat 0\u00b0 (both C and F) do not represent the \nabsence of heat (absolute zero), and a North \nAmerican size 0 shoe has non-zero length. \nTherefore, 30\u00b0C cannot be interpreted as twice \nas hot as 15\u00b0C, nor is a North American size \n9 shoe three times longer than a size 3 shoe.\nRatio scale: Ratio scales extend ordinal \nscales by requiring the 0 point to represent \nthe absence of the measured attribute. The \nfollowing are examples of ratio scales:\n\u2022\t Temperature in degrees Kelvin (K)\n\u2022\t Shoe sizes in the Mondopoint system \n(commonly used for athletic shoes, ski \nboots, skates and ballet shoes); a size \n270/105 shoe fits a foot 270 mm long and \n105 mm wide\n\u2022\t Count of decision constructs (e.g., if(), \nfor(), while(), in a given source code file)\n\u2022\t Money\nRatio scales support all arithmetic and sta-\ntistical manipulations. Values in one ratio \nscale can often be trivially transformed into \ncorresponding values in another ratio scale \nthat measures the same attribute by using a \nmultiplication factor. Distances in inches can \nbe trivially transformed into centimeters, \nweights in kilograms can be trivially trans-\nformed into pounds, speed in knots can be \ntrivially transformed into kilometers per hour, \nand so on.\nAn additional measurement scale, the abso-\nlute scale, is a ratio scale with uniqueness of \nmeasure (no transformation is possible). The \nnumber of software engineers working on a \nproject is an absolute scale because there are \nno other meaningful measures for numbers \nof people.\n7.2.\t Implications of Measurement Theory for \nProgramming Languages\nCommon programming languages support a \nset of built-in data types, often including the \nfollowing:\n\u2022\t Whole number types over varying ranges: \nint, integer, byte, short, long, etc.\n\u2022\t Floating-point numbers over varying \nranges with varying precision: real, float, \ndouble, etc.\n\u2022\t Single characters: char\n\u2022\t Ordered sequences of characters: string\nMany \nlanguages, \nalthough \nnot \nall, \nalso support type-safe enumeration (e.g., \nJava\u2019s \u201cenum\u201d).\nUnfortunately, these languages offer no \nsupport for measurement theory. They do not \nprevent, nor even warn programmers about, \ninappropriate manipulations. The whole and \n", "page": 380, "type": "text", "section": "Page 380"}
{"text": "ENGINEERING FOUNDATIONS   18-13\nfloating-point number data types in pro-\ngramming languages operate as ratio scales \nand support the full range of manipulations: \ncomparison, addition, subtraction, multi-\nplication, division and so on. But consider \nCMMI staged maturity level expressed as \na number. In measurement theory terms, as \nshown above, it is an ordinal scale, so addi-\ntion, subtraction, multiplication and division \nare inappropriate. If any programmer rep-\nresents a CMMI staged maturity level using \na whole number data type, nothing pre-\nvents the programmer from inappropriately \nadding, subtracting, multiplying or dividing \nthat number.\nThe same can be said for characters, strings \nand enumerations. Programming languages \nimplement them as ordinal scales; how-\never, they might only be intended for repre-\nsenting nominal-scale values. More-than and \nless-than comparisons are allowed even when \ninappropriate. The string \u201cminivan\u201d appears \nalphabetically before the string \u201csedan,\u201d but \ndrawing any conclusion other than the mere \nalphabetical ordering of arbitrary text strings \nas a result of that fact is inappropriate.\nCommon programming languages allow \nprogrammers to easily write code that is inap-\npropriate according to measurement theory. \nAs long as programming languages allow \nit, programmers can and will \u2014 intention-\nally or unintentionally \u2014 misuse measure-\nment scale types. A more sensible solution \nwould be data-type semantics that explicitly \nenforce measurement theory. For example, \na language could explicitly support nom-\ninal scales, as shown in Figure 18.3 Sample \nA. That language could then prevent, or at \nleast warn programmers against, more-than \nor less-than comparisons as shown in Figure \n18.3 Sample B.\nIf more-than or less-than comparisons are \nneeded, the language supports declaration \nof an ordinal type as shown in Figure 18.3 \nSample C. Figure 18.3 Sample D would not \ntrigger any error or warning. Similarly, an \ninterval scale could be supported, as shown in \nFigure 18.3 Sample E. A ratio scale could be \nsupported, as shown in Figure 18.3 Sample F.\nCommon programming languages have no \nproblem with the code shown in Figure 18.3 \nSample G. On the other hand, a measurement \ntheory\u2013aware programming language would \nbe expected to generate a compiler error \nor warning with the code shown in Figure \n18.3 Sample H.\nFuture programming languages should \nenforce measurement theory and not allow \ndevelopers to manipulate measurements inap-\npropriately. But until languages support mea-\nsurement theory, software engineers need to \nat least understand it and be on the lookout for \ninappropriate manipulations in, for example, \ncode reviews.\n7.3.\t Direct and Derived Measures \n\b\n[13*, c7s5]\nMeasures may be either direct or derived \n(sometimes called indirect measures). An \nexample of a direct measure is a count of how \nmany times an event occurred, such as the \nnumber of defects found in a software product. \nA derived measure combines direct measures \nin a way that is consistent with the measure-\nment methods used for those measures. For \nexample, calculating the average hours spent \nto repair per defect is a derived measure. In \nboth cases, the measurement method deter-\nmines how to perform the measurement. The \nscale types of those measures constrain how \nthey can be manipulated. When different \nscale types are involved:\n\u2022\t The scale type of the result of the manip-\nulation can be no higher than the scale \ntype of the most primitive measure-\nment scale involved (e.g., a manipula-\ntion involving an interval scale and a \nratio scale can only be done as if both \nare interval scales and can yield no better \nthan an interval scale result).\n\u2022\t Investment is required to make the \nmore primitive scale type compatible \nwith any higher scale type (e.g., effort \nis required to bring the interval scale up \nto a ratio scale so the result can also be \nratio-scaled).\n", "page": 381, "type": "text", "section": "Page 381"}
{"text": "18-14   SWEBOK \u00ae GUIDE V4.0\n7.4.\t Reliability and Validity\b\n[13*, c3s4-5]\nA basic question to ask when considering any \nmeasurement method is whether the proposed \nmeasurement method is truly measuring the \nconcept with good quality. Reliability and \nvalidity are the two most useful criteria for \naddressing this question.\nThe reliability of a measurement method is the \nextent to which the application of the method \nyields consistent results. Reliability refers to \nthe consistency of the values obtained when the \nsame item is measured several times. When the \nresults agree with each other, the measurement \nmethod is said to be reliable. Reliability usually \ndepends on the operational definition. It can be \nquantified by using the variation index, which \nis computed as the ratio between the standard \ndeviation and the mean. The smaller the index, \nthe more reliable the measurement results.\nValidity refers to whether the measurement \nmethod measures what we intend to measure. The \nvalidity of a measurement method may be consid-\nered from three different perspectives: construct \nvalidity, criteria validity and content validity.\n7.5.\t Assessing Reliability\b\n[13*, c3s5]\nMethods for assessing reliability include \nthe test-retest method, the alternative form \nNominal enum automobile_style = sedan, coupe, hatchback, \n\t\nminivan, suv, sports_car;\nSample A\nif( thisCarStyle >= sedan ) then \u2026 /\n/ this is not allowed\nSample B\nordinal enum CMMI_staged_level = initial, repeatable, defined, \n\t\nmanaged, optimizing;\nSample C\nif( anOrgsCMMILevel > repeatable ) then \u2026\nSample D\ninterval AirTemperatureCelsius from -120.0 to +180.0;\nAirTemperatureCelsius yesterdaysHighTemp;\nAirTemperatureCelsius todaysHighTemp;\nif( todaysHighTemp > yesterdaysHighTemp ) { \u2026 } /\n/ allowed\nif( todaysHighTemp > yesterdaysHighTemp * 2.0 ) { \u2026 } /\n/ not\nSample E\nratio TemperatureKelvin from 0.00 to 1000.00;\nTemperatureKelvin previousReading;\nTemperatureKelvin thisReading;\nif( thisReading > previousReading * 2. ) { \u2026 } /\n/ allowed\nSample F\ndouble priceOfBook;\ndouble highTemperature;\nhighTemperature = priceOfBook; /\n/ makes no sense but is allowed\nSample G\nratio Money from -10000.00 to +10000.00;\nratio TemperatureKelvin from 0.00 to 1000.00;\nMoney priceOfBook;\nTemperatureKelvin highTemperature;\ndouble highTemperature;\nhighTemperature = priceOfBook; /\n/ not allowed\nSample H\nFigure 18.3. Code Samples for Measurement Theory\n", "page": 382, "type": "text", "section": "Page 382"}
{"text": "ENGINEERING FOUNDATIONS   18-15\nmethod, the split-halves method and the \ninternal consistency method. The easiest of \nthese is the test-retest method. In this method, \nwe apply the measurement method twice to \nthe same subjects. The correlation coefficient \nbetween the first and second set of measure-\nment results gives us the reliability of the mea-\nsurement method.\n7.6.\t Goal-Question-Metric Paradigm:  \nWhy Measure?\nThe final concern to discuss here regarding \nmeasurement is the importance of under-\nstanding why we measure in the first place. \nThe Goal-Question-Metric paradigm can \nbe summarized with the simple observation \nthat a measurement should be made to sup-\nport decision-making. Some measurements \nsupport decisions in code. Other measure-\nments support decisions made by people \noutside of code (e.g., process improvement \nmeasures). The critical point is that some \ndecision should be made as a result of the \nmeasurement. Many real-world software \norganizations fall victim to a \u201cmeasurement \nfor the merely curious\u201d syndrome, where \nmetrics are gathered simply because they are \neasy to measure and interesting to look at \nwhen plotted in graphs. Those measurements \nare not used to support any decision and \nare a waste of time and energy. They should \nbe avoided. \n8.\t Standards\b\n[3*, c9s3.2]\nMoore states that a standard can be the \nfollowing: \na.\t\nAn object or measure of comparison \nthat defines or represents the magnitude \nof a unit \nb.\t A characterization that establishes allow-\nable tolerances for categories of items\nc.\t\nA degree or level of required excellence \nor attainment \nStandards are definitional in nature, estab-\nlished either to further understanding and \ninteraction or to acknowledge observed (or \ndesired) norms of exhibited characteristics or \nbehavior [14, p8]. \nStandards provide requirements, speci-\nfications or guidelines that engineers must \nobserve so that products, processes and mate-\nrials are of acceptable quality. The quali-\nties various standards dictate relate to safety, \nreliability or other product characteristics. \nStandards are considered critical to engineers, \nwho are expected to be familiar with and \nuse the appropriate standards for their spe-\ncific discipline.\nCompliance with or conformance to a \nstandard allows an organization to assure the \npublic that the organization\u2019s products meet \nthe requirements contained in that standard. \nThus, standards divide organizations or their \nproducts into those that conform to the stan-\ndard and those that do not. For a standard to \nbe useful, conformance must add real or per-\nceived value to the product, process or effort.\nApart from supporting organizational \ngoals, standards also serve several other pur-\nposes, such as protecting buyers, protecting \nbusinesses, and better defining the methods \nand procedures used in software engineering. \nStandards also provide users with common \nterminology and expectations.\nThere are many internationally recognized \nstandards-making organizations, including \nthe International Telecommunication Union \n(ITU), the International Electrotechnical \nCommission \n(IEC), \nIEEE, \nand \nthe \nInternational Organization for Standardization \n(ISO). In addition, regional and governmentally \nrecognized organizations generate standards \nfor their region or country. For example, in the \nUnited States, more than 300 organizations \ndevelop standards. These include organiza-\ntions such as the American National Standards \nInstitute (ANSI), ASTM International (for-\nmerly known as American Society for Testing \nand Materials), SAE International (formerly \nthe Society of Automotive Engineers), and \nUnderwriters Laboratories, Inc. (UL), as well \nas the US government. (For more information \non standards used in software engineering, see \nAppendix B.)\n", "page": 383, "type": "text", "section": "Page 383"}
{"text": "18-16   SWEBOK \u00ae GUIDE V4.0\nThere is a set of commonly used principles \nbehind standards. Standards makers attempt \nto reach consensus for their decisions. This \napproach fosters an openness within the com-\nmunity of interest so that once a standard is \nset, there is a good chance that it will be widely \naccepted. Most standards organizations have \nwell-defined processes for their efforts and \nadhere to them carefully. Engineers must \nbe aware of the existing standards and keep \nabreast of any changes to those standards \nover time.\nIn many engineering endeavors, under-\nstanding the applicable standards is critical, \nand the law may even require that spe-\ncific standards be followed. In these cases, \nthe standards often represent the minimal \nrequirements that must be met and thus are \nan element of the constraints imposed on \nthe design effort. Therefore, the engineer \nmust review all current standards related \nto a given endeavor and determine which \nmust be met. The design must then incor-\nporate all constraints imposed by the appli-\ncable standard.\n9.\t Root Cause Analysis \n\b\n[3*, c9s3-5] [13*, c5, c3s7, c9s8]\nRoot cause analysis (RCA) is a class of prob-\nlem-solving methods for identifying under-\nlying causes of undesirable outcomes. RCA \nmethods identify why and how an undesirable \noutcome happened, allowing organizations \nto take effective action to prevent recurrence. \nInstead of merely addressing immediately \nobvious symptoms, the organization can solve \nproblems by eliminating root causes. RCA \ncan play several important roles in software \nprojects, including the following:\n1.\t Identifying the real problem to be solved \nby an engineering effort\n2.\t Exposing the underlying drivers of risk, \nthus supporting project risk assessments\n3.\t Revealing opportunities and actions for \nsoftware process improvement\n4.\t Discovering sources of recurring defects \n(defect causal analysis)\n9.1.\t Root Cause Analysis Techniques\nSeveral RCA techniques exist, including the \nfollowing:\n\u2022\t Change analysis \ncompares \nsituations \nresulting in undesirable outcomes with \nsimilar situations that went well. The \nassumption is that the root cause will be \nfound in the area of difference.\n\u2022\t The 5-whys technique (see, for example, \n[2*, c4]) starts with an undesirable out-\ncome and uses repeated \u201cWhy?\u201d ques-\ntion-answer cycles to isolate the root cause.\n\u2022\t Cause-and-effect \ndiagrams, \nsometimes \ncalled Ishikawa diagrams [15] or fishbone \ncharts, break down, in successive levels of \ndetail, causes that potentially contrib-\nuted to an undesirable outcome. Causes \nare often grouped into major categories \nsuch as people, processes, tools, mate-\nrials, measurements and environment. \nThe diagram takes the form of a tree of \npotential causes that can all result in that \nundesirable outcome.\n\u2022\t Fault tree analysis (FTA) is a more formal \napproach to cause-and-effect diagram-\nming that focuses on and/or relationships \nbetween causes and effects. In some cases, \nany one of multiple causes can drive the \neffect (an \u201cor\u201d relationship); in other cases, a \ncombination of multiple causes is required \nto drive the effect (an \u201cand\u201d relationship). \nCause-and-effect diagrams do not distin-\nguish between and relationships and or \nrelationships; fault tree analysis does.\n\u2022\t Failure modes and effects analysis (FMEA) \nforward-chains, starting with elements \nthat can fail and cascade into undesirable \neffects. This approach contrasts with the \nbackward-chaining techniques above, \nwhich start from an undesirable outcome \nand work backward toward causes.\n\u2022\t A cause map [16] is a structured map of \ncause-effect relationships that includes \nan undesirable outcome along with (1) \nchaining backward to driving causes and \n(2) chaining forward to effects on orga-\nnizational goals. Cause maps require \n", "page": 384, "type": "text", "section": "Page 384"}
{"text": "ENGINEERING FOUNDATIONS   18-17\nevidence of the occurrence of causes and \nthe causality of effects and are thus more \nrigorous than cause-and-effect diagrams, \nFTA, and FMEA.\n\u2022\t A current reality tree [17] is a cause-ef-\nfect tree bound by the rules of logic \n(Categories of Legitimate Reservation).\n\u2022\t Human performance evaluation posits \nthat human performance depends on (1) \ninput detection, (2) input understanding, \n(3) action selection and (4) action execu-\ntion. An undesirable outcome that results \nfrom human performance can be identi-\nfied from a comprehensive list of poten-\ntial drivers, including cognitive overload, \ncognitive underload (boredom), memory \nlapse, tunnel vision or lack of a bigger \npicture, complacency, and fatigue.\nAdditional techniques can be found in \nthe DOE-NE-STD-1004-92 Root Cause \nAnalysis Guidance Document. \n9.2.\t Root Cause\u2013Based Improvement\nRCA is often an element in a greater pro-\ncess improvement effort. Why just identify a \nroot cause if nothing will be done about it? \nWhy go through the effort of identifying the \nroot cause of low-importance problems? An \nexample of a systematic process for a larger \nimprovement effort incorporating RCA is \ngiven below:\n1.\t Select the problem to solve: Techniques \nsuch as Pareto analysis (the \u201c80/20 \nRule\u201d), frequency-severity prioritization \n(problems that happen most frequently \nand consume the most resources to rec-\ntify are the best candidates), and statis-\ntical process control are used to identify \na high-priority, undesirable outcome to \naddress. This step needs to clearly define \nthe problem and its significance.\n2.\t Gather evidence about that problem \nand its cause(s): Consider information \nsurrounding the selected undesirable \noutcome, including statements or testi-\nmony, relevant processes or standards, \nspecifications, reports, historical trends, \nexperiments, or tests.\n3.\t Identify the root cause using one or more \nRCA techniques presented in 9.1. Root \nCause Analysis Techniques.\n4.\t Select corrective action(s) that (1) prevent \nrecurrence, (2) are within the organiza-\ntion\u2019s ability to control, (3) meet organi-\nzational goals and objectives, and (4) do \nnot cause other problems. More than one \ncandidate corrective action should be con-\nsidered, and the potential actions should \neliminate the cause, reduce the probability \nof the cause occurring or disconnect the \ncause from the effect. Selected correc-\ntive actions should generate the greatest \namount of control for the least cost.\n5.\t\nImplement \nthe \nselected \ncorrective \naction(s).\n6.\t Observe the selected corrective action(s) \nto ensure efficiency and effectiveness.\n10.\tIndustry 4.0 and Software Engineering\nThe manufacturing industry has always been \ncontinuously changing. Industry 4.0 is set to \nchange the manufacturing segment signifi-\ncantly, primarily focusing on custom manu-\nfacturing supported by artificial intelligence \n(AI). This offers potential benefits for cost, \nquality and efficiency.  Industry 4.0\u2019s emphasis \non digitization and AI calls for building \nbespoke hardware and software and inte-\ngrating these with other standard systems. \nThis is supported by Continuous Software \nEngineering \n(CSE), \nwhich \nhas \nbeen \naddressing continuous manufacturing prac-\ntices such as continuous planning, continuous \narchitecting/designing, \ncontinuous \ndevel-\nopment, continuous integration, continuous \ndeployments and continuous review/revision.\nSoftware is a key component in the Industry \n4.0 revolution, and engineering the software is \ncrucial to building robust and intelligent sys-\ntems. The engineering for one product affects \nothers, as more devices connect with other \ndevices, mostly wirelessly, to provide data \nand receive commands and data for further \nfunctioning. \n", "page": 385, "type": "text", "section": "Page 385"}
{"text": "18-18   SWEBOK \u00ae GUIDE V4.0\nMany technologies are used in Industry \n4.0, including the Internet of Things (IoT), \nBig data analytics, AI and machine learning, \ncybersecurity, cloud computing and Apps for \nmultiple platforms among others. Software \nplays a key role in the implementation of \nall these.\nContinuous \nSystems \nand \nSoftware \nEngineering for Industry 4.0 (CSSE I4.0) \nproposes how software engineering could \nbe applied in Industry 4.0. Quantum com-\nputing enables complex computations to be \nperformed faster and more cost-effectively. \nThe size and cost of devices that host the soft-\nware are decreasing significantly, easing the \nadoption of Industry 4.0. The software will \nbe increasingly self-learning and proactive, \ndeveloping the ability to predict users\u2019 wants. \nMATRIX OF TOPICS VS. REFERENCE MATERIAL\nTockey 2004 [2*]\nVoland 2003 [3*]\nMcConnell 2004\n[6*]\nMontgomery and \nRunger 2018 [8*]\nNull and Lobur\n2018 [9*]\nCheney and Kincaid \n2007 [10*]\nSommerville 2018 [11*]\nFairley 2009 [12*]\nKan 2002 [13*]\n1. The \nEngineering Process\nc4\n2.  Engineering Design\nc1s2-4\n2.1. Engineering Design \nin Engineering Education\n2.2. Design as a Problem-\nSolving Activity\nc1s4, \nc2s1, \nc3s3\nc5s1\n3. Abstraction and \nEncapsulation\nc5s2-4\n3.1. Levels of Abstraction\n3.2. Encapsulation\n3.3. Hierarchy\n3.4. Alternate \nAbstractions\n4. Empirical Methods \nand Experimental \nTechniques\nc1\n4.1. Designed \nExperiment\n4.2. Observational Study\n4.3. Retrospective Study\n5. Statistical Analysis\nc9s1, \nc2s1\nc11s3\n", "page": 386, "type": "text", "section": "Page 386"}
{"text": "ENGINEERING FOUNDATIONS   18-19\n5.1. Unit of Analysis \n(Sampling Units), \nPopulation and Sample\nc3s5, \nc3s8, \nc4s5, \nc7s1, \nc7s3, \nc8s1, \nc9s1\n5.2. Correlation and \nRegression\nc11s2, \nc11s8\n6. Modeling, \nSimulation and \nPrototyping\nc6\nc13s3\nc5\n6.1. Modeling\n6.2. Simulation\n6.3. Prototyping\nc2s8\n7. Measurement\npp \n442-\n447\nc4s4\nc7s5\nc3s1-2\n7.1. Levels (Scales) of \nMeasurement\np442-\n447\nc7s5\nc3s2\n7.2. Implications of \nMeasurement Theory for \nProgramming Languages\n7.3. Direct and \nDerived Measures\nc7s5\n7.4. Reliability \nand Validity\nc3s4-5\n7.5. Assessing Reliability\nc3s5\n7.6. Goal-Question-\nMetric Paradigm: \nWhy Measure?\n8. Standards\nc9s3.2\n9. Root Cause Analysis\nc9s3-5\nc5, c3s7,  \nc9s8\n9.1. Root Cause Analysis \nTechniques\nc4\n9.2. Root Cause-Based \nImprovement\n10. Industry 4.0 and \nSoftware Engineering\nFURTHER READINGS\nA. Abran, Software Metrics and Software \nMetrology. [18]\nThis book provides very good information on \nthe proper use of the terms measure, measure-\nment method and measurement outcome. It pro-\nvides strong support material for the entire \nsection on measurement.\n", "page": 387, "type": "text", "section": "Page 387"}
{"text": "18-20   SWEBOK \u00ae GUIDE V4.0\nW.G. Vincenti, What Engineers Know and \nHow They Know It. [19]\nThis book introduces engineering foundations \nthrough case studies showing many foun-\ndational concepts in real-world engineering \napplications. \nREFERENCES\n[1]\t\nISO/IEC/IEEE, \u201cISO/IEC/IEEE \n24765:2017 Systems and Software \nEngineering \u2014 Vocabulary,\u201d \n2nd ed. 2017\n[2*]\t\nS. Tockey, Return on Software: \nMaximizing the Return on Your \nSoftware Investment, 1st ed. Boston: \nAddison-Wesley, 2004.\n[3*]\t\nG. Voland, Engineering by Design, 2nd \ned. Upper Saddle River, NJ: Prentice \nHall, 2003.\n[4]\t\n\u201c2021 Accreditation Criteria and \nProcedures,\u201d Canadian Engineering \nAccreditation Board, Engineers \nCanada, 2021.\n[5]\t\nE.A. Commission, \u201cCriteria for \nAccrediting Engineering Programs, \n2022-2023,\u201d ABET, 2021.\n[6*]\t\nS. McConnell, Code Complete, 2nd ed. \nRedmond, WA: Microsoft Press, 2004.\n[7] \t\nEdsger W. Dijkstra, \u201cThe Humble \nProgrammer,\u201d Communications of the \nACM, vol. 15, issue 10, October 1972.\n[8*]\t\nD.C. Montgomery and G.C. Runger, \nApplied Statistics and Probability for \nEngineers, 7th ed. Hoboken, NJ: \nWiley, 2018.\n[9*]\t\nL. Null and J. Lobur, The Essentials \nof Computer Organization and \nArchitecture, 5th ed. Sudbury, MA: \nJones and Bartlett Publishers, 2018.\n[10*]\t E.W. Cheney and D.R. Kincaid, \nNumerical Mathematics and \nComputing, 6th ed. Belmont, CA: \nBrooks/Cole, 2007.\n[11*]\t I. Sommerville, Software Engineering, \n10th ed. New York: Addison-\nWesley, 2018.\n[12*]\t R.E. Fairley, Managing and Leading \nSoftware Projects. Hoboken, NJ: Wiley-\nIEEE Computer Society Press, 2009.\n[13*]\t S.H. Kan, Metrics and Models in \nSoftware Quality Engineering, 2nd ed. \nBoston: Addison-Wesley, 2002.\n[14]\t\nJ.W. Moore, The Road Map to Software \nEngineering: A Standards-Based Guide, \n1st ed. Hoboken, NJ: Wiley-IEEE \nComputer Society Press, 2006.\n[15] \t K. Ishikawa, Introduction to Quality \nControl, Productivity Press, 1990.\n[16] \t D. Gano, Apollo Root Cause Analysis, \n3rd ed., Apollonian Publications, 2007.\n[17] \t E. Goldratt, It\u2019s Not Luck, North \nRiver Press, 1994.\n[18]\t\nA. Abran, Software Metrics and \nSoftware Metrology: Wiley-IEEE \nComputer Society Press, 2010.\n[19]\t\nW.G. Vincenti, What Engineers \nKnow and How They Know It. Johns \nHopkins University Press, 1993.\n[20] \t Elisa Yumi Nakagawa, Pablo Oliveira \nAntonio, Frank Schnicke, Thomas \nKuhn, Peter Liggesmeyer, Continuous \nSystems and Software Engineering for \nIndustry 4.0: A disruptive view, Elsevier, \nVolume 135, July 2021, 106562 (https: \n//www.sciencedirect.com/science \n/article/abs/pii/S0950584921000458.)\n", "page": 388, "type": "text", "section": "Page 388"}
{"text": "A-1\nKNOWLEDGE AREA DESCRIPTION SPECIFICATIONS\nAppendix A \nINTRODUCTION\nThis appendix presents the specifications pro-\nvided to the knowledge area (KA) editors \nregarding the KA Descriptions of the Guide \nto the Software Engineering Body of Knowledge, \nVersion 4 (SWEBOK Guide, V4). This enables \nreaders, reviewers and users to clearly under-\nstand what specifications were used in devel-\noping this version of the SWEBOK Guide.\nThis appendix begins by situating the \nSWEBOK Guide as a foundational document \nfor the IEEE Computer Society\u2019s suite of soft-\nware engineering products and more widely \nwithin the software engineering commu-\nnity. The appendix then describes the role of \nthe baseline and change control. Criteria and \nrequirements are defined for the breakdowns \nof topics, for the rationale underlying these \nbreakdowns and the succinct description of \ntopics, and for reference materials. Important \ninput documents are also identified, and their \nrole within the project is explained. Finally, \nnon-content issues such as submission format \nand style guidelines are discussed.\nTHE SWEBOK GUIDE IS A \nFOUNDATIONAL DOCUMENT \nFOR THE IEEE COMPUTER \nSOCIETY SUITE OF SOFTWARE \nENGINEERING PRODUCTS\nThe SWEBOK Guide is an IEEE Computer \nSociety flagship and structural document for \nthe IEEE Computer Society\u2019s suite of software \nengineering products. The SWEBOK Guide is \nalso more widely recognized as a foundational \ndocument throughout the software engineering \ncommunity, notably through the official \nrecognition of the 2004 and 2014 versions \nas ISO/IEC Technical Report 19759:2005 \nand 19759:2015, respectively. The list of KAs \nand the breakdown of topics within each are \ndescribed and detailed in this SWEBOK Guide\u2019s \nintroduction. Consequently, the SWEBOK \nGuide is foundational to other initiatives within \nthe IEEE Computer Society, as follows:\n\u2022\t The list of KAs and the breakdown\nof topics within each are also adopted\nby the software engineering certifica-\ntion and associated professional devel-\nopment products offered by the IEEE\nComputer Society. (See www.computer\n.org/certification.)\n\u2022\t The list of KAs and the breakdown of\ntopics are also foundational to the soft-\nware engineering curriculum guide-\nlines developed or endorsed by the IEEE\nComputer Society. (See www.computer.\norg/portal/web/education/Curricula.)\n\u2022\t The Consolidated Reference List (see\nAppendix C) \u2014 meaning the list of\nRecommended References (to the level\nof section number) that accompanies the\nbreakdown of topics within each KA\n\u2014 is also adopted by the software engi-\nneering certification and associated pro-\nfessional development products offered\nby the IEEE Computer Society.\nBASELINE AND CHANGE CONTROL\nDue to the structural nature of the SWEBOK \nGuide and its adoption by other products, a \nbaseline was developed at the outset of the \nproject by a SWEBOK Steering Group. The \nbaseline comprises the list of KAs, including \n", "page": 389, "type": "text", "section": "Page 389"}
{"text": "A-2   SWEBOK \u00ae GUIDE V4.0\nnew ones, and the breakdown of topics for \neach KA from the previous version. \nFurthermore, a SWEBOK KA editors team \nhas been put in place for the development \nof this version to handle all major change \nrequests to this baseline coming from the KA \neditors, arising during the review process or \notherwise. Change requests must be approved \nboth by the SWEBOK Guide editors and by \nthe team before being implemented. The \nteam is composed of members of the initia-\ntives listed above and acts under the authority \nof the Engineering Discipline Committee of \nthe IEEE Computer Society Professional and \nEducational Activities Board (PEAB).\nCRITERIA AND REQUIREMENTS \nFOR THE BREAKDOWN OF TOPICS \nWITHIN A KNOWLEDGE AREA\n\u2022\t KA editors are instructed to refine the \nbaseline breakdown of topics to reflect \nthe recent development in the target area \nfor KAs that continue to exist from the \nprevious version. \n\u2022\t The breakdown of topics is expected to be \n\u201creasonable,\u201d not \u201cperfect.\u201d\n\u2022\t The breakdown of topics within a KA \nmust decompose the subset of the \nSWEBOK that is \u201cgenerally recognized.\u201d \n(See below for a more detailed discussion \nof this point.) \n\u2022\t The breakdown of topics within a KA \nmust not presume specific application \ndomains, business needs, sizes of organi-\nzations, organizational structures, man-\nagement philosophies, software life cycle \nmodels, software technologies or soft-\nware development methods. \n\u2022\t The breakdown of topics must, as much \nas possible, be compatible with the var-\nious schools of thought within software \nengineering. \n\u2022\t The breakdown of topics within a KA \nmust be compatible with the breakdown \nof software engineering generally found \nin industry and in the software engi-\nneering literature and standards. \n\u2022\t The breakdown of topics is expected to be \nas inclusive as possible. \n\u2022\t The SWEBOK Guide adopts the position \nthat even though the following \u201cthemes\u201d \nare common across all KAs, they are also \nan integral part of all KAs and, there-\nfore, must be incorporated into the pro-\nposed breakdown of topics of each KA. \nThese common themes are measurement, \nquality (in general) and security. \n\u2022\t The breakdown of topics should be at most \ntwo or three levels deep. Even though no \nupper or lower limit is imposed on the \nnumber of topics within each KA, a rea-\nsonable and manageable number of topics \nis expected to be included in each KA. \nEmphasis should also be put on the selection \nof the topics themselves rather than on their \norganization in an appropriate hierarchy.\n\u2022\t Topic names must be significant enough \nto be meaningful even when cited outside \nthe SWEBOK Guide. \n\u2022\t The Description of a KA will include a \nchart (in tree form) describing the knowl-\nedge breakdown. This chart will typically \nbe the first figure in the respective KA.\nCRITERIA AND REQUIREMENTS \nFOR DESCRIBING TOPICS\nTopics need only be sufficiently described \nso readers can select the appropriate refer-\nence material according to their needs. Topic \ndescriptions must not be prescriptive.\nCRITERIA AND REQUIREMENTS \nFOR REFERENCE MATERIAL\n\u2022\t KA editors are instructed to use the ref-\nerences (to the level of section number) \nallocated to their KA by the Consolidated \nReference List as their Recommended \nReferences.\n\u2022\t There are three categories of refer-\nence material:\n\t\n\u00bb Recommended References. The set of \nRecommended References (to the level \n", "page": 390, "type": "text", "section": "Page 390"}
{"text": "APPENDIX A    A-3\nof section number) is collectively known \nas the Consolidated Reference List. \n\t\n\u00bb Further Readings.\n\t\n\u00bb Additional references cited in the KA \nDescription (e.g., the source of a quo-\ntation or reference material in sup-\nport of a rationale behind a particular \nargument).\n\u2022\t The SWEBOK Guide is intended by defi-\nnition to be selective in its choice of topics \nand associated reference material. The list \nof reference material should be clearly \nviewed as an \u201cinformed and reasonable \nselection\u201d rather than as a definitive list.\n\u2022\t Reference material can be book chap-\nters, refereed journal papers, refereed \nconference papers, refereed technical or \nindustrial reports, or any other type of \nrecognized artifact. References to another \nKA, subarea or topic are also permitted.\n\u2022\t Reference material must be generally \navailable and must not be confidential \nin nature. \n\u2022\t Reference material must be in English. \n\u2022\t Criteria and requirements for rec-\nommended \nreference \nmaterial \nor \nConsolidated Reference List:\n\t\n\u00bb Collectively, the list of Recommended \nReferences should be:\ni.\t Complete \u2014 covering the entire \nscope of the SWEBOK Guide\nii.\t Sufficient \u2014 providing enough \ninformation to describe \u201cgenerally \naccepted\u201d knowledge\niii.\tConsistent \u2014 not providing con-\ntradictory \nknowledge \nor \ncon-\nflicting practices\niv.\tCredible \u2014 recognized as providing \nexpert treatment\nv.\t Current \u2014 treating the subject in a \nmanner that is commensurate with \ncurrent, generally accepted knowledge\nvi.\tSuccinct \u2014 as short as possible (both \nin the number of reference items and \nin total page count) without failing \nother objectives\n\t\n\u00bb Recommended \nreference \nmaterial \nmust be identified for each topic. \nEach recommended reference item \nmay, of course, cover multiple topics. \nRarely, a topic may be self-descriptive \nand not cite a reference material item \n(e.g., a topic that is a definition or a \ntopic for which the description itself \nwithout any cited reference material \nis sufficient for the objectives of the \nSWEBOK Guide). \n\t\n\u00bb Each reference to the recommended \nreference material should be as precise \nas possible, identifying what specific \nchapter or section is relevant.\n\t\n\u00bb A matrix of reference material (to the \nlevel of section number) versus topics \nmust be provided.\n\t\n\u00bb The latest versions or editions should be \nused as the Recommended References \nif there are multiple versions or editions.\n\t\n\u00bb A reasonable amount of recommended \nreference material must be identified \nfor each KA. The following guidelines \nshould be used in determining how \nmuch is reasonable: \ni.\t If \nthe \nrecommended \nreference \nmaterials are written in a coherent \nmanner, follow the proposed break-\ndown of topics, and use a consistent \nstyle (e.g., list a new book based on \nthe proposed KA description), an \naverage page number target across \nall KAs would be 750. However, this \ntarget may not be attainable when \nselecting existing reference mate-\nrial due to differences in style and to \noverlap and redundancy among the \nselected reference materials.\ni.\t In other words, the target for the \nnumber of pages for the entire col-\nlection of Recommended References \nin the SWEBOK Guide is in the \nrange of 10,000 to 15,000 pages.\ni.\t Another way of viewing this is that \nthe amount of recommended refer-\nence material would be reasonable if \nit consisted of the study material for \nthis KA for a software engineering \nlicensing exam that a graduate \nwould pass after completing four \nyears of work experience. \n", "page": 391, "type": "text", "section": "Page 391"}
{"text": "A-4   SWEBOK \u00ae GUIDE V4.0\n\u2022\t Additional reference material can be \nincluded by the KA editor in a \u201cFurther \nReading\u201d list: \n\t\n\u00bb These materials must be related to the \ntopics in the breakdown rather than, \nfor example, to more advanced topics.\n\t\n\u00bb The list must be annotated (one para-\ngraph per reference) to explain why each \nreference was included. Further Reading \ncould include alternative viewpoints on \na KA or a seminal treatment of a KA.\n\t\n\u00bb A general guideline to be followed is 10 \nor fewer further readings per KA.\n\t\n\u00bb There is no matrix of the reference \nmaterials listed in Further Reading and \nthe breakdown of topics. \n\u2022\t Criteria and requirements regarding \nadditional references cited in the KA \nDescription:\n\t\n\u00bb The SWEBOK Guide is not a research \ndocument, and its readership will be \nvaried. Therefore, a delicate balance \nmust be maintained between ensuring \na high level of readability within the \ndocument and maintaining its tech-\nnical excellence. Additional reference \nmaterial should, therefore, be brought \nin by the KA editor only if it is nec-\nessary to the discussion. For example, \nthe reference material might iden-\ntify the source of a quotation or offer \nsupport for the rationale behind an \nimportant argument.\nCOMMON STRUCTURE\nKA Descriptions should use the following \nstructure: \n\u2022\t Acronyms\n\u2022\t Introduction\n\u2022\t Breakdown of Topics of the KA (including \na figure describing the breakdown)\n\u2022\t Matrix of Topics vs. Reference Material\n\u2022\t List of Further Reading\n\u2022\t References\nWHAT DO WE MEAN BY \n\u201cGENERALLY RECOGNIZED \nKNOWLEDGE\u201d?\nThe Software Engineering Body of Knowledge \nis an all-inclusive term that describes the sum \nof knowledge within the profession of software \nengineering. However, the SWEBOK Guide \nseeks to identify and describe that subset of the \nbody of knowledge that is generally recognized \nor, in other words, the core body of knowledge. \nTo better illustrate what \u201cgenerally recognized\u201d \nknowledge is relative to other types of knowl-\nedge, Figure A.1 proposes a three-category \nschema for classifying knowledge.\nThe Project Management Institute, in \nits Guide to the Project Management Body of \nKnowledge, defines \u201cgenerally recognized\u201d \nknowledge for project management as:\nthat subset of the project management body of \nknowledge generally recognized as good prac-\ntice. \u201cGenerally recognized\u201d means the knowl-\nedge and practices described are applicable to \nmost projects most of the time, and there is con-\nsensus about their value and usefulness. \u201cGood \npractice\u201d means there is general agreement that \nthe application of these skills, tools, and tech-\nniques can enhance the chances of success over \na wide range of projects. \u201cGood practice\u201d does \nnot mean that the knowledge described should \nalways be applied uniformly to all projects; the \norganization and/or project management team \nis responsible for determining what is appro-\npriate for any given project [1].\nSpecialized Practices Used Only \nfor Certain Types of Software\nGenerally Recognized \nEstablished traditional practices \nrecommended by many \norganizations\nAdvanced and Research\nInnovative practices tested and used \nonly by some organizations and \nconcepts still being developed and \ntested in research organizations  \nFigure A.1. Categories of Knowledge\n", "page": 392, "type": "text", "section": "Page 392"}
{"text": "APPENDIX A    A-5\n\u201cGenerally accepted\u201d knowledge could also \nbe viewed as knowledge to be included in \nthe study material of a software engineering \nlicensing exam (in the US) that a graduate \nwould take after completing four years of \nwork experience. These two definitions should \nbe seen as complementary.\nKA editors are also expected to be some-\nwhat forward-looking in their interpretation \nby taking into consideration not only what is \n\u201cgenerally recognized\u201d today but also what \nthey expect will be \u201cgenerally recognized\u201d in \na three- to five-year time frame.\nLENGTH OF KA DESCRIPTION\nKA Descriptions are to be roughly 10 to \n20 pages using the formatting template for \npapers published in conference proceedings \nof the IEEE Computer Society. This includes \ntext, references, appendixes, tables, etc. This, \nof course, does not include the reference mate-\nrials themselves. \nIMPORTANT RELATED \nDOCUMENTS\nGraduate \nSoftware \nEngineering \n2009 \n(GSwE2009): \nCurriculum \nGuidelines \nfor \nGraduate \nDegree \nPrograms \nin \nSoftware \nEngineering, 2009 [2].\nThis document \u201cprovides guidelines and rec-\nommendations\u201d for defining the curricula of \na professional master\u2019s-level program in soft-\nware engineering. The SWEBOK Guide is \nidentified as a \u201cprimary reference\u201d in devel-\noping the body of knowledge underlying these \nguidelines. This document has been officially \nendorsed by the IEEE Computer Society and \nsponsored by the Association for Computing \nMachinery.\nISO/IEC/IEEE \n12207-2017 \nStandard \nfor Systems and Software Engineering \u2014 \nSoftware Life Cycle Processes, ISO/IEC/\nIEEE, 2017 [3].\nThis standard is considered the key standard \nregarding the definition of life cycle pro-\ncesses and has been adopted by the two main \nstandardization bodies in software engi-\nneering: ISO/IEC JTC1/SC7 and the IEEE \nComputer Society Software and Systems \nEngineering Standards Committees. It also \nhas been designated a pivotal standard by the \nSoftware and Systems Engineering Standards \nCommittee (S2ESC) of the IEEE. \nEven though we do not intend the SWEBOK \nGuide\u2008to be fully 12207-conformant, this stan-\ndard remains a key input to the SWEBOK Guide, \nand special care will be taken throughout the \nSWEBOK Guide regarding the compatibility \nof the Guide with the 12207 standard.\n\u201cSoftware Engineering 2014: Curriculum \nGuidelines \nfor \nUndergraduate \nDegree \nPrograms in Software Engineering,\u201d IEEE \nComputer Society and Association for \nComputing Machinery, 2015; https://www.\nacm.org/binaries/content/assets/education/\nse2014.pdf [4].\nThis document describes curriculum guidelines \nfor an undergraduate degree in software engi-\nneering. The SWEBOK Guide is identified as \n\u201cone of the primary sources\u201d in developing the \nbody of knowledge underlying these guidelines.\n\u201cISO/IEC/IEEE 24765:2017 Software and \nSystems Engineering \u2014 Vocabulary,\u201d ISO/\nIEC/IEEE, 2017; https://www.computer.\norg/sevocab [5].\nThe hierarchy of references for terminology is \nMerriam-Webster\u2019s Collegiate Dictionary (11th \ned.) [6], ISO/IEC/IEEE 24765 [5] and newly \nproposed definitions, if required.\n\u201cSoftware Professional Certification Program,\u201d \nIEEE \nComputer \nSociety; \nhttps://www. \ncomputer.org/education/certifications [7].\nInformation on the certification and associated \nprofessional development products developed \nand offered by the IEEE Computer Society for \nprofessionals in the field of software engineering \n", "page": 393, "type": "text", "section": "Page 393"}
{"text": "A-6   SWEBOK \u00ae GUIDE V4.0\ncan be found on this website. The SWEBOK \nGuide is foundational to these products.\nOTHER DETAILED GUIDELINES\nWhen referencing the Guide to the Software \nEngineering Body of Knowledge, use the title \nSWEBOK Guide.\nFor the purpose of simplicity, avoid foot-\nnotes, and try to include their content in the \nmain text.\nUse explicit references to standards, as \nopposed to simply inserting numbers refer-\nencing items in the bibliography. We believe \nthis approach allows the reader to be better \nexposed to the source and scope of a standard.\nThe text accompanying figures and tables \nshould be self-explanatory or have enough \nrelated text. This ensures that the reader \nknows what the figures and tables mean.\nTo make sure that some information in \nthe SWEBOK Guide does not become rap-\nidly obsolete and in order to reflect its generic \nnature, please avoid directly naming tools and \nproducts. Instead, try to name their functions.\nEDITING \nEditors of the SWEBOK Guide, as well as profes-\nsional copy editors, will edit KA Descriptions. \nEditing includes copy editing (grammar, punc-\ntuation and capitalization), style editing (con-\nformance to the Computer Society style guide), \nand content editing (flow, meaning, clarity, \ndirectness and organization). The final editing \nwill be a collaborative process in which the edi-\ntors of the SWEBOK Guide and the KA editors \nwill work together to achieve a concise, well-\nworded and useful KA Description.\nRELEASE OF COPYRIGHT\nAll intellectual property rights associated \nwith the SWEBOK Guide will remain with \nthe IEEE. KA editors must sign a copyright \nrelease form.\nIt is also understood that the SWEBOK Guide \nwill continue to be available free of charge in \nthe public domain in at least one format, pro-\nvided by the IEEE Computer Society through \nweb technology or by other means.\n(For more information, see www.computer.\norg/copyright.htm.)\nREFERENCES\n[1]\t Project Management Institute, A \nGuide to the Project Management Body of \nKnowledge (PMBOK\u00ae Guide), 7th ed., \nProject Management Institute, 2021.\n[2]\t Integrated Software and Systems \nEngineering Curriculum (iSSEc) Project, \nGraduate Software Engineering 2009 \n(GSwE2009): Curriculum Guidelines \nfor Graduate Degree Programs in \nSoftware Engineering, Stevens Institute \nof Technology, 2009; https://dl.acm.org/\ndoi/book/10.1145/2593248.\n[3]\t ISO/IEC/IEEE 12207-2017 Systems \nand Software Engineering \u2014 Software \nLife Cycle Processes,\u20082017.\n[4]\t Joint Task Force on Computing \nCurricula, IEEE Computer Society and \nAssociation for Computing Machinery, \n\u201cSoftware Engineering 2014: Curriculum \nGuidelines for Undergraduate Degree \nPrograms in Software Engineering, \n2015\u201d; https://www.acm.org/binaries/\ncontent/assets/education/se2014.pdf.\n[5]\t ISO/IEC/IEEE 24765:2017 Systems and \nSoftware Engineering \u2014 Vocabulary, \n2nd ed. 2017.\n[6]\t Merriam-Webster\u2019s Collegiate Dictionary, \n11th ed., 2003.\n[7]\t IEEE Computer Society, \u201cCertification \nand Training for Software Professionals,\u201d \n2013; https://www.computer.org/\neducation/certifications.\n", "page": 394, "type": "text", "section": "Page 394"}
{"text": "B-1 \nIEEE AND ISO/IEC STANDARDS\nAppendix B\nACRONYMS\nEIC\nInternational Electrotechnical \nCommission\nISO\nInternational Organization for \nStandardization\nJTC\nJoint Technical Committee\nMSS\nManagement System Standard\nS2ESC\nSystems and Software Engineering \nStandards Committee\nSC\nSubcommittee\nSUPPORTING THE SOFTWARE \nENGINEERING BODY OF \nKNOWLEDGE (SWEBOK)\n1.\t Overview\nThe purpose of this appendix is to describe the \nrelationship between IEEE software engi-\nneering standards and the SWEBOK and to \nintroduce the more prominent international \nsoftware engineering standards most directly \nrelated to the SWEBOK knowledge areas \n(KA). A summary list of some useful stan-\ndards for software engineering, including all \nthose referenced in this document, is in B.9.\n1.1 The SWEBOK and standards\nThe SWEBOK and other bodies of knowl-\nedge are closely related to standards for soft-\nware engineering, and standards are cited \nas resources in knowledge areas (KA) in the \nSWEBOK. Standards for software engi-\nneering extend and apply the generally accepted \nbody of knowledge that is collected in the \nSWEBOK. Conversely, standards also define \nand organize the systematic knowledge that \nis then reflected in collected bodies of knowl-\nedge. However, the SWEBOK has a different \npurpose from most software engineering stan-\ndards. The SWEBOK summarizes gener-\nally accepted concepts and experience-based \ninformation about how software engineering \nis practiced. This knowledge summary can \nbe applied in various ways: to define a curric-\nulum for educating software engineers, or for \nemployers or certification bodies determine if \na person has the knowledge and accepts the \nethical values needed to practice software \nengineering or to be certified.\nIn contrast, a standard is a \u201cdocument, \nestablished by consensus and approved by a \nrecognized body, that provides, for common \nand repeated use, rules, guidelines or charac-\nteristics for activities or their results, aimed \nat the achievement of the optimum degree \nof order in a given context\u201d (ISO/IEC TR \n29110-1:2016). In standards, the \u201cRules, \nguidelines, or characteristics\u201d are expressed \ndifferently:\n\u2022\t requirements in normative standards, \n(stated using shall or the imperative),\n\u2022\t recommended practices (stated using \n \nshould)\n\u2022\t other guidance on possible approaches \n(stated using may)\nStandards allow for global interoperability \nfor accepted concepts, processes, people, and \nproducts. The existence of standards takes a \nvery large (possibly infinite) trade space of alter-\nnatives and normalizes that space, supporting \nmutual understanding between acquirers and \nsuppliers. In that respect, software engineering \nstandards counter the tendency of competing \n", "page": 395, "type": "text", "section": "Page 395"}
{"text": "B-2   SWEBOK \u00ae GUIDE V4.0\norganizations to develop unique, proprietary \nproducts that do not interoperate outside \ntheir own suite. When standards are open, so \nthat organizations of all sizes can meet their \nrequirements, demand for trustworthy prod-\nucts and services increases to the benefit of \nmany suppliers and acquirers.\nStandards are voluntary; an individual or \norganization can choose to conform to their \nrequirements and follow their recommenda-\ntions. When the standard is incorporated in \ncontracts or other agreements, laws, and reg-\nulations, then compliance with the standard \nbecomes mandatory.\n1.2\t Types of Standards\nStandards can be characterized by what part \nof software engineering they standardize: \nconcepts and terms, processes, products, \npeople, or assessment of capabilities.\nSome software engineering standards simply \npresent concepts (characteristics) and define \nterms, perhaps even establishing a schema \nof knowledge about a software engineering \ntopic. An example of this type of standard is \nISO/IEC/IEEE 24765 Systems and software \nengineering: Vocabulary, which is freely avail-\nable online at www.computer.org/sevocab.1 \nHowever, most software engineering standards \ndescribe one or more of the software engi-\nneering processes and give requirements and \nrecommendations about how to perform that \nprocess. The primary process standard in soft-\nware engineering is ISO/IEC/IEEE 12207, \nSystems and software engineering: Software life \ncycle processes. There is even a standard for how \nto describe a process: ISO/IEC/IEEE 24774, \nSystems and software engineering \u2014Life cycle \nmanagement \u2014Specification for process descrip-\ntion. It describes the purpose, outcomes, activ-\nities, tasks, and possibly the inputs, outputs, \nand other features of a process. Process stan-\ndards should not be confused with procedures \nor instructions; they do not offer detailed rec-\nipes or step-by-step instructions for doing soft-\nware engineering.\n1\t http://pascal.computer.org/sev_display/index.action.\nA few software engineering standards have \nstandardized descriptions of products of soft-\nware engineering, such as models or informa-\ntion products like a project management plan \n(ISO/IEC/IEEE 16326). Another notable \nstandard for information products is ISO/\nIEC/IEEE 15289, Systems and software engi-\nneering\u2014Contents of life cycle information items \n(documentation). Initially, most software engi-\nneering standards were standards for a prom-\ninent information product, a plan. These \nallowed customers (acquirers of software) to \nunderstand and compare what their suppliers \nwould produce (a product). A standard for a \nplan describes what will be produced or deliv-\nered, what methods and techniques will be \nused, and what activities will be performed. \nIn recent years, most of the standards for \nplans have been revised to become standards \nfor software engineering processes.\nBesides standards for concepts, processes, \nand products, there are also standards for peo-\nple\u2019s skills, knowledge, or abilities, and stan-\ndards for certification schemes and bodies \nof knowledge in software engineering. An \nexample is ISO/IEC 24773-1:2019, Software \nand systems engineering \u2014 Certification of soft-\nware and systems engineering professionals \u2014 \nPart 1: General requirements. Reviews and \nassessments can be standardized for soft-\nware engineers, organizations, processes, and \nwork products.\n1.3\t Sources of Software Engineering Standards\nAlthough there are thousands of pages in hun-\ndreds of systems and software engineering \nstandards, guides, textbooks and handbooks, \nthere are only two international organizations \naccredited to produce systems and software \nengineering standards: ISO/IEC JTC 1/SC 7 \nand IEEE. Both have produced software engi-\nneering standards for over thirty-five years. Both \nare committed to produce standards using doc-\numented, consensus-based processes with open \nparticipation. ISO/IEC JTC 1 (International \nOrganization for Standardization / International \n", "page": 396, "type": "text", "section": "Page 396"}
{"text": "APPENDIX B   B-3\nElectrotechnical Commission Joint Technical \nCommittee) / SC 7 (Subcommittee), Software \nand Systems Engineering, produces standards \nthrough its membership of national standards \nbodies. JTC 1/SC 7 has a portfolio of over \ntwo hundred standards. The IEEE Computer \nSociety Systems and Software Standards \nCommittee (S2ESC) produces standards in \nworking groups of individual experts. It main-\ntains about fifty standards, of which about \n80% have been approved as ISO/IEC/IEEE \njoint standards. These are IEEE standards \nadopted by ISO/IEC JTC 1/SC 7, or stan-\ndards that are jointly developed and main-\ntained with ISO/IEC JTC 1 and designated \nas ISO/IEC/IEEE. The aim of these jointly \ndeveloped standards is to have a coordinated \ncollection of consistent standards for interna-\ntional use. For the ISO/IEC/IEEE standards \ndescribed in this appendix, the IEEE version \nand the ISO/IEC version are substantively \nidentical. The respective versions may have \ndifferent front and back matter but the tech-\nnical content is exactly the same.\nStandards can be purchased from the \nIEEE, ISO, and IEC websites, from national \nstandards organizations, and from commer-\ncial resellers. Academic institutions and soft-\nware engineering organizations can purchase \nor subscribe to collections of standards for \nuse by their staffs. A few standards are freely \navailable, generally those that provide intro-\nductions to concepts or terminology.\nIn both IEEE and ISO/IEC JTC 1, stan-\ndards for systems engineering are maintained \nby the same committee as those for software \nengineering. Most of the standards apply to \nboth, especially when software is considered as \na system or as the major component of a system \nof interest. So, instead of making fine distinc-\ntions, this appendix covers both as applicable \nto software engineering. It does not mention \nolder, now stabilized standards dealing with \nthe foundations of computing or computing \nlanguages and basic programming, mathemat-\nical, or engineering concepts.\nISO and IEEE have their own numbering \nsystems for their standards. When an IEEE \nstandard is adopted by ISO/IEC JTC 1, it \nis typically renumbered to a 5-digit number, \ne.g., IEEE 1062 becomes ISO/IEC/IEEE \n41062. ISO standards have long, taxonom-\nical titles with three and four levels of classi-\nfication. The first level shows the general area \n(e.g. systems and software engineering); the \nsecond level is the main title of the standard, \nand the third level provides even more detail, \nespecially for multi-part standards. To avoid \ncumbersome repetition, this appendix often \nuses a shortened title of the standard or simply \ncites it by number. The full title is given in the \nlist in B.9. All of these software engineering \nstandards are copyright protected, and IEEE \nstandard numbers are trademarked.\n2.\t The software engineering standards \nlandscape\nFigure B.1 presents an overview of the most \nprominent software engineering standards, \nmainly from the perspective of how other \nstandards relate to the major software engi-\nneering life cycle process standard, ISO/IEC/\nIEEE 12207, software engineering processes. \nIt is closely related to the SWEBOK in that \nboth present information related to many \nof the same software life cycle processes. \nAlso in the upper portion of Figure B.1 are \nthe foundational standards, such as the spe-\ncialized vocabulary for systems and soft-\nware engineering (SEVOCAB, ISO/IEC/\nIEEE 24765) and a specification for how to \ndescribe processes (ISO/IEC/IEEE 24774). \nThere are standards for how to plan for and \nmanage software engineering (ISO/IEC/\nIEEE 24748-5) and how to conduct rigorous \nreviews and audits, appropriate for critical \nsoftware like aerospace and defense systems \n(ISO/IEC/IEEE 24748-8).\nUsing the life cycle process model of 12207 \nas described in the following section, there \nare many more specialized standards covering \nindividual processes and modern approaches to \nthe processes, such as ISO/IEC/IEEE 32675, \nDevOps, as well as IEEE 1012, Verification \nand validation, and ISO/IEC/IEEE 29119, \nsoftware testing (in multiple parts). The life \ncycle processes in 12207 generally focus on a \n", "page": 397, "type": "text", "section": "Page 397"}
{"text": "B-4   SWEBOK \u00ae GUIDE V4.0\nsingle system of interest (SOI) but more spe-\ncialized series focus on processes and tools for \nproduct line engineering, and for systems of \nsystems (SoS). The System of Systems stan-\ndards, ISO/IEC/IEEE 21839, 21840, and \n21841, explain how to use systems engineering \nprocesses when the system of interest (SOI) is \na constituent part of a system of systems.\nThe life cycle process standards are intended \nto be compatible with other well-known stan-\ndards for management systems. According \nto ISO, \u201ca management system is the way in \nwhich an organization manages the interre-\nlated parts of its business in order to achieve \nits objectives.\u201d Management system standards \n(MSS) have a consistent structure and frame-\nwork of requirements, but each MSS covers \na specific aspect of managing and delivering \nengineering products and services. MSS \ntypically come in multiple parts with var-\nious guides for different aspects of their sys-\ntems. Well-known MSS related to software \nengineering include ISO 9000 for quality \nmanagement, ISO/IEC 20000 for service \nmanagement, the ISO/IEC 27000 series for \ninformation security management, the ISO/\nIEC 19770 series for managing IT assets like \nhardware and software, and the ISO/IEC \n30105 series for business process outsourcing \noperations.\n3.\t Life cycle process standards\nISO/IEC/IEEE 12207, Software life cycle \nprocesses, \nand \nISO/IEC/IEEE \n15288, \nSystem life cycle processes, are intentionally \nharmonized for use together. As stated in \nISO/IEC/IEEE 15288:2023, \u201cthere is a con-\ntinuum of human-made systems from those \nthat use little or no software to those in which \nsoftware is the primary interest. When soft-\nware is the predominant system or element \nof interest, ISO/IEC/IEEE 12207 should \nbe used.\u201d Both standards have identical life \ncycle models (the same four process groups, as \nshown in Figure B.2) and the same processes, \nThe processes have the same names, purposes, \nand process outcomes (there are minor vari-\nations in a couple of process names) in both \nstandards. Process activities and tasks differ \nbetween these two foundational standards, as \nsome aspects of engineering for software sys-\ntems are different from systems in general. \nConformance to ISO/IEC/IEEE 12207 or \nIEEE Guide to \nSW Engineering \nBody of Knowledge \n(SWEBOK)\nISO/IEC/IEEE 24765 \nVocabulary \n(SEVOCAB)\nProduct \nLines\nProcess Description\nISO/IEC/IEEE 24774\nDevOps Process View\nISO/IEC/IEEE 32675\nISO/IEC/IEEE 24748-4 SE Plans\nISO/IEC/IEEE 24748-8 \nReviews and Audits\nManagement Systems\nInformation Mgmt: \nISO/IEC/IEEE \n15289\nIndividual Processes\nVeri\ufb01cation/\nValidation\nIEEE 1012\nSoftware Testing\nISO/IEC/IEEE \n29119\nISO 9001 Quality\nISO/IEC 20000 Service\nISO/IEC 27000 Security\nISO/IEC 19770 IT \nAsset Mgmt.\nSystems of systems (SoS)\nISO/IEC/IEEE \n21839, 21840, 21841\nLife Cycle Processes\nISO/IEC/IEEE 12207\nFigure B.1. Software Engineering Standards Landscape\n", "page": 398, "type": "text", "section": "Page 398"}
{"text": "APPENDIX B   B-5\n15288 can be shown either by demonstrating \nthat all the outcomes of the process have been \nachieved, or that all the required activities \nand tasks of a process have been performed.\nThe life cycle processes are presented in \nthe context of their use on projects, supported \nby an organization that provides continuous \nservices applicable across multiple projects. \nHowever, the processes can be applied in \nvery small entities which are essentially orga-\nnized as a single team, as well as on large pro-\ngrams and continuing efforts that do not have \na defined end point like a project.\nIEEE Std 12207 establishes a common \nframework for software life cycle processes, \nwith well-defined terminology that can be ref-\nerenced by the software industry. ISO/IEC \n12207 applies to the acquisition of systems \nand software products and services and to the \nsupply, development, operation, maintenance, \nand disposal of software systems and the soft-\nware portion of a system, whether performed \ninternally or externally to an organization. \nThose aspects of system definition and enabling \nsystems (infrastructure) needed to provide the \ncontext for software products and services are \nincluded. Selected sets of these processes can \nbe applied throughout the life cycle for man-\naging and performing the stages of a system\u2019s \nlife cycle. This is accomplished through the \ninvolvement of all interested parties, with the \ngoal of achieving customer satisfaction.\nTable B.1 aligns the software life cycle \nprocesses of ISO/IEC/IEEE 12207 to the \nSWEBOK KA and identifies related stan-\ndards that offer more detailed requirements \nand guidance for individual processes. The \nSWEBOK KA do not directly cover all of \nthe process groups and processes in ISO/\nIEC/IEEE 12207. The Agreement processes \n(acquisition and supply) are not included, nor \nmany of the processes in the Organizational \nProject-enabling process group, and not all \nof the Technical Management or Technical \nprocess group processes. SWEBOK KA are \nselected to cover the essential knowledge \nareas applied by individual software engineers \nworking on projects or ongoing efforts, rather \nthan those generally handled at higher levels \nin the organization or on a more general level.\nThis version of the SWEBOK has added \nthe software security KA, which for historical \nreasons has been standardized separately from \nthe systems and software engineering stan-\ndards committees. Security is not identified as \na technical process in ISO/IEC/IEEE 12207. \nAn extensive suite of security standards based \non the ISO/IEC 27001 MSS are developed in \nISO/IEC JTC 1 SC 27, Information security, \ncybersecurity, and privacy protection.\nTable B.1 also identifies standards that are \nintended to identify process-related functions \nwhere software tools and methods should be \napplied, or to apply the processes to product \nline engineering (see B.6).\n4.\t Extensions and specialized applications \nof ISO/IEC/IEEE 12207\nNumerous useful standards supplement the \nrequirements of ISO/IEC/IEEE 12207 to \nhandle more rigorous or specialized situa-\ntions, or to provide more extended guidance \non its concepts and processes. Many of these \nstandards are parts of the ISO/IEC/IEEE \n24748 family.\n4.1, Explanations of concepts and several processes\nISO/IEC/IEEE 24748-1, -2 and -3 are \noverall guides to the life cycle processes and \ninvaluable for understanding and applying \nsystems and software engineering concepts. \nTechnical \nManagement\nTechnical\nOrganizational \nProject-enabling\nAgreement\nFigure B.2. Process groups of ISO/IEC/\nIEEE 12207\n", "page": 399, "type": "text", "section": "Page 399"}
{"text": "B-6   SWEBOK \u00ae GUIDE V4.0\nTABLE B.1. RELATED SOFTWARE ENGINEERING STANDARDS AND KA BY \nISO/IEC/IEEE 12207 PROCESS GROUP AND PROCESS\n12207 \nClause  \nNumber\nShort title\nSWEBOK KA\nRelated standard\n(ISO/IEC/\nIEEE unless \notherwise shown)\nProduct line or \ntool standard  \n(ISO/IEC)\nAgreement\n6.1.1\nAcquisition\n41062, 26512\n6,1,2\nSupply\n41062\nOrganizational process enabling\n6.2.1\nLife cycle model \nmanagement\nYes\n24748-1, 24748-2, \n24748-3, 33020\n6.2.2\nInfrastructure \nmanagement\n26550\n6.2.3\nPortfolio management\n33001\n26556\n6.2.4\nHuman Resources \nmanagement\nYes, Professional  \npractice\n24773\n6.2.5\nQuality management\nYes, Quality  \nAssurance\nIEEE 730, \n25000, 90003\n6.2.6\nKnowledge management\nTechnical management\n6.3.1\nProject planning\nYes\n16326, \n24748-4, 24748-5\n26555\n6.3.2\nProject \nassessment, control\nYes\n16326, 24748-4, \n24748-5, 24748-7, \n26511, 20246\n23396, \n23531, 26555, \n33001, 33002\n6.3.3\nDecision management\n6.3.4\nRisk Management\n16085, 15026 \n(all parts)\n6.3.5\nConfiguration \nManagement\nYes\nIEEE \n828, 16350,  \n19770 (all parts)\n26559, \n26560, 26561\n6.3.6\nInformation \nmanagement\n15289, \n26511, 26531, \n23026, 82079-1\n6.3.7\nMeasurement\nYes\n15939, 14143, \n32430, 19761, \n20926, 25020, \n25021, 25022, \n25023, 25024, \n29881, 33003\n6.3.8\nQuality Assurance\nYes\nIEEE 730, \nIEEE 982.1, \n25010, 25012\n", "page": 400, "type": "text", "section": "Page 400"}
{"text": "APPENDIX B   B-7\nISO/IEC/IEEE 24748-1, Guidelines for \nlife cycle management, is much more than \na guide to performing the life cycle man-\nagement process. It applies to both software \nand systems engineering processes, with fur-\nther explanations of system and process con-\ncepts. Instead of describing processes, which \nare usually applied repeatedly throughout \nthe life cycle, it includes a detailed descrip-\ntion of life cycle stages, covering their pur-\npose and outcomes. There are several models \nof life cycle stages, and in ISO/IEC/IEEE \n24748-1 the model that is analyzed in detail \nincludes the following stages: concept, devel-\nopment, production, utilization, support, and \nretirement. Since software engineers rarely \nTechnical\n6.4.1\nBusiness or \nMission Analysis\n26561\n6.4.2\nStakeholder needs & \nrequirements\nYes\n25030\n6.4.3\nSystems requirements \ndefinition\nYes\n29148\n26551\n6.4.4\nArchitecture definition\nYes\n42010, 42020\n26442, 26552\n6.4.5\nDesign definition\nYes\n24748-\n7000. 26514\n26557, 26580\n6.4.6\nSystem analysis\nYes, Models \nand Methods\nISO/IEC 24641\n20246, 26558\n6.4.7\nImplementation\nYes, \nConstruction\n26553\n6.4.8\nIntegration\nYes, \nConstruction\n24748-6\n6.4.9\nVerification\nYes, Testing\nIEEE 1012, \n25021,25040, \n25041, 25045, \n25062, 26513, \n29119-1, 29119-2, \n \n29119-3, \n33063, 42030\n23643,26554,  \n30130\n6.4.10\nTransition\n26562\n6.4.11\nValidation\nYes, Testing\nIEEE 1012\n6.4.12\nOperation\nYes\n32675\n23531\n6.4.13\nMaintenance\nYes\n14764\n6.4.14\nDisposal\nSoftware security\nYes\nISO/IEC 27000 \nfamily, 15026 \n(Parts 1 to 4) \nSoftware Engineering \ncomputing foundations\nYes\nNumerous  \nhistoric standards\nSoftware Engineering \nMathematical \nfoundations\nYes\nNumerous his-\ntoric standards\nSoftware engineering \nFoundations\nYes\nNumerous  \nhistoric standards\n", "page": 401, "type": "text", "section": "Page 401"}
{"text": "B-8   SWEBOK \u00ae GUIDE V4.0\nfocus on production as a stage of interest, an \nalternate model for software life cycle stages \nis more useful: concept, development, opera-\ntions and maintenance, and retirement. Life \ncycle models are characterized by their devel-\nopment approach: sequential, incremental, or \nevolutionary. The life cycle models are com-\npared in a risk-based approach.\nISO/IEC/IEEE 24748-2 is the overall \nguide to applying the systems engineering pro-\ncesses in ISO/IEC/IEEE 15288. However, \nit does not offer line-by-line expansions of \neach process, activity, and task, but presents \nan overall strategy for transitioning to use of \nstandardized life cycle processes. There is yet \nmore explanation of systems concepts, a pre-\nsentation of organizational concepts, some \ndiscussion of conformance or adaptation (tai-\nloring), of standard processes, and an intro-\nduction to model-based systems and software \nengineering (MBSSE).\nISO/IEC/IEEE 24748-3, guidelines for \nthe application of software life cycle pro-\ncesses, also offers commentary on concepts of \nsoftware systems, organizations and projects, \nprocesses, life cycle states, and life cycle pro-\ncess models for software systems. It includes \nguidance for each of the processes in ISO/\nIEC/IEEE 12207, including further anal-\nysis of process purposes; outcomes and out-\nputs; activities, tasks, and approaches; closely \nrelated processes; and related standards.\nISO/IEC/IEEE 32675 DevOps, (IEEE \n2675) has the informative subtitle of \n\u201cBuilding Reliable and Secure Systems, \nIncluding Application Build, Package, and \nDeployment\u201d. It defines DevOps as a \u201cset of \nprinciples and practices which enable better \ncommunication and collaboration between \nrelevant stakeholders for the purpose of spec-\nifying, developing, and operating software \nand systems products and services, and con-\ntinuous improvements in all aspects of the \nlife cycle.\u201d It expounds on the principles of \nDevOps, including business or mission first, \ncustomer focus, left shift and continuous \neverything, and systems thinking. (Left-\nshift is defined as \u201c prioritizing the involve-\nment of relevant stakeholders in applying \nquality activities, security, privacy, perfor-\nmance, verification, and validation earlier in \nthe life cycle.\u201d) IEEE 2675 emphasizes the \nleadership commitment needed for successful \napplication of DevOps. It reviews many of \nthe life cycle processes in ISO/IEC/IEEE \n12207 to analyze how they are transformed \nby DevOps, and discusses the use of DevOps \nwith agile methods.\nIn earlier versions, both ISO/IEC/IEEE \n24748-4 and 24748-5 covered what to include \nin a management plan (Systems Engineering \nManagement Plan or Software Engineering \nManagement Plan), respectively. That mate-\nrial is still there, but now they also include \nguidance for systems engineers and software \nengineers, respectively, on the management \nplanning and control processes, with brief \npresentations of related processes.\n4.2\t More specialized extensions\nAlthough standards are well established for \nspecialized areas of health and safety, secu-\nrity, and environmental concerns, standards \nrelating ethical values to software systems \nare relatively new. The potential for software \nsystems to cause harm through biased deci-\nsions, violations of privacy, or lack of social \nresponsibility led to the development of ISO/\nIEC/IEEE 24748-7000 (IEEE 7000). IEEE \n7000 presents a model process for incorpo-\nrating ethical values into systems design. \nEngineers, their managers, and other stake-\nholders benefit from well-defined processes \nfor considering ethical issues along with \nthe usual concerns of system performance \nand functionality early in the system life \ncycle. The standard requires consideration \nof values relevant to the culture where the \nsystem is to be deployed. It is applicable \nwith any life cycle model or development \nmethodology. The processes in this stan-\ndard are intended to be performed concur-\nrently with those in ISO/IEC/IEEE 12207 \n(Table B.3)\nEarlier versions of ISO/IEC/IEEE 12207 \nwere considered by some to be overly pre-\nscriptive in terms of required documentation, \n", "page": 402, "type": "text", "section": "Page 402"}
{"text": "APPENDIX B   B-9\nreviews, and task sequences. The current ver-\nsion is intended to be used by any size or type \nof organization, having a more strategic, \nagile, approach to the processes, with reduced \ndocumentation and review requirements. \nHowever, for highly complex and critical sys-\ntems, a more rigorous and structured set of \nprocesses, reviews, and audits was developed \nin coordination with the US Department \nof Defense and has been specified in ISO/\nIEC/IEEE 24748-7:2019 Systems and soft-\nware engineering \u2014 Life cycle management \u2014 \nPart 7: Application of systems engineering on \ndefense programs and ISO/IEC/IEEE 24748-\n8:2019 Systems and software engineering \u2014 Life \ncycle management \u2014 Part 8: Technical reviews \nand audits on defense programs. For more gen-\neral use, ISO/IEC 20246 outlines processes \nand characteristics for work product reviews \nthroughout the life cycle, covering both soft-\nware and information products.\nISO/IEC/IEEE 24748-9 is an application \nof system and software life cycle processes \nin epidemic prevention and control systems. \nMore generally, it shows ways of doing sys-\ntems and software engineering with lim-\nited infrastructure and staff support, such as \n\u201cinsufficient infrastructure protection, short \ndelivery cycles, frequent iterative upgrades, \nand special requirements such as accuracy, \ndisaster tolerance, degradation capability, \nsafety, user capacity and stress testing, and \nrapid demand capture.\u201d\n4.3\t SoS standards\nThree standards explore how the systems and \nsoftware engineering concepts and processes \ncan be applied to systems of systems (SoS). \nISO/IEC/IEEE 21839 describes how systems \nthat are constituents of SoS are affected at \neach stage in their life cycle. ISO/IEC/IEEE \n21940 takes the opposite view, exploring con-\ncepts of an SoS and how ISO/IEC/IEEE \n15288 can be applied to SoS. ISO/IEC/IEEE \n21841 is a brief taxonomy that identifies four \ntypes of SoS: directed, acknowledged, collab-\norative and virtual.\n5.\t Single Process Standards\nISO/IEC/IEEE 12207 applies to all types \nof software engineering with a variety of \nlife cycle models, techniques, and methods. \nIts process descriptions do not go into detail \nabout how the process should be performed \nor which techniques are considered best \npractice. To that end, there are numerous \nmore specialized standards with additional \nrequirements and guidelines applicable to \nmost of the software engineering processes. \nTable B.1 correlates each process in ISO/\nIEC/IEEE 12207 to the related SWEBOK \nKAs, more specialized standards and guid-\nance, and related standards for applying the \nprocess to product lines, tools, and methods. \nTable B.2 shows standards referenced in each \nknowledge area.\n6.\t Standards for product line, methods, and \ntools\nA product line is a \u201c set of products or ser-\nvices sharing explicitly defined and managed \ncommon and variable features and relying \non the same domain architecture to meet \nthe common and variable needs of specific \nmarkets\u201d (ISO/IEC 26550:2015) Product \nline engineering raises different consider-\nations, especially for ongoing configuration \nand release management, maintenance, and \noperations, from the basic approach of ISO/\nIEC/IEEE 12207, which applies software \nengineering from the perspective of a project \nwithin an organization.\nStandards in the ISO/IEC 26550 to 26569 \nseries also cover capabilities of tools related to \nvarious software engineering processes and \nmanagement tasks. Because software devel-\nopment and operations tool capabilities are \ncontinually being expanded and more tightly \nintegrated to support the DevOps pipeline, \nthe individual standards in this series are \nnot closely aligned with current commer-\ncial product suites or open-source libraries. \nHowever, the tool standards do suggest useful \nfeatures to seek in support of the software \nlifecycle.\n", "page": 403, "type": "text", "section": "Page 403"}
{"text": "B-10   SWEBOK \u00ae GUIDE V4.0\n7.\t Process assessment standards\nProcess assessment is a long-standing method \nof confirming the capabilities, quality, \nand maturity of software engineering pro-\ncesses, and encouraging process improve-\nment. Process audits look for evidence of \nperformance of activities and achievement of \noutcomes (artifacts like work products and \ninformation items). The assumption is that a \nrepeatable process with organizational sup-\nport performed by competent practitioners \nis more likely to produce acceptable soft-\nware products and services. The ISO/IEC \nTABLE B.2. STANDARDS CITED BY KNOWLEDGE AREA\nKA \nNumber\nKnowledge Area \nCited standards  \n(ISO/IEC/IEEE unless otherwise designated)\nIntroduction \n24765, 12207\n1\nSoftware Requirements\n24765, 12207, ISO/IEC 25010, 29148\n2\nSoftware Architecture\n24765, 12207, 42010\n3\nSoftware Design\n12207, 24748-7000, 24765\n4\nSoftware Construction\n5\nSoftware Testing\nIEEE 1012, ISO/IEC 20246, 24765, ISO/IEC 25010, \n29119 (multiple parts), 32675 \n6\nSoftware Operations\n12207, ISO/IEC 20000, 24765, 32675\n7\nSoftware Maintenance\n12207, 14764, 15288, 32675\n8\nSoftware Configuration \nManagement\nIEEE  828, 24765, 12207\n9\nSoftware Engineering \nManagement\n12207, 32675\n10\nSoftware \nEngineering Process\n12207, 24748-1, 24748-3, 24765, 24774, ISO/IEC \n25000, 29110, 33001, 32675\n11\nSoftware Engineering \nModels and Methods\n12\nSoftware Quality\nIEEE 730, IEEE 982.1, IEEE 1012, IEEE 1228, IEEE \n1633, ISO 9001, 12207, 15026-1, 15288, 20000, 20246, \n24765, 25010, 27001, 33061, 90003,  IEC 60300\n13\nSoftware Security\nISO/IEC 15408-1, ISO/IEC 18045, ISO/IEC 19770-1, \nISO/IEC 21827, 25010, ISO/IEC 27000, ISO/IEC \n27001, ISO/IEC 27032\n14\nSoftware Engineering \nProfessional Practice \nISO/IEC 24773-1, ISO/IEC 24773-4\n15\nSoftware \nEngineering Economics\n12207, 15288\n16\nComputing Foundations\n12207, 24765\n17\nMathematical \nFoundations\n18\nEngineering Foundations\n24765\n", "page": 404, "type": "text", "section": "Page 404"}
{"text": "APPENDIX B   B-11\n33000 family of standards currently includes \nover twenty active standards related to pro-\ncess assessment. The overall architecture \nand content of the ISO/IEC 330xx family \nis described in ISO/IEC 33001. A process \nassessment is conducted according to a doc-\numented assessment process, which identifies \nthe rating method for  process attributes and \nhow to determine process ratings. ISO/IEC \n33061 is the standard for process assessment \nwhich is aligned with ISO/IEC/IEEE 12207 \nsoftware engineering processes, treated as a \nprocess reference model. \n8.\t Professional Skills and Knowledge \nStandards\nThe ISO/IEC 24773 series contains require-\nments specifically related to certifications for \nsoftware and systems engineering profes-\nsionals. It is useful to industry organizations \nseeking to compare various certifications for \nprofessionals in systems and/or software engi-\nneering; to individual professionals seeking to \nobtain certification; and to employers who \nmay choose to recognize such certifications. \nThese standards are intended for international \nuse, and do not replace national or regional \nlicensing or registration requirements for \nengineers. ISO/IEC 24773-1 is an overview \nof certification concepts, and requirements for \nthe certification processes and certification \nschemes applicable to software and systems \nengineering. ISO/IEC 24773-4 provides spe-\ncific requirements for certification bodies in \nsoftware engineering. It specifies this IEEE \nSWEBOK as the reference body of knowl-\nedge in software engineering.\n9.\t Selected Software Engineering \nStandards\nThis is not an exhaustive list of standards \nrelated to software engineering or spon-\nsored by the IEEE Systems and Software \nEngineering Standards Committee (S2ESC) \nor ISO/IEC JTC 1/SC7, Software and sys-\ntems engineering. Those listed are considered \nmore authoritative, relevant, and helpful for \nSWEBOK users.\nThe standards described in this appendix \nare continually being revised or replaced by \nnewer standards. Users of standards should \nlook for the most recent version and for newer \ntitles relating to emerging topics in software \nengineering, such as digital engineering or \nstandards related to artificial intelligence (AI).\n\u2022\t IEEE 730-2014 IEEE Standard for \nSoftware Quality Assurance Processes\n\u2022\t IEEE 828-2012 IEEE Standard for \nConfiguration Management in Systems \nTABLE B.3. ALIGNMENT OF ETHICAL VALUE PROCESSES IN ISO/IEC/IEEE \n24748-7000 (IEEE 7000) AND SOFTWARE ENGINEERING PROCESSES IN ISO/\nIEC/IEEE 12207\nIEEE Std 7000 process clause \nISO/IEC/IEEE 12207:2017 and ISO/IEC/IEEE \n15288:2023 process clause \n7. Concept of Operations (ConOps) \nand Context Exploration\n6.4.1 Business or mission analysis\n8. Ethical Values Elicitation and \nPrioritization\n6.4.1 Business or mission analysis,  \n6.4.2 Stakeholder needs and requirements definition\n9. Ethical Requirements Definition \n6.4.2 Stakeholder needs and requirements definition,  \n6.4.3 System requirements definition\n10. Ethical Risk-Based Design \n6.4.4 Architecture definition,  \n6.4.5 Design definition\n11. Transparency Management \n6.3.6 Information management\n", "page": 405, "type": "text", "section": "Page 405"}
{"text": "B-12   SWEBOK \u00ae GUIDE V4.0\nand Software Engineering\n\u2022\t IEEE \n982.1-2005 \nIEEE \nStandard \nDictionary of Measures of the Software \nAspects of Dependability\n\u2022\t IEEE \n1012-2016 \nIEEE \nStandard \nfor System, Software, and Hardware \nVerification and Validation\n\u2022\t IEEE \n1228-1994 \n(R2002) \nIEEE \nStandard for Software Safety Plans\n\u2022\t IEEE 1633-2016 IEEE Recommended \nPractice on Software Reliability\n\u2022\t ISO 9000:2015 Quality management \nsystems \u2014 Fundamentals and vocabulary\n\u2022\t ISO 9001:2015 Quality management \nsystems \u2014 Requirements\n\u2022\t ISO/IEC/IEEE 12207:2017 Systems \nand software engineering: Software \nengineering processes\n\u2022\t ISO/IEC 14143 Information technolo-\ngy--Software measurement--Functional \nsize measurement (multiple parts)\n\u2022\t ISO/IEC/IEEE 14764-2021 Software \nEngineering - Software Life Cycle \nProcesses - Maintenance\n\u2022\t ISO/IEC/IEEE 15026-1-2019 Systems \nand Software Engineering\u2014Systems and \nSoftware Assurance\u2014 Part 1: Concepts \nand Vocabulary\n\u2022\t ISO/IEC/IEEE 15026- 2:2021 Systems \nand \nSoftware \nEngineering\u2014Systems \nand \nSoftware \nAssurance\u2014Part \n2: \nAssurance Case\n\u2022\t ISO/IEC 15026-3: 2023 Systems and \nSoftware \nEngineering\u2014Systems \nand \nSoftware Assurance\u2014Part 3: System \nIntegrity Levels\n\u2022\t ISO/IEC/IEEE 15026-4:2021, Systems \nand Software Engineering\u2014Systems and \nSoftware Assurance\u2014Part 4: Assurance \nin the Life Cycle\n\u2022\t ISO/IEC/IEEE 15288:2023 Standard \nfor Systems and Software Engineering\u2014\nSystem Life Cycle Processes\n\u2022\t ISO/IEC/IEEE 15289:2019 Systems \nand Software Engineering\u2014 Content \nof Life-Cycle Information Products \n(Documentation)\n\u2022\t ISO/IEC \n15408-1:2022 \nInformation \nsecurity, \ncybersecurity \nand \nprivacy \nprotection \u2014 Evaluation criteria for \nIT security \u2014 Part 1: Introduction and \ngeneral model\n\u2022\t ISO/IEC/IEEE 15939:2017 Systems \nand \nSoftware \nEngineering\u2014\nMeasurement Process\n\u2022\t ISO/IEC/IEEE 16085:2021 Systems \nand Software Engineering\u2014Software \nLife Cycle Processes\u2014 Risk Management\n\u2022\t ISO/IEC/IEEE 16326:2019 Systems \nand Software Engineering\u2014Life Cycle \nProcesses\u2014Project Management\n\u2022\t ISO/IEC 16350:2015 Information tech-\nnology \u2014 Systems and software engi-\nneering \u2014 Application management\n\u2022\t ISO/IEC 18045:2022 Information secu-\nrity, cybersecurity and privacy protection \n\u2014 Evaluation criteria for IT security \u2014 \nMethodology for IT security evaluation\n\u2022\t ISO/IEC \n19761:2011 \nSoftware \nEngineering\u2014COSMIC: A Functional \nSize Measurement Method\n\u2022\t ISO/IEC \n19770-1:2017 \nInformation \ntechnology \u2014 IT asset management \u2014 \nPart 1: IT asset management systems \n\u2014 Requirements\n\u2022\t ISO/IEC \n19770-2:2015 \nInformation \ntechnology \u2014 IT asset management \u2014 \nPart 2: Software identification tag\n\u2022\t ISO/IEC \n19770-3:2016 \nInformation \ntechnology \u2014 IT asset management \u2014 \nPart 3: Entitlement schema\n\u2022\t ISO/IEC \n19770-4:2017 \nInformation \ntechnology \u2014 IT asset management \u2014 \nPart 4: Resource utilization measurement\n\u2022\t ISO/IEC \n19770-5:2015 \nInformation \ntechnology \u2014 IT asset management \u2014 \nPart 5: Overview and vocabulary\n\u2022\t ISO/IEC \n19770-8:2020 \nInformation \ntechnology \u2014 IT asset management \n\u2014 Part 8: Guidelines for mapping of \nindustry practices to/from the ISO/IEC \n19770 family of standards\n\u2022\t ISO/IEC 19770-11:2021 Information \ntechnology \u2014 IT asset management \u2014 \nPart 11: Requirements for bodies pro-\nviding audit and certification of IT asset \nmanagement systems\n\u2022\t ISO/IEC \n20000-1:2018 \nInformation \n", "page": 406, "type": "text", "section": "Page 406"}
{"text": "APPENDIX B   B-13\nTechnology\u2014Service \nManagement\u2014\nPart 1: Service management system \nrequirements\n\u2022\t ISO/IEC 20246:2017 Software and sys-\ntems engineering -- Work product reviews\n\u2022\t ISO/IEC 20741:2017 Systems and soft-\nware engineering \u2014 Guideline for the \nevaluation and selection of software engi-\nneering tools\n\u2022\t ISO/IEC 20926:2009 Software and \nSystems \nEngineering\u2014Software \nMeasurement\u2014IFPUG Functional Size \nMeasurement Method SW Requirements\n\u2022\t ISO/IEC \n20968:2002 \nSoftware \nEngineering\u2014Mk II Function Point \nAnalysis\u2014Counting Practices Manual \nSW Requirements\n\u2022\t ISO/IEC 21827:2008 Information tech-\nnology \u2014 Security techniques \u2014 systems \nsecurity engineering \u2014 capability matu-\nrity model\u00ae (SSE-CMM\u00ae)\n\u2022\t ISO/IEC/IEEE 21839:2019 Systems \nand software engineering \u2014 system of \nsystems (SoS) considerations in life cycle \nstages of a system\n\u2022\t ISO/IEC/IEEE 21840:2019 Systems \nand software engineering \u2014 Guidelines \nfor the utilization of ISO/IEC/IEEE \n15288 in the context of system of \nsystems (SoS)\n\u2022\t ISO/IEC/IEEE 21841:2019 Systems \nand software engineering \u2014 Taxonomy \nof systems of systems\n\u2022\t ISO/IEC/IEEE 23026:2023 Systems \nand software engineering \u2014 Engineering \nand management of websites for systems, \nsoftware, and services information\n\u2022\t ISO/IEC 23396:2020 Systems and soft-\nware engineering \u2014 Capabilities of \nreview tools\n\u2022\t ISO/IEC 23531:2020 Systems and soft-\nware engineering \u2014 Capabilities of issue \nmanagement tools\n\u2022\t ISO/IEC 24570:2018 Software engi-\nneering -- NESMA functional size \nmeasurement method --Definitions and \ncounting guidelines for the application of \nfunction point analysis\n\u2022\t ISO/IEC/IEEE 24641:2023 Systems \nand Software engineering \u2014 Methods \nand tools for model-based systems and \nsoftware engineering\n\u2022\t ISO/IEC/IEEE 24748-1:2024 Systems \nand software engineering \u2014 Life cycle \nmanagement \u2014 Part 1: Guidelines for \nlife cycle management\n\u2022\t ISO/IEC/IEEE 24748-2:2024 Systems \nand software engineering \u2014 Life cycle \nmanagement \u2014 Part 2: Guidelines for \nthe application of ISO/IEC/IEEE 15288 \n(system life cycle processes)\n\u2022\t ISO/IEC/IEEE 24748-3:2020 Systems \nand software engineering \u2014 Life cycle \nmanagement \u2014 Part 3: Guidelines for \nthe application of ISO/IEC/IEEE 12207 \n(software life cycle processes)\n\u2022\t ISO/IEC/IEEE 24748-4:2016 Systems \nand software engineering \u2014 Life cycle \nmanagement \u2014 Part 4: Systems engi-\nneering planning\n\u2022\t ISO/IEC/IEEE 24748-5:2017 Systems \nand software engineering \u2014 Life cycle \nmanagement \u2014 Part 5: Software devel-\nopment planning\n\u2022\t ISO/IEC/IEEE 24748-6:2023, Systems \nand Software Engineering \u2014 Life Cycle \nManagement \u2014 Part 6: Systems and \nSoftware Integration\n\u2022\t ISO/IEC/IEEE 24748-7:2019 Systems \nand software engineering \u2014 Life cycle \nmanagement \u2014 Part 7: Application \n \nof systems engineering on defense \n \nprograms\n\u2022\t ISO/IEC/IEEE 24748-8:2019 Systems \nand software engineering \u2014 Life cycle \nmanagement \u2014 Part 8: Technical reviews \nand audits on defense programs\n\u2022\t ISO/IEC/IEEE 24748-9:2023 Systems \nand software engineering, prevention and \ncontrol systems\n\u2022\t ISO/IEC/IEEE \n24748-7000:2022 \n(IEEE 7000:2021) Model Process for \nAddressing Ethical Concerns during \nSystem Design\n\u2022\t ISO/IEC/IEEE 24765:2017 Systems \nand Software Engineering \u2014 Vocabulary, \navailable at www.computer.org/sevocab\n\u2022\t ISO/IEC 24773-1:2019 Software and \n", "page": 407, "type": "text", "section": "Page 407"}
{"text": "B-14   SWEBOK \u00ae GUIDE V4.0\nsystems engineering \u2014 Certification of \nsoftware and systems engineering profes-\nsionals \u2014 Part 1: General requirements\n\u2022\t ISO/IEC 24773-4:2023 Software and \nsystems engineering \u2014 Certification of \nsoftware and systems engineering profes-\nsionals \u2014 Part 4: Software engineering\n\u2022\t ISO/IEC/IEEE 24774:2021 Systems \nand software engineering \u2014 Life cycle \nmanagement \u2014 Specification for process \ndescription\n\u2022\t ISO/IEC 25000:2014 Systems and soft-\nware engineering \u2014 Systems and software \nQuality Requirements and Evaluation \n(SQuaRE) \u2014 Guide to SQuaRE\n\u2022\t ISO/IEC 25001:2014 Systems and soft-\nware engineering \u2014 Systems and software \nQuality Requirements and Evaluation \n(SQuaRE) \u2014 planning and management\n\u2022\t ISO/IEC \n25010:2023 \nSystems \nand \nsoftware engineering \u2014 Systems and \nsoftware Quality Requirements and \nEvaluation (SQuaRE) \u2014 System and \nsoftware quality models\n\u2022\t ISO/IEC 25012:2008 Software engi-\nneering \u2014 Software product Quality \nRequirements and Evaluation (SQuaRE) \n\u2014 Data quality model\n\u2022\t ISO/IEC \n25020:2019 \nSystems \nand \nsoftware engineering \u2014 Systems and \nsoftware Quality Requirements and \nEvaluation (SQuaRE) \u2014 Quality mea-\nsurement framework\n\u2022\t ISO/IEC \n25021:2012 \nSystems \nand \nsoftware engineering \u2014 Systems and \nsoftware Quality Requirements and \nEvaluation (SQuaRE) \u2014 Quality mea-\nsure elements\n\u2022\t ISO/IEC \n25022:2016 \nSystems \nand \nsoftware engineering \u2014 Systems and \nsoftware quality requirements and eval-\nuation (SQuaRE) \u2014 Measurement of \nquality in use\n\u2022\t ISO/IEC \n25023:2016 \nSystems \nand \nsoftware engineering \u2014 Systems and \nsoftware Quality Requirements and \nEvaluation (SQuaRE) \u2014 Measurement \nof system and software product quality\n\u2022\t ISO/IEC \n25024:2015 \nSystems \nand \nsoftware engineering \u2014 Systems and \nsoftware Quality Requirements and \nEvaluation (SQuaRE) \u2014 Measurement \nof data quality\n\u2022\t ISO/IEC \n25030:2019 \nSystems \nand \nsoftware engineering \u2014 Systems and \nsoftware quality requirements and eval-\nuation (SQuaRE) \u2014 Quality require-\nments framework\n\u2022\t ISO/IEC 25040:2011 Systems and soft-\nware engineering \u2014 Systems and software \nQuality Requirements and Evaluation \n(SQuaRE) \u2014 Evaluation process\n\u2022\t ISO/IEC \n25041:2012 \nSystems \nand \nsoftware engineering \u2014 Systems and \nsoftware Quality Requirements and \nEvaluation (SQuaRE) \u2014 Evaluation \nguide for developers, acquirers and inde-\npendent evaluators\n\u2022\t ISO/IEC \n25045:2010 \nSystems \nand \nsoftware engineering \u2014 Systems and \nsoftware Quality Requirements and \nEvaluation (SQuaRE) \u2014 Evaluation \nmodule for recoverability\n\u2022\t ISO/IEC 25051:2014 Software engi-\nneering \u2014 Systems and software Quality \nRequirements and Evaluation (SQuaRE) \n\u2014 Requirements for quality of Ready \nto Use Software Product (RUSP) and \ninstructions for testing\n\u2022\t ISO/IEC \n25062 \nSoftware \nProduct \nQuality Requirements and Evaluation \n(SQuaRE)\u2014Common Industry Format \n(CIF) for Usability\n\u2022\t ISO/IEC 26442:2019 Software and sys-\ntems engineering--Tools and methods for \nproduct line architecture design\n\u2022\t ISO/IEC/IEEE 26511:2018 Systems and \nsoftware engineering \u2014 Requirements \nfor managers of information for users of \nsystems, software, and services\n\u2022\t ISO/IEC/IEEE 26512:2018 Systems and \nsoftware engineering \u2014 Requirements \nfor acquirers and suppliers of informa-\ntion for users\n\u2022\t ISO/IEC/IEEE 26513:2017 Systems and \nsoftware engineering \u2014 Requirements \nfor testers and reviewers of informa-\ntion for users\n", "page": 408, "type": "text", "section": "Page 408"}
{"text": "APPENDIX B   B-15\n\u2022\t ISO/IEC \n26514:2021 \nSystems \nand \nSoftware \nEngineering--Design \nand \ndevelopment of information for users\n\u2022\t ISO/IEC/IEEE 26515:2018 Systems and \nsoftware engineering \u2014 Developing infor-\nmation for users in an agile environment\n\u2022\t ISO/IEC/IEEE 26531:2023 Systems \nand software engineering \u2014 Content \nmanagement for product life-cycle, user \nand service management documentation\n\u2022\t ISO/IEC 26550:2015 Software and sys-\ntems engineering \u2014 Reference model for \nproduct line engineering and management\n\u2022\t ISO/IEC 26551:2016 Software and sys-\ntems engineering \u2014 Tools and methods \nfor product line requirements engineering\n\u2022\t ISO/IEC 26552:2019 Software and sys-\ntems engineering \u2014 Tools and methods \nfor product line architecture design\n\u2022\t ISO/IEC 26553:2018 Information tech-\nnology \u2014 Software and systems engi-\nneering \u2014 Tools and methods for product \nline realization\n\u2022\t ISO/IEC 26554:2018 Information tech-\nnology \u2014 Software and systems engi-\nneering \u2014 Tools and methods for product \nline testing\n\u2022\t ISO/IEC 26555:2015 Software and sys-\ntems engineering \u2014 Tools and methods \nfor product line technical management\n\u2022\t ISO/IEC 26556:2018 Information tech-\nnology \u2014 Software and systems engi-\nneering \u2014 Tools and methods for product \nline organizational management\n\u2022\t ISO/IEC 26557:2016 Software and sys-\ntems engineering \u2014 Methods and tools \nfor variability mechanisms in software \nand systems product line\n\u2022\t ISO/IEC 26558:2017 Software and sys-\ntems engineering \u2014 Methods and tools \nfor variability modelling in software and \nsystems product line\n\u2022\t ISO/IEC 26559:2017 Software and sys-\ntems engineering \u2014 Methods and tools \nfor variability traceability in software and \nsystems product line\n\u2022\t ISO/IEC 26560:2019 Software and sys-\ntems engineering \u2014 Tools and methods \nfor product line product management\n\u2022\t ISO/IEC 26561:2019 Software and sys-\ntems engineering \u2014 Methods and tools \nfor product line technical probe\n\u2022\t ISO/IEC 26562:2019 Software and sys-\ntems engineering \u2014 Methods and tools \nfor product line transition management\n\u2022\t ISO/IEC 26580:2021 Software and sys-\ntems engineering \u2014 Methods and tools \nfor the feature-based approach to software \nand systems product line engineering\n\u2022\t ISO/IEC \n27000:2018 \nInformation \ntechnology \u2014 Security techniques \u2014 \nInformation security management sys-\ntems \u2014 Overview and vocabulary\n\u2022\t ISO/IEC 27001:2022 Information secu-\nrity, cybersecurity and privacy protection \n\u2014 Information security management \nsystems \u2014 Requirements\n\u2022\t ISO/IEC \n27032:2012 \nInformation \ntechnology \u2014 Security techniques \u2014 \nGuidelines for cybersecurity\n\u2022\t ISO/IEC TR 29110-1:2016 Systems and \nsoftware engineering \u2014 Lifecycle pro-\nfiles for Very Small Entities (VSEs) \u2014 \nPart 1: Overview\n\u2022\t ISO/IEC \n29110-2-1:2015 \nSoftware \nengineering \u2014 Lifecycle profiles for \nVery Small Entities (VSEs) \u2014 Part 2-1: \nFramework and taxonomy\n\u2022\t ISO/IEC TR 29110-5-3:2018 Systems \nand software engineering \u2014 Lifecycle \nprofiles for Very Small Entities (VSEs) \n\u2014 Part 5-3: Service delivery guidelines\n\u2022\t ISO/IEC/IEEE 29119-1: 2022 Software \nand systems engineering --Software \ntesting --Part 1: Concepts and definitions\n\u2022\t ISO/IEC/IEEE 29119-2: 2021 Software \nand systems engineering --Software \ntesting --Part 2: Test processes\n\u2022\t ISO/IEC/IEEE 29119-3: 2021 Software \nand systems engineering -- Software \ntesting --Part 3: Test documentation\n\u2022\t ISO/IEC/IEEE 29119-4 Software and \nsystems engineering--Software testing--\nPart 4: Test techniques\n\u2022\t ISO/IEC/IEEE 29119-5: 2016 Software \nand systems engineering -- Software \ntesting -- Part 5: Keyword-Driven Testing\n\u2022\t ISO/IEC TR 29119-6:2021 Software \n", "page": 409, "type": "text", "section": "Page 409"}
{"text": "B-16   SWEBOK \u00ae GUIDE V4.0\nand systems engineering \u2014 Software \ntesting \u2014 Part 6: Guidelines for the use \nof ISO/IEC/IEEE 29119 (all parts) in \nagile projects\n\u2022\t ISO/IEC TR 29119-11:2020 Software \nand systems engineering \u2014 Software \ntesting \u2014 Part 11: Guidelines on the \ntesting of AI-based systems\n\u2022\t ISO/IEC/IEEE 29148:2018. Systems \nand Software Engineering\u2014Life Cycle \nProcesses\u2014Requirements \nEngineering \nSW Requirements\n\u2022\t ISO/IEC 30130:2016 Software engi-\nneering \u2014 Capabilities of software \ntesting tools\n\u2022\t ISO/IEC \n33001:2015 \nInformation \ntechnology \u2014 Process assessment \u2014 \nConcepts and terminology\n\u2022\t ISO/IEC \n33002:2015 \nInformation \ntechnology \u2014 Process assessment \u2014 \nRequirements for performing process \nassessment\n\u2022\t ISO/IEC \n33003:2015 \nInformation \ntechnology \u2014 Process assessment \u2014 \nRequirements for process measurement \nframeworks\n\u2022\t ISO/IEC \n33004:2015 \nInformation \ntechnology \u2014 Process assessment \u2014 \nRequirements for process reference, pro-\ncess assessment and maturity models\n\u2022\t ISO/IEC TR 33014:2013 Information \ntechnology \u2014 Process assessment \u2014 \nGuide for process improvement\n\u2022\t ISO/IEC 33020:2019 Information tech-\nnology \u2014 Process assessment \u2014 Process \nmeasurement framework for assessment \nof process capability\n\u2022\t ISO/IEC TS 33061:2021 Information \ntechnology \u2014 Process assessment \u2014 \nProcess assessment model for software \nlife cycle processes\n\u2022\t ISO/IEC 33063:2015 Information tech-\nnology \u2014 Process assessment \u2014 Process \nassessment model for software testing\n\u2022\t ISO/IEC/IEEE 32430 Software engi-\nneering \n\u2014 \nStandard \nfor \nsoftware \nnon-functional size measurements\n\u2022\t ISO/IEC/IEEE \n32675:2021 \n(IEEE \n2675:2021) DevOps: Building Reliable \nand Secure Systems Including Application \nBuild, Package, and Deployment\n\u2022\t ISO/IEC 38500:2008 Corporate gover-\nnance of information technology\n\u2022\t ISO/IEC/IEEE 41062:2023 Software \nengineering \u2014 Recommended practice \nfor software acquisition\n\u2022\t ISO/IEC/IEEE 42010:2022 Software, \nsystems and enterprise \u2014 Architecture \ndescription\n\u2022\t ISO/IEC/IEEE 42020:2019: Software, \nsystems and enterprise \u2014 Architec\u00ad\nture processes\n\u2022\t ISO/IEC/IEEE 42030: 2019 Software, \nsystems, and enterprise \u2014 Architecture \nevaluation framework\n\u2022\t IEC 60300-1:2014 Dependability man-\nagement - Part 1: Guidance for manage-\nment and application.\n\u2022\t IEC/IEEE 82079-1 2019 Preparation0 \nof Information for Use (Instructions for \nUse) of Products - Part 1: Principles and \nGeneral Requirements\n\u2022\t ISO/IEC/IEEE 90003:2018 Software \nengineering \u2014 Guidelines for the \napplication of ISO 9001:2015 to com-\nputer software\n", "page": 410, "type": "text", "section": "Page 410"}
{"text": "C-1 \nCONSOLIDATED REFERENCE LIST\nAppendix C\nThe Consolidated Reference List identi-\nfies all recommended reference materials \n(to the level of section number) that accom-\npany the breakdown of topics within each \nknowledge area (KA). This Consolidated \nReference List is adopted by the software \nengineering certification and associated pro-\nfessional development products offered by \nthe IEEE Computer Society. KA Editors \nused the references allocated to their KA \nby the Consolidated Reference List as their \nRecommended References.\nCollectively this Consolidated Reference \n \nList is\n\u2022\t Complete: Covering the entire scope of \nthe SWEBOK Guide.\n\u2022\t Sufficient: Providing enough informa-\ntion to describe \u201cgenerally accepted\u201d \nknowledge.\n\u2022\t Consistent: Not providing contradictory \nknowledge nor conflicting practices.\n\u2022\t Credible: Recognized as providing expert \ntreatment.\n\u2022\t Current: Treating the subject in a manner \nthat is commensurate with currently gen-\nerally accepted knowledge.\n\u2022\t Succinct: As short as possible (both in \nnumber of reference items and in total page \ncount) without failing other objectives.\nIn total, there are 37 reference mate-\nrials below. \n\u2022\t J.H. Allen et al., Software Security \nEngineering: A Guide for Project \nManagers, Addison-Wesley, 2008.\n\u2022\t M. Bishop, Computer Security: Art \nand Science, 2nd Edition, Addison-\nWesley, 2018.\n\u2022\t B. Boehm and R. Turner, Balancing \nAgility and Discipline: A Guide for the \nPerplexed, Addison-Wesley, 2003.\n\u2022\t F. Bott et al., Professional Issues in \nSoftware Engineering, 3rd ed., Taylor & \nFrancis, 2000.\n\u2022\t J.G. Brookshear, Computer Science: \nAn Overview, 12th ed., Addison-\nWesley, 2017.\n\u2022\t D. Budgen, Software Design, 3rd ed., \nCRC Press, 2021.\n\u2022\t E.W. \nCheney \nand \nD.R. \nKincaid, \nNumerical Mathematics and Computing, \n6th ed., Brooks/Cole, 2007.\n\u2022\t P. Clements et al., Documenting Software \nArchitectures: Views and Beyond, 2nd \ned., Pearson Education, 2010.\n\u2022\t R.E. Fairley, Managing and Leading \nSoftware Projects, Wiley-IEEE Computer \nSociety Press, 2009.\n\u2022\t C.Y Laporte, A.April, Software Quality \nAssurance, IEEE Computer Society \nPress, 1st ed., 2018.\n\u2022\t E. Gamma et al., Design Patterns: \nElements of Reusable Object-Oriented \nSoftware, \n1st \ned., \nAddison-Wesley \nProfessional, 1994.\n\u2022\t P. Grubb and A.A. Takang, Software \nMaintenance: Concepts and Practice, 2nd \ned., World Scientific Publishing, 2003.\n\u2022\t A.M.J. Hass, Configuration Management \nPrinciples and Practices, 1st ed., Addison- \nWesley, 2003.\n\u2022\t S.H. Kan, Metrics and Models in \nSoftware Quality Engineering, 2nd ed., \nAddison-Wesley, 2002.\n\u2022\t S. McConnell, Code Complete, 2nd ed., \nMicrosoft Press, 2004.\n\u2022\t J. McGarry et al., Practical Software \nMeasurement: \nObjective \nInformation \n", "page": 411, "type": "text", "section": "Page 411"}
{"text": "C-2   SWEBOK \u00ae GUIDE V4.0\nfor Decision Makers, Addison-Wesley \nProfessional, 2001.\n\u2022\t S.J. Mellor and M.J. Balcer, Executable \nUML: \nA \nFoundation \nfor \nModel-\nDriven Architecture, 1st ed., Addison-\nWesley, 2002.\n\u2022\t S. Naik and P. Tripathy, Software \nTesting and Quality Assurance: Theory \nand Practice, Wiley-Spektrum, 2008.\n\u2022\t J. Nielsen, Usability Engineering, 1st ed., \nMorgan Kaufmann, 1993.\n\u2022\t L. Null and J. Lobur, The Essentials \nof \nComputer \nOrganization \nand \nArchitecture, 2nd ed., Jones and Bartlett \nPublishers, 2006.\n\u2022\t M. Page-Jones, Fundamentals of Object-\nOriented Design in UML, 1st ed., \nAddison-Wesley, 1999.\n\u2022\t A. Silberschatz, P.B. Galvin, and G. \nGagne, Operating System Concepts, 8th \ned., Wiley, 2008.\n\u2022\t I. Sommerville, Software Engineering, \n10th ed., Addison-Wesley, 2016.\n\u2022\t S. \nTockey, \nReturn \non \nSoftware: \nMaximizing \nthe \nReturn \non \nYour \nSoftware Investment, 1st ed., Addison-\nWesley, 2004.\n\u2022\t G. Voland, Engineering by Design, 2nd \ned., Prentice Hall, 2003.\n\u2022\t K.E. Wiegers, Software Requirements, \n3rd ed., Microsoft Press, 2013.\n\u2022\t J.M. Wing, \u201cA Specifier\u2019s Introduction to \nFormal Methods,\u201d Computer, vol. 23, no. \n9, 1990, pp. 8, 10\u201323.\n\u2022\t G. Kim, J. Humble, P. Debois, J. Willis \nand J. Allspaw, The DevOps handbook: \nHow to create world-class agility, reli-\nability, & security in technology organi-\nzations, 2nd ed., IT Revolution, 2021.\n\u2022\t G. Booch, J. Rumbaugh and I. Jacobson, \nThe \nUnified \nModeling \nLanguage \nUser Guide, 2nd edition, Addison-\nWesley, 2005. \n\u2022\t N. Rozanski and E. Woods, Software \nSystems Architecture: Working with \nStakeholders Using Viewpoints and \nPerspectives, 2nd edition, Addison-\nWesley, 2011. \n\u2022\t D. Farley, Modern Software Engineering: \nDoing What Works to Build Better \nSoftware \nFaster. \nAddison-Wesley \nProfessional, 2022.\n\u2022\t J. Shore and S. Warden, The Art of Agile \nDevelopment,  O\u2019Reilly Media, 2nd \nEdition, 2021.\n\u2022\t Project Management Institute and Agile \nAlliance, Agile Practice Guide, Project \nManagement Institute, 2017.\n\u2022\t D. C. Montgomery and G. C. Runger, \nApplied \nStatistics \nand \nProbability \nfor Engineers, 7th ed. Hoboken, NJ: \nWiley, 2018.\n\u2022\t K. Rosen, Discrete Mathematics and \nits Applications, 8th ed., McGraw-\nHill, 2018.\n\u2022\t E.W. Cheney and D.R. Kincaid, Numerical \nMathematics and Computing, 7th ed., \nAddison Wesley, 2020.\n\u2022\t L. Null and J. Lobur, The Essentials of \nComputer Organization and Architecture, \n5th ed. Sudbury, MA: Jones and Bartlett \nPublishers, 2018.\n", "page": 412, "type": "text", "section": "Page 412"}
{"text": "The Guide to the Software Engineering Body of \nKnowledge (SWEBOK Guide), published by the IEEE \nComputer Society, represents the current state \nof generally accepted knowledge and promotes a \nconsistent view of software engineering worldwide. \nGuide Version 4 reflects changes since the publication \nof Guide V3 in 2014, including modern development \npractices, new techniques, and the advancement of \nstandards, such as areas and descriptions related to \nagile and DevOps, architecture, operations, security, \nand AI.\nIEEE Computer Society is the largest computer \nscience and technology community dedicated to \nengaging engineers, scientists, academia, and industry \nprofessionals from across the globe, driving continued \nadvancements.\n", "page": 413, "type": "text", "section": "Page 413"}
