{"text": "Global \neditionaetn\nSoftware Engineering\nTENTH edition \nIan Sommerville\n", "page": 1, "type": "text", "section": "Page 1"}
{"text": "Software Engineering\nTenth Edition\nIan Sommerville\nBoston\u2002 \u2002 Columbus\u2002 \u2002 Indianapolis\u2002 \u2002 New York\u2002 \u2002 San Francisco\u2002 \u2002 Hoboken \nAmsterdam\u2002 \u2002 Cape Town\u2002 \u2002 Dubai\u2002 \u2002 London\u2002 \u2002 Madrid\u2002 \u2002 Milan\u2002 \u2002 Munich\u2002 \u2002 Paris\u2002 \u2002 Montreal\u2002 \u2002 Toronto  \nDelhi\u2002 \u2002 Mexico City\u2002 \u2002 S\u00e3o Paulo\u2002 \u2002 Sydney\u2002 \u2002 Hong Kong\u2002 \u2002 Seoul\u2002 \u2002 Singapore\u2002 \u2002 Taipei\u2002 \u2002 Tokyo\n", "page": 2, "type": "text", "section": "Page 2"}
{"text": "Editorial Director: Marcia Horton\nEditor in Chief: Michael Hirsch\nAcquisitions Editor: Matt Goldstein\nEditorial Assistant: Chelsea Bell\nAssistant Acquisitions Editor, Global \n\u2003 Edition: Murchana Borthakur\nAssociate Project Editor, Global \n\u2003 Edition: Binita Roy\nManaging Editor: Jeff Holcomb\nSenior Production Project \n\u2003 Manager: Marilyn Lloyd\nDirector of Marketing: Margaret Waples\nMarketing Coordinator: Kathryn Ferranti\nSenior Manufacturing Buyer: Carol Melville\nSenior Manufacturing Controller, Production, \n\u2003 Global Edition: Trudy Kimber\nText Designer: Susan Raymond\nCover Art Designer: Lumina Datamatics\nCover Image: \u00a9 Andrey Bayda/Shutterstock\nInterior Chapter Opener: \u00a9 graficart.net/Alamy\nFull-Service Project Management: Rashmi \n\u2003 Tickyani, Aptara\u00ae, Inc.\nComposition and Illustrations: Aptara\u00ae, Inc.\nPearson Education Limited \nEdinburgh Gate \nHarlow \nEssex CM20 2JE \nEngland\nand Associated Companies throughout the world\nVisit us on the World Wide Web at: \nwww.pearsonglobaleditions.com\n\u00a9 Pearson Education Limited 2016\nThe rights of Ian Sommerville to be identified as the author of this work have been asserted by him in \naccordance with the Copyright, Designs and Patents Act 1988.\nAuthorized adaptation from the United States edition, entitled Software Engineering, 10th edition, ISBN \n978-0-13-394303-0, by Ian Sommerville, published by Pearson Education \u00a9 2016.\nAll rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or \n\u00ad\ntransmitted in any form or by any means, electronic, mechanical, photocopying, recording or otherwise, \nwithout either the prior written permission of the publisher or a license permitting restricted copying in \nthe United Kingdom issued by the Copyright Licensing Agency Ltd, Saffron House, 6\u201310 Kirby Street, \nLondon EC1N 8TS.\nAll trademarks used herein are the property of their respective owners. The use of any trademark in this \ntext does not vest in the author or publisher any trademark ownership rights in such trademarks, nor does \nthe use of such trademarks imply any affiliation with or endorsement of this book by such owners.\nISBN 10: 1-292-09613-6\nISBN 13: 978-1-292-09613-1\nBritish Library Cataloguing-in-Publication Data \nA catalogue record for this book is available from the British Library\n10 9 8 7 6 5 4 3 2 1\nTypeset in 9 New Aster LT Std by Aptara\u00ae, Inc.\nPrinted and bound by Courier Westford in the United States of America.\n", "page": 3, "type": "text", "section": "Page 3"}
{"text": "Progress in software engineering over the last 50 years has been astonishing. Our \nsocieties could not function without large professional software systems. National \nutilities and infrastructure\u2014energy, communications and transport\u2014all rely on \ncomplex and mostly reliable computer systems. Software has allowed us to explore \nspace and to create the World Wide Web\u2014the most significant information system \nin the history of mankind. Smartphones and tablets are ubiquitous and an entire \u2018apps \nindustry\u2019 developing software for these devices has emerged in the past few years.\nHumanity is now facing a demanding set of challenges\u2014climate change and \nextreme weather, declining natural resources, an increasing world population to be fed \nand housed, international terrorism, and the need to help elderly people lead satisfying \nand fulfilled lives. We need new technologies to help us address these challenges and, \nfor sure, software will have a central role in these technologies. Software engineering \nis, therefore, critically important for our future on this planet. We have to continue to \neducate software engineers and develop the discipline so that we meet the demand for \nmore software and create the increasingly complex future systems that we need.\nOf course, there are still problems with software projects. Systems are still some-\ntimes delivered late and cost more than expected. We are creating increasingly com-\nplex software systems of systems and we should not be surprised that we encounter \ndifficulties along the way. However, we should not let these problems conceal the \nreal successes in software engineering and the impressive software engineering \nmethods and technologies that have been developed.\nThis book, in different editions, has now been around for over 30 years and this edi-\ntion is based around the essential principles that were established in the first edition:\n1.\t\nI write about software engineering as it is practiced in industry, without taking \nan evangelical position on particular approaches such as agile development or \nformal methods. In reality, industry mixes techniques such as agile and plan-\nbased development and this is reflected in the book.\nPreface\n", "page": 4, "type": "text", "section": "Page 4"}
{"text": "4\u2002 \u2002 Preface\n2.\t\nI write about what I know and understand. I have had many suggestions for \nadditional topics that might be covered in more detail such as open source \ndevelopment, the use of the UML and mobile software engineering. But I don\u2019t \nreally know enough about these areas. My own work has been in system depend-\nability and in systems engineering and this is reflected in my selection of \nadvanced topics for the book.\nI believe that the key issues for modern software engineering are managing com-\nplexity, integrating agility with other methods and ensuring that our systems are \nsecure and resilient. These issues have been the driver for the changes and additions \nin this new edition of my book.\nChanges from the 9th edition\nIn summary, the major updates and additions in this book from the 9th edition are:\n\u2022 I have extensively updated the chapter on agile software engineering, with new \nmaterial on Scrum. I have updated other chapters as required to reflect the increas-\ning use of agile methods of software engineering.\n\u2022 I have added new chapters on resilience engineering, systems engineering, and \nsystems of systems.\n\u2022 I have completely reorganized three chapters covering reliability, safety, and security.\n\u2022 I have added new material on RESTful services to the chapter covering service-\noriented software engineering.\n\u2022 I have revised and updated the chapter on configuration management with new \nmaterial on distributed version control systems.\n\u2022 I have moved chapters on aspect-oriented software engineering and process \nimprovement from the print version of the book to the web site.\n\u2022 New supplementary material has been added to the web site, including a set of \nsupporting videos. I have explained key topics on video and recommended related \nYouTube videos.\nThe 4-part structure of the book, introduced in earlier editions, has been retained \nbut I have made significant changes in each part of the book.\n1.\t\nIn Part 1, Introduction to software engineering, I have completely rewritten \nChapter 3 (agile methods) and updated this to reflect the increasing use of Scrum. \nA new case study on a digital learning environment has been added to Chapter 1 \nand is used in a number of chapters. Legacy systems are covered in more detail \nin Chapter 9. Minor changes and updates have been made to all other chapters.\n", "page": 5, "type": "text", "section": "Page 5"}
{"text": "\t\nPreface\u2002 \u2002 5\n2.\t\nPart 2, which covers dependable systems, has been revised and restructured. \nRather than an activity-oriented approach where information on safety, security \nand reliability is spread over several chapters, I have reorganized this so that \neach topic has a chapter in its own right. This makes it easier to cover a single \ntopic, such as security, as part of a more general course. I have added a com-\npletely new chapter on resilience engineering which covers cybersecurity, \norganizational resilience, and resilient systems design.\n3.\t\nIn Part 3, I have added new chapters on systems engineering and systems of \nsystems and have extensively revised the material on service-oriented systems \nengineering to reflect the increasing use of RESTful services. The chapter on \naspect-oriented software engineering has been deleted from the print version but \nremains available as a web chapter.\n4.\t\nIn Part 4, I have updated the material on configuration management to reflect \nthe increasing use of distributed version control tools such as Git. The chapter \non process improvement has been deleted from the print version but remains \navailable as a web chapter.\nAn important change in the supplementary material for the book is the addition of \nvideo recommendations in all chapters. I have made over 40 videos on a range of topics \nthat are available on my YouTube channel and linked from the book\u2019s web pages. In cases \nwhere I have not made videos, I have recommended YouTube videos that may be useful.\nI explain the rationale behind the changes that I\u2019ve made in this short video:\nhttp://software-engineering-book/videos/10th-edition-changes\nReadership\nThe book is primarily aimed at university and college students taking introductory \nand advanced courses in software and systems engineering. I assume that readers \nunderstand the basics of programming and fundamental data structures.\nSoftware engineers in industry may find the book useful as general reading and to \nupdate their knowledge on topics such as software reuse, architectural design, \ndependability and security and systems engineering.\nUsing the book in software engineering courses\nI have designed the book so that it can be used in three different types of software \nengineering course:\n1.\t\n\u0007\nGeneral introductory courses in software engineering. The first part of the book \nhas been designed to support a 1-semester course in introductory software engi-\nneering. There are 9 chapters that cover fundamental topics in software \u00ad\nengineering. \n", "page": 6, "type": "text", "section": "Page 6"}
{"text": "If your course has a practical component, management chapters in Part 4 may be \nsubstituted for some of these.\n\u2002 2.\t \u0007\nIntroductory or intermediate courses on specific software engineering topics. \nYou can create a range of more advanced courses using the chapters in parts \n2\u20134. For example, I have taught a course in critical systems using the chapters in \nPart 2 plus chapters on systems engineering and quality management. In a course \ncovering software-intensive systems engineering, I used chapters on systems \nengineering, requirements engineering, systems of systems, distributed software \nengineering, embedded software, project management and project planning.\n\u2002 3.\t \u0007\nMore advanced courses in specific software engineering topics. In this case, the \nchapters in the book form a foundation for the course. These are then supple-\nmented with further reading that explores the topic in more detail. For example, \na course on software reuse could be based around Chapters 15\u201318.\nInstructors may access additional teaching support material from Pearson\u2019s website. \nSome of this is password-protected and instructors using the book for teaching can \nobtain a password by registering at the Pearson website. The material available includes:\n\u2022 Model answers to selected end of chapter exercises.\n\u2022 Quiz questions and answers for each chapter.\nYou can access this material at:\nwww.pearsonglobaleditions.com/Sommerville\nBook website\nThis book has been designed as a hybrid print/web text in which core information in the \nprinted edition is linked to supplementary material on the web. Several chapters include \nspecially written \u2018web sections\u2019 that add to the information in that chapter. There are also \nsix \u2018web chapters\u2019 on topics that I have not covered in the print version of the book.\nYou can download a wide range of supporting material from the book\u2019s website \n(software-engineering-book.com) including:\n\u2022 A set of videos where I cover a range of software engineering topics. I also rec-\nommend other YouTube videos that can support learning.\n\u2022 An instructor\u2019s guide that gives advice on how to use the book in teaching differ-\nent courses.\n\u2022 Further information on the book\u2019s case studies (insulin pump, mental health care \nsystem, wilderness weather system, digital learning system), as well other case \nstudies, such as the failure of the Ariane 5 launcher.\n6\u2002 \u2002 Preface\n", "page": 7, "type": "text", "section": "Page 7"}
{"text": "\u2022 Six web chapters covering process improvement, formal methods, interaction \ndesign, application architectures, documentation and aspect-oriented development.\n\u2022 Web sections that add to the content presented in each chapter. These web sec-\ntions are linked from breakout boxes in each chapter.\n\u2022 PowerPoint presentations for all of the chapters in the book and additional \n\u00ad\nPowerPoint presentations covering a range of systems engineering topics are \navailable at pearsonglobaleditions.com/Sommerville.\nIn response to requests from users of the book, I have published a complete \nrequirements specification for one of the system case studies on the book\u2019s web site. \nIt is difficult for students to get access to such documents and so understand their \nstructure and complexity. To avoid confidentiality issues, I have re-engineered the \nrequirements document from a real system so there are no restrictions on its use.\nContact details\nWebsite: software-engineering-book.com\nEmail: name: software.engineering.book; domain: gmail.com\nBlog: iansommerville.com/systems-software-and-technology\nYouTube: youtube.com/user/SoftwareEngBook\nFacebook: facebook.com/sommerville.software.engineering\nTwitter: @SoftwareEngBook or @iansommerville (for more general tweets)\nFollow me on Twitter or Facebook to get updates on new material and comments on \nsoftware and systems engineering.\nAcknowledgements\nA large number of people have contributed over the years to the evolution of this \nbook and I\u2019d like to thank everyone (reviewers, students and book users) who have \ncommented on previous editions and made constructive suggestions for change. I\u2019d \nparticularly like to thank my family, Anne, Ali, and Jane, for their love, help and \nsupport while I was working on this book (and all of the previous editions).\nIan Sommerville,\nSeptember 2014\n\t\nPreface\u2002 \u2002 7\n", "page": 8, "type": "text", "section": "Page 8"}
{"text": "Contents at a glance\nPreface\t\n3\n\t\nPart 1\t Introduction to Software Engineering\t\n15\n\t\nChapter 1\t\n Introduction \t\n17\n\t\nChapter 2\t\n Software processes \t\n43\n\t\nChapter 3\t\n Agile software development \t\n72\n\t\nChapter 4\t\n Requirements engineering \t\n101\n\t\nChapter 5\t\n System modeling \t\n138\n\t\nChapter 6\t\n Architectural design \t\n167\n\t\nChapter 7\t\n Design and implementation \t\n196\n\t\nChapter 8\t\n Software testing \t\n226\n\t\nChapter 9\t\n Software evolution \t\n255\n\t\nPart 2\t System Dependability and Security\t\n283\n\t\nChapter 10\t  Dependable systems \t\n285\n\t\nChapter 11\t  Reliability engineering \t\n306\n\t\nChapter 12\t  Safety engineering \t\n339\n\t\nChapter 13\t  Security engineering \t\n373\n\t\nChapter 14\t  Resilience engineering \t\n408\n\t\nPart 3\t Advanced Software Engineering\t\n435\n\t\nChapter 15\t  Software reuse \t\n437\n\t\nChapter 16\t  Component-based software engineering \t\n464\n\t\nChapter 17\t  Distributed software engineering \t\n490\n\t\nChapter 18\t  Service-oriented software engineering \t\n520\n\t\nChapter 19\t  Systems engineering \t\n551\n\t\nChapter 20\t  Systems of systems \t\n580\n\t\nChapter 21\t  Real-time software engineering \t\n610\n\t\nPart 4\t Software management\t\n639\n\t\nChapter 22\t  Project management \t\n641\n\t\nChapter 23\t  Project planning \t\n667\n\t\nChapter 24\t  Quality management \t\n700\n\t\nChapter 25\t  Configuration management \t\n730\nGlossary\t\n757\nSubject index\t\n777\nAuthor index\t\n803 \n\u0007\nPearson wishes to thank and acknowledge the following people for their work on the Global Edition:\nContributor\nSherif G. Aly, The American University in Cairo\nMuthuraj M., Android developer \nReviewers\nMohit P. Tahiliani, National Institute of Technology Karnataka, Surathkal\nChitra Dhawale, P. R. Patil Group of Educational Institutes, Amravati \nSanjeevni Shantaiya, Disha Institute of Management & Technology\n", "page": 9, "type": "text", "section": "Page 9"}
{"text": "Contents\nPreface\t\n3\n\t\nPart 1\t Introduction to Software Engineering\t\n15\n\t\nChapter 1\t  Introduction \t\n17\n1.1 \t Professional software development \t\n19\n1.2 \t Software engineering ethics \t\n28\n1.3 \t Case studies \t\n31\n\t\nChapter 2\t Software processes \t\n43\n2.1 \t  Software process models \t\n45\n2.2 \t  Process activities \t\n54\n2.3 \t  Coping with change \t\n61\n2.4 \t  Process improvement \t\n65\n\t\nChapter 3\t Agile software development \t\n72\n3.1 \t Agile methods \t\n75\n3.2 \t Agile development techniques \t\n77\n3.3 \t Agile project management \t\n84\n3.4 \t Scaling agile methods \t\n88\n", "page": 10, "type": "text", "section": "Page 10"}
{"text": "10\u2002 \u2002 Contents\n\t\nChapter 4\t Requirements engineering \t\n101\n4.1 \t Functional and non-functional requirements \t\n105\n4.2 \t Requirements engineering processes \t\n111\n4.3 \t Requirements elicitation \t\n112\n4.4 \t Requirements specification \t\n120\n4.5 \t Requirements validation \t\n129\n4.6 \t Requirements change \t\n130\n\t\nChapter 5\t System modeling \t\n138\n5.1 \t Context models \t\n141\n5.2 \t Interaction models \t\n144\n5.3 \t Structural models \t\n149\n5.4 \t Behavioral models \t\n154\n5.5 \t Model-driven architecture \t\n159\n\t\nChapter 6\t Architectural design \t\n167\n6.1 \t  Architectural design decisions \t\n171\n6.2 \t  Architectural views \t\n173\n6.3 \t  Architectural patterns \t\n175\n6.4 \t  Application architectures \t\n184\n\t\nChapter 7\t Design and implementation \t\n196\n7.1 \t Object-oriented design using the UML \t\n198\n7.2 \t Design patterns \t\n209\n7.3 \t Implementation issues \t\n212\n7.4 \t Open-source development \t\n219\n\t\nChapter 8\t Software testing \t\n226\n8.1 \t Development testing \t\n231\n8.2 \t Test-driven development \t\n242\n", "page": 11, "type": "text", "section": "Page 11"}
{"text": "\t\nContents\u2002 \u2002 11\n8.3 \t Release testing \t\n245\n8.4 \t User testing \t\n249\n\t\nChapter 9\t Software evolution \t\n255\n9.1 \t Evolution processes \t\n258\n9.2 \t Legacy systems \t\n261\n9.3 \t Software maintenance \t\n270\n\t\nPart 2\t System Dependability and Security\t\n283\n\t\nChapter 10\t Dependable systems \t\n285\n10.1 \tDependability properties \t\n288\n10.2 \tSociotechnical systems \t\n291\n10.3 \tRedundancy and diversity \t\n295\n10.4 \tDependable processes \t\n297\n10.5 \tFormal methods and dependability \t\n299\n\t\nChapter 11\t Reliability engineering \t\n306\n11.1 \tAvailability and reliability \t\n309\n11.2 \tReliability requirements \t\n312\n11.3 \tFault-tolerant architectures \t\n318\n11.4 \tProgramming for reliability \t\n325\n11.5 \tReliability measurement \t\n331\n\t\nChapter 12\t Safety engineering \t\n339\n12.1 \tSafety-critical systems \t\n341\n12.2 \tSafety requirements \t\n344\n12.3 \tSafety engineering processes \t\n352\n12.4 \tSafety cases \t\n361\n", "page": 12, "type": "text", "section": "Page 12"}
{"text": "\t\nChapter 13\t Security engineering \t\n373\n13.1 \tSecurity and dependability \t\n376\n13.2 \tSecurity and organizations \t\n380\n13.3 \tSecurity requirements \t\n382\n13.4 \tSecure systems design \t\n388\n13.5 \tSecurity testing and assurance \t\n402\n\t\nChapter 14\t Resilience engineering \t\n408\n14.1 \tCybersecurity \t\n412\n14.2 \tSociotechnical resilience \t\n416\n14.3 \tResilient systems design \t\n424\n\t\nPart 3\t Advanced Software Engineering\t\n435\n\t\nChapter 15\t Software reuse \t\n437\n15.1 \tThe reuse landscape \t\n440\n15.2 \tApplication frameworks \t\n443\n15.3 \tSoftware product lines \t\n446\n15.4 \tApplication system reuse \t\n453\n\t\nChapter 16\t Component-based software engineering \t\n464\n16.1 \tComponents and component models \t\n467\n16.2 \tCBSE processes \t\n473\n16.3 \tComponent composition \t\n480\n\t\nChapter 17\t Distributed software engineering \t\n490\n17.1 \tDistributed systems \t\n492\n17.2 \tClient\u2013server computing \t\n499\n12\u2002 \u2002 Contents\n", "page": 13, "type": "text", "section": "Page 13"}
{"text": "17.3 \tArchitectural patterns for distributed systems \t\n501\n17.4 \tSoftware as a service \t\n512\n\t\nChapter 18\t Service-oriented software engineering \t\n520\n18.1 \tService-oriented architecture \t\n524\n18.2 \tRESTful services \t\n529\n18.3 \tService engineering \t\n533\n18.4 \tService composition \t\n541\n\t\nChapter 19\t Systems engineering \t\n551\n19.1 \tSociotechnical systems \t\n556\n19.2 \tConceptual design \t\n563\n19.3 \tSystem procurement \t\n566\n19.4 \tSystem development \t\n570\n19.5 \tSystem operation and evolution \t\n574\n\t\nChapter 20\t Systems of systems \t\n580\n20.1 \tSystem complexity \t\n584\n20.2 \tSystems of systems classification \t\n587\n20.3 \tReductionism and complex systems \t\n590\n20.4 \tSystems of systems engineering \t\n593\n20.5 \tSystems of systems architecture \t\n599\n\t\nChapter 21\t Real-time software engineering \t\n610\n21.1 \tEmbedded system design \t\n613\n21.2 \tArchitectural patterns for real-time software \t\n620\n21.3 \tTiming analysis \t\n626\n21.4 \tReal-time operating systems \t\n631\n\t\nContents\u2002 \u2002 13\n", "page": 14, "type": "text", "section": "Page 14"}
{"text": "\t\nPart 4\t Software Management\t\n639\n\t\nChapter 22\t Project management \t\n641\n22.1 \tRisk management \t\n644\n22.2 \tManaging people \t\n652\n22.3 \tTeamwork \t\n656\n\t\nChapter 23\t Project planning \t\n667\n23.1 \tSoftware pricing \t\n670\n23.2 \tPlan-driven development \t\n672\n23.3 \tProject scheduling \t\n675\n23.4 \tAgile planning \t\n680\n23.5 \tEstimation techniques \t\n682\n23.6 \tCOCOMO cost modeling \t\n686\n\t\nChapter 24\t Quality management \t\n700\n24.1 \tSoftware quality \t\n703\n24.2 \tSoftware standards \t\n706\n24.3 \tReviews and inspections \t\n710\n24.4 \tQuality management and agile development \t\n714\n24.5 \tSoftware measurement \t\n716\n\t\nChapter 25\t Configuration management \t\n730\n25.1 \tVersion management \t\n735\n25.2 \tSystem building \t\n740\n25.3 \tChange management \t\n745\n25.4 \tRelease management \t\n750\nGlossary \t\n757\nSubject index \t\n777\nAuthor index \t\n803\n14\u2002 \u2002 Contents\n", "page": 15, "type": "text", "section": "Page 15"}
{"text": "PART\nMy aim in this part of the book is to provide a general introduction to soft-\nware engineering. The chapters in this part have been designed to support \na one-semester first course in software engineering. I introduce impor-\ntant concepts such as software processes and agile methods, and describe \nessential software development activities, from requirements specification \nthrough to system evolution.\nChapter 1 is a general introduction that introduces professional software \nengineering and defines some software engineering concepts. I have also \nincluded a brief discussion of ethical issues in software engineering. It is \nimportant for software engineers to think about the wider implications of \ntheir work. This chapter also introduces four case studies that I use in the \nbook. These are an information system for managing records of patients \nundergoing treatment for mental health problems (Mentcare), a control \nsystem for a portable insulin pump, an embedded system for a wilder-\nness weather station and a digital learning environment (iLearn).\nChapters 2 and 3 cover software engineering processes and agile devel-\nopment. In Chapter 2, I introduce software process models, such as the \nwaterfall model, and I discuss the basic activities that are part of these \nprocesses. Chapter 3 supplements this with a discussion of agile devel-\nopment methods for software engineering. This chapter had been \n 1 \nIntroduction \nto Software \nEngineering\n", "page": 16, "type": "text", "section": "Page 16"}
{"text": "extensively changed from previous editions with a focus on agile devel-\nopment using Scrum and a discussion of agile practices such as stories \nfor requirements definition and test-driven development.\nThe remaining chapters in this part are extended descriptions of the \nsoftware process activities that are introduced in Chapter 2. Chapter 4 \ncovers the critically important topic of requirements engineering, where \nthe requirements for what a system should do are defined. Chapter 5 \nexplains system modeling using the UML, where I focus on the use of \nuse case diagrams, class diagrams, sequence diagrams and state dia-\ngrams for modeling a software system. In Chapter 6, I discuss the impor-\ntance of software architecture and the use of architectural patterns in \nsoftware design.\nChapter 7 introduces object oriented design and the use of design pat-\nterns. I also introduce important implementation issues here\u2014reuse, \nconfiguration management and host-target development and discuss \nopen source development. Chapter 8 focuses on software testing from \nunit testing during system development to the testing of software \nreleases. I also discuss the use of test-driven development\u2014an \napproach pioneered in agile methods but which has wide applicabil-\nity. Finally, Chapter 9 presents an overview of software evolution \nissues. I cover evolution processes, software maintenance and legacy \nsystem management.\n", "page": 17, "type": "text", "section": "Page 17"}
{"text": "Introduction\n1 \nObjectives\nThe objectives of this chapter are to introduce software engineering and \nto provide a framework for understanding the rest of the book. When you \nhave read this chapter, you will:\n\u25a0\t understand what software engineering is and why it is important;\n\u25a0\t understand that the development of different types of software \nsystem may require different software engineering techniques;\n\u25a0\t understand ethical and professional issues that are important  \nfor software engineers;\n\u25a0\t have been introduced to four systems, of different types, which are \nused as examples throughout the book.\nContents\n1.1 \tProfessional software development\n1.2 \tSoftware engineering ethics\n1.3 \tCase studies\n", "page": 18, "type": "text", "section": "Page 18"}
{"text": "18\u2002 \u2002 Chapter 1\u2002 \u25a0\u2002 Introduction\nSoftware engineering is essential for the functioning of government, society, and national \nand international businesses and institutions. We can\u2019t run the modern world without \nsoftware. National infrastructures and utilities are controlled by computer-based systems, \nand most electrical products include a computer and controlling software. Industrial \nmanufacturing and distribution is completely computerized, as is the financial system. \nEntertainment, including the music industry, computer games, and film and television, is \nsoftware-intensive. More than 75% of the world\u2019s population have a software-controlled \nmobile phone, and, by 2016, almost all of these will be Internet-enabled.\nSoftware systems are abstract and intangible. They are not constrained by the prop-\nerties of materials, nor are they governed by physical laws or by manufacturing pro-\ncesses. This simplifies software engineering, as there are no natural limits to the potential \nof software. However, because of the lack of physical constraints, software systems can \nquickly become extremely complex, difficult to understand, and expensive to change.\nThere are many different types of software system, ranging from simple embed-\nded systems to complex, worldwide information systems. There are no universal \nnotations, methods, or techniques for software engineering because different types \nof software require different approaches. Developing an organizational information \nsystem is completely different from developing a controller for a scientific instru-\nment. Neither of these systems has much in common with a graphics-intensive com-\nputer game. All of these applications need software engineering; they do not all need \nthe same software engineering methods and techniques.\nThere are still many reports of software projects going wrong and of \u201csoftware \nfailures.\u201d Software engineering is criticized as inadequate for modern software \ndevelopment. However, in my opinion, many of these so-called software failures \nare\u00a0a consequence of two factors:\n1.\t\nIncreasing system complexity As new software engineering techniques help us \nto build larger, more complex systems, the demands change. Systems have to be \nbuilt and delivered more quickly; larger, even more complex systems are \nrequired; and systems have to have new capabilities that were previously \nthought to be impossible. New software engineering techniques have to be \ndeveloped to meet new the challenges of delivering more complex software.\n2.\t\nFailure to use software engineering methods It is fairly easy to write computer \nprograms without using software engineering methods and techniques. Many \ncompanies have drifted into software development as their products and ser-\nvices have evolved. They do not use software engineering methods in their every-\nday work. Consequently, their software is often more expensive and less reliable \nthan it should be. We need better software engineering education and training to \naddress this problem.\nSoftware engineers can be rightly proud of their achievements. Of course, we still \nhave problems developing complex software, but without software engineering we \nwould not have explored space and we would not have the Internet or modern tele-\ncommunications. All forms of travel would be more dangerous and expensive. \nChallenges for humanity in the 21st century are climate change, fewer natural \n", "page": 19, "type": "text", "section": "Page 19"}
{"text": "\t\n1.1\u2002 \u25a0\u2002 Professional software development\u2002 \u2002 19\nresources, changing demographics, and an expanding world population. We will rely \non software engineering to develop the systems that we need to cope with these issues.\n \n1.1 Professional software development\nLots of people write programs. People in business write spreadsheet programs to \nsimplify their jobs; scientists and engineers write programs to process their experi-\nmental data; hobbyists write programs for their own interest and enjoyment. \nHowever, most software development is a professional activity in which software is \ndeveloped for business purposes, for inclusion in other devices, or as software prod-\nucts such as information systems and computer-aided design systems. The key dis-\ntinctions are that professional software is intended for use by someone apart from its \ndeveloper and that teams rather than individuals usually develop the software. It is \nmaintained and changed throughout its life.\nSoftware engineering is intended to support professional software development \nrather than individual programming. It includes techniques that support program \nspecification, design, and evolution, none of which are normally relevant for per-\nsonal software development. To help you to get a broad view of software engineer-\ning, I have summarized frequently asked questions about the subject in Figure 1.1.\nMany people think that software is simply another word for computer programs. \nHowever, when we are talking about software engineering, software is not just the \nprograms themselves but also all associated documentation, libraries, support web-\nsites, and configuration data that are needed to make these programs useful. A pro-\nfessionally developed software system is often more than a single program. A system \nmay consist of several separate programs and configuration files that are used to set \nup these programs. It may include system documentation, which describes the struc-\nture of the system, user documentation, which explains how to use the system, and \nwebsites for users to download recent product information.\nThis is one of the important differences between professional and amateur soft-\nware development. If you are writing a program for yourself, no one else will use it \nHistory of software engineering\nThe notion of software engineering was first proposed in 1968 at a conference held to discuss what was then \ncalled the software crisis (Naur and Randell 1969). It became clear that individual approaches to program devel-\nopment did not scale up to large and complex software systems. These were unreliable, cost more than \nexpected, and were delivered late.\nThroughout the 1970s and 1980s, a variety of new software engineering techniques and methods were \ndeveloped, such as structured programming, information hiding, and object-oriented development. Tools and \nstandard notations were developed which are the basis of today\u2019s software engineering.\nhttp://software-engineering-book.com/web/history/\n", "page": 20, "type": "text", "section": "Page 20"}
{"text": "20\u2002 \u2002 Chapter 1\u2002 \u25a0\u2002 Introduction\nFigure 1.1\u2002 Frequently \nasked questions about \nsoftware engineering\nQuestion\nAnswer\nWhat is software?\nComputer programs and associated documentation. Software \nproducts may be developed for a particular customer or may be \ndeveloped for a general market.\nWhat are the attributes of good \nsoftware?\nGood software should deliver the required functionality and \nperformance to the user and should be maintainable, dependable \nand usable.\nWhat is software engineering?\nSoftware engineering is an engineering discipline that is concerned \nwith all aspects of software production from initial conception to \noperation and maintenance.\nWhat are the fundamental \nsoftware engineering activities?\nSoftware specification, software development, software validation \nand software evolution.\nWhat is the difference between \nsoftware engineering and \ncomputer science?\nComputer science focuses on theory and fundamentals; software \nengineering is concerned with the practicalities of developing and \ndelivering useful software.\nWhat is the difference between \nsoftware engineering and system \nengineering?\nSystem engineering is concerned with all aspects of computer-\nbased systems development including hardware, software and \nprocess engineering. Software engineering is part of this more \ngeneral process.\nWhat are the key challenges \nfacing software engineering?\nCoping with increasing diversity, demands for reduced delivery \ntimes and developing trustworthy software.\nWhat are the costs of software \nengineering?\nRoughly 60% of software costs are development costs, 40% are \ntesting costs. For custom software, evolution costs often exceed \ndevelopment costs.\nWhat are the best software \nengineering techniques and \nmethods?\nWhile all software projects have to be professionally managed and \ndeveloped, different techniques are appropriate for different types \nof system. For example, games should always be developed using \na series of prototypes whereas safety critical control systems \nrequire a complete and analyzable specification to be developed. \nThere are no methods and techniques that are good for everything.\nWhat differences has the Internet \nmade to software engineering?\nNot only has the Internet led to the development of massive, highly \ndistributed, service-based systems, it has also supported the \ncreation of an \u201capp\u201d industry for mobile devices which has \nchanged the economics of software.\nand you don\u2019t have to worry about writing program guides, documenting the pro-\ngram design, and so on. However, if you are writing software that other people will \nuse and other engineers will change, then you usually have to provide additional \ninformation as well as the code of the program.\nSoftware engineers are concerned with developing software products, that is, \nsoftware that can be sold to a customer. There are two kinds of software product:\n1.\t\nGeneric products These are stand-alone systems that are produced by a \ndevelopment organization and sold on the open market to any customer who is \nable to buy them. Examples of this type of product include apps for mobile \ndevices, software for PCs such as databases, word processors, drawing packages, \nand project management tools. This kind of software also includes \u201cvertical\u201d \n", "page": 21, "type": "text", "section": "Page 21"}
{"text": "\t\n1.1\u2002 \u25a0\u2002 Professional software development\u2002 \u2002 21\napplications designed for a specific market such as library information systems, \naccounting systems, or systems for maintaining dental records.\n2.\t\nCustomized (or bespoke) software These are systems that are commissioned by \nand developed for a particular customer. A software contractor designs and \nimplements the software especially for that customer. Examples of this type of \nsoftware include control systems for electronic devices, systems written to \nsupport a particular business process, and air traffic control systems.\nThe critical distinction between these types of software is that, in generic prod-\nucts, the organization that develops the software controls the software specification. \nThis means that if they run into development problems, they can rethink what is to \nbe developed. For custom products, the specification is developed and controlled by \nthe organization that is buying the software. The software developers must work to \nthat specification.\nHowever, the distinction between these system product types is becoming increas-\ningly blurred. More and more systems are now being built with a generic product as \na base, which is then adapted to suit the requirements of a customer. Enterprise \nResource Planning (ERP) systems, such as systems from SAP and Oracle, are the \nbest examples of this approach. Here, a large and complex system is adapted for a \ncompany by incorporating information about business rules and processes, reports \nrequired, and so on.\nWhen we talk about the quality of professional software, we have to consider that \nthe software is used and changed by people apart from its developers. Quality is \ntherefore not just concerned with what the software does. Rather, it has to include the \nsoftware\u2019s behavior while it is executing and the structure and organization of the\u00a0sys-\ntem programs and associated documentation. This is reflected in the software\u2019s qual-\nity or non-functional attributes. Examples of these attributes are the software\u2019s \nresponse time to a user query and the understandability of the \u00ad\nprogram code.\nThe specific set of attributes that you might expect from a software system obvi-\nously depends on its application. Therefore, an aircraft control system must be safe,\u00a0an \ninteractive game must be responsive, a telephone switching system must be reliable, \nand so on. These can be generalized into the set of attributes shown in Figure\u00a01.2, \nwhich I think are the essential characteristics of a \u00ad\nprofessional software system.\n \n1.1.1  Software engineering\nSoftware engineering is an engineering discipline that is concerned with all aspects \nof software production from the early stages of system specification through to \nmaintaining the system after it has gone into use. In this definition, there are two \nkey phrases:\n1.\t\nEngineering discipline Engineers make things work. They apply theories, meth-\nods, and tools where these are appropriate. However, they use them selectively \n", "page": 22, "type": "text", "section": "Page 22"}
{"text": "22\u2002 \u2002 Chapter 1\u2002 \u25a0\u2002 Introduction\nFigure 1.2\u2002 Essential \nattributes of good \nsoftware\nProduct characteristic\nDescription\nAcceptability\nSoftware must be acceptable to the type of users for which it is \ndesigned. This means that it must be understandable, usable, and \ncompatible with other systems that they use.\nDependability and security\nSoftware dependability includes a range of characteristics including \nreliability, security, and safety. Dependable software should not \ncause physical or economic damage in the event of system failure. \nSoftware has to be secure so that malicious users cannot access or \ndamage the system.\nEfficiency\nSoftware should not make wasteful use of system resources such  \nas memory and processor cycles. Efficiency therefore includes \nresponsiveness, processing time, resource utilization, etc.\nMaintainability\nSoftware should be written in such a way that it can evolve to  \nmeet the changing needs of customers. This is a critical attribute \nbecause software change is an inevitable requirement of a  \nchanging business environment.\nand always try to discover solutions to problems even when there are no appli-\ncable theories and methods. Engineers also recognize that they must work \nwithin organizational and financial constraints, and they must look for solutions \nwithin these constraints.\n2.\t\nAll aspects of software production Software engineering is not just concerned \nwith the technical processes of software development. It also includes activities \nsuch as software project management and the development of tools, methods, \nand theories to support software development.\nEngineering is about getting results of the required quality within schedule and \nbudget. This often involves making compromises\u2014engineers cannot be perfection-\nists. People writing programs for themselves, however, can spend as much time as \nthey wish on the program development.\nIn general, software engineers adopt a systematic and organized approach to their \nwork, as this is often the most effective way to produce high-quality software. \nHowever, engineering is all about selecting the most appropriate method for a set of \ncircumstances, so a more creative, less formal approach to development may be the \nright one for some kinds of software. A more flexible software process that accom-\nmodates rapid change is particularly appropriate for the development of interactive \nweb-based systems and mobile apps, which require a blend of software and graphi-\ncal design skills.\nSoftware engineering is important for two reasons:\n1.\t\nMore and more, individuals and society rely on advanced software systems. We need \nto be able to produce reliable and trustworthy systems economically and quickly.\n2.\t\nIt is usually cheaper, in the long run, to use software engineering methods and \ntechniques for professional software systems rather than just write programs as \n", "page": 23, "type": "text", "section": "Page 23"}
{"text": "\t\n1.1\u2002 \u25a0\u2002 Professional software development\u2002 \u2002 23\na personal programming project. Failure to use software engineering method \nleads to higher costs for testing, quality assurance, and long-term maintenance.\nThe systematic approach that is used in software engineering is sometimes called \na software process. A software process is a sequence of activities that leads to the \nproduction of a software product. Four fundamental activities are common to all \nsoftware processes.\n1.\t\nSoftware specification, where customers and engineers define the software that \nis to be produced and the constraints on its operation.\n2.\t\nSoftware development, where the software is designed and programmed.\n3.\t\nSoftware validation, where the software is checked to ensure that it is what the \ncustomer requires.\n4.\t\nSoftware evolution, where the software is modified to reflect changing customer \nand market requirements.\nDifferent types of systems need different development processes, as I explain in \nChapter 2. For example, real-time software in an aircraft has to be completely speci-\nfied before development begins. In e-commerce systems, the specification and the \nprogram are usually developed together. Consequently, these generic activities may \nbe organized in different ways and described at different levels of detail, depending \non the type of software being developed.\nSoftware engineering is related to both computer science and systems engineering.\n1.\t\nComputer science is concerned with the theories and methods that underlie \ncomputers and software systems, whereas software engineering is concerned \nwith the practical problems of producing software. Some knowledge of com-\nputer science is essential for software engineers in the same way that some \nknowledge of physics is essential for electrical engineers. Computer science \ntheory, however, is often most applicable to relatively small programs. Elegant \ntheories of computer science are rarely relevant to large, complex problems that \nrequire a software solution.\n2.\t\nSystem engineering is concerned with all aspects of the development and evolu-\ntion of complex systems where software plays a major role. System engineering \nis therefore concerned with hardware development, policy and process design, \nand system deployment, as well as software engineering. System engineers are \ninvolved in specifying the system, defining its overall architecture, and then \nintegrating the different parts to create the finished system.\nAs I discuss in the next section, there are many different types of software. There are \nno universal software engineering methods or techniques that may be used. However, \nthere are four related issues that affect many different types of software:\n", "page": 24, "type": "text", "section": "Page 24"}
{"text": "24\u2002 \u2002 Chapter 1\u2002 \u25a0\u2002 Introduction\n1.\t\nHeterogeneity Increasingly, systems are required to operate as distributed sys-\ntems across networks that include different types of computer and mobile \ndevices. As well as running on general-purpose computers, software may also \nhave to execute on mobile phones and tablets. You often have to integrate new \nsoftware with older legacy systems written in different programming languages. \nThe challenge here is to develop techniques for building dependable software \nthat is flexible enough to cope with this heterogeneity.\n2.\t\nBusiness and social change Businesses and society are changing incredibly \nquickly as emerging economies develop and new technologies become availa-\nble. They need to be able to change their existing software and to rapidly \ndevelop new software. Many traditional software engineering techniques are \ntime consuming, and delivery of new systems often takes longer than planned. \nThey need to evolve so that the time required for software to deliver value to its \ncustomers is reduced.\n3.\t\nSecurity and trust As software is intertwined with all aspects of our lives, it is \nessential that we can trust that software. This is especially true for remote soft-\nware systems accessed through a web page or web service interface. We have to \nmake sure that malicious users cannot successfully attack our software and that \ninformation security is maintained.\n4.\t\nScale Software has to be developed across a very wide range of scales, from \nvery small embedded systems in portable or wearable devices through to \nInternet-scale, cloud-based systems that serve a global community.\nTo address these challenges, we will need new tools and techniques as well as \ninnovative ways of combining and using existing software engineering methods.\n \n1.1.2  Software engineering diversity\nSoftware engineering is a systematic approach to the production of software \nthat takes into account practical cost, schedule, and dependability issues, as \nwell as the needs of software customers and producers. The specific methods, \ntools, and techniques used depend on the organization developing the software, \nthe type of software, and the people involved in the development process. There \nare no universal software engineering methods that are suitable for all systems \nand all companies. Rather, a diverse set of software engineering methods and \ntools has evolved over the past 50 years. However, the SEMAT initiative \n(Jacobson et al. 2013) proposes that there can be a fundamental meta-process \nthat can be instantiated to create different kinds of process. This is at an early \nstage of development and may be a basis for improving our current software \nengineering methods.\nPerhaps the most significant factor in determining which software engineering \nmethods and techniques are most important is the type of application being devel-\noped. There are many different types of application, including:\n", "page": 25, "type": "text", "section": "Page 25"}
{"text": "\t\n1.1\u2002 \u25a0\u2002 Professional software development\u2002 \u2002 25\n1.\t\nStand-alone applications These are application systems that run on a personal \ncomputer or apps that run on a mobile device. They include all necessary func-\ntionality and may not need to be connected to a network. Examples of such \napplications are office applications on a PC, CAD programs, photo manipula-\ntion software, travel apps, productivity apps, and so on.\n2.\t\nInteractive transaction-based applications These are applications that execute \non a remote computer and that are accessed by users from their own computers, \nphones, or tablets. Obviously, these include web applications such as e-commerce \napplications where you interact with a remote system to buy goods and services. \nThis class of application also includes business systems, where a business \nprovides access to its systems through a web browser or special-purpose client \nprogram and cloud-based services, such as mail and photo sharing. Interactive \napplications often incorporate a large data store that is accessed and updated in \neach transaction.\n3.\t\nEmbedded control systems These are software control systems that control and \nmanage hardware devices. Numerically, there are probably more embedded sys-\ntems than any other type of system. Examples of embedded systems include the \nsoftware in a mobile (cell) phone, software that controls antilock braking in a \ncar, and software in a microwave oven to control the cooking process.\n4.\t\nBatch processing systems These are business systems that are designed to pro-\ncess data in large batches. They process large numbers of individual inputs to \ncreate corresponding outputs. Examples of batch systems are periodic billing \nsystems, such as phone billing systems, and salary payment systems.\n5.\t\nEntertainment systems These are systems for personal use that are intended to \nentertain the user. Most of these systems are games of one kind or another, \nwhich may run on special-purpose console hardware. The quality of the user \ninteraction offered is the most important distinguishing characteristic of enter-\ntainment systems.\n6.\t\nSystems for modeling and simulation These are systems that are developed by \nscientists and engineers to model physical processes or situations, which include \nmany separate, interacting objects. These are often computationally intensive \nand require high-performance parallel systems for execution.\n7.\t\nData collection and analysis systems Data collection systems are systems that \ncollect data from their environment and send that data to other systems for pro-\ncessing. The software may have to interact with sensors and often is installed in \na hostile environment such as inside an engine or in a remote location. \u201cBig \ndata\u201d analysis may involve cloud-based systems carrying out statistical analysis \nand looking for relationships in the collected data.\n8.\t\nSystems of systems These are systems, used in enterprises and other large organ-\nizations, that are composed of a number of other software systems. Some of \nthese may be generic software products, such as an ERP system. Other systems \nin the assembly may be specially written for that environment.\n", "page": 26, "type": "text", "section": "Page 26"}
{"text": "26\u2002 \u2002 Chapter 1\u2002 \u25a0\u2002 Introduction\nOf course, the boundaries between these system types are blurred. If you develop \na game for a phone, you have to take into account the same constraints (power, hard-\nware interaction) as the developers of the phone software. Batch processing systems \nare often used in conjunction with web-based transaction systems. For example, in a \ncompany, travel expense claims may be submitted through a web application but \nprocessed in a batch application for monthly payment.\nEach type of system requires specialized software engineering techniques because \nthe software has different characteristics. For example, an embedded control system \nin an automobile is safety-critical and is burned into ROM (read-only memory) \nwhen installed in the vehicle. It is therefore very expensive to change. Such a system \nneeds extensive verification and validation so that the chances of having to recall \ncars after sale to fix software problems are minimized. User interaction is minimal \n(or perhaps nonexistent), so there is no need to use a development process that relies \non user interface prototyping.\nFor an interactive web-based system or app, iterative development and delivery is \nthe best approach, with the system being composed of reusable components. \nHowever, such an approach may be impractical for a system of systems, where \ndetailed specifications of the system interactions have to be specified in advance so \nthat each system can be separately developed.\nNevertheless, there are software engineering fundamentals that apply to all types \nof software systems:\n1.\t\nThey should be developed using a managed and understood development pro-\ncess. The organization developing the software should plan the development \nprocess and have clear ideas of what will be produced and when it will be com-\npleted. Of course, the specific process that you should use depends on the type \nof software that you are developing.\n2.\t\nDependability and performance are important for all types of system. Software \nshould behave as expected, without failures, and should be available for use \nwhen it is required. It should be safe in its operation and, as far as possible, \nshould be secure against external attack. The system should perform efficiently \nand should not waste resources.\n3.\t\nUnderstanding and managing the software specification and requirements (what \nthe software should do) are important. You have to know what different custom-\ners and users of the system expect from it, and you have to manage their expec-\ntations so that a useful system can be delivered within budget and to schedule.\n4.\t\nYou should make effective use of existing resources. This means that, where \nappropriate, you should reuse software that has already been developed rather \nthan write new software.\nThese fundamental notions of process, dependability, requirements, manage-\nment, and reuse are important themes of this book. Different methods reflect them in \ndifferent ways, but they underlie all professional software development.\n", "page": 27, "type": "text", "section": "Page 27"}
{"text": "\t\n1.1\u2002 \u25a0\u2002 Professional software development\u2002 \u2002 27\nThese fundamentals are independent of the program language used for software \ndevelopment. I don\u2019t cover specific programming techniques in this book because \nthese vary dramatically from one type of system to another. For example, a dynamic \nlanguage, such as Ruby, is the right type of language for interactive system develop-\nment but is inappropriate for embedded systems engineering.\n \n1.1.3  Internet software engineering\nThe development of the Internet and the World Wide Web has had a profound \neffect on all of our lives. Initially, the web was primarily a universally accessible \ninformation store, and it had little effect on software systems. These systems ran \non local computers and were only accessible from within an organization. Around \n2000, the web started to evolve, and more and more functionality was added to \nbrowsers. This meant that web-based systems could be developed where, instead \nof a special-purpose user interface, these systems could be accessed using a web \nbrowser. This led to the development of a vast range of new system products that \ndelivered innovative services, accessed over the web. These are often funded by \nadverts that are displayed on the user\u2019s screen and do not involve direct payment \nfrom users.\nAs well as these system products, the development of web browsers that could \nrun small programs and do some local processing led to an evolution in business and \norganizational software. Instead of writing software and deploying it on users\u2019 PCs, \nthe software was deployed on a web server. This made it much cheaper to change \nand upgrade the software, as there was no need to install the software on every PC. \nIt also reduced costs, as user interface development is particularly expensive. \nWherever it has been possible to do so, businesses have moved to web-based inter-\naction with company software systems.\nThe notion of software as a service (Chapter 17) was proposed early in the 21st \ncentury This has now become the standard approach to the delivery of web-based \nsystem products such as Google Apps, Microsoft Office 365, and Adobe Creative \nSuite. More and more software runs on remote \u201cclouds\u201d instead of local servers and \nis accessed over the Internet. A computing cloud is a huge number of linked com-\nputer systems that is shared by many users. Users do not buy software but pay \naccording to how much the software is used or are given free access in return for \nwatching adverts that are displayed on their screen. If you use services such as web-\nbased mail, storage, or video, you are using a cloud-based system.\nThe advent of the web has led to a dramatic change in the way that business soft-\nware is organized. Before the web, business applications were mostly monolithic, \nsingle programs running on single computers or computer clusters. Communications \nwere local, within an organization. Now, software is highly distributed, sometimes \nacross the world. Business applications are not programmed from scratch but involve \nextensive reuse of components and programs.\nThis change in software organization has had a major effect on software engi-\nneering for web-based systems. For example:\n", "page": 28, "type": "text", "section": "Page 28"}
{"text": "28\u2002 \u2002 Chapter 1\u2002 \u25a0\u2002 Introduction\n1.\t\nSoftware reuse has become the dominant approach for constructing web-based \nsystems. When building these systems, you think about how you can assemble \nthem from preexisting software components and systems, often bundled together \nin a framework.\n2.\t\nIt is now generally recognized that it is impractical to specify all the require-\nments for such systems in advance. Web-based systems are always developed \nand delivered incrementally.\n3.\t\nSoftware may be implemented using service-oriented software engineering, \nwhere the software components are stand-alone web services. I discuss this \napproach to software engineering in Chapter 18.\n4.\t\nInterface development technology such as AJAX (Holdener 2008) and HTML5 \n(Freeman 2011) have emerged that support the creation of rich interfaces within \na web browser.\nThe fundamental ideas of software engineering, discussed in the previous section, \napply to web-based software, as they do to other types of software. Web-based sys-\ntems are getting larger and larger, so software engineering techniques that deal with \nscale and complexity are relevant for these systems.\n \n1.2  Software engineering ethics\nLike other engineering disciplines, software engineering is carried out within a \nsocial and legal framework that limits the freedom of people working in that area. As \na software engineer, you must accept that your job involves wider responsibilities \nthan simply the application of technical skills. You must also behave in an ethical \nand morally responsible way if you are to be respected as a professional engineer.\nIt goes without saying that you should uphold normal standards of honesty and \nintegrity. You should not use your skills and abilities to behave in a dishonest way or \nin a way that will bring disrepute to the software engineering profession. However, \nthere are areas where standards of acceptable behavior are not bound by laws but by \nthe more tenuous notion of professional responsibility. Some of these are:\n1.\t\nConfidentiality You should normally respect the confidentiality of your employ-\ners or clients regardless of whether or not a formal confidentiality agreement \nhas been signed.\n2.\t\nCompetence You should not misrepresent your level of competence. You should \nnot knowingly accept work that is outside your competence.\n3.\t\nIntellectual property rights You should be aware of local laws governing the \nuse of intellectual property such as patents and copyright. You should be careful \nto ensure that the intellectual property of employers and clients is protected.\n", "page": 29, "type": "text", "section": "Page 29"}
{"text": "\t\n1.2\u2002 \u25a0\u2002 Software engineering ethics\u2002 \u2002 29\n4.\t\nComputer misuse You should not use your technical skills to misuse other peo-\nple\u2019s computers. Computer misuse ranges from relatively trivial (game playing \non an employer\u2019s machine) to extremely serious (dissemination of viruses or \nother malware).\nProfessional societies and institutions have an important role to play in setting \nethical standards. Organizations such as the ACM, the IEEE (Institute of Electrical \nand Electronic Engineers), and the British Computer Society publish a code of pro-\nfessional conduct or code of ethics. Members of these organizations undertake to \nfollow that code when they sign up for membership. These codes of conduct are \ngenerally concerned with fundamental ethical behavior.\nProfessional associations, notably the ACM and the IEEE, have cooperated to \nproduce a joint code of ethics and professional practice. This code exists in both a \nshort form, shown in Figure 1.3, and a longer form (Gotterbarn, Miller, and Rogerson \n1999) that adds detail and substance to the shorter version. The rationale behind this \ncode is summarized in the first two paragraphs of the longer form:\nFigure 1.3\u2002 The ACM/\nIEEE Code of Ethics\nSoftware Engineering Code of Ethics and Professional Practice\nACM/IEEE-CS Joint Task Force on Software Engineering Ethics and Professional Practices\nPREAMBLE\nThe short version of the code summarizes aspirations at a high level of the abstraction; the clauses that are \nincluded in the full version give examples and details of how these aspirations change the way we act as soft-\nware engineering professionals. Without the aspirations, the details can become legalistic and tedious; without \nthe details, the aspirations can become high sounding but empty; together, the aspirations and the details form \na cohesive code.\nSoftware engineers shall commit themselves to making the analysis, specification, design, development, test-\ning, and maintenance of software a beneficial and respected profession. In accordance with their commitment \nto the health, safety, and welfare of the public, software engineers shall adhere to the following Eight Principles:\n1. PUBLIC \u2014 Software engineers shall act consistently with the public interest.\n2. CLIENT AND EMPLOYER \u2014 Software engineers shall act in a manner that is in the \nbest interests of their client and employer consistent with the public interest.\n3. PRODUCT \u2014 Software engineers shall ensure that their products and related \nmodifications meet the highest professional standards possible.\n4. JUDGMENT \u2014 Software engineers shall maintain integrity and independence in their \nprofessional judgment.\n5. MANAGEMENT \u2014 Software engineering managers and leaders shall subscribe to and \npromote an ethical approach to the management of software development and  \nmaintenance.\n6. PROFESSION \u2014 Software engineers shall advance the integrity and reputation of \nthe profession consistent with the public interest.\n7. COLLEAGUES \u2014 Software engineers shall be fair to and supportive of their  \ncolleagues.\n8. SELF \u2014 Software engineers shall participate in lifelong learning regarding  \nthe practice of their profession and shall promote an ethical approach to the \npractice of the profession.\n(ACM/IEEE-CS Joint \nTask Force on Software \nEngineering Ethics and \nProfessional Practices, \nshort version. http://\nwww.acm.org/about/ \nse-code)\n(\u00a9 1999 by the ACM, \nInc. and the IEEE, Inc.)\n", "page": 30, "type": "text", "section": "Page 30"}
{"text": "30\u2002 \u2002 Chapter 1\u2002 \u25a0\u2002 Introduction\nComputers have a central and growing role in commerce, industry, government, \nmedicine, education, entertainment and society at large. Software engineers are \nthose who contribute by direct participation or by teaching, to the analysis, spec-\nification, design, development, certification, maintenance and testing of software \nsystems. Because of their roles in developing software systems, software engi-\nneers have significant opportunities to do good or cause harm, to enable others to \ndo good or cause harm, or to influence others to do good or cause harm. To \nensure, as much as possible, that their efforts will be used for good, software \nengineers must commit themselves to making software engineering a beneficial \nand respected profession. In accordance with that commitment, software engi-\nneers shall adhere to the following Code of Ethics and Professional Practice\u2020.\nThe Code contains eight Principles related to the behaviour of and decisions \nmade by professional software engineers, including practitioners, educators, \nmanagers, supervisors and policy makers, as well as trainees and students of \nthe profession. The Principles identify the ethically responsible relationships \nin which individuals, groups, and organizations participate and the primary \nobligations within these relationships. The Clauses of each Principle are illus-\ntrations of some of the obligations included in these relationships. These obli-\ngations are founded in the software engineer\u2019s humanity, in special care owed \nto people affected by the work of software engineers, and the unique elements \nof the practice of software engineering. The Code prescribes these as obliga-\ntions of anyone claiming to be or aspiring to be a software engineer\u2020.\nIn any situation where different people have different views and objectives, you are \nlikely to be faced with ethical dilemmas. For example, if you disagree, in principle, with \nthe policies of more senior management in the company, how should you react? Clearly, \nthis depends on the people involved and the nature of the disagreement. Is it best to argue \na case for your position from within the organization or to resign in principle? If you feel \nthat there are problems with a software project, when do you reveal these problems to \nmanagement? If you discuss these while they are just a suspicion, you may be overreact-\ning to a situation; if you leave it too long, it may be impossible to resolve the difficulties.\nWe all face such ethical dilemmas in our professional lives, and, fortunately, in \nmost cases they are either relatively minor or can be resolved without too much dif-\nficulty. Where they cannot be resolved, the engineer is faced with, perhaps, another \nproblem. The principled action may be to resign from their job, but this may well \naffect others such as their partner or their children.\nA difficult situation for professional engineers arises when their employer acts in \nan unethical way. Say a company is responsible for developing a safety-critical \nsystem and, because of time pressure, falsifies the safety validation records. Is the \nengineer\u2019s responsibility to maintain confidentiality or to alert the customer or \npublicize, in some way, that the delivered system may be unsafe?\n\u2020ACM/IEEE-CS Joint Task Force on Software Engineering Ethics and Professional Practices, short  \nversion Preamble.  http://www.acm.org/about/se-code  Copyright \u00a9 1999 by the Association for  \nComputing Machinery, Inc. and the Institute for Electrical and Electronics Engineers, Inc.\n", "page": 31, "type": "text", "section": "Page 31"}
{"text": "\t\n1.3\u2002 \u25a0\u2002 Case studies\u2002 \u2002 31\nThe problem here is that there are no absolutes when it comes to safety. Although \nthe system may not have been validated according to predefined criteria, these \n\u00ad\ncriteria may be too strict. The system may actually operate safely throughout its life-\ntime. It is also the case that, even when properly validated, the system may fail and \ncause an accident. Early disclosure of problems may result in damage to the employer \nand other employees; failure to disclose problems may result in damage to others.\nYou must make up your own mind in these matters. The appropriate ethical posi-\ntion here depends on the views of the people involved. The potential for damage, the \nextent of the damage, and the people affected by the damage should influence the \ndecision. If the situation is very dangerous, it may be justified to publicize it using \nthe national press or social media. However, you should always try to resolve the \nsituation while respecting the rights of your employer.\nAnother ethical issue is participation in the development of military and nuclear \nsystems. Some people feel strongly about these issues and do not wish to participate in \nany systems development associated with defense systems. Others will work on mili-\ntary systems but not on weapons systems. Yet others feel that national security is an \noverriding principle and have no ethical objections to working on weapons systems.\nIn this situation, it is important that both employers and employees should make \ntheir views known to each other in advance. Where an organization is involved in \nmilitary or nuclear work, it should be able to specify that employees must be willing \nto accept any work assignment. Equally, if an employee is taken on and makes clear \nthat he or she does not wish to work on such systems, employers should not exert \npressure to do so at some later date.\nThe general area of ethics and professional responsibility is increasingly important \nas software-intensive systems pervade every aspect of work and everyday life. It can \nbe considered from a philosophical standpoint where the basic principles of ethics are \nconsidered and software engineering ethics are discussed with reference to these \nbasic principles. This is the approach taken by Laudon (Laudon 1995) and Johnson \n(Johnson 2001). More recent texts such as that by Tavani (Tavani 2013) introduce the \nnotion of cyberethics and cover both the philosophical background and practical and \nlegal issues. They include ethical issues for technology users as well as developers.\nI find that a philosophical approach is too abstract and difficult to relate to every-\nday experience so I prefer the more concrete approach embodied in professional \ncodes of conduct (Bott 2005; Duquenoy 2007). I think that ethics are best discussed \nin a software engineering context and not as a subject in its own right. Therefore, I \ndo not discuss software engineering ethics in an abstract way but include examples \nin the exercises that can be the starting point for a group discussion.\n \n1.3 Case studies\nTo illustrate software engineering concepts, I use examples from four different types \nof system. I have deliberately not used a single case study, as one of the key messages \nin this book is that software engineering practice depends on the type of systems \n", "page": 32, "type": "text", "section": "Page 32"}
{"text": "32\u2002 \u2002 Chapter 1\u2002 \u25a0\u2002 Introduction\nbeing produced. I therefore choose an appropriate example when discussing con-\ncepts such as safety and dependability, system modeling, reuse, etc.\nThe system types that I use as case studies are:\n1.\t\nAn embedded system This is a system where the software controls some hard-\nware device and is embedded in that device. Issues in embedded systems typi-\ncally include physical size, responsiveness, and power management, etc. The \nexample of an embedded system that I use is a software system to control an \ninsulin pump for people who have diabetes.\n2.\t\nAn information system The primary purpose of this type of system is to manage \nand provide access to a database of information. Issues in information systems \ninclude security, usability, privacy, and maintaining data integrity. The example \nof an information system used is a medical records system.\n3.\t\nA sensor-based data collection system This is a system whose primary purposes \nare to collect data from a set of sensors and to process that data in some way. \nThe key requirements of such systems are reliability, even in hostile environ-\nmental conditions, and maintainability. The example of a data collection system \nthat I use is a wilderness weather station.\n4.\t\nA support environment. This is an integrated collection of software tools that are \nused to support some kind of activity. Programming environments, such as \nEclipse (Vogel 2012) will be the most familiar type of environment for readers \nof this book. I describe an example here of a digital learning environment that \nis\u00a0used to support students\u2019 learning in schools.\nI introduce each of these systems in this chapter; more information about each of \nthem is available on the website (software-engineering-book.com).\n \n1.3.1  An insulin pump control system\nAn insulin pump is a medical system that simulates the operation of the pancreas (an \ninternal organ). The software controlling this system is an embedded system that \ncollects information from a sensor and controls a pump that delivers a controlled \ndose of insulin to a user.\nPeople who suffer from diabetes use the system. Diabetes is a relatively common \ncondition in which the human pancreas is unable to produce sufficient quantities of \na hormone called insulin. Insulin metabolizes glucose (sugar) in the blood. The con-\nventional treatment of diabetes involves regular injections of genetically engineered \ninsulin. Diabetics measure their blood sugar levels periodically using an external \nmeter and then estimate the dose of insulin they should inject.\nThe problem is that the level of insulin required does not just depend on the blood \nglucose level but also on the time of the last insulin injection. Irregular checking can \nlead to very low levels of blood glucose (if there is too much insulin) or very high \nlevels of blood sugar (if there is too little insulin). Low blood glucose is, in the short \nterm, a more serious condition as it can result in temporary brain malfunctioning and, \n", "page": 33, "type": "text", "section": "Page 33"}
{"text": "\t\n1.3\u2002 \u25a0\u2002 Case studies\u2002 \u2002 33\nultimately, unconsciousness and death. In the long term, however, continual high \nlevels of blood glucose can lead to eye damage, kidney damage, and heart problems.\nAdvances in developing miniaturized sensors have meant that it is now possible \nto develop automated insulin delivery systems. These systems monitor blood sugar \nlevels and deliver an appropriate dose of insulin when required. Insulin delivery \nsystems like this one are now available and are used by patients who find it difficult \nto control their insulin levels. In future, it may be possible for diabetics to have such \nsystems permanently attached to their bodies.\nA software-controlled insulin delivery system uses a microsensor embedded in \nthe patient to measure some blood parameter that is proportional to the sugar level. \nThis is then sent to the pump controller. This controller computes the sugar level and \nthe amount of insulin that is needed. It then sends signals to a miniaturized pump to \ndeliver the insulin via a permanently attached needle.\nFigure 1.4 shows the hardware components and organization of the insulin pump. \nTo understand the examples in this book, all you need to know is that the blood sensor \nmeasures the electrical conductivity of the blood under different conditions and that \nthese values can be related to the blood sugar level. The insulin pump delivers one unit \nof insulin in response to a single pulse from a controller. Therefore, to deliver 10 units \nof insulin, the controller sends 10 pulses to the pump. Figure 1.5 is a Unified Modeling \nNeedle\nassembly\nSensor\nDisplay1\nDisplay2\nAlarm\nPump\nClock\nController\nPower supply\nInsulin reservoir\nFigure 1.4\u2002 Insulin pump \nhardware architecture\nAnalyze sensor\nreading\nBlood\nsensor\nInsulin\npump\nBlood\nsugar\nCompute\ninsulin\nInsulin\ndose\nInsulin\nlog\nLog dose\nCompute pump\ncommands\nPump\ndata\nControl insulin\npump\nFigure 1.5\u2002 Activity \nmodel of the \ninsulin pump\n", "page": 34, "type": "text", "section": "Page 34"}
{"text": "34\u2002 \u2002 Chapter 1\u2002 \u25a0\u2002 Introduction\nLanguage (UML) activity model that illustrates how the software transforms an input \nblood sugar level to a sequence of commands that drive the insulin pump.\nClearly, this is a safety-critical system. If the pump fails to operate or does not \noperate correctly, then the user\u2019s health may be damaged or they may fall into a \ncoma because their blood sugar levels are too high or too low. This system must \ntherefore meet two essential high-level requirements:\n1.\t\nThe system shall be available to deliver insulin when required.\n2.\t\nThe system shall perform reliably and deliver the correct amount of insulin to \ncounteract the current level of blood sugar.\nThe system must therefore be designed and implemented to ensure that it always \nmeets these requirements. More detailed requirements and discussions of how to \nensure that the system is safe are discussed in later chapters.\n \n1.3.2  A patient information system for mental health care\nA patient information system to support mental health care (the Mentcare system) is a \nmedical information system that maintains information about patients suffering from \nmental health problems and the treatments that they have received. Most mental \nhealth patients do not require dedicated hospital treatment but need to attend special-\nist clinics regularly where they can meet a doctor who has detailed knowledge of their \nproblems. To make it easier for patients to attend, these clinics are not just run in \nhospitals. They may also be held in local medical practices or community centers.\nThe Mentcare system (Figure 1.6) is a patient information system that is intended \nfor use in clinics. It makes use of a centralized database of patient information but \nMentcare\nclient\nMentcare server\nPatient database\nMentcare\nclient\nMentcare\nclient\nNetwork\nFigure 1.6\u2002 The \norganization of the \nMentcare system\n", "page": 35, "type": "text", "section": "Page 35"}
{"text": "\t\n1.3\u2002 \u25a0\u2002 Case studies\u2002 \u2002 35\nhas also been designed to run on a laptop, so that it may be accessed and used from \nsites that do not have secure network connectivity. When the local systems have \nsecure network access, they use patient information in the database, but they can \ndownload and use local copies of patient records when they are disconnected. The \nsystem is not a complete medical records system and so does not maintain informa-\ntion about other medical conditions. However, it may interact and exchange data \nwith other clinical information systems.\nThis system has two purposes:\n1.\t\nTo generate management information that allows health service managers to \nassess performance against local and government targets.\n2.\t\nTo provide medical staff with timely information to support the treatment of \npatients.\nPatients who suffer from mental health problems are sometimes irrational and \ndisorganized so may miss appointments, deliberately or accidentally lose prescriptions \nand medication, forget instructions and make unreasonable demands on medical \nstaff. They may drop in on clinics unexpectedly. In a minority of cases, they may be \na danger to themselves or to other people. They may regularly change address or \nmay be homeless on a long-term or short-term basis. Where patients are dangerous, \nthey may need to be \u201csectioned\u201d\u2014that is, confined to a secure hospital for treatment \nand observation.\nUsers of the system include clinical staff such as doctors, nurses, and health visi-\ntors (nurses who visit people at home to check on their treatment). Nonmedical users \ninclude receptionists who make appointments, medical records staff who maintain \nthe records system, and administrative staff who generate reports.\nThe system is used to record information about patients (name, address, age, next \nof kin, etc.), consultations (date, doctor seen, subjective impressions of the patient, \netc.), conditions, and treatments. Reports are generated at regular intervals for medi-\ncal staff and health authority managers. Typically, reports for medical staff focus on \ninformation about individual patients, whereas management reports are anonymized \nand are concerned with conditions, costs of treatment, etc.\nThe key features of the system are:\n1.\t\nIndividual care management Clinicians can create records for patients, edit the \ninformation in the system, view patient history, and so on. The system supports \ndata summaries so that doctors who have not previously met a patient can \nquickly learn about the key problems and treatments that have been prescribed.\n2.\t\nPatient monitoring The system regularly monitors the records of patients that \nare involved in treatment and issues warnings if possible problems are detected. \nTherefore, if a patient has not seen a doctor for some time, a warning may be \nissued. One of the most important elements of the monitoring system is to keep \ntrack of patients who have been sectioned and to ensure that the legally required \nchecks are carried out at the right time.\n", "page": 36, "type": "text", "section": "Page 36"}
{"text": "36\u2002 \u2002 Chapter 1\u2002 \u25a0\u2002 Introduction\n3.\t\nAdministrative reporting The system generates monthly management reports \nshowing the number of patients treated at each clinic, the number of patients \nwho have entered and left the care system, the number of patients sectioned, the \ndrugs prescribed and their costs, etc.\nTwo different laws affect the system: laws on data protection that govern the con-\nfidentiality of personal information and mental health laws that govern the compul-\nsory detention of patients deemed to be a danger to themselves or others. Mental \nhealth is unique in this respect as it is the only medical speciality that can recommend \nthe detention of patients against their will. This is subject to strict legislative safe-\nguards. One aim of the Mentcare system is to ensure that staff always act in accord-\nance with the law and that their decisions are recorded for judicial review if necessary.\nAs in all medical systems, privacy is a critical system requirement. It is essential \nthat patient information is confidential and is never disclosed to anyone apart from \nauthorized medical staff and the patient themselves. The Mentcare system is also a \nsafety-critical system. Some mental illnesses cause patients to become suicidal or a \ndanger to other people. Wherever possible, the system should warn medical staff \nabout potentially suicidal or dangerous patients.\nThe overall design of the system has to take into account privacy and safety \nrequirements. The system must be available when needed; otherwise safety may be \ncompromised, and it may be impossible to prescribe the correct medication to patients. \nThere is a potential conflict here. Privacy is easiest to maintain when there is only a \nsingle copy of the system data. However, to ensure availability in the event of server \nfailure or when disconnected from a network, multiple copies of the data should be \nmaintained. I discuss the trade-offs between these requirements in later chapters.\n \n1.3.3  A wilderness weather station\nTo help monitor climate change and to improve the accuracy of weather forecasts in \nremote areas, the government of a country with large areas of wilderness decides to \ndeploy several hundred weather stations in remote areas. These weather stations col-\nlect data from a set of instruments that measure temperature and pressure, sunshine, \nrainfall, wind speed and wind direction.\nWilderness weather stations are part of a larger system (Figure 1.7), which is a \nweather information system that collects data from weather stations and makes it \navailable to other systems for processing. The systems in Figure 1.7 are:\n1.\t\nThe weather station system This system is responsible for collecting weather \ndata, carrying out some initial data processing, and transmitting it to the data \nmanagement system.\n2.\t\nThe data management and archiving system This system collects the data from \nall of the wilderness weather stations, carries out data processing and analysis, \nand archives the data in a form that can be retrieved by other systems, such as \nweather forecasting systems.\n", "page": 37, "type": "text", "section": "Page 37"}
{"text": "\t\n1.3\u2002 \u25a0\u2002 Case studies\u2002 \u2002 37\n3.\t\nThe station maintenance system This system can communicate by satellite with \nall wilderness weather stations to monitor the health of these systems and pro-\nvide reports of problems. It can update the embedded software in these systems. \nIn the event of system problems, this system can also be used to remotely con-\ntrol the weather station.\nIn Figure 1.7, I have used the UML package symbol to indicate that each system is \na collection of components and the separate systems are identified using the UML \n\u00ad\nstereotype \u00absystem\u00bb. The associations between the packages indicate there is an exchange \nof\u00a0information but, at this stage, there is no need to define them in any more detail.\nThe weather stations include instruments that measure weather parameters such \nas wind speed and direction, ground and air temperatures, barometric pressure, and \nrainfall over a 24-hour period. Each of these instruments is controlled by a software \nsystem that takes parameter readings periodically and manages the data collected \nfrom the instruments.\nThe weather station system operates by collecting weather observations at fre-\nquent intervals; for example, temperatures are measured every minute. However, \nbecause the bandwidth to the satellite is relatively narrow, the weather station carries \nout some local processing and aggregation of the data. It then transmits this aggre-\ngated data when requested by the data collection system. If it is impossible to make \na connection, then the weather station maintains the data locally until communica-\ntion can be resumed.\nEach weather station is battery-powered and must be entirely self-contained; there \nare no external power or network cables. All communications are through a relatively \nslow satellite link, and the weather station must include some mechanism (solar or \nwind power) to charge its batteries. As they are deployed in wilderness areas, they are \nexposed to severe environmental conditions and may be damaged by animals. The \nstation software is therefore not just concerned with data collection. It must also:\n1.\t\nMonitor the instruments, power. and communication hardware and report faults \nto the management system.\n2.\t\nManage the system power, ensuring that batteries are charged whenever the \nenvironmental conditions permit but also that generators are shut down in \npotentially damaging weather conditions, such as high wind.\n\u00absystem\u00bb\nData management\nand archiving\n\u00absystem\u00bb\nStation maintenance\n\u00absystem\u00bb\nWeather station\nFigure 1.7\u2002 The weather \nstation\u2019s environment\n", "page": 38, "type": "text", "section": "Page 38"}
{"text": "38\u2002 \u2002 Chapter 1\u2002 \u25a0\u2002 Introduction\n3.\t\nAllow for dynamic reconfiguration where parts of the software are replaced \nwith new versions and where backup instruments are switched into the system \nin the event of system failure.\nBecause weather stations have to be self-contained and unattended, this means \nthat the software installed is complex, even though the data collection functionality \nis fairly simple.\n \n1.3.4  A digital learning environment for schools\nMany teachers argue that using interactive software systems to support education \ncan lead to both improved learner motivation and a deeper level of knowledge and \nunderstanding in students. However, there is no general agreement on the \u2018best\u2019 \nstrategy for computer-supported learning, and teachers in practice use a range of dif-\nferent interactive, web-based tools to support learning. The tools used depend on the \nages of the learners, their cultural background, their experience with computers, \nequipment available, and the preferences of the teachers involved.\nA digital learning environment is a framework in which a set of general-purpose \nand specially designed tools for learning may be embedded, plus a set of applica-\ntions that are geared to the needs of the learners using the system. The framework \nprovides general services such as an authentication service, synchronous and asyn-\nchronous communication services, and a storage service.\nThe tools included in each version of the environment are chosen by teachers and \nlearners to suit their specific needs. These can be general applications such as spread-\nsheets, learning management applications such as a Virtual Learning Environment \n(VLE) to manage homework submission and assessment, games, and simulations. \nThey may also include specific content, such as content about the American Civil \nWar and applications to view and annotate that content.\nFigure 1.8 is a high-level architectural model of a digital learning environment \n(iLearn) that was designed for use in schools for students from 3 to 18 years of \nage. The approach adopted is that this is a distributed system in which all compo-\nnents of the environment are services that can be accessed from anywhere on the \nInternet. There is no requirement that all of the learning tools are gathered together \nin one place.\nThe system is a service-oriented system with all system components considered \nto be a replaceable service. There are three types of service in the system:\n1.\t\nUtility services that provide basic application-independent functionality and \nthat may be used by other services in the system. Utility services are usually \ndeveloped or adapted specifically for this system.\n2.\t\nApplication services that provide specific applications such as email, conferencing, \nphoto sharing, etc., and access to specific educational content such as scientific \nfilms or historical resources. Application services are external services that are \neither specifically purchased for the system or are available freely over the Internet.\n", "page": 39, "type": "text", "section": "Page 39"}
{"text": "\t\n1.3\u2002 \u25a0\u2002 Case studies\u2002 \u2002 39\n3.\t\nConfiguration services that are used to adapt the environment with a specific set \nof application services and to define how services are shared between students, \nteachers, and their parents.\nThe environment has been designed so that services can be replaced as new ser-\nvices become available and to provide different versions of the system that are suited \nfor the age of the users. This means that the system has to support two levels of ser-\nvice integration:\n1.\t\nIntegrated services are services that offer an API (application programming \ninterface) and that can be accessed by other services through that API. Direct \nservice-to-service communication is therefore possible. An authentication ser-\nvice is an example of an integrated service. Rather than use their own authenti-\ncation mechanisms, an authentication service may be called on by other services \nto authenticate users. If users are already authenticated, then the authentication \nservice may pass authentication information directly to another service, via an \nAPI, with no need for users to reauthenticate themselves.\n2.\t\nIndependent services are services that are simply accessed through a browser \ninterface and that operate independently of other services. Information can only \nbe shared with other services through explicit user actions such as copy and \npaste; reauthentication may be required for each independent service.\nIf an independent service becomes widely used, the development team may then \nintegrate that service so that it becomes an integrated and supported service.\nAuthentication\nBrowser-based user interface\nConfiguration services\nGroup\nmanagement\nApplication\nmanagement\nIdentity\nmanagement\nUser storage\nLogging and monitoring\nApplication storage\nInterfacing\nSearch\nUtility services\nApplication services\niLearn app\nEmail   Messaging   Video conferencing  Newspaper archive\nWord processing   Simulation   Video storage   Resource finder\nSpreadsheet   Virtual learning environment   History archive\nFigure 1.8\u2002 The \narchitecture of a \ndigital learning \nenvironment (iLearn)\n", "page": 40, "type": "text", "section": "Page 40"}
{"text": "40\u2002 \u2002 Chapter 1\u2002 \u25a0\u2002 Introduction\nFurther Reading\n\u201cSoftware Engineering Code of Ethics Is Approved.\u201d An article that discusses the background to the \ndevelopment of the ACM/IEEE Code of Ethics and that includes both the short and long form of the \ncode. (Comm. ACM, D. Gotterbarn, K. Miller, and S. Rogerson, October 1999). http://dx.doi.\norg/10.1109/MC.1999.796142\n\u201cA View of 20th and 21st Century Software Engineering.\u201d A backward and forward look at software \nengineering from one of the first and most distinguished software engineers. Barry Boehm identifies \ntimeless software engineering principles but also suggests that some commonly used practices are \nobsolete. (B. Boehm, Proc. 28th Software Engineering Conf., Shanghai. 2006). http://dx.doi.\norg/10.1145/1134285.1134288\n\u201cSoftware Engineering Ethics.\u201d Special issue of IEEE Computer, with several papers on the topic \n(IEEE Computer, 42 (6), June 2009).\nEthics for the Information Age. This is a wide-ranging book that covers all aspects of information \ntechnology (IT) ethics, not simply ethics for software engineers. I think this is the right approach  \nas you really need to understand software engineering ethics within a wider ethical framework  \n(M. J. Quinn, 2013, Addison-Wesley).\nKey Points\n\u25a0\t Software engineering is an engineering discipline that is concerned with all aspects of software \nproduction.\n\u25a0\t Software is not just a program or programs but also includes all electronic documentation that \nis needed by system users, quality assurance staff, and developers. Essential software product \nattributes are maintainability, dependability and security, efficiency, and acceptability.\n\u25a0\t The software process includes all of the activities involved in software development. The high-level \nactivities of specification, development, validation, and evolution are part of all software processes.\n\u25a0\t There are many different types of system, and each requires appropriate software engineering \ntools and techniques for their development. Few, if any, specific design and implementation \ntechniques are applicable to all kinds of system.\n\u25a0\t The fundamental ideas of software engineering are applicable to all types of software system. \nThese fundamentals include managed software processes, software dependability and security, \nrequirements engineering, and software reuse.\n\u25a0\t Software engineers have responsibilities to the engineering profession and society. They should \nnot simply be concerned with technical issues but should be aware of the ethical issues that \naffect their work.\n\u25a0\t Professional societies publish codes of conduct that embed ethical and professional standards. \nThese set out the standards of behavior expected of their members.\n", "page": 41, "type": "text", "section": "Page 41"}
{"text": "\t\n1.1\u2002 \u25a0\u2002 Case studies\u2002 \u2002 41\n\t\nChapter 1\u2002 \u25a0\u2002 Exercises\u2002 \u2002 41\nThe Essence of Software Engineering: Applying the SEMAT kernel. This book discusses the idea of a \nuniversal framework that can underlie all software engineering methods. It can be adapted and \nused for all types of systems and organizations. I am personally skeptical about whether or not a \nuniversal approach is realistic in practice, but the book has some interesting ideas that are worth \nexploring. (I. Jacobsen, P-W Ng, P. E. McMahon, I. Spence, and S. Lidman, 2013, Addison-Wesley)\nWebsite\nPowerPoint slides for this chapter:\nwww.pearsonglobaleditions.com/Sommerville\nLinks to supporting videos:\nhttp://software-engineering-book.com/videos/software-engineering/\nLinks to case study descriptions:\nhttp://software-engineering-book.com/case-studies/\nExercises\n\u2002 1.1. \tExplain why professional software that is developed for a customer is not simply the \nprograms that have been developed and delivered.\n\u2002 1.2. \tWhat is the most important difference between generic software product development and custom \nsoftware development? What might this mean in practice for users of generic software products?\n\u2002 1.3. \tBriefly discuss why it is usually cheaper in the long run to use software engineering methods \nand techniques for software systems.\n\u2002 1.4. \tSoftware engineering is not only concerned with issues like system heterogeneity, business \nand social change, trust, and security, but also with ethical issues affecting the domain. Give \nsome examples of ethical issues that have an impact on the software engineering domain.\n\u2002 1.5. \tBased on your own knowledge of some of the application types discussed in Section 1.1.2, \nexplain, with examples, why different application types require specialized software \nengineering techniques to support their design and development.\n\u2002 1.6. \tExplain why the fundamental software engineering principles of process, dependability, \nrequirements management, and reuse are relevant to all types of software system.\n\u2002 1.7. \tExplain how electronic connectivity between various development teams can support \nsoftware engineering activities.\n\u2002 1.8. \tNoncertified individuals are still allowed to practice software engineering. Discuss some of the \npossible drawbacks of this.\n", "page": 42, "type": "text", "section": "Page 42"}
{"text": "42\u2002 \u2002 Chapter 1\u2002 \u25a0\u2002 Introduction\n\u2002 1.9. \tFor each of the clauses in the ACM/IEEE Code of Ethics shown in Figure 1.4, propose an \nappropriate example that illustrates that clause.\n1.10. \tThe \u201cDrone Revolution\u201d is currently being debated and discussed all over the world. Drones \nare unmanned flying machines that are built and equipped with various kinds of software \nsystems that allow them to see, hear, and act. Discuss some of the societal challenges of \nbuilding such kinds of systems.\nReferences\nBott, F. 2005. Professional Issues in Information Technology. Swindon, UK: British Computer \nSociety.\nDuquenoy, P. 2007. Ethical, Legal and Professional Issues in Computing. London: Thomson \nLearning.\nFreeman, A. 2011. The Definitive Guide to HTML5. New York: Apress.\nGotterbarn, D., K. Miller, and S. Rogerson. 1999. \u201cSoftware Engineering Code of Ethics Is Approved.\u201d \nComm. ACM 42 (10): 102\u2013107. doi:10.1109/MC.1999.796142.\nHoldener, A. T. 2008. Ajax: The Definitive Guide. Sebastopol, CA: O\u2019Reilly and Associates.\nJacobson, I., P-W. Ng, P. E. McMahon, I. Spence, and S. Lidman. 2013. The Essence of Software \nEngineering. Boston: Addison-Wesley.\nJohnson, D. G. 2001. Computer Ethics. Englewood Cliffs, NJ: Prentice-Hall.\nLaudon, K. 1995. \u201cEthical Concepts and Information Technology.\u201d Comm. ACM 38 (12): 33\u201339. \ndoi:10.1145/219663.219677.\nNaur, P., and Randell, B. 1969. Software Engineering: Report on a conference sponsored by the NATO \nScience Committee. Brussels. http://homepages.cs.ncl.ac.uk/brian.randell/NATO/nato1968.pdf\nTavani, H. T. 2013. Ethics and Technology: Controversies, Questions, and Strategies for Ethical \nComputing, 4th ed. New York: John Wiley & Sons.\nVogel, L. 2012. Eclipse 4 Application Development: The Complete Guide to Eclipse 4 RCP \nDevelopment. Sebastopol, CA: O\u2019Reilly & Associates.\n", "page": 43, "type": "text", "section": "Page 43"}
{"text": "Software processes\n2\nObjectives\nThe objective of this chapter is to introduce you to the idea of a software \nprocess\u2014a coherent set of activities for software production. When you \nhave read this chapter, you will:\n\u25a0\t understand the concepts of software processes and software \nprocess\u00a0models;\n\u25a0\t have been introduced to three general software process models and \nwhen they might be used;\n\u25a0\t know about the fundamental process activities of software requirements \nengineering, software development, testing, and evolution;\n\u25a0\t understand why processes should be organized to cope with changes \nin the software requirements and design;\n\u25a0\t understand the notion of software process improvement and the \nfactors that affect software process quality.\nContents\n2.1 \tSoftware process models\n2.2 \tProcess activities\n2.3 \tCoping with change\n2.4 \tProcess improvement\n", "page": 44, "type": "text", "section": "Page 44"}
{"text": "44\u2002 \u2002 Chapter 2\u2002 \u25a0\u2002 Software processes\nA software process is a set of related activities that leads to the production of a soft-\nware system. As I discussed in Chapter 1, there are many different types of software \nsystems, and there is no universal software engineering method that is applicable to \nall of them. Consequently, there is no universally applicable software process. The \nprocess used in different companies depends on the type of software being devel-\noped, the requirements of the software customer, and the skills of the people writing \nthe software.\nHowever, although there are many different software processes, they all must \ninclude, in some form, the four fundamental software engineering activities that I \nintroduced in Chapter 1:\n1.\t\nSoftware specification The functionality of the software and constraints on its \noperation must be defined.\n2.\t\nSoftware development The software to meet the specification must be produced.\n3.\t\nSoftware validation The software must be validated to ensure that it does what \nthe customer wants.\n4.\t\nSoftware evolution The software must evolve to meet changing customer needs.\nThese activities are complex activities in themselves, and they include subactivi-\nties such as requirements validation, architectural design, and unit testing. Processes \nalso include other activities, such as software configuration management and project \nplanning that support production activities.\nWhen we describe and discuss processes, we usually talk about the activities in \nthese processes, such as specifying a data model and designing a user interface, and \nthe ordering of these activities. We can all relate to what people do to develop soft-\nware. However, when describing processes, it is also important to describe who is \ninvolved, what is produced, and conditions that influence the sequence of activities:\n1.\t\nProducts or deliverables are the outcomes of a process activity. For example, the \noutcome of the activity of architectural design may be a model of the software \narchitecture.\n2.\t\nRoles reflect the responsibilities of the people involved in the process. Examples \nof roles are project manager, configuration manager, and programmer.\n3.\t\nPre- and postconditions are conditions that must hold before and after a process \nactivity has been enacted or a product produced. For example, before architec-\ntural design begins, a precondition may be that the consumer has approved all \nrequirements; after this activity is finished, a postcondition might be that the \nUML models describing the architecture have been reviewed.\nSoftware processes are complex and, like all intellectual and creative processes, \nrely on people making decisions and judgments. As there is no universal process that \nis right for all kinds of software, most software companies have developed their own \n", "page": 45, "type": "text", "section": "Page 45"}
{"text": "\t\n2.1\u2002 \u25a0\u2002 Software process models\u2002 \u2002 45\ndevelopment processes. Processes have evolved to take advantage of the capabilities \nof the software developers in an organization and the characteristics of the systems \nthat are being developed. For safety-critical systems, a very structured development \nprocess is required where detailed records are maintained. For business systems, with \nrapidly changing requirements, a more flexible, agile process is likely to be better.\nAs I discussed in Chapter 1, professional Professional software development is a \nmanaged activity, so planning is an inherent part of all processes. Plan-driven pro-\ncesses are processes where all of the process activities are planned in advance and \nprogress is measured against this plan. In agile processes, which I discuss in Chapter 3, \nplanning is incremental and continual as the software is developed. It is therefore eas-\nier to change the process to reflect changing customer or product requirements. As \nBoehm and Turner (Boehm and Turner 2004) explain, each approach is suitable for \ndifferent types of software. Generally, for large systems, you need to find a balance \nbetween plan-driven and agile processes.\nAlthough there is no universal software process, there is scope for process improve-\nment in many organizations. Processes may include outdated techniques or may not \ntake advantage of the best practice in industrial software engineering. Indeed, many \norganizations still do not take advantage of software engineering methods in their \nsoftware development. They can improve their process by introducing techniques \nsuch as UML modeling and test-driven development. I discuss software process \nimprovement briefly later in thischapter text and in more detail in web Chapter 26.\n \n2.1  Software process models\nAs I explained in Chapter 1, a software process model (sometimes called a Software \nDevelopment Life Cycle or SDLC model) is a simplified representation of a soft-\nware process. Each process model represents a process from a particular perspective \nand thus only provides partial information about that process. For example, a pro-\ncess activity model shows the activities and their sequence but may not show the \nroles of the people involved in these activities. In this section, I introduce a number \nof very general process models (sometimes called process paradigms) and present \nthese from an architectural perspective. That is, we see the framework of the process \nbut not the details of process activities.\nThese generic models are high-level, abstract descriptions of software processes \nthat can be used to explain different approaches to software development. You can \nthink of them as process frameworks that may be extended and adapted to create \nmore specific software engineering processes.\nThe general process models that I cover here are:\n1.\t\nThe waterfall model This takes the fundamental process activities of specifica-\ntion, development, validation, and evolution and represents them as separate \nprocess phases such as requirements specification, software design, implemen-\ntation, and testing.\n", "page": 46, "type": "text", "section": "Page 46"}
{"text": "46\u2002 \u2002 Chapter 2\u2002 \u25a0\u2002 Software processes\n2.\t\nIncremental development This approach interleaves the activities of specifica-\ntion, development, and validation. The system is developed as a series of versions \n(increments), with each version adding functionality to the previous version.\n3.\t Integration and configuration This approach relies on the availability of reus-\nable components or systems. The system development process focuses on \nconfiguring these components for use in a new setting and integrating them \ninto a system.\nAs I have said, there is no universal process model that is right for all kinds of \nsoftware development. The right process depends on the customer and regulatory \nrequirements, the environment where the software will be used, and the type of soft-\nware being developed. For example, safety-critical software is usually developed \nusing a waterfall process as lots of analysis and documentation is required before \nimplementation begins. Software products are now always developed using an incre-\nmental process model. Business systems are increasingly being developed by con-\nfiguring existing systems and integrating these to create a new system with the \nfunctionality that is required.\nThe majority of practical software processes are based on a general model but \noften incorporate features of other models. This is particularly true for large systems \nengineering. For large systems, it makes sense to combine some of the best features \nof all of the general processes. You need to have information about the essential \nsystem requirements to design a software architecture to support these requirements. \nYou cannot develop this incrementally. Subsystems within a larger system may be \ndeveloped using different approaches. Parts of the system that are well understood \ncan be specified and developed using a waterfall-based process or may be bought in \nas off-the-shelf systems for configuration. Other parts of the system, which are dif-\nficult to specify in advance, should always be developed using an incremental \napproach. In both cases, software components are likely to be reused.\nVarious attempts have been made to develop \u201cuniversal\u201d process models that \ndraw on all of these general models. One of the best known of these universal \u00ad\nmodels \nis the Rational Unified Process (RUP) (Krutchen 2003), which was developed by \nRational, a U.S. software engineering company. The RUP is a flexible model that \nThe Rational Unified Process\nThe Rational Unified Process (RUP) brings together elements of all of the general process models discussed \nhere and supports prototyping and incremental delivery of software (Krutchen 2003). The RUP is normally \ndescribed from three perspectives: a dynamic perspective that shows the phases of the model in time, a static \nperspective that shows process activities, and a practice perspective that suggests good practices to be used in \nthe process. Phases of the RUP are inception, where a business case for the system is established; elaboration, \nwhere requirements and architecture are developed; construction where the software is implemented; and  \ntransition, where the system is deployed.\nhttp://software-engineering-book.com/web/rup/\n", "page": 47, "type": "text", "section": "Page 47"}
{"text": "\t\n2.1\u2002 \u25a0\u2002 Software process models\u2002 \u2002 47\ncan be instantiated in different ways to create processes that resemble any of the \ngeneral process models discussed here. The RUP has been adopted by some large \nsoftware companies (notably IBM), but it has not gained widespread acceptance.\n\t\n2.1.1 \t The waterfall model\nThe first published model of the software development process was derived from \nengineering process models used in large military systems engineering (Royce \n1970). It presents the software development process as a number of stages, as shown \nin Figure 2.1. Because of the cascade from one phase to another, this model is known \nas the waterfall model or software life cycle. The waterfall model is an example of a \nplan-driven process. In principle at least, you plan and schedule all of the process \nactivities before starting software development.\nThe stages of the waterfall model directly reflect the fundamental software devel-\nopment activities:\n1.\t\nRequirements analysis and definition The system\u2019s services, constraints, and \ngoals are established by consultation with system users. They are then defined \nin detail and serve as a system specification.\n2.\t\nSystem and software design The systems design process allocates the require-\nments to either hardware or software systems. It establishes an overall system \narchitecture. Software design involves identifying and describing the funda-\nmental software system abstractions and their relationships.\n3.\t\nImplementation and unit testing During this stage, the software design is real-\nized as a set of programs or program units. Unit testing involves verifying that \neach unit meets its specification.\nRequirements\ndefinition\nSystem and\nsoftware design\nImplementation\nand unit testing\nIntegration and\nsystem testing\nOperation and\nmaintenance\nFigure 2.1\u2002 The  \nwaterfall model\n", "page": 48, "type": "text", "section": "Page 48"}
{"text": "48\u2002 \u2002 Chapter 2\u2002 \u25a0\u2002 Software processes\n4.\t Integration and system testing The individual program units or programs are \nintegrated and tested as a complete system to ensure that the software \nrequirements have been met. After testing, the software system is delivered \nto the customer.\n5.\t\nOperation and maintenance Normally, this is the longest life-cycle phase. The \nsystem is installed and put into practical use. Maintenance involves correcting \nerrors that were not discovered in earlier stages of the life cycle, improving the \nimplementation of system units, and enhancing the system\u2019s services as new \nrequirements are discovered.\nIn principle, the result of each phase in the waterfall model is one or more docu-\nments that are approved (\u201csigned off\u201d). The following phase should not start until \nthe previous phase has finished. For hardware development, where high manufactur-\ning costs are involved, this makes sense. However, for software development, these \nstages overlap and feed information to each other. During design, problems with \nrequirements are identified; during coding design problems are found, and so on. \nThe software process, in practice, is never a simple linear model but involves feed-\nback from one phase to another.\nAs new information emerges in a process stage, the documents produced at previ-\nous stages should be modified to reflect the required system changes. For example, \nif it is discovered that a requirement is too expensive to implement, the requirements \ndocument should be changed to remove that requirement. However, this requires \ncustomer approval and delays the overall development process.\nAs a result, both customers and developers may prematurely freeze the software \nspecification so that no further changes are made to it. Unfortunately, this means that \nproblems are left for later resolution, ignored, or programmed around. Premature \nfreezing of requirements may mean that the system won\u2019t do what the user wants. It \nmay also lead to badly structured systems as design problems are circumvented by \nimplementation tricks.\nDuring the final life-cycle phase (operation and maintenance) the software is put \ninto use. Errors and omissions in the original software requirements are discovered. \nBoehm\u2019s spiral process model\nBarry Boehm, one of the pioneers in software engineering, proposed an incremental process model that was \nrisk-driven. The process is represented as a spiral rather than a sequence of activities (Boehm 1988).\nEach loop in the spiral represents a phase of the software process. Thus, the innermost loop might be con-\ncerned with system feasibility, the next loop with requirements definition, the next loop with system design, \nand so on. The spiral model combines change avoidance with change tolerance. It assumes that changes are \na\u00a0result of project risks and includes explicit risk management activities to reduce these risks.\nhttp://software-engineering-book.com/web/spiral-model/\n", "page": 49, "type": "text", "section": "Page 49"}
{"text": "Program and design errors emerge, and the need for new functionality is identified. \nThe system must therefore evolve to remain useful. Making these changes (software \nmaintenance) may involve repeating previous process stages.\nIn reality, software has to be flexible and accommodate change as it is being \ndeveloped. The need for early commitment and system rework when changes are \nmade means that the waterfall model is only appropriate for some types of system:\n1.\t\nEmbedded systems where the software has to interface with hardware systems. \nBecause of the inflexibility of hardware, it is not usually possible to delay deci-\nsions on the software\u2019s functionality until it is being implemented.\n2.\t\nCritical systems where there is a need for extensive safety and security analysis \nof the software specification and design. In these systems, the specification and \ndesign documents must be complete so that this analysis is possible. Safety-\nrelated problems in the specification and design are usually very expensive to \ncorrect at the implementation stage.\n3.\t\nLarge software systems that are part of broader engineering systems developed \nby several partner companies. The hardware in the systems may be developed \nusing a similar model, and companies find it easier to use a common model for \nhardware and software. Furthermore, where several companies are involved, \ncomplete specifications may be needed to allow for the independent develop-\nment of different subsystems.\nThe waterfall model is not the right process model in situations where informal \nteam communication is possible and software requirements change quickly. Iterative \ndevelopment and agile methods are better for these systems.\nAn important variant of the waterfall model is formal system development, where \na mathematical model of a system specification is created. This model is then refined, \nusing mathematical transformations that preserve its consistency, into executable \ncode. Formal development processes, such as that based on the B method (Abrial \n2005, 2010), are mostly used in the development of software systems that have strin-\ngent safety, reliability, or security requirements. The formal approach simplifies the \nproduction of a safety or security case. This demonstrates to customers or regulators \nthat the system actually meets its safety or security requirements. However, because \nof the high costs of developing a formal specification, this development model is \nrarely used except for critical systems engineering.\n\t\n2.1.2 \t Incremental development\nIncremental development is based on the idea of developing an initial implementa-\ntion, getting feedback from users and others, and evolving the software through \nseveral versions until the required system has been developed (Figure 2.2). \nSpecification, development, and validation activities are interleaved rather than \n\u00ad\nseparate, with rapid feedback across activities.\n\t\n2.1\u2002 \u25a0\u2002 Software process models\u2002 \u2002 49\n", "page": 50, "type": "text", "section": "Page 50"}
{"text": "50\u2002 \u2002 Chapter 2\u2002 \u25a0\u2002 Software processes\nIncremental development in some form is now the most common approach for \nthe development of application systems and software products. This approach can \nbe either plan-driven, agile or, more usually, a mixture of these approaches. In a \nplan-driven approach, the system increments are identified in advance; if an agile \napproach is adopted, the early increments are identified, but the development of \nlater increments depends on progress and customer priorities.\nIncremental software development, which is a fundamental part of agile \ndevelopment methods, is better than a waterfall approach for systems whose \nrequirements are likely to change during the development process. This is the \ncase for most business systems and software products. Incremental development \nreflects the way that we solve problems. We rarely work out a complete prob-\nlem solution in advance but move toward a solution in a series of steps, back-\ntracking when we realize that we have made a mistake. By developing the \nsoftware incrementally, it is cheaper and easier to make changes in the software \nas it is being developed.\nEach increment or version of the system incorporates some of the functional-\nity that is needed by the customer. Generally, the early increments of the system \ninclude the most important or most urgently required functionality. This means \nthat the customer or user can evaluate the system at a relatively early stage in \nthe development to see if it delivers what is required. If not, then only the cur-\nrent increment has to be changed and, possibly, new functionality defined for \nlater increments.\nIncremental development has three major advantages over the waterfall model:\n1.\t\nThe cost of implementing requirements changes is reduced. The amount of \nanalysis and documentation that has to be redone is significantly less than is \nrequired with the waterfall model.\n2.\t\nIt is easier to get customer feedback on the development work that has been \ndone. Customers can comment on demonstrations of the software and see how \nConcurrent\nactivities\nValidation\nFinal\nversion\nDevelopment\nIntermediate\nversions\nSpecification\nInitial\nversion\nOutline\ndescription\nFigure 2.2\u2002 Incremental \ndevelopment\n", "page": 51, "type": "text", "section": "Page 51"}
{"text": "much has been implemented. Customers find it difficult to judge progress from \nsoftware design documents.\n3.\t\nEarly delivery and deployment of useful software to the customer is possible, \neven if all of the functionality has not been included. Customers are able to use \nand gain value from the software earlier than is possible with a waterfall process.\nFrom a management perspective, the incremental approach has two problems:\n1.\t\nThe process is not visible. Managers need regular deliverables to measure pro-\ngress. If systems are developed quickly, it is not cost effective to produce docu-\nments that reflect every version of the system.\n2.\t\nSystem structure tends to degrade as new increments are added. Regular change \nleads to messy code as new functionality is added in whatever way is possible. \nIt becomes increasingly difficult and costly to add new features to a system. To \nreduce structural degradation and general code messiness, agile methods sug-\ngest that you should regularly refactor (improve and restructure) the software.\nThe problems of incremental development become particularly acute for large, \ncomplex, long-lifetime systems, where different teams develop different parts of the \nsystem. Large systems need a stable framework or architecture, and the responsi-\nbilities of the different teams working on parts of the system need to be clearly \ndefined with respect to that architecture. This has to be planned in advance rather \nthan developed incrementally.\nIncremental development does not mean that you have to deliver each increment \nto the system customer. You can develop a system incrementally and expose it to \ncustomers and other stakeholders for comment, without necessarily delivering it \nand deploying it in the customer\u2019s environment. Incremental delivery (covered in \nSection 2.3.2) means that the software is used in real, operational processes, so user \nfeedback is likely to be realistic. However, providing feedback is not always possi-\nble as experimenting with new software can disrupt normal business processes.\nProblems with incremental development\nAlthough incremental development has many advantages, it is not problem free. The primary cause of the \ndifficulty is the fact that large organizations have bureaucratic procedures that have evolved over time and  \nthere may be a mismatch between these procedures and a more informal iterative or agile process.\nSometimes these procedures are there for good reasons. For example, there may be procedures to ensure \nthat the software meets properly implements external regulations (e.g., in the United States, the Sarbanes \nOxley accounting regulations). Changing these procedures may not be possible, so process conflicts may \nbe\u00a0unavoidable.\nhttp://software-engineering-book.com/web/incremental-development\u200a\n/\n\t\n2.1\u2002 \u25a0\u2002 Software process models\u2002 \u2002 51\n", "page": 52, "type": "text", "section": "Page 52"}
{"text": "52\u2002 \u2002 Chapter 2\u2002 \u25a0\u2002 Software processes\n\t\n2.1.3 \t Integration and configuration\nIn the majority of software projects, there is some software reuse. This often happens \ninformally when people working on the project know of or search for code that is \nsimilar to what is required. They look for these, modify them as needed, and integrate \nthem with the new code that they have developed.\nThis informal reuse takes place regardless of the development process that is \nused. However, since 2000, software development processes that focus on the reuse \nof existing software have become widely used. Reuse-oriented approaches rely on a \nbase of reusable software components and an integrating framework for the compo-\nsition of these components.\nThree types of software components are frequently reused:\n1.\t\nStand-alone application systems that are configured for use in a particular envi-\nronment. These systems are general-purpose systems that have many features, \nbut they have to be adapted for use in a specific application.\n2.\t\nCollections of objects that are developed as a component or as a package to be \nintegrated with a component framework such as the Java Spring framework \n(Wheeler and White 2013).\n3.\t\nWeb services that are developed according to service standards and that are \navailable for remote invocation over the Internet.\nFigure 2.3 shows a general process model for reuse-based development, based on \nintegration and configuration. The stages in this process are:\n1.\t\nRequirements specification The initial requirements for the system are pro-\nposed. These do not have to be elaborated in detail but should include brief \ndescriptions of essential requirements and desirable system features.\n2.\t Software discovery and evaluation Given an outline of the software require-\nments, a search is made for components and systems that provide the func-\ntionality required. Candidate components and systems are evaluated to see if \nRequirements\nspecification\nSoftware\ndiscovery\nSoftware\nevaluation\nRequirements\nrefinement\nConfigure\napplication \nsystem\nAdapt \ncomponents\nIntegrate\nsystem\nDevelop new\ncomponents\nApplication system \navailable\nComponents\navailable\nFigure 2.3\u2002 Reuse- \noriented software \nengineering \n", "page": 53, "type": "text", "section": "Page 53"}
{"text": "they meet the essential requirements and if they are generally suitable for \nuse\u00a0in the system.\n3.\t Requirements refinement During this stage, the requirements are refined using \ninformation about the reusable components and applications that have been \ndiscovered. The requirements are modified to reflect the available compo-\nnents, and the system specification is re-defined. Where modifications are \nimpossible, the component analysis activity may be reentered to search for \nalternative solutions.\n4.\t\nApplication system configuration If an off-the-shelf application system that \nmeets the requirements is available, it may then be configured for use to create \nthe new system.\n5.\t\nComponent adaptation and integration If there is no off-the-shelf system, indi-\nvidual reusable components may be modified and new components developed. \nThese are then integrated to create the system.\nReuse-oriented software engineering, based around configuration and integra-\ntion, has the obvious advantage of reducing the amount of software to be developed \nand so reducing cost and risks. It usually also leads to faster delivery of the software. \nHowever, requirements compromises are inevitable, and this may lead to a system \nSoftware development tools\nSoftware development tools are programs that are used to support software engineering process activities. \nThese tools include requirements management tools, design editors, refactoring support tools, compilers, \ndebuggers, bug trackers, and system building tools.\nSoftware tools provide process support by automating some process activities and by providing information \nabout the software that is being developed. For example:\n\u25a0\t The development of graphical system models as part of the requirements specification or the software \ndesign\n\u25a0\t The generation of code from these graphical models\n\u25a0\t The generation of user interfaces from a graphical interface description that is created interactively by the user\n\u25a0\t Program debugging through the provision of information about an executing program\n\u25a0\t The automated translation of programs written using an old version of a programming language to a more \nrecent version\nTools may be combined within a framework called an Interactive Development Environment or IDE. This \n\u00ad\nprovides a common set of facilities that tools can use so that it is easier for tools to communicate and operate \nin an integrated way.\nhttp://software-engineering-book.com/web/software-tools/\n\t\n2.1\u2002 \u25a0\u2002 Software process models\u2002 \u2002 53\n", "page": 54, "type": "text", "section": "Page 54"}
{"text": "54\u2002 \u2002 Chapter 2\u2002 \u25a0\u2002 Software processes\nthat does not meet the real needs of users. Furthermore, some control over the sys-\ntem evolution is lost as new versions of the reusable components are not under the \ncontrol of the organization using them.\nSoftware reuse is very important, and so several chapters in the third I have dedi-\ncated several chapters in the 3rd part of the book to this topic. General issues of \nsoftware reuse are covered in Chapter 15, component-based software engineering in \nChapters 16 and 17, and service-oriented systems in Chapter 18.\n \n2.2  Process activities\nReal software processes are interleaved sequences of technical, collaborative, and \nmanagerial activities with the overall goal of specifying, designing, implementing, \nand testing a software system. Generally, processes are now tool-supported. This \nmeans that software developers may use a range of software tools to help them, such \nas requirements management systems, design model editors, program editors, auto-\nmated testing tools, and debuggers.\nThe four basic process activities of specification, development, validation, and \nevolution are organized differently in different development processes. In the water-\nfall model, they are organized in sequence, whereas in incremental development \nthey are interleaved. How these activities are carried out depends on the type of \nsoftware being developed, the experience and competence of the developers, and the \ntype of organization developing the software.\n\t\n2.2.1 \t Software specification\nSoftware specification or requirements engineering is the process of understanding \nand defining what services are required from the system and identifying the con-\nstraints on the system\u2019s operation and development. Requirements engineering is a \nparticularly critical stage of the software process, as mistakes made at this stage \ninevitably lead to later problems in the system design and implementation.\nBefore the requirements engineering process starts, a company may carry out a \nfeasibility or marketing study to assess whether or not there is a need or a market for \nthe software and whether or not it is technically and financially realistic to develop \nthe software required. Feasibility studies are short-term, relatively cheap studies that \ninform the decision of whether or not to go ahead with a more detailed analysis.\nThe requirements engineering process (Figure 2.4) aims to produce an agreed \nrequirements document that specifies a system satisfying stakeholder requirements. \nRequirements are usually presented at two levels of detail. End-users and customers \nneed a high-level statement of the requirements; system developers need a more \ndetailed system specification.\n", "page": 55, "type": "text", "section": "Page 55"}
{"text": "There are three main activities in the requirements engineering process:\n1.\t\nRequirements elicitation and analysis This is the process of deriving the system \nrequirements through observation of existing systems, discussions with poten-\ntial users and procurers, task analysis, and so on. This may involve the develop-\nment of one or more system models and prototypes. These help you understand \nthe system to be specified.\n2.\t\nRequirements specification Requirements specification is the activity of trans-\nlating the information gathered during requirements analysis into a document \nthat defines a set of requirements. Two types of requirements may be included \nin this document. User requirements are abstract statements of the system \nrequirements for the customer and end-user of the system; system requirements \nare a more detailed description of the functionality to be provided.\n3.\t Requirements validation This activity checks the requirements for realism, \nconsistency, and completeness. During this process, errors in the require-\nments document are inevitably discovered. It must then be modified to correct \nthese problems.\nRequirements analysis continues during definition and specification, and new \nrequirements come to light throughout the process. Therefore, the activities of analy-\nsis, definition, and specification are interleaved.\nIn agile methods, requirements specification is not a separate activity but is seen \nas part of system development. Requirements are informally specified for each \nincrement of the system just before that increment is developed. Requirements are \nspecified according to user priorities. The elicitation of requirements comes from \nusers who are part of or work closely with the development team.\nRequirements\nelicitation and\nanalysis\nRequirements\nspecification\nRequirements\nvalidation\nSystem \ndescriptions\nUser and system\nrequirements\nRequirements\ndocument\nFigure 2.4\u2002 The \nrequirements \nengineering process\n\t\n2.2\u2002 \u25a0\u2002 Process activities\u2002 \u2002 55\n", "page": 56, "type": "text", "section": "Page 56"}
{"text": "56\u2002 \u2002 Chapter 2\u2002 \u25a0\u2002 Software processes\n\t\n2.2.2 \t Software design and implementation\nThe implementation stage of software development is the process of developing \nan executable system for delivery to the customer. Sometimes this involves sepa-\nrate activities of software design and programming. However, if an agile approach \nto development is used, design and implementation are interleaved, with no for-\nmal design documents produced during the process. Of course, the software is \nstill designed, but the design is recorded informally on whiteboards and program-\nmer\u2019s notebooks.\nA software design is a description of the structure of the software to be imple-\nmented, the data models and structures used by the system, the interfaces between \nsystem components and, sometimes, the algorithms used. Designers do not arrive at \na finished design immediately but develop the design in stages. They add detail as \nthey develop their design, with constant backtracking to modify earlier designs.\nFigure 2.5 is an abstract model of the design process showing the inputs to the \ndesign process, process activities, and the process outputs. The design process activ-\nities are both interleaved and interdependent. New information about the design is \nconstantly being generated, and this affects previous design decisions. Design \nrework is therefore inevitable.\nDesign inputs\nDesign outputs\nArchitectural\ndesign\nInterface\ndesign\nDatabase\ndesign\nComponent\nselection \nand design\nDesign activities\nPlatform\ninformation\nSoftware\nrequirements\nData\ndescriptions\nSystem\narchitecture\nInterface\nspecification\nDatabase\ndesign\nComponent\ndescriptions\nFigure 2.5\u2002 A general \nmodel of the \ndesign process\n", "page": 57, "type": "text", "section": "Page 57"}
{"text": "Most software interfaces with other software systems. These other systems \ninclude the operating system, database, middleware, and other application systems. \nThese make up the \u201csoftware platform,\u2019 the environment in which the software will \nexecute. Information about this platform is an essential input to the design process, \nas designers must decide how best to integrate it with its environment. If the system \nis to process existing data, then the description of that data may be included in the \nplatform specification. Otherwise, the data description must be an input to the design \nprocess so that the system data organization can be defined.\nThe activities in the design process vary, depending on the type of system being \ndeveloped. For example, real-time systems require an additional stage of timing design \nbut may not include a database, so there is no database design involved. Figure 2.5 \nshows four activities that may be part of the design process for information systems:\n1.\t Architectural design, where you identify the overall structure of the system, the \nprincipal components (sometimes called subsystems or modules), their relation-\nships, and how they are distributed.\n2.\t Database design, where you design the system data structures and how these are \nto be represented in a database. Again, the work here depends on whether an \nexisting database is to be reused or a new database is to be created.\n3.\t Interface design, where you define the interfaces between system components. \nThis interface specification must be unambiguous. With a precise interface, a \ncomponent may be used by other components without them having to know \nhow it is implemented. Once interface specifications are agreed, the compo-\nnents can be separately designed and developed.\n4.\t Component selection and design, where you search for reusable components \nand, if no suitable components are available, design new software components. \nThe design at this stage may be a simple component description with the imple-\nmentation details left to the programmer. Alternatively, it may be a list of \nchanges to be made to a reusable component or a detailed design model \nexpressed in the UML. The design model may then be used to automatically \ngenerate an implementation.\nThese activities lead to the design outputs, which are also shown in Figure 2.5. \nFor critical systems, the outputs of the design process are detailed design documents \nsetting out precise and accurate descriptions of the system. If a model-driven \napproach is used (Chapter 5), the design outputs are design diagrams. Where agile \nmethods of development are used, the outputs of the design process may not be \nseparate specification documents but may be represented in the code of the program.\nThe development of a program to implement a system follows naturally from \nsystem design. Although some classes of program, such as safety-critical systems, \nare usually designed in detail before any implementation begins, it is more common \nfor design and program development to be interleaved. Software development tools \nmay be used to generate a skeleton program from a design. This includes code to \n\t\n2.2\u2002 \u25a0\u2002 Process activities\u2002 \u2002 57\n", "page": 58, "type": "text", "section": "Page 58"}
{"text": "58\u2002 \u2002 Chapter 2\u2002 \u25a0\u2002 Software processes\ndefine and implement interfaces, and, in many cases, the developer need only add \ndetails of the operation of each program component.\nProgramming is an individual activity, and there is no general process that is \nusually followed. Some programmers start with components that they understand, \ndevelop these, and then move on to less understood components. Others take the \nopposite approach, leaving familiar components till last because they know how to \ndevelop them. Some developers like to define data early in the process and then \nuse this to drive the program development; others leave data unspecified for as \nlong as possible.\nNormally, programmers carry out some testing of the code they have developed. \nThis often reveals program defects (bugs) that must be removed from the program. \nFinding and fixing program defects is called debugging. Defect testing and debug-\nging are different processes. Testing establishes the existence of defects. Debugging \nis concerned with locating and correcting these defects.\nWhen you are debugging, you have to generate hypotheses about the observa-\nble behavior of the program and then test these hypotheses in the hope of finding \nthe fault that caused the output anomaly. Testing the hypotheses may involve trac-\ning the program code manually. It may require new test cases to localize the prob-\nlem. Interactive debugging tools, which show the intermediate values of program \nvariables and a trace of the statements executed, are usually used to support the \ndebugging process.\n\t\n2.2.3 \t Software validation\nSoftware validation or, more generally, verification and validation (V & V) is \nintended to show that a system both conforms to its specification and meets the \nexpectations of the system customer. Program testing, where the system is executed \nusing simulated test data, is the principal validation technique. Validation may also \ninvolve checking processes, such as inspections and reviews, at each stage of the \nsoftware process from user requirements definition to program development. \nHowever, most V & V time and effort is spent on program testing.\nExcept for small programs, systems should not be tested as a single, monolithic \nunit. Figure 2.6 shows a three-stage testing process in which system components are \nindividually tested, then the integrated system is tested. For custom software, cus-\ntomer testing involves testing the system with real customer data. For products that \nare sold as applications, customer testing is sometimes called beta testing where \nselected users try out and comment on the software.\nSystem testing\nComponent\n testing\nCustomer\ntesting\nFigure 2.6\u2002 Stages \nof\u00a0testing\n", "page": 59, "type": "text", "section": "Page 59"}
{"text": "The stages in the testing process are:\n1.\u2002  \u200a\n\u2009\u200a\n\u200a\n\u200a\nComponent testing The components making up the system are tested by the people \ndeveloping the system. Each component is tested independently, without other \nsystem components. Components may be simple entities such as functions or \nobject classes or may be coherent groupings of these entities. Test automation \ntools, such as JUnit for Java, that can rerun tests when new versions of the \n\u00ad\ncomponent are created, are commonly used (Koskela 2013).\n2.\u2002  \u200a\n\u2009System testing System components are integrated to create a complete system. \nThis process is concerned with finding errors that result from unanticipated \ninteractions between components and component interface problems. It is also \nconcerned with showing that the system meets its functional and non-functional \nrequirements, and testing the emergent system properties. For large systems, \nthis may be a multistage process where components are integrated to form \n\u00ad\nsubsystems that are individually tested before these subsystems are integrated to \nform the final system.\n3.\u2002  \u200a\n\u2009Customer testing This is the final stage in the testing process before the system \nis accepted for operational use. The system is tested by the system customer (or \npotential customer) rather than with simulated test data. For custom-built \n\u00ad\nsoftware, customer testing may reveal errors and omissions in the system \nrequirements definition, because the real data exercise the system in different \nways from the test data. Customer testing may also reveal requirements problems \nwhere the system\u2019s facilities do not really meet the users\u2019 needs or the system \nperformance is unacceptable. For products, customer testing shows how well \nthe software product meets the customer\u2019s needs.\nIdeally, component defects are discovered early in the testing process, and inter-\nface problems are found when the system is integrated. However, as defects are dis-\ncovered, the program must be debugged, and this may require other stages in the \ntesting process to be repeated. Errors in program components, say, may come to \nlight during system testing. The process is therefore an iterative one with informa-\ntion being fed back from later stages to earlier parts of the process.\nNormally, component testing is simply part of the normal development process. \nProgrammers make up their own test data and incrementally test the code as it is \ndeveloped. The programmer knows the component and is therefore the best person \nto generate test cases.\nIf an incremental approach to development is used, each increment should be \ntested as it is developed, with these tests based on the requirements for that incre-\nment. In test-driven development, which is a normal part of agile processes, tests are \ndeveloped along with the requirements before development starts. This helps the \ntesters and developers to understand the requirements and ensures that there are no \ndelays as test cases are created.\nWhen a plan-driven software process is used (e.g., for critical systems develop-\nment), testing is driven by a set of test plans. An independent team of testers works \n\t\n2.2\u2002 \u25a0\u2002 Process activities\u2002 \u2002 59\n", "page": 60, "type": "text", "section": "Page 60"}
{"text": "60\u2002 \u2002 Chapter 2\u2002 \u25a0\u2002 Software processes\nfrom these test plans, which have been developed from the system specification and \ndesign. Figure 2.7 illustrates how test plans are the link between testing and develop-\nment activities. This is sometimes called the V-model of development (turn it on its \nside to see the V). The V-model shows the software validation activities that corre-\nspond to each stage of the waterfall process model.\nWhen a system is to be marketed as a software product, a testing process called \nbeta testing is often used. Beta testing involves delivering a system to a number of \npotential customers who agree to use that system. They report problems to the sys-\ntem developers. This exposes the product to real use and detects errors that may not \nhave been anticipated by the product developers. After this feedback, the software \nproduct may be modified and released for further beta testing or general sale.\n\t\n2.2.4 \t Software evolution\nThe flexibility of software is one of the main reasons why more and more software \nis being incorporated into large, complex systems. Once a decision has been made to \nmanufacture hardware, it is very expensive to make changes to the hardware design. \nHowever, changes can be made to software at any time during or after the system \ndevelopment. Even extensive changes are still much cheaper than corresponding \nchanges to system hardware.\nHistorically, there has always been a split between the process of software \ndevelopment and the process of software evolution (software maintenance). People \nthink of software development as a creative activity in which a software system is \ndeveloped from an initial concept through to a working system. However, they \nsometimes think of software maintenance as dull and uninteresting. They think \nthat software maintenance is less interesting and challenging than original soft-\nware development.\nThis distinction between development and maintenance is increasingly irrelevant. \nVery few software systems are completely new systems, and it makes much more \nRequirements\nspecification\nSystem\nspecification\nCustomer\ntest\nSystem\nintegration test\nSub-system\nintegration test\nSystem\ndesign\nComponent\ndesign\nService\nComponent \ncode and test\nCustomer\ntest plan\nSystem\nintegration\ntest plan\nSub-system\nintegration\ntest plan\nFigure 2.7\u2002 Testing \nphases in a plan-driven \nsoftware process\n", "page": 61, "type": "text", "section": "Page 61"}
{"text": "sense to see development and maintenance as a continuum. Rather than two separate \nprocesses, it is more realistic to think of software engineering as an evolutionary \nprocess (Figure 2.8) where software is continually changed over its lifetime in \nresponse to changing requirements and customer needs.\n \n2.3  Coping with change\nChange is inevitable in all large software projects. The system requirements \nchange as businesses respond to external pressures, competition, and changed \nmanagement priorities. As new technologies become available, new approaches to \ndesign and implementation become possible. Therefore whatever software pro-\ncess model is used, it is essential that it can accommodate changes to the software \nbeing developed.\nChange adds to the costs of software development because it usually means \nthat work that has been completed has to be redone. This is called rework. For \nexample, if the relationships between the requirements in a system have been ana-\nlyzed and new requirements are then identified, some or all of the requirements \nanalysis has to be repeated. It may then be necessary to redesign the system to \ndeliver the new requirements, change any programs that have been developed, \nand retest the system.\nTwo related approaches may be used to reduce the costs of rework:\n1.\t Change anticipation, where the software process includes activities that can \nanticipate or predict possible changes before significant rework is required. For \nexample, a prototype system may be developed to show some key features of \nthe system to customers. They can experiment with the prototype and refine \ntheir requirements before committing to high software production costs.\n2.\t Change tolerance, where the process and software are designed so that changes \ncan be easily made to the system. This normally involves some form of incre-\nmental development. Proposed changes may be implemented in increments that \nhave not yet been developed. If this is impossible, then only a single increment \n(a small part of the system) may have to be altered to incorporate the change.\nAssess existing\nsystems\nDefine system\nrequirements\nPropose system\nchanges\nModify\nsystems\nNew\nsystem\nExisting\nsystems\nFigure 2.8\u2002 Software \nsystem evolution\n\t\n2.3\u2002 \u25a0\u2002 Coping with change\u2002 \u2002 61\n", "page": 62, "type": "text", "section": "Page 62"}
{"text": "62\u2002 \u2002 Chapter 2\u2002 \u25a0\u2002 Software processes\nIn this section, I discuss two ways of coping with change and changing system \nrequirements:\n1.\t System prototyping, where a version of the system or part of the system is \ndeveloped quickly to check the customer\u2019s requirements and the feasibility of \ndesign decisions. This is a method of change anticipation as it allows users to \nexperiment with the system before delivery and so refine their requirements. \nThe number of requirements change proposals made after delivery is therefore \nlikely to be reduced.\n2.\t Incremental delivery, where system increments are delivered to the customer \nfor comment and experimentation. This supports both change avoidance and \nchange tolerance. It avoids the premature commitment to requirements for the \nwhole system and allows changes to be incorporated into later increments at \nrelatively low cost.\nThe notion of refactoring, namely, improving the structure and organization of a \nprogram, is also an important mechanism that supports change tolerance. I discuss \nthis in Chapter 3 (Agile methods).\n\t\n2.3.1 \t Prototyping\nA prototype is an early version of a software system that is used to demonstrate con-\ncepts, try out design options, and find out more about the problem and its possible \nsolutions. Rapid, iterative development of the prototype is essential so that costs are \ncontrolled and system stakeholders can experiment with the prototype early in the \nsoftware process.\nA software prototype can be used in a software development process to help \nanticipate changes that may be required:\n1.\t In the requirements engineering process, a prototype can help with the elicita-\ntion and validation of system requirements.\n2.\t In the system design process, a prototype can be used to explore software solu-\ntions and in the development of a user interface for the system.\nSystem prototypes allow potential users to see how well the system supports their \nwork. They may get new ideas for requirements and find areas of strength and weak-\nness in the software. They may then propose new system requirements. Furthermore, \nas the prototype is developed, it may reveal errors and omissions in the system \nrequirements. A feature described in a specification may seem to be clear and useful. \nHowever, when that function is combined with other functions, users often find that \ntheir initial view was incorrect or incomplete. The system specification can then be \nmodified to reflect the changed understanding of the requirements.\n", "page": 63, "type": "text", "section": "Page 63"}
{"text": "A system prototype may be used while the system is being designed to carry out \ndesign experiments to check the feasibility of a proposed design. For example, a \ndatabase design may be prototyped and tested to check that it supports efficient data \naccess for the most common user queries. Rapid prototyping with end-user involve-\nment is the only sensible way to develop user interfaces. Because of the dynamic \nnature of user interfaces, textual descriptions and diagrams are not good enough for \nexpressing the user interface requirements and design.\nA process model for prototype development is shown in Figure 2.9. The objec-\ntives of prototyping should be made explicit from the start of the process. These \nmay be to develop the user interface, to develop a system to validate functional \nsystem requirements, or to develop a system to demonstrate the application to man-\nagers. The same prototype usually cannot meet all objectives. If the objectives are \nleft unstated, management or end-users may misunderstand the function of the pro-\ntotype. Consequently, they may not get the benefits that they expected from the \nprototype development.\nThe next stage in the process is to decide what to put into and, perhaps more \nimportantly, what to leave out of the prototype system. To reduce prototyping costs \nand accelerate the delivery schedule, you may leave some functionality out of the \nprototype. You may decide to relax non-functional requirements such as response \ntime and memory utilization. Error handling and management may be ignored unless \nthe objective of the prototype is to establish a user interface. Standards of reliability \nand program quality may be reduced.\nThe final stage of the process is prototype evaluation. Provision must be \nmade during this stage for user training, and the prototype objectives should \nbe\u00a0used to derive a plan for evaluation. Potential users need time to become \ncomfortable with a new system and to settle into a normal pattern of usage. Once \nthey are using the system normally, they then discover requirements errors \nand\u00a0omissions. A general problem with prototyping is that users may not use the \nprototype in the same way as they use the final system. Prototype testers may \nnot be typical of system users. There may not be enough time to train users \n\u00ad\nduring prototype evaluation. If the prototype is slow, the evaluators may adjust \ntheir way of working and avoid those system features that have slow response \ntimes. When provided with better response in the final system, they may use it in \na different way.\nEstablish\nprototype\nobjectives\nDefine\nprototype\nfunctionality\nDevelop\nprototype\nEvaluate\nprototype\nPrototyping\nplan\nOutline\ndefinition\nExecutable\nprototype\nEvaluation\nreport\nFigure 2.9\u2002 Prototype \ndevelopment\n\t\n2.3\u2002 \u25a0\u2002 Coping with change\u2002 \u2002 63\n", "page": 64, "type": "text", "section": "Page 64"}
{"text": "64\u2002 \u2002 Chapter 2\u2002 \u25a0\u2002 Software processes\n\t\n2.3.2 \t Incremental delivery\nIncremental delivery (Figure 2.10) is an approach to software development where \nsome of the developed increments are delivered to the customer and deployed for \nuse in their working environment. In an incremental delivery process, customers \ndefine which of the services are most important and which are least important to \nthem. A number of delivery increments are then defined, with each increment pro-\nviding a subset of the system functionality. The allocation of services to increments \ndepends on the service priority, with the highest priority services implemented and \ndelivered first.\nOnce the system increments have been identified, the requirements for the \nservices to be delivered in the first increment are defined in detail and that incre-\nment is developed. During development, further requirements analysis for later \nincrements can take place, but requirements changes for the current increment \nare not accepted.\nOnce an increment is completed and delivered, it is installed in the customer\u2019s \nnormal working environment. They can experiment with the system, and this helps \nthem clarify their requirements for later system increments. As new increments are \ncompleted, they are integrated with existing increments so that system functionality \nimproves with each delivered increment.\nIncremental delivery has a number of advantages:\n1.\t Customers can use the early increments as prototypes and gain experience that \ninforms their requirements for later system increments. Unlike prototypes, \nthese are part of the real system, so there is no relearning when the complete \nsystem is available.\n2.\t Customers do not have to wait until the entire system is delivered before they \ncan gain value from it. The first increment satisfies their most critical require-\nments, so they can use the software immediately.\n3.\t The process maintains the benefits of incremental development in that it should \nbe relatively easy to incorporate changes into the system.\nDesign system\narchitecture\nDefine outline\n requirements\nAssign requirements\n      to increments\nSystem\nincomplete?\nFinal\nsystem\nDevelop system\nincrement\nValidate\nincrement\nIntegrate\nincrement\nValidate\nsystem\nDeploy\nincrement\nSystem\ncomplete?\nFigure 2.10\u2002  \nIncremental delivery\n", "page": 65, "type": "text", "section": "Page 65"}
{"text": "4.\t As the highest priority services are delivered first and later increments then inte-\ngrated, the most important system services receive the most testing. This means \nthat customers are less likely to encounter software failures in the most impor-\ntant parts of the system.\nHowever, there are problems with incremental delivery. In practice, it only works in \nsituations where a brand-new system is being introduced and the system evaluators are \ngiven time to experiment with the new system. Key problems with this approach are:\n1.\t Iterative delivery is problematic when the new system is intended to replace an \nexisting system. Users need all of the functionality of the old system and are \nusually unwilling to experiment with an incomplete new system. It is often \nimpractical to use the old and the new systems alongside each other as they are \nlikely to have different databases and user interfaces.\n2.\t\nMost systems require a set of basic facilities that are used by different parts of the \nsystem. As requirements are not defined in detail until an increment is to be imple-\nmented, it can be hard to identify common facilities that are needed by all increments.\n3.\t The essence of iterative processes is that the specification is developed in con-\njunction with the software. However, this conflicts with the procurement model \nof many organizations, where the complete system specification is part of the \nsystem development contract. In the incremental approach, there is no complete \nsystem specification until the final increment is specified. This requires a new \nform of contract, which large customers such as government agencies may find \ndifficult to accommodate.\nFor some types of systems, incremental development and delivery is not the best \napproach. These are very large systems where development may involve teams working \nin different locations, some embedded systems where the software depends on hardware \ndevelopment, and some critical systems where all the requirements must be analyzed to \ncheck for interactions that may compromise the safety or security of the system.\nThese large systems, of course, suffer from the same problems of uncertain and \nchanging requirements. Therefore, to address these problems and get some of the \nbenefits of incremental development, a system prototype may be developed and used \nas a platform for experiments with the system requirements and design. With the \nexperience gained from the prototype, definitive requirements can then be agreed.\n \n2.4  Process improvement\nNowadays, there is a constant demand from industry for cheaper, better software, \nwhich has to be delivered to ever-tighter deadlines. Consequently, many software \ncompanies have turned to software process improvement as a way of enhancing the \n\t\n2.4\u2002 \u25a0\u2002 Process improvement\u2002 \u2002 65\n", "page": 66, "type": "text", "section": "Page 66"}
{"text": "66\u2002 \u2002 Chapter 2\u2002 \u25a0\u2002 Software processes\nquality of their software, reducing costs, or accelerating their development pro-\ncesses. Process improvement means understanding existing processes and changing \nthese processes to increase product quality and/or reduce costs and development \ntime. I cover general issues of process measurement and process improvement in \ndetail in web Chapter 26.\nTwo quite different approaches to process improvement and change are used:\n1.\t The process maturity approach, which has focused on improving process and \nproject management and introducing good software engineering practice into an \norganization. The level of process maturity reflects the extent to which good \ntechnical and management practice has been adopted in organizational software \ndevelopment processes. The primary goals of this approach are improved prod-\nuct quality and process predictability.\n2.\t\nThe agile approach, which has focused on iterative development and the reduc-\ntion of overheads in the software process. The primary characteristics of agile \nmethods are rapid delivery of functionality and responsiveness to changing cus-\ntomer requirements. The improvement philosophy here is that the best processes \nare those with the lowest overheads and agile approaches can achieve this. \nI\u00a0describe agile approaches in Chapter 3.\nPeople who are enthusiastic about and committed to each of these approaches are \ngenerally skeptical of the benefits of the other. The process maturity approach is \nrooted in plan-driven development and usually requires increased \u201coverhead,\u201d in the \nsense that activities are introduced that are not directly relevant to program develop-\nment. Agile approaches focus on the code being developed and deliberately mini-\nmize formality and documentation.\nThe general process improvement process underlying the process maturity \napproach is a cyclical process, as shown in Figure 2.11. The stages in this process are:\n1.\t\nProcess measurement You measure one or more attributes of the software pro-\ncess or product. These measurements form a baseline that helps you decide if \nAnalyze\nMeasure\nChange\nFigure 2.11\u2002 The process \nimprovement cycle\n", "page": 67, "type": "text", "section": "Page 67"}
{"text": "process improvements have been effective. As you introduce improvements, you \nre-measure the same attributes, which will hopefully have improved in some way.\n2.\t\nProcess analysis The current process is assessed, and process weaknesses and \nbottlenecks are identified. Process models (sometimes called process maps) that \ndescribe the process may be developed during this stage. The analysis may be \nfocused by considering process characteristics such as rapidity and robustness.\n3.\t\nProcess change Process changes are proposed to address some of the identified \nprocess weaknesses. These are introduced, and the cycle resumes to collect data \nabout the effectiveness of the changes.\nWithout concrete data on a process or the software developed using that process, it \nis impossible to assess the value of process improvement. However, companies starting \nthe process improvement process are unlikely to have process data available as an \nimprovement baseline. Therefore, as part of the first cycle of changes, you may have to \ncollect data about the software process and to measure software product characteristics.\nProcess improvement is a long-term activity, so each of the stages in the improve-\nment process may last several months. It is also a continuous activity as, whatever \nnew processes are introduced, the business environment will change and the new \nprocesses will themselves have to evolve to take these changes into account.\nThe notion of process maturity was introduced in the late 1980s when the \nSoftware Engineering Institute (SEI) proposed their model of process capability \nmaturity (Humphrey 1988). The maturity of a software company\u2019s processes reflects \nthe process management, measurement, and use of good software engineering prac-\ntices in the company. This idea was introduced so that the U.S. Department of \nDefense could assess the software engineering capability of defense contractors, \nwith a view to limiting contracts to those contractors who had reached a required \nlevel of process maturity. Five levels of process maturity were proposed. as shown in \nFigure 2.12. These have evolved and developed over the last 25 years (Chrissis, \nKonrad, and Shrum 2011), but the fundamental ideas in Humphrey\u2019s model are still \nthe basis of software process maturity assessment.\nThe levels in the process maturity model are:\n1.\t\nInitial The goals associated with the process area are satisfied, and for all pro-\ncesses the scope of the work to be performed is explicitly set out and communi-\ncated to the team members.\n2.\t\nManaged At this level, the goals associated with the process area are met, and organ-\nizational policies are in place that define when each process should be used. There \nmust be documented project plans that define the project goals. Resource manage-\nment and process monitoring procedures must be in place across the institution.\n3.\t\nDefined This level focuses on organizational standardization and deployment of \nprocesses. Each project has a managed process that is adapted to the project require-\nments from a defined set of organizational processes. Process assets and process \nmeasurements must be collected and used for future process improvements.\n\t\n2.4\u2002 \u25a0\u2002 Process improvement\u2002 \u2002 67\n", "page": 68, "type": "text", "section": "Page 68"}
{"text": "68\u2002 \u2002 Chapter 2\u2002 \u25a0\u2002 Software processes\n4.\t\nQuantitatively managed At this level, there is an organizational responsibility to \nuse statistical and other quantitative methods to control subprocesses. That is, col-\nlected process and product measurements must be used in process management.\n5.\t\nOptimizing At this highest level, the organization must use the process and \nproduct measurements to drive process improvement. Trends must be analyzed \nand the processes adapted to changing business needs.\nThe work on process maturity levels has had a major impact on the software \nindustry. It focused attention on the software engineering processes and practices \nthat were used and led to significant improvements in software engineering capabil-\nity. However, there is too much overhead in formal process improvement for small \ncompanies, and maturity estimation with agile processes is difficult. Consequently, \nonly large software companies now use this maturity-focused approach to software \nprocess improvement.\nLevel 3\nDefined\nLevel 2\nManaged\nLevel 1\nInitial\nLevel 4\nQuantitatively\nmanaged\nLevel 5\nOptimizing\nFigure 2.12\u2002 Capability \nmaturity levels\nKey points\n\u25a0\t Software processes are the activities involved in producing a software system. Software process \nmodels are abstract representations of these processes.\n\u25a0\t General process models describe the organization of software processes. Examples of these \ngeneral models include the waterfall model, incremental development, and reusable component \nconfiguration and integration.\n", "page": 69, "type": "text", "section": "Page 69"}
{"text": "\t\nChapter 2\u2002 \u25a0\u2002 Website\u2002 \u2002 69\n\u25a0\t Requirements engineering is the process of developing a software specification. Specifications \nare intended to communicate the system needs of the customer to the system developers.\n\u25a0\t Design and implementation processes are concerned with transforming a requirements specifi-\ncation into an executable software system.\n\u25a0\t Software validation is the process of checking that the system conforms to its specification and \nthat it meets the real needs of the users of the system.\n\u25a0\t Software evolution takes place when you change existing software systems to meet new \nrequirements. Changes are continuous, and the software must evolve to remain useful.\n\u25a0\t Processes should include activities to cope with change. This may involve a prototyping phase that \nhelps avoid poor decisions on requirements and design. Processes may be structured for iterative \ndevelopment and delivery so that changes may be made without disrupting the system as a whole.\n\u25a0\t Process improvement is the process of improving existing software processes to improve soft-\nware quality, lower development costs, or reduce development time. It is a cyclic process involv-\ning process measurement, analysis, and change.\nFurther Reading\n\u201cProcess Models in Software Engineering.\u201d This is an excellent overview of a wide range of software \nengineering process models that have been proposed. (W. Scacchi, Encyclopaedia of Software \n\u00ad\nEngineering, ed. J. J. Marciniak, John Wiley & Sons, 2001) http://www.ics.uci.edu/~wscacchi/\nPapers/SE-Encyc/Process-Models-SE-Encyc.pdf\nSoftware Process Improvement: Results and Experience from the Field. This book is a collection of \npapers focusing on process improvement case studies in several small and medium-sized Norwegian \ncompanies. It also includes a good introduction to the general issues of process improvement. \n\u00ad\n(Conradi, R., Dyb\u00e5, T., Sj\u00f8berg, D., and Ulsund, T. (eds.), Springer, 2006).\n\u201cSoftware Development Life Cycle Models and Methodologies.\u201d This blog post is a succinct sum-\nmary of several software process models that have been proposed and used. It discusses the advan-\ntages and disadvantages of each of these models (M. Sami, 2012). http://melsatar.wordpress.\ncom/2012/03/15/software-development-life-cycle-models-and-methodologies/\nWebsite\nPowerPoint slides for this chapter:\nwww.pearsonglobaleditions.com/Sommerville\nLinks to supporting videos:\nhttp://software-engineering-book.com/videos/software-engineering/\n", "page": 70, "type": "text", "section": "Page 70"}
{"text": "70\u2002 \u2002 Chapter 2\u2002 \u25a0\u2002 Software processes\nExercises\n\u2002 2.1. \tSuggest the most appropriate generic software process model that might be used as a basis \nfor managing the development of the following systems. Explain your answer according to the \ntype of system being developed:\nA system to control antilock braking in a car\nA virtual reality system to support software maintenance\nA university accounting system that replaces an existing system\nAn interactive travel planning system that helps users plan journeys with the lowest \nenvironmental impact\n\u2002 2.2. \tIncremental software development could be very effectively used for customers who do not \nhave a clear idea about the systems needed for their operations. Discuss.\n\u2002 2.3. \tConsider the integration and configuration process model shown in Figure 2.3. Explain why it \nis essential to repeat the requirements engineering activity in the process.\n\u2002 2.4. \tSuggest why it is important to make a distinction between developing the user requirements \nand developing system requirements in the requirements engineering process.\n\u2002 2.5. \tUsing an example, explain why the design activities of architectural design, database design, \ninterface design, and component design are interdependent.\n\u2002 2.6. \tExplain why software testing should always be an incremental, staged activity. Are program-\nmers the best people to test the programs that they have developed?\n\u2002 2.7. \tImagine that a government wants a software program that helps to keep track of the utiliza-\ntion of the country\u2019s vast mineral resources. Although the requirements put forward by the \ngovernment were not very clear, a software company was tasked with the development of a \nprototype. The government found the prototype impressive, and asked it be extended to be \nthe actual system that would be used. Discuss the pros and cons of taking this approach.\n\u2002 2.8. \tYou have developed a prototype of a software system and your manager is very impressed by \nit. She proposes that it should be put into use as a production system, with new features \nadded as required. This avoids the expense of system development and makes the system \nimmediately useful. Write a short report for your manager explaining why prototype systems \nshould not normally be used as production systems.\n\u2002 2.9. \tSuggest two advantages and two disadvantages of the approach to process assessment and \nimprovement that is embodied in the SEI\u2019s Capability Maturity framework.\n2.10. \tHistorically, the introduction of technology has caused profound changes in the labor market \nand, temporarily at least, displaced people from jobs. Discuss whether the introduction of \nextensive process automation is likely to have the same consequences for software engi-\nneers. If you don\u2019t think it will, explain why not. If you think that it will reduce job opportuni-\nties, is it ethical for the engineers affected to passively or actively resist the introduction of \nthis technology?\n70\u2002 \u2002 Chapter 2\u2002 \u25a0\u2002 Software processes\n", "page": 71, "type": "text", "section": "Page 71"}
{"text": "\t\nChapter 2\u2002 \u25a0\u2002 References\u2002 \u2002 71\nReferences\nAbrial, J. R. 2005. The B Book: Assigning Programs to Meanings. Cambridge, UK: Cambridge \n\u00ad\nUniversity Press.\n\t\n\u2002 \u2002 . 2010. Modeling in Event-B: System and Software Engineering. Cambridge, UK: Cambridge \nUniversity Press.\nBoehm, B. W. (1988). \u201cA Spiral Model of Software Development and Enhancement.\u201d IEEE Computer, \n21 (5), 61\u201372. doi:10.1145/12944.12948\nBoehm, B. W., and R. Turner. 2004. \u201cBalancing Agility and Discipline: Evaluating and Integrating \nAgile and Plan-Driven Methods.\u201d In 26th Int. Conf on Software Engineering, Edinburgh, Scotland. \ndoi:10.1109/ICSE.2004.1317503.\nChrissis, M. B., M. Konrad, and S. Shrum. 2011. CMMI for Development: Guidelines for Process \n\u00ad\nIntegration and Product Improvement, 3rd ed. Boston: Addison-Wesley.\nHumphrey, W. S. 1988. \u201cCharacterizing the Software Process: A Maturity Framework.\u201d IEEE Software \n5 (2): 73\u201379. doi:10.1109/2.59.\nKoskela, L. 2013. Effective Unit Testing: A Guide for Java Developers. Greenwich, CT: Manning \nPublications.\nKrutchen, P. 2003. The Rational Unified Process\u2014An Introduction, 3rd ed. Reading, MA: Addison-Wesley.\nRoyce, W. W. 1970. \u201cManaging the Development of Large Software Systems: Concepts and \n\u00ad\nTechniques.\u201d In IEEE WESTCON, 1\u20139. Los Angeles, CA.\nWheeler, W., and J. White. 2013. Spring in Practice. Greenwich, CT: Manning Publications.\n", "page": 72, "type": "text", "section": "Page 72"}
{"text": "Agile software \ndevelopment\n3 \nObjectives\nThe objective of this chapter is to introduce you to agile software \ndevelopment methods. When you have read the chapter, you will:\n\u25a0\t understand the rationale for agile software development methods, \nthe agile manifesto, and the differences between agile and \nplan-driven development;\n\u25a0\t know about important agile development practices such as user \nstories, refactoring, pair programming and test-first development;\n\u25a0\t understand the Scrum approach to agile project management;\n\u25a0\t understand the issues of scaling agile development methods and \ncombining agile approaches with plan-driven approaches in the \ndevelopment of large software systems.\nContents\n3.1 \tAgile methods\n3.2 \tAgile development techniques\n3.3 \tAgile project management\n3.4 \tScaling agile methods\n", "page": 73, "type": "text", "section": "Page 73"}
{"text": "Businesses now operate in a global, rapidly changing environment. They have to \nrespond to new opportunities and markets, changing economic conditions and the \nemergence of competing products and services. Software is part of almost all busi-\nness operations, so new software has to be developed quickly to take advantage of \nnew opportunities and to respond to competitive pressure. Rapid software develop-\nment and delivery is therefore the most critical requirement for most business systems. \nIn fact, businesses may be willing to trade off software quality and compromise on \nrequirements if they can deploy essential new software quickly.\nBecause these businesses are operating in a changing environment, it is practi-\ncally impossible to derive a complete set of stable software requirements. \nRequirements change because customers find it impossible to predict how a system \nwill affect working practices, how it will interact with other systems, and what user \noperations should be automated. It may only be after a system has been delivered \nand users gain experience with it that the real requirements become clear. Even then, \nexternal factors drive requirements change.\nPlan-driven software development processes that completely specify the require-\nments and then design, build, and test a system are not geared to rapid software devel-\nopment. As the requirements change or as requirements problems are discovered, the \nsystem design or implementation has to be reworked and retested. As a consequence, \na conventional waterfall or specification-based process is usually a lengthy one, and \nthe final software is delivered to the customer long after it was originally specified.\nFor some types of software, such as safety-critical control systems, where a com-\nplete analysis of the system is essential, this plan-driven approach is the right one. \nHowever, in a fast-moving business environment, it can cause real problems. By the \ntime the software is available for use, the original reason for its procurement may \nhave changed so radically that the software is effectively useless. Therefore, for \nbusiness systems in particular, development processes that focus on rapid software \ndevelopment and delivery are essential.\nThe need for rapid software development and processes that can handle changing \nrequirements has been recognized for many years (Larman and Basili 2003). \nHowever, faster software development really took off in the late 1990s with the \ndevelopment of the idea of \u201cagile methods\u201d such as Extreme Programming (Beck \n1999), Scrum (Schwaber and Beedle 2001), and DSDM (Stapleton 2003).\nRapid software development became known as agile development or agile meth-\nods. These agile methods are designed to produce useful software quickly. All of the \nagile methods that have been proposed share a number of common characteristics:\n1.\t\nThe processes of specification, design and implementation are interleaved. \nThere is no detailed system specification, and design documentation is mini-\nmized or generated automatically by the programming environment used to \nimplement the system. The user requirements document is an outline definition \nof the most important characteristics of the system.\n2.\t\nThe system is developed in a series of increments. End-users and other system \nstakeholders are involved in specifying and evaluating each increment. \nChapter 3\u2002 \u25a0\u2002 Agile software development\u2002 \u2002 73\u2002\n", "page": 74, "type": "text", "section": "Page 74"}
{"text": "74\u2002 \u2002 Chapter 3\u2002 \u25a0\u2002 Agile software development\nThey\u00a0may propose changes to the software and new requirements that should be \nimplemented in a later version of the system.\n3.\t\nExtensive tool support is used to support the development process. Tools that \nmay be used include automated testing tools, tools to support configuration man-\nagement, and system integration and tools to automate user interface production.\nAgile methods are incremental development methods in which the increments are \nsmall, and, typically, new releases of the system are created and made available to \n\u00ad\ncustomers every two or three weeks. They involve customers in the development \n\u00ad\nprocess to get rapid feedback on changing requirements. They minimize documentation \nby using informal communications rather than formal meetings with written documents.\nAgile approaches to software development consider design and implementation \nto be the central activities in the software process. They incorporate other activities, \nsuch as requirements elicitation and testing, into design and implementation. By \ncontrast, a plan-driven approach to software engineering identifies separate stages in \nthe software process with outputs associated with each stage. The outputs from one \nstage are used as a basis for planning the following process activity.\nFigure 3.1 shows the essential distinctions between plan-driven and agile approaches \nto system specification. In a plan-driven software development process, iteration \noccurs within activities, with formal documents used to communicate between stages \nof the process. For example, the requirements will evolve, and, ultimately, a require-\nments specification will be produced. This is then an input to the design and imple-\nmentation process. In an agile approach, iteration occurs across activities. Therefore, \nthe requirements and the design are developed together rather than separately.\nIn practice, as I explain in Section 3.4.1, plan-driven processes are often used along \nwith agile programming practices, and agile methods may incorporate some planned \nRequirements\nspecification\nRequirements\nengineering\nDesign and\nimplementation\nRequirements change\nrequests\nPlan-based development\nAgile development\nRequirements\nengineering\nDesign and\nimplementation\nFigure 3.1\u2002 Plan-driven \nand agile development\n", "page": 75, "type": "text", "section": "Page 75"}
{"text": "\t\n3.1\u2002 \u25a0\u2002 Agile methods\u2002 \u2002 75\nactivities apart from programming and testing. It is perfectly feasible, in a plan-driven \nprocess, to allocate requirements and plan the design and development phase as a \nseries of increments. An agile process is not inevitably code-focused, and it may \n\u00ad\nproduce some design documentation. Agile developers may decide that an iteration \nshould not produce new code but rather should produce system models and documentation.\n \n3.1 Agile methods\nIn the 1980s and early 1990s, there was a widespread view that the best way to \nachieve better software was through careful project planning, formalized quality \nassurance, use of analysis and design methods supported by software tools, and con-\ntrolled and rigorous software development processes. This view came from the soft-\nware engineering community that was responsible for developing large, long-lived \nsoftware systems such as aerospace and government systems.\nThis plan-driven approach was developed for software developed by large teams, \nworking for different companies. Teams were often geographically dispersed and \nworked on the software for long periods of time. An example of this type of software \nis the control systems for a modern aircraft, which might take up to 10 years from \ninitial specification to deployment. Plan-driven approaches involve a significant \noverhead in planning, designing, and documenting the system. This overhead is jus-\ntified when the work of multiple development teams has to be coordinated, when the \nsystem is a critical system, and when many different people will be involved in \nmaintaining the software over its lifetime.\nHowever, when this heavyweight, plan-driven development approach is applied \nto small and medium-sized business systems, the overhead involved is so large that \nit dominates the software development process. More time is spent on how the sys-\ntem should be developed than on program development and testing. As the system \nrequirements change, rework is essential and, in principle at least, the specification \nand design have to change with the program.\nDissatisfaction with these heavyweight approaches to software engineering \nled to the development of agile methods in the late 1990s. These methods allowed \nthe development team to focus on the software itself rather than on its design and \ndocumentation. They are best suited to application development where the sys-\ntem requirements usually change rapidly during the development process. They \nare intended to deliver working software quickly to customers, who can then pro-\npose new and changed requirements to be included in later iterations of the sys-\ntem. They aim to cut down on process bureaucracy by avoiding work that has \ndubious long-term value and eliminating documentation that will probably never \nbe used.\nThe philosophy behind agile methods is reflected in the agile manifesto (http://\nagilemanifesto.org) issued by the leading developers of these methods. This mani-\nfesto states:\n", "page": 76, "type": "text", "section": "Page 76"}
{"text": "76\u2002 \u2002 Chapter 3\u2002 \u25a0\u2002 Agile software development\nWe are uncovering better ways of developing software by doing it and helping \nothers do it. Through this work we have come to value:\nIndividuals and interactions over processes and tools \nWorking software over comprehensive documentation \nCustomer collaboration over contract negotiation \nResponding to change over following a plan\nThat is, while there is value in the items on the right, we value the items on the \nleft more\u2020.\nAll agile methods suggest that software should be developed and delivered incre-\nmentally. These methods are based on different agile processes but they share a set \nof principles, based on the agile manifesto, and so they have much in common. I \nhave listed these principles in Figure 3.2.\nAgile methods have been particularly successful for two kinds of system \u00ad\ndevelopment.\n1.\t\nProduct development where a software company is developing a small or \nmedium-sized product for sale. Virtually all software products and apps are now \ndeveloped using an agile approach.\n2.\t\nCustom system development within an organization, where there is a clear com-\nmitment from the customer to become involved in the development process and \nwhere there are few external stakeholders and regulations that affect the software.\nAgile methods work well in these situations because it is possible to have con-\ntinuous communications between the product manager or system customer and the \ndevelopment team. The software itself is a stand-alone system rather than tightly \nintegrated with other systems being developed at the same time. Consequently, there \nis no need to coordinate parallel development streams. Small and medium-sized \nPrinciple\nDescription\nCustomer involvement\nCustomers should be closely involved throughout the development process. \nTheir role is provide and prioritize new system requirements and to evaluate \nthe iterations of the system.\nEmbrace change\nExpect the system requirements to change, and so design the system to \naccommodate these changes.\nIncremental delivery\nThe software is developed in increments, with the customer specifying the \nrequirements to be included in each increment.\nMaintain simplicity\nFocus on simplicity in both the software being developed and in the \ndevelopment process. Wherever possible, actively work to eliminate \ncomplexity from the system.\nPeople, not process\nThe skills of the development team should be recognized and exploited. \nTeam members should be left to develop their own ways of working without \nprescriptive processes.\nFigure 3.2\u2002 The \nprinciples of agile \nmethods\n\u2020http://agilemanifesto.org/\n", "page": 77, "type": "text", "section": "Page 77"}
{"text": "\t\n3.2 \u2002 \u25a0\u2002 Agile development techniques\u2002 \u2002 77\n\u00ad\nsystems can be developed by co-located teams, so informal communications among \nteam members work well.\n \n3.2  Agile development techniques\nThe ideas underlying agile methods were developed around the same time by a number \nof different people in the 1990s. However, perhaps the most significant approach to \nchanging software development culture was the development of Extreme Programming \n(XP). The name was coined by Kent Beck (Beck 1998) because the approach was \ndeveloped by pushing recognized good practice, such as iterative development, to \n\u201cextreme\u201d levels. For example, in XP, several new versions of a system may be devel-\noped by different programmers, integrated, and tested in a day. Figure 3.3 illustrates \nthe XP process to produce an increment of the system that is being developed.\nIn XP, requirements are expressed as scenarios (called user stories), which are \nimplemented directly as a series of tasks. Programmers work in pairs and develop \ntests for each task before writing the code. All tests must be successfully executed \nwhen new code is integrated into the system. There is a short time gap between \nreleases of the system.\nExtreme programming was controversial as it introduced a number of agile prac-\ntices that were quite different from the development practice of that time. These prac-\ntices are summarized in Figure 3.4 and reflect the principles of the agile manifesto:\n1.\t\nIncremental development is supported through small, frequent releases of the sys-\ntem. Requirements are based on simple customer stories or scenarios that are used \nas a basis for deciding what functionality should be included in a system increment.\n2.\t\nCustomer involvement is supported through the continuous engagement of the \ncustomer in the development team. The customer representative takes part in \nthe development and is responsible for defining acceptance tests for the system.\n3.\t\nPeople, not process, are supported through pair programming, collective owner-\nship of the system code, and a sustainable development process that does not \ninvolve excessively long working hours.\nBreak down\nstories to tasks\nSelect user\nstories for this\nrelease\nPlan release\nRelease\nsoftware\nEvaluate\nsystem\nDevelop/integrate/\ntest software\nFigure 3.3\u2002 The XP \nrelease cycle\n", "page": 78, "type": "text", "section": "Page 78"}
{"text": "78\u2002 \u2002 Chapter 3\u2002 \u25a0\u2002 Agile software development\nPrinciple or practice\nDescription\nCollective ownership\nThe pairs of developers work on all areas of the system, so that no islands of \nexpertise develop and all the developers take responsibility for all of the code. \nAnyone can change anything.\nContinuous \nintegration\nAs soon as the work on a task is complete, it is integrated into the whole \nsystem. After any such integration, all the unit tests in the system must pass.\nIncremental planning\nRequirements are recorded on \u201cstory cards,\u201d and the stories to be included in \na\u00a0release are determined by the time available and their relative priority. The \ndevelopers break these stories into development \u201ctasks.\u201d See Figures 3.5 \nand\u00a03.6.\nOn-site customer\nA representative of the end-user of the system (the Customer) should be \navailable full time for the use of the XP team. In an extreme programming \nprocess, the customer is a member of the development team and is \nresponsible for bringing system requirements to the team for implementation.\nPair programming\nDevelopers work in pairs, checking each other's work and providing the \nsupport to always do a good job.\nRefactoring\nAll developers are expected to refactor the code continuously as soon as \npotential code improvements are found. This keeps the code simple and \nmaintainable.\nSimple design\nEnough design is carried out to meet the current requirements and no more.\nSmall releases\nThe minimal useful set of functionality that provides business value is \ndeveloped first. Releases of the system are frequent and incrementally add \nfunctionality to the first release.\nSustainable pace\nLarge amounts of overtime are not considered acceptable, as the net effect is \noften to reduce code quality and medium-term productivity.\nTest first \ndevelopment\nAn automated unit test framework is used to write tests for a new piece of \nfunctionality before that functionality itself is implemented.\nFigure 3.4\u2002 Extreme \nprogramming practices 4.\t\nChange is embraced through regular system releases to customers, test-first \ndevelopment, refactoring to avoid code degeneration, and continuous integra-\ntion of new functionality.\n5.\t\nMaintaining simplicity is supported by constant refactoring that improves code \nquality and by using simple designs that do not unnecessarily anticipate future \nchanges to the system.\nIn practice, the application of Extreme Programming as originally proposed has \nproved to be more difficult than anticipated. It cannot be readily integrated with the \nmanagement practices and culture of most businesses. Therefore, companies adopt-\ning agile methods pick and choose those XP practices that are most appropriate for \ntheir way of working. Sometimes these are incorporated into their own development \nprocesses but, more commonly, they are used in conjunction with a management-\nfocused agile method such as Scrum (Rubin 2013).\n", "page": 79, "type": "text", "section": "Page 79"}
{"text": "\t\n3.2 \u2002 \u25a0\u2002 Agile development techniques\u2002 \u2002 79\nI am not convinced that XP on its own is a practical agile method for most com-\npanies, but its most significant contribution is probably the set of agile development \npractices that it introduced to the community. I discuss the most important of these \npractices in this section.\n\t\n3.2.1 \t User stories\nSoftware requirements always change. To handle these changes, agile methods do not \nhave a separate requirements engineering activity. Rather, they integrate requirements \nelicitation with development. To make this easier, the idea of \u201cuser stories\u201d was devel-\noped where a user story is a scenario of use that might be experienced by a system user.\nAs far as possible, the system customer works closely with the development team \nand discusses these scenarios with other team members. Together, they develop a \n\u201cstory card\u201d that briefly describes a story that encapsulates the customer needs. The \ndevelopment team then aims to implement that scenario in a future release of the \nsoftware. An example of a story card for the Mentcare system is shown in Figure 3.5. \nThis is a short description of a scenario for prescribing medication for a patient.\nUser stories may be used in planning system iterations. Once the story cards have \nbeen developed, the development team breaks these down into tasks (Figure 3.6) and \nestimates the effort and resources required for implementing each task. This usually \ninvolves discussions with the customer to refine the requirements. The customer \nthen prioritizes the stories for implementation, choosing those stories that can be \nKate is a doctor who wishes to prescribe medication for a patient attending a clinic.\nThe patient record is already displayed on her computer so she clicks on the\nmedication \ufb01eld and can select \u2018current medication\u2019, \u2018new medication\u2019 or \u2018formulary\u2019.\nIf she selects \u2018current medication\u2019, the system asks her to check the dose; If she\nwants to change the dose, she enters the new dose then con\ufb01rms the prescription.\nIf she chooses \u2018new medication\u2019, the system assumes that she knows which\nmedication to prescribe. She types the \ufb01rst few letters of the drug name. The system\ndisplays a list of possible drugs starting with these letters. She chooses the required\nmedication and the system responds by asking her to check that the medication\nselected is correct. She enters the dose then con\ufb01rms the prescription.\nIf she chooses \u2018formulary\u2019, the system displays a search box for the approved\nformulary. She can then search for the drug required. She selects a drug and is asked\nto check that the medication is correct. She enters the dose then con\ufb01rms the\nprescription.\nThe system always checks that the dose is within the approved range. If it isn\u2019t, Kate\nis asked to change the dose.\nAfter Kate has con\ufb01rmed the prescription, it will be displayed for checking. She either\nclicks \u2018OK\u2019 or \u2018Change\u2019. If she clicks \u2018OK\u2019, the prescription is recorded on the audit\ndatabase. If she clicks on \u2018Change\u2019, she reenters the \u2018Prescribing medication\u2019 process.\nPrescribing medication\nFigure 3.5\u2002 A  \n\u201cprescribing medication\u201d \nstory\n", "page": 80, "type": "text", "section": "Page 80"}
{"text": "80\u2002 \u2002 Chapter 3\u2002 \u25a0\u2002 Agile software development\nused immediately to deliver useful business support. The intention is to identify \n\u00ad\nuseful functionality that can be implemented in about two weeks, when the next \nrelease of the system is made available to the customer.\nOf course, as requirements change, the unimplemented stories change or may be \ndiscarded. If changes are required for a system that has already been delivered, new \nstory cards are developed and again, the customer decides whether these changes \nshould have priority over new functionality.\nThe idea of user stories is a powerful one\u2014people find it much easier to relate to \nthese stories than to a conventional requirements document or use cases. User stories can \nbe helpful in getting users involved in suggesting requirements during an initial prede-\nvelopment requirements elicitation activity. I discuss this in more detail in Chapter 4.\nThe principal problem with user stories is completeness. It is difficult to judge if \nenough user stories have been developed to cover all of the essential requirements \nof\u00a0a system. It is also difficult to judge if a single story gives a true picture of an \nactivity. Experienced users are often so familiar with their work that they leave \nthings out when describing it.\n\t\n3.2.2 \t Refactoring\nA fundamental precept of traditional software engineering is that you should design \nfor change. That is, you should anticipate future changes to the software and design \nit so that these changes can be easily implemented. Extreme programming, however, \nhas discarded this principle on the basis that designing for change is often wasted \neffort. It isn\u2019t worth taking time to add generality to a program to cope with change. \nOften the changes anticipated never materialize, or completely different change \nrequests may actually be made.\nOf course, in practice, changes will always have to be made to the code being devel-\noped. To make these changes easier, the developers of XP suggested that the code being \ndeveloped should be constantly refactored. Refactoring (Fowler et al. 1999) means that \nthe programming team look for possible improvements to the software and implements \nTask 1: Change dose of prescribed drug\nTask 2: Formulary selection\nTask 3: Dose checking\nDose checking is a safety precaution to check that\nthe doctor has not prescribed a dangerously small or\nlarge dose.\nUsing the formulary id for the generic drug name,\nlook up the formulary and retrieve the recommended\nmaximum and minimum dose.\nCheck the prescribed dose against the minimum and\nmaximum. If outside the range, issue an error\nmessage saying that the dose is too high or too low.\nIf within the range, enable the \u2018Con\ufb01rm\u2019 button.\nFigure 3.6\u2002 Examples of \ntask cards for prescribing \nmedication\n", "page": 81, "type": "text", "section": "Page 81"}
{"text": "\t\n3.2 \u2002 \u25a0\u2002 Agile development techniques\u2002 \u2002 81\nthem immediately. When team members see code that can be improved, they make \nthese improvements even in situations where there is no immediate need for them.\nA fundamental problem of incremental development is that local changes tend to \ndegrade the software structure. Consequently, further changes to the software become \nharder and harder to implement. Essentially, the development proceeds by finding \nworkarounds to problems, with the result that code is often duplicated, parts of the \nsoftware are reused in inappropriate ways, and the overall structure degrades as code is \nadded to the system. Refactoring improves the software structure and readability and \nso avoids the structural deterioration that naturally occurs when software is changed.\nExamples of refactoring include the reorganization of a class hierarchy to remove \nduplicate code, the tidying up and renaming of attributes and methods, and the \nreplacement of similar code sections, with calls to methods defined in a program \nlibrary. Program development environments usually include tools for refactoring. \nThese simplify the process of finding dependencies between code sections and mak-\ning global code modifications.\nIn principle, when refactoring is part of the development process, the software \nshould always be easy to understand and change as new requirements are proposed. \nIn practice, this is not always the case. Sometimes development pressure means that \nrefactoring is delayed because the time is devoted to the implementation of new \nfunctionality. Some new features and changes cannot readily be accommodated by \ncode-level refactoring and require that the architecture of the system be modified.\n\t\n3.2.3 \t Test-first development\nAs I discussed in the introduction to this chapter, one of the important differences \nbetween incremental development and plan-driven development is in the way that \nthe system is tested. With incremental development, there is no system specification \nthat can be used by an external testing team to develop system tests. As a conse-\nquence, some approaches to incremental development have a very informal testing \nprocess, in comparison with plan-driven testing.\nExtreme Programming developed a new approach to program testing to address \nthe difficulties of testing without a specification. Testing is automated and is central \nto the development process, and development cannot proceed until all tests have \nbeen successfully executed. The key features of testing in XP are:\n1.\t\ntest-first development,\n2.\t\nincremental test development from scenarios,\n3.\t\nuser involvement in the test development and validation, and\n4.\t\nthe use of automated testing frameworks.\nXP\u2019s test-first philosophy has now evolved into more general test-driven develop-\nment techniques (Jeffries and Melnik 2007). I believe that test-driven development is \none of the most important innovations in software engineering. Instead of writing code \nand then writing tests for that code, you write the tests before you write the code. This \n", "page": 82, "type": "text", "section": "Page 82"}
{"text": "82\u2002 \u2002 Chapter 3\u2002 \u25a0\u2002 Agile software development\nmeans that you can run the test as the code is being written and discover problems dur-\ning development. I discuss test-driven development in more depth in Chapter 8.\nWriting tests implicitly defines both an interface and a specification of behavior for \nthe functionality being developed. Problems of requirements and interface misunder-\nstandings are reduced. Test-first development requires there to be a clear relationship \nbetween system requirements and the code implementing the corresponding require-\nments. In XP, this relationship is clear because the story cards representing the require-\nments are broken down into tasks and the tasks are the principal unit of implementation.\nIn test-first development, the task implementers have to thoroughly understand \nthe specification so that they can write tests for the system. This means that ambi-\nguities and omissions in the specification have to be clarified before implementation \nbegins. Furthermore, it also avoids the problem of \u201ctest-lag.\u201d This may happen when \nthe developer of the system works at a faster pace than the tester. The implementa-\ntion gets further and further ahead of the testing and there is a tendency to skip tests, \nso that the development schedule can be maintained.\nXP\u2019s test-first approach assumes that user stories have been developed, and these \nhave been broken down into a set of task cards, as shown in Figure 3.6. Each task \ngenerates one or more unit tests that check the implementation described in that task. \nFigure 3.7 is a shortened description of a test case that has been developed to check \nthat the prescribed dose of a drug does not fall outside known safe limits.\nThe role of the customer in the testing process is to help develop acceptance tests \nfor the stories that are to be implemented in the next release of the system. As I \nexplain in Chapter 8, acceptance  testing is the process whereby the system is tested \nusing customer data to check that it meets the customer\u2019s real needs.\nTest automation is essential for test-first development. Tests are written as exe-\ncutable components before the task is implemented. These testing components \nshould be stand-alone, should simulate the submission of input to be tested, and \nshould check that the result meets the output specification. An automated test frame-\nwork is a system that makes it easy to write executable tests and submit a set of tests \nfor execution. Junit (Tahchiev et al. 2010) is a widely used example of an automated \ntesting framework for Java programs.\nInput:\n1.  A number in mg representing a single dose of the drug.\n2.  A number representing the number of single doses per day.\nTests:\n1.   Test for inputs where the single dose is correct but the frequency is too\nhigh.\n2.   Test for inputs where the single dose is too high and too low.\n3.   Test for inputs where the single dose * frequency is too high and too low.\n4.   Test for inputs where single dose * frequency is in the permitted range.\nOutput:\nOK or error message indicating that the dose is outside the safe range.\nTest 4: Dose checking\nFigure 3.7\u2002 Test case \ndescription for dose \nchecking\n", "page": 83, "type": "text", "section": "Page 83"}
{"text": "\t\n3.2 \u2002 \u25a0\u2002 Agile development techniques\u2002 \u2002 83\nAs testing is automated, there is always a set of tests that can be quickly and eas-\nily executed. Whenever any functionality is added to the system, the tests can be run \nand problems that the new code has introduced can be caught immediately.\nTest-first development and automated testing usually result in a large number of \ntests being written and executed. However, there are problems in ensuring that test \ncoverage is complete:\n1.\t\nProgrammers prefer programming to testing, and sometimes they take shortcuts \nwhen writing tests. For example, they may write incomplete tests that do not \ncheck for all possible exceptions that may occur.\n2.\t\nSome tests can be very difficult to write incrementally. For example, in a com-\nplex user interface, it is often difficult to write unit tests for the code that imple-\nments the \u201cdisplay logic\u201d and workflow between screens.\nIt is difficult to judge the completeness of a set of tests. Although you may have a lot \nof system tests, your test set may not provide complete coverage. Crucial parts of \nthe\u00a0system may not be executed and so will remain untested. Therefore, although a \nlarge set of frequently executed tests may give the impression that the system is complete \nand correct, this may not be the case. If the tests are not reviewed and further tests are \nwritten after development, then undetected bugs may be delivered in the system release.\n\t\n3.2.4 \t Pair programming\nAnother innovative practice that was introduced in XP is that programmers work in \npairs to develop the software. The programming pair sits at the same computer to \ndevelop the software. However, the same pair do not always program together. \nRather, pairs are created dynamically so that all team members work with each other \nduring the development process.\nPair programming has a number of advantages.\n1.\t\nIt supports the idea of collective ownership and responsibility for the system. \nThis reflects Weinberg\u2019s idea of egoless programming (Weinberg 1971) where \nthe software is owned by the team as a whole and individuals are not held \nresponsible for problems with the code. Instead, the team has collective respon-\nsibility for resolving these problems.\n2.\t\nIt acts as an informal review process because each line of code is looked at by at least \ntwo people. Code inspections and reviews (Chapter 24) are effective in discovering \na high percentage of software errors. However, they are time consuming to organize \nand, typically, introduce delays into the development process. Pair programming is a \nless formal process that probably doesn\u2019t find as many errors as code inspections. \nHowever, it is cheaper and easier to organize than formal program inspections.\n3.\t\nIt encourages refactoring to improve the software structure. The problem with ask-\ning programmers to refactor in a normal development environment is that effort \n", "page": 84, "type": "text", "section": "Page 84"}
{"text": "84\u2002 \u2002 Chapter 3\u2002 \u25a0\u2002 Agile software development\ninvolved is expended for long-term benefit. An developer who spends time refac-\ntoring may be judged to be less efficient than one who simply carries on developing \ncode. Where pair programming and collective ownership are used, others benefit \nimmediately from the refactoring so they are likely to support the process.\nYou might think that pair programming would be less efficient than individual \nprogramming. In a given time, a pair of developers would produce half as much code \nas two individuals working alone. Many companies that have adopted agile methods \nare suspicious of pair programming and do not use it. Other companies mix pair and \nindividual programming with an experienced programmer working with a less expe-\nrienced colleague when they have problems.\nFormal studies of the value of pair programming have had mixed results. Using \nstudent volunteers, Williams and her collaborators (Williams et al. 2000) found that \nproductivity with pair programming seems to be comparable to that of two people \nworking independently. The reasons suggested are that pairs discuss the software \nbefore development and so probably have fewer false starts and less rework. \nFurthermore, the number of errors avoided by the informal inspection is such that \nless time is spent repairing bugs discovered during the testing process.\nHowever, studies with more experienced programmers did not replicate these \nresults (Arisholm et al. 2007). They found that there was a significant loss of produc-\ntivity compared with two programmers working alone. There were some quality \nbenefits, but these did not fully compensate for the pair-programming overhead. \nNevertheless, the sharing of knowledge that happens during pair programming is \nvery important as it reduces the overall risks to a project when team members leave. \nIn itself, this may make pair programming worthwhile.\n \n3.3  Agile project management\nIn any software business, managers need to know what is going on and whether or not \na project is likely to meet its objectives and deliver the software on time with the pro-\nposed budget. Plan-driven approaches to software development evolved to meet this \nneed. As I discussed in Chapter 23, managers  draw up a plan for the project showing \nwhat should be delivered, when it should be delivered, and who will work on the devel-\nopment of the project deliverables. A plan-based approach requires a manager to have \na stable view of everything that has to be developed and the development processes.\nThe informal planning and project control that was proposed by the early adher-\nents of agile methods clashed with this business requirement for visibility. Teams \nwere self-organizing, did not produce documentation, and planned development in \nvery short cycles. While this can and does work for small companies developing \nsoftware products, it is inappropriate for larger companies who need to know what is \ngoing on in their organization.\nLike every other professional software development process, agile development \nhas to be managed so that the best use is made of the time and resources available to \n", "page": 85, "type": "text", "section": "Page 85"}
{"text": "\t\n3.3 \u2002 \u25a0\u2002 Agile project management\u2002 \u2002 85\nthe team. To address this issue, the Scrum agile method was developed (Schwaber \nand Beedle 2001; Rubin 2013) to provide a framework for organizing agile projects \nand, to some extent at least, provide external visibility of what is going on. The devel-\nopers of Scrum wished to make clear that Scrum was not a method for project man-\nagement in the conventional sense, so they deliberately invented new terminology, \nsuch as ScrumMaster, which replaced names such as project manager. Figure 3.8 \nsummarizes Scrum terminology and what it means.\nScrum is an agile method insofar as it follows the principles from the agile mani-\nfesto, which I showed in Figure 3.2. However, it focuses on providing a framework \nfor agile project organization, and it does not mandate the use of specific development \nScrum term\nDefinition\nDevelopment team\nA self-organizing group of software developers, which should be no \nmore than seven people. They are responsible for developing the \nsoftware and other essential project documents.\nPotentially shippable product \nincrement\nThe software increment that is delivered from a sprint. The idea is that \nthis should be \u201cpotentially shippable,\u201d which means that it is in a \nfinished state and no further work, such as testing, is needed to \nincorporate it into the final product. In practice, this is not always \nachievable.\nProduct backlog\nThis is a list of \u201cto do\u201d items that the Scrum team must tackle. They \nmay be feature definitions for the software, software requirements, user \nstories, or descriptions of supplementary tasks that are needed, such as \narchitecture definition or user documentation.\nProduct owner\nAn individual (or possibly a small group) whose job is to identify \nproduct features or requirements, prioritize these for development, and \ncontinuously review the product backlog to ensure that the project \ncontinues to meet critical business needs. The Product Owner can be a \ncustomer but might also be a product manager in a software company \nor other stakeholder representative.\nScrum\nA daily meeting of the Scrum team that reviews progress and prioritizes \nwork to be done that day. Ideally, this should be a short face-to-face \nmeeting that includes the whole team.\nScrumMaster\nThe ScrumMaster is responsible for ensuring that the Scrum process is \nfollowed and guides the team in the effective use of Scrum. He or she \nis responsible for interfacing with the rest of the company and for \nensuring that the Scrum team is not diverted by outside interference. \nThe Scrum developers are adamant that the ScrumMaster should not \nbe thought of as a project manager. Others, however, may not always \nfind it easy to see the difference.\nSprint\nA development iteration. Sprints are usually 2 to 4 weeks long.\nVelocity\nAn estimate of how much product backlog effort a team can cover in a \nsingle sprint. Understanding a team\u2019s velocity helps them estimate what \ncan be covered in a sprint and provides a basis for measuring \nimproving performance.\nFigure 3.8\u2002 Scrum \nterminology\n", "page": 86, "type": "text", "section": "Page 86"}
{"text": "86\u2002 \u2002 Chapter 3\u2002 \u25a0\u2002 Agile software development\npractices such as pair programming and test-first development. This means that it \ncan be more easily integrated with existing practice in a company. Consequently, as \nagile methods have become a mainstream approach to software development, Scrum \nhas emerged as the most widely used method.\nThe Scrum process or sprint cycle is shown in Figure 3.9. The input to the process \nis the product backlog. Each process iteration produces a product increment that \ncould be delivered to customers.\nThe starting point for the Scrum sprint cycle is the product backlog\u2014the list of \nitems such as product features, requirements, and engineering improvement that \nhave to be worked on by the Scrum team. The initial version of the product backlog \nmay be derived from a requirements document, a list of user stories, or other descrip-\ntion of the software to be developed.\nWhile the majority of entries in the product backlog are concerned with the imple-\nmentation of system features, other activities may also be included. Sometimes, when \nplanning an iteration, questions that cannot be easily answered come to light and addi-\ntional work is required to explore possible solutions. The team may carry out some pro-\ntotyping or trial development to understand the problem and solution. There may also be \nbacklog items to design the system architecture or to develop system documentation.\nThe product backlog may be specified at varying levels of detail, and it is the \nresponsibility of the Product Owner to ensure that the level of detail in the specifica-\ntion is appropriate for the work to be done. For example, a backlog item could be a \ncomplete user story such as that shown in Figure 3.5, or it could simply be an instruc-\ntion such as \u201cRefactor user interface code\u201d that leaves it up to the team to decide on \nthe refactoring to be done.\nEach sprint cycle lasts a fixed length of time, which is usually between 2 and 4 weeks. \nAt the beginning of each cycle, the Product Owner prioritizes the items on the product \nbacklog to define which are the most important items to be developed in that cycle. \nSprints are never extended to take account of unfinished work. Items are returned to the \nproduct backlog if these cannot be completed within the allocated time for the sprint.\nThe whole team is then involved in selecting which of the highest priority items \nthey believe can be completed. They then estimate the time required to complete \nthese items. To make these estimates, they use the velocity attained in previous \nReview work \nto be done\nSelect \nitems\nPlan\nsprint\nReview\nsprint\nSprint\nScrum\nProduct\nbacklog\nSprint\nbacklog\nPotentially\nshippable\nsoftware\nFigure 3.9\u2002 The Scrum \nsprint cycle\n", "page": 87, "type": "text", "section": "Page 87"}
{"text": "\t\n3.3 \u2002 \u25a0\u2002 Agile project management\u2002 \u2002 87\nsprints, that is, how much of the backlog could be covered in a single sprint. This \nleads to the creation of a sprint backlog\u2014the work to be done during that sprint. The \nteam self-organizes to decide who will work on what, and the sprint begins.\nDuring the sprint, the team holds short daily meetings (Scrums) to review pro-\ngress and, where necessary, to re-prioritize work. During the Scrum, all team mem-\nbers share information, describe their progress since the last meeting, bring up \nproblems that have arisen, and state what is planned for the following day. Thus, \neveryone on the team knows what is going on and, if problems arise, can re-plan \nshort-term work to cope with them. Everyone participates in this short-term plan-\nning; there is no top-down direction from the ScrumMaster.\nThe daily interactions among Scrum teams may be coordinated using a Scrum \nboard. This is an office whiteboard that includes information and post-it notes about \nthe Sprint backlog, work done, unavailability of staff, and so on. This is a shared \nresource for the whole team, and anyone can change or move items on the board. It \nmeans that any team member can, at a glance, see what others are doing and what \nwork remains to be done.\nAt the end of each sprint, there is a review meeting, which involves the whole \nteam. This meeting has two purposes. First, it is a means of process improvement. \nThe team reviews the way they have worked and reflects on how things could have \nbeen done better. Second, it provides input on the product and the product state for \nthe product backlog review that precedes the next sprint.\nWhile the ScrumMaster is not formally a project manager, in practice ScrumMasters \ntake this role in many organizations that have a conventional management structure. \nThey report on progress to senior management and are involved in longer-term plan-\nning and project budgeting. They may be involved in project administration (agreeing \non holidays for staff, liaising with HR, etc.) and hardware and software purchases.\nIn various Scrum success stories (Schatz and Abdelshafi 2005; Mulder and van \nVliet 2008; Bellouiti 2009), the things that users like about the Scrum method are:\n1.\t\nThe product is broken down into a set of manageable and understandable chunks \nthat stakeholders can relate to.\n2.\t\nUnstable requirements do not hold up progress.\n3.\t\nThe whole team has visibility of everything, and consequently team communi-\ncation and morale are improved.\n4.\t\nCustomers see on-time delivery of increments and gain feedback on how the \nproduct works. They are not faced with last-minute surprises when a team \nannounces that software will not be delivered as expected.\n5.\t\nTrust between customers and developers is established, and a positive culture is \ncreated in which everyone expects the project to succeed.\nScrum, as originally designed, was intended for use with co-located teams where \nall team members could get together every day in stand-up meetings. However, \nmuch software development now involves distributed teams, with team members \nlocated in different places around the world. This allows companies to take advantage \n", "page": 88, "type": "text", "section": "Page 88"}
{"text": "88\u2002 \u2002 Chapter 3\u2002 \u25a0\u2002 Agile software development\nof lower cost staff in other countries, makes access to specialist skills possible, and \nallows for 24-hour development, with work going on in different time zones.\nConsequently, there have been developments of Scrum for distributed development \nenvironments and multi-team working. Typically, for offshore development, the prod-\nuct owner is in a different country from the development team, which may also be \ndistributed. Figure 3.10 shows the requirements for Distributed Scrum (Deemer 2011).\n \n3.4  Scaling agile methods\nAgile methods were developed for use by small programming teams that could work \ntogether in the same room and communicate informally. They were originally used \nby for the development of small and medium-sized systems and software products. \nSmall companies, without formal processes or bureaucracy, were enthusiastic initial \nadopters of these methods.\nOf course, the need for faster delivery of software, which is more suited to cus-\ntomer needs, also applies to both larger systems and larger companies. Consequently, \nover the past few years, a lot of work has been put into evolving agile methods for \nboth large software systems and for use in large companies.\nScaling agile methods has closely related facets:\n1.\t\nScaling up these methods to handle the development of large systems that are \ntoo big to be developed by a single small team.\n2.\t\nScaling out these methods from specialized development teams to more widespread \nuse in a large company that has many years of software development experience.\nVideoconferencing \nbetween the product \nowner and the \ndevelopment team\nDistributed Scrum\nThe ScrumMaster \nshould be located with \nthe development team \nso that he or she is \naware of everyday \nproblems.\nThe Product Owner \nshould visit the \ndevelopers and try to \nestablish a good \nrelationship with them. \nIt is essential that they \ntrust each other.\nReal-time communica-\ntions between team \nmembers for informal \ncommunication, \nparticularly instant \nmessaging and video \ncalls.\nContinuous integration, \nso that all team \nmembers can be aware \nof the state of the \nproduct at any time.\nA common development \nenvironment for all teams\nFigure 3.10\u2002 Distributed \nScrum \n", "page": 89, "type": "text", "section": "Page 89"}
{"text": "\t\n3.4 \u2002 \u25a0\u2002 Scaling agile methods\u2002 \u2002 89\nOf course, scaling up and scaling out are closely related. Contracts to develop \nlarge software systems are usually awarded to large organizations, with multiple \nteams working on the development project. These large companies have often exper-\nimented with agile methods in smaller projects, so they face the problems of scaling \nup and scaling out at the same time.\nThere are many anecdotes about the effectiveness of agile methods, and it has \nbeen suggested that these can lead to orders of magnitude improvements in produc-\ntivity and comparable reductions in defects. Ambler (Ambler 2010), an influential \nagile method developer, suggests that these productivity improvements are exagger-\nated for large systems and organizations. He suggests that an organization moving to \nagile methods can expect to see productivity improvement across the organization of \nabout 15% over 3 years, with similar reductions in the number of product defects.\n\t\n3.4.1 \t Practical problems with agile methods\nIn some areas, particularly in the development of software products and apps, agile \ndevelopment has been incredibly successful. It is by far the best approach to use for \nthis type of system. However, agile methods may not be suitable for other types of \nsoftware development, such as embedded systems engineering or the development \nof large and complex systems.\nFor large, long-lifetime systems that are developed by a software company for an \nexternal client, using an agile approach presents a number of problems.\n1.\t\nThe informality of agile development is incompatible with the legal approach to \ncontract definition that is commonly used in large companies.\n2.\t\nAgile methods are most appropriate for new software development rather than \nfor software maintenance. Yet the majority of software costs in large companies \ncome from maintaining their existing software systems.\n3.\t\nAgile methods are designed for small co-located teams, yet much software \ndevelopment now involves worldwide distributed teams.\nContractual issues can be a major problem when agile methods are used. When \nthe system customer uses an outside organization for system development, a contract \nfor the software development is drawn up between them. The software requirements \ndocument is usually part of that contract between the customer and the supplier. \nBecause the interleaved development of requirements and code is fundamental to \nagile methods, there is no definitive statement of requirements that can be included \nin the contract.\nConsequently, agile methods have to rely on contracts in which the customer \npays for the time required for system development rather than the development of a \nspecific set of requirements. As long as all goes well, this benefits both the customer \nand the developer. However, if problems arise, then there may be difficult disputes \nover who is to blame and who should pay for the extra time and resources required \nto resolve the problems.\n", "page": 90, "type": "text", "section": "Page 90"}
{"text": "90\u2002 \u2002 Chapter 3\u2002 \u25a0\u2002 Agile software development\nAs I explain in Chapter 9, a  huge amount of software engineering effort goes into the \nmaintenance and evolution of existing software systems. Agile practices, such as incre-\nmental delivery, design for change, and maintaining simplicity all make sense when soft-\nware is being changed. In fact, you can think of an agile development process as a process \nthat supports continual change. If agile methods are used for software product develop-\nment, new releases of the product or app simply involve continuing the agile approach.\nHowever, where maintenance involves a custom system that must be changed in \nresponse to new business requirements, there is no clear consensus on the suitability \nof agile methods for software maintenance (Bird 2011; Kilner 2012). Three types of \nproblems can arise:\n\u25a0\t lack of product documentation\n\u25a0\t keeping customers involved\n\u25a0\t development team continuity\nFormal documentation is supposed to describe the system and so make it easier \nfor people changing the system to understand. In practice, however, formal docu-\nmentation is rarely updated and so does not accurately reflect the program code. For \nthis reason, agile methods enthusiasts argue that it is a waste of time to write this \ndocumentation and that the key to implementing maintainable software is to produce \nhigh-quality, readable code. The lack of documentation should not be a problem in \nmaintaining systems developed using an agile approach.\nHowever, my experience of system maintenance is that the most important docu-\nment is the system requirements document, which tells the software engineer what the \nsystem is supposed to do. Without such knowledge, it is difficult to assess the impact of \nproposed system changes. Many agile methods collect requirements informally and \nincrementally and do not create a coherent requirements document. The use of agile \nmethods may therefore make subsequent system maintenance more difficult and expen-\nsive. This is a particular problem if development team continuity cannot be maintained.\nA key challenge in using an agile approach to maintenance is keeping customers \ninvolved in the process. While a customer may be able to justify the full-time involve-\nment of a representative during system development, this is less likely during mainte-\nnance where changes are not continuous. Customer representatives are likely to lose \ninterest in the system. Therefore, it is likely that alternative mechanisms, such as change \nproposals, discussed in Chapter 25, will have to be adapted to fit in with an agile approach.\nAnother potential problem that may arise is maintaining continuity of the devel-\nopment team. Agile methods rely on team members understanding aspects of the \nsystem without having to consult documentation. If an agile development team is \nbroken up, then this implicit knowledge is lost and it is difficult for new team mem-\nbers to build up the same understanding of the system and its components. Many \nprogrammers prefer to work on new development to software maintenance, and so \nthey are unwilling to continue to work on a software system after the first release has \nbeen delivered. Therefore, even when the intention is to keep the development team \ntogether, people leave if they are assigned maintenance tasks.\n", "page": 91, "type": "text", "section": "Page 91"}
{"text": "\t\n3.4 \u2002 \u25a0\u2002 Scaling agile methods\u2002 \u2002 91\n\t\n3.4.2 \t Agile and plan-driven methods\nA fundamental requirement of scaling agile methods is to integrate them with plan-\ndriven approaches. Small startup companies can work with informal and short-term \nplanning, but larger companies have to have longer-term plans and budgets for \ninvestment, staffing, and business development. Their software development must \nsupport these plans, so longer-term software planning is essential.\nEarly adopters of agile methods in the first decade of the 21st century were enthu-\nsiasts and deeply committed to the agile manifesto. They deliberately rejected the \nplan-driven approach to software engineering and were reluctant to change the ini-\ntial vision of agile methods in any way. However, as organizations saw the value and \nbenefits of an agile approach, they adapted these methods to suit their own culture \nand ways of working. They had to do this because the principles underlying agile \nmethods are sometimes difficult to realize in practice (Figure 3.11).\nTo address these problems, most large \u201cagile\u201d software development projects com-\nbine practices from plan-driven and agile approaches. Some are mostly agile, and others \nare mostly plan-driven but with some agile practices. To decide on the balance between \na plan-based and an agile approach, you have to answer a range of technical, human and \norganizational questions. These relate to the system being developed, the development \nteam, and the organizations that are developing and procuring the system (Figure 3.12).\nAgile methods were developed and refined in projects to develop small to medium-\nsized business systems and software products, where the software developer controls \nthe specification of the system. Other types of system have attributes such as size, com-\nplexity, real-time response, and external regulation that mean a \u201cpure\u201d agile approach is \nPrinciple\nPractice\nCustomer involvement\nThis depends on having a customer who is willing and able to spend time with \nthe development team and who can represent all system stakeholders. Often, \ncustomer representatives have other demands on their time and cannot play a \nfull part in the software development. Where there are external stakeholders, \nsuch as regulators, it is difficult to represent their views to the agile team.\nEmbrace change\nPrioritizing changes can be extremely difficult, especially in systems for which \nthere are many stakeholders. Typically, each stakeholder gives different \npriorities to different changes.\nIncremental delivery\nRapid iterations and short-term planning for development does not always fit \nin with the longer-term planning cycles of business planning and marketing. \nMarketing managers may need to know product features several months in \nadvance to prepare an effective marketing campaign.\nMaintain simplicity\nUnder pressure from delivery schedules, team members may not have time to \ncarry out desirable system simplifications.\nPeople, not process\nIndividual team members may not have suitable personalities for the intense \ninvolvement that is typical of agile methods and therefore may not interact \nwell with other team members.\nFigure 3.11\u2002 Agile \nprinciples and \norganizational practice\n", "page": 92, "type": "text", "section": "Page 92"}
{"text": "92\u2002 \u2002 Chapter 3\u2002 \u25a0\u2002 Agile software development\nunlikely to work. There needs to be some up-front planning, design, and documentation \nin the systems engineering process. Some of the key issues are as follows:\n1.\t\nHow large is the system that is being developed? Agile methods are most effective \nwhen the system can be developed with a relatively small co-located team who \ncan communicate informally. This may not be possible for large systems that \nrequire larger development teams, so a plan-driven approach may have to be used.\n2.\t\nWhat type of system is being developed? Systems that require a lot of analysis \nbefore implementation (e.g., real-time system with complex timing require-\nments) usually need a fairly detailed design to carry out this analysis. A plan-\ndriven approach may be best in those circumstances.\n3.\t\nWhat is the expected system lifetime? Long-lifetime systems may require more \ndesign documentation to communicate the original intentions of the system \ndevelopers to the support team. However, supporters of agile methods rightly \nargue that documentation is frequently not kept up to date and is not of much \nuse for long-term system maintenance.\n4.\t\nIs the system subject to external regulation? If a system has to be approved \nby\u00a0an external regulator (e.g., the Federal Aviation Administration approves \nsoftware that is critical to the operation of an aircraft), then you will probably be \nrequired to produce detailed documentation as part of the system safety\u00a0case.\nAgile methods place a great deal of responsibility on the development team to \ncooperate and communicate during the development of the system. They rely on indi-\nvidual engineering skills and software support for the development process. However, \nin reality, not everyone is a highly skilled engineer, people do not communicate effec-\ntively, and it is not always possible for teams to work together. Some planning may be \nrequired to make the most effective use of the people available. Key issues are:\n1.\t How good are the designers and programmers in the development team? \nIt\u00a0is\u00a0sometimes argued that agile methods require higher skill levels than plan-\nbased approaches in which programmers simply translate a detailed design into \ncode. If you have a team with relatively low skill levels, you may need to use \nthe best people to develop the design, with others responsible for programming.\nSystem\nTeam\nOrganization\nScale\nTechnology\nDistribution\nContracts\nDelivery\nRegulation\nType\nLifetime\nCompetence\nCulture\nFigure 3.12\u2002 Factors \ninfluencing the choice  \nof plan-based or agile \ndevelopment\n", "page": 93, "type": "text", "section": "Page 93"}
{"text": "\t\n3.4 \u2002 \u25a0\u2002 Scaling agile methods\u2002 \u2002 93\n2.\t\nHow is the development team organized? If the development team is distributed \nor if part of the development is being outsourced, then you may need to develop \ndesign documents to communicate across the development teams.\n3.\t\nWhat technologies are available to support system development? Agile methods \noften rely on good tools to keep track of an evolving design. If you are develop-\ning a system using an IDE that does not have good tools for program visualiza-\ntion and analysis, then more design documentation may be required.\nTelevision and films have created a popular vision of software companies as \ninformal organizations run by young men (mostly) who provide a fashionable work-\ning environment, with a minimum of bureaucracy and organizational procedures. \nThis is far from the truth. Most software is developed in large companies that have \nestablished their own working practices and procedures. Management in these \n\u00ad\ncompanies may be uncomfortable with the lack of documentation and the informal \ndecision making in agile methods. Key issues are:\n1.\t\nIs it important to have a very detailed specification and design before moving to \nimplementation, perhaps for contractual reasons? If so, you probably need to \nuse a plan-driven approach for requirements engineering but may use agile \ndevelopment practices during system implementation.\n2.\t\nIs an incremental delivery strategy, where you deliver the software to customers \nor other system stakeholders and get rapid feedback from them, realistic? Will \ncustomer representatives be available, and are they willing to participate in the \ndevelopment team?\n3.\t\nAre there cultural issues that may affect system development? Traditional engi-\nneering organizations have a culture of plan-based development, as this is the \nnorm in engineering. This usually requires extensive design documentation \nrather than the informal knowledge used in agile processes.\nIn reality, the issue of whether a project can be labeled as plan-driven or agile \nis\u00a0not very important. Ultimately, the primary concern of buyers of a software \u00ad\nsystem \nis whether or not they have an executable software system that meets their needs and \ndoes useful things for the individual user or the organization. Software developers \nshould be pragmatic and should choose those methods that are most effective for the \ntype of system being developed, whether or not these are labeled agile or plan-driven.\n\t\n3.4.3 \t Agile methods for large systems\nAgile methods have to evolve to be used for large-scale software development. \nThe fundamental reason for this is that large-scale software systems are much \nmore complex and difficult to understand and manage than small-scale systems \nor software products. Six principal factors (Figure 3.13) contribute to this \n\u00ad\ncomplexity:\n", "page": 94, "type": "text", "section": "Page 94"}
{"text": "94\u2002 \u2002 Chapter 3\u2002 \u25a0\u2002 Agile software development\n1.\t\nLarge systems are usually systems of systems\u2014collections of separate, com-\nmunicating systems, where separate teams develop each system. Frequently, \nthese teams are working in different places, sometimes in different time zones. \nIt is practically impossible for each team to have a view of the whole system. \nConsequently, their priorities are usually to complete their part of the system \nwithout regard for wider systems issues.\n2.\t\nLarge systems are brownfield systems (Hopkins and Jenkins 2008); that is, they \ninclude and interact with a number of existing systems. Many of the system require-\nments are concerned with this interaction and so don\u2019t really lend themselves to \nflexibility and incremental development. Political issues can also be significant \nhere\u2014often the easiest solution to a problem is to change an existing system. \nHowever, this requires negotiation with the managers of that system to convince \nthem that the changes can be implemented without risk to the system\u2019s operation.\n3.\t\nWhere several systems are integrated to create a system, a significant fraction of \nthe development is concerned with system configuration rather than original \ncode development. This is not necessarily compatible with incremental devel-\nopment and frequent system integration.\n4.\t\nLarge systems and their development processes are often constrained by exter-\nnal rules and regulations limiting the way that they can be developed, that \nrequire certain types of system documentation to be produced, and so on. \nCustomers may have specific compliance requirements that may have to be fol-\nlowed, and these may require process documentation to be completed.\n5.\t\nLarge systems have a long procurement and development time. It is difficult to \nmaintain coherent teams who know about the system over that period as, inevi-\ntably, people move on to other jobs and projects.\n6.\t\nLarge systems usually have a diverse set of stakeholders with different perspec-\ntives and objectives. For example, nurses and administrators may be the end-users \nof a medical system, but senior medical staff, hospital managers, and others, are \nalso stakeholders in the system. It is practically impossible to involve all of \nthese different stakeholders in the development process.\nLarge software system\nSystem of\nsystems\nBrownfield\ndevelopment\nDiverse\nstakeholders\nProlonged\nprocurement\nSystem\nconfiguration\nRegulatory\nconstraints\nFigure 3.13\u2002 Large \nproject characteristics\n", "page": 95, "type": "text", "section": "Page 95"}
{"text": "\t\n3.4 \u2002 \u25a0\u2002 Scaling agile methods\u2002 \u2002 95\nDean Leffingwell, who has a great deal of experience in scaling agile methods, \nhas developed the Scaled Agile Framework (Leffingwell 2007, 2011) to support \nlarge-scale, multi-team software development. He reports how this method has been \nused successfully in a number of large companies. IBM has also developed a frame-\nwork for the large-scale use of agile methods called the Agile Scaling Model (ASM). \nFigure 3.14, taken from Ambler\u2019s white paper that discusses ASM (Ambler 2010), \nshows an overview of this model.\nThe ASM recognizes that scaling is a staged process where development teams \nmove from the core agile practices discussed here to what is called Disciplined Agile \nDelivery. Essentially, this stage involves adapting these practices to a disciplined \norganizational setting and recognizing that teams cannot simply focus on develop-\nment but must also take into account other stages of the software engineering \n\u00ad\nprocess, such as requirements and architectural design.\nThe final scaling stage in ASM is to move to Agility at Scale where the com-\nplexity that is inherent in large projects is recognized. This involves taking account \nof factors such as distributed development, complex legacy environments, and \nregulatory compliance requirements. The practices used for disciplined agile \ndelivery may have to be modified on a project-by-project basis to take these into \naccount and, sometimes, additional plan-based practices added to the process.\nNo single model is appropriate for all large-scale agile products as the type of \nproduct, the customer requirements, and the people available are all different. \nHowever, approaches to scaling agile methods have a number of things in common:\nCore agile \ndevelopment\nDisciplined \nagile delivery\nAgility at\nscale\nAgility at scale\nDisciplined agile delivery where \nscaling factors apply:\nLarge team size\nGeographic distribution\nRegulatory compliance\nDomain complexity\nOrganization distribution\nTechnical complexity\nOrganizational complexity\nEnterprise discipline\nDisciplined agile delivery\nRisk+value driven life-cycle\nSelf-organizing with appropriate\ngovernance framework\nFull delivery life-cycle\nCore agile development\nValue-driven life-cycle\nSelf-organizing teams\nFocus on construction\nFigure 3.14\u2002 IBM\u2019s  \nAgility at Scale model  \n(\u00a9 IBM 2010)\n", "page": 96, "type": "text", "section": "Page 96"}
{"text": "96\u2002 \u2002 Chapter 3\u2002 \u25a0\u2002 Agile software development\n1.\t\nA completely incremental approach to requirements engineering is impossible. \nSome early work on initial software requirements is essential. You need this \nwork to identify the different parts of the system that may be developed by \n\u00ad\ndifferent teams and, often, to be part of the contract for the system development. \nHowever, these requirements should not normally be specified in detail; details \nare best developed incrementally.\n2.\t\nThere cannot be a single product owner or customer representative. Different \npeople have to be involved for different parts of the system, and they have to \ncontinuously communicate and negotiate throughout the development process.\n3.\t It is not possible to focus only on the code of the system. You need to do more \nup-front design and system documentation. The software architecture has to be \ndesigned, and there has to be documentation produced to describe critical \naspects of the system, such as database schemas and the work breakdown \nacross teams.\n4.\t\nCross-team communication mechanisms have to be designed and used. This \nshould involve regular phone and videoconferences between team members and \nfrequent, short electronic meetings where teams update each other on progress. \nA range of communication channels such as email, instant messaging, wikis, \nand social networking systems should be provided to facilitate communications.\n5.\t\nContinuous integration, where the whole system is built every time any devel-\noper checks in a change, is practically impossible when several separate \nprograms have to be integrated to create the system. However, it is essential \nto maintain frequent system builds and regular releases of the system. \nConfiguration management tools that support multi-team software develop-\nment are essential.\nScrum has been adapted for large-scale development. In essence, the Scrum team \nmodel described in Section 3.3 is maintained, but multiple Scrum teams are set up. \nThe key characteristics of multi-team Scrum are:\n1.\t\nRole replication Each team has a Product Owner for its work component and \nScrumMaster. There may be a chief Product Owner and ScrumMaster for the \nentire project.\n2.\t\nProduct architects Each team chooses a product architect, and these architects \ncollaborate to design and evolve the overall system architecture.\n3.\t\nRelease alignment The dates of product releases from each team are aligned so \nthat a demonstrable and complete system is produced.\n4.\t\nScrum of Scrums There is a daily Scrum of Scrums where representatives from \neach team meet to discuss progress, identify problems, and plan the work to be \ndone that day. Individual team Scrums may be staggered in time so that repre-\nsentatives from other teams can attend if necessary.\n", "page": 97, "type": "text", "section": "Page 97"}
{"text": "\t\n3.4 \u2002 \u25a0\u2002 Scaling agile methods\u2002 \u2002 97\n\t\n3.4.4 \t Agile methods across organizations\nSmall software companies that develop software products have been among the \nmost enthusiastic adopters of agile methods. These companies are not constrained by \norganizational bureaucracies or process standards, and they can change quickly to \nadopt new ideas. Of course, larger companies have also experimented with agile \nmethods in specific projects, but it is much more difficult for them to \u201cscale out\u201d \nthese methods across the organization.\nIt can be difficult to introduce agile methods into large companies for a number of \nreasons:\n1.\t\nProject managers who do not have experience of agile methods may be reluctant \nto accept the risk of a new approach, as they do not know how this will affect \ntheir particular projects.\n2.\t\nLarge organizations often have quality procedures and standards that all pro-\njects are expected to follow, and, because of their bureaucratic nature, these are \nlikely to be incompatible with agile methods. Sometimes, these are supported \nby software tools (e.g., requirements management tools), and the use of these \ntools is mandated for all projects.\n3.\t\nAgile methods seem to work best when team members have a relatively high \nskill level. However, within large organizations, there are likely to be a wide \nrange of skills and abilities, and people with lower skill levels may not be effec-\ntive team members in agile processes.\n4.\t\nThere may be cultural resistance to agile methods, especially in those organiza-\ntions that have a long history of using conventional systems engineering \u00ad\nprocesses.\nChange management and testing procedures are examples of company procedures \nthat may not be compatible with agile methods. Change management is the process of \ncontrolling changes to a system, so that the impact of changes is predictable and costs are \ncontrolled. All changes have to be approved in advance before they are made, and this \nconflicts with the notion of refactoring. When refactoring is part of an agile process, any \ndeveloper can improve any code without getting external approval. For large systems, \nthere are also testing standards where a system build is handed over to an external testing \nteam. This may conflict with test-first approaches used in agile development methods.\nIntroducing and sustaining the use of agile methods across a large organization is \na process of cultural change. Cultural change takes a long time to implement and \noften requires a change of management before it can be accomplished. Companies \nwishing to use agile methods need evangelists to promote change. Rather than try-\ning to force agile methods onto unwilling developers, companies have found that the \nbest way to introduce agile is bit by bit, starting with an enthusiastic group of devel-\nopers. A successful agile project can act as a starting point, with the project team \nspreading agile practice across the organization. Once the notion of agile is widely \nknown, explicit actions can then be taken to spread it across the organization.\n", "page": 98, "type": "text", "section": "Page 98"}
{"text": "98\u2002 \u2002 Chapter 3\u2002 \u25a0\u2002 Agile software development\nKey Points\n\u25a0\t Agile methods are iterative development methods that focus on reducing process overheads and \ndocumentation and on incremental software delivery. They involve customer representatives \ndirectly in the development process.\n\u25a0\t The decision on whether to use an agile or a plan-driven approach to development should depend on \nthe type of software being developed, the capabilities of the development team, and the culture of the \ncompany developing the system. In practice, a mix of agile and plan-based techniques may be used.\n\u25a0\t Agile development practices include requirements expressed as user stories, pair programming, \nrefactoring, continuous integration, and test-first development.\n\u25a0\t Scrum is an agile method that provides a framework for organizing agile projects. It is centered \naround a set of sprints, which are fixed time periods when a system increment is developed. Plan-\nning is based on prioritizing a backlog of work and selecting the highest priority tasks for a\u00a0sprint.\n\u25a0\t To scale agile methods, some plan-based practices have to be integrated with agile practice. \nThese include up-front requirements, multiple customer representatives, more documentation, \ncommon tooling across project teams, and the alignment of releases across teams.\nFurther Reading\n\u201cGet Ready for Agile Methods, With Care.\u201d A thoughtful critique of agile methods that discusses their \nstrengths and weaknesses, written by a vastly experienced software engineer. Still very relevant, although \nalmost 15 years old. (B. Boehm, IEEE Computer, January 2002) http://dx.doi.org/10.1109/2.976920\nExtreme Programming Explained. This was the first book on XP and is still, perhaps, the most read-\nable. It explains the approach from the perspective of one of its inventors, and his enthusiasm comes \nthrough very clearly in the book. (K. Beck and C. Andres, Addison-Wesley, 2004) Essential Scrum: A \nPractical Guide to the Most Popular Agile Process. This is a comprehensive and readable description \nof the 2011 development of the Scrum method (K.S. Rubin, Addison-Wesley, 2013).\n\u201cAgility at Scale: Economic Governance, Measured Improvement and Disciplined Delivery.\u201d This \npaper discusses IBM's approach to scale agile methods, where they have a systematic approach to \nintegrating plan-based and agile development. It is an excellent and thoughtful \u00ad\ndiscussion of the key \nissues in scaling agile (A.W. Brown, S.W. Ambler, and W. Royce, Proc. 35th Int.\u00a0Conf. on Software \nEngineering, 2013) http://dx.doi.org/10.1145/12944.12948\nWebsite\nPowerPoint slides for this chapter:\nwww.pearsonglobaleditions.com/Sommerville\nLinks to supporting videos:\nhttp://software-engineering-book.com/videos/agile-methods/\n", "page": 99, "type": "text", "section": "Page 99"}
{"text": "\t\n3.4 \u2002 \u25a0\u2002 Agile development techniques\u2002 \u2002 99\nExercises\n\u2002 3.1. \tAt the end of their study program, students in a software engineering course are typically \nexpected to complete a major project. Explain how the agile methodology may be very useful \nfor the students to use in this case.\n\u2002 3.2. \tExplain how the principles underlying agile methods lead to the accelerated development and \ndeployment of software.\n\u2002 3.3. \tExtreme programming expresses user requirements as stories, with each story written on a \ncard. Discuss the advantages and disadvantages of this approach to requirements \u00ad\ndescription.\n\u2002 3.4. \tIn test-first development, tests are written before the code. Explain how the test suite may \ncompromise the quality of the software system being developed.\n\u2002 3.5. \tSuggest four reasons why the productivity rate of programmers working as a pair might be \nmore than half that of two programmers working individually.\n\u2002 3.6. \tCompare and contrast the Scrum approach to project management with conventional plan-\u00ad\nbased \napproaches as discussed in Chapter 23. Your comparison should be based on the \u00ad\neffectiveness \nof each approach for planning the allocation of people to projects, estimating the\u00a0cost of \n\u00ad\nprojects, maintaining team cohesion, and managing changes in project team \u00ad\nmembership.\n\u2002 3.7. \tTo reduce costs and the environmental impact of commuting, your company decides to close a \nnumber of offices and to provide support for staff to work from home. However, the\u00a0senior \nmanagement who introduce the policy are unaware that software is developed using Scrum. \nExplain how you could use technology to support Scrum in a distributed \u00ad\nenvironment to make \nthis possible. What problems are you likely to encounter using this\u00a0approach?\n\u2002 3.8. \tWhy is it necessary to introduce some methods and documentation from plan-based \napproaches when scaling agile methods to larger projects that are developed by distributed \ndevelopment teams?\n\u2002 3.9. \tExplain why agile methods may not work well in organizations that have teams with a wide \nrange of skills and abilities and well-established processes.\n3.10. \tOne of the problems of having a user closely involved with a software development team is \nthat they \u201cgo native.\u201d That is, they adopt the outlook of the development team and lose sight \nof the needs of their user colleagues. Suggest three ways how you might avoid this problem, \nand discuss the advantages and disadvantages of each approach.\nReferences\nAmbler, S. W. 2010. \u201cScaling Agile: A Executive Guide.\u201d http://www.ibm.com/developerworks/ \ncommunity/blogs/ambler/entry/scaling_agile_an_executive_guide10/\nArisholm, E., H. Gallis, T. Dyba, and D. I. K. Sjoberg. 2007. \u201cEvaluating Pair Programming with \nRespect to System Complexity and Programmer Expertise.\u201d IEEE Trans. on Software Eng. 33 (2): \n65\u201386. doi:10.1109/TSE.2007.17.\nBeck, K. 1998. \u201cChrysler Goes to \u2018Extremes.\u2019\u201d Distributed Computing (10): 24\u201328.\n\t\nChapter 3\u2002 \u25a0\u2002 References\u2002 \u2002 99\n", "page": 100, "type": "text", "section": "Page 100"}
{"text": "100\u2002 \u2002 Chapter 3\u2002 \u25a0\u2002 Agile Software Development\n\t\n\u2002 \u2002 . 1999. \u201cEmbracing Change with Extreme Programming.\u201d IEEE Computer 32 (10): 70\u201378. \ndoi:10.1109/2.796139.\nBellouiti, S. 2009. \u201cHow Scrum Helped Our A-Team.\u201d http://www.scrumalliance.org/community/\narticles/2009/2009-june/how-scrum-helped-our team\nBird, J. 2011. \u201cYou Can't Be Agile in Maintenance.\u201d http://swreflections.blogspot.co.uk/2011/10/\nyou-cant-be-agile-in-maintenance.html\nDeemer, P. 2011. \u201cThe Distributed Scrum Primer.\u201d http://www.goodagile.com/distributedscrumprimer/.\nFowler, M., K. Beck, J. Brant, W. Opdyke, and D. Roberts. 1999. Refactoring: Improving the Design of \nExisting Code. Boston: Addison-Wesley.\nHopkins, R., and K. Jenkins. 2008. Eating the IT Elephant: Moving from Greenfield Development to \nBrownfield. Boston: IBM Press.\nJeffries, R., and G. Melnik. 2007. \u201cTDD: The Art of Fearless Programming.\u201d IEEE Software 24: 24\u201330. \ndoi:10.1109/MS.2007.75.\nKilner, S. 2012. \u201cCan Agile Methods Work for Software Maintenance.\u201d http://www.vlegaci.com/can-\nagile-methods-work-for-software-maintenance-part-1/\nLarman, C., and V. R. Basili. 2003. \u201cIterative and Incremental Development: A Brief History.\u201d IEEE \nComputer 36 (6): 47\u201356. doi:10.1109/MC.2003.1204375.\nLeffingwell, D. 2007. Scaling Software Agility: Best Practices for Large Enterprises. Boston: Addison-Wesley.\nLeffingwell, D. 2011. Agile Software Requirements: Lean Requirements Practices for Teams,  \nPrograms and the Enterprise. Boston: Addison-Wesley.\nMulder, M., and M. van Vliet. 2008. \u201cCase Study: Distributed Scrum Project for Dutch Railways.\u201d \nInfoQ. http://www.infoq.com/articles/dutch-railway-scrum\nRubin, K. S. 2013. Essential Scrum. Boston: Addison-Wesley.\nSchatz, B., and I. Abdelshafi. 2005. \u201cPrimavera Gets Agile: A Successful Transition to Agile Develop-\nment.\u201d IEEE Software 22 (3): 36\u201342. doi:10.1109/MS.2005.74.\nSchwaber, K., and M. Beedle. 2001. Agile Software Development with Scrum. Englewood Cliffs, NJ: \nPrentice-Hall.\nStapleton, J. 2003. DSDM: Business Focused Development, 2nd ed. Harlow, UK: Pearson Education.\nTahchiev, P., F. Leme, V. Massol, and G. Gregory. 2010. JUnit in Action, 2/e. Greenwich, CT: Manning \nPublications.\nWeinberg, G. 1971. The Psychology of Computer Programming. New York: Van Nostrand.\nWilliams, L., R. R. Kessler, W. Cunningham, and R. Jeffries. 2000. \u201cStrengthening the Case for Pair \n\u00ad\nProgramming.\u201d IEEE Software 17 (4): 19\u201325. doi:10.1109/52.854064.\n100\u2002 \u2002 Chapter 3\u2002 \u25a0\u2002 Agile software development\n", "page": 101, "type": "text", "section": "Page 101"}
{"text": "Requirements \nengineering\n4\nObjectives\nThe objective of this chapter is to introduce software requirements and to \nexplain the processes involved in discovering and documenting these \nrequirements. When you have read the chapter, you will:\n\u25a0\t understand the concepts of user and system requirements and why \nthese requirements should be written in different ways;\n\u25a0\t understand the differences between functional and non-functional \nsoftware requirements;\n\u25a0\t understand the main requirements engineering activities of elicitation, \nanalysis, and validation, and the relationships between these \nactivities;\n\u25a0\t understand why requirements management is necessary and how it \nsupports other requirements engineering activities.\nContents\n4.1 \tFunctional and non-functional requirements\n4.2 \tRequirements engineering processes\n4.3 \tRequirements elicitation\n4.4 \tRequirements specification\n4.5 \tRequirements validation\n4.6 \tRequirements change\n", "page": 102, "type": "text", "section": "Page 102"}
{"text": "102\u2002 \u2002 Chapter 4\u2002 \u25a0\u2002 Requirements engineering\nThe requirements for a system are the descriptions of the services that a system should \nprovide and the constraints on its operation. These requirements reflect the needs of \ncustomers for a system that serves a certain purpose such as controlling a device, placing \nan order, or finding information. The process of finding out, analyzing, documenting \nand checking these services and constraints is called requirements engineering (RE).\nThe term requirement is not used consistently in the software industry. In some \ncases, a requirement is simply a high-level, abstract statement of a service that a \nsystem should provide or a constraint on a system. At the other extreme, it is a \ndetailed, formal definition of a system function. Davis (Davis 1993) explains why \nthese differences exist:\nIf a company wishes to let a contract for a large software development project, \nit must define its needs in a sufficiently abstract way that a solution is not pre-\ndefined. The requirements must be written so that several contractors can bid \nfor the contract, offering, perhaps, different ways of meeting the client organi-\nzation\u2019s needs. Once a contract has been awarded, the contractor must write a \nsystem definition for the client in more detail so that the client understands \nand can validate what the software will do. Both of these documents may be \ncalled the requirements document for the system\u2020.\nSome of the problems that arise during the requirements engineering process are \na result of failing to make a clear separation between these different levels of descrip-\ntion. I distinguish between them by using the term user requirements to mean the \nhigh-level abstract requirements and system requirements to mean the detailed \ndescription of what the system should do. User requirements and system require-\nments may be defined as follows:\n1.\t\nUser requirements are statements, in a natural language plus diagrams, of what ser-\nvices the system is expected to provide to system users and the constraints under \nwhich it must operate. The user requirements may vary from broad statements of the \nsystem features required to detailed, precise descriptions of the system functionality.\n2.\t\nSystem requirements are more detailed descriptions of the software system\u2019s \nfunctions, services, and operational constraints. The system requirements docu-\nment (sometimes called a functional specification) should define exactly what is \nto be implemented. It may be part of the contract between the system buyer and \nthe software developers.\nDifferent kinds of requirement are needed to communicate information about a \nsystem to different types of reader. Figure 4.1 illustrates the distinction between user \nand system requirements. This example from the mental health care patient informa-\ntion system (Mentcare) shows how a user requirement may be expanded into several \nsystem requirements. You can see from Figure 4.1 that the user requirement is quite \n\u2020Davis, A. M. 1993. Software Requirements: Objects, Functions and States. Englewood Cliffs, NJ: \nPrentice-Hall.\n", "page": 103, "type": "text", "section": "Page 103"}
{"text": "\t\nChapter 4\u2002 \u25a0\u2002 Requirements engineering\u2002 \u2002 103\ngeneral. The system requirements provide more specific information about the ser-\nvices and functions of the system that is to be implemented.\nYou need to write requirements at different levels of detail because different \ntypes of readers use them in different ways. Figure 4.2 shows the types of readers of \nthe user and system requirements. The readers of the user requirements are not usu-\nally concerned with how the system will be implemented and may be managers who \nare not interested in the detailed facilities of the system. The readers of the system \nrequirements need to know more precisely what the system will do because they are \nconcerned with how it will support the business processes or because they are \ninvolved in the system implementation.\nThe different types of document readers shown in Figure 4.2 are examples of \nsystem stakeholders. As well as users, many other people have some kind of interest \nin the system. System stakeholders include anyone who is affected by the system in \nsome way and so anyone who has a legitimate interest in it. Stakeholders range from \nend-users of a system through managers to external stakeholders such as regulators, \nThe Mentcare system shall generate monthly management reports \nshowing the cost of drugs prescribed by each clinic during that month.\n1.1  On the last working day of each month, a summary of the drugs\nprescribed, their cost and the prescribing clinics shall be generated.\n1.2  The system shall generate the report for printing after 17.30 on the \nlast working day of the month.\n1.3  A report shall be created for each clinic and shall list the individual\ndrug names, the total number of prescriptions, the number of doses \nprescribed and the total cost of the prescribed drugs.\n1.4  If drugs are available in different dose units (e.g. 10mg, 20mg, etc.)\nseparate reports shall be created for each dose unit.\n1.5  Access to drug cost reports shall be restricted to authorized users as \nlisted on a management access control list.\n1.\nUser requirements definition\nSystem requirements specification\nClient managers\nSystem end-users\nClient engineers\nContractor managers\nSystem architects\nSystem end-users\nClient engineers\nSystem architects\nSoftware developers\nUser\nrequirements\nSystem\nrequirements\nFigure 4.2\u2002 Readers of \ndifferent types of \nrequirements \nspecification\nFigure 4.1\u2002 User and \nsystem requirements\n", "page": 104, "type": "text", "section": "Page 104"}
{"text": "104\u2002 \u2002 Chapter 4\u2002 \u25a0\u2002 Requirements engineering\nwho certify the acceptability of the system. For example, system stakeholders for the \nMentcare system include:\n1.\t\nPatients whose information is recorded in the system and relatives of these patients.\n2.\t\nDoctors who are responsible for assessing and treating patients.\n3.\t\nNurses who coordinate the consultations with doctors and administer some \ntreatments.\n4.\t\nMedical receptionists who manage patients\u2019 appointments.\n5.\t\nIT staff who are responsible for installing and maintaining the system.\n6.\t\nA medical ethics manager who must ensure that the system meets current ethi-\ncal guidelines for patient care.\n7.\t\nHealth care managers who obtain management information from the system.\n8.\t\nMedical records staff who are responsible for ensuring that system information \ncan be maintained and preserved, and that record keeping procedures have been \nproperly implemented.\nRequirements engineering is usually presented as the first stage of the software \nengineering process. However, some understanding of the system requirements may \nhave to be developed before a decision is made to go ahead with the procurement or \ndevelopment of a system. This early-stage RE establishes a high-level view of what \nthe system might do and the benefits that it might provide. These may then be con-\nsidered in a feasibility study, which tries to assess whether or not the system is tech-\nnically and financially feasible. The results of that study help management decide \nwhether or not to go ahead with the procurement or development of the system.\nIn this chapter, I present a \u201ctraditional\u201d view of requirements rather than require-\nments in agile processes, which I discussed in Chapter 3. For the majority of large \nsystems, it is still the case that there is a clearly identifiable requirements engineering \nphase before implementation of the system begins. The outcome is a requirements \ndocument, which may be part of the system development contract. Of course, subsequent \nchanges are made to the requirements, and user requirements may be expanded into \nFeasibility studies\nA feasibility study is a short, focused study that should take place early in the RE process. It should answer three \nkey questions: (1) Does the system contribute to the overall objectives of the organization? (2) Can the system \nbe implemented within schedule and budget using current technology? and (3) Can the system be integrated \nwith other systems that are used?\nIf the answer to any of these questions is no, you should probably not go ahead with the project.\nhttp://software-engineering-book.com/web/feasibility-study/\n", "page": 105, "type": "text", "section": "Page 105"}
{"text": "\t\n4.1\u2002 \u25a0\u2002 Functional and non-functional requirements\u2002 \u2002 105\nmore detailed system requirements. Sometimes an agile approach of concurrently \neliciting the requirements as the system is developed may be used to add detail and \nto refine the user requirements.\n \n4.1  Functional and non-functional requirements\nSoftware system requirements are often classified as functional or non-functional \nrequirements:\n1.\t\nFunctional requirements These are statements of services the system should \nprovide, how the system should react to particular inputs, and how the system \nshould behave in particular situations. In some cases, the functional require-\nments may also explicitly state what the system should not do.\n2.\t\nNon-functional requirements These are constraints on the services or functions \noffered by the system. They include timing constraints, constraints on the devel-\nopment process, and constraints imposed by standards. Non-functional require-\nments often apply to the system as a whole rather than individual system features \nor services.\nIn reality, the distinction between different types of requirements is not as clear-\ncut as these simple definitions suggest. A user requirement concerned with security, \nsuch as a statement limiting access to authorized users, may appear to be a non-\nfunctional requirement. However, when developed in more detail, this requirement \nmay generate other requirements that are clearly functional, such as the need to \ninclude user authentication facilities in the system.\nThis shows that requirements are not independent and that one requirement often \ngenerates or constrains other requirements. The system requirements therefore do not \njust specify the services or the features of the system that are required; they also specify \nthe necessary functionality to ensure that these services/features are delivered effectively.\n \n4.1.1  Functional requirements\nThe functional requirements for a system describe what the system should do. These \nrequirements depend on the type of software being developed, the expected users of the \nsoftware, and the general approach taken by the organization when writing requirements. \nWhen expressed as user requirements, functional requirements should be written in natu-\nral language so that system users and managers can understand them. Functional system \nrequirements expand the user requirements and are written for system developers. They \nshould describe the system functions, their inputs and outputs, and exceptions in detail.\nFunctional system requirements vary from general requirements covering what \nthe system should do to very specific requirements reflecting local ways of working \nor an organization\u2019s existing systems. For example, here are examples of functional \n", "page": 106, "type": "text", "section": "Page 106"}
{"text": "106\u2002 \u2002 Chapter 4\u2002 \u25a0\u2002 Requirements engineering\nrequirements for the Mentcare system, used to maintain information about patients \nreceiving treatment for mental health problems:\n1.\t\nA user shall be able to search the appointments lists for all clinics.\n2.\t\nThe system shall generate each day, for each clinic, a list of patients who are \nexpected to attend appointments that day.\n3.\t\nEach staff member using the system shall be uniquely identified by his or her \neight-digit employee number.\nThese user requirements define specific functionality that should be included in \nthe system. The requirements show that functional requirements may be written at \ndifferent levels of detail (contrast requirements 1 and 3).\nFunctional requirements, as the name suggests, have traditionally focused on \nwhat the system should do. However, if an organization decides that an existing off-\nthe-shelf system software product can meet its needs, then there is very little point in \ndeveloping a detailed functional specification. In such cases, the focus should be on \nthe development of information requirements that specify the information needed \nfor people to do their work. Information requirements specify the information needed \nand how it is to be delivered and organized. Therefore, an information requirement \nfor the Mentcare system might specify what information is to be included in the list \nof patients expected for appointments that day.\nImprecision in the requirements specification can lead to disputes between custom-\ners and software developers. It is natural for a system developer to interpret an ambig-\nuous requirement in a way that simplifies its implementation. Often, however, this is \nnot what the customer wants. New requirements have to be established and changes \nmade to the system. Of course, this delays system delivery and increases costs.\nFor example, the first Mentcare system requirement in the above list states that a \nuser shall be able to search the appointments lists for all clinics. The rationale for this \nrequirement is that patients with mental health problems are sometimes confused. \nThey may have an appointment at one clinic but actually go to a different clinic. If they \nhave an appointment, they will be recorded as having attended, regardless of the clinic.\nDomain requirements\nDomain requirements are derived from the application domain of the system rather than from the specific \nneeds of system users. They may be new functional requirements in their own right, constrain existing func-\ntional requirements, or set out how particular computations must be carried out.\nThe problem with domain requirements is that software engineers may not understand the characteristics of \nthe domain in which the system operates. This means that these engineers may not know whether or not a \ndomain requirement has been missed out or conflicts with other requirements.\nhttp://software-engineering-book.com/web/domain-requirements/\n", "page": 107, "type": "text", "section": "Page 107"}
{"text": "\t\n4.1\u2002 \u25a0\u2002 Functional and non-functional requirements\u2002 \u2002 107\nA medical staff member specifying a search requirement may expect \u201csearch\u201d to \nmean that, given a patient name, the system looks for that name in all appointments at all \nclinics. However, this is not explicit in the requirement. System developers may interpret \nthe requirement so that it is easier to implement. Their search function may require the \nuser to choose a clinic and then carry out the search of the patients who attended that \nclinic. This involves more user input and so takes longer to complete the search.\nIdeally, the functional requirements specification of a system should be both \ncomplete and consistent. Completeness means that all services and information \nrequired by the user should be defined. Consistency means that requirements should \nnot be contradictory.\nIn practice, it is only possible to achieve requirements consistency and complete-\nness for very small software systems. One reason is that it is easy to make mistakes \nand omissions when writing specifications for large, complex systems. Another rea-\nson is that large systems have many stakeholders, with different backgrounds and \nexpectations. Stakeholders are likely to have different\u2014and often inconsistent\u2014\nneeds. These inconsistencies may not be obvious when the requirements are origi-\nnally specified, and the inconsistent requirements may only be discovered after \ndeeper analysis or during system development.\n \n4.1.2  Non-functional requirements\nNon-functional requirements, as the name suggests, are requirements that are not \ndirectly concerned with the specific services delivered by the system to its users. \nThese non-functional requirements usually specify or constrain characteristics of the \nsystem as a whole. They may relate to emergent system properties such as reliability, \nresponse time, and memory use. Alternatively, they may define constraints on the \nsystem implementation, such as the capabilities of I/O devices or the data represen-\ntations used in interfaces with other systems.\nNon-functional requirements are often more critical than individual functional \nrequirements. System users can usually find ways to work around a system function \nthat doesn\u2019t really meet their needs. However, failing to meet a non-functional \nrequirement can mean that the whole system is unusable. For example, if an aircraft \nsystem does not meet its reliability requirements, it will not be certified as safe for \noperation; if an embedded control system fails to meet its performance requirements, \nthe control functions will not operate correctly.\nWhile it is often possible to identify which system components implement spe-\ncific functional requirements (e.g., there may be formatting components that imple-\nment reporting requirements), this is often more difficult with non-functional \nrequirements. The implementation of these requirements may be spread throughout \nthe system, for two reasons:\n1.\t\nNon-functional requirements may affect the overall architecture of a system \nrather than the individual components. For example, to ensure that performance \nrequirements are met in an embedded system, you may have to organize the \nsystem to minimize communications between components.\n", "page": 108, "type": "text", "section": "Page 108"}
{"text": "108\u2002 \u2002 Chapter 4\u2002 \u25a0\u2002 Requirements engineering\nPerformance\nrequirements\nSpace\nrequirements\nUsability\nrequirements\nEfficiency\nrequirements\nDependability\nrequirements\nSecurity\nrequirements\nRegulatory\nrequirements\nEthical\nrequirements\nLegislative\nrequirements\nOperational\nrequirements\nDevelopment\nrequirements\nEnvironmental\nrequirements\nSafety/security\nrequirements\nAccounting\nrequirements\nProduct\nrequirements\nOrganizational\nrequirements\nExternal\nrequirements\nNon-functional\nrequirements\nFigure 4.3\u2002 Types of \nnon-functional \nrequirements\n2.\t\nAn individual non-functional requirement, such as a security requirement, may \ngenerate several, related functional requirements that define new system ser-\nvices that are required if the non-functional requirement is to be implemented. \nIn addition, it may also generate requirements that constrain existing require-\nments; for example, it may limit access to information in the system.\nNonfunctional requirements arise through user needs because of budget con-\nstraints, organizational policies, the need for interoperability with other software or \nhardware systems, or external factors such as safety regulations or privacy legisla-\ntion. Figure 4.3 is a classification of non-functional requirements. You can see from \nthis diagram that the non-functional requirements may come from required charac-\nteristics of the software (product requirements), the organization developing the \nsoftware (organizational requirements), or external sources:\n1.\t\nProduct requirements These requirements specify or constrain the runtime \nbehavior of the software. Examples include performance requirements for how \nfast the system must execute and how much memory it requires; reliability \nrequirements that set out the acceptable failure rate; security requirements; and \nusability requirements.\n2.\t\nOrganizational requirements These requirements are broad system require-\nments derived from policies and procedures in the customer\u2019s and developer\u2019s \norganizations. Examples include operational process requirements that define \nhow the system will be used; development process requirements that specify the \n", "page": 109, "type": "text", "section": "Page 109"}
{"text": "\t\n4.1\u2002 \u25a0\u2002 Functional and non-functional requirements\u2002 \u2002 109\nprogramming language; the development environment or process standards to \nbe used; and environmental requirements that specify the operating environ-\nment of the system.\n3.\t\nExternal requirements This broad heading covers all requirements that are \nderived from factors external to the system and its development process. These \nmay include regulatory requirements that set out what must be done for the sys-\ntem to be approved for use by a regulator, such as a nuclear safety authority; \nlegislative requirements that must be followed to ensure that the system oper-\nates within the law; and ethical requirements that ensure that the system will be \nacceptable to its users and the general public.\nFigure 4.4 shows examples of product, organizational, and external requirements \nthat could be included in the Mentcare system specification. The product require-\nment is an availability requirement that defines when the system has to be available \nand the allowed downtime each day. It says nothing about the functionality of the \nMentcare system and clearly identifies a constraint that has to be considered by \nthe\u00a0system designers.\nThe organizational requirement specifies how users authenticate themselves to \nthe system. The health authority that operates the system is moving to a standard \nauthentication procedure for all software where, instead of users having a login \nname, they swipe their identity card through a reader to identify themselves. The \nexternal requirement is derived from the need for the system to conform to privacy \nlegislation. Privacy is obviously a very important issue in health care systems, and \nthe requirement specifies that the system should be developed in accordance with a \nnational privacy standard.\nA common problem with non-functional requirements is that stakeholders pro-\npose requirements as general goals, such as ease of use, the ability of the system to \nrecover from failure, or rapid user response. Goals set out good intentions but cause \nproblems for system developers as they leave scope for interpretation and subse-\nquent dispute once the system is delivered. For example, the following system goal \nis typical of how a manager might express usability requirements:\nThe system should be easy to use by medical staff and should be organized in \nsuch a way that user errors are minimized.\nFigure 4.4\u2002 Examples of \npossible non-functional \nrequirements for the \nMentcare system\nProduct requirement\nThe Mentcare system shall be available to all clinics during normal working hours (Mon\u2013Fri, 08:30\u201317:30). \nDowntime within normal working hours shall not exceed 5 seconds in any one day.\nOrganizational requirement\nUsers of the Mentcare system shall identify themselves using their health authority identity card.\nExternal requirement\nThe system shall implement patient privacy provisions as set out in HStan-03-2006-priv.\n", "page": 110, "type": "text", "section": "Page 110"}
{"text": "110\u2002 \u2002 Chapter 4\u2002 \u25a0\u2002 Requirements engineering\nI have rewritten this to show how the goal could be expressed as a \u201ctestable\u201d non-\nfunctional requirement. It is impossible to objectively verify the system goal, but in \nthe following description you can at least include software instrumentation to count \nthe errors made by users when they are testing the system.\nMedical staff shall be able to use all the system functions after two hours of \ntraining. After this training, the average number of errors made by experienced \nusers shall not exceed two per hour of system use.\nWhenever possible, you should write non-functional requirements quantitatively \nso that they can be objectively tested. Figure 4.5 shows metrics that you can use to \nspecify non-functional system properties. You can measure these characteristics \nwhen the system is being tested to check whether or not the system has met its non-\nfunctional requirements.\nIn practice, customers for a system often find it difficult to translate their goals into \nmeasurable requirements. For some goals, such as maintainability, there are no sim-\nple metrics that can be used. In other cases, even when quantitative specification is \npossible, customers may not be able to relate their needs to these specifications. They \ndon\u2019t understand what some number defining the reliability (for example) means in \nterms of their everyday experience with computer systems. Furthermore, the cost of \nobjectively verifying measurable, non-functional requirements can be very high, and \nthe customers paying for the system may not think these costs are justified.\nNon-functional requirements often conflict and interact with other functional or \nnon-functional requirements. For example, the identification requirement in \nFigure\u00a04.4 requires a card reader to be installed with each computer that connects to \nthe system. However, there may be another requirement that requests mobile access \nto the system from doctors\u2019 or nurses\u2019 tablets or smartphones. These are not normally \nFigure 4.5\u2002 Metrics for \nspecifying non-\nfunctional requirements\nProperty\nMeasure\nSpeed\nProcessed transactions/second\nUser/event response time\nScreen refresh time\nSize\nMegabytes/Number of ROM chips\nEase of use\nTraining time\nNumber of help frames\nReliability\nMean time to failure\nProbability of unavailability\nRate of failure occurrence\nAvailability\nRobustness\nTime to restart after failure\nPercentage of events causing failure\nProbability of data corruption on failure\nPortability\nPercentage of target dependent statements\nNumber of target systems\n", "page": 111, "type": "text", "section": "Page 111"}
{"text": "\t\n4.2\u2002 \u25a0\u2002 Requirements engineering processes\u2002 \u2002 111\nequipped with card readers so, in these circumstances, some alternative identifica-\ntion method may have to be supported.\nIt is difficult to separate functional and non-functional requirements in the \nrequirements document. If the non-functional requirements are stated separately \nfrom the functional requirements, the relationships between them may be hard to \nunderstand. However, you should, ideally, highlight requirements that are clearly \nrelated to emergent system properties, such as performance or reliability. You can do \nthis by putting them in a separate section of the requirements document or by distin-\nguishing them, in some way, from other system requirements.\nNon-functional requirements such as reliability, safety, and confidentiality \nrequirements are particularly important for critical systems. I cover these dependa-\nbility requirements in Part 2, which describes ways of specifying reliability, safety, \nand security requirements.\n \n4.2  Requirements engineering processes\nAs I discussed in Chapter 2, requirements engineering involves three key activities. \nThese are discovering requirements by interacting with stakeholders (elicitation and \nanalysis); converting these requirements into a standard form (specification); and \nchecking that the requirements actually define the system that the customer wants \n(validation). I have shown these as sequential processes in Figure 2.4. However, \nin\u00a0practice, requirements engineering is an iterative process in which the activities \nare interleaved.\nFigure 4.6 shows this interleaving. The activities are organized as an iterative \nprocess around a spiral. The output of the RE process is a system requirements docu-\nment. The amount of time and effort devoted to each activity in an iteration depends \non the stage of the overall process, the type of system being developed, and the \nbudget that is available.\nEarly in the process, most effort will be spent on understanding high-level business \nand non-functional requirements, and the user requirements for the system. Later in the \nprocess, in the outer rings of the spiral, more effort will be devoted to eliciting and \nunderstanding the non-functional requirements and more detailed system requirements.\nThis spiral model accommodates approaches to development where the require-\nments are developed to different levels of detail. The number of iterations around the \nspiral can vary so that the spiral can be exited after some or all of the user require-\nments have been elicited. Agile development can be used instead of prototyping so \nthat the requirements and the system implementation are developed together.\nIn virtually all systems, requirements change. The people involved develop a bet-\nter understanding of what they want the software to do; the organization buying the \nsystem changes; and modifications are made to the system\u2019s hardware, software, and \norganizational environment. Changes have to be managed to understand the impact \non other requirements and the cost and system implications of making the change. \nI\u00a0discuss this process of requirements management in Section 4.6.\n", "page": 112, "type": "text", "section": "Page 112"}
{"text": "112\u2002 \u2002 Chapter 4\u2002 \u25a0\u2002 Requirements engineering\n \n4.3  Requirements elicitation\nThe aims of the requirements elicitation process are to understand the work that \nstakeholders do and how they might use a new system to help support that work. \nDuring requirements elicitation, software engineers work with stakeholders to find \nout about the application domain, work activities, the services and system features \nthat stakeholders want, the required performance of the system, hardware con-\nstraints, and so on.\nEliciting and understanding requirements from system stakeholders is a difficult \nprocess for several reasons:\n1.\t\nStakeholders often don\u2019t know what they want from a computer system except \nin the most general terms; they may find it difficult to articulate what they want \nthe system to do; they may make unrealistic demands because they don\u2019t know \nwhat is and isn\u2019t feasible.\nRequirements\nspecification\nRequirements\nvalidation\nRequirements\nelicitation\nSystem requirements\nspecification and\nmodeling\nSystem\nreq.\nelicitation\nUser requirements\nspecification\nUser\nrequirements\nelicitation\nBusiness requirements\nspecification\nPrototyping\nFeasibility\nstudy\nReviews\nSystem requirements\ndocument\nStart\nFigure 4.6\u2002 A spiral view \nof the requirements \nengineering process\n", "page": 113, "type": "text", "section": "Page 113"}
{"text": "\t\n4.3\u2002 \u25a0\u2002 Requirements elicitation\u2002 \u2002 113\n2.\t\nStakeholders in a system naturally express requirements in their own terms and \nwith implicit knowledge of their own work. Requirements engineers, without \nexperience in the customer\u2019s domain, may not understand these requirements.\n3.\t\nDifferent stakeholders, with diverse requirements, may express their require-\nments in different ways. Requirements engineers have to discover all potential \nsources of requirements and discover commonalities and conflict.\n4.\t\nPolitical factors may influence the requirements of a system. Managers may \ndemand specific system requirements because these will allow them to increase \ntheir influence in the organization.\n5.\t\nThe economic and business environment in which the analysis takes place is \ndynamic. It inevitably changes during the analysis process. The importance of \nparticular requirements may change. New requirements may emerge from new \nstakeholders who were not originally consulted.\nA process model of the elicitation and analysis process is shown in Figure 4.7. \nEach organization will have its own version or instantiation of this general model, \ndepending on local factors such as the expertise of the staff, the type of system being \ndeveloped, and the standards used.\nThe process activities are:\n1.\t\nRequirements discovery and understanding This is the process of interacting with \nstakeholders of the system to discover their requirements. Domain requirements \nfrom stakeholders and documentation are also discovered during this activity.\n2.\t\nRequirements classification and organization This activity takes the unstruc-\ntured collection of requirements, groups related requirements and organizes \nthem into coherent clusters.\n3.\t\nRequirements prioritization and negotiation Inevitably, when multiple stake-\nholders are involved, requirements will conflict. This activity is concerned with \nprioritizing requirements and finding and resolving requirements conflicts \n2. Requirements\nclassification and\norganization\n3. Requirements\nprioritization and\nnegotiation\n4. Requirements\ndocumentation\n1. Requirements \ndiscovery and \nunderstanding \nFigure 4.7\u2002 The \nrequirements elicitation \nand analysis process\n", "page": 114, "type": "text", "section": "Page 114"}
{"text": "114\u2002 \u2002 Chapter 4\u2002 \u25a0\u2002 Requirements engineering\nthrough negotiation. Usually, stakeholders have to meet to resolve differences \nand agree on compromise requirements.\n4.\t\nRequirements documentation The requirements are documented and input into \nthe next round of the spiral. An early draft of the software requirements docu-\nments may be produced at this stage, or the requirements may simply be main-\ntained informally on whiteboards, wikis, or other shared spaces.\nFigure 4.7 shows that requirements elicitation and analysis is an iterative process \nwith continual feedback from each activity to other activities. The process cycle \nstarts with requirements discovery and ends with the requirements documentation. \nThe analyst\u2019s understanding of the requirements improves with each round of the \ncycle. The cycle ends when the requirements document has been produced.\nTo simplify the analysis of requirements, it is helpful to organize and group the \nstakeholder information. One way of doing so is to consider each stakeholder group \nto be a viewpoint and to collect all requirements from that group into the viewpoint. \nYou may also include viewpoints to represent domain requirements and constraints \nfrom other systems. Alternatively, you can use a model of the system architecture to \nidentify subsystems and to associate requirements with each subsystem.\nInevitably, different stakeholders have different views on the importance and pri-\nority of requirements, and sometimes these views are conflicting. If some stakehold-\ners feel that their views have not been properly considered, then they may deliberately \nattempt to undermine the RE process. Therefore, it is important that you organize \nregular stakeholder meetings. Stakeholders should have the opportunity to express \ntheir concerns and agree on requirements compromises.\nAt the requirements documentation stage, it is important that you use simple lan-\nguage and diagrams to describe the requirements. This makes it possible for stake-\nholders to understand and comment on these requirements. To make information \nsharing easier, it is best to use a shared document (e.g., on Google Docs or Office 365) \nor a wiki that is accessible to all interested stakeholders.\n \n4.3.1  Requirements elicitation techniques\nRequirements elicitation involves meeting with stakeholders of different kinds to \ndiscover information about the proposed system. You may supplement this information \nViewpoints\nA viewpoint is a way of collecting and organizing a set of requirements from a group of stakeholders who have \nsomething in common. Each viewpoint therefore includes a set of system requirements. Viewpoints might come \nfrom end-users, managers, or others. They help identify the people who can provide information about their \nrequirements and structure the requirements for analysis.\nhttp://www.software-engineering-book.com/web/viewpoints/\n", "page": 115, "type": "text", "section": "Page 115"}
{"text": "\t\n4.3\u2002 \u25a0\u2002 Requirements elicitation\u2002 \u2002 115\nwith knowledge of existing systems and their usage and information from docu-\nments of various kinds. You need to spend time understanding how people work, \nwhat they produce, how they use other systems, and how they may need to change to \naccommodate a new system.\nThere are two fundamental approaches to requirements elicitation:\n1.\t\nInterviewing, where you talk to people about what they do.\n2.\t\nObservation or ethnography, where you watch people doing their job to see \nwhat artifacts they use, how they use them, and so on.\nYou should use a mix of interviewing and observation to collect information and, \nfrom that, you derive the requirements, which are then the basis for further discussions.\n4.3.1.1 Interviewing\nFormal or informal interviews with system stakeholders are part of most require-\nments engineering processes. In these interviews, the requirements engineering team \nputs questions to stakeholders about the system that they currently use and the sys-\ntem to be developed. Requirements are derived from the answers to these questions. \nInterviews may be of two types:\n1.\t\nClosed interviews, where the stakeholder answers a predefined set of questions.\n2.\t\nOpen interviews, in which there is no predefined agenda. The requirements \nengineering team explores a range of issues with system stakeholders and hence \ndevelops a better understanding of their needs.\nIn practice, interviews with stakeholders are normally a mixture of both of these. \nYou may have to obtain the answer to certain questions, but these usually lead to \nother issues that are discussed in a less structured way. Completely open-ended dis-\ncussions rarely work well. You usually have to ask some questions to get started and \nto keep the interview focused on the system to be developed.\nInterviews are good for getting an overall understanding of what stakeholders do, \nhow they might interact with the new system, and the difficulties that they face with \ncurrent systems. People like talking about their work, and so they are usually happy \nto get involved in interviews. However, unless you have a system prototype to dem-\nonstrate, you should not expect stakeholders to suggest specific and detailed require-\nments. Everyone finds it difficult to visualize what a system might be like. You need \nto analyze the information collected and to generate the requirements from this.\nEliciting domain knowledge through interviews can be difficult, for two reasons:\n1.\t\nAll application specialists use jargon specific to their area of work. It is impos-\nsible for them to discuss domain requirements without using this terminology. \nThey normally use words in a precise and subtle way that requirements engi-\nneers may misunderstand.\n", "page": 116, "type": "text", "section": "Page 116"}
{"text": "116\u2002 \u2002 Chapter 4\u2002 \u25a0\u2002 Requirements engineering\n2.\t\nSome domain knowledge is so familiar to stakeholders that they either find it \ndifficult to explain or they think it is so fundamental that it isn\u2019t worth mention-\ning. For example, for a librarian, it goes without saying that all acquisitions are \ncatalogued before they are added to the library. However, this may not be obvi-\nous to the interviewer, and so it isn\u2019t taken into account in the requirements.\nInterviews are not an effective technique for eliciting knowledge about organiza-\ntional requirements and constraints because there are subtle power relationships \nbetween the different people in the organization. Published organizational structures \nrarely match the reality of decision making in an organization, but interviewees may \nnot wish to reveal the actual rather than the theoretical structure to a stranger. In \ngeneral, most people are generally reluctant to discuss political and organizational \nissues that may affect the requirements.\nTo be an effective interviewer, you should bear two things in mind:\n1.\t\nYou should be open-minded, avoid preconceived ideas about the requirements, \nand willing to listen to stakeholders. If the stakeholder comes up with surprising \nrequirements, then you should be willing to change your mind about the system.\n2.\t\nYou should prompt the interviewee to get discussions going by using a spring-\nboard question or a requirements proposal, or by working together on a proto-\ntype system. Saying to people \u201ctell me what you want\u201d is unlikely to result in \nuseful information. They find it much easier to talk in a defined context rather \nthan in general terms.\nInformation from interviews is used along with other information about the sys-\ntem from documentation describing business processes or existing systems, user \nobservations, and developer experience. Sometimes, apart from the information in \nthe system documents, the interview information may be the only source of informa-\ntion about the system requirements. However, interviewing on its own is liable to \nmiss essential information, and so it should be used in conjunction with other \nrequirements elicitation techniques.\n4.3.1.2 Ethnography\nSoftware systems do not exist in isolation. They are used in a social and organiza-\ntional environment, and software system requirements may be generated or con-\nstrained by that environment. One reason why many software systems are delivered \nbut never used is that their requirements do not take proper account of how social \nand organizational factors affect the practical operation of the system. It is therefore \nvery important that, during the requirements engineering process, you try to under-\nstand the social and organizational issues that affect the use of the system.\nEthnography is an observational technique that can be used to understand opera-\ntional processes and help derive requirements for software to support these pro-\ncesses. An analyst immerses himself or herself in the working environment where \n", "page": 117, "type": "text", "section": "Page 117"}
{"text": "\t\n4.3\u2002 \u25a0\u2002 Requirements elicitation\u2002 \u2002 117\nthe system will be used. The day-to-day work is observed, and notes are made of the \nactual tasks in which participants are involved. The value of ethnography is that it \nhelps discover implicit system requirements that reflect the actual ways that people \nwork, rather than the formal processes defined by the organization.\nPeople often find it very difficult to articulate details of their work because it is \nsecond nature to them. They understand their own work but may not understand its \nrelationship to other work in the organization. Social and organizational factors that \naffect the work, but that are not obvious to individuals, may only become clear when \nnoticed by an unbiased observer. For example, a workgroup may self-organize so \nthat members know of each other\u2019s work and can cover for each other if someone is \nabsent. This may not be mentioned during an interview as the group might not see it \nas an integral part of their work.\nSuchman (Suchman 1983) pioneered the use of ethnography to study office work. \nShe found that actual work practices were far richer, more complex, and more \ndynamic than the simple models assumed by office automation systems. The differ-\nence between the assumed and the actual work was the most important reason why \nthese office systems had no significant effect on productivity. Crabtree (Crabtree \n2003) discusses a wide range of studies since then and describes, in general, the use \nof ethnography in systems design. In my own research, I have investigated methods \nof integrating ethnography into the software engineering process by linking it with \nrequirements engineering methods (Viller and Sommerville 2000) and documenting \npatterns of interaction in cooperative systems (Martin and Sommerville 2004).\nEthnography is particularly effective for discovering two types of requirements:\n1.\t\nRequirements derived from the way in which people actually work, rather than \nthe way in which business process definitions say they ought to work. In prac-\ntice, people never follow formal processes. For example, air traffic controllers \nmay switch off a conflict alert system that detects aircraft with intersecting \nflight paths, even though normal control procedures specify that it should be \nused. The conflict alert system is sensitive and issues audible warnings even \nwhen planes are far apart. Controllers may find these distracting and prefer to \nuse other strategies to ensure that planes are not on conflicting flight paths.\n2.\t\nRequirements derived from cooperation and awareness of other people\u2019s activi-\nties. For example, air traffic controllers (ATCs) may use an awareness of other \ncontrolles\u2019 work to predict the number of aircraft that will be entering their con-\ntrol sector. They then modify their control strategies depending on that pre-\ndicted workload. Therefore, an automated ATC system should allow controllers \nin a sector to have some visibility of the work in adjacent sectors.\nEthnography can be combined with the development of a system prototype \n(Figure 4.8). The ethnography informs the development of the prototype so that \nfewer prototype refinement cycles are required. Furthermore, the prototyping \nfocuses the ethnography by identifying problems and questions that can then be dis-\ncussed with the ethnographer. He or she should then look for the answers to these \nquestions during the next phase of the system study (Sommerville et al. 1993).\n", "page": 118, "type": "text", "section": "Page 118"}
{"text": "118\u2002 \u2002 Chapter 4\u2002 \u25a0\u2002 Requirements engineering\nEthnography is helpful to understand existing systems, but this understanding \ndoes not always help with innovation. Innovation is particularly relevant for new \nproduct development. Commentators have suggested that Nokia used ethnography \nto discover how people used their phones and developed new phone models on that \nbasis; Apple, on the other hand, ignored current use and revolutionized the mobile \nphone industry with the introduction of the iPhone.\nEthnographic studies can reveal critical process details that are often missed by \nother requirements elicitation techniques. However, because of its focus on the end-\nuser, this approach is not effective for discovering broader organizational or domain \nrequirements or for suggestion innovations. You therefore have to use ethnography \nas one of a number of techniques for requirements elicitation.\n \n4.3.2  Stories and scenarios\nPeople find it easier to relate to real-life examples than abstract descriptions. They \nare not good at telling you the system requirements. However, they may be able to \ndescribe how they handle particular situations or imagine things that they might do \nin a new way of working. Stories and scenarios are ways of capturing this kind of \ninformation. You can then use these when interviewing groups of stakeholders to \ndiscuss the system with other stakeholders and to develop more specific system \nrequirements.\nStories and scenarios are essentially the same thing. They are a description of how \nthe system can be used for some particular task. They describe what people do, what \ninformation they use and produce, and what systems they may use in this process. \nThe difference is in the ways that descriptions are structured and in the level of detail \npresented. Stories are written as narrative text and present a high-level description of \nsystem use; scenarios are usually structured with specific information collected such \nas inputs and outputs. I find stories to be effective in setting out the \u201cbig picture.\u201d \nParts of stories can then be developed in more detail and represented as scenarios.\nFigure 4.9 is an example of a story that I developed to understand the requirements \nfor the iLearn digital learning environment that I introduced in Chapter 1. This story \ndescribes a situation in a primary (elementary) school where the teacher is using the \nenvironment to support student projects on the fishing industry. You can see this is a \nvery high-level description. Its purpose is to facilitate discussion of how the iLearn \nsystem might be used and to act as a starting point for eliciting the requirements for \nthat system.\nEthnographic\nanalysis\nDebriefing\nmeetings\nFocused\nethnography\nPrototype\nevaluation\nGeneric system\ndevelopment\nSystem\nprotoyping\nFigure 4.8\u2002 Ethnography \nand prototyping for \nrequirements analysis\n", "page": 119, "type": "text", "section": "Page 119"}
{"text": "\t\n4.3\u2002 \u25a0\u2002 Requirements elicitation\u2002 \u2002 119\nThe advantage of stories is that everyone can easily relate to them. We found this \napproach to be particularly useful to get information from a wider community than \nwe could realistically interview. We made the stories available on a wiki and invited \nteachers and students from across the country to comment on them.\nThese high-level stories do not go into detail about a system, but they can be \ndeveloped into more specific scenarios. Scenarios are descriptions of example user \ninteraction sessions. I think that it is best to present scenarios in a structured way \nrather than as narrative text. User stories used in agile methods such as Extreme \nProgramming, are actually narrative scenarios rather than general stories to help \nelicit requirements.\nA scenario starts with an outline of the interaction. During the elicitation process, \ndetails are added to create a complete description of that interaction. At its most \ngeneral, a scenario may include:\n1.\t\nA description of what the system and users expect when the scenario starts.\n2.\t\nA description of the normal flow of events in the scenario.\n3.\t\nA description of what can go wrong and how resulting problems can be handled.\n4.\t\nInformation about other activities that might be going on at the same time.\n5.\t\nA description of the system state when the scenario ends.\nAs an example of a scenario, Figure 4.10 describes what happens when a student \nuploads photos to the KidsTakePics system, as explained in Figure 4.9. The key dif-\nference between this system and other systems is that a teacher moderates the \nuploaded photos to check that they are suitable for sharing.\nYou can see this is a much more detailed description than the story in Figure 4.9, \nand so it can be used to propose requirements for the iLearn system. Like stories, \nscenarios can be used to facilitate discussions with stakeholders who sometimes may \nhave different ways of achieving the same result.\nFigure 4.9\u2002 A user story \nfor the iLearn system\nPhoto sharing in the classroom\nJack is a primary school teacher in Ullapool (a village in northern Scotland). He has decided that a class project \nshould be focused on the fishing industry in the area, looking at the history, development, and economic impact \nof fishing. As part of this project, pupils are asked to gather and share reminiscences from relatives, use newspa-\nper archives, and collect old photographs related to fishing and fishing communities in the area. Pupils use an \niLearn wiki to gather together fishing stories and SCRAN (a history resources site) to access newspaper archives \nand photographs. However, Jack also needs a photo-sharing site because he wants pupils to take and comment \non each other\u2019s photos and to upload scans of old photographs that they may have in their families.\nJack sends an email to a primary school teachers\u2019 group, which he is a member of, to see if anyone can rec-\nommend an appropriate system. Two teachers reply, and both suggest that he use KidsTakePics, a photo-sharing \nsite that allows teachers to check and moderate content. As KidsTakePics is not integrated with the iLearn \nauthentication service, he sets up a teacher and a class account. He uses the iLearn setup service to add \nKidsTakePics to the services seen by the pupils in his class so that when they log in, they can immediately use \nthe system to upload photos from their mobile devices and class computers.\n", "page": 120, "type": "text", "section": "Page 120"}
{"text": "120\u2002 \u2002 Chapter 4\u2002 \u25a0\u2002 Requirements engineering\n \n4.4  Requirements specification\nRequirements specification is the process of writing down the user and system require-\nments in a requirements document. Ideally, the user and system requirements should \nbe clear, unambiguous, easy to understand, complete, and consistent. In practice, this \nis almost impossible to achieve. Stakeholders interpret the requirements in different \nways, and there are often inherent conflicts and inconsistencies in the requirements.\nUser requirements are almost always written in natural language supplemented \nby appropriate diagrams and tables in the requirements document. System require-\nments may also be written in natural language, but other notations based on forms, \ngraphical, or mathematical system models can also be used. Figure 4.11 summarizes \npossible notations for writing system requirements.\nThe user requirements for a system should describe the functional and nonfunctional \nrequirements so that they are understandable by system users who don\u2019t have detailed \ntechnical knowledge. Ideally, they should specify only the external behavior of the sys-\ntem. The requirements document should not include details of the system architecture \nor design. Consequently, if you are writing user requirements, you should not use soft-\nware jargon, structured notations, or formal notations. You should write user require-\nments in natural language, with simple tables, forms, and intuitive diagrams.\nFigure 4.10\u2002 Scenario \nfor\u00a0uploading photos \nin\u00a0KidsTakePics\nUploading photos to KidsTakePics\nInitial assumption: A user or a group of users have one or more digital photographs to be uploaded to the \npicture-sharing site. These photos are saved on either a tablet or a laptop computer. They have successfully \nlogged on to KidsTakePics.\nNormal: The user chooses to upload photos and is prompted to select the photos to be uploaded on the \ncomputer and to select the project name under which the photos will be stored. Users should also be given the \noption of inputting keywords that should be associated with each uploaded photo. Uploaded photos are named \nby creating a conjunction of the user name with the filename of the photo on the local computer.\nOn completion of the upload, the system automatically sends an email to the project moderator, asking them to \ncheck new content, and generates an on-screen message to the user that this checking has been done.\nWhat can go wrong: No moderator is associated with the selected project. An email is automatically generated to \nthe school administrator asking them to nominate a project moderator. Users should be informed of a possible \ndelay in making their photos visible.\nPhotos with the same name have already been uploaded by the same user. The user should be asked if he or she \nwishes to re-upload the photos with the same name, rename the photos, or cancel the upload. If users choose to \nre-upload the photos, the originals are overwritten. If they choose to rename the photos, a new name is \nautomatically generated by adding a number to the existing filename.\nOther activities: The moderator may be logged on to the system and may approve photos as they are uploaded.\nSystem state on completion: User is logged on. The selected photos have been uploaded and assigned a status \n\u201cawaiting moderation.\u201d Photos are visible to the moderator and to the user who uploaded them.\n", "page": 121, "type": "text", "section": "Page 121"}
{"text": "\t\n4.4\u2002 \u25a0\u2002 Requirements specification\u2002 \u2002 121\nSystem requirements are expanded versions of the user requirements that soft-\nware engineers use as the starting point for the system design. They add detail and \nexplain how the system should provide the user requirements. They may be used as \npart of the contract for the implementation of the system and should therefore be a \ncomplete and detailed specification of the whole system.\nIdeally, the system requirements should only describe the external behavior of the \nsystem and its operational constraints. They should not be concerned with how the \nsystem should be designed or implemented. However, at the level of detail required \nto completely specify a complex software system, it is neither possible nor desirable \nto exclude all design information. There are several reasons for this:\n1.\t\nYou may have to design an initial architecture of the system to help structure the \nrequirements specification. The system requirements are organized according to \nthe different subsystems that make up the system. We did this when we were \ndefining the requirements for the iLearn system, where we proposed the archi-\ntecture shown in Figure 1.8.\n2.\t\nIn most cases, systems must interoperate with existing systems, which constrain \nthe design and impose requirements on the new system.\n3.\t\nThe use of a specific architecture to satisfy non-functional requirements, such as \nN-version programming to achieve reliability, discussed in Chapter 11, may be \nnecessary. An external regulator who needs to certify that the system is safe may \nspecify that an architectural design that has already been certified should be used.\n \n4.4.1  Natural language specification\nNatural language has been used to write requirements for software since the 1950s. \nIt is expressive, intuitive, and universal. It is also potentially vague and ambiguous, \nand its interpretation depends on the background of the reader. As a result, there \nFigure 4.11\u2002 Notations \nfor writing system \nrequirements\nNotation\nDescription\nNatural language \nsentences\nThe requirements are written using numbered sentences in natural language. \nEach sentence should express one requirement.\nStructured natural \nlanguage\nThe requirements are written in natural language on a standard form or \ntemplate. Each field provides information about an aspect of the requirement.\nGraphical notations\nGraphical models, supplemented by text annotations, are used to define the \nfunctional requirements for the system. UML (unified modeling language) use \ncase and sequence diagrams are commonly used.\nMathematical \nspecifications\nThese notations are based on mathematical concepts such as finite-state \nmachines or sets. Although these unambiguous specifications can reduce the \nambiguity in a requirements document, most customers don\u2019t understand a \nformal specification. They cannot check that it represents what they want, and \nthey are reluctant to accept it as a system contract. (I discuss this approach, in \nChapter 10, which covers system dependability.)\n", "page": 122, "type": "text", "section": "Page 122"}
{"text": "122\u2002 \u2002 Chapter 4\u2002 \u25a0\u2002 Requirements engineering\nhave been many proposals for alternative ways to write requirements. However, \nnone of these proposals has been widely adopted, and natural language will continue \nto be the most widely used way of specifying system and software requirements.\nTo minimize misunderstandings when writing natural language requirements, I \nrecommend that you follow these simple guidelines:\n1.\t\nInvent a standard format and ensure that all requirement definitions adhere to \nthat format. Standardizing the format makes omissions less likely and requirements \neasier to check. I suggest that, wherever possible, you should write the requirement \nin one or two sentences of natural language.\n2.\t\nUse language consistently to distinguish between mandatory and desirable \nrequirements. Mandatory requirements are requirements that the system must \nsupport and are usually written using \u201cshall.\u201d Desirable requirements are not \nessential and are written using \u201cshould.\u201d\n3.\t\nUse text highlighting (bold, italic, or color) to pick out key parts of the requirement.\n4.\t\nDo not assume that readers understand technical, software engineering language. \nIt\u00a0is easy for words such as \u201carchitecture\u201d and \u201cmodule\u201d to be misunderstood. \nWherever possible, you should avoid the use of jargon, abbreviations, and acronyms.\n5.\t\nWhenever possible, you should try to associate a rationale with each user \nrequirement. The rationale should explain why the requirement has been \nincluded and who proposed the requirement (the requirement source), so that \nyou know whom to consult if the requirement has to be changed. Requirements \nrationale is particularly useful when requirements are changed, as it may help \ndecide what changes would be undesirable.\nFigure 4.12 illustrates how these guidelines may be used. It includes two require-\nments for the embedded software for the automated insulin pump, introduced in \nChapter 1. Other requirements for this embedded system are defined in the insulin \npump requirements document, which can be downloaded from the book\u2019s web pages.\n \n4.4.2  Structured specifications\nStructured natural language is a way of writing system requirements where require-\nments are written in a standard way rather than as free-form text. This approach \nmaintains most of the expressiveness and understandability of natural language but \nFigure 4.12\u2002 Example \nrequirements for the \ninsulin pump software \nsystem\n3.2 The system shall measure the blood sugar and deliver insulin, if required, every 10 minutes. (Changes in \nblood sugar are relatively slow, so more frequent measurement is unnecessary; less frequent measurement \ncould lead to unnecessarily high sugar levels.)\n3.6 The system shall run a self-test routine every minute with the conditions to be tested and the associated \nactions defined in Table 1. (A self-test routine can discover hardware and software problems and alert the user \nto the fact the normal operation may be impossible.)\n", "page": 123, "type": "text", "section": "Page 123"}
{"text": "\t\n4.4\u2002 \u25a0\u2002 Requirements specification\u2002 \u2002 123\nProblems with using natural language for requirements specification\nThe flexibility of natural language, which is so useful for specification, often causes problems. There is scope for \nwriting unclear requirements, and readers (the designers) may misinterpret requirements because they have a \ndifferent background to the user. It is easy to amalgamate several requirements into a single sentence, and \nstructuring natural language requirements can be difficult.\nhttp://software-engineering-book.com/web/natural-language/\nensures that some uniformity is imposed on the specification. Structured language \nnotations use templates to specify system requirements. The specification may use \nprogramming language constructs to show alternatives and iteration, and may high-\nlight key elements using shading or different fonts.\nThe Robertsons (Robertson and Robertson 2013), in their book on the VOLERE \nrequirements engineering method, recommend that user requirements be initially \nwritten on cards, one requirement per card. They suggest a number of fields on each \ncard, such as the requirements rationale, the dependencies on other requirements, the \nsource of the requirements, and supporting materials. This is similar to the approach \nused in the example of a structured specification shown in Figure 4.13.\nTo use a structured approach to specifying system requirements, you define one \nor more standard templates for requirements and represent these templates as struc-\ntured forms. The specification may be structured around the objects manipulated by \nthe system, the functions performed by the system, or the events processed by the \nsystem. An example of a form-based specification, in this case, one that defines how \nto calculate the dose of insulin to be delivered when the blood sugar is within a safe \nband, is shown in Figure 4.13.\nWhen a standard format is used for specifying functional requirements, the fol-\nlowing information should be included:\n1.\t\nA description of the function or entity being specified.\n2.\t\nA description of its inputs and the origin of these inputs.\n3.\t\nA description of its outputs and the destination of these outputs.\n4.\t\nInformation about the information needed for the computation or other entities \nin the system that are required (the \u201crequires\u201d part).\n5.\t\nA description of the action to be taken.\n6.\t\nIf a functional approach is used, a precondition setting out what must be true \nbefore the function is called, and a postcondition specifying what is true after \nthe function is called.\n7.\t\nA description of the side effects (if any) of the operation.\nUsing structured specifications removes some of the problems of natural \u00ad\nlanguage \nspecification. Variability in the specification is reduced, and requirements are \u00ad\norganized \n", "page": 124, "type": "text", "section": "Page 124"}
{"text": "124\u2002 \u2002 Chapter 4\u2002 \u25a0\u2002 Requirements engineering\nmore effectively. However, it is still sometimes difficult to write requirements in a \nclear and unambiguous way, particularly when complex computations (e.g., how to \ncalculate the insulin dose) are to be specified.\nTo address this problem, you can add extra information to natural language \nrequirements, for example, by using tables or graphical models of the system. These \ncan show how computations proceed, how the system state changes, how users inter-\nact with the system, and how sequences of actions are performed.\nTables are particularly useful when there are a number of possible alternative \nsituations and you need to describe the actions to be taken for each of these. The \ninsulin pump bases its computations of the insulin requirement on the rate of change \nof blood sugar levels. The rates of change are computed using the current and previ-\nous readings. Figure 4.14 is a tabular description of how the rate of change of blood \nsugar is used to calculate the amount of insulin to be delivered.\nFigure 4.14\u2002 The  \ntabular specification  \nof computation in an \ninsulin pump\nCondition\nAction\nSugar level falling (r2 6 r1)\nCompDose = 0\nSugar level stable (r2 = r1)\nCompDose = 0\nSugar level increasing and rate of increase \ndecreasing ((r2 - r1)<(r1 - r0))\nCompDose = 0\nSugar level increasing and rate of increase stable \nor increasing r2 7 r1 & ((r2 - r1) \u00da (r1 \u2212 r0))\nCompDose = round ((r2 - r1)/4)\nIf rounded result = 0 then\nCompDose = MinimumDose\nFigure 4.13\u2002 The \nstructured specification \nof a requirement for  \nan insulin pump\nInsulin Pump/Control Software/SRS/3.3.2\nFunction\t\nCompute insulin dose: Safe sugar level.\nDescription\t\n\u0007\nComputes the dose of insulin to be delivered when the current measured sugar level is in the \nsafe zone between 3 and 7 units.\nInputs\t\nCurrent sugar reading (r2), the previous two readings (r0 and r1).\nSource\t\nCurrent sugar reading from sensor. Other readings from memory.\nOutputs\t\nCompDose\u2014the dose in insulin to be delivered.\nDestination\t\nMain control loop.\nAction:\t\n\u0007\nCompDose is zero if the sugar level is stable or falling or if the level is increasing but the rate of \nincrease is decreasing. If the level is increasing and the rate of increase is increasing, then \nCompDose is computed by dividing the difference between the current sugar level and the \nprevious level by 4 and rounding the result. If the result, is rounded to zero then CompDose is \nset to the minimum dose that can be delivered. (see Figure 4.14)\nRequires\t\nTwo previous readings so that the rate of change of sugar level can be computed.\nPrecondition\t\nThe insulin reservoir contains at least the maximum allowed single dose of insulin.\nPostcondition\t\nr0 is replaced by r1 then r1 is replaced by r2.\nSide effects\t\nNone.\n", "page": 125, "type": "text", "section": "Page 125"}
{"text": "\t\n4.4\u2002 \u25a0\u2002 Requirements specification\u2002 \u2002 125\n \n4.4.3  Use cases\nUse cases are a way of describing interactions between users and a system using a \ngraphical model and structured text. They were first introduced in the Objectory \nmethod (Jacobsen et al. 1993) and have now become a fundamental feature of the \nUnified Modeling Language (UML). In their simplest form, a use case identifies the \nactors involved in an interaction and names the type of interaction. You then add \nadditional information describing the interaction with the system. The additional \ninformation may be a textual description or one or more graphical models such as \nthe UML sequence or state charts (see Chapter 5).\nUse cases are documented using a high-level use case diagram. The set of use \ncases represents all of the possible interactions that will be described in the system \nrequirements. Actors in the process, who may be human or other systems, are repre-\nsented as stick figures. Each class of interaction is represented as a named ellipse. \nLines link the actors with the interaction. Optionally, arrowheads may be added to \nlines to show how the interaction is initiated. This is illustrated in Figure 4.15, which \nshows some of the use cases for the Mentcare system.\nUse cases identify the individual interactions between the system and its users or \nother systems. Each use case should be documented with a textual description. These \ncan then be linked to other models in the UML that will develop the scenario in more \ndetail. For example, a brief description of the Setup Consultation use case from \nFigure 4.15 might be:\nSetup consultation allows two or more doctors, working in different offices, to \nview the same patient record at the same time. One doctor initiates the consul-\ntation by choosing the people involved from a dropdown menu of doctors who \nare online. The patient record is then displayed on their screens, but only the \ninitiating doctor can edit the record. In addition, a text chat window is created \nNurse\nMedical receptionist\nManager\nRegister\npatient\nView\npersonal info.\nView record\nGenerate\nreport\nExport\nstatistics\nDoctor\nEdit record\nSetup\nconsultation\nFigure 4.15\u2002 Use cases \nfor the Mentcare system\n", "page": 126, "type": "text", "section": "Page 126"}
{"text": "126\u2002 \u2002 Chapter 4\u2002 \u25a0\u2002 Requirements engineering\nto help coordinate actions. It is assumed that a phone call for voice communi-\ncation can be separately arranged.\nThe UML is a standard for object-oriented modeling, so use cases and use case-\nbased elicitation are used in the requirements engineering process. However, my \nexperience with use cases is that they are too fine-grained to be useful in discussing \nrequirements. Stakeholders don\u2019t understand the term use case; they don\u2019t find the \ngraphical model to be useful, and they are often not interested in a detailed descrip-\ntion of each and every system interaction. Consequently, I find use cases to be more \nhelpful in systems design than in requirements engineering. I discuss use cases fur-\nther in Chapter 5, which shows how they are used alongside other system models to \ndocument a system design.\nSome people think that each use case is a single, low-level interaction scenario. \nOthers, such as Stevens and Pooley (Stevens and Pooley 2006), suggest that each use \ncase includes a set of related, low-level scenarios. Each of these scenarios is a single \nthread through the use case. Therefore, there would be a scenario for the normal \ninteraction plus scenarios for each possible exception. In practice, you can use them \nin either way.\n \n4.4.4  The software requirements document\nThe software requirements document (sometimes called the software requirements \nspecification or SRS) is an official statement of what the system developers should \nimplement. It may include both the user requirements for a system and a detailed \nspecification of the system requirements. Sometimes the user and system require-\nments are integrated into a single description. In other cases, the user requirements \nare described in an introductory chapter in the system requirements specification.\nRequirements documents are essential when systems are outsourced for development, \nwhen different teams develop different parts of the system, and when a detailed analysis \nof the requirements is mandatory. In other circumstances, such as software product or \nbusiness system development, a detailed requirements document may not be needed.\nAgile methods argue that requirements change so rapidly that a requirements \ndocument is out of date as soon as it is written, so the effort is largely wasted. Rather \nthan a formal document, agile approaches often collect user requirements incremen-\ntally and write these on cards or whiteboards as short user stories. The user then \nprioritizes these stories for implementation in the next increment of the system.\nFor business systems where requirements are unstable, I think that this approach \nis a good one. However, I think that it is still useful to write a short supporting docu-\nment that defines the business and dependability requirements for the system; it is \neasy to forget the requirements that apply to the system as a whole when focusing on \nthe functional requirements for the next system release.\nThe requirements document has a diverse set of users, ranging from the senior \nmanagement of the organization that is paying for the system to the engineers \nresponsible for developing the software. Figure 4.16 shows possible users of the \ndocument and how they use it.\n", "page": 127, "type": "text", "section": "Page 127"}
{"text": "\t\n4.4\u2002 \u25a0\u2002 Requirements specification\u2002 \u2002 127\nUse the requirements to\ndevelop validation tests for\nthe system.\nUse the requirements\ndocument to plan a bid for\nthe system and to plan the\nsystem development process.\nUse the requirements to\nunderstand what system is\nto be developed.\nSystem test\nengineers\nManagers\nSystem\nengineers\nSpecify the requirements and\nread them to check that they\nmeet their needs. Customers\nspecify changes to the\nrequirements.\nSystem\ncustomers\nUse the requirements to\nunderstand the system and\nthe relationships between its\nparts.\nSystem\nmaintenance\nengineers\nFigure 4.16\u2002 Users of a \nrequirements document\nThe diversity of possible users means that the requirements document has to be a \ncompromise. It has to describe the requirements for customers, define the require-\nments in precise detail for developers and testers, as well as include information \nabout future system evolution. Information on anticipated changes helps system \ndesigners to avoid restrictive design decisions and maintenance engineers to adapt \nthe system to new requirements.\nThe level of detail that you should include in a requirements document depends \non the type of system that is being developed and the development process used. \nCritical systems need detailed requirements because safety and security have to be \nanalyzed in detail to find possible requirements errors. When the system is to be \ndeveloped by a separate company (e.g., through outsourcing), the system specifica-\ntions need to be detailed and precise. If an in-house, iterative development process is \nused, the requirements document can be less detailed. Details can be added to the \nrequirements and ambiguities resolved during development of the system.\nFigure 4.17 shows one possible organization for a requirements document that is \nbased on an IEEE standard for requirements documents (IEEE 1998). This standard \nis a generic one that can be adapted to specific uses. In this case, the standard has \nbeen extended to include information about predicted system evolution. This infor-\nmation helps the maintainers of the system and allows designers to include support \nfor future system features.\n", "page": 128, "type": "text", "section": "Page 128"}
{"text": "128\u2002 \u2002 Chapter 4\u2002 \u25a0\u2002 Requirements engineering\nFigure 4.17\u2002 The \nstructure of a \nrequirements  \ndocument\nChapter\nDescription\nPreface\nThis defines the expected readership of the document and describe its version history, \nincluding a rationale for the creation of a new version and a summary of the changes \nmade in each version.\nIntroduction\nThis describes the need for the system. It should briefly describe the system\u2019s functions \nand explain how it will work with other systems. It should also describe how the system \nfits into the overall business or strategic objectives of the organization commissioning the \nsoftware.\nGlossary\nThis defines the technical terms used in the document. You should not make assumptions \nabout the experience or expertise of the reader.\nUser \nrequirements \ndefinition\nHere, you describe the services provided for the user. The nonfunctional system \nrequirements should also be described in this section. This description may use natural \nlanguage, diagrams, or other notations that are understandable to customers. Product and \nprocess standards that must be followed should be specified.\nSystem \narchitecture\nThis chapter presents a high-level overview of the anticipated system architecture, showing \nthe distribution of functions across system modules. Architectural components that are \nreused should be highlighted.\nSystem \nrequirements \nspecification\nThis describes the functional and nonfunctional requirements in more detail. If necessary, \nfurther detail may also be added to the nonfunctional requirements. Interfaces to other \nsystems may be defined.\nSystem \nmodels\nThis chapter includes graphical system models showing the relationships between the \nsystem components and the system and its environment. Examples of possible models are \nobject models, data-flow models, or semantic data models.\nSystem \nevolution\nThis describes the fundamental assumptions on which the system is based, and any \nanticipated changes due to hardware evolution, changing user needs, and so on. This \nsection is useful for system designers as it may help them avoid design decisions that \nwould constrain likely future changes to the system.\nAppendices\nThese provide detailed, specific information that is related to the application being \ndeveloped\u2014for example, hardware and database descriptions. Hardware requirements \ndefine the minimal and optimal configurations for the system. Database requirements define \nthe logical organization of the data used by the system and the relationships between data.\nIndex\nSeveral indexes to the document may be included. As well as a normal alphabetic index, \nthere may be an index of diagrams, an index of functions, and so on.\nNaturally, the information included in a requirements document depends on the \ntype of software being developed and the approach to development that is to be used. \nA requirements document with a structure like that shown in Figure 4.17 might be \nproduced for a complex engineering system that includes hardware and software \ndeveloped by different companies. The requirements document is likely to be long \nand detailed. It is therefore important that a comprehensive table of contents and doc-\nument index be included so that readers can easily find the information they need.\nBy contrast, the requirements document for an in-house software product will \nleave out many of detailed chapters suggested above. The focus will be on defining \nthe user requirements and high-level, nonfunctional system requirements. The sys-\ntem designers and programmers use their judgment to decide how to meet the out-\nline user requirements for the system.\n", "page": 129, "type": "text", "section": "Page 129"}
{"text": "\t\n4.5\u2002 \u25a0\u2002 Requirements validation\u2002 \u2002 129\n \n4.5  Requirements validation\nRequirements validation is the process of checking that requirements define the sys-\ntem that the customer really wants. It overlaps with elicitation and analysis, as it is \nconcerned with finding problems with the requirements. Requirements validation is \ncritically important because errors in a requirements document can lead to extensive \nrework costs when these problems are discovered during development or after the \nsystem is in service.\nThe cost of fixing a requirements problem by making a system change is usually \nmuch greater than repairing design or coding errors. A change to the requirements \nusually means that the system design and implementation must also be changed. \nFurthermore, the system must then be retested.\nDuring the requirements validation process, different types of checks should be \ncarried out on the requirements in the requirements document. These checks include:\n1.\t\nValidity checks These check that the requirements reflect the real needs of sys-\ntem users. Because of changing circumstances, the user requirements may have \nchanged since they were originally elicited.\n2.\t\nConsistency checks Requirements in the document should not conflict. That is, \nthere should not be contradictory constraints or different descriptions of the \nsame system function.\n3.\t\nCompleteness checks The requirements document should include requirements \nthat define all functions and the constraints intended by the system user.\n4.\t\nRealism checks By using knowledge of existing technologies, the requirements \nshould be checked to ensure that they can be implemented within the proposed \nbudget for the system. These checks should also take account of the budget and \nschedule for the system development.\n5.\t\nVerifiability To reduce the potential for dispute between customer and contrac-\ntor, system requirements should always be written so that they are verifiable. \nThis means that you should be able to write a set of tests that can demonstrate \nthat the delivered system meets each specified requirement.\nRequirements document standards\nA number of large organizations, such as the U.S. Department of Defense and the IEEE, have defined standards \nfor requirements documents. These are usually very generic but are nevertheless useful as a basis for develop-\ning more detailed organizational standards. The U.S. Institute of Electrical and Electronic Engineers (IEEE) is one \nof the best-known standards providers, and they have developed a standard for the structure of requirements \ndocuments. This standard is most appropriate for systems such as military command and control systems that \nhave a long lifetime and are usually developed by a group of organizations.\nhttp://software-engineering-book.com/web/requirements-standard/\n", "page": 130, "type": "text", "section": "Page 130"}
{"text": "130\u2002 \u2002 Chapter 4\u2002 \u25a0\u2002 Requirements engineering\nA number of requirements validation techniques can be used individually or in \nconjunction with one another:\n1.\t\nRequirements reviews The requirements are analyzed systematically by a team \nof reviewers who check for errors and inconsistencies.\n2.\t\nPrototyping This involves developing an executable model of a system and \nusing this with end-users and customers to see if it meets their needs and expec-\ntations. Stakeholders experiment with the system and feed back requirements \nchanges to the development team.\n3.\t\nTest-case generation Requirements should be testable. If the tests for the \nrequirements are devised as part of the validation process, this often reveals \nrequirements problems. If a test is difficult or impossible to design, this usually \nmeans that the requirements will be difficult to implement and should be recon-\nsidered. Developing tests from the user requirements before any code is written \nis an integral part of test-driven development.\nYou should not underestimate the problems involved in requirements validation. \nUltimately, it is difficult to show that a set of requirements does in fact meet a user\u2019s \nneeds. Users need to picture the system in operation and imagine how that system \nwould fit into their work. It is hard even for skilled computer professionals to per-\nform this type of abstract analysis and harder still for system users.\nAs a result, you rarely find all requirements problems during the requirements \nvalidation process. Inevitably, further requirements changes will be needed to cor-\nrect omissions and misunderstandings after agreement has been reached on the \nrequirements document.\n \n4.6  Requirements change\nThe requirements for large software systems are always changing. One reason for \nthe frequent changes is that these systems are often developed to address \u201cwicked\u201d \nproblems\u2014problems that cannot be completely defined (Rittel and Webber 1973). \nBecause the problem cannot be fully defined, the software requirements are bound to \nRequirements reviews\nA requirements review is a process in which a group of people from the system customer and the system devel-\noper read the requirements document in detail and check for errors, anomalies, and inconsistencies. Once these \nhave been detected and recorded, it is then up to the customer and the developer to negotiate how the identi-\nfied problems should be solved.\nhttp://software-engineering-book.com/web/requirements-reviews/\n", "page": 131, "type": "text", "section": "Page 131"}
{"text": "\t\n4.6\u2002 \u25a0\u2002 Requirements change\u2002 \u2002 131\nbe incomplete. During the software development process, the stakeholders\u2019 under-\nstanding of the problem is constantly changing (Figure 4.18). The system require-\nments must then evolve to reflect this changed problem understanding.\nOnce a system has been installed and is regularly used, new requirements inevita-\nbly emerge. This is partly a consequence of errors and omissions in the original \nrequirements that have to be corrected. However, most changes to system require-\nments arise because of changes to the business environment of the system:\n1.\t\nThe business and technical environment of the system always changes after \ninstallation. New hardware may be introduced and existing hardware updated. It \nmay be necessary to interface the system with other systems. Business priorities \nmay change (with consequent changes in the system support required), and new \nlegislation and regulations may be introduced that require system compliance.\n2.\t\nThe people who pay for a system and the users of that system are rarely the \nsame people. System customers impose requirements because of organizational \nand budgetary constraints. These may conflict with end-user requirements, and, \nafter delivery, new features may have to be added for user support if the system \nis to meet its goals.\n3.\t\nLarge systems usually have a diverse stakeholder community, with stakeholders \nhaving different requirements. Their priorities may be conflicting or contradic-\ntory. The final system requirements are inevitably a compromise, and some \nstakeholders have to be given priority. With experience, it is often discovered \nthat the balance of support given to different stakeholders has to be changed and \nthe requirements re-prioritized.\nAs requirements are evolving, you need to keep track of individual requirements \nand maintain links between dependent requirements so that you can assess the \nimpact of requirements changes. You therefore need a formal process for making \nchange proposals and linking these to system requirements. This process of \u201crequire-\nments management\u201d should start as soon as a draft version of the requirements docu-\nment is available.\nAgile development processes have been designed to cope with requirements that \nchange during the development process. In these processes, when a user proposes a \nrequirements change, this change does not go through a formal change management \nTime\nChanged\nunderstanding\nof problem\nInitial\nunderstanding\nof problem\nChanged\nrequirements\nInitial\nrequirements\nFigure 4.18\u2002  \nRequirements evolution\n", "page": 132, "type": "text", "section": "Page 132"}
{"text": "132\u2002 \u2002 Chapter 4\u2002 \u25a0\u2002 Requirements engineering\nprocess. Rather, the user has to prioritize that change and, if it is high priority, decide \nwhat system features that were planned for the next iteration should be dropped for \nthe change to be implemented.\nThe problem with this approach is that users are not necessarily the best people to \ndecide on whether or not a requirements change is cost-effective. In systems with \nmultiple stakeholders, changes will benefit some stakeholders and not others. It is \noften better for an independent authority, who can balance the needs of all stake-\nholders, to decide on the changes that should be accepted.\n \n4.6.1  Requirements management planning\nRequirements management planning is concerned with establishing how a set of \nevolving requirements will be managed. During the planning stage, you have to \ndecide on a number of issues:\n1.\t\nRequirements identification Each requirement must be uniquely identified so \nthat it can be cross-referenced with other requirements and used in traceability \nassessments.\n2.\t\nA change management process This is the set of activities that assess the impact \nand cost of changes. I discuss this process in more detail in the following section.\n3.\t\nTraceability policies These policies define the relationships between each require-\nment and between the requirements and the system design that should be recorded. \nThe traceability policy should also define how these records should be maintained.\n4.\t\nTool support Requirements management involves the processing of large \namounts of information about the requirements. Tools that may be used range \nfrom specialist requirements management systems to shared spreadsheets and \nsimple database systems.\nRequirements management needs automated support, and the software tools for \nthis should be chosen during the planning phase. You need tool support for:\n1.\t\nRequirements storage The requirements should be maintained in a secure, man-\naged data store that is accessible to everyone involved in the requirements engi-\nneering process.\nEnduring and volatile requirements\nSome requirements are more susceptible to change than others. Enduring requirements are the requirements \nthat are associated with the core, slow-to-change activities of an organization. Enduring requirements are asso-\nciated with fundamental work activities. Volatile requirements are more likely to change. They are usually asso-\nciated with supporting activities that reflect how the organization does its work rather than the work itself.\nhttp://software-engineering-book.com/web/changing-requirements/\n", "page": 133, "type": "text", "section": "Page 133"}
{"text": "\t\n4.6\u2002 \u25a0\u2002 Requirements change\u2002 \u2002 133\n2.\t\nChange management The process of change management (Figure 4.19) is sim-\nplified if active tool support is available. Tools can keep track of suggested \nchanges and responses to these suggestions.\n3.\t\nTraceability management As discussed above, tool support for traceability \nallows related requirements to be discovered. Some tools are available which \nuse natural language processing techniques to help discover possible relation-\nships between requirements.\nFor small systems, you do not need to use specialized requirements management \ntools. Requirements management can be supported using shared web documents, \nspreadsheets, and databases. However, for larger systems, more specialized tool sup-\nport, using systems such as DOORS (IBM 2013), makes it much easier to keep track \nof a large number of changing requirements.\n \n4.6.2  Requirements change management\nRequirements change management (Figure 4.19) should be applied to all proposed \nchanges to a system\u2019s requirements after the requirements document has been approved. \nChange management is essential because you need to decide if the benefits of imple-\nmenting new requirements are justified by the costs of implementation. The advantage \nof using a formal process for change management is that all change proposals are treated \nconsistently and changes to the requirements document are made in a controlled way.\nThere are three principal stages to a change management process:\n1.\t Problem analysis and change specification The process starts with an identi-\nfied requirements problem or, sometimes, with a specific change proposal. \nDuring this stage, the problem or the change proposal is analyzed to check that \nit is valid. This analysis is fed back to the change requestor who may respond \nwith a more specific requirements change proposal, or decide to withdraw \nthe\u00a0request.\n2.\t\nChange analysis and costing The effect of the proposed change is assessed \nusing traceability information and general knowledge of the system require-\nments. The cost of making the change is estimated in terms of modifications to \nthe requirements document and, if appropriate, to the system design and imple-\nmentation. Once this analysis is completed, a decision is made as to whether or \nnot to proceed with the requirements change.\nChange\nimplementation\nChange analysis\nand costing\nProblem analysis and\nchange specification\nIdentified\nproblem\nRevised\nrequirements\nFigure 4.19\u2002  \nRequirements change \nmanagement\n", "page": 134, "type": "text", "section": "Page 134"}
{"text": "134\u2002 \u2002 Chapter 4\u2002 \u25a0\u2002 Requirements engineering\n3.\t\nChange implementation The requirements document and, where necessary, the \nsystem design and implementation, are modified. You should organize the \nrequirements document so that you can make changes to it without extensive \nrewriting or reorganization. As with programs, changeability in documents is \nachieved by minimizing external references and making the document sections \nas modular as possible. Thus, individual sections can be changed and replaced \nwithout affecting other parts of the document.\nIf a new requirement has to be urgently implemented, there is always a tempta-\ntion to change the system and then retrospectively modify the requirements docu-\nment. This almost inevitably leads to the requirements specification and the system \nimplementation getting out of step. Once system changes have been made, it is easy \nto forget to include these changes in the requirements document. In some circum-\nstances, emergency changes to a system have to be made. In those cases, it is impor-\ntant that you update the requirements document as soon as possible in order to \ninclude the revised requirements.\nKey Points\n\u25a0\t Requirements for a software system set out what the system should do and define constraints \non its operation and implementation.\n\u25a0\t Functional requirements are statements of the services that the system must provide or are \ndescriptions of how some computations must be carried out.\n\u25a0\t Non-functional requirements often constrain the system being developed and the development \nprocess being used. These might be product requirements, organizational requirements, or \nexternal requirements. They often relate to the emergent properties of the system and therefore \napply to the system as a whole.\n\u25a0\t The requirements engineering process includes requirements elicitation, requirements \nspecification, requirements validation, and requirements management.\n\u25a0\t Requirements elicitation is an iterative process that can be represented as a spiral of activities\u2014\nrequirements discovery, requirements classification and organization, requirements \nnegotiation, and requirements documentation.\nRequirements traceability\nYou need to keep track of the relationships between requirements, their sources, and the system design so that \nyou can analyze the reasons for proposed changes and the impact that these changes are likely to have on \nother parts of the system. You need to be able to trace how a change ripples its way through the system. Why?\nhttp://software-engineering-book.com/web/traceability/\n", "page": 135, "type": "text", "section": "Page 135"}
{"text": "\t\nChapter 4\u2002 \u25a0\u2002 Website\u2002 \u2002 135\n\u25a0\t Requirements specification is the process of formally documenting the user and system require-\nments and creating a software requirements document.\n\u25a0\t The software requirements document is an agreed statement of the system requirements. It \nshould be organized so that both system customers and software developers can use it.\n\u25a0\t Requirements validation is the process of checking the requirements for validity, consistency, \ncompleteness, realism, and verifiability.\n\u25a0\t Business, organizational, and technical changes inevitably lead to changes to the requirements \nfor a software system. Requirements management is the process of managing and controlling \nthese changes.\nFurther Reading\n\u201cIntegrated Requirements Engineering: A Tutorial.\u201d This is a tutorial paper that discusses require-\nments engineering activities and how these can be adapted to fit with modern software engineering \npractice. (I. Sommerville, IEEE Software, 22(1), January\u2013February 2005) http://dx.doi.org/10.1109/\nMS.2005.13.\n\u201cResearch Directions in Requirements Engineering.\u201d This is a good survey of requirements engineer-\ning research that highlights future research challenges in the area to address issues such as scale \nand agility. (B. H. C. Cheng and J. M. Atlee, Proc. Conf. on Future of Software Engineering, IEEE Com-\nputer Society, 2007) http://dx.doi.org/10.1109/FOSE.2007.17.\nMastering the Requirements Process, 3rd ed. A well-written, easy-to-read book that is based on a \nparticular method (VOLERE) but that also includes lots of good general advice about requirements \nengineering. (S. Robertson and J. Robertson, 2013, Addison-Wesley).\nWebsite\nPowerPoint slides for this chapter:\nwww.pearsonglobaleditions.com/Sommerville\nLinks to supporting videos:\nhttp://software-engineering-book.com/videos/requirements-and-design/\nRequirements document for the insulin pump:\nhttp://software-engineering-book.com/case-studies/insulin-pump/\nMentcare system requirements information:\nhttp://software-engineering-book.com/case-studies/mentcare-system/\n", "page": 136, "type": "text", "section": "Page 136"}
{"text": "136\u2002 \u2002 Chapter 4\u2002 \u25a0\u2002 Requirements engineering\nExercises\n4.1. \t Identify and briefly describe four types of requirements that may be defined for a computer-\nbased system.\n4.2. \t Discover ambiguities or omissions in the following statement of the requirements for part of a \ndrone system intended for search and recovery:\nThe drone, a quad chopper, will be very useful in search and recovery operations, especially in \nremote areas or in extreme weather conditions. It will click high-resolution images. It will fly \naccording to a path preset by a ground operator, but will be able to avoid obstacles on its \nown, returning to its original path whenever possible. The drone will also be able to identify \nvarious objects and match them to the target it is looking for.\n4.3. \t Rewrite the above description using the structured approach described in this chapter. \nResolve the identified ambiguities in a sensible way.\n4.4. \t Write a set of non-functional requirements for the drone system, setting out its expected \nsafety and response time.\n4.5. \t Using the technique suggested here, where natural language descriptions are presented in a \nstandard format, write plausible user requirements for the following functions:\nAn unattended petrol (gas) pump system that includes a credit card reader. The customer \nswipes the card through the reader, then specifies the amount of fuel required. The fuel is \ndelivered and the customer\u2019s account debited.\nThe cash-dispensing function in a bank ATM.\nIn an Internet banking system, a facility that allows customers to transfer funds from one \naccount held with the bank to another account with the same bank.\n4.6. \t Suggest how an engineer responsible for drawing up a system requirements specification \nmight keep track of the relationships between functional and non-functional requirements.\n4.7. \t Using your knowledge of how an ATM is used, develop a set of use cases that could serve as a \nbasis for understanding the requirements for an ATM system.\n4.8. \t To minimize mistakes during a requirements review, an organization decides to allocate two \nscribes to document the review session. Explain how this can be done.\n4.9. \t When emergency changes have to be made to systems, the system software may have to be \nmodified before changes to the requirements have been approved. Suggest a model of a pro-\ncess for making these modifications that will ensure that the requirements document and the \nsystem implementation do not become inconsistent.\n4.10. \t You have taken a job with a software user who has contracted your previous employer to \ndevelop a system for them. You discover that your company\u2019s interpretation of the require-\nments is different from the interpretation taken by your previous employer. Discuss what you \n", "page": 137, "type": "text", "section": "Page 137"}
{"text": "\t\nChapter 4\u2002 \u25a0\u2002 References\u2002 \u2002 137\nshould do in such a situation. You know that the costs to your current employer will increase if \nthe ambiguities are not resolved. However, you also have a responsibility of confidentiality to \nyour previous employer.\nReferences\nCrabtree, A. 2003. Designing Collaborative Systems: A Practical Guide to Ethnography. London: \nSpringer-Verlag.\nDavis, A. M. 1993. Software Requirements: Objects, Functions and States. Englewood Cliffs, NJ:  \nPrentice-Hall.\nIBM. 2013. \u201cRational Doors Next Generation: Requirements Engineering for Complex Systems.\u201d \nhttps://jazz.net/products/rational-doors-next-generation/\nIEEE. 1998. \u201cIEEE Recommended Practice for Software Requirements Specifications.\u201d In IEEE Soft-\nware Engineering Standards Collection. Los Alamitos, CA: IEEE Computer Society Press.\nJacobsen, I., M. Christerson, P. Jonsson, and G. Overgaard. 1993. Object-Oriented Software Engineering. \nWokingham, UK: Addison-Wesley.\nMartin, D., and I. Sommerville. 2004. \u201cPatterns of Cooperative Interaction: Linking Ethnomethodol-\nogy and Design.\u201d ACM Transactions on Computer-Human Interaction 11 (1) (March 1): 59\u201389. \ndoi:10.1145/972648.972651.\nRittel, H., and M. Webber. 1973. \u201cDilemmas in a General Theory of Planning.\u201d Policy Sciences 4:  \n155\u2013169. doi:10.1007/BF01405730.\nRobertson, S., and J. Robertson. 2013. Mastering the Requirements Process, 3rd ed. Boston:  \nAddison-Wesley.\nSommerville, I., T. Rodden, P. Sawyer, R. Bentley, and M. Twidale. 1993. \u201cIntegrating Ethnography \ninto the Requirements Engineering Process.\u201d In RE\u201993, 165\u2013173. San Diego, CA: IEEE Computer  \nSociety Press. doi:10.1109/ISRE.1993.324821.\nStevens, P., and R. Pooley. 2006. Using UML: Software Engineering with Objects and Components, \n2nd ed. Harlow, UK: Addison-Wesley.\nSuchman, L. 1983. \u201cOffice Procedures as Practical Action: Models of Work and System Design.\u201d ACM \nTransactions on Office Information Systems 1 (3): 320\u2013328. doi:10.1145/357442.357445.\nViller, S., and I. Sommerville. 2000. \u201cEthnographically Informed Analysis for Software Engineers.\u201d \nInt. J. of Human-Computer Studies 53 (1): 169\u2013196. doi:10.1006/ijhc.2000.0370.\n", "page": 138, "type": "text", "section": "Page 138"}
{"text": "Objectives\nThe aim of this chapter is to introduce system models that may be \ndeveloped as part of requirements engineering and system design \nprocesses. When you have read the chapter, you will:\n\u25a0\t understand how graphical models can be used to represent \nsoftware systems and why several types of model are needed to \nfully represent a system;\n\u25a0\t understand the fundamental system modeling perspectives of \ncontext, interaction, structure, and behavior;\n\u25a0\t understand the principal diagram types in the Unified Modeling \nLanguage (UML) and how these diagrams may be used in system \nmodeling;\n\u25a0\t have been introduced to model-driven engineering, where an \nexecutable system is automatically generated from structural and \nbehavioral models.\nContents\n5.1\t Context models\n5.2\t Interaction models\n5.3\t Structural models\n5.4\t Behavioral models\n5.5\t Model-driven engineering\nSystem modeling\n5 \n", "page": 139, "type": "text", "section": "Page 139"}
{"text": " \nChapter 5\u2002 \u25a0\u2002 System modeling\u2002 \u2002 139\nSystem modeling is the process of developing abstract models of a system, with each \nmodel presenting a different view or perspective of that system. System modeling \nnow usually means representing a system using some kind of graphical notation \nbased on diagram types in the Unified Modeling Language (UML). However, it is \nalso possible to develop formal (mathematical) models of a system, usually as a \ndetailed system specification. I cover graphical modeling using the UML here, and \nformal modeling is briefly discussed in Chapter 10.\nModels are used during the requirements engineering process to help derive the \ndetailed requirements for a system, during the design process to describe the system \nto engineers implementing the system, and after implementation to document the \nsystem\u2019s structure and operation. You may develop models of both the existing sys-\ntem and the system to be developed:\n1.\t\nModels of the existing system are used during requirements engineering. They \nhelp clarify what the existing system does, and they can be used to focus a stake-\nholder discussion on its strengths and weaknesses.\n2.\t\nModels of the new system are used during requirements engineering to help \nexplain the proposed requirements to other system stakeholders. Engineers use \nthese models to discuss design proposals and to document the system for imple-\nmentation. If you use a model-driven engineering process (Brambilla, Cabot, \nand Wimmer 2012), you can generate a complete or partial system implementa-\ntion from system models.\nIt is important to understand that a system model is not a complete representation of \nsystem. It purposely leaves out detail to make it easier to understand. A model is an \nabstraction of the system being studied rather than an alternative representation of that \nsystem. A representation of a system should maintain all the information about the entity \nbeing represented. An abstraction deliberately simplifies a system design and picks out \nthe most salient characteristics. For example, the PowerPoint slides that accompany this \nbook are an abstraction of the book\u2019s key points. However, if the book were translated \nfrom English into Italian, this would be an alternative \u00ad\nrepresentation. The translator\u2019s \nintention would be to maintain all the information as it is presented in English.\nYou may develop different models to represent the system from different \n\u00ad\nperspectives. For example:\n1.\t\nAn external perspective, where you model the context or environment of the \nsystem.\n2.\t\nAn interaction perspective, where you model the interactions between a system \nand its environment, or between the components of a system.\n3.\t\nA structural perspective, where you model the organization of a system or the \nstructure of the data processed by the system.\n4.\t\nA behavioral perspective, where you model the dynamic behavior of the system \nand how it responds to events.\n", "page": 140, "type": "text", "section": "Page 140"}
{"text": "140\u2002 \u2002 Chapter 5\u2002 \u25a0\u2002 System modeling\nWhen developing system models, you can often be flexible in the way that the \ngraphical notation is used. You do not always need to stick rigidly to the details of a \nnotation. The detail and rigor of a model depend on how you intend to use it. There \nare three ways in which graphical models are commonly used:\n1.\t\nAs a way to stimulate and focus discussion about an existing or proposed sys-\ntem. The purpose of the model is to stimulate and focus discussion among the \nsoftware engineers involved in developing the system. The models may be \nincomplete (as long as they cover the key points of the discussion), and they \nmay use the modeling notation informally. This is how models are normally \nused in agile modeling (Ambler and Jeffries 2002).\n2.\t\nAs a way of documenting an existing system. When models are used as docu-\nmentation, they do not have to be complete, as you may only need to use models \nto document some parts of a system. However, these models have to be \u00ad\ncorrect\u2014\nthey should use the notation correctly and be an accurate description of the \n\u00ad\nsystem.\n3.\t\nAs a detailed system description that can be used to generate a system imple-\nmentation. Where models are used as part of a model-based development pro-\ncess, the system models have to be both complete and correct. They are used as \na basis for generating the source code of the system, and you therefore have to \nbe very careful not to confuse similar symbols, such as stick and block arrow-\nheads, that may have different meanings.\nIn this chapter, I use diagrams defined in the Unified Modeling Language \n(UML) (Rumbaugh, Jacobson, and Booch 2004; Booch, Rumbaugh, and \nJacobson 2005), which has become a standard language for object-oriented mod-\neling. The UML has 13 diagram types and so supports the creation of many \n\u00ad\ndifferent types of system model. However, a survey (Erickson and Siau 2007) \nshowed that most users of the UML thought that five diagram types could repre-\nsent the essentials of a system. I therefore concentrate on these five UML \u00ad\ndiagram \ntypes here:\nThe Unified Modeling Language\nThe Unified Modeling Language (UML) is a set of 13 different diagram types that may be used to model soft-\nware systems. It emerged from work in the 1990s on object-oriented modeling, where similar object-oriented \nnotations were integrated to create the UML. A major revision (UML 2) was finalized in 2004. The UML is uni-\nversally accepted as the standard approach for developing models of software systems. Variants, such as SysML, \nhave been proposed for more general system modeling.\nhttp://software-engineering-book.com/web/uml/\n", "page": 141, "type": "text", "section": "Page 141"}
{"text": " \n5.1\u2002 \u25a0\u2002 Context models\u2002 \u2002 141\n1.\t\nActivity diagrams, which show the activities involved in a process or in data \nprocessing.\n2.\t\nUse case diagrams, which show the interactions between a system and its \n\u00ad\nenvironment.\n3.\t\nSequence diagrams, which show interactions between actors and the system and \nbetween system components.\n4.\t\nClass diagrams, which show the object classes in the system and the associa-\ntions between these classes.\n5.\t\nState diagrams, which show how the system reacts to internal and external events.\n \n5.1  Context models\nAt an early stage in the specification of a system, you should decide on the system \nboundaries, that is, on what is and is not part of the system being developed. This \ninvolves working with system stakeholders to decide what functionality should be \nincluded in the system and what processing and operations should be carried out in \nthe system\u2019s operational environment. You may decide that automated support for \nsome business processes should be implemented in the software being developed but \nthat other processes should be manual or supported by different systems. You should \nlook at possible overlaps in functionality with existing systems and decide where \nnew functionality should be implemented. These decisions should be made early in \nthe process to limit the system costs and the time needed for understanding the sys-\ntem requirements and design.\nIn some cases, the boundary between a system and its environment is relatively \nclear. For example, where an automated system is replacing an existing manual or \ncomputerized system, the environment of the new system is usually the same as the \nexisting system\u2019s environment. In other cases, there is more flexibility, and you \ndecide what constitutes the boundary between the system and its environment during \nthe requirements engineering process.\nFor example, say you are developing the specification for the Mentcare patient \ninformation system. This system is intended to manage information about patients \nattending mental health clinics and the treatments that have been prescribed. In devel-\noping the specification for this system, you have to decide whether the system should \nfocus exclusively on collecting information about consultations (using other systems \nto collect personal information about patients) or whether it should also \u00ad\ncollect per-\nsonal patient information. The advantage of relying on other systems for patient \ninformation is that you avoid duplicating data. The major disadvantage, \u00ad\nhowever, is \nthat using other systems may make it slower to access information, and if these sys-\ntems are unavailable, then it may be impossible to use the Mentcare \u00ad\nsystem.\nIn some situations, the user base for a system is very diverse, and users have a \nwide range of different system requirements. You may decide not to define \n", "page": 142, "type": "text", "section": "Page 142"}
{"text": "142\u2002 \u2002 Chapter 5\u2002 \u25a0\u2002 System modeling\n\u00ad\nboundaries explicitly but instead to develop a configurable system that can be \nadapted to the needs of different users. This was the approach that we adopted in the \niLearn systems, introduced in Chapter 1. There, users range from very young \n\u00ad\nchildren who can\u2019t read through to young adults, their teachers, and school adminis-\ntrators. Because these groups need different system boundaries, we specified a \n\u00ad\nconfiguration system that would allow the boundaries to be specified when the \n\u00ad\nsystem was deployed.\nThe definition of a system boundary is not a value-free judgment. Social and \norganizational concerns may mean that the position of a system boundary may be \ndetermined by nontechnical factors. For example, a system boundary may be delib-\nerately positioned so that the complete analysis process can be carried out on one \nsite; it may be chosen so that a particularly difficult manager need not be consulted; \nand it may be positioned so that the system cost is increased and the system develop-\nment division must therefore expand to design and implement the system.\nOnce some decisions on the boundaries of the system have been made, part of the \nanalysis activity is the definition of that context and the dependencies that a system \nhas on its environment. Normally, producing a simple architectural model is the first \nstep in this activity.\nFigure 5.1 is a context model that shows the Mentcare system and the other \nsystems in its environment. You can see that the Mentcare system is connected to \nan appointments system and a more general patient record system with which it \nshares data. The system is also connected to systems for management reporting and \nhospital admissions, and a statistics system that collects information for research. \nFinally, it makes use of a prescription system to generate prescriptions for patients\u2019 \nmedication.\nContext models normally show that the environment includes several other auto-\nmated systems. However, they do not show the types of relationships between the \nsystems in the environment and the system that is being specified. External systems \nmight produce data for or consume data from the system. They might share data with \nthe system, or they might be connected directly, through a network or not connected \nat all. They might be physically co-located or located in separate buildings. All of \n\u00absystem\u00bb\nMentcare\n\u00absystem\u00bb\nPatient record\nsystem\n\u00absystem\u00bb\nAppointments\nsystem\n\u00absystem\u00bb\nAdmissions\nsystem\n\u00absystem\u00bb\nManagement\nreporting\nsystem\n\u00absystem\u00bb\nPrescription\nsystem\n\u00absystem\u00bb\nHC statistics\nsystem\nFigure 5.1\u2002 The context \nof the Mentcare system\n", "page": 143, "type": "text", "section": "Page 143"}
{"text": " \n5.1\u2002 \u25a0\u2002 Context models\u2002 \u2002 143\nConfirm\ndetention\ndecision\nFind secure\nplace\nAdmit to\nhospital\nTransfer to\npolice station\nTransfer to\nsecure hospital\nInform next\nof kin\nInform\nsocial care\nInform\npatient of\nrights\nUpdate\nregister\n\u00absystem\u00bb\nAdmissions\nsystem\n\u00absystem\u00bb\nMentcare\n\u00absystem\u00bb\nMentcare\nRecord\ndetention\ndecision\n[dangerous]\n[not available]\n[not\ndangerous]\n[available]\nFigure 5.2\u2002 A process \nmodel of involuntary \ndetention\nthese relations may affect the requirements and design of the system being defined \nand so must be taken into account. Therefore, simple context models are used along \nwith other models, such as business process models. These describe human and auto-\nmated processes in which particular software systems are used.\nUML activity diagrams may be used to show the business processes in which \nsystems are used. Figure 5.2 is a UML activity diagram that shows where the \nMentcare system is used in an important mental health care process\u2014involuntary \ndetention.\nSometimes, patients who are suffering from mental health problems may be a \ndanger to others or to themselves. They may therefore have to be detained against \ntheir will in a hospital so that treatment can be administered. Such detention is sub-\nject to strict legal safeguards\u2014for example, the decision to detain a patient must be \nregularly reviewed so that people are not held indefinitely without good reason. One \ncritical function of the Mentcare system is to ensure that such safeguards are imple-\nmented and that the rights of patients are respected.\nUML activity diagrams show the activities in a process and the flow of control \nfrom one activity to another. The start of a process is indicated by a filled circle, the \nend by a filled circle inside another circle. Rectangles with round corners represent \nactivities, that is, the specific subprocesses that must be carried out. You may include \nobjects in activity charts. Figure 5.2 shows the systems that are used to support dif-\nferent subprocesses within the involuntary detection process. I have shown that these \nare separate systems by using the UML stereotype feature where the type of entity in \nthe box between chevrons is shown.\nArrows represent the flow of work from one activity to another, and a solid bar \nindicates activity coordination. When the flow from more than one activity leads to a \n", "page": 144, "type": "text", "section": "Page 144"}
{"text": "144\u2002 \u2002 Chapter 5\u2002 \u25a0\u2002 System modeling\nsolid bar, then all of these activities must be complete before progress is possible. \nWhen the flow from a solid bar leads to a number of activities, these may be exe-\ncuted in parallel. Therefore, in Figure 5.2, the activities to inform social care and the \npatient\u2019s next of kin, as well as to update the detention register, may be concurrent.\nArrows may be annotated with guards (in square brackets) that specify when that \nflow is followed. In Figure 5.2, you can see guards showing the flows for patients \nwho are dangerous and not dangerous to society. Patients who are dangerous to soci-\nety must be detained in a secure facility. However, patients who are suicidal and are \na danger to themselves may be admitted to an appropriate ward in a hospital, where \nthey can be kept under close supervision.\n \n5.2  Interaction models\nAll systems involve interaction of some kind. This can be user interaction, which \ninvolves user inputs and outputs; interaction between the software being developed and \nother systems in its environment; or interaction between the components of a software \nsystem. User interaction modeling is important as it helps to identify user requirements. \nModeling system-to-system interaction highlights the communication problems that \nmay arise. Modeling component interaction helps us understand if a\u00a0proposed system \nstructure is likely to deliver the required system performance and\u00a0dependability.\nThis section discusses two related approaches to interaction modeling:\n1.\t\nUse case modeling, which is mostly used to model interactions between a sys-\ntem and external agents (human users or other systems).\n2.\t\nSequence diagrams, which are used to model interactions between system com-\nponents, although external agents may also be included.\nUse case models and sequence diagrams present interactions at different levels of \ndetail and so may be used together. For example, the details of the interactions \ninvolved in a high-level use case may be documented in a sequence diagram. The \nUML also includes communication diagrams that can be used to model interactions. \nI don\u2019t describe this diagram type because communication diagrams are simply an \nalternative representation of sequence diagrams.\n\t\n5.2.1 \t Use case modeling\nUse case modeling was originally developed by Ivar Jacobsen in the 1990s (Jacobsen \net al. 1993), and a UML diagram type to support use case modeling is part of the \nMedical receptionist\nPatient record system\nTransfer data\nFigure 5.3\u2002 Transfer-data \nuse case \n", "page": 145, "type": "text", "section": "Page 145"}
{"text": " \n5.2\u2002 \u25a0\u2002 Interaction models\u2002 \u2002 145\nUML. A use case can be taken as a simple description of what a user expects from a \nsystem in that interaction. I have discussed use cases for requirements elicitation in \nChapter 4. As I said in Chapter 4, I find use case models to be more useful in the \nearly stages of system design rather than in requirements engineering.\nEach use case represents a discrete task that involves external interaction with a \nsystem. In its simplest form, a use case is shown as an ellipse, with the actors \ninvolved in the use case represented as stick figures. Figure 5.3 shows a use case \nfrom the Mentcare system that represents the task of uploading data from the \nMentcare system to a more general patient record system. This more general system \nmaintains summary data about a patient rather than data about each consultation, \nwhich is recorded in the Mentcare system.\nNotice that there are two actors in this use case\u2014the operator who is transferring \nthe data and the patient record system. The stick figure notation was originally devel-\noped to cover human interaction, but it is also used to represent other external sys-\ntems and hardware. Formally, use case diagrams should use lines without arrows as \narrows in the UML indicate the direction of flow of messages. Obviously, in a use \ncase, messages pass in both directions. However, the arrows in Figure 5.3 are used \ninformally to indicate that the medical receptionist initiates the transaction and data \nis transferred to the patient record system.\nUse case diagrams give a simple overview of an interaction, and you need to add \nmore detail for complete interaction description. This detail can either be a simple \ntextual description, a structured description in a table, or a sequence diagram. You \nchoose the most appropriate format depending on the use case and the level of detail \nthat you think is required in the model. I find a standard tabular format to be the most \nuseful. Figure 5.4 shows a tabular description of the \u201cTransfer data\u201d use case.\nComposite use case diagrams show a number of different use cases. Sometimes it \nis possible to include all possible interactions within a system in a single composite \nuse case diagram. However, this may be impossible because of the number of use \ncases. In such cases, you may develop several diagrams, each of which shows related \nuse cases. For example, Figure 5.5 shows all of the use cases in the Mentcare system \nFigure 5.4\u2002 Tabular \ndescription of the \nTransfer-data use case\nMentcare system: Transfer data\nActors\nMedical receptionist, Patient records system (PRS)\nDescription\nA receptionist may transfer data from the Mentcare system to a \ngeneral patient record database that is maintained by a health \nauthority. The information transferred may either be updated \npersonal information (address, phone number, etc.) or a \nsummary of the patient\u2019s diagnosis and treatment.\nData\nPatient\u2019s personal information, treatment summary\nStimulus\nUser command issued by medical receptionist\nResponse\nConfirmation that PRS has been updated\nComments\nThe receptionist must have appropriate security permissions to \naccess the patient information and the PRS.\n", "page": 146, "type": "text", "section": "Page 146"}
{"text": "146\u2002 \u2002 Chapter 5\u2002 \u25a0\u2002 System modeling\nin which the actor \u201cMedical Receptionist\u201d is involved. Each of these should be \naccompanied by a more detailed description.\nThe UML includes a number of constructs for sharing all or part of a use case in \nother use case diagrams. While these constructs can sometimes be helpful for system \ndesigners, my experience is that many people, especially end-users, find them diffi-\ncult to understand. For this reason, these constructs are not described\u00a0here.\n\t\n5.2.2 \t Sequence diagrams\nSequence diagrams in the UML are primarily used to model the interactions between \nthe actors and the objects in a system and the interactions between the objects them-\nselves. The UML has a rich syntax for sequence diagrams, which allows many dif-\nferent kinds of interaction to be modeled. As space does not allow covering all \npossibilities here, the focus will be on the basics of this diagram type.\nAs the name implies, a sequence diagram shows the sequence of interactions that \ntake place during a particular use case or use case instance. Figure 5.6 is an example \nof a sequence diagram that illustrates the basics of the notation. This diagram models \nthe interactions involved in the View patient information use case, where a medical \nreceptionist can see some patient information.\nThe objects and actors involved are listed along the top of the diagram, with a \ndotted line drawn vertically from these. Annotated arrows indicate interactions \nbetween objects. The rectangle on the dotted lines indicates the lifeline of the object \nconcerned (i.e., the time that object instance is involved in the computation). You \nread the sequence of interactions from top to bottom. The annotations on the arrows \nindicate the calls to the objects, their parameters, and the return values. This example \nalso shows the notation used to denote alternatives. A box named alt is used with the \nMedical\nreceptionist\nRegister\npatient\nTransfer data\nContact\npatient\nView patient\ninfo.\nUnregister\npatient\nFigure 5.5\u2002 Use cases \ninvolving the role \n\u201cMedical receptionist\u201d\n", "page": 147, "type": "text", "section": "Page 147"}
{"text": " \n5.2\u2002 \u25a0\u2002 Interaction models\u2002 \u2002 147\nconditions indicated in square brackets, with alternative interaction options sepa-\nrated by a dotted line.\nYou can read Figure 5.6 as follows:\n1.\t\nThe medical receptionist triggers the ViewInfo method in an instance P of the \nPatientInfo object class, supplying the patient\u2019s identifier, PID to identify the \nrequired information. P is a user interface object, which is displayed as a form \nshowing patient information.\n2.\t\nThe instance P calls the database to return the information required, supplying \nthe receptionist\u2019s identifier to allow security checking. (At this stage, it is not \nimportant where the receptionist\u2019s UID comes from.)\n3.\t\nThe database checks with an authorization system that the receptionist is author-\nized for this action.\n4.\t\nIf authorized, the patient information is returned and is displayed on a form on \nthe user\u2019s screen. If authorization fails, then an error message is returned. The \nbox denoted by \u201calt\u201d in the top-left corner is a choice box indicating that one of \nthe contained interactions will be executed. The condition that selects the choice \nis shown in square brackets.\nFigure 5.7 is a further example of a sequence diagram from the same system that \nillustrates two additional features. These are the direct communication between the \nactors in the system and the creation of objects as part of a sequence of operations. In \nthis example, an object of type Summary is created to hold the summary data that is \nP: PatientInfo\nViewInfo (PID)\nreport (Info, PID,\nUID)\nauthorize (Info,\nUID)\nPatient info\nD: Mentcare-DB \nAS: Authorization\nauthorization\nError (no access)\n[authorization OK]\n[authorization fail]\nMedical Receptionist\nalt\nFigure 5.6\u2002 Sequence \ndiagram for View patient \ninformation \n", "page": 148, "type": "text", "section": "Page 148"}
{"text": "148\u2002 \u2002 Chapter 5\u2002 \u25a0\u2002 System modeling\nto be uploaded to a national PRS (patient records system). You can read this diagram \nas follows:\n1.\t\nThe receptionist logs on to the PRS.\n2.\t Two options are available (as shown in the \u201calt\u201d box). These allow the direct \ntransfer of updated patient information from the Mentcare database to the \nPRS and the transfer of summary health data from the Mentcare database to \nthe PRS.\n3.\t\nIn each case, the receptionist\u2019s permissions are checked using the authorization \nsystem.\nP: PatientInfo\nlogin ( )\nD: Mentcare-DB \nAS: Authorization\nauthorization\n[sendInfo]\n[sendSummary]\nMedical Receptionist\nPRS\nok\nupdateInfo( )\nupdatePRS (UID )\nupdate (PID)\nupdate OK\nMessage (OK)\nsummarize (UID )\nauthorize (TF, UID)\nauthorization\nauthorize (TF, UID)\n:summary\nupdate (PID)\nUpdateSummary( )\nlogout ()\nalt\nupdate OK\nMessage (OK)\nFigure 5.7\u2002 Sequence \ndiagram for \nTransfer Data \n", "page": 149, "type": "text", "section": "Page 149"}
{"text": " \n5.3\u2002 \u25a0\u2002 Structural models\u2002 \u2002 149\n4.\t\nPersonal information may be transferred directly from the user interface object \nto the PRS. Alternatively, a summary record may be created from the database, \nand that record is then transferred.\n5.\t\nOn completion of the transfer, the PRS issues a status message and the user logs\u00a0off.\nUnless you are using sequence diagrams for code generation or detailed docu-\nmentation, you don\u2019t have to include every interaction in these diagrams. If you \ndevelop system models early in the development process to support requirements \nengineering and high-level design, there will be many interactions that depend on \nimplementation decisions. For example, in Figure 5.7 the decision on how to get the \nuser identifier to check authorization is one that can be delayed. In an implementa-\ntion, this might involve interacting with a User object. As this is not important at this \nstage, you do not need to include it in the sequence diagram.\n \n5.3  Structural models\nStructural models of software display the organization of a system in terms of the \ncomponents that make up that system and their relationships. Structural models may \nbe static models, which show the organization of the system design, or dynamic \nmodels, which show the organization of the system when it is executing. These are \nnot the same things\u2014the dynamic organization of a system as a set of interacting \nthreads may be very different from a static model of the system components.\nYou create structural models of a system when you are discussing and designing \nthe system architecture. These can be models of the overall system architecture or \nmore detailed models of the objects in the system and their relationships.\nIn this section, I focus on the use of class diagrams for modeling the static struc-\nture of the object classes in a software system. Architectural design is an important \ntopic in software engineering, and UML component, package, and deployment dia-\ngrams may all be used when presenting architectural models. I cover architectural \nmodeling in Chapters 6 and 17. \n\t\n5.3.1 \t Class diagrams\nClass diagrams are used when developing an object-oriented system model to show \nthe classes in a system and the associations between these classes. Loosely, an object \nclass can be thought of as a general definition of one kind of system object. An asso-\nciation is a link between classes indicating that some relationship exists between \nthese classes. Consequently, each class may have to have some knowledge of its \nassociated class.\nWhen you are developing models during the early stages of the software engi-\nneering process, objects represent something in the real world, such as a patient, a \n", "page": 150, "type": "text", "section": "Page 150"}
{"text": "150\u2002 \u2002 Chapter 5\u2002 \u25a0\u2002 System modeling\nprescription, or a doctor. As an implementation is developed, you define implemen-\ntation objects to represent data that is manipulated by the system. In this section, the \nfocus is on the modeling of real-world objects as part of the requirements or early \nsoftware design processes. A similar approach is used for data structure modeling.\nClass diagrams in the UML can be expressed at different levels of detail. When \nyou are developing a model, the first stage is usually to look at the world, identify \nthe essential objects, and represent these as classes. The simplest way of writing \nthese diagrams is to write the class name in a box. You can also note the existence of \nan association by drawing a line between classes. For example, Figure 5.8 is a sim-\nple class diagram showing two classes, Patient and Patient Record, with an associa-\ntion between them. At this stage, you do not need to say what the association is.\nFigure 5.9 develops the simple class diagram in Figure 5.8 to show that objects of \nclass Patient are also involved in relationships with a number of other classes. In this \nexample, I show that you can name associations to give the reader an indication of \nthe type of relationship that exists.\nFigures 5.8 and 5.9, shows an important feature of class diagrams\u2014the ability to \nshow how many objects are involved in the association. In Figure 5.8 each end of the \nassociation is annotated with a 1, meaning that there is a 1:1 relationship between \nobjects of these classes. That is, each patient has exactly one record, and each record \nmaintains information about exactly one patient.\nAs you can see from Figure 5.9, other multiplicities are possible. You can define \nthat an exact number of objects are involved (e.g., 1..4) or, by using a *, indicate that \nthere are an indefinite number of objects involved in the association. For example, \nthe (1..*) multiplicity in Figure 5.9 on the relationship between Patient and Condition \nshows that a patient may suffer from several conditions and that the same condition \nmay be associated with several patients.\nPatient\nPatient\nrecord\n1\n1\nFigure 5.8\u2002 UML Classes \nand association\nPatient\nGeneral\npractitioner\nConsultation\nConsultant\nMedication\nTreatment\nHospital\nDoctor\nCondition\nreferred-by\nreferred-to\ndiagnosed-\nwith\nattends\nprescribes\nprescribes\ninvolves\n1..*\n1\n1..*\n1\n1..*\n1..*\n1..*\n1..*\n1..4\n1..*\n1..*\n1..*\n1..*\n1..*\nFigure 5.9\u2002 Classes and \nassociations in the \nMentcare system\n", "page": 151, "type": "text", "section": "Page 151"}
{"text": " \n5.3\u2002 \u25a0\u2002 Structural models\u2002 \u2002 151\nAt this level of detail, class diagrams look like semantic data models. Semantic \ndata models are used in database design. They show the data entities, their associated \nattributes, and the relations between these entities (Hull and King 1987). The UML \ndoes not include a diagram type for database modeling, as it models data using \nobjects and their relationships. However, you can use the UML to represent a seman-\ntic data model. You can think of entities in a semantic data model as simplified \nobject classes (they have no operations), attributes as object class attributes, and rela-\ntions as named associations between object classes.\nWhen showing the associations between classes, it is best to represent these classes \nin the simplest possible way, without attributes or operations. To define objects in \nmore detail, you add information about their attributes (the object\u2019s characteristics) \nand operations (the object\u2019s functions). For example, a Patient object has the attribute \nAddress, and you may include an operation called ChangeAddress, which is called \nwhen a patient indicates that he or she has moved from one address to another.\nIn the UML, you show attributes and operations by extending the simple \u00ad\nrectangle \nthat represents a class. I illustrate this in Figure 5.10 that shows an object represent-\ning a consultation between doctor and patient:\n1.\t\nThe name of the object class is in the top section.\n2.\t\nThe class attributes are in the middle section. This includes the attribute names \nand, optionally, their types. I don\u2019t show the types in Figure 5.10.\n3.\t\nThe operations (called methods in Java and other OO programming languages) \nassociated with the object class are in the lower section of the rectangle. I show \nsome but not all operations in Figure 5.10.\nIn the example shown in Figure 5.10, it is assumed that doctors record voice notes \nthat are transcribed later to record details of the consultation. To prescribe \u00ad\nmedication, \nthe doctor involved must use the Prescribe method to generate an electronic prescription.\nConsultation\nDoctors\nDate\nTime\nClinic\nReason\nMedication prescribed\nTreatment prescribed\nVoice notes\nTranscript\n...\nNew ( )\nPrescribe ( )\nRecordNotes ( )\nTranscribe ( )\n...\nFigure 5.10\u2002 A \nConsultation class\n", "page": 152, "type": "text", "section": "Page 152"}
{"text": "152\u2002 \u2002 Chapter 5\u2002 \u25a0\u2002 System modeling\n\t\n5.3.2 \t Generalization\nGeneralization is an everyday technique that we use to manage complexity. \nRather than learn the detailed characteristics of everything that we experience, we \nlearn about general classes (animals, cars, houses, etc.) and learn the characteris-\ntics of these classes. We then reuse knowledge by classifying things and focus on \nthe differences between them and their class. For example, squirrels and rats are \nmembers of the class \u201crodents,\u201d and so share the characteristics of rodents. \nGeneral statements apply to all class members; for example, all rodents have teeth \nfor gnawing.\nWhen you are modeling systems, it is often useful to examine the classes in a \n\u00ad\nsystem to see if there is scope for generalization and class creation. This means \nthat common information will be maintained in one place only. This is good design \npractice as it means that, if changes are proposed, then you do not have to look at \nall classes in the system to see if they are affected by the change. You can make the \nchanges at the most general level. In object-oriented languages, such as Java, \n\u00ad\ngeneralization is implemented using the class inheritance mechanisms built into \nthe language.\nThe UML has a specific type of association to denote generalization, as illus-\ntrated in Figure 5.11. The generalization is shown as an arrowhead pointing up to \nthe more general class. This indicates that general practitioners and hospital doctors \ncan be generalized as doctors and that there are three types of Hospital Doctor: \nthose who have just graduated from medical school and have to be supervised \n(Trainee Doctor); those who can work unsupervised as part of a consultant\u2019s team \n(Registered Doctor); and consultants, who are senior doctors with full decision-\nmaking responsibilities.\nIn a generalization, the attributes and operations associated with higher-level \nclasses are also associated with the lower-level classes. The lower-level classes are \nsubclasses that inherit the attributes and operations from their superclasses. These \nlower-level classes then add more specific attributes and operations.\nDoctor\nGeneral\npractitioner\nHospital\ndoctor\nConsultant\nTeam doctor\nTrainee\ndoctor\nQualified\ndoctor\nFigure 5.11\u2002 A \ngeneralization hierarchy\n", "page": 153, "type": "text", "section": "Page 153"}
{"text": " \n5.3\u2002 \u25a0\u2002 Structural models\u2002 \u2002 153\nFor example, all doctors have a name and phone number, and all hospital doc-\ntors have a staff number and carry a pager. General practitioners don\u2019t have these \nattributes, as they work independently, but they have an individual practice name \nand address. Figure 5.12 shows part of the generalization hierarchy, which I have \nextended with class attributes, for the class Doctor. The operations associated with \nthe class Doctor are intended to register and de-register that doctor with the \nMentcare system.\n\t\n5.3.3 \t Aggregation\nObjects in the real world are often made up of different parts. For example, a study \npack for a course may be composed of a book, PowerPoint slides, quizzes, and rec-\nommendations for further reading. Sometimes in a system model, you need to illus-\ntrate this. The UML provides a special type of association between classes called \naggregation, which means that one object (the whole) is composed of other objects \n(the parts). To define aggregation, a diamond shape is added to the link next to the \nclass that represents the whole.\nFigure 5.13 shows that a patient record is an aggregate of Patient and an indefinite \nnumber of Consultations. That is, the record maintains personal patient information \nas well as an individual record for each consultation with a doctor.\nDoctor\nGeneral practitioner\nHospital doctor\nName\nPhone #\nEmail\nregister ( )\nde-register ( )\nStaff #\nPager #\nPractice\nAddress\nFigure 5.12\u2002 A \ngeneralization hierarchy \nwith added detail\nPatient record\nPatient\nConsultation\n1\n1\n1\n1..*\nFigure 5.13\u2002 The \naggregation association\n", "page": 154, "type": "text", "section": "Page 154"}
{"text": "154\u2002 \u2002 Chapter 5\u2002 \u25a0\u2002 System modeling\n \n5.4  Behavioral models\nBehavioral models are models of the dynamic behavior of a system as it is execut-\ning. They show what happens or what is supposed to happen when a system responds \nto a stimulus from its environment. These stimuli may be either data or events:\n1.\t\nData becomes available that has to be processed by the system. The availability \nof the data triggers the processing.\n2.\t\nAn event happens that triggers system processing. Events may have associated \ndata, although this is not always the case.\nMany business systems are data-processing systems that are primarily driven by \ndata. They are controlled by the data input to the system, with relatively little exter-\nnal event processing. Their processing involves a sequence of actions on that data \nand the generation of an output. For example, a phone billing system will accept \ninformation about calls made by a customer, calculate the costs of these calls, and \ngenerate a bill for that customer.\nBy contrast, real-time systems are usually event-driven, with limited data pro-\ncessing. For example, a landline phone switching system responds to events such as \n\u201chandset activated\u201d by generating a dial tone, pressing keys on a handset by captur-\ning the phone number, and so on.\n\t\n5.4.1 \t Data-driven modeling\nData-driven models show the sequence of actions involved in processing input data \nand generating an associated output. They can be used during the analysis of require-\nments as they show end-to-end processing in a system. That is, they show the entire \nsequence of actions that takes place from an initial input being processed to the cor-\nresponding output, which is the system\u2019s response.\nData-driven models were among the first graphical software models. In the 1970s, \nstructured design methods used data-flow diagrams (DFDs) as a way to illustrate the \nData flow diagrams\nData-flow diagrams (DFDs) are system models that show a functional perspective where each transformation \nrepresents a single function or process. DFDs are used to show how data flows through a sequence of process-\ning steps. For example, a processing step could be the filtering of duplicate records in a customer database. The \ndata is transformed at each step before moving on to the next stage. These processing steps or transformations \nrepresent software processes or functions, where data-flow diagrams are used to document a software design. \nActivity diagrams in the UML may be used to represent DFDs.\nhttp://software-engineering-book.com/web/dfds/\n", "page": 155, "type": "text", "section": "Page 155"}
{"text": " \n5.4\u2002 \u25a0\u2002 Behavioral models\u2002 \u2002 155\nprocessing steps in a system. Data-flow models are useful because tracking and doc-\numenting how data associated with a particular process moves through the system \nhelp analysts and designers understand what is going on in the process. DFDs are \nsimple and intuitive and so are more accessible to stakeholders than some other types \nof model. It is usually possible to explain them to potential system users who can \nthen participate in validating the model.\nData-flow diagrams can be represented in the UML using the activity diagram \ntype, described in Section 5.1. Figure 5.14 is a simple activity diagram that shows \nthe chain of processing involved in the insulin pump software. You can see the \n\u00ad\nprocessing steps, represented as activities (rounded rectangles), and the data flowing \nbetween these steps, represented as objects (rectangles).\nAn alternative way of showing the sequence of processing in a system is to use \nUML sequence diagrams. You have seen how these diagrams can be used to model \ninteraction, but if you draw these so that messages are only sent from left to right, \nthen they show the sequential data processing in the system. Figure 5.15 illustrates \nthis, using a sequence model of processing an order and sending it to a supplier. \nSequence models highlight objects in a system, whereas data-flow diagrams high-\nlight the operations or activities. In practice, nonexperts seem to find data-flow dia-\ngrams more intuitive, but engineers prefer sequence diagrams.\nCalculate\npump\ncommands\nBlood sugar\nsensor\nInsulin\npump\nBlood sugar\nlevel\nPump control\ncommands\nInsulin\nrequirement\nGet sensor\nvalue\nSensor\ndata\nCompute\nsugar level\nCalculate\ninsulin\ndelivery\nControl\npump\nFigure 5.14\u2002 An activity \nmodel of the insulin \npump\u2019s operation\n:Order\nFillin ( )\nPurchase officer\nValidate ( )\n[validation ok]\n\u00abdatastore\u00bb\nOrders\nBudget\nUpdate (amount)\nSave ( )\nSupplier\nSend ( )\nFigure 5.15\u2002 Order \nprocessing\n", "page": 156, "type": "text", "section": "Page 156"}
{"text": "156\u2002 \u2002 Chapter 5\u2002 \u25a0\u2002 System modeling\n\t\n5.4.2 \t Event-driven modeling\nEvent-driven modeling shows how a system responds to external and internal \nevents. It is based on the assumption that a system has a finite number of states \nand that events (stimuli) may cause a transition from one state to another. For \nexample, a system controlling a valve may move from a state \u201cValve open\u201d to a \nstate \u201cValve closed\u201d when an operator command (the stimulus) is received. This \nview of a system is particularly appropriate for real-time systems. Event-driven \nmodeling is used extensively when designing and documenting real-time systems \n(Chapter 21).\nThe UML supports event-based modeling using state diagrams, which are based \non Statecharts (Harel 1987). State diagrams show system states and events that cause \ntransitions from one state to another. They do not show the flow of data within the \nsystem but may include additional information on the computations carried out in \neach state.\nI use an example of control software for a very simple microwave oven to illus-\ntrate event-driven modeling (Figure 5.16). Real microwave ovens are much more \ncomplex than this system, but the simplified system is easier to understand. This \nsimple oven has a switch to select full or half power, a numeric keypad to input the \ncooking time, a start/stop button, and an alphanumeric display.\nFull power\nEnabled\ndo: operate\noven\nFull\npower\nHalf\npower\nHalf\npower\nFull\npower\nNumber\nDoor\nopen\nDoor\nclosed\nDoor\nclosed\nDoor\nopen\nStart\ndo: set power\n= 600\nHalf power\ndo: set power\n= 300\nSet time\ndo: get number\nexit: set time\nDisabled\nOperation\nCancel\nWaiting\ndo: display\ntime\nWaiting\ndo: display\ntime\ndo: display\n     'Ready'\ndo: display\n'Waiting'\nTimer\nTimer\nFigure 5.16\u2002 A state \ndiagram of a \nmicrowave oven \n", "page": 157, "type": "text", "section": "Page 157"}
{"text": " \n5.4\u2002 \u25a0\u2002 Behavioral models\u2002 \u2002 157\nCook\ndo: run\ngenerator\nDone\ndo: buzzer on\nfor 5 secs.\nWaiting\nAlarm\ndo: display\nevent\ndo: check\nstatus\nChecking\nTurntable\nfault\nEmitter\nfault\nDisabled\nOK\nTimeout\nTime\nDoor open\nCancel\nOperation\nFigure 5.17\u2002 A state \nmodel of the \nOperation state\nI have assumed that the sequence of actions in using the microwave is as follows:\n1.\t\nSelect the power level (either half power or full power).\n2.\t\nInput the cooking time using a numeric keypad.\n3.\t\nPress Start and the food is cooked for the given time.\nFor safety reasons, the oven should not operate when the door is open, and, on \ncompletion of cooking, a buzzer is sounded. The oven has a simple display that is \nused to display various alerts and warning messages.\nIn UML state diagrams, rounded rectangles represent system states. They may \ninclude a brief description (following \u201cdo\u201d) of the actions taken in that state. The \nlabeled arrows represent stimuli that force a transition from one state to another. You \ncan indicate start and end states using filled circles, as in activity diagrams.\nFrom Figure 5.16, you can see that the system starts in a waiting state and \nresponds initially to either the full-power or the half-power button. Users can change \ntheir minds after selecting one of these and may press the other button. The time is \nset and, if the door is closed, the Start button is enabled. Pushing this button starts the \noven operation, and cooking takes place for the specified time. This is the end of the \ncooking cycle, and the system returns to the waiting state.\nThe problem with state-based modeling is that the number of possible states \nincreases rapidly. For large system models, therefore, you need to hide detail in the \nmodels. One way to do this is by using the notion of a \u201csuperstate\u201d that encapsulates \na number of separate states. This superstate looks like a single state on a high-level \nmodel but is then expanded to show more detail on a separate diagram. To illustrate \nthis concept, consider the Operation state in Figure 5.16. This is a superstate that can \nbe expanded, as shown in Figure 5.17.\n", "page": 158, "type": "text", "section": "Page 158"}
{"text": "158\u2002 \u2002 Chapter 5\u2002 \u25a0\u2002 System modeling\nThe Operation state includes a number of substates. It shows that operation starts \nwith a status check and that if any problems are discovered an alarm is indicated and \noperation is disabled. Cooking involves running the microwave generator for the \nspecified time; on completion, a buzzer is sounded. If the door is opened during \noperation, the system moves to the disabled state, as shown in Figure 5.17.\nState models of a system provide an overview of event processing, but you nor-\nmally have to extend this with a more detailed description of the stimuli and the system \nstates. You may use a table to list the states and events that stimulate state transitions \nalong with a description of each state and event. Figure 5.18 shows a tabular descrip-\ntion of each state and how the stimuli that force state transitions are generated.\n\t\n5.4.3 \t Model-driven engineering\nModel-driven engineering (MDE) is an approach to software development whereby \nmodels rather than programs are the principal outputs of the development process \nFigure 5.18\u2002 States and \nstimuli for the \nmicrowave oven\nState\nDescription\nWaiting\nThe oven is waiting for input. The display shows the \ncurrent time.\nHalf power\nThe oven power is set to 300 watts. The display shows \n\u201cHalf power.\u201d\nFull power\nThe oven power is set to 600 watts. The display shows \n\u201cFull power.\u201d\nSet time\nThe cooking time is set to the user\u2019s input value. The display \nshows the cooking time selected and is updated as the time \nis set.\nDisabled\nOven operation is disabled for safety. Interior oven light is on. \nDisplay shows \u201cNot ready.\u201d\nEnabled\nOven operation is enabled. Interior oven light is off. Display \nshows \u201cReady to cook.\u201d\nOperation\nOven in operation. Interior oven light is on. Display shows the \ntimer countdown. On completion of cooking, the buzzer is \nsounded for 5 seconds. Oven light is on. Display shows \n\u201cCooking complete\u201d while buzzer is sounding.\nStimulus\nDescription\nHalf power\nThe user has pressed the half-power button.\nFull power\nThe user has pressed the full-power button.\nTimer\nThe user has pressed one of the timer buttons.\nNumber\nThe user has pressed a numeric key.\nDoor open\nThe oven door switch is not closed.\nDoor closed\nThe oven door switch is closed.\nStart\nThe user has pressed the Start button.\nCancel\nThe user has pressed the Cancel button.\n", "page": 159, "type": "text", "section": "Page 159"}
{"text": " \n5.5\u2002 \u25a0\u2002 Model-driven architecture\u2002 \u2002 159\n(Brambilla, Cabot, and Wimmer 2012). The programs that execute on a hardware/\nsoftware platform are generated automatically from the models. Proponents of MDE \nargue that this raises the level of abstraction in software engineering so that \u00ad\nengineers \nno longer have to be concerned with programming language details or the specifics \nof execution platforms.\nModel-driven engineering was developed from the idea of model-driven archi-\ntecture (MDA). This was proposed by the Object Management Group (OMG) as a \nnew software development paradigm (Mellor, Scott, and Weise 2004). MDA \nfocuses on the design and implementation stages of software development, whereas \nMDE is \u00ad\nconcerned with all aspects of the software engineering process. Therefore, \ntopics such as model-based requirements engineering, software processes for \nmodel-based development, and model-based testing are part of MDE but are not \nconsidered in MDA.\nMDA as an approach to system engineering has been adopted by a number of \nlarge companies to support their development processes. This section focuses on the \nuse of MDA for software implementation rather than discuss more general aspects of \nMDE. The take-up of more general model-driven engineering has been slow, and \nfew companies have adopted this approach throughout their software development \nlife cycle. In his blog, den Haan discusses possible reasons why MDE has not been \nwidely adopted (den Haan 2011).\n \n5.5  Model-driven architecture\nModel-driven architecture (Mellor, Scott, and Weise 2004; Stahl and Voelter \n2006) is a model-focused approach to software design and implementation that \nuses a subset of UML models to describe a system. Here, models at different \nlevels of abstraction are created. From a high-level, platform independent model, \nit is possible, in principle, to generate a working program without manual \n\u00ad\nintervention.\nThe MDA method recommends that three types of abstract system model should \nbe produced:\n1.\t\nA computation independent model (CIM) CIMs model the important domain \nabstractions used in a system and so are sometimes called domain models. You \nmay develop several different CIMs, reflecting different views of the system. \nFor example, there may be a security CIM in which you identify important secu-\nrity abstractions such as an asset, and a role and a patient record CIM, in which \nyou describe abstractions such as patients and consultations.\n2.\t\nA platform-independent model (PIM) PIMs model the operation of the system \nwithout reference to its implementation. A PIM is usually described using UML \nmodels that show the static system structure and how it responds to external and \ninternal events.\n", "page": 160, "type": "text", "section": "Page 160"}
{"text": "160\u2002 \u2002 Chapter 5\u2002 \u25a0\u2002 System modeling\n3.\t\nPlatform-specific models (PSM) PSMs are transformations of the platform-\u00ad\nindependent model with a separate PSM for each application platform. In \n\u00ad\nprinciple, there may be layers of PSM, with each layer adding some platform-\nspecific detail. So, the first level PSM could be middleware-specific but \n\u00ad\ndatabase-independent. When a specific database has been chosen, a database-\nspecific PSM can then be generated.\nModel-based engineering allows engineers to think about systems at a high \nlevel of abstraction, without concern for the details of their implementation. This \nreduces the likelihood of errors, speeds up the design and implementation process, \nand allows for the creation of reusable, platform-independent application models. \nBy using powerful tools, system implementations can be generated for different \nplatforms from the same model. Therefore, to adapt the system to some new plat-\nform technology, you write a model translator for that platform. When this is \navailable, all platform-independent models can then be rapidly re-hosted on the \nnew platform.\nFundamental to MDA is the notion that transformations between models can be \ndefined and applied automatically by software tools, as illustrated in Figure 5.19. \nThis diagram also shows a final level of automatic transformation where a transfor-\nmation is applied to the PSM to generate the executable code that will run on the \ndesignated software platform. Therefore, in principle at least, executable software \ncan be generated from a high-level system model.\nIn practice, completely automated translation of models to code is rarely possi-\nble. The translation of high-level CIM to PIM models remains a research problem, \nand for production systems, human intervention, illustrated using a stick figure in \nFigure 5.19, is normally required. A particularly difficult problem for automated \nmodel transformation is the need to link the concepts used in different CIMS. For \nexample, the concept of a role in a security CIM that includes role-driven access \ncontrol may have to be mapped onto the concept of a staff member in a hospital \nCIM. Only a person who understands both security and the hospital environment can \nmake this mapping.\nPlatform\nspecific model\nPlatform\nindependent\nmodel\nExecutable\ncode\nTranslator\nTranslator\nTranslator\nDomain specific\nguidelines\nPlatform\nspecific patterns\nand rules\nLanguage\nspecific\npatterns\nComputation\nindependent\nmodel\nFigure 5.19\u2002 MDA \ntransformations\n", "page": 161, "type": "text", "section": "Page 161"}
{"text": " \n5.5\u2002 \u25a0\u2002 Model-driven architecture\u2002 \u2002 161\nThe translation of platform-independent to platform-specific models is a simpler \ntechnical problem. Commercial tools and open-source tools (Koegel 2012) are avail-\nable that provide translators from PIMS to common platforms such as Java and \nJ2EE. These use an extensive library of platform-specific rules and patterns to \n\u00ad\nconvert a PIM to a PSM. There may be several PSMs for each PIM in the system. If \na software system is intended to run on different platforms (e.g., J2EE and .NET), \nthen, in principle, you only have to maintain a single PIM. The PSMs for each \n\u00ad\nplatform are automatically generated (Figure 5.20).\nAlthough MDA support tools include platform-specific translators, these \n\u00ad\nsometimes only offer partial support for translating PIMS to PSMs. The execution \nenvironment for a system is more than the standard execution platform, such as J2EE \nor Java. It also includes other application systems, specific application libraries that \nmay be created for a company, external services, and user interface libraries.\nThese vary from one company to another, so off-the-shelf tool support is not \navailable that takes these into account. Therefore, when MDA is introduced into an \norganization, special-purpose translators may have to be created to make use of the \nfacilities available in the local environment. This is one reason why many companies \nhave been reluctant to take on model-driven approaches to development. They do not \nwant to develop or maintain their own tools or to rely on small software companies, \nwho may go out of business, for tool development. Without these specialist tools, \nmodel-based development requires additional manual coding which reduces the \ncost-effectiveness of this approach.\nI believe that there are several other reasons why MDA has not become a main-\nstream approach to software development.\n1.\t\nModels are a good way of facilitating discussions about a software design. \nHowever, it does not always follow that the abstractions that are useful for dis-\ncussions are the right abstractions for implementation. You may decide to use a \ncompletely different implementation approach that is based on the reuse of off-\nthe-shelf application systems.\n2.\t\nFor most complex systems, implementation is not the major problem\u2014\u00ad\nrequirements engineering, security and dependability, integration with legacy \nPlatform\nindependent\nmodel\nJava program\nC# code\ngenerator\nJava code\ngenerator\nJ2EE Translator\n.Net Translator\nC# program\nJ2EE specific\nmodel\n.NET specific\nmodel\nFigure 5.20\u2002 Multiple \nplatform-specific models\n", "page": 162, "type": "text", "section": "Page 162"}
{"text": "162\u2002 \u2002 Chapter 5\u2002 \u25a0\u2002 System modeling\nsystems and testing are all more significant. Consequently, the gains from the \nuse of MDA are limited.\n3.\t\nThe arguments for platform independence are only valid for large, long-lifetime \nsystems, where the platforms become obsolete during a system\u2019s lifetime. For \nsoftware products and information systems that are developed for standard plat-\nforms, such as Windows and Linux, the savings from the use of MDA are likely \nto be outweighed by the costs of its introduction and tooling.\n4.\t\nThe widespread adoption of agile methods over the same period that MDA was \nevolving has diverted attention away from model-driven approaches.\nThe success stories for MDA (OMG 2012) have mostly come from companies \nthat are developing systems products, which include both hardware and software. \nThe software in these products has a long lifetime and may have to be modified \nto reflect changing hardware technologies. The domain of application (automo-\ntive, air traffic control, etc.) is often well understood and so can be formalized in \na CIM.\nHutchinson and his colleagues (Hutchinson, Rouncefield, and Whittle 2012) \nreport on the industrial use of MDA, and their work confirms that successes in the \nuse of model-driven development have been in systems products. Their assessment \nsuggests that companies have had mixed results when adopting this approach, but \nthe majority of users report that using MDA has increased productivity and reduced \nmaintenance costs. They found that MDA was particularly useful in facilitating \nreuse, and this led to major productivity improvements.\nThere is an uneasy relationship between agile methods and model-driven archi-\ntecture. The notion of extensive up-front modeling contradicts the fundamental ideas \nin the agile manifesto and I suspect that few agile developers feel comfortable with \nmodel-driven engineering. Ambler, a pioneer in the development of agile methods, \nsuggests that some aspects of MDA can be used in agile processes (Ambler 2004) \nbut considers automated code generation to be impractical. However, Zhang and \nPatel report on Motorola\u2019s success in using agile development with automated code \ngeneration (Zhang and Patel 2011).\nExecutable UML\nThe fundamental notion behind model-driven engineering is that completely automated transformation of \n\u00ad\nmodels to code should be possible. To achieve this, you have to be able to construct graphical models with \nclearly defined meanings that can be compiled to executable code. You also need a way of adding information \nto graphical models about the ways in which the operations defined in the model are implemented. This is \n\u00ad\npossible using a subset of UML 2, called Executable UML or xUML (Mellor and Balcer 2002).\nhttp://software-engineering-book.com/web/xuml/\n", "page": 163, "type": "text", "section": "Page 163"}
{"text": "Key Points\n\u25a0\t A model is an abstract view of a system that deliberately ignores some system details. Comple-\nmentary system models can be developed to show the system\u2019s context, interactions, structure, \nand behavior.\n\u25a0\t Context models show how a system that is being modeled is positioned in an environment with \nother systems and processes. They help define the boundaries of the system to be developed.\n\u25a0\t Use case diagrams and sequence diagrams are used to describe the interactions between users \nand systems in the system being designed. Use cases describe interactions between a system \nand external actors; sequence diagrams add more information to these by showing interactions \nbetween system objects.\n\u25a0\t Structural models show the organization and architecture of a system. Class diagrams are used \nto define the static structure of classes in a system and their associations.\n\u25a0\t Behavioral models are used to describe the dynamic behavior of an executing system. This \nbehavior can be modeled from the perspective of the data processed by the system or by the \nevents that stimulate responses from a system.\n\u25a0\t Activity diagrams may be used to model the processing of data, where each activity represents \none process step.\n\u25a0\t State diagrams are used to model a system\u2019s behavior in response to internal or external events.\n\u25a0\t Model-driven engineering is an approach to software development in which a system is repre-\nsented as a set of models that can be automatically transformed to executable code.\nFurther Reading\nAny of the introductory books on the UML provide more information about the notation than I can \ncover here. UML has only changed slightly in the last few years, so although some of these books \nare almost 10 years old, they are still relevant.\nUsing UML: Software Engineering with Objects and Components, 2nd ed. This book is a short, read-\nable introduction to the use of the UML in system specification and design. I think that it is excellent \nfor learning and understanding the UML notation, although it is less comprehensive than the \n\u00ad\ncomplete descriptions of UML found in the UML reference manual. (P. Stevens with R. Pooley, Addi-\nson-Wesley, 2006)\nModel-driven Software Engineering in Practice. This is quite a comprehensive book on model-driven \napproaches with a focus on model-driven design and implementation. As well as the UML, it also \ncovers the development of domain-specific modeling languages. (M. Brambilla, J. Cabot, and \nM.\u00a0Wimmer. Morgan Claypool, 2012)\n \nChapter 5\u2002 \u25a0\u2002 Further reading\u2002 \u2002 163\n", "page": 164, "type": "text", "section": "Page 164"}
{"text": "Website\nPowerPoint slides for this chapter:\nwww.pearsonglobaleditions.com/Sommerville\nLinks to supporting videos:\nhttp://software-engineering-book.com/videos/requirements-and-design/\nExercises\n\u2002 5.1.\t Scope creep can be defined as a continuous increase in the scope of a project that can \n\u00ad\nsignificantly increase project cost. Explain how a proper model of the system context can \nhelp \u00ad\nprevent scope creeps.\n\u2002 5.2.\t The way in which a system boundary is defined and an appropriate context model is created \nmay have serious implications on the complexity and cost of a project. Give two examples \nwhere this may be applicable.\n\u2002 5.3.\t You have been asked to develop a system that will help with planning large-scale events and \nparties such as weddings, graduation celebrations, and birthday parties. Using an activity dia-\ngram, model the process context for such a system that shows the activities involved in plan-\nning a party (booking a venue, organizing invitations, etc.) and the system elements that \nmight be used at each stage.\n\u2002 5.4.\t For the Mentcare system, propose a set of use cases that illustrates the interactions between a \ndoctor, who sees patients and prescribes medicine and treatments, and the Mentcare system.\n\u2002 5.5.\t Develop a sequence diagram showing the interactions involved when a student registers for a \ncourse in a university. Courses may have limited enrollment, so the registration process must \ninclude checks that places are available. Assume that the student accesses an electronic \ncourse catalog to find out about available courses.\n\u2002 5.6.\t Look carefully at how messages and mailboxes are represented in the email system that you \nuse. Model the object classes that might be used in the system implementation to represent a \nmailbox and an email message.\n\u2002 5.7.\t Based on your experience with a bank ATM, draw an activity diagram that models the data \nprocessing involved when a customer withdraws cash from the machine.\n\u2002 5.8.\t Draw a sequence diagram for the same system. Explain why you might want to develop both \nactivity and sequence diagrams when modeling the behavior of a system.\n\u2002 5.9.\t Draw state diagrams of the control software for:\n\u25a0\t an automatic washing machine that has different programs for different types of clothes;\n\u25a0\t the software for a DVD player;\n\u25a0\t the control software for the camera on your mobile phone. Ignore the flash if you have one \non your phone.\n164\u2002 \u2002 Chapter 5\u2002 \u25a0\u2002 System modeling\n", "page": 165, "type": "text", "section": "Page 165"}
{"text": " \nChapter 5\u2002 \u25a0\u2002 References\u2002 \u2002 165\n5.10. \tIn principle, it is possible to generate working programs from a high-level model without \n\u00ad\nmanual intervention when using model-driven architectures. Discuss some of the current \n\u00ad\nchallenges that stand in the way of the existence of completely automated translation tools.\nReferences\nAmbler, S. W. 2004. The Object Primer: Agile Model-Driven Development with UML 2.0, 3rd ed. \n\u00ad\nCambridge, UK: Cambridge University Press.\nAmbler, S. W., and R. Jeffries. 2002. Agile Modeling: Effective Practices for Extreme Programming \nand the Unified Process. New York: John Wiley & Sons.\nBooch, G., J. Rumbaugh, and I. Jacobson. 2005. The Unified Modeling Language User Guide, 2nd ed. \nBoston: Addison-Wesley.\nBrambilla, M., J. Cabot, and M. Wimmer. 2012. Model-Driven Software Engineering in Practice. San \nRafael, CA: Morgan Claypool.\nDen Haan, J. 2011. \u201cWhy There Is No Future for Model Driven Development.\u201d http://www.\u00ad\ntheenterprisearchitect.eu/archive/2011/01/25/why-there-is-no-future-for-model-driven-\u00ad\ndevelopment/\nErickson, J,, and K Siau. 2007. \u201cTheoretical and Practical Complexity of Modeling Methods.\u201d \nComm. ACM 50 (8): 46\u201351. doi:10.1145/1278201.1278205.\nHarel, D. 1987. \u201cStatecharts: A Visual Formalism for Complex Systems.\u201d Sci. Comput. Programming \n8 (3): 231\u2013274. doi:10.1016/0167-6423(87)90035-9.\nHull, R., and R King. 1987. \u201cSemantic Database Modeling: Survey, Applications and Research \nIssues.\u201d ACM Computing Surveys 19 (3): 201\u2013260. doi:10.1145/45072.45073.\nHutchinson, J., M. Rouncefield, and J. Whittle. 2012. \u201cModel-Driven Engineering Practices in \n\u00ad\nIndustry.\u201d In 34th Int. Conf. on Software Engineering, 633\u2013642. doi:10.1145/1985793.1985882.\nJacobsen, I., M. Christerson, P. Jonsson, and G. Overgaard. 1993. Object-Oriented Software \n\u00ad\nEngineering. Wokingham, UK: Addison-Wesley.\nKoegel, M. 2012. \u201cEMF Tutorial: What Every Eclipse Developer Should Know about EMF.\u201d http://\neclipsesource.com/blogs/tutorials/emf-tutorial/\nMellor, S. J., and M. J. Balcer. 2002. Executable UML. Boston: Addison-Wesley.\nMellor, S. J., K. Scott, and D. Weise. 2004. MDA Distilled: Principles of Model-Driven Architecture. \nBoston: Addison-Wesley.\nOMG. 2012. \u201cModel-Driven Architecture: Success Stories.\u201d http://www.omg.org/mda/products_\nsuccess.htm\n", "page": 166, "type": "text", "section": "Page 166"}
{"text": "Rumbaugh, J., I. Jacobson, and G Booch. 2004. The Unified Modelling Language Reference Manual, \n2nd ed. Boston: Addison-Wesley.\nStahl, T., and M. Voelter. 2006. Model-Driven Software Development: Technology, Engineering, \n\u00ad\nManagement. New York: John Wiley & Sons.\nZhang, Y., and S. Patel. 2011. \u201cAgile Model-Driven Development in Practice.\u201d IEEE Software 28 (2): \n84\u201391. doi:10.1109/MS.2010.85.\n166\u2002 \u2002 Chapter 5\u2002 \u25a0\u2002 System modeling\n", "page": 167, "type": "text", "section": "Page 167"}
{"text": "Architectural design\n6\nObjectives\nThe objective of this chapter is to introduce the concepts of software \narchitecture and architectural design. When you have read the chapter, \nyou will:\n\u25a0\t understand why the architectural design of software is important;\n\u25a0\t understand the decisions that have to be made about the software \narchitecture during the architectural design process;\n\u25a0\t have been introduced to the idea of Architectural patterns, well-tried \nways of organizing software architectures that can be reused in \nsystem designs;\n\u25a0\t understand how Application-Specific Architectural patterns may be \nused in transaction processing and language processing systems.\nContents\n6.1\t Architectural design decisions\n6.2\t Architectural views\n6.3\t Architectural patterns\n6.4\t Application architectures\n", "page": 168, "type": "text", "section": "Page 168"}
{"text": "168\u2002 \u2002 Chapter 6\u2002 \u25a0\u2002 Architectural design\nArchitectural design is concerned with understanding how a software system should \nbe organized and designing the overall structure of that system. In the model of the \nsoftware development process that I described in Chapter 2, architectural design is \nthe first stage in the software design process. It is the critical link between design and \nrequirements engineering, as it identifies the main structural components in a system \nand the relationships between them. The output of the architectural design process is \nan architectural model that describes how the system is organized as a set of \n\u00ad\ncommunicating components.\nIn agile processes, it is generally accepted that an early stage of an agile develop-\nment process should focus on designing an overall system architecture. Incremental \ndevelopment of architectures is not usually successful. Refactoring components in \nresponse to changes is usually relatively easy. However, refactoring the system \narchitecture is expensive because you may need to modify most system components \nto adapt them to the architectural changes.\nTo help you understand what I mean by system architecture, look at Figure 6.1. \nThis diagram shows an abstract model of the architecture for a packing robot system. \nThis robotic system can pack different kinds of objects. It uses a vision component \nto pick out objects on a conveyor, identify the type of object, and select the right \nkind of packaging. The system then moves objects from the delivery conveyor to be \npackaged. It places packaged objects on another conveyor. The architectural model \nshows these components and the links between them.\nIn practice, there is a significant overlap between the processes of requirements \nengineering and architectural design. Ideally, a system specification should not \nVision\nsystem\nObject\nidentification\nsystem\nArm\ncontroller\nGripper\ncontroller\nPackaging\nselection\nsystem\nPacking\nsystem\nConveyor\ncontroller\nFigure 6.1\u2002 The \narchitecture of a packing \nrobot control system\n", "page": 169, "type": "text", "section": "Page 169"}
{"text": "\t\nChapter 6\u2002 \u25a0\u2002 Architectural design\u2002 \u2002 169\ninclude any design information. This ideal is unrealistic, however, except for very \nsmall systems. You need to identify the main architectural components as these \nreflect the high-level features of the system. Therefore, as part of the requirements \nengineering process, you might propose an abstract system architecture where you \nassociate groups of system functions or features with large-scale components or sub-\nsystems. You then use this decomposition to discuss the requirements and more \ndetailed features of the system with stakeholders.\nYou can design software architectures at two levels of abstraction, which I call \narchitecture in the small and architecture in the large:\n1.\t Architecture in the small is concerned with the architecture of individual pro-\ngrams. At this level, we are concerned with the way that an individual pro-\ngram is decomposed into components. This chapter is mostly concerned with \nprogram architectures.\n2.\t\nArchitecture in the large is concerned with the architecture of complex enter-\nprise systems that include other systems, programs, and program components. \nThese enterprise systems may be distributed over different computers, which \nmay be owned and managed by different companies. (I cover architecture in the \nlarge in Chapters 17 and 18.)\nSoftware architecture is important because it affects the performance, robust-\nness, distributability, and maintainability of a system (Bosch 2000). As Bosch \nexplains, individual components implement the functional system requirements, \nbut the dominant influence on the non-functional system characteristics is the \nsystem\u2019s architecture. Chen et al. (Chen, Ali Babar, and Nuseibeh 2013) con-\nfirmed this in a study of \u201carchitecturally significant requirements\u201d where they \nfound that non-functional requirements had the most significant effect on the \nsystem\u2019s architecture.\nBass et al. (Bass, Clements, and Kazman 2012) suggest that explicitly designing \nand documenting software architecture has three advantages:\n1.\t\nStakeholder communication The architecture is a high-level presentation of the sys-\ntem that may be used as a focus for discussion by a range of different stakeholders.\n2.\t\nSystem analysis Making the system architecture explicit at an early stage in the \nsystem development requires some analysis. Architectural design decisions \nhave a profound effect on whether or not the system can meet critical require-\nments such as performance, reliability, and maintainability.\n3.\t\nLarge-scale reuse An architectural model is a compact, manageable description \nof how a system is organized and how the components interoperate. The system \narchitecture is often the same for systems with similar requirements and so can \nsupport large-scale software reuse. As I explain in Chapter 15, product-line \narchitectures are an approach to reuse where the same architecture is reused \nacross a range of related systems.\n", "page": 170, "type": "text", "section": "Page 170"}
{"text": "170\u2002 \u2002 Chapter 6\u2002 \u25a0\u2002 Architectural design\nSystem architectures are often modeled informally using simple block diagrams, \nas in Figure 6.1. Each box in the diagram represents a component. Boxes within \nboxes indicate that the component has been decomposed to subcomponents. Arrows \nmean that data and or control signals are passed from component to component in \nthe direction of the arrows. You can see many examples of this type of architectural \nmodel in Booch\u2019s handbook of software architecture (Booch 2014).\nBlock diagrams present a high-level picture of the system structure, which people \nfrom different disciplines, who are involved in the system development process, can \nreadily understand. In spite of their widespread use, Bass et al. (Bass, Clements, and \nKazman 2012) dislike informal block diagrams for describing an architecture. They \nclaim that these informal diagrams are poor architectural representations, as they \nshow neither the type of the relationships among system components nor the compo-\nnents\u2019 externally visible properties.\nThe apparent contradictions between architectural theory and industrial prac-\ntice arise because there are two ways in which an architectural model of a program \nis used:\n1.\t As a way of encouraging discussions about the system design A high-level \narchitectural view of a system is useful for communication with system stake-\nholders and project planning because it is not cluttered with detail. \nStakeholders can relate to it and understand an abstract view of the system. \nThey can then discuss the system as a whole without being confused by detail. \nThe architectural model identifies the key components that are to be devel-\noped so that managers can start assigning people to plan the development of \nthese systems.\n2.\t\nAs a way of documenting an architecture that has been designed The aim here \nis to produce a complete system model that shows the different components in a \nsystem, their interfaces and their connections. The argument for such a model is \nthat such a detailed architectural description makes it easier to understand and \nevolve the system.\nBlock diagrams are a good way of supporting communications between the peo-\nple involved in the software design process. They are intuitive, and domain experts \nand software engineers can relate to them and participate in discussions about the \nsystem. Managers find them helpful in planning the project. For many projects, \nblock diagrams are the only architectural description.\nIdeally, if the architecture of a system is to be documented in detail, it is better to \nuse a more rigorous notation for architectural description. Various architectural \ndescription languages (Bass, Clements, and Kazman 2012) have been developed for \nthis purpose. A more detailed and complete description means that there is less scope \nfor misunderstanding the relationships between the architectural components. \nHowever, developing a detailed architectural description is an expensive and \n\u00ad\ntime-consuming process. It is practically impossible to know whether or not it is \ncost-effective, so this approach is not widely used.\n", "page": 171, "type": "text", "section": "Page 171"}
{"text": "\t\n6.1\u2002 \u25a0\u2002 Architectural design decisions\u2002 \u2002 171\n \n6.1  Architectural design decisions\nArchitectural design is a creative process in which you design a system organization \nthat will satisfy the functional and non-functional requirements of a system. There is \nno formulaic architectural design process. It depends on the type of system being \ndeveloped, the background and experience of the system architect, and the specific \nrequirements for the system. Consequently, I think it is best to consider architectural \ndesign as a series of decisions to be made rather than a sequence of activities.\nDuring the architectural design process, system architects have to make a number \nof structural decisions that profoundly affect the system and its development pro-\ncess. Based on their knowledge and experience, they have to consider the fundamen-\ntal questions shown in Figure 6.2.\nAlthough each software system is unique, systems in the same application domain \noften have similar architectures that reflect the fundamental concepts of the domain. For \nexample, application product lines are applications that are built around a core architecture \nwith variants that satisfy specific customer requirements. When designing a system archi-\ntecture, you have to decide what your system and broader application classes have in com-\nmon, and decide how much knowledge from these application architectures you can reuse.\nFor embedded systems and apps designed for personal computers and mobile \ndevices, you do not have to design a distributed architecture for the system. However, \nmost large systems are distributed systems in which the system software is distrib-\nuted across many different computers. The choice of distribution architecture is a \nIs there a generic application \narchitecture that can act as a \ntemplate for the system that is \nbeing designed?\nHow will the system be \ndistributed across hardware \ncores or processors?\nWhat Architectural patterns or \nstyles might be used?\nWhat will be the fundamental \napproach used to structure \nthe system?\nHow will the structural \ncomponents in the system be \ndecomposed into \nsub-components?\nWhat strategy will be used to \ncontrol the operation of the \ncomponents in the system?\nWhat architectural organization \nis best for delivering the \nnon-functional requirements \nof the system?\nHow should the architecture \nof the system be \ndocumented?\n?\nFigure 6.2\u2002 Architectural \ndesign decisions\n", "page": 172, "type": "text", "section": "Page 172"}
{"text": "172\u2002 \u2002 Chapter 6\u2002 \u25a0\u2002 Architectural design\nkey decision that affects the performance and reliability of the system. This is a \nmajor topic in its own right that I cover in Chapter 17.\nThe architecture of a software system may be based on a particular Architectural \npattern or style (these terms have come to mean the same thing). An Architectural \npattern is a description of a system organization (Garlan and Shaw 1993), such as a \nclient\u2013server organization or a layered architecture. Architectural patterns capture \nthe essence of an architecture that has been used in different software systems. You \nshould be aware of common patterns, where they can be used, and their strengths \nand weaknesses when making decisions about the architecture of a system. I cover \nseveral frequently used patterns in Section 6.3.\nGarlan and Shaw\u2019s notion of an architectural style covers questions 4 to 6 in the \nlist of fundamental architectural questions shown in Figure 6.2. You have to choose \nthe most appropriate structure, such as client\u2013server or layered structuring, that will \nenable you to meet the system requirements. To decompose structural system units, \nyou decide on a strategy for decomposing components into subcomponents. Finally, \nin the control modeling process, you develop a general model of the control relation-\nships between the various parts of the system and make decisions about how the \nexecution of components is controlled.\nBecause of the close relationship between non-functional system characteristics \nand software architecture, the choice of architectural style and structure should \ndepend on the non-functional requirements of the system:\n1.\t\nPerformance If performance is a critical requirement, the architecture should be \ndesigned to localize critical operations within a small number of components, \nwith these components deployed on the same computer rather than distributed \nacross the network. This may mean using a few relatively large components \nrather than small, finer-grain components. Using large components reduces the \nnumber of component communications, as most of the interactions between \nrelated system features take place within a component. You may also consider \nruntime system organizations that allow the system to be replicated and exe-\ncuted on different processors.\n2.\t\nSecurity If security is a critical requirement, a layered structure for the architec-\nture should be used, with the most critical assets protected in the innermost lay-\ners and a high level of security validation applied to these layers.\n3.\t\nSafety If safety is a critical requirement, the architecture should be designed so \nthat safety-related operations are co-located in a single component or in a small \nnumber of components. This reduces the costs and problems of safety validation \nand may make it possible to provide related protection systems that can safely \nshut down the system in the event of failure.\n4.\t\nAvailability If availability is a critical requirement, the architecture should be \ndesigned to include redundant components so that it is possible to replace and \nupdate components without stopping the system. I describe fault-tolerant sys-\ntem architectures for high-availability systems in Chapter 11.\n", "page": 173, "type": "text", "section": "Page 173"}
{"text": "\t\n6.2\u2002 \u25a0\u2002 Architectural views\u2002 \u2002 173\n5.\t\nMaintainability If maintainability is a critical requirement, the system architec-\nture should be designed using fine-grain, self-contained components that may \nreadily be changed. Producers of data should be separated from consumers, and \nshared data structures should be avoided.\nObviously, there is potential conflict between some of these architectures. For \nexample, using large components improves performance, and using small, fine-grain \ncomponents improves maintainability. If both performance and maintainability are \nimportant system requirements, however, then some compromise must be found. \nYou can sometimes do this by using different Architectural patterns or styles for \nseparate parts of the system. Security is now almost always a critical requirement, \nand you have to design an architecture that maintains security while also satisfying \nother non-functional requirements.\nEvaluating an architectural design is difficult because the true test of an architec-\nture is how well the system meets its functional and non-functional requirements \nwhen it is in use. However, you can do some evaluation by comparing your design \nagainst reference architectures or generic Architectural patterns. Bosch\u2019s description \n(Bosch 2000) of the non-functional characteristics of some Architectural patterns can \nhelp with architectural evaluation.\n \n6.2  Architectural views\nI explained in the introduction to this chapter that architectural models of a software \nsystem can be used to focus discussion about the software requirements or design. \nAlternatively, they may be used to document a design so that it can be used as a basis \nfor more detailed design and implementation of the system. In this section, I discuss \ntwo issues that are relevant to both of these:\n1.\t\nWhat views or perspectives are useful when designing and documenting a sys-\ntem\u2019s architecture?\n2.\t\nWhat notations should be used for describing architectural models?\nIt is impossible to represent all relevant information about a system\u2019s architecture \nin a single diagram, as a graphical model can only show one view or perspective of \nthe system. It might show how a system is decomposed into modules, how the \n\u00ad\nruntime processes interact, or the different ways in which system components are \ndistributed across a network. Because all of these are useful at different times, for \nboth design and documentation, you usually need to present multiple views of the \nsoftware architecture.\nThere are different opinions as to what views are required. Krutchen (Krutchen\u00a01995) \nin his well-known 4\u200a\n\u200a\n+1 view model of software architecture, \u00ad\nsuggests that there should \n", "page": 174, "type": "text", "section": "Page 174"}
{"text": "174\u2002 \u2002 Chapter 6\u2002 \u25a0\u2002 Architectural design\nbe four fundamental architectural views, which can be linked through common use \ncases or scenarios (Figure 6.3). He suggests the following views:\n1.\t\nA logical view, which shows the key abstractions in the system as objects or \nobject classes. It should be possible to relate the system requirements to entities \nin this logical view.\n2.\t\nA process view, which shows how, at runtime, the system is composed of inter-\nacting processes. This view is useful for making judgments about non-func-\ntional \u00ad\nsystem characteristics such as performance and availability.\n3.\t\nA development view, which shows how the software is decomposed for develop-\nment; that is, it shows the breakdown of the software into components that are \nimplemented by a single developer or development team. This view is useful for \nsoftware managers and programmers.\n4.\t\nA physical view, which shows the system hardware and how software compo-\nnents are distributed across the processors in the system. This view is useful for \n\u00ad\nsystems engineers planning a system deployment.\nHofmeister et al. (Hofmeister, Nord, and Soni 2000) suggest the use of similar views \nbut add to this the notion of a conceptual view. This view is an abstract view of the system \nthat can be the basis for decomposing high-level requirements into more detailed specifi-\ncations, help engineers make decisions about components that can be reused, and repre-\nsent a product line (discussed in Chapter 15) rather than a single system. Figure 6.1, which \ndescribes the architecture of a packing robot, is an example of a conceptual system view.\nIn practice, conceptual views of a system\u2019s architecture are almost always devel-\noped during the design process. They are used to explain the system architecture to \nstakeholders and to inform architectural decision making. During the design process, \nsome of the other views may also be developed when different aspects of the system \nare discussed, but it is rarely necessary to develop a complete description from all \nperspectives. It may also be possible to associate Architectural patterns, discussed in \nthe next section, with the different views of a system.\nSystem\narchitecture\nLogical\nview\nPhysical\nview\nProcess\nview\nDevelopment\nview\nFigure 6.3\u2002 Architectural \nviews \n", "page": 175, "type": "text", "section": "Page 175"}
{"text": "\t\n6.3\u2002 \u25a0\u2002 Architectural patterns\u2002 \u2002 175\nThere are differing views about whether or not software architects should use the \nUML for describing and documenting software architectures. A survey in 2006 (Lange, \nChaudron, and Muskens 2006) showed that, when the UML was used, it was mostly \napplied in an informal way. The authors of that paper argued that this was a bad thing.\nI disagree with this view. The UML was designed for describing object-oriented \nsystems, and, at the architectural design stage, you often want to describe systems at a \nhigher level of abstraction. Object classes are too close to the implementation to be use-\nful for architectural description. I don\u2019t find the UML to be useful during the design \nprocess itself and prefer informal notations that are quicker to write and that can be eas-\nily drawn on a whiteboard. The UML is of most value when you are documenting an \narchitecture in detail or using model-driven development, as discussed in Chapter 5.\nA number of researchers (Bass, Clements, and Kazman 2012) have proposed the \nuse of more specialized architectural description languages (ADLs) to describe system \narchitectures. The basic elements of ADLs are components and connectors, and they \ninclude rules and guidelines for well-formed architectures. However, because ADLs \nare specialist languages, domain and application specialists find it hard to understand \nand use ADLs. There may be some value in using domain-specific ADLs as part of \nmodel-driven development, but I do not think they will become part of mainstream \nsoftware engineering practice. Informal models and notations, such as the UML, will \nremain the most commonly used ways of documenting system architectures.\nUsers of agile methods claim that detailed design documentation is mostly \nunused. It is, therefore, a waste of time and money to develop these documents. I \nlargely agree with this view, and I think that, except for critical systems, it is not \nworth developing a detailed architectural description from Krutchen\u2019s four perspec-\ntives. You should develop the views that are useful for communication and not worry \nabout whether or not your architectural documentation is complete.\n \n6.3  Architectural patterns\nThe idea of patterns as a way of presenting, sharing, and reusing knowledge about \nsoftware systems has been adopted in a number of areas of software engineering. The \ntrigger for this was the publication of a book on object-oriented design patterns \n(Gamma et al. 1995). This prompted the development of other types of patterns, such \nas patterns for organizational design (Coplien and Harrison 2004), usability patterns \n(Usability Group 1998), patterns of cooperative interaction (Martin and Sommerville \n2004), and configuration management patterns (Berczuk and Appleton 2002).\nArchitectural patterns were proposed in the 1990s under the name \u201carchitectural \nstyles\u201d (Shaw and Garlan 1996). A very detailed five-volume series of handbooks on \npattern-oriented software architecture was published between 1996 and 2007 \n(Buschmann et al. 1996; Schmidt et al. 2000; Buschmann, Henney, and Schmidt \n2007a, 2007b; Kircher and Jain 2004).\nIn this section, I introduce Architectural patterns and briefly describe a selection of \nArchitectural patterns that are commonly used. Patterns may be described in a stand-\nard way (Figures 6.4 and 6.5) using a mixture of narrative description and diagrams. \n", "page": 176, "type": "text", "section": "Page 176"}
{"text": "176\u2002 \u2002 Chapter 6\u2002 \u25a0\u2002 Architectural design\nFigure 6.4\u2002 The \nModel-View-Controller \n(MVC) pattern\nName\nMVC (Model-View-Controller)\nDescription\nSeparates presentation and interaction from the system data. The \nsystem\u00a0is structured into three logical components that interact with \neach\u00a0other. The Model component manages the system data and \nassociated operations on that data. The View component defines and \nmanages how the data is presented to the user. The Controller compo\u00ad\nnent manages user interaction (e.g., key presses, mouse clicks, etc.) and \npasses these interactions to the View and the Model. See Figure 6.5.\nExample\nFigure 6.6 shows the architecture of a web-based application system \norganized using the MVC pattern.\nWhen used\nUsed when there are multiple ways to view and interact with data. \nAlso used when the future requirements for interaction and \npresentation of data are unknown.\nAdvantages\nAllows the data to change independently of its representation and vice \nversa. Supports presentation of the same data in different ways, with \nchanges made in one representation shown in all of them.\nDisadvantages\nMay involve additional code and code complexity when the data \nmodel and interactions are simple.\nController\nView\nModel\nView\nselection\nState\nchange\nChange\nnotification\nState query\nUser events\nMaps user actions\nto model updates\nSelects view\nRenders model\nRequests model updates\nSends user events to\ncontroller\nEncapsulates application\nstate\nNotifies view of state\nchanges\nFigure 6.5\u2002 The \norganization of the \nModel-View-Controller\nFor more detailed information about patterns and their use, you should refer to the \npublished pattern handbooks.\nYou can think of an Architectural pattern as a stylized, abstract description of good \npractice, which has been tried and tested in different systems and environments. So, \nan Architectural pattern should describe a system organization that has been success-\nful in previous systems. It should include information on when it is and is not appro-\npriate to use that pattern, and details on the pattern\u2019s strengths and weaknesses.\nFigure 6.4 describes the well-known Model-View-Controller pattern. This pattern \nis the basis of interaction management in many web-based systems and is supported \nby most language frameworks. The stylized pattern description includes the pattern \n", "page": 177, "type": "text", "section": "Page 177"}
{"text": "\t\n6.3\u2002 \u25a0\u2002 Architectural patterns\u2002 \u2002 177\nname, a brief description, a graphical model, and an example of the type of system \nwhere the pattern is used. You should also include information about when the \n\u00ad\npattern should be used and its advantages and disadvantages.\nGraphical models of the architecture associated with the MVC pattern are shown \nin Figures 6.5 and 6.6. These present the architecture from different views: Figure 6.5 \nis a conceptual view, and Figure 6.6 shows a runtime system architecture when this \npattern is used for interaction management in a web-based system.\nIn this short space, it is impossible to describe all of the generic patterns that \ncan\u00a0be used in software development. Instead, I present some selected examples of \npatterns that are widely used and that capture good architectural design principles.\n\t\n6.3.1 \t Layered architecture\nThe notions of separation and independence are fundamental to architectural design \nbecause they allow changes to be localized. The MVC pattern, shown in Figure 6.4, \nseparates elements of a system, allowing them to change independently. For example, \nadding a new view or changing an existing view can be done without any changes to \nthe underlying data in the model. The Layered Architecture pattern is another way of \nachieving separation and independence. This pattern is shown in Figure 6.7. Here, the \nsystem functionality is organized into separate layers, and each layer only relies on \nthe facilities and services offered by the layer immediately beneath it.\nThis layered approach supports the incremental development of systems. As a \nlayer is developed, some of the services provided by that layer may be made availa-\nble to users. The architecture is also changeable and portable. If its interface is \nunchanged, a new layer with extended functionality can replace an existing layer \nController\nView\nModel\nForm to\ndisplay\nUpdate\nrequest\nChange\nnotification\nRefresh request\nUser events\nBrowser\nHTTP request processing\nApplication-specific logic\nData validation\nDynamic page\ngeneration\nForms management\nBusiness logic\nDatabase\nFigure 6.6\u2002 Web \napplication architecture \nusing the MVC pattern\n", "page": 178, "type": "text", "section": "Page 178"}
{"text": "178\u2002 \u2002 Chapter 6\u2002 \u25a0\u2002 Architectural design\nwithout changing other parts of the system. Furthermore, when layer interfaces \nchange or new facilities are added to a layer, only the adjacent layer is affected. As \nlayered systems localize machine dependencies, this makes it easier to provide \nmulti-platform implementations of an application system. Only the machine-\u00ad\ndependent layers need be reimplemented to take account of the facilities of a \u00ad\ndifferent \noperating system or database.\nFigure 6.8 is an example of a layered architecture with four layers. The lowest \nlayer includes system support software\u2014typically, database and operating system \nsupport. The next layer is the application layer, which includes the components \nconcerned with the application functionality and utility components used by other \napplication components.\nThe third layer is concerned with user interface management and providing user \nauthentication and authorization, with the top layer providing user interface facili-\nties. Of course, the number of layers is arbitrary. Any of the layers in Figure 6.6 \ncould be split into two or more layers.\nFigure 6.7\u2002 The \nLayered\u00a0Architecture \npattern\nName\nLayered architecture\nDescription\nOrganizes the system into layers, with related functionality associated with each layer. A layer \nprovides services to the layer above it, so the lowest level layers represent core services that \nare likely to be used throughout the system. See Figure 6.8.\nExample\nA layered model of a digital learning system to support learning of all subjects in schools (Figure 6.9).\nWhen used\nUsed when building new facilities on top of existing systems; when the development is \nspread across several teams with each team responsibility for a layer of functionality; when \nthere is a requirement for multilevel security.\nAdvantages\nAllows replacement of entire layers as long as the interface is\u00a0maintained. Redundant facilities \n(e.g., authentication) can be provided in each layer to increase the dependability of the\u00a0system.\nDisadvantages\nIn practice, providing a clean separation between layers is often difficult, and a high-level layer \nmay have to interact directly with lower-level layers rather than through the layer immediately \nbelow it. Performance can be a problem because of multiple levels of interpretation of a \nservice request as it is processed at each layer.\nUser interface\nCore business logic/application functionality\nSystem utilities\nSystem support (OS, database, etc.)\nUser interface management\nAuthentication and authorization\nFigure 6.8\u2002 A generic \nlayered architecture\n", "page": 179, "type": "text", "section": "Page 179"}
{"text": "\t\n6.3\u2002 \u25a0\u2002 Architectural patterns\u2002 \u2002 179\nAuthentication\nBrowser-based user interface\nConfiguration services\nGroup\nmanagement\nApplication\nmanagement\nIdentity\nmanagement\nUser storage\nLogging and monitoring\nApplication storage\nInterfacing\nSearch\nUtility services\nApplication services\niLearn app\nEmail   Messaging   Video conferencing  Newspaper archive\nWord processing   Simulation   Video storage   Resource finder\nSpreadsheet   Virtual learning environment   History archive\nFigure 6.9\u2002 The \narchitecture of the \niLearn system\nFigure 6.9 shows that the iLearn digital learning system, introduced in Chapter 1, \nhas a four-layer architecture that follows this pattern. You can see another example \nof the Layered Architecture pattern in Figure 6.19 (Section 6.4, which shows the \norganization of the Mentcare system.\n\t\n6.3.2 \t Repository architecture\nThe layered architecture and MVC patterns are examples of patterns where the view \npresented is the conceptual organization of a system. My next example, the Repository \npattern (Figure 6.10), describes how a set of interacting components can share data.\nName\nRepository\nDescription\nAll data in a system is managed in a central repository that is accessible to all system \ncomponents. Components do not interact directly, only through the repository.\nExample\nFigure 6.11 is an example of an IDE where the components use a repository of system design \ninfor\u00ad\nmation. Each software tool generates information, which is then available for use by other tools.\nWhen used\nYou should use this pattern when you have a system in which large volumes of information are \ngenerated that has to be stored for a long time. You may also use it in data-driven systems where \nthe inclusion of data in the repository triggers an action or tool.\nAdvantages\nComponents can be independent; they do not need to know of the existence of other \ncomponents. Changes made by one component can be propagated to all components. All data \ncan be managed consistently (e.g., backups done at the same time) as it is all in one place.\nDisadvantages\nThe repository is a single point of failure so problems in the repository affect the whole \nsystem. May be inefficiencies in organizing all communication through the repository. \nDistributing the repository across several computers may be difficult.\nFigure 6.10\u2002 The \nRepository pattern\n", "page": 180, "type": "text", "section": "Page 180"}
{"text": "180\u2002 \u2002 Chapter 6\u2002 \u25a0\u2002 Architectural design\nProject\nrepository\nDesign\ntranslator\nJava\neditor\nUML\neditors\nCode\ngenerators\nDesign\nanalyzer\nReport\ngenerator\nPython\neditor\nFigure 6.11\u2002 A repository \narchitecture for an IDE\nThe majority of systems that use large amounts of data are organized around a shared \ndatabase or repository. This model is therefore suited to applications in which data is \ngenerated by one component and used by another. Examples of this type of system \ninclude command and control systems, management information systems, Computer-\nAided Design (CAD) systems, and interactive development environments for software.\nFigure 6.11 illustrates a situation in which a repository might be used. This diagram \nshows an IDE that includes different tools to support model-driven development. The \nrepository in this case might be a version-controlled environment (as\u00a0discussed in \nChapter\u00a025) that keeps track of changes to software and allows rollback to earlier \u00ad\nversions.\nOrganizing tools around a repository is an efficient way of sharing large amounts \nof data. There is no need to transmit data explicitly from one component to another. \nHowever, components must operate around an agreed repository data model. \nInevitably, this is a compromise between the specific needs of each tool, and it may \nbe difficult or impossible to integrate new components if their data models do not fit \nthe agreed schema. In practice, it may be difficult to distribute the repository over a \nnumber of machines. Although it is possible to distribute a logically centralized \nrepository, this involves maintaining multiple copies of data. Keeping these consist-\nent and up to date adds more overhead to the system.\nIn the repository architecture shown in Figure 6.11, the repository is passive and \ncontrol is the responsibility of the components using the repository. An alternative \napproach, which has been derived for artificial intelligence (AI) systems, uses a \n\u201cblackboard\u201d model that triggers components when particular data become availa-\nble. This is appropriate when the data in the repository is unstructured. Decisions \nabout which tool is to be activated can only be made when the data has been ana-\nlyzed. This model was introduced by Nii (Nii 1986), and Bosch (Bosch 2000) \nincludes a good discussion of how this style relates to system quality attributes.\n\t\n6.3.3 \t Client\u2013server architecture\nThe Repository pattern is concerned with the static structure of a system and does \nnot show its runtime organization. My next example, the Client\u2013Server pattern \n(Figure\u00a06.12), illustrates a commonly used runtime organization for distributed \n", "page": 181, "type": "text", "section": "Page 181"}
{"text": "\t\n6.3\u2002 \u25a0\u2002 Architectural patterns\u2002 \u2002 181\nsystems. A system that follows the Client\u2013Server pattern is organized as a set of ser-\nvices and associated servers, and clients that access and use the services. The major \ncomponents of this model are:\n1.\t\nA set of servers that offer services to other components. Examples of servers \ninclude print servers that offer printing services, file servers that offer file man-\nagement services, and a compile server that offers programming language com-\npilation services. Servers are software components, and several servers may run \non the same computer.\n2.\t\nA set of clients that call on the services offered by servers. There will normally \nbe several instances of a client program executing concurrently on different \ncomputers.\n 3.\t A network that allows the clients to access these services. Client\u2013server sys-\ntems are usually implemented as distributed systems, connected using Internet \nprotocols.\nClient\u2013server architectures are usually thought of as distributed systems architec-\ntures, but the logical model of independent services running on separate servers can \nbe implemented on a single computer. Again, an important benefit is separation and \nindependence. Services and servers can be changed without affecting other parts of \nthe system.\nClients may have to know the names of the available servers and the services \nthey provide. However, servers do not need to know the identity of clients or how \nmany clients are accessing their services. Clients access the services provided by a \nserver through remote procedure calls using a request\u2013reply protocol (such as http), \nwhere a client makes a request to a server and waits until it receives a reply from \nthat server.\nFigure 6.12\u2002 The \nClient\u2013Server pattern\nName\nClient\u2013server\nDescription\nIn a client\u2013server architecture, the system is presented as a set of services, with each service \ndelivered by a separate server. Clients are users of these services and access servers to make \nuse of them.\nExample\nFigure 6.13 is an example of a film and video/DVD library organized as a client\u2013server system.\nWhen used\nUsed when data in a shared database has to be accessed from a range of locations. Because \nservers can be replicated, may also be used when the load on a system is variable.\nAdvantages\nThe principal advantage of this model is that servers can be distributed across a network. \nGeneral functionality (e.g., a printing service) can be available to all clients and does not \nneed to be implemented by all services.\nDisadvantages\nEach service is a single point of failure and so is susceptible to denial-of-service attacks \nor\u00a0server failure. Performance may be unpredictable because it depends on the network \nas\u00a0well as the system. Management problems may arise if servers are owned by \ndifferent\u00a0organizations.\n", "page": 182, "type": "text", "section": "Page 182"}
{"text": "182\u2002 \u2002 Chapter 6\u2002 \u25a0\u2002 Architectural design\nFigure 6.13 is an example of a system that is based on the client\u2013server model. \nThis is a multiuser, web-based system for providing a film and photograph library. \nIn this system, several servers manage and display the different types of media. \nVideo frames need to be transmitted quickly and in synchrony but at relatively low \nresolution. They may be compressed in a store, so the video server can handle \nvideo compression and decompression in different formats. Still pictures, how-\never, must be maintained at a high resolution, so it is appropriate to maintain them \non a separate server.\nThe catalog must be able to deal with a variety of queries and provide links into \nthe web information system that include data about the film and video clips, and an \ne-commerce system that supports the sale of photographs, film, and video clips. The \nclient program is simply an integrated user interface, constructed using a web \nbrowser, to access these services.\nThe most important advantage of the client\u2013server model is that it is a distributed \narchitecture. Effective use can be made of networked systems with many distributed \nprocessors. It is easy to add a new server and integrate it with the rest of the system \nor to upgrade servers transparently without affecting other parts of the system. I \ncover distributed architectures in Chapter 17, where I explain the client\u2013server \nmodel and its variants in more detail.\n\t\n6.3.4 \t Pipe and filter architecture\nMy final example of a general Architectural pattern is the Pipe and Filter pattern \n(Figure 6.14). This is a model of the runtime organization of a system where \nfunctional transformations process their inputs and produce outputs. Data flows \nfrom one to another and is transformed as it moves through the sequence. Each \nprocessing step is implemented as a transform. Input data flows through these \ntransforms until converted to output. The transformations may execute sequen-\ntially or in parallel. The data can be processed by each transform item by item or \nin a single batch.\nCatalog\nserver\nLibrary\ncatalogue\nVideo\nserver\nFilm store\nPicture\nserver\nPhoto store\nWeb\nserver\nFilm and\nphoto info.\nClient 1\nClient 2\nClient 3\nClient 4\nInternet\nFigure 6.13\u2002 A client\u2013\nserver architecture for a \nfilm library \n", "page": 183, "type": "text", "section": "Page 183"}
{"text": "\t\n6.3\u2002 \u25a0\u2002 Architectural patterns\u2002 \u2002 183\nThe name \u201cpipe and filter\u201d comes from the original Unix system where it was \npossible to link processes using \u201cpipes.\u201d These passed a text stream from one pro-\ncess to another. Systems that conform to this model can be implemented by combin-\ning Unix commands, using pipes and the control facilities of the Unix shell. The \nterm filter is used because a transformation \u201cfilters out\u201d the data it can process from \nits input data stream.\nVariants of this pattern have been in use since computers were first used for auto-\nmatic data processing. When transformations are sequential with data processed in \nbatches, this pipe and filter architectural model becomes a batch sequential model, a \ncommon architecture for data-processing systems such as billing systems. The archi-\ntecture of an embedded system may also be organized as a process pipeline, with \neach process executing concurrently. I cover use of this pattern in embedded systems \nin Chapter 21.\nAn example of this type of system architecture, used in a batch processing appli-\ncation, is shown in Figure 6.15. An organization has issued invoices to customers. \nOnce a week, payments that have been made are reconciled with the invoices. For \nFigure 6.14\u2002 The Pipe \nand Filter pattern\nName\nPipe and filter\nDescription\nThe processing of the data in a system is organized so that each processing component \n(filter) is discrete and carries out one type of data transformation. The data flows (as in a \npipe) from one component to another for processing.\nExample\nFigure 6.15 is an example of a pipe and filter system used for processing invoices.\nWhen used\nCommonly used in data-processing applications (both batch and transaction-based) \nwhere inputs are processed in separate stages to generate related outputs.\nAdvantages\nEasy to understand and supports transformation reuse. Workflow style matches the \nstructure of many business processes. Evolution by adding transformations is \nstraightforward. Can be implemented as either a sequential or concurrent system.\nDisadvantages\nThe format for data transfer has to be agreed between communicating transformations. \nEach transformation must parse its input and unparse its output to the agreed form. This \nincreases system overhead and may mean that it is impossible to reuse architectural \ncomponents that use incompatible data structures.\nRead issued\ninvoices\nIdentify\npayments\nIssue\nreceipts\nFind\npayments\ndue\nReceipts\nIssue\npayment\nreminder\nReminders\nInvoices\nPayments\nFigure 6.15\u2002 An \nexample of the pipe \nand filter architecture\n", "page": 184, "type": "text", "section": "Page 184"}
{"text": "184\u2002 \u2002 Chapter 6\u2002 \u25a0\u2002 Architectural design\nthose invoices that have been paid, a receipt is issued. For those invoices that have \nnot been paid within the allowed payment time, a reminder is issued.\nPipe and filter systems are best suited to batch processing systems and embedded \nsystems where there is limited user interaction. Interactive systems are difficult to \nwrite using the pipe and filter model because of the need for a stream of data to be \nprocessed. While simple textual input and output can be modeled in this way, graph-\nical user interfaces have more complex I/O formats and a control strategy that is \nbased on events such as mouse clicks or menu selections. It is difficult to implement \nthis as a sequential stream that conforms to the pipe and filter model.\n \n6.4  Application architectures\nApplication systems are intended to meet a business or an organizational need. All \nbusinesses have much in common\u2014they need to hire people, issue invoices, keep \naccounts, and so on. Businesses operating in the same sector use common sector-\nspecific applications. Therefore, as well as general business functions, all phone \ncompanies need systems to connect and meter calls, manage their network and issue \nbills to customers. Consequently, the application systems used by these businesses \nalso have much in common.\nThese commonalities have led to the development of software architectures that \ndescribe the structure and organization of particular types of software systems. \nApplication architectures encapsulate the principal characteristics of a class of sys-\ntems. For example, in real-time systems, there might be generic architectural models \nof different system types, such as data collection systems or monitoring systems. \nAlthough instances of these systems differ in detail, the common architectural struc-\nture can be reused when developing new systems of the same type.\nThe application architecture may be reimplemented when developing new sys-\ntems. However, for many business systems, application architecture reuse is implicit \nwhen generic application systems are configured to create a new application. We \nsee this in the widespread use of Enterprise Resource Planning (ERP) systems and \noff-the-shelf configurable application systems, such as systems for accounting and \nstock control. These systems have a standard architecture and components. The \ncomponents are configured and adapted to create a specific business application. \nArchitectural patterns for control\nThere are specific Architectural patterns that reflect commonly used ways of organizing control in a system. \nThese include centralized control, based on one component calling other components, and event-based control, \nwhere the system reacts to external events.\nhttp://software-engineering-book.com/web/archpatterns/\n", "page": 185, "type": "text", "section": "Page 185"}
{"text": "\t\n6.4\u2002 \u25a0\u2002 Application architectures\u2002 \u2002 185\nFor example, a system for supply chain management can be adapted for different \ntypes of suppliers, goods, and contractual arrangements.\nAs a software designer, you can use models of application architectures in a num-\nber of ways:\n1.\t\nAs a starting point for the architectural design process If you are unfamiliar \nwith the type of application that you are developing, you can base your initial \ndesign on a generic application architecture. You then specialize this for the \nspecific \u00ad\nsystem that is being developed.\n2.\t\nAs a design checklist If you have developed an architectural design for an appli-\ncation system, you can compare this with the generic application architecture. \nYou can check that your design is consistent with the generic architecture.\n3.\t\nAs a way of organizing the work of the development team The application archi-\ntectures identify stable structural features of the system architectures, and in \nmany cases, it is possible to develop these in parallel. You can assign work to \ngroup members to implement different components within the architecture.\n4.\t\nAs a means of assessing components for reuse If you have components you \nmight be able to reuse, you can compare these with the generic structures to see \nwhether there are comparable components in the application architecture.\n5.\t\nAs a vocabulary for talking about applications If you are discussing a specific \napplication or trying to compare applications, then you can use the concepts \nidentified in the generic architecture to talk about these applications.\nThere are many types of application system, and, in some cases, they may seem to \nbe very different. However, superficially dissimilar applications may have much in \ncommon and thus share an abstract application architecture. I illustrate this by \ndescribing the architectures of two types of application:\n1.\t\nTransaction processing applications Transaction processing applications are \ndatabase-centered applications that process user requests for information and \nupdate the information in a database. These are the most common types of inter-\nactive business systems. They are organized in such a way that user actions \ncan\u2019t interfere with each other and the integrity of the database is maintained. \nThis class of system includes interactive banking systems, e-commerce systems, \ninformation systems, and booking systems.\nApplication architectures\nThere are several examples of application architectures on the book\u2019s website. These include descriptions of \nbatch data-processing systems, resource allocation systems, and event-based editing systems.\nhttp://software-engineering-book.com/web/apparch/\n", "page": 186, "type": "text", "section": "Page 186"}
{"text": "186\u2002 \u2002 Chapter 6\u2002 \u25a0\u2002 Architectural design\n2.\t\nLanguage processing systems Language processing systems are systems in \nwhich the user\u2019s intentions are expressed in a formal language, such as a pro-\ngramming language. The language processing system processes this language \ninto an internal format and then interprets this internal representation. The best-\nknown language processing systems are compilers, which translate high-level \nlanguage programs into machine code. However, language processing systems \nare also used to interpret command languages for databases and information \nsystems, and markup languages such as XML.\nI have chosen these particular types of system because a large number of web-\nbased business systems are transaction processing systems, and all software devel-\nopment relies on language processing systems.\n\t\n6.4.1 \t Transaction processing systems\nTransaction processing systems are designed to process user requests for information \nfrom a database, or requests to update a database (Lewis, Bernstein, and Kifer 2003). \nTechnically, a database transaction is part of a sequence of operations and is treated \nas a single unit (an atomic unit). All of the operations in a transaction have to be \ncompleted before the database changes are made permanent. This ensures that failure \nof operations within a transaction does not lead to inconsistencies in the database.\nFrom a user perspective, a transaction is any coherent sequence of operations that \nsatisfies a goal, such as \u201cfind the times of flights from London to Paris.\u201d If the user \ntransaction does not require the database to be changed, then it may not be necessary \nto package this as a technical database transaction.\nAn example of a database transaction is a customer request to withdraw money from a \nbank account using an ATM. This involves checking the customer account balance to see \nif sufficient funds are available, modifying the balance by the amount withdrawn and \nsending commands to the ATM to deliver the cash. Until all of these steps have been com-\npleted, the transaction is incomplete and the customer accounts database is not changed.\nTransaction processing systems are usually interactive systems in which users \nmake asynchronous requests for service. Figure 6.16 illustrates the conceptual archi-\ntectural structure of transaction processing applications. First, a user makes a request \nto the system through an I/O processing component. The request is processed by \nsome application-specific logic. A transaction is created and passed to a transaction \nmanager, which is usually embedded in the database management system. After the \ntransaction manager has ensured that the transaction is properly completed, it signals \nto the application that processing has finished.\nTransaction processing systems may be organized as a \u201cpipe and filter\u201d architec-\nture, with system components responsible for input, processing, and output. For \nI/O\nprocessing\nApplication\nlogic\nTransaction\nmanager\nDatabase\nFigure 6.16\u2002 The \nstructure of transaction \nprocessing applications\n", "page": 187, "type": "text", "section": "Page 187"}
{"text": "\t\n6.4\u2002 \u25a0\u2002 Application architectures\u2002 \u2002 187\nexample, consider a banking system that allows customers to query their accounts \nand withdraw cash from an ATM. The system is composed of two cooperating soft-\nware components\u2014the ATM software and the account processing software in the \nbank\u2019s database server. The input and output components are implemented as soft-\nware in the ATM, and the processing component is part of the bank\u2019s database \nserver. Figure 6.17 shows the architecture of this system, illustrating the functions of \nthe input, process, and output components.\n\t\n6.4.2 \t Information systems\nAll systems that involve interaction with a shared database can be considered to be \ntransaction-based information systems. An information system allows controlled \naccess to a large base of information, such as a library catalog, a flight timetable, or \nthe records of patients in a hospital. Information systems are almost always web-\nbased systems, where the user interface is implemented in a web browser.\nFigure 6.18 presents a very general model of an information system. The system \nis modeled using a layered approach (discussed in Section 6.3) where the top layer \nInput\nProcess\nOutput\nATM\nDatabase\nATM\nGet customer\naccount id\nQuery account\nPrint details\nReturn card\nDispense cash\nUpdate account\nValidate card\nSelect service\nFigure 6.17\u2002 The \nsoftware architecture \nof an ATM system\nUser interface\nUser communications\nInformation retrieval and modification\nTransaction management\nDatabase\nAuthentication and\nauthorization\nFigure 6.18\u2002 Layered \ninformation system \narchitecture \n", "page": 188, "type": "text", "section": "Page 188"}
{"text": "188\u2002 \u2002 Chapter 6\u2002 \u25a0\u2002 Architectural design\nsupports the user interface and the bottom layer is the system database. The user \ncommunications layer handles all input and output from the user interface, and the \ninformation retrieval layer includes application-specific logic for accessing and \nupdating the database. The layers in this model can map directly onto servers in a \ndistributed Internet-based system.\nAs an example of an instantiation of this layered model, Figure 6.19 shows the \narchitecture of the Mentcare system. Recall that this system maintains and manages \ndetails of patients who are consulting specialist doctors about mental health prob-\nlems. I have added detail to each layer in the model by identifying the components \nthat support user communications and information retrieval and access:\n1.\t\nThe top layer is a browser-based user interface.\n2.\t\nThe second layer provides the user interface functionality that is delivered \nthrough the web browser. It includes components to allow users to log in to the \nsystem and checking components that ensure that the operations they use are \nallowed by their role. This layer includes form and menu management compo-\nnents that present information to users, and data validation components that \ncheck information consistency.\n3.\t\nThe third layer implements the functionality of the system and provides \n\u00ad\ncomponents that implement system security, patient information creation and \nupdating, import and export of patient data from other databases, and report \ngenerators that create management reports.\n4.\t\nFinally, the lowest layer, which is built using a commercial database manage-\nment system, provides transaction management and persistent data storage.\nInformation and resource management systems are sometimes also transaction pro-\ncessing systems. For example, e-commerce systems are Internet-based resource \nmanagement systems that accept electronic orders for goods or services and then \narrange delivery of these goods or services to the customer. In an e-commerce \nWeb browser\nReport\ngeneration\nTransaction management\nPatient database\nLogin\nForm and menu\nmanager\nData\nvalidation\nRole checking\nSecurity\nmanagement\nPatient info.\nmanager\nData import\nand export\nFigure 6.19\u2002 The \narchitecture of the \nMentcare system\n", "page": 189, "type": "text", "section": "Page 189"}
{"text": "\t\n6.4\u2002 \u25a0\u2002 Application architectures\u2002 \u2002 189\n\u00ad\nsystem, the application-specific layer includes additional functionality supporting a \n\u201cshopping cart\u201d in which users can place a number of items in separate transactions, \nthen pay for them all together in a single transaction.\nThe organization of servers in these systems usually reflects the four-layer generic \nmodel presented in Figure 6.18. These systems are often implemented as distributed \nsystems with a multitier client server/architecture\n1.\t\nThe web server is responsible for all user communications, with the user inter-\nface implemented using a web browser;\n2.\t\nThe application server is responsible for implementing application-specific \nlogic as well as information storage and retrieval requests;\n3.\t\nThe database server moves information to and from the database and handles \ntransaction management.\nUsing multiple servers allows high throughput and makes it possible to handle thou-\nsands of transactions per minute. As demand increases, servers can be added at each \nlevel to cope with the extra processing involved.\n\t\n6.4.3 \t Language processing systems\nLanguage processing systems translate one language into an alternative representation \nof that language and, for programming languages, may also execute the \u00ad\nresulting code. \nCompilers translate a programming language into machine code. Other language pro-\ncessing systems may translate an XML data description into commands to query a \ndatabase or to an alternative XML representation. Natural language processing sys-\ntems may translate one natural language to another, for example, French to Norwegian.\nA possible architecture for a language processing system for a programming \n\u00ad\nlanguage is illustrated in Figure 6.20. The source language instructions define the \nSource\nlanguage\ninstructions\nData\nResults\nTranslator\nInterpreter\nAbstract m/c\ninstructions\nCheck syntax\nCheck semantics\nGenerate\nFetch\nExecute\nFigure 6.20\u2002 The \narchitecture \nof a language \nprocessing system\n", "page": 190, "type": "text", "section": "Page 190"}
{"text": "190\u2002 \u2002 Chapter 6\u2002 \u25a0\u2002 Architectural design\nSyntax\nanalyzer\nLexical\nanalyzer\nSemantic\nanalyzer\nAbstract\nsyntax tree\nGrammar\ndefinition\nSymbol\ntable\nOutput\ndefinition\nFormatter\nEditor\nOptimizer\nCode\ngenerator\nRepository\nFigure 6.21\u2002 A \nrepository architecture \nfor a language \nprocessing system\nprogram to be executed, and a translator converts these into instructions for an abstract \nmachine. These instructions are then interpreted by another component that fetches \nthe instructions for execution and executes them using (if necessary) data from the \nenvironment. The output of the process is the result of interpreting the instructions on \nthe input data.\nFor many compilers, the interpreter is the system hardware that processes machine \ninstructions, and the abstract machine is a real processor. However, for dynamically \ntyped languages, such as Ruby or Python, the interpreter is a software component.\nProgramming language compilers that are part of a more general program-\nming environment have a generic architecture (Figure 6.21) that includes the fol-\nlowing components:\n1.\t\nA lexical analyzer, which takes input language tokens and converts them into an \ninternal form.\n2.\t\nA symbol table, which holds information about the names of entities (variables, \nclass names, object names, etc.) used in the text that is being translated.\n3.\t\nA syntax analyzer, which checks the syntax of the language being translated. It \nuses a defined grammar of the language and builds a syntax tree.\n4.\t\nA syntax tree, which is an internal structure representing the program being \ncompiled.\n5.\t\nA semantic analyzer, which uses information from the syntax tree and the sym-\nbol table to check the semantic correctness of the input language text.\n6.\t A code generator, which \u201cwalks\u201d the syntax tree and generates abstract \nmachine code.\nOther components might also be included that analyze and transform the syntax \ntree to improve efficiency and remove redundancy from the generated machine code. \n", "page": 191, "type": "text", "section": "Page 191"}
{"text": "\t\n6.4\u2002 \u25a0\u2002 Application architectures\u2002 \u2002 191\nIn other types of language processing system, such as a natural language translator, \nthere will be additional components such as a dictionary. The output of the system is \ntranslation of the input text.\nFigure 6.21 illustrates how a language processing system can be part of an inte-\ngrated set of programming support tools. In this example, the symbol table and syn-\ntax tree act as a central information repository. Tools or tool fragments communicate \nthrough it. Other information that is sometimes embedded in tools, such as the gram-\nmar definition and the definition of the output format for the program, have been \ntaken out of the tools and put into the repository. Therefore, a syntax-directed editor \ncan check that the syntax of a program is correct as it is being typed. A program \nformatter can create listings of the program that highlight different syntactic ele-\nments and are therefore easier to read and understand.\nAlternative Architectural patterns may be used in a language processing system \n(Garlan and Shaw 1993). Compilers can be implemented using a composite of a \nrepository and a pipe and filter model. In a compiler architecture, the symbol table is \na repository for shared data. The phases of lexical, syntactic, and semantic analysis \nare organized sequentially, as shown in Figure 6.22, and communicate through the \nshared symbol table.\nThis pipe and filter model of language compilation is effective in batch environ-\nments where programs are compiled and executed without user interaction; for \nexample, in the translation of one XML document to another. It is less effective when \na compiler is integrated with other language processing tools such as a structured \nediting system, an interactive debugger, or a program formatter. In this situation, \nchanges from one component need to be reflected immediately in other components. \nIt is better to organize the system around a repository, as shown in Figure 6.21 if you \nare implementing a general, language-oriented programming environment.\nLexical\nanalysis\nSyntactic\nanalysis\nSemantic\nanalysis\nCode\ngeneration\nSymbol table\nSyntax tree\nFigure 6.22\u2002 A pipe  \nand filter compiler \narchitecture \nReference architectures\nReference architectures capture important features of system architectures in a domain. Essentially, they include \neverything that might be in an application architecture, although, in reality, it is very unlikely that any individual \napplication would include all the features shown in a reference architecture. The main purpose of reference \narchitectures is to evaluate and compare design proposals, and to educate people about architectural character-\nistics in that domain.\nhttp://software-engineering-book.com/web/refarch/\n", "page": 192, "type": "text", "section": "Page 192"}
{"text": "Key Points\n\u25a0\t A software architecture is a description of how a software system is organized. Properties of a \nsystem such as performance, security, and availability are influenced by the architecture used.\n\u25a0\t Architectural design decisions include decisions on the type of application, the distribution of \nthe system, the architectural styles to be used, and the ways in which the architecture should \nbe\u00a0documented and evaluated.\n\u25a0\t Architectures may be documented from several different perspectives or views. Possible \nviews\u00a0include a conceptual view, a logical view, a process view, a development view, and a \nphysical view.\n\u25a0\t Architectural patterns are a means of reusing knowledge about generic system architectures. \nThey describe the architecture, explain when it may be used, and point out its advantages and \ndisadvantages.\n\u25a0\t Commonly used Architectural patterns include model-view-controller, layered architecture, \nrepository, client\u2013server, and pipe and filter.\n\u25a0\t Generic models of application systems architectures help us understand the operation of appli-\ncations, compare applications of the same type, validate application system designs, and assess \nlarge-scale components for reuse.\n\u25a0\t Transaction processing systems are interactive systems that allow information in a database to \nbe remotely accessed and modified by a number of users. Information systems and resource \nmanagement systems are examples of transaction processing systems.\n\u25a0\t Language processing systems are used to translate texts from one language into another and to \ncarry out the instructions specified in the input language. They include a translator and an \nabstract machine that executes the generated language.\nFurther Reading\nSoftware Architecture: Perspectives on an Emerging Discipline. This was the first book on soft-\nware architecture and has a good discussion on different architectural styles that is still relevant. \n(M. Shaw and D. Garlan, 1996, Prentice-Hall).\n\u201cThe Golden Age of Software Architecture.\u201d This paper surveys the development of software archi-\ntecture from its beginnings in the 1980s through to its usage in the 21st century. There is not a lot \nof technical content, but it is an interesting historical overview. (M. Shaw and P. Clements, IEEE \nSoftware, 21 (2), March\u2013April 2006) http://doi.dx.org/10.1109/MS.2006.58.\nSoftware Architecture in Practice (3rd ed.). This is a practical discussion of software architec-\ntures that does not oversell the benefits of architectural design. It provides a clear business \nrationale, explaining why architectures are important. (L. Bass, P. Clements, and R. Kazman, \n2012, Addison-Wesley).\n192\u2002 \u2002 Chapter 6\u2002 \u25a0\u2002 Architectural design\n", "page": 193, "type": "text", "section": "Page 193"}
{"text": " \nChapter 6\u2002 \u25a0\u2002 Exercises\u2002 \u2002 193\nHandbook of Software Architecture. This is a work in progress by Grady Booch, one of the early evan-\ngelists for software architecture. He has been documenting the architectures of a range of software \nsystems so that you can see reality rather than academic abstraction. Available on the web and \nintended to appear as a book. (G. Booch, 2014) http://www.handbookofsoftwarearchitecture.com/\nWebsite\nPowerPoint slides for this chapter:\nwww.pearsonglobaleditions.com/Sommerville\nLinks to supporting videos:\nhttp://software-engineering-book.com/videos/requirements-and-design/\nExercises\n\u2002 6.1.\t When describing a system, explain why you may have to start the design of the system archi-\ntecture before the requirements specification is complete.\n\u2002 6.2.\t You have been asked to prepare and deliver a presentation to a nontechnical manager to \n\u00ad\njustify the hiring of a system architect for a new project. Write a list of bullet points setting \nout the key points in your presentation in which you explain the importance of software \n\u00ad\narchitecture.\n\u2002 6.3.\t Performance and security may pose to be conflicting non-functional requirements when \n\u00ad\narchitecting software systems. Make an argument in support of this statement.\n\u2002 6.4.\t Draw diagrams showing a conceptual view and a process view of the architectures of the fol-\nlowing systems:\nA ticket machine used by passengers at a railway station.\nA computer-controlled video conferencing system that allows video, audio, and computer data \nto be visible to several participants at the same time.\nA robot floor-cleaner that is intended to clean relatively clear spaces such as corridors. The \ncleaner must be able to sense walls and other obstructions.\n\u2002 6.5.\t A software system will be built to allow drones to autonomously herd cattle in farms. These \ndrones can be remotely controlled by human operators. Explain how multiple architectural \npatterns can fit together to help build this kind of system.\n\u2002 6.6.\t Suggest an architecture for a system (such as iTunes) that is used to sell and distribute music \non the Internet. What Architectural patterns are the basis for your proposed architecture?\n\u2002 6.7.\t An information system is to be developed to maintain information about assets owned by a \nutility company such as buildings, vehicles, and equipment. It is intended that this will be \n", "page": 194, "type": "text", "section": "Page 194"}
{"text": "updatable by staff working in the field using mobile devices as new asset information \nbecomes available. The company has several existing asset databases that should be inte-\ngrated through this system. Design a layered architecture for this asset management system \nbased on the generic information system architecture shown in Figure 6.18.\n\u2002 6.8.\t Using the generic model of a language processing system presented here, design the archi-\ntecture of a system that accepts natural language commands and translates these into \n\u00ad\ndatabase queries in a language such as SQL.\n\u2002 6.9.\tUsing the basic model of an information system, as presented in Figure 6.18, suggest the \ncomponents that might be part of an information system that allows users to view box office \nevents, available tickets and prices, and to eventually buy tickets.\n6.10.\t Should there be a separate profession of \u2019software architect\u2019 whose role is to work indepen-\ndently with a customer to design the software system architecture? A separate software \n\u00ad\ncompany would then implement the system. What might be the difficulties of establishing \nsuch a profession?\nReferences\nBass, L., P. Clements, and R. Kazman. 2012. Software Architecture in Practice (3rd ed.). Boston: \nAddison-Wesley.\nBerczuk, S. P., and B. Appleton. 2002. Software Configuration Management Patterns: Effective \nTeamwork, Practical Integration. Boston: Addison-Wesley.\nBooch, G. 2014. \u201cHandbook of Software Architecture.\u201d http://handbookofsoftwarearchitecture.\ncom/\nBosch, J. 2000. Design and Use of Software Architectures. Harlow, UK: Addison-Wesley.\nBuschmann, F., K. Henney, and D. C. Schmidt. 2007a. Pattern-Oriented Software Architecture Vol-\nume 4: A Pattern Language for Distributed Computing. New York: John Wiley & Sons.\n\u2013\u2013\u2013\u2013\u2013\u2013. 2007b. Pattern-Oriented Software Architecture Volume 5: On Patterns and Pattern Lan-\nguages. New York: John Wiley & Sons.\nBuschmann, F., R. Meunier, H. Rohnert, and P. Sommerlad. 1996. Pattern-Oriented Software Archi-\ntecture Volume 1: A System of Patterns. New York: John Wiley & Sons.\nChen, L., M. Ali Babar, and B. Nuseibeh. 2013. \u201cCharacterizing Architecturally Significant Require-\nments.\u201d IEEE Software 30 (2): 38\u201345. doi:10.1109/MS.2012.174.\nCoplien, J. O., and N. B. Harrison. 2004. Organizational Patterns of Agile Software Development. \nEnglewood Cliffs, NJ: Prentice-Hall.\nGamma, E., R. Helm, R. Johnson, and J. Vlissides. 1995. Design Patterns: Elements of Reusable \nObject-Oriented Software. Reading, MA: Addison-Wesley.\n194\u2002 \u2002 Chapter 6\u2002 \u25a0\u2002 Architectural design\n", "page": 195, "type": "text", "section": "Page 195"}
{"text": "\t\nChapter 6\u2002 \u25a0\u2002 References\u2002 \u2002 195\nGarlan, D., and M. Shaw. 1993. \u201cAn Introduction to Software Architecture.\u201d In Advances in Software \nEngineering and Knowledge Engineering, edited by V. Ambriola and G. Tortora, 2:1\u201339. London: \nWorld Scientific Publishing Co.\nHofmeister, C., R. Nord, and D. Soni. 2000. Applied Software Architecture. Boston: Addison-Wesley.\nKircher, M., and P. Jain. 2004. Pattern-Oriented Software Architecture Volume 3: Patterns for \nResource Management. New York: John Wiley & Sons.\nKrutchen, P. 1995. \u201cThe 4+1 View Model of Software Architecture.\u201d IEEE Software 12 (6): 42\u201350. \ndoi:10.1109/52.469759.\nLange, C. F. J., M. R. V. Chaudron, and J. Muskens. 2006. \u201cUML Software Architecture and Design \nDescription.\u201d IEEE Software 23 (2): 40\u201346. doi:10.1109/MS.2006.50.\nLewis, P. M., A. J. Bernstein, and M. Kifer. 2003. Databases and Transaction Processing: An \n\u00ad\nApplication-Oriented Approach. Boston: Addison-Wesley.\nMartin, D., and I. Sommerville. 2004. \u201cPatterns of Cooperative Interaction: Linking Ethnomethodol-\nogy and Design.\u201d ACM Transactions on Computer-Human Interaction 11 (1) (March 1): 59\u201389. \ndoi:10.1145/972648.972651.\nNii, H. P. 1986. \u201cBlackboard Systems, Parts 1 and 2.\u201d AI Magazine 7 (2 and 3): 38\u201353 and 62\u201369. \nhttp://www.aaai.org/ojs/index.php/aimagazine/article/view/537/473\nSchmidt, D., M. Stal, H. Rohnert, and F. Buschmann. 2000. Pattern-Oriented Software Architecture \nVolume 2: Patterns for Concurrent and Networked Objects. New York: John Wiley & Sons.\nShaw, M., and D. Garlan. 1996. Software Architecture: Perspectives on an Emerging Discipline. \nEnglewood Cliffs, NJ: Prentice-Hall.\nUsability Group. 1998. \u201cUsability Patterns\u201d. University of Brighton. http://www.it.bton.ac.uk/\nResearch/patterns/home.html\n", "page": 196, "type": "text", "section": "Page 196"}
{"text": "Design and \nimplementation\n7 \nObjectives\nThe objectives of this chapter are to introduce object-oriented software \ndesign using the UML and highlight important implementation concerns. \nWhen you have read this chapter, you will:\n\u25a0\t understand the most important activities in a general, object-oriented \ndesign process;\n\u25a0\t understand some of the different models that may be used to \ndocument an object-oriented design;\n\u25a0\t know about the idea of design patterns and how these are a way of \nreusing design knowledge and experience;\n\u25a0\t have been introduced to key issues that have to be considered when \nimplementing software, including software reuse and open-source \ndevelopment.\nContents\n7.1 \tObject-oriented design using the UML\n7.2 \tDesign patterns\n7.3 \tImplementation issues\n7.4 \tOpen-source development\n", "page": 197, "type": "text", "section": "Page 197"}
{"text": " \nChapter 7\u2002 \u25a0\u2002 Design and implementation\u2002 \u2002 197\nSoftware design and implementation is the stage in the software engineering process \nat which an executable software system is developed. For some simple systems, \nsoftware engineering means software design and implementation and all other soft-\nware engineering activities are merged with this process. However, for large sys-\ntems, software design and implementation is only one of a number of software \nengineering processes (requirements engineering, verification and validation, etc.).\nSoftware design and implementation activities are invariably interleaved. Software \ndesign is a creative activity in which you identify software components and their \n\u00ad\nrelationships, based on a customer\u2019s requirements. Implementation is the process of \nrealizing the design as a program. Sometimes there is a separate design stage, and this \ndesign is modeled and documented. At other times, a design is in the programmer\u2019s \nhead or roughly sketched on a whiteboard or sheets of paper. Design is about how \nto\u00a0solve a problem, so there is always a design process. However, it isn\u2019t always neces-\nsary or appropriate to describe the design in detail using the UML or other design \ndescription language.\nDesign and implementation are closely linked, and you should normally take \nimplementation issues into account when developing a design. For example, using \nthe UML to document a design may be the right thing to do if you are programming \nin an object-oriented language such as Java or C#. It is less useful, I think, if you are \ndeveloping using a dynamically typed language like Python. There is no point in \nusing the UML if you are implementing your system by configuring an off-the-shelf \npackage. As I discussed in Chapter 3, agile methods usually work from informal \nsketches of the design and leave design decisions to programmers.\nOne of the most important implementation decisions that has to be made at an \nearly stage of a software project is whether to build or to buy the application soft-\nware. For many types of application, it is now possible to buy off-the-shelf applica-\ntion systems that can be adapted and tailored to the users\u2019 requirements. For example, \nif you want to implement a medical records system, you can buy a package that is \nalready used in hospitals. It is usually cheaper and faster to use this approach rather \nthan developing a new system in a conventional programming language.\nWhen you develop an application system by reusing an off-the-shelf product, the \ndesign process focuses on how to configure the system product to meet the applica-\ntion requirements. You don\u2019t develop design models of the system, such as models \nof the system objects and their interactions. I discuss this reuse-based approach to \ndevelopment in Chapter 15.\nI assume that most readers of this book have had experience of program design \nand implementation. This is something that you acquire as you learn to program \nand master the elements of a programming language like Java or Python. You will \nhave probably learned about good programming practice in the programming lan-\nguages that you have studied, as well as how to debug programs that you have \ndeveloped. Therefore, I don\u2019t cover programming topics here. Instead, this chapter \n \nhas two aims:\n1.\t\nTo show how system modeling and architectural design (covered in Chapters 5 \nand 6) are put into practice in developing an object-oriented software design.\n", "page": 198, "type": "text", "section": "Page 198"}
{"text": "198\u2002 \u2002 Chapter 7\u2002 \u25a0\u2002 Design and implementation\n2.\t\nTo introduce important implementation issues that are not usually covered in \nprogramming books. These include software reuse, configuration management \nand open-source development.\nAs there are a vast number of different development platforms, the chapter is not \nbiased toward any particular programming language or implementation technology. \nTherefore, I have presented all examples using the UML rather than a programming \nlanguage such as Java or Python.\n \n7.1  Object-oriented design using the UML\nAn object-oriented system is made up of interacting objects that maintain their own local \nstate and provide operations on that state. The representation of the state is private and \ncannot be accessed directly from outside the object. Object-oriented design processes \ninvolve designing object classes and the relationships between these classes. These \nclasses define the objects in the system and their interactions. When the design is realized \nas an executing program, the objects are created dynamically from these class definitions.\nObjects include both data and operations to manipulate that data. They may there-\nfore be understood and modified as stand-alone entities. Changing the implementa-\ntion of an object or adding services should not affect other system objects. Because \nobjects are associated with things, there is often a clear mapping between real-world \nentities (such as hardware components) and their controlling objects in the system. \nThis improves the understandability, and hence the maintainability, of the design.\nTo develop a system design from concept to detailed, object-oriented design, you \nneed to:\n1.\t\nUnderstand and define the context and the external interactions with the system.\n2.\t\nDesign the system architecture.\n3.\t\nIdentify the principal objects in the system.\n4.\t\nDevelop design models.\n5.\t\nSpecify interfaces.\nLike all creative activities, design is not a clear-cut, sequential process. You \ndevelop a design by getting ideas, proposing solutions, and refining these solutions \nas information becomes available. You inevitably have to backtrack and retry when \nproblems arise. Sometimes you explore options in detail to see if they work; at other \ntimes you ignore details until late in the process. Sometimes you use notations, such \nas the UML, precisely to clarify aspects of the design; at other times, notations are \nused informally to stimulate discussions.\nI explain object-oriented software design by developing a design for part of the \nembedded software for the wilderness weather station that I introduced in Chapter 1. \nWilderness weather stations are deployed in remote areas. Each weather station \n", "page": 199, "type": "text", "section": "Page 199"}
{"text": " \n7.1\u2002 \u25a0\u2002 Object-oriented design using the UML\u2002 \u2002 199\nrecords local weather information and periodically transfers this to a weather infor-\nmation system, using a satellite link.\n\t\n7.1.1 \t System context and interactions\nThe first stage in any software design process is to develop an understanding of the \nrelationships between the software that is being designed and its external environment. \nThis is essential for deciding how to provide the required system functionality and how \nto structure the system to communicate with its environment. As I discussed in Chapter 5, \nunderstanding the context also lets you establish the boundaries of the system.\nSetting the system boundaries helps you decide what features are implemented in \nthe system being designed and what features are in other associated systems. In this \ncase, you need to decide how functionality is distributed between the control system \nfor all of the weather stations and the embedded software in the weather station itself.\nSystem context models and interaction models present complementary views of \nthe relationships between a system and its environment:\n1.\t\nA system context model is a structural model that demonstrates the other sys-\ntems in the environment of the system being developed.\n2.\t\nAn interaction model is a dynamic model that shows how the system interacts \nwith its environment as it is used.\nThe context model of a system may be represented using associations. \nAssociations simply show that there are some relationships between the entities \ninvolved in the association. You can document the environment of the system using \na simple block diagram, showing the entities in the system and their associations. \nFigure 7.1 shows that the systems in the environment of each weather station are a \nweather information system, an onboard satellite system, and a control system. The \ncardinality information on the link shows that there is a single control system but \nseveral weather stations, one satellite, and one general weather information system.\nWhen you model the interactions of a system with its environment, you should \nuse an abstract approach that does not include too much detail. One way to do this is \nto use a use case model. As I discussed in Chapters 4 and 5, each  use case represents \nWeather\ninformation\nsystem\n1..n\n1\nWeather\nstation\nSatellite\n1\n1\n1..n\n1\nControl\nsystem\n1\n1\n1\n1..n\nFigure 7.1\u2002 System \ncontext for the \nweather station \n", "page": 200, "type": "text", "section": "Page 200"}
{"text": "200\u2002 \u2002 Chapter 7\u2002 \u25a0\u2002 Design and implementation\nan interaction with the system. Each possible interaction is named in an ellipse, and \nthe external entity involved in the interaction is represented by a stick figure.\nThe use case model for the weather station is shown in Figure 7.2. This shows \nthat the weather station interacts with the weather information system to report \nweather data and the status of the weather station hardware. Other interactions are \nwith a control system that can issue specific weather station control commands. The \nstick figure is used in the UML to represent other systems as well as human users.\nEach of these use cases should be described in structured natural language. This \nhelps designers identify objects in the system and gives them an understanding of \nwhat the system is intended to do. I use a standard format for this description that \nclearly identifies what information is exchanged, how the interaction is initiated, and \nso on. As I explain in Chapter 21, embedded systems are often modeled by \u00ad\ndescribing \nShutdown\nReport\nweather\nRestart\nReport status\nReconfigure\nWeather\ninformation\nsystem\nControl\nsystem\nPowersave\nRemote\ncontrol\nFigure 7.2\u2002 Weather \nstation use cases\nWeather station use cases\nReport weather\u2013send weather data to the weather information system\nReport status\u2013send status information to the weather information system\nRestart\u2013if the weather station is shut down, restart the system\nShutdown\u2013shut down the weather station\nReconfigure\u2013reconfigure the weather station software\nPowersave\u2013put the weather station into power-saving mode\nRemote control\u2013send control commands to any weather station subsystem\nhttp://software-engineering-book.com/web/ws-use-cases/\n", "page": 201, "type": "text", "section": "Page 201"}
{"text": " \n7.1\u2002 \u25a0\u2002 Object-oriented design using the UML\u2002 \u2002 201\nFigure 7.3\u2002 Use case \ndescription\u2014Report \nweather\nhow they respond to internal or external stimuli. Therefore, the stimuli and associ-\nated responses should be listed in the description. Figure 7.3 shows the description of \nthe Report weather use case from Figure 7.2 that is based on this approach.\n\t\n7.1.2 \t Architectural design\nOnce the interactions between the software system and the system\u2019s environment \nhave been defined, you use this information as a basis for designing the system archi-\ntecture. Of course, you need to combine this knowledge with your general knowl-\nedge of the principles of architectural design and with more detailed domain \nknowledge. You identify the major components that make up the system and their \ninteractions. You may then design the system organization using an architectural \npattern such as a layered or client\u2013server model.\nThe high-level architectural design for the weather station software is shown in \nFigure 7.4. The weather station is composed of independent subsystems that \u00ad\ncommunicate \n\u00absubsystem\u00bb\nData collection\n\u00absubsystem\u00bb\nCommunications\n\u00absubsystem\u00bb\nConfiguration manager\n\u00absubsystem\u00bb\nFault manager\n\u00absubsystem\u00bb\nPower manager\n\u00absubsystem\u00bb\nInstruments\nCommunication link\nFigure 7.4\u2002 High-level \narchitecture of \nweather station \nSystem\nWeather station\nUse case\nReport weather\nActors\nWeather information system, Weather station\nData\nThe weather station sends a summary of the weather data that has been collected from the \ninstruments in the collection period to the weather information system. The data sent are the \nmaximum, minimum, and average ground and air temperatures; the maximum, minimum, \nand average air pressures; the maximum, minimum and average wind speeds; the total \nrainfall; and the wind direction as sampled at 5-minute intervals.\nStimulus\nThe weather information system establishes a satellite communication link with the weather \nstation and requests transmission of the data.\nResponse\nThe summarized data is sent to the weather information system.\nComments\nWeather stations are usually asked to report once per hour, but this frequency may differ \nfrom one station to another and may be modified in future.\n", "page": 202, "type": "text", "section": "Page 202"}
{"text": "202\u2002 \u2002 Chapter 7\u2002 \u25a0\u2002 Design and implementation\nby broadcasting messages on a common infrastructure, shown as Communication link in \nFigure 7.4. Each subsystem listens for messages on that infrastructure and picks up the \nmessages that are intended for them. This \u201clistener model\u201d is a commonly used architec-\ntural style for distributed systems.\nWhen the communications subsystem receives a control command, such as shut-\ndown, the command is picked up by each of the other subsystems, which then shut \nthemselves down in the correct way. The key benefit of this architecture is that it is \neasy to support different configurations of subsystems because the sender of a mes-\nsage does not need to address the message to a particular subsystem.\nFigure 7.5 shows the architecture of the data collection subsystem, which is included \nin Figure 7.4. The Transmitter and Receiver objects are concerned with managing \ncommunications, and the WeatherData object encapsulates the information that is col-\nlected from the instruments and transmitted to the weather information system. This \narrangement follows the producer\u2013consumer pattern, discussed in Chapter 21.\n\t\n7.1.3 \t Object class identification\nBy this stage in the design process, you should have some ideas about the essential \nobjects in the system that you are designing. As your understanding of the design \ndevelops, you refine these ideas about the system objects. The use case description \nhelps to identify objects and operations in the system. From the description of the \nReport weather use case, it is obvious that you will need to implement objects repre-\nsenting the instruments that collect weather data and an object representing the \n\u00ad\nsummary of the weather data. You also usually need a high-level system object or \nobjects that encapsulate the system interactions defined in the use cases. With these \nobjects in mind, you can start to identify the general object classes in the system.\nAs object-oriented design evolved in the 1980s, various ways of identifying \nobject classes in object-oriented systems were suggested:\n1.\t\nUse a grammatical analysis of a natural language description of the system to be \nconstructed. Objects and attributes are nouns; operations or services are verbs \n(Abbott 1983).\n2.\t\nUse tangible entities (things) in the application domain such as aircraft, roles \nsuch as manager, events such as request, interactions such as meetings, locations \nData collection\nTransmitter\nReceiver\nWeatherData\nFigure 7.5\u2002 Architecture \nof data collection  \nsystem\n", "page": 203, "type": "text", "section": "Page 203"}
{"text": " \n7.1\u2002 \u25a0\u2002 Object-oriented design using the UML\u2002 \u2002 203\nsuch as offices, organizational units such as companies, and so on (Wirfs-Brock, \nWilkerson, and Weiner 1990).\n3.\t\nUse a scenario-based analysis where various scenarios of system use are identi-\nfied and analyzed in turn. As each scenario is analyzed, the team responsible for \nthe analysis must identify the required objects, attributes, and operations (Beck \nand Cunningham 1989).\nIn practice, you have to use several knowledge sources to discover object classes. \nObject classes, attributes, and operations that are initially identified from the informal \nsystem description can be a starting point for the design. Information from application \ndomain knowledge or scenario analysis may then be used to refine and extend the ini-\ntial objects. This information can be collected from requirements documents, discus-\nsions with users, or analyses of existing systems. As well as the objects representing \nentities external to the system, you may also have to design \u201cimplementation objects\u201d \nthat are used to provide general services such as searching and validity checking.\nIn the wilderness weather station, object identification is based on the tangible \nhardware in the system. I don\u2019t have space to include all the system objects here, but \nI have shown five object classes in Figure 7.6. The Ground thermometer, \nAnemometer, and Barometer objects are application domain objects, and the \nWeatherStation and WeatherData objects have been identified from the system \ndescription and the scenario (use case) description:\n1.\t\nThe WeatherStation object class provides the basic interface of the weather sta-\ntion with its environment. Its operations are based on the interactions shown in \nFigure 7.3. I use a single object class, and it includes all of these interactions. \nAlternatively, you could design the system interface as several different classes, \nwith one class per interaction.\nidentifier\nreportWeather ( )\nreportStatus ( )\npowerSave (instruments)\nremoteControl (commands)\nreconfigure (commands)\nrestart (instruments)\nshutdown (instruments)\nWeatherStation\nget ( )\ntest ( )\nGround\nthermometer\ntemperature\nAnemometer\nwindSpeed\nwindDirection\nget ( )\ntest ( )\nBarometer\npressure\nheight\nget ( )\ntest ( )\nWeatherData\nairTemperatures\ngroundTemperatures\nwindSpeeds\nwindDirections\npressures\nrainfall\ncollect ( )\nsummarize ( )\ngt_Ident\nan_Ident\nbar_Ident\nFigure 7.6\u2002 Weather \nstation objects\n", "page": 204, "type": "text", "section": "Page 204"}
{"text": "204\u2002 \u2002 Chapter 7\u2002 \u25a0\u2002 Design and implementation\n2.\t\nThe WeatherData object class is responsible for processing the report weather \ncommand. It sends the summarized data from the weather station instruments to \nthe weather information system.\n3.\t\nThe Ground thermometer, Anemometer, and Barometer object classes are directly \nrelated to instruments in the system. They reflect tangible hardware entities in the \nsystem and the operations are concerned with controlling that hardware. These \nobjects operate autonomously to collect data at the specified frequency and store the \ncollected data locally. This data is delivered to the WeatherData object on request.\nYou use knowledge of the application domain to identify other objects, attributes. \nand services:\n1.\t\nWeather stations are often located in remote places and include various instru-\nments that sometimes go wrong. Instrument failures should be reported auto-\nmatically. This implies that you need attributes and operations to check the \ncorrect functioning of the instruments.\n2.\t\nThere are many remote weather stations, so each weather station should have its \nown identifier so that it can be uniquely identified in communications.\n3.\t\nAs weather stations are installed at different times, the types of instrument may \nbe different. Therefore, each instrument should also be uniquely identified, and \na database of instrument information should be maintained.\nAt this stage in the design process, you should focus on the objects themselves, with-\nout thinking about how these objects might be implemented. Once you have identified \nthe objects, you then refine the object design. You look for common features and then \ndesign the inheritance hierarchy for the system. For example, you may identify an \nInstrument superclass, which defines the common features of all instruments, such as an \nidentifier, and get and test operations. You may also add new attributes and operations \nto the superclass, such as an attribute that records how often data should be collected.\n\t\n7.1.4 \t Design models\nDesign or system models, as I discussed in Chapter 5, show the objects or object classes \nin a system. They also show the associations and relationships between these entities. \nThese models are the bridge between the system requirements and the implementation \nof a system. They have to be abstract so that unnecessary detail doesn\u2019t hide the rela-\ntionships between them and the system requirements. However, they also have to \ninclude enough detail for programmers to make implementation decisions.\nThe level of detail that you need in a design model depends on the design process \nused. Where there are close links between requirements engineers, designers and \nprogrammers, then abstract models may be all that are required. Specific design \ndecisions may be made as the system is implemented, with problems resolved \nthrough informal discussions. Similarly, if agile development is used, outline design \nmodels on a whiteboard may be all that is required.\n", "page": 205, "type": "text", "section": "Page 205"}
{"text": " \n7.1\u2002 \u25a0\u2002 Object-oriented design using the UML\u2002 \u2002 205\nHowever, if a plan-based development process is used, you may need more \ndetailed models. When the links between requirements engineers, designers, and pro-\ngrammers are indirect (e.g., where a system is being designed in one part of an organ-\nization but implemented elsewhere), then precise design descriptions are needed for \ncommunication. Detailed models, derived from the high-level abstract models, are \nused so that all team members have a common understanding of the design.\nAn important step in the design process, therefore, is to decide on the design models \nthat you need and the level of detail required in these models. This depends on the type \nof system that is being developed. A sequential data-processing system is quite different \nfrom an embedded real-time system, so you need to use different types of design models. \nThe UML supports 13 different types of models, but, as I discussed in Chapter 5, many \nof these models are not widely used. Minimizing the number of models that are produced \nreduces the costs of the design and the time required to complete the design process.\nWhen you use the UML to develop a design, you should develop two kinds of \ndesign model:\n1.\t\nStructural models, which describe the static structure of the system using object \nclasses and their relationships. Important relationships that may be documented \nat this stage are generalization (inheritance) relationships, uses/used-by \n\u00ad\nrelationships, and composition relationships.\n2.\t\nDynamic models, which describe the dynamic structure of the system and show \nthe expected runtime interactions between the system objects. Interactions that \nmay be documented include the sequence of service requests made by objects \nand the state changes triggered by these object interactions.\nI think three UML model types are particularly useful for adding detail to use \ncase and architectural models:\n1.\t\nSubsystem models, which show logical groupings of objects into coherent subsys-\ntems. These are represented using a form of class diagram with each subsystem \nshown as a package with enclosed objects. Subsystem models are structural models.\n2.\t\nSequence models, which show the sequence of object interactions. These are \nrepresented using a UML sequence or a collaboration diagram. Sequence models \nare dynamic models.\n3.\t\nState machine models, which show how objects change their state in response to \nevents. These are represented in the UML using state diagrams. State machine \nmodels are dynamic models.\nA subsystem model is a useful static model that shows how a design is organized into \nlogically related groups of objects. I have already shown this type of model in Figure 7.4 \nto present the subsystems in the weather mapping system. As well as \u00ad\nsubsystem models, \nyou may also design detailed object models, showing the objects in the systems and their \nassociations (inheritance, generalization, aggregation, etc.). However, there is a danger \n", "page": 206, "type": "text", "section": "Page 206"}
{"text": "206\u2002 \u2002 Chapter 7\u2002 \u25a0\u2002 Design and implementation\nin doing too much modeling. You should not make detailed decisions about the imple-\nmentation that are really best left until the system is \u00ad\nimplemented.\nSequence models are dynamic models that describe, for each mode of interaction, \nthe sequence of object interactions that take place. When documenting a design, you \nshould produce a sequence model for each significant interaction. If you have devel-\noped a use case model, then there should be a sequence model for each use case that \nyou have identified.\nFigure 7.7 is an example of a sequence model, shown as a UML sequence \n\u00ad\ndiagram. This diagram shows the sequence of interactions that take place when an \nexternal system requests the summarized data from the weather station. You read \nsequence diagrams from top to bottom:\n1.\t\nThe SatComms object receives a request from the weather information system to \ncollect a weather report from a weather station. It acknowledges receipt of this \nrequest. The stick arrowhead on the sent message indicates that the external system \ndoes not wait for a reply but can carry on with other processing.\n2.\t\nSatComms sends a message to WeatherStation, via a satellite link, to create a \nsummary of the collected weather data. Again, the stick arrowhead indicates \nthat SatComms does not suspend itself waiting for a reply.\n3.\t\nWeatherStation sends a message to a Commslink object to summarize the \nweather data. In this case, the squared-off style of arrowhead indicates that the \ninstance of the WeatherStation object class waits for a reply.\n4.\t\nCommslink calls the summarize method in the object WeatherData and waits \nfor a reply.\n:SatComms\nrequest (report)\nacknowledge\nreportWeather ()\nget (summary)\nreply (report)\nacknowledge\n:WeatherStation\n:Commslink\nsummarize ()\n:WeatherData\nacknowledge\nsend (report)\nacknowledge\nWeather\ninformation system\nFigure 7.7\u2002 Sequence \ndiagram describing  \ndata collection\n", "page": 207, "type": "text", "section": "Page 207"}
{"text": " \n7.1\u2002 \u25a0\u2002 Object-oriented design using the UML\u2002 \u2002 207\n5.\t\nThe weather data summary is computed and returned to WeatherStation via the \nCommslink object.\n6.\t\nWeatherStation then calls the SatComms object to transmit the summarized data \nto the weather information system, through the satellite communications system.\nThe SatComms and WeatherStation objects may be implemented as concurrent \nprocesses, whose execution can be suspended and resumed. The SatComms object \ninstance listens for messages from the external system, decodes these messages, and \ninitiates weather station operations.\nSequence diagrams are used to model the combined behavior of a group of objects, \nbut you may also want to summarize the behavior of an object or a subsystem in response \nto messages and events. To do this, you can use a state machine model that shows how \nthe object instance changes state depending on the messages that it receives. As I discuss \nin Chapter 5, the UML includes state diagrams to describe state machine models.\nFigure 7.8 is a state diagram for the weather station system that shows how it \nresponds to requests for various services.\nYou can read this diagram as follows:\n1.\t\nIf the system state is Shutdown, then it can respond to a restart(), a reconfigure() \nor a powerSave() message. The unlabeled arrow with the black blob indicates \nthat the Shutdown state is the initial state. A restart() message causes a transition \nto normal operation. Both the powerSave() and reconfigure() messages cause a \ntransition to a state in which the system reconfigures itself. The state diagram \nshows that reconfiguration is allowed only if the system has been shut down.\ntransmission done\nremoteControl()\nreportStatus()\nrestart()\nshutdown()\ntest complete\nweather summary\ncomplete\nclock\ncollection\ndone\nOperation\nreportWeather()\nShutdown\nRunning\nTesting\nTransmitting\nCollecting\nSummarizing\nControlled\nConfiguring\nreconfigure()\nconfiguration done\npowerSave()\nFigure 7.8\u2002 Weather \nstation state diagram\n", "page": 208, "type": "text", "section": "Page 208"}
{"text": "208\u2002 \u2002 Chapter 7\u2002 \u25a0\u2002 Design and implementation\n2.\t\nIn the Running state, the system expects further messages. If a shutdown() mes-\nsage is received, the object returns to the shutdown state.\n3.\t\nIf a reportWeather() message is received, the system moves to the Summarizing \nstate. When the summary is complete, the system moves to a Transmitting state where \nthe information is transmitted to the remote system. It then returns to the Running state.\n4.\t\nIf a signal from the clock is received, the system moves to the Collecting state, \nwhere it collects data from the instruments. Each instrument is instructed in turn \nto collect its data from the associated sensors.\n5.\t\nIf a remoteControl() message is received, the system moves to a controlled state \nin which it responds to a different set of messages from the remote control room. \nThese are not shown on this diagram.\nState diagrams are useful high-level models of a system or an object\u2019s operation. \nHowever, you don\u2019t need a state diagram for all of the objects in the system. Many \nsystem objects in a system are simple, and their operation can be easily described \nwithout a state model.\n\t\n7.1.5 \t Interface specification\nAn important part of any design process is the specification of the interfaces between \nthe components in the design. You need to specify interfaces so that objects and \nsubsystems can be designed in parallel. Once an interface has been specified, the \ndevelopers of other objects may assume that interface will be implemented.\nInterface design is concerned with specifying the detail of the interface to an \nobject or to a group of objects. This means defining the signatures and semantics of \nthe services that are provided by the object or by a group of objects. Interfaces can be \nspecified in the UML using the same notation as a class diagram. However, there is \nno attribute section, and the UML stereotype \u00abinterface\u00bb should be included in the \nname part. The semantics of the interface may be defined using the object constraint \nlanguage (OCL). I discuss the use of the OCL in Chapter 16, where I explain how it \ncan be used to describe the semantics of components.\nYou should not include details of the data representation in an interface design, as \nattributes are not defined in an interface specification. However, you should include \noperations to access and update data. As the data representation is hidden, it can be \neasily changed without affecting the objects that use that data. This leads to a design \nthat is inherently more maintainable. For example, an array representation of a stack \nmay be changed to a list representation without affecting other objects that use the \nstack. By contrast, you should normally expose the attributes in an object model, as \nthis is the clearest way of describing the essential characteristics of the objects.\nThere is not a simple 1:1 relationship between objects and interfaces. The same \nobject may have several interfaces, each of which is a viewpoint on the methods that \nit provides. This is supported directly in Java, where interfaces are declared separately \nfrom objects and objects \u201cimplement\u201d interfaces. Equally, a group of objects may all \nbe accessed through a single interface.\n", "page": 209, "type": "text", "section": "Page 209"}
{"text": " \n7.2\u2002 \u25a0\u2002 Design patterns \u2002 \u2002 209\nFigure 7.9 shows two interfaces that may be defined for the weather station. The left-\nhand interface is a reporting interface that defines the operation names that are used to \ngenerate weather and status reports. These map directly to operations in the WeatherStation \nobject. The remote control interface provides four operations, which map onto a single \nmethod in the WeatherStation object. In this case, the individual operations are encoded \nin the command string associated with the remoteControl method, shown in Figure 7.6.\n \n7.2  Design patterns\nDesign patterns were derived from ideas put forward by Christopher Alexander \n(Alexander 1979), who suggested that there were certain common patterns of building \ndesign that were inherently pleasing and effective. The pattern is a description of the \nproblem and the essence of its solution, so that the solution may be reused in different \nsettings. The pattern is not a detailed specification. Rather, you can think of it as a descrip-\ntion of accumulated wisdom and experience, a well-tried solution to a common problem.\nA quote from the Hillside Group website (hillside.net/patterns/), which is dedi-\ncated to maintaining information about patterns, encapsulates their role in reuse:\nPatterns and Pattern Languages are ways to describe best practices, good \ndesigns, and capture experience in a way that it is possible for others to reuse \nthis experience\u2020.\nPatterns have made a huge impact on object-oriented software design. As well as \nbeing tested solutions to common problems, they have become a vocabulary for talk-\ning about a design. You can therefore explain your design by describing the patterns \nthat you have used. This is particularly true for the best known design patterns that \nwere originally described by the \u201cGang of Four\u201d in their patterns book, published in \n1995 (Gamma et al. 1995). Other important pattern descriptions are those published \nin a series of books by authors from Siemens, a large European technology company \n(Buschmann et al. 1996; Schmidt et al. 2000; Kircher and Jain 2004; Buschmann, \nHenney, and Schmidt 2007a, 2007b).\nPatterns are a way of reusing the knowledge and experience of other designers. \nDesign patterns are usually associated with object-oriented design. Published patterns \noften rely on object characteristics such as inheritance and polymorphism to provide \ngenerality. However, the general principle of encapsulating experience in a pattern is \n\u00abinterface\u00bb\nReporting\nweatherReport (WS-Ident): Wreport\nstatusReport (WS-Ident): Sreport\n\u00abinterface\u00bb\nRemote Control\nstartInstrument(instrument): iStatus\nstopInstrument (instrument): iStatus\ncollectData (instrument): iStatus\nprovideData (instrument ): string\nFigure 7.9\u2002 Weather \nstation interfaces\n\u2020The HIllside Group: hillside.net/patterns\n", "page": 210, "type": "text", "section": "Page 210"}
{"text": "210\u2002 \u2002 Chapter 7\u2002 \u25a0\u2002 Design and implementation\nPattern name: Observer\nDescription: Separates the display of the state of an object from the object itself and allows alternative displays \nto be provided. When the object state changes, all displays are automatically notified and updated to reflect \nthe change.\nProblem description: In many situations, you have to provide multiple displays of state information, such as a \ngraphical display and a tabular display. Not all of these may be known when the information is specified. All alter-\nnative presentations should support interaction and, when the state is changed, all displays must be updated.\nThis pattern may be used in situations where more than one display format for state information is required \nand where it is not necessary for the object that maintains the state information to know about the specific \ndisplay formats used.\nSolution description: This involves two abstract objects, Subject and Observer, and two concrete objects, \n\u00ad\nConcreteSubject and ConcreteObject, which inherit the attributes of the related abstract objects. The abstract \nobjects include general operations that are applicable in all situations. The state to be displayed is main-\ntained in ConcreteSubject, which inherits operations from Subject allowing it to add and remove Observers \n(each observer corresponds to a display) and to issue a notification when the state has changed.\nThe ConcreteObserver maintains a copy of the state of ConcreteSubject and implements the Update() \n\u00ad\ninterface of Observer that allows these copies to be kept in step. The ConcreteObserver automatically \n\u00ad\ndisplays the state and reflects changes whenever the state is updated.\nThe UML model of the pattern is shown in Figure 7.12.\nConsequences: The subject only knows the abstract Observer and does not know details of the concrete class. \nTherefore there is minimal coupling between these objects. Because of this lack of knowledge, optimizations \nthat enhance display performance are impractical. Changes to the subject may cause a set of linked updates \nto observers to be generated, some of which may not be necessary.\nFigure 7.10\u2002 The \nObserver pattern\none that is equally applicable to any kind of software design. For instance, you could \nhave configuration patterns for instantiating reusable application systems.\nThe Gang of Four defined the four essential elements of design patterns in their \nbook on patterns:\n1.\t\nA name that is a meaningful reference to the pattern.\n2.\t\nA description of the problem area that explains when the pattern may be applied.\n3.\t\nA solution description of the parts of the design solution, their relationships and their \nresponsibilities. This is not a concrete design description. It is a template for a design \nsolution that can be instantiated in different ways. This is often expressed graphically \nand shows the relationships between the objects and object classes in the solution.\n4.\t\nA statement of the consequences\u2014the results and trade-offs\u2014of applying the \npattern. This can help designers understand whether or not a pattern can be used \nin a particular situation.\nGamma and his co-authors break down the problem description into motivation \n(a description of why the pattern is useful) and applicability (a description of situa-\ntions in which the pattern may be used). Under the description of the solution, they \ndescribe the pattern structure, participants, collaborations, and implementation.\nTo illustrate pattern description, I use the Observer pattern, taken from the Gang \nof Four\u2019s patterns book. This is shown in Figure 7.10. In my description, I use the \n", "page": 211, "type": "text", "section": "Page 211"}
{"text": " \n7.2\u2002 \u25a0\u2002 Design patterns\u2002 \u2002 211\nA: 40\nB: 25\nC: 15\nD: 20\nObserver 1\nA\nB\nC\nD\nObserver 2\nSubject\n0\n50\n25\nA\nB\nC\nD\nFigure 7.11\u2002 Multiple \ndisplays \nfour essential description elements and also include a brief statement of what the \n\u00ad\npattern can do. This pattern can be used in situations where different presentations of \nan object\u2019s state are required. It separates the object that must be displayed from the \ndifferent forms of presentation. This is illustrated in Figure 7.11, which shows two \ndifferent graphical presentations of the same dataset.\nGraphical representations are normally used to illustrate the object classes in \n\u00ad\npatterns and their relationships. These supplement the pattern description and add \ndetail to the solution description. Figure 7.12 is the representation in UML of the \nObserver pattern.\nTo use patterns in your design, you need to recognize that any design problem \nyou are facing may have an associated pattern that can be applied. Examples of such \nproblems, documented in the Gang of Four\u2019s original patterns book, include:\n1.\t\nTell several objects that the state of some other object has changed (Observer pattern).\n2.\t\nTidy up the interfaces to a number of related objects that have often been devel-\noped incrementally (Fa\u00e7ade pattern).\nSubject\nObserver\nAttach (Observer)\nDetach (Observer)\nNotify ()\nUpdate ()\nConcreteSubject\nGetState ()\nsubjectState\nConcreteObserver\nUpdate ()\nobserverState\nobserverState =\n   subject -> GetState ()\nreturn subjectState\nfor all o in observers\n   o -> Update ()\nFigure 7.12\u2002 A UML \nmodel of the  \nObserver pattern\n", "page": 212, "type": "text", "section": "Page 212"}
{"text": "212\u2002 \u2002 Chapter 7\u2002 \u25a0\u2002 Design and implementation\n3.\t\nProvide a standard way of accessing the elements in a collection, irrespective of \nhow that collection is implemented (Iterator pattern).\n4.\t\nAllow for the possibility of extending the functionality of an existing class at \nruntime (Decorator pattern).\nPatterns support high-level, concept reuse. When you try to reuse executable \ncomponents you are inevitably constrained by detailed design decisions that have \nbeen made by the implementers of these components. These range from the particu-\nlar algorithms that have been used to implement the components to the objects and \ntypes in the component interfaces. When these design decisions conflict with your \nrequirements, reusing the component is either impossible or introduces inefficien-\ncies into your system. Using patterns means that you reuse the ideas but can adapt \nthe implementation to suit the system you are developing.\nWhen you start designing a system, it can be difficult to know, in advance, if you \nwill need a particular pattern. Therefore, using patterns in a design process often \ninvolves developing a design, experiencing a problem, and then recognizing that a \npattern can be used. This is certainly possible if you focus on the 23 general-purpose \npatterns documented in the original patterns book. However, if your problem is a \ndifferent one, you may find it difficult to find an appropriate pattern among the hun-\ndreds of different patterns that have been proposed.\nPatterns are a great idea, but you need experience of software design to use them \neffectively. You have to recognize situations where a pattern can be applied. Inexperienced \nprogrammers, even if they have read the pattern books, will always find it hard to decide \nwhether they can reuse a pattern or need to develop a special-purpose solution.\n \n7.3  Implementation issues\nSoftware engineering includes all of the activities involved in software development \nfrom the initial requirements of the system through to maintenance and management \nof the deployed system. A critical stage of this process is, of course, system imple-\nmentation, where you create an executable version of the software. Implementation \nmay involve developing programs in high- or low-level programming languages or \ntailoring and adapting generic, off-the-shelf systems to meet the specific requirements \nof an organization.\nI assume that most readers of this book will understand programming principles \nand will have some programming experience. As this chapter is intended to offer a \nlanguage-independent approach, I haven\u2019t focused on issues of good programming \npractice as language-specific examples need to be used. Instead, I introduce some \naspects of implementation that are particularly important to software engineering \nand that are often not covered in programming texts. These are:\n1.\t\nReuse Most modern software is constructed by reusing existing components or \nsystems. When you are developing software, you should make as much use as \npossible of existing code.\n", "page": 213, "type": "text", "section": "Page 213"}
{"text": " \n7.3\u2002 \u25a0\u2002 Implementation issues\u2002 \u2002 213\n2.\t\nConfiguration management During the development process, many different \nversions of each software component are created. If you don\u2019t keep track of \nthese versions in a configuration management system, you are liable to include \nthe wrong versions of these components in your system.\n3.\t\nHost-target development Production software does not usually execute on the \nsame computer as the software development environment. Rather, you develop \nit on one computer (the host system) and execute it on a separate computer (the \ntarget system). The host and target systems are sometimes of the same type, but \noften they are completely different.\n\t\n7.3.1 \t Reuse\nFrom the 1960s to the 1990s, most new software was developed from scratch, by \nwriting all code in a high-level programming language. The only significant reuse or \nsoftware was the reuse of functions and objects in programming language libraries. \nHowever, costs and schedule pressure meant that this approach became increasingly \nunviable, especially for commercial and Internet-based systems. Consequently, an \napproach to development based on the reuse of existing software is now the norm for \nmany types of system development. A reuse-based approach is now widely used for \nweb-based systems of all kinds, scientific software, and, increasingly, in embedded \nsystems engineering.\nSoftware reuse is possible at a number of different levels, as shown in Figure 7.13:\n1.\t\nThe abstraction level At this level, you don\u2019t reuse software directly but rather \nuse knowledge of successful abstractions in the design of your software. Design \npatterns and architectural patterns (covered in Chapter 6) are ways of representing \nabstract knowledge for reuse.\nSoftware reuse\nAbstraction \nArchitectural and \ndesign patterns\nSystem\nApplication systems \n(COTS)\nComponent\nComponent\nframeworks\nObject\nProgramming \nlanguage libraries\nFigure 7.13\u2002 Software \nreuse\n", "page": 214, "type": "text", "section": "Page 214"}
{"text": "214\u2002 \u2002 Chapter 7\u2002 \u25a0\u2002 Design and implementation\n2.\t\nThe object level At this level, you directly reuse objects from a library rather \nthan writing the code yourself. To implement this type of reuse, you have to find \nappropriate libraries and discover if the objects and methods offer the function-\nality that you need. For example, if you need to process email messages in a \nJava program, you may use objects and methods from a JavaMail library.\n3.\t The component level Components are collections of objects and object classes \nthat operate together to provide related functions and services. You often have \nto adapt and extend the component by adding some code of your own. An \nexample of component-level reuse is where you build your user interface using \na framework. This is a set of general object classes that implement event han-\ndling, display management, etc. You add connections to the data to be dis-\nplayed and write code to define specific display details such as screen layout \nand colors.\n4.\t\nThe system level At this level, you reuse entire application systems. This function \nusually involves some kind of configuration of these systems. This may be done \nby adding and modifying code (if you are reusing a software product line) or by \nusing the system\u2019s own configuration interface. Most commercial systems are \nnow built in this way where generic application systems systems are adapted and \nreused. Sometimes this approach may involve integrating several application \nsystems to create a new system.\nBy reusing existing software, you can develop new systems more quickly, with \nfewer development risks and at lower cost. As the reused software has been tested in \nother applications, it should be more reliable than new software. However, there are \ncosts associated with reuse:\n1.\t\nThe costs of the time spent in looking for software to reuse and assessing \nwhether or not it meets your needs. You may have to test the software to make \nsure that it will work in your environment, especially if this is different from its \ndevelopment environment.\n2.\t\nWhere applicable, the costs of buying the reusable software. For large off-the-\nshelf systems, these costs can be very high.\n3.\t\nThe costs of adapting and configuring the reusable software components or \n\u00ad\nsystems to reflect the requirements of the system that you are developing.\n4.\t\nThe costs of integrating reusable software elements with each other (if you are \nusing software from different sources) and with the new code that you have \ndeveloped. Integrating reusable software from different providers can be diffi-\ncult and expensive because the providers may make conflicting assumptions \nabout how their respective software will be reused.\nHow to reuse existing knowledge and software should be the first thing you should \nthink about when starting a software development project. You should consider the \n", "page": 215, "type": "text", "section": "Page 215"}
{"text": "possibilities of reuse before designing the software in detail, as you may wish to adapt \nyour design to reuse existing software assets. As I discussed in Chapter 2, in  a \n\u00ad\nreuse-oriented development process, you search for reusable elements, then modify \nyour requirements and design to make the best use of these.\nBecause of the importance of reuse in modern software engineering, I devote \nseveral chapters in Part 3 of this book to this topic (Chapters 15, 16, and 18).\n\t\n7.3.2 \t Configuration management\nIn software development, change happens all the time, so change management is \nabsolutely essential. When several people are involved in developing a software sys-\ntem, you have to make sure that team members don\u2019t interfere with each other\u2019s \nwork. That is, if two people are working on a component, their changes have to be \ncoordinated. Otherwise, one programmer may make changes and overwrite the oth-\ner\u2019s work. You also have to ensure that everyone can access the most up-to-date ver-\nsions of software components; otherwise developers may redo work that has already \nbeen done. When something goes wrong with a new version of a system, you have to \nbe able to go back to a working version of the system or component.\nConfiguration management is the name given to the general process of managing \na changing software system. The aim of configuration management is to support the \nsystem integration process so that all developers can access the project code and \ndocuments in a controlled way, find out what changes have been made, and compile \nand link components to create a system. As shown in Figure 7.14, there are four \nfundamental configuration management activities:\n1.\t\nVersion management, where support is provided to keep track of the different \nversions of software components. Version management systems include facilities \nto coordinate development by several programmers. They stop one developer \nfrom overwriting code that has been submitted to the system by someone else.\n2.\t\nSystem integration, where support is provided to help developers define what \nversions of components are used to create each version of a system. This \nComponent\nversions\nRelease\nmanagement\nChange\nproposals\nSystem\nreleases\nChange\nmanagement\nSystem\nversions\nVersion\nmanagement\nSystem\nbuilding\nFigure 7.14\u2002 Configuration \nmanagement\n \n7.3\u2002 \u25a0\u2002 Implementation issues\u2002 \u2002 215\n", "page": 216, "type": "text", "section": "Page 216"}
{"text": "description is then used to build a system automatically by compiling and link-\ning the required components.\n3.\t\nProblem tracking, where support is provided to allow users to report bugs and \nother problems, and to allow all developers to see who is working on these prob-\nlems and when they are fixed.\n4.\t\nRelease management, where new versions of a software system are released to \ncustomers. Release management is concerned with planning the functionality of \nnew releases and organizing the software for distribution.\nSoftware configuration management tools support each of the above activities. \nThese tools are usually installed in an integrated development environment, such as \nEclipse. Version management may be supported using a version management system \nsuch as Subversion (Pilato, Collins-Sussman, and Fitzpatrick 2008) or Git (Loeliger \nand McCullough 2012), which can support multi-site, multi-team development. \nSystem integration support may be built into the language or rely on a separate tool-\nset such as the GNU build system. Bug tracking or issue tracking systems, such as \nBugzilla, are used to report bugs and other issues and to keep track of whether or not \nthese have been fixed. A comprehensive set of tools built around the Git system is \navailable at Github (http://github.com).\nBecause of its importance in professional software engineering, I discuss change \nand configuration management in more detail in Chapter 25.\n\t\n7.3.3 \t Host-target development\nMost professional software development is based on a host-target model (Figure 7.15). \nSoftware is developed on one computer (the host) but runs on a separate machine (the \ntarget). More generally, we can talk about a development platform (host) and an \n\u00ad\nexecution platform (target). A platform is more than just hardware. It includes the \ninstalled operating system plus other supporting software such as a database manage-\nment system or, for development platforms, an interactive development environment.\nDevelopment \nplatform\nIDE\nCompilers\nTesting tools\nExecution\nplatform\nLibraries\nRelated systems\nDatabases\nDevelopment \nplatform\nIDE\nCompilers\nTesting tools\nTarget\nHost\nDownload\nsoftware\nFigure 7.15\u2002 Host-target \ndevelopment\n216\u2002 \u2002 Chapter 7\u2002 \u25a0\u2002 Design and implementation\n", "page": 217, "type": "text", "section": "Page 217"}
{"text": "Sometimes, the development platform and execution platform are the same, mak-\ning it possible to develop the software and test it on the same machine. Therefore, if \nyou develop in Java, the target environment is the Java Virtual Machine. In princi-\nple, this is the same on every computer, so programs should be portable from one \nmachine to another. However, particularly for embedded systems and mobile \n\u00ad\nsystems, the development and the execution platforms are different. You need to \neither move your developed software to the execution platform for testing or run a \nsimulator on your development machine.\nSimulators are often used when developing embedded systems. You simulate \nhardware devices, such as sensors, and the events in the environment in which the \nsystem will be deployed. Simulators speed up the development process for embed-\nded systems as each developer can have his or her own execution platform with no \nneed to download the software to the target hardware. However, simulators are \nexpensive to develop and so are usually available only for the most popular \n\u00ad\nhardware architectures.\nIf the target system has installed middleware or other software that you need \nto use, then you need to be able to test the system using that software. It may be \nimpractical to install that software on your development machine, even if it is \nthe same as the target platform, because of license restrictions. If this is the \ncase, you need to transfer your developed code to the execution platform to test \nthe system.\nA software development platform should provide a range of tools to support soft-\nware engineering processes. These may include:\n1.\t\nAn integrated compiler and syntax-directed editing system that allows you to \ncreate, edit, and compile code.\n2.\t\nA language debugging system.\n3.\t\nGraphical editing tools, such as tools to edit UML models.\n4.\t\nTesting tools, such as JUnit, that can automatically run a set of tests on a new \nversion of a program.\n5.\t\nTools to support refactoring and program visualization.\n6.\t\nConfiguration management tools to manage source code versions and to integrate \nand build systems.\nIn addition to these standard tools, your development system may include more \n\u00ad\nspecialized tools such as static analyzers (discussed in Chapter 12). Normally, devel-\nopment environments for teams also include a shared server that runs a change and \nconfiguration management system and, perhaps, a system to support requirements \nmanagement.\nSoftware development tools are now usually installed within an integrated devel-\nopment environment (IDE). An IDE is a set of software tools that supports different \naspects of software development within some common framework and user inter-\nface. Generally, IDEs are created to support development in a specific programming \n \n7.3\u2002 \u25a0\u2002 Implementation issues\u2002 \u2002 217\n", "page": 218, "type": "text", "section": "Page 218"}
{"text": "language such as Java. The language IDE may be developed specially or may be an \ninstantiation of a general-purpose IDE, with specific language-support tools.\nA general-purpose IDE is a framework for hosting software tools that provides data \nmanagement facilities for the software being developed and integration mechanisms \nthat allow tools to work together. The best-known general-purpose IDE is the Eclipse \nenvironment (http://www.eclipse.org). This environment is based on a plug-in architec-\nture so that it can be specialized for different languages, such as Java, and application \ndomains. Therefore, you can install Eclipse and tailor it for your specific needs by add-\ning plug-ins. For example, you may add a set of plug-ins to support networked systems \ndevelopment in Java (Vogel 2013) or embedded systems \u00ad\nengineering using C.\nAs part of the development process, you need to make decisions about how the \ndeveloped software will be deployed on the target platform. This is straightforward \nfor embedded systems, where the target is usually a single computer. However, for \ndistributed systems, you need to decide on the specific platforms where the compo-\nnents will be deployed. Issues that you have to consider in making this decision are:\n1.\t\nThe hardware and software requirements of a component If a component is \ndesigned for a specific hardware architecture, or relies on some other software \nsystem, it must obviously be deployed on a platform that provides the required \nhardware and software support.\n2.\t\nThe availability requirements of the system High-availability systems may require \ncomponents to be deployed on more than one platform. This means that, in the event \nof platform failure, an alternative implementation of the component is available.\n3.\t\nComponent communications If there is a lot of intercomponent communication, it is \nusually best to deploy them on the same platform or on platforms that are physically \nclose to one another. This reduces communications latency\u2014the delay between the \ntime that a message is sent by one component and received by another.\nYou can document your decisions on hardware and software deployment using \nUML deployment diagrams, which show how software components are distributed \nacross hardware platforms.\nIf you are developing an embedded system, you may have to take into account \ntarget characteristics, such as its physical size, power capabilities, the need for \n\u00ad\nreal-time responses to sensor events, the physical characteristics of actuators and its \nreal-time operating system. I discuss embedded systems engineering in Chapter 21. \n218\u2002 \u2002 Chapter 7\u2002 \u25a0\u2002 Design and implementation\nUML deployment diagrams\nUML deployment diagrams show how software components are physically deployed on processors. That is, the \ndeployment diagram shows the hardware and software in the system and the middleware used to connect the \ndifferent components in the system. Essentially, you can think of deployment diagrams as a way of defining and \ndocumenting the target environment.\nhttp://software-engineering-book.com/web/deployment/\n", "page": 219, "type": "text", "section": "Page 219"}
{"text": " \n7.4\u2002 \u25a0\u2002 Open-source development\u2002 \u2002 219\n \n7.4  Open-source development\nOpen-source development is an approach to software development in which the \nsource code of a software system is published and volunteers are invited to partici-\npate in the development process (Raymond 2001). Its roots are in the Free Software \nFoundation (www.fsf.org), which advocates that source code should not be proprie-\ntary but rather should always be available for users to examine and modify as they \nwish. There was an assumption that the code would be controlled and developed by \na small core group, rather than users of the code.\nOpen-source software extended this idea by using the Internet to recruit a much larger \npopulation of volunteer developers. Many of them are also users of the code. In principle \nat least, any contributor to an open-source project may report and fix bugs and propose \nnew features and functionality. However, in practice, successful open-source systems still \nrely on a core group of developers who control changes to the software.\nOpen-source software is the backbone of the Internet and software engineering. The \nLinux operating system is the most widely used server system, as is the open-source \nApache web server. Other important and universally used open-source products are \nJava, the Eclipse IDE, and the mySQL database management system. The Android \noperating system is installed on millions of mobile devices. Major players in the com-\nputer industry such as IBM and Oracle, support the open-source movement and base \ntheir software on open-source products. Thousands of other, lesser-known open-source \nsystems and components may also be used.\nIt is usually cheap or even free to acquire open-source software. You can normally \ndownload open-source software without charge. However, if you want documenta-\ntion and support, then you may have to pay for this, but costs are usually fairly low. \nThe other key benefit of using open-source products is that widely used open-source \nsystems are very reliable. They have a large population of users who are willing to \nfix problems themselves rather than report these problems to the developer and wait \nfor a new release of the system. Bugs are discovered and repaired more quickly than \nis usually possible with proprietary software.\nFor a company involved in software development, there are two open-source \nissues that have to be considered:\n1.\t\nShould the product that is being developed make use of open-source components?\n2.\t\nShould an open-source approach be used for its own software development?\nThe answers to these questions depend on the type of software that is being devel-\noped and the background and experience of the development team.\nIf you are developing a software product for sale, then time to market and reduced \ncosts are critical. If you are developing software in a domain in which there are high-quality \nopen-source systems available, you can save time and money by using these systems. \nHowever, if you are developing software to a specific set of organizational require-\nments, then using open-source components may not be an option. You may have to \nintegrate your software with existing systems that are incompatible with available \n", "page": 220, "type": "text", "section": "Page 220"}
{"text": "open-source systems. Even then, however, it could be quicker and cheaper to modify \nthe open-source system rather than redevelop the functionality that you need.\nMany software product companies are now using an open-source approach to devel-\nopment, especially for specialized systems. Their business model is not reliant on selling \na software product but rather on selling support for that product. They believe that \ninvolving the open-source community will allow software to be developed more cheaply \nand more quickly and will create a community of users for the software.\nSome companies believe that adopting an open-source approach will reveal con-\nfidential business knowledge to their competitors and so are reluctant to adopt this \ndevelopment model. However, if you are working in a small company and you open \nsource your software, this may reassure customers that they will be able to support \nthe software if your company goes out of business.\nPublishing the source code of a system does not mean that people from the wider \ncommunity will necessarily help with its development. Most successful open-source \nproducts have been platform products rather than application systems. There are a \nlimited number of developers who might be interested in specialized application sys-\ntems. Making a software system open source does not guarantee community involve-\nment. There are thousands of open-source projects on Sourceforge and GitHub that \nhave only a handful of downloads. However, if users of your software have concerns \nabout its availability in future, making the software open source means that they can \ntake their own copy and so be reassured that they will not lose access to it.\n\t\n7.4.1 \t Open-source licensing\nAlthough a fundamental principle of open-source development is that source code should \nbe freely available, this does not mean that anyone can do as they wish with that code. \nLegally, the developer of the code (either a company or an individual) owns the code. \nThey can place restrictions on how it is used by including legally binding conditions in an \nopen-source software license (St. Laurent 2004). Some open-source developers believe \nthat if an open-source component is used to develop a new system, then that system \nshould also be open source. Others are willing to allow their code to be used without this \nrestriction. The developed systems may be proprietary and sold as closed-source systems.\nMost open-source licenses (Chapman 2010) are variants of one of three \n\u00ad\ngeneral models:\n1.\t\nThe GNU General Public License (GPL). This is a so-called reciprocal license \nthat simplistically means that if you use open-source software that is licensed \nunder the GPL license, then you must make that software open source.\n2.\t\nThe GNU Lesser General Public License (LGPL). This is a variant of the GPL \nlicense where you can write components that link to open-source code without \nhaving to publish the source of these components. However, if you change the \nlicensed component, then you must publish this as open source.\n3.\t\nThe Berkley Standard Distribution (BSD) License. This is a nonreciprocal license, \nwhich means you are not obliged to re-publish any changes or modifications made to \n220\u2002 \u2002 Chapter 7\u2002 \u25a0\u2002 Design and implementation\n", "page": 221, "type": "text", "section": "Page 221"}
{"text": "open-source code. You can include the code in proprietary systems that are sold. If \nyou use open-source components, you must acknowledge the original creator of \nthe code. The MIT license is a variant of the BSD license with similar conditions.\nLicensing issues are important because if you use open-source software as part of \na software product, then you may be obliged by the terms of the license to make your \nown product open source. If you are trying to sell your software, you may wish to \nkeep it secret. This means that you may wish to avoid using GPL-licensed open-\nsource software in its development.\nIf you are building software that runs on an open-source platform but that does \nnot reuse open-source components, then licenses are not a problem. However, if \nyou embed open-source software in your software, you need processes and data-\nbases to keep track of what\u2019s been used and their license conditions. Bayersdorfer \n(Bayersdorfer 2007) suggests that companies managing projects that use open \nsource should:\n1.\t\nEstablish a system for maintaining information about open-source components \nthat are downloaded and used. You have to keep a copy of the license for each \ncomponent that was valid at the time the component was used. Licenses may \nchange, so you need to know the conditions that you have agreed to.\n2.\t\nBe aware of the different types of licenses and understand how a component is \nlicensed before it is used. You may decide to use a component in one system but \nnot in another because you plan to use these systems in different ways.\n3.\t\nBe aware of evolution pathways for components. You need to know a bit about \nthe open-source project where components are developed to understand how \nthey might change in future.\n4.\t\nEducate people about open source. It\u2019s not enough to have procedures in place \nto ensure compliance with license conditions. You also need to educate devel-\nopers about open source and open-source licensing.\n5.\t\nHave auditing systems in place. Developers, under tight deadlines, might be \ntempted to break the terms of a license. If possible, you should have software in \nplace to detect and stop this.\n6.\t\nParticipate in the open-source community. If you rely on open-source products, \nyou should participate in the community and help support their development.\nThe open-source approach is one of several business models for software. In this \nmodel, companies release the source of their software and sell add-on services and \nadvice in association with this. They may also sell cloud-based software services\u2014\nan attractive option for users who do not have the expertise to manage their own \nopen-source system and also specialized versions of their system for particular cli-\nents. Open-source is therefore likely to increase in importance as a way of develop-\ning and distributing software.\n \n7.4\u2002 \u25a0\u2002 Open-source development\u2002 \u2002 221\n", "page": 222, "type": "text", "section": "Page 222"}
{"text": "Key Points\n\u25a0\t Software design and implementation are interleaved activities. The level of detail in the design \ndepends on the type of system being developed and whether you are using a plan-driven or \nagile approach.\n\u25a0\t The process of object-oriented design includes activities to design the system architecture, \nidentify objects in the system, describe the design using different object models, and document \nthe component interfaces.\n\u25a0\t A range of different models may be produced during an object-oriented design process. These \ninclude static models (class models, generalization models, association models) and dynamic \nmodels (sequence models, state machine models).\n\u25a0\t Component interfaces must be defined precisely so that other objects can use them. A UML \ninterface stereotype may be used to define interfaces.\n\u25a0\t When developing software, you should always consider the possibility of reusing existing soft-\nware, either as components, services, or complete systems.\n\u25a0\t Configuration management is the process of managing changes to an evolving software system. \nIt is essential when a team of people is cooperating to develop software.\n\u25a0\t Most software development is host-target development. You use an IDE on a host machine to \ndevelop the software, which is transferred to a target machine for execution.\n\u25a0\t Open-source development involves making the source code of a system publicly available. This \nmeans that many people can propose changes and improvements to the software.\nFurther Reading\nDesign Patterns: Elements of Reusable Object-oriented Software. This is the original software pat-\nterns handbook that introduced software patterns to a wide community. (E. Gamma, R. Helm, R. \nJohnson and J. Vlissides, Addison-Wesley, 1995).\nApplying UML and Patterns: An Introduction to Object-oriented Analysis and Design and Iterative \nDevelopment, 3rd ed. Larman writes clearly on object-oriented design and also discusses use of the \nUML; this is a good introduction to using patterns in the design process. Although it is more than 10 \nyears old, it remains the best book on this topic that is available. (C. Larman, Prentice-Hall, 2004).\nProducing Open Source Software: How to Run a Successful Free Software Project. This book is a \ncomprehensive guide to the background to open-source software, licensing issues, and the practi-\ncalities of running an open-source development project. (K. Fogel, O\u2019Reilly Media Inc., 2008).\nFurther reading on software reuse is suggested in Chapter 15 and on configuration management in \nChapter 25.\n222\u2002 \u2002 Chapter 7\u2002 \u25a0\u2002 Design and implementation\n", "page": 223, "type": "text", "section": "Page 223"}
{"text": " \nChapter 7\u2002 \u25a0\u2002 Design and Implementation\u2002 \u2002 223\nWebsite\nPowerPoint slides for this chapter:\nwww.pearsonglobaleditions.com/Sommerville\nLinks to supporting videos:\nhttp://software-engineering-book.com/videos/implementation-and-evolution/\nMore information on the weather information system:\nhttp://software-engineering-book.com/case-studies/wilderness-weather-station/\nExercises\n7.1. \tUsing the tabular notation shown in Figure 7.3, specify the weather station use cases for Report \nstatus and Reconfigure. You should make reasonable assumptions about the functionality that \nis required here.\n7.2. \tAssume that the Mentcare system is being developed using an object-oriented approach. Draw \na use case diagram showing at least six possible use cases for this system.\n7.3. \tUsing the UML graphical notation for object classes, design the following object classes, identi-\nfying attributes and operations. Use your own experience to decide on the attributes and oper-\nations that should be associated with these objects.\n\u25a0\t\u2002 a messaging system on a mobile (cell) phone or tablet\n\u25a0\t\u2002 a printer for a personal computer\n\u25a0\t\u2002 a personal music system\n\u25a0\t\u2002 a bank account\n\u25a0\t\u2002 a library catalogue\n7.4. \tA shape can be classified into 2-D and 3-D. Design an inheritance hierarchy that will include \ndifferent kinds of 2-D and 3-D shapes. Make sure you identify at least five other classes \nof shapes.\n7.5. \tDevelop the design of the weather station to show the interaction between the data collection \nsubsystem and the instruments that collect weather data. Use sequence diagrams to show this \ninteraction.\n7.6. \tIdentify possible objects in the following systems and develop an object-oriented design for \nthem. You may make any reasonable assumptions about the systems when deriving the design.\n\u25a0\t\u2002 A group diary and time management system is intended to support the timetabling of meet-\nings and appointments across a group of co-workers. When an appointment is to be made \n \nChapter 7\u2002 \u25a0\u2002 Exercises\u2002 \u2002 223\n", "page": 224, "type": "text", "section": "Page 224"}
{"text": "224\u2002 \u2002 Chapter 1\u2002 \u25a0\u2002 Design and Implementation\nReferences\nAbbott, R. 1983. \u201cProgram Design by Informal English Descriptions.\u201d Comm. ACM 26 (11): 882\u2013894. \ndoi:10.1145/182.358441.\nAlexander, C. 1979. A Timeless Way of Building. Oxford, UK: Oxford University Press.\nBayersdorfer, M. 2007. \u201cManaging a Project with Open Source Components.\u201d ACM Interactions 14 \n(6): 33\u201334. doi:10.1145/1300655.1300677.\nBeck, K., and W. Cunningham. 1989. \u201cA Laboratory for Teaching Object-Oriented Thinking.\u201d In Proc. \nOOPSLA\u201989 (Conference on Object-Oriented Programming, Systems, Languages and Applications), \n1\u20136. ACM Press. doi:10.1145/74878.74879.\nBuschmann, F., K. Henney, and D. C. Schmidt. 2007a. Pattern-Oriented Software Architecture \n\u00ad\nVolume 4: A Pattern Language for Distributed Computing. New York: John Wiley & Sons.\n\t\n\u2002 \u2002 . 2007b. Pattern-Oriented Software Architecture Volume 5: On Patterns and Pattern  \nLanguages. New York: John Wiley & Sons.\nthat involves a number of people, the system finds a common slot in each of their diaries \nand arranges the appointment for that time. If no common slots are available, it interacts \nwith the user to rearrange his or her personal diary to make room for the appointment.\n\u25a0\t A filling station (gas station) is to be set up for fully automated operation. Drivers swipe their \ncredit card through a reader connected to the pump; the card is verified by communication \nwith a credit company computer, and a fuel limit is established. The driver may then take the \nfuel required. When fuel delivery is complete and the pump hose is returned to its holster, \nthe driver\u2019s credit card account is debited with the cost of the fuel taken. The credit card is \nreturned after debiting. If the card is invalid, the pump returns it before fuel is dispensed.\n7.7. \t\n \u200a\n\u2009\u0007\nDraw a sequence diagram showing the interactions of objects in a group diary system when a \ngroup of people are arranging a meeting.\n7.8. \t \u0007\nDraw a UML state diagram showing the possible state changes in either the group diary or the \nfilling station system.\n7.9. \t When code is integrated into a larger system, problems may surface. Explain how configura-\ntion management can be useful when handling such problems. \n7.10. \t\u2009\u2009\u0007\nA small company has developed a specialized software product that it configures specially \nfor each customer. New customers usually have specific requirements to be incorporated \ninto their system, and they pay for these to be developed and integrated with the product. \nThe software company has an opportunity to bid for a new contract, which would more than \ndouble its customer base. The new customer wishes to have some involvement in the con-\nfiguration of the system. Explain why, in these circumstances, it might be a good idea for the \ncompany owning the software to make it open source.\n224\u2002 \u2002 Chapter 7\u2002 \u25a0\u2002 Design and implementation\n", "page": 225, "type": "text", "section": "Page 225"}
{"text": " \nChapter 7\u2002 \u25a0\u2002 Design and Implementation\u2002 \u2002 225\nBuschmann, F., R. Meunier, H. Rohnert, and P. Sommerlad. 1996. Pattern-Oriented Software Architecture \nVolume 1: A System of Patterns. New York: John Wiley & Sons.\nChapman, C. 2010. \u201cA Short Guide to Open-Source and Similar Licences.\u201d Smashing Magazine. \nhttp://www.smashingmagazine.com/2010/03/24/a-short-guide-to-open-source-and-similar-licenses./\nGamma, E., R. Helm, R. Johnson, and J. Vlissides. 1995. Design Patterns: Elements of Reusable Object-\u00ad\nOriented Software. Reading, MA.: Addison-Wesley.\nKircher, M., and P. Jain. 2004. Pattern-Oriented Software Architecture Volume 3: Patterns for \nResource Management. New York: John Wiley & Sons.\nLoeliger, J., and M. McCullough. 2012. Version Control with Git: Powerful Tools and Techniques for \nCollaborative Software Development. Sebastopol, CA: O\u2019Reilly & Associates.\nPilato, C., B. Collins-Sussman, and B. Fitzpatrick. 2008. Version Control with Subversion. Sebastopol, \nCA: O\u2019Reilly & Associates.\nRaymond, E. S. 2001. The Cathedral and the Bazaar: Musings on Linux and Open Source by an Accidental \nRevolutionary. Sebastopol. CA: O\u2019Reilly & Associates.\nSchmidt, D., M. Stal, H. Rohnert, and F. Buschmann. 2000. Pattern-Oriented Software Architecture \nVolume 2: Patterns for Concurrent and Networked Objects. New York: John Wiley & Sons.\nSt. Laurent, A. 2004. Understanding Open Source and Free Software Licensing. Sebastopol, CA: \nO\u2019Reilly & Associates.\nVogel, L. 2013. Eclipse IDE: A Tutorial. Hamburg, Germany: Vogella Gmbh.\nWirfs-Brock, R., B. Wilkerson, and L. Weiner. 1990. Designing Object-Oriented Software. Englewood \nCliffs, NJ: Prentice-Hall.\n \nChapter 7\u2002 \u25a0\u2002 References\u2002 \u2002 225\n", "page": 226, "type": "text", "section": "Page 226"}
{"text": "Software testing\n8 \nObjectives\nThe objective of this chapter is to introduce software testing and \nsoftware testing processes. When you have read the chapter, you will:\n\u25a0\t understand the stages of testing from testing during development \nto acceptance testing by system customers;\n\u25a0\t have been introduced to techniques that help you choose test \ncases that are geared to discovering program defects;\n\u25a0\t understand test-first development, where you design tests before \nwriting code and run these tests automatically;\n\u25a0\t know about three distinct types of testing\u2014component testing, \nsystem testing, and release testing;\n\u25a0\t understand the distinctions between development testing and user \ntesting.\nContents\n8.1 \tDevelopment testing\n8.2 \tTest-driven development\n8.3 \tRelease testing\n8.4 \tUser testing\n", "page": 227, "type": "text", "section": "Page 227"}
{"text": " \nChapter 8\u2002 \u25a0\u2002 Software testing\u2002 \u2002 227\nTesting is intended to show that a program does what it is intended to do and to \n\u00ad\ndiscover program defects before it is put into use. When you test software, you exe-\ncute a program using artificial data. You check the results of the test run for errors, \nanomalies, or information about the program\u2019s non-functional attributes.\nWhen you test software, you are trying to do two things:\n1.\t\nDemonstrate to the developer and the customer that the software meets its \nrequirements. For custom software, this means that there should be at least one \ntest for every requirement in the requirements document. For generic software \nproducts, it means that there should be tests for all of the system features that \nwill be included in the product release. You may also test combinations of fea-\ntures to check for unwanted interactions between them.\n2.\t\nFind inputs or input sequences where the behavior of the software is incorrect, \nundesirable, or does not conform to its specification. These are caused by defects \n(bugs) in the software. When you test software to find defects, you are trying to \nroot out undesirable system behavior such as system crashes, unwanted interac-\ntions with other systems, incorrect computations, and data corruption.\nThe first of these is validation testing, where you expect the system to perform \ncorrectly using a set of test cases that reflect the system\u2019s expected use. The \u00ad\nsecond \nis defect testing, where the test cases are designed to expose defects. The test cases in \ndefect testing can be deliberately obscure and need not reflect how the system is \nnormally used. Of course, there is no definite boundary between these two approaches \nto testing. During validation testing, you will find defects in the \u00ad\nsystem; during \ndefect testing, some of the tests will show that the program meets its requirements.\nFigure 8.1 shows the differences between validation testing and defect testing. Think \nof the system being tested as a black box. The system accepts inputs from some input \nset I and generates outputs in an output set O. Some of the outputs will be erroneous. \nThese are the outputs in set Oe that are generated by the system in response to inputs in \nthe set Ie. The priority in defect testing is to find those inputs in\u00a0the set Ie because these \nreveal problems with the system. Validation testing involves testing with correct inputs \nthat are outside Ie. These stimulate the system to generate the expected correct outputs.\nTesting cannot demonstrate that the software is free of defects or that it will behave \nas specified in every circumstance. It is always possible that a test you have overlooked \ncould discover further problems with the system. As Edsger Dijkstra, an early con-\ntributor to the development of software engineering, eloquently stated (Dijkstra 1972):\n\u201cTesting can only show the presence of errors, not their absence\u200a\n\u2020\u201d\nTesting is part of a broader process of software verification and validation (V & V). \nVerification and validation are not the same thing, although they are often \u00ad\nconfused. \nBarry Boehm, a pioneer of software engineering, succinctly expressed the difference \nbetween them (Boehm 1979):\n\u2020Dijkstra, E. W. 1972. \u201cThe Humble Programmer.\u201d Comm. ACM 15 (10): 859\u201366. doi:10.1145/ \n355604.361591\n", "page": 228, "type": "text", "section": "Page 228"}
{"text": "228\u2002 \u2002 Chapter 8\u2002 \u25a0\u2002 Software testing\n\u25a0\t Validation: Are we building the right product?\n\u25a0\t Verification: Are we building the product right?\nVerification and validation processes are concerned with checking that software \nbeing developed meets its specification and delivers the functionality expected by \nthe people paying for the software. These checking processes start as soon as require-\nments become available and continue through all stages of the development process.\nSoftware verification is the process of checking that the software meets its stated \nfunctional and non-functional requirements. Validation is a more general process. \nThe aim of software validation is to ensure that the software meets the customer\u2019s \nexpectations. It goes beyond checking conformance with the specification to demon-\nstrating that the software does what the customer expects it to do. Validation is \nessential because, as I discussed in Chapter 4, statements of requirements do not \nalways reflect the real wishes or needs of system customers and users.\nThe goal of verification and validation processes is to establish confidence that \nthe software system is \u201cfit for purpose.\u201d This means that the system must be good \nenough for its intended use. The level of required confidence depends on the sys-\ntem\u2019s purpose, the expectations of the system users, and the current marketing \nenvironment for the system:\n1.\t\nSoftware purpose The more critical the software, the more important it is that it \nis reliable. For example, the level of confidence required for software used to \ncontrol a safety-critical system is much higher than that required for a demon-\nstrator system that prototypes new product ideas.\n2.\t\nUser expectations Because of their previous experiences with buggy, unreliable \nsoftware, users sometimes have low expectations of software quality. They are \nnot surprised when their software fails. When a new system is installed, users \nIe\nInput test data\nOe\nOutput test results\nSystem\nInputs causing\nanomalous\nbehavior\nOutputs which reveal\nthe presence of\ndefects\nFigure 8.1\u2002 An input\u2013\noutput model of \nprogram testing\n", "page": 229, "type": "text", "section": "Page 229"}
{"text": " \nChapter 8\u2002 \u25a0\u2002 Software testing\u2002 \u2002 229\nmay tolerate failures because the benefits of use outweigh the costs of failure \nrecovery. However, as a software product becomes more established, users \nexpect it to become more reliable. Consequently, more thorough testing of later \nversions of the system may be required.\n3.\t\nMarketing environment When a software company brings a system to market, it \nmust take into account competing products, the price that customers are willing \nto pay for a system, and the required schedule for delivering that system. In a \ncompetitive environment, the company may decide to release a program before \nit has been fully tested and debugged because it wants to be the first into the \nmarket. If a software product or app is very cheap, users may be willing to toler-\nate a lower level of reliability.\nAs well as software testing, the verification and validation process may involve \nsoftware inspections and reviews. Inspections and reviews analyze and check the \nsystem requirements, design models, the program source code, and even proposed \nsystem tests. These are \u201cstatic\u201d V & V techniques in which you don\u2019t need to execute \nthe software to verify it. Figure 8.2 shows that software inspections and testing sup-\nport V & V at different stages in the software process. The arrows indicate the stages \nin the process where the techniques may be used.\nInspections mostly focus on the source code of a system, but any readable repre-\nsentation of the software, such as its requirements or a design model, can be \ninspected. When you inspect a system, you use knowledge of the system, its \u00ad\napplication \ndomain, and the programming or modeling language to discover errors.\nSoftware inspection has three advantages over testing:\n1.\t During testing, errors can mask (hide) other errors. When an error leads to \nunexpected outputs, you can never be sure if later output anomalies are due to \na new error or are side effects of the original error. Because inspection doesn\u2019t \ninvolve executing the system, you don\u2019t have to worry about interactions \nbetween errors. Consequently, a single inspection session can discover many \nerrors in a system.\nUML design\nmodels\nSoftware\narchitecture\nRequirements\nspecification\nDatabase\nschemas\nProgram\nSystem\nprototype\nTesting\nInspections\nFigure 8.2\u2002 Inspections \nand testing \n", "page": 230, "type": "text", "section": "Page 230"}
{"text": "230\u2002 \u2002 Chapter 8\u2002 \u25a0\u2002 Software testing\n2.\t Incomplete versions of a system can be inspected without additional costs. If \na program is incomplete, then you need to develop specialized test harnesses \nto test the parts that are available. This obviously adds to the system develop-\nment costs.\n3.\t\nAs well as searching for program defects, an inspection can also consider \nbroader quality attributes of a program, such as compliance with standards, \nportability, and maintainability. You can look for inefficiencies, inappropriate \nalgorithms, and poor programming style that could make the system difficult to \nmaintain and update.\nProgram inspections are an old idea, and several studies and experiments have \nshown that inspections are more effective for defect discovery than program testing. \nFagan (Fagan 1976) reported that more than 60% of the errors in a program can be \ndetected using informal program inspections. In the Cleanroom process (Prowell et \nal. 1999), it is claimed that more than 90% of defects can be discovered in program \ninspections.\nHowever, inspections cannot replace software testing. Inspections are not good \nfor discovering defects that arise because of unexpected interactions between differ-\nent parts of a program, timing problems, or problems with system performance. In \nsmall companies or development groups, it can be difficult and expensive to put \ntogether a separate inspection team as all potential team members may also be \ndevelopers of the software.\nI discuss reviews and inspections in more detail in Chapter 24 (Quality \nManagement). Static analysis, where the source text of a program is automatically \nanalyzed to discover anomalies, is explained in Chapter 12. In this chapter, I focus \non testing and testing processes.\nFigure 8.3 is an abstract model of the traditional testing process, as used in plan-\ndriven development. Test cases are specifications of the inputs to the test and the \nexpected output from the system (the test results), plus a statement of what is being \ntested. Test data are the inputs that have been devised to test a system. Test data can \nsometimes be generated automatically, but automatic test case generation is impos-\nsible. People who understand what the system is supposed to do must be involved to \nspecify the expected test results. However, test execution can be automated. The test \nresults are automatically compared with the predicted results, so there is no need for \na person to look for errors and anomalies in the test run.\nDesign test\ncases\nPrepare test\ndata\nRun program\nwith test data\nCompare results\nto test cases\nT\nest\ncases\nT\nest\ndata\nT\nest\nresults\nT\nest\nreports\nFigure 8.3\u2002 A model \nof\u00a0the software \ntesting process\n", "page": 231, "type": "text", "section": "Page 231"}
{"text": " \n8.1\u2002 \u25a0\u2002 Development testing\u2002 \u2002 231\nTypically, a commercial software system has to go through three stages of testing:\n1.\t\nDevelopment testing, where the system is tested during development to discover \nbugs and defects. System designers and programmers are likely to be involved \nin the testing process.\n2.\t\nRelease testing, where a separate testing team tests a complete version of the \nsystem before it is released to users. The aim of release testing is to check that \nthe system meets the requirements of the system stakeholders.\n3.\t\nUser testing, where users or potential users of a system test the system in their \nown environment. For software products, the \u201cuser\u201d may be an internal market-\ning group that decides if the software can be marketed, released and sold. \nAcceptance testing is one type of user testing where the customer formally tests \na system to decide if it should be accepted from the system supplier or if further \ndevelopment is required.\nIn practice, the testing process usually involves a mixture of manual and auto-\nmated testing. In manual testing, a tester runs the program with some test data and \ncompares the results to their expectations. They note and report discrepancies to the \nprogram developers. In automated testing, the tests are encoded in a program that is \nrun each time the system under development is to be tested. This is faster than man-\nual testing, especially when it involves regression testing\u2014re-running previous tests \nto check that changes to the program have not introduced new bugs.\nUnfortunately, testing can never be completely automated as automated tests can \nonly check that a program does what it is supposed to do. It is practically impossible \nto use automated testing to test systems that depend on how things look (e.g., a graph-\nical user interface), or to test that a program does not have unanticipated side effects.\n \n8.1  Development testing\nDevelopment testing includes all testing activities that are carried out by the team \ndeveloping the system. The tester of the software is usually the programmer who \ndeveloped that software. Some development processes use programmer/tester pairs \n(Cusamano and Selby 1998) where each programmer has an associated tester who \nTest planning\nTest planning is concerned with scheduling and resourcing all of the activities in the testing process. It involves \ndefining the testing process, taking into account the people and the time available. Usually, a test plan will be \ncreated that defines what is to be tested, the predicted testing schedule, and how tests will be recorded. For \ncritical systems, the test plan may also include details of the tests to be run on the software.\nhttp://software-engineering-book.com/web/test-planning/\n", "page": 232, "type": "text", "section": "Page 232"}
{"text": "232\u2002 \u2002 Chapter 8\u2002 \u25a0\u2002 Software testing\ndevelops tests and assists with the testing process. For critical systems, a more for-\nmal process may be used, with a separate testing group within the development team. \nThis group is responsible for developing tests and maintaining detailed records of \ntest results.\nThere are three stages of development testing:\n1.\t\nUnit testing, where individual program units or object classes are tested. Unit \ntesting should focus on testing the functionality of objects or methods.\n2.\t\nComponent testing, where several individual units are integrated to create com-\nposite components. Component testing should focus on testing the component \ninterfaces that provide access to the component functions.\n3.\t\nSystem testing, where some or all of the components in a system are integrated \nand the system is tested as a whole. System testing should focus on testing com-\nponent interactions.\nDevelopment testing is primarily a defect testing process, where the aim of test-\ning is to discover bugs in the software. It is therefore usually interleaved with \ndebugging\u2014the process of locating problems with the code and changing the pro-\ngram to fix these problems.\n\t\n8.1.1 \t Unit testing\nUnit testing is the process of testing program components, such as methods or object \nclasses. Individual functions or methods are the simplest type of component. Your \ntests should be calls to these routines with different input parameters. You can use \nthe approaches to test-case design discussed in Section 8.1.2 to design the function \nor method tests.\nWhen you are testing object classes, you should design your tests to provide cov-\nerage of all of the features of the object. This means that you should test all opera-\ntions associated with the object; set and check the value of all attributes associated \nwith the object; and put the object into all possible states. This means that you should \nsimulate all events that cause a state change.\nConsider, for example, the weather station object from the example that I discussed \nin Chapter 7. The attributes and operations of this object are shown in Figure 8.4. \nDebugging\nDebugging is the process of fixing errors and problems that have been discovered by testing. Using information \nfrom the program tests, debuggers use their knowledge of the programming language and the intended out-\ncome of the test to locate and repair the program error. When you are debugging a program, you usually use \ninteractive tools that provide extra information about program execution.\nhttp://software-engineering-book.com/web/debugging/\n", "page": 233, "type": "text", "section": "Page 233"}
{"text": " \n8.1\u2002 \u25a0\u2002 Development testing\u2002 \u2002 233\nIt\u00a0has a single attribute, which is its identifier. This is a constant that is set when the \nweather station is installed. You therefore only need a test that checks if it has been \nproperly set up. You need to define test cases for all of the methods associated with the \nobject such as reportWeather and reportStatus. Ideally, you should test methods in \nisolation, but, in some cases, test sequences are necessary. For example, to test the \nmethod that shuts down the weather station instruments (shutdown), you need to have \nexecuted the restart method.\nGeneralization or inheritance makes object class testing more complicated. You \ncan\u2019t simply test an operation in the class where it is defined and assume that it will \nwork as expected in all of the subclasses that inherit the operation. The operation that \nis inherited may make assumptions about other operations and attributes. These \nassumptions may not be valid in some subclasses that inherit the operation. You \ntherefore have to test the inherited operation everywhere that it is used.\nTo test the states of the weather station, you can use a state model as discussed in \nChapter 7 (Figure 7.8). Using this model, you identify sequences of state transitions \nthat have to be tested and define event sequences to force these transitions. In princi-\nple, you should test every possible state transition sequence, although in practice this \nmay be too expensive. Examples of state sequences that should be tested in the \nweather station include:\nShutdown \u2192 Running \u2192 Shutdown\nConfiguring \u2192 Running \u2192 Testing \u2192 Transmitting \u2192 Running\nRunning \u2192 Collecting \u2192 Running \u2192 Summarizing \u2192 Transmitting \u2192 Running\nWhenever possible, you should automate unit testing. In automated unit testing, you \nmake use of a test automation framework, such as JUnit (Tahchiev et al. 2010) to write \nand run your program tests. Unit testing frameworks provide generic test classes that \nyou extend to create specific test cases. They can then run all of the tests that you have \nimplemented and report, often through some graphical unit interface (GUI), on the suc-\ncess or otherwise of the tests. An entire test suite can often be run in a few seconds, so it \nis possible to execute all tests every time you make a change to the program.\nAn automated test has three parts:\n1.\t\nA setup part, where you initialize the system with the test case, namely, the \ninputs and expected outputs.\nidentifier\nreportWeather ( )\nreportStatus ( )\npowerSave (instruments)\nremoteControl (commands)\nreconfigure (commands)\nrestart (instruments)\nshutdown (instruments)\nWeatherStation\nFigure 8.4\u2002 The weather \nstation object interface\n", "page": 234, "type": "text", "section": "Page 234"}
{"text": "234\u2002 \u2002 Chapter 8\u2002 \u25a0\u2002 Software testing\n2.\t\nA call part, where you call the object or method to be tested.\n3.\t\nAn assertion part, where you compare the result of the call with the expected \nresult. If the assertion evaluates to true, the test has been successful; if false, \nthen it has failed.\nSometimes, the object that you are testing has dependencies on other objects that \nmay not have been implemented or whose use slows down the testing process. For \nexample, if an object calls a database, this may involve a slow setup process before \nit can be used. In such cases, you may decide to use mock objects.\nMock objects are objects with the same interface as the external objects being \nused that simulate its functionality. For example, a mock object simulating a data-\nbase may have only a few data items that are organized in an array. They can be \naccessed quickly, without the overheads of calling a database and accessing disks. \nSimilarly, mock objects can be used to simulate abnormal operations or rare \nevents. For example, if your system is intended to take action at certain times of \nday, your mock object can simply return those times, irrespective of the actual \nclock time.\n\t\n8.1.2 \t Choosing unit test cases\nTesting is expensive and time consuming, so it is important that you choose effective \nunit test cases. Effectiveness, in this case, means two things:\n1.\t\nThe test cases should show that, when used as expected, the component that you \nare testing does what it is supposed to do.\n2.\t\nIf there are defects in the component, these should be revealed by test cases.\nYou should therefore design two kinds of test case. The first of these should \nreflect normal operation of a program and should show that the component works. \nFor example, if you are testing a component that creates and initializes a new patient \nrecord, then your test case should show that the record exists in a database and that \nits fields have been set as specified. The other kind of test case should be based on \ntesting experience of where common problems arise. It should use abnormal inputs \nto check that these are properly processed and do not crash the component.\nTwo strategies that can be effective in helping you choose test cases are:\n1.\t\nPartition testing, where you identify groups of inputs that have common charac-\nteristics and should be processed in the same way. You should choose tests from \nwithin each of these groups.\n2.\t\nGuideline-based testing, where you use testing guidelines to choose test cases. \nThese guidelines reflect previous experience of the kinds of errors that program-\nmers often make when developing components.\n", "page": 235, "type": "text", "section": "Page 235"}
{"text": " \n8.1\u2002 \u25a0\u2002 Development testing\u2002 \u2002 235\nThe input data and output results of a program can be thought of as members of \nsets with common characteristics. Examples of these sets are positive numbers, negative \nnumbers, and menu selections. Programs normally behave in a comparable way for \nall members of a set. That is, if you test a program that does a computation and \nrequires two positive numbers, then you would expect the program to behave in the \nsame way for all positive numbers.\nBecause of this equivalent behavior, these classes are sometimes called equiva-\nlence partitions or domains (Bezier 1990). One systematic approach to test-case \ndesign is based on identifying all input and output partitions for a system or compo-\nnent. Test cases are designed so that the inputs or outputs lie within these partitions. \nPartition testing can be used to design test cases for both systems and components.\nIn Figure 8.5, the large shaded ellipse on the left represents the set of all possible \ninputs to the program that is being tested. The smaller unshaded ellipses represent \nequivalence partitions. A program being tested should process all of the members of \nan input equivalence partition in the same way.\nOutput equivalence partitions are partitions within which all of the outputs have \nsomething in common. Sometimes there is a 1:1 mapping between input and output \nequivalence partitions. However, this is not always the case; you may need to define \na separate input equivalence partition, where the only common characteristic of the \ninputs is that they generate outputs within the same output partition. The shaded area \nin the left ellipse represents inputs that are invalid. The shaded area in the right \nellipse represents exceptions that may occur, that is, responses to invalid inputs.\nOnce you have identified a set of partitions, you choose test cases from each of \nthese partitions. A good rule of thumb for test-case selection is to choose test cases \non the boundaries of the partitions, plus cases close to the midpoint of the partition. \nThe reason for this is that designers and programmers tend to consider typical values \nof inputs when developing a system. You test these by choosing the midpoint of the \npartition. Boundary values are often atypical (e.g., zero may behave differently from \nother non-negative numbers) and so are sometimes overlooked by developers. \nProgram failures often occur when processing these atypical values.\nSystem\nPossible inputs\nInput equivalence partitions\nPossible outputs\nCorrect outputs\nOutput partitions\nFigure 8.5\u2002 Equivalence \npartitioning \n", "page": 236, "type": "text", "section": "Page 236"}
{"text": "236\u2002 \u2002 Chapter 8\u2002 \u25a0\u2002 Software testing\nYou identify partitions by using the program specification or user documentation and \nfrom experience where you predict the classes of input value that are likely to detect \nerrors. For example, say a program specification states that the program accepts four to \neight inputs which are five-digit integers greater than 10,000. You use this information to \nidentify the input partitions and possible test input values. These are shown in Figure 8.6.\nWhen you use the specification of a system to identify equivalence partitions, this \nis called black-box testing. You don\u2019t need any knowledge of how the system works. \nIt is sometimes useful to supplement the black-box tests with \u201cwhite-box testing,\u201d \nwhere you look at the code of the program to find other possible tests. For example, \nyour code may include exceptions to handle incorrect inputs. You can use this \nknowledge to identify \u201cexception partitions\u201d\u2014different ranges where the same \nexception handling should be applied.\nEquivalence partitioning is an effective approach to testing because it helps \naccount for errors that programmers often make when processing inputs at the edges \nof partitions. You can also use testing guidelines to help choose test cases. Guidelines \nencapsulate knowledge of what kinds of test cases are effective for discovering \nerrors. For example, when you are testing programs with sequences, arrays, or lists, \nguidelines that could help reveal defects include:\n1.\t\nTest software with sequences that have only a single value. Programmers natu-\nrally think of sequences as made up of several values, and sometimes they \nembed this assumption in their programs. Consequently, if presented with a \nsingle-value sequence, a program may not work properly.\n2.\t\nUse different sequences of different sizes in different tests. This decreases the \nchances that a program with defects will accidentally produce a correct output \nbecause of some accidental characteristics of the input.\n3.\t\nDerive tests so that the first, middle, and last elements of the sequence are \naccessed. This approach reveals problems at partition boundaries.\nBetween 10000 and 99999\nLess than 10000\nMore than 99999\n9999\n10000\n50000\n100000\n99999\nInput values\nBetween 4 and 10\nLess than 4\nMore than 10\n3\n4\n7\n11\n10\nNumber of input values\nFigure 8.6\u2002 Equivalence \npartitions \n", "page": 237, "type": "text", "section": "Page 237"}
{"text": " \n8.1\u2002 \u25a0\u2002 Development testing\u2002 \u2002 237\nWhittaker\u2019s book (Whittaker 2009) includes many examples of guidelines that \ncan be used in test-case design. Some of the most general guidelines that he suggests are:\n\u25a0\t Choose inputs that force the system to generate all error messages:\n\u25a0\t Design inputs that cause input buffers to overflow.\n\u25a0\t Repeat the same input or series of inputs numerous times.\n\u25a0\t Force invalid outputs to be generated.\n\u25a0\t Force computation results to be too large or too small.\nAs you gain experience with testing, you can develop your own guidelines about \nhow to choose effective test cases. I give more examples of testing guidelines in the \nnext section.\n\t\n8.1.3 \t Component testing\nSoftware components are often made up of several interacting objects. For example, \nin the weather station system, the reconfiguration component includes objects that \ndeal with each aspect of the reconfiguration. You access the functionality of these \nobjects through component interfaces (see Chapter 7). Testing composite components \nshould therefore focus on showing that the component interface or interfaces behave \naccording to its specification. You can assume that unit tests on the individual objects \nwithin the component have been completed.\nFigure 8.7 illustrates the idea of component interface testing. Assume that compo-\nnents A, B, and C have been integrated to create a larger component or subsystem. \nThe test cases are not applied to the individual components but rather to the interface \nof the composite component created by combining these components. Interface errors \nin the composite component may not be detectable by testing the individual objects \nbecause these errors result from interactions between the objects in the component.\nThere are different types of interface between program components and, conse-\nquently, different types of interface error that can occur:\n1.\t\nParameter interfaces These are interfaces in which data or sometimes function \nreferences are passed from one component to another. Methods in an object \nhave a parameter interface.\nPath testing\nPath testing is a testing strategy that aims to exercise every independent execution path through a component \nor program. If every independent path is executed, then all statements in the component must have been exe-\ncuted at least once. All conditional statements are tested for both true and false cases. In an object-oriented \ndevelopment process, path testing may be used to test the methods associated with objects.\nhttp://software-engineering-book.com/web/path-testing/\n", "page": 238, "type": "text", "section": "Page 238"}
{"text": "238\u2002 \u2002 Chapter 8\u2002 \u25a0\u2002 Software testing\n2.\t\nShared memory interfaces These are interfaces in which a block of memory is \nshared between components. Data is placed in the memory by one subsystem \nand retrieved from there by other subsystems. This type of interface is used in \nembedded systems, where sensors create data that is retrieved and processed by \nother system components.\n3.\t\nProcedural interfaces These are interfaces in which one component encapsu-\nlates a set of procedures that can be called by other components. Objects and \nreusable components have this form of interface.\n4.\t\nMessage passing interfaces These are interfaces in which one component \nrequests a service from another component by passing a message to it. A return \nmessage includes the results of executing the service. Some object-oriented sys-\ntems have this form of interface, as do client\u2013server systems.\nInterface errors are one of the most common forms of error in complex systems \n(Lutz 1993). These errors fall into three classes:\n\u25a0\t Interface misuse A calling component calls some other component and makes an \nerror in the use of its interface. This type of error is common in parameter inter-\nfaces, where parameters may be of the wrong type or be passed in the wrong \norder, or the wrong number of parameters may be passed.\n\u25a0\t Interface misunderstanding A calling component misunderstands the specification \nof the interface of the called component and makes assumptions about its behavior. \nThe called component does not behave as expected, which then causes unexpected \nbehavior in the calling component. For example, a binary search method may be \ncalled with a parameter that is an unordered array. The search would then fail.\n\u25a0\t Timing errors These occur in real-time systems that use a shared memory or a \nmessage-passing interface. The producer of data and the consumer of data may \nB\nC\nT\nest\ncases\nA\nFigure 8.7\u2002 Interface \ntesting \n", "page": 239, "type": "text", "section": "Page 239"}
{"text": " \n8.1\u2002 \u25a0\u2002 Development testing\u2002 \u2002 239\noperate at different speeds. Unless particular care is taken in the interface design, \nthe consumer can access out-of-date information because the producer of the \ninformation has not updated the shared interface information.\nTesting for interface defects is difficult because some interface faults may only \nmanifest themselves under unusual conditions. For example, say an object imple-\nments a queue as a fixed-length data structure. A calling object may assume that the \nqueue is implemented as an infinite data structure, and so it does not check for queue \noverflow when an item is entered.\nThis condition can only be detected during testing by designing a sequence of test \ncases that force the queue to overflow. The tests should check how calling objects \nhandle that overflow. However, as this is a rare condition, testers may think that this \nisn\u2019t worth checking when writing the test set for the queue object.\nA further problem may arise because of interactions between faults in different \nmodules or objects. Faults in one object may only be detected when some other \nobject behaves in an unexpected way. Say an object calls another object to receive \nsome service and the calling object assumes that the response is correct. If the called \nservice is faulty in some way, the returned value may be valid but incorrect. The \nproblem is therefore not immediately detectable but only becomes obvious when \nsome later computation, using the returned value, goes wrong.\nSome general guidelines for interface testing are:\n1.\t\nExamine the code to be tested and identify each call to an external component. \nDesign a set of tests in which the values of the parameters to the external com-\nponents are at the extreme ends of their ranges. These extreme values are most \nlikely to reveal interface inconsistencies.\n2.\t\nWhere pointers are passed across an interface, always test the interface with null \npointer parameters.\n3.\t\nWhere a component is called through a procedural interface, design tests that \ndeliberately cause the component to fail. Differing failure assumptions are one \nof the most common specification misunderstandings.\n4.\t\nUse stress testing in message passing systems. This means that you should \ndesign tests that generate many more messages than are likely to occur in prac-\ntice. This is an effective way of revealing timing problems.\n5.\t\nWhere several components interact through shared memory, design tests that \nvary the order in which these components are activated. These tests may reveal \nimplicit assumptions made by the programmer about the order in which the \nshared data is produced and consumed.\nSometimes it is better to use inspections and reviews rather than testing to look \nfor interface errors. Inspections can concentrate on component interfaces and ques-\ntions about the assumed interface behavior asked during the inspection process.\n", "page": 240, "type": "text", "section": "Page 240"}
{"text": "240\u2002 \u2002 Chapter 8\u2002 \u25a0\u2002 Software testing\n\t\n8.1.4 \t System testing\nSystem testing during development involves integrating components to create a ver-\nsion of the system and then testing the integrated system. System testing checks that \ncomponents are compatible, interact correctly, and transfer the right data at the right \ntime across their interfaces. It obviously overlaps with component testing, but there \nare two important differences:\n1.\t\nDuring system testing, reusable components that have been separately developed \nand off-the-shelf systems may be integrated with newly developed components. \nThe complete system is then tested.\n2.\t\nComponents developed by different team members or subteams may be integrated \nat this stage. System testing is a collective rather than an individual process. In \nsome companies, system testing may involve a separate testing team with no \ninvolvement from designers and programmers.\nAll systems have emergent behavior. This means that some system functionality \nand characteristics only become obvious when you put the components together. \nThis may be planned emergent behavior, which has to be tested. For example, you \nmay integrate an authentication component with a component that updates the sys-\ntem database. You then have a system feature that restricts information updating to \nauthorized users. Sometimes, however, the emergent behavior is unplanned and \nunwanted. You have to develop tests that check that the system is only doing what it \nis supposed to do.\nSystem testing should focus on testing the interactions between the components \nand objects that make up a system. You may also test reusable components or sys-\ntems to check that they work as expected when they are integrated with new compo-\nnents. This interaction testing should discover those component bugs that are only \nrevealed when a component is used by other components in the system. Interaction \ntesting also helps find misunderstandings, made by component developers, about \nother components in the system.\nBecause of its focus on interactions, use case-based testing is an effective \napproach to system testing. Several components or objects normally implement each \nuse case in the system. Testing the use case forces these interactions to occur. If you \nhave developed a sequence diagram to model the use case implementation, you can \nsee the objects or components that are involved in the interaction.\nIn the wilderness weather station example, the system software reports summa-\nrized weather data to a remote computeras described in Figure 7.3. Figure 8.8 shows \nthe sequence of operations in the weather station when it responds to a request to col-\nlect data for the mapping system. You can use this diagram to identify operations that \nwill be tested and to help design the test cases to execute the tests. Therefore issuing \na request for a report will result in the execution of the following thread of methods:\nSatComms:request \n\u2192 \nWeatherStation:reportWeather \n\u2192 \nCommslink:Get(summary) \n\u2192 WeatherData:summarize\n", "page": 241, "type": "text", "section": "Page 241"}
{"text": " \n8.1\u2002 \u25a0\u2002 Development testing\u2002 \u2002 241\nThe sequence diagram helps you design the specific test cases that you need, as it \nshows what inputs are required and what outputs are created:\n1.\t\nAn input of a request for a report should have an associated acknowledgment. \nA\u00a0report should ultimately be returned from the request. During testing, you \nshould create summarized data that can be used to check that the report is cor-\nrectly organized.\n2.\t\nAn input request for a report to WeatherStation results in a summarized report \nbeing generated. You can test this in isolation by creating raw data correspond-\ning to the summary that you have prepared for the test of SatComms and check-\ning that the WeatherStation object correctly produces this summary. This raw \ndata is also used to test the WeatherData object.\nOf course, I have simplified the sequence diagram in Figure 8.8 so that it does not \nshow exceptions. A complete use case/scenario test must take these exceptions into \naccount and ensure that they are correctly handled.\nFor most systems, it is difficult to know how much system testing is essential and \nwhen you should stop testing. Exhaustive testing, where every possible program \nexecution sequence is tested, is impossible. Testing, therefore, has to be based on a \nsubset of possible test cases. Ideally, software companies should have policies for \nchoosing this subset. These policies might be based on general testing policies, such \nas a policy that all program statements should be executed at least once. Alternatively, \nthey may be based on experience of system usage and focus on testing the features of \nthe operational system. For example:\nSatComms\nrequest (report)\nacknowledge\nreportWeather ()\nget (summary)\nreply (report)\nacknowledge\nWeatherStation\nCommslink\nsummarise ()\nWeatherData\nacknowledge\nsend (report)\nacknowledge\nWeather\ninformation system\nFigure 8.8\u2002 Collect \nweather data \nsequence chart \n", "page": 242, "type": "text", "section": "Page 242"}
{"text": "242\u2002 \u2002 Chapter 8\u2002 \u25a0\u2002 Software testing\n1.\t\nAll system functions that are accessed through menus should be tested.\n2.\t\nCombinations of functions (e.g., text formatting) that are accessed through the \nsame menu must be tested.\n3.\t\nWhere user input is provided, all functions must be tested with both correct and \nincorrect input.\nIt is clear from experience with major software products such as word processors \nor spreadsheets that similar guidelines are normally used during product testing. \nWhen features of the software are used in isolation, they normally work. Problems \narise, as Whittaker explains (Whittaker 2009), when combinations of less com-\nmonly used features have not been tested together. He gives the example of how, in \na commonly used word processor, using footnotes with multicolumn layout causes \nincorrect layout of the text.\nAutomated system testing is usually more difficult than automated unit or compo-\nnent testing. Automated unit testing relies on predicting the outputs and then \u00ad\nencoding \nthese predictions in a program. The prediction is then compared with the result. \nHowever, the point of implementing a system may be to generate outputs that are \nlarge or cannot be easily predicted. You may be able to examine an output and check \nits credibility without necessarily being able to create it in advance.\n \n8.2  Test-driven development\nTest-driven development (TDD) is an approach to program development in which \nyou interleave testing and code development (Beck 2002; Jeffries and Melnik 2007). \nYou develop the code incrementally, along with a set of tests for that increment. You \ndon\u2019t start working on the next increment until the code that you have developed \npasses all of its tests. Test-driven development was introduced as part of the XP agile \ndevelopment method. However, it has now gained mainstream acceptance and may \nbe used in both agile and plan-based processes.\nIncremental integration and testing\nSystem testing involves integrating different components, then testing the integrated system that you have \n\u00ad\ncreated. You should always use an incremental approach to integration and testing where you integrate a \n\u00ad\ncomponent, test the system, integrate another component, test again, and so on. If problems occur, they are \nprobably due to interactions with the most recently integrated component.\nIncremental integration and testing is fundamental to agile methods, where regression tests are run every time \na new increment is integrated.\nhttp://software-engineering-book.com/web/integration/\n", "page": 243, "type": "text", "section": "Page 243"}
{"text": " \n8.2\u2002 \u25a0\u2002 Test-driven development\u2002 \u2002 243\nThe fundamental TDD process is shown in Figure 8.9. The steps in the process \nare as follows:\n1.\t\nYou start by identifying the increment of functionality that is required. This \nshould normally be small and implementable in a few lines of code.\n2.\t\nYou write a test for this functionality and implement it as an automated test. \nThis means that the test can be executed and will report whether or not it has \npassed or failed.\n3.\t\nYou then run the test, along with all other tests that have been implemented. \nInitially, you have not implemented the functionality so the new test will fail. \nThis is deliberate as it shows that the test adds something to the test set.\n4.\t\nYou then implement the functionality and re-run the test. This may involve \nrefactoring existing code to improve it and add new code to what\u2019s already there.\n5.\t\nOnce all tests run successfully, you move on to implementing the next chunk of \nfunctionality.\nAn automated testing environment, such as the JUnit environment that supports \nJava program testing (Tahchiev et al. 2010) is essential for TDD. As the code is \ndeveloped in very small increments, you have to be able to run every test each time \nthat you add functionality or refactor the program. Therefore, the tests are embedded \nin a separate program that runs the tests and invokes the system that is being tested. \nUsing this approach, you can run hundreds of separate tests in a few seconds.\nTest-driven development helps programmers clarify their ideas of what a code \nsegment is actually supposed to do. To write a test, you need to understand what is \nintended, as this understanding makes it easier to write the required code. Of course, \nif you have incomplete knowledge or understanding, then TDD won\u2019t help.\nIf you don\u2019t know enough to write the tests, you won\u2019t develop the required code. \nFor example, if your computation involves division, you should check that you are \nnot dividing the numbers by zero. If you forget to write a test for this, then the check-\ning code will never be included in the program.\nAs well as better problem understanding, other benefits of test-driven development are:\n1.\t\nCode coverage In principle, every code segment that you write should have at \nleast one associated test. Therefore, you can be confident that all of the code in \nIdentify new\nfunctionality\nWrite test\nRun test\nImplement\nfunctionality and\nrefactor\nfail\npass\nFigure 8.9\u2002 Test-driven \ndevelopment \n", "page": 244, "type": "text", "section": "Page 244"}
{"text": "244\u2002 \u2002 Chapter 8\u2002 \u25a0\u2002 Software testing\nthe system has actually been executed. Code is tested as it is written, so defects \nare discovered early in the development process.\n2.\t\nRegression testing A test suite is developed incrementally as a program is devel-\noped. You can always run regression tests to check that changes to the program \nhave not introduced new bugs.\n3.\t Simplified debugging When a test fails, it should be obvious where the prob-\nlem lies. The newly written code needs to be checked and modified. You do \nnot need to use debugging tools to locate the problem. Reports of the use of \nTDD suggest that it is hardly ever necessary to use an automated debugger in \ntest-driven development (Martin 2007).\n4.\t\nSystem documentation The tests themselves act as a form of documentation that \ndescribe what the code should be doing. Reading the tests can make it easier to \nunderstand the code.\nOne of the most important benefits of TDD is that it reduces the costs of regres-\nsion testing. Regression testing involves running test sets that have successfully \nexecuted after changes have been made to a system. The regression test checks that \nthese changes have not introduced new bugs into the system and that the new code \ninteracts as expected with the existing code. Regression testing is expensive and \nsometimes impractical when a system is manually tested, as the costs in time and \neffort are very high. You have to try to choose the most relevant tests to re-run and it \nis easy to miss important tests.\nAutomated testing dramatically reduces the costs of regression testing. Existing \ntests may be re-run quickly and cheaply. After making a change to a system in test-\nfirst development, all existing tests must run successfully before any further func-\ntionality is added. As a programmer, you can be confident that the new functionality \nthat you have added has not caused or revealed problems with existing code.\nTest-driven development is of most value in new software development where \nthe functionality is either implemented in new code or by using components from \nstandard libraries. If you are reusing large code components or legacy systems, then \nyou need to write tests for these systems as a whole. You cannot easily decompose \nthem into separate testable elements. Incremental test-driven development is imprac-\ntical. Test-driven development may also be ineffective with multithreaded systems. \nThe different threads may be interleaved at different times in different test runs, and \nso may produce different results.\nIf you use TDD, you still need a system testing process to validate the system, \nthat is, to check that it meets the requirements of all of the system stakeholders. \nSystem testing also tests performance, reliability, and checks that the system does \nnot do things that it shouldn\u2019t do, such as produce unwanted outputs. Andrea (Andrea \n2007) suggests how testing tools can be extended to integrate some aspects of sys-\ntem testing with TDD.\nTest-driven development is now a widely used and mainstream approach to soft-\nware testing. Most programmers who have adopted this approach are happy with it \n", "page": 245, "type": "text", "section": "Page 245"}
{"text": "and find it a more productive way to develop software. It is also claimed that use of \nTDD encourages better structuring of a program and improved code quality. \nHowever, experiments to verify this claim have been inconclusive.\n \n8.3  Release testing\nRelease testing is the process of testing a particular release of a system that is intended \nfor use outside of the development team. Normally, the system release is for customers \nand users. In a complex project, however, the release could be for other teams that are \ndeveloping related systems. For software products, the release could be for product \nmanagement who then prepare it for sale.\nThere are two important distinctions between release testing and system testing \nduring the development process:\n1.\t\nThe system development, team should not be responsible for release testing.\n2.\t\nRelease testing is a process of validation checking to ensure that a system meets \nits requirements and is good enough for use by system customers. System test-\ning by the development team should focus on discovering bugs in the system \n(defect testing).\nThe primary goal of the release testing process is to convince the supplier of the \nsystem that it is good enough for use. If so, it can be released as a product or deliv-\nered to the customer. Release testing, therefore, has to show that the system delivers \nits specified functionality, performance, and dependability, and that it does not fail \nduring normal use.\nRelease testing is usually a black-box testing process whereby tests are derived \nfrom the system specification. The system is treated as a black box whose behavior \ncan only be determined by studying its inputs and the related outputs. Another name \nfor this is functional testing, so-called because the tester is only concerned with \nfunctionality and not the implementation of the software.\n\t\n8.3.1 \t Requirements-based testing\nA general principle of good requirements engineering practice is that require-\nments should be testable. That is, the requirement should be written so that a test \ncan be designed for that requirement. A tester can then check that the require-\nment has been satisfied. Requirements-based testing, therefore, is a systematic \napproach to test-case design where you consider each requirement and derive a \nset of tests for it. Requirements-based testing is validation rather than defect \ntesting\u2014you are trying to demonstrate that the system has properly implemented \nits requirements.\n \n8.3\u2002 \u25a0\u2002 Release testing\u2002 \u2002 245\n", "page": 246, "type": "text", "section": "Page 246"}
{"text": "246\u2002 \u2002 Chapter 8\u2002 \u25a0\u2002 Software testing\nFor example, consider the following Mentcare system requirements that are con-\ncerned with checking for drug allergies:\nIf a patient is known to be allergic to any particular medication, then prescrip-\ntion of that medication shall result in a warning message being issued to the \nsystem user.\nIf a prescriber chooses to ignore an allergy warning, he or she shall provide \na reason why this has been ignored.\nTo check if these requirements have been satisfied, you may need to develop sev-\neral related tests:\n1.\t\nSet up a patient record with no known allergies. Prescribe medication for aller-\ngies that are known to exist. Check that a warning message is not issued by the \nsystem.\n2.\t\nSet up a patient record with a known allergy. Prescribe the medication that the \npatient is allergic to and check that the warning is issued by the system.\n3.\t\nSet up a patient record in which allergies to two or more drugs are recorded. \nPrescribe both of these drugs separately and check that the correct warning for \neach drug is issued.\n4.\t\nPrescribe two drugs that the patient is allergic to. Check that two warnings are \ncorrectly issued.\n5.\t\nPrescribe a drug that issues a warning and overrule that warning. Check that the \nsystem requires the user to provide information explaining why the warning was \noverruled.\nYou can see from this list that testing a requirement does not mean just writing a \nsingle test. You normally have to write several tests to ensure that you have coverage \nof the requirement. You should also keep traceability records of your requirements-\nbased testing, which link the tests to the specific requirements that you have tested.\n\t\n8.3.2 \t Scenario testing\nScenario testing is an approach to release testing whereby you devise typical sce-\nnarios of use and use these scenarios to develop test cases for the system. A scenario \nis a story that describes one way in which the system might be used. Scenarios \nshould be realistic, and real system users should be able to relate to them. If you have \nused scenarios or user stories as part of the requirements engineering process \n(described in Chapter 4), then you may be able to reuse them as testing scenarios.\nIn a short paper on scenario testing, Kaner (Kaner 2003) suggests that a scenario \ntest should be a narrative story that is credible and fairly complex. It should moti-\nvate stakeholders; that is, they should relate to the scenario and believe that it is \n", "page": 247, "type": "text", "section": "Page 247"}
{"text": " \n8.3\u2002 \u25a0\u2002 Release testing\u2002 \u2002 247\nimportant that the system passes the test. He also suggests that it should be easy to \nevaluate. If\u00a0there are problems with the system, then the release testing team should \nrecognize them.\nAs an example of a possible scenario from the Mentcare system, Figure 8.10 \ndescribes one way that the system may be used on a home visit. This scenario tests a \nnumber of features of the Mentcare system:\n1.\t\nAuthentication by logging on to the system.\n2.\t\nDownloading and uploading of specified patient records to a laptop.\n3.\t\nHome visit scheduling.\n4.\t\nEncryption and decryption of patient records on a mobile device.\n5.\t\nRecord retrieval and modification.\n6.\t\nLinks with the drugs database that maintains side-effect information.\n7.\t\nThe system for call prompting.\nIf you are a release tester, you run through this scenario, playing the role of \nGeorge and observing how the system behaves in response to different inputs. As \nGeorge, you may make deliberate mistakes, such as inputting the wrong key phrase \nto decode records. This checks the response of the system to errors. You should care-\nfully note any problems that arise, including performance problems. If a system is \ntoo slow, this will change the way that it is used. For example, if it takes too long to \nencrypt a record, then users who are short of time may skip this stage. If they then \nlose their laptop, an unauthorized person could then view the patient records.\nWhen you use a scenario-based approach, you are normally testing several require-\nments within the same scenario. Therefore, as well as checking individual requirements, \nyou are also checking that combinations of requirements do not cause problems.\nGeorge is a nurse who specializes in mental health care. One of his responsibilities is to visit patients at home \nto check that their treatment is effective and that they are not suffering from medication side effects.\nOn a day for home visits, George logs into the Mentcare system and uses it to print his schedule of home \nvisits for that day, along with summary information about the patients to be visited. He requests that the records \nfor these patients be downloaded to his laptop. He is prompted for his key phrase to encrypt the records on the \nlaptop.\nOne of the patients whom he visits is Jim, who is being treated with medication for depression. Jim feels \nthat the medication is helping him but believes that it has the side effect of keeping him awake at night. George \nlooks up Jim\u2019s record and is prompted for his key phrase to decrypt the record. He checks the drug prescribed \nand queries its side effects. Sleeplessness is a known side effect, so he notes the problem in Jim\u2019s record and \nsuggests that he visit the clinic to have his medication changed. Jim agrees, so George enters a prompt to call \nhim when he gets back to the clinic to make an appointment with a physician. George ends the consultation, \nand the system re-encrypts Jim\u2019s record.\nAfter finishing his consultations, George returns to the clinic and uploads the records of patients visited to \nthe database. The system generates a call list for George of those patients whom he has to contact for follow-up \ninformation and make clinic appointments.\nFigure 8.10\u2002 A user \nstory\u00a0for the \nMentcare\u00a0system\n", "page": 248, "type": "text", "section": "Page 248"}
{"text": "248\u2002 \u2002 Chapter 8\u2002 \u25a0\u2002 Software testing\n\t\n8.3.3 \t Performance testing\nOnce a system has been completely integrated, it is possible to test for emergent \nproperties, such as performance and reliability. Performance tests have to be \ndesigned to ensure that the system can process its intended load. This usually \ninvolves running a series of tests where you increase the load until the system perfor-\nmance becomes unacceptable.\nAs with other types of testing, performance testing is concerned both with dem-\nonstrating that the system meets its requirements and discovering problems and \ndefects in the system. To test whether performance requirements are being achieved, \nyou may have to construct an operational profile. An operational profile (see Chapter 11) \nis a set of tests that reflect the actual mix of work that will be handled by the system. \nTherefore, if 90% of the transactions in a system are of type A, 5% of type B, and the \nremainder of types C, D, and E, then you have to design the operational profile so \nthat the vast majority of tests are of type A. Otherwise, you will not get an accurate \ntest of the operational performance of the system.\nThis approach, of course, is not necessarily the best approach for defect testing. \nExperience has shown that an effective way to discover defects is to design tests \naround the limits of the system. In performance testing, this means stressing the sys-\ntem by making demands that are outside the design limits of the software. This is \nknown as stress testing.\nSay you are testing a transaction processing system that is designed to process up \nto 300 transactions per second. You start by testing this system with fewer than \n300\u00a0transactions per second. You then gradually increase the load on the system \nbeyond 300 transactions per second until it is well beyond the maximum design load \nof the system and the system fails.\nStress testing helps you do two things:\n1.\t\nTest the failure behavior of the system. Circumstances may arise through an \nunexpected combination of events where the load placed on the system exceeds \nthe maximum anticipated load. In these circumstances, system failure should \nnot cause data corruption or unexpected loss of user services. Stress testing \nchecks that overloading the system causes it to \u201cfail-soft\u201d rather than collapse \nunder its load.\n2.\t\nReveal defects that only show up when the system is fully loaded. Although it can \nbe argued that these defects are unlikely to cause system failures in normal use, there \nmay be unusual combinations of circumstances that the stress testing replicates.\nStress testing is particularly relevant to distributed systems based on a network of \nprocessors. These systems often exhibit severe degradation when they are heavily \nloaded. The network becomes swamped with coordination data that the different \nprocesses must exchange. The processes become slower and slower as they wait for \nthe required data from other processes. Stress testing helps you discover when the \ndegradation begins so that you can add checks to the system to reject transactions \nbeyond this point.\n", "page": 249, "type": "text", "section": "Page 249"}
{"text": " \n8.4\u2002 \u25a0\u2002 User testing\u2002 \u2002 249\n \n8.4  User testing\nUser or customer testing is a stage in the testing process in which users or customers \nprovide input and advice on system testing. This may involve formally testing a sys-\ntem that has been commissioned from an external supplier. Alternatively, it may be \nan informal process where users experiment with a new software product to see if \nthey like it and to check that it does what they need. User testing is essential, even \nwhen comprehensive system and release testing have been carried out. Influences \nfrom the user\u2019s working environment can have a major effect on the reliability, per-\nformance, usability, and robustness of a system.\nIt is practically impossible for a system developer to replicate the system\u2019s work-\ning environment, as tests in the developer\u2019s environment are inevitably artificial. For \nexample, a system that is intended for use in a hospital is used in a clinical environ-\nment where other things are going on, such as patient emergencies and conversations \nwith relatives. These all affect the use of a system, but developers cannot include \nthem in their testing environment.\nThere are three different types of user testing:\n1.\t\nAlpha testing, where a selected group of software users work closely with the \ndevelopment team to test early releases of the software.\n2.\t\nBeta testing, where a release of the software is made available to a larger group \nof users to allow them to experiment and to raise problems that they discover \nwith the system developers.\n3.\t\nAcceptance testing, where customers test a system to decide whether or not it is ready \nto be accepted from the system developers and deployed in the customer environment.\nIn alpha testing, users and developers work together to test a system as it is being \ndeveloped. This means that the users can identify problems and issues that are not \nreadily apparent to the development testing team. Developers can only really work \nfrom the requirements, but these often do not reflect other factors that affect the \npractical use of the software. Users can therefore provide information about practice \nthat helps with the design of more realistic tests.\nAlpha testing is often used when developing software products or apps. Experienced \nusers of these products may be willing to get involved in the alpha testing process \nbecause this gives them early information about new system features that they can \nexploit. It also reduces the risk that unanticipated changes to the software will have \ndisruptive effects on their business. However, alpha testing may also be used when \ncustom software is being developed. Agile development methods advocate user \ninvolvement in the development process, and that users should play a key role in \ndesigning tests for the system.\nBeta testing takes place when an early, sometimes unfinished, release of a \u00ad\nsoftware \nsystem is made available to a larger group of customers and users for \u00ad\nevaluation. \nBeta testers may be a selected group of customers who are early adopters of the system. \n", "page": 250, "type": "text", "section": "Page 250"}
{"text": "250\u2002 \u2002 Chapter 8\u2002 \u25a0\u2002 Software testing\nAlternatively, the software may be made publicly available for use by anyone who is \ninterested in experimenting with it.\nBeta testing is mostly used for software products that are used in many different \nsettings. This is important as, unlike custom product developers, there is no way for \nthe product developer to limit the software\u2019s operating environment. It is impossible \nfor product developers to know and replicate all the settings in which the software \nproduct will be used. Beta testing is therefore used to discover interaction problems \nbetween the software and features of its operational environment. Beta testing is also \na form of marketing. Customers learn about their system and what it can do for them.\nAcceptance testing is an inherent part of custom systems development. Customers \ntest a system, using their own data, and decide if it should be accepted from the system \ndeveloper. Acceptance implies that final payment should be made for the software.\nFigure 8.11 shows that here are six stages in the acceptance testing process:\n1.\t\nDefine acceptance criteria This stage should ideally take place early in the pro-\ncess before the contract for the system is signed. The acceptance criteria should \nbe part of the system contract and be approved by the customer and the devel-\noper. In practice, however, it can be difficult to define criteria so early in the \nprocess. Detailed requirements may not be available, and the requirements will \nalmost certainly change during the development process.\n2.\t\nPlan acceptance testing This stage involves deciding on the resources, time, and \nbudget for acceptance testing and establishing a testing schedule. The accept-\nance test plan should also discuss the required coverage of the requirements and \nthe order in which system features are tested. It should define risks to the testing \nprocess such as system crashes and inadequate performance, and discuss how \nthese risks can be mitigated.\n3.\t\nDerive acceptance tests Once acceptance criteria have been established, tests \nhave to be designed to check whether or not a system is acceptable. Acceptance \ntests should aim to test both the functional and non-functional characteristics \n(e.g., performance) of the system. They should ideally provide complete cover-\nage of the system requirements. In practice, it is difficult to establish completely \nobjective acceptance criteria. There is often scope for argument about whether \nor not a test shows that a criterion has definitely been met.\n4.\t\nRun acceptance tests The agreed acceptance tests are executed on the system. \nIdeally, this step should take place in the actual environment where the system \nwill be used, but this may be disruptive and impractical. Therefore, a user \u00ad\ntesting \nDefine\nacceptance\ncriteria\nT\nest\ncriteria\nPlan\nacceptance\ntesting\nDerive\nacceptance\ntests\nRun\nacceptance\ntests\nNegotiate\ntest results\nAccept or\nreject\nsystem\nT\nest\nplan\nT\nests\nT\nest\nresults\nT\nesting\nreport\nFigure 8.11\u2002 The \nacceptance testing \nprocess \n", "page": 251, "type": "text", "section": "Page 251"}
{"text": " \n8.4\u2002 \u25a0\u2002 User testing\u2002 \u2002 251\nenvironment may have to be set up to run these tests. It is difficult to automate \nthis process as part of the acceptance tests may involve testing the interactions \nbetween end-users and the system. Some training of end-users may be required.\n5.\t\nNegotiate test results It is very unlikely that all of the defined acceptance tests \nwill pass and that there will be no problems with the system. If this is the case, \nthen acceptance testing is complete and the system can be handed over. More \ncommonly, some problems will be discovered. In such cases, the developer and \nthe customer have to negotiate to decide if the system is good enough to be used. \nThey must also agree on how the developer will fix the identified \u00ad\nproblems.\n6.\t\nReject/accept system This stage involves a meeting between the developers and \nthe customer to decide on whether or not the system should be accepted. If the \nsystem is not good enough for use, then further development is required to fix \nthe identified problems. Once complete, the acceptance testing phase is repeated.\nYou might think that acceptance testing is a clear-cut contractual issue. If a system \ndoes not pass its acceptance tests, then it should not be accepted and payment should \nnot be made. However, the reality is more complex. Customers want to use the soft-\nware as soon as they can because of the benefits of its immediate deployment. They \nmay have bought new hardware, trained staff, and changed their \u00ad\nprocesses. They may \nbe willing to accept the software, irrespective of problems, because the costs of not \nusing the software are greater than the costs of working around the problems.\nTherefore, the outcome of negotiations may be conditional acceptance of the sys-\ntem. The customer may accept the system so that deployment can begin. The system \nprovider agrees to repair urgent problems and deliver a new version to the customer \nas quickly as possible.\nIn agile methods such as Extreme Programming, there may be no separate accept-\nance testing activity. The end-user is part of the development team (i.e., he or she is \nan alpha tester) and provides the system requirements in terms of user stories. He or \nshe is also responsible for defining the tests, which decide whether or not the devel-\noped software supports the user stories. These tests are therefore equivalent to \nacceptance tests. The tests are automated, and development does not proceed until \nthe story acceptance tests have successfully been executed.\nWhen users are embedded in a software development team, they should ideally be \n\u201ctypical\u201d users with general knowledge of how the system will be used. However, it \ncan be difficult to find such users, and so the acceptance tests may actually not be a \ntrue reflection of how a system is used in practice. Furthermore, the requirement for \nautomated testing limits the flexibility of testing interactive systems. For such sys-\ntems, acceptance testing may require groups of end-users to use the system as if it \nwas part of their everyday work. Therefore, while an \u201cembedded user\u201d is an attrac-\ntive notion in principle, it does not necessarily lead to high-quality tests of the \u00ad\nsystem.\nThe problem of user involvement in agile teams is one reason why many compa-\nnies use a mix of agile and more traditional testing. The system may be developed \nusing agile techniques, but, after completion of a major release, separate acceptance \ntesting is used to decide if the system should be accepted.\n", "page": 252, "type": "text", "section": "Page 252"}
{"text": "252\u2002 \u2002 Chapter 8\u2002 \u25a0\u2002 Software testing\nKey Points\n\u25a0\t Testing can only show the presence of errors in a program. It cannot show that there are no \nremaining faults.\n\u25a0\t Development testing is the responsibility of the software development team. A separate team \nshould be responsible for testing a system before it is released to customers. In the user testing \nprocess, customers or system users provide test data and check that tests are successful.\n\u25a0\t Development testing includes unit testing in which you test individual objects and methods; \ncomponent testing in which you test related groups of objects; and system testing in which you \ntest partial or complete systems.\n\u25a0\t When testing software, you should try to \u201cbreak\u201d the software by using experience and \n\u00ad\nguidelines to choose types of test cases that have been effective in discovering defects in \nother\u00a0systems.\n\u25a0\t Wherever possible, you should write automated tests. The tests are embedded in a program \nthat can be run every time a change is made to a system.\n\u25a0\t Test-first development is an approach to development whereby tests are written before the code \nto be tested. Small code changes are made, and the code is refactored until all tests execute \nsuccessfully.\n\u25a0\t Scenario testing is useful because it replicates the practical use of the system. It involves \ninventing a typical usage scenario and using this to derive test cases.\n\u25a0\t Acceptance testing is a user testing process in which the aim is to decide if the software is good \nenough to be deployed and used in its planned operational environment.\nFurther Reading\n\u201cHow to design practical test cases.\u201d A how-to article on test-case design by an author from a \n\u00ad\nJapanese company that has a good reputation for delivering software with very few faults.  \n(T. Yamaura, IEEE Software, 15(6), November 1998) http://dx.doi.org/10.1109/52.730835.\n\u201cTest-driven development.\u201d This special issue on test-driven development includes a good general \noverview of TDD as well as experience papers on how TDD has been used for different types of \n\u00ad\nsoftware. (IEEE Software, 24 (3) May/June 2007).\nExploratory Software Testing. This is a practical, rather than theoretical, book on software testing \nwhich develops the ideas in Whittaker\u2019s earlier book, How to Break Software. The author presents a \nset of experience-based guidelines on software testing. (J. A. Whittaker, 2009, Addison-Wesley).\nHow Google Tests Software. This is a book about testing large-scale cloud-based systems and \nposes a whole set of new challenges compared to custom software applications. While I don\u2019t think \nthat the Google approach can be used directly, there are interesting lessons in this book for large-\nscale system testing. (J. Whittaker, J. Arbon, and J. Carollo, 2012, Addison-Wesley).\n252\u2002 \u2002 Chapter 8\u2002 \u25a0\u2002 Software testing\n", "page": 253, "type": "text", "section": "Page 253"}
{"text": " \nChapter 8\u2002 \u25a0\u2002 Software testing\u2002 \u2002 253\nWebsite\nPowerPoint slides for this chapter:\nwww.pearsonglobaleditions.com/Sommerville\nLinks to supporting videos:\nhttp://software-engineering-book.com/videos/implementation-and-evolution/\nExercises\n\u2002 8.1. \tExplain how the number of known defects remaining in a program at the time of delivery \naffects product support.\n\u2002 8.2. \tTesting is meant to show that a program does what it is intended to do. Why may testers not \nalways know what a program is intended for?\n\u2002 8.3. \tSome people argue that developers should not be involved in testing their own code but that \nall testing should be the responsibility of a separate team. Give arguments for and against \ntesting by the developers themselves.\n\u2002 \u200a\n\u200a\n8.4. \tYou have been asked to test a method called catWhiteSpace in a \u201cParagraph\u201d object that, within \nthe paragraph, replaces sequences of blank characters with a single blank character. Identify \ntesting partitions for this example and derive a set of tests for the catWhiteSpace method.\n\u2002 8.5. \tWhat is regression testing? Explain how the use of automated tests and a testing framework \nsuch as JUnit simplifies regression testing.\n\u2002 8.6. \tThe Mentcare system is constructed by adapting an off-the-shelf information system. What do \nyou think are the differences between testing such a system and testing software that is \ndeveloped using an object-oriented language such as Java?\n\u2002 \u200a\n\u200a\n\u200a\n8.7. \tWrite a scenario that could be used to help design tests for the wilderness weather station system.\n\u2002 8.8. \tWhat do you understand by the term stress testing? Suggest how you might stress-test the \nMentcare system.\n\u2002 8.9. \tWhat are the benefits of involving users in release testing at an early stage in the testing pro-\ncess? Are there disadvantages in user involvement?\n8.10. \tA common approach to system testing is to test the more important functionalities of a system \nfirst, followed by the less important functionalities until the testing budget is exhausted. Dis-\ncuss the ethics involved in identifying what \u201cmore important\u201d means.\n \nChapter 8\u2002 \u25a0\u2002 Exercises\u2002 \u2002 253\n", "page": 254, "type": "text", "section": "Page 254"}
{"text": "254\u2002 \u2002 Chapter 8\u2002 \u25a0\u2002 Software testing\nReferences\nAndrea, J. 2007. \u201cEnvisioning the Next Generation of Functional Testing Tools.\u201d IEEE Software 24 (3): \n58\u201365. doi:10.1109/MS.2007.73.\nBeck, K. 2002. Test Driven Development: By Example. Boston: Addison-Wesley.\nBezier, B. 1990. Software Testing Techniques, 2nd ed. New York: Van Nostrand Reinhold.\nBoehm, B. W. 1979. \u201cSoftware Engineering; R & D Trends and Defense Needs.\u201d In Research Directions \nin Software Technology, edited by P. Wegner, 1\u20139. Cambridge, MA: MIT Press.\nCusamano, M., and R. W. Selby. 1998. Microsoft Secrets. New York: Simon & Schuster.\nDijkstra, E. W. 1972. \u201cThe Humble Programmer.\u201d Comm. ACM 15 (10): 859\u2013866. \ndoi:10.1145/355604.361591.\nFagan, M. E. 1976. \u201cDesign and Code Inspections to Reduce Errors in Program Development.\u201d IBM \nSystems J. 15 (3): 182\u2013211.\nJeffries, R., and G. Melnik. 2007. \u201cTDD: The Art of Fearless Programming.\u201d IEEE Software 24: 24\u201330. \ndoi:10.1109/MS.2007.75.\nKaner, C. 2003. \u201cAn Introduction to Scenario Testing.\u201d Software Testing and Quality Engineering \n(October 2003).\nLutz, R. R. 1993. \u201cAnalysing Software Requirements Errors in Safety-Critical Embedded Systems.\u201d In \nRE\u201993, 126\u2013133. San Diego CA: IEEE. doi:0.1109/ISRE.1993.324825.\nMartin, R. C. 2007. \u201cProfessionalism and Test-Driven Development.\u201d IEEE Software 24 (3): 32\u201336. \ndoi:10.1109/MS.2007.85.\nProwell, S. J., C. J. Trammell, R. C. Linger, and J. H. Poore. 1999. Cleanroom Software Engineering: \nTechnology and Process. Reading, MA: Addison-Wesley.\nTahchiev, P., F. Leme, V. Massol, and G. Gregory. 2010. JUnit in Action, 2nd ed. Greenwich,  \nCT: \u00ad\nManning Publications.\nWhittaker, J. A. 2009. Exploratory Software Testing. Boston: Addison-Wesley.\n254\u2002 \u2002 Chapter 8\u2002 \u25a0\u2002 Software testing\n", "page": 255, "type": "text", "section": "Page 255"}
{"text": "Software evolution\n9\nObjectives\nThe objectives of this chapter are to explain why software evolution is \nsuch an important part of software engineering and to describe the \nchallenges of maintaining a large base of software systems, developed \nover many years. When you have read this chapter, you will:\n\u25a0\t understand that software systems have to adapt and evolve if they are \nto remain useful and that software change and evolution should be \nconsidered as an integral part of software engineering;\n\u25a0\t understand what is meant by legacy systems and why these systems \nare important to businesses;\n\u25a0\t understand how legacy systems can be assessed to decide whether \nthey should be scrapped, maintained, reengineered, or replaced;\n\u25a0\t have learned about different types of software maintenance and the \nfactors that affect the costs of making changes to legacy software \nsystems.\nContents\n9.1 \tEvolution processes\n9.2 \tLegacy systems\n9.3 \tSoftware maintenance\n", "page": 256, "type": "text", "section": "Page 256"}
{"text": "256\u2002 \u2002 Chapter 9\u2002 \u25a0\u2002 Software evolution\nLarge software systems usually have a long lifetime. For example, military or infra-\nstructure systems, such as air traffic control systems, may have a lifetime of 30 years or \nmore. Business systems are often more than 10 years old. Enterprise software costs a lot \nof money, so a company has to use a software system for many years to get a return on \nits investment. Successful software products and apps may have been introduced many \nyears ago with new versions released every few years. For example, the first version of \nMicrosoft Word was introduced in 1983, so it has been around for more than 30 years.\nDuring their lifetime, operational software systems have to change if they are \nto\u00a0emain useful. Business changes and changes to user expectations generate new \nrequirements for the software. Parts of the software may have to be modified to cor-\nrect errors that are found in operation, to adapt it for changes to its hardware and \nsoftware platform, and to improve its performance or other non-functional character-\nistics. Software products and apps have to evolve to cope with platform changes and \nnew features introduced by their competitors. Software systems, therefore, adapt and \nevolve during their lifetime from initial deployment to final retirement.\nBusinesses have to change their software to ensure that they continue to get value \nfrom it. Their systems are critical business assets, and they have to invest in change to \nmaintain the value of these assets. Consequently, most large companies spend more \non maintaining existing systems than on new systems development. Historical data \nsuggests that somewhere between 60% and 90% of software costs are evolution costs \n(Lientz and Swanson 1980; Erlikh 2000). Jones (Jones 2006) found that about 75% of \ndevelopment staff in the United States in 2006 were involved in software evolution \nand suggested that this percentage was unlikely to fall in the foreseeable future.\nSoftware evolution is particularly expensive in enterprise systems when individ-\nual software systems are part of a broader \u201csystem of systems.\u201d In such cases, you \ncannot just consider the changes to one system; you also need to examine how these \nchanges affect the broader system of systems. Changing one system may mean that \nother systems in its environment may also have to evolve to cope with that change.\nTherefore, as well as understanding and analyzing the impact of a proposed \nchange on the system itself, you also have to assess how this change may affect other \nsystems in the operational environment. Hopkins and Jenkins (Hopkins and Jenkins \n2008) have coined the term brownfield software development to describe situations \nin which software systems have to be developed and managed in an environment \nwhere they are dependent on other software systems.\nThe requirements of installed software systems change as the business and its \nenvironment change, so new releases of the systems that incorporate changes and \nupdates are usually created at regular intervals. Software engineering is therefore a \nspiral process with requirements, design, implementation, and testing going on \nthroughout the lifetime of the system (Figure 9.1). You start by creating release 1 of \nthe system. Once delivered, changes are proposed, and the development of release 2 \nstarts almost immediately. In fact, the need for evolution may become obvious even \nbefore the system is deployed, so later releases of the software may start develop-\nment before the current version has even been released.\nIn the last 10 years, the time between iterations of the spiral has reduced dramati-\ncally. Before the widespread use of the Internet, new versions of a software system \n", "page": 257, "type": "text", "section": "Page 257"}
{"text": "\t\nChapter 9\u2002 \u25a0\u2002 Software evolution\u2002 \u2002 257\nmay only have been released every 2 or 3 years. Now, because of competitive pres-\nsures and the need to respond quickly to user feedback, the gap between releases of \nsome apps and web-based systems may be weeks rather than years.\nThis model of software evolution is applicable when the same company is respon-\nsible for the software throughout its lifetime. There is a seamless transition from \ndevelopment to evolution, and the same software development methods and pro-\ncesses are applied throughout the lifetime of the software. Software products and \napps are developed using this approach.\nThe evolution of custom software, however, usually follows a different model. \nThe system customer may pay a software company to develop the software and \nthen take over responsibility for support and evolution using its own staff. \nAlternatively, the software customer might issue a separate contract to a different \nsoftware company for system support and evolution.\nIn this situation, there are likely to be discontinuities in the evolution process. \nRequirements and design documents may not be passed from one company to \nanother. Companies may merge or reorganize, inherit software from other compa-\nnies, and then find that this has to be changed. When the transition from develop-\nment to evolution is not seamless, the process of changing the software after delivery \nis called software maintenance. As I discuss later in this chapter, maintenance \ninvolves extra process activities, such as program understanding, in addition to the \nnormal activities of software development.\nRajlich and Bennett (Rajlich and Bennett 2000) propose an alternative view of \nthe software evolution life cycle for business systems. In this model, they distinguish \nbetween evolution and servicing. Evolution is the phase in which significant changes \nto the software architecture and functionality are made. During servicing, the only \nchanges that are made are relatively small but essential changes. These phases over-\nlap with each other, as shown in Figure 9.2.\nAccording to Rajlich and Bennett, when software is first used successfully, many \nchanges to the requirements by stakeholders are proposed and implemented. This is \nSpecification\nImplemention\nValidation\nOperation\nStart\nRelease 1\nRelease 2\nRelease 3\netc.\nFigure 9.1\u2002 A spiral \nmodel of development \nand evolution \n", "page": 258, "type": "text", "section": "Page 258"}
{"text": "258\u2002 \u2002 Chapter 9\u2002 \u25a0\u2002 Software evolution\nthe evolution phase. However, as the software is modified, its structure tends to \ndegrade, and system changes become more and more expensive. This often happens \nafter a few years of use when other environmental changes, such as hardware and \noperating systems, are also required. At some stage in the life cycle, the software \nreaches a transition point where significant changes and the implementation of new \nrequirements become less and less cost-effective. At this stage, the software moves \nfrom evolution to servicing.\nDuring the servicing phase, the software is still useful, but only small tactical \nchanges are made to it. During this stage, the company is usually considering how the \nsoftware can be replaced. In the final stage, the software may still be used, but only \nessential changes are made. Users have to work around problems that they discover. \nEventually, the software is retired and taken out of use. This often incurs further costs \nas data is transferred from an old system to a newer replacement system.\n \n9.1  Evolution processes\nAs with all software processes, there is no such thing as a standard software change \nor evolution process. The most appropriate evolution process for a software system \ndepends on the type of software being maintained, the software development pro-\ncesses used in an organization, and the skills of the people involved. For some types \nof system, such as mobile apps, evolution may be an informal process, where change \nrequests mostly come from conversations between system users and developers. For \nother types of systems, such as embedded critical systems, software evolution may be \nformalized, with structured documentation produced at each stage in the process.\nFormal or informal system change proposals are the driver for system evolution in all \norganizations. In a change proposal, an individual or group suggests changes and updates \nto an existing software system. These proposals may be based on existing requirements \nthat have not been implemented in the released system, requests for new requirements, \nbug reports from system stakeholders, and new ideas for software improvement from the \nsystem development team. The processes of change \u00ad\nidentification and system evolution \nare cyclical and continue throughout the lifetime of a system (Figure 9.3).\nBefore a change proposal is accepted, there needs to be an analysis of the \n\u00ad\nsoftware to work out which components need to be changed. This analysis allows \nthe cost and the impact of the change to be assessed. This is part of the general pro-\ncess of change management, which should also ensure that the correct versions of \nSoftware\ndevelopment\nSoftware\nevolution\nSoftware\nservicing\nSoftware\nretirement\nTime\nFigure 9.2\u2002 Evolution \nand servicing \n", "page": 259, "type": "text", "section": "Page 259"}
{"text": "\t\n9.1\u2002 \u25a0\u2002 Evolution processes\u2002 \u2002 259\n\u00ad\ncomponents are included in each system release. I discuss change and configuration \nmanagement in Chapter 25.\nFigure 9.4 shows some of the activities involved in software evolution. The pro-\ncess includes the fundamental activities of change analysis, release planning, system \nimplementation, and releasing a system to customers. The cost and impact of these \nchanges are assessed to see how much of the system is affected by the change and \nhow much it might cost to implement the change.\nIf the proposed changes are accepted, a new release of the system is planned. \nDuring release planning, all proposed changes (fault repair, adaptation, and new \nfunctionality) are considered. A decision is then made on which changes to imple-\nment in the next version of the system. The changes are implemented and validated, \nand a new version of the system is released. The process then iterates with a new set \nof changes proposed for the next release.\nIn situations where development and evolution are integrated, change implemen-\ntation is simply an iteration of the development process. Revisions to the system are \ndesigned, implemented, and tested. The only difference between initial development \nand evolution is that customer feedback after delivery has to be considered when \nplanning new releases of an application.\nWhere different teams are involved, a critical difference between development and \nevolution is that the first stage of change implementation requires program understanding. \nChange proposals\nNew system\nChange identification\nprocess\nSoftware evolution\nprocess\nFigure 9.3\u2002 Change \nidentification and \nevolution processes \nRelease\nplanning\nChange\nimplementation\nSystem\nrelease\nImpact\nanalysis\nChange\nrequests\nPlatform\nadaptation\nSystem\nenhancement\nFault repair\nFigure 9.4\u2002 A general \nmodel of the software \nevolution process \n", "page": 260, "type": "text", "section": "Page 260"}
{"text": "260\u2002 \u2002 Chapter 9\u2002 \u25a0\u2002 Software evolution\nDuring the program understanding phase, new developers have to understand how the \nprogram is structured, how it delivers functionality, and how the proposed change might \naffect the program. They need this understanding to make sure that the implemented \nchange does not cause new problems when it is introduced into the existing system.\nIf requirements specification and design documents are available, these should be \nupdated during the evolution process to reflect the changes that are required (Figure 9.5). \nNew software requirements should be written, and these should be analyzed and \nvalidated. If the design has been documented using UML models, these models \nshould be updated. The proposed changes may be prototyped as part of the change \nanalysis process, where you assess the implications and costs of making the change.\nHowever, change requests sometimes relate to problems in operational systems \nthat have to be tackled urgently. These urgent changes can arise for three reasons:\n1.\t\nIf a serious system fault is detected that has to be repaired to allow normal \noperation to continue or to address a serious security vulnerability.\n2.\t\nIf changes to the systems operating environment have unexpected effects that \ndisrupt normal operation.\n3.\t\nIf there are unanticipated changes to the business running the system, such as \nthe emergence of new competitors or the introduction of new legislation that \naffects the system.\nIn these cases, the need to make the change quickly means that you may not be\u00a0able \nto update all of the software documentation. Rather than modify the \u00ad\nrequirements and \ndesign, you make an emergency fix to the program to solve the immediate \u00ad\nproblem \n(Figure 9.6). The danger here is that the requirements, the software design, and the \ncode can become inconsistent. While you may intend to document the change in the \nrequirements and design, additional emergency fixes to the software may then be \nneeded. These take priority over documentation. Eventually, the original change is \nforgotten, and the system documentation and code are never realigned. This problem \nof maintaining multiple representations of a system is one of the arguments for mini-\nmal documentation, which is fundamental to agile development processes.\nEmergency system repairs have to be completed as quickly as possible. You \nchoose a quick and workable solution rather than the best solution as far as system \nstructure is concerned. This tends to accelerate the process of software ageing so that \nfuture changes become progressively more difficult and maintenance costs increase. \nIdeally, after emergency code repairs are made, the new code should be refactored \nRequirements\nupdating\nSoftware\ndevelopment\nRequirements\nanalysis\nProposed\nchanges\nFigure 9.5\u2002 Change \nimplementation \nModify\nsource code\nDeliver modified\nsystem\nAnalyze\nsource code\nChange\nrequests\nFigure 9.6\u2002 The \nemergency repair \nprocess \n", "page": 261, "type": "text", "section": "Page 261"}
{"text": "\t\n9.2\u2002 \u25a0\u2002 Legacy systems\u2002 \u2002 261\nand improved to avoid program degradation. Of course, the code of the repair may \nbe reused if possible. However, an alternative, better solution to the problem may be \ndiscovered when more time is available for analysis.\nAgile methods and processes, discussed in Chapter 3, may be used for program \nevolution as well as program development. Because these methods are based on \nincremental development, making the transition from agile development to postde-\nlivery evolution should be seamless.\nHowever, problems may arise during the handover from a development team to a \nseparate team responsible for system evolution. There are two potentially problem-\natic situations:\n1.\t\nWhere the development team has used an agile approach but the evolution team \nprefers a plan-based approach. The evolution team may expect detailed docu-\nmentation to support evolution, and this is rarely produced in agile processes. \nThere may be no definitive statement of the system requirements that can be \nmodified as changes are made to the system.\n2.\t\nWhere a plan-based approach has been used for development but the evolution \nteam prefers to use agile methods. In this case, the evolution team may have to \nstart from scratch developing automated tests. The code in the system may not \nhave been refactored and simplified, as is expected in agile development. In this \ncase, some program reengineering may be required to improve the code before \nit can be used in an agile development process.\nAgile techniques such as test-driven development and automated regression test-\ning are useful when system changes are made. System changes may be expressed as \nuser stories, and customer involvement can help prioritize changes that are required \nin an operational system. The Scrum approach of focusing on a backlog of work to \nbe done can help prioritize the most important system changes. In short, evolution \nsimply involves continuing the agile development process.\nAgile methods used in development may, however, have to be modified when \nthey are used for program maintenance and evolution. It may be practically impossible \nto involve users in the development team as change proposals come from a wide \nrange of stakeholders. Short development cycles may have to be interrupted to deal \nwith emergency repairs, and the gap between releases may have to be lengthened to \navoid disrupting operational processes.\n \n9.2  Legacy systems\nLarge companies started computerizing their operations in the 1960s, so for the past 50 \nyears or so, more and more software systems have been introduced. Many of these \n\u00ad\nsystems have been replaced (sometimes several times) as the business has changed and \nevolved. However, a lot of old systems are still in use and play a critical part in the run-\nning of the business. These older software systems are sometimes called legacy systems.\n", "page": 262, "type": "text", "section": "Page 262"}
{"text": "262\u2002 \u2002 Chapter 9\u2002 \u25a0\u2002 Software evolution\nLegacy systems are older systems that rely on languages and technology that are \nno longer used for new systems development. Typically, they have been maintained \nover a long period, and their structure may have been degraded by the changes that \nhave been made. Legacy software may be dependent on older hardware, such as \nmainframe computers and may have associated legacy processes and procedures. It \nmay be impossible to change to more effective business processes because the leg-\nacy software cannot be modified to support new processes.\nLegacy systems are not just software systems but are broader sociotechnical systems \nthat include hardware, software, libraries, and other supporting software and business \nprocesses. Figure 9.7 shows the logical parts of a legacy system and their relationships.\n1.\t\nSystem hardware Legacy systems may have been written for hardware that is no \nlonger available, that is expensive to maintain, and that may not be compatible \nwith current organizational IT purchasing policies.\n2.\t\nSupport software The legacy system may rely on a range of support software \nfrom the operating system and utilities provided by the hardware manufacturer \nthrough to the compilers used for system development. Again, these may be \nobsolete and no longer supported by their original providers.\n3.\t\nApplication software The application system that provides the business services \nis usually made up of a number of application programs that have been devel-\noped at different times. Some of these programs will also be part of other appli-\ncation software systems.\n4.\t\nApplication data These data are processed by the application system. In many \nlegacy systems, an immense volume of data has accumulated over the lifetime \nof the system. This data may be inconsistent, may be duplicated in several files, \nand may be spread over a number of different databases.\n5.\t\nBusiness processes These processes are used in the business to achieve some \nbusiness objective. An example of a business process in an insurance company \nwould be issuing an insurance policy; in a manufacturing company, a business \nprocess would be accepting an order for products and setting up the associated \nmanufacturing process. Business processes may be designed around a legacy \nsystem and constrained by the functionality that it provides.\n6.\t\nBusiness policies and rules These are definitions of how the business should be \ncarried out and constraints on the business. Use of the legacy application system \nmay be embedded in these policies and rules.\nAn alternative way of looking at these components of a legacy system is as a \nseries of layers, as shown in Figure 9.8.\nEach layer depends on the layer immediately below it and interfaces with that \nlayer. If interfaces are maintained, then you should be able to make changes within a \nlayer without affecting either of the adjacent layers. In practice, however, this simple \nencapsulation is an oversimplification, and changes to one layer of the system may \n", "page": 263, "type": "text", "section": "Page 263"}
{"text": "\t\n9.2\u2002 \u25a0\u2002 Legacy systems\u2002 \u2002 263\nrequire consequent changes to layers that are both above and below the changed \nlevel. The reasons for this are as follows:\n1.\t Changing one layer in the system may introduce new facilities, and higher \n\u00ad\nlayers in the system may then be changed to take advantage of these facilities. \nFor example, a new database introduced at the support software layer may \ninclude facilities to access the data through a web browser, and business \n\u00ad\nprocesses may be modified to take advantage of this facility.\n2.\t\nChanging the software may slow the system down so that new hardware is \nneeded to improve the system performance. The increase in performance from \nthe new hardware may then mean that further software changes that were \n\u00ad\npreviously impractical become possible.\n3.\t\nIt is often impossible to maintain hardware interfaces, especially if new hard-\nware is introduced. This is a particular problem in embedded systems where \nthere is a tight coupling between software and hardware. Major changes to the \napplication software may be required to make effective use of the new hardware.\nIt is difficult to know exactly how much legacy code is still in use, but, as an indi-\ncator, industry has estimated that there are more than 200 billion lines of COBOL \ncode in current business systems. COBOL is a programming language designed for \nwriting business systems, and it was the main business development language from \nthe 1960s to the 1990s, particularly in the finance industry (Mitchell 2012). These \nprograms still work effectively and efficiently, and the companies using them see no \nneed to change them. A major problem that they face, however, is a shortage of \nCOBOL programmers as the original developers of the system retire. Universities no \nlonger teach COBOL, and younger software engineers are more interested in pro-\ngramming in modern languages.\nSkill shortages are only one of the problems of maintaining business legacy sys-\ntems. Other issues include security vulnerabilities because these systems were \ndeveloped before the widespread use of the Internet and problems in interfacing \nwith systems written in modern programming languages. The original software tool \nsupplier may be out of business or may no longer maintain the support tools used to \nSystem\nhardware\nBusiness\nprocesses\nApplication\nsoftware\nBusiness policies\nand rules\nSupport\nsoftware\nApplication\n data\nConstrains\nUses\nUses\nRuns-on\nRuns-on\nEmbeds\nknowledge of\nUses\nFigure 9.7\u2002 The elements \nof a legacy system \n", "page": 264, "type": "text", "section": "Page 264"}
{"text": "264\u2002 \u2002 Chapter 9\u2002 \u25a0\u2002 Software evolution\ndevelop the system. The system hardware may be obsolete and so increasingly \nexpensive to maintain.\nWhy then do businesses not simply replace these systems with more modern \nequivalents? The simple answer to this question is that it is too expensive and too \nrisky to do so. If a legacy system works effectively, the costs of replacement may \nexceed the savings that come from the reduced support costs of a new system. \nScrapping legacy systems and replacing them with more modern software open up \nthe possibility of things going wrong and the new system failing to meet the needs \nof\u00a0the business. Managers try to minimize those risks and therefore do not want to \nface the uncertainties of new software systems.\nI discovered some of the problems of legacy system replacement when I was \ninvolved in analyzing a legacy system replacement project in a large organization. \nThis enterprise used more than 150 legacy systems to run its business. It decided to \nreplace all of these systems with a single, centrally maintained ERP system. For a \nnumber of business and technology reasons, the new system development was a \nfailure, and it did not deliver the improvements promised. After spending more than \n\u00a310 million, only a part of the new system was operational, and it worked less effec-\ntively than the systems it replaced. Users continued to use the older systems but \ncould not integrate these with the part of the new system that had been implemented, \nso additional manual processing was required.\nThere are several reasons why it is expensive and risky to replace legacy systems \nwith new systems:\n1.\t\nThere is rarely a complete specification of the legacy system. The original spec-\nification may have been lost. If a specification exists, it is unlikely that it has \nbeen updated with all of the system changes that have been made. Therefore, \nthere is no straightforward way of specifying a new system that is functionally \nidentical to the system that is in use.\n2.\t\nBusiness processes and the ways in which legacy systems operate are often inex-\ntricably intertwined. These processes are likely to have evolved to take advantage \nof the software\u2019s services and to work around the software\u2019s shortcomings. If the \nsystem is replaced, these processes have to change with potentially unpredictable \ncosts and consequences.\nSocio-technical system\nHardware\nPlatform and infrastructure software\nApplication software\nBusiness processes\nFigure 9.8\u2002 Legacy \nsystem layers \n", "page": 265, "type": "text", "section": "Page 265"}
{"text": "\t\n9.2\u2002 \u25a0\u2002 Legacy systems\u2002 \u2002 265\n3.\t\nImportant business rules may be embedded in the software and may not be doc-\numented elsewhere. A business rule is a constraint that applies to some business \nfunction, and breaking that constraint can have unpredictable consequences for \nthe business. For example, an insurance company may have embedded its rules \nfor assessing the risk of a policy application in its software. If these rules are not \nmaintained, the company may accept high-risk policies that could result in \nexpensive future claims.\n4.\t\nNew software development is inherently risky, so that there may be unexpected prob-\nlems with a new system. It may not be delivered on time and for the price expected.\nKeeping legacy systems in use avoids the risks of replacement, but making \nchanges to existing software inevitably becomes more expensive as systems get \nolder. Legacy software systems that are more than a few years old are particularly \nexpensive to change:\n1.\t\nThe program style and usage conventions are inconsistent because different \npeople have been responsible for system changes. This problem adds to the dif-\nficulty of understanding the system code.\n2.\t\nPart or all of the system may be implemented using obsolete programming \n\u00ad\nlanguages. It may be difficult to find people who have knowledge of these \u00ad\nlanguages. \nExpensive outsourcing of system maintenance may therefore be required.\n3.\t\nSystem documentation is often inadequate and out of date. In some cases, the \nonly documentation is the system source code.\n4.\t\nMany years of maintenance usually degrades the system structure, making it \nincreasingly difficult to understand. New programs may have been added and \ninterfaced with other parts of the system in an ad hoc way.\n5.\t The system may have been optimized for space utilization or execution \nspeed so that it runs effectively on older slower hardware. This normally \ninvolves using specific machine and language optimizations, and these usu-\nally lead to software that is hard to understand. This causes problems for \nprogrammers who have learned modern software engineering techniques and \nwho don\u2019t understand the programming tricks that have been used to opti-\nmize the software.\n6.\t\nThe data processed by the system may be maintained in different files that have \nincompatible structures. There may be data duplication, and the data itself may \nbe out of date, inaccurate, and incomplete. Several databases from different sup-\npliers may be used.\nAt same stage, the costs of managing and maintaining the legacy system become \nso high that it has to be replaced with a new system. In the next section, I discuss a \nsystematic decision-making approach to making such a replacement decision.\n", "page": 266, "type": "text", "section": "Page 266"}
{"text": "266\u2002 \u2002 Chapter 9\u2002 \u25a0\u2002 Software evolution\n\t\n9.2.1 \t Legacy system management\nFor new software systems developed using modern software engineering processes, \nsuch as agile development and software product lines, it is possible to plan how to \nintegrate system development and evolution. More and more companies understand \nthat the system development process is a whole life-cycle process. Separating soft-\nware development and software evolution is unhelpful and leads to higher costs. \nHowever, as I have discussed, there is still a huge number of legacy systems that are \ncritical business systems. These have to be extended and adapted to changing \ne-business practices.\nMost organizations have a limited budget for maintaining and upgrading their \nportfolio of legacy systems. They have to decide how to get the best return on their \ninvestment. This involves making a realistic assessment of their legacy systems and \nthen deciding on the most appropriate strategy for evolving these systems. There are \nfour strategic options:\n1.\t\nScrap the system completely This option should be chosen when the system is \nnot making an effective contribution to business processes. This usually occurs \nwhen business processes have changed since the system was installed and are \nno longer reliant on the legacy system.\n2.\t\nLeave the system unchanged and continue with regular maintenance This option \nshould be chosen when the system is still required but is fairly stable and the \nsystem users make relatively few change requests.\n3.\t\nReengineer the system to improve its maintainability This option should be chosen \nwhen the system quality has been degraded by change and where new change to \nthe system is still being proposed. This process may include developing new inter-\nface components so that the original system can work with other, newer systems.\n4.\t\nReplace all or part of the system with a new system This option should be chosen \nwhen factors, such as new hardware, mean that the old system cannot continue \nin operation, or where off-the-shelf systems would allow the new system to be \ndeveloped at a reasonable cost. In many cases, an evolutionary replacement \nstrategy can be adopted where major system components are replaced by off-\nthe-shelf systems with other components reused wherever possible.\nWhen you are assessing a legacy system, you have to look at it from both a busi-\nness perspective and a technical perspective (Warren 1998). From a business \n\u00ad\nperspective, you have to decide whether or not the business really needs the system. \nFrom a technical perspective, you have to assess the quality of the application soft-\nware and the system\u2019s support software and hardware. You then use a combination \nof the business value and the system quality to inform your decision on what to do \nwith the legacy system.\nFor example, assume that an organization has 10 legacy systems. You should \nassess the quality and the business value of each of these systems. You may then \ncreate a chart showing relative business value and system quality. An example of \n", "page": 267, "type": "text", "section": "Page 267"}
{"text": "\t\n9.2\u2002 \u25a0\u2002 Legacy systems\u2002 \u2002 267\nthis is shown in Figure 9.9. From this diagram, you can see that there are four \n\u00ad\nclusters of systems:\n1.\t\nLow quality, low business value Keeping these systems in operation will be \nexpensive, and the rate of the return to the business will be fairly small. These \nsystems should be scrapped.\n2.\t\nLow quality, high business value These systems are making an important business \ncontribution, so they cannot be scrapped. However, their low quality means that \nthey are expensive to maintain. These systems should be reengineered to improve \ntheir quality. They may be replaced, if suitable off-the-shelf systems are available.\n3.\t\nHigh quality, low business value These systems don\u2019t contribute much to the \nbusiness but may not be very expensive to maintain. It is not worth replacing \nthese systems, so normal system maintenance may be continued if expensive \nchanges are not required and the system hardware remains in use. If expensive \nchanges become necessary, the software should be scrapped.\n4.\t\nHigh quality, high business value These systems have to be kept in operation. \nHowever, their high quality means that you don\u2019t have to invest in transforma-\ntion or system replacement. Normal system maintenance should be continued.\nThe business value of a system is a measure of how much time and effort the \nsystem saves compared to manual processes or the use of other systems. To assess \nthe business value of a system, you have to identify system stakeholders, such as the \nend-users of a system and their managers, and ask a series of questions about the \nsystem. There are four basic issues that you have to discuss:\n1.\t\nThe use of the system If a system is only used occasionally or by a small number of \npeople, this may mean that it has a low business value. A legacy system may have \nbeen developed to meet a business need that has either changed or can now be met \n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\nSystem quality\nBusiness value\nHigh business value\nLow quality\nHigh business value\nHigh quality\nLow business value\nLow quality\nLow business value\nHigh quality\nFigure 9.9\u2002 An example \nof a legacy system \nassessment \n", "page": 268, "type": "text", "section": "Page 268"}
{"text": "268\u2002 \u2002 Chapter 9\u2002 \u25a0\u2002 Software evolution\nmore effectively in other ways. You have to be careful, however, about occasional \nbut important use of systems. For example, a university system for student regis-\ntration may only be used at the beginning of each academic year. Although it is \nused infrequently, it is an essential system with a high business value.\n2.\t\nThe business processes that are supported When a system is introduced, busi-\nness processes are usually introduced to exploit the system\u2019s capabilities. If the \nsystem is inflexible, changing these business processes may be impossible. \nHowever, as the environment changes, the original business processes may \nbecome obsolete. Therefore, a system may have a low business value because it \nforces the use of inefficient business processes.\n3.\t\nSystem dependability System dependability is not only a technical problem but \nalso a business problem. If a system is not dependable and the problems directly \naffect business customers, or mean that people in the business are diverted from \nother tasks to solve these problems, the system has a low business value.\n4.\t\nThe system outputs The key issue here is the importance of the system outputs to \nthe successful functioning of the business. If the business depends on these out-\nputs, then the system has a high business value. Conversely, if these outputs can \nbe cheaply generated in some other way, or if the system produces outputs that \nare rarely used, then the system has a low business value.\nFor example, assume that a company provides a travel ordering system that is \nused by staff responsible for arranging travel. They can place orders with an approved \ntravel agent. Tickets are then delivered, and the company is invoiced for them. \nHowever, a business value assessment may reveal that this system is only used for a \nfairly small percentage of travel orders placed. People making travel arrangements \nfind it cheaper and more convenient to deal directly with travel suppliers through \ntheir websites. This system may still be used, but there is no real point in keeping \nit\u2014the same functionality is available from external systems.\nConversely, say a company has developed a system that keeps track of all previ-\nous customer orders and automatically generates reminders for customers to reorder \ngoods. This results in a large number of repeat orders and keeps customers satisfied \nbecause they feel that their supplier is aware of their needs. The outputs from such a \nsystem are important to the business, so this system has a high business value.\nTo assess a software system from a technical perspective, you need to consider \nboth the application system itself and the environment in which the system operates. \nThe environment includes the hardware and all associated support software such as \ncompilers, debuggers and development environments that are needed to maintain the \nsystem. The environment is important because many system changes, such as upgrades \nto the hardware or operating system, result from changes to the environment.\nFactors that you should consider during the environment assessment are shown in \nFigure 9.10. Notice that these are not all technical characteristics of the environment. \nYou also have to consider the reliability of the suppliers of the hardware and support \nsoftware. If suppliers are no longer in business, their systems may not be supported, \nso you may have to replace these systems.\n", "page": 269, "type": "text", "section": "Page 269"}
{"text": "\t\n9.2\u2002 \u25a0\u2002 Legacy systems\u2002 \u2002 269\nIn the process of environmental assessment, if possible, you should ideally collect \ndata about the system and system changes. Examples of data that may be useful include \nthe costs of maintaining the system hardware and support software, the number of \nhardware faults that occur over some time period and the frequency of patches and \nfixes applied to the system support software.\nTo assess the technical quality of an application system, you have to assess those \nfactors (Figure 9.11) that are primarily related to the system dependability, the dif-\nficulties of maintaining the system, and the system documentation. You may also \ncollect data that will help you judge the quality of the system such as:\n1.\t\nThe number of system change requests System changes usually corrupt the system \nstructure and make further changes more difficult. The higher this accumulated \nvalue, the lower the quality of the system.\n2.\t\nThe number of user interfaces This is an important factor in forms-based sys-\ntems where each form can be considered as a separate user interface. The more \ninterfaces, the more likely it is that there will be inconsistencies and redundan-\ncies in these interfaces.\n3.\t\nThe volume of data used by the system As the volume of data (number of files, \nsize of database, etc.) processed by the system increases, so too do the inconsist-\nencies and errors in that data. When data has been collected over a long period \nof time, errors and inconsistencies are inevitable. Cleaning up old data is a very \nexpensive and time-consuming process.\nFactor\nQuestions\nSupplier stability\nIs the supplier still in existence? Is the supplier financially stable and likely to \ncontinue in existence? If the supplier is no longer in business, does someone else \nmaintain the systems?\nFailure rate\nDoes the hardware have a high rate of reported failures? Does the support software \ncrash and force system restarts?\nAge\nHow old is the hardware and software? The older the hardware and support \nsoftware, the more obsolete it will be. It may still function correctly, but there could \nbe significant economic and business benefits to moving to a more modern system.\nPerformance\nIs the performance of the system adequate? Do performance problems have a \nsignificant effect on system users?\nSupport \nrequirements\nWhat local support is required by the hardware and software? If high costs are \nassociated with this support, it may be worth considering system replacement.\nMaintenance costs\nWhat are the costs of hardware maintenance and support software licences? Older \nhardware may have higher maintenance costs than modern systems. Support \nsoftware may have high annual licensing costs.\nInteroperability\nAre there problems interfacing the system to other systems? Can compilers, for \nexample, be used with current versions of the operating system?\nFigure 9.10\u2002 Factors \nused in environment \nassessment\n", "page": 270, "type": "text", "section": "Page 270"}
{"text": "270\u2002 \u2002 Chapter 9\u2002 \u25a0\u2002 Software evolution\nIdeally, objective assessment should be used to inform decisions about what to do \nwith a legacy system. However, in many cases, decisions are not really objective but \nare based on organizational or political considerations. For example, if two businesses \nmerge, the most politically powerful partner will usually keep its systems and scrap \nthe other company\u2019s systems. If senior management in an organization decides to \nmove to a new hardware platform, then this may require applications to be \nreplaced. If no budget is available for system transformation in a particular year, \nthen system maintenance may be continued, even though this will result in higher \nlong-term costs.\n \n9.3  Software maintenance\nSoftware maintenance is the general process of changing a system after it has \nbeen delivered. The term is usually applied to custom software, where separate \ndevelopment groups are involved before and after delivery. The changes made to \nthe software may be simple changes to correct coding errors, more extensive \nchanges to correct design errors, or significant enhancements to correct specifica-\ntion errors or to accommodate new requirements. Changes are implemented by \nmodifying existing system components and, where necessary, by adding new \ncomponents to the system.\nFactor\nQuestions\nUnderstandability\nHow difficult is it to understand the source code of the current system? How \ncomplex are the control structures that are used? Do variables have \nmeaningful names that reflect their function?\nDocumentation\nWhat system documentation is available? Is the documentation complete, \nconsistent, and current?\nData\nIs there an explicit data model for the system? To what extent is data duplicated \nacross files? Is the data used by the system up to date and consistent?\nPerformance\nIs the performance of the application adequate? Do performance problems \nhave a significant effect on system users?\nProgramming language\nAre modern compilers available for the programming language used to \ndevelop the system? Is the programming language still used for new system \ndevelopment?\nConfiguration management\nAre all versions of all parts of the system managed by a configuration \nmanagement system? Is there an explicit description of the versions of \ncomponents that are used in the current system?\nTest data\nDoes test data for the system exist? Is there a record of regression tests \ncarried out when new features have been added to the system?\nPersonnel skills\nAre there people available who have the skills to maintain the application? \nAre there people available who have experience with the system?\nFigure 9.11\u2002 Factors \nused in application \nassessment\n", "page": 271, "type": "text", "section": "Page 271"}
{"text": "\t\n9.3\u2002 \u25a0\u2002 Software maintenance\u2002 \u2002 271\nThere are three different types of software maintenance:\n1.\t\nFault repairs to fix bugs and vulnerabilities. Coding errors are usually relatively \ncheap to correct; design errors are more expensive because they may involve \nrewriting several program components. Requirements errors are the most expen-\nsive to repair because extensive system redesign may be necessary.\n2.\t\nEnvironmental adaptation to adapt the software to new platforms and environ-\nments. This type of maintenance is required when some aspect of a system\u2019s \nenvironment, such as the hardware, the platform operating system, or other sup-\nport software, changes. Application systems may have to be modified to cope \nwith these environmental changes.\n3.\t\nFunctionality addition to add new features and to support new requirements. \nThis type of maintenance is necessary when system requirements change in \nresponse to organizational or business change. The scale of the changes required \nto the software is often much greater than for the other types of maintenance.\nIn practice, there is no clear-cut distinction between these types of maintenance. \nWhen you adapt a system to a new environment, you may add functionality to take \nadvantage of new environmental features. Software faults are often exposed because \nusers use the system in unanticipated ways. Changing the system to accommodate \ntheir way of working is the best way to fix these faults.\nThese types of maintenance are generally recognized, but different people some-\ntimes give them different names. \u201cCorrective maintenance\u201d is universally used to \nrefer to maintenance for fault repair. However, \u201cadaptive maintenance\u201d sometimes \nmeans adapting to a new environment and sometimes means adapting the software to \nnew requirements. \u201cPerfective maintenance\u201d sometimes means perfecting the soft-\nware by implementing new requirements; in other cases, it means maintaining the \nfunctionality of the system but improving its structure and its performance. Because \nof this naming uncertainty, I have avoided the use of these terms in this book.\nProgram evolution dynamics\nProgram evolution dynamics is the study of evolving software systems, pioneered by Manny Lehman and Les Belady \nin the 1970s. This led to so-called Lehman\u2019s Laws, which are said to apply to all large-scale software systems. The \nmost important of these laws are:\n1.\t A program must continually change if it is to remain useful.\n2.\t As an evolving program changes, its structure is degraded.\n3.\t Over a program\u2019s lifetime, the rate of change is roughly constant and independent of the resources available.\n4.\t The incremental change in each release of a system is roughly constant.\n5.\t New functionality must be added to systems to increase user satisfaction.\nhttp://software-engineering-book.com/web/program-evolution-dynamics/\n", "page": 272, "type": "text", "section": "Page 272"}
{"text": "272\u2002 \u2002 Chapter 9\u2002 \u25a0\u2002 Software evolution\nFigure 9.12 shows an approximate distribution of maintenance costs, based on \ndata from the most recent survey available (Davidsen and Krogstie 2010). This study \ncompared maintenance cost distribution with a number of earlier studies from 1980 \nto 2005. The authors found that the distribution of maintenance costs had changed \nvery little over 30 years. Although we don\u2019t have more recent data, this suggests that \nthis distribution is still largely correct. Repairing system faults is not the most expen-\nsive maintenance activity. Evolving the system to cope with new environments and \nnew or changed requirements generally consumes most maintenance effort.\nExperience has shown that it is usually more expensive to add new features to a \nsystem during maintenance than it is to implement the same features during initial \ndevelopment. The reasons for this are:\n1.\t\nA new team has to understand the program being maintained. After a system \nhas been delivered, it is normal for the development team to be broken up and \nfor people to work on new projects. The new team or the individuals responsible \nfor system maintenance do not understand the system or the background to sys-\ntem design decisions. They need to spend time understanding the existing sys-\ntem before they can implement changes to it.\n2.\t\nSeparating maintenance and development means there is no incentive for the \ndevelopment team to write maintainable software. The contract to maintain a \nsystem is usually separate from the system development contract. A different \ncompany, rather than the original software developer, may be responsible for \nsoftware maintenance. In those circumstances, a development team gets no ben-\nefit from investing effort to make the software maintainable. If a development \nteam can cut corners to save effort during development it is worthwhile for them \nto do so, even if this means that the software is more difficult to change in future.\n3.\t\nProgram maintenance work is unpopular. Maintenance has a poor image among \nsoftware engineers. It is seen as a less skilled process than system development \nFunctionality addition\nor modification\n(58%)\nFault repair\n(24%)\nEnvironmental \nadaptation\n(19%)\nFigure 9.12\u2002  \nMaintenance effort \ndistribution \n", "page": 273, "type": "text", "section": "Page 273"}
{"text": "\t\n9.3\u2002 \u25a0\u2002 Software maintenance\u2002 \u2002 273\nand is often allocated to the least experienced staff. Furthermore, old systems \nmay be written in obsolete programming languages. The developers working on \nmaintenance may not have much experience of these languages and must learn \nthese languages to maintain the system.\n4.\t\nAs programs age, their structure degrades and they become harder to change. \nAs changes are made to programs, their structure tends to degrade. Consequently, \nthey become harder to understand and change. Some systems have been \u00ad\ndeveloped \nwithout modern software engineering techniques. They may never have been \nwell structured and were perhaps optimized for efficiency rather than understand-\nability. System documentation may be lost or inconsistent. Old systems may not \nhave been subject to stringent configuration management, so developers have to \nspend time finding the right versions of system components to change.\nThe first three of these problems stem from the fact that many organizations still \nconsider software development and maintenance to be separate activities. \nMaintenance is seen as a second-class activity, and there is no incentive to spend \nmoney during development to reduce the costs of system change. The only long-\nterm solution to this problem is to think of systems as evolving throughout their \nlifetime through a continual development process. Maintenance should have as high \na status as new software development.\nThe fourth issue, the problem of degraded system structure, is, in some ways, the \neasiest problem to address. Software reengineering techniques (described later in \nthis chapter) may be applied to improve the system structure and understandability. \nArchitectural transformations can adapt the system to new hardware. Refactoring \ncan improve the quality of the system code and make it easier to change.\nIn principle, it is almost always cost-effective to invest effort in designing and \nimplementing a system to reduce the costs of future changes. Adding new function-\nality after delivery is expensive because you have to spend time learning the system \nand analyzing the impact of the proposed changes. Work done during development \nto structure the software and to make it easier to understand and change will reduce \nevolution costs. Good software engineering techniques such as precise specification, \ntest-first development, the use of object-oriented development, and configuration \nmanagement all help reduce maintenance cost.\nThese principled arguments for lifetime cost savings by investing in making \n\u00ad\nsystems more maintainable are, unfortunately, impossible to substantiate with real \nDocumentation\nSystem documentation can help the maintenance process by providing maintainers with information about the \nstructure and organization of the system and the features that it offers to system users. While proponents of agile \napproaches suggest that the code should be the principal documentation, higher level design models and infor-\nmation about dependencies and constraints can make it easier to understand and make changes to that code.\nhttp://software-engineering-book.com/web/documentation/ (web chapter)\n", "page": 274, "type": "text", "section": "Page 274"}
{"text": "274\u2002 \u2002 Chapter 9\u2002 \u25a0\u2002 Software evolution\ndata. Collecting data is expensive, and the value of that data is difficult to judge; \ntherefore, the vast majority of companies do not think it is worthwhile to gather and \nanalyze software engineering data.\nIn reality, most businesses are reluctant to spend more on software develop-\nment to reduce longer-term maintenance costs. There are two main reasons for \ntheir reluctance:\n1.\t\nCompanies set out quarterly or annual spending plans, and managers are incen-\ntivized to reduce short-term costs. Investing in maintainability leads to short-\nterm cost increases, which are measurable. However, the long-term gains can\u2019t \nbe measured at the same time, so companies are reluctant to spend money on \nsomething with an unknown future return.\n2.\t\nDevelopers are not usually responsible for maintaining the system they have \ndeveloped. Consequently, they don\u2019t see the point of doing additional work that \nmight reduce maintenance costs, as they will not get any benefit from it.\nThe only way around this problem is to integrate development and maintenance \nso that the original development team remains responsible for software throughout \nits lifetime. This is possible for software products and for companies such as \nAmazon, which develop and maintain their own software (O\u2019Hanlon 2006). \nHowever, for custom software developed by a software company for a client, this is \nunlikely to happen.\n\t\n9.3.1 \t Maintenance prediction\nMaintenance prediction is concerned with trying to assess the changes that may be \nrequired in a software system and with identifying those parts of the system that are \nlikely to be the most expensive to change. If you understand this, you can design the \nsoftware components that are most likely to change to make them more adaptable. \nYou can also invest effort in improving those components to reduce their lifetime \nmaintenance costs. By predicting changes, you can also assess the overall mainte-\nnance costs for a system in a given time period and so set a budget for maintaining \nthe software. Figure 9.13 shows possible predictions and the questions that these \npredictions may answer.\nPredicting the number of change requests for a system requires an understanding \nof the relationship between the system and its external environment. Some systems \nhave a very complex relationship with their external environment, and changes to \nthat environment inevitably result in changes to the system. To evaluate the relation-\nships between a system and its environment, you should look at:\n1.\t\nThe number and complexity of system interfaces The larger the number of inter-\nfaces and the more complex these interfaces, the more likely it is that interface \nchanges will be required as new requirements are proposed.\n", "page": 275, "type": "text", "section": "Page 275"}
{"text": "\t\n9.3\u2002 \u25a0\u2002 Software maintenance\u2002 \u2002 275\n2.\t\nThe number of inherently volatile system requirements As I discussed in Chapter 4, \nrequirements that reflect organizational policies and procedures are likely to be \nmore volatile than requirements that are based on stable domain characteristics.\n3.\t\nThe business processes in which the system is used As business processes \nevolve, they generate system change requests. As a system is integrated with \nmore and more business processes, there are increased demands for changes.\nIn early work on software maintenance, researchers looked at the relationships \nbetween program complexity and maintainability (Banker et al. 1993; Coleman et al. \n1994; Kozlov et al. 2008). These studies found that the more complex a system or \ncomponent, the more expensive it is to maintain. Complexity measurements are par-\nticularly useful in identifying program components that are likely to be expensive to \nmaintain. Therefore, to reduce maintenance costs you should try to replace complex \nsystem components with simpler alternatives.\nAfter a system has been put into service, you may be able to use process data to \nhelp predict maintainability. Examples of process metrics that can be used for assess-\ning maintainability are:\n1.\t\nNumber of requests for corrective maintenance An increase in the number of \nbug and failure reports may indicate that more errors are being introduced into \nthe program than are being repaired during the maintenance process. This may \nindicate a decline in maintainability.\n2.\t\nAverage time required for impact analysis This is related to the number of pro-\ngram components that are affected by the change request. If the time required \nfor impact analysis increases, it implies that more and more components are \naffected and maintainability is decreasing.\nPredicting\nmaintainability\nPredicting system\nchanges\nPredicting\nmaintenance\ncosts\nWhat will be the lifetime\nmaintenance costs of this\nsystem?\nWhat will be the costs of\nmaintaining this system\nover the next year?\nWhat parts of the system\nwill be the most expensive\nto maintain?\nHow many change\nrequests can be\nexpected?\nWhat parts of the system are\nmost likely to be affected by\nchange requests?\nFigure 9.13\u2002  \nMaintenance prediction \n", "page": 276, "type": "text", "section": "Page 276"}
{"text": "276\u2002 \u2002 Chapter 9\u2002 \u25a0\u2002 Software evolution\n3.\t\nAverage time taken to implement a change request This is not the same as the \ntime for impact analysis although it may correlate with it. This is the \u00a0amount of \ntime that you need to modify the system and its documentation, after you have \nassessed which components are affected. An increase in the time needed to \nimplement a change may indicate a decline in maintainability.\n4.\t\nNumber of outstanding change requests An increase in this number over time \nmay imply a decline in maintainability.\nYou use predicted information about change requests and predictions about sys-\ntem maintainability to predict maintenance costs. Most managers combine this infor-\nmation with intuition and experience to estimate costs. The COCOMO 2 model of \ncost estimation, discussed in Chapter 23, suggests that an estimate for software \nmaintenance effort can be based on the effort to understand existing code and the \neffort to develop the new code.\n\t\n9.3.2 \t Software reengineering\nSoftware maintenance involves understanding the program that has to be changed \nand then implementing any required changes. However, many systems, especially \nolder legacy systems, are difficult to understand and change. The programs may \nhave been optimized for performance or space utilization at the expense of under-\nstandability, or, over time, the initial program structure may have been corrupted by \na series of changes.\nTo make legacy software systems easier to maintain, you can reengineer these \nsystems to improve their structure and understandability. Reengineering may \ninvolve redocumenting the system, refactoring the system architecture, translat-\ning programs to a modern programming language, or modifying and updating the \nstructure and values of the system\u2019s data. The functionality of the software is not \nchanged, and, normally, you should try to avoid making major changes to the \nsystem architecture.\nReengineering has two important advantages over replacement:\n1.\t\nReduced risk There is a high risk in redeveloping business-critical software. \nErrors may be made in the system specification or there may be development \nproblems. Delays in introducing the new software may mean that business is \nlost and extra costs are incurred.\n2.\t Reduced cost The cost of reengineering may be significantly less than the cost \nof developing new software. Ulrich (Ulrich 1990) quotes an example of a \ncommercial system for which the reimplementation costs were estimated at \n$50 million. The system was successfully reengineered for $12 million. I sus-\npect that, with modern software technology, the relative cost of reimplemen-\ntation is probably less than Ulrich\u2019s figure but will still be more than the costs \nof reengineering.\n", "page": 277, "type": "text", "section": "Page 277"}
{"text": "\t\n9.3\u2002 \u25a0\u2002 Software maintenance\u2002 \u2002 277\nFigure 9.14 is a general model of the reengineering process. The input to the pro-\ncess is a legacy program, and the output is an improved and restructured version of \nthe same program. The activities in this reengineering process are:\n1.\t\nSource code translation Using a translation tool, you can convert the program \nfrom an old programming language to a more modern version of the same lan-\nguage or to a different language.\n2.\t\nReverse engineering The program is analyzed and information extracted from \nit. This helps to document its organization and functionality. Again, this process \nis usually completely automated.\n3.\t\nProgram structure improvement The control structure of the program is ana-\nlyzed and modified to make it easier to read and understand. This can be par-\ntially automated, but some manual intervention is usually required.\n4.\t\nProgram modularization Related parts of the program are grouped together, \nand, where appropriate, redundancy is removed. In some cases, this stage may \ninvolve architectural refactoring (e.g., a system that uses several different data \nstores may be refactored to use a single repository). This is a manual process.\n5.\t\nData reengineering The data processed by the program is changed to reflect \nprogram changes. This may mean redefining database schemas and converting \nexisting databases to the new structure. You should usually also clean up the \ndata. This involves finding and correcting mistakes, removing duplicate records, \nand so on. This can be a very expensive and prolonged process.\nProgram reengineering may not necessarily require all of the steps in Figure 9.11. \nYou don\u2019t need source code translation if you still use the application\u2019s \u00ad\nprogramming \nlanguage. If you can do all reengineering automatically, then recovering documenta-\ntion through reverse engineering may be unnecessary. Data \u00ad\nreengineering is required \nonly if the data structures in the program change during system reengineering.\nReverse\nengineering\nProgram\ndocumentation\nData\nreengineering\nOriginal data\nProgram\nstructure\nimprovement\nProgram\nmodularization\nRestructured\nprogram\nReengineered\ndata\nReengineered\nprogram\nOriginal\nprogram\nSource code\ntranslation\nFigure 9.14\u2002 The \nreengineering  \nprocess \n", "page": 278, "type": "text", "section": "Page 278"}
{"text": "278\u2002 \u2002 Chapter 9\u2002 \u25a0\u2002 Software evolution\nTo make the reengineered system interoperate with the new software, you may \nhave to develop adaptor services, as discussed in Chapter 18. These hide the original \ninterfaces of the software system and present new, better-structured interfaces that \ncan be used by other components. This process of legacy system wrapping is an \nimportant technique for developing large-scale reusable services.\nThe costs of reengineering obviously depend on the extent of the work that is \ncarried out. There is a spectrum of possible approaches to reengineering, as shown \nin Figure 9.15. Costs increase from left to right so that source code translation is \nthe cheapest option, and reengineering, as part of architectural migration, is the \nmost expensive.\nThe problem with software reengineering is that there are practical limits to how \nmuch you can improve a system by reengineering. It isn\u2019t possible, for example, to \nconvert a system written using a functional approach to an object-oriented system. \nMajor architectural changes or radical reorganizing of the system data management \ncannot be carried out automatically, so they are very expensive. Although reengineer-\ning can improve maintainability, the reengineered system will probably not be as \nmaintainable as a new system developed using modern \u00ad\nsoftware engineering methods.\n\t\n9.3.3 \t Refactoring\nRefactoring is the process of making improvements to a program to slow down deg-\nradation through change. It means modifying a program to improve its structure, \nreduce its complexity, or make it easier to understand. Refactoring is sometimes \nconsidered to be limited to object-oriented development, but the principles can in \nfact be applied to any development approach. When you refactor a program, you \nshould not add functionality but rather should concentrate on program improvement. \nYou can therefore think of refactoring as \u201cpreventative maintenance\u201d that reduces \nthe problems of future change.\nRefactoring is an inherent part of agile methods because these methods are based \non change. Program quality is liable to degrade quickly, so agile developers \u00ad\nfrequently \nrefactor their programs to avoid this degradation. The emphasis on regression testing \nin agile methods lowers the risk of introducing new errors through refactoring. Any \nerrors that are introduced should be detectable, as previously successful tests should \nthen fail. However, refactoring is not dependent on other \u201cagile activities.\u201d\nAutomated restructuring\nwith manual changes\nAutomated source\ncode conversion\nRestructuring plus\narchitectural changes\nAutomated program\nrestructuring\nProgram and data\nrestructuring\nIncreased cost\nFigure 9.15\u2002  \nReengineering \napproaches \n", "page": 279, "type": "text", "section": "Page 279"}
{"text": "\t\n9.3\u2002 \u25a0\u2002 Software maintenance\u2002 \u2002 279\nAlthough reengineering and refactoring are both intended to make software easier \nto understand and change, they are not the same thing. Reengineering takes place after \na system has been maintained for some time, and maintenance costs are increasing. \nYou use automated tools to process and reengineer a legacy system to create a new \nsystem that is more maintainable. Refactoring is a continuous process of improvement \nthroughout the development and evolution process. It is intended to avoid the structure \nand code degradation that increases the costs and difficulties of maintaining a system.\nFowler et al. (Fowler et al. 1999) suggest that there are stereotypical situations \n(Fowler calls them \u201cbad smells\u201d) where the code of a program can be improved. \nExamples of bad smells that can be improved through refactoring include:\n1.\t\nDuplicate code The same or very similar code may be included at different \nplaces in a program. This can be removed and implemented as a single method \nor function that is called as required.\n2.\t\nLong methods If a method is too long, it should be redesigned as a number of \nshorter methods.\n3.\t\nSwitch (case) statements These often involve duplication, where the switch \ndepends on the type of a value. The switch statements may be scattered around \na program. In object-oriented languages, you can often use polymorphism to \nachieve the same thing.\n4.\t\nData clumping Data clumps occur when the same group of data items (fields in \nclasses, parameters in methods) reoccurs in several places in a program. These \ncan often be replaced with an object that encapsulates all of the data.\n5.\t\nSpeculative generality This occurs when developers include generality in a pro-\ngram in case it is required in the future. This can often simply be removed.\nFowler, in both his book and website, also suggests some primitive refactoring \ntransformations that can be used singly or together to deal with bad smells. Examples \nof these transformations include Extract method, where you remove duplication and \ncreate a new method; Consolidate conditional expression, where you replace a \nsequence of tests with a single test; and Pull up method, where you replace similar \nmethods in subclasses with a single method in a superclass. Interactive development \nenvironments, such as Eclipse, usually include refactoring support in their editors. \nThis makes it easier to find dependent parts of a program that have to be changed to \nimplement the refactoring.\nRefactoring, carried out during program development, is an effective way to \nreduce the long-term maintenance costs of a program. However, if you take over a \nprogram for maintenance whose structure has been significantly degraded, then it \nmay be practically impossible to refactor the code alone. You may also have to think \nabout design refactoring, which is likely to be a more expensive and difficult prob-\nlem. Design refactoring involves identifying relevant design patterns (discussed in \nChapter 7) and replacing existing code with code that implements these design pat-\nterns (Kerievsky 2004).\n", "page": 280, "type": "text", "section": "Page 280"}
{"text": "Key Points\n\u25a0\t Software development and evolution can be thought of as an integrated, iterative process that \ncan be represented using a spiral model.\n\u25a0\t For custom systems, the costs of software maintenance usually exceed the software develop-\nment costs.\n\u25a0\t The process of software evolution is driven by requests for changes and includes change impact \nanalysis, release planning, and change implementation.\n\u25a0\t Legacy systems are older software systems, developed using obsolete software and hardware \ntechnologies, that remain useful for a business.\n\u25a0\t It is often cheaper and less risky to maintain a legacy system than to develop a replacement sys-\ntem using modern technology.\n\u25a0\t The business value of a legacy system and the quality of the application software and its envi-\nronment should be assessed to determine whether a system should be replaced, transformed, \nor maintained.\n\u25a0\t There are three types of software maintenance, namely, bug fixing, modifying software to work \nin a new environment, and implementing new or changed requirements.\n\u25a0\t Software reengineering is concerned with restructuring and redocumenting software to make it \neasier to understand and change.\n\u25a0\t Refactoring, making small program changes that preserve functionality, can be thought of as \npreventative maintenance.\nFurther Reading\nWorking Effectively with Legacy Code. Solid practical advice on the problems and difficulties of \n\u00ad\ndealing with legacy systems. (M. Feathers, 2004, John Wiley & Sons).\n\u201cThe Economics of Software Maintenance in the 21st Century.\u201d This article is a general introduction \nto maintenance and a comprehensive discussion of maintenance costs. Jones discusses the factors \nthat affect maintenance costs and suggests that almost 75% of the software workforce are involved \nin software maintenance activities. (C. Jones, 2006) http://www.compaid.com/caiinternet/ezine/\ncapersjones-maintenance.pdf\n\u201cYou Can\u2019t Be Agile in Maintenance?\u201d In spite of the title, this blog post argues that agile techniques \nare appropriate for maintenance and discusses which techniques as suggested in XP can be effective. \n(J. Bird, 2011) http://swreflections.blogspot.co.uk/2011/10/you-cant-be-agile-in-maintenance.html\n\u201cSoftware Reengineering and Testing Considerations.\u201d This is an excellent summary white \npaper\u00a0of maintenance issues from a major Indian software company. (Y. Kumar and Dipti, 2012) \nhttp://www.infosys.com/engineering-services/white-papers/Documents/software-re-engineering-\u00ad\nprocesses.pdf\n280\u2002 \u2002 Chapter 9\u2002 \u25a0\u2002 Software evolution\n", "page": 281, "type": "text", "section": "Page 281"}
{"text": "\t\n\u2002 Chapter 9\u2002 \u25a0\u2002 References\u2002 \u2002 281\nWebsite\nPowerPoint slides for this chapter:\nwww.pearsonglobaleditions.com/Sommerville\nLinks to supporting videos:\nhttp://software-engineering-book.com/videos/implementation-and-evolution/\nExercises\n\u2002 9.1.\t Explain how advances in technology can force a software subsystem to undergo change or run \nthe risk of becoming useless.\n\u2002 9.2.\t From Figure 9.4, you can see that impact analysis is an important subprocess in the software evolu-\ntion process. Using a diagram, suggest what activities might be involved in change impact analysis.\n\u2002 9.3.\t Explain why legacy systems should be thought of as sociotechnical systems rather than \n\u00ad\nsimply software systems that were developed using old technology.\n\u2002 9.4.\t Some software subsystems are seen as \u201clow quality, high business value.\u201d Discuss how those \nsubsystems can be re-engineered with minimal impact on the operations of the organization.\n\u2002 9.5.\t What are the strategic options for legacy system evolution? When would you normally replace \nall or part of a system rather than continue maintenance of the software?\n\u2002 9.6.\t Explain why problems with support software might mean that an organization has to replace \nits legacy systems.\n\u2002 9.7.\t As a software project manager in a company that specializes in the development of software \nfor the offshore oil industry, you have been given the task of discovering the factors that affect \nthe maintainability of the systems developed by your company. Suggest how you might set up \na program to analyze the maintenance process and determine appropriate maintainability \nmetrics for the company.\n\u2002 9.8.\t Briefly describe the three main types of software maintenance. Why is it sometimes difficult to \ndistinguish between them?\n\u2002 9.9.\t Explain the differences between software reengineering and refactoring?\n9.10.\t Do software engineers have a professional responsibility to develop code that can be easily \nmaintained even if their employer does not explicitly request it?\nReferences\nBanker, R. D., S. M. Datar, C. F. Kemerer, and D. Zweig. 1993. \u201cSoftware Complexity and Mainte-\nnance Costs.\u201d Comm. ACM 36 (11): 81\u201394. doi:10.1145/163359.163375.\nColeman, D., D. Ash, B. Lowther, and P. Oman. 1994. \u201cUsing Metrics to Evaluate Software System \nMaintainability.\u201d IEEE Computer 27 (8): 44\u201349. doi:10.1109/2.303623.\n", "page": 282, "type": "text", "section": "Page 282"}
{"text": "282\u2002 \u2002 Chapter 9\u2002 \u25a0\u2002 Software evolution\nDavidsen, M. G., and J. Krogstie. 2010. \u201cA Longitudinal Study of Development and Maintenance.\u201d \nInformation and Software Technology 52 (7): 707\u2013719. doi:10.1016/j.infsof.2010.03.003.\nErlikh, L. 2000. \u201cLeveraging Legacy System Dollars for E-Business.\u201d IT Professional 2 (3 (May/June \n2000)): 17\u201323. doi:10.1109/6294.846201.\nFowler, M., K. Beck, J. Brant, W. Opdyke, and D. Roberts. 1999. Refactoring: Improving the Design of \nExisting Code. Boston: Addison-Wesley.\nHopkins, R., and K. Jenkins. 2008. Eating the IT Elephant: Moving from Greenfield Development to \nBrownfield. Boston: IBM Press.\nJones, T. C. 2006. \u201cThe Economics of Software Maintenance in the 21st Century.\u201d www.compaid \n.com/caiinternet/ezine/capersjones-maintenance.pdf.\nKerievsky, J. 2004. Refactoring to Patterns. Boston: Addison-Wesley.\nKozlov, D., J. Koskinen, M. Sakkinen, and J. Markkula. 2008. \u201cAssessing Maintainability Change over \nMultiple Software Releases.\u201d J. of Software Maintenance and Evolution 20 (1): 31\u201358. doi:10.1002/\nsmr.361.\nLientz, B. P., and E. B. Swanson. 1980. Software Maintenance Management. Reading, MA: Addison-\nWesley.\nMitchell, R. M. 2012. \u201cCOBOL on the Mainframe: Does It Have a Future?\u201d Computerworld US. http://\nfeatures.techworld.com/applications/3344704/cobol-on-the-mainframe-does-it-have-a-future/\nO\u2019Hanlon, C. 2006. \u201cA Conversation with Werner Vogels.\u201d ACM Queue 4 (4): 14\u201322.\ndoi:10.1145/1142055.1142065.\nRajlich, V. T., and K. H. Bennett. 2000. \u201cA Staged Model for the Software Life Cycle.\u201d IEEE Computer \n33 (7): 66\u201371. doi:10.1109/2.869374.\nUlrich, W. M. 1990. \u201cThe Evolutionary Growth of Software Reengineering and the Decade Ahead.\u201d \nAmerican Programmer 3 (10): 14\u201320.\nWarren, I. (ed.). 1998. The Renaissance of Legacy Systems. London: Springer.\n", "page": 283, "type": "text", "section": "Page 283"}
{"text": "PART \nAs software systems are now part of all aspects of our lives, I believe that \nthe most significant challenge that we face in software engineering is \nensuring that we can trust these systems. To trust a system, we must have \n\u00ad\nconfidence that it will be available when required and perform as expected. \nIt must be secure so that our computers or data are not threatened by it and \nit has to recover quickly in the event of failure or cyberattack. This part of \nthe book has therefore focuses on the important topics of software system \ndependability and security.\nChapter 10 introduces the basic concepts of dependability and security \nnamely reliability, availability, safety, security and resilience. I explain \nwhy building secure, dependable systems is not simply a technical \nproblem. I introduce redundancy and diversity as the fundamental \nmechanisms used to create dependable and secure systems. The indi-\nvidual dependability attributes are covered in more detail in the fol-\nlowing chapters.\nChapter 11 focuses on reliability and availability and I explain how these \nattributes can be specified as probabilities of failure or downtime. I dis-\ncuss a number of architectural patterns for fault-tolerant system architec-\ntures and development techniques that can be used to reduce the number \nof faults in a system. In the final section, I explain how the reliability of a \nsystem may be tested and measured.\n2\nDependability \nand Security\n", "page": 284, "type": "text", "section": "Page 284"}
{"text": "More and more systems are safety-critical systems, where system failure \ncan endanger people. Chapter 12 is concerned with safety engineering \nand techniques that may be used to develop these safety-critical systems. \nI explain why safety is a broader notion than reliability and discuss meth-\nods for deriving system safety requirements. I also explain why defined \nand documented processes for safety-critical systems engineering are \nimportant and describe software safety cases\u2014structured documents \nthat are used to justify why a system is safe.\nThreats to the security of our systems are one of the major problems \nfaced by today\u2019s societies and I devote two chapters to this topic. \nChapter 13 is concerned with application security engineering\u2014\u00ad\nmethods \nused to achieve security in individual software systems. I explain the \nrelationships between security and other dependability attributes and \ncover security requirements engineering, secure systems design and \nsecurity testing.\nChapter 14 is a new chapter that addresses the broader issue of resil-\nience. A resilient system can continue to deliver its essential services \neven when individual parts of the system fail or are subject to a cyberat-\ntack. I explain the basics of cybersecurity and discuss how resilience is \nachieved by using redundancy and diversity and by empowering people \nas well as through technical mechanisms. Finally, I discuss systems and \nsoftware design issues that can contribute to improving the resilience of \na system.\n", "page": 285, "type": "text", "section": "Page 285"}
{"text": "Dependable systems\n10 \nObjectives\nThe objective of this chapter is to introduce the topic of software \ndependability and what is involved in developing dependable software \nsystems. When you have read this chapter, you will:\n\u25a0\t understand why dependability and security are important attributes \nfor all software systems;\n\u25a0\t understand the five important dimensions of dependability, namely, \navailability, reliability, safety, security, and resilience;\n\u25a0\t understand the notion of sociotechnical systems and why we have to \nconsider these systems as a whole rather than just software systems;\n\u25a0\t know why redundancy and diversity are the fundamental concepts \nused in achieving dependable systems and processes;\n\u25a0\t be aware of the potential for using formal methods in dependable \nsystems engineering.\nContents\n10.1\tDependability properties\n10.2\tSociotechnical systems\n10.3\tRedundancy and diversity\n10.4\tDependable processes\n10.5\tFormal methods and dependability\n", "page": 286, "type": "text", "section": "Page 286"}
{"text": "286\u2002 \u2002 Chapter 10\u2002 \u25a0\u2002 Dependable systems\nAs computer systems have become deeply embedded in our business and personal \nlives, the problems that result from system and software failure are increasing. A \nfailure of server software in an e-commerce company could lead to a major loss of \nrevenue and customers for that company. A software error in an embedded control \nsystem in a car could lead to expensive recalls of that model for repair and, in the \nworst case, could be a contributory factor in accidents. The infection of company \nPCs with malware requires expensive clean-up operations to sort out the problem \nand could lead to the loss of or damage to sensitive information.\nBecause software-intensive systems are so important to governments, companies, \nand individuals, we have to be able to trust these systems. The software should be \navailable when it is needed, and it should operate correctly without undesirable side \neffects, such as unauthorized information disclosure. In short, we should be able to \ndepend on our software systems.\nThe term dependability was proposed by Jean-Claude Laprie in 1995 to cover the \nrelated systems attributes of availability, reliability, safety, and security. His ideas \nwere revised over the next few years and are discussed in a definitive paper pub-\nlished in 2004 (Avizienis et al. 2004). As I discuss in Section 10.1, these properties \nare inextricably linked, so having a single term to cover them all makes sense.\nThe dependability of systems is usually more important than their detailed func-\ntionality for the following reasons:\n1.\t System failures affect a large number of people Many systems include func-\ntionality that is rarely used. If this functionality were left out of the system, only \na small number of users would be affected. System failures that affect the avail-\nability of a system potentially affect all users of the system. Unavailable sys-\ntems may mean that normal business is impossible.\n2.\t\nUsers often reject systems that are unreliable, unsafe, or insecure If users find \nthat a system is unreliable or insecure, they will refuse to use it. Furthermore, \nthey may also refuse to buy or use other products from the company that pro-\nduced the unreliable system. They do not want a repetition of their bad experi-\nence with an undependable system.\n3.\t\nSystem failure costs may be enormous For some applications, such as a reactor \ncontrol system or an aircraft navigation system, the cost of system failure is \norders of magnitude greater than the cost of the control system. Failures in sys-\ntems that control critical infrastructure such as the power network have wide-\nspread economic consequences.\n4.\t\nUndependable systems may cause information loss Data is very expensive to collect \nand maintain; it is usually worth much more than the computer system on which it \nis processed. The cost of recovering lost or corrupt data is usually very high.\nHowever, a system can be useful without it being very dependable. I don\u2019t think \nthat the word processor that I used to write this book is a very dependable system. \nIt\u00a0sometimes freezes and has to be restarted. Nevertheless, because it is very useful, \n", "page": 287, "type": "text", "section": "Page 287"}
{"text": "\t\nChapter 10\u2002 \u25a0\u2002 Dependable systems\u2002 \u2002 287\nI am prepared to tolerate occasional failure. However, to reflect my lack of trust in \nthe system, I save my work frequently and keep multiple backup copies of it. I com-\npensate for the lack of system dependability by actions that limit the damage that \ncould result from system failure.\nBuilding dependable software is part of the more general process of dependable \nsystems engineering. As I discuss in Section 10.2, software is always part of a \nbroader system. It executes in an operational environment that includes the hardware \non which the software executes, the human users of that software and the organiza-\ntional or business processes where the software is used. When designing a \u00ad\ndependable \nsystem, you therefore have to consider:\n1.\t\nHardware failure System hardware may fail because of mistakes in its design, \nbecause components fail as a result of manufacturing errors, because of envi-\nronmental factors such as dampness or high temperatures, or because compo-\nnents have reached the end of their natural life.\n2.\t\nSoftware failure System software may fail because of mistakes in its specifica-\ntion, design, or implementation.\n3.\t\nOperational failure Human users may fail to use or operate the system as \nintended by its designers. As hardware and software have become more reliable, \nfailures in operation are now, perhaps, the largest single cause of system failures.\nThese failures are often interrelated. A failed hardware component may mean \nsystem operators have to cope with an unexpected situation and additional workload. \nThis puts them under stress, and people under stress often make mistakes. These \nmistakes can cause the software to fail, which means more work for operators, even \nmore stress, and so on.\nAs a result, it is particularly important that designers of dependable, software-\nintensive systems take a holistic sociotechnical systems perspective rather than focus \non a single aspect of the system such as its software or hardware. If hardware, soft-\nware, and operational processes are designed separately, without taking into account \nthe potential weaknesses of other parts of the system, then it is more likely that errors \nwill occur at the interfaces between the different parts of the system.\nCritical systems\nSome classes of system are \u201ccritical systems\u201d where system failure may result in injury to people, damage to the \nenvironment, or extensive economic losses. Examples of critical systems include embedded systems in medical \ndevices, such as an insulin pump (safety-critical), spacecraft navigation systems (mission-critical), and online \nmoney transfer systems (business critical).\nCritical systems are very expensive to develop. Not only must they be developed so that failures are very rare, \nbut they must also include recovery mechanisms to be used if and when failures occur.\nhttp://software-engineering-book.com/web/critical-systems/\n", "page": 288, "type": "text", "section": "Page 288"}
{"text": "288\u2002 \u2002 Chapter 10\u2002 \u25a0\u2002 Dependable systems\n \n10.1  Dependability properties\nAll of us are familiar with the problem of computer system failure. For no obvious \nreason, our computers sometimes crash or go wrong in some way. Programs running \non these computers may not operate as expected and occasionally may corrupt the \ndata that is managed by the system. We have learned to live with these failures, but \nfew of us completely trust the personal computers that we normally use.\nThe dependability of a computer system is a property of the system that reflects \nits trustworthiness. Trustworthiness here essentially means the degree of confidence \na user has that the system will operate as they expect and that the system will not \n\u201cfail\u201d in normal use. It is not meaningful to express dependability numerically. \nRather, relative terms such as \u201cnot dependable,\u201d \u201cvery dependable,\u201d and \u201cultra-\ndependable\u201d can reflect the degree of trust that we might have in a system.\nThere are five principal dimensions to dependability, as I have shown in \nFigure 10.1.\n1.\t\nAvailability Informally, the availability of a system is the probability that it will \nbe up and running and able to deliver useful services to users at any given time.\n2.\t\nReliability Informally, the reliability of a system is the probability, over a given \nperiod of time, that the system will correctly deliver services as expected by the user.\n3.\t\nSafety Informally, the safety of a system is a judgment of how likely it is that the \nsystem will cause damage to people or its environment.\n4.\t\nSecurity Informally, the security of a system is a judgment of how likely it is \nthat the system can resist accidental or deliberate intrusions.\n5.\t\nResilience Informally, the resilience of a system is a judgment of how well that \n\u00ad\nsystem can maintain the continuity of its critical services in the presence of \n\u00ad\ndisruptive events, such as equipment failure and cyberattacks. Resilience is a \nmore recent addition to the set of dependability properties that were originally \nsuggested by Laprie.\nThe dependability properties shown in Figure 10.1 are complex properties that \ncan be broken down into several simpler properties. For example, security includes \n\u201cintegrity\u201d (ensuring that the systems program and data are not damaged) and \u201ccon-\nfidentiality\u201d (ensuring that information can only be accessed by people who are \nauthorized). Reliability includes \u201ccorrectness\u201d (ensuring the system services are as \nspecified), \u201cprecision\u201d (ensuring information is delivered at an appropriate level of \ndetail), and \u201ctimeliness\u201d (ensuring that information is delivered when it is required).\nOf course, not all dependability properties are critical for all systems. For the \ninsulin pump system, introduced in Chapter 1, the most important properties are reli-\nability (it must deliver the correct dose of insulin) and safety (it must never deliver a \ndangerous dose of insulin). Security is not an issue as the pump does not store confi-\ndential information. It is not networked and so cannot be maliciously attacked. For \n", "page": 289, "type": "text", "section": "Page 289"}
{"text": "\t\n10.1\u2002 \u25a0\u2002 Dependability properties\u2002 \u2002 289\nthe wilderness weather system, availability and reliability are the most important \nproperties because the costs of repair may be very high. For the Mentcare patient \ninformation system, security and resilience are particularly important because of the \nsensitive private data that is maintained and the need for the system to be available \nfor patient consultations.\nOther system properties are closely related to these five dependability properties \nand influence a system\u2019s dependability:\n1.\t\nRepairability System failures are inevitable, but the disruption caused by failure \ncan be minimized if the system can be repaired quickly. It must be possible to \ndiagnose the problem, access the component that has failed, and make changes \nto fix that component. Repairability in software is enhanced when the organiza-\ntion using the system has access to the source code and has the skills to make \nchanges to it. Open-source software makes this easier, but the reuse of compo-\nnents can make it more difficult.\n2.\t\nMaintainability As systems are used, new requirements emerge, and it is impor-\ntant to maintain the value of a system by changing it to include these new \nrequirements. Maintainable software is software that can be adapted economi-\ncally to cope with new requirements, and where there is a low probability that \nmaking changes will introduce new errors into the system.\n3.\t\nError tolerance This property can be considered as part of usability and reflects \nthe extent to which the system has been designed, so that user input errors are \navoided and tolerated. When user errors occur, the system should, as far as pos-\nsible, detect these errors and either fix them automatically or request the user to \nre-input their data.\nThe notion of system dependability as an encompassing property was introduced \nbecause the dependability properties of availability, security, reliability, safety, and \nresilience are closely related. Safe system operation usually depends on the system \nbeing available and operating reliably. A system may become unreliable because an \nintruder has corrupted its data. Denial-of-service attacks on a system are intended to \nDependability\nAvailability\nReliability\nSecurity\nSafety\nResilience\nThe ability of the system \nto protect itself against \ndeliberate or accidental \nintrusion\nThe ability of the system \nto resist and recover \nfrom damaging events\nThe ability of the system \nto operate without \ncatastrophic failure\nThe ability of the system \nto deliver services as \nspecified\nThe ability of the system \nto deliver services when \nrequested\nFigure 10.1\u2002 Principal \ndependability  \nproperties \n", "page": 290, "type": "text", "section": "Page 290"}
{"text": "290\u2002 \u2002 Chapter 10\u2002 \u25a0\u2002 Dependable systems\ncompromise the system\u2019s availability. If a system is infected with a virus, you cannot \nthen be confident in its reliability or safety because the virus may change its behavior.\nTo develop dependable software, you therefore need to ensure that:\n1.\t\nYou avoid the introduction of accidental errors into the system during software \nspecification and development.\n2.\t\nYou design verification and validation processes that are effective in discover-\ning residual errors that affect the dependability of the system.\n3.\t\nYou design the system to be fault tolerant so that it can continue working when \nthings go wrong.\n4.\t\nYou design protection mechanisms that guard against external attacks that can \ncompromise the availability or security of the system.\n5.\t\nYou configure the deployed system and its supporting software correctly for its \noperating environment.\n6.\t\nYou include system capabilities to recognize external cyberattacks and to resist \nthese attacks.\n7.\t\nYou design systems so that they can quickly recover from system failures and \ncyberattacks without the loss of critical data.\nThe need for fault tolerance means that dependable systems have to include \nredundant code to help them monitor themselves, detect erroneous states, and \nrecover from faults before failures occur. This affects the performance of systems, as \nadditional checking is required each time the system executes. Therefore, designers \nusually have to trade off performance and dependability. You may need to leave \nchecks out of the system because these slow the system down. However, the conse-\nquential risk here is that the system fails because a fault has not been detected.\nBuilding dependable systems is expensive. Increasing the dependability of a \n\u00ad\nsystem means that you incur extra costs for system design, implementation, and val-\nidation. Verification and validation costs are particularly high for systems that must \nbe ultra-dependable such as safety-critical control systems. As well as validating that \nthe system meets its requirements, the validation process may have to prove to an \nexternal regulator that the system is safe. For example, aircraft systems have to dem-\nonstrate to regulators, such as the Federal Aviation Authority, that the probability of \na catastrophic system failure that affects aircraft safety is extremely low.\nFigure 10.2 shows the relationship between costs and incremental improvements \nin dependability. If your software is not very dependable, you can get significant \nimprovements fairly cheaply by using better software engineering. However, if you \nare already using good practice, the costs of improvement are much greater, and the \nbenefits from that improvement are less.\nThere is also the problem of testing software to demonstrate that it is dependable. \nSolving this problem relies on running many tests and looking at the number of fail-\nures that occur. As your software becomes more dependable, you see fewer and \n", "page": 291, "type": "text", "section": "Page 291"}
{"text": "\t\n10.2\u2002 \u25a0\u2002 Sociotechnical systems\u2002 \u2002 291\nfewer failures. Consequently, more and more tests are needed to try and assess how \nmany problems remain in the software. Testing is a very expensive process, so this \ncan significantly increase the cost of high-dependability systems.\n \n10.2  Sociotechnical systems\nIn a computer system, the software and the hardware are interdependent. Without \nhardware, a software system is an abstraction, which is simply a representation of \nsome human knowledge and ideas. Without software, hardware is a set of inert elec-\ntronic devices. However, if you put them together to form a system, you create a \nmachine that can carry out complex computations and deliver the results of these \ncomputations to its environment.\nThis illustrates one of the fundamental characteristics of a system\u2014it is more than \nthe sum of its parts. Systems have properties that become apparent only when their \ncomponents are integrated and operate together. Software systems are not isolated \nsystems but are part of more extensive systems that have a human, social, or organi-\nzational purpose. Therefore software engineering is not an isolated activity but is an \nintrinsic part of systems engineering (Chapter 19).\nFor example, the wilderness weather system software controls the instruments in \na weather station. It communicates with other software systems and is a part of wider \nnational and international weather forecasting systems. As well as hardware and \nsoftware, these systems include processes for forecasting the weather and people \nwho operate the system and analyze its outputs. The system also includes the organ-\nizations that depend on the system to help them provide weather forecasts to indi-\nviduals, government and industry.\nCost\nLow\nMedium\nHigh\nVery\nhigh\nUltra-\nhigh\nDependability\nFigure 10.2\u2002 Cost/\ndependability curve \n", "page": 292, "type": "text", "section": "Page 292"}
{"text": "292\u2002 \u2002 Chapter 10\u2002 \u25a0\u2002 Dependable systems\nThese broader systems are called sociotechnical systems. They include nontech-\nnical elements such as people, processes, and regulations, as well as technical \n\u00ad\ncomponents such as computers, software, and other equipment. System \u00ad\ndependability \nis influenced by all of the elements in a sociotechnical system\u2014hardware, software, \npeople, and organizations.\nSociotechnical systems are so complex that it is impossible to understand them as \na whole. Rather, you have to view them as layers, as shown in Figure 10.3. These \nlayers make up the sociotechnical systems stack:\n1.\t\nThe equipment layer is composed of hardware devices, some of which may be \ncomputers.\n2.\t\nThe operating system layer interacts with the hardware and provides a set of \ncommon facilities for higher software layers in the system.\n3.\t\nThe communications and data management layer extends the operating system \nfacilities and provides an interface that allows interaction with more extensive \nfunctionality, such as access to remote systems and access to a system database. \nThis is sometimes called middleware, as it is in between the application and the \noperating system.\n4.\t\nThe application layer delivers the application-specific functionality that is \nrequired. There may be many different application programs in this layer.\n5.\t\nThe business process layer includes the organizational business processes, \nwhich make use of the software system.\n6.\t\nThe organizational layer includes higher-level strategic processes as well as \nbusiness rules, policies, and norms that should be followed when using the \n\u00ad\nsystem.\n7.\t\nThe social layer refers to the laws and regulations of society that govern the \noperation of the system.\nEquipment\nOperating system\nCommunications and data management\nApplication system\nBusiness processes\nOrganization\nSociety\nSystems\nengineering\nSoftware\nengineering\nFigure 10.3\u2002 The \nsociotechnical \nsystems stack \n", "page": 293, "type": "text", "section": "Page 293"}
{"text": "\t\n10.2\u2002 \u25a0\u2002 Sociotechnical systems\u2002 \u2002 293\nNotice that there is no separate \u201csoftware layer.\u201d Software of one kind or another \nis an important part of all of the layers in the sociotechnical system. Equipment is \ncontrolled by embedded software; the operating system and applications are soft-\nware. Business processes, organizations, and society rely on the Internet (software) \nand other global software systems.\nIn principle, most interactions should be between neighboring layers in the \nstack, with each layer hiding the detail of the layer below from the layer above. In \npractice, however, there can be unexpected interactions between layers, which \nresult in \u00ad\nproblems for the system as a whole. For example, say there is a change in \nthe law governing access to personal information. This comes from the social layer. \nIt leads to new organizational procedures and changes to the business processes. \nThe application system itself may not be able to provide the required level of pri-\nvacy, so changes may have to be implemented in the communications and data \nmanagement layer.\nThinking holistically about systems, rather than simply considering software in \nisolation, is essential when considering software security and dependability. \nSoftware itself is intangible and, even when damaged, is easily and cheaply restored. \nHowever, when these software failures ripple through other parts of the system, they \naffect the software\u2019s physical and human environment. Here, the consequences of \nfailure are more significant. Important data may be lost or corrupted. People may \nhave to do extra work to contain or recover from the failure; for example, equipment \nmay be damaged, data may be lost or corrupted, or confidentiality may be breached, \nwith unknown consequences.\nYou must, therefore, take a system-level view when you are designing software \nthat has to be dependable and secure. You have to take into account the consequences \nof software failures for other elements in the system. You also need to understand \nhow these other system elements may be the cause of software failure and how they \ncan help to protect against and recover from software failures.\nIt is important to ensure that, wherever possible, software failure does not lead to \noverall system failure. You must therefore examine how the software interacts with \nits immediate environment to ensure that:\n1.\t\nSoftware failures are, as far as possible, contained within the enclosing layer of \nthe system stack and do not seriously affect the operation of other layers in the \nsystem.\n2.\t\nYou understand how faults and failures in the other layers of the systems stack \nmay affect the software. You may also consider how checks may be built into \nthe software to help detect these failures, and how support can be provided for \nrecovering from failure.\nAs software is inherently flexible, unexpected system problems are often left to \nsoftware engineers to solve. Say a radar installation has been sited so that ghosting \nof the radar image occurs. It is impractical to move the radar to a site with less \n\u00ad\ninterference, so the systems engineers have to find another way of removing this \n", "page": 294, "type": "text", "section": "Page 294"}
{"text": "294\u2002 \u2002 Chapter 10\u2002 \u25a0\u2002 Dependable systems\nghosting. Their solution may be to enhance the image-processing capabilities of the \nsoftware to remove the ghost images. This may slow down the software so that its \nperformance becomes unacceptable. The problem may then be characterized as a \nsoftware failure, whereas, in fact, it is a failure in the design process for the system \nas a whole.\nThis sort of situation, in which software engineers are left with the problem of \nenhancing software capabilities without increasing hardware cost, is very common. \nMany so-called software failures are not a consequence of inherent software prob-\nlems but rather are the result of trying to change the software to accommodate mod-\nified system engineering requirements. A good example was the failure of the \nDenver airport baggage system (Swartz 1996), where the controlling software was \nexpected to deal with limitations of the equipment used.\n\t\n10.2.1 \t Regulation and compliance\nThe general model of economic organization that is now almost universal in the \nworld is that privately owned companies offer goods and services and make a profit \non these. We have a competitive environment so that these companies may compete \non cost, on quality, on delivery time, and so on. However, to ensure the safety of \ntheir citizens, most governments limit the freedom of privately owned companies so \nthat they must follow certain standards to ensure that their products are safe and \nsecure. A company therefore cannot offer products for sale more cheaply because \nthey have reduced their costs by reducing the safety of their products.\nGovernments have created a set of rules and regulations in different areas that \ndefine standards for safety and security. They have also established regulators or \nregulatory bodies whose job is to ensure that companies offering products in an area \ncomply with these rules. Regulators have wide powers. They can fine companies and \neven imprison directors if regulations are breached. They may have a licensing role \n(e.g., in the aviation and nuclear industries) where they must issue a license before a \nnew system may be used. Therefore, aircraft manufacturers have to have a certificate \nof airworthiness from the regulator in each country where the aircraft is used.\nTo achieve certification, companies that are developing safety-critical systems \nhave to produce an extensive safety case (discussed in Chapter 13) that shows that \nrules and regulations have been followed. The case must convince a regulator that \nthe system can operate safely. Developing such a safety case is very costly. It can be \nas expensive to develop the documentation for certification as it is to develop the \nsystem itself.\nRegulation and compliance (following the rules) applies to the sociotechnical \nsystem as a whole and not simply the software element of that system. For example, \na regulator in the nuclear industry is concerned that in the event of overheating, a \nnuclear reactor will not release radioactivity into the environment. Arguments to \nconvince the regulator that this is the case may be based on software protection sys-\ntems, the operational process used to monitor the reactor core and the integrity of \nstructures that contain any release of radioactivity.\n", "page": 295, "type": "text", "section": "Page 295"}
{"text": "\t\n10.3\u2002 \u25a0\u2002 Redundancy and diversity\u2002 \u2002 295\nEach of these elements has to have its own safety case. So, the protection system \nmust have a safety case that demonstrates that the software will operate correctly and \nshut down the reactor as intended. The overall case must also show that if the soft-\nware protection system fails, there are alternative safety mechanisms, which do not \nrely on software, that are invoked.\n \n10.3  Redundancy and diversity\nComponent failures in any system are inevitable. People make mistakes, undiscov-\nered bugs in software cause undesirable behavior, and hardware burns out. We use a \nrange of strategies to reduce the number of human failures such as replacing hard-\nware components before the end of their predicted lifetime and checking software \nusing static analysis tools. However, we cannot be sure that these will eliminate \ncomponent failures. We should therefore design systems so that individual compo-\nnent failures do not lead to overall system failure.\nStrategies to achieve and enhance dependability rely on both redundancy and \ndiversity. Redundancy means that spare capacity is included in a system that can be \nused if part of that system fails. Diversity means that redundant components of the \nsystem are of different types, thus increasing the chances that they will not fail in \nexactly the same way.\nWe use redundancy and diversity to enhance dependability in our everyday \nlives. Commonly, to secure our homes we use more than one lock (redundancy), \nand, usually, the locks used are of different types (diversity). This means that if \nintruders find a way to defeat one of the locks, they have to find a different way of \ndefeating the other locks before they can gain entry. As a matter of routine, we \nshould all back up our computers and so maintain redundant copies of our data. To \navoid problems with disk failure, backups should be kept on a separate, diverse, \nexternal device.\nSoftware systems that are designed for dependability may include redundant \ncomponents that provide the same functionality as other system components. These \nare switched into the system if the primary component fails. If these redundant com-\nponents are diverse, that is, not the same as other components, a common fault in \nreplicated components will not result in a system failure. Another form of redun-\ndancy is the inclusion of checking code, which is not strictly necessary for the sys-\ntem to function. This code can detect some kinds of problems, such as data corruption, \nbefore they cause failures. It can invoke recovery mechanisms to correct problems to \nensure that the system continues to operate.\nIn systems for which availability is a critical requirement, redundant servers are \nnormally used. These automatically come into operation if a designated server fails. \nSometimes, to ensure that attacks on the system cannot exploit a common vulnera-\nbility, these servers may be of different types and may run different operating sys-\ntems. Using different operating systems is an example of software diversity and \n", "page": 296, "type": "text", "section": "Page 296"}
{"text": "296\u2002 \u2002 Chapter 10\u2002 \u25a0\u2002 Dependable systems\nredundancy, where similar functionality is provided in different ways. (I discuss \nsoftware diversity in more detail in Chapter 12.)\nDiversity and redundancy may also be also used in the design of dependable soft-\nware development processes. Dependable development processes avoid the intro-\nduction of faults into a system. In a dependable process, activities such as software \nvalidation do not rely on a single tool or technique. This improves software depend-\nability because it reduces the chances of process failure, where human errors made \nduring the software development process lead to software errors.\nFor example, validation activities may include program testing, manual program \ninspections, and static analysis as fault-finding techniques. Any one of these techniques \nmight find faults that are missed by the other methods. Furthermore, different team \nmembers may be responsible for the same process activity (e.g., a program inspection). \nPeople tackle tasks in different ways depending on their personality, experience, and \neducation, so this kind of redundancy provides a diverse perspective on the system.\nHowever, as I discuss in Chapter 11, using software redundancy and diversity \ncan itself introduce bugs into software. Diversity and redundancy make systems \nmore complex and usually harder to understand. Not only is there more code to \nwrite and check, but additional functionality must also be added to the system to \ndetect component failure and to switch control to alternative components. This addi-\ntional complexity means that it is more likely that programmers will make errors \nand less likely that people checking the system will find these errors.\nSome engineers therefore think that, as software cannot wear out, it is best to \navoid software redundancy and diversity. Their view is that the best approach is to \ndesign the software to be as simple as possible, with extremely rigorous software \nverification and validation procedures (Parnas, van Schouwen, and Shu 1990). More \ncan be spent on verification and validation because of the savings that result from \nnot having to develop redundant software components.\nBoth approaches are used in commercial, safety-critical software systems. For \nexample, the Airbus 340 flight control hardware and software is both diverse and \nredundant. The flight control software on the Boeing 777 runs on redundant hard-\nware, but each computer runs the same software, which has been very extensively \nvalidated. The Boeing 777 flight control system designers have focused on simplic-\nity rather than redundancy. Both of these aircraft are very reliable, so both the diverse \nand the simple approach to dependability can clearly be successful.\nThe Ariane 5 explosion\nIn 1996, the European Space Agency\u2019s Ariane 5 rocket exploded 37 seconds after lift-off on its maiden flight. \nThe fault was caused by a software systems failure. There was a backup system but it was not diverse, and \nso the software in the backup computer failed in exactly the same way. The rocket and its satellite payload \nwere destroyed.\nhttp://software-engineering-book.com/web/ariane/\n", "page": 297, "type": "text", "section": "Page 297"}
{"text": "\t\n10.4\u2002 \u25a0\u2002 Dependable processes\u2002 \u2002 297\n \n10.4  Dependable processes\nDependable software processes are software processes that are designed to pro-\nduce dependable software. The rationale for investing in dependable processes is \nthat a good software process is likely to lead to delivered software that contains \nfewer errors and is therefore less likely to fail in execution. A company using a \n\u00ad\ndependable process can be sure that the process has been properly enacted and \ndocumented and that appropriate development techniques have been used for crit-\nical systems \u00ad\ndevelopment. Figure 10.4 shows some of the attributes of dependable \nsoftware \u00ad\nprocesses.\nThe evidence that a dependable process has been used is often important in con-\nvincing a regulator that the most effective software engineering practice has been \napplied in developing the software. System developers will normally present a model \nof the process to a regulator, along with evidence that the process has been followed. \nThe regulator also has to be convinced that the process is used consistently by all of \nthe process participants and that it can be used in different development projects. \nThis means that the process must be explicitly defined and repeatable:\n1.\t\nAn explicitly defined process is one that has a defined process model that is \nused to drive the software production process. Data must be collected during the \nprocess that proves that the development team has followed the process as \ndefined in the process model.\n2.\t\nA repeatable process is one that does not rely on individual interpretation and \njudgment. Rather, the process can be repeated across projects and with different \nteam members, irrespective of who is involved in the development. This is par-\nticularly important for critical systems, which often have a long development \ncycle during which there are often significant changes in the development team.\nDependable processes make use of redundancy and diversity to achieve reliabil-\nity. They often include different activities that have the same aim. For example, \nprogram inspections and testing aim to discover errors in a program. The approaches \ncan be used together so that they are likely to find more errors than would be found \nusing one technique on its own.\nDependable operational processes\nThis chapter discusses dependable development processes, but system operational processes are equally \nimportant contributors for system dependability. In designing these operational processes, you have to take into \naccount human factors and always bear in mind that people are liable to make mistakes when using a system. \nA dependable process should be designed to avoid human errors, and, when mistakes are made, the software \nshould detect the mistakes and allow them to be corrected.\nhttp://software-engineering-book.com/web/human-error/\n", "page": 298, "type": "text", "section": "Page 298"}
{"text": "298\u2002 \u2002 Chapter 10\u2002 \u25a0\u2002 Dependable systems\nThe activities that are used in dependable processes obviously depend on the type \nof software that is being developed. In general, however, these activities should be \ngeared toward avoiding the introduction of errors into a system, detecting and \nremoving errors, and maintaining information about the process itself.\nExamples of activities that might be included in a dependable process include:\n1.\t\nRequirements reviews to check that the requirements are, as far as possible, \ncomplete and consistent.\n2.\t\nRequirements management to ensure that changes to the requirements are con-\ntrolled and that the impact of proposed requirements changes is understood by \nall developers affected by the change.\n3.\t\nFormal specification, where a mathematical model of the software is created \nand analyzed. (I discussed the benefits of formal specification in Section 10.5.) \nPerhaps its most important benefit is that it forces a very detailed analysis of the \nsystem requirements. This analysis itself is likely to discover requirements \nproblems that may have been missed in requirements reviews.\n4.\t\nSystem modeling, where the software design is explicitly documented as a set of \ngraphical models and the links between the requirements and these models are \nexplicitly documented. If a model-driven engineering approach is used (see \nChapter 5), code may be generated automatically from these models.\n5.\t\nDesign and program inspections, where the different descriptions of the system \nare inspected and checked by different people. A checklist of common design \nand programming errors may be used to focus the inspection process.\n6.\t\nStatic analysis, where automated checks are carried out on the source code of \nthe program. These look for anomalies that could indicate programming errors \nor omissions. (I cover static analysis in Chapter 12.)\n7.\t\nTest planning and management, where a comprehensive set of system tests is \ndesigned. The testing process has to be carefully managed to demonstrate that \nthese tests provide coverage of the system requirements and have been correctly \napplied in the testing process.\nFigure 10.4\u2002 Attributes \nof dependable \nprocesses\nProcess characteristic\nDescription\nAuditable\nThe process should be understandable by people apart from process \nparticipants, who can check that process standards are being followed and \nmake suggestions for process improvement.\nDiverse\nThe process should include redundant and diverse verification and \nvalidation\u00a0activities.\nDocumentable\nThe process should have a defined process model that sets out the activities in \nthe process and the documentation that is to be produced during these activities.\nRobust\nThe process should be able to recover from failures of individual process \nactivities.\nStandardized\nA comprehensive set of software development standards covering software \nproduction and documentation should be available.\n", "page": 299, "type": "text", "section": "Page 299"}
{"text": "\t\n10.5\u2002 \u25a0\u2002 Formal methods and dependability\u2002 \u2002 299\nAs well as process activities that focus on system development and testing, there \nmust also be well-defined quality management and change management processes. \nWhile the specific activities in a dependable process may vary from one company to \nanother, the need for effective quality and change management is universal.\nQuality management processes (covered in Chapter 24) establish a set of process and \nproduct standards. They also include activities that capture process information to dem-\nonstrate that these standards have been followed. For example, there may be a standard \ndefined for carrying out program inspections. The inspection team leader is responsible \nfor documenting the process to show that the inspection standard has been followed.\nChange management, discussed in Chapter 25, is concerned with managing changes \nto a system, ensuring that accepted changes are actually implemented, and confirming \nthat planned releases of the software include the planned changes. One common problem \nwith software is that the wrong components are included in a system build. This can lead \nto a situation where an executing system includes components that have not been checked \nduring the development process. Configuration management procedures must be defined \nas part of the change management process to ensure that this does not happen.\nAs agile methods have become increasingly used, researchers and practitioners have \nthought carefully about how to use agile approaches in dependable software development \n(Trimble 2012). Most companies that develop critical software systems have based their \ndevelopment on plan-based processes and have been reluctant to make radical changes to \ntheir development process. However, they recognize the value of agile approaches and \nare exploring how their dependable development processes can be more agile.\nAs dependable software often requires certification, both process and product \ndocumentation have to be produced. Up-front requirements analysis is also essential \nto discover possible requirements and requirements conflicts that may compromise \nthe safety and security of the system. Formal change analysis is essential to assess \nthe effect of changes on the safety and integrity of the system. These requirements \nconflict with the general approach in agile development of co-development of the \nrequirements and the system and minimizing documentation.\nAlthough most agile development uses an informal, undocumented process, this \nis not a fundamental requirement of agility. An agile process may be defined that \nincorporates techniques such as iterative development, test-first development and \nuser involvement in the development team. As long as the team follows that process \nand documents their actions, agile techniques can be used. To support this notion, \nvarious proposals of modified agile methods have been made that incorporate the \nrequirements of dependable systems engineering (Douglass 2013). These combine \nthe most appropriate techniques from agile and plan-based development.\n \n10.5  Formal methods and dependability\nFor more than 30 years, researchers have advocated the use of formal methods of \n\u00ad\nsoftware development. Formal methods are mathematical approaches to software \ndevelopment where you define a formal model of the software. You may then for-\nmally analyze this model to search for errors and inconsistencies, prove that a program \n", "page": 300, "type": "text", "section": "Page 300"}
{"text": "300\u2002 \u2002 Chapter 10\u2002 \u25a0\u2002 Dependable systems\nis consistent with this model, or you may apply a series of correctness-preserving \ntransformations to the model to generate a program. Abrial (Abrial 2009) claims that \nthe use of formal methods can lead to \u201cfaultless systems,\u201d although he is careful to \nlimit what he means in this claim.\nIn an excellent survey, Woodcock et al. (Woodcock et al. 2009) discuss industrial \napplications where formal methods have been successfully applied. These include \ntrain control systems (Badeau and Amelot 2005), cash card systems (Hall and \nChapman 2002), and flight control systems (Miller et al. 2005). Formal methods are \nthe basis of tools used in static verification, such as the driver verification system \nused by Microsoft (Ball et al. 2006).\nUsing a mathematically formal approach to software development was proposed \nat an early stage in the development of computer science. The idea was that a formal \nspecification and a program could be developed independently. A mathematical \nproof could then be developed to show that the program and its specification were \nconsistent. Initially, proofs were developed manually but this was a long and expen-\nsive process. It quickly became clear that manual proofs could only be developed for \nvery small systems. Program proving is now supported by large-scale automated \ntheorem proving software, which has meant that larger systems can be proved. \nHowever, developing the proof obligations for theorem provers is a difficult and \nspecialized task, so formal verification is not widely used.\nAn alternative approach, which avoids a separate proof activity, is refinement-\nbased development. Here, a formal specification of a system is refined through \na\u00a0 series of correctness-preserving transformations to generate the software. \nBecause these are trusted transformations, you can be confident that the gener-\nated program is consistent with its formal specification. This was the approach \nused in the software development for the Paris Metro system (Badeau and Amelot \n2005). It used a language called B (Abrial 2010), which was designed to support \nspecification refinement.\nFormal methods based on model-checking (Jhala and Majumdar 2009) have been \nused in a number of systems (Bochot et al. 2009; Calinescu and Kwiatkowska 2009). \nThese systems rely on constructing or generating a formal state model of a system \nand using a model-checker to check that properties of the model, such as safety \nproperties, always hold. The model-checking program exhaustively analyzes the \nspecification and either reports that the system property is satisfied by the model or \npresents an example that shows it is not satisfied. If a model can be automatically or \nsystematically generated from a program, this means that bugs in the program can be \nuncovered. (I cover model checking in safety-critical systems in Chapter 12.)\nFormal methods for software engineering are effective for discovering or avoid-\ning two classes of error in software representations:\n1.\t\nSpecification and design errors and omissions. The process of developing and \nanalyzing a formal model of the software may reveal errors and omissions in the \nsoftware requirements. If the model is generated automatically or systematically \nfrom source code, analysis using model checking can discover undesirable \nstates that may occur, such as deadlock in a concurrent system.\n", "page": 301, "type": "text", "section": "Page 301"}
{"text": "\t\n10.5\u2002 \u25a0\u2002 Formal methods and dependability\u2002 \u2002 301\n2.\t\nInconsistencies between a specification and a program. If a refinement method \nis used, mistakes made by developers that make the software inconsistent with \nthe specification are avoided. Program proving discovers inconsistencies \nbetween a program and its specification.\nThe starting point for all formal methods is a mathematical system model, which \nacts as a system specification. To create this model, you translate the system\u2019s user \nrequirements, which are expressed in natural language, diagrams, and tables, into a \nmathematical language that has formally defined semantics. The formal specifica-\ntion is an unambiguous description of what the system should do.\nFormal specifications are the most precise way of specifying systems, and so \nreduce the scope for misunderstanding. Many supporters of formal methods believe \nthat creating formal specification, even without refinement or program proof, is \nworthwhile. Constructing a formal specification forces a detailed analysis of the \nrequirements and this is an effective way of discovering requirements problems. In a \nnatural language specification, errors can be concealed by the imprecision of the \nlanguage. This is not the case if the system is formally specified.\nThe advantages of developing a formal specification and using it in a formal \ndevelopment process are:\n1.\t\nAs you develop a formal specification in detail, you develop a deep and detailed \nunderstanding of the system requirements. Requirements problems that are dis-\ncovered early are usually much cheaper to correct than if they are found at later \nstages in the development process.\n2.\t\nAs the specification is expressed in a language with formally defined semantics, \nyou can analyze it automatically to discover inconsistencies and incompleteness.\n3.\t\nIf you use a method such as the B method, you can transform the formal speci-\nfication into a program through a sequence of correctness-preserving transfor-\nmations. The resulting program is therefore guaranteed to meet its specification.\n4.\t\nProgram testing costs may be reduced because you have verified the program \nagainst its specification. For example, in the development of the software for the \nParis Metro systems, the use of refinement meant that there was no need for \nsoftware component testing and only system testing was required.\nFormal specification techniques\nFormal system specifications may be expressed using two fundamental approaches, either as models of the \n\u00ad\nsystem interfaces (algebraic specifications) or as models of the system state. An extra web chapter on this topic \nshows examples of both of these approaches. The chapter includes a formal specification of part of the insulin \npump system. \nhttp://software-engineering-book.com/web/formal-methods/ (web chapter)\n", "page": 302, "type": "text", "section": "Page 302"}
{"text": "302\u2002 \u2002 Chapter 10\u2002 \u25a0\u2002 Dependable systems\nWoodcock\u2019s survey (Woodcock et al. 2009) found that users of formal methods \nreported fewer errors in the delivered software. Neither the costs nor the time needed \nfor software development were higher than in comparable development projects. \nThere were significant benefits in using formal approaches in safety critical systems \nthat required regulator certification. The documentation produced was an important \npart of the safety case (see Chapter 12) for the system.\nIn spite of these advantages, formal methods have had limited impact on practical \nsoftware development, even for critical systems. Woodcock reports on 62 projects \nover 25 years that used formal methods. Even if we allow for projects that used these \ntechniques but did not report their use, this is a tiny fraction of the total number of \ncritical systems developed in that time. Industry has been reluctant to adopt formal \nmethods for a number of reasons:\n1.\t\nProblem owners and domain experts cannot understand a formal specification, \nso they cannot check that it accurately represents their requirements. Software \nengineers, who understand the formal specification, may not understand the \napplication domain, so they too cannot be sure that the formal specification is an \naccurate reflection of the system requirements.\n2.\t\nIt is fairly easy to quantify the costs of creating a formal specification, but more \ndifficult to estimate the possible cost savings that will result from its use. As a \nresult, managers are unwilling to take the risk of adopting formal methods. They \nare unconvinced by reports of success as, by and large, these came from atypical \nprojects where the developers were keen advocates of a formal approach.\n3.\t\nMost software engineers have not been trained to use formal specification lan-\nguages. Hence, they are reluctant to propose their use in development processes.\n4.\t\nIt is difficult to scale current formal methods up to very large systems. When \nformal methods are used, it is mostly for specifying critical kernel software \nrather than complete systems.\n5.\t\nTool support for formal methods is limited, and the available tools are often \nopen source and difficult to use. The market is too small for commercial tool \nproviders.\n6.\t\nFormal methods are not compatible with agile development where programs are \ndeveloped incrementally. This is not a major issue, however, as most critical \nsystems are still developed using a plan-based approach.\nParnas, an early advocate of formal development, has criticized current formal \nmethods and claims that these have started from a fundamentally wrong premise \n(Parnas 2010). He believes that these methods will not gain acceptance until they \nare radically simplified, which will require a different type of mathematics as a \nbasis. My own view is that even this will not mean that formal methods are rou-\ntinely adopted for critical systems engineering unless it can be clearly demon-\nstrated that their adoption and use is cost-effective, compared to other software \nengineering methods.\n", "page": 303, "type": "text", "section": "Page 303"}
{"text": "Key Points\n\u25a0\t System dependability is important because failure of critical computer systems can lead to large \neconomic losses, serious information loss, physical damage or threats to human life.\n\u25a0\t The dependability of a computer system is a system property that reflects the user\u2019s degree of \ntrust in the system. The most important dimensions of dependability are availability, reliability, \nsafety, security, and resilience.\n\u25a0\t Sociotechnical systems include computer hardware, software, and people, and are situated within \nan organization. They are designed to support organizational or business goals and objectives.\n\u25a0\t The use of a dependable, repeatable process is essential if faults in a system are to be \n\u00ad\nminimized. The process should include verification and validation activities at all stages, from \nrequirements definition through to system implementation.\n\u25a0\t The use of redundancy and diversity in hardware, software processes, and software systems is \nessential to the development of dependable systems.\n\u25a0\t Formal methods, where a formal model of a system is used as a basis for development, help reduce \nthe number of specification and implementation errors in a system. However, formal methods have \nhad a limited take-up in industry because of concerns about the cost-effectiveness of this approach.\nFurther Reading\n\u201cBasic Concepts and Taxonomy of Dependable and Secure Computing.\u201d This work presents a \u00ad\nthorough \ndiscussion of dependability concepts written by some of the pioneers in the field who were\u00a0responsible \nfor developing these ideas. (A. Avizienis, J.-C. Laprie, B. Randell and C. Landwehr., IEEE Transactions on \nDependable and Secure Computing, 1 (1), 2004) http://dx.doi.org/10.1109/TDSC.2004.2\nFormal Methods: Practice and Experience. An excellent survey of the use of formal methods in \n\u00ad\nindustry, along with a description of some projects that have used formal methods. The authors \n\u00ad\npresent a realistic summary of the barriers to the use of these methods. (J. Woodcock, P. G. Larsen, \nJ.\u00a0Bicarregui, and J. Fitzgerald. Computing Surveys, 41 (1) January 2009) http://dx.doi.org/10.1145/ \n1592434.1592436\nThe LSCITS Socio-technical Systems Handbook. This handbook introduces sociotechnical systems \nin\u00a0an accessible way and provides access to more detailed papers on sociotechnical topics. (2012) \nhttp://archive.cs.st-andrews.ac.uk/STSE-Handbook/\nWebsite\nPowerPoint slides for this chapter:\nwww.pearsonglobaleditions.com/Sommerville\nLinks to supporting videos:\nhttp://software-engineering-book.com/videos/critical-systems/\n\t\nChapter 10\u2002 \u25a0\u2002 Website\u2002 \u2002 303\n", "page": 304, "type": "text", "section": "Page 304"}
{"text": "Exercises\n\u2002 10.1.\t \u0007\nSuggest six reasons why software dependability is important in most sociotechnical systems.\n\u2002 10.2.\t \u0007\nExplain with an example why resilience to cyber attacks is a very important characteristic of \nsystem dependability.\n\u2002 10.3.\t \u0007\nUsing an example, explain why it is important when developing dependable systems to consider \nthese as sociotechnical systems and not simply as technical software and hardware systems.\n\u2002 10.4.\t\u0007\nGive two examples of government functions that are supported by complex sociotechnical \nsystems and explain why, in the foreseeable future, these functions cannot be completely \nautomated.\n\u2002 10.5.\t Explain the difference between redundancy and diversity.\n\u2002 10.6.\t \u0007\nExplain why it is reasonable to assume that the use of dependable processes will lead to the \ncreation of dependable software.\n\u2002 10.7.\t \u0007\nGive two examples of diverse, redundant activities that might be incorporated into depend-\nable processes.\n\u2002 10.8.\t \u0007\nGive two reasons why different versions of a system based on software diversity may fail in \na\u00a0similar way.\n\u2002 10.9.\t \u0007\nYou are an engineer in charge of the development of a small, safety-critical train control \n\u00ad\nsystem, which must be demonstrably safe and secure. You suggest that formal methods \nshould be used in the development of this system, but your manager is skeptical of this \napproach. Write a report highlighting the benefits of formal methods and presenting a \ncase\u00a0for their use in this project.\n10.10.\t \u0007\nIt has been suggested that the need for regulation inhibits innovation and that regulators \nforce the use of older methods of systems development that have been used on other \n\u00ad\nsystems. Discuss whether or not you think this is true and the desirability of regulators \nimposing their views on what methods should be used.\nReferences\nAbrial, J. R. 2009. \u201cFaultless Systems: Yes We Can.\u201d IEEE Computer 42 (9): 30\u201336. doi:10.1109/\nMC.2009.283.\n\t\n\u2002 \u2002 . 2010. Modeling in Event-B: System and Software Engineering. Cambridge, UK: Cambridge \nUniversity Press.\nAvizienis, A., J. C. Laprie, B. Randell, and C. Landwehr. 2004. \u201cBasic Concepts and Taxonomy of \nDependable and Secure Computing.\u201d IEEE Trans. on Dependable and Secure Computing 1 (1): 11\u201333. \ndoi:10.1109/TDSC.2004.2.\nBadeau, F., and A. Amelot. 2005. \u201cUsing B as a High Level Programming Language in an Industrial \nProject: Roissy VAL.\u201d In Proc. ZB 2005: Formal Specification and Development in Z and B. Guildford, \nUK: Springer. doi:10.1007/11415787_20.\n304\u2002 \u2002 Chapter 10\u2002 \u25a0\u2002 Dependable systems\n", "page": 305, "type": "text", "section": "Page 305"}
{"text": "\t\nChapter 10\u2002 \u25a0\u2002 References\u2002 \u2002 305\nBall, T., E. Bounimova, B. Cook, V. Levin, J. Lichtenberg, C. McGarvey, B. Ondrusek, S. K. Rajamani, \nand A. Ustuner. 2006. \u201cThorough Static Analysis of Device Drivers.\u201d In Proc. EuroSys 2006. Leuven, \nBelgium. doi:10.1145/1218063.1217943.\nBochot, T., P. Virelizier, H. Waeselynck, and V. Wiels. 2009. \u201cModel Checking Flight Control Sys-\ntems: The Airbus Experience.\u201d In Proc. 31st International Conf. on Software Engineering, Companion \nVolume, 18\u201327. Leipzig: IEEE Computer Society Press. doi:10.1109/ICSE-COMPANION.2009.5070960.\nCalinescu, R. C., and M. Z. Kwiatkowska. 2009. \u201cUsing Quantitative Analysis to Implement Auto-\nnomic IT Systems.\u201d In Proc. 31st International Conf. on Software Engineering, Companion Volume, \n100\u201310. Leipzig: IEEE Computer Society Press. doi:10.1109/ICSE.2009.5070512.\nDouglass, B. 2013. \u201cAgile Analysis Practices for Safety-Critical Software Development.\u201d http://www \n.ibm.com/developerworks/rational/library/agile-analysis-practices-safety-critical-development/.\nHall, A., and R. Chapman. 2002. \u201cCorrectness by Construction: Developing a Commercially Secure \nSystem.\u201d IEEE Software 19 (1): 18\u201325.doi:10.1109/52.976937.\nJhala, R., and R. Majumdar. 2009. \u201cSoftware Model Checking.\u201d Computing Surveys 41 (4), Article 21. \ndoi:1145/1592434.1592438.\nMiller, S. P., E. A. Anderson, L. G. Wagner, M. W. Whalen, and M. P. E. Heimdahl. 2005. \u201cFormal Veri-\nfication of Flight Critical Software.\u201d In Proc. AIAA Guidance, Navigation and Control Conference. San \nFrancisco. doi:10.2514/6.2005-6431.\nParnas, D. 2010. \u201cReally Rethinking Formal Methods.\u201d IEEE Computer 43 (1): 28\u201334. doi:10.1109/\nMC.2010.22.\nParnas, D., J. van Schouwen, and P. K. Shu. 1990. \u201cEvaluation of Safety-Critical Software.\u201d Comm. \nACM 33 (6): 636\u2013651. doi:10.1145/78973.78974.\nSwartz, A. J. 1996. \u201cAirport 95: Automated Baggage System?\u201d ACM Software Engineering Notes 21 \n(2): 79\u201383. doi:10.1145/227531.227544.\nTrimble, J. 2012. \u201cAgile Development Methods for Space Operations.\u201d In SpaceOps 2012. Stockholm. \ndoi:10.2514/6.2012-1264554.\nWoodcock, J., P. G. Larsen, J. Bicarregui, and J. Fitzgerald. 2009. \u201cFormal Methods: Practice and \nExperience.\u201d Computing Surveys 41 (4): 1\u201336. doi:10.1145/1592434.1592436.\n", "page": 306, "type": "text", "section": "Page 306"}
{"text": "Reliability engineering\n11 \nObjectives\nThe objective of this chapter is to explain how software reliability may \nbe specified, implemented, and measured. When you have read this \nchapter, you will:\n\u25a0\t understand the distinction between software reliability and \nsoftware availability;\n\u25a0\t have been introduced to metrics for reliability specification and \nhow these are used to specify measurable reliability requirements;\n\u25a0\t understand how different architectural styles may be used to \nimplement reliable, fault-tolerant systems architectures;\n\u25a0\t know about good programming practice for reliable software \nengineering;\n\u25a0\t understand how the reliability of a software system may be \nmeasured using statistical testing.\nContents\n11.1\t Availability and reliability\n11.2\t Reliability requirements\n11.3\t Fault-tolerant architectures\n11.4\t Programming for reliability\n11.5\t Reliability measurement\n", "page": 307, "type": "text", "section": "Page 307"}
{"text": " \nChapter 11\u2002 \u25a0\u2002 Reliability engineering\u2002 \u2002 307\nOur dependence on software systems for almost all aspects of our business and \n\u00ad\npersonal lives means that we expect that software to be available when we need it. \nThis may be early in the morning or late at night, at weekends or during holidays\u2014\nthe software must run all day, every day of the year. We expect that software will \noperate without crashes and failures and will preserve our data and personal infor-\nmation. We need to be able to trust the software that we use, which means that the \nsoftware must be reliable.\nThe use of software engineering techniques, better programming languages, and \neffective quality management has led to significant improvements in software relia-\nbility over the past 20 years. Nevertheless, system failures still occur that affect the \nsystem\u2019s availability or lead to incorrect results being produced. In situations where \nsoftware has a particularly critical role\u2014perhaps in an aircraft or as part of the national \ncritical infrastructure\u2014special reliability engineering techniques may be used to \nachieve the high levels of reliability and availability that are required.\nUnfortunately, it is easy to get confused when talking about system reliability, with \ndifferent people meaning different things when they talk about system faults and failures. \nBrian Randell, a pioneer researcher in software reliability, defined a fault\u2013error\u2013failure \nmodel (Randell 2000) based on the notion that human errors cause faults; faults lead to \nerrors, and errors lead to system failures. He defined these terms precisely:\n1.\t\nHuman error or mistake Human behavior that results in the introduction of \nfaults into a system. For example, in the wilderness weather system, a program-\nmer might decide that the way to compute the time for the next transmission is \nto add 1 hour to the current time. This works except when the transmission time \nis between 23.00 and midnight (midnight is 00.00 in the 24-hour clock).\n2.\t\nSystem fault A characteristic of a software system that can lead to a system \nerror. The fault in the above example is the inclusion of code to add 1 to a \u00ad\nvariable \ncalled Transmission_time, without a check to see if the value of Transmission_\ntime is greater than or equal to 23.00.\n3.\t\nSystem error An erroneous system state during execution that can lead to sys-\ntem behavior that is unexpected by system users. In this example, the value of \nthe variable Transmission_time is set incorrectly to 24.XX rather than 00.XX \nwhen the faulty code is executed.\n4.\t\nSystem failure An event that occurs at some point in time when the system does \nnot deliver a service as expected by its users. In this case, no weather data is \ntransmitted because the time is invalid.\nSystem faults do not necessarily result in system errors, and system errors do not \nnecessarily result in system failures:\n1.\t\nNot all code in a program is executed. The code that includes a fault (e.g., the \nfailure to initialize a variable) may never be executed because of the way that \nthe software is used.\n", "page": 308, "type": "text", "section": "Page 308"}
{"text": "308\u2002 \u2002 Chapter 11\u2002 \u25a0\u2002 Reliability engineering\n2.\t\nErrors are transient. A state variable may have an incorrect value caused by the \nexecution of faulty code. However, before this is accessed and causes a system \nfailure, some other system input may be processed that resets the state to a valid \nvalue. The wrong value has no practical effect.\n3.\t\nThe system may include fault detection and protection mechanisms. These \nensure that the erroneous behavior is discovered and corrected before the sys-\ntem services are affected.\nAnother reason why the faults in a system may not lead to system failures is that \nusers adapt their behavior to avoid using inputs that they know cause program \u00ad\nfailures. \nExperienced users \u201cwork around\u201d software features that they have found to be unrelia-\nble. For example, I avoid some features, such as automatic numbering, in the word \nprocessing system that I use because my experience is that it often goes wrong. Repairing \nfaults in such unused features makes no practical difference to the system reliability.\nThe distinction between faults, errors, and failures leads to three complementary \napproaches that are used to improve the reliability of a system:\n1.\t\nFault avoidance The software design and implementation process should use \napproaches to software development that help avoid design and programming \nerrors and so minimize the number of faults introduced into the system. Fewer \nfaults means less chance of runtime failures. Fault-avoidance techniques include \nthe use of strongly typed programming language to allow extensive compiler \nchecking and minimizing the use of error-prone programming language con-\nstructs, such as pointers.\n2.\t\nFault detection and correction Verification and validation processes are designed \nto discover and remove faults in a program, before it is deployed for operational \nuse. Critical systems require extensive verification and validation to\u00a0discover as \nmany faults as possible before deployment and to convince the system stake-\nholders and regulators that the system is dependable. Systematic testing and \ndebugging and static analysis are examples of fault-detection techniques.\n3.\t\nFault tolerance The system is designed so that faults or unexpected system \nbehavior during execution are detected at runtime and are managed in such a \nway that system failure does not occur. Simple approaches to fault tolerance \nbased on built-in runtime checking may be included in all systems. More spe-\ncialized fault-tolerance techniques, such as the use of fault-tolerant system \narchitectures, discussed in Section 11.3, may be used when a very high level of \nsystem availability and reliability is required.\nUnfortunately, applying fault-avoidance, fault-detection, and fault-tolerance \ntechniques is not always cost-effective. The cost of finding and removing the remain-\ning faults in a software system rises exponentially as program faults are discovered \nand removed (Figure 11.1). As the software becomes more reliable, you need to \nspend more and more time and effort to find fewer and fewer faults. At some stage, \neven for critical systems, the costs of this additional effort become unjustifiable.\n", "page": 309, "type": "text", "section": "Page 309"}
{"text": " \n11.1\u2002 \u25a0\u2002 Availability and reliability\u2002 \u2002 309\nAs a result, software companies accept that their software will always contain \nsome residual faults. The level of faults depends on the type of system. Software \nproducts have a relatively high level of faults, whereas critical systems usually have \na much lower fault density.\nThe rationale for accepting faults is that, if and when the system fails, it is cheaper \nto pay for the consequences of failure than it would be to discover and remove the \nfaults before system delivery. However, the decision to release faulty software is not \nsimply an economic one. The social and political acceptability of system failure \nmust also be taken into account.\n \n11.1 Availability and reliability\nIn Chapter 10, I introduced the concepts of system reliability and system availability. \nIf we think of systems as delivering some kind of service (to deliver cash, control \nbrakes, or connect phone calls, for example), then the availability of that service is \nwhether or not that service is up and running and its reliability is whether or not that \nservice delivers correct results. Availability and reliability can both be expressed as \nprobabilities. If the availability is 0.999, this means that, over some time period, the \nsystem is available for 99.9% of that time. If, on average, 2 inputs in every 1000 result \nin failures, then the reliability, expressed as a rate of occurrence of failure, is 0.002.\nMore precise definitions of availability and reliability are:\n1.\t\nReliability The probability of failure-free operation over a specified time, in a \ngiven environment, for a specific purpose.\n2.\t\nAvailability The probability that a system, at a point in time, will be operational \nand able to deliver the requested services.\nCost per error detected\nFew\nNumber of residual errors\nMany\nVery few\nFigure 11.1\u2002 The \nincreasing costs of \nresidual fault removal \n", "page": 310, "type": "text", "section": "Page 310"}
{"text": "310\u2002 \u2002 Chapter 11\u2002 \u25a0\u2002 Reliability engineering\nSystem reliability is not an absolute value\u2014it depends on where and how that \nsystem is used. For example, let\u2019s say that you measure the reliability of an applica-\ntion in an office environment where most users are uninterested in the operation of \nthe software. They follow the instructions for its use and do not try to experiment \nwith the system. If you then measure the reliability of the same system in a university \nenvironment, then the reliability may be quite different. Here, students may explore \nthe boundaries of the system and use it in unexpected ways. This may result in system \nfailures that did not occur in the more constrained office environment. Therefore, the \nperceptions of the system\u2019s reliability in each of these environments are different.\nThe above definition of reliability is based on the idea of failure-free operation, \nwhere failures are external events that affect the users of a system. But what consti-\ntutes \u201cfailure\u201d? A technical definition of failure is behavior that does not conform to \nthe system\u2019s specification. However, there are two problems with this definition:\n1.\t\nSoftware specifications are often incomplete or incorrect, and it is left to soft-\nware engineers to interpret how the system should behave. As they are not \ndomain experts, they may not implement the behavior that users expect. The \nsoftware may behave as specified, but, for users, it is still failing.\n2.\t\nNo one except system developers reads software specification documents. Users \nmay therefore anticipate that the software should behave in one way when the \nspecification says something completely different.\nFailure is therefore not something that can be objectively defined. Rather, it is a \njudgment made by users of a system. This is one reason why users do not all have the \nsame impression of a system\u2019s reliability.\nTo understand why reliability is different in different environments, we need to\u00a0think \nabout a system as an input/output mapping. Figure 11.2 shows a software system that \nIe\nInput set\nOe\nOutput set\nProgram\nInputs causing\nerroneous outputs\nErroneous\noutputs\nFigure 11.2\u2002 A system \nas\u00a0an input/output \nmapping \n", "page": 311, "type": "text", "section": "Page 311"}
{"text": " \n11.1\u2002 \u25a0\u2002 Availability and reliability\u2002 \u2002 311\nlinks a set of inputs with a set of outputs. Given an input or input sequence, the program \nresponds by producing a corresponding output. For example, given an input of a URL, \na web browser produces an output that is the display of the requested web page.\nMost inputs do not lead to system failure. However, some inputs or input combi-\nnations, shown in the shaded ellipse Ie in Figure 11.2, cause system failures or \n\u00ad\nerroneous outputs to be generated. The program\u2019s reliability depends on the number \nof system inputs that are members of the set of inputs that lead to an erroneous \n\u00ad\noutput\u2014in other words, the set of inputs that cause faulty code to be executed and \nsystem errors to occur. If inputs in the set Ie are executed by frequently used parts of \nthe system, then failures will be frequent. However, if the inputs in Ie are executed by \ncode that is rarely used, then users will hardly ever see failures.\nFaults that affect the reliability of the system for one user may never show up \nunder someone else\u2019s mode of working. In Figure 11.3, the set of erroneous inputs \ncorresponds to the ellipse labeled Ie in Figure 11.2. The set of inputs produced by \nUser 2 intersects with this erroneous input set. User 2 will therefore experience some \nsystem failures. User 1 and User 3, however, never use inputs from the erroneous \nset. For them, the software will always appear to be reliable.\nThe availability of a system does not just depend on the number of system fail-\nures, but also on the time needed to repair the faults that have caused the failure. \nTherefore, if system A fails once a year and system B fails once a month, then A is \napparently more reliable then B. However, assume that system A takes 6 hours to \nrestart after a failure, whereas system B takes 5 minutes to restart. The availability of \nsystem B over the year (60 minutes of down time) is much better than that of system \nA (360 minutes of downtime).\nFurthermore, the disruption caused by unavailable systems is not reflected in the \nsimple availability metric that specifies the percentage of time that the system is \navailable. The time when the system fails is also important. If a system is unavailable \nfor an hour each day between 3 am and 4 am, this may not affect many users. \nHowever, if the same system is unavailable for 10 minutes during the working day, \nsystem unavailability has a much greater effect on users.\nReliability and availability are closely related, but sometimes one is more impor-\ntant than the other. If users expect continuous service from a system, then the system \nPossible\ninputs\nUser\n1\nUser\n3\nUser\n2\nErroneous\ninputs\nFigure 11.3\u2002 Software \nusage patterns \n", "page": 312, "type": "text", "section": "Page 312"}
{"text": "312\u2002 \u2002 Chapter 11\u2002 \u25a0\u2002 Reliability engineering\nhas a high-availability requirement. It must be available whenever a demand is \nmade. However, if a system can recover quickly from failures without loss of user \ndata, then these failures may not significantly affect system users.\nA telephone exchange switch that routes phone calls is an example of a system \nwhere availability is more important than reliability. Users expect to be able to make a \ncall when they pick up a phone or activate a phone app, so the system has high-\u00ad\navailability requirements. If a system fault occurs while a connection is being set up, \nthis is often quickly recoverable. Exchange or base station switches can reset the \u00ad\nsystem \nand retry the connection attempt. This can be done quickly, and phone users may not \neven notice that a failure has occurred. Furthermore, even if a call is interrupted, the \nconsequences are usually not serious. Users simply reconnect if this happens.\n \n11.2 Reliability requirements\nIn September 1993, a plane landed at Warsaw Airport in Poland during a thunder-\nstorm. For 9 seconds after landing, the brakes on the computer-controlled braking \nsystem did not work. The braking system had not recognized that the plane had \nlanded and assumed that the aircraft was still airborne. A safety feature on the air-\ncraft had stopped the deployment of the reverse thrust system, which slows down the \naircraft, because reverse thrust is catastrophic if the plane is in the air. The plane ran \noff the end of the runway, hit an earth bank, and caught fire.\nThe inquiry into the accident showed that the braking system software had oper-\nated according to its specification. There were no errors in the control system. \nHowever, the software specification was incomplete and had not taken into account \na rare situation, which arose in this case. The software worked, but the system failed.\nThis incident shows that system dependability does not just depend on good engi-\nneering. It also requires attention to detail when the system requirements are derived \nand the specification of software requirements that are geared to ensuring the \ndependability of a system. Those dependability requirements are of two types:\n1.\t\nFunctional requirements, which define checking and recovery facilities that \nshould be included in the system and features that provide protection against \nsystem failures and external attacks.\n2.\t\nNon-functional requirements, which define the required reliability and availa-\nbility of the system.\nAs I discussed in Chapter 10, the overall reliability of a system depends on the \nhardware reliability, the software reliability, and the reliability of the system opera-\ntors. The system software has to take this requirement into account. As well as \nincluding requirements that compensate for software failure, there may also be \nrelated reliability requirements to help detect and recover from hardware failures \nand operator errors.\n", "page": 313, "type": "text", "section": "Page 313"}
{"text": " \n11.2\u2002 \u25a0\u2002 Reliability requirements\u2002 \u2002 313\n\t\n11.2.1\t Reliability metrics\nReliability can be specified as a probability that a system failure will occur when a \nsystem is in use within a specified operating environment. If you are willing to \naccept, for example, that 1 in any 1000 transactions may fail, then you can specify \nthe failure probability as 0.001. This doesn\u2019t mean that there will be exactly 1 failure \nin every 1000 transactions. It means that if you observe N thousand transactions, the \nnumber of failures that you observe should be about N.\nThree metrics may be used to specify reliability and availability:\n1.\t\nProbability of failure on demand (POFOD) If you use this metric, you define \nthe probability that a demand for service from a system will result in a system \nfailure. So, POFOD = 0.001 means that there is a 1/1000 chance that a failure \nwill occur when a demand is made.\n2.\t\nRate of occurrence of failures (ROCOF) This metric sets out the probable num-\nber of system failures that are likely to be observed relative to a certain time \nperiod (e.g., an hour), or to the number of system executions. In the example \nabove, the ROCOF is 1/1000. The reciprocal of ROCOF is the mean time to \nfailure (MTTF), which is sometimes used as a reliability metric. MTTF is the \naverage number of time units between observed system failures. A ROCOF of \ntwo failures per hour implies that the mean time to failure is 30 minutes.\n3.\t\nAvailability (AVAIL) AVAIL is the probability that a system will be operational \nwhen a demand is made for service. Therefore, an availability of 0.9999 means \nthat, on average, the system will be available for 99.99% of the operating time. \nFigure 11.4 shows what different levels of availability mean in practice.\nPOFOD should be used in situations where a failure on demand can lead to a serious \nsystem failure. This applies irrespective of the frequency of the demands. For example, \na protection system that monitors a chemical reactor and shuts down the reaction if it is \noverheating should have its reliability specified using POFOD. Generally, demands on \na protection system are infrequent as the system is a last line of defense, after all other \nrecovery strategies have failed. Therefore a POFOD of 0.001 (1 failure in 1000 demands) \nAvailability\nExplanation\n0.9\nThe system is available for 90% of the time. This means \nthat, in a 24-hour period (1440 minutes), the system \nwill be unavailable for 144 minutes.\n0.99\nIn a 24-hour period, the system is unavailable for 14.4 \nminutes.\n0.999\nThe system is unavailable for 84 seconds in a 24-hour \nperiod.\n0.9999\nThe system is unavailable for 8.4 seconds in a 24-hour \nperiod\u2014roughly, one minute per week.\nFigure 11.4\u2002 Availability \nspecification\n", "page": 314, "type": "text", "section": "Page 314"}
{"text": "314\u2002 \u2002 Chapter 11\u2002 \u25a0\u2002 Reliability engineering\nmight seem to be risky. However, if there are only two or three demands on the system \nin its entire lifetime, then the system is unlikely to ever fail.\nROCOF should be used when demands on systems are made regularly rather than \nintermittently. For example, in a system that handles a large number of transactions, \nyou may specify a ROCOF of 10 failures per day. This means that you are willing to \naccept that an average of 10 transactions per day will not complete successfully and \nwill have to be canceled and resubmitted. Alternatively, you may specify ROCOF as \nthe number of failures per 1000 transactions.\nIf the absolute time between failures is important, you may specify the reliability \nas the mean time to failures (MTTF). For example, if you are specifying the required \nreliability for a system with long transactions (such as a computer-aided design sys-\ntem), you should use this metric. The MTTF should be much longer than the average \ntime that a user works on his or her models without saving the user\u2019s results. This \nmeans that users are unlikely to lose work through a system failure in any one session.\n\t\n11.2.2\t Non-functional reliability requirements\nNon-functional reliability requirements are specifications of the required reliability \nand availability of a system using one of the reliability metrics (POFOD, ROCOF, or \nAVAIL) described in the previous section. Quantitative reliability and availability \nspecification has been used for many years in safety-critical systems but is uncom-\nmon for business critical systems. However, as more and more companies demand \n24/7 service from their systems, it makes sense for them to be precise about their \nreliability and availability expectations.\nQuantitative reliability specification is useful in a number of ways:\n1.\t\nThe process of deciding the required level of the reliability helps to clarify what \nstakeholders really need. It helps stakeholders understand that there are \u00ad\ndifferent \ntypes of system failure, and it makes clear to them that high levels of reliability \nare expensive to achieve.\n2.\t\nIt provides a basis for assessing when to stop testing a system. You stop when \nthe system has reached its required reliability level.\n3.\t\nIt is a means of assessing different design strategies intended to improve the relia-\nbility of a system. You can make a judgment about how each strategy might lead \nto the required levels of reliability.\n4.\t\nIf a regulator has to approve a system before it goes into service (e.g., all systems \nthat are critical to flight safety on an aircraft are regulated), then evidence that a \nrequired reliability target has been met is important for system certification.\nTo avoid incurring excessive and unnecessary costs, it is important that you spec-\nify the reliability that you really need rather than simply choose a very high level of \nreliability for the whole system. You may have different requirements for different \n", "page": 315, "type": "text", "section": "Page 315"}
{"text": " \n11.2\u2002 \u25a0\u2002 Reliability requirements\u2002 \u2002 315\nparts of the system if some parts are more critical than others. You should follow \nthese three guidelines when specifying reliability requirements:\n1.\t\nSpecify the availability and reliability requirements for different types of fail-\nure. There should be a lower probability of high-cost failures than failures that \ndon\u2019t have serious consequences.\n2.\t\nSpecify the availability and reliability requirements for different types of system \nservice. Critical system services should have the highest reliability but you may \nbe willing to tolerate more failures in less critical services. You may decide that \nit is only cost-effective to use quantitative reliability specification for the most \ncritical system services.\n3.\t\nThink about whether high reliability is really required. For example, you may \nuse error-detection mechanisms to check the outputs of a system and have error-\ncorrection processes in place to correct errors. There may then be no need for a \nhigh level of reliability in the system that generates the outputs as errors can be \ndetected and corrected.\nTo illustrate these guidelines, think about the reliability and availability require-\nments for a bank ATM system that dispenses cash and provides other services to \ncustomers. Banks have two concerns with such systems:\n1.\t\nTo ensure that they carry out customer services as requested and that they \n\u00ad\nproperly record customer transactions in the account database.\n2.\t\nTo ensure that these systems are available for use when required.\nBanks have many years of experience with identifying and correcting incorrect \naccount transactions. They use accounting methods to detect when things have gone \nwrong. Most transactions that fail can simply be canceled, resulting in no loss to the \nbank and minor customer inconvenience. Banks that run ATM networks therefore \naccept that ATM failures may mean that a small number of transactions are incor-\nrect, but they think it more cost-effective to fix these errors later rather than incur \nhigh costs in avoiding faulty transactions. Therefore, the absolute reliability required \nof an ATM may be relatively low. Several failures per day may be acceptable.\nOverspecification of reliability\nOverspecification of reliability means defining a level of required reliability that is higher than really necessary \nfor the practical operation of the software. Overspecification of reliability increases development costs dispro-\nportionately. The reason for this is that the costs of reducing faults and verifying reliability increase exponentially \nas reliability increases\nhttp://software-engineering-book.com/web/over-specifying-reliability/\n", "page": 316, "type": "text", "section": "Page 316"}
{"text": "316\u2002 \u2002 Chapter 11\u2002 \u25a0\u2002 Reliability engineering\nFor a bank (and for the bank\u2019s customers), the availability of the ATM network \nis\u00a0more important than whether or not individual ATM transactions fail. Lack of \navailability means increased demand on counter services, customer dissatisfaction, \nengineering costs to repair the network, and so on. Therefore, for transaction-based \nsystems such as banking and e-commerce systems, the focus of reliability specifica-\ntion is usually on specifying the availability of the system.\nTo specify the availability of an ATM network, you should identify the system \nservices and specify the required availability for each of these services, notably:\n\u25a0\t the customer account database service; and\n\u25a0\t the individual services provided by an ATM such as \u201cwithdraw cash\u201d and \u201cprovide \naccount information.\u201d\nThe database service is the most critical as failure of this service means that all \nof\u00a0the ATMs in the network are out of action. Therefore, you should specify this \nservice to have a high level of availability. In this case, an acceptable figure for data-\nbase availability (ignoring issues such as scheduled maintenance and upgrades) \nwould probably be around 0.9999, between 7 am and 11 pm. This means a downtime \nof less than 1 minute per week.\nFor an individual ATM, the overall availability depends on mechanical reliability \nand the fact that it can run out of cash. Software issues are probably less significant \nthan these factors. Therefore, a lower level of software availability for the ATM \nsoftware is acceptable. The overall availability of the ATM software might therefore \nbe specified as 0.999, which means that a machine might be unavailable for between \n1 and 2 minutes each day. This allows for the ATM software to be restarted in the \nevent of a problem.\nThe reliability of control systems is usually specified in terms of the probability \nthat the system will fail when a demand is made (POFOD). Consider the reliability \nrequirements for the control software in the insulin pump, introduced in Chapter 1. \nThis system delivers insulin a number of times per day and monitors the user\u2019s blood \nglucose several times per hour.\nThere are two possible types of failure in the insulin pump:\n1.\t Transient software failures, which can be repaired by user actions such as \nresetting or recalibrating the machine. For these types of failure, a relatively \nlow value of POFOD (say 0.002) may be acceptable. This means that one \nfailure may occur in every 500 demands made on the machine. This is approx-\nimately once every 3.5 days, because the blood sugar is checked about 5 \ntimes per hour.\n2.\t Permanent software failures, which require the software to be reinstalled by \nthe manufacturer. The probability of this type of failure should be much lower. \nRoughly once a year is the minimum figure, so POFOD should be no more \nthan 0.00002.\n", "page": 317, "type": "text", "section": "Page 317"}
{"text": " \n11.2\u2002 \u25a0\u2002 Reliability requirements\u2002 \u2002 317\nFailure to deliver insulin does not have immediate safety implications, so com-\nmercial factors rather than safety factors govern the level of reliability required. \nService costs are high because users need fast repair and replacement. It is in the \nmanufacturer\u2019s interest to limit the number of permanent failures that require repair.\n\t\n11.2.3\t Functional reliability specification\nTo achieve a high level of reliability and availability in a software-intensive system, \nyou use a combination of fault-avoidance, fault-detection, and fault-tolerance tech-\nniques. This means that functional reliability requirements have to be generated which \nspecify how the system should provide fault avoidance, detection, and tolerance.\nThese functional reliability requirements should specify the faults to be detected \nand the actions to be taken to ensure that these faults do not lead to system failures. \nFunctional reliability specification, therefore, involves analyzing the non-functional \nrequirements (if these have been specified), assessing the risks to reliability and \nspecifying system functionality to address these risks.\nThere are four types of functional reliability requirements:\n1.\t\nChecking requirements These requirements identify checks on inputs to the sys-\ntem to ensure that incorrect or out-of-range inputs are detected before they are \nprocessed by the system.\n2.\t\nRecovery requirements These requirements are geared to helping the system \nrecover after a failure has occurred. These requirements are usually concerned \nwith maintaining copies of the system and its data and specifying how to restore \nsystem services after failure.\n3.\t\nRedundancy requirements These specify redundant features of the system that \nensure that a single component failure does not lead to a complete loss of ser-\nvice. I discuss this in more detail in the next chapter.\n4.\t\nProcess requirements These are fault-avoidance requirements, which ensure \nthat good practice is used in the development process. The practices specified \nshould reduce the number of faults in a system.\nSome examples of these types of reliability requirement are shown in Figure 11.5.\nFigure 11.5\u2002 Examples \nof functional reliability \nrequirements\nRR1: A predefined range for all operator inputs shall be defined, and the system shall \ncheck that all operator inputs fall within this predefined range. (Checking)\nRR2: Copies of the patient database shall be maintained on two separate servers that \nare not housed in the same building. (Recovery, redundancy)\nRR3: N-version programming shall be used to implement the braking control system. \n(Redundancy)\nRR4: The system must be implemented in a safe subset of Ada and checked using \nstatic analysis. (Process)\n", "page": 318, "type": "text", "section": "Page 318"}
{"text": "318\u2002 \u2002 Chapter 11\u2002 \u25a0\u2002 Reliability engineering\nThere are no simple rules for deriving functional reliability requirements. \nOrganizations that develop critical systems usually have organizational knowledge \nabout possible reliability requirements and how these requirements reflect the actual \nreliability of a system. These organizations may specialize in specific types of sys-\ntems, such as railway control systems, so the reliability requirements can be reused \nacross a range of systems.\n \n11.3 Fault-tolerant architectures\nFault tolerance is a runtime approach to dependability in which systems include \nmechanisms to continue in operation, even after a software or hardware fault has \noccurred and the system state is erroneous. Fault-tolerance mechanisms detect and \ncorrect this erroneous state so that the occurrence of a fault does not lead to a system \nfailure. Fault tolerance is required in systems that are safety or security critical and \nwhere the system cannot move to a safe state when an error is detected.\nTo provide fault tolerance, the system architecture has to be designed to include \nredundant and diverse hardware and software. Examples of systems that may need \nfault-tolerant architectures are aircraft systems that must be available throughout \nthe duration of the flight, telecommunication systems, and critical command and \ncontrol systems.\nThe simplest realization of a dependable architecture is in replicated servers, where \ntwo or more servers carry out the same task. Requests for processing are channeled \nthrough a server management component that routes each request to a particular \nserver. This component also keeps track of server responses. In the event of server \nfailure, which can be detected by a lack of response, the faulty server is switched out \nof the system. Unprocessed requests are resubmitted to other servers for processing.\nThis replicated server approach is widely used for transaction processing systems \nwhere it is easy to maintain copies of transactions to be processed. Transaction \n\u00ad\nprocessing systems are designed so that data is only updated once a transaction has \nfinished correctly. Delays in processing do not affect the integrity of the system. It can \nbe an efficient way of using hardware if the backup server is one that is normally used \nfor low-priority tasks. If a problem occurs with a primary server, its unprocessed trans-\nactions are transferred to the backup server, which gives that work the highest priority.\nReplicated servers provide redundancy but not usually diversity. The server \n\u00ad\nhardware is usually identical, and the servers run the same version of the software. \nTherefore, they can cope with hardware failures and software failures that are local-\nized to a single machine. They cannot cope with software design problems that cause \nall versions of the software to fail at the same time. To handle software design fail-\nures, a system has to use diverse software and hardware.\nTorres-Pomales surveys a range of software fault-tolerance techniques \n(Torres-Pomales 2000), and Pullum (Pullum 2001) describes different types of \nfault-tolerant architecture. In the following sections, I describe three architec-\ntural patterns that have been used in fault-tolerant systems.\n", "page": 319, "type": "text", "section": "Page 319"}
{"text": " \n11.3\u2002 \u25a0\u2002 Fault-tolerant architectures\u2002 \u2002 319\n\t\n11.3.1\t Protection systems\nA protection system is a specialized system that is associated with some other sys-\ntem. This is usually a control system for some process, such as a chemical manu-\nfacturing process, or an equipment control system, such as the system on a \ndriverless train. An example of a protection system might be a system on a train \nthat detects if the train has gone through a red signal. If there is no indication that \nthe train control system is slowing down the train, then the protection system auto-\nmatically applies the train brakes to bring it to a halt. Protection systems indepen-\ndently monitor their environment. If sensors indicate a problem that the controlled \nsystem is not dealing with, then the protection system is activated to shut down the \nprocess or equipment.\nFigure 11.6 illustrates the relationship between a protection system and a con-\ntrolled system. The protection system monitors both the controlled equipment and \nthe environment. If a problem is detected, it issues commands to the actuators to shut \ndown the system or invoke other protection mechanisms such as opening a pressure-\nrelease valve. Notice that there are two sets of sensors. One set is used for normal \nsystem monitoring and the other specifically for the protection system. In the event \nof sensor failure, backups are in place that will allow the protection system to con-\ntinue in operation. The system may also have redundant actuators.\nA protection system only includes the critical functionality that is required to \nmove the system from a potentially unsafe state to a safe state (which could be sys-\ntem shutdown). It is an instance of a more general fault-tolerant architecture in which \na principal system is supported by a smaller and simpler backup system that only \nincludes essential functionality. For example, the control software for the U.S. Space \nShuttle had a backup system with \u201cget you home\u201d functionality. That is, the backup \nsystem could land the vehicle if the principal control system failed but had no other \ncontrol functions.\nProtection\nsensors\nSystem environment\nActuators\nControlled\nequipment\nControl system\nProtection\nsystem\nSensors\nFigure 11.6\u2002 Protection \nsystem architecture \n", "page": 320, "type": "text", "section": "Page 320"}
{"text": "320\u2002 \u2002 Chapter 11\u2002 \u25a0\u2002 Reliability engineering\nThe advantage of this architectural style is that protection system software can be \nmuch simpler than the software that is controlling the protected process. The only \nfunction of the protection system is to monitor operation and to ensure that the sys-\ntem is brought to a safe state in the event of an emergency. Therefore, it is possible \nto invest more effort in fault avoidance and fault detection. You can check that the \nsoftware specification is correct and consistent and that the software is correct with \nrespect to its specification. The aim is to ensure that the reliability of the protection \nsystem is such that it has a very low probability of failure on demand (say, 0.001). \nGiven that demands on the protection system should be rare, a probability of failure \non demand of 1/1000 means that protection system failures should be very rare.\n\t\n11.3.2\t Self-monitoring architectures\nA self-monitoring architecture (Figure 11.7) is a system architecture in which the sys-\ntem is designed to monitor its own operation and to take some action if a problem is \ndetected. Computations are carried out on separate channels, and the outputs of these \ncomputations are compared. If the outputs are identical and are available at the same \ntime, then the system is judged to be operating correctly. If the outputs are different, \nthen a failure is assumed. When this occurs, the system raises a failure exception on the \nstatus output line. This signals that control should be transferred to some other system.\nTo be effective in detecting both hardware and software faults, self-monitoring \nsystems have to be designed so that:\n1.\t\nThe hardware used in each channel is diverse. In practice, this might mean that \neach channel uses a different processor type to carry out the required computa-\ntions, or the chipset making up the system may be sourced from different manu-\nfacturers. This reduces the probability of common processor design faults \naffecting the computation.\n2.\t\nThe software used in each channel is diverse. Otherwise, the same software \nerror could arise at the same time on each channel.\nOn its own, this architecture may be used in situations where it is important for \ncomputations to be correct, but where availability is not essential. If the answers \nSplitter\nChannel 1\nChannel 2\nComparator\nInput value\nOutput value\nStatus\nFigure 11.7\u2002 Self-\nmonitoring architecture \n", "page": 321, "type": "text", "section": "Page 321"}
{"text": " \n11.3\u2002 \u25a0\u2002 Fault-tolerant architectures\u2002 \u2002 321\nfrom each channel differ, the system shuts down. For many medical treatment and \ndiagnostic systems, reliability is more important than availability because an incor-\nrect system response could lead to the patient receiving incorrect treatment. However, \nif the system shuts down in the event of an error, this is an inconvenience but the \npatient will not usually be harmed.\nIn situations that require high availability, you have to use several self-checking \nsystems in parallel. You need a switching unit that detects faults and selects a \nresult from one of the systems, where both channels are producing a consistent \nresponse. This approach is used in the flight control system for the Airbus 340 \nseries of aircraft, which uses five self-checking computers. Figure 11.8 is a simpli-\nfied diagram of the Airbus flight control system that shows the organization of the \nself-monitoring systems.\nIn the Airbus flight control system, each of the flight control computers carries out \nthe computations in parallel, using the same inputs. The outputs are connected to \nhardware filters that detect if the status indicates a fault and, if so, that the output from \nthat computer is switched off. The output is then taken from an alternative system. \nTherefore, it is possible for four computers to fail and for the aircraft operation to \ncontinue. In more than 15 years of operation, there have been no reports of situations \nwhere control of the aircraft has been lost due to total flight control system failure.\nSplitter\nChannel 1\nChannel 2\nComparator\nOutput\nStatus\nPrimary flight control system 1\nPrimary flight control system 2\nPrimary flight control system 3\nSplitter\nChannel 1\nChannel 2\nComparator\nOutput\nStatus\nSecondary flight control system 1\nSecondary flight control system 2\nInput\nFilter\nFilter\nFilter\nFilter\nFilter\nStatus\nStatus\nStatus\nOutput\nOutput\nOutput\nOutput\nFigure 11.8\u2002 The \nAirbus\u00a0flight control \nsystem architecture \n", "page": 322, "type": "text", "section": "Page 322"}
{"text": "322\u2002 \u2002 Chapter 11\u2002 \u25a0\u2002 Reliability engineering\nThe designers of the Airbus system have tried to achieve diversity in a number of \ndifferent ways:\n1.\t\nThe primary flight control computers use a different processor from the second-\nary flight control systems.\n2.\t\nThe chipset that is used in each channel in the primary and secondary systems is \nsupplied by a different manufacturer.\n3.\t\nThe software in the secondary flight control systems provides critical function-\nality only\u2014it is less complex than the primary software.\n4.\t\nThe software for each channel in both the primary and the secondary systems is \ndeveloped using different programming languages and by different teams.\n5.\t\nDifferent programming languages are used in the secondary and primary systems.\nAs I discuss in Section 11.3.4, these do not guarantee diversity but they reduce \nthe probability of common failures in different channels.\n\t\n11.3.3\t N-version programming\nSelf-monitoring architectures are examples of systems in which multiversion \n\u00ad\nprogramming is used to provide software redundancy and diversity. This notion of \nmultiversion programming has been derived from hardware systems where the \nnotion of triple modular redundancy (TMR) has been used for many years to build \nsystems that are tolerant of hardware failures (Figure 11.9).\nIn a TMR system, the hardware unit is replicated three (or sometimes more) \ntimes. The output from each unit is passed to an output comparator that is usually \nimplemented as a voting system. This system compares all of its inputs, and, if two \nor more are the same, then that value is output. If one of the units fails and does not \nproduce the same output as the other units, its output is ignored. A fault manager \nmay try to repair the faulty unit automatically, but if this is impossible, the system is \nautomatically reconfigured to take the unit out of service. The system then continues \nto function with two working units.\nThis approach to fault tolerance relies on most hardware failures being the result \nof component failure rather than design faults. The components are therefore likely \nA2\nA1\nA3\nOutput\nselector\nInput\nFigure 11.9\u2002 Triple \nmodular redundancy\n", "page": 323, "type": "text", "section": "Page 323"}
{"text": " \n11.3\u2002 \u25a0\u2002 Fault-tolerant architectures\u2002 \u2002 323\nto fail independently. It assumes that, when fully operational, all hardware units per-\nform to specification. There is therefore a low probability of simultaneous compo-\nnent failure in all hardware units.\nOf course, the components could all have a common design fault and thus all \nproduce the same (wrong) answer. Using hardware units that have a common speci-\nfication but that are designed and built by different manufacturers reduces the \nchances of such a common mode failure. It is assumed that the probability of differ-\nent teams making the same design or manufacturing error is small.\nA similar approach can be used for fault-tolerant software where N diverse ver-\nsions of a software system execute in parallel (Avizienis 1995). This approach to \nsoftware fault tolerance, illustrated in Figure 11.10, has been used in railway signal-\ning systems, aircraft systems, and reactor protection systems.\nUsing a common specification, the same software system is implemented by a \nnumber of teams. These versions are executed on separate computers. Their outputs \nare compared using a voting system, and inconsistent outputs or outputs that are not \nproduced in time are rejected. At least three versions of the system should be avail-\nable so that two versions should be consistent in the event of a single failure.\n N-version programming may be less expensive than self-checking architectures \nin systems for which a high level of availability is required. However, it still requires \nseveral different teams to develop different versions of the software. This leads to \nvery high software development costs. As a result, this approach is only used in sys-\ntems where it is impractical to provide a protection system that can guard against \nsafety-critical failures.\n\t\n11.3.4\t Software diversity\nAll of the above fault-tolerant architectures rely on software diversity to achieve fault \ntolerance. This is based on the assumption that diverse implementations of the same \nspecification (or a part of the specification, for protection systems) are independent. \nThey should not include common errors and so will not fail in the same way, at the \nsame time. The software should therefore be written by different teams who should \nnot communicate during the development process. This requirement reduces the \nchances of common misunderstandings or misinterpretations of the specification.\nVersion 2\nVersion 1\nVersion 3\nOutput\nselector\nN software versions\nAgreed\nresult\nFault\nmanager\nInput\nFigure 11.10\u2002  N-version \nprogramming \n", "page": 324, "type": "text", "section": "Page 324"}
{"text": "324\u2002 \u2002 Chapter 11\u2002 \u25a0\u2002 Reliability engineering\nThe company that is procuring the system may include explicit diversity policies that \nare intended to maximize the differences between the system versions. For example:\n1.\t\nBy including requirements that different design methods should be used. For \nexample, one team may be required to produce an object-oriented design, and \nanother team may produce a function-oriented design.\n2.\t\nBy stipulating that the programs should be implemented using different pro-\ngramming languages. For example, in a three-version system, Ada, C++, and \nJava could be used to write the software versions.\n3.\t\nBy requiring the use of different tools and development environments for the \nsystem.\n4.\t\nBy requiring different algorithms to be used in some parts of the implementa-\ntion. However, this limits the freedom of the design team and may be difficult to \nreconcile with system performance requirements.\nIdeally, the diverse versions of the system should have no dependencies and so \nshould fail in completely different ways. If this is the case, then the overall reliability \nof a diverse system is obtained by multiplying the reliabilities of each channel. So, if \neach channel has a probability of failure on demand of 0.001, then the overall \nPOFOD of a three-channel system (with all channels independent) is a million times \ngreater than the reliability of a single channel system.\nIn practice, however, achieving complete channel independence is impossible. It has \nbeen shown experimentally that independent software design teams often make the \nsame mistakes or misunderstand the same parts of the specification (Brilliant, Knight, \nand Leveson 1990; Leveson 1995). There are several reasons for this misunderstanding:\n1.\t\nMembers of different teams are often from the same cultural background and may \nhave been educated using the same approach and textbooks. This means that they \nmay find the same things difficult to understand and have common difficulties in \ncommunicating with domain experts. It is quite possible that they will, indepen-\ndently, make the same mistakes and design the same algorithms to solve a problem.\n2.\t\nIf the requirements are incorrect or they are based on misunderstandings about \nthe environment of the system, then these mistakes will be reflected in each \nimplementation of the system.\n3.\t\nIn a critical system, the detailed system specification that is derived from the \nsystem\u2019s requirements should provide an unambiguous definition of the sys-\ntem\u2019s behavior. However, if the specification is ambiguous, then different teams \nmay misinterpret the specification in the same way.\nOne way to reduce the possibility of common specification errors is to develop \ndetailed specifications for the system independently and to define the specifications in \ndifferent languages. One development team might work from a formal specification, \n", "page": 325, "type": "text", "section": "Page 325"}
{"text": " \n11.4\u2002 \u25a0\u2002 Programming for reliability\u2002 \u2002 325\nanother from a state-based system model, and a third from a natural language specifica-\ntion. This approach helps avoid some errors of specification interpretation, but does not \nget around the problem of requirements errors. It also introduces the possibility of \nerrors in the translation of the requirements, leading to inconsistent specifications.\nIn an analysis of the experiments, Hatton (Hatton 1997) concluded that a three-channel \nsystem was somewhere between 5 and 9 times more reliable than a single-channel \nsystem. He concluded that improvements in reliability that could be obtained by devot-\ning more resources to a single version could not match this and so N-version approaches \nwere more likely to lead to more reliable systems than single-version approaches.\nWhat is unclear, however, is whether the improvements in reliability from a mul-\ntiversion system are worth the extra development costs. For many systems, the extra \ncosts may not be justifiable, as a well-engineered single-version system may be good \nenough. It is only in safety- and mission-critical systems, where the costs of failure \nare very high, that multiversion software may be required. Even in such situations \n(e.g., a spacecraft system), it may be enough to provide a simple backup with limited \nfunctionality until the principal system can be repaired and restarted.\n \n11.4 Programming for reliability\nI have deliberately focused in this book on programming-language independent \naspects of software engineering. It is almost impossible to discuss programming \nwithout getting into the details of a specific programming language. However, when \nconsidering reliability engineering, there are a set of accepted good programming \npractices that are fairly universal and that help reduce faults in delivered systems.\nA list of eight good practice guidelines is shown in Figure 11.11. They can be \napplied regardless of the particular programming language used for systems devel-\nopment, although the way they are used depends on the specific languages and nota-\ntions that are used for system development. Following these guidelines also reduces \nthe chances of introducing security-related vulnerabilities into programs.\n\t\n\t Guideline 1: Control the visibility of information in a program\nA security principle that is adopted by military organizations is the \u201cneed to know\u201d \nprinciple. Only those individuals who need to know a particular piece of information \nin order to carry out their duties are given that information. Information that is not \ndirectly relevant to their work is withheld.\nWhen programming, you should adopt an analogous principle to control access to the \nvariables and data structures that you use. Program components should only be allowed \naccess to data that they need for their implementation. Other program data should be \ninaccessible and hidden from them. If you hide information, it cannot be corrupted by \nprogram components that are not supposed to use it. If the interface remains the same, the \ndata representation may be changed without affecting other components in the system.\n", "page": 326, "type": "text", "section": "Page 326"}
{"text": "326\u2002 \u2002 Chapter 11\u2002 \u25a0\u2002 Reliability engineering\nYou can achieve this by implementing data structures in your program as abstract \ndata types. An abstract data type is one in which the internal structure and represen-\ntation of a variable of that type are hidden. The structure and attributes of the type \nare not externally visible, and all access to the data is through operations.\nFor example, you might have an abstract data type that represents a queue of \nrequests for service. Operations should include get and put, which add and remove \nitems from the queue, and an operation that returns the number of items in the queue. \nYou might initially implement the queue as an array but subsequently decide to \nchange the implementation to a linked list. This can be achieved without any changes \nto code using the queue, because the queue representation is never directly accessed.\nIn some object-oriented languages, you can implement abstract data types using \ninterface definitions, where you declare the interface to an object without reference \nto its implementation. For example, you can define an interface Queue, which sup-\nports methods to place objects onto the queue, remove them from the queue, and \nquery the size of the queue. In the object class that implements this interface, the \nattributes and methods should be private to that class.\n\t\n\t Guideline 2: Check all inputs for validity\nAll programs take inputs from their environment and process them. The specification \nmakes assumptions about these inputs that reflect their real-world use. For example, it \nmay be assumed that a bank account number is always an eight-digit positive integer. In \nmany cases, however, the system specification does not define what actions should be \ntaken if the input is incorrect. Inevitably, users will make mistakes and will sometimes \nenter the wrong data. As I discuss in Chapter 13, \u00ad\nmalicious attacks on a system may \nrely on deliberately entering invalid information. Even when inputs come from sensors \nor other systems, these systems can go wrong and provide incorrect values.\nYou should therefore always check the validity of inputs as soon as they are read \nfrom the program\u2019s operating environment. The checks involved obviously depend \non the inputs themselves, but possible checks that may be used are:\n1.\t\nRange checks You may expect inputs to be within a particular range. For exam-\nple, an input that represents a probability should be within the range 0.0 to 1.0; \nan input that represents the temperature of a liquid water should be between 0 \ndegrees Celsius and 100 degrees Celsius, and so on.\nDependable programming guidelines\n1.\u2002 Limit the visibility of information in a program.\n2.\u2002 Check all inputs for validity.\n3.\u2002 Provide a handler for all exceptions.\n4.\u2002 Minimize the use of error-prone constructs.\n5.\u2002 Provide restart capabilities.\n6.\u2002 Check array bounds.\n7.\u2002 Include timeouts when calling external components.\n8.\u2002 Name all constants that represent real-world values.\nFigure 11.11\u2002 Good \npractice guidelines for \ndependable \nprogramming\n", "page": 327, "type": "text", "section": "Page 327"}
{"text": " \n11.4\u2002 \u25a0\u2002 Programming for reliability\u2002 \u2002 327\n2.\t\nSize checks You may expect inputs to be a given number of characters, for \nexample, 8 characters to represent a bank account. In other cases, the size may \nnot be fixed, but there may be a realistic upper limit. For example, it is unlikely \nthat a person\u2019s name will have more than 40 characters.\n3.\t\nRepresentation checks You may expect an input to be of a particular type, which \nis represented in a standard way. For example, people\u2019s names do not include \nnumeric characters, email addresses are made up of two parts, separated by a @ \nsign, and so on.\n4.\t\nReasonableness checks Where an input is one of a series and you know some-\nthing about the relationships between the members of the series, then you can \ncheck that an input value is reasonable. For example, if the input value repre-\nsents the readings of a household electricity meter, then you would expect the \namount of electricity used to be approximately the same as in the corresponding \nperiod in the previous year. Of course, there will be variations. but order of \nmagnitude differences suggest that something has gone wrong.\nThe actions that you take if an input validation check fails depend on the type \nof system being implemented. In some cases, you report the problem to the user \nand request that the value is re-input. Where a value comes from a sensor, you \nmight use the most recent valid value. In embedded real-time systems, you might \nhave to estimate the value based on previous data, so that the system can continue \nin operation.\n\t\n\t Guideline 3: Provide a handler for all exceptions\nDuring program execution, errors or unexpected events inevitably occur. These may \narise because of a program fault, or they may be a result of unpredictable external \ncircumstances. An error or an unexpected event that occurs during the execution of a \nprogram is called an exception. Examples of exceptions might be a system power \nfailure, an attempt to access nonexistent data, or numeric overflow or underflow.\nExceptions may be caused by hardware or software conditions. When an excep-\ntion occurs, it must be managed by the system. This can be done within the program \nitself, or it may involve transferring control to a system exception-handling mecha-\nnism. Typically, the system\u2019s exception management mechanism reports the error \nand shuts down execution. Therefore, to ensure that program exceptions do not \ncause system failure, you should define an exception handler for all possible excep-\ntions that may arise; you should also make sure that all exceptions are detected and \nexplicitly handled.\nLanguages such as Java, C++, and Python have built-in exception-handling \n\u00ad\nconstructs. When an exceptional situation occurs, the exception is signaled and the \nlanguage runtime system transfers control to an exception handler. This is a code \nsection that states exception names and appropriate actions to handle each exception \n(Figure 11.12). The exception handler is outside the normal flow of control, and this \nnormal control flow does not resume after the exception has been handled.\n", "page": 328, "type": "text", "section": "Page 328"}
{"text": "328\u2002 \u2002 Chapter 11\u2002 \u25a0\u2002 Reliability engineering\nAn exception handler usually does one of three things:\n1.\t\nSignals to a higher-level component that an exception has occurred and pro-\nvides information to that component about the type of exception. You use this \napproach when one component calls another and the calling component needs to \nknow if the called component has executed successfully. If not, it is up to the \ncalling component to take action to recover from the problem.\n2.\t\nCarries out some alternative processing to that which was originally intended. \nTherefore, the exception handler takes some actions to recover from the prob-\nlem. Processing may then continue as normal. Alternatively, the exception han-\ndler may indicate that an exception has occurred so that a calling component is \naware of and can deal with the exception.\n3.\t\nPasses control to the programming language runtime support system that han-\ndles the exception. This is often the default when faults occur in a program, for \nexample, when a numeric value overflows. The usual action of the runtime sys-\ntem is to halt processing. You should only use this approach when it is possible \nto move the system to a safe and quiescent state, before handing over control to \nthe runtime system.\nHandling exceptions within a program makes it possible to detect and recover \nfrom some input errors and unexpected external events. As such, it provides a degree \nof fault tolerance. The program detects faults and can take action to recover from \nthem. As most input errors and unexpected external events are usually transient, it is \noften possible to continue normal operation after the exception has been processed.\n\t\n\t Guideline 4: Minimize the use of error-prone constructs\nFaults in programs, and therefore many program failures, are usually a consequence \nof human error. Programmers make mistakes because they lose track of the numer-\nous relationships between the state variables. They write program statements that \nresult in unexpected behavior and system state changes. People will always make \nCode section\nException-handling code\nNormal flow\nof control\nException detected\nNormal exit\nException\nprocessing\nFigure 11.12\u2002 Exception \nhandling \n", "page": 329, "type": "text", "section": "Page 329"}
{"text": " \n11.4\u2002 \u25a0\u2002 Programming for reliability\u2002 \u2002 329\nmistakes, but in the late 1960s it became clear that some approaches to programming \nwere more likely to introduce errors into a program than others.\nFor example, you should try to avoid using floating-point numbers because the \nprecision of floating point numbers is limited by their hardware representation. \nComparisons of very large or very small numbers are unreliable. Another construct \nthat is potentially error-prone is dynamic storage allocation where you explicitly \nmanage storage in the program. It is very easy to forget to release storage when it\u2019s \nno longer needed, and this can lead to hard to detect runtime errors.\nSome standards for safety-critical systems development completely prohibit the \nuse of error-prone constructs. However, such an extreme position is not normally \npractical. All of these constructs and techniques are useful, though they must be used \nwith care. Wherever possible, their potentially dangerous effects should be con-\ntrolled by using them within abstract data types or objects. These act as natural \u201cfire-\nwalls\u201d limiting the damage caused if errors occur.\n\t\n\t Guideline 5: Provide restart capabilities\nMany organizational information systems are based on short transactions where pro-\ncessing user inputs takes a relatively short time. These systems are designed so that \nchanges to the system\u2019s database are only finalized after all other processing has been \nsuccessfully completed. If something goes wrong during processing, the database is \nnot updated and so does not become inconsistent. Virtually all e-commerce systems, \nwhere you only commit to your purchase on the final screen, work in this way.\nUser interactions with e-commerce systems usually last a few minutes and \ninvolve minimal processing. Database transactions are short and are usually com-\npleted in less than a second. However, other types of system such as CAD systems \nand word processing systems involve long transactions. In a long transaction system, \nthe time between starting to use the system and finishing work may be several min-\nutes or hours. If the system fails during a long transaction, then all of the work may \nbe lost. Similarly, in computationally intensive systems such as some e-science sys-\ntems, minutes or hours of processing may be required to complete the computation. \nAll of this time is lost in the event of a system failure.\nIn all of these types of systems, you should provide a restart capability that is \nbased on keeping copies of data collected or generated during processing. The restart \nfacility should allow the system to restart using these copies, rather than having to \nError-prone constructs\nSome programming language features are more likely than others to lead to the introduction of program bugs. \nProgram reliability is likely to be improved if you avoid using these constructs. Wherever possible, you should \nminimize the use of go to statements, floating-point numbers, pointers, dynamic memory allocation, parallel-\nism, recursion, interrupts, aliasing, unbounded arrays, and default input processing.\nhttp://software-engineering-book.com/web/error-prone-constructs/\n", "page": 330, "type": "text", "section": "Page 330"}
{"text": "330\u2002 \u2002 Chapter 11\u2002 \u25a0\u2002 Reliability engineering\nstart all over from the beginning. These copies are sometimes called checkpoints. \nFor example:\n1.\t\nIn an e-commerce system, you can keep copies of forms filled in by a user and \nallow them to access and submit these forms without having to fill them in again.\n2.\t\nIn a long transaction or computationally intensive system, you can automatically \nsave data every few minutes and, in the event of a system failure, restart with the \nmost recently saved data. You should also allow for user error and provide a way \nfor users to go back to the most recent checkpoint and start again from there.\nIf an exception occurs and it is impossible to continue normal operation, you can \nhandle the exception using backward error recovery. This means that you reset the state \nof the system to the saved state in the checkpoint and restart operation from that point.\n\t\n\t Guideline 6: Check array bounds\nAll programming languages allow the specification of arrays\u2014sequential data struc-\ntures that are accessed using a numeric index. These arrays are usually laid out in \ncontiguous areas within the working memory of a program. Arrays are specified to \nbe of a particular size, which reflects how they are used. For example, if you wish to \nrepresent the ages of up to 10,000 people, then you might declare an array with \n10,000 locations to hold the age data.\nSome programming languages, such as Java, always check that when a value is \nentered into an array, the index is within that array. So, if an array A is indexed from 0 to \n10,000, an attempt to enter values into elements A [-5] or A [12345] will lead to an \nexception being raised. However, programming languages such as C and C++ do not \nautomatically include array bound checks and simply calculate an offset from the begin-\nning of the array. Therefore, A [12345] would access the word that was 12345 locations \nfrom the beginning of the array, irrespective of whether or not this was part of the array.\nThese languages do not include automatic array bound checking because this \nintroduces an overhead every time the array is accessed and so it increases program \nexecution time. However, the lack of bound checking leads to security vulnerabili-\nties, such as buffer overflow, which I discuss in Chapter 13. More generally, it intro-\nduces a system vulnerability that can lead to system failure. If you are using a \nlanguage such as C or C++ that does not include array bound checking, you should \nalways include checks that the array index is within bounds.\n\t\n\t Guideline 7: Include timeouts when calling external components\nIn distributed systems, components of the system execute on different computers, and \ncalls are made across the network from component to component. To receive some \nservice, component A may call component B. A waits for B to respond before con-\ntinuing execution. However, if component B fails to respond for some reason, then \ncomponent A cannot continue. It simply waits indefinitely for a response. A person \n", "page": 331, "type": "text", "section": "Page 331"}
{"text": " \n11.5\u2002 \u25a0\u2002 Reliability measurement\u2002 \u2002 331\nwho is waiting for a response from the system sees a silent system failure, with no \nresponse from the system. They have no alternative but to kill the waiting process and \nrestart the system.\nTo avoid this prospect, you should always include timeouts when calling external \ncomponents. A timeout is an automatic assumption that a called component has \nfailed and will not produce a response. You define a time period during which you \nexpect to receive a response from a called component. If you have not received a \nresponse in that time, you assume failure and take back control from the called com-\nponent. You can then attempt to recover from the failure or tell the system users \nwhat has happened and allow them to decide what to do.\n\t\n\t Guideline 8: Name all constants that represent real-world values\nAll nontrivial programs include a number of constant values that represent the values of \nreal-world entities. These values are not modified as the program executes. Sometimes, \nthese are absolute constants and never change (e.g., the speed of light), but more often \nthey are values that change relatively slowly over time. For example, a program to \n\u00ad\ncalculate personal tax will include constants that are the current tax rates. These change \nfrom year to year, and so the program must be updated with the new constant values.\nYou should always include a section in your program in which you name all real-\nworld constant values that are used. When using the constants, you should refer to \nthem by name rather than by their value. This has two advantages as far as depend-\nability is concerned:\n1.\t\nYou are less likely to make mistakes and use the wrong value. It is easy to mistype \na number, and the system will often be unable to detect a mistake. For example, \nsay a tax rate is 34%. A simple transposition error might lead to this being \nmistyped as 43%. However, if you mistype a name (such as Standard-\u00ad\n\u00ad\ntax-rate), \nthis error can be detected by the compiler as an undeclared variable.\n2.\t\nWhen a value changes, you do not have to look through the whole program to \ndiscover where you have used that value. All you need do is to change the value \nassociated with the constant declaration. The new value is then automatically \nincluded everywhere that it is needed.\n \n11.5 Reliability measurement\nTo assess the reliability of a system, you have to collect data about its operation. The \ndata required may include:\n1.\t\nThe number of system failures given a number of requests for system services. \nThis is used to measure the POFOD and applies irrespective of the time over \nwhich the demands are made.\n", "page": 332, "type": "text", "section": "Page 332"}
{"text": "332\u2002 \u2002 Chapter 11\u2002 \u25a0\u2002 Reliability engineering\n2.\t\nThe time or the number of transactions between system failures plus the total \nelapsed time or total number of transactions. This is used to measure ROCOF \nand MTTF.\n3.\t\nThe repair or restart time after a system failure that leads to loss of service. This \nis used in the measurement of availability. Availability does not just depend on \nthe time between failures but also on the time required to get the system back \ninto operation.\nThe time units that may be used in these metrics are calendar time or a discrete \nunit such as number of transactions. You should use calendar time for systems that \nare in continuous operation. Monitoring systems, such as process control systems, \nfall into this category. Therefore, the ROCOF might be the number of failures per \nday. Systems that process transactions such as bank ATMs or airline reservation \nsystems have variable loads placed on them depending on the time of day. In these \ncases, the unit of \u201ctime\u201d used could be the number of transactions; that is, the \nROCOF would be number of failed transactions per N thousand transactions.\nReliability testing is a statistical testing process that aims to measure the \u00ad\nreliability \nof a system. Reliability metrics such as POFOD, the probability of failure on \ndemand, and ROCOF, the rate of occurrence of failure, may be used to quantita-\ntively specify the required software reliability. You can check on the reliability test-\ning process if the system has achieved that required reliability level.\nThe process of measuring the reliability of a system is sometimes called statistical \ntesting (Figure 11.13). The statistical testing process is explicitly geared to reliability \nmeasurement rather than fault finding. Prowell et al. (Prowell et al. 1999) give a good \ndescription of statistical testing in their book on Cleanroom software engineering.\nThere are four stages in the statistical testing process:\n1.\t\nYou start by studying existing systems of the same type to understand how these \nare used in practice. This is important as you are trying to measure the reliability \nas experienced by system users. Your aim is to define an operational profile. An \noperational profile identifies classes of system inputs and the probability that \nthese inputs will occur in normal use.\n2.\t\nYou then construct a set of test data that reflect the operational profile. This \nmeans that you create test data with the same probability distribution as the test \ndata for the systems that you have studied. Normally, you use a test data genera-\ntor to support this process.\n3.\t\nYou test the system using these data and count the number and type of failures \nthat occur. The times of these failures are also logged. As I discussed in Chapter \n10, the time units chosen should be appropriate for the reliability metric used.\nCompute\nobserved\nreliability\nApply tests to\nsystem\nPrepare test\ndataset\nIdentify\noperational\nprofiles\nFigure 11.13\u2002 Statistical \ntesting for reliability \nmeasurement \n", "page": 333, "type": "text", "section": "Page 333"}
{"text": " \n11.5\u2002 \u25a0\u2002 Reliability measurement\u2002 \u2002 333\n4.\t After you have observed a statistically significant number of failures, you \ncan compute the software reliability and work out the appropriate reliability \nmetric value.\nThis conceptually attractive approach to reliability measurement is not easy to \napply in practice. The principal difficulties that arise are due to:\n1.\t\nOperational profile uncertainty The operational profiles based on experience \nwith other systems may not be an accurate reflection of the real use of the system.\n2.\t\nHigh costs of test data generation It can be very expensive to generate the large \nvolume of data required in an operational profile unless the process can be \ntotally automated.\n3.\t\nStatistical uncertainty when high reliability is specified You have to generate a \nstatistically significant number of failures to allow accurate reliability measure-\nments. When the software is already reliable, relatively few failures occur and it \nis difficult to generate new failures.\n4.\t\nRecognizing failure It is not always obvious whether or not a system failure has \noccurred. If you have a formal specification, you may be able to identify devia-\ntions from that specification, but, if the specification is in natural language, \nthere may be ambiguities that mean observers could disagree on whether the \nsystem has failed.\nBy far the best way to generate the large dataset required for reliability measure-\nment is to use a test data generator, which can be set up to automatically generate \ninputs matching the operational profile. However, it is not usually possible to auto-\nmate the production of all test data for interactive systems because the inputs are \noften a response to system outputs. Datasets for these systems have to be generated \nmanually, with correspondingly higher costs. Even where complete automation is \npossible, writing commands for the test data generator may take a significant amount \nof time.\nStatistical testing may be used in conjunction with fault injection to gather data \nabout how effective the process of defect testing has been. Fault injection (Voas and \nMcGraw 1997) is the deliberate injection of errors into a program. When the pro-\ngram is executed, these lead to program faults and associated failures. You then \nanalyze the failure to discover if the root cause is one of the errors that you have \nadded to the program. If you find that X% of the injected faults lead to failures, then \nproponents of fault injection argue that this suggests that the defect testing process \nwill also have discovered X% of the actual faults in the program.\nThis approach assumes that the distribution and type of injected faults reflect the \nactual faults in the system. It is reasonable to think that this might be true for faults \ndue to programming errors, but it is less likely to be true for faults resulting from \nrequirements or design problems. Fault injection is ineffective in predicting the \nnumber of faults that stem from anything but programming errors.\n", "page": 334, "type": "text", "section": "Page 334"}
{"text": "334\u2002 \u2002 Chapter 11\u2002 \u25a0\u2002 Reliability engineering\n\t\n11.5.1\t Operational profiles\nThe operational profile of a software system reflects how it will be used in practice. \nIt consists of a specification of classes of input and the probability of their occur-\nrence. When a new software system replaces an existing automated system, it is \nreasonably easy to assess the probable pattern of usage of the new software. It should \ncorrespond to the existing usage, with some allowance made for the new functional-\nity that is (presumably) included in the new software. For example, an operational \nprofile can be specified for telephone switching systems because telecommunication \ncompanies know the call patterns that these systems have to handle.\nTypically, the operational profile is such that the inputs that have the highest \nprobability of being generated fall into a small number of classes, as shown on the \nleft of Figure 11.14. There are many classes where inputs are highly improbable but \nnot impossible. These are shown on the right of Figure 11.14. The ellipsis (. . .) \nmeans that there are many more of these uncommon inputs than are shown.\nMusa (Musa 1998) discusses the development of operational profiles in tele-\ncommunication systems. As there is a long history of collecting usage data in that \ndomain, the process of operational profile development is relatively straightfor-\nward. It simply reflects the historical usage data. For a system that required about \n15 \u00ad\nperson-years of development effort, an operational profile was developed in \nabout 1 person-month. In other cases, operational profile generation took longer \n(2\u20133 \u00ad\nperson-years), but the cost was spread over a number of system releases.\nWhen a software system is new and innovative, however, it is difficult to antici-\npate how it will be used. Consequently, it is practically impossible to create an accu-\nrate operational profile. Many different users with different expectations, \nbackgrounds, and experience may use the new system. There is no historical usage \ndatabase. These users may make use of systems in ways that the system developers \ndid not anticipate.\nDeveloping an accurate operational profile is certainly possible for some types of \nsystem, such as telecommunication systems, that have a standardized pattern of use. \nHowever, for other types of system, developing an accurate operational profile may \nbe difficult or impossible:\n1.\t A system may have many different users who each have their own ways of \nusing the system. As I explained earlier in this chapter, different users have \nReliability growth modeling\nA reliability growth model is a model of how the system reliability changes over time during the testing process. \nAs system failures are discovered, the underlying faults causing these failures are repaired so that the reliability \nof the system should improve during system testing and debugging. To predict reliability, the conceptual reliabil-\nity growth model must then be translated into a mathematical model.\nhttp://software-engineering-book.com/web/reliability-growth-modeling/\n", "page": 335, "type": "text", "section": "Page 335"}
{"text": " \nChapter 11\u2002 \u25a0\u2002 Key points\u2002 \u2002 335\ndifferent impressions of reliability because they use a system in different ways. \nIt is difficult to match all of these patterns of use in a single operational profile.\n2.\t Users change the ways that they use a system over time. As users learn about \na new system and become more confident with it, they start to use it in more \nsophisticated ways. Therefore, an operational profile that matches the initial \nusage pattern of a system may not be valid after users become familiar with \nthe system.\nFor these reasons, it is often impossible to develop a trustworthy operational pro-\nfile. If you use an out-of-date or incorrect operational profile, you cannot be confi-\ndent about the accuracy of any reliability measurements that you make.\nKey Points\n\u25a0\t Software reliability can be achieved by avoiding the introduction of faults, by detecting and \nremoving faults before system deployment, and by including fault-tolerance facilities that allow \nthe system to remain operational after a fault has caused a system failure.\n\u25a0\t Reliability requirements can be defined quantitatively in the system requirements specification. \nReliability metrics include probability of failure on demand (POFOD), rate of occurrence of fail-\nure (ROCOF), and availability (AVAIL).\n\u25a0\t Functional reliability requirements are requirements for system functionality, such as checking \nand redundancy requirements, which help the system meet its non-functional reliability \nrequirements.\n...\nNumber of inputs\nInput classes\nFigure 11.14\u2002  \nDistribution of\u00a0inputs in \nan operational profile \n", "page": 336, "type": "text", "section": "Page 336"}
{"text": "336\u2002 \u2002 Chapter 11\u2002 \u25a0\u2002 Reliability engineering\n\u25a0\t Dependable system architectures are system architectures that are designed for fault tolerance. \nA number of architectural styles support fault tolerance, including protection systems, self-\nmonitoring architectures, and N-version programming.\n\u25a0\t Software diversity is difficult to achieve because it is practically impossible to ensure that each \nversion of the software is truly independent.\n\u25a0\t Dependable programming relies on including redundancy in a program as checks on the validity \nof inputs and the values of program variables.\n\u25a0\t Statistical testing is used to estimate software reliability. It relies on testing the system with \ntest data that matches an operational profile, which reflects the distribution of inputs to the \nsoftware when it is in use.\nWebsite\nPowerPoint slides for this chapter:\nwww.pearsonglobaleditions.com/Sommerville\nLinks to supporting videos:\nhttp://software-engineering-book.com/videos/reliability-and-safety/\nMore information on the Airbus flight control system:\nhttp://software-engineering-book.com/case-studies/airbus-340/\nFurther Reading\nSoftware Fault Tolerance Techniques and Implementation. A comprehensive discussion of tech-\nniques to achieve software fault tolerance and fault-tolerant architectures. The book also covers \ngeneral issues of software dependability. Reliability engineering is a mature area, and the tech-\nniques discussed here are still current. (L. L. Pullum, Artech House, 2001).\n\u201cSoftware Reliability Engineering: A Roadmap.\u201d This survey paper by a leading researcher in soft-\nware reliability summarizes the state of the art in software reliability engineering and discusses \nresearch challenges in this area. (M. R. Lyu, Proc. Future of Software Engineering, IEEE Computer \nSociety, 2007) http://dx.doi.org/10.1109/FOSE.2007.24\n\u201cMars Code.\u201d This paper discusses the approach to reliability engineering used in the development \nof software for the Mars Curiosity Rover. This relied on the use of good programming practice, \nredundancy, and model checking (covered in Chapter 12). (G. J. Holzmann, Comm. ACM., 57 (2), \n2014) http://dx.doi.org/10.1145/2560217.2560218\n336\u2002 \u2002 Chapter 11\u2002 \u25a0\u2002 Reliability engineering\n", "page": 337, "type": "text", "section": "Page 337"}
{"text": " \n11.5\u2002 \u25a0\u2002 Reliability measurement\u2002 \u2002 337\nExercises\n\u2002 11.1.\t  \nExplain why it is practically impossible to validate reliability specifications when these are \nexpressed in terms of a very small number of failures over the total lifetime of a system.\n\u2002 11.2.\t  \nSuggest appropriate reliability metrics for the classes of software system below. Give rea-\nsons for your choice of metric. Predict the usage of these systems and suggest appropriate \nvalues for the reliability metrics.\n\u25a0\t a system that monitors patients in a hospital intensive care unit\n\u25a0\t a word processor\n\u25a0\t an automated vending machine control system\n\u25a0\t a system to control braking in a car\n\u25a0\t a system to control a refrigeration unit\n\u25a0\t a management report generator\n\u2002 11.3.\t \nImagine that a network operations center monitors and controls the national telecommu-\nnications network of a country. This includes controlling and monitoring the operational \nstatus of switching and transmission equipment and keeping track of nationwide equip-\nment inventories. The center needs to have redundant systems. Explain three reliability \nmetrics you would use to specify the needs of such systems.\n\u2002 11.4.\t  \nWhat is the common characteristic of all architectural styles that are geared to supporting \nsoftware fault tolerance?\n\u2002 11.5. \t \nSuggest circumstances where it is appropriate to use a fault-tolerant architecture when \nimplementing a software-based control system and explain why this approach is required.\n\u2002 11.6. \t \nYou are responsible for the design of a communications switch that has to provide 24/7 \navailability but that is not safety-critical. Giving reasons for your answer, suggest an archi-\ntectural style that might be used for this system.\n\u2002 11.7. \t \nIt has been suggested that the control software for a radiation therapy machine, used to \ntreat patients with cancer, should be implemented using N-version programming. Comment \non whether or not you think this is a good suggestion.\n\u2002 11.8. \t \nExplain why all the versions in a system designed around software diversity may fail in a \nsimilar way.\n\u2002 11.9. \t \nExplain how programming language support of exception handling can contribute to the reli-\nability of software systems.\n11.10. \t \nSoftware failures can cause considerable inconvenience to users of the software. Is it \n\u00ad\nethical for companies to release software that they know includes faults that could lead \nto\u00a0software failures? Should they be liable for compensating users for losses that are \ncaused by the failure of their software? Should they be required by law to offer soft\u00ad\nware \nwarranties in the same way that consumer goods manufacturers must guarantee \ntheir\u00a0products?\n \nChapter 11\u2002 \u25a0\u2002 Exercises\u2002 \u2002 337\n", "page": 338, "type": "text", "section": "Page 338"}
{"text": "338\u2002 \u2002 Chapter 11\u2002 \u25a0\u2002 Reliability engineering\nReferences\nAvizienis, A. A. 1995. \u201cA Methodology of N-Version Programming.\u201d In Software Fault Tolerance, \nedited by M. R. Lyu, 23\u201346. Chichester, UK: John Wiley & Sons.\nBrilliant, S. S., J. C. Knight, and N. G. Leveson. 1990. \u201cAnalysis of Faults in an N-Version Software \nExperiment.\u201d IEEE Trans. On Software Engineering 16 (2): 238\u2013247. doi:10.1109/32.44387.\nHatton, L. 1997. \u201cN-Version Design Versus One Good Version.\u201d IEEE Software 14 (6): 71\u201376. \ndoi:10.1109/52.636672.\nLeveson, N. G. 1995. Safeware: System Safety and Computers. Reading, MA: Addison-Wesley.\nMusa, J. D. 1998. Software Reliability Engineering: More Reliable Software, Faster Development and \nTesting. New York: McGraw-Hill.\nProwell, S. J., C. J. Trammell, R. C. Linger, and J. H. Poore. 1999. Cleanroom Software Engineering: \nTechnology and Process. Reading, MA: Addison-Wesley.\nPullum, L. 2001. Software Fault Tolerance Techniques and Implementation. Norwood, MA: Artech \nHouse.\nRandell, B. 2000. \u201cFacing Up To Faults.\u201d Computer J. 45 (2): 95\u2013106. doi:10.1093/comjnl/43.2.95.\nTorres-Pomales, W. 2000. \u201cSoftware Fault Tolerance: A Tutorial.\u201d NASA. http://ntrs.nasa.gov/\narchive/nasa/casi. . ./20000120144_2000175863.pdf\nVoas, J., and G. McGraw. 1997. Software Fault Injection: Innoculating Programs Against Errors. New \nYork: John Wiley & Sons.\n338\u2002 \u2002 Chapter 11\u2002 \u25a0\u2002 Reliability engineering\n", "page": 339, "type": "text", "section": "Page 339"}
{"text": "Safety engineering\n12 \nObjectives\nThe objective of this chapter is to explain techniques that are used to \nensure safety when developing critical systems. When you have read this \nchapter, you will:\n\u25a0\t understand what is meant by a safety-critical system and why safety \nhas to be considered separately from reliability in critical systems \nengineering;\n\u25a0\t understand how an analysis of hazards can be used to derive safety \nrequirements;\n\u25a0\t know about processes and tools that are used for software safety \nassurance;\n\u25a0\t understand the notion of a safety case that is used to justify the safety \nof a system to regulators, and how formal arguments may be used in \nsafety cases.\nContents\n12.1\t Safety-critical systems\n12.2\t Safety requirements\n12.3\t Safety engineering processes\n12.4\t Safety cases\n", "page": 340, "type": "text", "section": "Page 340"}
{"text": "340\u2002 \u2002 Chapter 12\u2002 \u25a0\u2002 Safety engineering\nIn Section 11.2, I briefly described an air accident at Warsaw Airport where an \nAirbus crashed on landing. Two people were killed and 54 were injured. The subse-\nquent inquiry showed that a major contributory cause of the accident was a failure of \nthe control software that reduced the efficiency of the aircraft\u2019s braking system. This \nis one of the, thankfully rare, examples of where the behavior of a software system \nhas led to death or injury. It illustrates that software is now a central component in \nmany systems that are critical to preserving and maintaining life. These are safety-\ncritical software systems, and a range of specialized methods and techniques have \nbeen developed for safety-critical software engineering.\nAs I discussed in Chapter 10, safety is one of the principal dependability proper-\nties. A system can be considered to be safe if it operates without catastrophic failure, \nthat is, failure that causes or may cause death or injury to people. Systems whose \nfailure may lead to environmental damage may also be safety-critical as environmen-\ntal damage (such as a chemical leak) can lead to subsequent human injury or death.\nSoftware in safety-critical systems has a dual role to play in achieving safety:\n1.\t\nThe system may be software-controlled so that the decisions made by the soft-\nware and subsequent actions are safety-critical. Therefore, the software behav-\nior is directly related to the overall safety of the system.\n2.\t\nSoftware is extensively used for checking and monitoring other safety-critical com-\nponents in a system. For example, all aircraft engine components are monitored by \nsoftware looking for early indications of component failure. This \u00ad\nsoftware is safety-\ncritical because, if it fails, other components may fail and cause an accident.\nSafety in software systems is achieved by developing an understanding of the situ-\nations that might lead to safety-related failures. The software is engineered so that \nsuch failures do not occur. You might therefore think that if a safety-critical system is \nreliable and behaves as specified, it will therefore be safe. Unfortunately, it isn\u2019t quite \nas simple as that. System reliability is necessary for safety achievement, but it isn\u2019t \nenough. Reliable systems can be unsafe and vice versa. The Warsaw Airport accident \nwas an example of such a situation, which I\u2019ll discuss in more detail in Section 12.2.\nSoftware systems that are reliable may not be safe for four reasons:\n1.\t\nWe can never be 100% certain that a software system is fault-free and \n\u00ad\nfault-tolerant. Undetected faults can be dormant for a long time, and software \nfailures can occur after many years of reliable operation.\n2.\t\nThe specification may be incomplete in that it does not describe the required \nbehavior of the system in some critical situations. A high percentage of system \nmalfunctions are the result of specification rather than design errors. In a study \nof errors in embedded systems, Lutz (Lutz 1993) concludes that \u201cdifficulties \nwith requirements are the key root cause of the safety-related software errors, \nwhich have persisted until integration and system testing.\u2020\u201d\n\u2020Lutz, R R. 1993. \u201cAnalysing Software Requirements Errors in Safety-Critical Embedded Systems.\u201d In \nRE\u201993, 126\u2013133. San Diego CA: IEEE. doi:0.1109/ISRE.1993.324825.\n", "page": 341, "type": "text", "section": "Page 341"}
{"text": "\t\n12.1\u2002 \u25a0\u2002 Safety-critical systems\u2002 \u2002 341\nMore recent work by Veras et al. (Veras et al. 2010) in space systems confirms \nthat requirements errors are still a major problem for embedded systems.\n3.\t\nHardware malfunctions may cause sensors and actuators to behave in an unpre-\ndictable way. When components are close to physical failure, they may behave \nerratically and generate signals that are outside the ranges that can be handled by \nthe software. The software may then either fail or wrongly \u00ad\ninterpret these signals.\n4.\t\nThe system operators may generate inputs that are not individually incorrect but \nthat, in some situations, can lead to a system malfunction. An anecdotal exam-\nple of this occurred when an aircraft undercarriage collapsed while the aircraft \nwas on the ground. Apparently, a technician pressed a button that instructed the \nutility management software to raise the undercarriage. The software carried out \nthe mechanic\u2019s instruction perfectly. However, the system should have disal-\nlowed the command unless the plane was in the air.\nTherefore, safety has to be considered as well as reliability when developing \nsafety-critical systems. The reliability engineering techniques that I introduced in \nChapter 11 are obviously applicable for safety-critical systems engineering. I there-\nfore do not discuss system architectures and dependable programming here but \ninstead focus on techniques for improving and assuring system safety.\n \n12.1 Safety-critical systems\nSafety-critical systems are systems in which it is essential that system operation is \nalways safe. That is, the system should never damage people or the system\u2019s environ-\nment, irrespective of whether or not the system conforms to its specification. Examples \nof safety-critical systems include control and monitoring systems in aircraft, process \ncontrol systems in chemical and pharmaceutical plants, and automobile control systems.\nSafety-critical software falls into two classes:\n1.\t\nPrimary safety-critical software This is software that is embedded as a control-\nler in a system. Malfunctioning of such software can cause a hardware malfunc-\ntion, which results in human injury or environmental damage. The insulin pump \nsoftware that I introduced in Chapter 1 is an example of a primary safety-critical \nsystem. System failure may lead to user injury.\n\t\nThe insulin pump system is a simple system, but software control is also used in \nvery complex safety-critical systems. Software rather than hardware control is \nessential because of the need to manage large numbers of sensors and actuators, \nwhich have complex control laws. For example, advanced, aerodynamically \nunstable, military aircraft require continual software-controlled adjustment of \ntheir flight surfaces to ensure that they do not crash.\n2.\t\nSecondary safety-critical software This is software that can indirectly result in an \ninjury. An example of such software is a computer-aided engineering design system \n", "page": 342, "type": "text", "section": "Page 342"}
{"text": "342\u2002 \u2002 Chapter 12\u2002 \u25a0\u2002 Safety engineering\nwhose malfunctioning might result in a design fault in the object being designed. \nThis fault may cause injury to people if the designed system malfunctions. Another \nexample of a secondary safety-critical system is the Mentcare system for mental \nhealth patient management. Failure of this system, whereby an unstable patient may \nnot be treated properly, could lead to that patient injuring himself or others.\n\t\nSome control systems, such as those controlling critical national infrastructure (elec-\ntricity supply, telecommunications, sewage treatment, etc.), are secondary safety-\ncritical systems. Failure of these systems is unlikely to have immediate human \nconsequences. However, a prolonged outage of the controlled systems could lead to \ninjury and death. For example, failure of a sewage treatment system could lead to a \nhigher level of infectious disease as raw sewage is released into the environment.\nI explained in Chapter 11 how software and system availability and reliability are \nachieved through fault avoidance, fault detection and removal, and fault tolerance. \nSafety-critical systems development uses these approaches and augments them with \nhazard-driven techniques that consider the potential system accidents that may occur:\n1.\t\nHazard avoidance The system is designed so that hazards are avoided. For \nexample, a paper-cutting system that requires an operator to use two hands to \npress separate buttons simultaneously avoids the hazard of the operator\u2019s hands \nbeing in the blade\u2019s pathway.\n2.\t\nHazard detection and removal The system is designed so that hazards are \ndetected and removed before they result in an accident. For example, a chemical \nplant system may detect excessive pressure and open a relief valve to reduce \npressure before an explosion occurs.\n3.\t\nDamage limitation The system may include protection features that minimize \nthe damage that may result from an accident. For example, an aircraft engine \nnormally includes automatic fire extinguishers. If there is an engine fire, it can \noften be controlled before it poses a threat to the aircraft.\nA hazard is a system state that could lead to an accident. Using the above example \nof the paper-cutting system, a hazard arises when the operator\u2019s hand is in a position \nwhere the cutting blade could injure it. Hazards are not accidents\u2014we often get our-\nselves into hazardous situations and get out of them without any problems. However, \naccidents are always preceded by hazards, so reducing hazards reduces accidents.\nA hazard is one example of the specialized vocabulary that is used in \u00ad\nsafety-critical sys-\ntems engineering. I explain other terminology used in safety-critical systems in Figure 12.1.\nWe are now actually pretty good at building systems that can cope with one thing \ngoing wrong. We can design mechanisms into the system that can detect and recover \nfrom single problems. However, when several things go wrong at the same time, acci-\ndents are more likely. As systems become more and more complex, we don\u2019t understand \nthe relationships between the different parts of the system. Consequently, we cannot \npredict the consequences of a combination of unexpected system events or failures.\nIn an analysis of serious accidents, Perrow (Perrow 1984) suggested that almost \nall of the accidents were due to a combination of failures in different parts of a system. \n", "page": 343, "type": "text", "section": "Page 343"}
{"text": "\t\n12.1\u2002 \u25a0\u2002 Safety-critical systems\u2002 \u2002 343\nTerm\nDefinition\nAccident (or mishap)\nAn unplanned event or sequence of events that results in human death or injury, \ndamage to property or to the environment. An overdose of insulin is an example of \nan accident.\nDamage\nA measure of the loss resulting from a mishap. Damage can range from many \npeople being killed as a result of an accident to minor injury or property damage. \nDamage resulting from an overdose of insulin could lead to serious injury or the \ndeath of the user of the insulin pump.\nHazard\nA condition with the potential for causing or contributing to an accident. A failure of \nthe sensor that measures blood glucose is an example of a hazard.\nHazard probability\nThe probability of the events occurring which create a hazard. Probability values \ntend to be arbitrary but range from \u201cprobable\u201d (say 1/100 chance of a hazard \noccurring) to \u201cimplausible\u201d (no conceivable situations are likely in which the hazard \ncould occur). The probability of a sensor failure in the insulin pump that \noverestimates the user\u2019s blood sugar level is low.\nHazard severity\nAn assessment of the worst possible damage that could result from a particular \nhazard. Hazard severity can range from catastrophic, where many people are killed, \nto minor, where only minor damage results. When an individual death is a \npossibility, a reasonable assessment of hazard severity is \u201cvery high.\u201d\nRisk\nA measure of the probability that the system will cause an accident. The risk is assessed \nby considering the hazard probability, the hazard severity, and the probability that the \nhazard will lead to an accident. The risk of an insulin overdose is medium to low.\nFigure 12.1\u2002 Safety \nterminology\nUnanticipated combinations of subsystem failures led to interactions that resulted in \noverall system failure. For example, failure of an air conditioning system may lead \nto overheating. Once hardware gets hot, its behavior becomes unpredictable, so \noverheating may lead to the system hardware generating incorrect signals. These \nwrong signals may then cause the software to react incorrectly.\nPerrow made the point that, in complex systems, it is impossible to anticipate all \npossible combinations of failures. He therefore coined the phrase \u201cnormal acci-\ndents,\u201d with the implication that accidents have to be considered as inevitable when \nwe build complex safety-critical systems.\nTo reduce complexity, we could use simple hardware controllers rather than soft-\nware control. However, software-controlled systems can monitor a wider range of \nconditions than simpler electromechanical systems. They can be adapted relatively \neasily. They use computer hardware, which has high inherent reliability and which is \nphysically small and lightweight.\nSoftware-controlled systems can provide sophisticated safety interlocks. They \ncan support control strategies that reduce the amount of time people need to spend in \nhazardous environments. Although software control may introduce more ways in \nwhich a system can go wrong, it also allows better monitoring and protection. \nTherefore, software control can contribute to improvements in system safety.\nIt is important to maintain a sense of proportion about safety-critical systems. Critical \nsoftware systems operate without problems most of the time. Relatively few people \nworldwide have been killed or injured because of faulty software. Perrow is right in say-\n", "page": 344, "type": "text", "section": "Page 344"}
{"text": "344\u2002 \u2002 Chapter 12\u2002 \u25a0\u2002 Safety engineering\ning that accidents will always be a possibility. It is impossible to make a system 100% \nsafe, and society has to decide whether or not the consequences of an occasional \n\u00ad\naccident are worth the benefits that come from the use of advanced technologies.\n \n12.2 Safety requirements\nIn the introduction to this chapter, I described an air accident at Warsaw Airport \nwhere the braking system on an Airbus failed. The inquiry into this accident showed \nthat the braking system software had operated according to its specification. There \nwere no errors in the program. However, the software specification was incomplete \nand had not taken into account a rare situation, which arose in this case. The soft-\nware worked, but the system failed.\nThis episode illustrates that system safety does not just depend on good engineer-\ning. It requires attention to detail when the system requirements are derived and the \ninclusion of special software requirements that are geared to ensuring the safety of a \nsystem. Safety requirements are functional requirements, which define checking and \nrecovery facilities that should be included in the system and features that provide \nprotection against system failures and external attacks.\nThe starting point for generating functional safety requirements is usually domain \nknowledge, safety standards, and regulations. These lead to high-level requirements \nthat are perhaps best described as \u201cshall not\u201d requirements. By contrast with normal \nfunctional requirements that define what the system shall do, \u201cshall not\u201d requirements \ndefine system behavior that is unacceptable. Examples of \u201cshall not\u201d requirements are:\n\u201cThe system shall not allow reverse thrust mode to be selected when the aircraft \nis in flight.\u201d\n\u201cThe system shall not allow the simultaneous activation of more than three alarm \nsignals.\u201d\n\u201cThe navigation system shall not allow users to set the required destination when \nthe car is moving.\u201d\nThese \u201cshall not\u201d requirements cannot be implemented directly but have to be \ndecomposed into more specific software functional requirements. Alternatively, \nthey may be implemented through system design decisions such as a decision to use \nparticular types of equipment in the system.\nRisk-based requirements specification\nRisk-based specification is an approach that has been widely used by safety and security-critical systems developers. \nIt\u00a0focuses on those events that could cause the most damage or that are likely to occur frequently. Events that have only \nminor consequences or that are extremely rare may be ignored. The risk-based specification process involves under-\nstanding the risks faced by the system, discovering their root causes, and generating requirements to manage these risks.\nhttp://software-engineering-book.com/web/risk-based-specification/\n", "page": 345, "type": "text", "section": "Page 345"}
{"text": "\t\n12.2\u2002 \u25a0\u2002 Safety requirements\u2002 \u2002 345\nSafety requirements are primarily protection requirements and are not concerned \nwith normal system operation. They may specify that the system should be shut down \nso that safety is maintained. In deriving safety requirements, you therefore need to find \nan acceptable balance between safety and functionality and avoid overprotection. There \nis no point in building a very safe system if it does not operate in a cost-effective way.\nRisk-based requirements specification is a general approach used in critical \u00ad\nsystems \nengineering where risks faced by the system are identified and requirements to avoid \nor mitigate these risks are identified. It may be used for all types of dependability \nrequirements. For safety-critical systems, it translates into a process driven by identi-\nfied hazards. As I discussed in the previous section, a hazard is something that could \n(but need not) result in death or injury to a person.\nThere are four activities in a hazard-driven safety specification process:\n1.\t\nHazard identification The hazard identification process identifies hazards that \nmay threaten the system. These hazards may be recorded in a hazard register. \nThis is a formal document that records the safety analyses and assessments and \nthat may be submitted to a regulator as part of a safety case.\n2.\t\nHazard assessment The hazard assessment process decides which hazards are \nthe most dangerous and/or the most likely to occur. These should be prioritized \nwhen deriving safety requirements.\n3.\t\nHazard analysis This is a process of root-cause analysis that identifies the \nevents that can lead to the occurrence of a hazard.\n4.\t\nRisk reduction This process is based on the outcome of hazard analysis and \nleads to identification of safety requirements. These requirements may be con-\ncerned with ensuring that a hazard does not arise or lead to an accident or that if \nan accident does occur, the associated damage is minimized.\nFigure 12.2 illustrates this hazard-driven safety requirements specification process.\n\t\n12.2.1\t Hazard identification\nIn safety-critical systems, hazard identification starts by identifying different classes of \nhazards, such as physical, electrical, biological, radiation, and service failure hazards. \nEach of these classes can then be analyzed to discover specific hazards that could occur. \nPossible combinations of hazards that are potentially dangerous must also be identified.\nHazard \nprobability and \nacceptability\nSafety \nrequirements\nRoot cause \nanalyses\nHazard register\nHazard \nidentification\nHazard \nassessment\nHazard \nanalysis\nRisk reduction\nFigure 12.2\u2002 Hazard-\ndriven requirements \nspecification \n", "page": 346, "type": "text", "section": "Page 346"}
{"text": "346\u2002 \u2002 Chapter 12\u2002 \u25a0\u2002 Safety engineering\nExperienced engineers, working with domain experts and professional safety \nadvisers, identify hazards from previous experience and from an analysis of the appli-\ncation domain. Group working techniques such as brainstorming may be used, where \na group meets to exchange ideas. For the insulin pump system, people who may be \ninvolved include doctors, medical physicists and engineers, and software designers.\nThe insulin pump system that I introduced in Chapter 1 is a safety-critical system, \nbecause failure can cause injury or even death to the system user. Accidents that may \noccur when using this machine include the user suffering from long-term conse-\nquences of poor blood sugar control (eye, heart, and kidney problems), cognitive \ndysfunction as a result of low blood sugar levels, or the occurrence of some other \nmedical conditions, such as an allergic reaction.\nSome of the hazards that may arise in the insulin pump system are:\n\u25a0\t insulin overdose computation (service failure);\n\u25a0\t insulin underdose computation (service failure);\n\u25a0\t failure of the hardware monitoring system (service failure);\n\u25a0\t power failure due to exhausted battery (electrical);\n\u25a0\t electrical interference with other medical equipment such as a heart pacemaker \n(electrical);\n\u25a0\t poor sensor and actuator contact caused by incorrect fitting (physical);\n\u25a0\t parts of machine breaking off in patient\u2019s body (physical);\n\u25a0\t infection caused by introduction of machine (biological); and\n\u25a0\t allergic reaction to the materials or insulin used in the machine (biological).\nSoftware-related hazards are normally concerned with failure to deliver a system \nservice or with the failure of monitoring and protection systems. Monitoring and \nprotection systems may be included in a device to detect conditions, such as a low \nbattery level, which could lead to device failure.\nA hazard register may be used to record the identified hazards with an explanation of \nwhy the hazard has been included. The hazard register is an important legal document \nthat records all safety-related decisions about each hazard. It can be used to show that \nthe requirements engineers have paid due care and attention in considering all foresee-\nable hazards and that these hazards have been analyzed. In the event of an accident, the \nhazard register may be used in a subsequent inquiry or legal proceedings to show that \nthe system developers have not been negligent in their system safety analysis.\n\t\n12.2.2\t Hazard assessment\nThe hazard assessment process focuses on understanding the factors that lead to the \noccurrence of a hazard and the consequences if an accident or incident associated \nwith that hazard should occur. You need to carry out this analysis to understand \n", "page": 347, "type": "text", "section": "Page 347"}
{"text": "\t\n12.2\u2002 \u25a0\u2002 Safety requirements\u2002 \u2002 347\nwhether a hazard is a serious threat to the system or environment. The analysis also \nprovides a basis for deciding on how to manage the risk associated with the hazard.\nFor each hazard, the outcome of the analysis and classification process is a state-\nment of acceptability. This is expressed in terms of risk, where the risk takes into \naccount the likelihood of an accident and its consequences. There are three risk cat-\negories that are used in hazard assessment:\n1.\t\nIntolerable risks in safety-critical systems are those that threaten human life. \nThe system must be designed so that such hazards either cannot arise or, that if \nthey do, features in the system will ensure that they are detected before they \ncause an accident. In the case of the insulin pump, an intolerable risk is that an \noverdose of insulin should be delivered.\n2.\t\nAs low as reasonably practical (ALARP) risks are those that have less serious \nconsequences or that are serious but have a very low probability of occurrence. \nThe system should be designed so that the probability of an accident arising \nbecause of a hazard is minimized, subject to other considerations such as cost and \ndelivery. An ALARP risk for an insulin pump might be the failure of the hardware \nmonitoring system. The consequences of this failure are, at worst, a short-term \ninsulin underdose. This situation would not lead to a serious accident.\n3.\t\nAcceptable risks are those where the associated accidents normally result in \nminor damage. System designers should take all possible steps to reduce \n\u201cacceptable\u201d risks, as long as these measures do not significantly increase costs, \ndelivery time, or other non-functional system attributes. An acceptable risk in \nthe case of the insulin pump might be the risk of an allergic reaction arising in \nthe user. This reaction usually causes only minor skin irritation. It would not be \nworth using special, more expensive materials in the device to reduce this risk.\nFigure 12.3 shows these three regions. The width of the triangle reflects the \ncosts of ensuring that risks do not result in incidents or accidents. The highest \nUnacceptable region\nRisk cannot be tolerated\nRisk tolerated only if\nrisk reduction is impractical\nor excessively expensive\nAcceptable\nregion\nNegligible risk\nALARP\nregion\nFigure 12.3\u2002 The risk \ntriangle\n", "page": 348, "type": "text", "section": "Page 348"}
{"text": "348\u2002 \u2002 Chapter 12\u2002 \u25a0\u2002 Safety engineering\ncosts are incurred by risks at the top of the diagram, the lowest costs by risks at the \napex of the triangle.\nThe boundaries between the regions in Figure 12.3 are not fixed but depend on \nhow acceptable risks are in the societies where the system will be deployed. This \nvaries from country to country\u2014some societies are more risk averse and litigious \nthan others. Over time, however, all societies have become more risk-averse, so the \nboundaries have moved downward. For rare events, the financial costs of accepting \nrisks and paying for any resulting accidents may be less than the costs of accident \nprevention. However, public opinion may demand that money be spent to reduce the \nlikelihood of a system accident irrespective of cost.\nFor example, it may be cheaper for a company to clean up pollution on the rare occa-\nsion it occurs, rather than to install systems for pollution prevention. However, because \nthe public and the media will not tolerate such accidents, clearing up the damage rather \nthan preventing the accident is no longer acceptable. Events in other systems may also \nlead to a reclassification of risk. For example, risks that were thought to be improbable \n(and hence in the ALARP region) may be reclassified as intolerable because of external \nevents, such as terrorist attacks, or natural phenomena, such as tsunamis.\nFigure 12.4 shows a risk classification for the hazards identified in the previous \nsection for the insulin delivery system. I have separated the hazards that relate to the \nincorrect computation of insulin into an insulin overdose and an insulin underdose. \nAn insulin overdose is potentially more serious than an insulin underdose in the \nshort term. Insulin overdose can result in cognitive dysfunction, coma, and ulti-\nmately death. Insulin underdoses lead to high levels of blood sugar. In the short \nterm, these high levels cause tiredness but are not very serious; in the longer term, \nhowever, they can lead to serious heart, kidney, and eye problems.\nHazards 4\u20139 in Figure 12.4 are not software related, but software nevertheless has a \nrole to play in hazard detection. The hardware monitoring software should monitor the \nsystem state and warn of potential problems. The warning will often allow the hazard to \nIdentified hazard\nHazard \nprobability\nAccident \nseverity\nEstimated \nrisk\nAcceptability\n1. \u0007\nInsulin overdose computation\nMedium\nHigh\nHigh\nIntolerable\n2. \u0007\nInsulin underdose \ncomputation\nMedium\nLow\nLow\nAcceptable\n3. \u0007\nFailure of hardware \nmonitoring system\nMedium\nMedium\nLow\nALARP\n4. Power failure\nHigh\nLow\nLow\nAcceptable\n5. Machine incorrectly fitted\nHigh\nHigh\nHigh\nIntolerable\n6. Machine breaks in patient\nLow\nHigh\nMedium\nALARP\n7. Machine causes infection\nMedium\nMedium\nMedium\nALARP\n8. Electrical interference\nLow\nHigh\nMedium\nALARP\n9. Allergic reaction\nLow\nLow\nLow\nAcceptable\nFigure 12.4\u2002 Risk \nclassification for the \ninsulin pump\n", "page": 349, "type": "text", "section": "Page 349"}
{"text": "\t\n12.2\u2002 \u25a0\u2002 Safety requirements\u2002 \u2002 349\nbe detected before it causes an accident. Examples of hazards that might be detected are \npower failure, which is detected by monitoring the battery, and incorrect fitting of the \nmachine, which may be detected by monitoring signals from the blood sugar sensor.\nThe monitoring software in the system is, of course, safety-related. Failure to detect a \nhazard could result in an accident. If the monitoring system fails but the hardware is work-\ning correctly, then this is not a serious failure. However, if the monitoring system fails and \nhardware failure cannot then be detected, then this could have more serious consequences.\nHazard assessment involves estimating the hazard probability and risk severity. \nThis is difficult as hazards and accidents are uncommon. Consequently, the engineers \ninvolved may not have direct experience of previous incidents or accidents. In estimat-\ning probabilities and accident severity, it makes sense to use relative terms such as \nprobable, unlikely, rare, high, medium, and low. Quantifying these terms is practically \nimpossible because not enough statistical data is available for most types of accident.\n\t\n12.2.3\t Hazard analysis\nHazard analysis is the process of discovering the root causes of hazards in a safety-critical \nsystem. Your aim is to find out what events or combination of events could cause a system \nfailure that results in a hazard. To do this, you can use either a top-down or a bottom-up \napproach. Deductive, top-down techniques, which are easier to use, start with the hazard \nand work from that to the possible system failure. Inductive, bottom-up techniques start \nwith a proposed system failure and identify what hazards might result from that failure.\nVarious techniques have been proposed as possible approaches to hazard decom-\nposition or analysis (Storey 1996). One of the most commonly used techniques is \nfault tree analysis, a top-down technique that was developed for the analysis of both \nhardware and software hazards (Leveson, Cha, and Shimeall 1991). This technique \nis fairly easy to understand without specialist domain knowledge.\nTo do a fault tree analysis, you start with the hazards that have been identified. \nFor each hazard, you then work backwards to discover the possible causes of that \nhazard. You put the hazard at the root of the tree and identify the system states that \ncan lead to that hazard. For each of these states, you then identify further system \nstates that can lead to them. You continue this decomposition until you reach the root \ncause(s) of the risk. Hazards that can only arise from a combination of root causes \nare usually less likely to lead to an accident than hazards with a single root cause.\nFigure 12.5 is a fault tree for the software-related hazards in the insulin delivery sys-\ntem that could lead to an incorrect dose of insulin being delivered. In this case, I have \nmerged insulin underdose and insulin overdose into a single hazard, namely, \u201cincorrect \ninsulin dose administered.\u201d This reduces the number of fault trees that are required. Of \ncourse, when you specify how the software should react to this hazard, you have to \ndistinguish between an insulin underdose and an insulin overdose. As I have said, they \nare not equally serious\u2014in the short term, an overdose is the more serious hazard.\nFrom Figure 12.5, you can see that:\n1.\t\nThree conditions could lead to the administration of an incorrect dose of insulin. \n(1) The level of blood sugar may have been incorrectly measured, so the insulin \nrequirement has been computed with an incorrect input. (2) The delivery system \n", "page": 350, "type": "text", "section": "Page 350"}
{"text": "350\u2002 \u2002 Chapter 12\u2002 \u25a0\u2002 Safety engineering\nmay not respond correctly to commands specifying the amount of insulin to be \ninjected. Alternatively, (3) the dose may be correctly computed, but it is deliv-\nered too early or too late.\n2.\t\nThe left branch of the fault tree, concerned with incorrect measurement of the \nblood sugar level, identifies how this might happen. This could occur either \nbecause the sensor that provides an input to calculate the sugar level has failed or \nbecause the calculation of the blood sugar level has been carried out incorrectly. \nThe sugar level is calculated from some measured parameter, such as the conduc-\ntivity of the skin. Incorrect computation can result from either an incorrect algo-\nrithm or an arithmetic error that results from the use of floating-point numbers.\n3.\t\nThe central branch of the tree is concerned with timing problems and concludes \nthat these can only result from system timer failure.\nIncorrect\nsugar level\nmeasured\nIncorrect\ninsulin dose\nadministered\nor\nCorrect dose\ndelivered at\nwrong time\nSensor\nfailure\nor\nSugar\ncomputation\nerror\nTimer\nfailure\nPump\nsignals\nincorrect\nor\nInsulin\ncomputation\nincorrect\nDelivery\nsystem\nfailure\nArithmetic\nerror\nor\nAlgorithm\nerror\nArithmetic\nerror\nor\nAlgorithm\nerror\nFigure 12.5\u2002 An \nexample of a \nfault tree \n", "page": 351, "type": "text", "section": "Page 351"}
{"text": "\t\n12.2\u2002 \u25a0\u2002 Safety requirements\u2002 \u2002 351\n4.\t\nThe right branch of the tree, concerned with delivery system failure, examines \npossible causes of this failure. These could result from an incorrect computation \nof the insulin requirement or from a failure to send the correct signals to the \npump that delivers the insulin. Again, an incorrect computation can result from \nalgorithm failure or arithmetic errors.\nFault trees are also used to identify potential hardware problems. Hardware fault \ntrees may provide insights into requirements for software to detect and, perhaps, cor-\nrect these problems. For example, insulin doses are not administered frequently\u2014no \nmore than five or six times per hour and sometimes less often than that. Therefore, \nprocessor capacity is available to run diagnostic and self-checking programs. \nHardware errors such as sensor, pump, or timer errors can be discovered and warn-\nings issued before they have a serious effect on the patient.\n\t\n12.2.4\t Risk reduction\nOnce potential risks and their root causes have been identified, you are then able to \nderive safety requirements that manage the risks and ensure that incidents or acci-\ndents do not occur. You can use three possible strategies:\n1.\t\nHazard avoidance, where a system is designed so that the hazard cannot occur.\n2.\t\nHazard detection and removal, where a system is designed so that hazards are \ndetected and neutralized before they result in an accident.\n3.\t\nDamage limitation, where a system is designed so that the consequences of an \naccident are minimized.\nNormally, designers of critical systems use a combination of these approaches. In a \nsafety-critical system, intolerable hazards may be handled by minimizing their probabil-\nity and adding a protection system (see Chapter 11) that provides a safety backup. For \nexample, in a chemical plant control system, the system will attempt to detect and avoid \nexcess pressure in the reactor. However, there may also be an independent protection \nsystem that monitors the pressure and opens a relief valve if high pressure is detected.\nIn the insulin delivery system, a safe state is a shutdown state where no insulin is \ninjected. Over a short period, this is not a threat to the diabetic\u2019s health. For the soft-\nware failures that could lead to an incorrect dose of insulin, the following \u201csolu-\ntions\u201d might be developed:\n1.\t\nArithmetic error This error may occur when an arithmetic computation causes a \nrepresentation failure. The specification should identify all possible arithmetic \nerrors that may occur and state that an exception handler must be included for \neach possible error. The specification should set out the action to be taken for \neach of these errors. The default safe action is to shut down the delivery system \nand activate a warning alarm.\n2.\t\nAlgorithmic error This is a more difficult situation as there is no clear program \nexception that must be handled. This type of error could be detected by comparing \n", "page": 352, "type": "text", "section": "Page 352"}
{"text": "352\u2002 \u2002 Chapter 12\u2002 \u25a0\u2002 Safety engineering\nthe required insulin dose computed with the previously delivered dose. If it is much \nhigher, this may mean that the amount has been computed incorrectly. The system \nmay also keep track of the dose sequence. After a number of above-average doses \nhave been delivered, a warning may be issued and further dosage limited.\nSome of the resulting safety requirements for the insulin pump software are shown \nin Figure 12.6. The requirements in Figure 12.6 are user requirements. Naturally, they \nwould be expressed in more detail in a more detailed system requirements specification.\n \n12.3 Safety engineering processes\nThe software processes used to develop safety-critical software are based on the \nprocesses used in software reliability engineering. In general, a great deal of care is \ntaken in developing a complete, and often very detailed, system specification. The \ndesign and implementation of the system usual follow a plan-based, waterfall model, \nwith reviews and checks at each stage in the process. Fault avoidance and fault \ndetection are the drivers of the process. For some types of system, such as aircraft \nsystems, fault-tolerant architectures, as I discussed in Chapter 11, may be used.\nReliability is a prerequisite for safety-critical systems. Because of the very high \ncosts and potentially tragic consequences of system failure, additional verification \nactivities may be used in safety-critical systems development. These activities may \ninclude developing formal models of a system, analyzing them to discover errors \nand inconsistencies, and using static analysis software tools that parse the software \nsource code to discover potential faults.\nSafe systems have to be reliable, but, as I have discussed, reliability is not enough. \nRequirements and verification errors and omissions may mean that reliable systems \nare unsafe. Therefore, safety-critical systems development processes should include \nFigure 12.6\u2002  \nExamples of safety \nrequirements\n\u0007\nSR1: The system shall not deliver a single dose of insulin that is greater than a specified \nmaximum dose for a system user.\nSR2: The system shall not deliver a daily cumulative dose of insulin that is greater than \na specified maximum daily dose for a system user.\nSR3: The system shall include a hardware diagnostic facility that shall be executed at \nleast four times per hour.\nSR4: The system shall include an exception handler for all of the exceptions that are \nidentified in Table 3.\nSR5: The audible alarm shall be sounded when any hardware or software anomaly is \ndiscovered and a diagnostic message as defined in Table 4 shall be displayed.\nSR6: In the event of an alarm, insulin delivery shall be suspended until the user has \nreset the system and cleared the alarm.\nNote: Tables 3 and 4 relate to tables that are included in the requirements document; \nthey are not shown here.\n", "page": 353, "type": "text", "section": "Page 353"}
{"text": "\t\n12.3\u2002 \u25a0\u2002 Safety engineering processes\u2002 \u2002 353\nsafety reviews, where engineers and system stakeholders examine the work done \nand explicitly look for potential issues that could affect the safety of the system.\nSome types of safety-critical systems are regulated, as I explained in Chapter 10. \nNational and international regulators require detailed evidence that the system is \nsafe. This evidence might include:\n1.\t\nThe specification of the system that has been developed and records of the \nchecks made on that specification.\n2.\t\nEvidence of the verification and validation processes that have been carried out \nand the results of the system verification and validation.\n3.\t\nEvidence that the organizations developing the system have defined and depend-\nable software processes that include safety assurance reviews. There must also \nbe records showing that these processes have been properly enacted.\nNot all safety-critical systems are regulated. For example, there is no regulator for \nautomobiles, although cars now have many embedded computer systems. The safety \nof car-based systems is the responsibility of the car manufacturer. However, because \nof the possibility of legal action in the event of an accident, developers of unregu-\nlated systems have to maintain the same detailed safety information. If a case is \nbrought against them, they have to be able to show that they have not been negligent \nin the development of the car\u2019s software.\nThe need for this extensive process and product documentation is another reason \nwhy agile processes cannot be used, without significant change, for safety-critical \nsystems development. Agile processes focus on the software itself and (rightly) \nargue that a great deal of process documentation is never actually used after it has \nbeen produced. However, where you have to keep records for legal or regulatory \nreasons, you must maintain documentation about both the processes used and the \nsystem itself.\nSafety-critical systems, like other types of system that have high dependability \nrequirements, need to be based on dependable processes (see Chapter 10). A \ndependable process will normally include activities such as requirements man-\nagement, change management and configuration control, system modeling, \nreviews and inspections, test planning, and test coverage analysis. When a system \nis safety-critical, there may be additional safety assurance and verification and \nanalyses processes.\n\t\n12.3.1\t Safety assurance processes\nSafety assurance is a set of activities that check that a system will operate safely. Specific \nsafety assurance activities should be included at all stages in the software development \nprocess. These activities record the safety analyses that have been carried out and the \nperson or persons responsible for these analyses. Safety assurance activities have to be \nthoroughly documented. This documentation may be part of the evidence that is used to \nconvince a regulator or system owner that a system will operate safely.\n", "page": 354, "type": "text", "section": "Page 354"}
{"text": "354\u2002 \u2002 Chapter 12\u2002 \u25a0\u2002 Safety engineering\nExamples of safety assurance activities are:\n1.\t\nHazard analysis and monitoring, where hazards are traced from preliminary \nhazard analysis through to testing and system validation.\n2.\t\nSafety reviews, which are used throughout the development process.\n3.\t\nSafety certification, where the safety of critical components is formally certi-\nfied. This involves a group external to the system development team examining \nthe available evidence and deciding whether or not a system or component \nshould be considered to be safe before it is made available for use.\nTo support these safety assurance processes, project safety engineers should be \nappointed who have explicit responsibility for the safety aspects of a system. These \nindividuals will be accountable if a safety-related system failure occurs. They must be \nable to demonstrate that the safety assurance activities have been properly carried out.\nSafety engineers work with quality managers to ensure that a detailed configura-\ntion management system is used to track all safety-related documentation and keep it \nin step with the associated technical documentation. There is little point in having \nstringent validation procedures if a failure of configuration management means that \nthe wrong system is delivered to the customer. Quality and configuration manage-\nment are covered in Chapters 24 and 25.\nHazard analysis is an essential part of safety-critical systems development. It \ninvolves identifying hazards, their probability of occurrence, and the probability of a \nhazard leading to an accident. If there is program code that checks for and handles \neach hazard, then you can argue that these hazards will not result in accidents. Where \nexternal certification is required before a system is used (e.g., in an aircraft), it is \nusually a condition of certification that this traceability can be demonstrated.\nThe central safety document that should be produced is the hazard register. This docu-\nment provides evidence of how identified hazards have been taken into account during \nsoftware development. This hazard register is used at each stage of the software develop-\nment process to document how that development stage has taken the hazards into account.\nA simplified example of a hazard register entry for the insulin delivery system is \nshown in Figure 12.7. This register documents the process of hazard analysis and \nshows design requirements that have been generated during this process. These \ndesign requirements are intended to ensure that the control system can never deliver \nan insulin overdose to a user of the insulin pump.\nIndividuals who have safety responsibilities should be explicitly identified in the \nhazard register. Personal identification is important for two reasons:\n1.\t\nWhen people are identified, they can be held accountable for their actions. They \nare likely to take more care because any problems can be traced back to their work.\n2.\t\nIn the event of an accident, there may be legal proceedings or an inquiry. It is \nimportant to be able to identify those responsible for safety assurance so that \nthey can defend their actions as part of the legal process.\n", "page": 355, "type": "text", "section": "Page 355"}
{"text": "\t\n12.3\u2002 \u25a0\u2002 Safety engineering processes\u2002 \u2002 355\nSafety reviews are reviews of the software specification, design, and source code \nwhose aim is to discover potentially hazardous conditions. These are not automated \nprocesses but involve people carefully checking for errors that have been made and \nfor assumptions or omissions that may affect the safety of a system. For example, in \nthe aircraft accident that I introduced earlier, a safety review might have questioned \nthe assumption that an aircraft is on the ground when there is weight on both wheels \nand the wheels are rotating.\nSafety reviews should be driven by the hazard register. For each of the identified \nhazards, a review team examines the system and judges whether or not it would cope \nwith that hazard in a safe way. Any doubts raised are flagged in the review team\u2019s \nreport and have to be addressed by the system development team. I discuss reviews of \ndifferent types in more detail in Chapter 24, which covers software \u00ad\nquality assurance.\nSoftware safety certification is used when external components are incorporated \ninto a safety-critical system. When all parts of a system have been locally developed, \ncomplete information about the development processes used can be maintained. \nHowever, it is not cost-effective to develop components that are readily available \nfrom other vendors. The problem for safety-critical systems development is that \nthese external components may have been developed to different standards than \nlocally developed components. Their safety is unknown.\nConsequently, it may be a requirement that all external components must be certified \nbefore they can be integrated with a system. The safety certification team, which is \nseparate from the development team, carries out extensive verification and validation of \nFigure 12.7\u2002  \nA simplified hazard \nregister entry\nHazard Register.\t\nPage 4: Printed 20.02.2012\nSystem: Insulin Pump System\t\nFile: InsulinPump/Safety/HazardLog \nSafety Engineer: James Brown\t\nLog version: 1/3\nIdentified Hazard\t\nInsulin overdose delivered to patient\nIdentified by\t\nJane Williams\nCriticality class\t\n1\nIdentified risk\t\nHigh\nFault tree identified\t\nYES\t\nDate\t\n24.01.11\t\nLocation\t\nHazard register, \n\t\n\t\n\t\n\t\n\t\nPage 5\nFault tree creators\t\nJane Williams and Bill Smith\nFault tree checked\t\nYES\t\nDate\t\n28.01.11\t\nChecker\t\nJames Brown\nSystem safety design requirements\n1. \u0007\nThe system shall include self-testing software that will test the sensor system, the \nclock, and the insulin delivery system.\n2. The self-checking software shall be executed once per minute.\n3. \u0007\nIn the event of the self-checking software discovering a fault in any of the system \ncomponents, an audible warning shall be issued and the pump display shall indi-\ncate the name of the component where the fault has been discovered. The deliv-\nery of insulin shall be suspended.\n4. \u0007\nThe system shall incorporate an override system that allows the system user to \nmodify the computed dose of insulin that is to be delivered by the system.\n5. \u0007\nThe amount of override shall be no greater than a pre-set value (maxOverride), \nwhich is set when the system is configured by medical staff.\n", "page": 356, "type": "text", "section": "Page 356"}
{"text": "356\u2002 \u2002 Chapter 12\u2002 \u25a0\u2002 Safety engineering\nthe components. If appropriate, they liaise with the component developers to check that \nthe developers have used dependable processes to create these components and to \nexamine the component source code. Once the safety certification team is satisfied that \na component meets its specification and does not have \u201chidden\u201d functionality, they may \nissue a certificate allowing that component to be used in safety-critical systems.\n\t\n12.3.2\t Formal verification\nFormal methods of software development, as I discussed in Chapter 10, rely on a \nformal model of the system that serves as a system specification. These formal \n\u00ad\nmethods are mainly concerned with mathematically analyzing the specification; \nwith transforming the specification to a more detailed, semantically equivalent rep-\nresentation; or with formally verifying that one representation of the system is \nsemantically equivalent to another representation.\nThe need for assurance in safety-critical systems has been one of the principal \ndrivers in the development of formal methods. Comprehensive system testing is \nextremely expensive and cannot be guaranteed to uncover all of the faults in a sys-\ntem. This is particularly true of systems that are distributed, so that system compo-\nnents are running concurrently. Several safety-critical railway systems were \ndeveloped using formal methods in the 1990s (Dehbonei and Mejia 1995; Behm \net al. 1999). Companies such as Airbus routinely use formal methods in their soft-\nware development for critical systems (Souyris et al. 2009).\nFormal methods may be used at different stages in the V & V process:\n1.\t\nA formal specification of the system may be developed and mathematically ana-\nlyzed for inconsistency. This technique is effective in discovering specification \nerrors and omissions. Model checking, discussed in the next section, is a par-\nticularly effective approach to specification analysis.\n2.\t\nYou can formally verify, using mathematical arguments, that the code of a soft-\nware system is consistent with its specification. This requires a formal specifi-\ncation. It is effective in discovering programming and some design errors.\nBecause of the wide semantic gap between a formal system specification and pro-\ngram code, it is difficult and expensive to prove that a separately developed program is \nLicensing of software engineers\nIn some areas of engineering, safety engineers must be licensed engineers. Inexperienced, poorly qualified engineers \nare not allowed to take responsibility for safety. In 30 states of the United States, there is some form of licensing for \nsoftware engineers involved in safety-related systems development. These states require that engineering involved \nin safety-critical software development should be licensed engineers, with a defined minimum level of qualifica-\ntions and experience. This is a controversial issue, and licensing is not required in many other countries.\nhttp://software-engineering-book.com/safety-licensing/\n", "page": 357, "type": "text", "section": "Page 357"}
{"text": "\t\n12.3\u2002 \u25a0\u2002 Safety engineering processes\u2002 \u2002 357\nconsistent with its specification. Work on program verification is now mostly based on \ntransformational development. In a transformational development process, a formal \nspecification is systematically transformed through a series of representations to pro-\ngram code. Software tools support the development of the transformations and help \nverify that corresponding representations of the system are consistent. The B method is \nprobably the most widely used formal transformational method (Abrial 2010). It has \nbeen used for the development of train control systems and avionics software.\nAdvocates of formal methods claim that the use of these methods leads to more \nreliable and safer systems. Formal verification demonstrates that the developed pro-\ngram meets its specification and that implementation errors will not compromise the \ndependability of the system. If you develop a formal model of concurrent systems \nusing a specification written in a language such as CSP (Schneider 1999), you can \ndiscover conditions that might result in deadlock in the final program, and you will \nbe able to address these problems. This is very difficult to do by testing alone.\nHowever, formal specification and proof do not guarantee that the software will \nbe safe in practical use:\n1.\t\nThe specification may not reflect the real requirements of users and other system \nstakeholders. As I discussed in Chapter 10, system system stakeholders rarely \nunderstand formal notations, so they cannot directly read the formal specification \nto find errors and omissions. This means that there it is likely that the formal \nspecification is not an accurate representation of the system requirements.\n2.\t\nThe proof may contain errors. Program proofs are large and complex, so, like \nlarge and complex programs, they usually contain errors.\n3.\t\nThe proof may make incorrect assumptions about the way that the system is \nused. If the system is not used as anticipated, then the system\u2019s behavior lies \noutside the scope of the proof.\nVerifying a nontrivial software system takes a great deal of time. It requires math-\nematical expertise and specialized software tools, such as theorem provers. It is an \nexpensive process, and, as the system size increases, the costs of formal verification \nincrease disproportionately.\nMany software engineers therefore think that formal verification is not \n\u00ad\ncost-effective. They believe that the same level of confidence in the system can be \nachieved more cheaply by using other validation techniques, such as inspections and \nsystem testing. However, companies such as Airbus that make use of formal verifi-\ncation claim that unit testing of components is not required, which leads to signifi-\ncant cost savings (Moy et al. 2013).\nI am convinced that that formal methods and formal verification have an \nimportant role to play in the development of critical software systems. Formal \nspecifications are very effective in discovering some types of specification prob-\nlems that may lead to system failure. Although formal verification remains \nimpractical for large systems, it can be used to verify critical safety and security \ncritical core components.\n", "page": 358, "type": "text", "section": "Page 358"}
{"text": "358\u2002 \u2002 Chapter 12\u2002 \u25a0\u2002 Safety engineering\n\t\n12.3.3\t Model checking\nFormally verifying programs using a deductive approach is difficult and expensive, \nbut alternative approaches to formal analysis have been developed that are based on a \nmore restricted notion of correctness. The most successful of these approaches is called \nmodel checking (Jhala and Majumdar 2009). Model checking involves creating a for-\nmal state model of a system and checking the correctness of that model using special-\nized software tools. The stages involved in model checking are shown in Figure 12.8.\nModel checking has been widely used to check hardware systems designs. It is \nincreasingly being used in critical software systems such as the control software in \nNASA\u2019s Mars exploration vehicles (Regan and Hamilton 2004; Holzmann 2014) \nand by Airbus in avionics software development (Bochot et al. 2009).\nMany different model-checking tools have been developed. SPIN was an early \nexample of a software model checker (Holzmann, 2003). More recent systems \ninclude SLAM from Microsoft (Ball, Levin, and Rajamani 2011) and PRISM \n(Kwiatkowska, Norman, and Parker 2011).\nThe models used by model-checking systems are extended finite-state models of \nthe software. Models are expressed in the language of whatever model-checking \nsystem is used\u2014for example, the SPIN model checker uses a language called \nPromela. A set of desirable system properties are identified and written in a formal \nnotation, usually based on temporal logic. For example, in the wilderness weather \nsystem, a property to be checked might be that the system will always reach the \n\u201ctransmitting\u201d state from the \u201crecording\u201d state.\nThe model checker then explores all paths through the model (i.e., all possible \nstate transitions), checking that the property holds for each path. If it does, then the \nmodel checker confirms that the model is correct with respect to that property. If it \ndoes not hold for a particular path, the model checker outputs a counterexample \nillustrating where the property is not true. Model checking is particularly useful in \nthe validation of concurrent systems, which are notoriously difficult to test because \nof their sensitivity to time. The checker can explore interleaved, concurrent transi-\ntions and discover potential problems.\nA key issue in model checking is the creation of the system model. If the model has to \nbe created manually (from a requirements or design document), it is an expensive pro-\ncess as model creation takes a great deal of time. In addition, there is the possibility that \nthe model created will not be an accurate model of the requirements or design. It is therefore \nModel\nbuilding\nRequirements,\ndesign or\nprogram\nProperty\nspecification\nExtended finite-\nstate model of\nsystem\nDesired system\nproperties\nModel\nchecker\nConfirmation or\ncounter-\nexamples\nFigure 12.8\u2002 Model \nchecking \n", "page": 359, "type": "text", "section": "Page 359"}
{"text": "\t\n12.3\u2002 \u25a0\u2002 Safety engineering processes\u2002 \u2002 359\nbest if the model can be created automatically from the program source code. Model \ncheckers are available that work directly from programs in Java, C, C++, and Ada.\nModel checking is computationally very expensive because it uses an exhaustive \napproach to check all paths through the system model. As the size of a system \nincreases, so too does the number of states, with a consequent increase in the number \nof paths to be checked. For large systems, therefore, model checking may be imprac-\ntical, due to the computer time required to run the checks. However, better algo-\nrithms are under development that can identify parts of the state that do not have to \nbe explored when checking a particular property. As these algorithms are incorpo-\nrated into model checkers, it will be increasingly possible to use model checking \nroutinely in large-scale critical systems development.\n\t\n12.3.4\t Static program analysis\nAutomated static analyzers are software tools that scan the source text of a program \nand detect possible faults and anomalies. They parse the program text and thus recog-\nnize the different types of statements in a program. They can then detect whether or not \nstatements are well formed, make inferences about the control flow in the program, \nand, in many cases, compute the set of all possible values for program data. They \n\u00ad\ncomplement the error-detection facilities provided by the language compiler, and they \ncan be used as part of the inspection process or as a separate V & V process activity.\nAutomated static analysis is faster and cheaper than detailed code reviews and is \nvery effective in discovering some types of program faults. However, it cannot dis-\ncover some classes of errors that could be identified in program inspection meetings.\nStatic analysis tools (Lopes, Vicente, and Silva 2009) work on the source code of \na system, and, for some types of analysis at least, no further inputs are required. This \nmeans that programmers do not need to learn specialized notations to write program \nspecifications, so the benefits of analysis can be immediately clear. This makes auto-\nmated static analysis easier to introduce into a development process than formal \nverification or model checking.\nThe intention of automatic static analysis is to draw a code reader\u2019s attention to \nanomalies in the program, such as variables that are used without initialization, vari-\nables that are unused, or data whose values could go out of range. Examples of the \nproblems that can be detected by static analysis are shown in Figure 12.9.\nOf course, the specific checks made by the static analyzer are programming-language-\nspecific and depend on what is and isn\u2019t allowed in the language. Anomalies are \noften a result of programming errors or omissions, so they highlight things that could \ngo wrong when the program is executed. However, these anomalies are not necessar-\nily program faults; they may be deliberate constructs introduced by the programmer, \nor the anomaly may have no adverse consequences.\nThree levels of checking may be implemented in static analyzers:\n1.\t\nCharacteristic error checking At this level, the static analyzer knows about com-\nmon errors that are made by programmers in languages such as Java or C. The \ntool analyzes the code looking for patterns that are characteristic of that problem \n", "page": 360, "type": "text", "section": "Page 360"}
{"text": "360\u2002 \u2002 Chapter 12\u2002 \u25a0\u2002 Safety engineering\nand highlights these to the programmer. Though relatively simple, analysis based \non common errors can be very cost-effective. Zheng and his collaborators (Zheng \net al. 2006) analyzed a large code base in C and C++. They discovered that 90% \nof the errors in the programs resulted from 10 types of characteristic error.\n2.\t\nUser-defined error checking In this approach, the users of the static analyzer \ndefine error patterns to be detected. These may relate to the application domain \nor may be based on knowledge of the specific system that is being developed. \nAn example of an error pattern is \u201cmaintain ordering\u201d; for example, method A \nmust always be called before method B. Over time, an organization can collect \ninformation about common bugs that occur in their programs and extend the \nstatic analysis tools with error patterns to highlight these errors.\n3.\t\nAssertion checking This is the most general and most powerful approach to \nstatic analysis. Developers include formal assertions (often written as stylized \ncomments) in their program that state relationships that must hold at that point \nin a program. For example, the program might include an assertion stating that \nthe value of some variable must lie in the range x..y. The analyzer symbolically \nexecutes the code and highlights statements where the assertion may not hold.\nStatic analysis is effective in finding errors in programs but, commonly, generates a \nlarge number of false positives. These are code sections where there are no errors but \nwhere the static analyzer\u2019s rules have detected a potential for error. The number of false \npositives can be reduced by adding more information to the program in the form of asser-\ntions, but this requires additional work by the developer of the code. Work has to be done \nin screening out these false positives before the code itself can be checked for errors.\nMany organizations now routinely use static analysis in their software develop-\nment processes. Microsoft introduced static analysis in the development of device \nFault class\nStatic analysis check\nData faults\nVariables used before initialization\nVariables declared but never used\nVariables assigned twice but never used between assignments\nPossible array bound violations\nUndeclared variables\nControl faults\nUnreachable code\nUnconditional branches into loops\nInput/output faults\nVariables output twice with no intervening assignment\nInterface faults\nParameter type mismatches\nParameter number mismatches\nNonusage of the results of functions\nUncalled functions and procedures\nStorage management faults\nUnassigned pointers\nPointer arithmetic\nMemory leaks\nFigure 12.9\u2002  \nAutomated static \nanalysis checks\n", "page": 361, "type": "text", "section": "Page 361"}
{"text": "\t\n12.4\u2002 \u25a0\u2002 Safety cases\u2002 \u2002 361\ndrivers where program failures can have a serious effect. They extended the approach \nacross a much wider range of their software to look for security problems as well as \nerrors that affect program reliability (Ball, Levin, and Rajamani 2011). Checking for \nwell-known problems, such as buffer overflow, is effective for improving security as \nattackers often base their attacks on those common vulnerabilities. Attacks may tar-\nget little-used code sections that may not have been thoroughly tested. Static analy-\nsis is a cost-effective way of finding these types of vulnerability.\n \n12.4 Safety cases\nAs I have discussed, many safety-critical, software-intensive systems are regulated. \nAn external authority has significant influence on their development and deployment. \nRegulators are government bodies whose job is to ensure that commercial companies \ndo not deploy systems that pose threats to public and environmental safety or the \nnational economy. The owners of safety-critical systems must convince regulators \nthat they have made the best possible efforts to ensure that their systems are safe. The \nregulator assesses the safety case for the system, which presents evidence and argu-\nments that normal operation of the system will not cause harm to a user.\nThis evidence is collected during the systems development process. It may \ninclude information about hazard analysis and mitigation, test results, static analy-\nses, information about the development processes used, records of review meetings, \nand so on. It is assembled and organized into a safety case, a detailed presentation of \nwhy the system owners and developers believe that a system is safe.\nA safety case is a set of documents that includes a description of the system to be \ncertified, information about the processes used to develop the system, and, critically, \nlogical arguments that demonstrate that the system is likely to be safe. More suc-\ncinctly, Bishop and Bloomfield (Bishop and Bloomfield 1998) define a safety case as:\nA documented body of evidence that provides a convincing and valid argument \nthat a system is adequately safe for a given application in a given environment\u2020.\nThe organization and contents of a safety case depend on the type of system that \nis to be certified and its context of operation. Figure 12.10 shows one possible struc-\nture for a safety case, but there are no universal industrial standards in this area. \nSafety case structures vary, depending on the industry and the maturity of the domain. \nFor example, nuclear safety cases have been required for many years. They are very \ncomprehensive and presented in a way that is familiar to nuclear engineers. However, \nsafety cases for medical devices have been introduced more recently. The case struc-\nture is more flexible, and the cases themselves are less detailed than nuclear cases.\nA safety case refers to a system as a whole, and, as part of that case, there may be \na subsidiary software safety case. When constructing a software safety case, you \nhave to relate software failures to wider system failures and demonstrate either that \n\u2020Bishop, P., and R. E. Bloomfield. 1998. \u201cA Methodology for Safety Case Development.\u201d In Proc. Safety-\nCritical Systems Symposium. Birmingham, UK: Springer. http://www.adelard.com/papers/sss98web.pdf\n", "page": 362, "type": "text", "section": "Page 362"}
{"text": "362\u2002 \u2002 Chapter 12\u2002 \u25a0\u2002 Safety engineering\nthese software failures will not occur or that they will not be propagated in such a \nway that dangerous system failures may occur.\nSafety cases are large and complex documents, and so they are very expensive to \nproduce and maintain. Because of these high costs, safety-critical system developers \nhave to take the requirements of the safety case into account in the development process:\n1.\t\nGraydon et al. (Graydon, Knight, and Strunk 2007) argue that the development \nof a safety case should be tightly integrated with system design and implemen-\ntation. This means that system design decisions may be influenced by the \nrequirements of the safety case. Design choices that may add significantly to the \ndifficulties and costs of case development can then be avoided.\n2.\t Regulators have their own views on what is acceptable and unacceptable in a \nsafety case. It therefore makes sense for a development team to work with them \nfrom early in the development to establish what the regulator expects from the \nsystem safety case.\nThe development of safety cases is expensive because of the costs of the record \nkeeping required as well as the costs of comprehensive system validation and safety \nassurance processes. System changes and rework also add to the costs of a safety \nChapter\nDescription\nSystem description\nAn overview of the system and a description of its critical components.\nSafety \nrequirements\nThe safety requirements taken from the system requirements specification. Details of \nother relevant system requirements may also be included.\nHazard and risk \nanalysis\nDocuments describing the hazards and risks that have been identified and the \nmeasures taken to reduce risk. Hazard analyses and hazard logs.\nDesign analysis\nA set of structured arguments (see Section 12.4.1) that justify why the design is safe.\nVerification and \nvalidation\nA description of the V & V procedures used and, where appropriate, the test plans for \nthe system. Summaries of the test results showing defects that have been detected \nand corrected. If formal methods have been used, a formal system specification and \nany analyses of that specification. Records of static analyses of the source code.\nReview reports\nRecords of all design and safety reviews.\nTeam \ncompetences\nEvidence of the competence of all of the team involved in safety-related systems \ndevelopment and validation.\nProcess QA\nRecords of the quality assurance processes (see Chapter 24) carried out during system \ndevelopment.\nChange \nmanagement \nprocesses\nRecords of all changes proposed, actions taken, and, where appropriate, justification of \nthe safety of these changes. Information about configuration management procedures \nand configuration management logs.\nAssociated safety \ncases\nReferences to other safety cases that may impact the safety case.\nFigure 12.10\u2002 Possible \ncontents of a software \nsafety case\n", "page": 363, "type": "text", "section": "Page 363"}
{"text": "\t\n12.4\u2002 \u25a0\u2002 Safety cases\u2002 \u2002 363\ncase. When \u00ad\nsoftware or hardware changes are made to a system, a large part of the \nsafety case may have to be rewritten to demonstrate that the system safety has not \nbeen affected by the change.\n\t\n12.4.1\t Structured arguments\nThe decision on whether or not a system is operationally safe should be based on \nlogical arguments. These arguments should demonstrate that the evidence presented \nsupports the claims about a system\u2019s security and dependability. These claims may \nbe absolute (event X will or will not happen) or probabilistic (the probability of \noccurrence of event Y is 0.n). An argument links the evidence and the claim. As \nshown in Figure 12.11, an argument is a relationship between what is thought to be \nthe case (the claim) and a body of evidence that has been collected. The argument \nessentially explains why the claim, which is an assertion about system security or \ndependability, can be inferred from the available evidence.\nArguments in a safety case are usually presented as \u201cclaim based\u201d arguments. \nSome claim about system safety is made, and, on the basis of available evidence, \nan argument is presented as to why that claim holds. For example, the following \nargument might be used to justify a claim that computations carried out by the con-\ntrol software in an insulin pump will not lead to an overdose of insulin being deliv-\nered. Of course, this is a very simplified presentation of the argument. In a real \nsafety case, more detailed references to the evidence would be presented.\nClaim: The maximum single dose computed by the insulin pump will not \nexceed maxDose, where maxDose has been assessed as a safe single dose for a \nparticular patient.\nEvidence: Safety argument for insulin pump software control program (covered \nlater in this section).\nEvidence: Test datasets for the insulin pump. In 400 tests, which provided com-\nplete code coverage, the value of the dose of insulin to be delivered, currentDose, \nnever exceeded maxDose.\nEVIDENCE\nEVIDENCE\nEVIDENCE\n<< ARGUMENT >>\nCLAIM\nSupports\nSupports\nSupports\nJustifies\nFigure 12.11\u2002 Structured \narguments \n", "page": 364, "type": "text", "section": "Page 364"}
{"text": "364\u2002 \u2002 Chapter 12\u2002 \u25a0\u2002 Safety engineering\nEvidence: A static analysis report for the insulin pump control program. The static \nanalysis of the control software revealed no anomalies that affected the value of \ncurrentDose, the program variable that holds the dose of insulin to be delivered.\nArgument: The evidence presented demonstrates that the maximum dose of insu-\nlin that can be computed is equal to maxDose.\nIt is therefore reasonable to assume, with a high level of confidence, that the evi-\ndence justifies the claim that the insulin pump will not compute a dose of insulin \nto be delivered that exceeds the maximum single safe dose.\nThe evidence presented is both redundant and diverse. The software is checked using \nseveral different mechanisms with significant overlap between them. As I discussed \nin Chapter 10, using redundant and diverse processes increases confidence. If omis-\nsions and mistakes are not detected by one validation process, there is a good chance \nthat they will be found by one of the other processes.\nThere will normally be many claims about the safety of a system, with the validity of \none claim often depending on whether or not other claims are valid. Therefore, claims may \nbe organized in a hierarchy. Figure 12.12 shows part of this claim hierarchy for the insulin \npump. To demonstrate that a high-level claim is valid, you first have to work through the \narguments for lower-level claims. If you can show that each of these lower-level claims is \njustified, then you may be able to infer that the higher-level claims are justified.\n\t\n12.4.2\t Software safety arguments\nA general assumption that underlies work in system safety is that the number of sys-\ntem faults that can lead to safety hazards is significantly less than the total number of \nfaults that may exist in the system. Safety assurance can therefore concentrate on \nThe maximum single\ndose computed by\nthe pump software\nwill not exceed\nmaxDose\nmaxDose is set up\ncorrectly when the\npump is configured\nmaxDose is a safe\ndose for the user of\nthe insulin pump\nThe insulin pump will\nnot deliver a single\ndose of insulin that is\nunsafe\nIn normal\noperation, the\nmaximum dose\ncomputed will not\nexceed maxDose\nIf the software fails,\nthe maximum dose\ncomputed will not\nexceed maxDose\nFigure 12.12\u2002 A safety \nclaim hierarchy for the \ninsulin pump \n", "page": 365, "type": "text", "section": "Page 365"}
{"text": "\t\n12.4\u2002 \u25a0\u2002 Safety cases\u2002 \u2002 365\nthese faults, which have hazard potential. If it can be demonstrated that these faults \ncannot occur or, if they occur, that the associated hazard will not result in an acci-\ndent, then the system is safe. This is the basis of software safety arguments.\nSoftware safety arguments are a type of structured argument which demonstrates \nthat a program meets its safety obligations. In a safety argument, it is not necessary to \nprove that the program works as intended. It is only necessary to show that program \nexecution cannot result in it reaching a potentially unsafe state. Safety arguments are \ntherefore cheaper to make than correctness arguments. You don\u2019t have to consider all \nprogram states\u2014you can simply concentrate on states that could lead to a hazard.\nSafety arguments demonstrate that, assuming normal execution conditions, a pro-\ngram should be safe. They are usually based on contradiction, where you assume \nthat the system is unsafe and then show that it is impossible to reach an unsafe state. \nThe steps involved in creating a safety argument are:\n1.\t\nYou start by assuming that an unsafe state, which has been identified by the \nsystem hazard analysis, can be reached by executing the program.\n2.\t\nYou write a predicate (a logical expression) that defines this unsafe state.\n3.\t\nYou then systematically analyze a system model or the program and show that, \nfor all program paths leading to that state, the terminating condition of these paths, \nalso defined as a predicate, contradicts the unsafe state predicate. If this is the \ncase, you may then claim that the initial assumption of an unsafe state is incorrect.\n4.\t\nWhen you have repeated this analysis for all identified hazards, then you have \nstrong evidence that the system is safe.\nSafety arguments can be applied at different levels, from requirements through \ndesign models to code. At the requirements level, you are trying to demonstrate that \nthere are no missing safety requirements and that the requirements do not make invalid \nassumptions about the system. At the design level, you might analyze a state model of \nthe system to find unsafe states. At the code level, you consider all of the paths through \nthe safety-critical code to show that the execution of all paths leads to a contradiction.\nAs an example, consider the code outlined in Figure 12.13, which is a simpli-\nfied description of part of the implementation of the insulin delivery system. The \ncode computes the dose of insulin to be delivered and then applies some safety \nchecks that this is not an overdose for that patient. Developing a safety argument \nfor this code involves demonstrating that the dose of insulin administered is never \ngreater than the maximum safe level for a single dose. This dose is established for \neach individual diabetic user in discussions with their medical advisors.\nTo demonstrate safety, you do not have to prove that the system delivers the \u201ccor-\nrect\u201d dose, but merely that it never delivers an overdose to the patient. You work on \nthe assumption that maxDose is the safe level for that system user.\nTo construct the safety argument, you identify the predicate that defines the unsafe \nstate, which is that currentDose > maxDose. You then demonstrate that all program \npaths lead to a contradiction of this unsafe assertion. If this is the case, the unsafe \ncondition cannot be true. If you can prove a contradiction, you can be confident that \n", "page": 366, "type": "text", "section": "Page 366"}
{"text": "366\u2002 \u2002 Chapter 12\u2002 \u25a0\u2002 Safety engineering\nthe program will not compute an unsafe dose of insulin. You can structure and present \nthe safety arguments graphically as shown in Figure 12.14.\nThe safety argument shown in Figure 12.14 presents three possible program paths \nthat lead to the call to the administerInsulin method. You have to show that the \namount of insulin delivered never exceeds maxDose. All possible program paths to \nadministerInsulin are considered:\n1.\t\nNeither branch of if-statement 2 is executed. This can only happen if current-\nDose is outside of the range minimumDose..maxDose. The postcondition predi-\ncate is therefore:\ncurrentDose >= minimumDose and currentDose <= maxDose\n2.\t\nThe then-branch of if-statement 2 is executed. In this case, the assignment set-\nting currentDose to zero is executed. Therefore, its postcondition predicate is \ncurrentDose = 0.\n3.\t\nThe else-if-branch of if-statement 2 is executed. In this case, the assignment set-\nting currentDose to maxDose is executed. Therefore, after this statement has \nbeen executed, we know that the postcondition is currentDose = maxDose.\nIn all three cases, the postcondition predicates contradict the unsafe precondition \nthat currentDose > maxDose. As both cannot be true, we can claim that our initial \nassumption was incorrect, and so the computation is safe.\nTo construct a structured argument that a program does not make an unsafe computa-\ntion, you first identify all possible paths through the code that could lead to a potentially \n\u2014 The insulin dose to be delivered is a function of\n\u2014 blood sugar level, the previous dose delivered and\n\u2014 the time of delivery of the previous dose\ncurrentDose = computeInsulin () ;\n// Safety check\u2014adjust currentDose if necessary.\n// if statement 1\nif (previousDose == 0)\n{\n\u2003 \u2003 if (currentDose > maxDose/2)\n\u2003 \u2003 \u2003 \u2002currentDose = maxDose/2 ;\n}\nelse\n\u2003 \u2003 if (currentDose > (previousDose * 2) )\n\u2003 \u2003 \u2003 \u2002\u2009\ncurrentDose = previousDose * 2 ;\n// if statement 2\nif ( currentDose < minimumDose )\n\u2003  \u2009\ncurrentDose = 0 ;\nelse if ( currentDose > maxDose )\n\u2003  \u2009\ncurrentDose = maxDose ;\nadministerInsulin (currentDose) ;\nFigure 12.13\u2002 Insulin \ndose computation with \nsafety checks\n", "page": 367, "type": "text", "section": "Page 367"}
{"text": "\t\n12.4\u2002 \u25a0\u2002 Safety cases\u2002 \u2002 367\nunsafe assignment. You work backwards from the unsafe state and consider the last \nassignment to all of the state variables on each path leading to this unsafe state. If you \ncan show that none of the values of these variables is unsafe, then you have shown that \nyour initial assumption (that the computation is unsafe) is incorrect.\nWorking backwards is important because it means that you can ignore all inter-\nmediate states apart from the final states that lead to the exit condition for the code. \nThe previous values don\u2019t matter to the safety of the system. In this example, all you \nneed be concerned with is the set of possible values of currentDose immediately \nbefore the administerInsulin method is executed. You can ignore computations, such \nas if-statement 1 in Figure 12.13 in the safety argument because their results are \noverwritten in later program statements.\ncurrentDose = 0\ncurrentDose = 0\nif statement 2\nthen branch\nexecuted\ncurrentDose =\nmaxDose\ncurrentDose =\nmaxDose\nif statement 2\nelse branch\nexecuted\nif statement 2\nnot executed\ncurrentDose >= minimumDose and\ncurrentDose <= maxDose\nor\ncurrentDose >\nmaxDose\nadministerInsulin\nContradiction\nContradiction\nContradiction\nPrecondition\nfor unsafe state\nOverdose\nadministered\nassign\nassign\nFigure 12.14\u2002 Informal \nsafety argument based \non demonstrating \ncontradictions \n", "page": 368, "type": "text", "section": "Page 368"}
{"text": "368\u2002 \u2002 Chapter 12\u2002 \u25a0\u2002 Safety engineering\nKey Points\n\u25a0\t Safety-critical systems are systems whose failure can lead to human injury or death.\n\u25a0\t A hazard-driven approach may be used to understand the safety requirements for safety-critical systems. \nYou identify potential hazards and decompose them (using methods such as fault tree analysis) to \ndiscover their root causes. You then specify requirements to avoid or recover from these problems.\n\u25a0\t It is important to have a well-defined, certified process for safety-critical systems development. \nThe process should include the identification and monitoring of potential hazards.\n\u25a0\t Static analysis is an approach to V & V that examines the source code (or other representation) \nof a system, looking for errors and anomalies. It allows all parts of a program to be checked, not \njust those parts that are exercised by system tests.\n\u25a0\t Model checking is a formal approach to static analysis that exhaustively checks all states in a \n\u00ad\nsystem for potential errors.\n\u25a0\t Safety and dependability cases collect all of the evidence that demonstrates a system is safe \nand dependable. Safety cases are required when an external regulator must certify the system \nbefore it is used.\nFurther Reading\nSafeware: System Safety and Computers. Although now 20 years old, this book still offers the best \nand most thorough coverage of safety-critical systems. It is particularly strong in its description of \nhazard analysis and the derivation of requirements from it. (N. Leveson, Addison-Wesley, 1995).\n\u201cSafety-Critical Software.\u201d A special edition of IEEE Software magazine that focuses on safety-critical \nsystems. It includes papers on model-based development of safety-critical systems, model checking \nand formal methods. (IEEE Software, 30 (3), May/June 2013).\n\u201cConstructing Safety Assurance Cases for Medical Devices.\u201d This short paper gives a practical example \nof how a safety case can be created for an analgesic pump. (A. Ray and R. Cleaveland, Proc. Workshop \non Assurance Cases for Software-Intensive Systems, San Francisco, 2013) http://dx.doi.org/10.1109/\nASSURE.2013.6614270\nWebsite\nPowerPoint slides for this chapter:\nwww.pearsonglobaleditions.com/Sommerville\nLinks to supporting videos:\nhttp://software-engineering-book.com/videos/reliability-and-safety/\n368\u2002 \u2002 Chapter 12\u2002 \u25a0\u2002 Safety engineering\n", "page": 369, "type": "text", "section": "Page 369"}
{"text": "\t\n12.4\u2002 \u25a0\u2002 Safety cases\u2002 \u2002 369\nExercises\n12.1.\t Identify six consumer products that are likely to be controlled by safety-critical software \u00ad\nsystems.\n12.2.\t A software system is to be deployed for a company that has extremely high safety standards \nand allows for almost no risks, not even minor injuries. How will this affect the look of the risk \ntriangle in Figure 12.3?\n12.3.\t In the insulin pump system, the user has to change the needle and insulin supply at regular \nintervals and may also change the maximum single dose and the maximum daily dose that \nmay be administered. Suggest three user errors that might occur and propose safety require-\nments that would avoid these errors resulting in an accident.\n12.4.\t A safety-critical software system for managing roller coasters controls two main components:\n\u25a0\u2003 \u0007\nThe lock and release of the roller coaster harness which is supposed to keep riders in place \nas the coaster performs sharp and sudden moves. The roller coaster could not move with \nany unlocked harnesses.\n\u25a0\u2003 \u0007\nThe minimum and maximum speeds of the roller coaster as it moves along the various segments \nof the ride to prevent derailing, given the number of people riding the roller coaster.\nIdentify three hazards that may arise in this system. For each hazard, suggest a \ndefensive requirement that will reduce the probability that these hazards will result in \nan accident. Explain why your suggested defense is likely to reduce the risk associated \nwith the hazard.\n12.5.\t A train protection system automatically applies the brakes of a train if the speed limit for a \nsegment of track is exceeded, or if the train enters a track segment that is currently signaled \nwith a red light (i.e., the segment should not be entered). There are two critical-safety \n\u00ad\nrequirements for this train protection system:\nThe train shall not enter a segment of track that is signaled with a red light.\nThe train shall not exceed the specified speed limit for a section of track.\nAssuming that the signal status and the speed limit for the track segment are transmitted to \non-board software on the train before it enters the track segment, propose five possible \nfunctional system requirements for the onboard software that may be generated from the \nsystem safety requirements.\n12.6.\tExplain when it may be cost-effective to use formal specification and verification in the \n\u00ad\ndevelopment of safety-critical software systems. Why do you think that some critical systems \nengineers are against the use of formal methods?\n12.7.\t Explain why using model checking is sometimes a more cost-effective approach to verification \nthan verifying a program\u2019s correctness against a formal specification.\n12.8.\t List four types of systems that may require software safety cases, explaining why safety cases \nare required.\n12.9.\tThe door lock control mechanism in a nuclear waste storage facility is designed for safe \noperation. It ensures that entry to the storeroom is only permitted when radiation shields are \n\t\nChapter 12\u2002 \u25a0\u2002 Exercises\u2002 \u2002 369\n", "page": 370, "type": "text", "section": "Page 370"}
{"text": "370\u2002 \u2002 Chapter 12\u2002 \u25a0\u2002 Safety engineering\nin place or when the radiation level in the room falls below some given value (dangerLevel). \nSo:\n(i)\t\n\u0007\nIf remotely controlled radiation shields are in place within a room, an authorized \noperator may open the door.\n(ii)\t\n\u0007\nIf the radiation level in a room is below a specified value, an authorized operator may \nopen the door.\n(iii)\t An authorized operator is identified by the input of an authorized door entry code.\nThe code shown in Figure 12.15 controls the door-locking mechanism. Note that the safe state \nis that entry should not be permitted. Using the approach discussed in this chapter, develop a \nsafety argument for this code. Use the line numbers to refer to specific statements. If you find \nthat the code is unsafe, suggest how it should be modified to make it safe.\n12.10.\t Should software engineers working on the specification and development of safety-related \nsystems be professionally certified or licensed in some way? Explain your reasoning.\n1\t\nentryCode = lock.getEntryCode () ;\n2\t\nif (entryCode == lock.authorizedCode)\n3\t\n{\n4\t\n\t\nshieldStatus = Shield.getStatus ();\n5\t\n\t\nradiationLevel = RadSensor.get ();\n6\t\n\t\nif (radiationLevel < dangerLevel)\n7\t\n\t\n\t\nstate = safe;\n8\t\n\t\nelse\n9\t\n\t\n\t\nstate = unsafe;\n10\t\n\t\nif (shieldStatus == Shield.inPlace() )\n11\t\n\t\n\t\nstate = safe;\n12\t\n\t\nif (state == safe)\n13\t\n\t\n\t\n{\n14\t\n\t\n\t\n\t\nDoor.locked = false ;\n15\t\n\t\n\t\n\t\nDoor.unlock ();\n16\t\n\t\n\t\n}\n17\t\n\t\nelse\n18\t\n\t\n{\n19\t\n\t\n\t\nDoor.lock ( );\n20\t\n\t\n\t\nDoor.locked := true ;\n21\t\n\t\n}\n22\t\n}\nFigure 12.15\u2002 Door \nentry code\nReferences\nAbrial, J. R. 2010. Modeling in Event-B: System and Software Engineering. Cambridge, UK: Cam-\nbridge University Press.\nBall, T., V. Levin, and S. K. Rajamani. 2011. \u201cA Decade of Software Model Checking with SLAM.\u201d \nCommunications of the ACM 54 (7) (July 1): 68. doi:10.1145/1965724.1965743.\n370\u2002 \u2002 Chapter 12\u2002 \u25a0\u2002 Safety engineering\n", "page": 371, "type": "text", "section": "Page 371"}
{"text": "Behm, P., P. Benoit, A. Faivre, and J-M. Meynadier. 1999. \u201cMeteor: A Successful Application of B \nin\u00a0a\u00a0Large Project.\u201d In Formal Methods\u201999, 369\u2013387. Berlin: Springer-Verlag. doi:10.1007/ \n3-540-48119-2_22.\nBishop, P., and R. E. Bloomfield. 1998. \u201cA Methodology for Safety Case Development.\u201d In Proc. \nSafety-Critical Systems Symposium. Birmingham, UK: Springer. http://www.adelard.com/papers/\nsss98web.pdf\nBochot, T., P. Virelizier, H. Waeselynck, and V. Wiels. 2009. \u201cModel Checking Flight Control \n\u00ad\nSystems: The Airbus Experience.\u201d In Proc. 31st International Conf. on Software Engineering, \n\u00ad\nCompanion \u00ad\nVolume, 18\u201327. Leipzig: IEEE Computer Society Press. doi:10.1109/ICSE-COMPANION. \n2009.5070960.\nDehbonei, B., and F. Mejia. 1995. \u201cFormal Development of Safety-Critical Software Systems in Railway \nSignalling.\u201d In Applications of Formal Methods, edited by M. Hinchey and J. P. Bowen, 227\u2013252. \n\u00ad\nLondon: Prentice-Hall.\nGraydon, P. J., J. C. Knight, and E. A. Strunk. 2007. \u201cAssurance Based Development of Critical Sys-\ntems.\u201d In Proc. 37th Annual IEEE Conf. on Dependable Systems and Networks, 347\u2013357. Edinburgh, \nScotland. doi:10.1109/DSN.2007.17.\nHolzmann, G. J. 2014. \u201cMars Code.\u201d Comm ACM 57 (2): 64\u201373. doi:10.1145/2560217.2560218.\nJhala, R., and R. Majumdar. 2009. \u201cSoftware Model Checking.\u201d Computing Surveys 41 (4). \ndoi:10.1145/1592434.1592438.\nKwiatkowska, M., G. Norman, and D. Parker. 2011. \u201cPRISM 4.0: Verification of Probabilistic Real-\nTime Systems.\u201d In Proc. 23rd Int. Conf. on Computer Aided Verification, 585\u2013591. Snowbird, \u00ad\n \nUT: Springer-Verlag. doi:10.1007/978-3-642-22110-1_47.\nLeveson, N. G., S. S. Cha, and T. J. Shimeall. 1991. \u201cSafety Verification of Ada Programs Using \n\u00ad\nSoftware Fault Trees.\u201d IEEE Software 8 (4): 48\u201359. doi:10.1109/52.300036.\nLopes, R., D. Vicente, and N. Silva. 2009. \u201cStatic Analysis Tools, a Practical Approach for Safety-\u00ad\nCritical Software Verification.\u201d In Proceedings of DASIA 2009 Data Systems in Aerospace. \n\u00ad\nNoordwijk, Netherlands: European Space Agency.\nLutz, R. R. 1993. \u201cAnalysing Software Requirements Errors in Safety-Critical Embedded Systems.\u201d \nIn\u00a0RE\u201993, 126\u2013133. San Diego, CA: IEEE. doi:0.1109/ISRE.1993.324825.\nMoy, Y., E. Ledinot, H. Delseny, V. Wiels, and B. Monate. 2013. \u201cTesting or Formal Verification: \n\u00ad\nDO-178C Alternatives and Industrial Experience.\u201d IEEE Software 30 (3) (May 1): 50\u201357. doi:10.1109/\nMS.2013.43.\nPerrow, C. 1984. Normal Accidents: Living with High-Risk Technology. New York: Basic Books.\nRegan, P., and S. Hamilton. 2004. \u201cNASA\u2019s Mission Reliable.\u201d IEEE Computer 37 (1): 59\u201368. \ndoi:10.1109/MC.2004.1260727.\nSchneider, S. 1999. Concurrent and Real-Time Systems: The CSP Approach. Chichester, UK: John \nWiley & Sons.\n\t\nChapter 12\u2002 \u25a0\u2002 References\u2002 \u2002 371\n", "page": 372, "type": "text", "section": "Page 372"}
{"text": "372\u2002 \u2002 Chapter 12\u2002 \u25a0\u2002 Safety engineering\nSouyris, J., V. Weils, D. Delmas, and H. Delseny. 2009. \u201cFormal Verification of Avionics Software \nProducts.\u201d In Formal Methods\u201909: Proceedings of the 2nd World Congress on Formal Methods, \n\u00ad\n532\u2013546. Springer-Verlag. doi:10.1007/978-3-642-05089-3_34.\nStorey, N. 1996. Safety-Critical Computer Systems. Harlow, UK: Addison-Wesley.\nVeras, P. C., E. Villani, A. M. Ambrosio, N. Silva, M. Vieira, and H. Madeira. 2010. \u201cErrors in Space \nSoftware Requirements: A Field Study and Application Scenarios.\u201d In 21st Int. Symp. on Software \nReliability Engineering. San Jose, CA. doi:10.1109/ISSRE.2010.37.\nZheng, J., L. Williams, N. Nagappan, W. Snipes, J. P. Hudepohl, and M. A. Vouk. 2006. \u201cOn the Value \nof Static Analysis for Fault Detection in Software.\u201d IEEE Trans. on Software Eng. 32 (4): 240\u2013253. \ndoi:10.1109/TSE.2006.38.\n372\u2002 \u2002 Chapter 12\u2002 \u25a0\u2002 Safety engineering\n", "page": 373, "type": "text", "section": "Page 373"}
{"text": "Security engineering\n13 \nObjectives\nThe objective of this chapter is to introduce security issues that you \nshould consider when you are developing application systems. When you \nhave read this chapter, you will:\n\u25a0\t understand the importance of security engineering and the difference \nbetween application security and infrastructure security;\n\u25a0\t know how a risk-based approach can be used to derive security \nrequirements and analyze system designs;\n\u25a0\t know of software architectural patterns and design guidelines for \nsecure systems engineering;\n\u25a0\t understand why security testing and assurance is difficult and \nexpensive.\nContents\n13.1\t Security and dependability\n13.2\t Security and organizations\n13.3\t Security requirements\n13.4\t Secure systems design\n13.5\t Security testing and assurance\n", "page": 374, "type": "text", "section": "Page 374"}
{"text": "374\u2002 \u2002 Chapter 13\u2002 \u25a0\u2002 Security engineering\nThe widespread adoption of the Internet in the 1990s introduced a new challenge for \nsoftware engineers\u2014designing and implementing systems that were secure. As more \nand more systems were connected to the Internet, a variety of different external attacks \nwere devised to threaten these systems. The problems of producing \u00ad\ndependable systems \nwere hugely increased. Systems engineers had to consider threats from \u00ad\nmalicious and \ntechnically skilled attackers as well as problems resulting from \u00ad\naccidental mistakes in \nthe development process.\nIt is now essential to design systems to withstand external attacks and to recover \nfrom such attacks. Without security precautions, attackers will inevitably \u00ad\ncompromise \na networked system. They may misuse the system hardware, steal confidential data, \nor disrupt the services offered by the system.\nYou have to take three security dimensions into account in secure systems \u00ad\nengineering:\n1.\t\nConfidentiality Information in a system may be disclosed or made accessible to \npeople or programs that are not authorized to have access to that information. \nFor example, the theft of credit card data from an e-commerce system is a \n\u00ad\nconfidentiality problem.\n2.\t\nIntegrity Information in a system may be damaged or corrupted, making it \n\u00ad\nunusual or unreliable. For example, a worm that deletes data in a system is an \nintegrity problem.\n3.\t\nAvailability Access to a system or its data that is normally available may not be \npossible. A denial-of-service attack that overloads a server is an example of a \nsituation where the system availability is compromised.\nThese dimensions are closely related. If an attack makes the system unavailable, \nthen you will not be able to update information that changes with time. This means \nthat the integrity of the system may be compromised. If an attack succeeds and the \nintegrity of the system is compromised, then it may have to be taken down to repair \nthe problem. Therefore, the availability of the system is reduced.\nFrom an organizational perspective, security has to be considered at three levels:\n1.\t\nInfrastructure security, which is concerned with maintaining the security of all \nsystems and networks that provide an infrastructure and a set of shared services \nto the organization.\n2.\t\nApplication security, which is concerned with the security of individual \n\u00ad\napplication systems or related groups of systems.\n3.\t\nOperational security, which is concerned with the secure operation and use of \nthe organization\u2019s systems.\nFigure 13.1 is a diagram of an application system stack that shows how an \n\u00ad\napplication system relies on an infrastructure of other systems in its operation. The \nlower levels of the infrastructure are hardware, but the software infrastructure for \napplication systems may include:\n", "page": 375, "type": "text", "section": "Page 375"}
{"text": "\t\nChapter 13\u2002 \u25a0\u2002 Security engineering\u2002 \u2002 375\n\u25a0\t an operating system platform, such as Linux or Windows;\n\u25a0\t other generic applications that run on that system, such as web browsers and \nemail clients;\n\u25a0\t a database management system;\n\u25a0\t middleware that supports distributed computing and database access; and\n\u25a0\t libraries of reusable components that are used by the application software.\nNetwork systems are software controlled, and networks may be subject to \u00ad\nsecurity \nthreats where an attacker intercepts and reads or changes network packets. However, \nthis requires specialized equipment, so the majority of security attacks are on the \nsoftware infrastructure of systems. Attackers focus on software infrastructures \nbecause infrastructure components, such as web browsers, are universally available. \nAttackers can probe these systems for weaknesses and share information about \n\u00ad\nvulnerabilities that they have discovered. As many people use the same software, \nattacks have wide applicability.\nInfrastructure security is primarily a system management problem, where system \nmanagers configure the infrastructure to resist attacks. System security management \nincludes a range of activities such as user and permission management, system \n\u00ad\nsoftware deployment and maintenance, and attack monitoring, detection, and \u00ad\nrecovery:\n1.\t\nUser and permission management involves adding and removing users from the \nsystem, ensuring that appropriate user authentication mechanisms are in place, \nand setting up the permissions in the system so that users only have access to the \nresources they need.\n2.\t\nSystem software deployment and maintenance involves installing system \u00ad\nsoftware \nand middleware and configuring these properly so that security \u00ad\nvulnerabilities are \navoided. It also involves updating this software regularly with new versions or \npatches, which repair security problems that have been discovered.\nOperating System\nGeneric, shared applications (browsers, email, etc.)\nDatabase management\nMiddleware\nReusable components and libraries\nApplication\nNetwork\nComputer hardware\nFigure 13.1\u2002 System \nlayers where security \nmay be compromised \n", "page": 376, "type": "text", "section": "Page 376"}
{"text": "376\u2002 \u2002 Chapter 13\u2002 \u25a0\u2002 Security engineering\n3.\t\nAttack monitoring, detection, and recovery involves monitoring the system for \nunauthorized access, detecting and putting in place strategies for resisting \nattacks, and organizing backups of programs and data so that normal operation \ncan be resumed after an external attack.\nOperational security is primarily a human and social issue. It focuses on ensuring \nthat the people using the system do not behave in such a way that system security is \ncompromised. For example, users may leave themselves logged on to a system while \nit is unattended. An attacker can then easily get access to the system. Users often \nbehave in an insecure way to help them do their jobs more effectively, and they have \ngood reason to behave in an insecure way. A challenge for operational security is to \nraise awareness of security issues and to find the right balance between security and \nsystem effectiveness.\nThe term cybersecurity is now commonly used in discussions of system security. \nCybersecurity is a very wide-ranging term that covers all aspects of the protection of \ncitizens, businesses, and critical infrastructures from threats that arise from their use \nof computers and the Internet. Its scope includes all system levels from hardware \nand networks through application systems to mobile devices that may be used to \naccess these systems. I discuss general cybersecurity issues, including infrastructure \nsecurity, in Chapter 14, which covers resilience engineering. \nIn this chapter, I focus on issues of application security engineering\u2014security \nrequirements, design for security, and security testing. I don\u2019t cover general security \ntechniques that may be used, such as encryption, and access control mechanisms or \nattack vectors, such as viruses and worms. General textbooks on computer security \n(Pfleeger and Pfleeger 2007; Anderson 2008; Stallings and Brown 2012) discuss \nthese techniques in detail.\n \n13.1 Security and dependability\nSecurity is a system attribute that reflects the ability of the system to protect itself \nfrom malicious internal or external attacks. These external attacks are possible \nbecause most computers and mobile devices are networked and are therefore \n\u00ad\naccessible by outsiders. Examples of attacks might be the installation of viruses and \nTrojan horses, unauthorized use of system services, or unauthorized modification of \na system or its data.\nIf you really want a system to be as secure as possible, it is best not to connect it \nto the Internet. Then, your security problems are limited to ensuring that authorized \nusers do not abuse the system and to controlling the use of devices such as USB \ndrives. In practice, however, networked access provides huge benefits for most \n\u00ad\nsystems, so disconnecting from the Internet is not a viable security option.\nFor some systems, security is the most important system dependability attribute. \nMilitary systems, systems for electronic commerce, and systems that involve the \nprocessing and interchange of confidential information must be designed so that \n", "page": 377, "type": "text", "section": "Page 377"}
{"text": "\t\n13.1\u2002 \u25a0\u2002 Security and dependability\u2002 \u2002 377\nFigure 13.2\u2002 Security \nterminology\nTerm\nDefinition\nAsset\nSomething of value that has to be protected. The asset may be the software system \nitself or the data used by that system.\nAttack\nAn exploitation of a system\u2019s vulnerability where an attacker has the goal of causing \nsome damage to a system asset or assets. Attacks may be from outside the system \n(external attacks) or from authorized insiders (insider attacks).\nControl\nA protective measure that reduces a system\u2019s vulnerability. Encryption is an example of \na control that reduces a vulnerability of a weak access control system.\nExposure\nPossible loss or harm to a computing system. This can be loss or damage to data or \ncan be a loss of time and effort if recovery is necessary after a security breach.\nThreat\nCircumstances that have potential to cause loss or harm. You can think of a threat as a \nsystem vulnerability that is subjected to an attack.\nVulnerability\nA weakness in a computer-based system that may be exploited to cause loss or harm.\nthey achieve a high level of security. If an airline reservation system is unavailable, \nfor example, this causes inconvenience and some delays in issuing tickets. However, \nif the system is insecure, then an attacker could delete all bookings and it would be \npractically impossible for normal airline operations to continue.\nAs with other aspects of dependability, a specialized terminology is associated \nwith security (Pfleeger and Pfleeger 2007). This terminology is explained in Figure \n13.2. Figure 13.3 is a security story from the Mentcare system that I use to illustrate \nsome of these terms. Figure 13.4 takes the security concepts defined in Figure 13.2 \nand shows how they apply to this security story.\nSystem vulnerabilities may arise because of requirements, design, or \u00ad\nimplementation \nproblems, or they may stem from human, social, or organizational failings. People may \nchoose easy-to-guess passwords or write down their passwords in places where they \ncan be found. System administrators make errors in setting up access control or con-\nfiguration files, and users don\u2019t install or use protection \u00ad\nsoftware. However, we cannot \nsimply class these problems as human errors. User \u00ad\nmistakes or omissions often reflect \npoor systems design decisions that require, for example, frequent password changes \n(so that users write down their passwords) or complex configuration mechanisms.\nUnauthorized access to the Mentcare system\nClinic staff log on to the Mentcare system using a username and password. The system requires passwords to \nbe at least eight letters long but allows any password to be set without further checking. A criminal finds out \nthat a well-paid sports star is receiving treatment for mental health problems. He would like to gain illegal \naccess to information in this system so that he can blackmail the star.\nBy posing as a concerned relative and talking with the nurses in the mental health clinic, he discovers how \nto access the system and personal information about the nurses and their families. By checking name badges, \nhe discovers the names of some of the people allowed access. He then attempts to log on to the system by \nusing these names and systematically guessing possible passwords, such as the names of the nurses\u2019 children.\nFigure 13.3\u2002 A security \nstory for the Mentcare \nsystem\n", "page": 378, "type": "text", "section": "Page 378"}
{"text": "378\u2002 \u2002 Chapter 13\u2002 \u25a0\u2002 Security engineering\nFour types of security threats may arise:\n1.\t\nInterception threats that allow an attacker to gain access to an asset. So, a \n\u00ad\npossible threat to the Mentcare system might be a situation where an attacker \ngains access to the records of an individual patient.\n2.\t\nInterruption threats that allow an attacker to make part of the system \u00ad\nunavailable. \nTherefore, a possible threat might be a denial-of-service attack on a system \ndatabase server.\n3.\t\nModification threats that allow an attacker to tamper with a system asset. In the \nMentcare system, a modification threat would be where an attacker alters or \ndestroys a patient record.\n4.\t\nFabrication threats that allow an attacker to insert false information into a sys-\ntem. This is perhaps not a credible threat in the Mentcare system but would \ncertainly be a threat in a banking system, where false transactions might be \nadded to the system that transfers money to the perpetrator\u2019s bank account.\nThe controls that you might put in place to enhance system security are based on \nthe fundamental notions of avoidance, detection, and recovery:\n1.\t\nVulnerability avoidance Controls that are intended to ensure that attacks are \nunsuccessful. The strategy here is to design the system so that security problems \nare avoided. For example, sensitive military systems are not connected to the \nInternet so that external access is more difficult. You should also think of \nencryption as a control based on avoidance. Any unauthorized access to \nencrypted data means that the attacker cannot read the encrypted data. It is \nexpensive and time consuming to crack strong encryption.\n2.\t\nAttack detection and neutralization Controls that are intended to detect and \nrepel attacks. These controls involve including functionality in a system that \nmonitors its operation and checks for unusual patterns of activity. If these \nFigure 13.4\u2002 Examples \nof security terminology\nTerm\nExample\nAsset\nThe record of each patient who is receiving or has received treatment.\nAttack\nAn impersonation of an authorized user.\nControl\nA password checking system that disallows user passwords that are proper names \nor words that are normally included in a dictionary.\nExposure\nPotential financial loss from future patients who do not seek treatment because \nthey do not trust the clinic to maintain their data. Financial loss from legal action \nby the sports star. Loss of reputation.\nThreat\nAn unauthorized user will gain access to the system by guessing the credentials \n(login name and password) of an authorized user.\nVulnerability\nAuthentication is based on a password system that does not require strong \npasswords. Users can then set easily guessable passwords.\n", "page": 379, "type": "text", "section": "Page 379"}
{"text": "attacks are detected, then action may be taken, such as shutting down parts of \nthe system or restricting access to certain users.\n3.\t\nExposure limitation and recovery Controls that support recovery from prob-\nlems. These can range from automated backup strategies and information \u201cmir-\nroring\u201d through to insurance policies that cover the costs associated with a \nsuccessful attack on the system.\nSecurity is closely related to the other dependability attributes of reliability, avail-\nability, safety, and resilience:\n1.\t\nSecurity and reliability If a system is attacked and the system or its data are cor-\nrupted as a consequence of that attack, then this may induce system failures that \ncompromise the reliability of the system.\nErrors in the development of a system can lead to security loopholes. If a system \ndoes not reject unexpected inputs or if array bounds are not checked, then attackers can \nexploit these weaknesses to gain access to the system. For example, failure to check the \nvalidity of an input may mean that an attacker can inject and execute malicious code.\n2.\t\nSecurity and availability A common attack on a web-based system is a denial-\nof-service attack, where a web server is flooded with service requests from a \nrange of different sources. The aim of this attack is to make the system unavail-\nable. A variant of this attack is where a profitable site is threatened with this \ntype of attack unless a ransom is paid to the attackers.\n3.\t\nSecurity and safety Again, the key problem is an attack that corrupts the system \nor its data. Safety checks are based on the assumption that we can analyze the \nsource code of safety-critical software and that the executing code is a com-\npletely accurate translation of that source code. If this is not the case, because an \nattacker has changed the executing code, safety-related failures may be induced \nand the safety case made for the software is invalid.\nLike safety, we cannot assign a numeric value to the security of a system, nor \ncan we exhaustively test the system for security. Both safety and security can be \nthought of as \u201cnegative\u201d or \u201cshall not\u201d characteristics in that they are concerned \nwith things that should not happen. As we can never prove a negative, we can \nnever prove that a system is safe or secure.\n4.\t\nSecurity and resilience Resilience, covered in Chapter 14, is a system character-\nistic that reflects its ability to resist and recover from damaging events. The \nmost probable damaging event on networked software systems is a cyberattack \nof some kind, so most of the work now done in resilience is aimed at deterring, \ndetecting, and recovering from such attacks.\nSecurity has to be maintained if we are to create reliable, available, and safe software-\nintensive systems. It is not an add-on, which can be added later but has to be considered \nat all stages of the development life cycle from early requirements to system operation.\n\t\n13.1\u2002 \u25a0\u2002 Security and dependability\u2002 \u2002 379\n", "page": 380, "type": "text", "section": "Page 380"}
{"text": "380\u2002 \u2002 Chapter 13\u2002 \u25a0\u2002 Security engineering\n \n13.2 Security and organizations\nBuilding secure systems is expensive and uncertain. It is impossible to predict the \ncosts of a security failure, so companies and other organizations find it difficult to \njudge how much they should spend on system security. In this respect, security and \nsafety are different. There are laws that govern workplace and operator safety, and \ndevelopers of safety-critical systems have to comply with these irrespective of the \ncosts. They may be subject to legal action if they use an unsafe system. However, \nunless a security failure discloses personal information, there are no laws that pre-\nvent an insecure system from being deployed.\nCompanies assess the risks and losses that may arise from certain types of attacks \non system assets. They may then decide that it is cheaper to accept these risks rather \nthan build a secure system that can deter or repel the external attacks. Credit card \ncompanies apply this approach to fraud prevention. It is usually possible to introduce \nnew technology to reduce credit card fraud. However, it is often cheaper for these \ncompanies to compensate users for their losses due to fraud than to buy and deploy \nfraud-reduction technology.\nSecurity risk management is therefore a business rather than a technical issue. It \nhas to take into account the financial and reputational losses from a successful sys-\ntem attack as well as the costs of security procedures and technologies that may \nreduce these losses. For risk management to be effective, organizations should have \na documented information security policy that sets out:\n1.\t\nThe assets that must be protected It does not necessarily make sense to apply \nstringent security procedures to all organizational assets. Many assets are not con-\nfidential, and a company can improve its image by making these assets freely \navailable. The costs of maintaining the security of information that is in the public \ndomain are much less than the costs of keeping confidential information secure.\n2.\t\nThe level of protection that is required for different types of assets Not all assets \nneed the same level of protection. In some cases (e.g., for sensitive personal \ninformation), a high level of security is required; for other information, the con-\nsequences of loss may be minor, so a lower level of security is adequate. \nTherefore, some information may be made available to any authorized and \nlogged-in user; other information may be much more sensitive and only availa-\nble to users in certain roles or positions of responsibility.\n3.\t\nThe responsibilities of individual users, managers, and the organization The \nsecurity policy should set out what is expected of users\u2014for example, use \nstrong passwords, log out of computers, and lock offices. It also defines what \nusers can expect from the company, such as backup and information-archiving \nservices, and equipment provision.\n4.\t\nExisting security procedures and technologies that should be maintained For \nreasons of practicality and cost, it may be essential to continue to use existing \napproaches to security even where these have known limitations. For example, \n", "page": 381, "type": "text", "section": "Page 381"}
{"text": "a company may require the use of a login name/password for authentication, \nsimply because other approaches are likely to be rejected by users.\nSecurity policies often set out general information access strategies that should \napply across the organization. For example, an access strategy may be based on the \nclearance or seniority of the person accessing the information. Therefore, a military \nsecurity policy may state: \u201cReaders may only examine documents whose classifica-\ntion is the same as or below the reader\u2019s vetting level.\u201d This means that if a reader \nhas been vetted to a \u201csecret\u201d level, he or she may access documents that are classed \nas secret, confidential, or open but not documents classed as top secret.\nThe point of security policies is to inform everyone in an organization about secu-\nrity, so these should not be long and detailed technical documents. From a security \nengineering perspective, the security policy defines, in broad terms, the security \ngoals of the organization. The security engineering process is concerned with imple-\nmenting these goals.\n\t\n13.2.1\t Security risk assessment\nSecurity risk assessment and management are organizational activities that focus on iden-\ntifying and understanding the risks to information assets (systems and data) in the organi-\nzation. In principle, an individual risk assessment should be carried out for all assets; in \npractice, however, this may be impractical if a large number of existing systems and \ndatabases need to be assessed. In those situations, a generic assessment may be applied to \nall of them. However, individual risk assessments should be carried out for new systems.\nRisk assessment and management is an organizational activity rather than a tech-\nnical activity that is part of the software development life cycle. The reason for this \nis that some types of attack are not technology-based but rather rely on weaknesses \nin more general organizational security. For example, an attacker may gain access to \nequipment by pretending to be an accredited engineer. If an organization has a pro-\ncess to check with the equipment supplier that an engineer\u2019s visit is planned, this can \ndeter this type of attack. This approach is much simpler than trying to address the \nproblem using a technological solution.\nWhen a new system is to be developed, security risk assessment and management \nshould be a continuing process throughout the development life cycle from initial \nspecification to operational use. The stages of risk assessment are:\n1.\t\nPreliminary risk assessment The aim of this initial risk assessment is to identify \ngeneric risks that are applicable to the system and to decide if an adequate level \nof security can be achieved at a reasonable cost. At this stage, decisions on the \ndetailed system requirements, the system design, or the implementation technol-\nogy have not been made. You don\u2019t know of potential technology vulnerabilities \nor the controls that are included in reused system components or middleware. \nThe risk assessment should therefore focus on the identification and analysis of \nhigh-level risks to the system. The outcomes of the risk assessment process are \nused to help identify security requirements.\n\t\n13.2\u2002 \u25a0\u2002 Security and organizations\u2002 \u2002 381\n", "page": 382, "type": "text", "section": "Page 382"}
{"text": "382\u2002 \u2002 Chapter 13\u2002 \u25a0\u2002 Security engineering\n2.\t\nDesign risk assessment This risk assessment takes place during the system devel-\nopment life cycle and is informed by the technical system design and implementa-\ntion decisions. The results of the assessment may lead to changes to the security \nrequirements and the addition of new requirements. Known and potential vulnera-\nbilities are identified, and this knowledge is used to inform decision making about \nthe system functionality and how it is to be implemented, tested, and deployed.\n3.\t\nOperational risk assessment This risk assessment process focuses on the use of \nthe system and the possible risks that can arise. For example, when a system is \nused in an environment where interruptions are common, a security risk is that a \nlogged-in user leaves his or her computer unattended to deal with a problem. To \ncounter this risk, a timeout requirement may be specified so that a user is auto-\nmatically logged out after a period of inactivity.\nOperational risk assessment should continue after a system has been installed to \ntake account of how the system is used and proposals for new and changed require-\nments. Assumptions about the operating requirement made when the system was \nspecified may be incorrect. Organizational changes may mean that the system is \nused in different ways from those originally planned. These changes lead to new \nsecurity requirements that have to be implemented as the system evolves.\n \n13.3 Security requirements\nThe specification of security requirements for systems has much in common with \nthe specification of safety requirements. You cannot specify safety or security \nrequirements as probabilities. Like safety requirements, security requirements are \noften \u201cshall not\u201d requirements that define unacceptable system behavior rather than \nrequired system functionality.\nHowever, security is a more challenging problem than safety, for a number of \nreasons:\n1.\t\nWhen considering safety, you can assume that the environment in which the \nsystem is installed is not hostile. No one is trying to cause a safety-related inci-\ndent. When considering security, you have to assume that attacks on the system \nare deliberate and that the attacker may have knowledge of system weaknesses.\n2.\t\nWhen system failures occur that pose a risk to safety, you look for the errors or \nomissions that have caused the failure. When deliberate attacks cause system \nfailure, finding the root cause may be more difficult as the attacker may try to \nconceal the cause of the failure.\n3.\t\nIt is usually acceptable to shut down a system or to degrade system services to \navoid a safety-related failure. However, attacks on a system may be denial-of-\nservice attacks, which are intended to compromise system availability. Shutting \ndown the system means that the attack has been successful.\n", "page": 383, "type": "text", "section": "Page 383"}
{"text": "4.\t\nSafety-related events are accidental and are not created by an intelligent adver-\nsary. An attacker can probe a system\u2019s defenses in a series of attacks, modifying \nthe attacks as he or she learns more about the system and its responses.\nThese distinctions mean that security requirements have to be more extensive \nthan safety requirements. Safety requirements lead to the generation of functional \nsystem requirements that provide protection against events and faults that could \ncause safety-related failures. These requirements are mostly concerned with check-\ning for problems and taking actions if these problems occur. By contrast, many types \nof security requirements cover the different threats faced by a system.\nFiresmith (Firesmith 2003) identified 10 types of security requirements that may \nbe included in a system specification:\n1.\t\nIdentification requirements specify whether or not a system should identify its \nusers before interacting with them.\n2.\t\nAuthentication requirements specify how users are identified.\n3.\t\nAuthorization requirements specify the privileges and access permissions of \nidentified users.\n4.\t\nImmunity requirements specify how a system should protect itself against \nviruses, worms, and similar threats.\n5.\t\nIntegrity requirements specify how data corruption can be avoided.\n6.\t\nIntrusion detection requirements specify what mechanisms should be used to \ndetect attacks on the system.\n7.\t\nNonrepudiation requirements specify that a party in a transaction cannot deny \nits involvement in that transaction.\n8.\t\nPrivacy requirements specify how data privacy is to be maintained.\n9.\t\nSecurity auditing requirements specify how system use can be audited and \nchecked.\n10.\t System maintenance security requirements specify how an application can pre-\nvent authorized changes from accidentally defeating its security mechanisms.\nOf course, you will not see all of these types of security requirements in every \nsystem. The particular requirements depend on the type of system, the situation of \nuse, and the expected users.\nPreliminary risk assessment and analysis aim to identify the generic security risks \nfor a system and its associated data. This risk assessment is an important input to the \nsecurity requirements engineering process. Security requirements can be proposed to \nsupport the general risk management strategies of avoidance, detection and mitigation.\n1.\t\nRisk avoidance requirements set out the risks that should be avoided by design-\ning the system so that these risks simply cannot arise.\n\t\n13.3\u2002 \u25a0\u2002 Security requirements\u2002 \u2002 383\n", "page": 384, "type": "text", "section": "Page 384"}
{"text": "384\u2002 \u2002 Chapter 13\u2002 \u25a0\u2002 Security engineering\n2.\t\nRisk detection requirements define mechanisms that identify the risk if it arises \nand neutralize the risk before losses occur.\n3.\t\nRisk mitigation requirements set out how the system should be designed so that \nit can recover from and restore system assets after some loss has occurred.\nA risk-driven security requirements process is shown in Figure 13.5. The process \nstages are:\n1.\t\nAsset identification, where the system assets that may require protection are \nidentified. The system itself or particular system functions may be identified as \nassets as well as the data associated with the system.\n2.\t\nAsset value assessment, where you estimate the value of the identified assets.\n3.\t\nExposure assessment, where you assess the potential losses associated with \neach asset. This process should take into account direct losses such as the theft \nof information, the costs of recovery, and the possible loss of reputation.\n4.\t\nThreat identification, where you identify the threats to system assets.\n5.\t\nAttack assessment, where you decompose each threat into attacks that might be \nmade on the system and the possible ways in which these attacks may occur. \nYou may use attack trees (Schneier 1999) to analyze the possible attacks. These \nare similar to fault trees, (Chapter 12) as you start with a threat at the root of the \ntree and then identify possible causal attacks and how these might be made.\n6.\t\nControl identification, where you propose the controls that might be put in place \nto protect an asset. The controls are the technical mechanisms, such as encryp-\ntion, that you can use to protect assets.\n7.\t\nFeasibility assessment, where you assess the technical feasibility and the costs \nof the proposed controls. It is not worth having expensive controls to protect \nassets that don\u2019t have a high value.\nAsset\nidentification\nAsset value\nassessment\nThreat\nidentification\nAttack\nassessment\nExposure\nassessment\nSecurity req.\ndefinition\nControl\nidentification\nFeasibility\nassessment\nFigure 13.5\u2002 The \npreliminary risk \nassessment process for \nsecurity requirements \n", "page": 385, "type": "text", "section": "Page 385"}
{"text": "8.\t\nSecurity requirements definition, where knowledge of the exposure, threats, and \ncontrol assessments is used to derive system security requirements. These \nrequirements may apply to the system infrastructure or the application system.\nThe Mentcare patient management system is a security-critical system. Figures \n13.6 and 13.7 are fragments of a report that documents the risk analysis of that soft-\nware system. Figure 13.6 is an asset analysis that describes the assets in the system \nand their value. Figure 13.7 shows some of the threats that a system may face.\nOnce a preliminary risk assessment has been completed, then requirements can be \nproposed that aim to avoid, detect, and mitigate risks to the system. However, creating \nthese requirements is not a formulaic or automated process. It requires inputs from \nboth engineers and domain experts to suggest requirements based on their understand-\ning of the risk analysis and the functional requirements of the software system. Some \nexamples of the Mentcare system security requirements and associated risks are:\n1.\t\nPatient information shall be downloaded, at the start of a clinic session, from \nthe database to a secure area on the system client.\n\t\nRisk: Damage from denial-of-service attack. Maintaining local copies means \nthat access is still possible.\n2.\t\nAll patient information on the system client shall be encrypted.\n\t\nRisk: External access to patient records. If data is encrypted, then attacker must \nhave access to the encryption key to discover patient information.\n3.\t\nPatient information shall be uploaded to the database when a clinic session is \nover and deleted from the client computer.\n\t\nRisk: External access to patience records through stolen laptop.\n4.\t\nA log of all changes made to the system database and the initiator of these \nchanges shall be maintained on a separate computer from the database server.\n\t\nRisk: Insider or external attacks that corrupt current data. A log should allow \nup-to-date records to be re-created from a backup.\nFigure 13.6\u2002 Asset \nanalysis in a \npreliminary risk \nassessment report for \nthe Mentcare system\nAsset\nValue\nExposure\nThe information \nsystem\nHigh. Required to support \nall clinical consultations. \nPotentially safety critical.\nHigh. Financial loss as clinics may have to \nbe canceled. Costs of restoring system. \nPossible patient harm if treatment cannot \nbe prescribed.\nThe patient database\nHigh. Required to support \nall clinical consultations. \nPotentially safety critical.\nHigh. Financial loss as clinics may have to \nbe canceled. Costs of restoring system. \nPossible patient harm if treatment cannot \nbe prescribed.\nAn individual patient \nrecord\nNormally low, although \nmay be high for specific \nhigh-profile patients\nLow direct losses but possible loss of \nreputation.\n\t\n13.3\u2002 \u25a0\u2002 Security requirements\u2002 \u2002 385\n", "page": 386, "type": "text", "section": "Page 386"}
{"text": "386\u2002 \u2002 Chapter 13\u2002 \u25a0\u2002 Security engineering\nThe first two requirements are related\u2014patient information is downloaded to a \nlocal machine, so that consultations may continue if the patient database server is \nattacked or becomes unavailable. However, this information must be deleted so \nthat later users of the client computer cannot access the information. The fourth \nrequirement is a recovery and auditing requirement. It means that changes can be \nrecovered by replaying the change log and that it is possible to discover who has \nmade the changes. This accountability discourages misuse of the system by \nauthorized staff.\n\t\n13.3.1\t Misuse cases\nThe derivation of security requirements from a risk analysis is a creative process \ninvolving engineers and domain experts. One approach that has been developed to \nsupport this process for users of the UML is the idea of misuse cases (Sindre and \nOpdahl 2005). Misuse cases are scenarios that represent malicious interactions with \na system. You can use these scenarios to discuss and identify possible threats and, \ntherefore also determine the system\u2019s security requirements. They can be used \nalongside use cases when deriving the system requirements (Chapters 4 and 5).\nMisuse cases are associated with use case instances and represent threats or \nattacks associated with these use cases. They may be included in a use case diagram \nbut should also have a more complete and detailed textual description. In Figure \n13.8, I have taken the use cases for a medical receptionist using the Mentcare system \nand have added misuse cases. These are normally represented as black ellipses.\nAs with use cases, misuse cases can be described in several ways. I think that it is \nmost helpful to describe them as a supplement to the original use case description. I \nalso think it is best to have a flexible format for misuse cases as different types of attack \nhave to be described in different ways. Figure 13.9 shows the original description of \nthe Transfer Data use case (Figure 5.4), with the addition of a misuse case description.\nThe problem with misuse cases mirrors the general problem of use cases, which \nis that interactions between end-users and a system do not capture all of the system \nFigure 13.7\u2002 Threat  \nand control analysis  \nin a preliminary risk \nassessment report\nThreat\nProbability\nControl\nFeasibility\nAn unauthorized user \ngains access as system \nmanager and makes \nsystem unavailable\nLow\nOnly allow system \nmanagement from \nspecific locations that \nare physically secure.\nLow cost of implementation, but care \nmust be taken with key distribution \nand to ensure that keys are available \nin the event of an emergency.\nAn unauthorized user \ngains access as system \nuser to confidential \ninformation\nHigh\nRequire all users to \nauthenticate \nthemselves using a \nbiometric mechanism.\nTechnically feasible but high- cost \nsolution. Possible user resistance.\nLog all changes to \npatient information to \ntrack system usage.\nSimple and transparent to \nimplement and also supports \nrecovery.\n", "page": 387, "type": "text", "section": "Page 387"}
{"text": "Medical\nreceptionist\nRegister\npatient\nTransfer data\nContact\npatient\nView patient\ninfo.\nUnregister\npatient\nImpersonate\nreceptionist\nIntercept\ntransfer\nAttacker\nFigure 13.8\u2002 Misuse \ncases \nFigure 13.9\u2002 Misuse case \ndescriptions\nMentcare system: Intercept transfer (Misuse case)\nActors\nMedical receptionist, Patient records system (PRS), Attacker\nDescription\nA receptionist transfers data from his or her PC to the Mentcare system on the server.\nAn attacker intercepts the data transfer and takes a copy of that data.\nData (assets)\nPatient\u2019s personal information, treatment summary\nAttacks\nA network monitor is added to the system, and packets from the receptionist to the \nserver are intercepted.\nA spoof server is set up between the receptionist and the database server so that \nreceptionist believes they are interacting with the real system.\nMitigations\nAll networking equipment must be maintained in a locked room. Engineers accessing \nthe equipment must be accredited.\nAll data transfers between the client and server must be encrypted.\nCertificate-based client\u2013server communication must be used.\nRequirements\nAll communications between the client and the server must use the Secure Socket \nLayer (SSL). The https protocol uses certificate-based authentication and encryption.\nMentcare system: Transfer data\nActors\nMedical receptionist, Patient records system (PRS)\nDescription\nA receptionist may transfer data from the Mentcare system to a general patient \nrecord database that is maintained by a health authority. The information transferred \nmay either be updated personal information (address, phone number, etc.) or a \nsummary of the patient\u2019s diagnosis and treatment\nData\nPatient\u2019s personal information, treatment summary\nStimulus\nUser command issued by medical receptionist\nResponse\nConfirmation that PRS has been updated\nComments\nThe receptionist must have appropriate security permissions to access the patient \ninformation and the PRS.\n\t\n13.3\u2002 \u25a0\u2002 Security requirements\u2002 \u2002 387\n", "page": 388, "type": "text", "section": "Page 388"}
{"text": "388\u2002 \u2002 Chapter 13\u2002 \u25a0\u2002 Security engineering\nrequirements. Misuse cases can be used as part of the security requirements engi-\nneering process, but you also need to consider risks that are associated with system \nstakeholders who do not interact directly with the system.\n \n13.4 Secure systems design\nIt is very difficult to add security to a system after it has been implemented. Therefore, \nyou need to take security issues into account during the systems design process and \nmake design choices that enhance the security of a system. In this section, I focus on \ntwo application-independent issues relevant to secure systems design:\n1.\t\nArchitectural design\u2014how do architectural design decisions affect the security \nof a system?\n2.\t\nGood practice\u2014what is accepted good practice when designing secure \u00ad\nsystems?\nOf course, these are not the only design issues that are important for security. \nEvery application is different, and security design also has to take into account the \npurpose, criticality, and operational environment of the application. For example, if \nyou are designing a military system, you need to adopt their security classification \nmodel (secret, top secret, etc.) If you are designing a system that maintains personal \ninformation, you may have to take into account data protection legislation that places \nrestrictions on how data is managed.\nUsing redundancy and diversity, which is essential for dependability, may mean \nthat a system can resist and recover from attacks that target specific design or imple-\nmentation characteristics. Mechanisms to support a high level of availability may \nhelp the system to recover from denial-of-service attacks, where the aim of an \nattacker is to bring down the system and stop it from working properly.\nDesigning a system to be secure inevitably involves compromises. It is usually \npossible to design multiple security measures into a system that will reduce the \nchances of a successful attack. However, these security measures may require addi-\ntional computation and so affect the overall performance of the system. For example, \nyou can reduce the chances of confidential information being disclosed by encrypt-\ning that information. However, this means that users of the information have to wait \nfor it to be decrypted, which may slow down their work.\nThere are also tensions between security and usability\u2014another emergent system \nproperty. Security measures sometimes require the user to remember and provide \nadditional information (e.g., multiple passwords). However, sometimes users forget \nthis information, so the additional security means that they can\u2019t use the system.\nSystem designers have to find a balance between security, performance, and usa-\nbility. This depends on the type of system being developed, the expectations of its \nusers, and its operational environment. For example, in a military system, users are \nfamiliar with high-security systems and so accept and follow processes that require \nfrequent checks. In a system for stock trading, where speed is essential, interruptions \nof operation for security checks would be completely unacceptable.\n", "page": 389, "type": "text", "section": "Page 389"}
{"text": "\t\n13.4.1\t Design risk assessment\nSecurity risk assessment during requirements engineering identifies a set of high-\nlevel security requirements for a system. However, as the system is designed and \nimplemented, architectural and technology decisions made during the system design \nprocess influence the security of a system. These decisions generate new design \nrequirements and may mean that existing requirements have to change.\nSystem design and the assessment of design-related risks are interleaved pro-\ncesses (Figure 13.10). Preliminary design decisions are made, and the risks associ-\nated with these decisions are assessed. This assessment may lead to new requirements \nto mitigate the risks that have been identified or design changes to reduce these risks. \nAs the system design evolves and is developed in more detail, the risks are reas-\nsessed and the results are fed back to the system designers. The design risk assess-\nment process ends when the design is complete and the remaining risks are acceptable.\nWhen assessing risks during design and implementation, you have more informa-\ntion about what needs to be protected, and you also will know something about the \nvulnerabilities in the system. Some of these vulnerabilities will be inherent in the \ndesign choices made. For example, an inherent vulnerability in password-based \nauthentication is that an authorized user reveals their password to an unauthorized \nuser. So, if password-based authentication is used, the risk assessment process may \nsuggest new requirements to mitigate the risk. For example, there may be a require-\nment for multifactor authentication where users must authenticate themselves using \nsome personal knowledge as well as a password.\nDenial-of-service attacks\nDenial-of-service attacks attempt to bring down a networked system by bombarding it with a huge number of \nservice requests, usually from hundreds of attacking systems. These place a load on the system for which it was \nnot designed and they exclude legitimate requests for system service. Consequently, the system may become \nunavailable either because it crashes with the heavy load or has to be taken offline by system managers to stop \nthe flow of requests.\nhttp://software-engineering-book.com/web/denial-of-service/\nDesign risk\nassessment\nSystem\ndesign\nTechnology\nchoices\nDesign assets\nDesign and\nrequirements\nchanges\nArchitectural\ndesign\nSystem \nrequirements\nFigure 13.10\u2002 Interleaved \ndesign and risk \nassessment \n\t\n13.4\u2002 \u25a0\u2002 Secure systems design\u2002 \u2002 389\n", "page": 390, "type": "text", "section": "Page 390"}
{"text": "390\u2002 \u2002 Chapter 13\u2002 \u25a0\u2002 Security engineering\nFigure 13.11 is a model of the design risk assessment process. The key difference \nbetween preliminary risk analysis and design risk assessment is that, at the design \nstage, you now have information about information representation and distribution \nand the database organization for the high-level assets that have to be protected. You \nalso know about important design decisions such as the software to be reused, infra-\nstructure controls and protection, and so forth. Based on this information, your \nassessment can identify changes to the security requirements and the system design \nto provide additional protection for the important system assets.\nTwo examples from the Mentcare system illustrate how protection requirements \nare influenced by decisions on information representation and distribution:\n1.\t\nYou may make a design decision to separate personal patient information and \ninformation (design assets) about treatments received, with a key linking these \nrecords. The treatment information is technical and so much less sensitive than \nthe personal patient information. If the key is protected, then an attacker will \nonly be able to access routine information, without being able to link this to an \nindividual patient.\n2.\t\nAssume that, at the beginning of a session, a design decision is made to copy \npatient records to a local client system. This allows work to continue if the \nserver is unavailable. It makes it possible for a healthcare worker to access \npatient records from a laptop, even if no network connection is available. \nHowever, you now have two sets of records to protect and the client copies are \nsubject to additional risks, such as theft of the laptop computer. You therefore \nhave to think about what controls should be used to reduce risk. You may there-\nfore include a requirement that client records held on laptops or other personal \ncomputers may have to be encrypted.\nDesign assets\nAsset value\nassessment\nThreat\nidentification\nAttack\nassessment\nExposure\nassessment\nControl\nidentification\nTechnology and\n architecture  choices\nAvailable\ncontrols\nDesign and\nrequirements\nchanges\nFigure 13.11\u2002 Design \nrisk assessment \n", "page": 391, "type": "text", "section": "Page 391"}
{"text": "To illustrate how decisions on development technologies influence security, \nassume that the health care provider has decided to build a Mentcare system using an \noff-the-shelf information system for maintaining patient records. This system has to \nbe configured for each type of clinic in which it is used. This decision has been made \nbecause it appears to offer the most extensive functionality for the lowest develop-\nment cost and fastest deployment time.\nWhen you develop an application by reusing an existing system, you have to \naccept the design decisions made by the developers of that system. Let us assume \nthat some of these design decisions are:\n1.\t\nSystem users are authenticated using a login name/password combination. No \nother authentication method is supported.\n2.\t\nThe system architecture is client\u2013server, with clients accessing data through a \nstandard web browser on a client computer.\n3.\t\nInformation is presented to users as an editable web form. They can change \ninformation in place and upload the revised information to the server.\nFor a generic system, these design decisions are perfectly acceptable, but design \nrisk assessment shows that they have associated vulnerabilities. Examples of these \npossible vulnerabilities are shown in Figure 13.12.\nOnce vulnerabilities have been identified, you then have to decide what steps you \ncan take to reduce the associated risks. This will often involve making decisions \nLogin/password\nauthentication\nUsers set\nguessable\npasswords\nAuthorized users reveal\ntheir passwords to\nunauthorized users\nTechnology choice\nVulnerabilities\nClient/server\narchitecture using\nweb browser\nServer subject to\ndenial-of-service\nattack\nConfidential information\nmay be left in browser\ncache\nBrowser security\nloopholes lead to\nunauthorized access\nUse of editable\nweb forms\nFine-grain logging\nof changes is\nimpossible\nAuthorization can\u2019t be\nvaried according to user\u2019s\nrole\nFigure 13.12\u2002  \nVulnerabilities \nassociated with \ntechnology choices \n\t\n13.4\u2002 \u25a0\u2002 Secure systems design\u2002 \u2002 391\n", "page": 392, "type": "text", "section": "Page 392"}
{"text": "392\u2002 \u2002 Chapter 13\u2002 \u25a0\u2002 Security engineering\nabout additional system security requirements or the operational process of using the \nsystem. Examples of these requirements might be:\n1.\t\nA password checker program shall be made available and shall be run daily to \ncheck all user passwords. User passwords that appear in the system dictionary \nshall be identified, and users with weak passwords shall be reported to system \nadministrators.\n2.\t\nAccess to the system shall only be allowed to client computers that have been \napproved and registered with the system administrators.\n3.\t\nOnly one approved web browser shall be installed on client computers.\nAs an off-the-shelf system is used, it isn\u2019t possible to include a password checker \nin the application system itself, so a separate system must be used. Password check-\ners analyze the strength of user passwords when they are set up and notify users if \nthey have chosen weak passwords. Therefore, vulnerable passwords can be identi-\nfied reasonably quickly after they have been set up, and action can then be taken to \nensure that users change their password.\nThe second and third requirements mean that all users will always access the sys-\ntem through the same browser. You can decide what is the most secure browser \nwhen the system is deployed and install that on all client computers. Security updates \nare simplified because there is no need to update different browsers when security \nvulnerabilities are discovered and fixed.\nThe process model shown in Figure 13.10 assumes a design process where the \ndesign is developed to a fairly detailed level before implementation begins. This is \nnot the case for agile processes where the design and the implementation are devel-\noped together, with the code refactored as the design is developed. Frequent delivery \nof system increments does not allow time for a detailed risk assessment, even if \ninformation on assets and technology choices is available.\nThe issues surrounding security and agile development have been widely dis-\ncussed (Lane 2010; Schoenfield 2013). So far, the issue has not really been \nresolved\u2014some people think that a fundamental conflict exists between security \nand agile development, and others believe that this conflict can be resolved using \nsecurity-focused stories (Safecode 2012). This remains an outstanding problem \nfor developers of agile methods. Meanwhile, many security-conscious companies \nrefuse to use agile methods because they conflict with their security and risk \nanalysis policies.\n\t\n13.4.2\t Architectural design\nSoftware architecture design decisions can have profound effects on the emergent \nproperties of a software system. If an inappropriate architecture is used, it may be \nvery difficult to maintain the confidentiality and integrity of information in the sys-\ntem or to guarantee a required level of system availability.\n", "page": 393, "type": "text", "section": "Page 393"}
{"text": "In designing a system architecture that maintains security, you need to consider \ntwo fundamental issues:\n1.\t\nProtection\u2014how should the system be organized so that critical assets can be \nprotected against external attack?\n2.\t\nDistribution\u2014how should system assets be distributed so that the consequences \nof a successful attack are minimized?\nThese issues are potentially conflicting. If you put all your assets in one place, \nthen you can build layers of protection around them. As you only have to build a \nsingle protection system, you may be able to afford a strong system with several pro-\ntection layers. However, if that protection fails, then all your assets are compromised. \nAdding several layers of protection also affects the usability of a system, so it may \nmean that it is more difficult to meet system usability and performance requirements.\nOn the other hand, if you distribute assets, they are more expensive to protect \nbecause protection systems have to be implemented for each distributed asset. \nTypically, then, you cannot afford to implement as many protection layers. The \nchances are greater that the protection will be breached. However, if this happens, \nyou don\u2019t suffer a total loss. It may be possible to duplicate and distribute informa-\ntion assets so that if one copy is corrupted or inaccessible, then the other copy can be \nused. However, if the information is confidential, keeping additional copies increases \nthe risk that an intruder will gain access to this information.\nFor the Mentcare system, a client\u2013server architecture with a shared central data-\nbase is used. To provide protection, the system has a layered architecture with the \nPlatform-level protection\nApplication-level protection \nRecord-level protection\nPatient records\nSystem\nauthentication\nSystem\nauthorization\nFile integrity\nmanagement\nDatabase\nlogin\nDatabase\nauthorization\nTransaction\nmanagement\nDatabase\nrecovery\nRecord access\nauthorization\nRecord\nencryption\nRecord integrity\nmanagement\nFigure 13.13\u2002 A layered \nprotection architecture\n\t\n13.4\u2002 \u25a0\u2002 Secure systems design\u2002 \u2002 393\n", "page": 394, "type": "text", "section": "Page 394"}
{"text": "394\u2002 \u2002 Chapter 13\u2002 \u25a0\u2002 Security engineering\ncritical protected assets at the lowest level in the system. Figure 13.13 illustrates this \nmultilevel system architecture in which the critical assets to be protected are the \nrecords of individual patients.\nTo access and modify patient records, an attacker has to penetrate three system layers:\n1.\t\nPlatform-level protection. The top level controls access to the platform on \nwhich the patient record system runs. This usually involves a user signing-on to \na particular computer. The platform will also normally include support for \nmaintaining the integrity of files on the system, backups, and so on.\n2.\t\nApplication-level protection. The next protection level is built into the applica-\ntion itself. It involves a user accessing the application, being authenticated, and \ngetting authorization to take actions such as viewing or modifying data. \nApplication-specific integrity management support may be available.\n3.\t\nRecord-level protection. This level is invoked when access to specific records is \nrequired, and involves checking that a user is authorized to carry out the \nrequested operations on that record. Protection at this level might also involve \nencryption to ensure that records cannot be browsed using a file browser. \nIntegrity checking using, for example, cryptographic checksums can detect \nchanges that have been made outside the normal record update mechanisms.\nThe number of protection layers that you need in any particular application \ndepends on the criticality of the data. Not all applications need protection at the \nrecord level, and, therefore, coarser-grain access control is more commonly used. To \nachieve security, you should not allow the same user credentials to be used at each \nlevel. Ideally, if you have a password-based system, then the application password \nshould be different from both the system password and the record-level password. \nHowever, multiple passwords are difficult for users to remember, and they find \nrepeated requests to authenticate themselves irritating. Therefore, you often have to \ncompromise on security in favor of system usability.\nIf protection of data is a critical requirement, then a centralized client\u2013server \narchitecture is usually the most effective security architecture. The server is respon-\nsible for protecting sensitive data. However, if the protection is compromised, then \nthe losses associated with an attack are high, as all data may be lost or damaged. \nRecovery costs may also be high (e.g., all user credentials may have to be reissued). \nCentralized systems are also more vulnerable to denial-of-service attacks, which \noverload the server and make it impossible for anyone to access the system database.\nIf the consequences of a server breach are high, you may decide to use an alternative \ndistributed architecture for the application. In this situation, the system\u2019s assets are dis-\ntributed across a number of different platforms, with separate protection mechanisms \nused for each of these platforms. An attack on one node might mean that some assets \nare unavailable, but it would still be possible to provide some system services. Data can \nbe replicated across the nodes in the system so that recovery from attacks is simplified.\nFigure 13.14 illustrates the architecture of a banking system for trading in stocks \nand funds on the New York, London, Frankfurt, and Hong Kong markets. The system \n", "page": 395, "type": "text", "section": "Page 395"}
{"text": "is distributed so that data about each market is maintained separately. Assets required \nto support the critical activity of equity trading (user accounts and prices) are repli-\ncated and available on all nodes. If a node of the system is attacked and becomes \nunavailable, the critical activity of equity trading can be transferred to another coun-\ntry and so can still be available to users.\nI have already discussed the problem of finding a balance between security and \nsystem performance. A problem of secure system design is that in many cases, the \narchitectural style that is best for the security requirements may not be the best one \nfor meeting the performance requirements. For example, say an application has an \nabsolute requirement to maintain the confidentiality of a large database and another \nrequirement for very fast access to that data. A high-level of protection suggests that \nlayers of protection are required, which means that there must be communications \nbetween the system layers. This has an inevitable performance overhead and so will \nslow down access to the data.\nIf an alternative architecture is used, then implementing protection and guaran-\nteeing confidentiality may be more difficult and expensive. In such a situation, you \nhave to discuss the inherent conflicts with the customer who is paying for the system \nand agree on how these conflicts are to be resolved.\nUS equity data\nUS trading\nhistory\nInternational\nequity prices\nUS funds data\nUS user accounts\nInternational\nuser accounts\nNew York trading system\nAuthentication and authorization\nUK equity data\nUK trading\nhistory\nInternational\nequity prices\nUK funds data\nUK user accounts\nInternational\nuser accounts\nLondon trading system\nAuthentication and authorization\nEuro. equity data\nEuro. trading\nhistory\nInternational\nequity prices\nEuro. funds data\nEuropean user\naccounts\nInternational\nuser accounts\nFrankfurt trading system\nAuthentication and authorization\nAsian equity data\nHK trading\nhistory\nInternational\nequity prices\nAsian funds data\nHK user accounts\nInternational\nuser accounts\nHong Kong trading system\nAuthentication and authorization\nFigure 13.14\u2002  \nDistributed assets in an \nequity trading system \n\t\n13.4\u2002 \u25a0\u2002 Secure systems design\u2002 \u2002 395\n", "page": 396, "type": "text", "section": "Page 396"}
{"text": "396\u2002 \u2002 Chapter 13\u2002 \u25a0\u2002 Security engineering\n\t\n13.4.3\t Design guidelines\nThere are no easy ways to ensure system security. Different types of systems require \ndifferent technical measures to achieve a level of security that is acceptable to the sys-\ntem owner. The attitudes and requirements of different groups of users profoundly affect \nwhat is and is not acceptable. For example, in a bank, users are likely to accept a higher \nlevel of security, and hence more intrusive security procedures than, say, in a university.\nHowever, some general guidelines have wide applicability when designing sys-\ntem security solutions. These guidelines encapsulate good design practice for secure \nsystems engineering. General design guidelines for security, such as those discussed, \nbelow, have two principal uses:\n1.\t\nThey help raise awareness of security issues in a software engineering team. \nSoftware engineers often focus on the short-term goal of getting the software \nworking and delivered to customers. It is easy for them to overlook security \nissues. Knowledge of these guidelines can mean that security issues are consid-\nered when software design decisions are made.\n2.\t\nThey can be used as a review checklist that can be used in the system validation \nprocess. From the high-level guidelines discussed here, more specific questions \ncan be derived that explore how security has been engineered into a system.\nSecurity guidelines are sometimes very general principles such as \u201cSecure the \nweakest link in a system,\u201d \u201cKeep it simple,\u201d and \u201cAvoid security through obscurity.\u201d \nI think these general guidelines are too vague to be of real use in the design process. \nConsequently, I have focused here on more specific design guidelines. The 10 design \nguidelines, summarized in Figure 13.15, have been taken from different sources \n(Schneier 2000; Viega and McGraw 2001; Wheeler 2004).\n\t\n\t Guideline 1: Base security decisions on an explicit security policy\nAn organizational security policy is a high-level statement that sets out fundamental secu-\nrity conditions for an organization. It defines the \u201cwhat\u201d of security rather than the \u201chow.\u201d \nso the policy should not define the mechanisms to be used to provide and enforce security. \nIn principle, all aspects of the security policy should be reflected in the system require-\nments. In practice, especially if agile development is used, this is unlikely to happen.\nDesigners should use the security policy as a framework for making and evaluat-\ning design decisions. For example, say you are designing an access control system \nfor the Mentcare system. The hospital security policy may state that only accredited \nclinical staff may modify electronic patient records. This leads to requirements to \ncheck the accreditation of anyone attempting to modify the system and to reject \nmodifications from unaccredited people.\nThe problem that you may face is that many organizations do not have an explicit \nsystems security policy. Over time, changes may have been made to systems in \nresponse to identified problems, but with no overarching policy document to guide \nthe evolution of a system. In such situations, you need to work out and document the \npolicy from examples and confirm it with managers in the company.\n", "page": 397, "type": "text", "section": "Page 397"}
{"text": "\t\n\t Guideline 2: Use defense in depth\nIn any critical system, it is good design practice to try to avoid a single point of fail-\nure. That is, a single failure in part of the system should not result in an overall sys-\ntems failure. In security terms, this means that you should not rely on a single \nmechanism to ensure security; rather, you should employ several different tech-\nniques. This concept is sometimes called \u201cdefense in depth.\u201d\nAn example of defense in depth is multifactor authentication. For example, if you \nuse a password to authenticate users to a system, you may also include a challenge/\nresponse authentication mechanism where users have to pre-register questions and \nanswers with the system. After they have input their login credentials, they must \nthen answer questions correctly before being allowed access.\n\t\n\t Guideline 3: Fail securely\nSystem failures are inevitable in all systems, and, in the same way that safety-critical \nsystems should always fail-safe; security-critical systems should always \u201cfail-secure.\u201d \nWhen the system fails, you should not use fallback procedures that are less secure \nthan the system itself. Nor should system failure mean that an attacker can access \ndata that would not normally be allowed.\nFor example, in the Mentcare system, I suggested a requirement that patient data \nshould be downloaded to a system client at the beginning of a clinic session. This \nspeeds up access and means that access is possible if the server is unavailable. \nNormally, the server deletes this data at the end of the clinic session. However, if the \nserver has failed, then it is possible that the information on the client will be main-\ntained. A fail-secure approach in those circumstances is to encrypt all patient data \nstored on the client. This means that an unauthorized user cannot read the data.\n\t\n\t Guideline 4: Balance security and usability\nThe demands of security and usability are often contradictory. To make a system \nsecure, you have to introduce checks that users are authorized to use the system and \nFigure 13.15\u2002 Design \nguidelines for secure \nsystems engineering\nDesign guidelines for security\n\u2002 \u200a\n\u200a\n1\nBase security decisions on an explicit security policy\n\u2002 \u200a\n\u200a\n2\nUse defense in depth\n\u2002 \u200a\n\u200a\n3\nFail securely\n\u2002 \u200a\n\u200a\n4\nBalance security and usability\n\u2002 \u200a\n\u200a\n5\nLog user actions\n\u2002 \u200a\n\u200a\n6\nUse redundancy and diversity to reduce risk\n\u2002 \u200a\n\u200a\n7\nSpecify the format of system inputs\n\u2002 \u200a\n\u200a\n8\nCompartmentalize your assets\n\u2002 \u200a\n\u200a\n9\nDesign for deployment\n10\nDesign for recovery\n\t\n13.4\u2002 \u25a0\u2002 Secure systems design\u2002 \u2002 397\n", "page": 398, "type": "text", "section": "Page 398"}
{"text": "398\u2002 \u2002 Chapter 13\u2002 \u25a0\u2002 Security engineering\nthat they are acting in accordance with security policies. All of these inevitably make \ndemands on users\u2014they may have to remember login names and passwords, only \nuse the system from certain computers, and so on. These mean that it takes users \nmore time to get started with the system and use it effectively. As you add security \nfeatures to a system, it usually becomes more difficult to use. I recommend Cranor \nand Garfinkel\u2019s book (Cranor and Garfinkel 2005), which discusses a wide range of \nissues in the general area of security and usability.\nThere comes a point when it is counterproductive to keep adding on new security \nfeatures at the expense of usability. For example, if you require users to input multi-\nple passwords or to change their passwords to impossible to remember character \nstrings at frequent intervals, they will simply write down these passwords. An \nattacker (especially an insider) may then be able to find the passwords that have been \nwritten down and gain access to the system.\n\t\n\t Guideline 5: Log user actions\nIf it is practically possible to do so, you should always maintain a log of user actions. \nThis log should, at least, record who did what, the assets used and the time and date of \nthe action. If you maintain this as a list of executable commands, you can replay the log \nto recover from failures. You also need tools that allow you to analyze the log and detect \npotentially anomalous actions. These tools can scan the log and find anomalous actions, \nand thus help detect attacks and trace how the attacker gained access to the system.\nApart from helping recover from failure, a log of user actions is useful because it \nacts as a deterrent to insider attacks. If people know that their actions are being \nlogged, then they are less likely to do unauthorized things. This is most effective for \ncasual attacks, such as a nurse looking up patient records of neighbors, or for detect-\ning attacks where legitimate user credentials have been stolen through social engi-\nneering. Of course, this approach is not foolproof, as technically skilled insiders may \nalso be able to access and change the log.\n\t\n\t Guideline 6: Use redundancy and diversity to reduce risk\nRedundancy means that you maintain more than one version of software or data in a \nsystem. Diversity, when applied to software, means that the different versions should \nnot rely on the same platform or be implemented using the same technologies. \nTherefore, platform or technology vulnerabilities will not affect all versions and so \nwill lead to a common failure.\nI have already discussed examples of redundancy\u2014maintaining patient informa-\ntion on both the server and the client, first in the Mentcare system and then in the \ndistributed equity trading system shown in Figure 13.14. In the patient records sys-\ntem, you could use diverse operating systems on the client and the server (e.g., Linux \non the server, Windows on the client). This ensures that an attack based on an oper-\nating system vulnerability will not affect both the server and the client. Of course, \nrunning multiple operating systems leads to higher systems management costs. You \nhave to trade off security benefits against this increased cost.\n", "page": 399, "type": "text", "section": "Page 399"}
{"text": "\t\n\t Guideline 7: Specify the format of system inputs\nA common attack on a system involves providing the system with unexpected inputs \nthat cause it to behave in an unanticipated way. These inputs may simply cause a sys-\ntem crash, resulting in a loss of service, or the inputs could be made up of malicious \ncode that is executed by the system. Buffer overflow vulnerabilities, first demonstrated \nin the Internet worm (Spafford 1989) and commonly used by attackers, may be trig-\ngered using long input strings. So-called SQL poisoning, where a malicious user inputs \nan SQL fragment that is interpreted by a server, is another fairly common attack.\nYou can avoid many of these problems if you specify the format and structure of \nthe system inputs that are expected. This specification should be based on your \nknowledge of the expected system inputs. For example, if a surname is to be input, \nyou might specify that all characters must be alphabetic with no numbers or punc-\ntuation (apart from a hyphen) allowed. You might also limit the length of the name. \nFor example, no one has a family name with more than 40 characters, and no \naddresses are more than 100 characters long. If a numeric value is expected, no \nalphabetic characters should be allowed. This information is then used in input \nchecks when the system is implemented.\n\t\n\t Guideline 8: Compartmentalize your assets\nCompartmentalizing means that you should not provide users with access to all \ninformation in a system. Based on a general \u201cneed to know\u201d security principle, you \nshould organize the information in a system into compartments. Users should only \nhave access to the information that they need for their work, rather than to all of the \ninformation in a system. This means that the effects of an attack that compromises \nan individual user account may be contained. Some information may be lost or dam-\naged, but it is unlikely that all of the information in the system will be affected.\nFor example, the Mentcare system could be designed so that clinic staff will nor-\nmally only have access to the records of patients who have an appointment at their \nclinic. They should not normally have access to all patient records in the system. Not \nonly does this limit the potential loss from insider attacks, but it also means that if an \nintruder steals their credentials, then they cannot damage all patient records.\nHaving said this, you also may have to have mechanisms in the system to grant \nunexpected access\u2014say to a patient who is seriously ill and requires urgent treat-\nment without an appointment. In those circumstances, you might use some alterna-\ntive secure mechanism to override the compartmentalization in the system. In such \nsituations, where security is relaxed to maintain system availability, it is essential \nthat you use a logging mechanism to record system usage. You can then check the \nlogs to trace any unauthorized use.\n\t\n\t Guideline 9: Design for deployment\nMany security problems arise because the system is not configured correctly when it \nis deployed in its operational environment. Deployment means installing the software \n\t\n13.4\u2002 \u25a0\u2002 Secure systems design\u2002 \u2002 399\n", "page": 400, "type": "text", "section": "Page 400"}
{"text": "400\u2002 \u2002 Chapter 13\u2002 \u25a0\u2002 Security engineering\non the computers where it will execute and setting software parameters to reflect the \nexecution environment and the preferences of the system user. Mistakes such as \nforgetting to turn off debugging facilities or forgetting to change the default admin-\nistration password can introduce vulnerabilities into a system.\nGood management practice can avoid many security problems that arise from \nconfiguration and deployment mistakes. However, software designers have the \nresponsibility to \u201cdesign for deployment.\u201d You should always provide support for \ndeployment that reduces the chances of users and system administrators making \nmistakes when configuring the software.\nI recommend four ways to incorporate deployment support in a system:\n1.\t\nInclude support for viewing and analyzing configurations You should always \ninclude facilities in a system that allow administrators or permitted users to \nexamine the current configuration of the system.\n2.\t\nMinimize default privileges You should design software so that the default con-\nfiguration of a system provides minimum essential privileges.\n3.\t\nLocalize configuration settings When designing system configuration support, \nyou should ensure that everything in a configuration that affects the same part of \na system is set up in the same place.\n4.\t\nProvide easy ways to fix security vulnerabilities You should include straightfor-\nward mechanisms for updating the system to repair security vulnerabilities that \nhave been discovered.\nDeployment issues are less of a problem than they used to be as more and more \nsoftware does not require client installation. Rather, the software runs as a service \nand is accessed through a web browser. However, server software is still vulnerable \nto deployment errors and omissions, and some types of system require dedicated \nsoftware running on the user\u2019s computer.\n\t\n\t Guideline 10: Design for recovery\nIrrespective of how much effort you put into maintaining systems security, you \nshould always design your system with the assumption that a security failure could \noccur. Therefore, you should think about how to recover from possible failures and \nrestore the system to a secure operational state. For example, you may include a \nbackup authentication system in case your password authentication is compromised.\nFor example, say an unauthorized person from outside the clinic gains access to \nthe Mentcare system and you don\u2019t know how that person obtained a valid login/\npassword combination. You need to re-initialize the authentication system and not \njust change the credentials used by the intruder. This is essential because the intruder \nmay also have gained access to other user passwords. You need, therefore, to ensure \nthat all authorized users change their passwords. You also must ensure that the unau-\nthorized person does not have access to the password-changing mechanism.\n", "page": 401, "type": "text", "section": "Page 401"}
{"text": "You therefore have to design your system to deny access to everyone until they \nhave changed their password and to email all users asking them to make the \nchange. You need an alternative mechanism to authenticate real users for password \nchange, assuming that their chosen passwords may not be secure. One way of \ndoing this is to use a challenge/response mechanism, where users have to answer \nquestions for which they have pre-registered answers. This is only invoked when \npasswords are changed, allowing for recovery from the attack with relatively little \nuser disruption.\nDesigning for recoverability is an essential element of building resilience into \nsystems. I cover this topic in more detail in Chapter 14.\n\t\n13.4.4\t Secure systems programming\nSecure system design means designing security into an application system. However, \nas well as focusing on security at the design level, it is also important to consider security \nwhen programming a software system. Many successful attacks on software rely on \nprogram vulnerabilities that were introduced when the program was developed.\nThe first widely known attack on Internet-based systems happened in 1988 when \na worm was introduced into Unix systems across the network (Spafford 1989). This \ntook advantage of a well-known programming vulnerability. If systems are pro-\ngrammed in C, there is no automatic array bound checking. An attacker can include \na long string with program commands as an input, and this overwrites the program \nstack and can cause control to be transferred to malicious code. This vulnerability \nhas been exploited in many other systems programmed in C or C++ since then.\nThis example illustrates two important aspects of secure systems programming:\n1.\t\nVulnerabilities are often language-specific. Array bound checking is automatic \nin languages such as Java, so this is not a vulnerability that can be exploited in \nJava programs. However, millions of programs are written in C and C++ as \nthese allow for the development of more efficient software. Thus. simply avoid-\ning the use of these languages is not a realistic option.\n2.\t\nSecurity vulnerabilities are closely related to program reliability. The above \nexample caused the program concerned to crash, so actions taken to improve \nprogram reliability can also improve system security.\nIn Chapter 11, I introduced programming guidelines for dependable system pro-\ngramming. These  are shown in Figure 13.16. These guidelines also help improve \nthe security of a program as attackers focus on program vulnerabilities to gain access \nto a system. For example, an SQL poisoning attack is based on the attacker filling in \na form with SQL commands rather than the text expected by the system. These can \ncorrupt the database or release confidential information. You can completely avoid \nthis problem if you implement input checks (Guideline 2) based on the expected \nformat and structure of the inputs.\n\t\n13.4\u2002 \u25a0\u2002 Secure systems design\u2002 \u2002 401\n", "page": 402, "type": "text", "section": "Page 402"}
{"text": "402\u2002 \u2002 Chapter 13\u2002 \u25a0\u2002 Security engineering\n \n13.5 Security testing and assurance\nThe assessment of system security is increasingly important so that we can be confi-\ndent that the systems we use are secure. The verification and validation processes for \nweb-based systems should therefore focus on security assessment, where the ability of \nthe system to resist different types of attack is tested. However, as Anderson explains \n(Anderson 2008), this type of security assessment is very difficult to carry out. \nConsequently, systems are often deployed with security loopholes. Attackers use these \nvulnerabilities to gain access to the system or to cause damage to the system or its data.\nFundamentally, security testing is difficult for two reasons:\n1.\t\nSecurity requirements, like some safety requirements, are \u201cshall not\u201d require-\nments. That is, they specify what should not happen rather than system func-\ntionality or required behavior. It is not usually possible to define this unwanted \nbehavior as simple constraints to be checked by the system.\n\t\nIf resources are available, you can demonstrate, in principle at least, that a sys-\ntem meets its functional requirements. However, it is impossible to prove that a \nsystem does not do something. Irrespective of the amount of testing, security \nvulnerabilities may remain in a system after it has been deployed.\n\t\nYou may, of course, generate functional requirements that are designed to guard \nthe system against some known types of attack. However, you cannot derive \nrequirements for unknown or unanticipated types of attack. Even in systems that \nhave been in use for many years, an ingenious attacker can discover a new \nattack and can penetrate what was thought to be a secure system.\n2.\t\nThe people attacking a system are intelligent and are actively looking for vul-\nnerabilities that they can exploit. They are willing to experiment with the system \nand to try things that are far outside normal activity and system use. For exam-\nple, in a surname field they may enter 1000 characters with a mixture of letters, \npunctuation, and numbers simply to see how the system responds.\n\t\nOnce they find a vulnerability, they publicize it and so increase the number of \npossible attackers. Internet forums have been set up to exchange information \nabout system vulnerabilities. There is also a thriving market in malware where \nFigure 13.16\u2002  \nDependable \nprogramming  \nguidelines\nDependable programming guidelines\n1.\t Limit the visibility of information in a program.\n2.\t Check all inputs for validity.\n3.\t Provide a handler for all exceptions.\n4.\t Minimize the use of error-prone constructs.\n5.\t Provide restart capabilities.\n6.\t Check array bounds.\n7.\t Include timeouts when calling external components.\n8.\t Name all constants that represent real-world values.\n", "page": 403, "type": "text", "section": "Page 403"}
{"text": "attackers can get access to kits that help them easily develop malware such as \nworms and keystroke loggers.\nAttackers may try to discover the assumptions made by system developers and \nthen challenge these assumptions to see what happens. They are in a position to use \nand explore a system over a period of time and analyze it using software tools to \ndiscover vulnerabilities that they may be able to exploit. They may, in fact, have \nmore time to spend on looking for vulnerabilities than system test engineers, as test-\ners must also focus on testing the system.\nYou may use a combination of testing, tool-based analysis, and formal verifica-\ntion to check and analyze the security of an application system:\n1.\t\nExperience-based testing In this case, the system is analyzed against types of \nattack that are known to the validation team. This may involve developing test \ncases or examining the source code of a system. For example, to check that the \nsystem is not susceptible to the well-known SQL poisoning attack, you might \ntest the system using inputs that include SQL commands. To check that buffer \noverflow errors will not occur, you can examine all input buffers to see if the \nprogram is checking that assignments to buffer elements are within bounds.\n\t\nChecklists of known security problems may be created to assist with the process. \nFigure 13.17 gives some examples of questions that might be used to drive \nexperience-based testing. Checks on whether design and programming \n\u00ad\nguidelines for security have been followed may also be included in a security \n\u00ad\nproblem checklist.\n2.\t\nPenetration testing This is a form of experience-based testing where it is possible \nto draw on experience from outside the development team to test an application \nsystem. The penetration testing teams are given the objective of breaching the \nsystem security. They simulate attacks on the system and use their ingenuity to \ndiscover new ways to compromise the system security. Penetration testing team \nFigure 13.17\u2002 Examples \nof entries in a security \nchecklist\nSecurity checklist\n1. \u2002 \u0007\nDo all files that are created in the application have appropriate access permissions? The wrong access permis-\nsions may lead to these files being accessed by unauthorized users.\n2. \u2002 \u0007\nDoes the system automatically terminate user sessions after a period of inactivity? Sessions that are left \nactive may allow unauthorized access through an unattended computer.\n3. \u0007\n\u2002 \u0007\nIf the system is written in a programming language without array bound checking, are there situations \nwhere buffer overflow may be exploited? Buffer overflow may allow attackers to send code strings to the \nsystem and then execute them.\n4. \u0007\n\u2002 \u0007\nIf passwords are set, does the system check that passwords are \u201cstrong\u201d? Strong passwords consist of \nmixed letters, numbers, and punctuation, and are not normal dictionary entries. They are more difficult to \nbreak than simple passwords.\n5. \u0007\n\u2002 \u0007\nAre inputs from the system\u2019s environment always checked against an input specification? Incorrect process-\ning of badly formed inputs is a common cause of security vulnerabilities.\n\t\n13.5\u2002 \u25a0\u2002 Security testing and assurance\u2002 \u2002 403\n", "page": 404, "type": "text", "section": "Page 404"}
{"text": "404\u2002 \u2002 Chapter 13\u2002 \u25a0\u2002 Security engineering\nmembers should have \u00ad\nprevious experience with security testing and finding \nsecurity weaknesses in systems.\n3.\t\nTool-based analysis In this approach, security tools such as password checkers \nare used to analyze the system. Password checkers detect insecure passwords \nsuch as common names or strings of consecutive letters. This approach is really \nan extension of experience-based validation, where experience of security flaws \nis embodied in the tools used. Static analysis is, of course, another type of tool-\nbased analysis, which has become increasingly used.\n\t\nTool-based static analysis (Chapter 12) is a particularly useful approach to secu-\nrity checking. A static analysis of a program can quickly guide the testing team \nto areas of a program that may include errors and vulnerabilities. Anomalies \nrevealed in the static analysis can be directly fixed or can help identify tests that \nneed to be done to reveal whether or not these anomalies actually represent a \nrisk to the system. Microsoft uses static analysis routinely to check its software \nfor possible security vulnerabilities (Jenney 2013). Hewlett-Packard offers a \ntool called Fortify (Hewlett-Packard 2012) specifically designed for checking \nJava programs for security vulnerabilities.\n4.\t\nFormal verification I have discussed the use of formal program verification in \nChapters 10 and 12. Essentially, this involves making formal, mathematical \narguments that demonstrate that a program conforms to its specification. Hall \nand Chapman (Hall and Chapman 2002) demonstrated the feasibility of proving \nthat a system met its formal security requirements more than 10 years ago, and \nthere have been a number of other experiments since then. However, as in other \nareas, formal verification for security is not widely used. It requires specialist \nexpertise and is unlikely to be as cost-effective as static analysis.\nSecurity testing takes a long time, and, usually, the time available to the testing \nteam is limited. This means that you should adopt a risk-based approach to security \ntesting and focus on what you think are the most significant risks faced by the sys-\ntem. If you have an analysis of the security risks to the system, these can be used to \ndrive the testing process. As well as testing the system against the security require-\nments derived from these risks, the test team should also try to break the system by \nadopting alternative approaches that threaten the system assets.\nKey Points\n\u25a0\t Security engineering focuses on how to develop and maintain software systems that can resist \nmalicious attacks intended to damage a computer-based system or its data.\n\u25a0\t Security threats can be threats to the confidentiality, integrity, or availability of a system or its\u00a0data.\n", "page": 405, "type": "text", "section": "Page 405"}
{"text": "\u25a0\t Security risk management involves assessing the losses that might ensue from attacks on a  \nsystem, and deriving security requirements that are aimed at eliminating or reducing  \nthese losses.\n\u25a0\t To specify security requirements, you should identify the assets that are to be protected and \ndefine how security techniques and technology should be used to protect these assets.\n\u25a0\t Key issues when designing a secure systems architecture include organizing the system struc-\nture to protect key assets and distributing the system assets to minimize the losses from a suc-\ncessful attack.\n\u25a0\t Security design guidelines sensitize system designers to security issues that they may not have \nconsidered. They provide a basis for creating security review checklists.\n\u25a0\t Security validation is difficult because security requirements state what should not happen in a \nsystem, rather than what should. Furthermore, system attackers are intelligent and may have \nmore time to probe for weaknesses than is available for security testing.\nFurther Reading\nSecurity Engineering: A Guide to Building Dependable Distributed Systems, 2nd ed. This is a thor-\nough and comprehensive discussion of the problems of building secure systems. The focus is on \nsystems rather than software engineering, with extensive coverage of hardware and networking, \nwith excellent examples drawn from real system failures. (R. Anderson, John Wiley & Sons, 2008) \nhttp://www.cl.cam.ac.uk/~rja14/book.html\n24 Deadly Sins of Software Security: Programming Flaws and How to Fix Them. I think this is one of \nthe best practical books on secure systems programming. The authors discuss the most common \nprogramming vulnerabilities and describe how they can be avoided in practice. (M. Howard, D. LeB-\nlanc, and J. Viega, McGraw-Hill, 2009).\nComputer Security: Principles and Practice. This is a good general text on computer security issues. \nIt covers security technology, trusted systems, security management, and cryptography. (W. Stallings \nand L. Brown, Addison-Wesley, 2012).\nWebsite\nPowerPoint slides for this chapter:\nwww.pearsonglobaleditions.com/Sommerville\nLinks to supporting videos:\nhttp://software-engineering-book.com/videos/security-and-resilience/\n\t\nChapter 13\u2002 \u25a0\u2002 Website\u2002 \u2002 405\n", "page": 406, "type": "text", "section": "Page 406"}
{"text": "Exercises\n\u2002 13.1. \u200a\n\u200a\n\u200a\n\u200a\n\u0007\nDescribe the security dimensions and security levels that have to be considered in secure \nsystems engineering.\n\u2002 13.2. \u200a\n\u200a\n\u200a\n\u200a\n\u0007\nFor the Mentcare system, suggest an example of an asset, an exposure, a vulnerability, an \nattack, a threat, and a control, in addition to those discussed in this chapter.\n\u2002 13.3. \u200a\n\u200a\n\u200a\n\u200a\n\u0007\nExplain why security is considered a more challenging problem than safety in a system.\n\u2002 13.4. \u200a\n\u200a\n\u200a\n\u200a\n\u0007\nExtend the table in Figure 13.7 to identify two further threats to the Mentcare system, along \nwith associated controls. Use these as a basis for generating software security requirements \nthat implement the proposed controls.\n\u2002 13.5. \u200a\n\u200a\n\u200a\n\u200a\n\u0007\nExplain, using an analogy drawn from a non-software engineering context, why a layered \napproach to asset protection should be used.\n\u2002 13.6. \u200a\n\u200a\n\u200a\n\u200a\n\u0007\nExplain why it is important to log user actions in the development of secure systems.\n\u2002 13.7. \u200a\n\u200a\n\u200a\n\u200a\n\u0007\nFor the equity trading system discussed in Section 13.4.2, whose architecture is shown in \nFigure 13.14, suggest two further plausible attacks on the system and propose possible strat-\negies that could counter these attacks.\n\u2002 13.8. \u200a\n\u200a\n\u200a\n\u200a\n\u0007\nExplain why it is important when writing secure systems to validate all user inputs to check \nthat these have the expected format.\n\u2002 13.9. \u200a\n\u200a\n\u200a\n\u200a\n\u200a\n\u0007\nSuggest how you would go about validating a password protection system for an application \nthat you have developed. Explain the function of any tools that you think may be useful.\n13.10. \u200a\n\u200a\n\u200a\n\u200a\n\u200a\n\u0007\nThe Mentcare system has to be secure against attacks that might reveal confidential patient \ninformation. Suggest three possible attacks against this system that might occur. Using this \ninformation, extend the checklist in Figure 13.17 to guide testers of the Mentcare system.\nReferences\nAnderson, R. 2008. Security Engineering, 2nd ed. Chichester, UK: John Wiley & Sons.\nCranor, L. and S. Garfinkel. 2005. Designing Secure Systems That People Can Use. Sebastopol, CA: \nO\u2019Reilly Media Inc.\nFiresmith, D. G. 2003. \u201cEngineering Security Requirements.\u201d Journal of Object Technology 2 (1): \n53\u201368. http://www.jot.fm/issues/issue_2003_01/column6\nHall, A., and R. Chapman. 2002. \u201cCorrectness by Construction: Developing a Commercially Secure \nSystem.\u201d IEEE Software 19 (1): 18\u201325. doi:10.1109/52.976937.\nHewlett-Packard. 2012. \u201cSecuring Your Enterprise Software: Hp Fortify Code Analyzer.\u201d http://\nh20195.www2.hp.com/V2/GetDocument.aspx?docname=4AA4-2455ENW&cc=us&lc=en\n406\u2002 \u2002 Chapter 13\u2002 \u25a0\u2002 Security engineering\n", "page": 407, "type": "text", "section": "Page 407"}
{"text": "Jenney, P. 2013. \u201cStatic Analysis Strategies: Success with Code Scanning.\u201d http://msdn.microsoft \n.com/en-us/security/gg615593.aspx\nLane, A. 2010. \u201cAgile Development and Security.\u201d https://securosis.com/blog/agile-development-\nand-security\nPfleeger, C. P., and S. L. Pfleeger. 2007. Security in Computing, 4th ed. Boston: Addison-Wesley.\nSafecode. 2012. \u201cPractical Security Stories and Security Tasks for Agile Development Environ-\nments.\u201d http://www.safecode.org/publications/SAFECode_Agile_Dev_Security0712.pdf\nSchneier, B. 1999. \u201cAttack Trees.\u201d Dr Dobbs Journal 24 (12): 1\u20139. https://www.schneier.com/paper-\nattacktrees-ddj-ft.html\n\t\n\u2002 \u2002 . 2000. Secrets and Lies: Digital Security in a Networked World. New York: John Wiley & Sons.\nSchoenfield, B. 2013. \u201cAgile and Security: Enemies for Life?\u201d http://brookschoenfield.com/?p=151\nSindre, G., and A. L. Opdahl. 2005. \u201cEliciting Security Requirements through Misuse Cases.\u201d \nRequirements Engineering 10 (1): 34\u201344. doi:10.1007/s00766-004-0194-4.\nSpafford, E. 1989. \u201cThe Internet Worm: Crisis and Aftermath.\u201d Comm ACM 32 (6): 678\u2013687. \ndoi:10.1145/63526.63527.\nStallings, W., and L. Brown. 2012. Computer Security: Principles, d Practice. (2nd ed.) Boston: \n\u00ad\nAddison-Wesley.\nViega, J., and G. McGraw. 2001. Building Secure Software. Boston: Addison-Wesley.\nWheeler, D. A. 2004. Secure Programming for Linux and Unix. Self-published. http://www.dwheeler \n.com/secure-programs/\n\t\nChapter 13\u2002 \u25a0\u2002 References\u2002 \u2002 407\n", "page": 408, "type": "text", "section": "Page 408"}
{"text": "Contents\n14.1\t Cybersecurity\n14.2\t Sociotechnical resilience\n14.3\t Resilient systems design\nObjectives\nThe objective of this chapter is to introduce the idea of resilience \nengineering where systems are designed to withstand adverse \nexternal events such as operator errors and cyberattacks. When you \nhave read this chapter, you will:\n\u25a0\t understand the differences between resilience, reliability, and \nsecurity and why resilience is important for networked systems;\n\u25a0\t be aware of the fundamental issues in building resilient systems, \nnamely, recognition of problems, resistance to failures and \nattacks, recovery of critical services, and system reinstatement;\n\u25a0\t understand why resilience is a sociotechnical rather than a \ntechnical issue and the role of system operators and managers in \nproviding resilience;\n\u25a0\t have been introduced to a system design method that supports \nresilience.\n14 \nResilience engineering\n", "page": 409, "type": "text", "section": "Page 409"}
{"text": " \nChapter 14\u2002 \u25a0\u2002 Resilience engineering\u2002 \u2002 409\nIn April 1970, the Apollo 13 manned mission to the moon suffered a catastrophic \nfailure. An oxygen tank exploded in space, resulting in a serious loss of atmospheric \noxygen and oxygen for the fuel cells that powered the spacecraft. The situation was \nlife threatening, with no possibility of rescue. There were no contingency plans for \nthis situation. However, by using equipment in unintended ways and by adapting \nstandard procedures, the combined efforts of the spacecraft crew and ground staff \nworked around the problems. The spacecraft was brought back to earth safely, and \nall the crew survived. The overall system (people, equipment, and processes) was \nresilient. It adapted to cope with and recover from the failure.\nI introduced the idea of resilience in Chapter 10, as one of the fundamental \n\u00ad\nattributes of system dependability. I defined resilience in Chapter 10 as: \nThe resilience of a system is a judgment of how well that system can maintain \nthe continuity of its critical services in the presence of disruptive events, such \nas equipment failure and cyberattacks.\nThis is not a \u201cstandard\u201d definition of resilience\u2014different authors such as Laprie \n(Laprie 2008) and Hollnagel (Hollnagel 2006) propose general definitions based on \nthe ability of a system to withstand change. That is, a resilient system is one that can \noperate successfully when some of the fundamental assumptions made by the \u00ad\nsystem \ndesigners no longer hold.\nFor example, an initial design assumption may be that users will make mistakes \nbut will not deliberately seek out system vulnerabilities to be exploited. If the system \nis used in an environment where it may be subject to cyberattacks, this is no longer \ntrue. A resilient system can cope with the environmental change and can continue to \noperate successfully.\nWhile these definitions are more general, my definition of resilience is closer to \nhow the term is now used in practice by governments and industry. It embeds three \nessential ideas:\n1.\t\nThe idea that some of the services offered by a system are critical services \nwhose failure could have serious human, social, or economic effects.\n2.\t\nThe idea that some events are disruptive and can affect the ability of a system to \ndeliver its critical services.\n3.\t\nThe idea that resilience is a judgment\u2014there are no resilience metrics, and \n\u00ad\nresilience cannot be measured. The resilience of a system can only be assessed \nby experts, who can examine the system and its operational processes.\nFundamental work on system resilience started in the safety-critical systems \n\u00ad\ncommunity, where the aim was to understand what factors led to accidents being avoided \nand survived. However, the increasing number of cyberattacks on \u00ad\nnetworked systems has \nmeant that resilience is now often seen as a security issue. It is essential to build systems \nthat can withstand malicious cyberattacks and continue to deliver services to their users.\n", "page": 410, "type": "text", "section": "Page 410"}
{"text": "410\u2002 \u2002 Chapter 14\u2002 \u25a0\u2002 Resilience engineering\nObviously, resilience engineering is closely related to reliability and security \nengineering. The aim of reliability engineering is to ensure that systems do not fail. \nA system failure is an externally observable event, which is often a consequence of \na fault in the system. Therefore, techniques such as fault avoidance and fault toler-\nance, as discussed in Chapter 11, have been developed to reduce the number of sys-\ntem faults and to trap faults before they lead to system failure.\nIn spite of our best efforts, faults will always be present in a large, complex sys-\ntem, and they may lead to system failure. Delivery schedules are short, and testing \nbudgets are limited. Development teams are working under pressure, and it is practi-\ncally impossible to detect all of the faults and security vulnerabilities in a software \nsystem. We are building systems that are so complex (see Chapter 19) that we cannot \npossibly understand all of the interactions between the system components. Some of \nthese interactions may be a trigger for overall system failure.\nResilience engineering does not focus on avoiding failure but rather on accepting \nthe reality that failures will occur. It makes two important assumptions:\n1.\t\nResilience engineering assumes that it is impossible to avoid system failures and \nso is concerned with limiting the costs of these failures and recovering from them.\n2.\t\nResilience engineering assumes that good reliability engineering practices have \nbeen used to minimize the number of technical faults in a system. It therefore \nplaces more emphasis on limiting the number of system failures that arise from \nexternal events such as operator errors or cyberattacks.\nIn practice, technical system failures are often triggered by events that are \u00ad\nexternal \nto\u00a0the system. These events may involve operator actions or user errors that are unex-\npected. Over the last few years, however, as the number of networked systems has \nincreased, these events have often been cyberattacks. In a cyberattack, a \u00ad\nmalicious \n\u00ad\nperson or group tries to damage the system or to steal confidential information. These are \nnow more significant than user or operator errors as a potential source of system failure.\nBecause of the assumption that failures will inevitably occur, resilience engineer-\ning is concerned with both the immediate recovery from failure to maintain critical \n\u00ad\nservices and the longer-term reinstatement of all system services. As I discuss in \nSection 14.3, this means that system designers have to include system features to \nmaintain the state of the system\u2019s software and data. In the event of a failure, \u00ad\nessential \ninformation may then be restored.\nFour related resilience activities are involved in the detection of and recovery \nfrom system problems:\n1.\t\nRecognition The system or its operators should be able to recognize the symp-\ntoms of a problem that may lead to system failure. Ideally, this recognition \nshould be possible before the failure occurs.\n2.\t\nResistance If the symptoms of a problem or signs of a cyberattack are detected \nearly, then resistance strategies may be invoked that reduce the probability that the \nsystem will fail. These resistance strategies may focus on isolating critical parts of \nthe system so that they are unaffected by problems elsewhere. Resistance includes \n", "page": 411, "type": "text", "section": "Page 411"}
{"text": " \nChapter 14\u2002 \u25a0\u2002 Resilience engineering\u2002 \u2002 411\nproactive resistance where defenses are included in a system to trap problems and \nreactive resistance where actions are taken when a problem is discovered.\n3.\t\nRecovery If a failure occurs, the aim of the recovery activity is to ensure that \ncritical system services are restored quickly so that system users are not seri-\nously affected by the failure.\n4.\t\nReinstatement In this final activity, all of the system services are restored, and \nnormal system operation can continue.\nThese activities lead to changes to the system state as shown in Figure 14.1, \nwhich shows the state changes in the system in the event of a cyberattack. In parallel \nwith normal system operation, the system monitors network traffic for possible \ncyberattacks. In the event of a cyberattack, the system moves to a resistance state in \nwhich normal services may be restricted.\nIf resistance successfully repels the attack, normal service is resumed. Otherwise, the \nsystem moves to a recovery state where only critical services are available. Repairs to the \ndamage caused by the cyberattack are carried out. Finally, when repairs are complete, \nthe system moves to a reinstatement state. In this state, the system\u2019s services are incre-\nmentally restored. Finally, when all restoration is complete, normal service is resumed.\nAs the Apollo 13 example illustrates, resilience cannot be \u201cprogrammed in\u201d to a \nsystem. It is impossible to anticipate everything that might go wrong and every con-\ntext where problems might arise. The key to resilience, therefore, is flexibility and \nadaptability. As I discuss in Section 14.2, it should be possible for system operators \nand managers to take actions to protect and repair the system, even if these actions \nare abnormal or are normally disallowed.\nIncreasing the resilience of a system of course has significant costs. Software \nmay have to be purchased or modified, and additional investments made in hardware \nor cloud services to provide backup systems that can be used in the event of a system \nfailure. The benefits from these costs are impossible to calculate because the losses \nfrom a failure or attack can only be calculated after the event.\nCompanies may therefore be reluctant to invest in resilience if they have never \nsuffered a serious attack or associated loss. However, the increasing number of \nRecognition\nNormal operating\nstate\nAttack\nrecognition\nResistance\nRecovery\nReinstatement\nCritical service\ndelivery\nCritical service\ndelivery\nAttack\nresistance\nSystem\nrepair\nSoftware and data\nrestoration\nRestricted service\ndelivery\nReinstatement complete\nAttack\ndetected\nAttack\nsuccessful\nRepair\ncomplete\nAttack repelled\nFigure 14.1\u2002 Resilience \nactivities \n", "page": 412, "type": "text", "section": "Page 412"}
{"text": "412\u2002 \u2002 Chapter 14\u2002 \u25a0\u2002 Resilience engineering\n\u00ad\nhigh-profile cyberattacks that have damaged business and government systems have \nincreased awareness of the need for resilience. It is clear that losses can be very \n\u00ad\nsignificant, and sometimes businesses may not survive a successful cyberattack. \nTherefore, there is increasing investment in resilience engineering to reduce the \nbusiness risks associated with system failure.\n \n14.1 Cybersecurity\nMaintaining the security of our networked infrastructure and government, business, \nand personal computer systems is one of the most significant problems facing our \nsociety. The ubiquity of the Internet and our dependence on computer systems have \ncreated new criminal opportunities for theft and social disruption. It is very difficult \nto measure the losses due to cybercrime. However, in 2013, it was estimated that \nlosses to the global economy due to cybercrime were between $100 billion and $500 \nbillion (InfoSecurity 2013).\nAs I suggested in Chapter 13, cybersecurity  is a broader issue than system security \nengineering. Software security engineering is a primarily technical activity that focuses \non techniques and technologies to ensure that application systems are secure. \nCybersecurity is a sociotechnical concern. It covers all aspects of ensuring the protection \nof citizens, businesses, and critical infrastructures from threats that arise from their use \nof computers and the Internet. While technical issues are important, technology on its \nown cannot guarantee security. Factors that contribute to cybersecurity failures include:\n\u25a0\t organizational ignorance of the seriousness of the problem,\n\u25a0\t poor design and lax application of security procedures,\n\u25a0\t human carelessness, and\n\u25a0\t inappropriate trade-offs between usability and security.\nCybersecurity is concerned with all of an organization\u2019s IT assets from networks \nthrough to application systems. The vast majority of these assets are externally procured, \nand companies do not understand their detailed operation. Systems such as web brows-\ners are large and complex programs, and inevitably they contain bugs that can be a \nsource of vulnerability. The different systems in an organization are related to each other \nin many different ways. They may be stored on the same disk, share data, rely on com-\nmon operating systems components, and so on. The organizational \u201csystem of systems\u201d \nis incredibly complex. It is impossible to ensure that it is free of security vulnerabilities.\nConsequently, you should generally assume that your systems are vulnerable to \ncyberattack and that, at some stage, a cyberattack is likely to occur. A successful \ncyberattack can have very serious financial consequences for businesses, so it is \nessential that attacks are contained and losses minimized. Effective resilience engi-\nneering at the organizational and systems levels can repel attacks and bring systems \nback into operation quickly and so limit the losses incurred.\n", "page": 413, "type": "text", "section": "Page 413"}
{"text": " \n14.1\u2002 \u25a0\u2002 Cybersecurity\u2002 \u2002 413\nIn Chapter 13, where I discussed security engineering, I introduced concepts that \nare fundamental to resilience planning. Some of these concepts are:\n1.\t\nAssets, which are systems and data that have to be protected. Some assets are \nmore valuable than others and so require a higher level of protection.\n2.\t\nThreats, which are circumstances that can cause harm by damaging or stealing \norganizational IT infrastructure or system assets.\n3.\t\nAttacks, which are manifestations of a threat where an attacker aims to damage \nor steal IT assets, such as websites or personal data.\nThree types of threats have to be considered in resilience planning:\n1.\t\nThreats to the confidentiality of assets In this case, data is not damaged, but it is \nmade available to people who should not have access to it. An example of a \nthreat to confidentiality is when a credit card database held by a company is \nstolen, with the potential for illegal use of card information.\n2.\t\nThreats to the integrity of assets These are threats where systems or data are \ndamaged in some way by a cyberattack. This may involve introducing a virus or \na worm into software or corrupting organizational databases.\n3.\t\nThreats to the availability of assets These are threats that aim to deny use of \nassets by authorized users. The best-known example is a denial-of-service attack \nthat aims to take down a website and so make it unavailable for external use.\nThese are not independent threat classes. An attacker may compromise the integ-\nrity of a user\u2019s system by introducing malware, such as a botnet component. This \nmay then be invoked remotely as part of a distributed denial-of-service attack on \nanother system. Other types of malware may be used to capture personal details and \nso allow confidential assets to be accessed.\nTo counter these threats, organizations should put controls in place that make it \ndifficult for attackers to access or damage assets. It is also important to raise aware-\nness of cybersecurity issues so that people know why these controls are important \nand so are less likely to reveal information to an attacker.\nExamples of controls that may be used are:\n1.\t\nAuthentication, where users of a system have to show that they are authorized to \naccess the system. The familiar login/password approach to authentication is a \nuniversally used but rather weak control.\n2.\t\nEncryption, where data is algorithmically scrambled so that an unauthorized \nreader cannot access the information. Many companies now require that laptop \ndisks are encrypted. If the computer is lost or stolen, this reduces the likelihood \nthat the confidentiality of the information will be breached.\n3.\t\nFirewalls, where incoming network packets are examined, then accepted or \nrejected according to a set of organizational rules. Firewalls can be used to \n", "page": 414, "type": "text", "section": "Page 414"}
{"text": "414\u2002 \u2002 Chapter 14\u2002 \u25a0\u2002 Resilience engineering\nensure that only traffic from trusted sources is allowed to pass from the external \nInternet into the local organizational network.\nA set of controls in an organization provides a layered protection system. An \nattacker has to get through all of the protection layers for the attack to succeed. \nHowever, there is a trade-off between protection and efficiency. As the number of \nlayers of protection increases, the system slows down. The protection systems con-\nsume an increasing amount of memory and processor resources, leaving less availa-\nble to do useful work. The more security, the more inconvenient it is for\u00a0users and \nthe more likely that they will adopt insecure practices to increase system usability.\nAs with other aspects of system dependability, the fundamental means of protect-\ning against cyberattacks depends on redundancy and diversity. Recall that redun-\ndancy means having spare capacity and duplicated resources in a system. Diversity \nmeans that different types of equipment, software, and procedures are used so that \ncommon failures are less likely to occur across a number of systems. Examples of \nwhere redundancy and diversity are valuable for cyber-resilience are:\n1.\t\nFor each system, copies of data and software should be maintained on separate \ncomputer systems. Shared disks should be avoided if possible. This supports \nrecovery after a successful cyberattack (recovery and reinstatement).\n2.\t\nMulti-stage diverse authentication can protect against password attacks. As well \nas login/password authentication, additional authentication steps may be \ninvolved that require users to provide some personal information or a code gen-\nerated by their mobile device (resistance).\n3.\t\nCritical servers may be overprovisioned; that is, they may be more powerful \nthan is required to handle their expected load. The spare capacity means that \nattacks may be resisted without necessarily degrading the normal response of \nthe server. Furthermore, if other servers are damaged, spare capacity is available \nto run their software while they are being repaired (resistance and recovery).\nPlanning for cybersecurity has to be based on assets and controls and the 4 Rs of resil-\nience engineering\u2014recognition, resistance, recovery, and reinstatement. Figure 14.2 \nshows a planning process that may be followed. The key stages in this process are:\n1.\t\nAsset classification The organization\u2019s hardware, software, and human assets \nare examined and classified depending on how essential they are to normal \noperations. They may be classed as critical, important, or useful.\n2.\t\nThreat identification For each of the assets (or at least the critical and important \nassets), you should identify and classify threats to that asset. In some cases, you \nmay try to estimate the probability that a threat will arise, but such estimates are \noften inaccurate as you don\u2019t have enough information about potential attackers.\n3.\t\nThreat recognition For each threat or, sometimes asset/threat pair, you should \nidentify how an attack based on that threat might be recognized. You may \n", "page": 415, "type": "text", "section": "Page 415"}
{"text": " \n14.1\u2002 \u25a0\u2002 Cybersecurity\u2002 \u2002 415\ndecide that additional software needs to be bought or written for threat recogni-\ntion or that regular checking procedures are put in place.\n4.\t\nThreat resistance For each threat or asset/threat pair, you should identify possi-\nble resistance strategies. These either may be embedded in the system (technical \nstrategies) or may rely on operational procedures. You may also need to think of \nthreat neutralization strategies so that the threat does not recur.\n5.\t\nAsset recovery For each critical asset or asset/threat pair, you should work out \nhow that asset could be recovered in the event of a successful cyberattack. This \nmay involve making extra hardware available or changing backup procedures to \nmake it easier to access redundant copies of data.\n6.\t\nAsset reinstatement This is a more general process of asset recovery where you \ndefine procedures to bring the system back into normal operation. Asset rein-\nstatement should be concerned with all assets and not simply assets that are \ncritical to the organization.\nInformation about all of these stages should be maintained in a cyber-resilience \nplan. This plan should be regularly updated, and, wherever possible, the strategies \nidentified should be tested in mock attacks on the system.\nAnother important part of cyber-resilience planning is to decide how to support a flex-\nible response in the event of a cyberattack. Paradoxically, resilience and security \n\u00ad\nrequirements often conflict. The aim of security is usually to limit privilege as far as pos-\nsible so that users can only do what the security policy of the organization allows. \nHowever, to deal with problems, a user or system operator may have to take the initiative \nand take actions that are normally carried out by someone with a higher level of privilege.\nFor example, the system manager of a medical system may not normally be \nallowed to change the access rights of medical staff to records. For security reasons, \naccess permissions have to be formally authorized, and two people need to be \ninvolved in making the change. This reduces the chances of system managers col-\nluding with attackers and allowing access to confidential medical information.\nNow, imagine that the system manager notices that a logged-in user is accessing \na large number of records outside of normal working hours. The manager suspects \nThreat\nrecognition\n Cyber-resilience plan\nInterface\ndevelopment \nIntegration and\ndeployment \nAsset\nclassification\nThreat\nidentification\nThreat\nresistance\nInterface\ndevelopment \nIntegration and\ndeployment \nAsset\nrecovery\nAsset \nreinstatement\nFigure 14.2\u2002 Cyber-\nresilience planning \n", "page": 416, "type": "text", "section": "Page 416"}
{"text": "416\u2002 \u2002 Chapter 14\u2002 \u25a0\u2002 Resilience engineering\nthat an account has been compromised and that the user accessing the records is not \nactually the authorized user. To limit the damage, the user\u2019s access rights should be \nremoved and a check then made with the authorized user to see if the accesses were \nactually illegal. However, the security procedures limiting the rights of system man-\nagers to change users\u2019 permissions make this impossible.\nResilience planning should take such situations into account. One way of doing \nso is to include an \u201cemergency\u201d mode in systems where normal checks are ignored. \nRather than forbidding operations, the system logs what has been done and who was \nresponsible. Therefore, the audit trail of emergency actions can be used to check that \na system manager\u2019s actions were justified. Of course, there is scope for misuse here, \nand the existence of an emergency mode is itself a potential vulnerability. Therefore, \norganizations have to trade off possible losses against the benefits of adding more \nfeatures to a system to support resilience.\n \n14.2 Sociotechnical resilience\nFundamentally, resilience engineering is a sociotechnical rather than a technical \nactivity. As I explained in Chapter 10, a sociotechnical system includes hardware, \nsoftware, and people and is influenced by the culture, policies, and procedures of the \norganization that owns and uses the system. To design a resilient system, you have to \nthink about sociotechnical systems design and not exclusively focus on software. \nResilience engineering is concerned with adverse external events that can lead to \nsystem failure. Dealing with these events is often easier and more effective in the \nbroader sociotechnical system.\nFor example, the Mentcare system maintains confidential patient data, and a possible \nexternal cyberattack may aim to steal that data. Technical safeguards such as authentica-\ntion and encryption may be used to protect the data, but these are not effective if an \nattacker has access to the credentials of a genuine system user. You could try to solve \nthis problem at the technical level by using more complex authentication procedures. \nHowever, these procedures annoy users and may lead to vulnerabilities as they write \ndown authentication information. A better strategy may be to introduce organizational \npolicies and procedures that emphasize the importance of not sharing login credentials \nand that tell users about easy ways to create and maintain strong passwords.\nResilient systems are flexible and adaptable so that they can cope with the unex-\npected. It is very difficult to create software that can adapt to cope with problems \nthat have not been anticipated. However, as we saw from the Apollo 13 accident, \npeople are very good at this. Therefore, to achieve resilience, you should take advan-\ntage of the fact that people are an inherent part of sociotechnical systems. Rather \nthan try to anticipate and deal with all problems in software, you should leave some \ntypes of problem solving to the people responsible for operating and managing the \nsoftware system.\nTo understand why you should leave some types of problem solving to people, \nyou have to consider the hierarchy of sociotechnical systems that includes technical, \nsoftware-intensive systems. Figure 14.3 shows that technical systems S1 and S2 are \n", "page": 417, "type": "text", "section": "Page 417"}
{"text": " \n14.2\u2002 \u25a0\u2002 Sociotechnical resilience\u2002 \u2002 417\npart of a broader sociotechnical system ST1. That sociotechnical system includes \noperators who monitor the condition of S1 and S2 and who can take actions to \nresolve problems in these systems. If system S1 (say) fails, then the operators in \nST1 may detect that failure and take recovery actions before the software failure \nleads to failure in the broader sociotechnical system. Operators may also invoke \nrecovery and reinstatement procedures to get S1 back to its normal operating state.\nOperational and management processes are the interface between the organiza-\ntion and the technical systems that are used. If these processes are well designed, \nthey allow people to discover and to cope with technical system failures, as well as \nensuring that operator errors are minimized. As I discuss in Section 14.2.2, rigid \nprocesses that are overautomated are not inherently resilient. They do not allow peo-\nple to use their skills and knowledge to adapt and change processes to cope with the \nunexpected and deal with unanticipated failures.\nThe system ST1 is one of a number of sociotechnical systems in the organization. \nIf the system operators cannot contain a technical system failure, then this may lead \nto a failure in the sociotechnical system ST1. Managers at the organizational level \nthen must detect the problem and take steps to recover from it. Resilience is there-\nfore an organizational as well as a system characteristic.\nHollnagel (Hollnagel 2010), who was an early advocate of resilience engineer-\ning, argues that it is important for organizations to study and learn from successes as \nwell as failure. High-profile safety and security failures lead to inquiries and changes \nin practice and procedures. However, rather than respond to these failures, it is \n\u00ad\nbetter to avoid them by observing how people deal with problems and maintain \nresilience. This good practice can then be disseminated throughout the organization. \nFigure 14.4 shows four characteristics that Hollnagel suggests reflect the resilience \nof an organization. These characteristics are:\n1.\t\nThe ability to respond Organizations have to be able to adapt their processes and \nprocedures in response to risks. These risks may be anticipated risks, or they \nmay be detected threats to the organization and its systems. For example, if a \nnew security threat is detected and publicized, a resilient organization can make \nchanges quickly so that this threat does not disrupt its operations.\n2.\t\nThe ability to monitor Organizations should monitor both their internal \n\u00ad\noperations and their external environment for threats before they arise. For \nexample, a company should monitor how its employees follow security policies. \nS2\nS1\nST1\nOrganization\nFailure\nFailure\nOperators\nManagers\nFigure 14.3\u2002 Nested \ntechnical and \nsociotechnical systems \n", "page": 418, "type": "text", "section": "Page 418"}
{"text": "418\u2002 \u2002 Chapter 14\u2002 \u25a0\u2002 Resilience engineering\nLearning from experience\nResponding to threats \nand vulnerabilities\nAnticipating future\nthreats and \nopportunities\nMonitoring the\norganization and\nenvironment\nFigure 14.4\u2002  \nCharacteristics of \nresilient organizations \nIf potentially insecure behavior is detected, the company should respond by \u00ad\ntaking \nactions to understand why this has occurred and to change employee behavior.\n3.\t\nThe ability to anticipate A resilient organization should not simply focus on its \ncurrent operations but should anticipate possible future events and changes that \nmay affect its operations and resilience. These events may include technological \ninnovations, changes in regulations or laws, and modifications in customer \nbehavior. For example, wearable technology is starting to become available, \nand companies should now be thinking about how this might affect their current \nsecurity policies and procedures.\n4.\t\nThe ability to learn Organizational resilience can be improved by learning from \nexperience. It is particularly important to learn from successful responses to \nadverse events such as the effective resistance of a cyberattack. Learning from \nsuccess allows good practice to be disseminated throughout the organization.\nAs Hollnagel says, to become resilient organizations have to address all of these \nissues to some extent. Some will focus more on one quality than others. For exam-\nple, a company running a large-scale data center may focus mostly on monitoring \nand responsiveness. However, a digital library that manages long-term archival \ninformation may have to anticipate how future changes may affect its business as \nwell as respond to any immediate security threats.\n\t\n14.2.1\t Human error\nEarly work on resilience engineering was concerned with accidents in safety- \ncritical systems and with how the behavior of human operators could lead to safety-\nrelated system failures. This led to an understanding of system defenses that is \nequally applicable to systems that have to withstand malicious as well as accidental \nhuman actions.\nWe know that people make mistakes, and, unless a system is completely automated, \nit is inevitable that users and system operators will sometimes do the wrong thing. \nUnfortunately, these human errors sometimes lead to serious system \u00ad\nfailures. Reason \n(Reason, 2000) suggests that the problem of human error can be viewed in two ways:\n1.\t The person approach Errors are considered to be the responsibility of the indi-\nvidual and \u201cunsafe acts\u201d (such as an operator failing to engage a safety barrier) \n", "page": 419, "type": "text", "section": "Page 419"}
{"text": " \n14.2\u2002 \u25a0\u2002 Sociotechnical resilience\u2002 \u2002 419\nare a consequence of individual carelessness or reckless behavior. People who \nadopt this approach believe that human errors can be reduced by threats of \n\u00ad\ndisciplinary action, more stringent procedures, retraining, and so on. Their view \nis that the error is the fault of the individual responsible for making the mistake.\n2.\t\nThe systems approach The basic assumption is that people are fallible and will make \nmistakes. People make mistakes because they are under pressure from high work-\nloads, because of poor training, or because of inappropriate system design. Good \nsystems should recognize the possibility of human error and include barriers and \nsafeguards that detect human errors and allow the system to recover before failure \noccurs. When a failure does occur, the best way to avoid its recurrence is to understand \nhow and why the system defenses did not trap the error. Blaming and punishing the \nperson who triggered the failure does not improve long-term system safety.\nI believe that the systems approach is the right one and that systems engineers \nshould assume that human errors will occur during system operation. Therefore, to \nimprove the resilience of a system, designers have to think about the defenses and \nbarriers to human error that could be part of a system. They should also think about \nwhether these barriers should be built into the technical components of the system. \nIf not, they could be part of the processes, procedures, and guidelines for using the \nsystem. For example, two operators may be required to check critical system inputs.\nThe barriers and safeguards that protect against human errors may be technical or \nsociotechnical. For example, code to validate all inputs is a technical defense; an approval \nprocedure for critical system updates that needs two people to confirm the update is a \nsociotechnical defense. Using diverse barriers means that shared vulnerabilities are less \nlikely and that a user error is more likely to be trapped before system failure.\nIn general, you should use redundancy and diversity to create a set of defensive \nlayers (Figure 14.5), where each layer uses a different approach to deter attackers or \nto trap component failures or human errors. Dark blue barriers are software checks; \nlight blue barriers are checks carried out by people.\nAs an example of this approach to defense in depth, some of the checks for con-\ntroller errors that may be part of an air traffic control system include:\n1.\t\nA conflict alert warning as part of an air traffic control system When a control-\nler instructs an aircraft to change its speed or altitude, the system extrapolates its \ntrajectory to see if it intersects with any other aircraft. If so, it sounds an alarm.\n2.\t\nFormalized recording procedures for air traffic management The same ATC \nsystem may have a clearly defined procedure setting out how to record the con-\ntrol instructions that have been issued to aircraft. These procedures help control-\nlers check if they have issued the instruction correctly and make the information \nvisible to others for checking.\n3.\t\nCollaborative checking Air traffic control involves a team of controllers who \nconstantly monitor each other\u2019s work. When a controller makes a mistake, oth-\ners usually detect and correct it before an incident occurs.\n", "page": 420, "type": "text", "section": "Page 420"}
{"text": "420\u2002 \u2002 Chapter 14\u2002 \u25a0\u2002 Resilience engineering\nReason (Reason 2000) draws on the idea of defensive layers in a theory of how \nhuman errors lead to system failures. He introduces the so-called Swiss cheese \nmodel, which suggests that defensive layers are not solid barriers but are instead like \nslices of Swiss cheese. Some types of Swiss cheese, such as Emmenthal, have holes \nof varying sizes in them. Reason suggests that vulnerabilities, or what he calls latent \nconditions in the layers, are analogous to these holes.\nThese latent conditions are not static\u2014they change depending on the state of the \nsystem and the people involved in system operation. To continue with the analogy, \nthe holes change size and move around the defensive layers during \u00ad\nsystem operation. \nFor example, if a system relies on operators checking each \u00ad\nother\u2019s work, a possible \nvulnerability is that both make the same mistake. This is unlikely under normal con-\nditions so, in the Swiss cheese model, the hole is small. However, when the system \nis heavily loaded and the workload of both operators is high, then mistakes are more \nlikely. The size of the hole representing this vulnerability increases.\nFailure in a system with layered defenses occurs when there is some external trig-\nger event that has the potential to cause damage. This event might be a human error \n(which Reason calls an active failure) or it could be a cyberattack. If all of the defen-\nsive barriers fail, then the system as a whole will fail. Conceptually, this corresponds \nto the holes in the Swiss cheese slices lining up, as shown in Figure 14.6.\nThis model suggests that different strategies can be used to increase system resil-\nience to adverse external events:\n1.\t\nReduce the probability of the occurrence of an external event that might trigger \n\u00ad\nsystem failures. To reduce human errors, you may introduce improved training for \noperators or give operators more control over their workload so that they are not \noverloaded. To reduce cyberattacks, you may reduce the number of people who have \nprivileged system information and so reduce the chances of disclosure to an attacker.\n2.\t Increase the number of defensive layers. As a general rule, the more layers that \nyou have in a system, the less likely it is that the holes will line up and a system \nfailure will occur. However, if these layers are not independent, then they may \nshare a common vulnerability. Thus, the barriers are likely to have the same \n\u201chole\u201d in the same place, so there is only a limited benefit in adding a new layer.\nSociotechnical defenses\nTechnical defenses\nErrors or\nattacks\nFigure 14.5\u2002 Defensive \nlayers \n", "page": 421, "type": "text", "section": "Page 421"}
{"text": " \n14.2\u2002 \u25a0\u2002 Sociotechnical resilience\u2002 \u2002 421\n3.\t\nDesign a system so that diverse types of barriers are included. This means that \nthe \u201choles\u201d will probably be in different places, and so there is less chance of the \nholes lining up and failing to trap an error.\n4.\t\nMinimize the number of latent conditions in a system. Effectively, this means \nreducing the number and size of system \u201choles.\u201d However, this may significantly \nincrease systems engineering costs. Reducing the number of bugs in the system \nincreases testing and V & V costs. Therefore, this option may not be cost-effective.\nIn designing a system, you need to consider all of these options and make choices \nabout what might be the most cost-effective ways to improve the system\u2019s defenses. \nIf you are building custom software, then using software checking to increase the \nnumber and diversity of layers may be the best option. However, if you are using \noff-the-shelf software, then you may have to consider how sociotechnical defenses \nmay be added. You may decide to change training procedures to reduce the chances \nof problems occurring and to make it easier to deal with incidents when they arise.\n\t\n14.2.2\t Operational and management processes\nAll software systems have associated operational processes that reflect the assump-\ntions of the designers about how these systems will be used. Some software systems, \nparticularly those that control or are interfaced to special equipment, have trained \noperators who are an intrinsic part of the control system. Decisions are made during \nthe design stage about which functions should be part of the technical system and \nwhich functions should be the operator\u2019s responsibility. For example, in an imaging \nsystem in a hospital, the operator may have the responsibility of checking the quality \nof the images immediately after they have been processed. This check allows the \nimaging procedure to be repeated if there is a problem.\nOperational processes are the processes that are involved in using the system for \nits defined purpose. For example, operators of an air traffic control system follow \nspecific processes when aircraft enter and leave airspace, when they have to change \nheight or speed, when an emergency occurs, and so on. For new systems, these oper-\national processes have to be defined and documented during the system develop-\nment process. Operators may have to be trained and other work processes adapted to \nmake effective use of the new system.\nSystem failure\nActive failure\n(Human error)\nLatent conditions in defensive layers\nFigure 14.6\u2002 Reason\u2019s \nSwiss cheese model of \nsystem failure \n", "page": 422, "type": "text", "section": "Page 422"}
{"text": "422\u2002 \u2002 Chapter 14\u2002 \u25a0\u2002 Resilience engineering\nMost software systems, however, do not have trained operators but have system \nusers, who use the system as part of their work or to support their personal interests. \nFor personal systems, the designers may describe the expected use of the system but \nhave no control over how users will actually behave. For enterprise IT systems, how-\never, training may be provided for users to teach them how to use the system. \nAlthough user behavior cannot be controlled, it is reasonable to expect that they will \nnormally follow the defined process.\nEnterprise IT systems will also usually have system administrators or managers \nwho are responsible for maintaining that system. While they are not part of the busi-\nness process supported by the system, their job is to monitor the software system for \nerrors and problems. If problems arise, system managers take action to resolve them \nand restore the system to its normal operational state.\nIn the previous section, I discussed the importance of defense in depth and the use \nof diverse mechanisms to check for adverse events that could lead to system failure. \nOperational and management processes are an important defense mechanism, and, \nin designing a process, you need to find a balance between efficient operation and \nproblem management. These are often in conflict as shown in Figure 14.7 as increas-\ning efficiency removes redundancy and diversity from a system.\nOver the past 25 years, businesses have focused on so-called process improve-\nment. To improve the efficiency of operational and management processes, compa-\nnies study how their processes are enacted and look for particularly efficient and \ninefficient practice. Efficient practice is codified and documented, and software may \nbe developed to support this \u201coptimum\u201d process. Inefficient practice is replaced by \nmore efficient ways of doing things. Sometimes process control mechanisms are \nintroduced to ensure that system operators and managers follow this \u201cbest practice.\u201d\nThe problem with process improvement is that it often makes it harder for people to \ncope with problems. What seems to be \u201cinefficient\u201d practice often arises because people \nmaintain redundant information or share information because they know this makes it \neasier to deal with problems when things go wrong. For example, air traffic controllers \nmay print flight details as well as rely on the flight database because they will then have \ninformation about flights in the air if the system database becomes unavailable.\nPeople have a unique capability to respond effectively to unexpected situations, \neven when they have never had direct experience of these situations. Therefore, \nwhen things go wrong, operators and system managers can often recover the situa-\ntion, although they may sometimes have to break rules and \u201cwork around\u201d the \ndefined process. You should therefore design operational processes to be flexible \nand adaptable. The operational processes should not be too constraining; they should \nnot require operations to be done in a particular order; and the system software \nshould not rely on a specific process being followed.\nFor example, an emergency service control room system is used to manage emer-\ngency calls and to initiate a response to these calls. The \u201cnormal\u201d process of han-\ndling a call is to log the caller\u2019s details and then send a message to the appropriate \nemergency service giving details of the incident and the address. This procedure \nprovides an audit trail of the actions taken. A subsequent investigation can check \nthat the emergency call has been properly handled.\n", "page": 423, "type": "text", "section": "Page 423"}
{"text": " \n14.2\u2002 \u25a0\u2002 Sociotechnical resilience\u2002 \u2002 423\nNow imagine that this system is subject to a denial-of-service attack, which makes \nthe messaging system unavailable. Rather than simply not responding to calls, the oper-\nators may use their personal mobile phones and their knowledge of call responders to \ncall the emergency service units directly so that they can respond to serious incidents.\nManagement and provision of information are also important for resilient operation. \nTo make a process more efficient, it may make sense to present operators with the \ninformation they need, when they need it. From a security perspective, information \nshould not be accessible unless the operator or manager needs that information. \nHowever, a more liberal approach to information access can improve system resilience.\nIf operators are only presented with information that the process designer thinks \nthey \u201cneed to know,\u201d then they may be unable to detect problems that do not directly \naffect their immediate tasks. When things go wrong, the system operators do not \nhave a broad picture of what is happening in the system, so it is more difficult for \nthem to formulate strategies for dealing with problems. If they cannot access some \ninformation in the system for security reasons, then they may be unable to stop \nattacks and repair the damage that has been caused.\nAutomating the system management process means that a single manager may be \nable to manage a large number of systems. Automated systems can detect common \nproblems and take actions to recover from these problems. Fewer people are needed \nfor system operations and management, and so costs are reduced. However, process \nautomation has two disadvantages:\n1.\t\nAutomated management systems may go wrong and take incorrect actions. As \nproblems develop, the system may take unexpected actions that make the situa-\ntion worse and that cannot be understood by the system managers.\n2.\t\nProblem solving is a collaborative process. If fewer managers are available, it is \nlikely to take longer to work out a strategy to recover from a problem or cyberattack.\nTherefore, process automation can have both positive and negative effects on \nsystem resilience. If the automated system works properly, it can detect problems, \ninvoke cyberattack resistance if necessary, and start automated recovery procedures. \nHowever, if the automated system can\u2019t handle the problem, fewer people will be \navailable to tackle the problem and the system may have been damaged by the pro-\ncess automation doing the wrong thing.\nIn an environment where there are different types of system and equipment, it \nmay be impractical to expect all operators and managers to be able to deal with all of \nEfficient process operation\nProblem management\nProcess optimization and control\nProcess flexibility and adaptability\nInformation hiding and security\nInformation sharing and visibility\nAutomation to reduce operator workload with fewer \noperators and managers\nManual processes and spare operator/manager \ncapacity to deal with problems\nRole specialization\nRole sharing\nFigure 14.7\u2002 Efficiency \nand resilience\n", "page": 424, "type": "text", "section": "Page 424"}
{"text": "424\u2002 \u2002 Chapter 14\u2002 \u25a0\u2002 Resilience engineering\nthe different systems. Individuals may therefore specialize so that they become \nexpert and knowledgeable about a small number of systems. This leads to more effi-\ncient operation but has consequences for the resilience of the system.\nThe problem with role specialization is that there may not be anyone available at \na particular time who understands the interactions between systems. Consequently, \nit is difficult to cope with problems if the specialist is not available. If people work \nwith several systems, they come to understand the dependencies and relationships \nbetween them and so can tackle problems that affect more than one system. With no \nspecialist available, it becomes much more difficult to contain the problem and \nrepair any damage that has been caused.\nYou may use risk assessment, as discussed in Chapter 13, to help make decisions \non the balance between process efficiency and resilience. You consider all of the \nrisks where operator or manager intervention may be required and assess the likeli-\nhood of these risks and the extent of the possible losses that might arise. For risks \nthat may lead to serious damage and extensive loss and for risks that are likely to \noccur, you should favor resilience over process efficiency.\n \n14.3 Resilient systems design\nResilient systems can resist and recover from adverse incidents such as software \nfailures and cyberattacks. They can deliver critical services with minimal interrup-\ntions and can quickly return to their normal operating state after an incident has \noccurred. In designing a resilient system, you have to assume that system failures or \npenetration by an attacker will occur, and you have to include redundant and diverse \nfeatures to cope with these adverse events.\nDesigning systems for resilience involves two closely related streams of work:\n1.\t\nIdentifying critical services and assets Critical services and assets are those ele-\nments of the system that allow a system to fulfill its primary purpose. For exam-\nple, the primary purpose of a system that handles ambulance dispatch in \nresponse to emergency calls is to get help to people who need it as quickly as \npossible. The critical services are those concerned with taking calls and dis-\npatching ambulances to the medical emergency. Other services such as call log-\nging and ambulance tracking are less important.\n2.\t\nDesigning system components that support problem recognition, resistance, \nrecovery, and reinstatement For example, in an ambulance dispatch system, a \nwatchdog timer (see Chapter 12) may be included to detect if the system is not \nresponding to events. Operators may have to authenticate with a hardware token \nto resist the possibility of unauthorized access. If the system fails, calls may be \ndiverted to another center so that the essential services are maintained. Copies \nof the system database and software on alternative hardware may be maintained \nto allow for reinstatement after an outage.\n", "page": 425, "type": "text", "section": "Page 425"}
{"text": " \n14.3\u2002 \u25a0\u2002 Resilient systems design\u2002 \u2002 425\nThe fundamental notions of recognition, resistance, and recovery were the basis \nof early work in resilience engineering by Ellison et al. (Ellison et al. 1999, 2002). \nThey designed a method of analysis called survivable systems analysis. This method \nis used to assess vulnerabilities in systems and to support the design of system archi-\ntectures and features that promote system survivability.\nSurvivable systems analysis is a four-stage process (Figure 14.8) that analyzes \nthe current or proposed system requirements and architecture, identifies critical ser-\nvices, attack scenarios, and system \u201csoftspots,\u201d and proposes changes to improve the \nsurvivability of a system. The key activities in each of these stages are as follows:\n1.\t\nSystem understanding For an existing or proposed system, review the goals of \nthe system (sometimes called the mission objectives), the system requirements, \nand the system architecture.\n2.\t\nCritical service identification The services that must always be maintained and \nthe components that are required to maintain these services are identified.\n3.\t\nAttack simulation Scenarios or use cases for possible attacks are identified, \nalong with the system components that would be affected by these attacks.\n4.\t\nSurvivability analysis Components that are both essential and compromisable \nby an attack are identified, and survivability strategies based on resistance, rec-\nognition, and recovery are identified.\nThe fundamental problem with this approach to survivability analysis is that its \nstarting point is the requirements and architecture documentation for a system. This \nis a reasonable assumption for defense systems (the work was sponsored by the U.S. \nDepartment of Defense), but it poses two problems for business systems:\n1.\t\nIt is not explicitly related to the business requirements for resilience. I believe that \nthese are a more appropriate starting point than technical system requirements.\n1. Review system\nrequirements and\narchitecture\n2. Identify critical services\nand components\n3. Identify attacks and\ncompromisable\ncomponents\n4. Identify softspots and\nsurvivability strategies\nFigure 14.8\u2002 Stages in \nsurvivability analysis \n", "page": 426, "type": "text", "section": "Page 426"}
{"text": "426\u2002 \u2002 Chapter 14\u2002 \u25a0\u2002 Resilience engineering\nIdentify business \nresilience \nrequirements\nIdentify critical\nservices\nPlan backup\nstrategy\nTest system\nreinstatement\nPlan system\nreinstatement\nIdentify assets \nthat deliver \ncritical services\nIdentify events\nthat compromise \nassets\nPlan event\nrecognition and \nresistance\nPropose software \nchanges\nBuy new software\nrequired\nPlan critical\nservice recovery\nPlan critical\nasset recovery\nDevelop software \nto support \nasset recovery\nDesign asset\nredundancy\nstrategy\nResilience test\nplanning\nIdentify attack\nand failure \nscenarios\nTest service \nrecovery\nTest system\nresistance\nDevelop software\nto support\nreinstatement\nReinstatement\nRecognition and\nresistance\nRecovery\nTesting\nFigure 14.9\u2002  \nResilience engineering \n2.\t\nIt assumes that there is a detailed requirements statement for a system. In fact, \nresilience may have to be \u201cretrofitted\u201d to a system where there is no complete or \nup-to-date requirements document. For new systems, resilience may itself be a \nrequirement, or systems may be developed using an agile approach. The system \narchitecture may be designed to take resilience into account.\nA more general resilience engineering method, as shown in Figure 14.9, takes the \nlack of detailed requirements into account as well as explicitly designing recovery \nand reinstatement into the system. For the majority of components in a system, you \nwill not have access to their source code and will not be able to make changes to \nthem. Your strategy for resilience has to be designed with this limitation in mind.\nThere are five interrelated streams of work in this approach to resilience engineering:\n1.\t\nYou identify business resilience requirements. These requirements set out how \nthe business as a whole must maintain the services that it delivers to customers \nand, from this, resilience requirements for individual systems are developed. \nProviding resilience is expensive, and it is important not to overengineer sys-\ntems with unnecessary resilience support.\n2.\t\nYou plan how to reinstate a system or a set of systems to their normal operating \nstate after an adverse event. This plan has to be integrated with the business\u2019s \n", "page": 427, "type": "text", "section": "Page 427"}
{"text": " \n14.3\u2002 \u25a0\u2002 Resilient systems design\u2002 \u2002 427\nnormal backup and archiving strategy that allows recovery of information after \na technical or human error. It should also be part of a wider disaster recovery \nstrategy. You have to take account of the possibility of physical events such as \nfire and flooding and study how to maintain critical information in separate \nlocations. You may decide to use cloud backups for this plan.\n3.\t\nYou identify system failures and cyberattacks that can compromise a system, and \nyou design recognition and resilience strategies to cope with these adverse events.\n4.\t\nYou plan how to recover critical services quickly after they have been damaged \nor taken offline by a failure or cyberattack. This step usually involves providing \nredundant copies of the critical assets that provide these services and switching \nto these copies when required.\n5.\t\nCritically, you should test all aspects of your resilience planning. This testing \ninvolves identifying failure and attack scenarios and playing these scenarios out \nagainst your system.\nMaintaining the availability of critical services is the essence of resilience. \nAccordingly, you have to know:\n\u25a0\t the system services that are the most critical for a business,\n\u25a0\t the minimal quality of service that must be maintained,\n\u25a0\t how these services might be compromised,\n\u25a0\t how these services can be protected, and\n\u25a0\t how you can recover quickly if the services become unavailable.\nAs part of the analysis of critical services, you have to identify the system assets \nthat are essential for delivering these services. These assets may be hardware (serv-\ners, network, etc.), software, data, and people. To build a resilient system, you have \nto think about how to use redundancy and diversity to ensure that these assets remain \navailable in the event of a system failure.\nFor all of these activities, the key to providing a rapid response and recovery plan \nafter an adverse event is to have additional software that supports resistance, recov-\nery, and reinstatement. This may be commercial security software or resilience sup-\nport that is programmed into application systems. It may also include scripts and \nspecially written programs that are developed for recovery and \u00ad\nreinstatement. If you \nhave the right support software, the processes of recovery and reinstatement can be \npartially automated and quickly invoked and executed after a system failure.\nResilience testing involves simulating possible system failures and cyberattacks to \ntest whether the resilience plans that have been drawn up work as expected. Testing \nis essential because we know from experience that the assumptions made in resil-\nience planning are often invalid and that planned actions do not always work. Testing \nfor resilience can reveal these problems so that the resilience plan can be refined.\n", "page": 428, "type": "text", "section": "Page 428"}
{"text": "428\u2002 \u2002 Chapter 14\u2002 \u25a0\u2002 Resilience engineering\nTesting can be very difficult and expensive as, obviously, the testing cannot be carried \nout on an operational system. The system and its environment may have to be duplicated \nfor testing, and staff may have to be released from their normal responsibilities to work \non the test system. To reduce costs, you can use \u201cdesk testing.\u201d The testing team assumes \na problem has occurred and tests their reactions to it; they do not simulate that problem \non a real system. While this approach can provide useful information about system resil-\nience, it is less effective than testing in discovering deficiencies in the resilience plan.\nAs an example of this approach, let us look at resilience engineering for the \nMentcare system. To recap, this system is used to support clinicians treating patients \nin a variety of locations who have mental health problems. It provides patient infor-\nmation and records of consultations with doctors and specialist nurses. It includes a \nnumber of checks that can flag patients who may be potentially dangerous or sui-\ncidal. Figure 14.10 shows the architecture of this system.\nThe system is consulted by doctors and nurses before and during a consultation, \nand patient information is updated after the consultation. To ensure the effectiveness \nof clinics, the business resilience requirements are that the critical system services \nare available during normal working hours, that the patient data should not be per-\nmanently damaged or lost by a system failure or cyberattack, and that patient infor-\nmation should not be released to unauthorized people.\nTwo critical services in the system have to be maintained:\n1.\t\nAn information service that provides information about a patient\u2019s current diag-\nnosis and treatment plan.\n2.\t\nA warning service that highlights patients who could pose a danger to others or \nto themselves.\nNotice that the critical service is not the availability of the complete patient \nrecord. Doctors and nurses only need to go back to previous treatments occasionally, \nMentcare\nclient\nMentcare server\nPatient database\nMentcare\nclient\nMentcare\nclient\nNetwork\nFigure 14.10\u2002 The \nclient\u2013server architecture \nof the Mentcare system \n", "page": 429, "type": "text", "section": "Page 429"}
{"text": " \n14.3\u2002 \u25a0\u2002 Resilient systems design\u2002 \u2002 429\nso clinical care is not seriously affected if a full record is not available. Therefore, it \nis possible to deliver effective care using a summary record that only includes infor-\nmation about the patient and recent treatment.\nThe assets required to deliver these services in normal system operations are:\n1.\t\nThe patient record database that maintains all patient information.\n2.\t\nA database server that provides access to the database for local client computers.\n3.\t\nA network for client/server communications.\n4.\t\nLocal laptop or desktop computers used by clinicians to access patient information.\n5.\t\nA set of rules that identify patients who are potentially dangerous and that can\u00a0flag \npatient records. Client software highlights dangerous patients to \u00ad\nsystem users.\nTo plan recognition, resistance, and recovery strategies, you need to develop a set \nof scenarios that anticipate adverse events that might compromise the critical ser-\nvices offered by the system. Examples of these adverse events are:\n1.\t\nThe unavailability of the database server either through a system failure, a \n\u00ad\nnetwork failure, or a denial-of-service cyberattack.\n2.\t\nThe deliberate or accidental corruption of the patient record database or the \nrules that define what is meant by a \u201cdangerous patient.\u201d\n3.\t\nInfection of client computers with malware.\n4.\t\nAccess to client computers by unauthorized people who gain access to patient records.\nFigure 14.11 shows possible recognition and resistance strategies for these \nadverse events. Notice that these are not just technical approaches but also include \nworkshops to inform system users about security issues. We know that many secu-\nrity breaches arise because users inadvertently reveal privileged information to an \nattacker and these workshops reduce the chances of this happening. I don\u2019t have \nspace here to discuss all of the options that I identified in Figure 14.11. Instead, I \nfocus on how the system architecture can be modified to be more resilient.\nIn Figure 14.11, I suggested that maintaining patient information on client com-\nputers was a possible redundancy strategy that could help maintain critical services. \nThis leads to the modified software architecture shown in Figure 14.12. The key \nfeatures of this architecture are:\n1.\t\nSummary patient records that are maintained on local client computers The \nlocal computers can communicate directly with each other and exchange infor-\nmation using either the system network or, if necessary, an ad hoc network cre-\nated using mobile phones. Therefore, if the database is unavailable, doctors and \nnurses can still access essential patient information. (resistance and recovery)\n2.\t\nA backup server to allow for main server failure This server is responsible for \ntaking regular snapshots of the database as backups. In the event the main server \n", "page": 430, "type": "text", "section": "Page 430"}
{"text": "430\u2002 \u2002 Chapter 14\u2002 \u25a0\u2002 Resilience engineering\nfails, it can also act as the main server for the whole system. This provides con-\ntinuity of service and recovery after a server failure (resistance and recovery).\n3.\t\nDatabase integrity checking and recovery software Integrity checking runs as a \nbackground task checking for signs of database corruption. If corruption is dis-\ncovered, it can automatically initiate the recovery of some or all of the data from \nbackups. The transaction log allows these backups to be updated with details of \nrecent changes (recognition and recovery).\nTo maintain the key services of patient information access and staff warning, we \ncan make use of the inherent redundancy in a client-server system. By downloading \ninformation to the client at the start of a clinic session, the consultation can continue \nwithout server access. Only the information about the patients who are scheduled to \nattend consultations that day needs to be downloaded. If there is a need to access \nother patient information and the server is unavailable, then other client computers \nmay be contacted using peer-to-peer communication to see if the information is \navailable on them.\nThe service that provides a warning to staff of patients who may be dangerous \ncan easily be implemented using this approach. The records of patients who may \nharm themselves or others are identified before the download process. When clinical \nstaff access these records, the software can highlight the records to indicate the \npatients that require special care.\nFigure 14.11\u2002  \nRecognition and \nresistance strategies  \nfor adverse events \nEvent\nRecognition\nResistance\nServer \nunavailability\n1. \u0007\nWatchdog timer on client \nthat times out if no response \nto client access\n2. \u0007\nText messages from system \nmanagers to clinical users\n1. \u0007\nDesign system architecture to maintain local \ncopies of critical information\n2. \u0007\nProvide peer-to-peer search across clients for \npatient data\n3. \u0007\nProvide staff with smartphones that can be \nused to access the network in the event of \nserver failure\n4. Provide backup server\nPatient database \ncorruption\n1. \u0007\nRecord level cryptographic \nchecksums\n2. \u0007\nRegular auto-checking of \ndatabase integrity\n3. \u0007\nReporting system for \nincorrect information\n1. \u0007\nReplayable transaction log to update database \nbackup with recent transactions\n2. \u0007\nMaintenance of local copies of patient \ninformation and software to restore database \nfrom local copies and backups\nMalware \ninfection of \nclient computers\n1. \u0007\nReporting system so that \ncomputer users can report \nunusual behavior\n2. \u0007\nAutomated malware checks \non startup\n1. \u0007\nSecurity awareness workshops for all system users\n2. \u0007\nDisabling of USB ports on client computers\n3. Automated system setup for new clients\n4. Support access to system from mobile devices\n5. Installation of security software\nUnauthorized \naccess to patient \ninformation\n1. \u0007\nWarning text messages from \nusers about possible intruders\n2. \u0007\nLog analysis for unusual \nactivity\n1. Multilevel system authentication process\n2. Disabling of USB ports on client computers\n3. Access logging and real-time log analysis\n4. \u0007\nSecurity awareness workshops for all system users\n", "page": 431, "type": "text", "section": "Page 431"}
{"text": " \n14.3\u2002 \u25a0\u2002 Resilient systems design\u2002 \u2002 431\nThe features in this architecture that support the resistance to adverse events are \nalso useful in supporting recovery from these events. By maintaining multiple copies \nof information and having backup hardware available, critical system services can \nbe quickly restored to normal operation. Because the system need only be available \nduring normal working hours (say, 8 a.m to 6 p.m), the system can be reinstated \novernight so that it is available for the following day after a failure.\nAs well as maintaining critical services, the other business requirements of main-\ntaining the confidentiality and integrity of patient data must also be supported. The \narchitecture shown in Figure 14.12 includes a backup system and explicit database \nintegrity checking to reduce the chances that patient information is damaged acci-\ndentally or in a malicious attack. Information on client computers is also available \nand can be used to support recovery from data corruption or damage.\nWhile maintaining multiple copies of data is a safeguard against data corruption, \nit poses a risk to confidentiality as all of these copies have to be secured. In this case, \nthis risk can be controlled by:\n1.\t\nOnly downloading the summary records of patients who are scheduled to attend \na clinic. This limits the number of records that could be compromised.\n2.\t\nEncrypting the disk on local client computers. Attackers who do not have the \nencryption key cannot read the disk if they gain access to the computer.\n3.\t\nSecurely deleting the downloaded information at the end of a clinic session. This \nfurther reduces the chances of an attacker gaining access to confidential information.\nMentcare\nclient\nMentcare server\nPatient database\nMentcare\nclient\nMentcare\nclient\nNetwork\nSummary\npatient records\nSummary\npatient records\nSummary\npatient records\nBackup server\nDatabase \nintegrity\nchecker\nTransaction\nlog\nDatabase backup\nFigure 14.12\u2002 An \narchitecture for \nMentcare system \nresilience \n", "page": 432, "type": "text", "section": "Page 432"}
{"text": "432\u2002 \u2002 Chapter 14\u2002 \u25a0\u2002 Resilience engineering\n4.\t\nEnsuring that all network transactions are encrypted. If an attacker intercepts \nthese transactions, they cannot get access to the information.\nBecause of performance degradation, it is probably impractical to encrypt the entire \npatient database on the server. Strong authentication should therefore be used to \nprotect this information.\nKey Points\n\u25a0 The resilience of a system is a judgment of how well that system can maintain the continuity of its \ncritical services in the presence of disruptive events, such as equipment failure and cyberattacks.\n\u25a0 Resilience should be based on the 4 Rs model\u2014recognition, resistance, recovery, and reinstatement.\n\u25a0 Resilience planning should be based on the assumption that networked systems will be subject to \ncyberattacks by malicious insiders and outsiders and that some of these attacks will be successful.\n\u25a0 Systems should be designed with a number of defensive layers of different types. If these layers \nare effective, human and technical failures can be trapped and cyberattacks resisted.\n\u25a0 To allow system operators and managers to cope with problems, processes should be flexible \nand adaptable. Process automation can make it more difficult for people to cope with problems.\n\u25a0 Business resilience requirements should be the starting point for designing systems for resil-\nience. To achieve system resilience, you have to focus on recognition and recovery from prob-\nlems, recovery of critical services and assets, and reinstatement of the system.\n\u25a0 An important part of design for resilience is identifying critical services, which are those services \nthat are essential if a system is to ensure its primary purpose. Systems should be designed so \nthat these services are protected and, in the event of failure, recovered as quickly as possible.\nFurther Reading\n\u201cSurvivable Network System Analysis: A Case Study.\u201d An excellent paper that introduces the notion \nof system survivability and uses a case study of a mental health record treatment system to illus-\ntrate the application of a survivability method. (R. J. Ellison, R. C. Linger, T. Longstaff, and N. R. \nMead, IEEE Software, 16 (4), July/August 1999) http://dx.doi.org/10.1109/52.776952\nResilience Engineering in Practice: A Guidebook. This is a collection of articles and case studies \non\u00a0resilience engineering that takes a broad, sociotechnical systems perspective. (E. Hollnagel,  \nJ. Paries, D. W. Woods, and J. Wreathall, Ashgate Publishing Co., 2011).\n\u201cCyber Risk and Resilience Management.\u201d This is a website with a wide range of resources on \n\u00ad\ncybersecurity and resilience, including a model for resilience management. (Software Engineering \nInstitute, 2013) https://www.cert.org/resilience/\n", "page": 433, "type": "text", "section": "Page 433"}
{"text": "Website\nPowerPoint slides for this chapter:\nwww.pearsonglobaleditions.com/Sommerville\nLinks to supporting videos:\nhttp://software-engineering-book.com/videos/security-and-resilience/\nExercises\n14.1.\t Explain how the complementary strategies of resistance, recognition, recovery, and reinstate-\nment may be used to provide system resilience.\n14.2.\t What are the types of threats that have to be considered in resilience planning? Provide \n\u00ad\nexamples of the controls that organizations should put in place to counter those threats.\n14.3.\t Describe the ways in which human error can be viewed according to Reason (Reason, 2000) \nand the strategies that can be used to increase resilience according to the Swiss cheese \nmodel (Figure 14.6).\n14.4.\t A hospital proposes to introduce a policy that any member of clinical staff (doctors or nurses) \nwho takes or authorizes actions that leads to a patient being injured will be subject to criminal \ncharges. Explain why this is a bad idea, which is unlikely to improve patient safety, and why it \nis likely to adversely affect the resilience of the organization.\n14.5.\t What is survivable systems analysis and what are the key activities in each of the four stages \ninvolved in it as shown in Figure 14.8?\n14.6.\t Explain why process inflexibility can inhibit the ability of a sociotechnical system to resist and \nrecover from adverse events such as cyberattacks and software failure. If you have experience \nof process inflexibility, illustrate your answer with examples from your experience.\n14.7.\t Suggest how the approach to resilience engineering that I proposed in Figure 14.9 could be \nused in conjunction with an agile development process for the software in the system. What \nproblems might arise in using agile development for systems where resilience is important?\n14.8.\t In Section 13.4.2,  (1) an unauthorized user places malicious orders to move prices and (2) an \nintrusion corrupts the database of transactions that have taken place. For each of these cyber-\nattacks, identify resistance, recognition, and recovery strategies that might be used.\n14.9.\t In Figure 14.11, I suggested a number of adverse events that could affect the Mentcare system. \nDraw up a test plan for this system that sets out how you could test the ability of the Mentcare \nsystem to recognize, resist, and recover from these events.\n14.10.\t \u0007\nA senior manager in a company is concerned about insider attacks from disaffected staff on \nthe company\u2019s IT assets. As part of a resilience improvement program, she proposes that a \nlogging system and data analysis software be introduced to capture and analyze all employee \nactions but that employees should not be told about this system. Discuss the ethics of both \nintroducing a logging system and doing so without telling system users.\n \nChapter 14\u2002 \u25a0\u2002 Exercises\u2002 \u2002 433\n", "page": 434, "type": "text", "section": "Page 434"}
{"text": "References\nEllison, R. J., R. C. Linger, T. Longstaff, and N. R. Mead. 1999. \u201cSurvivable Network System Analysis: \nA Case Study.\u201d IEEE Software 16 (4): 70\u201377. doi:10.1109/52.776952.\nEllison, R. J., R. C. Linger, H. Lipson, N. R. Mead, and A. Moore. 2002. \u201cFoundations of Survivable \nSystems Engineering.\u201d Crosstalk: The Journal of Defense Software Engineering 12: 10\u201315.  \nhttp://resources.sei.cmu.edu/asset_files/WhitePaper/2002_019_001_77700.pdf\nHollnagel, E. 2006. \u201cResilience\u2014the Challenge of the Unstable.\u201d In Resilience Engineering: Concepts \nand Precepts, edited by E. Hollnagel, D. D. Woods, and N.G. Leveson, 9\u201318.\n\t\n\u2002 \u2002 . 2010. \u201cRAG\u2014The Resilience Analysis Grid.\u201d In Resilience Engineering in Practice, edited by \nE. Hollnagel, J. Paries, D. Woods, and J. Wreathall, 275\u2013295. Farnham, UK: Ashgate Publishing Group.\nInfoSecurity. 2013. \u201cGlobal Cybercrime, Espionage Costs $100\u2013$500 Billion Per Year.\u201d http://www \n.infosecurity-magazine.com/view/33569/global-cybercrime-espionage-costs-100500-billion-per-year\nLaprie, J-C. 2008. \u201cFrom Dependability to Resilience.\u201d In 38th Int. Conf. on Dependable Systems and \nNetworks. Anchorage, Alaska. http://2008.dsn.org/fastabs/dsn08fastabs_laprie.pdf\nReason, J. 2000. \u201cHuman Error: Models and Management.\u201d British Medical J. 320: 768\u2013770. \ndoi:10.1136/bmj.320.7237.768.\n434\u2002 \u2002 Chapter 14\u2002 \u25a0\u2002 Resilience engineering\n", "page": 435, "type": "text", "section": "Page 435"}
{"text": "PART \nThis part of the book covers more advanced software engineering topics. \nI assume in these chapters that readers understand the basics of the disci-\npline, covered in Chapters 1\u20139.\nChapters 15\u201318 focus on the dominant development paradigm for web-\nbased information systems and enterprise systems\u2014software reuse. \nChapter 15 introduces the topic and explains the different types of reuse \nthat are possible. I then cover the most common approach to reuse, \nwhich is the reuse of application systems. These are configured and \nadapted to the specific needs of each business.\nChapter 16 is concerned with the reuse of software components rather \nthan entire software systems. In this chapter, I explain what is meant by a \ncomponent and why standard component models are needed for effec-\ntive component reuse. I also discuss the general process of component-\nbased software engineering and the problems of component composition.\nThe majority of large systems are now distributed systems and Chapter 17 \ncovers issues and problems of building distributed systems. I introduce \nthe client-server approach as a fundamental paradigm of distributed sys-\ntems engineering, and explain ways of implementing this architectural \nstyle. The final section explains software as a service\u2013the delivery of soft-\nware functionality over the Internet, which has changed the market for \nsoftware products.\n3 \nAdvanced \nSoftware \nEngineering\n", "page": 436, "type": "text", "section": "Page 436"}
{"text": "Chapter 18 introduces the related topic of service-oriented architectures, \nwhich link the notions of distribution and reuse. Services are reusable \nsoftware components whose functionality can be accessed over the \nInternet. I discuss two widely-used approaches to service development \nnamely SOAP-based and RESTful services. I explain what is involved in \ncreating services (service engineering) and composing services to create \nnew software systems.\nThe focus of Chapters 19\u201321 is systems engineering. In Chapter 19, \nI introduce the topic and explain why it is important that software \nengineers should understand systems engineering. I discuss the sys-\ntems engineering life cycle and the importance of procurement in that \nlife-cycle.\nChapter 20 covers systems of systems (SoS). The large systems that we \nwill build in the 21st century will not be developed from scratch but will \nbe created by integrating existing complex systems. I explain why an \nunderstanding of complexity is important in SoS development and dis-\ncuss architectural patterns for complex systems of systems.\nMost software systems are not apps or business systems but are embed-\nded real-time systems. Chapter 21 covers this important topic. I introduce \nthe idea of a real-time embedded system and describe architectural pat-\nterns that are used in embedded systems design. I then explain the pro-\ncess of timing analysis and conclude the chapter with a discussion of \nreal-time operating systems.\n", "page": 437, "type": "text", "section": "Page 437"}
{"text": "Software reuse\n15 \nObjectives\nThe objectives of this chapter are to introduce software reuse and to \ndescribe approaches to system development based on large-scale \nsoftware reuse. When you have read this chapter, you will:\n\u25a0\t understand the benefits and problems of reusing software when \ndeveloping new systems;\n\u25a0\t understand the concept of an application framework as a set of \nreusable objects and how frameworks can be used in application \ndevelopment;\n\u25a0\t have been introduced to software product lines, which are made up  \nof a common core architecture and reusable components that are \nconfigured for each version of the product;\n\u25a0\t have learned how systems can be developed by configuring and \ncomposing off-the-shelf application software systems.\nContents\n15.1\t The reuse landscape\n15.2\t Application frameworks\n15.3\t Software product lines\n15.4\t Application system reuse\n", "page": 438, "type": "text", "section": "Page 438"}
{"text": "438\u2002 \u2002 Chapter 15\u2002 \u25a0\u2002 Software reuse\nReuse-based software engineering is a software engineering strategy where the \ndevelopment process is geared to reusing existing software. Until around 2000, \n\u00ad\nsystematic software reuse was uncommon, but it is now used extensively in the \ndevelopment of new business systems. The move to reuse-based development has \nbeen in response to demands for lower software production and maintenance costs, \nfaster delivery of systems, and increased software quality. Companies see their \n\u00ad\nsoftware as a valuable asset. They are promoting reuse of existing systems to \nincrease their return on software investments.\nReusable software of different kinds is now widely available. The open-source \nmovement has meant that there is a huge code base that can be reused. This may be in \nthe form of program libraries or entire applications. Many domain-specific \u00ad\napplication \nsystems, such as ERP systems, are available that can be tailored and adapted to cus-\ntomer requirements. Some large companies provide a range of \u00ad\nreusable components \nfor their customers. Standards, such as web service standards, have\u00a0made it easier to \ndevelop software services and reuse them across a range of \u00ad\napplications.\nReuse-based software engineering is an approach to development that tries to \nmaximize the reuse of existing software. The software units that are reused may be \nof radically different sizes. For example:\n1.\t\nSystem reuse Complete systems, which may be made up of a number of \n\u00ad\napplication programs, may be reused as part of a system of systems (Chapter 20).\n2.\t\nApplication reuse An application may be reused by incorporating it without \nchange into other systems or by configuring the application for different \n\u00ad\ncustomers. Alternatively, application families or software product lines that \nhave a common architecture, but that are adapted to individual customer \n\u00ad\nrequirements, may be used to develop a new system.\n3.\t\nComponent reuse Components of an application, ranging in size from subsys-\ntems to single objects, may be reused. For example, a pattern-matching system \n\u00ad\ndeveloped as part of a text-processing system may be reused in a database \n\u00ad\nmanagement system. Components may be hosted on the cloud or on private \nservers and may be accessible through an application programming interface \n(API) as services.\n4.\t\nObject and function reuse Software components that implement a single func-\ntion, such as a mathematical function, or an object class may be reused. This \nform of reuse, designed around standard libraries, has been common for the past \n40 years. Many libraries of functions and classes are freely available. You reuse \nthe classes and functions in these libraries by linking them with newly devel-\noped application code. In areas such as mathematical algorithms and graphics, \nwhere specialized, expensive expertise is needed to develop efficient objects \nand \u00ad\nfunctions, reuse is particularly cost-effective.\nAll software systems and components that include generic functionality are \npotentially reusable. However, these systems or components are sometimes so \n", "page": 439, "type": "text", "section": "Page 439"}
{"text": "\t\nChapter 15\u2002 \u25a0\u2002 Software reuse\u2002 \u2002 439\n\u00ad\nspecific that it is very expensive to modify them for a new situation. Rather than \nreuse the code, however, you can reuse the ideas that are the basis of the software. \nThis is called concept reuse.\nIn concept reuse you do not reuse a software component; rather, you reuse an \nidea, a way of working, or an algorithm. The concept that you reuse is represented in \nan abstract notation, such as a system model, which does not include implementation \ndetail. It can, therefore, be configured and adapted for a range of situations. Concept \nreuse is embodied in approaches such as design patterns (Chapter 7), configurable \nsystem products, and program generators. When concepts are reused, the reuse pro-\ncess must include an activity where the abstract concepts are instantiated to create \nexecutable components.\nAn obvious advantage of software reuse is that overall development costs are \nlower. Fewer software components need to be specified, designed, implemented, \nand validated. However, cost reduction is only one benefit of software reuse. I have \nlisted other advantages of reusing software in Figure 15.1.\nHowever, there are costs and difficulties associated with reuse (Figure 15.2). \nThere is a significant cost associated with understanding whether or not a compo-\nnent is suitable for reuse in a particular situation, and in testing that component to \nensure its dependability. These additional costs mean that the savings in develop-\nment costs may not be less than anticipated. However, the other benefits of reuse \nstill apply.\nFigure 15.1\u2002 Benefits \nof software reuse\nBenefit\nExplanation\nAccelerated development\nBringing a system to market as early as possible is often more important \nthan overall development costs. Reusing software can speed up system \nproduction because both development and validation time may be reduced.\nEffective use of specialists\nInstead of doing the same work over and over again, application specialists \ncan develop reusable software that encapsulates their knowledge.\nIncreased dependability\nReused software, which has been tried and tested in working systems, \nshould be more dependable than new software. Its design and \nimplementation faults should have been found and fixed.\nLower development costs\nDevelopment costs are proportional to the size of the software being \ndeveloped. Reusing software means that fewer lines of code have to be written.\nReduced process risk\nThe cost of existing software is already known, while the costs of \ndevelopment are always a matter of judgment. This is an important factor for \nproject management because it reduces the margin of error in project cost \nestimation. This is especially true when large software components such as \nsubsystems are reused.\nStandards compliance\nSome standards, such as user interface standards, can be implemented as a \nset of reusable components. For example, if menus in a user interface are \nimplemented using reusable components, all applications present the same \nmenu formats to users. The use of standard user interfaces improves \ndependability because users make fewer mistakes when presented with a \nfamiliar interface.\n", "page": 440, "type": "text", "section": "Page 440"}
{"text": "440\u2002 \u2002 Chapter 15\u2002 \u25a0\u2002 Software reuse\nAs I discussed in Chapter 2, software development processes have to be adapted \nto take reuse into account. In particular, there has to be a requirements refinement \nstage where the requirements for the system are modified to reflect the reusable soft-\nware that is available. The design and implementation stages of the system may also \ninclude explicit activities to look for and evaluate candidate components for reuse.\n \n15.1  The reuse landscape\nOver the past 20 years, many techniques have been developed to support software \nreuse. These techniques exploit the facts that systems in the same application domain \nare similar and have potential for reuse, that reuse is possible at different levels from \nsimple functions to complete applications, and that standards for reusable compo-\nnents facilitate reuse. Figure 15.3 shows the \u201creuse landscape\u201d\u2014different ways of \nimplementing software reuse. Each of these approaches to reuse is briefly described \nin Figure 15.4.\nGiven this array of techniques for reuse, the key question is \u201cwhich is the most \nappropriate technique to use in a particular situation?\u201d Obviously, the answer to this \nquestion depends on the requirements for the system being developed, the \u00ad\ntechnology \nProblem\nExplanation\nCreating, maintaining, and using a \ncomponent library\nPopulating a reusable component library and ensuring the software \ndevelopers can use this library can be expensive. Development \nprocesses have to be adapted to ensure that the library is used.\nFinding, understanding, and \nadapting reusable components\nSoftware components have to be discovered in a library, understood, \nand sometimes adapted to work in a new environment. Engineers \nmust be reasonably confident of finding a component in the library \nbefore they include a component search as part of their normal \ndevelopment process.\nIncreased maintenance costs\nIf the source code of a reused software system or component is not \navailable, then maintenance costs may be higher because the reused \nelements of the system may become incompatible with changes \nmade to the system.\nLack of tool support\nSome software tools do not support development with reuse. It may \nbe difficult or impossible to integrate these tools with a component \nlibrary system. The software process assumed by these tools may not \ntake reuse into account. This is more likely to be the case for tools \nthat support embedded systems engineering than for object-oriented \ndevelopment tools.\n\u201cNot-invented-here\u201d syndrome\nSome software engineers prefer to rewrite components because they \nbelieve they can improve on them. This is partly to do with trust and \npartly to do with the fact that writing original software is seen as \nmore challenging than reusing other people\u2019s software.\nFigure 15.2\u2002 Problems \nwith software reuse\n", "page": 441, "type": "text", "section": "Page 441"}
{"text": "\t\n15.1\u2002 \u25a0\u2002 The reuse landscape\u2002 \u2002 441\nDesign\npatterns\nArchitectural\npatterns\nApplication\nframeworks\nSoftware product\nlines\nApplication\nsystem integration\nERP systems\nSystems of\nsystems\nConfigurable\napplication systems\nLegacy system\nwrapping\nComponent-based\nsoftware engineering\nModel-driven\nengineering\nService-oriented\nsystems\nAspect-oriented\nsoftware engineering\nProgram\ngenerators\nProgram\nlibraries\nFigure 15.3\u2002 The reuse \nlandscape \nand reusable assets available, and the expertise of the development team. Key factors \nthat you should consider when planning reuse are:\n1.\t\nThe development schedule for the software If the software has to be developed \nquickly, you should try to reuse complete systems rather than individual compo-\nnents. Although the fit to requirements may be imperfect, this approach mini-\nmizes the amount of development required.\n2.\t\nThe expected software lifetime If you are developing a long-lifetime system, \nyou should focus on the maintainability of the system. You should not just think \nabout the immediate benefits of reuse but also of the long-term implications.\n\t\nOver its lifetime, you will have to adapt the system to new requirements, which \nwill mean making changes to parts of the system. If you do not have access to \nthe source code of the reusable components, you may prefer to avoid off-the-\nshelf components and systems from external suppliers. These suppliers may not \nbe able to continue support for the reused software. You may decide that it is \nsafer to reuse open-source systems and components (Chapter 7) as this means \nyou can access and keep copies of the source code.\n3.\t\nThe background, skills and experience of the development team All reuse tech-\nnologies are fairly complex, and you need quite a lot of time to understand and \nuse them effectively. Therefore, you should focus your reuse effort in areas \nwhere your development team has expertise.\n4.\t\nThe criticality of the software and its non-functional requirements For a critical \nsystem that has to be certified by an external regulator you may have to create a \nsafety or security case for the system (discussed in Chapter 12). This is difficult \nif you don\u2019t have access to the source code of the software. If your software has \nstringent performance requirements, it may be impossible to use strategies such \nas model-driven engineering (MDE) (Chapter 5). MDE relies on generating \ncode from a reusable domain-specific model of a system. However, the code \ngenerators used in MDE often generate relatively inefficient code.\n", "page": 442, "type": "text", "section": "Page 442"}
{"text": "442\u2002 \u2002 Chapter 15\u2002 \u25a0\u2002 Software reuse\n5.\t The application domain In many application domains, such as manufacturing \nand medical information systems, there are generic products that may be reused \nby configuring them to a local situation. This is one of the most effective \napproaches to reuse, and it is almost always cheaper to buy rather than build a \nnew system.\nApproach\nDescription\nApplication frameworks\nCollections of abstract and concrete classes are adapted and \nextended to create application systems.\nApplication system integration\nTwo or more application systems are integrated to provide extended \nfunctionality.\nArchitectural patterns\nStandard software architectures that support common types of \napplication system are used as the basis of applications. Described in \nChapters 6, 11, and 17.\nAspect-oriented software  \ndevelopment\nShared components are woven into an application at different places \nwhen the program is compiled. Described in web Chapter 31.\nComponent-based software \nengineering\nSystems are developed by integrating components (collections of \nobjects) that conform to component-model standards. Described in \nChapter 16.\nConfigurable application systems\nDomain-specific systems are designed so that they can be configured \nto the needs of specific system customers.\nDesign patterns\nGeneric abstractions that occur across applications are represented \nas design patterns showing abstract and concrete objects and \ninteractions. Described in Chapter 7.\nERP systems\nLarge-scale systems that encapsulate generic business functionality \nand rules are configured for an organization.\nLegacy system wrapping\nLegacy systems (Chapter 9) are \u201cwrapped\u201d by defining a set of \ninterfaces and providing access to these legacy systems through \nthese interfaces.\nModel-driven engineering\nSoftware is represented as domain models and implementation \nindependent models, and code is generated from these models. \nDescribed in Chapter 5.\nProgram generators\nA generator system embeds knowledge of a type of application and \nis used to generate systems in that domain from a user-supplied \nsystem model.\nProgram libraries\nClass and function libraries that implement commonly used \nabstractions are available for reuse.\nService-oriented systems\nSystems are developed by linking shared services, which may be \nexternally provided. Described in Chapter 18.\nSoftware product lines\nAn application type is generalized around a common architecture so \nthat it can be adapted for different customers.\nSystems of systems\nTwo or more distributed systems are integrated to create a new \nsystem. Described in Chapter 20.\nFigure 15.4\u2002  \nApproaches\u00a0that \nsupport\u00a0software  \nreuse\n", "page": 443, "type": "text", "section": "Page 443"}
{"text": "\t\n15.2\u2002 \u25a0\u2002 Application frameworks\u2002 \u2002 443\n6.\t\nThe platform on which the system will run Some components models, such as \n.NET, are specific to Microsoft platforms. Similarly, generic application sys-\ntems may be platform-specific, and you may only be able to reuse these if your \nsystem is designed for the same platform.\nThe range of available reuse techniques is such that, in most situations, there is the \npossibility of some software reuse. Whether or not reuse is achieved is often a manage-\nrial rather than a technical issue. Managers may be unwilling to compromise their \nrequirements to allow reusable components to be used. They may not understand the \nrisks associated with reuse as well as they understand the risks of original development. \nAlthough the risks of new software development may be higher, some managers may \nprefer known risks of development to unknown risks of reuse. To promote company-\nwide reuse, it may be necessary to introduce a reuse program that focuses on the creation \nof reusable assets and processes to facilitate reuse (Jacobsen, Griss, and Jonsson 1997).\n \n15.2  Application frameworks\nEarly enthusiasts for object-oriented development suggested that one of the key ben-\nefits of using an object-oriented approach was that objects could be reused in differ-\nent systems. However, experience has shown that objects are often too fine-grained \nand are often specialized for a particular application. It often takes longer to under-\nstand and adapt the object than to reimplement it. It has now become clear that \nobject-oriented reuse is best supported in an object-oriented development process \nthrough larger-grain abstractions called frameworks.\nAs the name suggests, a framework is a generic structure that is extended to cre-\nate a more specific subsystem or application. Schmidt et al. (Schmidt et al. 2004) \ndefine a framework to be\nan integrated set of software artifacts (such as classes, objects and components) that \ncollaborate to provide a reusable architecture for a family of related applications.\u2020\n Frameworks provide support for generic features that are likely to be used in all appli-\ncations of a similar type. For example, a user interface framework will provide support \nGenerator-based reuse\nGenerator-based reuse involves incorporating reusable concepts and knowledge into automated tools and \n\u00ad\nproviding an easy way for tool users to integrate specific code with this generic knowledge. This approach is \nusually most effective in domain-specific applications. Known solutions to problems in that domain are \n\u00ad\nembedded in the generator system and selected by the user to create a new system.\nhttp://software-engineering-book.com/web/generator-reuse/\n\u2020Schmidt, D. C., A. Gokhale, and B. Natarajan. 2004. \u201cLeveraging Application Frameworks.\u201d ACM \nQueue 2 (5 (July/August)): 66\u201375. doi:10.1145/1016998.1017005.\n", "page": 444, "type": "text", "section": "Page 444"}
{"text": "444\u2002 \u2002 Chapter 15\u2002 \u25a0\u2002 Software reuse\nfor interface event handling and will include a set of widgets that can be\u00a0used to construct \ndisplays. It is then left to the developer to specialize these by adding specific functionality \nfor a particular application. For example, in a user interface framework, the developer \ndefines display layouts that are appropriate to the application being implemented.\nFrameworks support design reuse in that they provide a skeleton architecture for \nthe application as well as the reuse of specific classes in the system. The architecture \nis implemented by the object classes and their interactions. Classes are reused \ndirectly and may be extended using features such as inheritance and polymorphism.\nFrameworks are implemented as a collection of concrete and abstract object \nclasses in an object-oriented programming language. Therefore, frameworks are \nlanguage-specific. Frameworks are available in commonly used object-oriented \n\u00ad\nprogramming languages such as Java, C#, and C++, as well as in dynamic languages \nsuch as Ruby and Python. In fact, a framework can incorporate other frameworks, \nwhere each framework is designed to support the development of part of the applica-\ntion. You can use a framework to create a complete application or to implement part \nof an application, such as the graphical user interface.\nThe most widely used application frameworks are web application frameworks \n(WAFs), which support the construction of dynamic websites. The architecture of a \nWAF is usually based on the Model-View-Controller (MVC) Composite pattern shown \nin Figure 15.5. The MVC pattern was originally proposed in the 1980s as an approach \nto GUI design that allowed for multiple presentations of an object and separate styles \nof interaction with each of these presentations. In essence, it separates the state from \nits presentation so that the state may be updated from each presentation.\nAn MVC framework supports the presentation of data in different ways and \nallows interaction with each of these presentations. When the data is modified \nthrough one of the presentations, the system model is changed and the controllers \nassociated with each view update their presentation.\nFrameworks are often implementations of design patterns, as discussed in Chapter\u00a07. \nFor example, an MVC framework includes the Observer pattern, the Strategy pattern, the \nComposite pattern, and a number of others that are discussed by Gamma\u00a0et\u00a0al. (Gamma et \nal. 1995). The general nature of patterns and their use of abstract and concrete classes allow \nfor extensibility. Without patterns, frameworks would almost certainly be impractical.\nModel methods\nController methods\nView methods\nUser\ninputs\nview modification\nmessages\nModel edits\nModel queries\nand updates\nController state\nView state\nModel state\nFigure 15.5\u2002 The \nModel-View-Controller \npattern\n", "page": 445, "type": "text", "section": "Page 445"}
{"text": "\t\n15.2\u2002 \u25a0\u2002 Application frameworks\u2002 \u2002 445\nWhile each framework includes slightly different functionality, web application \nframeworks usually provide components and classes that support:\n1.\t\nSecurity WAFs may include classes to help implement user authentication \n(login) and access control to ensure that users can only access permitted func-\ntionality in the system.\n2.\t\nDynamic web pages Classes are provided to help you define web page templates \nand to populate these dynamically with specific data from the system database.\n3.\t\nDatabase integration Frameworks don\u2019t usually include a database but assume \nthat a separate database, such as MySQL, will be used. The framework may \ninclude classes that provide an abstract interface to different databases.\n4.\t\nSession management Classes to create and manage sessions (a number of inter-\nactions with the system by a user) are usually part of a WAF.\n5.\t\nUser interaction Web frameworks provide AJAX (Holdener 2008) and/or \nHTML5 support (Sarris 2013), which allows interactive web pages to be cre-\nated. They may include classes that allow device-independent interfaces to be \ncreated, which adapt automatically to mobile phones and tablets.\nTo implement a system using a framework, you add concrete classes that inherit \noperations from abstract classes in the framework. In addition, you define \n\u201ccallbacks\u201d\u00ad\n\u2014methods that are called in response to events recognized by the frame-\nwork. The framework objects, rather than the application-specific objects, are \nresponsible for control in the system. Schmidt et al. (Schmidt, Gokhale, and \nNatarajan 2004) call this \u201cinversion of control.\u201d\nIn response to events from the user interface and database framework objects \ninvoke \u201chook methods\u201d that are then linked to user-provided functionality. The user-\nprovided functionality defines how the application should respond to the event \n(Figure 15.6). For example, a framework will have a method that handles a mouse \nclick from the environment. This method is called the hook method, which you must \nconfigure to call the appropriate application methods to handle the mouse click.\nApplication-specific classes\nGUI\nDatabase\nEvent\nloop\nCallbacks\nEvent\nloop\nPlatform\nEvent\nloop\nCallbacks\nCallbacks\nFigure 15.6\u2002 Inversion of \ncontrol in frameworks \n", "page": 446, "type": "text", "section": "Page 446"}
{"text": "446\u2002 \u2002 Chapter 15\u2002 \u25a0\u2002 Software reuse\nFayad and Schmidt (Fayad and Schmidt 1997) discuss three other classes of \nframework:\n1.\t\nSystem infrastructure frameworks support the development of system infra-\nstructures such as communications, user interfaces, and compilers.\n2.\t\nMiddleware integration frameworks consist of a set of standards and associated \nobject classes that support component communication and information \nexchange. Examples of this type of framework include Microsoft\u2019s .NET and \nEnterprise Java Beans (EJB). These frameworks provide support for standard-\nized component models, as discussed in Chapter 16.\n3.\t\nEnterprise application frameworks are concerned with specific application \ndomains such as telecommunications or financial systems (Baumer et al. 1997). \nThese embed application domain knowledge and support the development of \nend-user applications. These are not now widely used and have been largely \nsuperseded by software product lines.\u2020\nApplications that are constructed using frameworks can be the basis for further \nreuse through the concept of software product lines or application families. Because \nthese applications are constructed using a framework, modifying family members to \ncreate instances of the system is often a straightforward process. It involves rewrit-\ning concrete classes and methods that you have added to the framework.\nFrameworks are a very effective approach to reuse. However, they are expensive to \nintroduce into software development processes as they are inherently complex and it can \ntake several months to learn to use them. It can be difficult and expensive to evaluate \navailable frameworks to choose the most appropriate one. Debugging framework-based \napplications is more difficult than debugging original code because you may not under-\nstand how the framework methods interact. Debugging tools may provide information \nabout the reused framework components, which the developer does not understand.\n \n15.3  Software product lines\nWhen a company has to support a number of similar but not identical systems, one of the \nmost effective approaches to reuse is to create a software product line. Hardware control \nsystems are often developed using this approach to reuse as are domain-specific applica-\ntions in areas such as logistics or medical systems. For example, a printer manufacturer \nhas to develop printer control software, where there is a specific version of the product \nfor each type of printer. These software versions have much in common, so it makes \nsense to create a core product (the product line) and adapt this for each printer type.\nA software product line is a set of applications with a common architecture and \nshared components, with each application specialized to reflect specific customer \nrequirements. The core system is designed so that it can be configured and adapted to \n\u2020Fayad, M. E., and D. C. Schmidt. 1997. \u201cObject-Oriented Application Frameworks.\u201d Comm. ACM 40 (10): \n32\u201338. doi:10.1145/262793.262798.\n", "page": 447, "type": "text", "section": "Page 447"}
{"text": "\t\n15.3\u2002 \u25a0\u2002 Software product lines\u2002 \u2002 447\nsuit the needs of different customers or equipment. This may involve the configuration \nof some components, implementing additional components, and modifying some of \nthe components to reflect new requirements.\nDeveloping applications by adapting a generic version of the application means \nthat a high proportion of the application code is reused in each system. Testing is \nsimplified because tests for large parts of the application may also be reused, thus \nreducing the overall application development time. Engineers learn about the appli-\ncation domain through the software product line and so become specialists who can \nwork quickly to develop new applications.\nSoftware product lines usually emerge from existing applications. That is, an \norganization develops an application and then, when a similar system is required, \ninformally reuses code from this in the new application. The same process is used as \nother similar applications are developed. However, change tends to corrupt application \nstructure so, as more new instances are developed, it becomes increasingly difficult to \ncreate a new version. Consequently, a decision to design a generic product line may \nthen be made. This involves identifying common functionality in product instances \nand developing a base application, which is then used for future development.\nThis base application (Figure 15.7) is designed to simplify reuse and reconfigura-\ntion. Generally, a base application includes:\n1.\t\nCore components that provide infrastructure support. These are not usually \nmodified when developing a new instance of the product line.\n2.\t\nConfigurable components that may be modified and configured to specialize them \nto a new application. Sometimes it is possible to reconfigure these components \nwithout changing their code by using a built-in component configuration language.\n3.\t\nSpecialized, domain-specific components some or all of which may be replaced \nwhen a new instance of a product line is created.\nApplication frameworks and software product lines have much in common. They \nboth support a common architecture and components, and require new development \nto create a specific version of a system. The main differences between these \napproaches are as follows:\n1.\t\nApplication frameworks rely on object-oriented features such as inheritance and \npolymorphism to implement extensions to the framework. Generally, the framework \nCore\ncomponents\nConfigurable application \ncomponents\nSpecialized application components\nFigure 15.7\u2002 The \norganization of a base \nsystem for a product line \n", "page": 448, "type": "text", "section": "Page 448"}
{"text": "448\u2002 \u2002 Chapter 15\u2002 \u25a0\u2002 Software reuse\ncode is not modified, and the possible modifications are limited to whatever is sup-\nported by the framework. Software product lines are not necessarily created using \nan object-oriented approach. Application components are changed, deleted, or \nrewritten. There are no limits, in principle at least, to the changes that can be made.\n2.\t\nMost application frameworks provide general support rather than domain-\u00ad\nspecific \nsupport. For example, there are application frameworks to create web-based \napplications. A software product line usually embeds detailed domain and plat-\nform information. For example, there could be a software product line con-\ncerned with web-based applications for health record management.\n3.\t\nSoftware product lines are often control applications for equipment. For exam-\nple, there may be a software product line for a family of printers. This means \nthat the product line has to provide support for hardware interfacing. Application \nframeworks are usually software-oriented, and they do not usually include hard-\nware interaction components.\n4.\t\nSoftware product lines are made up of a family of related applications, owned by \nthe same organization. When you create a new application, your starting point is \noften the closest member of the application family, not the generic core application.\nIf you are developing a software product line using an object-oriented program-\nming language, then you may use an application framework as a basis for the \u00ad\nsystem. \nYou create the core of the product line by extending the framework with domain-\nspecific components using its built-in mechanisms. There is then a second phase of \ndevelopment where versions of the system for different customers are created. For \nexample, you can use a web-based framework to build the core of a software product \nline that supports web-based help desks. This \u201chelp desk product line\u201d may then be \nfurther specialized to provide particular types of help desk support.\nThe architecture of a software product line often reflects a general, application-\nspecific architectural style or pattern. For example, consider a product-line system \nthat is designed to handle vehicle dispatching for emergency services. Operators of \nthis system take calls about incidents, find the appropriate vehicle to respond to the \nincident, and dispatch the vehicle to the incident site. The developers of such a \n\u00ad\nsystem may market versions of it for police, fire, and ambulance services.\nThis vehicle dispatching system is an example of a generic resource allocation \nand management architecture (Figure 15.8). Resource management systems use a \ndatabase of available resources and include components to implement the resource \nallocation policy that has been decided by the company using the system. Users \ninteract with a resource management system to request and release resources and to \nask questions about resources and their availability.\nYou can see how this four-layer structure may be instantiated in Figure 15.9, \nwhich shows the modules that might be included in a vehicle dispatching system \nproduct line. The components at each level in the product-line system are as follows:\n1.\t\nAt the interaction level, components provide an operator display interface and \nan interface with the communications systems used.\n", "page": 449, "type": "text", "section": "Page 449"}
{"text": "\t\n15.3\u2002 \u25a0\u2002 Software product lines\u2002 \u2002 449\n2.\t\nAt the I/O management level (level 2), components handle operator authentication, \ngenerate reports of incidents and vehicles dispatched, support map output and route \nplanning, and provide a mechanism for operators to query the system databases.\n3.\t\nAt the resource management level (level 3), components allow vehicles to be \nlocated and dispatched, update the status of vehicles and equipment, and log \ndetails of incidents.\n4.\t\nAt the database level, as well as the usual transaction management support, \nthere are separate databases of vehicles, equipment, and maps.\nUser interface\nResource\ntracking\nResource policy\ncontrol\nResource\nallocation\nUser\nauthentication\nQuery\nmanagement\nResource database\nResource\ndelivery\nTransaction management\nInteraction\nI/O management\nResource management\nDatabase management\nFigure 15.8\u2002 The \narchitecture of a \nresource management \nsystem \nI/O management\nOperator interface\nVehicle status\nmanager\nIncident\nlogger\nResource management\nOperator\nauthentication\nQuery\nmanager\nEquipment\ndatabase\nMap and route\nplanner\nTransaction management\nVehicle database\nIncident log\nMap database\nVehicle\ndispatcher\nEquipment\nmanager\nVehicle\nlocator\nReport\ngenerator\nComms system\ninterface\nDatabase management\nResource management\nI/O management\nInteraction\nFigure 15.9\u2002 A product-\nline architecture \nof a vehicle \ndispatcher system \n", "page": 450, "type": "text", "section": "Page 450"}
{"text": "450\u2002 \u2002 Chapter 15\u2002 \u25a0\u2002 Software reuse\nTo create a new instance of this system, you may have to modify individual com-\nponents. For example, the police have a large number of vehicles but a relatively \nsmall number of vehicle types. By contrast, the fire service has many types of spe-\ncialized vehicles but relatively few vehicles. Therefore, when you are implementing \na system for these different services, you may have to define a different vehicle \ndatabase structure.\nVarious types of specialization of a software product line may be developed:\n1.\t\nPlatform specialization Versions of the application may be developed for differ-\nent platforms. For example, versions of the application may exist for Windows, \nMac OS, and Linux platforms. In this case, the functionality of the application is \nnormally unchanged; only those components that interface with the hardware \nand operating system are modified.\n2.\t\nEnvironment specialization Versions of the application may be created to handle \ndifferent operating environments and peripheral devices. For example, a system \nfor the emergency services may exist in different versions, depending on the \ncommunications hardware used by each service. For example, police radios may \nhave built-in encryption that has to be used. The product-line components are \nchanged to reflect the functionality and characteristics of the equipment used.\n3.\t\nFunctional specialization Versions of the application may be created for specific \ncustomers who have different requirements. For example, a library automation \nsystem may be modified depending on whether it is used in a public library, a \nreference library, or a university library. In this case, components that implement \nfunctionality may be modified and new components added to the system.\n4.\t\nProcess specialization The system may be adapted to cope with specific business \nprocesses. For example, an ordering system may be adapted to cope with a central-\nized ordering process in one company and with a distributed process in another.\nFigure 15.10 shows the process for extending a software product line to create a \nnew application. The activities in this process are:\n1.\t\nElicit stakeholder requirements You may start with a normal requirements engi-\nneering process. However, because a system already exists, you can demon-\nstrate the system and have stakeholders experiment with it, expressing their \nrequirements as modifications to the functions provided.\nElicit\nstakeholder\nrequirements\nChoose\nclosest-fit\nsystem instance\nDeliver new\nsystem instance\nRenegotiate\nrequirements\nAdapt existing\nsystem\nFigure 15.10\u2002 Product \ninstance development \n", "page": 451, "type": "text", "section": "Page 451"}
{"text": "\t\n15.3\u2002 \u25a0\u2002 Software product lines\u2002 \u2002 451\n2.\t\nSelect the existing system that is the closest fit to the requirements When creat-\ning a new member of a product line, you may start with the nearest product \ninstance. The requirements are analyzed, and the family member that is the clos-\nest fit is chosen for modification.\n3.\t\nRenegotiate requirements As more details of required changes emerge and the \nproject is planned, some requirements may be renegotiated with the customer to \nminimize the changes that will have to be made to the base application.\n4.\t\nAdapt existing system New modules are developed for the existing system, and \nexisting system modules are adapted to meet the new requirements.\n5.\t\nDeliver new product family member The new instance of the product line is \ndelivered to the customer. Some deployment-time configuration may be \nrequired to reflect the particular environments where the system will be used. At \nthis stage, you should document its key features so that it may be used as a basis \nfor other system developments in the future.\nWhen you create a new member of a product line, you may have to find a com-\npromise between reusing as much of the generic application as possible and satis-\nfying detailed stakeholder requirements. The more detailed the system \nrequirements, the less likely it is that the existing components will meet these \nrequirements. However, if stakeholders are willing to be flexible and to limit the \nsystem modifications that are required, you can usually deliver the system more \nquickly and at a lower cost.\nSoftware product lines are designed to be reconfigurable. This reconfigura-\ntion may involve adding or removing components from the system, defining \nparameters and constraints for system components, and including knowledge of \nbusiness processes. This configuration may occur at different stages in the devel-\nopment process:\n1.\t\nDesign-time configuration The organization that is developing the software \nmodifies a common product-line core by developing, selecting, or adapting \ncomponents to create a new system for a customer.\n2.\t\nDeployment-time configuration A generic system is designed for configuration \nby a customer or consultants working with the customer. Knowledge of the \n\u00ad\ncustomer\u2019s specific requirements and the system\u2019s operating environment is \nembedded in the configuration data used by the generic system.\nWhen a system is configured at design time, the supplier starts with either a \ngeneric system or an existing product instance. By modifying and extending mod-\nules in this system, the supplier creates a specific system that delivers the required \ncustomer functionality. This usually involves changing and extending the source \ncode of the system so that greater flexibility is possible than with deployment-\ntime configuration.\n", "page": 452, "type": "text", "section": "Page 452"}
{"text": "452\u2002 \u2002 Chapter 15\u2002 \u25a0\u2002 Software reuse\nDesign-time configuration is used when it is impossible to use the existing \ndeployment-time configuration facilities in a system to develop a new system \n\u00ad\nversion. However, over time, when you have created several family members with \ncomparable functionality, you may decide to refactor the core product line to include \nfunctionality that has been implemented in several application family members. You \nthen make that new functionality configurable when the system is deployed.\nDeployment-time configuration involves using a configuration tool to create a \nspecific system configuration that is recorded in a configuration database or as a set \nof configuration files (Figure 15.11). The executing system, which may either run on \na server or as a stand-alone system on a PC, consults this database when executing so \nthat its functionality may be specialized to its execution context.\nSeveral levels of deployment-time configuration may be provided in a system:\n1.\t Component selection, where you select the modules in a system that provide the \nrequired functionality. For example, in a patient information system, you may \nselect an image management component that allows you to link medical images \n(X-rays, CT scans, etc.) to the patient\u2019s medical record.\n2.\t Workflow and rule definition, where you define workflows (how information is \nprocessed, stage by stage), and validation rules that should apply to information \nentered by users or generated by the system.\n3.\t\nParameter definition, where you specify the values of specific system parameters \nthat reflect the instance of the application that you are creating. For example, you \nmay specify the maximum length of fields for data input by a user or the charac-\nteristics of hardware attached to the system.\nDeployment-time configuration can be very complex, and for large systems, it may \ntake several months to configure and test a system for a customer. Large configurable \nsystems may support the configuration process by providing software tools, such as \nplanning tools, to support the configuration process. I discuss deployment-time con-\nfiguration further in Section 15.4.1. This discussion covers the reuse of application \nsystems that have to be configured to work in different operational environments.\nConfiguration\ndatabase\nSystem database\nGeneric system\nConfiguration\nplanning tool\nFigure 15.11\u2002  \nDeployment-time \nconfiguration \n", "page": 453, "type": "text", "section": "Page 453"}
{"text": "\t\n15.4\u2002 \u25a0\u2002 Application system reuse\u2002 \u2002 453\n \n15.4  Application system reuse\nAn application system product is a software system that can be adapted to the needs \nof different customers without changing the source code of the system. Application \nsystems are developed by a system vendor for a general market; they are not spe-\ncially developed for an individual customer. These system products are sometimes \nknown as COTS (Commercial Off-the Shelf System) products. However, the term \n\u201cCOTS\u201d is mostly used in military systems, and I prefer to call these system prod-\nucts application systems.\nVirtually all desktop software for business and many server-based systems are \napplication systems. This software is designed for general use, so it includes many \nfeatures and functions. It therefore has the potential to be reused in different environ-\nments and as part of different applications. Torchiano and Morisio (Torchiano and \nMorisio 2004) also discovered that open-source products were often used without \nchange and without looking at the source code.\nApplication system products are adapted by using built-in configuration mecha-\nnisms that allow the functionality of the system to be tailored to specific customer \nneeds. For example, in a hospital patient record system, separate input forms and \noutput reports might be defined for different types of patients. Other configuration \nfeatures may allow the system to accept plug-ins that extend functionality or check \nuser inputs to ensure that they are valid.\nThis approach to software reuse has been very widely adopted by large com-\npanies since the late 1990s, as it offers significant benefits over customized soft-\nware development:\n1.\t As with other types of reuse, more rapid deployment of a reliable system may \nbe possible.\n2.\t\nIt is possible to see what functionality is provided by the applications, and so it \nis easier to judge whether or not they are likely to be suitable. Other companies \nmay already use the applications, so experience of the systems is available.\n3.\t\nSome development risks are avoided by using existing software. However, this \napproach has its own risks, as I discuss below.\n4.\t\nBusinesses can focus on their core activity without having to devote a lot of \nresources to IT systems development.\n5.\t\nAs operating platforms evolve, technology updates may be simplified as these \nare the responsibility of the application system vendor rather than the customer.\nOf course, this approach to software engineering has its own problems:\n1.\t\nRequirements usually have to be adapted to reflect the functionality and mode \nof operation of the off-the-shelf application system. This can lead to disruptive \nchanges to existing business processes.\n", "page": 454, "type": "text", "section": "Page 454"}
{"text": "454\u2002 \u2002 Chapter 15\u2002 \u25a0\u2002 Software reuse\n2.\t\nThe application system may be based on assumptions that are practically impos-\nsible to change. The customer must therefore adapt its business to reflect these \nassumptions.\n3.\t\nChoosing the right application system for an enterprise can be a difficult process, \nespecially as many of these systems are not well documented. Making the wrong \nchoice means that it may be impossible to make the new system work as required.\n4.\t\nThere may be a lack of local expertise to support systems development. \nConsequently, the customer has to rely on the vendor and external consultants \nfor development advice. This advice may be geared to selling products and ser-\nvices, with insufficient time taken to understand the real needs of the customer.\n5.\t\nThe system vendor controls system support and evolution. It may go out of busi-\nness, be taken over, or make changes that cause difficulties for customers.\nApplication systems may be used as individual systems or in combination, where \ntwo or more systems are integrated. Individual systems consist of a generic application \nfrom a single vendor that is configured to customer requirements. Integrated systems \ninvolve integrating the functionality of individual systems, often from different vendors, \nto create a new application system. Figure 15.12 summarizes the differences between \nthese different approaches. I discuss application system integration in Section 15.4.2.\n\t\n15.4.1 \t Configurable application systems\nConfigurable application systems are generic application systems that may be \ndesigned to support a particular business type, business activity, or, sometimes, a \ncomplete business enterprise. For example, a system produced for dentists may han-\ndle appointments, reminders, dental records, patient recall, and billing. At a larger \nscale, an Enterprise Resource Planning (ERP) system may support the manufactur-\ning, ordering, and customer relationship management processes in a large company.\nDomain-specific application systems, such as systems to support a business function \n(e.g., document management), provide functionality that is likely to be required by a \nrange of potential users. However, they also incorporate built-in assumptions about how \nConfigurable application systems\nApplication system integration\nSingle product that provides the functionality \nrequired by a customer\nSeveral different application systems are \nintegrated\u00a0to provide customized functionality\nBased on a generic solution and standardized \nprocesses\nFlexible solutions may be developed for customer \nprocesses\nDevelopment focus is on system configuration\nDevelopment focus is on system integration\nSystem vendor is responsible for maintenance\nSystem owner is responsible for maintenance\nSystem vendor provides the platform for the system\nSystem owner provides the platform for the system\nFigure 15.12\u2002  \nIndividual and \nintegrated\u00a0application \nsystems\n", "page": 455, "type": "text", "section": "Page 455"}
{"text": "\t\n15.4\u2002 \u25a0\u2002 Application system reuse\u2002 \u2002 455\nusers work, and these assumptions may cause problems in specific situations. For exam-\nple, a system to support student registration in a university may assume that students will \nbe registered for one degree at one university. However, if universities collaborate to offer \njoint degrees, then it may be practically impossible to represent this detail in the system.\nEnterprise Resource Planning (ERP) systems, such as those produced by SAP and \nOracle, are large-scale, integrated systems designed to support business practices \nsuch as ordering and invoicing, inventory management, and manufacturing schedul-\ning (Monk and Wagner 2013). The configuration process for these systems involves \ngathering detailed information about the customer\u2019s business and business pro-\ncesses, and embedding this information in a configuration database. This often \nrequires detailed knowledge of configuration notations and tools and is usually car-\nried out by consultants working alongside system customers.\nA generic ERP system includes a number of modules that may be composed in \ndifferent ways to create a system for a customer. The configuration process involves \nchoosing which modules are to be included, configuring these individual modules, \ndefining business processes and business rules, and defining the structure and organ-\nization of the system database. A model of the overall architecture of an ERP system \nthat supports a range of business functions is shown in Figure 15.13.\nThe key features of this architecture are as follows:\n1.\t\nA number of modules to support different business functions. These are large grain \nmodules that may support entire departments or divisions of the business. In the \nexample shown in Figure 15.13, the modules that have been selected for inclusion \nin the system are a module to support purchasing; a module to support supply chain \nmanagement; a logistics module to support the delivery of goods; and a customer \nrelationship management (CRM) module to maintain customer information.\n2.\t\nA defined set of business process models, associated with each module, which \nrelate to activities in that module. For example, the ordering process model may \ndefine how orders are created and approved. This will specify the roles and \nactivities involved in placing an order.\n3.\t\nA common database that maintains information about all related business func-\ntions. Thus, it should not be necessary to replicate information, such as cus-\ntomer details, in different parts of the business.\nSystem database\nBusiness rules\nPurchasing\nSupply chain\nLogistics\nCRM\nProcesses\nProcesses\nProcesses\nProcesses\nFigure 15.13\u2002 The \narchitecture of an \nERP system \n", "page": 456, "type": "text", "section": "Page 456"}
{"text": "456\u2002 \u2002 Chapter 15\u2002 \u25a0\u2002 Software reuse\n4.\t\nA set of business rules that apply to all data in the database. Therefore, when \ndata is input from one function, these rules should ensure that it is consistent \nwith the data required by other functions. For example, a business rule may \nrequire that all expense claims have to be approved by someone more senior \nthan the person making the claim.\nERP systems are used in almost all large companies to support some or all of their \nfunctions. They are, therefore, a very widely used form of software reuse. The obvi-\nous limitation of this approach to reuse is that the functionality of the customer\u2019s \napplication is restricted to the functionality of the ERP system\u2019s built-in modules. If \na company needs additional functionality, it may have to develop a separate add-on \nsystem to provide this functionality.\nFurthermore, the buyer company\u2019s processes and operations have to be defined in \nthe ERP system\u2019s configuration language. This language embeds the understanding \nof business processes as seen by the system vendor, and there may be a mismatch \nbetween these assumptions and the concepts and processes used in the customer\u2019s \nbusiness. A serious mismatch between the customer\u2019s business model and the sys-\ntem model used by the ERP system makes it highly probable that the ERP system \nwill not meet the customer\u2019s real needs (Scott 1999).\nFor example, in an ERP system that was sold to a university, a fundamental system \nconcept was the notion of a customer. In this system, a customer was an external agent \nthat bought goods and services from a supplier. This concept caused great difficulties \nwhen configuring the system. Universities do not really have customers. Rather, they \nhave customer-type relationships with a range of people and organizations such as \nstudents, research funding agencies, and educational charities. None of these relation-\nships is compatible with a customer relationship where a person or business buys prod-\nucts or services from another. In this particular case, it took several months to resolve \nthis mismatch, and the final solution only partially met the university\u2019s requirements.\nERP systems usually require extensive configuration to adapt them to the require-\nments of each organization where they are installed. This configuration may involve:\n1.\t\nSelecting the required functionality from the system, for example, by deciding \nwhat modules should be included.\n2.\t\nEstablishing a data model that defines how the organization\u2019s data will be struc-\ntured in the system database.\n3.\t\nDefining business rules that apply to that data.\n4.\t\nDefining the expected interactions with external systems.\n5.\t\nDesigning the input forms and the output reports generated by the system.\n6.\t\nDesigning new business processes that conform to the underlying process model \nsupported by the system.\n7.\t\nSetting parameters that define how the system is deployed on its underlying \nplatform.\n", "page": 457, "type": "text", "section": "Page 457"}
{"text": "\t\n15.4\u2002 \u25a0\u2002 Application system reuse\u2002 \u2002 457\nOnce the configuration settings are completed, the new system is then ready for \ntesting. Testing is a major problem when systems are configured rather than pro-\ngrammed using a conventional language. There are two reasons for this:\n1.\t\nTest automation may be difficult or impossible. There may be no easy access to \nan API that can be used by testing frameworks such as JUnit, so the system has \nto be tested manually by testers inputting test data to the system. Furthermore, \nsystems are often specified informally, so defining test cases may be difficult \nwithout a lot of help from end-users.\n2.\t Systems errors are often subtle and specific to business processes. The \napplication system or ERP system is a reliable platform, so technical system \nfailures are rare. The problems that occur are often due to misunderstand-\nings between those configuring the system and user stakeholders. System \ntesters without detailed knowledge of the end-user processes cannot detect \nthese errors.\n\t\n15.4.2 \t Integrated application systems\nIntegrated application systems include two or more application systems or, some-\ntimes, legacy systems. You may use this approach when no single application sys-\ntem meets all of your needs or when you wish to integrate a new application system \nwith systems that you are already using. The component systems may interact \nthrough their APIs or service interfaces if these are defined. Alternatively, they may \nbe composed by connecting the output of one system to the input of another or by \nupdating the databases used by the applications.\nTo develop integrated application systems, you have to make a number of \ndesign choices:\n1.\t\nWhich individual application systems offer the most appropriate functionality? \nTypically, several system products will be available, which can be combined in \ndifferent ways. If you don\u2019t already have experience with a particular applica-\ntion system, it can be difficult to decide which product is the most suitable.\n2.\t How will data be exchanged? Different systems normally use unique data \nstructures and formats. You have to write adaptors that convert from one repre-\nsentation to another. These adaptors are runtime systems that operate alongside \nthe constituent application systems.\n3.\t What features of a product will actually be used? Individual application sys-\ntems may include more functionality than you need, and functionality may be \nduplicated across different products. You have to decide which features in what \nproduct are most appropriate for your requirements. If possible, you should \nalso deny access to unused functionality because this can interfere with normal \nsystem operation.\n", "page": 458, "type": "text", "section": "Page 458"}
{"text": "458\u2002 \u2002 Chapter 15\u2002 \u25a0\u2002 Software reuse\nConsider the following scenario as an illustration of application system integration. \nA large organization intends to develop a procurement system that allows staff to \nplace orders from their desk. By introducing this system across the organization, the \ncompany estimates that it can save $5 million per year. By centralizing buying, the \nnew procurement system can ensure that orders are always made from suppliers who \noffer the best prices and should reduce the administration associated with orders. \nAs\u00a0with manual systems, the system involves choosing the goods available from a \nsupplier, creating an order, having the order approved, sending the order to a sup-\nplier, receiving the goods, and confirming that payment should be made.\nThe company has a legacy ordering system that is used by a central procurement \noffice. This order processing software is integrated with an existing invoicing and \ndelivery system. To create the new ordering system, the legacy system is integrated \nwith a web-based e-commerce platform and an email system that handles commu-\nnications with users. The structure of the final procurement system is shown in \nFigure 15.14.\nThis procurement system should be a client\u2013server system with standard web \nbrowsing and email systems used on the client. On the server, the e-commerce \nplatform has to integrate with the existing ordering system through an adaptor. The \ne-commerce system has its own format for orders, confirmations of delivery, and \nso forth, and these have to be converted into the format used by the ordering sys-\ntem. The e-commerce system uses the email system to send notifications to users, \nbut the ordering system was never designed for this purpose. Therefore, another \nadaptor has to be written to convert the notifications from the ordering system into \nemail messages.\nMonths, sometimes years, of implementation effort can be saved, and the time to \ndevelop and deploy a system can be drastically reduced by integrating existing appli-\ncation systems. The procurement system described above was implemented and \ndeployed in a very large company in nine months. It had originally been estimated \nthat it would take three years to develop a procurement system in Java that could be \nintegrated with the legacy ordering system.\nClient\nWeb browser\nEmail system\nServer\nE-commerce\nsystem\nOrdering and\ninvoicing system\nEmail system\nAdaptor\nAdaptor\nFigure 15.14\u2002 An \nintegrated procurement \nsystem \n", "page": 459, "type": "text", "section": "Page 459"}
{"text": "\t\n15.4\u2002 \u25a0\u2002 Application system reuse\u2002 \u2002 459\nApplication system integration can be simplified if a service-oriented approach \nis used. Essentially, a service-oriented approach means allowing access to the \napplication system\u2019s functionality through a standard service interface, with a \nservice for each discrete unit of functionality. Some applications may offer a ser-\nvice interface, but sometimes this service interface has to be implemented by the \nsystem integrator. Essentially, you have to program a wrapper that hides the \napplication and provides externally visible services (Figure 15.15). This approach \nis particularly valuable for legacy systems that have to be integrated with newer \napplication systems.\nIn principle, integrating application systems is the same as integrating any other \ncomponent. You have to understand the system interfaces and use them exclusively \nto communicate with the software; you have to trade off specific requirements \nagainst rapid development and reuse; and you have to design a system architecture \nthat allows the application systems to operate together.\nHowever, the fact that these products are usually large systems in their own right, and \nare often sold as separate standalone systems, introduces additional problems. Boehm \nand Abts (Boehm and Abts 1999) highlight four important system integration problems:\n1.\t\nLack of control over functionality and performance Although the published \ninterface of a product may appear to offer the required facilities, the system may \nnot be properly implemented or may perform poorly. The product may have \nhidden operations that interfere with its use in a specific situation. Fixing these \nproblems may be a priority for the system integrator but may not be of real con-\ncern for the product vendor. Users may simply have to find workarounds to \nproblems if they wish to reuse the application system.\n2.\t\nProblems with system interoperability It is sometimes difficult to get individual \napplication systems to work together because each system embeds its own \nassumptions about how it will be used. Garlan et al. (Garlan, Allen, and \nOckerbloom 1995), reporting on their experience integrating four application \nsystems, found that three of these products were event-based but that each used \na different model of events. Each system assumed that it had exclusive access to \nthe event queue. As a consequence, integration was very difficult. The project \nApplication\nsystem\nService wrapper\nServices\nServices\nFigure 15.15\u2002  \nApplication wrapping \n", "page": 460, "type": "text", "section": "Page 460"}
{"text": "460\u2002 \u2002 Chapter 15\u2002 \u25a0\u2002 Software reuse\nrequired five times as much effort as originally predicted. The schedule was \nextended to two years rather than the predicted six months.\n\t\nIn a retrospective analysis of their work 10 years later, Garlan et al. (Garlan, \nAllen, and Ockerbloom 2009) concluded that the integration problems that they \ndiscovered had not been solved. Torchiano and Morisio (Torchiano and Morisio \n2004) found that lack of compliance with standards in many application systems \nmeant that integration was more difficult than anticipated.\n3.\t\nNo control over system evolution Vendors of application systems make their own \ndecisions on system changes, in response to market pressures. For PC products in \nparticular, new versions are often produced frequently and may not be compatible \nwith all previous versions. New versions may have additional unwanted function-\nality, and previous versions may become unavailable and unsupported.\n4.\t\nSupport from system vendors The level of support available from system \n\u00ad\nvendors varies widely. Vendor support is particularly important when problems \narise as developers do not have access to the source code and detailed documen-\ntation of the system. While vendors may commit to providing support, changing \nmarket and economic circumstances may make it difficult for them to deliver \nthis commitment. For example, a system vendor may decide to discontinue a \nproduct because of limited demand, or they may be taken over by another com-\npany that does not wish to support the products that have been acquired.\nBoehm and Abts reckon that, in many cases, the cost of system maintenance and \nevolution may be greater for integrated application systems. The above difficulties \nare life-cycle problems; they don\u2019t just affect the initial development of the system. \nThe further removed the people involved in the system maintenance become from \nthe original system developers, the more likely it is that difficulties will arise with the \nintegrated system.\nKey Points\n\u25a0\t There are many different ways to reuse software. These range from the reuse of classes and \nmethods in libraries to the reuse of complete application systems.\n\u25a0\t The advantages of software reuse are lower costs, faster software development, and lower risks. \nSystem dependability is increased. Specialists can be used more effectively by concentrating \ntheir expertise on the design of reusable components.\n\u25a0\t Application frameworks are collections of concrete and abstract objects that are designed for \nreuse through specialization and the addition of new objects. They usually incorporate good \ndesign practice through design patterns.\n", "page": 461, "type": "text", "section": "Page 461"}
{"text": "\t\nChapter 15\u2002 \u25a0\u2002 Website\u2002 \u2002 461\n\u25a0\t Software product lines are related applications that are developed from one or more base appli-\ncations. A generic system is adapted and specialized to meet specific requirements for function-\nality, target platform, or operational configuration.\n\u25a0\t Application system reuse is concerned with the reuse of large-scale, off-the-shelf systems. \nThese provide a lot of functionality, and their reuse can radically reduce costs and development \ntime. Systems may be developed by configuring a single, generic application system or by inte-\ngrating two or more application systems.\n\u25a0\t Potential problems with application system reuse include lack of control over functionality, per-\nformance, and system evolution; the need for support from external vendors; and difficulties in \nensuring that systems can interoperate.\nFurther Reading\n\u201cOverlooked Aspects of COTS-Based Development.\u201d An interesting article that discusses a survey of \ndevelopers using a COTS-based approach, and the problems that they encountered. (M. Torchiano \nand M. Morisio, IEEE Software, 21 (2), March\u2013April 2004) http://dx.doi.org/10.1109/\nMS.2004.1270770\nCRUISE\u2014Component Reuse in Software Engineering. This e-book covers a wide range of reuse top-\nics, including case studies, component-based reuse, and reuse processes. However, its coverage of \napplication system reuse is limited. (L. Nascimento et al., 2007) http://www.academia.edu/179616/\nC.R.U.I.S.E_-_Component_Reuse_in_Software_Engineering\n\u201cConstruction by Configuration: A New Challenge for Software Engineering.\u201d In this invited paper, \nI\u00a0discuss the problems and difficulties of constructing a new application by configuring existing \n\u00ad\nsystems. (I. Sommerville, Proc. 19th Australian Software Engineering Conference, 2008) http://dx.\ndoi.org/10.1109/ASWEC.2008.75\n\u201cArchitectural Mismatch: Why Reuse Is Still So Hard.\u201d This article looks back on an earlier paper \nthat discussed the problems of reusing and integrating a number of application systems. The \nauthors concluded that, although some progress has been made, there were still problems in \n\u00ad\nconflicting assumptions made by the designers of the individual systems. (D. Garlan et al., IEEE \nSoftware, 26 (4), July\u2013August 2009) http://dx.doi.org//10.1109/MS.2009.86\nWebsite\nPowerPoint slides for this chapter:\nwww.pearsonglobaleditions.com/Sommerville\nLinks to supporting videos:\nhttp://software-engineering-book.com/videos/software-reuse/\n", "page": 462, "type": "text", "section": "Page 462"}
{"text": "462\u2002 \u2002 Chapter 15\u2002 \u25a0\u2002 Software reuse\nExercises\n\u2002 15.1. \t\u0007\nWhat major technical and nontechnical factors hinder software reuse? Do you personally \nreuse much software and, if not, why not?\n\u2002 15.2. \t\u0007\nList the benefits of software reuse and explain why the expected lifetime of the software \nshould be considered when planning reuse.\n\u2002 15.3. \t\u0007\nHow does the base application\u2019s design in the product line simplify reuse and reconfiguration?\n\u2002 15.4. \t\u0007\nExplain what is meant by \u201cinversion of control\u201d in application frameworks. Explain why this \napproach could cause problems if you integrated two separate systems that were originally \ncreated using the same application framework.\n\u2002 15.5. \t\u0007\nUsing the example of the weather station system described in Chapters 1 and 7, suggest a \nproduct-line architecture for a family of applications that are concerned with remote monitor-\ning and data collection. You should present your architecture as a layered model, showing \nthe components that might be included at each level.\n\u2002 15.6. \t\u0007\nMost desktop software, such as word processing software, can be configured in a number of \ndifferent ways. Examine software that you regularly use and list the configuration options for \nthat software. Suggest difficulties that users might have in configuring the software. Micro-\nsoft Office (or one of its open-source alternatives) is a good example to use for this exercise.\n\u2002 15.7.\t \u0007\nWhy have many large companies chosen ERP systems as the basis for their organizational \ninformation system? What problems may arise when deploying a large-scale ERP system in \nan organization?\n\u2002 15.8.\t \u0007\nWhat are the significant benefits offered by the application system reuse approach when \ncompared with the custom software development approach?\n\u2002 15.9.\t \u0007\nExplain why adaptors are usually needed when systems are constructed by integrating \n\u00ad\napplication systems. Suggest three practical problems that might arise in writing adaptor \nsoftware to link two application systems.\n15.10. \t\u0007\nThe reuse of software raises a number of copyright and intellectual property issues. If a \u00ad\ncustomer \npays a software contractor to develop a system, who has the right to reuse the developed code? \nDoes the software contractor have the right to use that code as a basis for a\u00a0generic component? \nWhat payment mechanisms might be used to reimburse providers of reusable components? \n\u00ad\nDiscuss these issues and other ethical issues associated with the reuse of software.\nReferences\nBaumer, D., G. Gryczan, R. Knoll, C. Lilienthal, D. Riehle, and H. Zullighoven. 1997. \u201cFramework \nDevelopment for Large Systems.\u201d Comm. ACM 40 (10): 52\u201359. doi:10.1145/262793.262804.\nBoehm, B., and C. Abts. 1999. \u201cCOTS Integration: Plug and Pray?\u201d Computer 32 (1): 135\u2013138. \ndoi:10.1109/2.738311.\nFayad, M.E., and D.C. Schmidt. 1997. \u201cObject-Oriented Application Frameworks.\u201d Comm. ACM 40 \n(10): 32\u201338. doi:10.1145/262793.262798.\n", "page": 463, "type": "text", "section": "Page 463"}
{"text": "Gamma, E., R. Helm, R. Johnson, and J. Vlissides. 1995. Design Patterns: Elements of Reusable \nObject-Oriented Software. Reading, MA: Addison-Wesley.\nGarlan, D., R. Allen, and J. Ockerbloom. 1995. \u201cArchitectural Mismatch: Why Reuse Is So Hard.\u201d IEEE \nSoftware 12 (6): 17\u201326. doi:10.1109/52.469757.\n \n\u2013\u2013\u2013\u2013\u2013\u2013. 2009. \u201cArchitectural Mismatch: Why Reuse Is Still so Hard.\u201d IEEE Software 26 (4): 66\u201369. \ndoi:10.1109/MS.2009.86.\nHoldener, A.T. 2008. Ajax: The Definitive Guide. Sebastopol, CA: O\u2019Reilly and Associates.\nJacobsen, I., M. Griss, and P. Jonsson. 1997. Software Reuse. Reading, MA: Addison-Wesley.\nMonk, E., and B. Wagner. 2013. Concepts in Enterprise Resource Planning, 4th ed. Independence, \nKY: CENGAGE Learning.\nSarris, S. 2013. HTML5 Unleashed. Indianapolis, IN: Sams Publishing.\nSchmidt, D. C., A. Gokhale, and B. Natarajan. 2004. \u201cLeveraging Application Frameworks.\u201d ACM \nQueue 2 (5 (July/August)): 66\u201375. doi:10.1145/1016998.1017005.\nScott, J. E. 1999. \u201cThe FoxMeyer Drug\u2019s Bankruptcy: Was It a Failure of ERP.\u201d In Proc. Association for \nInformation Systems 5th Americas Conf. on Information Systems. Milwaukee, WI. http://www.uta.\nedu/faculty/weltman/OPMA5364TW/FoxMeyer.pdf\nTorchiano, M., and M. Morisio. 2004. \u201cOverlooked Aspects of COTS-Based Development.\u201d IEEE \n\u00ad\nSoftware 21 (2): 88\u201393. doi:10.1109/MS.2004.1270770.\n\t\nChapter 15\u2002 \u25a0\u2002 References\u2002 \u2002 463\n", "page": 464, "type": "text", "section": "Page 464"}
{"text": "16 \nComponent-based \nsoftware engineering\nContents\n16.1\t Components and component models\n16.2\t CBSE processes\n16.3\t Component composition\nObjectives\nThe objective of this chapter is to describe an approach to software \nreuse based on the composition of standardized, reusable \ncomponents. When you have read this chapter, you will:\n\u25a0\t understand what is meant by a software component that may be \nincluded in a program as an executable element;\n\u25a0\t understand the key elements of software component models and \nthe support provided by middleware for these models;\n\u25a0\t be aware of the key activities in the component-based software \nengineering (CBSE) process for reuse and the CBSE process with \nreuse;\n\u25a0\t understand three different types of component composition and \nsome of the problems that have to be resolved when components \nare composed to create new components or systems.\n", "page": 465, "type": "text", "section": "Page 465"}
{"text": "Component-based software engineering (CBSE) emerged in the late 1990s as an \napproach to software systems development based on reusing software components. \nIts creation was motivated by frustration that object-oriented development had not \nled to extensive reuse, as had been originally suggested. Single-object classes were \ntoo detailed and specific and often had to be bound with an application at compile-\ntime. You had to have detailed knowledge of the classes to use them, which usually \nmeant that you had to have the component source code. Selling or distributing \nobjects as individual reusable components was therefore practically impossible.\nComponents are higher-level abstractions than objects and are defined by their \ninterfaces. They are usually larger than individual objects, and all implementation \ndetails are hidden from other components. Component-based software engineering \nis the process of defining, implementing, and integrating or composing these loosely \ncoupled, independent components into systems.\nCBSE has become as an important software development approach for large-\nscale enterprise systems, with demanding performance and security requirements. \nCustomers are demanding secure and dependable software that is delivered and \ndeployed more quickly. The only way that these demands can be met is to build soft-\nware by reusing existing components.\nThe essentials of component-based software engineering are:\n1.\t\nIndependent components that are completely specified by their interfaces. There \nshould be a clear separation between the component interface and its implemen-\ntation. This means that one implementation of a component can be replaced by \nanother, without the need to change other parts of the system.\n2.\t\nComponent standards that define interfaces and so facilitate the integration of \ncomponents. These standards are embodied in a component model. They define, at \nthe very minimum, how component interfaces should be specified and how com-\nponents communicate. Some models go much further and define interfaces that \nshould be implemented by all conformant components. If components \u00ad\nconform to \nstandards, then their operation is independent of their programming language. \nComponents written in different languages can be integrated into the same system.\n3.\t Middleware that provides software support for component integration. To \nmake independent, distributed components work together, you need \n\u00ad\nmiddleware \u00ad\nsupport that handles component communications. Middleware for \ncomponent support handles low-level issues efficiently and allows you to \nfocus on application-related problems. In addition, middleware for component \nsupport may provide support for resource allocation, transaction management, \nsecurity, and\u00a0concurrency.\n4.\t\nA development process that is geared to component-based software engineer-\ning. You need a development process that allows requirements to evolve, \ndepending on the functionality of available components.\nComponent-based development embodies good software engineering practice. It \noften makes sense to design a system using components, even if you have to develop \n \nChapter 16\u2002 \u25a0\u2002 Component-based software engineering\u2002 \u2002 465\n", "page": 466, "type": "text", "section": "Page 466"}
{"text": "466\u2002 \u2002 Chapter 16\u2002 \u25a0\u2002 Component-based software engineering\nrather than reuse these components. Underlying CBSE are sound design principles \nthat support the construction of understandable and maintainable software:\n1.\t\nComponents are independent, so they do not interfere with each other\u2019s opera-\ntion. Implementation details are hidden. The component\u2019s implementation can \nbe changed without affecting the rest of the system.\n2.\t\nComponents communicate through well-defined interfaces. If these interfaces \nare maintained, one component can be replaced by another component provid-\ning additional or enhanced functionality.\n3.\t\nComponent infrastructures offer a range of standard services that can be used in \napplication systems. This reduces the amount of new code that has to be developed.\nThe initial motivation for CBSE was the need to support both reuse and distributed \nsoftware engineering. A component was seen as an element of a software system that \ncould be accessed, using a remote procedure call mechanism, by other components run-\nning on separate computers. Each system that reused a component had to incorporate its \nown copy of that component. This idea of a component extended the notion of distrib-\nuted objects, as defined in distributed systems models such as the CORBA specification \n(Pope 1997). Several different protocols and technology-specific \u201cstandards\u201d were \nintroduced to support this view of a component, including Sun\u2019s Enterprise Java Beans \n(EJB), Microsoft\u2019s COM and .NET, and CORBA\u2019s CCM (Lau and Wang 2007).\nUnfortunately, the companies involved in proposing standards could not agree on \na single standard for components, thereby limiting the impact of this approach to soft-\nware reuse. It is impossible for components developed using different approaches to \nwork together. Components that are developed for different platforms, such as .NET \nor J2EE, cannot interoperate. Furthermore, the standards and protocols proposed \nwere complex and difficult to understand. This was also a \u00ad\nbarrier to their adoption.\nIn response to these problems, the notion of a component as a service was devel-\noped, and standards were proposed to support service-oriented software engineering. \nThe most significant difference between a component as a service and the original \nnotion of a component is that services are stand-alone entities that are external to a \nprogram using them. When you build a service-oriented system, you reference the \nexternal service rather than including a copy of that service in your system.\nService-oriented software engineering is a type of component-based software engi-\nneering. It uses a simpler notion of a component than that originally proposed in CBSE, \nProblems with CBSE\nCBSE is now a mainstream approach to software engineering and is widely used when creating new systems. \nHowever, when used as an approach to reuse, problems include component trustworthiness, component \n\u00ad\ncertification, requirements compromises, and prediction of the properties of components, especially when they \nare integrated with other components.\nhttp://software-engineering-book.com/web/cbse-problems/\n", "page": 467, "type": "text", "section": "Page 467"}
{"text": " \n16.1\u2002 \u25a0\u2002 Components and component models\u2002 \u2002 467\nwhere components were executable routines that were included in larger systems. Each \nsystem that used a component embedded its own version of that component. Service-\noriented approaches are gradually replacing CBSE with embedded components as an \napproach to systems development. In this chapter, I discuss the use of CBSE with \nembedded components; service-oriented software engineering is covered in Chapter 18.\n \n16.1  Components and component models\nThe software reuse community generally agrees that a component is an independent \nsoftware unit that can be composed with other components to create a software \u00ad\nsystem. \nBeyond that, however, people have proposed varying definitions of a software compo-\nnent. Councill and Heineman (Councill and Heineman 2001) define a component as:\nA software element that conforms to a standard component model and can be \nindependently deployed and composed without modification according to a \ncomposition standard.\u2020\nThis definition is standards-based so that a software unit that conforms to these stand-\nards is a component. Szyperski (Szyperski 2002), however, does not mention standards in \nhis definition of a component but focuses instead on the key characteristics of components:\nA software component is a unit of composition with contractually-specified \ninterfaces and explicit context dependencies only. A software component can \nbe deployed independently and is subject to composition by third parties.\u2021\nBoth of these definitions were developed around the idea of a component as an \nelement that is embedded in a system, rather than a service that is referenced by the \nsystem. However, they are equally applicable to service components.\nSzyperski also states that a component has no externally observable state; that is, \ncopies of components are indistinguishable. However, some component models, \nsuch as the Enterprise Java Beans model, allow stateful components, so these do not \ncorrespond with Szyperski\u2019s definition. While stateless components are certainly \nsimpler to use, in some systems stateful components are more convenient and reduce \nsystem complexity.\nWhat the above definitions have in common is that they agree that components \nare independent and that they are the fundamental unit of composition in a system. I \nthink that, if we combine these proposals, we get a more rounded description of a \nreusable component. Figure 16.1 shows what I consider to be the essential character-\nistics of a component as used in CBSE.\n\u2020Councill, W. T., and G. T. Heineman. 2001. \u201cDefinition of a Software Component and Its Elements.\u201d \nIn Component-Based Software Engineering, edited by G T Heineman and W T Councill, 5\u201320. Boston: \nAddison Wesley.\n\u2021Szyperski, C. 2002. Component Software: Beyond Object-Oriented Programming, 2nd Ed. Harlow, \nUK: Addison Wesley.\n", "page": 468, "type": "text", "section": "Page 468"}
{"text": "468\u2002 \u2002 Chapter 16\u2002 \u25a0\u2002 Component-based software engineering\nA useful way of thinking about a component is as a provider of one or more \n\u00ad\nservices, even if the component is embedded rather than implemented as a \u00ad\nservice. \nWhen a system needs something to be done, it calls on a component to provide that \nservice without caring about where that component is executing or the programming \nlanguage used to develop the component. For example, a component in a system \nused in a public library might provide a search service that allows users to search the \nlibrary catalog. A component that converts from one graphical format to another \n(e.g., TIFF to JPEG) provides a data conversion \u00ad\nservice and so on.\nViewing a component as a service provider emphasizes two critical characteris-\ntics of a reusable component:\n1.\t\nThe component is an independent executable entity that is defined by its inter-\nfaces. You don\u2019t need any knowledge of its source code to use it. It can either be \nreferenced as an external service or included directly in a program.\n2.\t\nThe services offered by a component are made available through an interface, and \nall interactions are through that interface. The component interface is expressed \nin terms of parameterized operations, and its internal state is never exposed.\nIn principle, all components have two related interfaces, as shown in Figure 16.2. \nThese interfaces reflect the services that the component provides and the services \nthat the component requires to operate correctly:\n1.\t\nThe \u201cprovides\u201d interface defines the services provided by the component. This \ninterface is the component API. It defines the methods that can be called by a user \nFigure 16.1\u2002 Component \ncharacteristics\nComponent \ncharacteristic\nDescription\nComposable\nFor a component to be composable, all external interactions must take place through \npublicly defined interfaces. In addition, it must provide external access to information \nabout itself, such as its methods and attributes.\nDeployable\nTo be deployable, a component has to be self-contained. It must be able to operate \nas a stand-alone entity on a component platform that provides an implementation of \nthe component model. This usually means that the component is binary and does \nnot have to be compiled before it is deployed. If a component is implemented as a \nservice, it does not have to be deployed by a user of that component. Rather, it is \ndeployed by the service provider.\nDocumented\nComponents have to be fully documented so that potential users can decide \nwhether or not the components meet their needs. The syntax and, ideally, the \nsemantics of all component interfaces should be specified.\nIndependent\nA component should be independent\u2014it should be possible to compose and deploy \nit without having to use other specific components. In situations where the \ncomponent needs externally provided services, these should be explicitly set out in a \n\u201crequires\u201d interface specification.\nStandardized\nComponent standardization means that a component used in a CBSE process has to \nconform to a standard component model. This model may define component \ninterfaces, component metadata, documentation, composition, and deployment.\n", "page": 469, "type": "text", "section": "Page 469"}
{"text": " \n16.1\u2002 \u25a0\u2002 Components and component models\u2002 \u2002 469\nof the component. In a UML component diagram, the \u201cprovides\u201d interface for a \ncomponent is indicated by a circle at the end of a line from the component icon.\n2.\t\nThe \u201crequires\u201d interface specifies the services that other components in the system \nmust provide if a component is to operate correctly. If these services are not availa-\nble, then the component will not work. This does not compromise the independence \nor deployability of a component because the \u201crequires\u201d interface does not define \nhow these services should be provided. In the UML, the symbol for a \u201crequires\u201d \ninterface is a semicircle at the end of a line from the component icon. Notice that \n\u201cprovides\u201d and \u201crequires\u201d interface icons can fit together like a ball and socket.\nTo illustrate these interfaces, Figure 16.3 shows a model of a component that has \nbeen designed to collect and collate information from an array of sensors. It runs \nautonomously to collect data over a period of time and, on request, provides collated \ndata to a calling component. The \u201cprovides\u201d interface includes methods to add, \nremove, start, stop, and test sensors. The report method returns the sensor data that \nhas been collected, and the listAll method provides information about the attached \nsensors. Although I have not shown them here, these methods have associated \nparameters specifying the sensor identifiers, locations, and so on.\nThe \u201crequires\u201d interface is used to connect the component to the sensors. It \nassumes that sensors have a data interface, accessed through sensorData, and a man-\nagement interface, accessed through sensorManagement. This interface has been \ndesigned to connect to different types of sensors so that it does not include specific \nsensor operations such as Test and provideReading. Instead, the commands used by a \nspecific type of sensor are embedded in a string, which is a parameter to the opera-\ntions in the \u201crequires\u201d interface. Adaptor components parse this parameter string and \ntranslate the embedded commands into the specific control interface of each type of \nsensor. I discuss the use of adaptors later in this chapter, where I show how the data \ncollector component may be connected to a sensor (Figure 16.12).\nProvides interface\nRequires interface\nComponent\nDefines the services\nthat are needed and\nshould be provided\nby other components\nDefines the services\nthat are provided\nby the component\nto other components\nFigure 16.2\u2002  Component \ninterfaces \nProvides interface\nRequires interface\nData collector\naddSensor\nremoveSensor\nstartSensor\nstopSensor\ntestSensor\nlistAll\nreport\ninitialize\nsensorManagement\nsensorData\nFigure 16.3\u2002 A model \nof\u00a0a data collector \ncomponent \n", "page": 470, "type": "text", "section": "Page 470"}
{"text": "470\u2002 \u2002 Chapter 16\u2002 \u25a0\u2002 Component-based software engineering\nComponents are accessed using remote procedure calls (RPCs). Each component \nhas a unique identifier and, using this name, may be called from another computer. \nThe called component uses the same mechanism to access the \u201crequired\u201d compo-\nnents that are defined in its interface.\nAn important difference between a component as an external service and a com-\nponent as a program element accessed using a remote procedure call is that services \nare completely independent entities. They do not have an explicit \u201crequires\u201d inter-\nface. Of course, they do require other components to support their operation, but \nthese are provided internally. Other programs can use services without the need to \nimplement any additional support required by the service.\n\t\n16.1.1 \t Component models\nA component model is a definition of standards for component implementation, doc-\numentation, and deployment. These standards are for component developers to \nensure that components can interoperate. They are also for providers of component \nexecution infrastructures who provide middleware to support component operation. \nFor service components, the most important component model is the Web Service \nmodels, and for embedded components, widely used models include the Enterprise \nJava Beans (EJB) model and Microsoft\u2019s .NET model (Lau and Wang 2007).\nThe basic elements of an ideal component model are discussed by Weinreich and \nSametinger (Weinreich and Sametinger 2001). I summarize these model elements in \nFigure 16.4. This diagram shows that the elements of a component model define the \ncomponent interfaces, the information that you need to use the component in a pro-\ngram, and how a component should be deployed:\n1.\t\nInterfaces Components are defined by specifying their interfaces. The compo-\nnent model specifies how the interfaces should be defined and the elements, \nsuch as operation names, parameters, and exceptions, which should be included \nin the interface definition. The model should also specify the language used to \ndefine the component interfaces.\n\t\nFor web services, interface specification uses XML-based languages as \n\u00ad\ndiscussed in Chapter 18; EJB is Java-specific, so Java is used as the interface \ndefinition language; in .NET, interfaces are defined using Microsoft\u2019s Common \nComponents and objects\nComponents are often implemented in object-oriented languages, and, in some cases, accessing the \u201cprovides\u201d \ninterface of a component is done through method calls. However, components and object classes are not the \nsame thing. Unlike object classes, components are independently deployable, do not define types, are language-\nindependent, and are based on a standard component model.\nhttp://software-engineering-book.com/web/components-and-objects/\n", "page": 471, "type": "text", "section": "Page 471"}
{"text": " \n16.1\u2002 \u25a0\u2002 Components and component models\u2002 \u2002 471\nIntermediate Language (CIL). Some component models require specific inter-\nfaces that must be defined by a component. These are used to compose the com-\nponent with the component model infrastructure, which provides standardized \nservices such as security and transaction management.\n2.\t\nUsage In order for components to be distributed and accessed remotely via \nRPCs, they need to have a unique name or handle associated with them. This \nhas to be globally unique. For example, in EJB, a hierarchical name is generated \nwith the root based on an Internet domain name. Services have a unique URI \n(Uniform Resource Identifier).\n\t\nComponent meta-data is data about the component itself, such as information \nabout its interfaces and attributes. The meta-data is important because it allows \nusers of the component to find out what services are provided and required. \nComponent model implementations normally include specific ways (such as the \nuse of a reflection interface in Java) to access this component meta-data.\n\t\nComponents are generic entities, and, when deployed, they have to be config-\nured to fit into an application system. For example, you could configure the \nData collector component (Figure 16.3) by defining the maximum number of \nsensors in a sensor array. The component model may therefore specify how the \nbinary components can be customized for a particular deployment environment.\n3.\t\nDeployment The component model includes a specification of how components \nshould be packaged for deployment as independent, executable routines. \nBecause components are independent entities, they have to be packaged with all \nsupporting software that is not provided by the component infrastructure, or is \nnot defined in a \u201crequires\u201d interface. Deployment information includes informa-\ntion about the contents of a package and its binary organization.\n\t\nInevitably, as new requirements emerge, components will have to be changed or \nreplaced. The component model may therefore include rules governing when \nand how component replacement is allowed. Finally, the component model may \ndefine the component documentation that should be produced. This is used to \nfind the component and to decide whether it is appropriate.\nComponent model\nInterfaces\nUsage\ninformation\nDeployment\nand use\nInterface\ndefinition\nSpecific\ninterfaces\nComposition\nNaming\nconvention\nMeta-data\naccess\nCustomization\nPackaging\nDocumentation\nEvolution\nsupport\nFigure 16.4\u2002  Basic \nelements of a \ncomponent model \n", "page": 472, "type": "text", "section": "Page 472"}
{"text": "472\u2002 \u2002 Chapter 16\u2002 \u25a0\u2002 Component-based software engineering\nFor components that are executable routines rather than external services, the \ncomponent model defines the services to be provided by the middleware that \n\u00ad\nsupports the executing components. Weinreich and Sametinger use the analogy of an \noperating system to explain component models. An operating system provides a set \nof generic services that can be used by applications. A component model implemen-\ntation provides comparable shared services for components. Figure 16.5 shows some \nof the services that may be provided by an implementation of a component model.\nThe services provided by a component model implementation fall into two \ncategories:\n1.\t\nPlatform services, which enable components to communicate and interoperate \nin a distributed environment. These are the fundamental services that must be \navailable in all component-based systems.\n2.\t\nSupport services, which are common services that many different components \nare likely to require. For example, many components require authentication to \nensure that the user of component services is authorized. It makes sense to \n\u00ad\nprovide a standard set of middleware services for use by all components. This \nreduces the costs of component development, and potential component incom-\npatibilities can be avoided.\nMiddleware implements the common component services and provides interfaces to \nthem. To make use of the services provided by a component model infrastructure, you \ncan think of the components as being deployed in a \u201ccontainer.\u201d A container is an imple-\nmentation of the support services plus a definition of the interfaces that a component \nmust provide to integrate it with the container. Conceptually, when you add a com\u00ad\nponent to the container, the component can access the support services and the container \ncan access the component interfaces. When in use, the component interfaces themselves \nare not accessed directly by other components. They are accessed through a container \ninterface that invokes code to access the interface of the embedded component.\nContainers are large and complex and, when you deploy a component in a con-\ntainer, you get access to all middleware services. However, simple components may \nPlatform services\nAddressing\nInterface\ndefinition\nComponent\ncommunications\nException\nmanagement\nSupport services\nSecurity\nTransaction\nmanagement\nConcurrency\nComponent\nmanagement\nPersistence\nResource\nmanagement\nFigure 16.5\u2002  Middleware \nservices defined in a \ncomponent model \n", "page": 473, "type": "text", "section": "Page 473"}
{"text": " \n16.2\u2002 \u25a0\u2002 CBSE processes\u2002 \u2002 473\nnot need all of the facilities offered by the supporting middleware. The approach \ntaken in web services to common service provision is therefore rather different. For \nweb services, standards have been defined for common services such as transaction \nmanagement and security, and these standards have been implemented as program \nlibraries. If you are implementing a service component, you only use the common \nservices that you need.\nThe services associated with a component model have much in common with \nthe facilities provided by object-oriented frameworks, which I discussed in \nChapter 15. Although the services provided may not be as comprehensive, frame-\nwork services are often more efficient than container-based services. As a conse-\nquence, some people think that it is best to use frameworks such as SPRING \n(Wheeler and White 2013) for Java development rather than the fully-featured \ncomponent model in EJB.\n \n16.2  CBSE processes\nCBSE processes are software processes that support component-based software \nengineering. They take into account the possibilities of reuse and the different pro-\ncess activities involved in developing and using reusable components. Figure 16.6 \n(Kotonya 2003) presents an overview of the processes in CBSE. At the highest level, \nthere are two types of CBSE processes:\n1.\t\nDevelopment for reuse This process is concerned with developing components \nor services that will be reused in other applications. It usually involves general-\nizing existing components.\n2.\t\nDevelopment with reuse This process is the process of developing new applica-\ntions using existing components and services.\nThese processes have different objectives and therefore include different activi-\nties. In the development for reuse process, the objective is to produce one or more \nreusable components. You know the components that you will be working with, and \nyou have access to their source code to generalize them. In development with reuse, \nyou don\u2019t know what components are available, so you need to discover these com-\nponents and design your system to make the most effective use of them. You may \nnot have access to the component source code.\nYou can see from Figure 16.6 that the basic processes of CBSE with and for reuse \nhave supporting processes that are concerned with component acquisition, compo-\nnent management, and component certification:\n1.\t\nComponent acquisition is the process of acquiring components for reuse or devel-\nopment into a reusable component. It may involve accessing locally developed \ncomponents or services or finding these components from an external source.\n", "page": 474, "type": "text", "section": "Page 474"}
{"text": "474\u2002 \u2002 Chapter 16\u2002 \u25a0\u2002 Component-based software engineering\n2.\t\nComponent management is concerned with managing a company\u2019s reusable \ncomponents, ensuring that they are properly catalogued, stored, and made avail-\nable for reuse.\n3.\t\nComponent certification is the process of checking a component and certifying \nthat it meets its specification.\nComponents maintained by an organization may be stored in a component repos-\nitory that includes both the components and information about their use.\n\t\n16.2.1 \t CBSE for reuse\nCBSE for reuse is the process of developing reusable components and making them \navailable for reuse through a component management system. The vision of early \nsupporters of CBSE (Szyperski 2002) was that a thriving component marketplace \nwould develop. There would be specialist component providers and component ven-\ndors who would organize the sale of components from different developers. Software \ndevelopers would buy components to include in a system or pay for services as they \nwere used. However, this vision has not been realized. There are relatively few com-\nponent suppliers, and buying off-the-shelf components is uncommon.\nConsequently, CBSE for reuse is mostly used within organizations that have \nmade a commitment to reuse-driven software engineering. These companies have a \nbase of internally developed components that can be reused. However, these inter-\nnally developed components may not be reusable without change. They often include \napplication-specific features and interfaces that are unlikely to be required in other \nprograms where the component is reused.\nCBSE for\nreuse\nCBSE with\nreuse\nComponent\nacquisition\nComponent\ncertification\nComponent\nrepository\nCBSE processes\nSpecifier,\nDesigner,\nIntegrator,\nMaintainer\nLibrarian,\nVendor,\nBroker\nComponent\nmanagement\nLibrarian\nLocal or\nexternal\ncertifier\nExternal\nsource\nDomain analyst,\nDesigner,\nImplementor,\nMaintainer,\nMarket analyst\nFigure 16.6\u2002  CBSE \nprocesses \n", "page": 475, "type": "text", "section": "Page 475"}
{"text": " \n16.2\u2002 \u25a0\u2002 CBSE processes\u2002 \u2002 475\nTo make components reusable, you have to adapt and extend the application-\nspecific components to create more generic and therefore more reusable versions. \nObviously, this adaptation has an associated cost. You have to decide first, whether \na component is likely to be reused and second, whether the cost savings from future \nreuse justify the costs of making the component reusable.\nTo answer the first of these questions, you have to decide whether or not the com-\nponent implements one or more stable domain abstractions. Stable domain abstrac-\ntions are fundamental elements of the application domain that change slowly. For \nexample, in a banking system, domain abstractions might include accounts, account \nholders, and statements. In a hospital management system, domain abstractions might \ninclude patients, treatments, and nurses. These domain abstractions are sometimes \ncalled business objects. If the component is an implementation of a commonly used \ndomain abstraction or group of related business objects, it can probably be reused.\nTo answer the question about cost-effectiveness, you have to assess the costs of \nchanges\u00a0that are required to make the component reusable. These costs are the costs of \ncomponent documentation and component validation, and of making the component more \ngeneric. Changes that you may make to a component to make it more reusable include:\n\u25a0\t removing application-specific methods;\n\u25a0\t changing names to make them more general;\n\u25a0\t adding methods to provide more complete functional coverage;\n\u25a0\t making exception handling consistent for all methods;\n\u25a0\t adding a \u201cconfiguration\u201d interface to allow the component to be adapted to \n\u00ad\ndifferent situations of use;\n\u25a0\t integrating required components to increase independence.\nThe problem of exception handling is a difficult one. In principle, components \nshould not handle exceptions themselves because each application will have its own \nrequirements for exception management. Rather, the component should define what \nexceptions can arise and should publish these exceptions as part of the interface. For \nexample, a simple component implementing a stack data structure should detect and \npublish stack overflow and stack underflow exceptions. In practice, however, there \nare two problems with this process:\n1.\t\nPublishing all exceptions leads to bloated interfaces that are harder to under-\nstand. This may put off potential users of the component.\n2.\t\nThe operation of the component may depend on local exception handling, and \nchanging this may have serious implications for the functionality of the component.\nYou therefore have to take a pragmatic approach to component exception handling. \nCommon technical exceptions, where recovery is important for the functioning of the \ncomponent, should be handled locally. These exceptions and how they are handled \n", "page": 476, "type": "text", "section": "Page 476"}
{"text": "476\u2002 \u2002 Chapter 16\u2002 \u25a0\u2002 Component-based software engineering\nshould be documented with the component. Other exceptions that are related to the busi-\nness function of the component should be passed to the calling component for handling.\nMili et al. (Mili et al. 2002) discuss ways of estimating the costs of making a compo-\nnent reusable and the returns from that investment. The benefits of reusing rather than \nredeveloping a component are not simply productivity gains. There are also quality gains, \nbecause a reused component should be more dependable, and time-to-market gains. \nThese are the increased returns that accrue from deploying the software more quickly.\nMili et al. present various formulas for estimating these gains, as does the COCOMO \nmodel, discussed in Chapter 23. However, the parameters of these formulas are diffi-\ncult to estimate accurately, and the formulas must be adapted to local \u00ad\ncircumstances, \nmaking them difficult to use. I suspect that few software project managers use these \nmodels to estimate the return on investment from component reusability.\nWhether or not a component is reusable depends on its application domain, \n\u00ad\nfunctionality, and generality. If the domain is a general one and the component \nimplements standard functionality in that domain, then it is more likely to be reusa-\nble. As you add generality to a component, you increase its reusability because it can \nbe applied in a wider range of environments. Unfortunately, this normally means \nthat the component has more operations and is more complex, which makes the \ncomponent harder to understand and use.\nThere is, therefore, a trade-off between the reusability and understandability of a \ncomponent. To make a component reusable you have to provide a set of generic \ninterfaces with operations that cater to all of the ways in which the component could \nbe used. Reusability adds complexity and hence reduces component understandabil-\nity. This makes it more difficult and time consuming to decide whether a component \nis suitable for reuse. Because of the time involved in understanding a reusable com-\nponent, it is sometimes more cost-effective to reimplement a simpler component \nwith the specific functionality that is required.\nA potential source of components is legacy systems. As I discussed in Chapter 9, \nlegacy  systems are systems that fulfill an important business function but are written \nusing obsolete software technologies. As a result, it may be difficult to use them with \nnew systems. However, if you convert these old systems to components, their func-\ntionality can be reused in new applications.\nOf course, these legacy systems do not normally have clearly defined \u201crequires\u201d and \n\u201cprovides\u201d interfaces. To make these components reusable, you have to create a wrapper \nthat defines the component interfaces. The wrapper hides the complexity of the underly-\ning code and provides an interface for external components to access services that are \nprovided. Although this wrapper is a fairly complex piece of software, the cost of wrapper \ndevelopment may be significantly less than the cost of reimplementing the legacy system.\nOnce you have developed and tested a reusable component or service, it then has \nto be managed for future reuse. Management involves deciding how to classify the \ncomponent so that it can be discovered, making the component available either in a \nrepository or as a service, maintaining information about the use of the component, \nand keeping track of different component versions. If the component is open-source, \nyou may make it available in a public repository such as GitHub or Sourceforge. If it \nis intended for use in a company, then you may use an internal repository system.\n", "page": 477, "type": "text", "section": "Page 477"}
{"text": " \n16.2\u2002 \u25a0\u2002 CBSE processes\u2002 \u2002 477\nA company with a reuse program may carry out some form of component certifi-\ncation before the component is made available for reuse. Certification means that \nsomeone apart from the developer checks the quality of the component. They test the \ncomponent and certify that it has reached an acceptable quality standard, before it is \nmade available for reuse. However, this process can be expensive, and so many \ncompanies simply leave testing and quality checking to the component developers.\n\t\n16.2.2 \t CBSE with reuse\nThe successful reuse of components requires a development process tailored to \nincluding reusable components in the software being developed. The CBSE with \nreuse process has to include activities that find and integrate reusable components. \nThe structure of such a process was discussed in Chapter 2, and Figure 16.7 shows \nthe principal activities within that process. Some of these activities, such as the \n\u00ad\ninitial discovery of user requirements, are carried out in the same way as in other \nsoftware processes. However, the essential differences between CBSE with reuse \nand software processes for original software development are as follows:\n1.\t\nThe user requirements are initially developed in outline rather than in detail, and \nstakeholders are encouraged to be as flexible as possible in defining their \nrequirements. Requirements that are too specific limit the number of compo-\nnents that could meet these requirements. However, unlike incremental devel-\nopment, you need a complete description of the requirements so that you can \nidentify as many components as possible for reuse.\n2.\t\nRequirements are refined and modified early in the process depending on the \ncomponents available. If the user requirements cannot be satisfied from available \ncomponents, you should discuss the related requirements that can be supported \nby the reusable components. Users may be willing to change their minds if this \nmeans cheaper or quicker system delivery.\n3.\t\nThere is a further component search and design refinement activity after the sys-\ntem architecture has been designed. Apparently, usable components may turn out \nIdentify candidate\ncomponents\nOutline\nsystem\nrequirements\nModify\nrequirements\naccording to discovered\ncomponents\nArchitectural\ndesign\nCompose\ncomponents to\ncreate system\nIdentify candidate\ncomponents\nFigure 16.7\u2002 CBSE with \nreuse \n", "page": 478, "type": "text", "section": "Page 478"}
{"text": "478\u2002 \u2002 Chapter 16\u2002 \u25a0\u2002 Component-based software engineering\nto be unsuitable or may not work properly with other chosen components. You \nmay have to find alternatives to these components. Further requirements changes \nmay therefore be necessary, depending on the functionality of these components.\n4.\t\nDevelopment is a composition process where the discovered components are \nintegrated. This involves integrating the components with the component model \ninfrastructure and, often, developing adaptors that reconcile the interfaces of \nincompatible components. Of course, additional functionality may also be \nrequired over and above that provided by reused components.\nThe architectural design stage is particularly important. Jacobsen et al. (Jacobsen, \nGriss, and Jonsson 1997) found that defining a robust architecture is critical for suc-\ncessful reuse. During the architectural design activity, you may choose a component \nmodel and implementation platform. However, many companies have a standard \ndevelopment platform (e.g., .NET), so the component model is predetermined. As I \ndiscussed in Chapter 6, you also establish the high-level architecture of the system at \nthis stage and make decisions about system distribution and control.\nAn activity that is unique to the CBSE process is identifying candidate compo-\nnents or services for reuse. This involves a number of subactivities, as shown in \nFigure 16.8. Initially, your focus should be on search and selection. You need to \nconvince yourself that components are available to meet your requirements. \nObviously, you should do some initial checking that the component is suitable, but \ndetailed testing may not be required. In the later stage, after the system architecture \nhas been designed, you should spend more time on component validation. You need \nto be confident that the identified components are really suited to your application; if \nnot, then you have to repeat the search and selection processes.\nThe first step in identifying components is to look for components that are \u00ad\navailable \nwithin your company or from trusted suppliers. There are few component vendors, so \nyou are most likely to be looking for components that have been developed in your own \norganization or in the repositories of open-source software that are\u00a0available. Software \ndevelopment companies can build their own database of reusable components without \nthe risks inherent in using components from external suppliers. Alternatively, you may \ndecide to search code libraries available on the web, such as Sourceforge, GitHub, or \nGoogle Code, to see if source code for the component that you need is available.\nOnce the component search process has identified possible components, you have\u00a0to \nselect candidate components for assessment. In some cases, this will be a straightforward \ntask. Components on the list will directly implement the user requirements, and there will \nnot be competing components that match these requirements. In other cases, however, \nthe selection process is more complex. There will not be a clear mapping of requirements \nonto components. You may find that several components have to be integrated to meet a \nComponent\nselection\nComponent\nsearch\nComponent\nvalidation\nFigure 16.8\u2002  The \ncomponent \nidentification process \n", "page": 479, "type": "text", "section": "Page 479"}
{"text": " \n16.2\u2002 \u25a0\u2002 CBSE processes\u2002 \u2002 479\nspecific requirement or group of requirements. You therefore have to decide which of \nthese component compositions provide the best coverage of the requirements.\nOnce you have selected components for possible inclusion in a system, you should \nthen validate them to check that they behave as advertised. The extent of the validation \nrequired depends on the source of the components. If you are using a component that \nhas been developed by a known and trusted source, you may decide that component \ntesting is unnecessary. You simply test the component when it is integrated with other \ncomponents. On the other hand, if you are using a component from an unknown source, \nyou should always check and test that component before including it in your system.\nComponent validation involves developing a set of test cases for a component \n(or, possibly, extending test cases supplied with that component) and developing a \ntest harness to run component tests. The major problem with component validation \nis that the component specification may not be sufficiently detailed to allow you to \ndevelop a complete set of component tests. Components are usually specified infor-\nmally, with the only formal documentation being their interface specification. This \nmay not include enough information for you to develop a complete set of tests that \nwould convince you that the component\u2019s advertised interface is what you require.\nAs well as testing that a component for reuse does what you require, you may also \nhave to check that the component does not include malicious code or functionality \nthat you don\u2019t need. Professional developers rarely use components from untrusted \nsources, especially if these sources do not provide source code. Therefore, the mali-\ncious code problem does not usually arise. However, reused components may often \ncontain functionality that you don\u2019t need, and you have to check that this functional-\nity will not interfere with your use of the component.\nThe problem with unnecessary functionality is that it may be activated by the \ncomponent itself. While this may have no effect on the application reusing the com-\nponent, it can slow down the component, cause it to produce surprising results or, in \nexceptional cases, cause serious system failures. Figure 16.9 summarizes a situation \nwhere the failure of a reused software system, which had unnecessary functionality, \nled to catastrophic system failure.\nThe Ariane 5 launcher failure\nWhile developing the Ariane 5 space launcher, the designers decided to reuse the inertial reference software \nthat had performed successfully in the Ariane 4 launcher. The inertial reference software maintains the stability \nof the rocket. The designers decided to reuse this without change (as you would do with components), \nalthough it included additional functionality that was not required in Ariane 5.\nIn the first launch of Ariane 5, the inertial navigation software failed, and the rocket could not be controlled. \nThe rocket and its payload were destroyed. The cause of the problem was an unhandled exception when a con-\nversion of a fixed-point number to an integer resulted in a numeric overflow. This caused the runtime system to \nshut down the inertial reference system, and launcher stability could not be maintained. The fault had never \noccurred in Ariane 4 because it had less powerful engines and the value that was converted could not be large \nenough for the conversion to overflow.\nThis illustrates an important problem with software reuse. Software may be based on assumptions about the \ncontext where the system will be used, and these assumptions may not be valid in a different situation.\nMore information about this failure is available at: http://software-engineering-book.com/case-studies/ariane5/\nFigure 16.9\u2002 An \nexample\u00a0of validation \nfailure with reused \nsoftware\n", "page": 480, "type": "text", "section": "Page 480"}
{"text": "480\u2002 \u2002 Chapter 16\u2002 \u25a0\u2002 Component-based software engineering\nThe problem in the Ariane 5 launcher arose because the assumptions made about \nthe software for Ariane 4 were invalid for Ariane 5. This is a general problem with \nreusable components. They are originally implemented for a specific application \nenvironment and, naturally, embed assumptions about that environment. These \nassumptions are rarely documented, so when the component is reused, it is impossi-\nble to develop tests to check if the assumptions are still valid. If you are reusing a \ncomponent in a new environment, you may not discover the embedded environmen-\ntal assumptions until you use the component in an operational system.\n \n16.3  Component composition\nComponent composition is the process of integrating components with each other, \nand with specially written \u201cglue code\u201d to create a system or another component. You \ncan compose components in several different ways, as shown in Figure 16.10. From \nleft to right these diagrams illustrate sequential composition, hierarchical composi-\ntion, and additive composition. In the discussion below, I assume that you are com-\nposing two components (A and B) to create a new component:\n1.\t\nSequential composition In a sequential composition, you create a new compo-\nnent from two existing components by calling the existing components in \nsequence. You can think of the composition as a composition of the \u201cprovides \ninterfaces.\u201d That is, the services offered by component A are called, and the \nresults returned by A are then used in the call to the services offered by compo-\nnent B. The components do not call each other in sequential composition but are \ncalled by the external application. This type of composition may be used with \nembedded or service components.\n\t\nSome extra glue code may be required to call the component services in the right \norder and to ensure that the results delivered by component A are compatible \nwith the inputs expected by component B. The \u201cglue code\u201d transforms these \noutputs to be of the form expected by component B.\n2.\t\nHierarchical composition This type of composition occurs when one component \ncalls directly on the services provided by another component. That is, \u00ad\ncomponent \nA calls component B. The called component provides the services that are required \nby the calling component. Therefore, the \u201cprovides\u201d interface of the called com-\nponent must be compatible with the \u201crequires\u201d interface of the calling component.\n\t\nComponent A calls on component B directly, and, if their interfaces match, \nthere may be no need for additional code. However, if there is a mismatch \nbetween the \u201crequires\u201d interface of A and the \u201cprovides\u201d interface of B, then \nsome conversion code may be required. As services do not have a \u201crequires\u201d \ninterface, this mode of composition is not used when components are imple-\nmented as services accessed over the web.\n", "page": 481, "type": "text", "section": "Page 481"}
{"text": " \n16.3\u2002 \u25a0\u2002 Component composition\u2002 \u2002 481\n3.\t\nAdditive composition This occurs when two or more components are put together \n(added) to create a new component, which combines their functionality. The \u201cpro-\nvides\u201d interface and \u201crequires\u201d interface of the new component are a combination \nof the corresponding interfaces in components A and B. The components are \ncalled separately through the external interface of the composed component and \nmay be called in any order. A and B are not dependent and do not call each other. \nThis type of composition may be used with embedded or service components.\nYou might use all the forms of component composition when creating a system. \nIn all cases, you may have to write \u201cglue code\u201d that links the components. For exam-\nple, for sequential composition, the output of component A typically becomes the \ninput to component B. You need intermediate statements that call component A, \ncollect the result, and then call component B, with that result as a parameter. When \none component calls another, you may need to introduce an intermediate component \nthat ensures that the \u201cprovides\u201d interface and the \u201crequires\u201d interface are compatible.\nWhen you write new components especially for composition, you should design the \ninterfaces of these components so that they are compatible with other components in \nthe system. You can therefore easily compose these components into a \u00ad\nsingle unit. \nHowever, when components are developed independently for reuse, you will often be \nfaced with interface incompatibilities. This means that the interfaces of the components \nthat you wish to compose are not the same. Three types of incompatibility can occur:\n1.\t\nParameter incompatibility The operations on each side of the interface have the \nsame name, but their parameter types or the number of parameters are different. In \nFigure 16.11, the location parameter returned by addressFinder is incompatible \nwith the parameters required by the displayMap and printMap methods in mapDB.\n2.\t\nOperation incompatibility The names of the operations in the provides and \n\u201crequires\u201d interfaces are different. This is a further incompatibility between the \ncomponents shown in Figure 16.11.\n3.\t\nOperation incompleteness The \u201cprovides\u201d interface of a component is a subset \nof the \u201crequires\u201d interface of another component, or vice versa.\n(1)\nA\nA\nB\nB\nA\nB\n(2)\n(3)\nFigure 16.10\u2002  Types of \ncomponent composition \n", "page": 482, "type": "text", "section": "Page 482"}
{"text": "482\u2002 \u2002 Chapter 16\u2002 \u25a0\u2002 Component-based software engineering\nIn all cases, you tackle the problem of incompatibility by writing an adaptor that \nreconciles the interfaces of the two components being reused. An adaptor compo-\nnent converts one interface to another.\nThe precise form of the adaptor depends on the type of composition. Sometimes, as \nin the next example, the adaptor takes a result from one component and converts it into \na form where it can be used as an input to another. In other cases, the adaptor may be \ncalled by component A as a proxy for component B. This situation occurs if A wishes \nto call B, but the details of the \u201crequires\u201d interface of A do not match the details of the \n\u201cprovides\u201d interface of B. The adaptor reconciles these differences by converting its \ninput parameters from A into the required input parameters for B. It then calls B to \ndeliver the services required by A.\nTo illustrate adaptors, consider the two simple components shown in Figure 16.11, \nwhose interfaces are incompatible. These might be part of a system used by the emer-\ngency services. When the emergency operator takes a call, the phone number is input \nto the addressFinder component to locate the address. Then, using the mapper compo-\nnent, the operator prints a map to be sent to the vehicle dispatched to the emergency.\nThe first component, addressFinder, finds the address that matches a phone num-\nber. It can also return the owner of the property associated with the phone number and \nthe type of property. The mapper component takes a post code (in the United States, \na standard ZIP code with the additional four digits identifying property location) and \ndisplays or prints a street map of the area around that code at a specified scale.\nThese components are composable in principle because the property location \nincludes the post or ZIP code. However, you have to write an adaptor component \ncalled postCodeStripper that takes the location data from addressFinder and strips out \nthe post code. This post code is then used as an input to mapper, and the street map is \ndisplayed at a scale of 1:10,000. The following code, which is an example of sequential \ncomposition, illustrates the sequence of calls that is required to implement this process:\naddress = addressFinder.location (phonenumber) ;\npostCode = postCodeStripper.getPostCode (address) ;\nmapper.displayMap(postCode, 10000) ;\nAnother case in which an adaptor component may be used is in hierarchical composi-\ntion, where one component wishes to make use of another but there is an incompatibility \naddressFinder\nphoneDatabase (string command)\nstring location (string pn)\nstring owner (string pn)\nstring propertyType (string pn)\nmapper\nmapDB (string command)\ndisplayMap (string postCode, scale)\nprintMap (string postCode, scale)\nFigure 16.11\u2002  \nComponents with \nincompatible interfaces \n", "page": 483, "type": "text", "section": "Page 483"}
{"text": " \n16.3\u2002 \u25a0\u2002 Component composition\u2002 \u2002 483\nbetween the \u201cprovides\u201d interface and \u201crequires\u201d interface of the components in the \ncomposition. I have illustrated the use of an adaptor in Figure 16.12 where an adaptor \nis used to link a data collector and a sensor component. These could be used in the \nimplementation of a wilderness weather station system, as discussed in Chapter 7.\nThe sensor and data collector components are composed using an adaptor that \nreconciles the \u201crequires\u201d interface of the data collection component with the \u201cpro-\nvides\u201d interface of the sensor component. The data collector component has been \ndesigned with a generic \u201crequires\u201d interface that supports sensor data collection and \nsensor management. For each of these operations, the parameter is a text string rep-\nresenting the specific sensor commands. For example, to issue a collect command, \nyou would say sensorData(\u201ccollect\u201d). As I have shown in Figure 16.12, the sensor \nitself has separate operations such as start, stop, and getdata.\nThe adaptor parses the input string, identifies the command (e.g., collect), and then calls \nSensor.getdata to collect the sensor value. It then returns the result (as a character string) \nto the data collector component. This interface style means that the data collector can interact\u00a0 \nwith different types of sensor. A separate adaptor, which converts the sensor commands \nfrom Data collector to the sensor interface, is implemented for each type of sensor.\nThe above discussion of component composition assumes you can tell from the \ncomponent documentation whether or not interfaces are compatible. Of course, the \ninterface definition includes the operation name and parameter types, so you can make \nsome assessment of the compatibility from this. However, you depend on the compo-\nnent documentation to decide whether the interfaces are semantically compatible.\nTo illustrate this problem, consider the composition shown in Figure 16.13. These \ncomponents are used to implement a system that downloads images from a camera and \nstores them in a photograph library. The system user can provide additional information \nto describe and catalog the photograph. To avoid clutter, I have not shown all interface \nData collector\naddSensor\nremoveSensor\nstartSensor\nstopSensor\ntestSensor\nlistAll\nreport\ninitialize\nsensorManagement\nsensorData\nAdaptor\nsensor\nstart\ngetdata\nstop\nFigure 16.12\u2002  An \nadaptor linking a data \ncollector and a sensor \nPhoto\nLibrary\nadaptor\nImage\nManager\ngetImage\nUser\nInterface\ngetCatalogEntry\naddItem\nretrieve\ncatEntry\nFigure 16.13\u2002  Photo \nlibrary composition \n", "page": 484, "type": "text", "section": "Page 484"}
{"text": "484\u2002 \u2002 Chapter 16\u2002 \u25a0\u2002 Component-based software engineering\nmethods here. Rather, I simply show the methods that are needed to illustrate the com-\nponent documentation problem. The methods in the interface of Photo Library are:\npublic void addItem (Identifier pid ; Photograph p; CatalogEntry photodesc) ;\npublic Photograph retrieve (Identifier pid) ;\npublic CatalogEntry catEntry (Identifier pid) ;\nAssume that the documentation for the addItem method in Photo Library is:\nThis method adds a photograph to the library and associates the photograph \nidentifier and catalog descriptor with the photograph.\nThis description appears to explain what the component does, but consider the \nfollowing questions:\n\u25a0\t What happens if the photograph identifier is already associated with a photograph \nin the library?\n\u25a0\t Is the photograph descriptor associated with the catalog entry as well as the \n\u00ad\nphotograph? That is, if you delete the photograph, do you also delete the catalog \ninformation?\nThere is not enough information in the informal description of addItem to answer \nthese questions. Of course, it is possible to add more information to the natural lan-\nguage description of the method, but in general, the best way to resolve ambiguities \nis to use a formal language to describe the interface. The specification shown in \nFigure 16.14 is part of the description of the interface of Photo Library that adds \ninformation to the informal description.\n\u2014 The context keyword names the component to which the conditions apply\ncontext addItem\n\u2014 The preconditions specify what must be true before execution of addItem\npre:\u2002\u2002\u2002\u2002\u2002\u2009\nPhotoLibrary.libSize() > 0\n\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2006\n\u2006\n\u2006\nPhotoLibrary.retrieve(pid) = null\n\u2014 The postconditions specify what is true after execution\npost:\u2002\u2002\u2002\u2002libSize () = libSize()@pre + 1\n\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002PhotoLibrary.retrieve(pid) = p\n\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002PhotoLibrary.catEntry(pid) = photodesc\ncontext delete\npre:\u2002\u2002\u2002\u2002\u2002\u2009\nPhotoLibrary.retrieve(pid) <> null ;\npost:\u2002\u2002\u2002\u2002PhotoLibrary.retrieve(pid) = null\n\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002PhotoLibrary.catEntry(pid) = PhotoLibrary.catEntry(pid)@pre\n\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002\u2002PhotoLibrary.libSize() = libSize()@pre\u20141\nFigure 16.14\u2002 The \nOCL\u00a0description of \nthe\u00a0Photo\u00a0Library \ninterface\n", "page": 485, "type": "text", "section": "Page 485"}
{"text": " \n16.3\u2002 \u25a0\u2002 Component composition\u2002 \u2002 485\nFigure 16.14 shows pre- and postconditions that are defined in a notation based on \nthe object constraint language (OCL), which is part of the UML (Warmer and Kleppe \n2003). OCL is designed to describe constraints in UML object models; it allows you \nto express predicates that must always be true, that must be true before a method has \nexecuted; and that must be true after a method has executed. These are invariants, \npreconditions, and postconditions. To access the value of a variable before an opera-\ntion, you add @pre after its name. Therefore, using age as an \u00ad\nexample:\nage = age@pre + 1\nThis statement means that the value of age after an operation is one more than it \nwas before that operation.\nOCL-based approaches are primarily used in model-based software engineering \nto add semantic information to UML models. The OCL descriptions may be used to \ndrive code generators in model-driven engineering. The general approach has been \nderived from Meyer\u2019s Design by Contract approach (Meyer 1992), in which the \ninterfaces and obligations of communicating objects are formally specified and \nenforced by the runtime system. Meyer suggests that using Design by Contract is \nessential if we are to develop trusted components (Meyer 2003).\nFigure 16.14 shows the specification for the addItem and delete methods in Photo \nLibrary. The method being specified is indicated by the keyword context and the pre- and \npostconditions by the keywords pre and post. The preconditions for addItem state that:\n1.\t\nThere must not be a photograph in the library with the same identifier as the \nphotograph to be entered.\n2.\t\nThe library must exist\u2014assume that creating a library adds a single item to it so \nthat the size of a library is always greater than zero.\n3.\t\nThe postconditions for addItem state that:\n\t\nThe size of the library has increased by 1 (so only a single entry has been made).\n\t\nIf you retrieve using the same identifier, then you get back the photograph that \nyou added.\n\t\nIf you look up the catalog using that identifier, you get back the catalog entry \nthat you made.\nThe specification of delete provides further information. The precondition states \nthat to delete an item, it must be in the library, and, after deletion, the photo can no \nlonger be retrieved and the size of the library is reduced by 1. However, delete does \nnot delete the catalog entry\u2014you can still retrieve it after the photo has been deleted. \nThe reason for this is that you may wish to maintain information in the catalog about \nwhy a photo was deleted, its new location, and so on.\nWhen you create a system by composing components, you may find that there \nare potential conflicts between functional and non-functional requirements, the \nneed to deliver\u00a0a system as quickly as possible, and the need to create a system that \n", "page": 486, "type": "text", "section": "Page 486"}
{"text": "486\u2002 \u2002 Chapter 16\u2002 \u25a0\u2002 Component-based software engineering\ncan evolve as requirements change. You may have to take trade-offs into account \nfor component decisions:\n1.\t\nWhat composition of components is most effective for delivering the functional \nrequirements for the system?\n2.\t\nWhat composition of the components will make it easier to adapt the composite \ncomponent when its requirements change?\n3.\t\nWhat will be the emergent properties of the composed system? These properties \ninclude performance and dependability. You can only assess these properties \nonce the complete system is implemented.\nUnfortunately, in many situations the solutions to the composition problems may \nconflict. For example, consider a situation such as that illustrated in Figure 16.15, \nwhere a system can be created through two alternative compositions. The system is \na data collection and reporting system where data is collected from different sources, \nstored in a database, and then different reports summarizing that data are produced.\nHere, there is a potential conflict between adaptability and performance. \nComposition (a) is more adaptable, but composition (b) is likely to be faster and more \nreliable. The advantages of composition (a) are that reporting and data management \nare separate, so there is more flexibility for future change. The data management \nsystem could be replaced, and, if reports are required that the current reporting com-\nponent cannot produce, that component can also be replaced without having to \nchange the data management component.\nIn composition (b), a database component with built-in reporting facilities (e.g., \nMicrosoft Access) is used. The key advantage of composition (b) is that there are fewer \ncomponents, so this will be a faster implementation because there are no component \ncommunication overheads. Furthermore, data integrity rules that apply to the database \nwill also apply to reports. These reports will not be able to combine data in incorrect \nways. In composition (a), there are no such constraints, so errors in reports could occur.\nIn general, a good composition principle to follow is the principle of separation of \nconcerns. That is, you should try to design your system so that each component has \na clearly defined role. Ideally, component roles should not overlap. However, it may \nbe cheaper to buy one multifunctional component rather than two or three separate \ncomponents. Furthermore, dependability or performance penalties may be incurred \nwhen multiple components are used.\n(a)\nData\ncollection\n(b)\nData\nmanagement\nReport\ngenerator\nData\ncollection\nDatabase\nReport\nReport\nFigure 16.15\u2002  Data \ncollection and report \ngeneration components \n", "page": 487, "type": "text", "section": "Page 487"}
{"text": " \n16.3\u2002 \u25a0\u2002 Component composition\u2002 \u2002 487\nKey Points\n\u25a0\t Component-based software engineering is a reuse-based approach to defining, implementing, \nand composing loosely coupled independent components into systems.\n\u25a0\t A component is a software unit whose functionality and dependencies are completely defined \nby a set of public interfaces. Components can be composed with other components without \nknowledge of their implementation and can be deployed as an executable unit.\n\u25a0\t Components may be implemented as executable routines that are included in a system or as \nexternal services that are referenced from within a system.\n\u25a0\t A component model defines a set of standards for components, including interface standards, \nusage standards, and deployment standards. The implementation of the component model pro-\nvides a set of common services that may be used by all components.\n\u25a0\t During the CBSE process, you have to interleave the processes of requirements engineering and \nsystem design. You have to trade off desirable requirements against the services that are avail-\nable from existing reusable components.\n\u25a0\t Component composition is the process of \u201cwiring\u201d components together to create a system. \nTypes of composition include sequential composition, hierarchical composition, and additive \ncomposition.\n\u25a0\t When composing reusable components that have not been written for your application, you may \nneed to write adaptors or \u201cglue code\u201d to reconcile the different component interfaces.\n\u25a0\t When choosing compositions, you have to consider the required functionality of the system, the \nnon-functional requirements, and the ease with which one component can be replaced when the \nsystem is changed.\nFurther Reading\nComponent Software: Beyond Object-Oriented Programming, 2nd ed. This updated edition of the \nfirst book on CBSE covers technical and nontechnical issues in CBSE. It has more detail on specific \ntechnologies than Heineman and Councill\u2019s book and includes a thorough discussion of market \nissues. (C. Szyperski, Addison-Wesley, 2002).\n\u201cSpecification, Implementation and Deployment of Components.\u201d A good introduction to the funda-\nmentals of CBSE. The same issue of the CACM includes articles on components and component-\nbased development. (I. Crnkovic, B. Hnich, T. Jonsson, and Z. Kiziltan, Comm. ACM, 45(10), October \n2002) http://dx.doi.org/10.1145/570907.570928\n\u201cSoftware Component Models.\u201d This comprehensive discussion of commercial and research compo-\nnent models classifies these models and explains the differences between them. (K-K. Lau and Z. \nWang, IEEE Transactions on Software Engineering, 33 (10), October 2007) http://dx.doi.\norg/10.1109/TSE.2007.70726\n \nChapter 16\u2002 \u25a0\u2002 Further reading\u2002 \u2002 487\n", "page": 488, "type": "text", "section": "Page 488"}
{"text": "488\u2002 \u2002 Chapter 16\u2002 \u25a0\u2002 Component-based software engineering\n\u201cSoftware Components Beyond Programming: From Routines to Services.\u201d This is the opening arti-\ncle in a special issue of the magazine that includes several articles on software components. This \narticle discusses the evolution of components and how service-oriented components are replacing \nexecutable program routines. (I. Crnkovic, J. Stafford, and C. Szyperski, IEEE Software, 28 (3), May/\nJune 2011) http://dx.doi.org/10.1109/MS.2011.62\nObject Constraint Language (OCL) Tutorial. A good introduction to the use of the object-constraint \nlanguage. (J. Cabot, 2012) http://modeling-languages.com/ocl-tutorial/\nWebsite\nPowerPoint slides for this chapter:\nwww.pearsonglobaleditions.com/Sommerville\nLinks to supporting videos:\nhttp://software-engineering-book.com/videos/software-reuse/\nA more detailed discussion of the Ariane5 accident:\nhttp://software-engineering-book.com/case-studies/ariane5/\nExercises\n16.1.\t What are the design principles underlying the CBSE that support the construction of under-\nstandable and maintainable software?\n16.2.\t The principle of component independence means that it ought to be possible to replace one \ncomponent with another that is implemented in a completely different way. Using an example, \nexplain how such component replacement could have undesired consequences and may lead \nto system failure.\n16.3.\t In a reusable component, what are the critical characteristics that are emphasized when the \ncomponent is viewed as a service?\n16.4.\t Why is it important that components should be based on a standard component model?\n16.5.\t Using an example of a component that implements an abstract data type such as a stack or a \nlist, show why it is usually necessary to extend and adapt components for reuse.\n16.6.\t What are the essential differences between CBSE with reuse and software processes for original \nsoftware development?\n16.7.\t Design the \u201cprovides\u201d interface and the \u201crequires\u201d interface of a reusable component that \nmay be used to represent a patient in the Mentcare system that I introduced in Chapter 1.\n488\u2002 \u2002 Chapter 16\u2002 \u25a0\u2002 Component-based software engineering\n", "page": 489, "type": "text", "section": "Page 489"}
{"text": " \n16.3\u2002 \u25a0\u2002 Component composition\u2002 \u2002 489\n\u2002 16.8.\t \u0007\nUsing examples, illustrate the different types of adaptor needed to support sequential com-\nposition, hierarchical composition, and additive composition.\n\u2002 16.9.\t \u0007\nDesign the interfaces of components that might be used in a system for an emergency con-\ntrol room. You should design interfaces for a call-logging component that records calls \nmade, and a vehicle discovery component that, given a post code (zip code) and an incident \ntype, finds the nearest suitable vehicle to be dispatched to the incident.\n16.10.\t \u0007\nIt has been suggested that an independent certification authority should be established. Vendors \nwould submit their components to this authority, which would validate that the component was \ntrustworthy. What would be the advantages and disadvantages of such a certification authority?\nReferences\nCouncill, W. T., and G. T. Heineman. 2001. \u201cDefinition of a Software Component and Its Elements.\u201d \nIn\u00a0Component-Based Software Engineering, edited by G. T. Heineman and W. T. Councill, 5\u201320. \n\u00ad\nBoston: Addison-Wesley.\nJacobsen, I., M. Griss, and P. Jonsson. 1997. Software Reuse. Reading, MA: Addison-Wesley.\nKotonya, G. 2003. \u201cThe CBSE Process: Issues and Future Visions.\u201d In 2nd CBSEnet Workshop. Budapest, \nHungary. http://miro.sztaki.hu/projects/cbsenet/budapest/presentations/Gerald-CBSEProcess.ppt\nLau, K-K., and Z. Wang. 2007. \u201cSoftware Component Models.\u201d IEEE Trans. on Software Eng. 33 (10): \n709\u2013724. doi:10.1109/TSE.2007.70726.\nMeyer, B. 1992. \u201cApplying Design by Contract.\u201d IEEE Computer 25 (10): 40\u201351. doi:10.1109/2.161279.\n\t\n\u2002 \u2002 . 2003. \u201cThe Grand Challenge of Trusted Components.\u201d In Proc. 25th Int. Conf. on Software \nEngineering. Portland, OR: IEEE Press. doi:10.1109/ICSE.2003.1201252.\nMili, H., A. Mili, S. Yacoub, and E. Addy. 2002. Reuse-Based Software Engineering. New York: John \nWiley & Sons.\nPope, A. 1997. The CORBA Reference Guide: Understanding the Common Object Request Broker \nArchitecture. Harlow, UK: Addison-Wesley.\nSzyperski, C. 2002. Component Software: Beyond Object-Oriented Programming, 2nd ed. Harlow, \nUK: Addison-Wesley.\nWarmer, J., and A. Kleppe. 2003. The Object Constraint Language: Getting Your Models Ready for \nMDA. Boston: Addison-Wesley.\nWeinreich, R., and J. Sametinger. 2001. \u201cComponent Models and Component Services: Concepts and \nPrinciples.\u201d In Component-Based Software Engineering, edited by G. T. Heineman and W. T. Councill, \n33\u201348. Boston: Addison-Wesley.\nWheeler, W., and J. White. 2013. Spring in Practice. Greenwich, CT: Manning Publications.\n \nChapter 16\u2002 \u25a0\u2002 References\u2002 \u2002 489\n", "page": 490, "type": "text", "section": "Page 490"}
{"text": "Distributed software \n17 \nObjectives\nThe objective of this chapter is to introduce distributed systems \nengineering and distributed systems architectures. When you have \nread this chapter, you will:\n\u25a0\t know the key issues that have to be considered when designing \nand implementing distributed software systems;\n\u25a0\t understand the client\u2013server computing model and the layered \narchitecture of client\u2013server systems;\n\u25a0\t have been introduced to commonly used patterns for distributed \nsystems architectures and know the types of system for which \neach architectural pattern is applicable;\n\u25a0\t understand the notion of software as a service, providing web-\nbased access to remotely deployed application systems.\nContents\n17.1\t Distributed systems\n17.2\t Client\u2013server computing\n17.3\t Architectural patterns for distributed systems\n17.4\t Software as a service\nengineering\n", "page": 491, "type": "text", "section": "Page 491"}
{"text": " \n\ufeff\nChapter 17\u2002 \u25a0\u2002 Distributed software engineering\u2002 \u2002 491\nMost computer-based systems are now distributed systems. A distributed system is one \ninvolving several computers rather than a single application running on a single machine. \nEven apparently self-contained applications on a PC or laptop, such as image editors, are \ndistributed systems. They execute on a single computer system but often rely on remote \ncloud systems for update, storage, and other services. Tanenbaum and Van Steen \n(Tanenbaum and Van Steen 2007) define a distributed system to be \u201ca collection of \nindependent computers that appears to the user as a single coherent system.\u201d\u2020\nWhen you are designing a distributed system, there are specific issues that have to \nbe taken into account simply because the system is distributed. These issues arise \nbecause different parts of the system are running on independently managed com-\nputers and because the characteristics of the network, such as latency and reliability, \nmay have to be considered in your design.\nCoulouris et al. (Coulouris et al. 2011) identify the five benefits of developing \nsystems as distributed systems:\n1.\t\nResource sharing A distributed system allows the sharing of hardware and soft-\nware resources\u2014such as disks, printers, files, and compilers\u2014that are associated \nwith computers on a network.\n2.\t\nOpenness Distributed systems are normally open systems\u2014systems designed \naround standard Internet protocols so that equipment and software from different \nvendors can be combined.\n3.\t\nConcurrency In a distributed system, several processes may operate at the same \ntime on separate computers on the network. These processes may (but need not) \ncommunicate with each other during their normal operation.\n4.\t\nScalability In principle at least, distributed systems are scalable in that the capa-\nbilities of the system can be increased by adding new resources to cope with \nnew demands on the system. In practice, the network linking the individual \ncomputers in the system may limit the system scalability.\n5.\t\nFault tolerance The availability of several computers and the potential for replicat-\ning information means that distributed systems can be tolerant of some hardware \nand software failures (see Chapter 11). In most distributed systems, a degraded \nservice can be provided when failures occur; complete loss of service only occurs \nwhen there is a network failure.\u2021\nDistributed systems are inherently more complex than centralized systems. This \nmakes them more difficult to design, implement, and test. It is harder to understand \nthe emergent properties of distributed systems because of the complexity of the inter-\nactions between system components and system infrastructure. For example, rather \nthan being dependent on the execution speed of one processor, system performance \n\u2020Tanenbaum, A. S., and M. Van Steen. 2007. Distributed Systems: Principles and Paradigms, 2nd Ed. \nUpper Saddle River, NJ: Prentice-Hall.\n\u2021Coulouris, G., J. Dollimore, T. Kindberg, and G. Blair. 2011. Distributed Systems: Concepts and  \nDesign, 5th Edition. Harlow, UK.: Addison Wesley.\n", "page": 492, "type": "text", "section": "Page 492"}
{"text": "492\u2002 \u2002 Chapter 17\u2002 \u25a0\u2002 Distributed software engineering\ndepends on network bandwidth, network load, and the speed of other computers that \nare part of the system. Moving resources from one part of the system to another can \nsignificantly affect the system\u2019s performance.\nFurthermore, as all users of the WWW know, distributed systems are unpredictable in \ntheir response. Response time depends on the overall load on the system, its \u00ad\narchitecture, \nand the network load. As all of these factors may change over a short time, the time taken \nto respond to a user request may change significantly from one request to another.\nThe most important developments that have affected distributed software systems in \nthe past few years are service-oriented systems and the advent of cloud computing, \ndelivering infrastructure, platforms, and software as a service. In this chapter, I focus on \ngeneral issues of distributed systems, and in Section 17.4 I cover the idea of software as \na service. In Chapter 18, I discuss other aspects of service-oriented software engineering.\n \n17.1  Distributed systems\nAs I discussed in the introduction to this chapter, distributed systems are more complex \nthan systems that run on a single processor. This complexity arises because it is practi-\ncally impossible to have a top-down model of control of these systems. The nodes in the \nsystem that deliver functionality are often independent systems that are managed and \ncontrolled by their owners. There is no single authority in charge of the entire distributed \nsystem. The network connecting these nodes is also a separately managed system. It is a \ncomplex system in its own right and cannot be controlled by the owners of systems \nusing the network. There is, therefore, an inherent unpredictability in the operation of \ndistributed systems that has to be taken into account when you are designing a system.\nSome of the most important design issues that have to be considered in distrib-\nuted systems engineering are:\n1.\t\nTransparency To what extent should the distributed system appear to the user as a \nsingle system? When is it useful for users to understand that the system is distributed?\n2.\t\nOpenness Should a system be designed using standard protocols that support \ninteroperability, or should more specialized protocols be used? Although stand-\nard network protocols are now universally used, this is not the case for higher \nlevels of interaction, such as service communication.\n3.\t\nScalability How can the system be constructed so that it is scalable? That is, \nhow can the overall system be designed so that its capacity can be increased in \nresponse to increasing demands made on the system?\n4.\t\nSecurity How can usable security policies be defined and implemented that \napply across a set of independently managed systems?\n5.\t\nQuality of service How should the quality of service that is delivered to system \nusers be specified, and how should the system be implemented to deliver an \nacceptable quality of service to all users.\n6.\t\nFailure management How can system failures be detected, contained (so that \nthey have minimal effects on other components in the system), and repaired?\n", "page": 493, "type": "text", "section": "Page 493"}
{"text": " \n17.1\u2002 \u25a0\u2002 Distributed systems\u2002 \u2002 493\nIn an ideal world, the fact that a system is distributed would be transparent to users. \nUsers would see the system as a single system whose behavior is not affected by the \nway that the system is distributed. In practice, this is impossible to achieve because \nthere is no central control over the system as a whole. As a result, individual comput-\ners in a system may behave differently at different times. Furthermore, because it \nalways takes a finite length of time for signals to travel across a network, network \ndelays are unavoidable. The length of these delays depends on the location of resources \nin the system, the quality of the user\u2019s network connection, and the \u00ad\nnetwork load.\nTo make a distributed system transparent (i.e., conceal its distributed nature), you \nhave to hide the underlying distribution. You create abstractions that hide the system \nresources so that the location and implementation of these resources can be changed \nwithout having to change the distributed application. Middleware (discussed in \nSection 17.1.2) is used to map the logical resources referenced by a program onto the \nactual physical resources and to manage resource interactions.\nIn practice, it is impossible to make a system completely transparent, and users, gener-\nally, are aware that they are dealing with a distributed system. You may therefore decide \nthat it is best to expose the distribution to users. They can then be prepared for some of \nthe consequences of distribution such as network delays and remote node failures.\nOpen distributed systems are built according to generally accepted standards. \nComponents from any supplier can therefore be integrated into the system and can \ninteroperate with the other system components. At the networking level, openness is \nnow taken for granted, with systems conforming to Internet protocols, but at the \ncomponent level, openness is still not universal. Openness implies that system com-\nponents can be independently developed in any programming language and, if these \nconform to standards, they will work with other components.\nThe CORBA standard (Pope 1997), developed in the 1990s, was intended to be \nthe universal standard for open distributed systems, However, the CORBA standard \nnever achieved a critical mass of adopters. Rather, many companies preferred to \ndevelop systems using proprietary standards for components from companies such as \nSun (now Oracle) and Microsoft. These provided better implementations and support \nsoftware and better long-term support for industrial protocols.\nWeb service standards (discussed in Chapter 18) for service-oriented architec-\ntures were developed to be open standards. However, these standards have met with \nsignificant resistance because of their perceived inefficiency. Many developers of \nservice-based systems have opted instead for so-called RESTful protocols because \nCORBA\u2014Common Object Request Broker Architecture\nCORBA was proposed as a specification for a middleware system in the 1990s by the Object Management \nGroup. It was intended as an open standard that would allow the development of middleware to support dis-\ntributed component communications and execution, as well as provide a set of standard services that could be \nused by these components.\nSeveral implementations of CORBA were produced, but the system was not widely adopted. Users preferred \nproprietary systems such as those from Microsoft or Oracle, or they moved to service-oriented architectures.\nhttp://software-engineering-book.com/web/corba/\n", "page": 494, "type": "text", "section": "Page 494"}
{"text": "494\u2002 \u2002 Chapter 17\u2002 \u25a0\u2002 Distributed software engineering\nthese have an inherently lower overhead than web service protocols. The use of \nRESTful protocols is not standardized.\nThe scalability of a system reflects its ability to deliver high-quality service as \ndemands on the system increase. The three dimensions of scalability are size, distri-\nbution, and manageability.\n1.\t\nSize It should be possible to add more resources to a system to cope with increas-\ning numbers of users. Ideally, then, as the number of users increases, the system \nshould increase in size automatically to handle the increased number of users.\n2.\t\nDistribution It should be possible to geographically disperse the components of \na system without degrading its performance. As new components are added, it \nshould not matter where these are located. Large companies can often make use \nof computing resources in their different facilities around the world.\n3.\t\nManageability It should be possible to manage a system as it increases in size, \neven if parts of the system are located in independent organizations. This is one \nof the most difficult challenges of scale as it involves managers communicating \nand agreeing on management policies. In practice, the manageability of a sys-\ntem is often the factor that limits the extent to which it can be scaled.\nChanging the size of a system may involve either scaling up or scaling out. Scaling \nup means replacing resources in the system with more powerful resources. For exam-\nple, you may increase the memory in a server from 16 Gb to 64 Gb. Scaling out means \nadding more resources to the system (e.g., an extra web server to work alongside an \nexisting server). Scaling out is often more cost-effective than scaling up, especially \nnow that cloud computing makes it easy to add or remove servers from a system. \nHowever, this only provides performance improvements when concurrent processing \nis possible.\nI have discussed general security issues and issues of security engineering in Part 2 of \nthis book. When a system is distributed, attackers may target any of the individual system \ncomponents or the network itself. If a part of the system is successfully attacked, then the \nattacker may be able to use this as a \u201cback door\u201d into other parts of the system.\nA distributed system must defend itself against the following types of attack:\n1.\t\nInterception, where an attacker intercepts communications between parts of the \nsystem so that there is a loss of confidentiality.\n2.\t\nInterruption, where system services are attacked and cannot be delivered as \nexpected. Denial-of-service attacks involve bombarding a node with illegitimate \nservice requests so that it cannot deal with valid requests.\n3.\t\nModification, where an attacker gains access to the system and changes data or \nsystem services.\n4.\t\nFabrication, where an attacker generates information that should not exist and \nthen uses this information to gain some privileges. For example, an attacker \nmay generate a false password entry and use this to gain access to a system.\n", "page": 495, "type": "text", "section": "Page 495"}
{"text": " \n17.1\u2002 \u25a0\u2002 Distributed systems\u2002 \u2002 495\nThe major difficulty in distributed systems is establishing a security policy that \ncan be reliably applied to all of the components in a system. As I discussed in Chapter \n13, a security policy sets out the level of security to be achieved by a system. Security \nmechanisms, such as encryption and authentication, are used to enforce the security \npolicy. The difficulties in a distributed system arise because different organizations \nmay own parts of the system. These organizations may have mutually incompatible \nsecurity policies and security mechanisms. Security compromises may have to be \nmade in order to allow the systems to work together.\nThe quality of service (QoS) offered by a distributed system reflects the system\u2019s \nability to deliver its services dependably and with a response time and throughput \nthat are acceptable to its users. Ideally, the QoS requirements should be specified in \nadvance and the system designed and configured to deliver that QoS. Unfortunately, \nthis is not always practicable for two reasons:\n1.\t\nIt may not be cost-effective to design and configure the system to deliver a high \nquality of service under peak load. The peak demands may mean that you need \nmany extra servers than normal to ensure that response times are maintained. \nThis problem has been lessened by the advent of cloud computing where cloud \nservers may be rented from a cloud provider for as long as they are required. As \ndemand increases, extra servers can be automatically added.\n2.\t\nThe quality-of-service parameters may be mutually contradictory. For example, \nincreased reliability may mean reduced throughput, as checking procedures are \nintroduced to ensure that all system inputs are valid.\nQuality of service is particularly important when the system is dealing with time-\ncritical data such as sound or video streams. In these circumstances, if the quality of \nservice falls below a threshold value then the sound or video may become so \ndegraded that it is impossible to understand. Systems dealing with sound and video \nshould include quality of service negotiation and management components. These \nshould evaluate the QoS requirements against the available resources and, if these \nare insufficient, negotiate for more resources or for a reduced QoS target.\nIn a distributed system, it is inevitable that failures will occur, so the system has to \nbe designed to be resilient to these failures. Failure is so ubiquitous that one flippant \ndefinition of a distributed system suggested by Leslie Lamport, a prominent distrib-\nuted systems researcher, is:\nYou know that you have a distributed system when the crash of a system that \nyou\u2019ve never heard of stops you getting any work done.\u2020\nThis is even truer now that more and more systems are executing in the cloud. \nFailure management involves applying the fault-tolerance techniques discussed in \nChapter 11. Distributed systems should therefore include mechanisms for discover-\ning whether a component of the system has failed, should continue to deliver as\u00a0many \nservices as possible in spite of that failure, and, as far as possible, should automatically \n\u2020Leslie Lamport, in Ross J. Anderson, Security Engineering: A Guide to Building Dependable Distributed \nSystems (2nd ed.), Wiley (April 14, 2008).\n", "page": 496, "type": "text", "section": "Page 496"}
{"text": "496\u2002 \u2002 Chapter 17\u2002 \u25a0\u2002 Distributed software engineering\nrecover from the failure. One important benefit of cloud computing is that it has \ndramatically reduced the cost of providing redundant system components.\n\t\n17.1.1 \t Models of interaction\nTwo fundamental types of interaction may take place between the computers in a dis-\ntributed computing system: procedural interaction and message-based interaction. \nProcedural interaction involves one computer calling on a known service offered by \nsome other computer and waiting for that service to be delivered. Message-based \ninteraction involves the \u201csending\u201d computer defining information about what is \nrequired in a message, which is then sent to another computer. Messages usually trans-\nmit more information in a single interaction than a procedure call to another machine.\nTo illustrate the difference between procedural and message-based interaction, \nconsider a situation where you are ordering a meal in a restaurant. When you have a \nconversation with the waiter, you are involved in a series of synchronous, procedural \ninteractions that define your order. You make a request, the waiter acknowledges \nthat request, you make another request, which is acknowledged, and so on. This is \ncomparable to components interacting in a software system where one component \ncalls methods from other components. The waiter writes down your order along with \nthe order of other people with you. He or she then passes this order, which includes \ndetails of everything that has been ordered, to the kitchen to prepare the food. \nEssentially, the waiter is passing a message to the kitchen staff, defining the food to \nbe prepared. This is message-based interaction.\nI have illustrated this kind of interaction in Figure 17.1, which shows the synchronous \nordering process as a series of calls, and in Figure 17.2, which shows a hypothetical XML \nmessage that defines an order made by the table of three people. The difference between \nthese forms of information exchange is clear. The waiter takes the order as a series of \nTomato soup please\nWaiter\nDiner\nWhat would you like?\nAnd to follow?\nFillet steak\nHow would you like it cooked?\nRare please\nWith salad or french fries?\nSalad please\netc.\nFigure 17.1\u2002  Procedural \ninteraction between a \ndiner and a waiter \n", "page": 497, "type": "text", "section": "Page 497"}
{"text": " \n17.1\u2002 \u25a0\u2002 Distributed systems\u2002 \u2002 497\ninteractions, with each interaction defining part of the order. However, the waiter has a \nsingle interaction with the kitchen where the message defines the complete order.\nProcedural communication in a distributed system is usually implemented using \nremote procedure calls (RPCs). In an RPC, components have globally unique names \n(such as a URL). Using that name, a component can call on the services offered by \nanother component as if it was a local procedure or method. System middleware \nintercepts this call and passes it on to a remote component. This carries out the \nrequired computation and, via the middleware, returns the result to the calling \n\u00ad\ncomponent. In Java, remote method invocations (RMIs) are remote procedure calls.\nRemote procedure calls require a \u201cstub\u201d for the called procedure to be accessible on \nthe computer that is initiating the call. This stub defines the interface of the remote \nprocedure. The stub is called, and it translates the procedure parameters into a standard \nrepresentation for transmission to the remote procedure. Through the middleware, it \nthen sends the request for execution to the remote procedure. The remote procedure \nuses library functions to convert the parameters into the required format, carries out the \ncomputation, and then returns the results via the \u201cstub\u201d that is representing the caller.\nMessage-based interaction normally involves one component creating a message that \ndetails the services required from another component. This message is sent to the receiv-\ning component via the system middleware. The receiver parses the message, carries out \nthe computations, and creates a message for the sending component with the required \nresults. This is then passed to the middleware for transmission to the sending component.\nA problem with the RPC approach to interaction is that both the caller and the \ncallee need to be available at the time of the communication, and they must know \nhow to refer to each other. In essence, an RPC has the same requirements as a local \nprocedure or method call. By contrast, in a message-based approach, unavailability \ncan be tolerated. If the system component that is processing the message is unavail-\nable, the message simply stays in a queue until the receiver comes back online. \nFurthermore, it is not necessary for the sender to know the name of the message \nreceiver and vice versa. They simply communicate with the middleware, which is \nresponsible for ensuring that messages are passed to the appropriate system.\nFigure 17.2\u2002  \nMessage-based \ninteraction between a  \nwaiter and the kitchen \nstaff\n<starter>\n<dish name = \u201csoup\u201d type = \u201ctomato\u201d />\n<dish name = \u201csoup\u201d type = \u201cfish\u201d />\n<dish name = \u201cpigeon salad\u201d />\n</starter>\n<main course>\n<dish name = \u201csteak\u201d type = \u201csirloin\u201d cooking = \u201cmedium\u201d />\n<dish name = \u201csteak\u201d type = \u201cfillet\u201d cooking = \u201crare\u201d />\n<dish name = \u201csea bass\u201d>\n</main>\n<accompaniment>\n<dish name = \u201cfrench fries\u201d portions = \u201c2\u201d />\n<dish name = \u201csalad\u201d portions = \u201c1\u201d />\n</accompaniment>\n", "page": 498, "type": "text", "section": "Page 498"}
{"text": "498\u2002 \u2002 Chapter 17\u2002 \u25a0\u2002 Distributed software engineering\n\t\n17.1.2 \t Middleware\nThe components in a distributed system may be implemented in different program-\nming languages and may execute on different types of processors. Models of data, \ninformation representation, and protocols for communication may all be different. A \ndistributed system therefore requires software that can manage these diverse parts \nand ensure that they can communicate and exchange data.\nThe term middleware is used to refer to this software\u2014it sits in the middle between \nthe distributed components of the system. This concept is illustrated in Figure 17.3, \nwhich shows that middleware is a layer between the operating system and application \nprograms. Middleware is normally implemented as a set of libraries, which are installed \non each distributed computer, plus a runtime system to manage communications.\nBernstein (Bernstein 1996) describes types of middleware that are available to \nsupport distributed computing. Middleware is general-purpose software that is usu-\nally bought off-the-shelf rather than written specially by application developers. \nExamples of middleware include software for managing communications with data-\nbases, transaction managers, data converters, and communication controllers.\nIn a distributed system, middleware provides two distinct types of support:\n1.\t\nInteraction support, where the middleware coordinates interactions between differ-\nent components in the system. The middleware provides location transparency in \nthat it isn\u2019t necessary for components to know the physical locations of other compo-\nnents. It may also support parameter conversion if different programming languages \nare used to implement components, event detection, communication, and so on.\n2.\t\nThe provision of common services, where the middleware provides reusable \nimplementations of services that may be required by several components in the \ndistributed system. By using these common services, components can easily \ninteroperate and provide user services in a consistent way.\nI have already given examples of the interaction support that middleware can pro-\nvide in Section 17.1.1. You use middleware to support remote procedure and remote \nmethod calls, message exchange, and so forth.\nApplication components\nOperating system\nMiddleware\nNetworking\nApplication components\nOperating system\nMiddleware\nNetworking\nLogical\ninteraction\nInformation\nexchange and\ncommon services\nCoordinated\noperation\nPhysical\nconnectivity\nSystem 1\nSystem 2\nFigure 17.3\u2002  \nMiddleware in a \ndistributed system \n", "page": 499, "type": "text", "section": "Page 499"}
{"text": " \n17.2\u2002 \u25a0\u2002 Client\u2013server computing\u2002 \u2002 499\nCommon services are those services that may be required by different compo-\nnents irrespective of the functionality of these components. As I discussed in Chapter \n16, these may include security services (authentication and authorization), notifica-\ntion and naming services, and transaction management services. For distributed \ncomponents, you can think of these common services as being provided by a mid-\ndleware container; for services, they are provided through shared libraries. You then \ndeploy your component, and it can access and use these common services.\n \n17.2  Client\u2013server computing\nDistributed systems that are accessed over the Internet are organized as client\u2013server \nsystems. In a client\u2013server system, the user interacts with a program running on their \nlocal computer, such as a web browser or app on a mobile device. This interacts with \nanother program running on a remote computer, such as a web server. The remote \ncomputer provides services, such as access to web pages, which are available to \nexternal clients. This client\u2013server model, as I discussed in Chapter 6, is a general \narchitectural model of an application. It is not restricted to applications distributed \nacross several machines. You can also use it as a logical interaction model where the \nclient and the server run on the same computer.\nIn a client\u2013server architecture, an application is modeled as a set of services that are \nprovided by servers. Clients may access these services and present results to end-users. \nClients need to be aware of the servers that are available but don\u2019t have to know any-\nthing about other clients. Clients and servers are separate processes, as shown in Figure \n17.4. This figure illustrates a situation in which there are four servers (s1\u2013s4) that \ndeliver different services. Each service has a set of associated clients that access these \nservices.\nFigure 17.4 shows client and server processes rather than processors. It is normal \nfor several client processes to run on a single processor. For example, on your PC, \nyou may run a mail client that downloads mail from a remote mail server. You may \nalso run a web browser that interacts with a remote web server and a print client that \nsends documents to a remote printer. Figure 17.5 shows a possible arrangement \nwhere the 12 logical clients shown in Figure 17.4 are running on six computers. The \nfour server processes are mapped onto two physical server computers.\nSeveral different server processes may run on the same processor, but, often, \nservers are implemented as multiprocessor systems in which a separate instance of \nthe server process runs on each machine. Load-balancing software distributes \nrequests for service from clients to different servers so that each server does the \nsame amount of work. This allows a higher volume of transactions with clients to be \nhandled, without degrading the response to individual clients.\nClient\u2013server systems depend on there being a clear separation between the pres-\nentation of information and the computations that create and process that informa-\ntion. Consequently, you should design the architecture of distributed client\u2013server \nsystems so that they are structured into several logical layers, with clear interfaces \n", "page": 500, "type": "text", "section": "Page 500"}
{"text": "500\u2002 \u2002 Chapter 17\u2002 \u25a0\u2002 Distributed software engineering\nbetween these layers. This allows each layer to be distributed to a different computer. \nFigure 17.6 illustrates this model, showing an application structured into four layers:\n1.\t\nA presentation layer that is concerned with presenting information to the user \nand managing all user interaction.\n2.\t\nA data-handling layer that manages the data that is passed to and from the \u00ad\nclient. \nThis layer may implement checks on the data, generate web pages, and so on.\n3.\t\nAn application processing layer that is concerned with implementing the logic \nof the application and so providing the required functionality to end-users.\n4.\t\nA database layer that stores the data and provides transaction management and \nquery services.\nThe following section explains how different client\u2013server architectures distrib-\nute these logical layers in different ways. The client\u2013server model also underlies the \nnotion of software as a service (SaaS), an important way of deploying software and \naccessing it over the Internet. I cover this topic in Section 17.4.\ns1\ns2\ns3\ns4\nc1\nc2\nc3\nc4\nc5\nc6\nc7\nc8\nc9\nc10\nc11\nc12\nClient process\nServer process\nFigure 17.4\u2002  Client\u2013\nserver interaction \nNetwork\nSC1\nSC2\nCC1\nCC2\nCC3\nCC5\nCC6\nCC4\nServer\ncomputer\nClient\ncomputer\ns1, s2\ns3, s4\nc5, c6, c7\nc1\nc2\nc3, c4\nc8, c9\nc10, c11, c12\nFigure 17.5\u2002  Mapping  \nof clients and servers  \nto networked computers \n", "page": 501, "type": "text", "section": "Page 501"}
{"text": " \n17.3 \u2002 \u25a0\u2002 Architectural patterns for distributed systems\u2002 \u2002 501\n \n17.3  Architectural patterns for distributed systems\nAs I explained in the introduction to this chapter, designers of distributed systems \nhave to organize their system designs to find a balance between performance, depend-\nability, security, and manageability of the system. Because no universal model of \nsystem organization is appropriate for all circumstances, various distributed architec-\ntural styles have emerged. When designing a distributed application, you should \nchoose an architectural style that supports the critical non-functional requirements of \nyour system.\nIn this section, I discuss five architectural styles:\n1.\t\nMaster-slave architecture, which is used in real-time systems in which guaran-\nteed interaction response times are required.\n2.\t\nTwo-tier client\u2013server architecture, which is used for simple client\u2013server systems \nand in situations where it is important to centralize the system for security reasons.\n3.\t\nMulti-tier client\u2013server architecture, which is used when the server has to pro-\ncess a high volume of transactions.\n4.\t\nDistributed component architecture, which is used when resources from differ-\nent systems and databases need to be combined, or as an implementation model \nfor multi-tier client\u2013server systems.\n5.\t Peer-to-peer architecture, which is used when clients exchange locally stored \ninformation and the role of the server is to introduce clients to each other. It \nmay also be used when a large number of independent computations may have \nto be made.\n\t\n17.3.1 \t Master\u2013slave architectures\nMaster\u2013slave architectures for distributed systems are commonly used in real-\ntime systems. In those systems, there may be separate processors associated with \ndata acquisition from the system\u2019s environment, data processing and \u00ad\ncomputation, \nPresentation \nApplication processing \nData handling\nDatabase \nFigure 17.6\u2002 Layered \narchitectural model for \nclient\u2013server application \n", "page": 502, "type": "text", "section": "Page 502"}
{"text": "502\u2002 \u2002 Chapter 17\u2002 \u25a0\u2002 Distributed software engineering\nand actuator management. Actuators, as I discuss in Chapter 21, are devices con-\ntrolled by the software system that act to change the system\u2019s environment. For \nexample, an actuator may control a valve and change its state from \u201copen\u201d to \n\u201cclosed.\u201d The \u201cmaster\u201d process is usually responsible for computation, coordina-\ntion, and communications, and it controls the \u201cslave\u201d processes. \u201cSlave\u201d pro-\ncesses are dedicated to specific actions, such as the acquisition of data from an \narray of sensors.\n Figure 17.7 shows an example of this architectural model. A traffic control sys-\ntem in a city has three logical processes that run on separate processors. The master \nprocess is the control room process, which communicates with separate slave pro-\ncesses that are responsible for collecting traffic data and managing the operation of \ntraffic lights.\nA set of distributed sensors collects information on the traffic flow. The sensor \ncontrol process polls the sensors periodically to capture the traffic flow informa-\ntion and collates this information for further processing. The sensor processor is \nitself polled periodically for information by the master process that is concerned \nwith displaying traffic status to operators, computing traffic light sequences, and \naccepting operator commands to modify these sequences. The control room sys-\ntem sends commands to a traffic light control process that converts these into sig-\nnals to control the traffic light hardware. The master control room system is itself \norganized as a client\u2013server system, with the client processes running on the oper-\nator\u2019s consoles.\nYou use this master\u2013slave model of a distributed system in situations where you \ncan predict the distributed processing that is required and where processing can be \neasily localized to slave processors. This situation is common in real-time systems, \nwhere it is important to meet processing deadlines. Slave processors can be used for \ncomputationally intensive operations, such as signal processing and the management \nof equipment controlled by the system.\nTraffic lights\nLight\ncontrol\nprocess\nTraffic light control\nprocessor\nControl room\nprocessor\nOperator consoles\nTraffic flow sensors and\ncameras\nSensor\nprocessor\nSensor\ncontrol\nprocess\nCoordination\nand display\nprocess\nSlave\nSlave\nMaster\nFigure 17.7\u2002  A traffic \nmanagement system \nwith a master\u2013 \nslave architecture \n", "page": 503, "type": "text", "section": "Page 503"}
{"text": " \n17.3 \u2002 \u25a0\u2002 Architectural patterns for distributed systems\u2002 \u2002 503\n\t\n17.3.2 \t Two-tier client\u2013server architectures\nIn Section 17.2, I explained the general organization of client\u2013server systems in which \npart of the application system runs on the user\u2019s computer (the client), and part runs \non a remote computer (the server). I also presented a layered application model \n(Figure 17.6) where the different layers in the system may execute on different \n\u00ad\ncomputers.\nA two-tier client\u2013server architecture is the simplest form of client\u2013server archi-\ntecture. The system is implemented as a single logical server plus an indefinite num-\nber of clients that use that server. This is illustrated in Figure 17.8, which shows two \nforms of this architectural model:\n1.\t\nA thin-client model, where the presentation layer is implemented on the client \nand all other layers (data handling, application processing, and database) are \nimplemented on a server. The client presentation software is usually a web \nbrowser, but apps for mobile devices may also be available.\n2.\t\nA fat-client model, where some or all of the application processing is carried out \non the client. Data management and database functions are implemented on the \nserver. In this case, the client software may be a specially written program that \nis tightly integrated with the server application.\nThe advantage of the thin-client model is that it is simple to manage the clients. \nThis becomes a major issue when there are a large number of clients, as it may be \ndifficult and expensive to install new software on all of them. If a web browser is \nused as the client, there is no need to install any software.\nThe disadvantage of the thin-client approach, however, is that it places a heavy \nprocessing load on both the server and the network. The server is responsible for all \ncomputation, which may lead to the generation of significant network traffic between \nthe client and the server. Implementing a system using this model may therefore \nrequire additional investment in network and server capacity.\nThe fat-client model makes use of available processing power on the computer \nrunning the client software, and distributes some or all of the application processing \nThin-client\nmodel\nFat-client\nmodel\nClient\nClient\nServer\nDatabase\nData management\nApplication processing\nPresentation\nServer\nDatabase\nData management\nPresentation\nApplication processing\nFigure 17.8\u2002 Thin- and \nfat-client architectural \nmodels \n", "page": 504, "type": "text", "section": "Page 504"}
{"text": "504\u2002 \u2002 Chapter 17\u2002 \u25a0\u2002 Distributed software engineering\nand the presentation to the client. The server is essentially a transaction server that \nmanages all database transactions. Data handling is straightforward as there is no \nneed to manage the interaction between the client and the application processing \nsystem. The fat-client model requires system management to deploy and maintain \nthe software on the client computer.\nAn example of a situation in which a fat-client architecture is used is in a bank \nATM system, which delivers cash and other banking services to users. The ATM is the \nclient computer, and the server is, typically, a mainframe running the customer account \ndatabase. A mainframe computer is a powerful machine that is designed for transac-\ntion processing. It can therefore handle the large volume of transactions generated by \nATMs, other teller systems, and online banking. The software in the teller machine \ncarries out a lot of the customer-related processing associated with a transaction.\n Figure 17.9 shows a simplified version of the ATM system organization. The ATMs \ndo not connect directly to the customer database, but rather to a teleprocessing (TP) mon-\nitor. A TP monitor is a middleware system that organizes communications with remote \nclients and serializes client transactions for processing by the database. This ensures that \ntransactions are independent and do not interfere with one other. Using serial transactions \nmeans that the system can recover from faults without corrupting the system data.\nWhile a fat-client model distributes processing more effectively than a thin-client \nmodel, system management is more complex if a special-purpose client, rather than \na browser, is used. Application functionality is spread across many computers. When \nthe application software has to be changed, this involves software reinstallation on \nevery client computer. This can be a major cost if there are hundreds of clients in the \nsystem. Auto-update of the client software can reduce these costs but introduces its \nown problems if the client functionality is changed. The new functionality may mean \nthat businesses have to change the ways they use the system.\nThe extensive use of mobile devices means that it is important to mimimize net-\nwork traffic wherever possible. These devices now include powerful computers that \ncan carry out local processing. As a consequence, the distinction between thin-client \nand fat-client architectures has become blurred. Apps can have inbuilt functionality \nthat carries out local processing, and web pages may include Javascript components \nAccount server\nCustomer\naccount\ndatabase\nTele-\nprocessing\nmonitor\nATM\nATM\nATM\nATM\nFigure 17.9\u2002 A fat-client \narchitecture for an \nATM system \n", "page": 505, "type": "text", "section": "Page 505"}
{"text": " \n17.3 \u2002 \u25a0\u2002 Architectural patterns for distributed systems\u2002 \u2002 505\nthat execute on the user\u2019s local computer. The update problem for apps remains an \nissue, but it has been addressed, to some extent, by automatically updating apps with-\nout explicit user intervention. Consequently, while it is sometimes helpful to use \nthese models as a general basis for the architecture of a distributed system, in practice \nfew web-based applications implement all processing on the remote server.\n\t\n17.3.3 \t Multi-tier client\u2013server architectures\nThe fundamental problem with a two-tier client\u2013server approach is that the logical layers \nin the system\u2014presentation, application processing, data management, and database\u2014\nmust be mapped onto two computer systems: the client and the server. This may lead to \nproblems with scalability and performance if the thin-client model is chosen, or problems \nof system management if the fat-client model is used. To avoid some of these problems, \na \u201cmulti-tier client\u2013server\u201d architecture can be used. In this architecture, the different lay-\ners of the system, namely presentation, data management, application processing, and \ndatabase, are separate processes that may execute on different processors.\nAn Internet banking system (Figure 17.10) is an example of a multi-tier client\u2013\nserver architecture, where there are three tiers in the system. The bank\u2019s customer \ndatabase (usually hosted on a mainframe computer as discussed above) provides \ndatabase services. A web server provides data management services such as web \npage generation and some application services. Application services such as facili-\nties to transfer cash, generate statements, pay bills, and so on are implemented in the \nweb server and as scripts that are executed by the client. The user\u2019s own computer \nwith an Internet browser is the client. This system is scalable because it is relatively \neasy to add servers (scale out) as the number of customers increase.\nIn this case, the use of a three-tier architecture allows the information transfer \nbetween the web server and the database server to be optimized. Efficient middle-\nware that supports database queries in SQL (Structured Query Language) is used to \nhandle information retrieval from the database.\nDatabase server\nCustomer\naccount\ndatabase\nWeb server\nClient\nClient\nAccount service\nprovision\nSQL\nSQL query\nHTTPS interaction\nClient\nClient\nTier 1. Presentation\nTier 2. Application\nprocessing and data\nhandling\nTier 3. Database\nprocessing\nFigure 17.10\u2002  Three-tier \narchitecture for an \nInternet banking  \nsystem\n", "page": 506, "type": "text", "section": "Page 506"}
{"text": "506\u2002 \u2002 Chapter 17\u2002 \u25a0\u2002 Distributed software engineering\nThe three-tier client\u2013server model can be extended to a multi-tier variant, where \nadditional servers are added to the system. This may involve using a web server for \ndata management and separate servers for application processing and database ser-\nvices. Multi-tier systems may also be used when applications need to access and use \ndata from different databases. In this case, you may need to add an integration server \nto the system. The integration server collects the distributed data and presents it to \nthe application server as if it were from a single database. As I discuss in the follow-\ning section, distributed component architectures may be used to implement multi-\ntier client\u2013server systems.\nMulti-tier client\u2013server systems that distribute application processing across sev-\neral servers are more scalable than two-tier architectures. The tiers in the system can \nbe independently managed, with additional servers added as the load increases. \nProcessing may be distributed between the application logic and the data-handling \nservers, thus leading to more rapid response to client requests.\nDesigners of client\u2013server architectures must take a number of factors into account \nwhen choosing the most appropriate distribution architecture. Situations in which the \nclient\u2013server architectures discussed here may be used are described in Figure 17.11.\n\t\n17.3.4 \t Distributed component architectures\nBy organizing processing into layers, as shown in Figure 17.6, each layer of a system \ncan be implemented as a separate logical server. This model works well for many \ntypes of application. However, it limits the flexibility of system designers in that they \nFigure 17.11\u2002 Use of \nclient\u2013server \narchitectural patterns\nArchitecture\nApplications\nTwo-tier client\u2013server \narchitecture with thin clients\nLegacy system applications that are used when separating application \nprocessing and data handling is impractical. Clients may access these as \nservices, as discussed in Section 17.4.\nComputationally intensive applications such as compilers with little or no \nrequirements for data handling.\nData-intensive applications (browsing and querying) with non-intensive \napplication processing. Simple web browsing is the most common \nexample of a situation where this architecture is used.\nTwo-tier client\u2013server \narchitecture with fat clients\nApplications where application processing is provided by off-the-shelf \nsoftware (e.g., Microsoft Excel) on the client.\nApplications where computationally intensive processing of data (e.g., \ndata visualization) is required.\nMobile applications where internet connectivity cannot be guaranteed. \nLocal processing using cached information from the database is therefore \npossible.\nMulti-tier client\u2013server \narchitecture\nLarge-scale applications with hundreds or thousands of clients.\nApplications where both the data and the application are volatile.\nApplications where data from multiple sources are integrated.\n", "page": 507, "type": "text", "section": "Page 507"}
{"text": " \n17.3 \u2002 \u25a0\u2002 Architectural patterns for distributed systems\u2002 \u2002 507\nhave to decide what services should be included in each layer. In practice, however, it \nis not always clear whether a service is a data management service, an application \nservice, or a database service. Designers must also plan for scalability and so provide \nsome means for servers to be replicated as more clients are added to the system.\nA more general approach to distributed system design is to design the system as a \nset of services, without attempting to allocate these services to layers in the system. \nEach service, or group of related services, can be implemented using a separate object \nor component. In a distributed component architecture (Figure 17.12), the system is \norganized as a set of interacting components as I discussed in Chapter 16. These com-\nponents provide an interface to a set of services that they provide. Other components \ncall on these services through middleware, using remote procedure or method calls.\nDistributed component systems are reliant on middleware. This manages component \ninteractions, reconciles differences between types of the parameters passed between \ncomponents, and provides a set of common services that application components can \nuse. The CORBA standard (Orfali, Harkey, and Edwards 1997) defined middleware \nfor distributed component systems, but CORBA implementations have never been \nwidely adopted. Enterprises preferred to use proprietary software such as Enterprise \nJava Beans (EJB) or .NET.\nUsing a distributed component model for implementing distributed systems has a \nnumber of benefits:\n1.\t\nIt allows the system designer to delay decisions on where and how services \nshould be provided. Service-providing components may execute on any node of \nthe network. There is no need to decide in advance whether a service is part of a \ndata management layer, an application layer, or a user interface layer.\n2.\t\nIt is a very open-system architecture that allows new resources to be added as \nrequired. New system services can be added easily without major disruption to \nthe existing system.\n3.\t\nThe system is flexible and scalable. New objects or replicated objects can be added \nas the load on the system increases, without disrupting other parts of the system.\nCommunication middleware\nClient\nClient\nClient\nClient\nClient\nComp 1\nCommon\nservices\nComp 2\nCommon\nservices\nComp 3\nCommon\nservices\nComp 4\nCommon\nservices\nFigure 17.12\u2002  A \ndistributed component \narchitecture \n", "page": 508, "type": "text", "section": "Page 508"}
{"text": "508\u2002 \u2002 Chapter 17\u2002 \u25a0\u2002 Distributed software engineering\n4.\t\nIt is possible to reconfigure the system dynamically with components migrating across \nthe network as required. This may be important where there are fluctuating patterns \nof demand on services. A service-providing component can migrate to the same \n\u00ad\nprocessor as service-requesting objects, thus improving the performance of the system.\nA distributed component architecture can be used as a logical model that allows \nyou to structure and organize the system. In this case, you think about how to pro-\nvide application functionality solely in terms of services and combinations of ser-\nvices. You then work out how to implement these services. For example, a retail \napplication may have application components concerned with stock control, cus-\ntomer communications, goods ordering, and so on.\nData-mining systems are a good example of a type of system that can be imple-\nmented using a distributed component architecture. Data-mining systems look for \nrelationships between the data that may be distributed across databases (Figure 17.13). \nThese systems pull in information from several separate databases, carry out compu-\ntationally intensive processing, and present easy-to-understand visualizations of the \nrelationships that have been discovered.\nAn example of such a data-mining application might be a system for a retail busi-\nness that sells food and books. Retail businesses maintain separate databases with \ndetailed information about food products and books. They use a loyalty card system \nto keep track of customers\u2019 purchases, so there is a large database linking bar codes \nof products with customer information. The marketing department wants to find \nrelationships between a customer\u2019s food and book purchases. For instance, a rela-\ntively high proportion of people who buy pizzas might also buy crime novels. With \nthis knowledge, the business can specifically target customers who make specific \nfood purchases with information about new novels when they are published.\nDatabase 1\nDatabase 2\nDatabase 3\nIntegrator 1\nIntegrator 2\nVisualizer\nDisplay\nReport gen.\nClients\nFigure 17.13\u2002  A \ndistributed component \narchitecture for a \ndata-mining system \n", "page": 509, "type": "text", "section": "Page 509"}
{"text": " \n17.3 \u2002 \u25a0\u2002 Architectural patterns for distributed systems\u2002 \u2002 509\nIn this example, each sales database can be encapsulated as a distributed compo-\nnent with an interface that provides read-only access to its data. Integrator components \nare each concerned with specific types of relationships, and they collect information \nfrom all of the databases to try to deduce the relationships. There might be an integra-\ntor component that is concerned with seasonal variations in goods sold, and another \nintegrator that is concerned with relationships between different types of goods.\nVisualizer components interact with integrator components to create a visualization \nor a report on the relationships that have been discovered. Because of the large vol-\numes of data that are handled, visualizer components normally present their results \ngraphically. Finally, a display component may be responsible for delivering the \ngraphical models to clients for final presentation in their web browser.\nA distributed component architecture rather than a layered architecture is appro-\npriate for this type of application because you can add new databases to the system \nwithout major disruption. Each new database is simply accessed by adding another \ndistributed component. The database access components provide a simplified inter-\nface that controls access to the data. The databases that are accessed may reside on \ndifferent machines. The architecture also makes it easy to mine new types of rela-\ntionships by adding new integrator objects.\nDistributed component architectures suffer from two major disadvantages:\n1.\t\nThey are more complex to design than client\u2013server systems. Multilayer client\u2013\nserver systems appear to be a fairly intuitive way to think about systems. They \nreflect many human transactions where people request and receive services \nfrom other people who specialize in providing these services. The complexity of \ndistributed component architectures increases the costs of implementation.\n2.\t\nThere are no universal standards for distributed component models or middle-\nware. Rather, different vendors, such as Microsoft and Sun, developed different, \nincompatible middleware. This middleware is complex, and reliance on it sig-\nnificantly increases the complexity of distributed component systems.\nAs a result of these problems, distributed component architectures are being replaced \nby service-oriented systems (discussed in Chapter 18). However, distributed compo-\nnent systems have performance benefits over service-oriented systems. RPC communi-\ncations are usually faster than the message-based interaction used in service-oriented \nsystems. Distributed component architectures are therefore still used for high-throughput \nsystems in which large numbers of transactions have to be processed quickly.\n\t\n17.3.5 \t Peer-to-peer architectures\nThe client\u2013server model of computing that I have discussed in previous sections of the \nchapter makes a clear distinction between servers, which are providers of services, and \nclients, which are receivers of services. This model usually leads to an uneven distribution \nof load on the system, where servers do more work than clients. This may lead to organi-\nzations spending a lot on server capacity while there is unused processing capacity on the \nhundreds or thousands of PCs and mobile devices used to access the system servers.\n", "page": 510, "type": "text", "section": "Page 510"}
{"text": "510\u2002 \u2002 Chapter 17\u2002 \u25a0\u2002 Distributed software engineering\nPeer-to-peer (p2p) systems (Oram 2001) are decentralized systems in which com-\nputations may be carried out by any node on the network. In principle at least, no \ndistinctions are made between clients and servers. In peer-to-peer applications, the \noverall system is designed to take advantage of the computational power and storage \navailable across a potentially huge network of computers. The standards and proto-\ncols that enable communications across the nodes are embedded in the application \nitself, and each node must run a copy of that application.\nPeer-to-peer technologies have mostly been used for personal rather than busi-\nness systems. The fact that there are no central servers means that these systems are \nharder to monitor; therefore, a higher level of communication privacy is possible.\nFor example, file-sharing systems based on the BitTorrent protocol are widely used \nto exchange files on users\u2019 PCs. Private instant messaging systems, such as ICQ and \nJabber, provide direct communications between users without an intermediate server. \nBitcoin is a peer-to-peer payments system using the Bitcoin electronic currency. Freenet \nis a decentralized database that has been designed to make it easier to publish informa-\ntion anonymously and to make it difficult for authorities to suppress this information.\nOther p2p systems have been developed where privacy is not the principal \nrequirement. Voice over IP (VoIP) phone services, such as Viber, rely on peer-to-\npeer communication between the parties involved in the phone call or conference. \nSETI@home is a long-running project that processes data from radio telescopes on \nhome PCs in order to search for indications of extraterrestrial life. In these systems, \nthe advantage of the p2p model is that a central server is not a processing bottleneck.\nPeer-to-peer systems have also been used by businesses to harness the power in \ntheir PC networks (McDougall 2000). Intel and Boeing have both implemented p2p \nsystems for computationally intensive applications. Such systems take advantage of \nunused processing capacity on local computers. Instead of buying expensive high-\nperformance hardware, engineering computations can be run overnight when desk-\ntop computers are unused. Businesses also make extensive use of commercial p2p \nsystems, such as messaging and VoIP systems.\nIn principle, every node in a p2p network could be aware of every other node. \nNodes could connect to and exchange data directly with any other node in the network. \nIn practice, this is impossible unless the network has only a few members. Consequently, \nnodes are usually organized into \u201clocalities,\u201d with some nodes acting as bridges to \nother node localities. Figure 17.14 shows this decentralized p2p architecture.\nIn a decentralized architecture, the nodes in the network are not simply functional \nelements but are also communications switches that can route data and control sig-\nnals from one node to another. For example, assume that Figure 17.14 represents a \ndecentralized, document-management system. A consortium of researchers uses this \nsystem to share documents. Each member of the consortium maintains his or her \nown document store. However, when a document is retrieved, the node retrieving \nthat document also makes it available to other nodes.\nIf someone needs a document that is stored somewhere on the network, they issue \na search command, which is sent to nodes in their \u201clocality.\u201d These nodes check \nwhether they have the document and, if so, return it to the requestor. If they do not \nhave it, they route the search to other nodes. Therefore if n1 issues a search for a \n", "page": 511, "type": "text", "section": "Page 511"}
{"text": " \n17.3 \u2002 \u25a0\u2002 Architectural patterns for distributed systems\u2002 \u2002 511\ndocument that is stored at n10, this search is routed through nodes n3, n6, and n9 to \nn10. When the document is finally discovered, the node holding the document then \nsends it to the requesting node directly by making a peer-to-peer connection.\nThis decentralized architecture has the advantage of being highly redundant and \nhence both fault-tolerant and tolerant of nodes disconnecting from the network. \nHowever, the disadvantages are that many different nodes may process the same \nsearch, and there is also significant overhead in replicated peer communications.\nAn alternative p2p architectural model, which departs from a pure p2p architec-\nture, is a semicentralized architecture where, within the network, one or more nodes \nact as servers to facilitate node communications. This reduces the amount of traffic \nbetween nodes. Figure 17.15 illustrates how this semicentralized architectural model \ndiffers from the completely decentralized model shown in Figure 17.14.\nIn a semicentralized architecture, the role of the server (sometimes called a super-\npeer) is to help establish contact between peers in the network or to coordinate the \nresults of a computation. For example, if Figure 17.15 represents an instant messaging \nsystem, then network nodes communicate with the server (indicated by dashed lines) \nto find out what other nodes are available. Once these nodes are discovered, direct \ncommunications can be established and the connection to the server becomes unnec-\nessary. Therefore, nodes n2, n3, n5, and n6 are in direct communication.\nIn a computational p2p system, where a processor-intensive computation is distributed \nacross a large number of nodes, it is normal for some nodes to be superpeers. Their role is \nto distribute work to other nodes and to collate and check the results of the computation.\nThe peer-to-peer architectural model may be the best model for a distributed sys-\ntem in two circumstances:\n1.\t\nWhere the system is computationally-intensive and it is possible to separate the \nprocessing required into a large number of independent computations. For exam-\nple, a peer-to-peer system that supports computational drug discovery distributes \ncomputations that look for potential cancer treatments by analyzing a huge num-\nber of molecules to see if they have the characteristics required to suppress the \ngrowth of cancers. Each molecule can be considered separately, so there is no \nneed for the peers in the system to communicate.\nn4\nn2\nn3\nn6\nn7\nn10\nn8\nn12\nn11\nn14\nn13\nn9\nn1\nn5\nFigure 17.14\u2002   \nA decentralized  \np2p architecture \n", "page": 512, "type": "text", "section": "Page 512"}
{"text": "512\u2002 \u2002 Chapter 17\u2002 \u25a0\u2002 Distributed software engineering\n2.\t\nWhere the system primarily involves the exchange of information between indi-\nvidual computers on a network and there is no need for this information to be \ncentrally stored or managed. Examples of such applications include file-sharing \nsystems that allow peers to exchange local files such as music and video files, and \nphone systems that support voice and video communications between \u00ad\ncomputers.\nPeer-to-peer architectures allow for the efficient use of capacity across a network. \nHowever, security concerns are the principal reason why these systems have not become \nmore widely used, especially in business (Wallach 2003). The lack of \u00ad\ncentralized man-\nagement means that attackers can set up malicious nodes that deliver spam and malware \nto legitimate p2p system users. Peer-to-peer communications involve opening your \ncomputer to direct interactions with other peers and this means that these systems could \npotentially access any of your resources. To counter this possibility, you need to \n\u00ad\norganize your system so that these resources are protected. If this is done incorrectly, \nthen your system is insecure and vulnerable to external corruption.\n \n17.4  Software as a service\nIn the previous sections, I discussed client\u2013server models and how functionality may \nbe distributed between the client and the server. To implement a client\u2013server \u00ad\nsystem, \nyou may have to install a program or an app on the client computer, which commu-\nnicates with the server, implements client-side functionality, and manages the user \ninterface. For example, a mail client, such as Outlook or Mac Mail, provides mail \nmanagement features on your own computer. This avoids the problem of server over-\nload in thin-client systems, where all of the processing is carried out at the server.\nThe problems of server overload can be significantly reduced by using web tech-\nnologies such as AJAX (Holdener, 2008) and HTML5 (Sarris 2013). These \u00ad\ntechnologies \nsupport efficient management of web page presentation and local computation by exe-\ncuting scripts that are part of the web page. This means that a browser can be configured \nand used as client, with significant local processing. The application software can be \nn1\nn6\nn2\nn3\nn5\nn4\nDiscovery server\n(Super peer)\nFigure 17.15\u2002  A \nsemicentralized p2p \narchitecture \n", "page": 513, "type": "text", "section": "Page 513"}
{"text": " \n17.4\u2002 \u25a0\u2002 Software as a service\u2002 \u2002 513\nthought of as a remote service, which can be accessed from any device that can run a \nstandard browser. Widely used examples of SaaS include web-based mail systems, \nsuch as Yahoo and Gmail, and office applications, such as Google Docs and Office 365.\nThis idea of software as a service (SaaS) involves hosting the software remotely and \nproviding access to it over the Internet. The key elements of SaaS are as follows:\n1.\t\nSoftware is deployed on a server (or more commonly in the cloud) and is \naccessed through a web browser. It is not deployed on a local PC.\n2.\t\nThe software is owned and managed by a software provider rather than the \norganizations using the software.\n3.\t\nUsers may pay for the software according to how much use they make of it or \nthrough an annual or monthly subscription. Sometimes the software is free for \nanyone to use, but users must then agree to accept advertisements, which fund \nthe software service.\nThe development of SaaS has accelerated over the past few years as cloud com-\nputing has become widely used. When a service is deployed in the cloud, the number \nof servers can quickly change to match the user demands for that service. There is no \nneed for service providers to provision for peak loads; as a result, the costs for these \nproviders have been dramatically reduced.\nFor software purchasers, the benefit of SaaS is that the costs of management of \nsoftware are transferred to the provider. The provider is responsible for fixing \nbugs and installing software upgrades, dealing with changes to the operating sys-\ntem platform, and ensuring that hardware capacity can meet demand. Software \nlicense management costs are zero. If someone has several computers, there is no \nneed to license software for all of these. If a software application is only used \noccasionally, the pay-per-use model may be cheaper than buying an application. \nThe software may be accessed from mobile devices, such as smartphones, from \nanywhere in the\u00a0world.\nThe main problem that inhibits the use of SaaS is data transfer with the remote \nservice. Data transfer takes place at network speeds, and so transferring a large \namount of data, such as video or high-quality images takes a lot of time. You may \nalso have to pay the service provider according to the amount transferred. Other \nproblems are lack of control over software evolution (the provider may change the \nsoftware when it wishes) and problems with laws and regulations. Many countries \nhave laws governing the storage, management, preservation, and accessibility of \ndata, and moving data to a remote service may breach these laws.\nThe notion of software as a service and service-oriented architectures (SOA), \ndiscussed in Chapter 18, are related, but they are not the same:\n1.\t\nSoftware as a service is a way of providing functionality on a remote server with \nclient access through a web browser. The server maintains the user\u2019s data and \nstate during an interaction session. Transactions are usually long transactions, \nfor example, editing a document.\n", "page": 514, "type": "text", "section": "Page 514"}
{"text": "514\u2002 \u2002 Chapter 17\u2002 \u25a0\u2002 Distributed software engineering\n2.\t\nService-oriented architecture is an approach to structuring a software system as \na set of separate, stateless services. These services may be provided by multiple \nproviders and may be distributed. Typically, transactions are short transactions \nwhere a service is called, does something, and then returns a result.\nSaaS is a way of delivering application functionality to users, whereas SOA is an \nimplementation technology for application systems. Systems that are implemented \nusing SOA do not have to be accessed by users as web services. SaaS applications \nfor business may be implemented using components rather than services. However, \nif SaaS is implemented using SOA, it becomes possible for applications to use \n\u00ad\nservice APIs to access the functionality of other applications. They can then be \n\u00ad\nintegrated into more complex systems. These systems are called mashups and are \nanother approach to software reuse and rapid software development.\nFrom a software development perspective, the process of service development \nhas much in common with other types of software development. However, service \nconstruction is not usually driven by user requirements, but by the service provider\u2019s \nassumptions about what users need. Accordingly, the software needs to be able to \nevolve quickly after the provider gets feedback from users on their requirements. \nAgile development with incremental delivery is therefore an effective approach for \nsoftware that is to be deployed as a service.\nSome software that is implemented as a service, such as Google Docs for web users, \noffers a generic experience to all users. However, businesses may wish to have specific \nservices that are tailored to their own requirements. If you are implementing SaaS for \nbusiness, you may base your software service on a generic service that is tailored to the \nneeds of each business customer. Three important factors have to be considered:\n1.\t\nConfigurability How do you configure the software for the specific require-\nments of each organization?\n2.\t\nMulti-tenancy How do you present each user of the software with the impres-\nsion that they are working with their own copy of the system while, at the same \ntime, making efficient use of system resources?\n3.\t\nScalability How do you design the system so that it can be scaled to accommo-\ndate an unpredictably large number of users?\nThe notion of product-line architectures, discussed in Chapter 16, is one way of config-\nuring software for users who have overlapping but not identical requirements. You start \nwith a generic system and adapt it according to the specific requirements of each user.\nThis does not work for SaaS, however, for it would mean deploying a different copy \nof the service for each organization that uses the software. Rather, you need to design \nconfigurability into the system and provide a configuration interface that allows users \nto specify their preferences. You then use these preferences to adjust the behavior of \nthe software dynamically as it is used. Configuration facilities may allow for:\n1.\t\nBranding, where users from each organization are presented with an interface \nthat reflects their own organization.\n", "page": 515, "type": "text", "section": "Page 515"}
{"text": " \n17.4\u2002 \u25a0\u2002 Software as a service\u2002 \u2002 515\n2.\t\nBusiness rules and workflows, where each organization defines its own rules \nthat govern the use of the service and its data.\n3.\t\nDatabase extensions, where each organization defines how the generic service \ndata model is extended to meet its specific needs.\n4.\t\nAccess control, where service customers create individual accounts for their staff \nand define the resources and functions that are accessible to each of their users.\n Figure 17.16 illustrates this situation. This diagram shows five users of the appli-\ncation service, who work for three different customers of the service provider. Users \ninteract with the service through a customer profile that defines the service configu-\nration for their employer.\nMulti-tenancy is a situation in which many different users access the same system \nand the system architecture is defined to allow the efficient sharing of system resources. \nHowever, it must appear to users that they each have sole use of the system. Multi-\ntenancy involves designing the system so that there is an absolute separation between \nsystem functionality and system data. All operations must therefore be stateless so that \nthey can be shared. Data must either be provided by the client or should be available in \na storage system or database that can be accessed from any system instance.\nA particular problem in multi-tenant systems is data management. The simplest \nway to provide data management is for all customers to have their own database, \nwhich they may use and configure as they wish. However, this requires the service \nprovider to maintain many different database instances (one per customer) and to \nmake these databases available on demand.\nAs an alternative, the service provider can use a single database, with different \nusers being virtually isolated within that database. This is illustrated in Figure 17.17, \nwhere you can see that database entries also have a \u201ctenant identifier\u201d that links \nthese entries to specific users. By using database views, you can extract the entries \nfor each service customer and so present users from that customer with a virtual, \npersonal database. This process can be extended to meet specific customer needs \nusing the configuration features discussed above.\nScalability is the ability of the system to cope with increasing numbers of users \nwithout reducing the overall quality of service that is delivered to any user. Generally, \nUser 1\nUser 1\nUser 2\nUser 3\nUser 4\nUser 5\nApplication service\nProfile C1\nProfile C2\nProfile C3\nFigure 17.16\u2002  \nConfiguration of a \nsoftware system  \noffered as a service \n", "page": 516, "type": "text", "section": "Page 516"}
{"text": "516\u2002 \u2002 Chapter 17\u2002 \u25a0\u2002 Distributed software engineering\nwhen considering scalability in the context of SaaS, you are considering \u201cscaling \nout\u201d rather than \u201cscaling up.\u201d Recall that scaling out means adding additional servers \nand so also increasing the number of transactions that can be processed in parallel. \nScalability is a complex topic that I cannot cover in detail here, but following are \nsome general guidelines for implementing scalable software:\n1.\t\nDevelop applications where each component is implemented as a simple state-\nless service that may be run on any server. In the course of a single transaction, \na user may therefore interact with instances of the same service that are running \non several different servers.\n2.\t\nDesign the system using asynchronous interaction so that the application does \nnot have to wait for the result of an interaction (such as a read request). This \nallows the application to carry on doing useful work while it is waiting for the \ninteraction to finish.\n3.\t\nManage resources, such as network and database connections, as a pool so that \nno single server is likely to run out of resources.\n4.\t\nDesign your database to allow fine-grain locking. That is, do not lock out whole \nrecords in the database when only part of a record is in use.\n5.\t\nUse a cloud PaaS platform, such as Google App Engine (Sanderson 2012) or \nother PaaS platform for system implementation. These include mechanisms that \nwill automatically scale out your system as the load increases.\nThe notion of software as a service is a major paradigm shift for distributed com-\nputing. We have already seen consumer software and professional applications, such \nas Photoshop, move to this model of delivery. Increasingly, businesses are replacing \ntheir own systems, such as CRM and inventory systems, with cloud-based SaaS sys-\ntems from external providers such as Salesforce. Specialized software companies \nthat implement business applications prefer to provide SaaS because it simplifies \nsoftware update and management.\nSaaS represents a new way to think about the engineering of enterprise systems. \nIt has always been helpful to think of systems delivering services to users, but, until \nSaaS, this function has involved using different abstractions, such as objects, when \nimplementing the system. Where there is a closer match between user and system \nabstractions, the resultant systems are easier to understand, maintain, and evolve.\nTenant    Key       Name   \n  Address\n  234\nC100     XYZ Corp\n  43, Anystreet, Sometown\n  234\nC110     BigCorp\n  2, Main St, Motown\n  435\nX234     J. Bowie\n  56, Mill St, Starville\n  592\nPP37     R. Burns\n  Alloway, Ayrshire\nFigure 17.17\u2002  A \nmulti-tenant database \n", "page": 517, "type": "text", "section": "Page 517"}
{"text": " \n17.4\u2002 \u25a0\u2002 Further Reading\u2002 \u2002 517\nKey Points\n\u25a0\t The benefits of distributed systems are that they can be scaled to cope with increasing demand, \ncan continue to provide user services (even if some parts of the system fail), and they enable \nresources to be shared.\n\u25a0\t Issues to be considered in the design of distributed systems include transparency, openness, \nscalability, security, quality of service, and failure management.\n\u25a0\t Client\u2013server systems are distributed systems in which the system is structured into layers, with \nthe presentation layer implemented on a client computer. Servers provide data management, \napplication, and database services.\n\u25a0\t Client\u2013server systems may have several tiers, with different layers of the system distributed to \ndifferent computers.\n\u25a0\t Architectural patterns for distributed systems include master\u2013slave architectures, two-tier and multi-\ntier client\u2013server architectures, distributed component architectures, and peer-to-peer architectures.\n\u25a0\t Distributed component systems require middleware to handle component communications and to \nallow objects to be added to and removed from the system.\n\u25a0\t Peer-to-peer architectures are decentralized architectures in which there are no distinguished \u00ad\nclients \nand servers. Computations can be distributed over many systems in different organizations.\n\u25a0\t Software as a service is a way of deploying applications as thin client\u2013server systems, where the \nclient is a web browser.\nFurther Reading\nPeer-to-Peer: Harnessing the Power of Disruptive Technologies. Although this book does not have a \nlot of information on p2p architectures, it is an excellent introduction to p2p computing and \n\u00ad\ndiscusses the organization and approach used in a number of p2p systems. (A. Oram (ed.), O\u2019Reilly \nand Associates Inc., 2001).\n\u201cTurning Software into a Service.\u201d A good overview paper that discusses the principles of service- \noriented computing. Unlike many papers on this topic, it does not conceal these principles behind a \ndiscussion of the standards involved. (M. Turner, D. Budgen, and P. Brereton, IEEE Computer, 36 (10), \nOctober 2003) http://dx.doi.org/10.1109/MC.2003.1236470\nDistributed Systems, 5th ed. A comprehensive textbook that discusses all aspects of distributed sys-\ntems design and implementation. It includes coverage of peer-to-peer systems and mobile \u00ad\nsystems. \n(G. Coulouris, J. Dollimore, T. Kindberg, and G. Blair. Addison-Wesley, 2011).\nEngineering Software as a Service: An Agile Approach Using Cloud Computing. This book accompanies \nthe authors\u2019 online course on the topic. A good practical book that is aimed at people new to this type \nof development. (A. Fox and D. Patterson, Strawberry Canyon LLC, 2014) http://www.\u00ad\nsaasbook.info\n \nChapter 17\u2002 \u25a0\u2002 Further reading\u2002 \u2002 517\n", "page": 518, "type": "text", "section": "Page 518"}
{"text": "518\u2002 \u2002 Chapter 17\u2002 \u25a0\u2002 Distributed software engineering\nWebsite\nPowerPoint slides for this chapter:\nwww.pearsonglobaleditions.com/Sommerville\nLinks to supporting videos:\nhttp://software-engineering-book.com/videos/requirements-and-design/\nExercises\n17.1. \tWhat do you understand by \u201cscalability\u201d? Discuss the differences between scaling up and \nscaling out and explain when these different approaches to scalability may be used.\n17.2. \tExplain why distributed software systems are more complex than centralized software sys-\ntems, where all of the system functionality is implemented on a single computer.\n17.3. \tUsing an example of a remote procedure call, explain how middleware coordinates the inter-\naction of computers in a distributed system.\n17.4. \tWhat are the different logical layers in an application with a distributed client\u2013server \n\u00ad\narchitecture?\n17.5. \tYou have been asked to design a secure system that requires strong authentication and \nauthorization. The system must be designed so that communications between parts of the \nsystem cannot be intercepted and read by an attacker. Suggest the most appropriate client\u2013\nserver architecture for this system and, giving the reasons for your answer, propose how func-\ntionality should be distributed between the client and the server systems.\n17.6. \tYour customer wants to develop a system for stock information where dealers can access infor-\nmation about companies and evaluate various investment scenarios using a simulation system. \nEach dealer uses this simulation in a different way, according to his or her experience and the \ntype of stocks in question. Suggest a client\u2013server architecture for this system that shows \nwhere functionality is located. Justify the client\u2013server system model that you have chosen.\n17.7. \tUsing a distributed component approach, propose an architecture for a national theater book-\ning system. Users can check seat availability and book seats at a group of theaters. The sys-\ntem should support ticket returns so that people may return their tickets for last-minute \nresale to other customers.\n17.8. \tWhat is the fundamental problem with a two-tier client\u2013server approach? Define how a multi-\ntier client\u2013server approach overcomes this.\n17.9. \tList the benefits that a distributed component model has when used for implementing distrib-\nuted systems.\n17.10. \tYour company wishes to move from using desktop applications to accessing the same func-\ntionality remotely as services. Identify three risks that might arise and suggest how these \nrisks may be reduced.\n518\u2002 \u2002 Chapter 17\u2002 \u25a0\u2002 Distributed software engineering\n", "page": 519, "type": "text", "section": "Page 519"}
{"text": " \n17.4\u2002 \u25a0\u2002 References\u2002 \u2002 519\nReferences\nBernstein, P. A. 1996. \u201cMiddleware: A Model for Distributed System Services.\u201d Comm. ACM 39 (2): \n86\u201397. doi:10.1145/230798.230809.\nCoulouris, G., J. Dollimore, T. Kindberg, and G. Blair. 2011. Distributed Systems: Concepts and \nDesign, 5th ed. Harlow, UK: Addison-Wesley.\nHoldener, A. T. (2008). Ajax: The Definitive Guide. Sebastopol, CA.: O\u2019Reilly & Associates.\nMcDougall, P. 2000. \u201cThe Power of Peer-to-Peer.\u201d Information Week (August 28, 2000). http://www \n.informationweek.com/801/peer.htm\nOram, A. 2001. \u201cPeer-to-Peer: Harnessing the Benefits of a Disruptive Technology.\u201d Sebastopol, CA: \nO\u2019Reilly & Associates.\nOrfali, R., D. Harkey, and J. Edwards. 1997. Instant CORBA. Chichester, UK: John Wiley & Sons.\nPope, A. 1997. The CORBA Reference Guide: Understanding the Common Object Request Broker \nArchitecture. Harlow, UK: Addison-Wesley.\nSanderson, D. 2012. Programming with Google App Engine. Sebastopol, CA: O\u2019Reilly Media Inc.\nSarris, S. 2013. HTML5 Unleashed. Indianapolis, IN: Sams Publishing.\nTanenbaum, A. S., and M. Van Steen. 2007. Distributed Systems: Principles and Paradigms, 2nd ed. \nUpper Saddle River, NJ: Prentice-Hall.\nWallach, D. S. 2003. \u201cA Survey of Peer-to-Peer Security Issues.\u201d In Software Security: Theories and \nSystems, edited by M. Okada, B. C. Pierce, A. Scedrov, H. Tokuda, and A. Yonezawa, 42\u201357. \n\u00ad\nHeidelberg: Springer-Verlag. doi:10.1007/3-540-36532-X_4. \n \nChapter 17\u2002 \u25a0\u2002 References\u2002 \u2002 519\n", "page": 520, "type": "text", "section": "Page 520"}
{"text": "Service-oriented  \nsoftware engineering\n18 \nObjectives\nThe objective of this chapter is to introduce service-oriented software \nengineering as a way of building distributed applications using web \nservices. When you have read this chapter, you will:\n\u25a0\t understand the basic notions of a web service, web service \nstandards, and service-oriented architecture;\n\u25a0\t understand the idea of RESTful services and the important \ndifferences between RESTful and SOAP-based services;\n\u25a0\t understand the service engineering process that is intended to \nproduce reusable web services;\n\u25a0\t understand how workflow-based service composition can be used \nto create service-oriented software that supports business processes.\nContents\n18.1 Service-oriented architecture\n18.2 RESTful services\n18.3\t Service engineering\n18.4\t Service composition\n", "page": 521, "type": "text", "section": "Page 521"}
{"text": "The development of the Web in the 1990s revolutionized organizational information \nexchange. Client computers could gain access to information on remote servers out-\nside their own organizations. However, access was solely through a web browser, \nand direct access to the information by other programs was not practical. This meant \nthat opportunistic connections between servers, where, for example, a program could \nquery a number of catalogs from different suppliers, were not possible.\nTo get around this problem, web services were developed that allowed programs \nto access and update resources available on the web. Using a web service, organiza-\ntions that wish to make their information accessible to other programs can do so by \ndefining and publishing a programmatic web service interface. This interface defines \nthe data available and how it can be accessed and used.\nMore generally, a web service is a standard representation for some computational or \ninformation resource that can be used by other programs. These may be information \nresources, such as a parts catalog, computer resources, such as a specialized processor, or \nstorage resources. For example, an archive service could be implemented that permanently \nand reliably stores organizational data that, by law, has to be maintained for many years.\nA web service is an instance of a more general notion of a service, which Lovelock \net al. (Lovelock et al., 1996) defined as:\nan act or performance offered by one party to another. Although the process \nmay be tied to a physical product, the performance is essentially intangible \nand does not normally result in ownership of any of the factors of production.\u2020\nServices are a natural development of software components where the component \nmodel is, in essence, a set of standards associated with web services. A web service \ncan therefore be defined as:\nA loosely coupled, reusable software component that encapsulates discrete func-\ntionality, which may be distributed and programmatically accessed. A web service \nis a service that is accessed using standard Internet and XML-based protocols.\nA critical distinction between a service and a software component, as defined in \ncomponent-based software engineering, is that services should be independent and \nloosely coupled. That is, they should always operate in the same way, irrespective of \ntheir execution environment. They should not rely on external components that may \nhave different functional and non-functional behavior. Therefore, web services do \nnot have a \u201crequires\u201d interface that, in CBSE, defines the other system components \nthat must be present. A web service interface is simply a \u201cprovides\u201d interface that \ndefines the service functionality and parameters.\nService-oriented systems are a way of developing distributed systems where the \nsystem components are stand-alone services, executing on geographically distributed \ncomputers. Services are platform and implementation-language independent. Software \nsystems can be constructed by composing local services and external services from \ndifferent providers, with seamless interaction between the services in the system.\n \nChapter 18\u2002 \u25a0\u2002 Service-oriented software engineering\u2002 \u2002 521\n\u2020Lovelock, C., Vandermerwe, S. and Lewis, B. (1996). Services Marketing. Englewood Cliffs, NJ: Prentice Hall.\n", "page": 522, "type": "text", "section": "Page 522"}
{"text": "522\u2002 \u2002 Chapter 18\u2002 \u25a0\u2002 Service-oriented software engineering\nAs I discussed in Chapter 17, the ideas of \u201csoftware as a service\u201d and \u201cservice-\noriented systems\u201d are not the same thing. Software as a service means offering \n\u00ad\nsoftware functionality to users remotely over the web, rather than through applica-\ntions installed on a user\u2019s computer. Service-oriented systems are systems that are \nimplemented using reusable service components and that are accessed by other pro-\ngrams, rather than directly by users. Software that is offered as a service may be \nimplemented using a service-oriented system. However, you don\u2019t have to imple-\nment software in this way to offer it as a user service.\nAdopting a service-oriented approach to software engineering has a number of \nimportant benefits:\n1.\t\nServices can be offered by any service provider inside or outside of an \u00ad\norganization. \nAssuming these services conform to certain standards, organizations can create \napplications by integrating services from a range of providers. For example, a \nmanufacturing company can link directly to services provided by its suppliers.\n2.\t\nThe service provider makes information about the service public so that any \nauthorized user can use the service. The service provider and the service user do \nnot need to negotiate about what the service does before it can be incorporated \nin an application program.\n3.\t\nApplications can delay the binding of services until they are deployed or until \nexecution. Therefore, an application using a stock price service (say) could, in \nprinciple, dynamically change service providers while the system was execut-\ning. This means that applications can be reactive and adapt their operation to \ncope with changes to their execution environment.\n4.\t\nOpportunistic construction of new services is possible. A service provider may \n\u00ad\nrecognize new services that can be created by linking existing services in \n\u00ad\ninnovative ways.\n5.\t\nService users can pay for services according to their use rather than their \u00ad\nprovision. \nTherefore, instead of buying an expensive component that is rarely used, the appli-\ncation writer can use an external service that will be paid for only when required.\n6.\t\nApplications can be made smaller, which is particularly important for mobile \ndevices with limited processing and memory capabilities. Some \u00ad\ncomputationally \nintensive processing and exception handling can be offloaded to external \u00ad\nservices.\nService-oriented systems have loosely coupled architectures where service bindings \nmay change during system execution. A different, but equivalent, version of the ser-\nvice may therefore be executed at different times. Some systems will be solely built \nusing web services, and others will mix web services with locally developed compo-\nnents. To illustrate how applications that use a mixture of services and components \nmay be organized, consider the following scenario:\nAn in-car information system provides drivers with information on weather, \nroad traffic conditions, local information and so forth. This is linked to the car \n", "page": 523, "type": "text", "section": "Page 523"}
{"text": "radio so that information is delivered as a signal on a specific radio channel. \nThe car is equipped with GPS receiver to discover its position, and, based on \nthat position, the system accesses a range of information services. Information \nmay then be delivered in the driver\u2019s specified language.\nFigure 18.1 illustrates a possible organization for such a system. The in-car soft-\nware includes five modules. These handle communications with the driver, with a \nGPS receiver that reports the car\u2019s position, and with the car radio. The Transmitter \nand Receiver modules handle all communications with external services.\nThe car communicates with an external mobile information service that aggre-\ngates information from a range of other services, providing information on weather, \ntraffic, and local facilities. Different providers in different places offer these services, \nand the in-car system accesses an external discovery service to find the services \navailable in the local area. The mobile information service also uses the discovery \nservice to bind to the appropriate weather, traffic, and facilities services. The aggre-\ngated information is then sent to the car through a service that translates that infor-\nmation into the driver\u2019s preferred language.\nThis example illustrates one of the key advantages of the service-oriented approach. \nWhen the system is programmed or deployed, you don\u2019t have to decide what service \nUser interface\nLocator\nDiscovers car\nposition\nWeather\ninfo\nReceives request\nfrom user\nReceiver\nReceives\ninformation stream\nfrom services\nTransmitter\nSends position and\ninformation request\nto services\nRadio\nTranslates digital\ninfo stream to\nradio signal\nIn-car software system\nMobile Info Service\nFacilities\ninfo\nTranslator\nRoad\nlocator\nTraffic\ninfo\nCollates information\nRoad traffic info\ncommand\ngps coord\ngps\ncoord\ngps coord\ngps coord\nLanguage\ninfo\nInfo\nstream\nService discovery\nFinds available\nservices\nFigure 18.1\u2002 A service-\nbased, in-car \ninformation system \n \nChapter 18\u2002 \u25a0\u2002 Service-oriented software engineering\u2002 \u2002 523\n", "page": 524, "type": "text", "section": "Page 524"}
{"text": "524\u2002 \u2002 Chapter 18\u2002 \u25a0\u2002 Service-oriented software engineering\nprovider should be used or what specific services should be accessed. As the car moves \naround, the in-car software uses the service discovery service to find the most useful local \ninformation service. Because of the use of a translation service, it can move across bor-\nders and make local information available to people who don\u2019t speak the local language.\nI think that the service-oriented approach to software engineering is as important \na development as object-oriented software engineering. Service-oriented systems are \nessential to the cloud and mobile systems. Newcomer and Lomow (Newcomer and \nLomow 2005), in their book on SOA, summarize the potential of service-oriented \napproaches, which is now being realized:\nDriven by the convergence of key technologies and the universal adoption of \nWeb services, the service-oriented enterprise promises to significantly improve \ncorporate agility, speed time-to-market for new products and services, reduce \nIT costs and improve operational efficiency.\u2020\nBuilding applications based on services allows companies and other organiza-\ntions to cooperate and make use of each other\u2019s business functions. Thus, systems \nthat involve extensive information exchange across company boundaries, such as \nsupply chain systems where one company orders goods from another, can easily be \nautomated. Service-based applications may be constructed by linking services from \nvarious providers using either a standard programming language or a specialized \nworkflow language, as discussed in Section 18.4.\nInitial work on service provision and implementation was heavily influenced by \nthe failure of the software industry to agree on component standards. It was therefore \nstandards-driven, with all of the main industrial companies involved in standards \ndevelopment. This led to a whole range of standards (WS* standards) and the notion \nof service-oriented architectures. These were proposed as architectures for service-\nbased systems, with all service communication being standards-based. However, the \nstandards proposed were complex and had a significant execution overhead. This \nproblem has led many companies to adopt an alternative architectural approach, \nbased on so-called RESTful services. A RESTful approach is a simpler approach \nthan a service-oriented architecture, but it is less suited to services that offer complex \nfunctionality. I discuss both of these architectural approaches in this chapter.\n \n18.1  Service-oriented architecture\nService-oriented architecture (SOA) is an architectural style based on the idea that execut-\nable services can be included in applications. Services have well-defined, published inter-\nfaces, and applications can choose whether or not these are appropriate. An important \nidea underlying SOA is that the same service may be available from different providers \nand that applications could make a runtime decision of which service provider to use.\n\u2020Newcomer, E. and Lomow, G. (2005). Understanding SOA with Web Services. Boston: Addison-Wesley.\n", "page": 525, "type": "text", "section": "Page 525"}
{"text": "Figure 18.2 illustrates the structure of a service-oriented architecture. Service provid-\ners design and implement services and specify the interface to these services. They also \npublish information about these services in an accessible registry. Service requestors \n(sometimes called service clients) who wish to make use of a service discover the speci-\nfication of that service and locate the service provider. They can then bind their applica-\ntion to that specific service and communicate with it, using standard service protocols.\nThe development and use of internationally agreed standards is fundamental to \nSOA. As a result, service-oriented architectures have not suffered from the incompat-\nibilities that normally arise with technical innovations, where different suppliers \nmaintain their proprietary version of the technology. Figure 18.3 shows the stack of \nkey standards that have been established to support web services.\nWeb service protocols cover all aspects of service-oriented architectures, from the \nbasic mechanisms for service information exchange (SOAP) to programming language \nstandards (WS-BPEL). These standards are all based on XML, a human and machine-\nreadable notation that allows the definition of structured data where text is tagged with \na meaningful identifier. XML has a range of supporting technologies, such as XSD for \nschema definition, which are used to extend and manipulate XML descriptions. Erl (Erl \n2004) provides a good summary of XML technologies and their role in web services.\nBriefly, the fundamental standards for service-oriented architectures are:\n1.\t\nSOAP This is a message interchange standard that supports communication \nbetween services. It defines the essential and optional components of messages \nTransport (HTTP, HTTPS, SMTP, ...)\nMessaging (SOAP)\nService definition (UDDI, WSDL)\nProcess (WS-BPEL)\nSupport (WS-Security, WS-Addressing, ...)\nXML technologies (XML, XSD, XSLT, ....)\nFigure 18.3\u2002  Web \nservice standards \nService\nregistry\nService\nrequestor\nService\nprovider\nService\nFind\nPublish\nBind (SOAP)\n(WSDL)\nFigure 18.2\u2002 Service-\noriented architecture \n \n18.1\u2002 \u25a0\u2002 Service-oriented architecture\u2002 \u2002 525\n", "page": 526, "type": "text", "section": "Page 526"}
{"text": "526\u2002 \u2002 Chapter 18\u2002 \u25a0\u2002 Service-oriented software engineering\npassed between services. Services in a service-oriented architecture are some-\ntimes called SOAP-based services.\n2.\t\nWSDL The Web Service Description Language (WSDL) is a standard for ser-\nvice interface definition. It sets out how the service operations (operation names, \nparameters, and their types) and service bindings should be defined.\n3.\t\nWS-BPEL This is a standard for a workflow language that is used to define pro-\ncess programs involving several different services. I explain what process pro-\ngrams are in Section 18.3.\nThe UDDI (Universal Description, Discovery, and Integration) discovery standard \ndefines the components of a service specification intended to help potential users \ndiscover the existence of a service. This standard was meant to allow companies to set \nup registries, with UDDI descriptions defining the services they offered. Some com-\npanies set up UDDI registries in the early years of the 21st century, but users preferred \nstandard search engines to find services. All public UDDI registries have now closed.\nThe principal SOA standards are supported by a range of supporting standards \nthat focus on more specialized aspects of SOA. There are many supporting standards \nbecause they are intended to support SOA in different types of enterprise applica-\ntion. Some examples of these standards include:\n1.\t\nWS-Reliable Messaging, a standard for message exchange that ensures mes-\nsages will be delivered once and once only.\n2.\t\nWS-Security, a set of standards supporting web service security, including stand-\nards that specify the definition of security policies and standards that cover the \nuse of digital signatures.\n3.\t\nWS-Addressing, which defines how address information should be represented \nin a SOAP message.\n4.\t\nWS-Transactions, which defines how transactions across distributed services \nshould be coordinated.\nWeb service standards are a huge topic, and I don\u2019t have space to discuss them in \ndetail here. I recommend Erl\u2019s books (Erl 2004, 2005) for an overview of these \nstandards. Their detailed descriptions are also available as public documents on the \nWeb (W3C 2013).\n\t\n18.1.1 \t Service components in an SOA\nMessage exchange, as I explained in Section 17.1, is an important mechanism for \ncoordinating actions in a distributed computing system. Services in a SOA commu-\nnicate by exchanging messages, expressed in XML, and these messages are distrib-\nuted using standard Internet transport protocols such as HTTP and TCP/IP.\nA service defines what it needs from another service by setting out its require-\nments in a message, which is sent to that service. The receiving service parses the \n", "page": 527, "type": "text", "section": "Page 527"}
{"text": "message, carries out the computation, and, upon completion, sends a reply, as a mes-\nsage, to the requesting service. This service then parses the reply to extract the \nrequired information. Unlike software components, services do not use remote \n\u00ad\nprocedure or method calls to access functionality associated with other services.\nWhen you intend to use a web service, you need to know where the service is located \n(its Uniform Resource Identifier\u2014URI) and the details of its interface. These details are \nprovided in a service description that is written in an XML-based language called WSDL \n(Web Service Description Language). The WSDL specification defines three aspects of \na Web service: what the service does, how it communicates, and where to find it:\n1.\t\nThe \u201cwhat\u201d part of a WSDL document, called an interface, specifies what oper-\nations the service supports and defines the format of the messages sent and \nreceived by the service.\n2.\t\nThe \u201chow\u201d part of a WSDL document, called a binding, maps the abstract inter-\nface to a concrete set of protocols. The binding specifies the technical details of \nhow to communicate with a Web service.\n3.\t\nThe \u201cwhere\u201d part of a WSDL document describes the location of a specific Web \nservice implementation (its endpoint).\nThe WSDL conceptual model (Figure 18.4) shows the elements of a service \ndescription. Each element is expressed in XML and may be provided in separate \nfiles. These elements are:\n1.\t\nAn introductory part that usually defines the XML namespaces used and that \nmay include a documentation section providing additional information about \nthe service.\n2.\t\nAn optional description of the types used in the messages exchanged by the service.\n3.\t\nA description of the service interface, that is, the operations that the service \nprovides for other services or users.\n4.\t\nA description of the input and output messages processed by the service.\n5.\t\nA description of the binding used by the service, that is, the messaging protocol \nthat will be used to send and receive messages. The default is SOAP, but other \nIntro\nAbstract interface\nConcrete\nimplementation\nWSDL service definition\nXML namespace declarations\nType declarations\nInterface declarations\nMessage declarations\nBinding declarations\nEndpoint declarations\nFigure 18.4\u2002  \nOrganization of a WSDL \nspecification \n \n18.1\u2002 \u25a0\u2002 Service-oriented architecture\u2002 \u2002 527\n", "page": 528, "type": "text", "section": "Page 528"}
{"text": "528\u2002 \u2002 Chapter 18\u2002 \u25a0\u2002 Service-oriented software engineering\nbindings may also be specified. The binding sets out how the input and output \nmessages associated with the service should be packaged into a message, and \nspecifies the communication protocols used. The binding may also specify how \nsupporting information, such as security credentials or transaction identifiers, is \nincluded in messages to the service.\n6.\t\nAn endpoint specification that is the physical location of the service, expressed \nas a URI\u2014the address of a resource that can be accessed over the Internet.\nFigure 18.5 shows part of the interface for a simple service that, given a date and a \nplace, specified as a town within a country, returns the maximum and minimum tem-\nperature recorded in that place on that date. The input message also specifies whether \nthese temperatures are to be returned in degrees Celsius or degrees Fahrenheit.\nXML-based service descriptions include definitions of XML namespaces. A names-\npace identifier may precede any identifier used in the XML description, making it \u00ad\npossible \nto distinguish between identifiers with the same name that have been defined in different \nparts of an XML description. You don\u2019t have to understand the details of namespaces to \nFigure 18.5\u2002 Part of a \nWSDL description for a \nweb service\nDefine some of the types used. Assume that the namespace prefixes \u2019ws\u2019 refers to \nthe namespace URI for XML schemas and the namespace prefix associated with this \ndefinition is weathns.\n<types>\n<xs: schema targetNameSpace = \u201chttp://.\u2009\n.\u2009\n./weathns\u201d\nxmlns: weathns = \u201chttp://.\u2009\n.\u2009\n./weathns\u201d >\n<xs:element name = \u201cPlaceAndDate\u201d type = \u201cpdrec\u201d />\n<xs:element name = \u201cMaxMinTemp\u201d type = \u201cmmtrec\u201d />\n<xs:element name = \u201cInDataFault\u201d type = \u201cerrmess\u201d />\n<xs:complexType name = \u201cpdrec\u201d\n<xs:sequence>\n<xs:element name = \u201ctown\u201d type = \u201cxs:string\u201d/>\n<xs:element name = \u201ccountry\u201d type = \u201cxs:string\u201d/>\n<xs:element name = \u201cday\u201d type = \u201cxs:date\u201d />\n</xs:complexType>\nDefinitions of MaxMinType and InDataFault here\n</schema>\n</types>\nNow define the interface and its operations. In this case, there is only a single \noperation to return maximum and minimum temperatures\n<interface name = \u201cweatherInfo\u201d >\n<operation name = \u201cgetMaxMinTemps\u201d pattern = \u201cwsdlns: in-out\u201d>\n<input messageLabel = \u201cIn\u201d element = \u201cweathns: PlaceAndDate\u201d />\n<output messageLabel = \u201cOut\u201d element = \u201cweathns:MaxMinTemp\u201d />\n<outfault messageLabel = \u201cOut\u201d element = \u201cweathns:InDataFault\u201d />\n</operation>\n</interface>\n", "page": 529, "type": "text", "section": "Page 529"}
{"text": "understand the examples here. You only need to know that names may be prefixed with a \nnamespace identifier and that the namespace:name pair should be unique.\nIn Figure 18.5, the first part of the description shows part of the element and type \ndefinition that is used in the service specification. This defines the elements \nPlaceAndDate, MaxMinTemp, and InDataFault. I have only included the specification \nof PlaceAndDate, which you can think of as a record with three fields\u2014town, country \nand date. A similar approach would be used to define MaxMinTemp and InDataFault.\nThe second part of the description shows how the service interface is defined. In this \nexample, the service weatherInfo has a single operation, although there are no restrictions \non the number of operations that may be defined. The weatherInfo operation has an asso-\nciated in-out pattern meaning that it takes one input message and generates one output \nmessage. The WSDL 2.0 specification allows for a number of message exchange patterns \nsuch as in-only, in-out, out-only, in-optional-out, and out-in. The input and output mes-\nsages, which refer to the definitions made earlier in the types section, are then defined.\nA service interface that is defined in WSDL is simply a description of the service \nsignature, that is, the operations and their parameters. It does not include any infor-\nmation about the semantics of the service or its non-functional characteristics, such \nas performance and dependability. If you plan to use the service, you have to work \nout what the service actually does and the meaning of the input and output messages. \nYou have to experiment to discover the service\u2019s performance and dependability. \nWhile meaningful names and documentation help with understanding the service \nfunctionality, it is still possible to misunderstand what the service actually does.\nXML-based service descriptions are long, detailed, and tedious to read. WSDL \nspecifications are not normally written by hand, and most of the information in a \nspecification is automatically generated.\n \n18.2  RESTful services\nThe initial developments of web services and service-oriented software engineering \nwere standards-based, with XML-based messages exchanged between services. This \nis a general approach that allows for the development of complex services, dynamic \nservice binding, and control over quality of service and service dependability. \nHowever, as services were developed, it emerged that most of these were single-\nfunction services with relatively simple input and output interfaces. Service users \nwere not really interested in dynamic binding and the use of multiple service provid-\ners. They rarely use web service standards for quality of service, reliability, and so forth.\nThe problem is that web services standards are \u201cheavyweight\u201d standards that are \nsometimes overly general and inefficient. Implementing these standards requires a con-\nsiderable amount of processing to create, transmit, and interpret the associated XML \nmessages. This slows down communications between services, and, for high-throughput \nsystems, additional hardware may be required to deliver the quality of service required.\nIn response to this situation, an alternative \u201clightweight\u201d approach to web service \narchitecture has been developed. This approach is based on the REST architectural \n \n18.2\u2002 \u25a0\u2002 RESTful services\u2002 \u2002 529\n", "page": 530, "type": "text", "section": "Page 530"}
{"text": "530\u2002 \u2002 Chapter 18\u2002 \u25a0\u2002 Service-oriented software engineering\nstyle, where REST stands for Representational State Transfer (Fielding 2000). REST \nis an architectural style based on transferring representations of resources from a \nserver to a client. It is the style that underlies the web as a whole and has been used as \na much simpler method than SOAP/WSDL for implementing web service interfaces.\nThe fundamental element in a RESTful architecture is a resource. Essentially, a \nresource is simply a data element such as a catalog and a medical record, or a docu-\nment, such as this book chapter. In general, resources may have multiple representa-\ntions; that is, they can exist in different formats. For example, this book chapter has \nthree representations. These are a MS Word representation, which is used for editing, \na PDF representation, which is used for web display, and a InDesign representation, \nwhich is used for publishing. The underlying logical resource made up of text and \nimages is the same in all of these representations.\nIn a RESTful architecture, everything is represented as a resource. Resources have \na unique identifier, which is their URL. Resources are a bit like objects, with four fun-\ndamental polymorphic operations associated with them, as shown in Figure 18.6(a):\n1.\t\nCreate\u2014bring the resource into existence.\n2.\t\nRead\u2014return a representation of the resource.\n3.\t\nUpdate\u2014change the value of the resource.\n4.\t\nDelete\u2014make the resource inaccessible.\nThe Web is an example of a system that has a RESTful architecture. Web pages \nare resources, and the unique identifier of a web page is its URL.\nThe web protocols http and https are based on four actions, namely, POST, GET, \nPUT, and DELETE. These map onto the basic resource operations, as I have shown \nin Figure 18.6(b):\n1.\t\nPOST is used to create a resource. It has associated data that defines the resource.\n2.\t\nGET is used to read the value of a resource and return that to the requestor in the \nspecified representation, such as XHTML, that can be rendered in a web browser.\nResource R\nCREATE\nUPDATE\nREAD\nDELETE\nWeb-accessible\nresource R\nPOST\nPUT\nGET\nDELETE\nURL\n(a) General resource actions\n(b) Web resources\nFigure 18.6\u2002 Resources \nand actions \n", "page": 531, "type": "text", "section": "Page 531"}
{"text": "3.\t\nPUT is used to update the value of a resource.\n4.\t\nDELETE is used to delete the resource.\nAll services, in some way, operate on data. For example, the service described in \nSection 18.2 that returns the maximum and minimum temperatures for a location on \na given data uses a weather information database. SOAP-based services execute \nactions on this database to return particular values from it. RESTful services \n(Richardson and Ruby 2007) access the data directly.\nWhen a RESTful approach is used, the data is exposed and is accessed using its \nURL. RESTful services use http or https protocols, with the only allowed actions \nbeing POST, GET, PUT, and DELETE. Therefore, the weather data for each place in \nthe database might be accessed using URLs such as:\nhttp://weather-info-example.net/temperatures/boston\nhttp://weather-info-example.net/temperatures/edinburgh\nThis would invoke the GET operation and return a list of maximum and minimum \ntemperatures. To request the temperatures for a specific date, a URL query can be used:\nhttp://weather-info-example.net/temperatures/edinburgh?date=20140226\nURL queries can also be used to disambiguate the request, given that there may \nbe several places in the world with the same name:\nhttp://weather-info-example.net/temperatures/boston?date=20140226&country=\nUSA&state=\u201cMass\u201d\nAn important difference between RESTful services and SOAP-based services is \nthat RESTful services are not exclusively XML-based. So, when a resource is \nrequested, created, or changed, the representation may be specified. This is impor-\ntant for RESTful services because representations such as JSON (Javascript Object \nNotation), as well as XML, may be used. These can be processed more efficiently \nthan XML-based notations, thus reducing the overhead involved in a service call. \nTherefore, the above request for maximum and minimum temperatures for Boston \nmay return the following information:\n{\n\u201cplace\u201d: \u201cBoston\u201d,\n\u201ccountry  \u201cUSA\u201d,\n\u201cstate\u201d: \u201cMass\u201d,\n\u201cdate\u201d: \u201c26 Feb 2014\u201d,\n\u201cunits\u201d: \u201cFahrenheit\u201d,\n\u201cmax temp\u201d: 41,\n\u201cmin temp\u201d: 29\n}\nThe response to a GET request in a RESTful service may include URLs. \nTherefore, if the response to a request is a set of resources, then the URL of each of \n \n18.2\u2002 \u25a0\u2002 RESTful services\u2002 \u2002 531\n", "page": 532, "type": "text", "section": "Page 532"}
{"text": "532\u2002 \u2002 Chapter 18\u2002 \u25a0\u2002 Service-oriented software engineering\nthese services may be included. The requesting service may then process the \nrequests in its own way. Therefore, a request for weather information given a place \nname that is not unique may return the URLs of all of the places that match the request. \nFor example:\nhttp://weather-info-example.net/temperatures/edinburgh-scotland\nhttp://weather-info-example.net/temperatures/edinburgh-australia\nhttp://weather-info-example.net/temperatures/edinburgh-maryland\nA fundamental design principle for RESTful services is that they should be state-\nless. That is, in an interaction session, the resource itself should not include any state \ninformation, such as the time of the last request. Instead, all necessary state informa-\ntion should be returned to the requestor. If state information is required in later \nrequests, it should be returned to the server by the requestor.\nRESTful services have become more widely used over the past few years because \nof the widespread use of mobile devices. These devices have limited processing \ncapabilities, so the lower overhead of RESTful services allows better system perfor-\nmance. They are also easy to use with existing websites\u2014implementing a RESTful \nAPI for a website is usually fairly straightforward.\nHowever, there are problems with the RESTful approach:\n1.\t\nWhen a service has a complex interface and is not a simple resource, it can be \ndifficult to design a set of RESTful services to represent this interface.\n2.\t\nThere are no standards for RESTful interface description, so service users must \nrely on informal documentation to understand the interface.\n3.\t\nWhen you use RESTful services, you have to implement your own infrastruc-\nture for monitoring and managing the quality of service and the service reliabil-\nity. SOAP-based services have additional infrastructure support standards such \nas WS-Reliability and WS-Transactions.\nPautasso et al. (Pautasso, Zimmermann, and Leymann 2008) discuss when \nRESTful and SOAP-based should be used. However, it is often possible to provide \nboth SOAP-based and RESTful interfaces to the same service or resource (Figure \n18.7). This dual approach is now common for cloud services from providers such as \nMicrosoft, Google, and Amazon. Service clients can then choose the service access \nmethod that is best suited to their applications.\nResource\nR\nRestful API\nSOAP-based\nAPI\nService\nrequestor 1\nService\nrequestor 2\nFigure 18.7\u2002 RESTful \nand SOAP-based APIs \n", "page": 533, "type": "text", "section": "Page 533"}
{"text": " \n18.3  Service engineering\nService engineering is the process of developing services for reuse in service-oriented \napplications. It has much in common with component engineering. Service engi-\nneers have to ensure that the service represents a reusable abstraction that could \nbe useful in different systems. They must design and develop generally useful \nfunctionality associated with that abstraction and ensure that the service is robust \nand reliable. They have to document the service so that it can be discovered and \nunderstood by potential users.\nAs shown in Figure 18.8, there are three logical stages in the service engineering \nprocess:\n1.\t\nService candidate identification, where you identify possible services that might \nbe implemented and define the service requirements.\n2.\t\nService design, where you design the logical service interface and its implemen-\ntation interfaces (SOAP-based and/or RESTful).\n3.\t\nService implementation and deployment, where you implement and test the ser-\nvice and make it available for use.\nAs I discussed in Chapter 16, the development of a reusable component may \nstart with an existing component that has already been implemented and used in \nan application. The same is true for services\u2014the starting point for this process \nwill often be an existing service or a component that is to be converted to a ser-\nvice. In this situation, the design process involves generalizing the existing com-\nponent so that application-specific features are removed. Implementation means \nadapting the component by adding service interfaces and implementing the \nrequired generalizations.\n\t\n18.3.1 \t Service candidate identification\nThe basic idea of service-oriented computing is that services should support business \nprocesses. As every organization has a wide range of processes, many possible \n\u00ad\nservices may be implemented. Service candidate identification therefore involves \nService design\nService\ncandidate\nidentification\nService\nimplementation\nand deployment\nService\nrequirements\nService interface\nspecification\nValidated and\ndeployed service\nFigure 18.8\u2002 The service \nengineering process \n \n18.3\u2002 \u25a0\u2002 Service engineering\u2002 \u2002 533\n", "page": 534, "type": "text", "section": "Page 534"}
{"text": "534\u2002 \u2002 Chapter 18\u2002 \u25a0\u2002 Service-oriented software engineering\nunderstanding and analyzing the organization\u2019s business processes to decide which \nreusable services could be implemented to support these processes.\nErl (Erl 2005) suggests that there are three fundamental types of service:\n1.\t\nUtility services. These services implement some general functionality that may \nbe used by different business processes. An example of a utility service is a cur-\nrency conversion service that can be accessed to compute the conversion of one \ncurrency (e.g., dollars) to another (e.g., euros).\n2.\t\nBusiness services. These services are associated with a specific business func-\ntion. An example of a business function in a university would be the registration \nof students for a course.\n3.\t\nCoordination or process services. These services support a more general busi-\nness process that usually involves different actors and activities. An example of \na coordination service in a company is an ordering service that allows orders to \nbe placed with suppliers, goods accepted, and payments made.\nErl also suggests that services can be thought of as task-oriented or entity-\u00ad\noriented. Task-oriented services are associated with some activity, whereas entity-\noriented services are associated with a system resource. The resource is a business \nentity such as a job application form. Figure 18.9 shows examples of services that \nare task-oriented or entity-oriented. Utility or business services may be entity-\noriented or task-oriented. Coordination services are always task-oriented.\nYour goal in service candidate identification should be to identify services that \nare logically coherent, independent, and reusable. Erl\u2019s classification is helpful in \nthis respect, as it suggests how to discover reusable services by looking at business \nentities as resources and business activities. However, identifying service candidates \nis sometimes difficult because you have to envisage how the services could be used. \nYou have to think of possible candidates and then ask a series of questions about \nthem to see if they are likely to be useful services. Possible questions that you might \nask to identify potentially reusable services are:\n1.\t\nFor an entity-oriented service, is the service associated with a single logical \nresource that is used in different business processes? What operations are nor-\nmally performed on that entity that must be supported? Do these fit with the \nRESTful service operations PUT, CREATE, POST, and DELETE?\n2.\t\nFor a task-oriented service, is the task one that is carried out by different people \nin the organization? Will they be willing to accept the inevitable standardization \nFigure 18.9\u2002 Service \nclassification\nUtility\nBusiness\nCoordination\nTask\nCurrency converter\nEmployee locator\nValidate claim form\nCheck credit rating\nProcess expense claim\nPay external supplier\nEntity\nDocument translator\nWeb form to XML converter\nExpenses form\nStudent application form\n", "page": 535, "type": "text", "section": "Page 535"}
{"text": "that occurs when a single support service is provided? Can this fit into the \nRESTful model, or should it be redesigned as an entity-oriented service.\n3.\t\nIs the service independent? That is, to what extent does it rely on the availability \nof other services?\n4.\t\nDoes the service have to maintain state? If state information is required, this \nmust either be maintained in a database or passed as a parameter to the service. \nUsing a database affects service reusability as there is a dependency between the \nservice and the required database. In general, services where the state is passed \nto the service are easier to reuse, as no database binding is required.\n5.\t\nMight this service be used by external clients? For example, an entity-oriented \nservice associated with a catalog could be made available to both internal and \nexternal users.\n6.\t\nAre different users of the service likely to have different non-functional require-\nments? If they do, then more than one version of a service should perhaps be \nimplemented.\nThe answers to these questions help you select and refine abstractions that can be \nimplemented as services. However, there is no formulaic way of deciding which are \nthe best services. You need to use your experience and business knowledge to decide \non what are the most appropriate services.\nThe output of the service selection process is a set of identified services and asso-\nciated requirements for these services. The functional service requirements should \ndefine what the service should do. The non-functional requirements should define \nthe security, performance, and availability requirements of the service.\nTo help you understand the process of service candidate identification and \n\u00ad\nimplementation, consider the following example:\nA company, which sells computer equipment, has arranged special prices for \napproved configurations for some large customers. To facilitate automated \nordering, the company wishes to produce a catalog service that will allow \ncustomers to select the equipment that they need. Unlike a consumer catalog, \norders are not placed directly through a catalog interface. Instead, goods are \nordered through the web-based procurement system of each company that \naccesses the catalog as a web service. The reason for this is that large compa-\nnies usually have their own budgeting and approval procedures for orders that \nmust be followed when an order is placed.\nThe catalog service is an example of an entity-oriented service, where the underlying \nresource is the catalog. The functional catalog service requirements are as follows:\n1.\t\nA specific version of the catalog shall be provided for each user company. This \nshall include the approved configurations and equipment that may be ordered by \n \n18.3\u2002 \u25a0\u2002 Service engineering\u2002 \u2002 535\n", "page": 536, "type": "text", "section": "Page 536"}
{"text": "536\u2002 \u2002 Chapter 18\u2002 \u25a0\u2002 Service-oriented software engineering\nemployees of the customer company and the equipment prices that have been \nagreed to with that company.\n2.\t\nThe catalog shall allow a customer employee to download a version of the catalog \nfor offline browsing.\n3.\t\nThe catalog shall allow users to compare the specifications and prices of up to \nsix catalog items.\n4.\t\nThe catalog shall provide browsing and search facilities for users.\n5.\t\nUsers of the catalog shall be able to discover the predicted delivery date for a \ngiven number of specific catalog items.\n6.\t\nUsers of the catalog shall be able to place \u201cvirtual orders\u201d where the items \nrequired will be reserved for them for 48 hours. Virtual orders must be con-\nfirmed by a real order placed by a procurement system. The real order must be \nreceived within 48 hours of the virtual order.\nIn addition to these functional requirements, the catalog has a number of non-\nfunctional requirements:\n1.\t\nAccess to the catalog service shall be restricted to employees of accredited \norganizations.\n2.\t\nThe prices and configurations offered to each customer shall be confidential, \nand access to these shall only be provided to employees of that customer.\n3.\t\nThe catalog shall be available without disruption of service from 0700 GMT to \n1100 GMT.\n4.\t\nThe catalog service shall be able to process up to 100 requests per second peak load.\nThere is no non-functional requirement related to the response time of the catalog \nservice. This depends on the size of the catalog and the expected number of simulta-\nneous users. As this is not a time-critical service, there is no need to specify the \nrequired performance at this stage.\n\t\n18.3.2 \t Service interface design\nOnce you have identified candidate services, the next stage in the service engineer-\ning process is to design the service interfaces. This involves defining the operations \nassociated with the service and their parameters. If SOAP-based services are used, \nyou have to design the input and output messages. If RESTful services are used, you \nhave to think about the resources required and how the standard operations should be \nused to implement the service operations.\nThe starting point for service interface design is abstract interface design. where \nyou identify the entities and the operations associated with the service, their inputs and \n", "page": 537, "type": "text", "section": "Page 537"}
{"text": "outputs, and the exceptions associated with these operations. You then need to think \nabout how this abstract interface is realized as SOAP-based or RESTful services.\nIf you choose a SOAP-based approach, you have to design the structure of the XML \nmessages that are sent and received by the service. The operations and messages are the \nbasis of an interface description written in WSDL. If you choose a RESTful approach, \nyou have to design how the service operations map onto the RESTful operations.\nAbstract interface design starts with the service requirements and defines the \noperation names and parameters. At this stage, you should also define the exceptions \nthat may arise when a service operation is invoked. Figure 18.10 shows the catalog \noperations that implement the requirements. There is no need for these to be speci-\nfied in detail; you add detail at the next stage of the design process.\nOnce you have established an informal description of what the service should do, \nthe next stage is to add more detail of the service inputs and outputs. I have shown \nthis for the catalog service in Figure 18.11, which extends the functional description \nin Figure 18.10.\nDefining exceptions and how these exceptions can be communicated to service \nusers is particularly important. Service engineers do not know how their services \nwill be used. It is usually unwise to make assumptions that service users will have \ncompletely understood the service specification. Input messages may be incorrect, \nso you should define exceptions that report incorrect inputs to the service client. It is \ngenerally good practice in reusable component development to leave all exception \nhandling to the user of the component. Service developers should not impose their \nviews on how exceptions should be handled.\nIn some cases, a textual description of the operations and their inputs and outputs \nis all that is required. The detailed realization of the service is left as an implementa-\ntion decision. Sometimes, however, you need to have a more detailed design, and a \ndetailed interface description can be specified in a graphical notation such as the \nUML or in a readable description format such as JSON. Figure 18.12, which \ndescribes the inputs and outputs for the getDelivery operation, shows how you can \nuse the UML to describe the interface in detail.\nFigure 18.10\u2002 Catalog \noperations\nOperation\nDescription\nMakeCatalog\nCreates a version of the catalog tailored for a specific customer. Includes an \noptional parameter to create a downloadable PDF version of the catalog.\nLookup\nDisplays all of the data associated with a specified catalog item.\nSearch\nTakes a logical expression and searches the catalog according to that \nexpression. It displays a list of all items that match the search expression.\nCompare\nProvides a comparison of up to six characteristics (e.g., price, dimensions, \nprocessor speed, etc.) of up to four catalog items.\nCheckDelivery\nReturns the predicted delivery date for an item if ordered that day.\nMakeVirtualOrder\nReserves the number of items to be ordered by a customer and provides item \ninformation for the customer\u2019s own procurement system.\n \n18.3\u2002 \u25a0\u2002 Service engineering\u2002 \u2002 537\n", "page": 538, "type": "text", "section": "Page 538"}
{"text": "538\u2002 \u2002 Chapter 18\u2002 \u25a0\u2002 Service-oriented software engineering\nFigure 18.11\u2002 Catalog \ninterface design\nOperation\nInputs\nOutputs\nExceptions\nMakeCatalog\nmcIn\nCompany id\nPDF-flag\nmcOut\nURL of the catalog for \nthat company\nmcFault\nInvalid company id\nLookup\nlookIn\nCatalog URL\nCatalog number\nlookOut\nURL of page with the  \nitem information\nlookFault\nInvalid catalog \nnumber\nSearch\nsearchIn\nCatalog URL\nSearch string\nsearchOut\nURL of web page with \nsearch results\nsearchFault\nBadly formed search \nstring\nCompare\ncompIn\nCatalog URL\nEntry attribute (up to 6)\nCatalog number (up to 4)\ncompOut\nURL of page showing \ncomparison table\ncompFault\nInvalid company id\nInvalid catalog number\nUnknown attribute\nCheckDelivery\ncdIn\nCompany id\nCatalog number\nNumber of items required\ncdOut\nExpected delivery  \ndate\ncdFault\nInvalid company id\nNo availability\nZero items requested\nMakeVirtualOrder\nvoIn\nCompany id\nCatalog number\nNumber of items required\nvoOut\nCatalog number\nNumber of items  \nrequired\nPredicted delivery date\nUnit price estimate\nTotal price estimate\nvoFault\nInvalid company id\nInvalid catalog \nnumber\nZero items requested\ncdIn\ncID: string\ncatNum: string\nnumItems: integer\nsize (cID) = 6\nsize (catNum) = 10\nnumItems > 0\ncdOut\ncatNum: string\ndelivDate: date\nsize (catNum) = 10\ndelivDate > Today\ncdFault\nerrCode: integer\nInvalid company id\nerrCode=1\nInvalid catalog number\nerrCode = 2\nNo availability\nerrCode = 3\nZero items requested\nerrCode = 4\nFigure 18.12\u2002 UML \ndefinition of input and \noutput messages \n", "page": 539, "type": "text", "section": "Page 539"}
{"text": "Notice how I have added detail to the description by annotating the UML diagram \nwith constraints. These details define the length of the strings representing the com-\npany and the catalog item, and specify that the number of items must be greater than \nzero and that delivery must be after the current date. The annotations also show \nwhich error codes are associated with each possible fault.\nThe catalog service is an example of a practical service, which illustrates that it is \nnot always straightforward whether to choose a RESTful or a SOAP-based approach \nto \u00ad\nservice implementation. As an entity-based service, the catalog can be represented \nas a resource, which suggests that a RESTful model is the right one to use. However, \noperations on the catalog are not simple GET operations, and you need to maintain \nsome state in an interaction session with the catalog. This suggests the use of a SOAP-\nbased approach. Such dilemmas are common in service engineering, and usually \nlocal circumstances (e.g., availability of expertise) are a major factor in the decision \nof which approach to use.\nTo implement a set of RESTful services, you have to decide on the set of resources \nthat will be used to represent the catalog and how the fundamental GET, POST, and \nPUT operations will operate on these resources. Some of these design decisions are \nstraightforward:\n1.\t\nThere should be a resource representing a company-specific catalog. This should \nhave a URL of the form <base catalog>/<company name> and should be cre-\nated using a POST operation.\n2.\t\nEach catalog item should have its own URL of the form <base catalog>/<company \nname>/<item identifier>.\n3.\t\nYou use the GET operation to retrieve items. Lookup is implemented by using the \nURL of an item in a catalog as the GET parameter. Search is implemented by using \nGET with the company catalog as the URL and the search string as a query parameter. \nThis GET operation returns a list of URLs of the items matching the search.\nHowever, the Compare, CheckDelivery, and MakeVirtualOrder operations are \nmore complex:\n1.\t\nThe Compare operation can be implemented as a sequence of GET operations to \nretrieve the individual items, followed by a POST operation to create the com-\nparison table and a final GET operation to return this to the user.\n2.\t\nThe CheckDelivery and MakeVirtualOrder operations require an additional \nresource, representing a virtual order. A POST operation is used to create this \nresource with the number of items required. The company id is used to auto-\nmatically fill in the order form, and the delivery date is calculated. The resource \ncan then be retrieved using a GET operation.\nYou need to think carefully about how exceptions are mapped onto the standard \nhttp response codes such as a 404 code, meaning that a URL cannot be retrieved. \nI don\u2019t have space to go into this issue here, but it adds a further level of complexity \nto the service interface design.\n \n18.3\u2002 \u25a0\u2002 Service engineering\u2002 \u2002 539\n", "page": 540, "type": "text", "section": "Page 540"}
{"text": "540\u2002 \u2002 Chapter 18\u2002 \u25a0\u2002 Service-oriented software engineering\nFor SOAP-based services, the realization process, in this case, is simpler as the \nlogical interface design can be translated automatically into WSDL. Most program-\nming environments that support service-oriented development (e.g., the ECLIPSE \nenvironment) include tools that can translate a logical interface description into its \ncorresponding WSDL representation.\n\t\n18.3.3 \t Service implementation and deployment\nOnce you have identified candidate services and designed their interfaces, the final \nstage of the service engineering process is service implementation. This implemen-\ntation may involve programming the service using a language such as Java or C#. \nBoth of these languages include libraries with extensive support for developing \nSOAP-based and RESTful services.\nAlternatively, you can implement services by creating service interfaces to existing \ncomponents or legacy systems. Software assets that have already proved to be useful \ncan therefore be made available for reuse. In the case of legacy systems, it may mean \nthat the system functionality can be accessed by new applications. You can also develop \nnew services by defining compositions of existing services, as I explain in Section 18.4.\nOnce a service has been implemented, it then has to be tested before it is deployed. \nThis involves examining and partitioning the service inputs (as explained in Chapter 8), \ncreating input messages that reflect these input combinations, and then checking that \nthe outputs are expected. You should always try to generate exceptions during the test \nto check that the service can cope with invalid inputs. For SOAP-based services, testing \ntools are available that allow services to be examined and tested, and that generate tests \nfrom a WSDL specification. However, these tools can only test the conformity of the \nservice interface to the WSDL. They cannot test the service\u2019s functional behavior.\nService deployment, the final stage of the process, involves making the service \navailable for use on a web server. Most server software makes this operation straight-\nforward. You install the file containing the executable service in a specific directory. \nIt then automatically becomes available for use.\nIf the service is intended to be available within a large organization or as a pub-\nlicly available service, you then have to provide documentation for external service \nusers. Potential users can then decide if the service is likely to meet their needs and \nLegacy system services\nLegacy systems are old software systems that are used by an organization. It may not be cost-effective to rewrite \nor replace these systems, and many organizations would like to use them in conjunction with more modern \nsystems. One of the most important uses of services is to implement \u201cwrappers\u201d for legacy systems that provide \naccess to a system\u2019s functions and data. These systems can then be accessed over the web and integrated with \nother applications.\nhttp://software-engineering-book.com/web/legacy-services\n", "page": 541, "type": "text", "section": "Page 541"}
{"text": "if they can trust you, as a service provider, to deliver the service reliably and securely. \nInformation that you may include in a service description might be:\n1.\t\nInformation about your business, contact details, and so on. This is important \nfor trust reasons. External users of a service have to be confident that it will not \nbehave maliciously. Information about the service provider allows users to \ncheck their credentials with business information agencies.\n2.\t\nAn informal description of the functionality provided by the service. This helps \npotential users to decide if the service is what they want.\n3.\t\nA description of how to use the service. For simple services, this can be an \ninformal textual description that explains the input and output parameters. For \nmore complex SOAP-based services, the WSDL description may be published.\n4.\t\nSubscription information that allows users to register for information about \nupdates to the service.\nA general difficulty with service specifications is that the functional behavior of \nthe service is usually specified informally, as a natural language description. Natural \nlanguage descriptions are easy to read, but they are subject to misinterpretation. To \naddress this problem, there has been extensive research on using ontologies and \nontology languages for specifying service semantics by marking up the service with \nontology information (W3C 2012). However, ontology-based specification is com-\nplex and not widely understood. Consequently, it has not been widely used.\n \n18.4  Service composition\nThe underlying principle of service-oriented software engineering is that you compose \nand configure services to create new, composite services. These may be integrated \nwith a user interface implemented in a browser to create a web application, or they \nmay be used as components in some other service composition. The services involved \nin the composition may be specially developed for the application, business services \ndeveloped within a company, or services from an external provider. Both RESTful and \nSOAP-based services can be composed to create services with extended functionality.\nMany companies have converted their enterprise applications into service-oriented \nsystems, where the basic application building block is a service rather than a compo-\nnent. This allows for widespread reuse within the company. We are now seeing the \nemergence of interorganizational applications between trusted suppliers, who use \neach other\u2019s services. The final realization of the long-term vision of service-oriented \nsystems will rely on the development of a \u201cservices market,\u201d where services are \nbought from trusted external suppliers.\nService composition may be used to integrate separate business processes to pro-\nvide an integrated process offering more extensive functionality. Say an airline wishes \nto develop a travel aggregation service that provides a complete vacation package for \n \n18.4\u2002 \u25a0\u2002 Service composition\u2002 \u2002 541\n", "page": 542, "type": "text", "section": "Page 542"}
{"text": "542\u2002 \u2002 Chapter 18\u2002 \u25a0\u2002 Service-oriented software engineering\ntravelers. In addition to booking their flights, travelers can also book hotels in their pre-\nferred location, arrange car rental or book a taxi from the airport, browse a travel guide, \nand make reservations to visit local attractions. To create this application, the airline \ncomposes its own booking service with services offered by a hotel booking agency, rental \ncar and taxi companies, and reservation services offered by owners of local attractions. \nThe end result is a single service that integrates the services from different providers.\nYou can think of this process as a sequence of separate steps, as shown in Figure \n18.13. Information is passed from one step to the next. For example, the rental car \ncompany is informed of the time that the flight is scheduled to arrive. The sequence of \nsteps is called a workflow\u2014a set of activities ordered in time, with each activity carry-\ning out some part of the work. A workflow is a model of a business process; that is, it \nsets out the steps involved in reaching a particular goal that is important for a business. \nIn this case, the business process is the vacation booking service, offered by the airline.\nWorkflow is a simple idea, and the above scenario of booking a vacation seems to \nbe straightforward. In practice, service composition is usually more complex than \nthis simple model implies. You have to consider the possibility of service failure and \ninclude exception management to handle these failures. You also have to take into \naccount nonstandard demands made by users of the application. For example, say a \ntraveler was disabled and required a wheelchair to be rented and delivered to the \nairport. This would require extra services to be implemented and composed, with \nadditional steps added to the workflow.\nWhen designing a travel aggregation service, you must be able to cope with situ-\nations where the normal execution of one of the services results in an incompatibility \nwith some other service execution. For example, say a flight is booked to leave on \nJune 1 and to return on June 7. The workflow then proceeds to the hotel booking \nstage. However, the resort is hosting a major convention until June 2, so no hotel \nrooms are available. The hotel booking service reports this lack of availability. This \nis not a failure; lack of availability is a common situation.\nYou therefore have to \u201cundo\u201d the flight booking and pass the information about \nlack of availability back to the user. He or she then has to decide whether to change \nthe dates or the resort. In workflow terminology, this is called a compensation action. \nCompensation actions are used to undo actions that have already been completed but \nthat must be changed as a result of later workflow activities.\nThe process of designing new services by reusing existing services is a process of \nsoftware design with reuse (Figure 18.13). Design with reuse inevitably involves \nrequirements compromises. The \u201cideal\u201d requirements for the system have to be mod-\nified to reflect the services that are actually available, whose costs fall within budget \nand whose quality of service is acceptable.\nBook\nflights\nBook\nhotel\nArrange\ncar or taxi\nBrowse\nattractions\nBook\nattractions\nArrival/departure\ndates/times\nHotel location\nDates/preferences\nFigure 18.13\u2002 Vacation \npackage workflow \n", "page": 543, "type": "text", "section": "Page 543"}
{"text": "I have shown the six key stages in the process of system construction by composi-\ntion in Figure 18.14:\n1.\t\nFormulate outline workflow In this initial stage of service design, you use the \nrequirements for the composite service as a basis for creating an \u201cideal\u201d service \ndesign. You should create a fairly abstract design at this stage, with the intention \nof adding details once you know more about available services.\n2.\t\nDiscover services During this stage of the process, you look for existing ser-\nvices to include in the composition. Most service reuse is within enterprises, so \nthis may involve searching local service catalogs. Alternatively, you may search \nthe services offered by trusted service providers, such as Oracle and Microsoft.\n3.\t\nSelect possible services From the set of possible service candidates that you \nhave discovered, you then select possible services that can implement workflow \nactivities. Your selection criteria will obviously include the functionality of the \nservices offered. They may also include the cost of the services and the quality \nof service (responsiveness, availability, etc.) offered.\n4.\t\nRefine workflow On the basis of information about the services that you have selected, \nyou then refine the workflow. This involves adding detail to the abstract description \nand perhaps adding or removing workflow activities. You may then repeat the ser-\nvice\u00a0discovery and selection stages. Once a stable set of services has been chosen and \nthe final workflow design established, you move on to the next stage in the process.\n5.\t\nCreate workflow program During this stage, the abstract workflow design is \ntransformed to an executable program and the service interface is defined. You \ncan implement workflow programs using a programming language, such as Java \nor C#, or by using a workflow language, such as BPMN (explained below). This \nstage may also involve the creation of web-based user interfaces to allow the \nnew service to be accessed from a web browser.\n6.\t\nTest completed service or application The process of testing the completed, \ncomposite service is more complex than component testing in situations where \nexternal services are used. I discuss testing issues in Section 18.4.2.\nThis process assumes that existing services are available for composition. If you \nrely on external information that is not available through a service interface, you \nmay have to implement these services yourself. This usually involves a \u201cscreen \nFormulate\noutline\nworkflow\nDiscover\nservices\nWorkflow\ndesign\nService list\nService\nspecifications\nWorkflow\ndesign\nSelect\nservices\nRefine\nworkflow\nCreate\nworkflow\nprogram\nExecutable\nworkflow\nTest\nservice\nDeployable\nservice\nFigure 18.14\u2002 Service \nconstruction by \ncomposition \n \n18.4\u2002 \u25a0\u2002 Service composition\u2002 \u2002 543\n", "page": 544, "type": "text", "section": "Page 544"}
{"text": "544\u2002 \u2002 Chapter 18\u2002 \u25a0\u2002 Service-oriented software engineering\nscraping\u201d process where your program extracts information from the HTML text of \nweb pages that are sent to a browser for rendering.\n\t\n18.4.1 \t Workflow design and implementation\nWorkflow design involves analyzing existing or planned business processes to \nunderstand the tasks involved and how these tasks exchange information. You then \ndefine the new business process in a workflow design notation. This sets out the \nstages involved in enacting the process and the information that is passed between \nthe different process stages. However, existing processes may be informal and \ndependent on the skills and ability of the people involved. There may be no \u201cnormal\u201d \nway of working or process definition. In such cases, you have to use your knowledge \nof the current process to design a workflow that achieves the same goals.\nWorkflows represent business process models. They are graphical models that are \nwritten using UML activity diagrams or BPMN, the Business Process Modeling Notation \n(White and Miers 2008; OMG 2011). I use BPMN for the examples in this chapter. If \nyou use SOAP-based services, it is possible to convert BPMN workflows automatically \ninto WS-BPEL, an XML-based workflow language. This is conformant with other web \nservice standards such as SOAP and WSDL. RESTful services may be composed within \na program in a standard programming language such as Java. Alternatively, a composi-\ntion language used for service mashups may be used (Rosenberg et al. 2008).\nFigure 18.15 is an example of a simple BPMN model of part of the vacation pack-\nage scenario, shown in Figure 18.14. The model shows a simplified workflow for \nhotel booking and assumes the existence of a Hotels service with associated opera-\ntions called GetRequirements, CheckAvailability, ReserveRooms, NoAvailability, \nConfirmReservation, and CancelReservation. The process involves getting require-\nments from the customer, checking room availability, and then, if rooms are availa-\nble, making a booking for the required dates.\nThis model introduces some of the core concepts of BPMN that are used to create \nworkflow models:\n1.\t\nRectangles with rounded corners represent activities. An activity can be exe-\ncuted by a human or by an automated service.\n2.\t\nCircles represent discrete events. An event is something that happens during a \nbusiness process. A simple circle is used to represent a starting event and a \ndarker circle to represent an end event. A double circle (not shown) is used to \nrepresent an intermediate event. Events can be clock events, thus allowing work-\nflows to be executed periodically or timed out.\n3.\t\nA diamond is used to represent a gateway. A gateway is a stage in the process \nwhere some choice is made. For example, in Figure 18.15, a choice is made on \nthe basis of whether or not rooms are available.\n4.\t\nA solid arrow shows the sequence of activities; a dashed arrow represents mes-\nsage flow between activities. In Figure 18.15, these messages are passed \nbetween the hotel booking service and the customer.\n", "page": 545, "type": "text", "section": "Page 545"}
{"text": "These key features are enough to describe most workflows. However, BPMN \nincludes many additional features that I don\u2019t have space to describe here. These add \ninformation to a business process description that allows it to be automatically trans-\nlated into an executable service.\nFigure 18.15 shows a process that is enacted in a single organization, the com-\npany that provides a booking service. However, the key benefit of a service-oriented \napproach is that it supports interorganizational computing. This means that a compu-\ntation involves processes and services in different companies. This process is repre-\nsented in BPMN by developing separate workflows for each of the organizations \ninvolved with interactions between them.\nTo illustrate multiple workflow processes, I use a different example, drawn \nfrom high-performance computing, where hardware is offered as a service. \nServices are created to provide access to high-performance computers to a geo-\ngraphically distributed user community. In this example, a vector-processing com-\nputer (a machine that can carry out parallel computations on arrays of values) is \noffered as a service (VectorProcService) by a research laboratory. This is accessed \nthrough another service called SetupComputation. These services and their \n\u00ad\ninteractions are shown in Figure 18.16.\nIn this example, the workflow for the SetupComputation service asks for access \nto a vector processor and, if a processor is available, establishes the computation \nrequired and downloads data to the processing service. Once the computation is \ncomplete, the results are stored on the local computer. The workflow for \nVectorProcService includes the following steps:\nCheck if a processor is available\nAllocate resources for the computation\nInitialize the system\nHotels.\nGetRequirements\nCustomer\nHotels.\nCheckAvailability\nHotels.\nNoAvailability\nHotels.\nReserveRooms\nHotels.\nConfirmReservation\nRetry\nCancel\nRooms OK\nNo rooms\nFigure 18.15\u2002 A \nfragment of a hotel \nbooking workflow \n \n18.4\u2002 \u25a0\u2002 Service composition\u2002 \u2002 545\n", "page": 546, "type": "text", "section": "Page 546"}
{"text": "546\u2002 \u2002 Chapter 18\u2002 \u25a0\u2002 Service-oriented software engineering\nCarry out the computation\nReturn the results to the client service\nIn BPMN terms, the workflow for each organization is represented in a separate \npool. It is shown graphically by enclosing the workflow for each participant in the \nprocess in a rectangle, with the name written vertically on the left edge. The work-\nflows in each pool are coordinated by exchanging messages. In situations where \ndifferent parts of an organization are involved in a workflow, pools are divided into \nnamed \u201clanes.\u201d Each lane shows the activities in that part of the organization.\nOnce a business process model has been designed, it has to be refined depending \non the services that have been discovered. As I suggested in the discussion of Figure \n18.14, the model may go through a number of iterations until a design that allows the \nmaximum possible reuse of available services has been created.\nOnce the final design is available, you can then develop the final service-oriented \nsystem. This involves implementing services that are not available for reuse and con-\nverting the workflow model into an executable program. As services are implementa-\ntion-language independent, new services can be written in any language. The workflow \nmodel may be automatically processed to create an executable WS-BPEL model if \nSOAP-based services are used. Alternatively, if RESTful services are used, the work-\nflow may be manually programmed, with the model acting as a program specification.\n\t\n18.4.2 \t Testing service compositions\nTesting is important in all system development processes as it demonstrates that a \nsystem meets its functional and non-functional requirements and detects defects that \nRequest\nprocessor\nSet up job\nparameters\nDownload\ndata\nStart\ncomputation\nStore\nresults\nReport\ncompletion\nRestart\nFail\nSetupComputation\nCheck\nAvailability\nAllocate\nresources\nInitialize\nCompute\nReturn\nresults\nOK\nNo processor\nOK\nVectorProcService\nFigure 18.16\u2002 Interacting \nworkflows \n", "page": 547, "type": "text", "section": "Page 547"}
{"text": "have been introduced during the development process. Many testing techniques, \nsuch as program inspections and coverage testing, rely on analysis of the software \nsource code. However, if you use services from an external provider, you will not \nhave access to the source code of the service implementations. You cannot therefore \nuse \u201cwhite box\u201d testing techniques that rely on the source code of the system.\nAs well as problems of understanding the implementation of the service, testers \nmay also face further difficulties when testing service compositions:\n1.\t\nExternal services are under the control of the service provider rather than the \nuser of the service. The service provider may withdraw these services at any time \nor may make changes to them, which invalidates any previous \u00ad\napplication test-\ning. These problems are handled in software components by maintaining differ-\nent versions of the component, but service versions are not normally supported.\n2.\t\nIf services are dynamically bound, an application may not always use the same \nservice each time that it is executed. Therefore, tests may be successful when an \napplication is bound to a particular service, but it cannot be guaranteed that that \nservice will be used during an actual execution of the system. This problem has \nbeen one reason why dynamic binding has not been widely used.\n3.\t\nThe non-functional behavior of a service is not simply dependent on how it is used \nby the application that is being tested. A service may perform well during testing \nbecause it is not operating under a heavy load. In practice, the observed service \nbehavior may be different because of the demands made by other \u00ad\nservice users.\n4.\t\nThe payment model for services could make service testing very expensive. \nThere are different possible payment models: Some services may be freely \navailable, some may be paid for by subscription, and others may be paid for on \na per-use basis. If services are free, then the service provider will not wish them \nto be loaded by applications being tested; if a subscription is required, then a \nservice user may be reluctant to enter into a subscription agreement before test-\ning the service. Similarly, if the usage is based on payment for each use, service \nusers may find the cost of testing to be prohibitive.\n5.\t\nI have discussed the notion of compensation actions that are invoked when an \nexception occurs and previous commitments that have been made (such as a \nflight reservation) have to be revoked. There is a problem in testing such actions \nas they may depend on the failure of other services. Simulating the failure of \nthese services during the testing process is usually difficult.\nThese problems are particularly acute when external services are used. They are \nless serious when services are used within the same company or where \u00ad\ncooperating \ncompanies trust services offered by their partners. In such cases, source code may \nbe available to guide the testing process, and payment for services is unlikely to \nbe a problem. Resolving these testing problems and producing guidelines, tools, \nand techniques for testing service-oriented applications remains an important \nresearch issue.\n \n18.4\u2002 \u25a0\u2002 Service composition\u2002 \u2002 547\n", "page": 548, "type": "text", "section": "Page 548"}
{"text": "548\u2002 \u2002 Chapter 18\u2002 \u25a0\u2002 Service-oriented software engineering\nKey Points\n\u25a0\t Service-oriented architecture is an approach to software engineering where reusable, standard-\nized services are the basic building blocks for application systems.\n\u25a0\t Services may be implemented within a service-oriented architecture using a set of XML-based \nweb service standards. These include standards for service communication, interface definition, \nand service enactment in workflows.\n\u25a0\t Alternatively, a RESTful architecture may be used, which is based on resources and standard \noperations on these resources. A RESTful approach uses the http and https protocols for service \ncommunication and maps operations on the standard http verbs POST, GET, PUT, and DELETE.\n\u25a0\t Services may be classified as utility services that provide a general-purpose functionality,  \nbusiness services that implement part of a business process, or coordination services that  \ncoordinate the execution of other services.\n\u25a0\t The service engineering process involves identifying candidate services for implementation, \ndefining the service interface, and implementing, testing, and deploying the service.\n\u25a0\t The development of software using services is based on the idea that programs are created by \ncomposing and configuring services to create new composite services and systems.\n\u25a0\t Graphical workflow languages, such as BPMN, may be used to describe a business process and \nthe services used in that process. These languages can describe interactions between the \norganizations that are involved.\nFurther Reading\nThere is an immense amount of tutorial material on the web covering all aspects of web services. \nHowever, I found the book by Thomas Erl to be the best overview and description of services and ser-\nvice standards. Erl includes some discussion of software engineering issues in service-oriented com-\nputing. He has also written more recent books on RESTful services.\nService-Oriented Architecture: Concepts, Technology and Design. Erl has written a number of books \non service-oriented systems covering both SOA and RESTful architectures. In this book, Erl discusses \nSOA and web service standards but mostly concentrates on discussing how a service-oriented \napproach may be used at all stages of the software process. (T. Erl, Prentice-Hall, 2005).\n\u201cService-oriented architecture.\u201d This is a good, readable introduction to SOA. (Various authors, 2008) \nhttp://msdn.microsoft.com/en-us/library/bb833022.aspx\n\u201cRESTful Web Services: The Basics.\u201d A good introductory tutorial on the RESTful approach and RESTful \nservices. (A. Rodriguez, 2008). https://www.ibm.com/developerworks/webservices/library/ws-restful/\nService Design Patterns: Fundamental Design Solutions for SOAP/WSDL, and RESTful Web Services. \nThis is a more advanced text for developers who wish to use web services in enterprise applications. \nIt describes a number of common problems and abstract web service solutions to these problems.  \n(R. Daigneau, Addison-Wesley, 2012).\n548\u2002 \u2002 Chapter 18\u2002 \u25a0\u2002 Service-oriented software engineering\n", "page": 549, "type": "text", "section": "Page 549"}
{"text": " \n1.1\u2002 \u25a0\u2002 Professional software development\u2002 \u2002 549\n\u201cWeb Services Tutorial.\u201d This is an extensive tutorial on all aspects of service-oriented architecture, \nweb services, and web service standards, written by people involved in the development of these \nstandards. Very useful if you need a detailed understanding of the standards. (W3C schools, 1999\u20132014) \nhttp://www.w3schools.com/webservices/default.asp\nWebsite\nPowerPoint slides for this chapter:\nwww.pearsonglobaleditions.com/Sommerville\nLinks to supporting videos:\nhttp://software-engineering-book.com/videos/software-reuse/\nExercises\n\u2002 18.1. \u200a\n\u200a\n\u200a\n\u200a\n\u200a\n\u200a\nWhy is it important to define exceptions in service engineering?\n\u2002 18.2. \u200a\n\u200a\n\u200a\n\u200a\n\u200a\n\u200a\n\u0007\nStandards are fundamental to service-oriented architectures, and it was believed that stand-\nards conformance was essential for successful adoption of a service-based approach. How-\never, RESTful services, which are increasingly widely used, are not standards-based. Discuss \nwhy you think this change has occurred and whether or not you think that the lack of stand-\nards will inhibit the development and takeup of RESTful services.\n\u2002 18.3. \u200a\n\u200a\n\u200a\n\u200a\n\u200a\n\u0007\nExtend Figure 18.5 to include WSDL definitions for MaxMinType and InDataFault. The  \ntemperatures should be represented as integers, with an additional field indicating whether \nthe temperature is in degrees Fahrenheit or degrees Celsius. InDataFault should be a  \nsimple type consisting of an error code.\n\u2002 18.4. \u200a\n\u200a\n\u200a\n\u200a\n\u200a\n\u200a\n\u0007\nSuggest how the SimpleInterestCalculator service could be implemented as a RESTful \n\u00ad\nservice.\n\u2002 18.5. \u200a\n\u200a\n\u200a\n\u200a\n\u200a\n\u200a\n\u200a\n\u0007\nWhat is a workflow? List out the key stages in the process of system construction by \n\u00ad\ncomposition.\n\u2002 18.6. \u200a\n\u200a\n\u200a\n\u200a\n\u200a\n\u200a\n\u0007\nDesign possible input and output messages for the services shown in Figure 18.13. You may \nspecify these in the UML or in XML.\n\u2002 18.7. \u200a\n\u200a\n\u200a\n\u200a\n\u200a\n\u200a\n\u200a\n\u0007\nGiving reasons for your answer, suggest two important types of application where you would \nnot recommend the use of service-oriented architecture.\u2002\n\u2002 18.8. \u200a\n\u200a\n\u200a\n\u200a\n\u200a\n\u0007\nExplain what is meant by a \u201ccompensation action\u201d and, using an example, show why these \nactions may have to be included in workflows.\n \nChapter 18\u2002 \u25a0\u2002 Exercises\u2002 \u2002 549\n", "page": 550, "type": "text", "section": "Page 550"}
{"text": "550\u2002 \u2002 Chapter 18\u2002 \u25a0\u2002 Service-oriented software engineering\n\u2002 18.9. \u200a\n\u200a\n\u200a\n\u200a\n\u200a\n\u200a\n\u0007\nFor the example of the vacation package reservation service, design a workflow that will \nbook ground transportation for a group of passengers arriving at an airport. They should be \ngiven the option of booking either a taxi or a hire car. You may assume that the taxi and \nrental car companies offer web services to make a reservation.\n18.10. \u200a\n\u200a\n\u200a\n\u200a\n\u200a\n\u0007\nUsing an example, explain in detail why the thorough testing of services that include com-\npensation actions is difficult.\nReferences\nErl, T. 2004. Service-Oriented Architecture: A Field Guide to Integrating XML and Web Services. \nUpper Saddle River, NJ: Prentice-Hall.\n\t\n\u2002 \u2002 . 2005. Service-Oriented Architecture: Concepts, Technology and Design. Upper Saddle River, \nNJ: Prentice-Hall.\nFielding, R. 2000. \u201cRepresentational State Transfer.\u201d Architectural Styles and the Design of Network-\nBased Software Architecture. https://www.ics.uci.edu/~fielding/pubs/. . ./fielding_dissertation.pdf\nLovelock, C, S Vandermerwe, and B Lewis. 1996. Services Marketing. Englewood Cliffs, NJ.: \n\u00ad\nPrentice-Hall.\nNewcomer, E., and G. Lomow. 2005. Understanding SOA with Web Services. Boston: \n\u00ad\nAddison-Wesley.\nOMG. 2011. \u201cDocuments Associated with Business Process Model and Notation (BPMN) Version \n2.0.\u201d http://www.omg.org/spec/BPMN/2.0/\nPautasso, C., O. Zimmermann, and F. Leymann. 2008. \u201cRESTful Web Services vs. \u2018Big\u2019 Web Services: \nMaking the Right Architectural Decision.\u201d In Proc. WWW 2008, 805\u201314. Beijing, China. \ndoi:10.1145/1367497.1367606.\nRichardson, L., and S. Ruby. 2007. RESTful Web Services. Sebastopol, CA: O\u2019Reilly Media Inc.\nRosenberg, F., F. Curbera, M. Duftler, and R. Khalaf. 2008. \u201cComposing RESTful Services and Collab-\norative Workflows: A Lightweight Approach.\u201d IEEE Internet Computing 12 (5): 24\u201331. doi:10.1109/\nMIC.2008.98.\nW3C. 2012. \u201cOWL 2 Web Ontology Language.\u201d http://www.w3.org/TR/owl2-overview/\n\t\n\u2002 \u2002 . 2013. \u201cWeb of Services.\u201d http://www.w3.org/standards/webofservices/\nWhite, S. A., and D. Miers. 2008. BPMN Modeling and Reference Guide: Understanding and Using \nBPMN. Lighthouse Point, FL. USA: Future Strategies Inc.\n550\u2002 \u2002 Chapter 18\u2002 \u25a0\u2002 Service-oriented software engineering\n", "page": 551, "type": "text", "section": "Page 551"}
{"text": "Systems engineering\n19 \nObjectives\nThe objectives of this chapter are to explain why software engineers \nshould understand systems engineering and to introduce the most \nimportant systems engineering processes. When you have read this \nchapter, you will:\n\u25a0 know what is meant by a sociotechnical system and understand why \nhuman, social, and organizational issues affect the requirements and \ndesign of software systems;\n\u25a0 understand the idea of conceptual design and why it is an essential \nfirst stage in the systems engineering process;\n\u25a0 know what is meant by system procurement and understand why different \nsystem procurement processes are used for different types of system;\n\u25a0 know about the key systems engineering development processes and \ntheir relationships.\nContents\n19.1\t Sociotechnical systems\n19.2\t Conceptual design\n19.3\t System procurement\n19.4\t System development\n19.5\t System operation and evolution\n", "page": 552, "type": "text", "section": "Page 552"}
{"text": "552\u2002 \u2002 Chapter 19\u2002 \u25a0\u2002 Systems engineering\nA computer only becomes useful when it includes both software and hardware. \nWithout hardware, a software system is an abstraction\u2014simply a representation of \nsome human knowledge and ideas. Without software, a hardware system is a set of \ninert electronic devices. However, if you put them together to form a computer sys-\ntem, you create a machine that can carry out complex computations and deliver the \nresults of these computations to its environment.\nThis illustrates one of the fundamental characteristics of a system: It is more than the \nsum of its parts. Systems have properties that only become apparent when their compo-\nnents are integrated and operate together. Furthermore, systems are developed to sup-\nport human activities\u2014work, entertainment, communication, protection of people and \nthe environment, and so on. They interact with people, and their design is influenced by \nhuman and organizational concerns. Hardware, human, social, and organizational fac-\ntors have to be taken into account when developing all professional software systems.\nSystems that include software fall into two categories:\n1.\t\nTechnical computer-based systems are systems that include hardware and soft-\nware components but not procedures and processes. Examples of technical \n\u00ad\nsystems include televisions, mobile phones, and other equipment with embed-\nded software. Applications for PCs, computer games, and mobile devices are \nalso technical systems. Individuals and organizations use technical systems for a \nparticular purpose, but knowledge of this purpose is not part of the technical \nsystem. For example, the word processor I am using (Microsoft Word) is not \naware that it is being used to write a book.\n2\t\nSociotechnical systems: include one or more technical systems but, crucially, also \npeople, who understand the purpose of the system, within the system itself. \nSociotechnical systems have defined operational processes, and people (the opera-\ntors) are inherent parts of the system. They are governed by organizational policies \nand rules and may be affected by external constraints such as national laws and regu-\nlatory policies. For example, this book was created through a sociotechnical publish-\ning system that includes various processes (creation, editing, layout, etc.) and \ntechnical systems (Microsoft Word and Excel, Adobe Illustrator, Indesign, etc.).\nSystems engineering (White et al. 1993; Stevens et al. 1998; Thayer 2002) is the \nactivity of designing entire systems, taking into account the characteristics of hardware, \nsoftware, and human elements of these systems. Systems engineering includes every-\nthing to do with procuring, specifying, developing, deploying, operating, and maintain-\ning both technical and sociotechnical systems. Systems engineers have to consider the \ncapabilities of hardware and software as well as the system\u2019s interactions with users \nand its environment. They must think about the system\u2019s services, the constraints under \nwhich the system must be built and operated, and the ways in which the system is used.\nIn this chapter, my focus is on the engineering of large and complex software-\nintensive systems. These are \u201centerprise systems,\u201d that is, systems that are used to \nsupport the goals of a large organization. Enterprise systems are used by govern-\nment and the military services as well as large companies and other public bodies. \n", "page": 553, "type": "text", "section": "Page 553"}
{"text": "\t\nChapter 19\u2002 \u25a0\u2002 Systems engineering\u2002 \u2002 553\nThey are sociotechnical systems that are influenced by the ways that the organization \nworks and by national and international rules and regulations. They may be made up \nof a number of separate systems and are distributed systems with large-scale data-\nbases. They have a long lifetime and are critical for the operation of the enterprise.\nI believe that it is important for software engineers to know about systems engi-\nneering and to be active participants in systems engineering processes for two reasons:\n1.\t\nSoftware is now the dominant element in all enterprise systems, yet many senior \ndecision makers in organizations have a limited understanding of software. Software \nengineers have to play a more active part in high-level systems decision making if \nthe system software is to be dependable and developed on time and to budget.\n2.\t\nAs a software engineer, it helps if you have a broader awareness of how software \ninteracts with other hardware and software systems, and the human, social, and \norganizational factors that affect the ways in which software is used. This knowledge \nhelps you understand the limits of software and to design better software systems.\nThere are four overlapping stages (Figure 19.1) in the lifetime of large, complex \nsystems:\n1.\t\nConceptual design This initial systems engineering activity develops the con-\ncept of the type of system that is required. It sets out, in nontechnical language, \nthe purpose of the system, why it is needed, and the high-level features that \nusers might expect to see in the system. It may also describe broad constraints, \nsuch as the need for interoperability with other systems. These limit the freedom \nof systems engineers in designing and developing the system.\n2.\t\nProcurement or acquisition During this stage, the conceptual design is further devel-\noped so that information is available to make decisions about the contract for the \nsystem development. This may involve making decisions about the distribution of \nProcurement\nDevelopment\nOperation\nDeployment\nEquipment and\nsoftware updates\nSystem\nevolution\nConceptual design\nUser information\nOutline\nrequirements\nSystem vision \nand features\nFigure 19.1\u2002 Stages of \nsystems engineering\n", "page": 554, "type": "text", "section": "Page 554"}
{"text": "554\u2002 \u2002 Chapter 19\u2002 \u25a0\u2002 Systems engineering\nfunctionality across hardware, software, and operational processes. You also make \ndecisions about which hardware and software has to be acquired, which suppliers \nshould develop the system, and the terms and conditions of the supply contract.\n3.\t\nDevelopment During this stage, the system is developed. Development pro-\ncesses include requirements definition, system design, hardware and software \nengineering, system integration, and testing. Operational processes are defined, \nand the training courses for system users are designed.\n4.\t\nOperation At this stage, the system is deployed, users are trained, and the sys-\ntem is brought into use. The planned operational processes usually then have to \nchange to reflect the real working environment where the system is used. Over \ntime, the system evolves as new requirements are identified. Eventually, the \nsystem declines in value, and it is decommissioned and replaced.\nFigure 19.1 shows the interactions between these stages. The conceptual design \nactivity is a basis for the system procurement and development but is also used to \nprovide information to users about the system. Development and procurement over-\nlap and further procurement during development, and operation may be needed as \nnew equipment and software become available. Once the system is operational, \nrequirements changes are inevitable; implementing these changes requires further \ndevelopment and, perhaps, software and hardware procurement.\nDecisions made at any one of these stages may have a profound influence on the \nother stages. Design options may be restricted by procurement decisions on the \nscope of the system and on its hardware and software. Human errors made during \nthe specification, design, and development stages may mean that faults are intro-\nduced into the system. A decision to limit testing for budget reasons may mean that \nfaults are not discovered before a system is put into use. During operation, errors in \nconfiguring the system for deployment may lead to problems in using the system. \nDecisions made during the original procurement may be forgotten when system \nchanges are proposed. This may lead to unforeseen consequences arising from the \nimplementation of the changes.\nAn important difference between systems and software engineering is the \ninvolvement of a range of professionals throughout the lifetime of the system. \nThese include engineers who may be involved in hardware and software design, \nsystem end-users, managers who are concerned with organizational issues, and \nexperts in the system\u2019s application domain. For example, engineering the insulin \npump system introduced in Chapter 1 requires experts in electronics, mechanical \nengineering, software, and medicine.\nFor very large systems, an even wider range of expertise may be required. \nFigure 19.2 illustrates the technical disciplines that may be involved in the procure-\nment and development of a new system for air traffic management. Architects and \ncivil \u00ad\nengineers are involved because new air traffic management systems usually \nhave to be installed in a new building. Electrical and mechanical engineers are \ninvolved to specify and maintain the power and air conditioning. Electronic engi-\nneers are \u00ad\nconcerned with computers, radars, and other equipment. Ergonomists \n", "page": 555, "type": "text", "section": "Page 555"}
{"text": "design the controller workstations and software engineers, and user interface design-\ners are responsible for the software in the system.\nThe involvement of a range of professional disciplines is essential because of the \ndifferent types of components in complex systems. However, differences and mis\u00ad\nunderstandings between disciplines can lead to inappropriate design decisions. \nThese poor decisions can delay the system\u2019s development or make it less suitable for \nits intended purpose. There are three reasons why there may be misunderstandings \nor other differences between engineers with different backgrounds:\n1.\t Different professional disciplines often use the same words, but these words \ndo not always mean the same thing. Consequently, misunderstandings are \ncommon in discussions between engineers from different backgrounds. If \nthese are not discovered and resolved during system development, they can \nlead to errors in delivered systems. For example, an electronic engineer may \nknow a bit about C programming but may not understand that a method in \nJava is like a function in C.\n2.\t\nEach discipline makes assumptions about what other disciplines can or cannot \ndo. These assumptions are often based on an inadequate understanding of what \nis possible. For example, an electronic engineer may decide that all signal pro-\ncessing (a computationally intensive task) should be done by software to sim-\nplify the hardware design. However, this may mean significantly greater \nsoftware effort to ensure that the system processor can cope with the amount of \ncomputation that is resolved.\n3.\t\nDisciplines try to protect their professional boundaries and may argue for certain \ndesign decisions because these decisions will call for their professional expertise. \nTherefore, a software engineer may argue for a software-based door locking sys-\ntem in a building, although a mechanical, key-based system may be more reliable.\nMy experience is that interdisciplinary working can be successful only if enough \ntime is available for these issues to be discussed and resolved. This requires regular \nface-to-face discussions and a flexible approach from everyone involved in the sys-\ntems engineering process.\nSystems\nengineering\nElectrical\nengineering\nErgonomics\nSoftware\nengineering\nCivil\nengineering\nArchitecture\nUser interface\ndesign\nElectronic \nengineering\nMechanical\n engineering\nFigure 19.2\u2002 Professional \ndisciplines involved in \nATC systems engineering\n\t\nChapter 19\u2002 \u25a0\u2002 Systems engineering\u2002 \u2002 555\n", "page": 556, "type": "text", "section": "Page 556"}
{"text": "556\u2002 \u2002 Chapter 19\u2002 \u25a0\u2002 Systems engineering\n \n19.1  Sociotechnical systems\nThe term system is universally used. We talk about computer systems, operating systems, \npayment systems, the education system, the system of government, and so on. These are \nall obviously quite different uses of the word \u201csystem,\u201d although they share the essential \ncharacteristic that, somehow, the system is more than simply the sum of its parts.\nAbstract systems, such as the system of government, are outside the scope of this \nbook. I focus here on systems that include computers and software and that have some \nspecific purpose such as to enable communication, support navigation, or maintain \nmedical records. A useful working definition of these types of system is as follows:\nA system is a purposeful collection of interrelated components of different kinds \nthat work together to deliver a set of services to the system owner and its users.\nThis general definition can cover a very wide range of systems. For example, a \nsimple system, such as a laser pointer, delivers an indication service. It may include a \nfew hardware components with a tiny control program in read-only memory (ROM). \nBy contrast, an air traffic control system includes thousands of hardware and soft-\nware components as well as human users who make decisions based on information \nfrom that computer system. It delivers a range of services, including providing infor-\nmation to pilots, maintaining safe separation of planes, utilizing airspace, and so on.\nIn all complex systems, the properties and behavior of the system components are \ninextricably intermingled. The successful functioning of each system component \ndepends on the functioning of other components. Software can only operate if the \nprocessor is operational. The processor can only carry out computations if the soft-\nware system defining these computations has been successfully installed.\nLarge-scale systems are often \u201csystems of systems.\u201d That is, they are made up of \nseveral separate systems. For example, a police command and control system may \ninclude a geographical information system to provide details of the location of inci-\ndents. The same geographical information system may be used in systems for trans-\nport logistics and emergency command and control. Engineering systems of systems \nis an increasingly important topic in software engineering that I cover in Chapter 20. \nLarge-scale systems are, with a few exceptions, sociotechnical systems, which I \nexplained in Chapter 10. That is, they do not just include software and hardware but \nalso people, processes, and organizational policies. Sociotechnical systems are \n\u00ad\nenterprise systems that are intended to help deliver a business purpose. This purpose \nmight be to increase sales, reduce material used in manufacturing, collect taxes, main-\ntain a safe airspace, and so on. Because they are embedded in an organizational envi-\nronment, the procurement, development, and use of these systems are influenced by \nthe organization\u2019s policies and procedures, as well as by its working culture. The \nusers of the system are people who are influenced by the way the organization is man-\naged and by their interactions with other people inside and outside of the organization.\nThe close relationships between sociotechnical systems and the organizations that \nuse these systems means that it is often difficult to establish system boundaries. \n", "page": 557, "type": "text", "section": "Page 557"}
{"text": "\t\n19.1\u2002 \u25a0\u2002 Sociotechnical systems\u2002 \u2002 557\nDifferent people within the organization will see the boundaries of the system in dif-\nferent ways. This is significant because establishing what is and what is not in the \nscope of the system is important when defining the system requirements.\nFigure 19.3 illustrates this problem. The diagram shows a sociotechnical system \nas a set of layers, where each layer contributes, in some way, to the functioning of \nthe system. At the core is a software-intensive technical system and its operational \nprocesses (shaded in Figure 19.3). Most people would agree that these are both parts \nof the system. However, the system\u2019s behavior is influenced by a range of sociotech-\nnical factors outside of the core. Should the system boundary simply be drawn \naround the core, or should it include other organizational levels?\nWhether or not these broader sociotechnical considerations should be considered to \nbe part of a system depends on the organization and its policies and rules. If organiza-\ntional rules and policies can be changed, then some people might argue they should be \npart of the system. However, it is more difficult to change organizational culture and \neven more challenging to change strategy and goals. Only governments can change laws \nto accommodate a system. Moreover, different stakeholders may have different opinions \non where the system boundaries should be drawn. There are no simple answers to these \nquestions, but they have to be discussed and negotiated during the system design process.\nGenerally, large sociotechnical systems are used in organizations. When you are \ndesigning and developing sociotechnical systems, you need to understand, as far as \npossible, the organizational environment in which they will be used. If you don\u2019t, the \nsystems may not meet business needs. Users and their managers may reject the sys-\ntem or fail to use it to its full potential.\nFigure 19.4 shows the key elements in an organization that may affect the require-\nments, design, and operation of a sociotechnical system. A new system may lead to \nchanges in some or all of these elements:\n1.\t\nProcess changes A new system may mean that people have to change the way \nthat they work. If so, training will certainly be required. If changes are signifi-\ncant, or if they involve people losing their jobs, there is a danger that the users \nwill resist the introduction of the system.\nTechnical\nsystem\nN\nat\nio\nn\nal\n l\na\nw\ns \na\nn\nd \nre\ng\nul\nat\nio\nns\nO\nrg\na\nni\nz\nat\nio\nn\nal\n s\ntr\nat\ne\ngi\ne\ns \na\nn\nd\n g\no\nal\ns\nO\nr\ng\na\nn\ni\nz\na\nti\no\nn\na\nl \nc\nu\nlt\nu\nr\ne\nO\nr\ng\na\nn\ni\nz\na\nt\ni\no\nn\na\nl\n \np\no\nli\nc\ni\ne\ns\n \na\nn\nd\n \nr\nu\nl\ne\ns\nO\np\ne\nr\na\nt\ni\no\nn\na\nl\n \np\nr\no\nc\ne\ns\ns\ne\ns\nFigure 19.3\u2002 Layered \nstructure of \nsociotechnical systems\n", "page": 558, "type": "text", "section": "Page 558"}
{"text": "558\u2002 \u2002 Chapter 19\u2002 \u25a0\u2002 Systems engineering\n2.\t\nJob changes New systems may deskill the users in an environment or cause them \nto change the way they work. If so, users may actively resist the introduction of \nthe system into the organization. Professional staff, such as doctors or teachers, \nmay resist system designs that require them to change their normal way of work-\ning. The people involved may feel that their professional expertise is being \neroded and that their status in the organization is being reduced by the system.\n3.\t\nOrganizational policies The proposed system may not be completely consistent \nwith organizational policies (e.g., on privacy). This may require system changes, \npolicy changes, or process changes to bring the system and policies into line.\n4.\t\nOrganizational politics The system may change the political power structure in \nan organization. For example, if an organization is dependent on a complex sys-\ntem, those who control access to that system have a great deal of political power. \nAlternatively, if an organization reorganizes itself into a different structure, this \nmay affect the requirements and use of the system.\nSociotechnical systems are complex systems, which means that it is practically \nimpossible to have a complete understanding, in advance, of their behavior. This \ncomplexity leads to three important characteristics of sociotechnical systems:\n1.\t\nThey have emergent properties that are properties of the system as a whole, rather \nthan associated with individual parts of the system. Emergent properties depend \non both the system components and the relationships between them. Some of \nthese relationships only come into existence when the system is \u00ad\nintegrated from its \ncomponents, so the emergent properties can only be evaluated at that time. \nSecurity and dependability are examples of important emergent system properties.\n2.\t\nThey are nondeterministic, so that when presented with a specific input, they \nmay not always produce the same output. The system\u2019s behavior depends on the \nhuman operators, and people do not always react in the same way. Furthermore, \nuse of the system may create new relationships between the system components \nand hence change its emergent behavior.\n3.\t\nThe system\u2019s success criteria are subjective rather than objective. The extent to \nwhich the system supports organizational objectives does not just depend on the \nsystem itself. It also depends on the stability of these objectives, the relationships \nPolicies\nProcesses\nJobs\nPolitics\nSystems\nFigure 19.4\u2002  \nOrganizational elements\n", "page": 559, "type": "text", "section": "Page 559"}
{"text": "\t\n19.1\u2002 \u25a0\u2002 Sociotechnical systems\u2002 \u2002 559\nand conflicts between organizational objectives, and how people in the organi-\nzation interpret these objectives. New management may reinterpret the organi-\nzational objectives that a system was designed to support so that a \u201csuccessful\u201d \nsystem may then be seen as no longer fit for its intended purpose.\nSociotechnical considerations are often critical in determining whether or not a \nsystem has successfully met its objectives. Unfortunately, taking these into account \nis very difficult for engineers who have little experience of social or cultural studies. \nTo help understand the effects of systems on organizations, various sociotechnical \nsystems methodologies have been proposed. My paper on sociotechnical systems \ndesign discusses the advantages and disadvantages of these sociotechnical design \nmethodologies (Baxter and Sommerville 2011).\n\t\n19.1.1 \t Emergent properties\nThe complex relationships between the components in a system mean that a system \nis more than simply the sum of its parts. It has properties that are properties of the \nsystem as a whole. These \u201cemergent properties\u201d (Checkland 1981) cannot be attrib-\nuted to any specific part of the system. Rather, they only emerge once the system \ncomponents have been integrated. Some emergent properties, such as weight, can be \nderived directly from the subsystem properties. More often, however, they emerge \nfrom a combination of subsystem properties and subsystem relationships. The \n\u00ad\nsystem property cannot be calculated directly from the properties of the individual \nsystem components. Examples of emergent properties are shown in Figure 19.5.\nThere are two types of emergent properties:\n1.\t\nFunctional emergent properties, when the purpose of a system only emerges after \nits components are integrated. For example, a bicycle has the functional property \nof being a transportation device once it has been assembled from its components.\nFigure 19.5\u2002 Examples \nof\u00a0emergent properties\nProperty\nDescription\nReliability\nSystem reliability depends on component reliability, but unexpected interactions \ncan cause new types of failure and therefore affect the reliability of the system.\nRepairability\nThis property reflects how easy it is to fix a problem with the system once it has \nbeen discovered. It depends on being able to diagnose the problem, access the \ncomponents that are faulty, and modify or replace these components.\nSecurity\nThe security of the system (its ability to resist attack) is a complex property that \ncannot be easily measured. Attacks may be devised that were not anticipated by \nthe system designers and so may defeat built-in safeguards.\nUsability\nThis property reflects how easy it is to use the system. It depends on the \ntechnical system components, its operators, and its operating environment.\nVolume\nThe volume of a system (the total space occupied) depends on how the \ncomponent assemblies are arranged and connected.\n", "page": 560, "type": "text", "section": "Page 560"}
{"text": "560\u2002 \u2002 Chapter 19\u2002 \u25a0\u2002 Systems engineering\n2.\t\nNon-functional emergent properties, which relate to the behavior of the system \nin its operational environment. Reliability, performance, safety, and security are \nexamples of these properties. These system characteristics are critical for \n\u00ad\ncomputer-based systems, as failure to achieve a minimum defined level in these \nproperties usually makes the system unusable. Some users may not need some of \nthe system functions, so the system may be acceptable without them. However, \na system that is unreliable or too slow is likely to be rejected by all its users.\nEmergent properties, such as reliability, depend on both the properties of \n\u00ad\nindividual components and their interactions or relationships. For example, the \n\u00ad\nreliability of a sociotechnical system is influenced by three things:\n1.\t\nHardware reliability What is the probability of hardware components failing, \nand how long does it take to repair a failed component?\n2.\t\nSoftware reliability How likely is it that a software component will produce an \nincorrect output? Software failure is unlike hardware failure in that software \ndoes not wear out. Failures are often transient. The system carries on working \nafter an incorrect result has been produced.\n3.\t\nOperator reliability How likely is it that the operator of a system will make an \nerror and provide an incorrect input? How likely is it that the software will fail \nto detect this error and propagate the mistake?\nHardware, software, and operator reliability are not independent but affect each other \nin unpredictable ways. Figure 19.6 shows how failures at one level can be prop\u00ad\nagated to other levels in the system. Say a hardware component in a system starts to \ngo wrong. Hardware failure can sometimes generate spurious signals that are outside \nthe range of inputs expected by the software. The software can then behave unpre-\ndictably and produce unexpected outputs. These may confuse and consequently \ncause stress in the system operator.\nWe know that people are more likely to make mistakes when they feel stressed. \nSo a hardware failure may be the trigger for operator errors. These mistakes can, in \nturn, lead to unexpected software behavior, resulting in additional demands on the \nprocessor. This could overload the hardware, causing more failures and so on. Thus, \nan initial, relatively minor, failure, can rapidly develop into a serious problem that \ncould lead to a complete shutdown of the system.\nThe reliability of a system depends on the context in which that system is used. \nHowever, the system\u2019s environment cannot be completely specified, and it is often \nimpossible for the system designers to limit the environment for operational sys-\ntems. Different systems operating within an environment may react to problems in \nunpredictable ways, thus affecting the reliability of all of these systems.\nFor example, say a system is designed to operate at normal room temperature. \nTo\u00a0allow for variations and exceptional conditions, the electronic components of \na\u00a0system are designed to operate within a certain range of temperatures, say, from \n0\u00a0degrees to 40 degrees Celsius. Outside this temperature range, the components will \n", "page": 561, "type": "text", "section": "Page 561"}
{"text": "\t\n19.1\u2002 \u25a0\u2002 Sociotechnical systems\u2002 \u2002 561\nbehave in an unpredictable way. Now assume that this system is installed close to an \nair conditioner. If this air conditioner fails and vents hot gas over the electronics, then \nthe system may overheat. The components, and hence the whole system may then fail.\nIf this system had been installed elsewhere in that environment, this problem \nwould not have occurred. When the air conditioner worked properly, there were no \nproblems. However, because of the physical closeness of these machines, an unan-\nticipated relationship existed between them that led to system failure.\nLike reliability, emergent properties such as performance or usability are hard to \nassess but can be measured after the system is operational. Properties such as safety \nand security, however, are not directly measurable. Here, you are not simply con-\ncerned with attributes that relate to the behavior of the system but also with unwanted \nor unacceptable behavior.\nA secure system is one that does not allow unauthorized access to its data. \nUnfortunately, it is clearly impossible to predict all possible modes of access and \nexplicitly forbid them. Therefore, it may only be possible to assess these \u201cshall not\u201d \nproperties after the system is operational. That is, you only know that a system is \ninsecure when someone manages to penetrate the system.\n\t\n19.1.2 \t Non-determinism\nA deterministic system is one that is absolutely predictable. If we ignore issues of \nconcurrency, software systems that run on reliable hardware are deterministic. When \nthey are presented with a sequence of inputs they will always produce the same \nsequence of outputs. Of course, there is no such thing as completely reliable hardware, \nbut hardware is usually reliable enough to think of hardware systems as deterministic.\nPeople, on the other hand, are non-deterministic. When presented with exactly \nthe\u00a0same input (say a request to complete a task), their responses will depend on \ntheir\u00a0emotional and physical state, the person making the request, other people in the \nenvironment, and whatever else they are doing. Sometimes they will be happy to do \nthe work, and, at other times, they will refuse; sometimes they will perform a task \nwell, and sometimes they will do it badly.\nSociotechnical systems are nondeterministic partly because they include people \nand partly because changes to the hardware, software, and data in these systems are \nHardware\nSoftware\nOperation\nInitial\nfailure\nFailure\npropagation\nFailure\nconsequence\nFigure 19.6\u2002 Failure \npropagation\n", "page": 562, "type": "text", "section": "Page 562"}
{"text": "562\u2002 \u2002 Chapter 19\u2002 \u25a0\u2002 Systems engineering\nso frequent. The interactions between these changes are complex, and so the behav-\nior of the system is unpredictable. Users do not know when and why changes have \nbeen made, so they see the system as nondeterministic.\nFor example, say a system is presented with a set of 20 test inputs. It processes \nthese inputs and the results are recorded. At some later time, the same 20 test inputs \nare processed, and the results are compared to the previous stored results. Five of \nthem are different. Does this mean that there have been five failures? Or are the dif-\nferences simply reasonable variations in the system\u2019s behavior? You can only find \nthis out by looking at the results in more depth and making judgments about the way \nthe system has handled each input.\nNon-determinism is often seen as a bad thing, and it is felt that designers should \ntry to avoid nondeterministic behavior wherever possible. In fact, in sociotechnical \nsystems, non-determinism has important benefits. It means that the behavior of a \nsystem is not fixed for all time but can change depending on the system\u2019s environ-\nment. For example, operators may observe that a system is showing signs of failure. \nInstead of using the system normally, they can change their behavior to diagnose and \nrecover from the detected problems.\n\t\n19.1.3 \t Success criteria\nGenerally, complex sociotechnical systems are developed to tackle \u201cwicked prob-\nlems\u201d (Rittel and Webber 1973). A wicked problem is a problem that is so complex \nand that involves so many related entities that there is no definitive problem specifi-\ncation. Different stakeholders see the problem in different ways, and no one has a \nfull understanding of the problem as a whole. The true nature of the problem may \nonly emerge as a solution is developed.\nAn extreme example of a wicked problem is emergency planning to deal with the \naftermath of an earthquake. No one can accurately predict where the epicenter of an \nearthquake will be, what time it will occur, or what effect it will have on the local \nenvironment. It is impossible to specify in detail how to deal with the problem. \nSystem designers have to make assumptions, but understanding what is required \nemerges only after the earthquake has happened.\nThis makes it difficult to define the success criteria for a system. How do you decide \nif a new system contributes to the business goals of the company that paid for the system? \nThe judgment of success is not usually made against the original reasons for procuring \nand developing the system. Rather, it is based on whether or not the system is effective at \nthe time it is deployed. As the business environment can change very quickly, the busi-\nness goals may have changed significantly during the development of the system.\nThe situation is even more complex when there are multiple conflicting goals that \nare interpreted differently by different stakeholders. For instance, the system on which \nthe Mentcare system is based was designed to support two separate business goals:\n1.\t\nTo improve the quality of care for sufferers from mental illness.\n2.\t\nTo improve the cost-effectiveness of treatments by providing managers with \ndetailed reports of care provided and the costs of that care.\n", "page": 563, "type": "text", "section": "Page 563"}
{"text": "\t\n19.2\u2002 \u25a0\u2002 Conceptual design\u2002 \u2002 563\nUnfortunately, these proved to be conflicting goals because the information that \nwas needed to satisfy the reporting goal meant that doctors and nurses had to provide \nadditional information, over and above the health records that they normally main-\ntained. This reduced the quality of care for patients as it meant that clinical staff \nhad\u00a0less time to talk with them. From a doctor\u2019s perspective, this system was not \nan\u00a0improvement on the previous manual system, but from a manager\u2019s perspective, \nit was.\nThus, any success criteria that are established in the early stages of the systems \nengineering process have to be regularly reconsidered during system development \nand use. You cannot evaluate these criteria objectively as they depend on the sys-\ntem\u2019s effect on its environment and its users. A system may apparently meet its \nrequirements as originally specified but be practically useless because of changes in \nthe environment where it is used.\n \n19.2  Conceptual design\nOnce an idea for a system has been suggested, conceptual design is the very first \nthing that you do in the systems engineering process. In the conceptual design phase, \nyou take that initial idea, investigate its feasibility, and develop it to create an overall \nvision of a system that could be developed. You then have to describe the envisaged \nsystem so that nonexperts, such as system users, senior company decision makers, or \npoliticians, can understand what you are proposing.\nThere is an obvious overlap between conceptual design and requirements \n\u00ad\nengineering. As part of the conceptual design process, you have to imagine how the \nproposed system will be used. This may involve discussions with potential users and \nother stakeholders, focus groups, and observations of how existing systems are used. \nThe goal of these activities is to understand how users work, what is important to \nthem, and what practical constraints on the system there might be.\nThe importance of establishing a vision of a proposed system is rarely mentioned \nin the software design and requirements literature. However, this vision has been \npart of the systems engineering process for military systems for many years. Fairley \net al. (Fairley, Thayer, and Bjorke 1994) discuss the idea of concept analysis and the \ndocumentation of the results of concept analysis in a \u201cConcept of Operations\u201d \n(ConOps) document. This idea of developing a ConOps document is now widely \nused for large-scale systems, and you can find many examples of ConOps documents \non the web.\nUnfortunately, as is so often the case with military and government systems, good \nideas can become mired in bureaucracy and inflexible standards. This is exactly what \nhappened with ConOps, and a ConOps document standard was proposed (IEEE, \n2007). As Mostashari et al. say (Mostashari et al. 2012), this tends to lead to long and \nunreadable documents, which do not serve their intended purpose. They propose a \nmore agile approach to the development of a ConOps document with a shorter and \nmore flexible document as the output of the process.\n", "page": 564, "type": "text", "section": "Page 564"}
{"text": "564\u2002 \u2002 Chapter 19\u2002 \u25a0\u2002 Systems engineering\nI don\u2019t like the term Concept of Operations partly because of its military connota-\ntions and partly because I think that a conceptual design document is not just about \nsystem operation. It should also present the system engineer\u2019s understanding of why \nthe system is being developed, an explanation of why the design proposals are appro-\npriate, and, sometimes, an initial organization for the system. As Fairley says, \u201cIt \nshould be organized to tell a story,\u201d that is, written so that people without a technical \nbackground can understand the proposals that are being made.\nFigure 19.7 shows activities that may be part of the conceptual design process. \nConceptual design should always be a team process that involves people from differ-\nent backgrounds. I was part of the conceptual design team for the digital learning \nenvironment, introduced in Chapter 1. For the digital learning environment, the \ndesign team included teachers, education researchers, software engineers, system \nadministrators, and system managers.\nConcept formulation is the first stage of the process where you try to refine an \ninitial statement of needs and work out what type of system would be best to meet \nthe needs of system stakeholders. Initially, we were tasked with proposing an \nintranet for information sharing across schools that was easier to use than the cur-\nrent system. However, after discussions with teachers, we discovered that this was \nnot really what was required. The existing system was awkward to use, but people \nhad found workarounds. What was really required was a flexible digital learning \nenvironment that could be adapted by adding subject and age-specific tools and \ncontent that are freely available on the Internet.\nWe discovered this because the concept formulation activity overlapped with the \nactivity of problem understanding. To understand a problem, you need to discuss \nwith users and other stakeholders how they do their work. You need to find out what \nis important to them, what are the barriers that stop them from doing what they want \nto do, and their ideas of what changes are required. You need to be open-minded (it \nis their problem, not yours) and to be prepared to change your ideas when the reality \ndoes not match your initial vision.\nConcept formulation\nProblem understanding\nSystem proposal development\nFeasibility study\nSystem structure development\nSystem vision document\nFigure 19.7\u2002 Conceptual \ndesign activities\n", "page": 565, "type": "text", "section": "Page 565"}
{"text": "\t\n19.2\u2002 \u25a0\u2002 Conceptual design\u2002 \u2002 565\nIn the system proposal development stage, the conceptual design team set out \ntheir ideas for alternative systems and these are the basis for a feasibility study to \ndecide which of the ideas are worth further development. In a feasibility study, you \nshould look at comparable systems that have been developed elsewhere and techno-\nlogical issues (e.g., use of mobile devices) that may affect use of the system. Then \nyou need to assess whether or not the system could be implemented using current \nhardware and software technologies.\nI have found that an additional useful activity is to develop an outline structure \nor architecture for the system. This activity is helpful both for making a feasibility \nassessment and for providing a basis for more detailed requirements engineering \nand architectural design. Furthermore, as the majority of systems are now assem-\nbled from existing systems and components, an initial architecture means that the \nkey parts of the system have been identified and can be procured separately. \nThis\u00a0approach is often better than procuring a system as a monolithic unit from a \nsingle supplier.\nFor the digital learning environment, we decided on a layered service architecture \n(shown in Figure 1.8). All components in the system should be considered to be \nreplaceable services. In this way, users can replace a standard service with their pre-\nferred alternative and so adapt the system to the ages and interests of the students \nlearning with the system.\nAll of these activities generate information that is used to develop the system \nvision document. This is a critical document that senior decision makers use to \ndecide whether or not further development of the system should go ahead. It is also \nused to develop further documents such as a risk analysis and budget estimate, which \nare also important inputs to the decision-making process.\nManagers use the system vision document to understand the system; a procure-\nment team uses it to define a tender document; and requirements engineers use it \nas a basis for refining the system requirements. Because these different people \nneed different levels of detail, I suggest that the document should be structured \ninto two parts:\n1.\t\nA short summary for senior decision makers that presents the key points of the \nproblem and the proposed system. It should be written so that readers can imme-\ndiately see how the system will be used and the benefits that it will provide.\n2.\t\nA number of appendices that develop the ideas in more detail and that can be \nused in the system procurement and requirements engineering activities.\nIt is challenging to write a summary of the system vision inasmuch as the readers \nare busy people who are unlikely to have a technical background. I have found that \nusing user stories is very effective, providing a tangible vision of system use that \nnontechnical people can relate to. Stories should be short and personalized and should \nbe a feasible description of the use of the system, as shown in Figure 19.8. There is \nanother example of a user story from the same system in Chapter 4 (Figure 4.9).\n", "page": 566, "type": "text", "section": "Page 566"}
{"text": "566\u2002 \u2002 Chapter 19\u2002 \u25a0\u2002 Systems engineering\nUser stories are effective because, as already noted, readers can relate to them; in \naddition, they can show the capabilities of the proposed system in an easily accessi-\nble way. Of course, these are only part of a system vision, and the summary must \nalso include a high-level description of the basic assumptions made and the ways in \nwhich the system will deliver value to the organization.\n \n19.3  System procurement\nSystem procurement or system acquisition is a process whose outcome is a decision \nto buy one or more systems from system suppliers. At this stage, decisions are made \non the scope of a system that is to be purchased, system budgets and timescales, and \nhigh-level system requirements. Using this information, further decisions are then \nmade on whether to procure a system, the type of system required, and the supplier \nor suppliers of the system. The drivers for these decisions are:\n1.\t\nThe replacement of other organizational systems If the organization has a mix-\nture of systems that cannot work together or that are expensive to maintain, then \nprocuring a replacement system, with additional capabilities, may lead to \n\u00ad\nsignificant business benefits.\n2.\t\nThe need to comply with external regulations Increasingly, businesses are regu-\nlated and have to demonstrate compliance with externally defined regulations \n(e.g., Sarbanes\u2013Oxley accounting regulations in the United States). Compliance \nmay require the replacement of noncompliant systems or the provision of new \nsystems specifically to monitor compliance.\nFigure 19.8\u2002 A user story \nused in a system vision \ndocument\nDigital art\nJill is an S2 pupil at a secondary school in Dundee. She has a smartphone of her own, and the family has a \nshared Samsung tablet and a Dell laptop computer. At school, Jill signs on to the school computer and is pre-\nsented with a personalized Glow+ environment, which includes a range of services, some chosen by her teach-\ners and some she has chosen herself from the Glow app library.\nShe is working on a Celtic art project, and she uses Google to research a range of art sites. She sketches out \nsome designs on paper and then uses the camera on her phone to photograph what she has done; she uploads \nthis using the school wifi to her personal Glow+ space. Her homework is to complete the design and write a \nshort commentary on her ideas.\nAt home, she uses the family tablet to sign on to Glow+, and she then uses an artwork app to process her \nphotograph and to extend the work, add color, and so on. She finishes this part of the work, and to complete it \nshe moves to her home laptop to type up her commentary. She uploads the finished work to Glow+ and sends \na message to her art teacher that it is available for review. Her teacher looks at the project in a free period \nbefore Jill\u2019s next art class using a school tablet, and, in class, she discusses the work with Jill.\nAfter the discussion, the teacher and Jill decide that the work should be shared, and so they publish it to the \nschool web pages that show examples of students\u2019 work. In addition, the work is included in Jill\u2019s e-portfolio\u2014\nher record of schoolwork from age 3 to 18.\n", "page": 567, "type": "text", "section": "Page 567"}
{"text": "\t\n19.3\u2002 \u25a0\u2002 System procurement\u2002 \u2002 567\n3.\t\nExternal competition If a business needs to compete more effectively or maintain \na competitive position, managers may decide to buy new systems to improve busi-\nness efficiency or effectiveness. For military systems, the need to improve capa-\nbility in the face of new threats is an important reason for procuring new systems.\n4.\t\nBusiness reorganization Businesses and other organizations frequently restructure \nwith the intention of improving efficiency and/or customer service. Reorganizations \nlead to changes in business processes that require new systems support.\n5.\t\nAvailable budget The budget that is available is an obvious factor in determining \nthe scope of new systems that can be procured.\nIn addition, new government systems are often procured to reflect political \nchanges and political policies. For example, politicians may decide to buy new sur-\nveillance systems, which they claim will counter terrorism. Buying such systems \nshows voters that they are taking action.\nLarge complex systems are usually engineered using a mixture of off-the-shelf \nand specially built components. They are often integrated with existing legacy sys-\ntems and organizational databases. When legacy systems and off-the-shelf systems \nare used, new custom software may be needed to integrate these components. The \nnew software manages the component interfaces so that these components can inter-\noperate. The need to develop this \u201cglueware\u201d is one reason why the savings from \nusing off-the-shelf components are sometimes not as great as anticipated.\nThree types of systems or system components may have to be procured:\n1.\t\nOff-the-shelf applications that may be used without change and that need only \nminimal configuration for use.\n2.\t\nConfigurable application or ERP systems that have to be modified or adapted \nfor use either by modifying the code or by using inbuilt configuration features, \nsuch as process definitions and rules.\n3.\t\nCustom systems that have to be specially designed and implemented for use.\nEach of these components tends to follow a different procurement process. Figure 19.9 \nillustrates the main features of the procurement process for these types of system. Key \nissues that affect procurement processes are:\n1.\t\nOrganizations often have an approved and recommended set of application soft-\nware that has been checked by the IT department. It is usually possible to buy or \nacquire open-source software from this set directly without the need for detailed \njustification. For example, in the iLearn system, we recommended that \nWordpress should be made available for student and staff blogs. If microphones \nare needed, off-the-shelf hardware can be bought. There are no detailed require-\nments, and the users adapt to the features of the chosen application.\n2.\t\nOff-the-shelf components do not usually match requirements exactly, unless the \nrequirements have been written with these components in mind. Therefore, choosing \n", "page": 568, "type": "text", "section": "Page 568"}
{"text": "568\u2002 \u2002 Chapter 19\u2002 \u25a0\u2002 Systems engineering\na system means that you have to find the closest match between the system require-\nments and the facilities offered by off-the-shelf systems. ERP and other large-scale \napplication systems usually fall into this category. You may then have to modify the \nrequirements to fit in with the system assumptions. This can have knock-on effects \non other subsystems. You also usually have an extensive configuration process to \ntailor and adapt the application or ERP system to the buyer\u2019s working environment.\n3.\t\nWhen a system is to be built specially, the specification of requirements is part \nof the contract for the system being acquired. It is therefore a legal as well as a \ntechnical document. The requirements document is critical, and procurement \nprocesses of this type usually take a considerable amount of time.\n4.\t\nFor public sector systems in particular, there are detailed rules and regulations \nthat affect the procurement of systems. For example, in the European Union, all \npublic sector systems over a certain price must be open to tender by any supplier \nin Europe. This requires detailed tender documents to be drawn up and the ten-\nder to be advertised across Europe for a fixed period of time. Not only does this \nrule slow down the procurement process, it also tends to inhibit agile develop-\nment. It forces the system buyer to develop requirements so that all companies \nhave enough information to bid for the system contract.\n5.\t\nFor application systems that require change or for custom systems, there is usu-\nally a contract negotiation period when the customer and supplier negotiate the \nterms and conditions for development of the system. Once a system has been \nConceptual \ndesign\nConceptual \ndesign\nAssess \napproved \napplications\nSelect \nsystem \nrequired\nPlace order \nfor system\nConceptual \ndesign\nOff-the-shelf systems\nConfigurable systems\nMarket \nsurvey\nChoose \nsystem shortlist\nRefine \nrequirements\nChoose system \nsupplier\nNegotiate \ncontract\nModify \nrequirements\nDefine\nrequirements\nIssue request\nfor tender\nCustom systems\nChoose system \nsupplier\nNegotiate \ncontract\nModify \nrequirements\nFigure 19.9\u2002 System \nprocurement processes\n", "page": 569, "type": "text", "section": "Page 569"}
{"text": "\t\n19.3\u2002 \u25a0\u2002 System procurement\u2002 \u2002 569\nselected, you may negotiate with the supplier on costs, license conditions, \n\u00ad\npossible changes to the system, and other contractual issues. For custom sys-\ntems, negotiations are likely to involve payment schedules, reporting, accept-\nance criteria, requirements change requests, and costs of system changes. During \nthis process, requirements changes may be agreed that will reduce the overall \ncosts and avoid some development problems.\nComplex sociotechnical systems are rarely developed \u201cin house\u201d by the buyer of \nthe system. Rather, external systems companies are invited to bid for the systems \nengineering contract. The customer\u2019s business is not systems engineering, so its \nemployees do not have the skills needed to develop the systems themselves. For \ncomplex hardware/software systems, it may be necessary to use a group of suppliers, \neach with a different type of expertise.\nFor large systems, such as an air traffic management system, a group of suppliers \nmay form a consortium to bid for a contract. The consortium should include all of the \ncapabilities required for this type of system. For an ATC system, this would include \ncomputer hardware suppliers, software companies, peripheral suppliers, and suppli-\ners of specialist equipment such as radar systems.\nCustomers do not usually wish to negotiate with multiple suppliers, so the contract \nis usually awarded to a principal contractor, who coordinates the project. The princi-\npal contractor coordinates the development of different subsystems by subcontrac-\ntors. The subcontractors design and build parts of the system to a specification that is \nnegotiated with the principal contractor and the customer. Once completed, the prin-\ncipal contractor integrates these components and delivers them to the customer.\nDecisions made at the procurement stage of the systems engineering process are \ncritical for later stages in that process. Poor procurement decisions often lead to prob-\nlems such as late delivery of a system and development of systems that are unsuited to \ntheir operational environment. If the wrong system or the wrong supplier is chosen, then \nthe technical processes of system and software engineering become more complex.\nFor example, I studied a system \u201cfailure\u201d where a decision was made to choose an \nERP\u00a0system because this would \u201cstandardize\u201d operations across the organization. These \noperations were very diverse, and it turned out there were good reasons for this. \nStandardization was practically impossible. The ERP system could not be adapted to cope \nwith this diversity. It was ultimately abandoned after incurring costs of around \u00a310 million.\nDecisions and choices made during system procurement have a profound effect \non the security and dependability of a system. For example, if a decision is made to \nprocure an off-the-shelf system, then the organization has to accept that they have no \ninfluence over the security and dependability requirements of this system. System \nsecurity depends on decisions made by system vendors. In addition, off-the-shelf \nsystems may have known security weaknesses or may require complex configura-\ntion. Configuration errors, where entry points to the system are not properly secured, \nare a significant source of security problems.\nOn the other hand, a decision to procure a custom system means that a lot of effort \nmust be devoted to understanding and defining security and dependability requirements. \nIf a company has limited experience in this area, this is quite a difficult thing to do. If the \n", "page": 570, "type": "text", "section": "Page 570"}
{"text": "570\u2002 \u2002 Chapter 19\u2002 \u25a0\u2002 Systems engineering\nrequired level of dependability as well as acceptable system performance is to be \nachieved, then the development time may have to be extended and the budget increased.\nMany bad procurement decisions stem from political rather than technical causes. \nSenior management may wish to have more control and so demand that a single system \nis used across an organization. Suppliers may be chosen because they have a long-\nstanding relationship with a company rather than because they offer the best technology. \nManagers may wish to maintain compatibility with existing systems because they feel \nthreatened by new technologies. As I discuss in Chapter 20, people  who do not under-\nstand the required system are often responsible for procurement decisions. Engineering \nissues do not necessarily play a major part in their decision-making process.\n \n19.4  System development\nSystem development is a complex process in which the elements that are part of the \nsystem are developed or purchased and then integrated to create the final system. \nThe system requirements are the bridge between the conceptual design and the \ndevelopment processes. During conceptual design, business and high-level func-\ntional and non-functional system requirements are defined. You can think of this as \nthe start of development, hence the overlapping processes shown in Figure 19.1. \nOnce contracts for the system elements have been agreed, more detailed require-\nments engineering takes place.\nFigure 19.10 is a model of the systems development process. Systems engineer-\ning processes usually follow a \u201cwaterfall\u201d process model similar to the one that I \ndiscussed in Chapter 2. Although the waterfall model is inappropriate for most types \nof software development, higher-level systems engineering processes are plan-driven \nprocesses that still follow this model.\nPlan-driven processes are used in systems engineering because different elements \nof the system are independently developed. Different contractors are working con-\ncurrently on separate subsystems. Therefore, the interfaces to these elements have to \nbe designed before development begins. For systems that include hardware and other \nequipment, changes during development can be very expensive or, sometimes, prac-\ntically impossible. It is essential therefore, that the system requirements are fully \nunderstood before hardware development or building work begins.\nOne of the most confusing aspects of systems engineering is that companies use \ndifferent terminology for each stage of the process. Sometimes, requirements engi-\nneering is part of the development process, and sometimes it is a separate activity. \nHowever, after conceptual design, there are seven fundamental development activities:\n1.\t\nRequirements engineering is the process of refining, analyzing, and documenting \nthe high-level and business requirements identified in the conceptual design. I \nhave covered the most important requirements engineering activities in Chapter 4.\n2.\t\nArchitectural design overlaps significantly with the requirements engineering \nprocess. The process involves establishing the overall architecture of the system, \n", "page": 571, "type": "text", "section": "Page 571"}
{"text": "\t\n19.4\u2002 \u25a0\u2002 System development\u2002 \u2002 571\nidentifying the different system components, and understanding the relation-\nships between them.\n3.\t\nRequirements partitioning is concerned with deciding which subsystems (iden-\ntified in the system architecture) are responsible for implementing the system \nrequirements. Requirements may have to be allocated to hardware, software, or \noperational processes and prioritized for implementation. Ideally, you should \nallocate requirements to individual subsystems so that the implementation of a \ncritical requirement does not need subsystem collaboration. However, this is not \nalways possible. At this stage you also decide on the operational processes and \non how these are used in the requirements implementation.\n4.\t\nSubsystem engineering involves developing the software components of the sys-\ntem, configuring off-the-shelf hardware and software, designing, if necessary, \nspecial-purpose hardware, defining the operational processes for the system, \nand re-designing essential business processes.\n5.\t\nSystem integration is the process of putting together system elements to create a \nnew system. Only then do the emergent system properties become apparent.\n6.\t\nSystem testing is an extended activity where the whole system is tested and problems \nare exposed. The subsystem engineering and system integration phases are reentered \nto repair these problems, tune the performance of the system, and implement new \nrequirements. System testing may involve both testing by the system developer and \nacceptance/user testing by the organization that has procured the system.\n7.\t\nSystem deployment is the process of making the system available to its users, \ntransferring data from existing systems, and establishing communications with \nother systems in the environment. The process culminates with a \u201cgo live,\u201d after \nwhich users start to use the system to support their work.\nAlthough the overall process is plan-driven, the processes of requirements devel-\nopment and system design are inextricably linked. The requirements and the high-level \nSubsystem \nengineering\nArchitectural \ndesign\nRequirements\nengineering\nSystem\ndeployment\nSystem\ntesting\nSystem \nintegration\nRequirements\npartitioning\nFigure 19.10\u2002 The \nsystems development \nprocess\n", "page": 572, "type": "text", "section": "Page 572"}
{"text": "572\u2002 \u2002 Chapter 19\u2002 \u25a0\u2002 Systems engineering\ndesign are developed concurrently. Constraints posed by existing systems may limit \ndesign choices, and these choices may be specified in the requirements. You may \nhave to do some initial design to structure and organize the requirements engineering \nprocess. As the design process continues, you may discover problems with existing \nrequirements and new requirements may emerge. Consequently, you can think of \nthese linked processes as a spiral, as shown in Figure 19.11.\nThe spiral reflects the reality that requirements affect design decisions and vice \nversa, and so it makes sense to interleave these processes. Starting in the center, each \nround of the spiral may add detail to the requirements and the design. As subsystems \nare identified in the architecture, decisions are made on the responsibilities of these \nsubsystems for providing the system requirements. Some rounds of the spiral may \nfocus on requirements, others on design. Sometimes new knowledge collected dur-\ning the requirements and design process means that the problem statement itself has \nto be changed.\nFor almost all systems, many possible designs meet the requirements. These \ncover a range of solutions that combine hardware, software, and human operations. \nThe solution that you choose for further development may be the most appropriate \ntechnical solution that meets the requirements. However, wider organizational and \npolitical considerations may influence the choice of solution. For example, a govern-\nment client may prefer to use national rather than foreign suppliers for its system, \neven if national products are technically inferior.\nThese influences usually take effect in the review and assessment phase of the \nspiral model where designs and requirements may be accepted or rejected. The pro-\ncess ends when a review decides that the requirements and high-level design are \nsufficiently detailed for subsystems to be specified and designed.\nSystem requirements and\ndesign documentation\nReview and\nassessment\nArchitectural\ndesign\nStart\nRequirements\nelicitation and\nanalysis\nDomain and problem\nunderstanding\nRequirements \npartitioning\nFigure 19.11\u2002  \nRequirements and \ndesign spiral\n", "page": 573, "type": "text", "section": "Page 573"}
{"text": "\t\n19.4\u2002 \u25a0\u2002 System development\u2002 \u2002 573\nSubsystem engineering involves designing and building the system\u2019s hardware and \nsoftware components. For some types of systems, such as spacecraft, all hardware and \nsoftware components may be designed and built during the development process. \nHowever, in most systems, some components are bought rather than developed. It is \nusually much cheaper to buy existing products than to develop special-purpose compo-\nnents. However, if you buy large off-the-shelf systems, such as ERP systems, there is a \nsignificant cost in configuring these systems for use in their operational environment.\nSubsystems are usually developed in parallel. When problems that cut across sub-\nsystem boundaries are encountered, a system modification request must be made. \nWhere systems involve extensive hardware engineering, making modifications after \nmanufacturing has started is usually very expensive. Often \u201cworkarounds\u201d that com-\npensate for the problem must be found. These workarounds usually involve software \nchanges to implement new requirements.\nDuring systems integration, you take the independently developed subsystems \nand put them together to make up a complete system. This integration can be \nachieved using a \u201cbig bang\u201d approach, where all the subsystems are integrated at the \nsame time. However, for technical and managerial reasons, an incremental integra-\ntion process where subsystems are integrated one at a time is the best approach:\n1.\t\nIt is usually impossible to schedule the development of all the subsystems so \nthat they are all finished at the same time.\n2.\t\nIncremental integration reduces the cost of error location. If many subsystems \nare simultaneously integrated, an error that arises during testing may be in any of \nthese subsystems. When a single subsystem is integrated with an already work-\ning system, errors that occur are probably in the newly integrated subsystem or \nin the interactions between the existing subsystems and the new subsystem.\nAs an increasing number of systems are built by integrating off-the-shelf hardware \nand software application systems, the distinction between implementation and integra-\ntion is becoming blurred. In some cases, there is no need to develop new hardware or \nsoftware. Essentially, systems integration is the implementation phase of the system.\nDuring and after the integration process, the system is tested. This testing should \nfocus on testing the interfaces between components and the behavior of the system as a \nwhole. Inevitably, testing also reveals problems with individual subsystems that have to \nbe repaired. Testing takes a long time, and a common problem in system development \nis that the testing team may run out of either budget or time. This problem can lead to the \ndelivery of error-prone systems that need be repaired after they have been deployed.\nSubsystem faults that are a consequence of invalid assumptions about other subsys-\ntems are often exposed during system integration. This may lead to disputes between \nthe contractors responsible for implementing different subsystems. When problems \nare discovered in subsystem interaction, the contractors may argue about which sub-\nsystem is faulty. Negotiations on how to solve the problems can take weeks or months.\nThe final stage of the system development process is system delivery and deploy-\nment. The software is installed on the hardware and is readied for operation. This\u00a0may \n", "page": 574, "type": "text", "section": "Page 574"}
{"text": "574\u2002 \u2002 Chapter 19\u2002 \u25a0\u2002 Systems engineering\ninvolve more system configuration to reflect the local environment where it is used, \nthe transfer of data from existing systems, and the preparation of user documentation \nand training. At this stage, you may also have to reconfigure other systems in the \nenvironment to ensure that the new system interoperates with them.\nAlthough system deployment is straightforward in principle, it is often more diffi-\ncult than anticipated. The user environment may be different from that anticipated by \nthe system developers. Adapting the system to make it work in an unexpected environ-\nment can be difficult. The existing system data may require extensive clean-up, and \nparts of it may involve more effort than expected. The interfaces to other systems may \nnot be properly documented. You may find that the planned operational processes \nhave to be changed because they are not compatible with the operational processes for \nother systems. User training is often difficult to arrange, with the consequence that, \ninitially at least, users are unable to access the capabilities of the system. System \ndeployment can therefore take much longer and cost much more than anticipated.\n \n19.5  System operation and evolution\nOperational processes are the processes that are involved in using the system as \nintended by its designers. For example, operators of an air traffic control system \nfollow specific processes when aircraft enter and leave airspace, when they have to \nchange height or speed, when an emergency occurs, and so on. For new systems, \nthese operational processes have to be defined and documented during the system \ndevelopment process. Operators may have to be trained and other work processes \nadapted to make effective use of the new system. Undetected problems may arise \nat this stage because the system specification may contain errors or omissions. \nWhile the system may perform to specification, its functions may not meet the real \noperational needs. Consequently, the operators may not use the system as its \ndesigners intended.\nAlthough the designers of operational processes may have based their process \ndesigns on extensive user studies, there is always a period of \u201cdomestication\u201d \n(Stewart and Williams 2005) when users adapt to the new system and work out \npractical processes of how to use it. While user interface design is important, studies \nhave shown that, given time, users can adapt to complex interfaces. As they become \nexperienced, they prefer ways of using the system quickly rather than easily. This \nmeans that when designing systems, you should not simply cater for inexperienced \nusers but you should design the user interface to be adaptable for experienced users.\nSome people think that system operators are a source of problems in a system and \nthat we should move toward automated systems where operator involvement is min-\nimized. In my opinion, there are two problems with this approach:\n1.\t\nIt is likely to increase the technical complexity of the system because it has to be \ndesigned to cope with all anticipated failure modes. This increases the costs and \n", "page": 575, "type": "text", "section": "Page 575"}
{"text": "\t\n19.5\u2002 \u25a0\u2002 System operation and evolution\u2002 \u2002 575\ntime required to build the system. Provision also has to be made to bring in peo-\nple to deal with unanticipated failures.\n2.\t\nPeople are adaptable and can cope with problems and unexpected situations. \nThus, you do not have to anticipate everything that could possibly go wrong \nwhen you are specifying and designing the system.\nPeople have a unique capability of being able to respond effectively to the unex-\npected, even when they have never had direct experience of these unexpected events or \nsystem states. Therefore, when things go wrong, the system operators can often recover \nthe situation by finding workarounds and using the system in nonstandard ways. \nOperators also use their local knowledge to adapt and improve processes. Normally, the \nactual operational processes are different from those anticipated by the system designers.\nConsequently, you should design operational processes to be flexible and adapt-\nable. The operational processes should not be too constraining; they should not \nrequire operations to be done in a particular order; and the system software should \nnot rely on a specific process being followed. Operators usually improve the process \nbecause they know what does and does not work in a real situation.\nA problem that may only emerge after the system goes into operation is the oper-\nation of the new system alongside existing systems. There may be physical problems \nof incompatibility, or it may be difficult to transfer data from one system to another. \nMore subtle problems might arise because different systems have different user \ninterfaces. Introducing a new system may increase the operator error rate, as the \noperators use user interface commands for the wrong system.\n\t\n19.5.1 \t System evolution\nLarge, complex systems usually have a long lifetime. Complex hardware/software \nsystems may remain in use for more than 20 years, even though both the original \nhardware and software technologies used are obsolete. There are several reasons for \nthis longevity, as shown in Figure 19.12.\nOver their lifetime, large complex systems change and evolve to correct errors in the \noriginal system requirements and to implement new requirements that have emerged. \nThe system\u2019s computers are likely to be replaced with new, faster machines. The organ-\nization that uses the system may reorganize itself and hence use the system in a different \nway. The external environment of the system may change, forcing changes to the sys-\ntem. Hence, evolution is a process that runs alongside normal system operational pro-\ncesses. System evolution involves reentering the development process to make changes \nand extensions to the system\u2019s hardware, software, and operational processes.\nSystem evolution, like software evolution (discussed in Chapter 9), is inherently \ncostly for several reasons:\n1.\t\nProposed changes have to be analyzed very carefully from a business and a tech-\nnical perspective. Changes have to contribute to the goals of the system and \nshould not simply be technically motivated.\n", "page": 576, "type": "text", "section": "Page 576"}
{"text": "576\u2002 \u2002 Chapter 19\u2002 \u25a0\u2002 Systems engineering\n2.\t\nBecause subsystems are never completely independent, changes to one subsystem \nmay have side-effects that adversely affect the performance or behavior of other \nsubsystems. Consequent changes to these subsystems may therefore be needed.\n3.\t\nThe reasons for original design decisions are often unrecorded. Those responsible \nfor\u00a0the system evolution have to work out why particular design decisions were made.\n4.\t\nAs systems age, their structure becomes corrupted by change, so the costs of \nmaking further changes increases.\nSystems that have been in use for many years are often reliant on obsolete hard-\nware and software technology. These \u201clegacy systems\u201d (discussed in Chapter 9) are \nsociotechnical computer-based systems that have been developed using technology \nthat is now obsolete. However, they don\u2019t just include legacy hardware and software. \nThey also rely on legacy processes and procedures\u2014old ways of doing things that \nare difficult to change because they rely on legacy software. Changes to one part of \nthe system inevitably involve changes to other components.\nChanges made to a system during system evolution are often a source of problems \nand vulnerabilities. If the people implementing the changes are different from those \nwho developed the system, they may be unaware that a design decision was taken for \ndependability and security reasons. Therefore, they may change the system and lose \nsome safeguards that were deliberately implemented when the system was built. \nFurthermore, as testing is so expensive, complete retesting may be impossible after \nevery system change. Consequently, testing may not discover the adverse side-\neffects of changes that introduce or expose faults in other system components.\nFigure 19.12\u2002 Factors \nthat influence system \nlifetimes\nFactor\nRationale\nInvestment cost\nThe costs of a systems engineering project may be tens or even hundreds of \nmillions of dollars. These costs can only be justified if the system can deliver \nvalue to an organization for many years.\nLoss of expertise\nAs businesses change and restructure to focus on their core activities, they \noften lose engineering expertise. This may mean that they lack the ability to \nspecify the requirements for a new system.\nReplacement cost\nThe cost of replacing a large system is very high. Replacing an existing system can \nbe justified only if this leads to significant cost savings over the existing system.\nReturn on investment\nIf a fixed budget is available for systems engineering, spending on new \nsystems in some other area of the business may lead to a higher return on \ninvestment than replacing an existing system.\nRisks of change\nSystems are an inherent part of business operations, and the risks of \nreplacing existing systems with new systems cannot be justified. The danger \nwith a new system is that things can go wrong in the hardware, software, and \noperational processes. The potential costs of these problems for the business \nmay be so high that they cannot take the risk of system replacement.\nSystem dependencies\nSystems are interdependent and replacing one of these systems may lead to \nextensive changes in other systems.\n", "page": 577, "type": "text", "section": "Page 577"}
{"text": "\t\nChapter 19\u2002 \u25a0\u2002 Further reading \u2002 \u2002 577\nKey Points\n\u25a0 Systems engineering is concerned with all aspects of specifying, buying, designing, and testing \ncomplex sociotechnical systems.\n\u25a0 Sociotechnical systems include computer hardware, software, and people, and are situated \nwithin an organization. They are designed to support organizational or business goals and \nobjectives.\n\u25a0 The emergent properties of a system are characteristics of the system as a whole rather than of \nits component parts. They include properties such as performance, reliability, usability, safety, \nand security.\n\u25a0 The fundamental systems engineering processes are conceptual systems design, system pro-\ncurement, system development, and system operation.\n\u25a0 Conceptual systems design is a key activity where high-level system requirements and a vision \nof the operational system is developed.\n\u25a0 System procurement covers all of the activities involved in deciding what system to buy and who \nshould supply that system. Different procurement processes are used for off-the-shelf applica-\ntion systems, configurable COTS systems, and custom systems.\n\u25a0 System development processes include requirements specification, design, construction, inte-\ngration, and testing.\n\u25a0 When a system is put into use, the operational processes and the system itself inevitably change \nto reflect changes to the business requirements and the system\u2019s environment.\nFurther Reading\n\u201cAirport 95: Automated Baggage System.\u201d An excellent, readable case study of what can go wrong \nwith a systems engineering project and how software tends to get the blame for wider systems fail-\nures. (ACM Software Engineering Notes, 21, March 1996). http://doi.acm.org/10.1145/227531.227544\n\u201cFundamentals of Systems Engineering.\u201d This is the introductory chapter in NASA\u2019s systems engi-\nneering handbook. It presents an overview of the systems engineering process for space systems. \nAlthough these are mostly technical systems, there are sociotechnical issues to be considered. \nDependability is obviously critically important. (In NASA Systems Engineering Handbook, NASA-SP \n2007-6105, 2007). http://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20080008301_2008008500.pdf\nThe LSCITS Socio-technical Systems Handbook. This handbook introduces sociotechnical systems in \nan accessible way and provides access to more detailed papers on sociotechnical topics. (Various \nauthors, 2012). http://archive.cs.st-andrews.ac.uk/STSE-Handbook\nArchitecting systems: Concepts, Principles and Practice. This is a refreshingly different book on \u00ad\nsystems \nengineering that does not have the hardware focus of many \u201ctraditional\u201d systems engineering books. \n", "page": 578, "type": "text", "section": "Page 578"}
{"text": "The author, who is an experienced systems engineer, draws on examples from a wide range of \n\u00ad\nsystems and recognizes the importance of sociotechnical as well as technical issues. (H. Sillitto, \n\u00ad\nCollege Publications, 2014).\nWebsite\nPowerPoint slides for this chapter:\nwww.pearsonglobaleditions.com/Sommerville\nLinks to supporting videos:\nhttp://software-engineering-book.com/videos/systems-engineering/\nExercises\n\u2002 19.1.  \u0007\nGive two examples of government functions that are supported by complex sociotechnical sys-\ntems and explain why, in the foreseeable future, these functions cannot be completely automated.\n\u2002 19.2.  \u0007\nExplain briefly why the involvement of a range of professional disciplines is essential in sys-\ntems engineering.\n\u2002 19.3.  \u0007\nComplex sociotechnical systems lead to three important characteristics. What are they? \nExplain each in brief.\n\u2002 19.4.  \u0007\nWhat is a \u201cwicked problem\u201d? Explain why the development of a national medical records \n\u00ad\nsystem should be considered a \u201cwicked problem.\u201d\n\u2002 19.5.  \u0007\nA multimedia virtual museum system offering virtual experiences of ancient Greece is to be \ndeveloped for a consortium of European museums. The system should provide users with \nthe facility to view 3-D models of ancient Greece through a standard web browser and \nshould also support an immersive virtual reality experience. Develop a conceptual design for \nsuch a system, highlighting its key characteristics and essential high-level requirements.\n\u2002 19.6.  \u0007\nExplain why you need to be flexible and adapt system requirements when procuring large \noff-the-shelf software systems, such as ERP systems. Search the web for discussions of the \nfailures of such systems and explain, from a sociotechnical perspective, why these failures \noccurred. A possible starting point is: http://blog.360cloudsolutions.com/blog/bid/94028/\nTop-Six-ERP-Implementation-Failures\n\u2002 19.7.  \u0007\nWhy is system integration a particularly critical part of the systems development process? \n\u00ad\nSuggest three sociotechnical issues that may cause difficulties in the system integration process.\n\u2002 19.8.  Why is system evolution inherently costly?\n578\u2002 \u2002 Chapter 19\u2002 \u25a0\u2002 Systems engineering\n", "page": 579, "type": "text", "section": "Page 579"}
{"text": "\t\nChapter 19\u2002 \u25a0\u2002 References\u2002 \u2002 579\n\u2002 19.9.  \u0007\nWhat are the arguments for and against considering system engineering as a profession in \nits own right, like electrical engineering or software engineering?\n19.10.  \u0007\nYou are an engineer involved in the development of a financial system. During installation, \nyou discover that this system will make a significant number of people redundant. The peo-\nple in the environment deny you access to essential information to complete the system \ninstallation. To what extent should you, as a systems engineer, become involved in this situa-\ntion? Is it your professional responsibility to complete the installation as contracted? Should \nyou simply abandon the work until the procuring organization has sorted out the problem?\nReferences\nBaxter, G., and I. Sommerville. 2011. \u201cSocio-Technical Systems: From Design Methods to Systems \nEngineering.\u201d Interacting with Computers 23 (1): 4\u201317. doi:10.1016/j.intcom.2010.07.003.\nCheckland, P. 1981. Systems Thinking, Systems Practice. Chichester, UK: John Wiley & Sons.\nFairley, R. E., R. H. Thayer, and P. Bjorke. 1994. \u201cThe Concept of Operations: The Bridge from Opera-\ntional Requirements to Technical Specifications.\u201d In 1st Int. Conf. on Requirements Engineering, \n40\u20137. Colorado Springs, CO. doi:10.1109/ICRE.1994.292405.\nIEEE. 2007. \u201cIEEE Guide for Information Technology. System Definition\u2014Concept of Operations \n(ConOps) Document.\u201d Electronics. Vol. 1998. doi:10.1109/IEEESTD.1998.89424. http://ieeexplore.\nieee.org/servlet/opac?punumber=6166\nMostashari, A., S. A. McComb, D. M. Kennedy, R. Cloutier, and P. Korfiatis. 2012. \u201cDeveloping a \nStakeholder-Assisted Agile CONOPS Development Process.\u201d Systems Engineering 15 (1): 1\u201313. \ndoi:10.1002/sys.20190.\nRittel, H., and M. Webber. 1973. \u201cDilemmas in a General Theory of Planning.\u201d Policy Sciences 4: \n155\u2013169. doi:10.1007/BF01405730.\nStevens, R., P. Brook, K. Jackson, and S. Arnold. 1998. Systems Engineering: Coping with Complex-\nity. London: Prentice-Hall.\nStewart, J., and R. Williams. 2005. \u201cThe Wrong Trousers? Beyond the Design Fallacy: Social Learning \nand the User.\u201d In User Involvement in Innovation Processes. Strategies and Limitations from a \nSocio-Technical Perspective, edited by H. Rohrache, 39\u201371. Berlin: Profil-Verlag.\nThayer, R. H. 2002. \u201cSoftware System Engineering: A Tutorial.\u201d IEEE Computer 35 (4): 68\u201373. \ndoi:10.1109/MC.2002.993773.\nWhite, S., M. Alford, J. Holtzman, S. Kuehl, B. McCay, D. Oliver, D. Owens, C. Tully, and A. Willey. \n1993. \u201cSystems Engineering of Computer-Based Systems.\u201d IEEE Computer 26 (11): 54\u201365. \ndoi:10.1109/ECBS.1994.331687.\n", "page": 580, "type": "text", "section": "Page 580"}
{"text": "Contents\n20.1\t System complexity\n20.2\t Systems of systems classification\n20.3\t Reductionism and complex systems\n20.4\t Systems of systems engineering\n20.5\t Systems of systems architecture\nObjectives\nThe objectives of this chapter are to introduce the idea of a system of \nsystems and to discuss the challenges of building complex systems of \nsoftware systems. When you have read this chapter, you will:\n\u25a0\t understand what is meant by a system of systems and how it \ndiffers from an individual system;\n\u25a0\t understand systems of systems classification and the differences \nbetween different types of systems of systems;\n\u25a0\t understand why conventional methods of software engineering \nthat are based on reductionism are inadequate for developing \nsystems of systems;\n\u25a0\t have been introduced to the systems of systems engineering \nprocess and architectural patterns for systems of systems.\nSystems of systems\n20 \n", "page": 581, "type": "text", "section": "Page 581"}
{"text": "We need software engineering because we create large and complex software \n\u00ad\nsystems. The discipline emerged in the 1960s because the first attempts to build \nlarge software systems mostly went wrong. Creating software was much more \nexpensive than expected, took longer than planned, and the software itself was often \nunreliable. To address these problems, we have developed a range of software engi-\nneering techniques and technologies, which have been remarkably successful. We \ncan now build systems that are much larger, more complex, much more reliable, and \nmore effective than the software systems of the 1970s.\nHowever, we have not \u201csolved\u201d the problems of large system engineering. \nSoftware project failures are still common. For example, there have been serious \nproblems and delays in the implementation of government health care systems in \nboth the United States and the UK. The root cause of these problems is, as it was in \nthe 1960s, that we are trying to build systems that are larger and more complex than \nbefore. We are attempting to build these \u201cmega-systems\u201d using methods and tech-\nnology that were never designed for this purpose. As I discuss later in the chapter, I \nbelieve that current software engineering technology cannot scale up to cope with \nthe complexity that is inherent in many of the systems now being proposed.\nThe increase in size of software systems since the introduction of software engi-\nneering has been remarkable. Today\u2019s large systems may be a hundred or even a \nthousand times larger than the \u201clarge\u201d systems of the 1960s. Northrop and her col-\nleagues (Northrop et al. 2006) suggested in 2006 that we would shortly see the \ndevelopment of systems with a billion lines of code. Almost 10 years after this pre-\ndiction, I suspect such systems are already in use.\nOf course, we do not start with nothing and then write a billion lines of code. As \nI discussed in Chapter 15, the real success story of software engineering has been \nsoftware reuse. It is only because we have developed ways of reusing software \nacross applications and systems that large-scale development is possible. Very large-\nscale systems now and in the future will be built by integrating existing systems \nfrom different providers to create systems of systems (SoS).\nWhat do we mean when we talk about a system of systems? As Hitchens says \n(Hitchins 2009), from a general systems perspective, there is no difference between \na system and a system of systems. Both have emergent properties and can be com-\nposed from subsystems. However, from a software engineering perspective, I think \nthere is a useful distinction between these terms. This distinction is sociotechnical \nrather than technical:\nA system of systems is a system that contains two or more independently \nmanaged elements.\nThis means that there is no single manager for all of the parts of the system of \nsystems and that different parts of a system are subject to different management and \ncontrol policies and rules. As we shall see, distributed management and control has \na profound effect on the overall complexity of the system.\nThis definition of systems of systems says nothing about the size of systems of \nsystems. A relatively small system that includes services from different providers is \n \nChapter 20\u2002 \u25a0\u2002 Systems of systems\u2002 \u2002 581\n", "page": 582, "type": "text", "section": "Page 582"}
{"text": "582\u2002 \u2002 Chapter 20\u2002 \u25a0\u2002 Systems of systems\na system of systems. Some of the problems of SoS engineering apply to such small \nsystems, but the real challenges emerge when the constituent systems are themselves \nlarge-scale systems.\nMuch of the work in the area of systems of systems has come from the defense \ncommunity. As the capability of software systems increased in the late 20th century, \nit became possible to coordinate and control previously independent military \n\u00ad\nsystems, such as naval and ground-based air and ship defense systems. The system \nmight include tens or hundreds of separate elements, with software systems keeping \ntrack of these elements and providing controllers with information that allows them \nto be deployed most effectively.\nThis type of system of systems is outside the scope of a software engineering \nbook. Instead, I focus here on systems of systems where the system elements are \nsoftware systems rather than hardware such as aircraft, military vehicles, or radars. \nSystems of software systems are created by integrating separate software systems, \nand, at the time of writing, most software SoS include a relatively small number of \nseparate systems. Each constituent system is usually a complex system in its own \nright. However, it is predicted that, over the next few years, the size of software SoS \nis likely to grow significantly as more and more systems are integrated to make use \nof the capabilities that they offer.\nExamples of systems of systems of software systems are:\n1.\t\nA cloud management system that handles local private cloud management and \nmanagement of servers on public clouds such as Amazon and Microsoft.\n2.\t\nAn online banking system that handles loan requests and that connects to a \ncredit reference system provided by credit reference agencies to check the credit \nof applicants.\n3.\t\nAn emergency information system that integrates information from police, \nambulance, fire, and coast guard services about the assets available to deal with \ncivil emergencies such as flooding and large-scale accidents.\n4.\t The digital learning environment (iLearn) that I introduced in Chapter 1. \nThis system provides a range of learning support by integrating separate \nsoftware systems such as Microsoft Office 365, virtual learning environ-\nments such as Moodle, simulation modeling tools, and content such as \nnewspaper archives.\nMaier (Maier 1998) identified five essential characteristics of systems of systems:\n1.\t\nOperational independence of elements Parts of the system are not simply com-\nponents but can operate as useful systems in their own right. The systems within \nthe SoS evolve independently.\n2.\t\nManagerial independence of elements Parts of the system are \u201cowned\u201d and man-\naged by different organizations or by different parts of a larger organization. \nTherefore different rules and policies apply to the management and evolution of \n", "page": 583, "type": "text", "section": "Page 583"}
{"text": " \nChapter 20\u2002 \u25a0\u2002 Systems of systems\u2002 \u2002 583\nthese systems. As I have suggested, this is the key factor that distinguishes a \nsystem of systems from a system.\n3.\t\nEvolutionary development SoS are not developed in a single project but evolve \nover time from their constituent systems.\n4.\t\nEmergence SoS have emergent characteristics that only become apparent after \nthe SoS has been created. Of course, as I have discussed in Chapter 19, emer-\ngence is a characteristic of all systems, but it is particularly important in SoS.\n5.\t\nGeographical distribution of elements The elements of a SoS are often geograph-\nically distributed across different organizations. This is important technically \nbecause it means that an externally-managed network is an integral part of the \nSoS. It is also important managerially as it increases the difficulties of communi-\ncation between those involved in making system management decisions and adds \nto the difficulties of maintaining system security.\u2020\nI would like to add two further characteristics to Maier\u2019s list that are particularly \nrelevant to systems of software systems:\n1.\t\nData intensive A software SoS typically relies on and manages a very large \nvolume of data. In terms of size, this may be tens or even hundreds of times \nlarger than the code of the constituent systems itself.\n2.\t\nHeterogeneity The different systems in a software SoS are unlikely to have been \ndeveloped using the same programming languages and design methods. This is \na consequence of the very rapid pace of evolution of software technologies. \nCompanies frequently update their development methods and tools as new, \nimproved versions become available. In a 20-year lifetime of a large SoS, tech-\nnologies may change four or five times.\nAs I discuss in Section 20.1, these characteristics mean that SoS can be much \nmore complex than systems with a single owner and manager. I believe that our cur-\nrent software engineering methods and techniques cannot scale to cope with this \ncomplexity. Consequently, problems with the very large and complex systems that \nwe are now developing are inevitable. We need a completely new set of abstractions, \nmethods, and technologies for software systems of systems engineering.\nThis need has been recognized independently by a number of different authori-\nties. In the UK, a report published in 2004 (Royal Academy of Engineering 2004) \nled to the establishment of a national research and training initiative in large-scale \ncomplex IT systems (Sommerville et al. 2012). In the United States, the Software \nEngineering Institute reported on Ultra-Large Scale Systems in 2006 (Northrop et al. \n2006). From the systems engineering community, Stevens (Stevens 2010) discusses \nthe problems of constructing \u201cmega-systems\u201d in transport, health care, and defense.\n\u2020Maier, M. W. 1998. \u201cArchitecting Principles for Systems-of-Systems.\u201d Systems Engineering 1 (4): \n267\u2013284. doi:10.1002/(SICI)1520-6858(1998)1:4<267::AID-SYS3>3.0.CO;2-D.\n", "page": 584, "type": "text", "section": "Page 584"}
{"text": "584\u2002 \u2002 Chapter 20\u2002 \u25a0\u2002 Systems of systems\n \n20.1  System complexity\nI suggested in the introduction that the engineering problems that arise when con-\nstructing systems of software systems are due to the inherent complexity of these \nsystems. In this section, I explain the basis of system complexity and discuss the \ndifferent types of complexity that arise in software SoS.\nAll systems are composed of parts (elements) with relationships between these \nelements of the system. For example, the parts of a program may be objects, and the \nparts of each object may be constants, variables, and methods. Examples of relation-\nships include \u201ccalls\u201d (method A calls method B), \u201cinherits-from\u201d (object X inherits \nthe methods and attributes of object Y), and \u201cpart of\u200a\n\u200a\n\u200a\n\u201d (method A is part of object X).\nThe complexity of any system depends on the number and types of relationships \nbetween system elements. Figure 20.1 shows examples of two systems. System (a) is \na relatively simple system with only a small number of relationships between its ele-\nments. By contrast, System (b), with the same number of elements, is a more com-\nplex system because it has many more element\u2013element relationships.\nThe type of relationship also influences the overall complexity of a system. Static \nrelationships are relationships that are planned and analyzable from static depictions \nof the system. Therefore, the \u201cuses\u201d relationship in a software system is a static rela-\ntionship. From either the software source code or a UML model of a system, you can \nwork out how any one software component uses other components.\nDynamic relationships are relationships that exist in an executing system. The \n\u201ccalls\u201d relationship is a dynamic relationship because, in any system with if-statements, \nyou cannot tell whether or not one method will call another method. It depends on \nthe\u00a0runtime inputs to the system. Dynamic relationships are more complex to analyze \nas you need to know the system inputs and data used as well as the source code of \nthe\u00a0system.\nAs well as system complexity, we also have to consider the complexity of the \nprocesses used to develop and maintain the system once it has gone into use. Figure 20.2 \nillustrates these processes and their relationship with the developed system.\nSystem (a)\nSystem (b)\nFigure 20.1\u2002 Simple  \nand complex systems \n", "page": 585, "type": "text", "section": "Page 585"}
{"text": " \n20.1\u2002 \u25a0\u2002 System complexity\u2002 \u2002 585\nAs systems grow in size, they need more complex production and management pro-\ncesses. Complex processes are themselves complex systems. They are difficult to under-\nstand and may have undesirable emergent properties. They are more time consuming \nthan simpler processes, and they require more documentation and coordination between \nthe people and the organizations involved in the system development. The complexity of \nthe production process is one of the main reasons why projects go wrong, with software \ndelivered late and overbudget. Therefore, large systems are always at risk of cost and \ntime overruns.\nComplexity is important for software engineering because it is the main influence \non the understandability and the changeability of a system. The more complex a sys-\ntem, the more difficult it is to understand and analyze. Given that complexity is a func-\ntion of the number of relationships between elements of a system, it is inevitable that \nlarge systems are more complex than small systems. As complexity increases, there \nare more and more relationships between elements of the system and an increased \nlikelihood that changing one part of a system will have undesirable effects elsewhere.\nSeveral different types of complexity are relevant to sociotechnical systems:\n1.\t\nThe technical complexity of the system is derived from the relationships between \nthe different components of the system itself.\n2.\t\nThe managerial complexity of the system is derived from the complexity of the \nrelationships between the system and its managers (i.e., what can managers \nchange in the system) and the relationships between the managers of different \nparts of the system.\nProduction process\nManagement process\nComplex system\nProduces\nManages\nFigure 20.2\u2002 Production \nand management \nprocesses \n", "page": 586, "type": "text", "section": "Page 586"}
{"text": "586\u2002 \u2002 Chapter 20\u2002 \u25a0\u2002 Systems of systems\n3.\t\nThe governance complexity of a system depends on the relationships between \nthe laws, regulations, and policies that affect the system and the relationships \nbetween the decision-making processes in the organizations responsible for the \nsystem. As different parts of the system may be in different organizations and in \ndifferent countries, different laws, rules, and policies may apply to each system \nwithin the SoS.\nGovernance and managerial complexity are related, but they are not the same \nthing. Managerial complexity is an operational issue\u2014what can and can\u2019t actually be \ndone with the system. Governance complexity is associated with the higher level of \ndecision-making processes in organizations that affect the system. These decision-\nmaking processes are constrained by national and international laws and regulations.\nFor example, say a company decides to allow its staff to access its systems using \ntheir own mobile devices rather than company-issued laptops. The decision to allow \nthis is a governance decision because it changes the policy of the company. As a \nresult of this decision, management of the system becomes more complex as manag-\ners have to ensure that the mobile devices are configured properly so that company \ndata is secure. The technical complexity of the system also increases as there is no \nlonger a single implementation platform. Software may have to be modified to work \non laptops, tablets and phones.\nAs well as technical complexity, the characteristics of systems of systems may also \nlead to significantly increased managerial and governance complexity. Figure 20.3 \nsummarizes how the different SoS characteristics primarily contribute to different \ntypes of complexity:\n1.\t\nOperational independence The constituent systems in the SoS are subject to dif-\nferent policies and rules (governance complexity) and ways of managing the \nsystem (managerial complexity).\n2.\t\nManagerial independence The constituent systems in the SoS are managed by \ndifferent people in different ways. They have to coordinate to ensure that manage-\nment changes are consistent (managerial complexity). Special software may be \nneeded to support consistent management and evolution (technical complexity).\n3.\t\nEvolutionary development contributes to the technical complexity of a SoS because \ndifferent parts of the system are likely to be built using different technologies.\n4.\t\nEmergence is a consequence of complexity. The more complex a system, the \nmore likely it is that it will have undesirable emergent properties. These proper-\nties increase the technical complexity of the system as software has to be devel-\noped or changed to compensate for them.\n5.\t\nGeographical distribution increases the technical, managerial, and governance \ncomplexity in a SoS. Technical complexity is increased because software is \nrequired to coordinate and synchronize remote systems; managerial complexity \nis increased because it is more difficult for managers in different countries to \ncoordinate their actions; governance complexity is increased because different \n", "page": 587, "type": "text", "section": "Page 587"}
{"text": " \n20.2\u2002 \u25a0\u2002 Systems of systems classification\u2002 \u2002 587\nparts of the systems may be located in different jurisdictions and so are subject \nto different laws and regulations.\n6.\t\nData-intensive systems are technically complex because of the relationships \nbetween the data items. The technical complexity is also likely to be increased \nto cope with data errors and incompleteness. Governance complexity may be \nincreased because of different laws governing the use of data.\n7.\t\nThe heterogeneity of a system contributes to its technical complexity because of \nthe difficulties of ensuring that different technologies used in different parts of \nthe system are compatible.\nLarge-scale systems of systems are now unimaginably complex entities that can-\nnot be understood or analyzed as a whole. As I discuss in Section 20.3, the large \nnumber of interactions between the parts and the dynamic nature of these interac-\ntions means that conventional engineering approaches do not work well for complex \nsystems. It is complexity that is the root cause of problems in projects to develop \nlarge software-intensive systems, not poor management or technical failings.\n \n20.2  Systems of systems classification\nEarlier, I suggested that the distinguishing feature of a system of systems was that \ntwo or more of its elements were independently managed. Different people with \ndifferent priorities have the authority to take day-to-day operational decisions about \nchanges to the system. As their work is not necessarily aligned, conflicts can arise \nthat require a significant amount of time and effort to resolve. Systems of systems, \ntherefore, always have some degree of managerial complexity.\nHowever, this broad definition of SoS covers a very wide range of system types. It \nincludes systems that are owned by a single organization but are managed by different \nFigure 20.3\u2002 SoS \ncharacteristics and \nsystem complexity\nSoS characteristic\nTechnical \ncomplexity\nManagerial \ncomplexity\nGovernance \ncomplexity\nOperational independence\nX\nX\nManagerial independence\nX\nX\nEvolutionary development\nX\nEmergence\nX\nGeographical distribution\nX\nX\nX\nData-intensive\nX\nX\nHeterogeneity\nX\n", "page": 588, "type": "text", "section": "Page 588"}
{"text": "588\u2002 \u2002 Chapter 20\u2002 \u25a0\u2002 Systems of systems\nparts of that organization. It also includes systems whose constituent systems are \nowned and managed by different organizations that may, at times, compete with \neach other. Maier (Maier 1998) devised a classification scheme for SoS based on \ntheir governance and management complexity:\n1.\t\nDirected systems. Directed SoS are owned by a single organization and are \ndeveloped by integrating systems that are also owned by that organization. The \nsystem elements may be independently managed by parts of the organization. \nHowever, there is an ultimate governing body within the organization that can \nset priorities for system management. It can resolve disputes between the man-\nagers of different elements of the system. Directed systems therefore have some \nmanagerial complexity but no governance complexity. A military command-\nand-control system that integrates information from airborne and ground-based \nsystems is an example of a directed SoS.\n2.\t Collaborative systems. Collaborative SoS are systems with no central authority \nto set management priorities and resolve disputes. Typically, elements of the \nsystem are owned and governed by different organizations. However, all of the \norganizations involved recognize the mutual benefits of joint governance of \nthe system. They therefore usually set up a voluntary governance body that \nmakes decisions about the system. Collaborative systems have both manage-\nrial complexity and a limited degree of governance complexity. An integrated \npublic transport information system is an example of a collaborative system of \nsystems. Bus, rail, and air transport providers agree to link their systems to \nprovide passengers with up-to-date information.\n3.\t\nVirtual systems. Virtual systems have no central governance, and the partici-\npants may not agree on the overall purpose of the system. Participant systems \nmay enter or leave the SoS. Interoperability is not guaranteed but depends on \npublished interfaces that may change. These systems have a very high degree of \nboth managerial and governance complexity. An example of a virtual SoS is an \nautomated high-speed algorithmic trading system. These systems from different \ncompanies automatically buy and sell stock from each other, with trades taking \nplace in fractions of a second.\nUnfortunately, I think that the names that Maier has used do not really reflect the \ndistinctions between these different types of systems. As Maier himself says, there is \nalways some collaboration in the management of the system elements. So, \u201ccollabora-\ntive systems\u201d is not really a good name. The term directed systems implies top-down \nauthority. However, even within a single organization, the need to maintain good \nworking relationships between the people involved means that governance is agreed \nto rather than imposed.\nIn \u201cvirtual\u201d SoS, there may be no formal mechanisms for collaboration, but the \nsystem has some mutual benefit for all participants. Therefore, they are likely to col-\nlaborate informally to ensure that the system can continue to operate. Furthermore, \nMaier\u2019s use of the term virtual could be confusing because \u201cvirtual\u201d has now come \nto mean \u201cimplemented by software,\u201d as in virtual machines and virtual reality.\n", "page": 589, "type": "text", "section": "Page 589"}
{"text": " \n20.2\u2002 \u25a0\u2002 Systems of systems classification\u2002 \u2002 589\nFigure 20.4 illustrates the collaboration in these different types of system. Rather \nthan use Maier\u2019s names, I have used what I hope are more descriptive terms:\n1.\t\nOrganizational systems of systems are SoS where the governance and manage-\nment of the system lies within the same organization or company. These corre-\nspond to Maier\u2019s \u201cdirected SoS.\u201d Collaboration between system owners is \nmanaged by the organization. The SoS may be geographically distributed, with \ndifferent parts of the system subject to different national laws and regulations. \nIn Figure 20.4, Systems 1, 2, and 3 are independently managed, but the govern-\nance of these systems is centralized.\n2.\t\nFederated systems are SoS where the governance of the SoS depends on a vol-\nuntary participative body in which all of the system owners are represented. In \nFigure 20.4, this is shown by the owners of Systems 1, 2, and 3 participating in \na single governance body. The system owners agree to collaborate and believe \nthat decisions made by the governance body are binding. They implement these \ndecisions in their individual management policies, although implementations \nmay differ because of national laws, regulations, and culture.\n3.\t System of system coalitions are SoS with no formal governance mechanisms \nbut where the organizations involved informally collaborate and manage their \nown systems to maintain the system as a whole. For example, if one system \nprovides a data feed to others, the managers of that system will not change the \nformat of the data without notice. Figure 20.4 shows that there is no govern-\nance at the organizational level but that informal collaboration exists at the \nmanagement level.\nThis governance-based classification scheme provides a means of identifying the \ngovernance requirements for a SoS. By classifying a system according to this model, \nyou can check if the appropriate governance structures exist and if these are the ones \nyou really need. Setting up these structures across organizations is a political process \nand inevitably takes a long time. It is therefore helpful to understand the governance \nGovernance\nManagement\nTechnical\nOrganizational\nFederated\nCoalition\n1\n2\n3\n1\n2\n3\n1\n2\n3\n1\n2\n3\n1\n2\n3\n1\n2\n3\n1\n2\n3\nFigure 20.4\u2002 SoS \ncollaboration \n", "page": 590, "type": "text", "section": "Page 590"}
{"text": "590\u2002 \u2002 Chapter 20\u2002 \u25a0\u2002 Systems of systems\nproblem early in the process and take actions to ensure that appropriate governance \nis in place. It may be the case that you need to adopt a governance model that moves \na system from one class to another. Moving the governance model to the left in \nFigure 20.4 usually reduces complexity.\nAs I have suggested, the school digital learning environment (iLearn) is a system \nof systems. As well as the digital learning system itself, it is connected to school \nadministration systems and to network management systems. These network man-\nagement systems are used for Internet filtering, which stops students from accessing \nundesirable material on the Internet.\niLearn is a relatively simple technical system, but it has a high level of govern-\nance complexity. This complexity arises because of the way that education is funded \nand managed. In many countries pre-university education is funded and organized at \na local level rather than at a national level. States, cities, or counties are responsible \nfor schools in their area and have autonomy in deciding school funding and policies. \nEach local authority maintains its own school administration system and network \nmanagement system.\nIn Scotland, there are 32 local authorities with responsibility for education in \ntheir area. School administration is outsourced to one of three providers and iLearn \nmust connect to their systems. However, each local authority has its own network \nmanagement policies with separate network management systems involved.\nThe development of a digital learning system is a national initiative, but to cre-\nate a digital learning environment, it has to be integrated with network manage-\nment and school administration systems. It is therefore a system of systems with \nadministration and network management systems, as well as the systems within \niLearn such as Office 365 and Wordpress. There is no common governance pro-\ncess across authorities, so, according to the classification scheme, this is a coali-\ntion of systems. In practice, this means that it cannot be guaranteed that students \nin different places can access the same tools and content, because of different \nInternet filtering policies.\nWhen we produced the conceptual model for the system, we made a strong rec-\nommendation that common policies should be established across local authorities on \nadministrative information provision and Internet filtering. In essence, we suggested \nthat the system should be a federated system rather than a coalition of systems. This \nsuggestion requires a new governance body to be established to agree on common \npolicies and standards for the system.\n \n20.3  Reductionism and complex systems\nI have already suggested that our current software engineering methods and tech-\nnologies cannot cope with the complexity that is inherent in modern systems of sys-\ntems. Of course, this idea is not new: Progress in all engineering disciplines has \nalways been driven by challenging and difficult problems. New methods and tools \nare developed in response to failures and difficulties with existing approaches.\n", "page": 591, "type": "text", "section": "Page 591"}
{"text": " \n20.3\u2002 \u25a0\u2002 Reductionism and complex systems\u2002 \u2002 591\nIn software engineering, we have seen the incredibly rapid development of the \ndiscipline to help manage the increasing size and complexity of software systems. \nThis effort has been very successful indeed. We can now build systems that are \norders of magnitude larger and more complex than those of the 1960s and 1970s.\nAs with other engineering disciplines, the approach that has been the basis \nof\u00a0 complexity management in software engineering is called reductionism. \nReductionism is a philosophical position based on the assumptions that any system \nis made up of parts or subsystems. It assumes that the behavior and properties of the \nsystem as a whole can be understood and predicted by understanding the individual \nparts and the relationships between these parts. Therefore, to design a system, the \nparts making up that system are identified, constructed separately, and then assem-\nbled into the complete system. Systems can be thought of as hierarchies, with the \nimportant relationships between parent and child nodes in the hierarchy.\nReductionism has been and continues to be the fundamental underpinning \napproach to all kinds of engineering. We can identify common abstractions \nacross the same types of system and design and build these separately. They can \nthen be integrated to create the required system. For example, the abstractions in \nan automobile might be a body shell, a drive train, an engine, a fuel system, and \nso on. There are a relatively small number of relationships between these abstrac-\ntions, so it is possible to specify interfaces and design and build each part of the \nsystem separately.\nThe same reductionist approach has been the basis of software engineering for \nalmost 50 years. Top-down design, where you start with a very high-level model of \na system and break this down to its components is a reductionist approach. This is \nthe basis of all software design methods, such as object-oriented design. Programming \nlanguages include abstractions, such as procedures and objects that directly reflect \nreductionist system decomposition.\nAgile methods, although they may appear quite different from top-down systems \ndesign, are also reductionist. They rely on being able to decompose a system into \nparts, implement these parts separately, and then integrate these to create the system. \nThe only real difference between agile methods and top-down design is that the sys-\ntem is decomposed into components incrementally rather than all at once.\nReductionist methods are most successful when there are relatively few rela-\ntionships or interactions between the parts of a system and it is possible to model \nthese relationships in a scientific way. This is generally true for mechanical and \nelectrical systems where there are physical linkages between the system compo-\nnents. It is less true for electronic systems and certainly not the case for software \nsystems, where there may be many more static and dynamic relationships between \nsystem components.\nThe distinctions between software and hardware components was recognized in \nthe 1970s. Design methods emphasized the importance of limiting and controlling \nthe relationships between the parts of a system. These methods suggested that com-\nponents should be tightly integrated with loose coupling between these components. \nTight integration meant that most of the relationships were internal to a component, \nand loose coupling meant that there were relatively few component\u2013component \n", "page": 592, "type": "text", "section": "Page 592"}
{"text": "592\u2002 \u2002 Chapter 20\u2002 \u25a0\u2002 Systems of systems\nrelationships. The need for tight integration (data and operations) and loose cou-\npling was the driver for the development of object-oriented software engineering.\nUnfortunately, controlling the number and types of relationship is practically \nimpossible in large systems, especially systems of systems. Reductionism does not \nwork well when there are many relationships in a system and when these relation-\nships are difficult to understand and analyze. Therefore, any type of large system \ndevelopment is likely to run into difficulties.\nThe reasons for these potential difficulties are that the fundamental assumptions \ninherent to reductionism are inapplicable for large and complex systems (Sommerville \net al. 2012). These assumptions are shown in Figure 20.5 and apply in three areas:\n1.\t\nSystem ownership and control Reductionism assumes that there is a controlling \nauthority for a system that can resolve disputes and make high-level technical \ndecisions that will apply across the system. As we have seen, because there are \nmultiple bodies involved in their governance, this is simply not true for systems \nof systems.\n2.\t\nRational decision making Reductionism assumes that interactions between com-\nponents can be objectively assessed by, for example, mathematical model- \ning. These assessments are the driver for system decision making. Therefore, if \none particular design of a vehicle, say, offers the best fuel economy without a \nreduction in power, then a reductionist approach assumes that this will be the \ndesign chosen.\n3.\t\nDefined system boundaries Reductionism assumes that the boundaries of a sys-\ntem can be agreed to and defined. This is often straightforward: There may be a \nphysical shell defining the system as in a car, a bridge has to cross a given \nstretch of water, and so on. Complex systems are often developed to address \nwicked problems (Rittel and Webber 1973). For such problems, deciding on \nwhat is part of the system and what is outside it is usually a subjective judgment, \nwith frequent disagreements between the stakeholders involved.\nReductionist assumptions\nOwners of a \nsystem control \nits development\nDecisions are made \nrationally, driven \nby technical criteria\nThere is a definable \nproblem and clear \nsystem boundaries\nThere is no single \nsystem owner \nor controller\nDecision making \ndriven by political \nmotives\nWicked problem with\nconstantly renegotiated \nsystem boundaries\nControl\nDecision making\nProblem definition\nSystems of systems reality\nFigure 20.5\u2002  \nReductionist \nassumptions \nand\u00a0complex \nsystem reality \n", "page": 593, "type": "text", "section": "Page 593"}
{"text": " \n20.4\u2002 \u25a0\u2002 Systems of systems engineering\u2002 \u2002 593\nThese reductionist assumptions break down for all complex systems, but when \nthese systems are software-intensive, the difficulties are compounded:\n1.\t\nRelationships in software systems are not governed by physical laws. We cannot \nproduce mathematical models of software systems that will predict their behavior and \nattributes. We therefore have no scientific basis for decision making. Political factors \nare usually the driver of decision making for large and complex software systems.\n2.\t\nSoftware has no physical limitations; hence there are no limits on where the \nboundaries of a system should be drawn. Different stakeholders will argue for the \nboundaries to be placed in such a way that is best for them. Furthermore, it is \nmuch easier to change software requirements than hardware requirements. The \nboundaries and the scope of a system are likely to change during its development.\n3.\t\nLinking software systems from different owners is relatively easy; hence we are more \nlikely to try and create a SoS where there is no single governing body. The manage-\nment and evolution of the different systems involved cannot be completely controlled.\nFor these reasons, I believe that the problems and difficulties that are commonplace \nin large software systems engineering are inevitable. Failures of large government \nprojects such as the health automation projects in the UK and the United States are a \nconsequence of complexity rather than technical or project management failures.\nReductionist approaches such as object-oriented development have been very suc-\ncessful in improving our ability to engineer many types of software system. They will \ncontinue to be useful and effective in developing small and medium-sized systems \nwhose complexity can be controlled and which may be parts of a software SoS. \nHowever, because of the fundamental assumptions underlying reductionism, \u201cimprov-\ning\u201d these methods will not lead to an improvement in our ability to engineer complex \nsystems of systems. Rather, we need new abstractions, methods, and tools that recog-\nnize the technical, human, social, and political complexities of SoS engineering. I \nbelieve that these new methods will be probabilistic and statistical and that tools will \nrely on system simulation to support decision making. Developing these new approaches \nis a major challenge for software and systems engineering in the 21st century.\n \n20.4  Systems of systems engineering\nSystems of systems engineering is the process of integrating existing systems to create \nnew functionality and capabilities. Systems of systems are not designed in a top-down \nway. Rather, they are created when an organization recognizes that they can add value \nto existing systems by integrating these into a SoS. For example, a city government \nmight wish to reduce air pollution at particular hot-spots in the city. To do so, it might \nintegrate its traffic management system with a national real-time pollution monitoring \nsystems. This then allows for the traffic management system to alter its strategy to \nreduce pollution by changing traffic light sequences, speed limits and so on.\n", "page": 594, "type": "text", "section": "Page 594"}
{"text": "594\u2002 \u2002 Chapter 20\u2002 \u25a0\u2002 Systems of systems\nThe problems of software SoS engineering have much in common with the prob-\nlems of integrating large-scale application systems that I discussed in Chapter 15 \n(Boehm and Abts 1999). To recap, these were:\n1.\t\nLack of control over system functionality and performance.\n2.\t\nDiffering and incompatible assumptions made by the developers of the different \nsystems.\n3.\t\nDifferent evolution strategies and timetables for the different systems.\n4.\t\nLack of support from system owners when problems arise.\nMuch of the effort in building systems of software systems comes from address-\ning these problems. It involves deciding on the system architecture, developing soft-\nware interfaces that reconcile differences between the participating systems, and \nmaking the system resilient to unforeseen changes that may occur.\nSoftware systems of systems are large and complex entities, and the processes \nused for their development vary widely depending on the type of systems involved, \nthe application domain, and the needs of the organizations involved in developing \nthe SoS. However, as shown in Figure 20.6, five general activities are involved in \nSoS development processes:\n1.\t\nConceptual design I introduced the idea of conceptual design in Chapter 19, which \ncovers systems engineering. Conceptual design is the activity of creating a high-\nlevel vision for a system, defining essential requirements, and identifying constraints \non the overall system. In SoS engineering, an important input to the conceptual \ndesign process is knowledge of the existing systems that may participate in the SoS.\n2.\t System selection During this activity, a set of systems for inclusion in the SoS \nis chosen. This process is comparable to the process of choosing application \nConceptual\ndesign \nSystem\nselection\nArchitectural\ndesign \nInterface\ndevelopment \nIntegration and\ndeployment \nSystems\nknowledge\n Governance and management policy setting\nFigure 20.6\u2002 An SoS \nengineering process \n", "page": 595, "type": "text", "section": "Page 595"}
{"text": " \n20.4\u2002 \u25a0\u2002 Systems of systems engineering\u2002 \u2002 595\nsystems for reuse, covered in Chapter 15. You need to assess and evaluate exist-\ning systems to choose the capabilities that you need. When you are selecting \napplication systems, the selection criteria are largely commercial; that is, which \nsystems offer the most suitable functionality at a price you are \u00ad\nprepared to pay?\nHowever, political imperatives and issues of system governance and management \nare often the key factors that influence what systems are included in a SoS. For \nexample, some systems may be excluded from consideration because an organiza-\ntion does not wish to collaborate with a competitor. In other cases, organizations \nthat are contributing to a federation of systems may have systems in place and \ninsist that these are used, even though they are not necessarily the best systems.\n3.\t\nArchitectural design In parallel with system selection, an overall architecture \nfor the SoS has to be developed. Architectural design is a major topic in its own \nright that I cover in Section 20.5.\n4.\t\nInterface development The different systems involved in a SoS usually have \nincompatible interfaces. Therefore, a major part of the software engineering \neffort in developing a SoS is to develop interfaces so that constituent systems \ncan interoperate. This may also involve the development of a unified user inter-\nface so that SoS operators do not have to deal with multiple user interfaces as \nthey use the different systems in the SoS.\n5.\t\nIntegration and deployment This stage involves making the different systems \ninvolved in the SoS work together and interoperate through the developed inter-\nfaces. System deployment means putting the system into place in the organizations \nconcerned and making it operational.\nIn parallel with these technical activities, there needs to be a high-level activity \nconcerned with establishing policies for the governance of the system of systems and \ndefining management guidelines to implement these policies. Where there are several \norganizations involved, this process can be prolonged and difficult. It may involve \norganizations changing their own policies and processes. It is therefore important to \nstart governance discussions at an early stage in the SoS development process.\n\t\n20.4.1 \t Interface development\nThe constituent systems in a SoS are usually developed independently for some spe-\ncific purpose. Their user interface is tailored to that original purpose. These systems \nmay or may not have application programming interfaces (APIs) that allow other \nsystems to interface directly to them. Therefore, when these systems are integrated \ninto a SoS, software interfaces have to be developed, which allows the constituent \nsystems in the SoS to interoperate.\nIn general, the aim in SoS development is for systems to be able to communicate \ndirectly with each other without user intervention. If these systems already offer a \nservice-based interface, as discussed in Chapter 18, then this communication can be \nimplemented using this approach. Interface development involves describing how to \n", "page": 596, "type": "text", "section": "Page 596"}
{"text": "596\u2002 \u2002 Chapter 20\u2002 \u25a0\u2002 Systems of systems\nuse the interfaces to access the functionality of each system. The systems involved \ncan communicate directly with each other. System coalitions, where all of the sys-\ntems involved are peers, are likely to use this type of direct interaction as it does not \nrequire prearranged agreements on system communication protocols.\nMore commonly, however, the constituent systems in a SoS either have their own \nspecialized API or only allow their functionality to be accessed through their user \ninterfaces. You therefore have to develop software that reconciles the differences \nbetween these interfaces. It is best to implement these interfaces as service-based \ninterfaces, as shown in Figure 20.7 (Sillitto 2010).\nTo develop service-based interfaces, you have to examine the functionality of exist-\ning systems and define a set of services to reflect that functionality. The interface then \nprovides these services. The services are implemented either by calls to the underlying \nsystem API or by mimicking user interaction with the system. One of the systems in \nthe SoS is usually a principal or coordinating system that manages the interactions \nbetween the constituent systems. The principal system acts as a service broker, direct-\ning service calls between the different systems in the SoS. Each system therefore does \nnot need to know which other system is providing a called service.\nUser interfaces for each system in a SoS are likely to be different. The principal \nsystem must have some overall user interfaces that handle user authentication and \nprovide access to the features of the underlying system. However, it is usually \nexpensive and time consuming to implement a unified user interface to replace the \nindividual interfaces of the underlying systems.\nA unified user interface (UI) makes it easier for new users to learn to use the SoS \nand reduces the likelihood of user error. However, whether or not unified UI devel-\nopment is cost-effective depends on a number of factors:\n1.\t\nThe interaction assumptions of the systems in the SoS Some systems may have a \nprocess-driven model of interaction where the system controls the interface and \nprompts the user for inputs. Others may give control to the user, so that the user \nchooses the sequence of interactions with the system. It is practically impossible \nto unify different interaction models.\nSystem 3\nSystem 2\nSystem 1\nPrincipal\nsystem\nService interfaces\nUnified service\ninterface\nFigure 20.7\u2002 Systems \nwith service interfaces \n", "page": 597, "type": "text", "section": "Page 597"}
{"text": " \n20.4\u2002 \u25a0\u2002 Systems of systems engineering\u2002 \u2002 597\n2.\t\nThe mode of use of the SoS In many cases, SoS are used in such a way that most \nof the interactions of users at a site are with one of the constituent systems. They \nuse other systems only when additional information is required. For example, air \ntraffic controllers may normally use a radar system for flight information and only \naccess a flight plan database when additional information is required. A unified \ninterface is a bad idea in these situations because it would slow down interaction \nwith the most commonly used system. However, if the operators interact with all \nof the constituent systems, then a unified UI may be the best way forward.\n3.\t\nThe \u201copenness\u201d of the SoS If the SoS is open, so that new systems may be \nadded to it when it is in use, then unified UI development is impractical. It is \nimpossible to anticipate what the UI of new systems will be. Openness also \napplies to the organizations using the SoS. If new organizations can become \ninvolved, then they may have existing equipment and their own preferences for \nuser interaction. They may therefore prefer not to have a unified UI.\nIn practice, the limiting factor in UI unification is likely to be the budget and time \navailable for UI development. UI development is one of the most expensive systems \nengineering activities. In many cases, there is simply not enough project budget \navailable to pay for the creation of a unified SoS user interface.\n\t\n20.4.2 \t Integration and deployment\nSystem integration and deployment are usually separate activities. A system is inte-\ngrated from its components by an integration and testing team, validated, and then \nreleased for deployment. The components are managed so that changes are con-\ntrolled and the integration team can be confident that the required version is included \nin the system. However, for SoS, such an approach may not be possible. Some of the \ncomponent systems may already be deployed and in use, and the integration team \ncannot control changes to these systems.\nFor SoS, therefore, it makes sense to consider integration and deployment to be \npart of the same process. This approach reflects one of the design guidelines that I \ndiscuss in the following section, which is that an incomplete system of systems \nshould be usable and provide useful functionality. The integration \u00ad\nprocess should \nbegin with systems that are already deployed, with new systems added to the SoS to \nprovide coherent additions to the functionality of the overall system.\nIt often makes sense to plan the deployment of the SoS to reflect this, so that SoS \ndeployment takes place in a number of stages. For example, Figure 20.8 illustrates a \nthree-stage deployment process for the iLearn digital learning environment:\n1.\t\nThe initial deployment provides authentication, basic learning functionality, \nand integration with school administration systems.\n2.\t\nStage 2 of the deployment adds an integrated storage system and a set of more \nspecialized tools to support subject-specific learning. These tools might include \n", "page": 598, "type": "text", "section": "Page 598"}
{"text": "598\u2002 \u2002 Chapter 20\u2002 \u25a0\u2002 Systems of systems\narchives for history, simulation systems for science, and programming environ-\nments for computing.\n3.\t\nStage 3 adds features for user configuration and the ability of users to add new \nsystems to the iLearn environment. This stage allows different versions of the \nsystem to be created for different age groups, further specialized tools, and \nalternatives to the standard tools to be included.\nAs in any large systems engineering project, the most time-consuming and expen-\nsive part of system integration is system testing. Testing systems of systems is difficult \nand expensive for three reasons:\n1.\t\nThere may not be a detailed requirements specification that can be used as a \nbasis for system testing. It may not be cost-effective to develop a SoS require-\nments document because the details of the system functionality are defined by \nthe systems that are included.\n2.\t\nThe constituent systems may change in the course of the testing process, so tests \nmay not be repeatable.\n3.\t\nIf problems are discovered, it may not be possible to fix the problems by requir-\ning one or more of the constituent systems to be changed. Rather, some interme-\ndiate software may have to be introduced to solve the problem.\nTo help address some of these problems, I believe that SoS testing should take on \nboard some of the testing techniques developed in agile methods:\n1.\t\nAgile methods do not rely on having a complete system specification for system \nacceptance testing. Rather, stakeholders are closely engaged with the testing process \niLearn V1\nAuthentication system\nOffice 365\nWordpress\nSchool admin systems\nMoodle VLE\nLearning portfolio system\nConferencing system\niLearn V2\nAuthentication system\nProgramming\nenvironments\nDrawing and photo tools\nScience simulation systems\nStorage system\nContent systems \n(history, languages, etc.)\niLearn V1 tools\niLearn V3\nAuthentication system\niLearn V2 tools\nStorage system\nConfiguration system\nAge-specific tools\nGoogle Apps\nibook tools\nData analysis tools\nRelease timeline\nFigure 20.8\u2002 Release \nsequence For the  \niLearn SoS\n", "page": 599, "type": "text", "section": "Page 599"}
{"text": " \n20.5\u2002 \u25a0\u2002 Systems of systems architecture\u2002 \u2002 599\nand have the authority to decide when the overall system is acceptable. For SoS, a \nrange of stakeholders should be involved in the testing process if possible, and \nthey can comment on whether or not the system is ready for deployment.\n2.\t\nAgile methods make extensive use of automated testing. This makes it much \neasier to rerun tests to discover if unexpected system changes have caused prob-\nlems for the SoS as a whole.\nDepending on the type of system, you may have to plan the installation of equip-\nment and user training as part of the deployment process. If the system is being \ninstalled in a new environment, equipment installation is straightforward. However, \nif it is intended to replace an existing system, there may be problems in installing new \nequipment if it is not compatible with the equipment that is in use. There may not be \nthe physical space for the new equipment to be installed alongside the working sys-\ntem. There may be insufficient electrical power, or users may not have time to be \ninvolved because they are busy using the current system. These nontechnical issues \ncan delay the deployment process and slow down the adoption and use of the SoS.\n \n20.5  Systems of systems architecture\nPerhaps the most crucial activity of the systems of systems engineering process is \narchitectural design. Architectural design involves selecting the systems to be \nincluded in the SoS, assessing how these systems will interoperate, and designing \nmechanisms that facilitate interaction. Key decisions on data management, redun-\ndancy, and communications are made. In essence, the SoS architect is responsible \nfor realizing the vision set out in the conceptual design of the system. For organiza-\ntional and federated systems, in particular, decisions made at this stage are crucial to \nthe performance, resilience, and maintainability of the system of systems.\nMaier (Maier 1998) discusses four general principles for the architecting of com-\nplex systems of systems:\n1.\t\nDesign systems so that they can deliver value if they are incomplete. Where a \nsystem is composed of several other systems, it should not just be useful if all of \nits components are working properly. Rather, there should be several \u201cstable \nintermediate forms\u201d so that a partial system works and can do useful things.\n2.\t\nBe realistic about what can be controlled. The best performance from a SoS may be \nachieved when an individual or group exerts control over the overall system and its \nconstituents. If there is no control, then delivering value from the SoS is difficult. \nHowever, attempts to overcontrol the SoS are likely to lead to resistance from the \nindividual system owners and consequent delays in system deployment and evolution.\n3.\t\nFocus on the system interfaces. To build a successful system of systems, you \nhave to design interfaces so that the system elements can interoperate. It is \n", "page": 600, "type": "text", "section": "Page 600"}
{"text": "600\u2002 \u2002 Chapter 20\u2002 \u25a0\u2002 Systems of systems\nimportant that these interfaces are not too restrictive so that the system elements \ncan evolve and continue to be useful participants in the SoS.\n4.\t\nProvide collaboration incentives. When the system elements are independently \nowned and managed, it is important each system owner have incentives to continue \nto participate in the system. These may be financial incentives (pay per use or reduced \noperational costs), access incentives (you share your data and I\u2019ll share mine), or \ncommunity incentives (participate in a SoS and you get a say in the community).\nSillitto (Sillitto 2010) has added to these principles and suggests additional \nimportant design guidelines. These include the following:\n1.\t\nDesign a SoS as node and web architecture. Nodes are sociotechnical systems \nthat include data, software, hardware, infrastructure (technical components), \nand organizational policies, people, processes, and training (sociotechnical). \nThe web is not just the communications infrastructure between nodes, but it also \nprovides a mechanism for informal and formal social communications between \nthe people managing and running the systems at each node.\n2.\t\nSpecify behavior as services exchanged between nodes. The development of \nservice-oriented architectures now provides a standard mechanism for system \noperability. If a system does not already provide a service interface, then this \ninterface should be implemented as part of the SoS development process.\n3.\t\nUnderstand and manage system vulnerabilities. In any SoS, there will be unex-\npected failures and undesirable behavior. It is critically important to try to \nunderstand vulnerabilities and design the system to be resilient to such failures.\nThe key message that emerges from both Maier\u2019s and Sillitto\u2019s work is that SoS \narchitects have to take a broad perspective. They need to look at the system as a \nwhole, taking into account both technical and sociotechnical considerations. \nSometimes the best solution to a problem is not more software but changes to the \nrules and policies that govern the operation of the system.\nArchitectural frameworks such as MODAF (MOD 2008) and TOGAF (TOGAF \nis a registered trademark of The Open Group 2011) have been suggested as a means \nof supporting the architectural design of systems of systems. Architectural frame-\nworks were originally developed to support enterprise systems architectures, which \nare portfolios of separate systems. Enterprise systems may be organizational systems \nof systems, or they may have a simpler management structure so that the system \nportfolio can be managed as a whole. Architectural frameworks are intended for the \ndevelopment of organizational systems of systems where there is a single govern-\nance authority for the entire SoS.\nAn architectural framework recognizes that a single model of an architecture does \nnot present all of the information needed for architectural and business analysis. \nRather, frameworks propose a number of architectural views that should be created \nand maintained to describe and document enterprise systems. Frameworks have \nmuch in common and tend to reflect the language and history of the organizations \n", "page": 601, "type": "text", "section": "Page 601"}
{"text": " \n20.5\u2002 \u25a0\u2002 Systems of systems architecture\u2002 \u2002 601\ninvolved. For example, MODAF and DODAF are comparable frameworks from the \nUK Ministry of Defence (MOD) and the U.S. Department of Defense (DOD).\nThe TOGAF framework has been developed by the Open Group as an open stand-\nard and is intended to support the design of a business architecture, a data architec-\nture, an application architecture, and a technology architecture for an enterprise. At \nits heart is the Architecture Development Method (ADM), which consists of a num-\nber of discrete phases. These are shown in Figure 20.9, taken from the TOGAF refer-\nence documentation (Open Group 2011).\nAll architectural frameworks involve the production and management of a large \nset of architectural models. Each of the activities shown in Figure 20.8 leads to the \nproduction of system models. However, this is problematic for two reasons:\n1.\t\nInitial model development takes a long time and involves extensive negotiations \nbetween system stakeholders. This slows the development of the overall system.\n2.\t\nIt is time-consuming and expensive to maintain model consistency as changes \nare made to the organization and the constituent systems in a SoS.\nArchitecture frameworks are fundamentally reductionist, and they largely ignore \nsociotechnical and political issues. While they do recognize that problems are diffi-\ncult to define and are open-ended, they assume a degree of control and governance \nA.\nArchitecture\nvision\nB.\nBusiness\narchitecture\nC.\nInformation\nsystems \narchitectures\nD.\nTechnology\narchitecture\nE.\nOpportunities \nand solutions\nF.\nMigration\nplanning\nG.\nImplementation\ngovernance\nH.\nArchitecture\nchange\nmanagement\nRequirements\nmanagement\nPreliminary\nFigure 20.9\u2002 The TOGAF \narchitecture development \nmethod (TOGAF\u200a\n\u00ae  \nVersion 9.1, \u00a9 1999\u20132011. \nThe Open Group.) \n", "page": 602, "type": "text", "section": "Page 602"}
{"text": "602\u2002 \u2002 Chapter 20\u2002 \u25a0\u2002 Systems of systems\nthat is impossible to achieve in many systems of systems. They are a useful checklist \nto remind architects of things to think about in the architectural design process. \nHowever, I think that the overhead involved in model management and the reduction-\nist approach taken by frameworks limits their usefulness in SoS architectural design.\n\t\n20.5.1 \t Architectural patterns for systems of systems\nI have described architectural patterns for different types of system in Chapters 6, \n17, and 21. In short, an architectural pattern is a stylized architecture that can be \nrecognized across a range of different systems. Architectural patterns are a useful \nway of stimulating discussions about the most appropriate architecture for a system \nand for documenting and explaining the architectures used. This section covers a \nnumber of \u201ctypical\u201d patterns in systems of software systems. As with all architec-\ntural patterns, real systems are usually based on more than one of these patterns.\nThe notion of architectural patterns for systems of systems is still at an early stage \nof development. Kawalsky (Kawalsky et al. 2013) discusses the value of architec-\ntural patterns in understanding and supporting SoS design, with a focus on patterns \nfor command and control systems. I find that patterns are effective in illustrating \nSoS organization, without the need for detailed domain knowledge.\nSystems as data-feeds\nIn this architectural pattern (Figure 20.10), there is a principal system that requires \ndata of different types. This data is available from other systems, and the principal \nsystem queries these systems to get the data required. Generally, the systems that \nprovide data do not interact with each other. This pattern is often observed in organ-\nizational or federated systems where some governance mechanisms are in place.\nFor example, to license a vehicle in the UK, you need to have both valid insurance and \na roadworthiness certificate. When you interact with the vehicle licensing system, it inter-\nacts with two other systems to check that these documents are valid. These systems are:\n1.\t\nAn \u201cinsured vehicles\u201d system, which is a federated system run by car insurance \ncompanies that maintains information about all current car insurance policies.\nData feed 3\nData feed 1\nData feed 4\nData feed 2\nPrincipal\nsystem\nFigure 20.10\u2002 Systems \nas\u00a0data feeds \n", "page": 603, "type": "text", "section": "Page 603"}
{"text": " \n20.5\u2002 \u25a0\u2002 Systems of systems architecture\u2002 \u2002 603\n2.\t\nAn \u201cMOT certificate\u201d system, which is used to record all roadworthiness cer-\ntificates issued by testing agencies licensed by the government.\nThe \u201csystems as data feeds\u201d architecture is an appropriate architecture to use \nwhen it is possible to identify entities in a unique way and create relatively simple \nqueries about these entities. In the licensing system, vehicles can be uniquely identi-\nfied by their registration number. In other systems, it may be possible to identify \nentities such as pollution monitors by their GPS coordinates.\nA variant of the \u201csystems as data feeds\u201d architecture arises when a number of \nsystems provide data that are similar but not identical. Therefore, the architecture \nhas to include an intermediate layer as shown in Figure 20.11. The role of this \nintermediate layer is to translate the general query from the principal system into the \nspecific query required by the individual information system.\nFor example, the iLearn environment interacts with school administration systems \nfrom three different providers. All of these systems provide the same information about \nstudents (names, personal information, etc.) but have different interfaces. The databases \nhave different organizations, and the format of the data returned differs from one system \nto another. The unifying interface here detects where the user of the system is based \nand, using this regional information, knows which administrative system should be \naccessed. It then converts a standard query into the appropriate query for that system.\nProblems that can arise in systems that use this pattern are primarily interface \nproblems when the data feeds are unavailable or are slow to respond. It is important \nto ensure that timeouts are included in the system so that a failure of a data feed does \nnot compromise the response time of the system as a whole. Governance mecha-\nnisms should be in place to ensure that the format of provided data is not changed \nwithout the agreement of all system owners.\nSystems in a container\nSystems in a container are systems of systems where one of the systems acts as a \nvirtual container and provides a set of common services such as an authentication \nand a storage service. Conceptually, other systems are then placed into this container \nData feed 1\nData feed 3\nData feed 2\nPrincipal\nsystem\nData feed 1(a)\nData feed 1(b)\nData feed 1(c)\nFigure 20.11\u2002 Systems \nas data feeds with a \nunifying interface \n", "page": 604, "type": "text", "section": "Page 604"}
{"text": "604\u2002 \u2002 Chapter 20\u2002 \u25a0\u2002 Systems of systems\nto make their functionality accessible to system users. Figure 20.12 illustrates a con-\ntainer system with three common services and six included systems. The systems \nthat are included may be selected from an approved list of systems and need not be \naware that they are included in the container. This pattern of SoS is most often \nobserved in federated systems or system coalitions.\nThe iLearn environment is a system in a container. There are common services \nthat support authentication, storage of user data, and system configuration. Other \nfunctionality comes from choosing existing systems such as a newspaper archive or \na virtual learning environment and integrating these into the container.\nOf course, you don\u2019t place systems into a real container to implement these systems \nof systems. Rather, for each approved system, there is a separate interface that allows \nit to be integrated with the common services. This interface manages the translation of \nthe common services provided by the container and the requirements of the integrated \nsystem. It may also be possible to include systems that are not approved. However, \nthese will not have access to the common services provided by the container.\nFigure 20.13 illustrates this integration. This graphic is a simplified version of \niLearn that provides three common services:\n1.\t\nAn authentication service that provides a single sign-in to all approved systems. \nUsers do not have to maintain separate credentials for these systems.\n2.\t\nA storage service for user data. This service can be seamlessly transferred to and \nfrom approved systems.\n3.\t\nA configuration service that is used to include or remove systems from the container.\nThis example shows a version of iLearn for Physics. As well as an office productivity \nsystem (Office 365) and a VLE (Moodle), this system includes simulation and data anal-\nysis systems. Other systems\u2014YouTube and a science encyclopedia\u2014are also part of this \nsystem. However, these are not \u201capproved,\u201d and so no container interface is available. \nUsers must log on to these systems separately and organize their own data transfers.\nIncluded systems\nContainer system\nCommon service 1\nCommon service 2\nCommon service 3\ns1\ns2\ns3\ns4\ns5\ns6\nFigure 20.12\u2002 Systems in \na container \n", "page": 605, "type": "text", "section": "Page 605"}
{"text": " \n20.5\u2002 \u25a0\u2002 Systems of systems architecture\u2002 \u2002 605\nThere are two problems with this type of SoS architecture:\n1.\t\nA separate interface must be developed for each approved system so that com-\nmon services can be used with these systems. This means that only a relatively \nsmall number of approved systems can be supported.\n2.\t\nThe owners of the container system have no influence on the functionality and \nbehavior of the included systems. Systems may stop working, or they may be \nwithdrawn at any time.\nHowever, the main benefit of this architecture is that it allows for incremental \ndevelopment. An early version of the container system can be based on \u201cunap-\nproved\u201d systems. Interfaces to these can be developed in later versions so that they \nare more closely integrated with the container services.\nTrading systems\nTrading systems are systems of systems where there is no single principal system but \nprocessing may take place in any of the constituent systems. The systems involved \ntrade information among themselves. There may be one-to-one or one-to-many inter-\nactions between these systems. Each system publishes its own interface, but there may \nnot be any interface standards that are followed by all systems. This \u00ad\nsystem is shown \nin Figure 20.14. Trading systems may be federated systems or system coalitions.\nAn example of a trading SoS is a system of systems for algorithmic trading of \nstocks and shares. Brokers all have their own separate systems that can automati-\ncally buy and sell stock from other systems. They set prices and negotiate individu-\nally with these systems. Another example of a trading system is a travel aggregator \nthat shows price comparisons and allows travel to be booked directly by a user.\nThe Digital Learning Environment\nExternal interaction\nConfiguration\nStorage\nAuthentication\nYouTube\nScience\nencyclopedia\nMS Office \n365\nPhysics\nsimulator\nMoodle\nLab data\nanalyzer\nInterfaces\nFigure 20.13\u2002 The DLE \nas a container system \n", "page": 606, "type": "text", "section": "Page 606"}
{"text": "606\u2002 \u2002 Chapter 20\u2002 \u25a0\u2002 Systems of systems\nKey Points\n\u25a0\t Systems of systems are systems where two or more of the constituent systems are indepen-\ndently managed and governed.\n\u25a0\t Three types of complexity are important for systems of systems\u2014technical complexity, manage-\nrial complexity, and governance complexity.\n\u25a0\t System governance can be used as the basis for a classification scheme for SoS. This leads to \nthree classes of SoS, namely, organizational systems, federated systems, and system coalitions.\n\u25a0\t Reductionism as an engineering method breaks down because of the inherent complexity of \nsystems of systems. Reductionism assumes clear system boundaries, rational decision making, \nand well-defined problems. None of these are true for systems of systems.\n\u25a0\t The key stages of the SoS development process are conceptual design, system selection, archi-\ntectural design, interface development, and integration and deployment. Governance and man-\nagement policies must be designed in parallel with these activities.\nTrading systems may be developed for any type of marketplace, with the informa-\ntion exchanged being information about the goods being traded and their prices. \nAlthough trading systems are systems in their own right and could conceivably be \nused for individual trading, they are most useful in an automated trading context \nwhere the systems negotiate directly with each other.\nThe major problem with this type of system is that there is no governance mecha-\nnism, so any of the systems involved may change at any time. Because these changes \nmay contradict the assumptions made by other systems, trading cannot continue. \nSometimes the owners of the systems in the coalition wish to be able to continue \ntrading with other systems and so may make informal arrangements to ensure that \nchanges to one system do not make trading impossible. In other cases, such as a \ntravel aggregator, an airline may deliberately change its system so that it is unavail-\nable and so force bookings to be made directly with it.\nTrading \nsystem 1\nTrading \nsystem 2\nTrading \nsystem 3\nTrading \nsystem 4\nFigure 20.14\u2002 A trading \nsystem of systems \n", "page": 607, "type": "text", "section": "Page 607"}
{"text": "\u25a0\t Architectural patterns for systems of systems are a means of describing and discussing typical \narchitectures for SoS. Important patterns are systems as data feeds, systems in a container, and \ntrading systems.\nFurther Reading\n\u201cArchitecting Principles for Systems of Systems.\u201d A now-classic paper on systems of systems that \nintroduces a classification scheme for SoS, discusses its value, and proposes a number of architec-\ntural principles for SoS design. (M. Maier, Systems Engineering, 1 (4), 1998).\nUltra-large Scale Systems: The Software Challenge of the Future This book, produced for the U.S. \nDepartment of Defense in 2006, introduces the notion of ultra-large-scale systems, which are sys-\ntems of systems with hundreds of nodes. It discusses the issues and challenges in developing such \nsystems. (L. Northrop et al., Software Engineering Institute, 2006). http://www.sei.cmu.edu/library/\nassets/ULS_Book20062.pdf\n\u201cLarge-scale Complex IT Systems.\u201d This paper discusses the problems of large-scale complex IT  \nsystems that are systems of systems and expands on the ideas here on the breakdown of reductionism. \nIt proposes a number of research challenges in the area of SoS. (I. Sommerville et al., Communica-\ntions of the ACM, 55 (7), July 2012). http://dx.doi.org/ 10.1145/2209249.2209268\nWebsite\nPowerPoint slides for this chapter:\nwww.pearsonglobaleditions.com/Sommerville\nLinks to supporting videos:\nhttp://software-engineering-book.com/videos/systems-engineering/\nExercises\n20.1. \tExplain why managerial and operational independence are the key distinguishing characteris-\ntics of systems of systems when compared to other large, complex systems.\n20.2. \tBriefly explain any four essential characteristics of systems of systems.\n \nChapter 20\u2002 \u25a0\u2002 Exercises\u2002 \u2002 607\n", "page": 608, "type": "text", "section": "Page 608"}
{"text": "20.3. \tThe classification of SoS presented in Section 20.2 suggests a governance-based classifica-\ntion scheme. Giving reasons for your answer, identify the classifications for the following \n\u00ad\nsystems of systems:\n(a)\t A health care system that provides unified access to all patient health records from hospi-\ntals, clinics, and primary care.\n(b)\t The World Wide Web\n(c)\t A government system that provides access to a range of welfare services such as pen-\nsions, disability benefits, and unemployment benefits.\nAre there any problems with the suggested classification for any of these systems?\n20.4. \tExplain what is meant by reductionism and why it is effective as a basis for many kinds of \nengineering.\n20.5. \tDefine systems of systems engineering. List the problems of software SoS engineering that \nare also common to problems of integrating large-scale application systems.\n20.6. \tHow beneficial is a unified user interface in the interface design of SoS? What are the factors on \nwhich the cost-effectiveness of a unified user interface is dependent?\n20.7. \tSillitto suggests that communications between nodes in a SoS are not just technical but \nshould also include informal sociotechnical communications between the people involved in \nthe system. Using the iLearn SoS as an example, suggest where these informal communica-\ntions may be important to improve the effectiveness of the system.\n20.8. \tSuggest the closest-fit architectural pattern for the systems of systems introduced in Exer-\ncise 20.3.\n20.9. \t\u0007\nThe trading system pattern assumes that there is no central authority involved. However, in \nareas such as equity trading, trading systems must follow regulatory rules. Suggest how this \npattern might be modified to allow a regulator to check that these rules have been followed. \nThis should not involve all trades going through a central node.\n20.10.\t \u0007\nYou work for a software company that has developed a system that provides information \nabout consumers and that is used within a SoS by a number of other retail businesses. They \npay you for the services used. Discuss the ethics of changing the system interfaces without \nnotice to coerce users into paying higher charges. Consider this question from the point of \nview of the company\u2019s employees, customers, and shareholders.\nReferences\nBoehm, B., and C. Abts. 1999. \u201cCOTS Integration: Plug and Pray?\u201d Computer 32 (1): 135\u2013138. \ndoi:10.1109/2.738311.\nHitchins, D. 2009. \u201cSystem of Systems\u2014The Ultimate Tautology.\u201d http://www.hitchins.net/profs-\nstuff/profs-blog/system-of-systems---the.html\n608\u2002 \u2002 Chapter 20\u2002 \u25a0\u2002 Systems of systems\n", "page": 609, "type": "text", "section": "Page 609"}
{"text": "Kawalsky, R., D. Joannou, Y. Tian, and A. Fayoumi. 2013. \u201cUsing Architecture Patterns to Architect \nand Analyze Systems of Systems.\u201d In Conference on Systems Engineering Research (CSER 13),  \n283\u2013292. doi:10.1016/j.procs.2013.01.030.\nMaier, M. W. 1998. \u201cArchitecting Principles for Systems-of-Systems.\u201d Systems Engineering 1 (4): \n267\u2013284. doi:10.1002/(SICI)1520\u20136858(1998)1:4<267::AID-SYS3>3.0.CO;2-D.\nMOD, UK. 2008. \u201cMOD Architecture Framework.\u201d https://www.gov.uk/mod-architecture-framework\nNorthrop, Linda, R. P. Gabriel, M. Klein, and D. Schmidt. 2006. Ultra-Large-Scale Systems: The  \nSoftware Challenge of the Future. Pittsburgh: Software Engineering Institute. http://www.sei.cmu.\nedu/library/assets/ULS_Book20062.pdf\nOpen Group. 2011. \u201cOpen Group Standard TOGAF Version 9.1.\u201d http://pubs.opengroup.org/archi-\ntecture/togaf91-doc/arch/\nRittel, H., and M. Webber. 1973. \u201cDilemmas in a General Theory of Planning.\u201d Policy Sciences 4:  \n155\u2013169. doi:10.1007/BF01405730.\nRoyal Academy of Engineering. 2004. \u201cChallenges of Complex IT Projects.\u201d London. http://www.\nbcs.org/upload/pdf/complexity.pdf\nSillitto, H. 2010. \u201cDesign Principles for Ultra-Large-Scale Systems.\u201d In Proceedings of the 20th  \nInternational Council for Systems Engineering International Symposium. Chicago.\nSommerville, I., D. Cliff, R. Calinescu, J. Keen, T. Kelly, M. Kwiatkowska, J. McDermid, and R. Paige. \n2012. \u201cLarge-Scale Complex IT Systems.\u201d Comm. ACM 55 (7): 71\u201377. doi:10.1145/2209249.2209268.\nStevens, R. 2010. Engineering Mega-Systems: The Challenge of Systems Engineering in the \n\u00ad\nInformation Age. Boca Raton, FL: CRC Press.\n \nChapter 20\u2002 \u25a0\u2002 References\u2002 \u2002 609\n", "page": 610, "type": "text", "section": "Page 610"}
{"text": "Contents\n21.1\t Embedded systems design\n21.2\t Architectural patterns for real-time software\n21.3\t Timing analysis\n21.4\t Real-time operating systems\nObjectives\nThe objective of this chapter is to introduce some of the characteristic \nfeatures of embedded real-time software engineering. When you have \nread this chapter, you will:\n\u25a0\t understand the concept of embedded software, which is used to \ncontrol systems that react to external events in their environment;\n\u25a0\t have been introduced to a design process for real-time systems, \nwhere the software systems are organized as a set of cooperating \nprocesses;\n\u25a0\t understand three architectural patterns that are commonly used in \nembedded real-time systems design;\n\u25a0\t understand the organization of real-time operating systems and \nthe role that they play in an embedded, real-time system.\nReal-time software \nengineering\n21 \n", "page": 611, "type": "text", "section": "Page 611"}
{"text": " \nChapter 21\u2002 \u25a0\u2002 Real-time software engineering\u2002 \u2002 611\nComputers are used to control a wide range of systems from simple domestic \nmachines, through games controllers, to entire manufacturing plants. These comput-\ners interact directly with hardware devices. Their software must react to events \n\u00ad\ngenerated by the hardware and often issue control signals in response to these \nevents. These signals result in an action, such as the initiation of a phone call, the \nmovement of a character on the screen, the opening of a valve, or the display of the \nsystem status. The software in these systems is embedded in system hardware, often \nin read-only memory. It responds, in real time, to events from the system\u2019s environ-\nment. By real time, I mean that the software system has a deadline for responding to \nexternal events. If this deadline is missed, then the overall hardware\u2013software sys-\ntem will not operate correctly.\nEmbedded software is very important economically because almost every electri-\ncal device now includes software. There are therefore many more embedded software \nsystems than other types of software systems. Ebert and Jones (Ebert and Jones 2009) \nestimated that there were about 30 embedded microprocessor systems per person in \ndeveloped countries. This figure was increasing between 10% and 20% per year. This \nsuggests that, by 2020, there will be more than 100 embedded systems per person.\nResponsiveness in real time is the critical difference between embedded systems \nand other software systems, such as information systems, web-based systems, or per-\nsonal software systems, whose main purpose is data processing. For non\u2013real-time \nsystems, the correctness of a system can be defined by specifying how system inputs \nmap to corresponding outputs that should be produced by the system. In response to \nan input, a corresponding output should be generated by the system and, often, some \ndata should be stored. For example, if you choose a create command in a patient \ninformation system, then the correct system response is to create a new patient \nrecord in a database and to confirm that this has been done. Within reasonable limits, \nit does not matter how long this takes.\nHowever, in a real-time system, the correctness depends both on the response to \nan input and the time taken to generate that response. If the system takes too long to \nrespond, then the required response may be ineffective. For example, if embedded \nsoftware controlling a car\u2019s braking system is too slow, then an accident may occur \nbecause it is impossible to stop the car in time.\nTherefore, time is fundamental in the definition of a real-time software system:\nA real-time software system is a system whose correct operation depends on \nboth the results produced by the system and the time at which these results are \nproduced. A \u201csoft real-time system\u201d is a system whose operation is degraded \nif results are not produced according to the specified timing requirements. If \nresults are not produced according to the timing specification in a \u201chard real-\ntime system,\u201d this is considered to be a system failure.\nTimely response is an important factor in all embedded systems, but not all embedded \nsystems require a very fast response. For example, the insulin pump software that I have \nused as an example in several chapters of this book is an embedded system. However, \nwhile the system needs to check the glucose level at periodic intervals, it does not need to \n", "page": 612, "type": "text", "section": "Page 612"}
{"text": "612\u2002 \u2002 Chapter 21\u2002 \u25a0\u2002 Real-time software engineering\nrespond very quickly to external events. The wilderness weather station software is also \nan embedded system, but, again, it does not require a fast response to external events.\nAs well as the need for real-time response, there are other important differences \nbetween embedded systems and other types of software system:\n1.\t\nEmbedded systems generally run continuously and do not terminate. They start \nwhen the hardware is switched on, and execute until the hardware is switched \noff. Techniques for reliable software engineering, as discussed in Chapter 11, \nmay therefore have to be used to ensure continuous operation. The real-time \nsystem may include update mechanisms that support dynamic reconfiguration \nso that the system can be updated while it is in service.\n2.\t\nInteractions with the system\u2019s environment are unpredictable. In interactive sys-\ntems, the pace of the interaction is controlled by the system. By limiting user \noptions, the events and commands to be processed are known in advance. By \ncontrast, real-time embedded systems must be able to respond to expected and \nunexpected events at any time. This leads to a design for real-time systems \nbased on concurrency, with several processes executing in parallel.\n3.\t\nPhysical limitations may affect the design of a system. Examples of limitations \ninclude restrictions on the power available to the system and the physical space \ntaken up by the hardware. These limitations may generate requirements for the \nembedded software, such as the need to conserve power and so prolong battery life. \nSize and weight limitations may mean that the software has to take over some hard-\nware functions because of the need to limit the number of chips used in the system.\n4.\t\nDirect hardware interaction may be necessary. In interactive systems and infor-\nmation systems, a layer of software (the device drivers) hides the hardware from \nthe operating system. This is possible because you can only connect a few types \nof device to these systems, such as keyboards, mice, and displays. By contrast, \nembedded systems may have to interact with a wide range of hardware devices \nthat do not have separate device drivers.\n5.\t\nIssues of safety and reliability may dominate the system design. Many embed-\nded systems control devices whose failure may have high human or economic \ncosts. Therefore, dependability is critical, and the system design has to ensure \nsafety-critical behavior at all times. This often leads to a conservative approach \nto design where tried and tested techniques are used instead of newer techniques \nthat may introduce new failure modes.\nReal-time embedded systems can be thought of as reactive systems; that is, they \nmust react to events in their environment (Berry 1989; Lee 2002). Response times \nare often governed by the laws of physics rather than chosen for human conveni-\nence. This is in contrast to other types of software where the system controls the \nspeed of the interaction. For example, the word processor that I am using to write \nthis book can check spelling and grammar, and there are no practical limits on the \ntime taken to do so.\n", "page": 613, "type": "text", "section": "Page 613"}
{"text": " \n21.1 \u2002 \u25a0\u2002 Embedded system design\u2002 \u2002 613\n \n21.1  Embedded system design\nDuring the design process for embedded software, software designers have to consider in \ndetail the design and performance of the system hardware. Part of the system design \nprocess may involve deciding which system capabilities are to be implemented in soft-\nware and which in hardware. For many real-time systems that are embedded in consumer \nproducts, such as the systems in cell phones, the costs and power consumption of the \nhardware are critical. Specific processors designed to support embedded systems may be \nused. For some systems, special-purpose hardware may have to be designed and built.\nA top-down software design process, in which the design starts with an abstract \nmodel that is decomposed and developed in a series of stages, is impractical for most \nreal-time systems. Low-level decisions on hardware, support software, and system \ntiming must be considered early in the process. These limit the flexibility of system \ndesigners. Additional software functionality, such as battery and power manage-\nment, may have to be included in the system.\nGiven that embedded systems are reactive systems that react to events in their \nenvironment, the most general approach to embedded, real-time software design is \nbased on a stimulus-response model. A stimulus is an event occurring in the soft-\nware system\u2019s environment that causes the system to react in some way; a response \nis a signal or message that the software sends to its environment.\nYou can define the behavior of a real-time system by listing the stimuli received \nby the system, the associated responses, and the time at which the response must be \nproduced. For example, Figure 21.1 shows possible stimuli and system responses for \na burglar alarm system (discussed in Section 21.2.1).\nStimuli fall into two classes:\n1.\t\nPeriodic stimuli These occur at predictable time intervals. For example, the sys-\ntem may examine a sensor every 50 milliseconds and take action (respond) \ndepending on that sensor value (the stimulus).\n2.\t\nAperiodic stimuli These occur irregularly and unpredictably and are usually sig-\nnaled, using the computer\u2019s interrupt mechanism. An example of such a stimulus \nwould be an interrupt indicating that an I/O transfer was complete and that data \nwas available in a buffer.\nStimuli come from sensors in the system\u2019s environment, and responses are sent to \nactuators, as shown in Figure 21.2. These actuators control equipment, such as a \npump, which then makes changes to the system\u2019s environment. The actuators them-\nselves may also generate stimuli. The stimuli from actuators often indicate that some \nproblem with the actuator has occurred, which must be handled by the system.\nA general design guideline for real-time systems is to have separate control pro-\ncesses for each type of sensor and actuator (Figure 21.3). For each type of sensor, \nthere may be a sensor management process that handles data collection from these \nsensors. Data-processing processes compute the required responses for the stimuli \nreceived by the system. Actuator control processes are associated with each actuator \n", "page": 614, "type": "text", "section": "Page 614"}
{"text": "614\u2002 \u2002 Chapter 21\u2002 \u25a0\u2002 Real-time software engineering\nand manage the operation of that actuator. This model allows data to be collected \nquickly from the sensor (before it is overwritten by the next input) and enables pro-\ncessing and the associated actuator response to be carried out later.\nA real-time system has to respond to stimuli that occur at different times. You \ntherefore have to organize the system architecture so that, as soon as a stimulus is \nreceived, control is transferred to the correct handler. This is impractical in sequen-\ntial programs. Consequently, real-time software systems are normally designed as a \nset of concurrent, cooperating processes. To support the management of these pro-\ncesses, the execution platform on which the real-time system executes may include a \nreal-time operating system (discussed in Section 21.4). The functions provided by \nthis operating system are accessed through the runtime support system for the real-\ntime programming language that is used.\nThere is no standard embedded system design process. Rather, different processes \nare used that depend on the type of system, available hardware, and the organization \nthat is developing the system. The following activities may be included in a real-\ntime software design process:\n1.\t\nPlatform selection In this activity, you choose an execution platform for the \nsystem, that is, the hardware and the real-time operating system to be used. \nFactors that influence these choices include the timing constraints on the sys-\ntem, limitations on power available, the experience of the development team, \nand the price target for the delivered system.\n2.\t\nStimuli/response identification This involves identifying the stimuli that the \nsystem must process and the associated response or responses for each stimulus.\nStimulus\nResponse\nClear alarms\nSwitch off all active alarms; switch off all lights \nthat have been switched on.\nConsole panic button positive\nInitiate alarm; turn on lights around console; call \npolice.\nPower supply failure\nCall service technician.\nSensor failure\nCall service technician.\nSingle sensor positive\nInitiate alarm; turn on lights around site of \npositive sensor.\nTwo or more sensors positive\nInitiate alarm; turn on lights around sites of \npositive sensors; call police with location of \nsuspected break-in.\nVoltage drop of between 10% \nand 20%\nSwitch to battery backup; run power supply test.\nVoltage drop of more than \n20%\nSwitch to battery backup; initiate alarm; call \npolice, run power supply test.\nFigure 21.1\u2002 Stimuli  \nand responses for a \nburglar alarm system\n", "page": 615, "type": "text", "section": "Page 615"}
{"text": " \n21.1 \u2002 \u25a0\u2002 Embedded system design\u2002 \u2002 615\nReal-time\ncontrol system\nActuator\nActuator\nActuator\nActuator\nSensor\nSensor\nSensor\nSensor\nSensor\nSensor\nStimuli\nResponses\nFigure 21.2\u2002 A general \nmodel of an embedded \nreal-time system \n3.\t\nTiming analysis For each stimulus and associated response, you identify the \ntiming constraints that apply to both stimulus and response processing. These \nconstraints are used to establish the deadlines for the processes in the system.\n4.\t\nProcess design Process design involves aggregating the stimulus and response \nprocessing into a number of concurrent processes. A good starting point for \ndesigning the process architecture is the architectural patterns that I describe in \nSection 20.2. You then optimize the process architecture to reflect the specific \nrequirements that you have to implement.\n5.\t\nAlgorithm design For each stimulus and response, you design algorithms to \ncarry out the required computations. Algorithm designs may have to be devel-\noped relatively early in the design process to indicate the amount of processing \nrequired and the time needed to complete that processing. This is especially \nimportant for computationally intensive tasks, such as signal processing.\n6.\t\nData design You specify the information that is exchanged by processes and the \nevents that coordinate information exchange, and design data structures to man-\nage this information exchange. Several concurrent processes may share these \ndata structures.\n7.\t\nProcess scheduling You design a scheduling system that will ensure that pro-\ncesses are started in time to meet their deadlines.\nThe specific activities and the activity sequence in a real-time system design pro-\ncess depend on the type of system being developed, its novelty, and its environment. \n \nData\nprocessor\nActuator\ncontrol\nActuator\nSensor\ncontrol\nSensor\nStimulus\nResponse\nFigure 21.3\u2002 Sensor and \nactuator processes \n", "page": 616, "type": "text", "section": "Page 616"}
{"text": "616\u2002 \u2002 Chapter 21\u2002 \u25a0\u2002 Real-time software engineering\nIn some cases, for new systems, you may be able to follow a fairly abstract approach \nwhere you start with the stimuli and associated processing, and decide on the hardware \nand execution platforms late in the process. In other cases, the choice of hardware and \noperating system is made before the software design starts. You then have to design \nthe software to take account of the constraints imposed by the system hardware.\nProcesses in a real-time system have to be coordinated and share information. \nProcess coordination mechanisms ensure mutual exclusion to shared resources. When \none process is modifying a shared resource, other processes should not be able to change \nthat resource. Mechanisms for ensuring mutual exclusion include semaphores, moni-\ntors, and critical regions. These process synchronization mechanisms are described in \nmost operating system books (Silberschaltz, Galvin, and Gagne 2013; Stallings 2014).\nWhen designing the information exchange between processes, you have to take \ninto account that these processes may be running at different speeds. One process is \nproducing information, and the other process is consuming that information. If the \nproducer is running faster than the consumer, new information could overwrite a \npreviously read information item before the consumer process has read the original \ninformation. If the consumer process is running faster than the producer process, the \nsame item could be read twice.\nTo avoid this problem, you should implement information exchange using a \nshared buffer and use mutual exclusion mechanisms to control access to that buffer. \nThis means that information can\u2019t be overwritten before it has been read and that \ninformation cannot be read twice. Figure 21.4 illustrates the organization of a shared \nbuffer. This is usually implemented as a circular queue, using a list data structure. \nMismatches in speed between the producer and consumer processes can be accom-\nmodated without having to delay process execution.\nThe producer process always enters data in the buffer location at the end of the \nqueue (represented as v10 in Figure 21.4). The consumer process always retrieves \ninformation from the head of the queue (represented as v1 in Figure 21.4). After the \nconsumer process has retrieved the information, the tail of the queue is adjusted to \npoint at the next item (v2). After the producer process has added information, the tail \nof the queue is adjusted to point at the next free slot in the queue.\nConsumer\nprocess\nProducer\nprocess\nCircular Buffer\nHead\nTail\nv1\nv2\nv3\nv4\nv5\nv6\nv7\nv8\nv9\nv10\nFigure 21.4\u2002 Producer/\nconsumer processes \nsharing a circular buffer\u00a0\n", "page": 617, "type": "text", "section": "Page 617"}
{"text": " \n21.1 \u2002 \u25a0\u2002 Embedded system design\u2002 \u2002 617\nObviously, it is important to ensure that the producer and consumer process do \nnot attempt to access the same item at the same time (i.e., when Head = Tail). If they \ndo, the value of the item is unpredictable. The system also has to ensure that the \nproducer process does not add items to a full buffer and that the consumer process \ndoes not try to take items from an empty buffer.\nTo do this, you implement the circular buffer as a process with Get and Put oper\u00ad\nations to access the buffer. The Put operation is called by the producer process and \nthe Get operation by the consumer process. Synchronization primitives, such as \nsemaphores or critical regions, are used to ensure that the operation of Get and Put \nare synchronized, so that they don\u2019t access the same location simultaneously. If the \nbuffer is full, the Put process has to wait until a slot is free; if the buffer is empty, the \nGet process has to wait until an entry has been made.\nOnce you have chosen the execution platform for the system, designed a process \narchitecture, and decided on a scheduling policy, you have to check that the system \nwill meet its timing requirements. You can perform this check through static analysis \nof the system using knowledge of the timing behavior of components, or through \nsimulation. This analysis may reveal that the system will not perform adequately. The \nprocess architecture, the scheduling policy, the execution platform, or all of these \nmay then have to be redesigned to improve the performance of the system.\nTiming constraints or other requirements may sometimes mean that it is best to \nimplement some system functions, such as signal processing, in hardware. Modern \nhardware components, such as FPGAs (field-programmable gate arrays), are flexible \nand can be adapted to different functions. Hardware components deliver much better \nperformance than the equivalent software. System processing bottlenecks can be \nidentified and replaced by hardware, thus avoiding expensive software optimization.\n\t\n21.1.1 \t Real-time system modeling\nThe events that a real-time system must react to often cause the system to move from \none state to another. For this reason, state models, which I introduced in Chapter 5, \nare used to describe real-time systems. A state model of a system assumes that, at \nany time, the system is in one of a number of possible states. When a stimulus is \nreceived, this may cause a transition to a different state. For example, a system con-\ntrolling a valve may move from a state \u201cValve open\u201d to a state \u201cValve closed\u201d when \nan operator command (the stimulus) is received.\nState models are an integral part of real-time system design methods. The UML \nsupports the development of state models based on Statecharts (Harel 1987, 1988). \nStatecharts are formal state machine models that support hierarchical states, so that \ngroups of states can be considered as a single entity. Douglass discusses the use of \nthe UML in real-time systems development (Douglass 1999).\nI have already illustrated this approach to system modeling in Chapter 5 where I \nused an example of a model of a simple microwave oven. Figure 21.5 is another \nexample of a state model that shows the operation of a fuel delivery software system \nembedded in a petrol (gas) pump. The rounded rectangles represent system states, \nand the arrows represent stimuli that force a transition from one state to another. \n", "page": 618, "type": "text", "section": "Page 618"}
{"text": "618\u2002 \u2002 Chapter 21\u2002 \u25a0\u2002 Real-time software engineering\nThe names chosen in the state machine diagram are descriptive. The associated \ninformation indicates actions taken by the system actuators or information that is \ndisplayed. Notice that this system never terminates but idles in a waiting state when \nthe pump is not operating.\nThe fuel delivery system is designed to allow unattended operation, with the fol-\nlowing sequence of actions:\n1.\t\nThe buyer inserts a credit card into a card reader built into the pump. This causes \na transition to a Reading state where the card details are read and the buyer is \nthen asked to remove the card.\n2.\t\nRemoval of the card triggers a transition to a Validating state where the card is \nvalidated.\n3.\t\nIf the card is valid, the system initializes the pump and, when the fuel hose is \nremoved from its holster, transitions to the Delivering state, where is ready to \ndeliver fuel. Activating the trigger on the nozzle causes fuel to be pumped; this \nstops when the trigger is released (for simplicity, I have ignored the pressure \nswitch that is designed to stop fuel spillage).\nCard\ninserted\ninto reader\nTimeout\nResetting\ndo: display CC\nerror\nInitializing\ndo: initialize\ndisplay\nPaying\nStopped\nReading\ndo: get CC\ndetails\nWaiting\ndo: display\n     welcome\ndo:\ndeliver fuel\ndo: debit\nCC account\nPayment ack.\nReady\nDelivering\nupdate display\nNozzle\ntrigger on\nNozzle trigger off\nNozzle trigger on\nHose in\nholster\ndo: validate\ncredit card\nValidating\nInvalid card\nCard removed\nCard OK\nHose out of holster\nHose in\nholster\nTimeout\nFigure 21.5\u2002 State \nmachine model of a \npetrol (gas) pump \n", "page": 619, "type": "text", "section": "Page 619"}
{"text": " \n21.1 \u2002 \u25a0\u2002 Embedded system design\u2002 \u2002 619\n4.\t\nAfter the fuel delivery is complete and the buyer has replaced the hose in its \nholster, the system moves to a Paying state where the user\u2019s account is debited.\n5.\t\nAfter payment, the pump software returns to the Waiting state.\nState models are used in model-driven engineering, which I discussed in Chapter 5, \nto define the operation of a system. They can be transformed automatically or semiau-\ntomatically to an executable program.\n\t\n21.1.2 \t Real-time programming\nProgramming languages for real-time systems development have to include facilities \nto access system hardware, and it should be possible to predict the timing of particu-\nlar operations in these languages. Hard real-time systems, running on limited hard-\nware, are still sometimes programmed in assembly language so that tight deadlines \ncan be met. Systems programming languages, such as C, which allow efficient code \nto be generated, are widely used.\nThe advantage of using a systems programming language like C is that it allows \nthe development of efficient programs. However, these languages do not include \nconstructs to support concurrency or the management of shared resources. \nConcurrency and resource management are implemented through calls to primitives \nprovided by the real-time operating system for mutual exclusion. Because the com-\npiler cannot check these calls, programming errors are more likely. Programs are \nalso often more difficult to understand because the language does not include real-\ntime features. As well as understanding the program, the reader also has to know \nhow real-time support is provided using system calls.\nBecause real-time systems must meet their timing constraints, you may not be \nable to use object-oriented development for hard real-time systems. Object-oriented \ndevelopment involves hiding data representations and accessing attribute values \nthrough operations defined with the object. There is a significant performance over-\nhead in object-oriented systems because extra code is required to mediate access to \nattributes and handle calls to operations. The consequent loss of performance may \nmake it impossible to meet real-time deadlines.\nA version of Java has been developed for embedded systems development (Burns \nand Wellings 2009; Bruno and Bollella 2009). This language includes a modified \nthread mechanism, which allows threads to be specified that will not be interrupted \nReal-time Java\nThe Java programming language has been modified to make it suitable for real-time systems development. \nThese modifications include asynchronous communications, the addition of time, including absolute and \n\u00ad\nrelative time, a new thread model where threads cannot be interrupted by garbage collection, and a new \n\u00ad\nmemory management model that avoids the unpredictable delays that can result from garbage collection.\nhttp://software-engineering-book.com/web/real-time-java/\n", "page": 620, "type": "text", "section": "Page 620"}
{"text": "620\u2002 \u2002 Chapter 21\u2002 \u25a0\u2002 Real-time software engineering\nby the language garbage collection mechanism. Asynchronous event handling and \ntiming specification has also been included. However, at the time of writing, this \nspecification has mostly been used on platforms that have significant processor and \nmemory capacity (e.g., a cell phone) rather than simpler embedded systems, with \nmore limited resources. These systems are still usually implemented in C.\n \n21.2  Architectural patterns for real-time software\nArchitectural patterns are abstract, stylized descriptions of good design practice. \nThey capture knowledge about the organization of system architectures, when these \narchitectures should be used, and their advantages and disadvantages. You use an \narchitectural pattern to understand an architecture and as starting point for creating \nyour own, specific architectural design.\nThe difference between real-time and interactive software means that there are \ndistinct architectural patterns for real-time embedded systems. Real-time systems\u2019 \npatterns are process-oriented rather than object- or component-oriented. In this sec-\ntion, I discuss three real-time architectural patterns that are commonly used:\n1.\t\nObserve and React This pattern is used when a set of sensors are routinely monitored \nand displayed. When the sensors show that some event has occurred (e.g., an incom-\ning call on a cell phone), the system reacts by initiating a process to handle that event.\n2.\t\nEnvironmental Control This pattern is used when a system includes sensors, \nwhich provide information about the environment and actuators that can change \nthe environment. In response to environmental changes detected by the sensor, \ncontrol signals are sent to the system actuators.\n3.\t\nProcess Pipeline This pattern is used when data has to be transformed from one \nrepresentation to another before it can be processed. The transformation is \nimplemented as a sequence of processing steps, which may be carried out con-\ncurrently. This allows for very fast data processing, because a separate core or \nprocessor can execute each transformation.\nThese patterns can of course be combined, and you will often see more than one of \nthem in a single system. For example, when the Environmental Control pattern is \nused, it is very common for the actuators to be monitored using the Observe and React \npattern. In the event of an actuator failure, the system may react by displaying a warn-\ning message, shutting down the actuator, switching in a backup system, and so forth.\nThe patterns that I cover are architectural patterns that describe the overall struc-\nture of an embedded system. Douglass (Douglass 2002) describes lower-level, real-\ntime design patterns that support more detailed design decision making. These \npatterns include design patterns for execution control, communications, resource \nallocation, and safety and reliability.\n", "page": 621, "type": "text", "section": "Page 621"}
{"text": " \n21.2\u2002 \u25a0\u2002 Architectural patterns for real-time software\u2002 \u2002 621\nThese architectural patterns should be the starting point for an embedded systems \ndesign; however, they are not design templates. If you use them as such, you will \nprobably end up with an inefficient process architecture. You have to optimize the \nprocess structure to ensure that you do not have too many processes. You also should \nensure that there is a clear correspondence between the processes and the sensors \nand actuators in the system.\n\t\n21.2.1 \t Observe and react\nMonitoring systems are an important class of embedded real-time systems. A moni-\ntoring system examines its environment through a set of sensors and usually displays \nthe state of the environment in some way. This could be on a built-in screen, on \nspecial-purpose instrument displays, or on a remote display. If the system detects \nsome exceptional event or sensor state, the monitoring system takes some action. \nName\nObserve and React\nDescription\nThe input values of a set of sensors of the same types are \ncollected and analyzed. These values are displayed in some \nway. If the sensor values indicate that some exceptional \ncondition has arisen, then actions are initiated to draw the \noperator\u2019s attention to that value and, if necessary, take actions \nin response to the exceptional value.\nStimuli\nValues from sensors attached to the system.\nResponses\nOutputs to display, alarm triggers, signals to reacting systems.\nProcesses\nObserver, Analysis, Display, Alarm, Reactor.\nUsed in\nMonitoring systems, alarm systems.\nFigure 21.6\u2002 The \nObserve and React \npattern\nAnalysis\nprocess\nObserver\nprocess\nReactor process\nAlarm\nprocess\nSensor\nvalues\nDisplay\nprocess\nDisplay\nvalues\nDisplay\nSensors\nAlarm\nOther equipment\nFigure 21.7\u2002 The \nObserve and React \nprocess structure \n", "page": 622, "type": "text", "section": "Page 622"}
{"text": "622\u2002 \u2002 Chapter 21\u2002 \u25a0\u2002 Real-time software engineering\nThis often involves raising an alarm to draw an operator\u2019s attention to the event. \nSometimes the system may initiate some other preventative action, such as shutting \ndown the system to preserve it from damage.\nThe Observe and React pattern (Figures 21.6 and 21.7) is commonly used in \nmonitoring systems. The values of sensors are observed, and the system initiates \nactions that depend on these sensor values. Monitoring systems may be composed of \nseveral instantiations of the Observe and React pattern, one for each type of sensor \nin the system. Depending on the system requirements, you may then optimize the \ndesign by combining processes (e.g., you may use a single display process to display \nthe information from all of the different types of sensor).\nAs an example of the use of this pattern, consider the design of a burglar alarm \nsystem to be installed in an office building:\nA software system is to be implemented as part of a burglar alarm system for \ncommercial buildings. This uses several different types of sensors. These sen-\nsors include movement detectors in individual rooms, door sensors that detect \ncorridor doors opening, and window sensors on ground-floor windows that \ncan detect when a window has been opened.\nWhen a sensor detects the presence of an intruder, the system automatically calls \nthe local police and, using a\u200a\n voice synthesizer, reports the location of the alarm. \nIt switches on lights in the rooms around the active sensor and sets off an audible \nalarm. The sensor system is normally powered by mains power but is equipped \nwith a battery backup. Power loss is detected using a separate power circuit \nmonitor that monitors the mains voltage. If a voltage drop is detected, the system \nassumes that intruders have interrupted the power supply, so an alarm is raised.\nA process architecture for the alarm system is shown in Figure 21.8. The arrows \nrepresent signals sent from one process to another. This system is a \u201csoft\u201d real-time \nsystem that does not have stringent timing requirements. The sensors only need to detect \nLighting control\nprocess\nExternal alert\nprocess\nVoltage monitor\nprocess\nSystem\ncontroller\nConsole display\nprocess\nDoor sensor\nprocess\nMovement\ndetector process\nWindow sensor\nprocess\nAudible alarm\nprocess\nControl panel\nprocess\nTesting process\nPower management\nprocess\nFigure 21.8\u2002 The process \nstructure of a burglar \nalarm system \n", "page": 623, "type": "text", "section": "Page 623"}
{"text": " \n21.2\u2002 \u25a0\u2002 Architectural patterns for real-time software\u2002 \u2002 623\nthe presence of people rather than high-speed events, so they only need to be polled 2 or \n3 times per second. I cover the timing requirements for this system in Section 21.3.\nI have already introduced the stimuli and responses in this alarm system in Figure \n21.1. These responses are used as a starting point for the system design. The Observe \nand React pattern is used in this design. There are observer processes associated with \neach type of sensor and reactor processes for each type of reaction. A single analysis \nprocess checks the data from all of the sensors. The display processes in the pattern \nare combined into a single display process.\n\t\n21.2.2 \t Environmental Control\nThe most widespread use of real-time embedded software is in control systems. In \nthese systems, the software controls the operation of equipment, based on stimuli \nName\nEnvironmental Control\nDescription\nThe system analyzes information from a set of sensors that \ncollect data from the system\u2019s environment. Further \ninformation may also be collected on the state of the \nactuators that are connected to the system. Based on the \ndata from the sensors and actuators, control signals are \nsent to the actuators, which then cause changes to the \nsystem\u2019s environment. Information about the sensor values \nand the state of the actuators may be displayed.\nStimuli\nValues from sensors attached to the system and the state \nof the system actuators.\nResponses\nControl signals to actuators display information.\nProcesses\nMonitor, Control, Display, Actuator driver, Actuator monitor.\nUsed in\nControl systems.\nFigure 21.9\u2002 The \nEnvironmental  \nControl pattern\nControl\nprocess\nMonitor\nprocess\nActuator monitor\nprocess\nActuator\ndriver process\nSensor\nvalues\nDisplay\nprocess\nDisplay\nvalues\nDisplay\nSensors\nActuator\nControl\ninstructions\nActuator\nstate\nFigure 21.10\u2002  \nThe Environmental \nControl process \nstructure \n", "page": 624, "type": "text", "section": "Page 624"}
{"text": "624\u2002 \u2002 Chapter 21\u2002 \u25a0\u2002 Real-time software engineering\nfrom the equipment\u2019s environment. For example, an anti-skid braking system in a \ncar monitors the car\u2019s wheels and brake system (the system\u2019s environment). It looks \nfor signs that the wheels are skidding when brake pressure is applied. If this is the \ncase, the system adjusts the brake pressure to stop the wheels locking and reduce the \nlikelihood of a skid.\nControl systems may make use of the Environmental Control pattern, which is a \ngeneral control pattern that includes sensor and actuator processes. This pattern is \ndescribed in Figure 21.9, with the process architecture shown in Figure 21.10. A \nvariant of this pattern leaves out the display process. This variant is used in situa-\ntions where user intervention is not required or where the rate of control is so high \nthat a display would not be meaningful.\nThis pattern can be the basis for a control system design with an instantiation \nof the Environmental Control pattern for each actuator (or actuator type) being \ncontrolled. You then optimize the design to reduce the number of processes. For \nexample, you may combine actuator monitoring and actuator control processes, \nor you may have a single monitoring and control process for several actuators. \nThe optimizations that you choose depend on the timing requirements. You may \nneed to monitor sensors more frequently than you send control signals, in which \ncase it may be impractical to combine control and monitoring processes. There \nmay also be direct feedback between the actuator control and the actuator moni-\ntoring process. This allows fine-grain control decisions to be made by the actua-\ntor control process.\nYou can see how this pattern is used in Figure 21.11, which shows an example of a \ncontroller for a car braking system. The starting point for the design is associating an \ninstance of the pattern with each actuator type in the system. In this case, there are four \nactuators, with each controlling the brake on one wheel. The individual sensor processes \nare combined into a single wheel-monitoring process that monitors the sensors on all \nAnalysis\nprocess\nWheel\nmonitor\nPedal\nmonitor\nBrake 4\nprocess\nBrake 1\nprocess\nBrake 2\nprocess\nBrake 3\nprocess\nBrake 1\nBrake 2\nBrake 3\nBrake 4\nPedal pressure sensor\nWheel sensors\nFigure 21.11\u2002 Control \nsystem architecture  \nfor an anti-skid  \nbraking system \n", "page": 625, "type": "text", "section": "Page 625"}
{"text": " \n21.2\u2002 \u25a0\u2002 Architectural patterns for real-time software\u2002 \u2002 625\nwheels. This monitors the state of each wheel to check if the wheel is turning or locked. \nA separate process monitors the pressure on the brake pedal exerted by the car driver.\nThe system includes an anti-skid feature, which is triggered if the sensors indicate \nthat a wheel is locked when the brake has been applied. This means that there is \ninsufficient friction between the road and the tire; in other words, the car is skidding. \nIf the wheel is locked, the driver cannot steer that wheel. To counteract this effect, \nthe system sends a rapid sequence of on/off signals to the brake on that wheel, which \nallows the wheel to turn and control to be regained.\nThe Wheel monitor process monitors whether or not each wheel is turning. If a \nwheel is skidding (not turning), it informs the Analysis process. This then signals the \nprocesses associated with the wheels that are skidding to initiate anti-skid braking.\n\t\n21.2.3 \t Process pipeline\nMany real-time systems are concerned with collecting analog data from the system\u2019s \nenvironment. They then digitize that data for analysis and processing by the system. \nThe system may also convert digital data to analog data, which it then sends to its \nenvironment. For example, a software radio accepts incoming packets of digital data \nrepresenting the radio transmission and transforms the data into a sound signal that \npeople can listen to.\nThe data processing involved in many of these systems has to be carried out very \nquickly. Otherwise, incoming data may be lost and outgoing signals may be broken \nup because essential information is missing. The Process Pipeline pattern makes \nthis rapid processing possible by breaking down the required data processing into a \nsequence of separate transformations. Each of these transformations is implemented \nName\nProcess Pipeline\nDescription\nA pipeline of processes is set up with data moving in sequence \nfrom one end of the pipeline to another. The processes are often \nlinked by synchronized buffers to allow the producer and \nconsumer processes to run at different speeds. The culmination \nof a pipeline may be display or data storage, or the pipeline may \nterminate in an actuator.\nStimuli\nInput values from the environment or some other process\nResponses\nOutput values to the environment or a shared buffer\nProcesses\nProducer, Buffer, Consumer\nUsed in\nData acquisition systems, multi-media systems\nFigure 21.12\u2002  \nThe Process  \nPipeline pattern\nBuffer\nprocess\nProducer\nprocess\nProduced\ndata\nConsumer\nprocess\nConsumed\ndata\n...\nFigure 21.13\u2002 Process \nPipeline process \nstructure \n", "page": 626, "type": "text", "section": "Page 626"}
{"text": "626\u2002 \u2002 Chapter 21\u2002 \u25a0\u2002 Real-time software engineering\nby an independent process. This architecture is efficient for systems that use multi-\nple processors or multicore processors. Each process in the pipeline can be associ-\nated with a separate processor or core, so that the processing steps can be carried \nout in parallel.\nFigure 21.12 is a brief description of the data pipeline pattern, and Figure 21.13 \nshows the process architecture for this pattern. Notice that the processes involved \nproduce and consume information. The processes exchange information using \n\u00ad\nsynchronized buffers, as I explained in Section 21.1. Producer and consumer pro-\ncesses can thereby operate at different speeds without data losses.\nAn example of a system that may use a process pipeline is a high-speed data \nacquisition system. Data acquisition systems collect data from sensors for subse-\nquent processing and analysis. These systems are used in situations where the sen-\nsors are collecting large volumes of data from the system\u2019s environment and it isn\u2019t \npossible or necessary to process that data in real time. Rather, it is collected and \nstored for later analysis. Data acquisition systems are often used in scientific experi-\nments and process control systems where physical processes, such as chemical reac-\ntions, are very rapid. In these systems, the sensors may be generating data very \nquickly, and the data acquisition system has to ensure that a sensor reading is col-\nlected before the sensor value changes.\nFigure 21.14 is a simplified model of a data acquisition system that might be part \nof the control software in a nuclear reactor. This system collects data from sensors \nmonitoring the neutron flux (the density of neutrons) in the reactor. The sensor data \nis placed in a buffer from which it is extracted and processed. The average flux level \nis displayed on an operator\u2019s display and stored for future processing.\n \n21.3  Timing analysis\nAs I discussed in the introduction to this chapter, the correctness of a real-time sys-\ntem depends not just on the correctness of its outputs but also on the time at which \nthese outputs were produced. Therefore, timing analysis is an important activity in \nthe embedded, real-time software development process. In such an analysis, you cal-\nculate how often each process in the system must be executed to ensure that all inputs \nFlux value\nbuffer\nFlux\nprocessing\nRaw data\nbuffer\nA-D\nconvertor\nSensor\nidentifier and\nflux value\nProcessed\nflux level\nNeutron flux sensors\nStorage\nDisplay\nFigure 21.14\u2002 Neutron \nflux data acquisition \n", "page": 627, "type": "text", "section": "Page 627"}
{"text": " \n21.3\u2002 \u25a0\u2002 Timing analysis\u2002 \u2002 627\nare processed and all system responses are produced in a timely way. The results of \nthe timing analysis are used to decide how frequently each process should execute \nand how these processes should be scheduled by the real-time operating system.\nTiming analysis for real-time systems is particularly difficult when the system \nhas to deal with a mixture of periodic and aperiodic stimuli and responses. \nBecause aperiodic stimuli are unpredictable, you have to make assumptions about \nthe probability of these stimuli occurring and therefore requiring service at any \nparticular time. These assumptions may be incorrect, and system performance \nafter delivery may not be adequate. Cooling\u2019s book (Cooling 2003) discusses \ntechniques for real-time system performance analysis that takes aperiodic events \ninto account.\nAs computers have become faster, it has become possible in many systems to \ndesign using only periodic stimuli. When processors were slow, aperiodic stimuli \nhad to be used to ensure that critical events were processed before their deadline, \nas delays in processing usually involved some loss to the system. For example, \nthe failure of a power supply in an embedded system may mean that the system \nhas to shut down attached equipment in a controlled way, within a very short \ntime (say 50 milliseconds). This could be implemented as a \u201cpower fail\u201d inter-\nrupt. However, it can also be implemented using a periodic process that runs \nfrequently and checks the power. As long as the time between process invoca-\ntions is short, there is still time to perform a controlled shutdown of the system \nbefore the lack of power causes damage. For this reason, I only discuss timing \nissues for periodic processes.\nWhen you are analyzing the timing requirements of embedded real-time systems and \ndesigning systems to meet these requirements, you have to consider three key factors:\n1.\t\nDeadlines The times by which stimuli must be processed and some response \nproduced by the system. If the system does not meet a deadline, then, if it is a \nhard real-time system, this is a system failure; in a soft real-time system, it \nresults in degraded system service.\n2.\t\nFrequency The number of times per second that a process must execute so that \nyou are confident that it can always meet its deadlines.\n3.\t\nExecution time The time required to process a stimulus and produce a response. \nExecution time is not always the same because of the conditional execution of \ncode, delays waiting for other processes, and so on. Therefore, you may have to \nconsider both the average execution time of a process and the worst-case execu-\ntion time for that process. The worst-case execution time is the maximum time \nthat the process takes to execute. In a hard real-time system, you may have to \nmake assumptions based on the worst-case execution time to ensure that dead-\nlines are not missed. In soft real-time systems, you can base your calculations on \nthe average execution time.\nTo continue the example of a power supply failure, let\u2019s calculate the worst-\ncase execution time for a process that switches equipment power from mains \n", "page": 628, "type": "text", "section": "Page 628"}
{"text": "628\u2002 \u2002 Chapter 21\u2002 \u25a0\u2002 Real-time software engineering\npower to a battery backup. Figure 21.15 presents a timeline showing the events in \nthe system:\n1.\t Assume that, after a mains power failure event, it takes 50 milliseconds (ms) \nfor the supplied voltage to drop to a level where the equipment may be dam-\naged. The battery backup must therefore be activated and in operation within \n50 ms. Usually, you allow for a margin of error, so you should set a shorter \ndeadline of 40 ms because of physical variations in the equipment. This \nmeans that all equipment must be running on the battery backup power sup-\nply within 40 ms.\n2.\t\nHowever, the battery backup system cannot be instantaneously activated. It \ntakes 16 ms from starting the backup power supply to the supply being fully \noperational. This means that the time available to detect the power failure and \nstart the battery backup system is 24 ms.\n3.\t\nThere is a process that is scheduled to run 250 times per second, that is, every 4 ms. \nThis process assumes that there is a power supply problem if a significant drop \nin voltage occurs between readings and is sustained for three readings. This time \nis allowed so that temporary fluctuations do not cause a switch to the battery \nbackup system.\n4.\t\nIn the above timeline, the power fails immediately after a reading has been \ntaken. Therefore, reading R1 is the start reading for the power fail check. The \nvoltage continues to drop for readings R2\u2013R4, so a power failure is assumed. \nThis is the worst possible case, where a power failure event occurs immediately \nafter a sensor check, so 16 ms have elapsed since that event.\n5.\t\nAt this stage, the process that switches to the battery backup is started. Because \nthe battery backup takes 16 ms to become operational, the worst-case execution \ntime for this process is 8 ms, so that the 40 ms deadline can be reached.\n4ms\n8ms\n12ms\n16ms\n20ms\n24ms\n28ms\n32ms\n36ms\n40ms\nR1\nR2\nR3\nR4\nBattery startup\nPower switcher\nNormal voltage\nlevel\nCritical voltage\nlevel\nTime\nVoltage\nFigure 21.15\u2002  \nPower failure timing \nanalysis \n", "page": 629, "type": "text", "section": "Page 629"}
{"text": " \n21.3\u2002 \u25a0\u2002 Timing analysis\u2002 \u2002 629\nThe starting point for timing analysis in a real-time system is the timing require-\nments, which should set out the deadlines for each required response in the system. \nFigure 21.16 shows possible timing requirements for the office building burglar \nalarm system discussed in Section 21.2.1. To simplify this example, let us ignore \nstimuli generated by system testing procedures and external signals to reset the sys-\ntem in the event of a false alarm. This means there are only two types of stimulus \nprocessed by the system:\n1.\t\nPower failure is detected by observing a voltage drop of more than 20%. The \nrequired response is to switch the circuit to backup power by signaling an elec-\ntronic power-switching device that switches the mains power to battery backup.\n2.\t\nIntruder alarm is a stimulus generated by one of the system sensors. The \nresponse to this stimulus is to compute the room number of the active sensor, set \nup a call to the police, initiate the voice synthesizer to manage the call, and \nswitch on the audible intruder alarm and building lights in the area.\nAs shown in Figure 21.16, you should list the timing constraints for each class of \nsensor separately, even when (as in this case) they are the same. By considering \nthem separately, you leave scope for future change and make it easier to compute the \nnumber of times the controlling process has to be executed each second.\nAllocating the system functions to concurrent processes is the next design stage. \nFour types of sensors must be polled periodically, each with an associated process: \nthe voltage sensor, door sensors, window sensors, and movement detectors. \nNormally, the processes associated with the sensor will execute very quickly as all \nStimulus/Response\nTiming requirements\nAudible alarm\nThe audible alarm should be switched on within half a \nsecond of an alarm being raised by a sensor.\nCommunications\nThe call to the police should be started within \n2\u00a0seconds of an alarm being raised by a sensor.\nDoor alarm\nEach door alarm should be polled twice per second.\nLights switch\nThe lights should be switched on within half a second \nof an alarm being raised by a sensor.\nMovement detector\nEach movement detector should be polled twice per \nsecond.\nPower failure\nThe switch to backup power must be completed within \na deadline of 50 ms.\nVoice synthesizer\nA synthesized message should be available within \n2\u00a0seconds of an alarm being raised by a sensor.\nWindow alarm\nEach window alarm should be polled twice per second.\nFigure 21.16\u2002  \nTiming requirements  \nfor the burglar  \nalarm system\n", "page": 630, "type": "text", "section": "Page 630"}
{"text": "630\u2002 \u2002 Chapter 21\u2002 \u25a0\u2002 Real-time software engineering\nthey are doing is checking whether or not a sensor has changed its status (e.g., from \noff to on). It is reasonable to assume that the execution time to check and assess the \nstate of one sensor is less than 1 millisecond.\nTo ensure that you meet the deadlines defined by the timing requirements, you \nthen have to decide how frequently the related processes have to run and how many \nsensors should be examined during each execution of the process. There are obvious \ntrade-offs here between frequency and execution time:\n1.\t\nThe deadline for detecting a change of state is 0.25 second, which means that \neach sensor has to be checked 4 times per second. If you examine one sensor \nduring each process execution, then if there are N sensors of a particular type, \nyou must schedule the process 4N times per second to ensure that all sensors are \nchecked within the deadline.\n2.\t\nIf you examine four sensors, say, during each process execution, then the execu-\ntion time is increased to about 4 ms, but you need only run the process N times/\nsecond to meet the timing requirement.\nIn this case, because the system requirements define actions when two or more \nsensors are positive, the best strategy is to examine sensors in groups, with groups \nbased on the physical proximity of the sensors. If an intruder has entered the build-\ning, then it will probably be adjacent sensors that are positive.\nWhen you have completed the timing analysis, you may then annotate the process \nmodel with information about frequency of execution and their expected execution \ntime (see Figure 21.17). Here, periodic processes are annotated with their frequency, \nprocesses that are started in response to a stimulus are annotated with R, and the test-\ning process is a background process, annotated with B. This background process \nLighting control\nprocess\nExternal alert\nprocess\nVoltage monitor\nprocess\nSystem\ncontroller\nConsole display\nprocess\nDoor sensor\nprocess\nMovement\ndetector process\nWindow sensor\nprocess\nAudible alarm\nprocess\nControl panel\nprocess\nTesting process\nPower management\nprocess\n50 Hz (0.5 ms)\n50 Hz (1 ms)\n50 Hz (0.5 ms)\n250 Hz (0.5 ms)\n250 Hz\n(1 ms)\nB\n50 Hz (0.5 ms)\n50 Hz (1 ms)\nR (20 ms)\nR (10 ms)\nR (5 ms)\nR (5 ms)\nFigure 21.17\u2002  \nAlarm process timing \n", "page": 631, "type": "text", "section": "Page 631"}
{"text": " \n21.4\u2002 \u25a0\u2002 Real-time operating systems\u2002 \u2002 631\nonly runs when processor time is available. In general, it is simpler to design a sys-\ntem so that there are a small number of process frequencies. The execution times \nrepresent the required worst-case execution times of the processes.\nThe final step in the design process is to design a scheduling system that will \nensure that a process will always be scheduled to meet its deadlines. You can only do \nthis if you know the scheduling approaches that are supported by the real-time oper-\nating system (OS) used (Burns and Wellings 2009). The scheduler in the real-time \nOS allocates a process to a processor for a given amount of time. The time can be \nfixed, or it may vary depending on the priority of the process.\nIn allocating process priorities, you have to consider the deadlines of each process so \nthat processes with short deadlines receive processor time to meet these deadlines. For \nexample, the voltage monitor process in the burglar alarm needs to be scheduled so that \nvoltage drops can be detected and a switch made to backup power before the system \nfails. This should therefore have a higher priority than the processes that check sensor \nvalues, as these have fairly relaxed deadlines compared to their expected execution time.\n \n21.4  Real-time operating systems\nThe execution platform for most application systems is an operating system that \nmanages shared resources and provides features such as a file system and runtime \nprocess management. However, the extensive functionality in a conventional operat-\ning system takes up a great deal of space and slows down the operation of programs. \nFurthermore, the process management features in the system may not be designed to \nallow fine-grain control over the scheduling of processes.\nFor these reasons, standard operating systems, such as Linux and Windows, are not \nnormally used as the execution platform for real-time systems. Very simple embedded \nsystems may be implemented as \u201cbare metal\u201d systems. The systems provide their own \nexecution support and so include system startup and shutdown, process and resource \nmanagement, and process scheduling. More commonly, however, embedded applica-\ntions are built on top of a real-time operating system (RTOS), which is an efficient \noperating system that offers the features needed by real-time systems. Examples of \nRTOS are Windows Embedded Compact, VxWorks, and RTLinux.\nA real-time operating system manages processes and resource allocation for a \nreal-time system. It starts and stops processes so that stimuli can be handled, and it \nallocates memory and processor resources. The components of an RTOS (Figure \n21.18) depend on the size and complexity of the real-time system being developed. \nFor all except the simplest systems, they usually include:\n1.\t\nA real-time clock, which provides the information required to schedule pro-\ncesses periodically.\n2.\t\nIf interrupts are supported, an interrupt handler, which manages aperiodic \nrequests for service.\n", "page": 632, "type": "text", "section": "Page 632"}
{"text": "632\u2002 \u2002 Chapter 21\u2002 \u25a0\u2002 Real-time software engineering\n3.\t\nA scheduler, which is responsible for examining the processes that can be exe-\ncuted and for choosing one of these processes for execution.\n4.\t\nA resource manager, which allocates appropriate memory and processor \nresources to processes that have been scheduled for execution.\n5.\t\nA dispatcher, which is responsible for starting the execution of processes.\nReal-time operating systems for large systems, such as process control or telecom-\nmunication systems, may have additional facilities, namely, disk storage management, \nfault management facilities that detect and report system faults, and a configuration \nmanager that supports the dynamic reconfiguration of real-time applications.\n\t\n21.4.1 \t Process management\nReal-time systems have to handle external events quickly and, in some cases, meet \ndeadlines for processing these events. The event-handling processes must therefore \nbe scheduled for execution in time to detect the event. They must also be allocated \nsufficient processor resources to meet their deadline. The process manager in an \nRTOS is responsible for choosing processes for execution, allocating processor and \nmemory resources, and starting and stopping process execution on a processor.\nProcess resource\nrequirements\nScheduler\nScheduling\ninformation\nResource\nmanager\nDispatcher\nReal-time\nclock\nProcesses\nawaiting\nresources\nReady\nlist\nInterrupt\nhandler\nAvailable\nresource\nlist\nProcessor\nlist\nExecuting process\nReady\nprocesses\nReleased\nresources\nFigure 21.18\u2002  \nComponents of a  \nreal-time operating  \nsystem \n", "page": 633, "type": "text", "section": "Page 633"}
{"text": " \n21.4\u2002 \u25a0\u2002 Real-time operating systems\u2002 \u2002 633\nThe process manager has to manage processes with different priorities. For \nsome stimuli, such as those associated with certain exceptional events, it is essen-\ntial that their processing should be completed within the specified time limits. \nOther processes may be safely delayed if a more critical process requires service. \nConsequently, the RTOS has to be able to manage at least two priority levels for \nsystem processes:\n1.\t\nClock level This level of priority is allocated to periodic processes.\n2.\t\nInterrupt level This is the highest priority level. It is allocated to processes that \nneed a very fast response. One of these processes will be the real-time clock \nprocess. This process is not required if interrupts are not supported in the system.\nA further priority level may be allocated to background processes (such as a self-\nchecking process) that do not need to meet real-time deadlines. These processes are \nscheduled for execution when processor capacity is available.\nPeriodic processes must be executed at specified time intervals for data acquisition \nand actuator control. In most real-time systems, there will be several types of periodic \nprocess. Using the timing requirements specified in the application program, the RTOS \narranges the execution of periodic processes so that they can all meet their deadlines.\nThe actions taken by the operating system for periodic process management are \nshown in Figure 21.19. The scheduler examines the list of periodic processes and \nselects a process to be executed. The choice depends on the process priority, the \nprocess periods, the expected execution times, and the deadlines of the ready pro-\ncesses. Sometimes two processes with different deadlines should be executed at the \nsame clock tick. In such a situation, one process must be delayed. Normally, the \nsystem will choose to delay the process with the longest deadline.\nProcesses that have to respond quickly to asynchronous events may be interrupt-\ndriven. The computer\u2019s interrupt mechanism causes control to transfer to a prede-\ntermined memory location. This location contains an instruction to jump to a \nsimple and fast interrupt service routine. The service routine disables further inter-\nrupts to avoid being interrupted itself. It then discovers the cause of the interrupt \nand initiates, with a high priority, a process to handle the stimulus causing the \ninterrupt. In some high-speed data acquisition systems, the interrupt handler saves \nthe data that the interrupt signaled was available in a buffer for later processing. \nInterrupts are then enabled again, and control is returned to the operating system.\nResource manager\nAllocate memory\nand processor\nScheduler\nChoose process\nfor execution\nDispatcher\nStart execution on an\navailable processor\nProcess queue\nMemory map\nProcessor list\nReady list\nFigure 21.19\u2002 RTOS \nactions required  \nto start a process \n", "page": 634, "type": "text", "section": "Page 634"}
{"text": "634\u2002 \u2002 Chapter 21\u2002 \u25a0\u2002 Real-time software engineering\nAt any one time several processes, all with different priorities, could be executed. \nThe process scheduler implements system-scheduling policies that determine the \norder of process execution. There are two commonly used scheduling strategies:\n1.\t\nNonpreemptive scheduling After a process has been scheduled for execution, it \nruns to completion or until it is blocked for some reason, such as waiting for \ninput. This can cause problems if there are processes with different priorities \nand a high-priority process has to wait for a low-priority process to finish.\n2.\t\nPreemptive scheduling The execution of an executing process may be stopped if \na higher-priority process requires service. The higher-priority process preempts \nthe execution of the lower-priority process and is allocated to a processor.\nWithin these strategies, different scheduling algorithms have been developed. \nThese include round-robin scheduling, where each process is executed in turn; rate \nmonotonic scheduling, where the process with the shortest period (highest fre-\nquency) is given priority; and shortest deadline first scheduling, where the process in \nthe queue with the shortest deadline is scheduled (Burns and Wellings 2009).\nInformation about the process to be executed is passed to the resource manager. \nThe resource manager allocates memory and, in a multiprocessor system, also adds \na processor to this process. The process is then placed on the \u201cready list,\u201d a list of \nprocesses that are ready for execution. When a processor finishes executing a pro-\ncess and becomes available, the dispatcher is invoked. It scans the ready list to find \na process that can be executed on the available processor and starts its execution.\nKey Points\n\u25a0 An embedded software system is part of a hardware/software system that reacts to events in \nits\u00a0environment. The software is \u201cembedded\u201d in the hardware. Embedded systems are normally \nreal-time systems.\n\u25a0 A real-time system is a software system that must respond to events in real time. System \n\u00ad\ncorrectness does not just depend on the results it produces, but also on the time when these \nresults are produced.\n\u25a0 Real-time systems are usually implemented as a set of communicating processes that react to \nstimuli to produce responses.\n\u25a0 State models are an important design representation for embedded real-time systems. They are used \nto show how the system reacts to its environment as events trigger changes of state in the system.\n\u25a0 Several standard patterns can be observed in different types of embedded system. These \ninclude a pattern for monitoring the system\u2019s environment for adverse events, a pattern for \n\u00ad\nactuator control, and a data-processing pattern.\n", "page": 635, "type": "text", "section": "Page 635"}
{"text": "\u25a0\t Designers of real-time systems have to do a timing analysis, which is driven by the deadlines for \nprocessing and responding to stimuli. They have to decide how often each process in the system \nshould run and the expected and worst-case execution time for processes.\n\u25a0\t A real-time operating system is responsible for process and resource management. It always \nincludes a scheduler, which is the component responsible for deciding which process should be \nscheduled for execution.\nFurther Reading\nReal-time Systems and Programming Language: Ada, Real-time Java and C/Real-time POSIX, 4th ed. \nAn excellent and comprehensive text that provides broad coverage of all aspects of real-time sys-\ntems. (A. Burns and A. Wellings, Addison-Wesley, 2009).\n\u201cTrends in Embedded Software Engineering.\u201d This article suggests that model-driven development \n(as discussed in Chapter 5 of this book) will become an important approach to embedded systems \ndevelopment. This is part of a special issue on embedded systems, and other articles, such as the \none by Ebert and Jones, are also useful reading. (IEEE Software, 26 (3), May\u2013June 2009). http://dx.\ndoi.org/10.1109/MS.2009.80\nReal-time systems: Design Principles for Distributed Embedded Applications, 2nd ed. This is a com-\nprehensive textbook on modern real-time systems that may be distributed and mobile systems. The \nauthor focuses on hard real-time systems and covers important topics such as Internet connectivity \nand power management. (H. Kopetz, Springer, 2013).\nWebsite\nPowerPoint slides for this chapter:\nwww.pearsonglobaleditions.com/Sommerville\nLinks to supporting videos:\nhttp://software-engineering-book.com/videos/systems-engineering/\nExercises\n21.1. \tExplain why responsiveness in real time is the critical difference between embedded sys-\ntems and other software systems.\n21.2. \tIdentify possible stimuli and the expected responses for an embedded system that controls a \nhome refrigerator or a domestic washing machine.\n21.3. \tUsing the state-based approach to modeling, as discussed in Section 21.1.1, model the \n\u00ad\noperation of the embedded software for a voicemail system that is included in a landline phone. \n \nChapter 21\u2002 \u25a0\u2002 Exercises\u2002 \u2002 635\n", "page": 636, "type": "text", "section": "Page 636"}
{"text": "This should display the number of recorded messages on an LED display and should allow the \nuser to dial-in and listen to the recorded messages.\n21.4. \tWhat are the commonly used architectural patterns in real-time systems and when are they \nused?\n21.5. \tShow how the Environmental Control pattern could be used as the basis of the design of a \nsystem to control the temperature in a greenhouse. The temperature should be between 10 \nand 30 degrees Celsius. If it falls below 10 degrees, the heating system should be switched \non; if it goes above 30, the windows should be automatically opened.\n21.6. \t\nDesign a process architecture for an environmental monitoring system that collects data \nfrom a set of air quality sensors situated around a city. There are 5000 sensors organized \ninto 100 neighborhoods. Each sensor must be interrogated four times per second. When \nmore than 30% of the sensors in a particular neighborhood indicate that the air quality is \nbelow an acceptable level, local warning lights are activated. All sensors return the read-\nings to a central computer, which generates reports every 15 minutes on the air quality in \nthe city.\n21.7. \tA train protection system automatically applies the brakes of a train if the speed limit for a \nsegment of track is exceeded or if the train enters a track segment that is currently signaled \nwith a red light (i.e., the segment should not be entered). Details are shown in Figure 21.20. \nIdentify the stimuli that must be processed by the on-board train control system and the \n\u00ad\nassociated responses to these stimuli.\nTrain protection system\n\u2022\u2002 \u0007\nThe system acquires information on the speed limit of a segment from a trackside transmitter, which  \ncontinually broadcasts the segment identifier and its speed limit. The same transmitter also broadcasts  \ninformation on the status of the signal controlling that track segment. The time required to broadcast track \nsegment and signal information is 50 ms.\n\u2022\u2002 \u0007\nThe train can receive information from the trackside transmitter when it is within 10 m of a transmitter.\n\u2022\u2002 The maximum train speed is 180 kph.\n\u2022\u2002 \u0007\nSensors on the train provide information about the current train speed (updated every 250 ms) and the train \nbrake status (updated every 100 ms).\n\u2022\u2002 \u0007\nIf the train speed exceeds the current segment speed limit by more than 5 kph, a warning is sounded in the \ndriver\u2019s cabin. If the train speed exceeds the current segment speed limit by more than 10 kph, the train\u2019s \nbrakes are automatically applied until the speed falls to the segment speed limit. Train brakes should be \napplied within 100 ms of the time when the excessive train speed has been detected.\n\u2022\u2002 \u0007\nIf the train enters a track segment that is signaled with a red light, the train protection system applies the train \nbrakes and reduces the speed to zero. Train brakes should be applied within 100 ms of the time when the red \nlight signal is received.\n\u2022\u2002 The system continually updates a status display in the driver\u2019s cabin.\nFigure 21.20\u2002  \nRequirements for  \na train protection  \nsystem\n636\u2002 \u2002 Chapter 21\u2002 \u25a0\u2002 Real-time software engineering\n", "page": 637, "type": "text", "section": "Page 637"}
{"text": "21.8. \tSuggest a possible process architecture for this system.\n21.9. \tIf a periodic process in the on-board train protection system is used to collect data from the \ntrackside transmitter, how often must it be scheduled to ensure that the system is guaranteed \nto collect information from the transmitter? Explain how you arrived at your answer.\n21.10.\t \u0007\nWith the help of examples, define what a real-time operating system is. Explain how it is \n\u00ad\ndifferent from a conventional operating system. What are the components included in real-time \noperating systems and what are their responsibilities?\nReferences\nBerry, G. 1989. \u201cReal-Time Programming: Special-Purpose or General-Purpose Languages.\u201d In  \nInformation Processing, edited by G. Ritter, 89:11\u201317. Amsterdam: Elsevier Science Publishers.\nBruno, E. J., and G. Bollella. 2009. Real-Time Java Programming: With Java RTS. Boston: Prentice-Hall.\nBurns, A., and A. Wellings. 2009. Real-Time Systems and Programming Languages: Ada, Real-Time \nJava and C/Real-Time POSIX. Boston: Addison-Wesley.\nCooling, J. 2003. Software Engineering for Real-Time Systems. Harlow, UK: Addison-Wesley.\nDouglass, B. P. 1999. Real-Time UML: Developing Efficient Objects for Embedded Systems, 2nd ed. \nBoston: Addison-Wesley.\n\u2013\u2013\u2013\u2013\u2013\u2013. 2002. Real-Time Design Patterns: Robust Scalable Architecture for Real-Time Systems. \n\u00ad\nBoston: Addison-Wesley.\nEbert, C., and C. Jones. 2009. \u201cEmbedded Software: Facts, Figures and Future.\u201d IEEE Computer 26 (3): \n42\u201352. doi:10.1109/MC.2009.118.\nHarel, D. 1987. \u201cStatecharts: A Visual Formalism for Complex Systems.\u201d Sci. Comput. Programming 8 \n(3): 231\u2013274. doi:10.1016/0167-6423(87)90035-9.\n\u2013\u2013\u2013\u2013\u2013\u2013. 1988. \u201cOn Visual Formalisms.\u201d Comm. ACM 31 (5): 514\u2013530. doi:10.1145/42411.42414.\nLee, E A. 2002. \u201cEmbedded Software.\u201d In Advances in Computers, edited by M. Zelkowitz. Vol. 56. \nLondon: Academic Press.\nSilberschaltz, A., P. B. Galvin, and G. Gagne. 2013. Operating System Concepts, 9th ed. New York: \nJohn Wiley & Sons.\nStallings, W. 2014. Operating Systems: Internals and Design Principles, 8th ed. Boston: Prentice-Hall.\n \nChapter 21\u2002 \u25a0\u2002 References\u2002 \u2002 637\n", "page": 638, "type": "text", "section": "Page 638"}
{"text": "This page intentionally left blank\n", "page": 639, "type": "text", "section": "Page 639"}
{"text": "PART \nIt is sometimes suggested that the key difference between software engi-\nneering and other types of programming is that software engineering is \na managed process. By this, I mean that the software development takes \nplace within an organization and is subject to a range of schedule, budget \nand organizational constraints. I introduce a range of management topics in \nthis part of the book with a focus on technical management issues rather \nthan \u2018softer\u2019 management issues such as people management, or the more \nstrategic management of enterprise systems.\nChapters 22 and 23 focus on the essential project management activities, \nplanning, risk management and people management. Chapter 22 intro-\nduces software project management and its first major section is con-\ncerned with risk management where managers identify what might go \nwrong and plan what they might do about it. This chapter also includes \nsections on people management and team working.\nChapter 23 covers project planning and estimation. I introduce bar charts \nas fundamental planning tools and explain why plan-driven development \nwill remain an important development approach, in spite of the success \nof agile methods. I also discuss issues that influence the price charged \nfor a system and techniques of software cost estimation. I use the \nCOCOMO family of cost models to describe algorithmic cost modeling \nand explain the benefits and disadvantages of algorithmic approaches.\n4 \nSoftware \nManagement\n", "page": 640, "type": "text", "section": "Page 640"}
{"text": "Chapters 24 explains the basics of software quality management, as \npractised in large projects. Quality management is concerned with pro-\ncesses and techniques for ensuring and improving the quality of soft-\nware. I discuss the importance of standards in quality management, the \nuse of reviews and inspections in the quality assurance process. The final \nsection of this chapter covers software measurement and I discuss the \nbenefits and problems in using metrics and software data analytics in \nquality management.\nFinally, Chapter 25 discusses configuration management, a critical issue \nfor all large systems. However, the need for configuration management is \nnot always obvious to students who have only been concerned with per-\nsonal software development, so I describe the various aspects of this \ntopic here, including version management, system building, change man-\nagement and release management. I explain why continuous integration \nor daily system building is important. An important change in this edition \nis the inclusion of new material on distributed version management sys-\ntems, such as Git, which are being increasingly used to support software \nengineering by distributed teams.\n", "page": 641, "type": "text", "section": "Page 641"}
{"text": "Project management\n22\nObjectives\nThe objective of this chapter is to introduce software project management \nand two important management activities, namely, risk management and \npeople management. When you have read the chapter you will:\n\u25a0\t know the principal tasks of software project managers;\n\u25a0\t have been introduced to the notion of risk management and some of \nthe risks that can arise in software projects;\n\u25a0\t understand factors that influence personal motivation and what these \nmight mean for software project managers;\n\u25a0\t understand key issues that influence team working, such as team \ncomposition, organization, and communication.\nContents\n22.1\t Risk management\n22.2\t Managing people\n22.3\t Teamwork\n", "page": 642, "type": "text", "section": "Page 642"}
{"text": "642\u2002 \u2002 Chapter 22\u2002 \u25a0\u2002 Project management\nSoftware project management is an essential part of software engineering. Projects \nneed to be managed because professional software engineering is always subject to \norganizational budget and schedule constraints. The project manager\u2019s job is to ensure \nthat the software project meets and overcomes these constraints as well as delivering \nhigh-quality software. Good management cannot guarantee project success. However, \nbad management usually results in project failure: The software may be delivered late, \ncost more than originally estimated, or fail to meet the expectations of customers.\nThe success criteria for project management obviously vary from project to pro-\nject, but, for most projects, important goals are:\n\u25a0\t to deliver the software to the customer at the agreed time;\n\u25a0\t to keep overall costs within budget;\n\u25a0\t to deliver software that meets the customer\u2019s expectations;\n\u25a0\t to maintain a coherent and well-functioning development team.\nThese goals are not unique to software engineering but are the goals of all \n\u00ad\nengineering projects. However, software engineering is different from other types of \nengineering in a number of ways that make software management particularly chal-\nlenging. Some of these differences are:\n1.\t\nThe product is intangible A manager of a shipbuilding or a civil engineering \nproject can see the product being developed. If a schedule slips, the effect on the \nproduct is visible\u2014parts of the structure are obviously unfinished. Software is \nintangible. It cannot be seen or touched. Software project managers cannot see \nprogress by looking at the artifact that is being constructed. Rather, they rely on \nothers to produce evidence that they can use to review the progress of the work.\n2.\t\nLarge software projects are often \u201cone-off\u201d projects Every large software \ndevelopment project is unique because every environment where software is \ndeveloped is, in some ways, different from all others. Even managers who have \na large body of previous experience may find it difficult to anticipate problems. \nFurthermore, rapid technological changes in computers and communications \ncan make experience obsolete. Lessons learned from previous projects may not \nbe readily transferable to new projects.\n3.\t\nSoftware processes are variable and organization-specific The engineering process \nfor some types of system, such as bridges and buildings, is well understood. However, \ndifferent companies use quite different software development \u00ad\nprocesses. We cannot \nreliably predict when a particular software process is likely to lead to development \nproblems. This is especially true when the software project is part of a wider systems \nengineering project or when completely new software is being developed.\nBecause of these issues, it is not surprising that some software projects are late, \noverbudget, and behind schedule. Software systems are often new, very complex, \nand technically innovative. Schedule and cost overruns are also common in other \n", "page": 643, "type": "text", "section": "Page 643"}
{"text": "engineering projects, such as new transport systems, that are complex and innova-\ntive. Given the difficulties involved, it is perhaps remarkable that so many software \nprojects are delivered on time and to budget.\nIt is impossible to write a standard job description for a software project manager. The \njob varies tremendously depending on the organization and the software being developed. \nSome of the most important factors that affect how software projects are managed are:\n1.\t\nCompany size Small companies can operate with informal management and \nteam communications and do not need formal policies and management struc-\ntures. They have less management overhead than larger organizations. In larger \norganizations, management hierarchies, formal reporting and budgeting, and \napproval processes must be followed.\n2.\t\nSoftware customers If the customer is an internal customer (as is the case for \nsoftware product development), then customer communications can be informal \nand there is no need to fit in with the customer\u2019s ways of working. If custom \nsoftware is being developed for an external customer, agreement has to be \nreached on more formal communication channels. If the customer is a govern-\nment agency, the software company must operate according to the agency\u2019s \npolicies and procedures, which are likely to be bureaucratic.\n3.\t\nSoftware size Small systems can be developed by a small team, which can get \ntogether in the same room to discuss progress and other management issues. Large \nsystems usually need multiple development teams that may be \u00ad\ngeographically \ndistributed and in different companies. The project manager has to coordinate the \nactivities of these teams and arrange for them to communicate with each other.\n4.\t\nSoftware type If the software being developed is a consumer product, formal \nrecords of project management decisions are unnecessary. On the other hand, if \na safety-critical system is being developed, all project management decisions \nshould be recorded and justified as these may affect the safety of the system.\n5.\t\nOrganizational culture Some organizations have a culture that is based on \n\u00ad\nsupporting and encouraging individuals, while others are group focused. Large \norganizations are often bureaucratic. Some organizations have a culture of \n\u00ad\ntaking risks, whereas others are risk averse.\n6.\t\nSoftware development processes Agile processes typically try to operate with \n\u201clightweight\u201d management. More formal processes require management \n\u00ad\nmonitoring to ensure that the development team is following the defined process.\nThese factors mean that project managers in different organizations may work in \nquite different ways. However, a number of fundamental project management activ-\nities are common to all organizations:\n1.\t\nProject planning Project managers are responsible for planning, estimating, and \nscheduling project development and assigning people to tasks. They supervise \n\t\nChapter 22\u2002 \u25a0\u2002 Project management\u2002 \u2002 643\n", "page": 644, "type": "text", "section": "Page 644"}
{"text": "644\u2002 \u2002 Chapter 22\u2002 \u25a0\u2002 Project management\nthe work to ensure that it is carried out to the required standards, and they mon-\nitor progress to check that the development is on time and within budget.\n2.\t\nRisk management Project managers have to assess the risks that may affect a \nproject, monitor these risks, and take action when problems arise.\n3.\t\nPeople management Project managers are responsible for managing a team of \npeople. They have to choose people for their team and establish ways of work-\ning that lead to effective team performance. \n4.\t\nReporting Project managers are usually responsible for reporting on the progress \nof a project to customers and to the managers of the company developing the \nsoftware. They have to be able to communicate at a range of levels, from detailed \ntechnical information to management summaries. They have to write concise, \ncoherent documents that abstract critical information from detailed project \nreports. They must be able to present this information during progress reviews.\n5.\t\nProposal writing The first stage in a software project may involve writing a \nproposal to win a contract to carry out an item of work. The proposal describes \nthe objectives of the project and how it will be carried out. It usually includes \ncost and schedule estimates and justifies why the project contract should be \nawarded to a particular organization or team. Proposal writing is a critical task \nas the survival of many software companies depends on having enough propos-\nals accepted and contracts awarded.\nProject planning is an important topic in its own right, which I discuss in \nChapter\u00a023. In this chapter, I focus on risk management and people management.\n \n22.1  Risk management\nRisk management is one of the most important jobs for a project manager. You can think \nof a risk as something that you\u2019d prefer not to have happen. Risks may threaten the pro-\nject, the software that is being developed, or the organization. Risk management involves \nanticipating risks that might affect the project schedule or the quality of the software \nbeing developed, and then taking action to avoid these risks (Hall 1998; Ould 1999).\nRisks can be categorized according to type of risk (technical, organizational, \netc.), as I explain in Section 22.1.1. A complementary classification is to classify \nrisks according to what these risks affect:\n1.\t\nProject risks affect the project schedule or resources. An example of a project \nrisk is the loss of an experienced system architect. Finding a replacement archi-\ntect with appropriate skills and experience may take a long time; consequently, \nit will take longer to develop the software design than originally planned.\n2.\t\nProduct risks affect the quality or performance of the software being developed. \nAn example of a product risk is the failure of a purchased component to perform \n", "page": 645, "type": "text", "section": "Page 645"}
{"text": "\t\n22.1\u2002 \u25a0\u2002 Risk management\u2002 \u2002 645\nas expected. This may affect the overall performance of the system so that it is \nslower than expected.\n3.\t\nBusiness risks affect the organization developing or procuring the software. For \nexample, a competitor introducing a new product is a business risk. The intro-\nduction of a competitive product may mean that the assumptions made about \nsales of existing software products may be unduly optimistic.\nOf course, these risk categories overlap. An experienced engineer\u2019s decision to \nleave a project, for example, presents a project risk because the software delivery \nschedule will be affected. It inevitably takes time for a new project member to under-\nstand the work that has been done, so he or she cannot be immediately productive. \nConsequently, the delivery of the system may be delayed. The loss of a team mem-\nber can also be a product risk because a replacement may not be as experienced and \nso could make programming errors. Finally, losing a team member can be a business \nrisk because an experienced engineer\u2019s reputation may be a critical factor in winning \nnew contracts.\nFor large projects, you should record the results of the risk analysis in a risk reg-\nister along with a consequence analysis. This sets out the consequences of the risk \nfor the project, product, and business. Effective risk management makes it easier to \ncope with problems and to ensure that these do not lead to unacceptable budget or \nschedule slippage. For small projects, formal risk recording may not be required, but \nthe project manager should be aware of them.\nThe specific risks that may affect a project depend on the project and the organi-\nzational environment in which the software is being developed. However, there are \nalso common risks that are independent of the type of software being developed. \nThese can occur in any software development project. Some examples of these com-\nmon risks are shown in Figure 22.1.\nSoftware risk management is important because of the inherent uncertainties in \nsoftware development. These uncertainties stem from loosely defined requirements, \nrequirements changes due to changes in customer needs, difficulties in estimating the \ntime and resources required for software development, and differences in individual \nskills. You have to anticipate risks, understand their impact on the project, the product, \nand the business, and take steps to avoid these risks. You may need to draw up contin-\ngency plans so that, if the risks do occur, you can take immediate recovery action.\nAn outline of the process of risk management is presented in Figure 22.2. It \ninvolves several stages:\n1.\t\nRisk identification You should identify possible project, product, and business risks.\n2.\t\nRisk analysis You should assess the likelihood and consequences of these risks.\n3.\t\nRisk planning You should make plans to address the risk, either by avoiding it or \nby minimizing its effects on the project.\n4.\t\nRisk monitoring You should regularly assess the risk and your plans for risk \nmitigation and revise these plans when you learn more about the risk.\n", "page": 646, "type": "text", "section": "Page 646"}
{"text": "646\u2002 \u2002 Chapter 22\u2002 \u25a0\u2002 Project management\nRisk\nAffects\nDescription\nStaff turnover\nProject\nExperienced staff will leave the project before it is \nfinished.\nManagement change\nProject\nThere will be a change of company management \nwith different priorities.\nHardware \nunavailability\nProject\nHardware that is essential for the project will not \nbe delivered on schedule.\nRequirements \nchange\nProject and product\nThere will be a larger number of changes to the \nrequirements than anticipated.\nSpecification delays\nProject and product\nSpecifications of essential interfaces are not \navailable on schedule.\nSize underestimate\nProject and product\nThe size of the system has been underestimated.\nSoftware tool \nunderperformance\nProduct\nSoftware tools that support the project do not \nperform as anticipated.\nTechnology change\nBusiness\nThe underlying technology on which the system is \nbuilt is superseded by new technology.\nProduct competition\nBusiness\nA competitive product is marketed before the \nsystem is completed.\nFigure 22.1\u2002 Examples \nof common project, \nproduct, and business \nrisks\nRisk\nidentification\nRisk\nanalysis\nRisk\nplanning\nRisk\nmonitoring\nList of potential\nrisks\nPrioritized risk\nlist\nRisk avoidance\nand contingency\nplans\nRisk\nassessment\nFor large projects, you should document the outcomes of the risk management \nprocess in a risk management plan. This should include a discussion of the risks \nfaced by the project, an analysis of these risks, and information on how you plan to \nmanage the risk if it seems likely to be a problem.\nThe risk management process is an iterative process that continues throughout \na project. Once you have drawn up an initial risk management plan, you monitor \nthe situation to detect emerging risks. As more information about the risks becomes \nFigure 22.2\u2002 The risk \nmanagement process\n", "page": 647, "type": "text", "section": "Page 647"}
{"text": "\t\n22.1\u2002 \u25a0\u2002 Risk management\u2002 \u2002 647\navailable, you have to re-analyze the risks and decide if the risk priority has \nchanged. You may then have to change your plans for risk avoidance and contin-\ngency management.\nRisk management in agile development is less formal. The same fundamental \nactivities should still be followed and risks discussed, although these may not be \nformally documented. Agile development reduces some risks, such as risks from \nrequirements changes. However, agile development also has a downside. Because of \nits reliance on people, staff turnover can have significant effects on the project, prod-\nuct, and business. Because of the lack of formal documentation and its reliance on \ninformal communications, it is very hard to maintain continuity and momentum if \nkey people leave the project.\n\t\n22.1.1 \t Risk identification\nRisk identification is the first stage of the risk management process. It is concerned \nwith identifying the risks that could pose a major threat to the software engineering \nprocess, the software being developed, or the development organization. Risk identi-\nfication may be a team process in which a team gets together to brainstorm possible \nrisks. Alternatively, project managers may identify risks based on their experience of \nwhat went wrong on previous projects.\nAs a starting point for risk identification, a checklist of different types of risk may \nbe used. Six types of risk may be included in a risk checklist:\n1.\t\nEstimation risks arise from the management estimates of the resources required \nto build the system.\n2.\t\nOrganizational risks arise from the organizational environment where the soft-\nware is being developed.\n3.\t\nPeople risks are associated with the people in the development team.\n4.\t\nRequirements risks come from changes to the customer requirements and the \nprocess of managing the requirements change.\n5.\t\nTechnology risks come from the software or hardware technologies that are \nused to develop the system.\n6.\t\nTools risks come from the software tools and other support software used to \ndevelop the system.\nFigure 22.3 shows examples of possible risks in each of these categories. When \nyou have finished the risk identification process, you should have a long list of risks \nthat could occur and that could affect the product, the process, and the business. You \nthen need to prune this list to a manageable size. If you have too many risks, it is \npractically impossible to keep track of all of them.\n", "page": 648, "type": "text", "section": "Page 648"}
{"text": "648\u2002 \u2002 Chapter 22\u2002 \u25a0\u2002 Project management\nFigure 22.3\u2002 Examples \nof different types of \nrisk\nRisk type\nPossible risks\nEstimation\n\u2002 \u200a\n\u200a\n1. \u0007\nThe time required to develop the software is \nunderestimated.\n\u2002 \u200a\n\u200a\n2. The rate of defect repair is underestimated.\n\u2002 \u200a\n\u200a\n3. The size of the software is underestimated.\nOrganizational\n\u2002 \u200a\n\u200a\n4. \u0007\nThe organization is restructured so that different \nmanagement are responsible for the project.\n\u2002 \u200a\n\u200a\n5. \u0007\nOrganizational financial problems force reductions in the \nproject budget.\nPeople\n\u2002 \u200a\n\u200a\n6. It is impossible to recruit staff with the skills required.\n\u2002 \u200a\n\u200a\n7. Key staff are ill and unavailable at critical times.\n\u2002 \u200a\n\u200a\n8. Required training for staff is not available.\nRequirements\n\u2002 \u200a\n\u200a\n9. \u0007\nChanges to requirements that require major design \nrework are proposed.\n10. \u0007\nCustomers fail to understand the impact of requirements \nchanges.\nTechnology\n11. \u0007\nThe database used in the system cannot process as many \ntransactions per second as expected.\n12. \u0007\nFaults in reusable software components have to be \nrepaired before these components are reused.\nTools\n13. \u0007\nThe code generated by software code generation tools is \ninefficient.\n14. \u0007\nSoftware tools cannot work together in an integrated way.\n\t\n22.1.2 \t Risk analysis\nDuring the risk analysis process, you have to consider each identified risk and make \na judgment about the probability and seriousness of that risk. There is no easy way to \ndo so. You have to rely on your judgment and experience of previous projects and \nthe problems that arose in them. It is not possible to make precise, numeric assess-\nment of the probability and seriousness of each risk. Rather, you should assign the \nrisk to one of a number of bands:\n1.\t\nThe probability of the risk might be assessed as insignificant, low, moderate, \nhigh, or very high.\n2.\t\nThe effects of the risk might be assessed as catastrophic (threaten the survival of \nthe project), serious (would cause major delays), tolerable (delays are within \nallowed contingency), or insignificant.\nYou may then tabulate the results of this analysis process using a table \nordered according to the seriousness of the risk. Figure 22.4 illustrates this for \nthe risks that I have identified in Figure 22.3. Obviously, the assessment of \nprobability and \u00ad\nseriousness is arbitrary here. To make this assessment, you need \n", "page": 649, "type": "text", "section": "Page 649"}
{"text": "\t\n22.1\u2002 \u25a0\u2002 Risk management\u2002 \u2002 649\nFigure 22.4\u2002 Risk types \nand examples\nRisk\nProbability\nEffects\nOrganizational financial problems force reductions in the project \nbudget (5).\nLow\nCatastrophic\nIt is impossible to recruit staff with the skills required (6).\nHigh\nCatastrophic\nKey staff are ill at critical times in the project (7).\nModerate\nSerious\nFaults in reusable software components have to be repaired \nbefore these components are reused (12).\nModerate\nSerious\nChanges to requirements that require major design rework are \nproposed (9).\nModerate\nSerious\nThe organization is restructured so that different managements are \nresponsible for the project (4).\nHigh\nSerious\nThe database used in the system cannot process as many \ntransactions per second as expected (11).\nModerate\nSerious\nThe time required to develop the software is underestimated (1).\nHigh\nSerious\nSoftware tools cannot be integrated (14).\nHigh\nTolerable\nCustomers fail to understand the impact of requirements \nchanges\u00a0(10).\nModerate\nTolerable\nRequired training for staff is not available (8).\nModerate\nTolerable\nThe rate of defect repair is underestimated (2).\nModerate\nTolerable\nThe size of the software is underestimated (3).\nHigh\nTolerable\nCode generated by code generation tools is inefficient (13).\nModerate\nInsignificant\ndetailed information about the project, the process, the development team, and \nthe organization.\nOf course, both the probability and the assessment of the effects of a risk may \nchange as more information about the risk becomes available and as risk manage-\nment plans are implemented. You should therefore update this table during each \niteration of the risk management process.\nOnce the risks have been analyzed and ranked, you should assess which of these \nrisks are most significant. Your judgment must depend on a combination of the prob-\nability of the risk arising and the effects of that risk. In general, catastrophic risks \nshould always be considered, as should all serious risks that have more than a moder-\nate probability of occurrence.\nBoehm (Boehm 1988) recommends identifying and monitoring the \u201ctop 10\u201d risks. \nHowever, I think that the right number of risks to monitor must depend on the pro-\nject. It might be 5 or it might be 15. From the risks identified in Figure 22.4, I think \nthat it is appropriate to consider the eight risks that have catastrophic or serious con-\nsequences (Figure 22.5).\n", "page": 650, "type": "text", "section": "Page 650"}
{"text": "650\u2002 \u2002 Chapter 22\u2002 \u25a0\u2002 Project management\n\t\n22.1.3 \t Risk planning\nThe risk planning process develops strategies to manage the key risks that threaten \nthe project. For each risk, you have to think of actions that you might take to mini-\nmize the disruption to the project if the problem identified in the risk occurs. You \nshould also think about the information that you need to collect while monitoring the \nproject so that emerging problems can be detected before they become serious.\nIn risk planning, you have to ask \u201cwhat-if\u201d questions that consider both individual \nrisks, combinations of risks, and external factors that affect these risks. For example, \nquestions that you might ask are:\n1.\t\nWhat if several engineers are ill at the same time?\n2.\t\nWhat if an economic downturn leads to budget cuts of 20% for the project?\n3.\t\nWhat if the performance of open-source software is inadequate and the only \nexpert on that open-source software leaves?\n4.\t\nWhat if the company that supplies and maintains software components goes out \nof business?\n5.\t\nWhat if the customer fails to deliver the revised requirements as predicted?\nBased on the answers to these \u201cwhat-if\u201d questions, you may devise strategies for \nmanaging the risks. Figure 22.5 shows possible risk management strategies that have \nbeen identified for the key risks (i.e., those that are serious or intolerable) shown in \nFigure 22.4. These strategies fall into three categories:\n1.\t\nAvoidance strategies Following these strategies means that the probability that \nthe risk will arise is reduced. An example of a risk avoidance strategy is the \nstrategy for dealing with defective components shown in Figure 22.5.\n2.\t\nMinimization strategies Following these strategies means that the impact of the \nrisk is reduced. An example of a risk minimization strategy is the strategy for \nstaff illness shown in Figure 22.5.\n3.\t\nContingency plans Following these strategies means that you are prepared for \nthe worst and have a strategy in place to deal with it. An example of a contin-\ngency strategy is the strategy for organizational financial problems that I have \nshown in Figure 22.5.\nYou can see a clear analogy here with the strategies used in critical systems \nto ensure reliability, security, and safety, where you must avoid, tolerate, or \nrecover from failures. Obviously, it is best to use a strategy that avoids the risk. \nIf this is not possible, you should use a strategy that reduces the chances that the \nrisk will have serious effects. Finally, you should have strategies in place to \n", "page": 651, "type": "text", "section": "Page 651"}
{"text": "\t\n22.1\u2002 \u25a0\u2002 Risk management\u2002 \u2002 651\ncope with the risk if it arises. These should reduce the overall impact of a risk on \nthe project or product.\n\t\n22.1.4 \t Risk monitoring\nRisk monitoring is the process of checking that your assumptions about the product, \nprocess, and business risks have not changed. You should regularly assess each of \nthe identified risks to decide whether or not that risk is becoming more or less prob-\nable. You should also think about whether or not the effects of the risk have changed. \nTo do this, you have to look at other factors, such as the number of requirements \nchange requests, which give you clues about the risk probability and its effects. \nThese factors are obviously dependent on the types of risk. Figure 22.6 gives some \nexamples of factors that may be helpful in assessing these risk types.\nYou should monitor risks regularly at all stages in a project. At every manage-\nment review, you should consider and discuss each of the key risks separately. You \nshould decide if the risk is more or less likely to arise and if the seriousness and \nconsequences of the risk have changed.\nFigure 22.5\u2002 Strategies \nto help manage risk\nRisk\nStrategy\nOrganizational \nfinancial problems\nPrepare a briefing document for senior management \nshowing how the project is making a very important \ncontribution to the goals of the business and presenting \nreasons why cuts to the project budget would not be \ncost-effective.\nRecruitment \nproblems\nAlert customer to potential difficulties and the possibility \nof delays; investigate buying-in components.\nStaff illness\nReorganize team so that there is more overlap of work \nand people therefore understand each other\u2019s jobs.\nDefective \ncomponents\nReplace potentially defective components with bought-in \ncomponents of known reliability.\nRequirements \nchanges\nDerive traceability information to assess requirements \nchange impact; maximize information hiding in the design.\nOrganizational \nrestructuring\nPrepare a briefing document for senior management \nshowing how the project is making a very important \ncontribution to the goals of the business.\nDatabase \nperformance\nInvestigate the possibility of buying a higher-performance \ndatabase.\nUnderestimated \ndevelopment time\nInvestigate buying-in components; investigate use of \nautomated code generation.\n", "page": 652, "type": "text", "section": "Page 652"}
{"text": "652\u2002 \u2002 Chapter 22\u2002 \u25a0\u2002 Project management\nFigure 22.6\u2002 Risk \nindicators\nRisk type\nPotential indicators\nEstimation\nFailure to meet agreed schedule; failure to clear reported \ndefects.\nOrganizational\nOrganizational gossip; lack of action by senior management.\nPeople\nPoor staff morale; poor relationships among team members; \nhigh staff turnover.\nRequirements\nMany requirements change requests; customer complaints.\nTechnology\nLate delivery of hardware or support software; many \nreported technology problems.\nTools\nReluctance by team members to use tools; complaints about \nsoftware tools; requests for faster computers/more memory, \nand so on.\n \n22.2  Managing people\nThe people working in a software organization are its greatest assets. It is expen-\nsive to recruit and retain good people, and it is up to software managers to ensure \nthat the engineers working on a project are as productive as possible. In success-\nful companies and economies, this productivity is achieved when people are \nrespected by the organization and are assigned responsibilities that reflect their \nskills and experience.\nIt is important that software project managers understand the technical issues that \ninfluence the work of software development. Unfortunately, however, good software \nengineers are not always good people managers. Software engineers often have \nstrong technical skills but may lack the softer skills that enable them to motivate and \nlead a project development team. As a project manager, you should be aware of the \npotential problems of people management and should try to develop people manage-\nment skills.\nThere are four critical factors that influence the relationship between a manager \nand the people that he or she manages:\n1.\t\nConsistency All the people in a project team should be treated in a comparable \nway. No one expects all rewards to be identical, but people should not feel that \ntheir contribution to the organization is undervalued.\n2.\t\nRespect Different people have different skills, and managers should respect \nthese differences. All members of the team should be given an opportunity to \nmake a contribution. In some cases, of course, you will find that people simply \ndon\u2019t fit into a team and they cannot continue, but it is important not to jump to \nconclusions about them at an early stage in the project.\n", "page": 653, "type": "text", "section": "Page 653"}
{"text": "\t\n22.2\u2002 \u25a0\u2002 Managing people\u2002 \u2002 653\n3.\t Inclusion People contribute effectively when they feel that others listen to \nthem and take account of their proposals. It is important to develop a working \nenvironment where all views, even those of the least experienced staff, are \nconsidered.\n4.\t\nHonesty As a manager, you should always be honest about what is going well \nand what is going badly in the team. You should also be honest about your level \nof technical knowledge and be willing to defer to staff with more knowledge \nwhen necessary. If you try to cover up ignorance or problems, you will eventu-\nally be found out and will lose the respect of the group.\nPractical people management has to be based on experiences so my aim in this \nsection and the following section on teamwork is to raise awareness of the most \nimportant issues that project managers may have to deal with.\n\t\n22.2.1 \t Motivating people\nAs a project manager, you need to motivate the people who work with you so that \nthey will contribute to the best of their abilities. In practice, motivation means organ-\nizing work and its environment to encourage people to work as effectively as possi-\nble. If people are not motivated, they will be less interested in the work they are \ndoing. They will work slowly, be more likely to make mistakes, and will not contrib-\nute to the broader goals of the team or the organization.\nTo provide this encouragement, you should understand a little about what moti-\nvates people. Maslow (Maslow 1954) suggests that people are motivated by satisfy-\ning their needs. These needs are arranged in a series of levels, as shown in Figure\u00a022.7. \nThe lower levels of this hierarchy represent fundamental needs for food, sleep, and \nso on, and the need to feel secure in an environment. Social need is concerned with \nthe need to feel part of a social grouping. Esteem need represents the need to feel \nrespected by others, and self-realization need is concerned with personal develop-\nment. People need to satisfy lower-level needs such as hunger before the more \nabstract, higher-level needs.\nPeople working in software development organizations are not usually hungry, \nthirsty, or physically threatened by their environment. Therefore, making sure that \npeoples\u2019 social, esteem, and self-realization needs are satisfied is most important \nfrom a management point of view.\n1.\t\nTo satisfy social needs, you need to give people time to meet their co-workers \nand provide places for them to meet. Software companies such as Google pro-\nvide social space in their offices for people to get together. This is relatively \neasy when all of the members of a development team work in the same place, \nbut, increasingly, team members are not located in the same building or even the \nsame town or state. They may work for different organizations or from home \nmost of the time.\n", "page": 654, "type": "text", "section": "Page 654"}
{"text": "654\u2002 \u2002 Chapter 22\u2002 \u25a0\u2002 Project management\n\t\nSocial networking systems and teleconferencing can be used for remote com-\nmunications, but my experience with these systems is that they are most effec-\ntive when people already know each other. You should arrange some face-to-face \nmeetings early in the project so that people can directly interact with other \nmembers of the team. Through this direct interaction, people become part of a \nsocial group and accept the goals and priorities of that group.\n2.\t\nTo satisfy esteem needs, you need to show people that they are valued by the \norganization. Public recognition of achievements is a simple and effective way \nof doing this. Obviously, people must also feel that they are paid at a level that \nreflects their skills and experience.\n3.\t\nFinally, to satisfy self-realization needs, you need to give people responsibility \nfor their work, assign them demanding (but not impossible) tasks, and provide \nopportunities for training and development where people can enhance their \nskills. Training is an important motivating influence as people like to gain new \nknowledge and learn new skills.\nMaslow\u2019s model of motivation is helpful up to a point, but I think that a problem \nwith it is that it takes an exclusively personal viewpoint on motivation. It does not \ntake adequate account of the fact that people feel themselves to be part of an organ-\nization, a professional group, and one or more cultures. Being a member of a cohe-\nsive group is highly motivating for most people. People with fulfilling jobs often \nlike to go to work because they are motivated by the people they work with and the \nwork that they do. Therefore, as a manager, you also have to think about how a \ngroup as a whole can be motivated. I discuss this and other teamwork issues in \nSection 22.3.\nIn Figure 22.8, I illustrate a problem of motivation that managers often have to \nface. In this example, a competent group member loses interest in the work and in \nthe group as a whole. The quality of her work falls and becomes unacceptable. This \nsituation has to be dealt with quickly. If you don\u2019t sort out the problem, the other \ngroup members will become dissatisfied and feel that they are doing an unfair share \nof the work.\nPhysiological needs\nSafety needs\nSocial needs\nEsteem needs\nSelf-realization\nneeds\nFigure 22.7\u2002 Human \nneeds hierarchy\n", "page": 655, "type": "text", "section": "Page 655"}
{"text": "\t\n22.2\u2002 \u25a0\u2002 Managing people\u2002 \u2002 655\nIn this example, Alice tries to find out if Dorothy\u2019s personal circumstances could \nbe the problem. Personal difficulties commonly affect motivation because people \ncannot therefore concentrate on their work. You may have to give them time and \nsupport to resolve these issues, although you also have to make it clear that they still \nhave a responsibility to their employer.\nDorothy\u2019s motivation problem is one that can arise when projects develop in an \nunexpected direction. People who expect to do one type of work may end up doing \nsomething completely different. In those circumstances, you may decide that the \nteam member should leave the team and find opportunities elsewhere. In this \n\u00ad\nexample, however, Alice decides to try to convince Dorothy that broadening her \nexperience is a positive career step. She gives Dorothy more design autonomy and \norganizes training courses in software engineering that will give her more opportuni-\nties after her current project has finished.\nPsychological personality type also influences motivation. Bass and Dunteman \n(Bass and Dunteman 1963) identified three classifications for professional workers:\n1.\t\nTask-oriented people, who are motivated by the work they do. In software engi-\nneering, these are people who are motivated by the intellectual challenge of soft-\nware development.\nFigure 22.8\u2002 Individual \nmotivation\nCase study: Motivation\nAlice is a software project manager working in a company that develops alarm systems. \nThis company wishes to enter the growing market of assistive technology to help elderly \nand disabled people live independently. Alice has been asked to lead a team of six \ndevelopers that can develop new products based on the company\u2019s alarm technology.\nAlice\u2019s assistive technology project starts well. Good working relationships develop \nwithin the team, and \u00ad\ncreative new ideas are developed. The team decides to develop a \nsystem that a user can initiate and control the alarm system from a cell phone or tablet \ncomputer. However, some months into the project, Alice notices that Dorothy, a hard-\nware expert, starts coming into work late, that the quality of her work is deteriorating, \nand, increasingly, that she does not appear to be communicating with other members \nof the team.\nAlice talks about the problem informally with other team members to try to find out \nif Dorothy\u2019s personal \u00ad\ncircumstances have changed and if this might be affecting her \nwork. They don\u2019t know of anything, so Alice decides to talk with Dorothy to try to \nunderstand the problem.\nAfter some initial denials of any problem, Dorothy admits that she has lost interest \nin the job. She expected that she would be able to develop and use her hardware \ninterfacing skills. However, because of the product direction that has been chosen, she \nhas little opportunity to use these skills. Basically, she is working as a C \u00ad\nprogrammer on \nthe alarm system software.\nWhile she admits that the work is challenging, she is concerned that she is not \ndeveloping her interfacing skills. She is worried that finding a job that involves hard-\nware interfacing will be difficult after this project. Because she does not want to upset \nthe team by revealing that she is thinking about the next project, she has decided that \nit is best to minimize conversation with them.\n", "page": 656, "type": "text", "section": "Page 656"}
{"text": "656\u2002 \u2002 Chapter 22\u2002 \u25a0\u2002 Project management\n2.\t\nSelf-oriented people, who are principally motivated by personal success and \nrecognition. They are interested in software development as a means of achiev-\ning their own goals. They often have longer-term goals, such as career progres-\nsion, that motivate them, and they wish to be successful in their work to help \nrealize these goals.\n3.\t\nInteraction-oriented people, who are motivated by the presence and actions of \nco-workers. As more and more attention is paid to user interface design, interac-\ntion-oriented individuals are becoming more involved in software engineering.\nResearch has shown that interaction-oriented personalities usually like to work as \npart of a group, whereas task-oriented and self-oriented people usually prefer to act \nas individuals. Women are more likely to be interaction-oriented than men are. They \nare often more effective communicators. I discuss the mix of these different person-\nality types in groups in the case study shown later in Figure 22.10.\nEach individual\u2019s motivation is made up of elements of each class, but one type \nof motivation is usually dominant at any one time. However, individuals can change. \nFor example, technical people who feel they are not being properly rewarded can \nbecome self-oriented and put personal interests before technical concerns. If a group \nworks particularly well, self-oriented people can become more interaction-oriented.\n \n22.3  Teamwork\nMost professional software is developed by project teams that range in size from \ntwo to several hundred people. However, as it is impossible for everyone in a large \ngroup to work together on a single problem, large teams are usually split into a \nnumber of smaller groups. Each group is responsible for developing part of the \noverall system. The best size for a software engineering group is 4 to 6 members, \nand they should never have more than 12 members. When groups are small, com-\nmunication problems are reduced. Everyone knows everyone else, and the whole \ngroup can get around a table for a meeting to discuss the project and the software \nthat they are developing.\nThe People Capability Maturity Model\nThe People Capability Maturity Model (P-CMM) is a framework for assessing how well organizations manage \nthe development of their staff. It highlights best practice in people management and provides a basis for organi-\nzations to improve their people management processes. It is best suited to large rather than small, informal \ncompanies.\nhttp://software-engineering-book.com/web/people-cmm/\n", "page": 657, "type": "text", "section": "Page 657"}
{"text": "\t\n22.3\u2002 \u25a0\u2002 Teamwork\u2002 \u2002 657\nPutting together a group that has the right balance of technical skills, experi-\nence, and personalities is a critical management task. However, successful groups \nare more than simply a collection of individuals with the right balance of skills. A \ngood group is cohesive and thinks of itself as a strong, single unit. The people \ninvolved are motivated by the success of the group as well as by their own per-\nsonal goals.\nIn a cohesive group, members think of the group as more important than the \nindividuals who are group members. Members of a well-led, cohesive group are \nloyal to the group. They identify with group goals and other group members. \nThey attempt to protect the group, as an entity, from outside interference. This \nmakes the group robust and able to cope with problems and unexpected \n\u00ad\nsituations.\nThe benefits of creating a cohesive group are:\n1.\t\nThe group can establish its own quality standards Because these standards are \nestablished by consensus, they are more likely to be observed than external \nstandards imposed on the group.\n2.\t\nIndividuals learn from and support each other Group members learn by work-\ning together. Inhibitions caused by ignorance are minimized as mutual learning \nis encouraged.\n3.\t\nKnowledge is shared Continuity can be maintained if a group member leaves. \nOthers in the group can take over critical tasks and ensure that the project is not \nunduly disrupted.\n4.\t\nRefactoring and continual improvement is encouraged Group members work \ncollectively to deliver high-quality results and fix problems, irrespective of the \nindividuals who originally created the design or program.\nGood project managers should always try to encourage group cohesiveness. They \nmay try to establish a sense of group identity by naming the group and establishing a \ngroup identity and territory. Some managers like explicit group-building activities \nsuch as sports and games, although these are not always popular with group mem-\nbers. Social events for group members and their families are a good way to bring \npeople together.\nOne of the most effective ways of promoting cohesion is to be inclusive. That is, \nyou should treat group members as responsible and trustworthy, and make informa-\ntion freely available. Sometimes managers feel that they cannot reveal certain infor-\nmation to everyone in the group. This invariably creates a climate of mistrust. An \neffective way of making people feel valued and part of a group is to make sure that \nthey know what is going on.\nYou can see an example in the case study in Figure 22.9. Alice arranges regular \ninformal meetings where she tells the other group members what is going on. She \nmakes a point of involving people in the product development by asking them to \ncome up with new ideas derived from their own family experiences. The \u201caway \n", "page": 658, "type": "text", "section": "Page 658"}
{"text": "658\u2002 \u2002 Chapter 22\u2002 \u25a0\u2002 Project management\ndays\u201d are also good ways of promoting cohesion: People relax together while they \nhelp each other learn about new technologies.\nWhether or not a group is effective depends, to some extent, on the nature of the \nproject and the organization doing the work. If an organization is in a state of turmoil \nwith constant reorganizations and job insecurity, it is difficult for team members to \nfocus on software development. Similarly, if a project keeps changing and is in dan-\nger of cancellation, people lose interest in it.\nGiven a stable organizational and project environment, the three factors that have \nthe biggest effect on team working are:\n1.\t\nThe people in the group You need a mix of people in a project group as software \ndevelopment involves diverse activities such as negotiating with clients, pro-\ngramming, testing, and documentation.\n2.\t\nThe way the group is organized A group should be organized so that individuals \ncan contribute to the best of their abilities and tasks can be completed as \nexpected.\n3.\t\nTechnical and managerial communications Good communication between \ngroup members, and between the software engineering team and other project \nstakeholders, is essential.\nAs with all management issues, getting the right team cannot guarantee project \nsuccess. Too many other things can go wrong, including changes to the business and \nthe business environment. However, if you don\u2019t pay attention to group composi-\ntion, organization, and communications, you increase the likelihood that your pro-\nject will run into difficulties.\nFigure 22.9\u2002 Group \ncohesion\nCase study: Team spirit\nAlice, an experienced project manager, understands the importance of creating a cohe-\nsive group. As her company is developing a new product, she takes the opportunity to \ninvolve all group members in the product specification and design by getting them to \ndiscuss possible technology with elderly members of their families. She encourages \nthem to bring these family members to meet other members of the development group.\nAlice also arranges monthly lunches for everyone in the group. These lunches are an \nopportunity for all team members to meet informally, talk around issues of concern, \nand get to know each other. At the lunch, Alice tells the group what she knows about \norganizational news, policies, strategies, and so forth. Each team member then briefly \nsummarizes what they have been doing, and the group discusses a general topic, such \nas new product ideas from elderly relatives.\nEvery few months, Alice organizes an \u201caway day\u201d for the group where the team \nspends two days on \u201ctechnology updating.\u201d Each team member prepares an update on \na relevant technology and presents it to the group. This is an offsite meeting, and \nplenty of time is scheduled for discussion and social interaction.\n", "page": 659, "type": "text", "section": "Page 659"}
{"text": "\t\n22.3\u2002 \u25a0\u2002 Teamwork\u2002 \u2002 659\n\t\n22.3.1 \t Selecting group members\nA manager or team leader\u2019s job is to create a cohesive group and organize that group \nso that they work together effectively. This task involves selecting a group with the \nright balance of technical skills and personalities. Sometimes people are hired from \noutside the organization; more often, software engineering groups are put together \nfrom current employees who have experience on other projects. Managers rarely \nhave a completely free hand in team selection. They often have to use the people \nwho are available in the company, even if they are not the ideal people for the job.\nMany software engineers are motivated primarily by their work. Software devel-\nopment groups, therefore, are often composed of people who have their own ideas \nabout how technical problems should be solved. They want to do the best job possi-\nble, so they may deliberately redesign systems that they think can be improved and \nadd extra system features that are not in the system requirements. Agile methods \nencourage engineers to take the initiative to improve the software. However, some-\ntimes this means that time is spent doing things that aren\u2019t really needed and that \ndifferent engineers compete to rewrite each other\u2019s code.\nTechnical knowledge and ability should not be the only factor used to select group \nmembers. The \u201ccompeting engineers\u201d problem can be reduced if the people in the \ngroup have complementary motivations. People who are motivated by the work are \nlikely to be the strongest technically. People who are self-oriented will probably be \nbest at pushing the work forward to finish the job. People who are interaction-ori-\nented help facilitate communications within the group. I think that it is particularly \nimportant to have interaction-oriented people in a group. They like to talk to people \nand can detect tensions and disagreements at an early stage, before these problems \nhave a serious impact on the group.\nIn the case study in Figure 22.10, I have suggested how Alice, the project man-\nager, has tried to create a group with complementary personalities. This particular \ngroup has a good mix of interaction- and task-oriented people, but I have already \ndiscussed, in Figure 22.8, how Dorothy\u2019s self-oriented personality has caused prob-\nlems because she has not been doing the work that she expected. Fred\u2019s part-time \nrole in the group as a domain expert might also be a problem. He is mostly interested \nin technical challenges, so he may not interact well with other group members. The \nfact that he is not always part of the team means that he may not fully relate to the \nteam\u2019s goals.\nIt is sometimes impossible to choose a group with complementary personalities. \nIf this is the case, the project manager has to control the group so that individual \ngoals do not take precedence over organizational and group objectives. This control \nis easier to achieve if all group members participate in each stage of the project. \nIndividual initiative is most likely to develop when group members are given instruc-\ntions without being aware of the part that their task plays in the overall project.\nFor example, say a software engineer takes over the development of a system and \nnotices that possible improvements could be made to the design. If he or she imple-\nments these improvements without understanding the rationale for the original \ndesign, any changes, though well-intentioned, might have adverse implications for \n", "page": 660, "type": "text", "section": "Page 660"}
{"text": "660\u2002 \u2002 Chapter 22\u2002 \u25a0\u2002 Project management\nother parts of the system. If all the members of the group are involved in the design \nfrom the start, they are more likely to understand why design decisions have been \nmade. They may then identify with these decisions rather than oppose them.\n\t\n22.2.3 \t Group organization\nThe way a group is organized affects the group\u2019s decisions, the ways information is \nexchanged, and the interactions between the development group and external project \nstakeholders. Important organizational questions for project managers include the \nfollowing:\n1.\t\nShould the project manager be the technical leader of the group? The technical \nleader or system architect is responsible for the critical technical decisions made \nduring software development. Sometimes the project manager has the skill and \nexperience to take on this role. However, for large projects, it is best to separate \ntechnical and managerial roles. The project manager should appoint a senior engi-\nneer to be the project architect, who will take responsibility for technical leadership.\n2.\t\nWho will be involved in making critical technical decisions, and how will these \ndecisions be made? Will decisions be made by the system architect or the pro-\nject manager or by reaching consensus among a wider range of team members?\n3.\t\nHow will interactions with external stakeholders and senior company manage-\nment be handled? In many cases, the project manager will be responsible for these \ninteractions, assisted by the system architect if there is one. However, an \u00ad\nalternative \norganizational model is to create a dedicated role concerned with external liaison \nand appoint someone with appropriate interaction skills to that role.\nFigure 22.10\u2002 Group \ncomposition\nCase study: Group composition\nIn creating a group for assistive technology development, Alice is aware of the impor-\ntance of selecting members with complementary personalities. When interviewing \npotential group members, she tried to assess whether they were task-oriented, self- \noriented, or interaction-oriented. She felt that she was primarily a self-oriented type \nbecause she considered the project to be a way of getting noticed by senior manage-\nment and possibly being promoted. She therefore looked for one or perhaps two inter-\naction-oriented personalities, with task-oriented individuals to complete the team. The \nfinal assessment that she arrived at was:\nAlice\u2014self-oriented\nBrian\u2014task-oriented\nChun\u2014interaction-oriented\nDorothy\u2014self-oriented\nEd\u2014interaction-oriented\nFiona\u2014task-oriented\nFred\u2014task-oriented\nHassan\u2014interaction-oriented\n", "page": 661, "type": "text", "section": "Page 661"}
{"text": "\t\n22.3\u2002 \u25a0\u2002 Teamwork\u2002 \u2002 661\n4.\t\nHow can groups integrate people who are not co-located? It is now common for \ngroups to include members from different organizations and for people to work \nfrom home as well as in a shared office. This change has to be considered in \ngroup decision-making processes.\n5.\t\nHow can knowledge be shared across the group? Group organization affects \ninformation sharing as certain methods of organization are better for sharing \nthan others. However, you should avoid too much information sharing as people \nbecome overloaded and excessive information distracts them from their work.\nSmall programming groups are usually organized in an informal way. The group \nleader gets involved in the software development with the other group members. In an \ninformal group, the group as a whole discusses the work to be carried out, and tasks \nare allocated according to ability and experience. More senior group members may be \nresponsible for the architectural design. However, detailed design and implementation \nis the responsibility of the team member who is allocated to a particular task.\nAgile development teams are always informal groups. Agile enthusiasts claim \nthat formal structure inhibits information exchange. Many decisions that are usually \nseen as management decisions (such as decisions on schedule) may be devolved to \ngroup members. However, there still needs to be a project manager who is responsi-\nble for strategic decision making and communications outside of the group.\nInformal groups can be very successful, particularly when most group members \nare experienced and competent. Such a group makes decisions by consensus, which \nimproves cohesiveness and performance. However, if a group is composed mostly of \ninexperienced or incompetent members, informality can be a hindrance. With no \nexperienced engineers to direct the work, the result can be a lack of coordination \nbetween group members and, possibly, eventual project failure.\nIn hierarchical groups the group leader is at the top of the hierarchy. He or she has \nmore formal authority than the group members and so can direct their work. There is \na clear organizational structure, and decisions are made toward the top of the hierar-\nchy and implemented by people lower down. Communications are primarily \n\u00ad\ninstructions from senior staff; the people at lower levels of the hierarchy have rela-\ntively little communication with the managers at the upper levels.\nHiring the right people\nProject managers are often responsible for selecting the people in the organization who will join their software \nengineering team. Getting the best possible people in this process is very important as poor selection decisions \nmay be a serious risk to the project.\nKey factors that should influence the selection of staff are education and training, application domain and tech-\nnology experience, communication ability, adaptability, and problem solving ability.\nhttp://software-engineering-book.com/web/people-selection/\n", "page": 662, "type": "text", "section": "Page 662"}
{"text": "662\u2002 \u2002 Chapter 22\u2002 \u25a0\u2002 Project management\nHierarchical groups can work well when a well-understood problem can be easily \nbroken down into software components that can be developed in different parts of the \nhierarchy. This grouping allows for rapid decision making, which is why \u00ad\nmilitary organ-\nizations follow this model. However, it rarely works well for complex software engineer-\ning. In software development, effective team communications at all levels is essential:\n1.\t\nChanges to the software often require changes to several parts of the system, and \nthis requires discussion and negotiation at all levels in the hierarchy.\n2.\t\nSoftware technologies change so fast that more junior staff may know more \nabout new technologies than experienced staff. Top-down communications may \nmean that the project manager does not find out about the opportunities of using \nthese new technologies. More junior staff may become frustrated because of \nwhat they see as old-fashioned technologies being used for development.\nA major challenge facing project managers is the difference in technical ability \nbetween group members. The best programmers may be up to 25 times more \u00ad\nproductive \nthan the worst programmers. It makes sense to use these \u201csuper-\u00ad\nprogrammers\u201d in the \nmost effective way and to provide them with as much support as possible.\nAt the same time, focusing on the super-programmers can be demotivating for other \ngroup members who are resentful that they are not given responsibility. They may be \nconcerned that this will affect their career development. Furthermore, if a \u201csuper-\u00ad\nprogrammer\u201d leaves the company, the impact on a project can be huge. Therefore, \nadopting a group model that is based on individual experts can pose \u00ad\nsignificant risks.\n\t\n22.3.3 \t Group communications\nIt is absolutely essential that group members communicate effectively and efficiently \nwith each other and with other project stakeholders. Group members must exchange \ninformation on the status of their work, the design decisions that have been made, \nand changes to previous design decisions. They have to resolve problems that arise \nwith other stakeholders and inform these stakeholders of changes to the system, the \ngroup, and delivery plans. Good communication also helps strengthen group cohe-\nsiveness. Group members come to understand the motivations, strengths, and weak-\nnesses of other people in the group.\nThe effectiveness and efficiency of communications are influenced by:\n1.\t\nGroup size As a group gets bigger, it gets harder for members to communicate \n\u00ad\neffectively. The number of one-way communication links is n * (n \u2212 1), where n \nis the group size, so, with a group of eight members, there are 56 possible \n\u00ad\ncommunication pathways. This means that it is quite possible that some people \nwill rarely communicate with each other. Status differences between group \nmembers mean that communications are often one-way. Managers and experi-\nenced engineers tend to dominate communications with less experienced staff, \nwho may be reluctant to start a conversation or make critical remarks.\n", "page": 663, "type": "text", "section": "Page 663"}
{"text": "\t\n22.3\u2002 \u25a0\u2002 Teamwork\u2002 \u2002 663\n2.\t\nGroup structure People in informally structured groups communicate more \neffectively than people in groups with a formal, hierarchical structure. In hierar-\nchical groups, communications tend to flow up and down the hierarchy. People \nat the same level may not talk to each other. This is a particular problem in a \nlarge project with several development groups. If people working on different \nsubsystems only communicate through their managers, then there are more \nlikely to be delays and misunderstandings.\n3.\t\nGroup composition People with the same personality types (discussed in \nSection\u00a022.2) may clash, and, as a result, communications can be inhibited. \nCommunication is also usually better in mixed-sex groups than in single-sex \ngroups (Marshall and Heslin 1975). Women are often more interaction-oriented \nthan men and may act as interaction controllers and facilitators for the group.\n4.\t\nThe physical work environment The organization of the workplace is a major factor \nin facilitating or inhibiting communications. While some companies use standard \nopen-plan offices for their staff, others invest in providing a workspace that includes \na mixture of private and group working areas. This allows for both collaborative \nactivities and individual development that require a high level of\u00a0concentration.\n5.\t\nThe available communication channels There are many different forms of \n\u00ad\ncommunication\u2014face to face, email messages, formal documents, telephone, \nand technologies such as social networking and wikis. As project teams become \nincreasingly distributed, with team members working remotely, you need to \nmake use of interaction technologies, such as conferencing systems, to facilitate \ngroup communications.\nProject managers usually work to tight deadlines, and, consequently, they often try \nto use communication channels that don\u2019t take up too much of their time. They may \nrely on meetings and formal documents to pass on information to project staff and \nstakeholders and send long emails to project staff. Unfortunately, while this may be an \nefficient approach to communication from a project manager\u2019s perspective, it is not \nusually very effective. There are often good reasons why people can\u2019t attend meetings, \nand so they don\u2019t hear the presentation. People do not have time to read long docu-\nments and emails that are not directly relevant to their work. When several versions of \nthe same document are produced, readers find it difficult to keep track of the changes.\nThe physical work environment\nGroup communications and individual productivity are both affected by the team\u2019s working environment. \n\u00ad\nIndividual workspaces are better for concentration on detailed technical work as people are less likely to be \n\u00ad\ndistracted by interruptions. However, shared workspaces are better for communications. A well-designed work \nenvironment takes both of these needs into account.\nhttp://software-engineering-book.com/web/workspace/\n", "page": 664, "type": "text", "section": "Page 664"}
{"text": "664\u2002 \u2002 Chapter 22\u2002 \u25a0\u2002 Project management\nEffective communication is achieved when communications are two-way and \nthe people involved can discuss issues and information and establish a common \nunderstanding of proposals and problems. All this can be done through meetings, \nalthough these meetings are often dominated by powerful personalities. Informal \ndiscussions when a manager meets with the team for coffee are sometimes more \neffective.\nMore and more project teams include remote members, which also makes meet-\nings more difficult. To involve them in communications, you may make use of \nwikis and blogs to support information exchange. Wikis support the collaborative \ncreation and editing of documents, and blogs support threaded discussions about \nquestions and comments made by group members. Wikis and blogs allow project \nmembers and external stakeholders to exchange information, irrespective of their \nlocation. They help manage information and keep track of discussion threads, \nwhich often become confusing when conducted by email. You can also use instant \nmessaging and teleconferences, which can be easily arranged, to resolve issues that \nneed discussion.\nKey Points\n\u25a0\t Good software project management is essential if software engineering projects are to be devel-\noped on schedule and within budget.\n\u25a0\t Software management is distinct from other engineering management. Software is intangible. \nProjects may be novel or innovative, so there is no body of experience to guide their manage-\nment. Software processes are not as mature as traditional engineering processes.\n\u25a0\t Risk management involves identifying and assessing major project risks to establish the prob-\nability that they will occur and the consequences for the project if that risk does arise. You \nshould make plans to avoid, manage, or deal with likely risks if or when they arise.\n\u25a0\t People management involves choosing the right people to work on a project and organizing the \nteam and its working environment so that they are as productive as possible.\n\u25a0\t People are motivated by interaction with other people, by the recognition of management and \ntheir peers, and by being given opportunities for personal development.\n\u25a0\t Software development groups should be fairly small and cohesive. The key factors that influ-\nence the effectiveness of a group are the people in that group, the way that it is organized, and \nthe communication between group members.\n\u25a0\t Communications within a group are influenced by factors such as the status of group members, \nthe size of the group, the gender composition of the group, personalities, and available commu-\nnication channels.\n", "page": 665, "type": "text", "section": "Page 665"}
{"text": "Further Reading\nThe Mythical Man Month: Essays on Software Engineering (Anniversary Edition). The problems of \nsoftware management have remained largely unchanged since the 1960s, and this is one of the best \nbooks on the topic. It presents an interesting and readable account of the management of one of the \nfirst very large software projects, the IBM OS/360 operating system. The anniversary edition \n(\u00ad\npublished 20 years after the original edition in 1975) includes other classic papers by Brooks. \n(F. P. Brooks, 1995, Addison-Wesley).\nPeopleware: Productive Projects and Teams, 2nd ed. This now classic book focuses on the impor-\ntance of treating people properly when managing software projects. It is one of the few books that \nrecognizes how the place where people work influences communications and productivity. Strongly \nrecommended. (T. DeMarco and T. Lister, 1999, Dorset House).\nWaltzing with Bears: Managing Risk on Software Projects. A very practical and easy-to-read intro-\nduction to risks and risk management. (T. DeMarco and T. Lister, 2003, Dorset House).\nEffective Project Management: Traditional, Agile, Extreme. 2014 (7th ed.). This is a textbook on pro-\nject management in general rather than software project management. It is based on the so-called \nPMBOK (Project Management Body of Knowledge) and, unlike most books on this topic, discusses \nPM techniques for agile projects. (R. K. Wysocki, 2014).\nWebsite\nPowerPoint slides for this chapter:\nwww.pearsonglobaleditions.com/Sommerville\nLinks to supporting videos:\nhttp://software-engineering-book.com/videos/software-management/\nExercises\n22.1. Explain why the intangibility of software systems poses special problems for software project \nmanagement.\n22.2. \tExplain how company size and software size are factors that affect software project \n\u00ad\nmanagement.\n22.3. \u0007\nUsing reported instances of project problems in the literature, list management difficulties \nand errors that occurred in these failed programming projects. (I suggest that you start with \nThe Mythical Man Month, as suggested in Further Reading.)\n22.4. In addition to the risks shown in Figure 22.1, identify at least six other possible risks that \ncould arise in software projects.\n22.5. What is risk monitoring? How can risks be monitored? List a few examples of types of risks \nand their potential indicators.\n\t\nChapter 22\u2002 \u25a0\u2002 Exercises\u2002 \u2002 665\n", "page": 666, "type": "text", "section": "Page 666"}
{"text": "22.6.  Fixed-price contracts, where the contractor bids a fixed price to complete a system develop-\nment, may be used to move project risk from client to contractor. If anything goes wrong, the \ncontractor has to pay. Suggest how the use of such contracts may increase the likelihood that \nproduct risks will arise.\n22.7.  Explain why keeping all members of a group informed about progress and technical decisions \nin a project can improve group cohesiveness.\n22.8.  What qualities of a cohesive group\u2019s members make the group robust? List out the key \n\u00ad\nbenefits of creating a cohesive group.\n22.9. Write a case study in the style used here to illustrate the importance of communications in a \nproject team. Assume that some team members work remotely and that it is not possible to \nget the whole team together at short notice.\n22.10.  \u0007\nYour manager asks you to deliver software to a schedule that you know can only be met by \nasking your project team to work unpaid overtime. All team members have young children. \nDiscuss whether you should accept this demand from your manager or whether you should \npersuade your team to give their time to the organization rather than to their families. What \nfactors might be significant in your decision?\nReferences\nBass, B. M., and G. Dunteman. 1963. \u201cBehaviour in Groups as a Function of Self, Interaction and \nTask Orientation.\u201d J. Abnorm. Soc. Psychology. 66 (4): 19\u201328. doi:10.1037/h0042764.\nBoehm, B. W. 1988. \u201cA Spiral Model of Software Development and Enhancement.\u201d IEEE Computer \n21 (5): 61\u201372. doi:10.1109/2.59.\nHall, E. 1998. Managing Risk: Methods for Software Systems Development. Reading, MA: Addison-\nWesley.\nMarshall, J. E., and R. Heslin. 1975. \u201cBoys and Girls Together. Sexual Composition and the Effect of \nDensity on Group Size and Cohesiveness.\u201d J. of Personality and Social Psychology 35 (5): 952\u2013961. \ndoi:10.1037/h0076838.\nMaslow, A. A. 1954. Motivation and Personality. New York: Harper & Row.\nOuld, M. 1999. Managing Software Quality and Business Risk. Chichester, UK: John Wiley & Sons.\n666\u2002 \u2002 Chapter 22\u2002 \u25a0\u2002 Project management\n", "page": 667, "type": "text", "section": "Page 667"}
{"text": "Project planning\n23 \nObjectives\nThe objective of this chapter is to introduce project planning, scheduling, \nand cost estimation. When you have read the chapter, you will:\n\u25a0\t understand the fundamentals of software costing and the factors that \naffect the price of a software system to be developed for external \nclients;\n\u25a0\t know what sections should be included in a project plan that is \ncreated within a plan-driven development process;\n\u25a0\t understand what is involved in project scheduling and the use of bar \ncharts to present a project schedule;\n\u25a0\t have been introduced to agile project planning based on the \n\u201cplanning game\u201d;\n\u25a0\t understand cost estimation techniques and how the COCOMO II \nmodel can be used for software cost estimation.\nContents\n23.1\t Software pricing\n23.2\t Plan-driven development\n23.3\t Project scheduling\n23.4\t Agile planning\n23.5\t Estimation techniques\n23.6\t COCOMO cost modeling\n", "page": 668, "type": "text", "section": "Page 668"}
{"text": "668\u2002 \u2002 Chapter 23\u2002 \u25a0\u2002 Project planning\nProject planning is one of the most important jobs of a software project manager. As \na manager, you have to break down the work into parts and assign them to project \nteam members, anticipate problems that might arise, and prepare tentative solutions \nto those problems. The project plan, which is created at the start of a project and \nupdated as the project progresses, is used to show how the work will be done and to \nassess progress on the project.\nProject planning takes place at three stages in a project life cycle:\n1.\t\nAt the proposal stage, when you are bidding for a contract to develop or provide \na software system. You need a plan at this stage to help you decide if you have \nthe resources to complete the work and to work out the price that you should \nquote to a customer.\n2.\t\nDuring the project startup phase, when you have to plan who will work on the \nproject, how the project will be broken down into increments, how resources \nwill be allocated across your company, and so on. Here, you have more infor-\nmation than at the proposal stage, and you can therefore refine the initial effort \nestimates that you have prepared.\n3.\t\nPeriodically throughout the project, when you update your plan to reflect new \ninformation about the software and its development. You learn more about the \nsystem being implemented and the capabilities of your development team. As \nsoftware requirements change, the work breakdown has to be altered and the \nschedule extended. This information allows you to make more accurate esti-\nmates of how long the work will take.\nPlanning at the proposal stage is inevitably speculative, as you do not have a \ncomplete set of requirements for the software to be developed. You have to respond \nto a call for proposals based on a high-level description of the software functional-\nity that is required. A plan is often a required part of a proposal, so you have to \nproduce a credible plan for carrying out the work. If you win the contract, you then \nhave to \u00ad\nre-plan the project, taking into account changes since the proposal was \nmade and new information about the system, the development process, and the \ndevelopment team.\nWhen you are bidding for a contract, you have to work out the price that you \nwill propose to the customer for developing the software. As a starting point for \ncalculating this price, you need to draw up an estimate of your costs for complet-\ning the project work. Estimation involves working out how much effort is \nrequired to complete each activity and, from this step, calculating the total cost \nof activities. You should always calculate software costs objectively, with the \naim of accurately predicting the cost of developing the software. Once you \nhave a reasonable estimate of the likely costs, you are then in a position to calcu-\nlate the price that you will quote to the customer. As I discuss in the next section, \nmany factors influence the pricing of a software project\u2014it is not simply cost \nplus profit.\n", "page": 669, "type": "text", "section": "Page 669"}
{"text": "You should use three main parameters when computing the costs of a software \ndevelopment project:\n\u25a0\t effort costs (the costs of paying software engineers and managers);\n\u25a0\t hardware and software costs, including hardware maintenance and software \n\u00ad\nsupport; and\n\u25a0\t travel and training costs.\nFor most projects, the biggest cost is the effort cost. You have to estimate the total \neffort (in person-months) that is likely to be required to complete the work of a pro-\nject. Obviously, you have limited information to make such an estimate. You there-\nfore make the best possible estimate and then add contingency (extra time and effort) \nin case your initial estimate is optimistic.\nFor commercial systems, you normally use commodity hardware, which is rela-\ntively cheap. However, software costs can be significant if you have to license mid-\ndleware and platform software. Extensive travel may be needed when a project is \ndeveloped at different sites. While travel costs themselves are usually a small frac-\ntion of the effort costs, the time spent traveling is often wasted and adds significantly \nto the effort costs of the project. You can use electronic meeting systems and other \ncollaborative software to reduce travel and so have more time available for produc-\ntive work.\nOnce a contract to develop a system has been awarded, the outline project \nplan for the project has to be refined to create a project startup plan. At this stage, \nyou should know more about the requirements for this system. Your aim should \nbe to create a project plan with enough detail to help make decisions about pro-\nject staffing and budgeting. You use this plan as a basis for allocating resources \nto the project from within the organization and to help decide if you need to hire \nnew staff.\nThe plan should also define project monitoring mechanisms. You must keep track \nof the progress of the project and compare actual and planned progress and costs. \nAlthough most companies have formal procedures for monitoring, a good manager \nshould be able to form a clear picture of what is going on through informal discus-\nsions with project staff. Informal monitoring can predict potential project problems \nby revealing difficulties as they occur. For example, daily discussions with project \nOverhead costs\nWhen you estimate the costs of effort on a software project, you don\u2019t simply multiply the salaries of the people \ninvolved by the time spent on the project. You have to take into account all of the organizational overheads \n(office space, administration, etc.) that must be covered by the income from a project. You calculate the costs \nby computing these overheads and adding a proportion to the costs of each engineer working on a project.\nhttp://software-engineering-book.com/web/overhead-costs/\n\t\nChapter 23\u2002 \u25a0\u2002 Project planning\u2002 \u2002 669\n", "page": 670, "type": "text", "section": "Page 670"}
{"text": "670\u2002 \u2002 Chapter 23\u2002 \u25a0\u2002 Project planning\nstaff might reveal that the team is having problems with a software fault in the com-\nmunications systems. The project manager can then immediately assign a communi-\ncations expert to the problem to help find and solve the problem.\nThe project plan always evolves during the development process because of \nrequirements changes, technology issues, and development problems. Development \nplanning is intended to ensure that the project plan remains a useful document for staff \nto understand what is to be achieved and when it is to be delivered. Therefore, the \nschedule, cost estimate, and risks all have to be revised as the software is developed.\nIf an agile method is used, there is still a need for a project startup plan because \nregardless of the approach used, the company still needs to plan how resources will \nbe allocated to a project. However, this is not a detailed plan, and you only need to \ninclude essential information about the work breakdown and project schedule. \nDuring development, an informal project plan and effort estimates are drawn up for \neach release of the software, with the whole team involved in the planning process. \nSome aspects of agile planning have already been covered in Chapter 3, and I \u00ad\ndiscuss \nother approaches in Section 23.4.\n \n23.1  Software pricing\nIn principle, the price of a software system developed for a customer is simply the \ncost of development plus profit for the developer. In practice, however, the relation-\nship between the project cost and the price quoted to the customer is not usually so \nsimple. When calculating a price, you take broader organizational, economic, polit-\nical, and business considerations into account (Figure 23.1). You need to think \nabout organizational concerns, the risks associated with the project, and the type of \ncontract that will be used. These issues may cause the price to be adjusted upward \nor downward.\nTo illustrate some of the project pricing issues, consider the following scenario:\nA small software company, PharmaSoft, employs 10 software engineers. It has \njust finished a large project but only has contracts in place that require five \ndevelopment staff. However, it is bidding for a very large contract with a \nmajor pharmaceutical company that requires 30 person-years of effort over \ntwo years. The project will not start for at least 12 months but, if granted, it \nwill transform the finances of the company.\nPharmaSoft gets an opportunity to bid on a project that requires six people \nand has to be completed in 10 months. The costs (including overheads of this \nproject) are estimated at $1.2 million. However, to improve its competitive \nposition, PharmaSoft decides to bid a price to the customer of $0.8 million. \nThis means that, although it loses money on this contract, it can retain special-\nist staff for the more profitable future projects that are likely to come on stream \nin a year\u2019s time.\n", "page": 671, "type": "text", "section": "Page 671"}
{"text": "\t\n23.1\u2002 \u25a0\u2002 Software pricing\u2002 \u2002 671\nThis is an example of an approach to software pricing called \u201cpricing to win.\u201d \nPricing to win means that a company has some idea of the price that the customer \nexpects to pay and makes a bid for the contract based on the customer\u2019s expected \nprice. This may seem unethical and unbusinesslike, but it does have advantages for \nboth the customer and the system provider.\nA project cost is agreed on the basis of an outline proposal. Negotiations then take \nplace between client and customer to establish the detailed project specification. \nThis specification is constrained by the agreed cost. The buyer and seller must agree \non what is acceptable system functionality. The fixed factor in many projects is not \nthe project requirements but the cost. The requirements may be changed so that the \nproject costs remain within budget.\nFor example, say a company (OilSoft) is bidding for a contract to develop a fuel \ndelivery system for an oil company that schedules deliveries of fuel to its service \nstations. There is no detailed requirements document for this system, so OilSoft esti-\nmates that a price of $900,000 is likely to be competitive and within the oil compa-\nny\u2019s budget. After being granted the contract, OilSoft then negotiates the detailed \nrequirements of the system so that basic functionality is delivered. It then estimates \nthe additional costs for other requirements.\nThis approach has advantages for both the software developer and the cus-\ntomer. The requirements are negotiated to avoid requirements that are difficult \nto implement and potentially very expensive. Flexible requirements make it eas-\nier to reuse software. The oil company has awarded the contract to a known \ncompany that it can trust. Furthermore, it may be possible to spread the cost of \nFactor\nDescription\nContractual terms\nA customer may be willing to allow the developer to retain ownership \nof the source code and reuse it in other projects. The price charged \nmight then be reduced to reflect the value of the source code to the \ndeveloper.\nCost estimate uncertainty\nIf an organization is unsure of its cost estimate, it may increase its price \nby a contingency over and above its normal profit.\nFinancial health\nCompanies with financial problems may lower their price to gain a \ncontract. It is better to make a smaller-than-normal profit or break even \nthan to go out of business. Cash flow is more important than profit in \ndifficult economic times.\nMarket opportunity\nA development organization may quote a low price because it wishes to \nmove into a new segment of the software market. Accepting a low \nprofit on one project may give the organization the opportunity to make \na greater profit later. The experience gained may also help it develop \nnew products.\nRequirements volatility\nIf the requirements are likely to change, an organization may lower its \nprice to win a contract. After the contract is awarded, high prices can be \ncharged for changes to the requirements.\nFigure 23.1\u2002 Factors \naffecting software \npricing\n", "page": 672, "type": "text", "section": "Page 672"}
{"text": "672\u2002 \u2002 Chapter 23\u2002 \u25a0\u2002 Project planning\nthe project over several versions of the system. This may reduce the costs of \nsystem deployment and allow the client to budget for the project cost over sev-\neral financial years.\n \n23.2  Plan-driven development\nPlan-driven or plan-based development is an approach to software engineering \nwhere the development process is planned in detail. A project plan is created that \nrecords the work to be done, who will do it, the development schedule, and the work \nproducts. Managers use the plan to support project decision making and as a way of \nmeasuring progress. Plan-driven development is based on engineering project man-\nagement techniques and can be thought of as the \u201ctraditional\u201d way of managing large \nsoftware development projects. Agile development involves a different planning \nprocess, discussed in Section 23.4, where decisions are delayed.\nThe problem with plan-driven development is that early decisions have to be revised \nbecause of changes to the environments in which the software is developed and used. \nDelaying planning decisions avoids unnecessary rework. However, the arguments in favor \nof a plan-driven approach are that early planning allows organizational issues (availability \nof staff, other projects, etc.) to be taken into account. Potential problems and dependencies \nare discovered before the project starts, rather than once the project is underway.\nIn my view, the best approach to project planning involves a sensible mixture of \nplan-based and agile development. The balance depends on the type of project and \nskills of the people who are available. At one extreme, large security and safety-\ncritical systems require extensive up-front analysis and may have to be certified \nbefore they are put into use. These systems should be mostly plan-driven. At the \nother extreme, small to medium-size information systems, to be used in a rapidly \nchanging competitive environment, should be mostly agile. Where several compa-\nnies are involved in a development project, a plan-driven approach is normally used \nto coordinate the work across each development site.\n\t\n23.2.1 \t Project plans\nIn a plan-driven development project, a project plan sets out the resources available to \nthe project, the work breakdown, and a schedule for carrying out the work. The plan \nshould identify the approach that is taken to risk management as well as risks to the pro-\nject and the software under development. The details of project plans vary depending on \nthe type of project and organization but plans normally include the following sections:\n1.\t\nIntroduction Briefly describes the objectives of the project and sets out the con-\nstraints (e.g., budget, time) that affect the management of the project.\n2.\t\nProject organization Describes the way in which the development team is \norganized, the people involved, and their roles in the team.\n", "page": 673, "type": "text", "section": "Page 673"}
{"text": "\t\n23.2\u2002 \u25a0\u2002 Plan-driven development\u2002 \u2002 673\n3.\t\nRisk analysis Describes possible project risks, the likelihood of these risks aris-\ning, and the risk reduction strategies (discussed in Chapter 22) that are proposed.\n4.\t\nHardware and software resource requirements Specifies the hardware and support \nsoftware required to carry out the development. If hardware has to be purchased, \nestimates of the prices and the delivery schedule may be included.\n5.\t\nWork breakdown Sets out the breakdown of the project into activities and iden-\ntifies the inputs to and the outputs from each project activity.\n6.\t\nProject schedule Shows the dependencies between activities, the estimated time \nrequired to reach each milestone, and the allocation of people to activities. The \nways in which the schedule may be presented are discussed in the next section \nof the chapter.\n7.\t\nMonitoring and reporting mechanisms Defines the management reports that \nshould be produced, when these should be produced, and the project monitoring \nmechanisms to be used.\nThe main project plan should always include a project risk assessment and a \nschedule for the project. In addition, you may develop a number of supplementary \nplans for activities such as testing and configuration management. Figure 23.2 shows \nsome supplementary plans that may be developed. These are all usually needed in \nlarge projects developing large, complex systems.\n\t\n23.2.2 \t The planning process\nProject planning is an iterative process that starts when you create an initial project \nplan during the project startup phase. Figure 23.3 is a UML activity diagram that \nshows a typical workflow for a project planning process. Plan changes are inevita-\nble. As more information about the system and the project team becomes available \nPlan\nDescription\nConfiguration management plan\nDescribes the configuration management procedures and \nstructures to be used.\nDeployment plan\nDescribes how the software and associated hardware (if required) \nwill be deployed in the customer\u2019s environment. This should \ninclude a plan for migrating data from existing systems.\nMaintenance plan\nPredicts the maintenance requirements, costs, and effort.\nQuality plan\nDescribes the quality procedures and standards that will be \nused in a project.\nValidation plan\nDescribes the approach, resources, and schedule used for \nsystem validation.\nFigure 23.2\u2002 Project \nplan supplements\n", "page": 674, "type": "text", "section": "Page 674"}
{"text": "674\u2002 \u2002 Chapter 23\u2002 \u25a0\u2002 Project planning\nduring the project, you should regularly revise the plan to reflect requirements, \nschedule, and risk changes. Changing business goals also leads to changes in project \nplans. As business goals change, this could affect all projects, which may then have \nto be re-planned.\nAt the beginning of a planning process, you should assess the constraints affect-\ning the project. These constraints are the required delivery date, staff available, over-\nall budget, available tools, and so on. In conjunction with this assessment, you \nshould also identify the project milestones and deliverables. Milestones are points in \nthe schedule against which you can assess progress, for example, the handover of the \nsystem for testing. Deliverables are work products that are delivered to the customer, \nfor example, a requirements document for the system.\nThe process then enters a loop that terminates when the project is complete. You \ndraw up an estimated schedule for the project, and the activities defined in the schedule \nare initiated or are approved to continue. After some time (usually about two to three \nweeks), you should review progress and note discrepancies from the planned schedule. \nBecause initial estimates of project parameters are inevitably approximate, minor slip-\npages are normal and you will have to make modifications to the original plan.\nYou should make realistic rather than optimistic assumptions when you are defin-\ning a project plan. Problems of some description always arise during a project, and \nthese lead to project delays. Your initial assumptions and scheduling should there-\nfore be pessimistic and take unexpected problems into account. You should include \ncontingency in your plan so that if things go wrong, then your delivery schedule is \nnot seriously disrupted.\nIf there are serious problems with the development work that are likely to lead to \nsignificant delays, you need to initiate risk mitigation actions to reduce the risks of \nproject failure. In conjunction with these actions, you also have to re-plan the pro-\nject. This may involve renegotiating the project constraints and deliverables with the \ncustomer. A new schedule of when work should be completed also has to be estab-\nlished and agreed to with the customer.\nDefine project\nschedule\nIdentify\nrisks\nIdentify\nconstraints\nDefine\nmilestones\nand\ndeliverables\n\u00absystem\u00bb\nProject planner\nDo the work\nMonitor progress\nagainst plan\n[ no problems ]\n[minor problems and slippages]\n[project\nfinished]\n[unfinished]\n[serious\nproblems]\nInitiate risk\nmitigation actions\nReplan\nproject\nFigure 23.3\u2002 The project \nplanning process\n", "page": 675, "type": "text", "section": "Page 675"}
{"text": "\t\n23.3\u2002 \u25a0\u2002 Project scheduling\u2002 \u2002 675\nIf this renegotiation is unsuccessful or the risk mitigation actions are ineffective, \nthen you should arrange for a formal project technical review. The objectives of this \nreview are to find an alternative approach that will allow the project to continue. \nReviews should also check that the customer\u2019s goals are unchanged and that the \nproject remains aligned with these goals.\nThe outcome of a review may be a decision to cancel a project. This may be a \nresult of technical or managerial failings but, more often, is a consequence of exter-\nnal changes that affect the project. The development time for a large software project \nis often several years. During that time, the business objectives and priorities inevi-\ntably change. These changes may mean that the software is no longer required or \nthat the original project requirements are inappropriate. Management may then \ndecide to stop software development or to make major changes to the project to \nreflect the changes in the organizational objectives.\n \n23.3  Project scheduling\nProject scheduling is the process of deciding how the work in a project will be organ-\nized as separate tasks, and when and how these tasks will be executed. You estimate \nthe calendar time needed to complete each task and the effort required, and you sug-\ngest who will work on the tasks that have been identified. You also have to estimate \nthe hardware and software resources that are needed to complete each task. For \nexample, if you are developing an embedded system, you have to estimate the time \nthat you need on specialized hardware and the costs of running a system simulator. \nIn terms of the planning stages that I introduced in the introduction of this chapter, \nan initial project schedule is usually created during the project startup phase. This \nschedule is then refined and modified during development planning.\nBoth plan-based and agile processes need an initial project schedule, although less \ndetail is included in an agile project plan. This initial schedule is used to plan how peo-\nple will be allocated to projects and to check the progress of the project against its \ncontractual commitments. In traditional development processes, the complete schedule \nis initially developed and then modified as the project progresses. In agile processes, \nthere has to be an overall schedule that identifies when the major phases of the project \nwill be completed. An iterative approach to scheduling is then used to plan each phase.\nScheduling in plan-driven projects (Figure 23.4) involves breaking down the total \nwork involved in a project into separate tasks and estimating the time required to \ncomplete each task. Tasks should normally last at least a week and no longer than \n2 months. Finer subdivision means that a disproportionate amount of time must be \nspent on re-planning and updating the project plan. The maximum amount of time \nfor any task should be 6 to 8 weeks. If a task will take longer than this, it should be \nsplit into subtasks for project planning and scheduling.\nSome of these tasks are carried out in parallel, with different people working on \ndifferent components of the system. You have to coordinate these parallel tasks and \norganize the work so that the workforce is used optimally and you don\u2019t introduce \n", "page": 676, "type": "text", "section": "Page 676"}
{"text": "676\u2002 \u2002 Chapter 23\u2002 \u25a0\u2002 Project planning\nunnecessary dependencies between the tasks. It is important to avoid a situation \nwhere the whole project is delayed because a critical task is unfinished.\nIf a project is technically advanced, initial estimates will almost certainly be opti-\nmistic even when you try to consider all eventualities. In this respect, software \nscheduling is no different from scheduling any other type of large advanced project. \nNew aircraft, bridges, and even new models of cars are frequently late because of \nunanticipated problems. Schedules, therefore, must be continually updated as better \nprogress information becomes available. If the project being scheduled is similar to \na previous project, previous estimates may be reused. However, projects may use \ndifferent design methods and implementation languages, so experience from previ-\nous projects may not be applicable in the planning of a new project.\nWhen you are estimating schedules, you must take into account the possibility \nthat things will go wrong. People working on a project may fall ill or leave, hardware \nmay fail, and essential support software or hardware may be delivered late. If the \nproject is new and technically advanced, parts of it may turn out to be more difficult \nand take longer than originally anticipated.\nA good rule of thumb is to estimate as if nothing will go wrong and then increase \nyour estimate to cover anticipated problems. A further contingency factor to cover \nunanticipated problems may also be added to the estimate. This extra contingency factor \ndepends on the type of project, the process parameters (deadline, standards, etc.), and \nthe quality and experience of the software engineers working on the project. Contingency \nestimates may add 30 to 50% to the effort and time required for the project.\n\t\n23.3.1 \t Schedule presentation\nProject schedules may simply be documented in a table or spreadsheet showing the \ntasks, estimated effort, duration, and task dependencies (Figure 23.5). However, this \nstyle of presentation makes it difficult to see the relationships and dependencies \nbetween the different activities. For this reason, alternative graphical visualizations \nof project schedules have been developed that are often easier to read and under-\nstand. Two types of visualization are commonly used:\n1.\t\nCalendar-based bar charts show who is responsible for each activity, the \nexpected elapsed time, and when the activity is scheduled to begin and end. Bar \ncharts are also called Gantt charts, after their inventor, Henry Gantt.\nEstimate resources\nfor activities\nIdentify activity\ndependencies\nIdentify\nactivities\nAllocate people\nto activities\nSoftware requirements\nand design information\nBar charts describing the\nproject schedule\nCreate project\ncharts\nFigure 23.4\u2002 The project \nscheduling process\n", "page": 677, "type": "text", "section": "Page 677"}
{"text": "\t\n23.3\u2002 \u25a0\u2002 Project scheduling\u2002 \u2002 677\n2.\t Activity networks show the dependencies between the different activities mak-\ning up a project. These networks are described in an associated web section.\nProject activities are the basic planning element. Each activity has:\n\u25a0\t a duration in calendar days or months;\n\u25a0\t an effort estimate, which shows the number of person-days or person-months to \ncomplete the work;\n\u25a0\t a deadline by which the activity should be complete; and\n\u25a0\t a defined endpoint, which might be a document, the holding of a review meeting, \nthe successful execution of all tests, or the like.\nWhen planning a project, you may decide to define project milestones. A mile-\nstone is a logical end to a stage of the project where the progress of the work can \nbe reviewed. Each milestone should be documented by a brief report (often sim-\nply an email) that summarizes the work done and whether or not the work has \nbeen completed as planned. Milestones may be associated with a single task or \nwith groups of related activities. For example, in Figure 23.5, milestone M1 is \nassociated with task T1 and marks the end of that activity. Milestone M3 is asso-\nciated with a pair of tasks T2 and T4; there is no individual milestone at the end \nof these tasks.\nTask\nEffort (person-days)\nDuration (days)\nDependencies\nT1\n15\n10\nT2\n8\n15\nT3\n20\n15\nT1 (M1)\nT4\n5\n10\nT5\n5\n10\nT2, T4 (M3)\nT6\n10\n5\nT1, T2 (M4)\nT7\n25\n20\nT1 (M1)\nT8\n75\n25\nT4 (M2)\nT9\n10\n15\nT3, T6 (M5)\nT10\n20\n15\nT7, T8 (M6)\nT11\n10\n10\nT9 (M7)\nT12\n20\n10\nT10, T11 (M8)\nFigure 23.5\u2002 Tasks, \ndurations, and \ndependencies\n", "page": 678, "type": "text", "section": "Page 678"}
{"text": "678\u2002 \u2002 Chapter 23\u2002 \u25a0\u2002 Project planning\nSome activities create project deliverables\u2014outputs that are delivered to the \nsoftware customer. Usually, the deliverables that are required are specified in the \nproject contract, and the customer\u2019s view of the project\u2019s progress depends on \nthese deliverables. Milestones and deliverables are not the same thing. Milestones \nare short reports that are used for progress reporting, whereas deliverables are \nmore substantial project outputs such as a requirements document or the initial \nimplementation of a system.\n Figure 23.5 shows a hypothetical set of tasks, their estimated effort and duration, \nand task dependencies. From this table, you can see that task T3 is dependent on task \nT1. This means that task T1 has to be completed before T3 starts. For example, T1 \nmight be the selection of a system for reuse and T3, the configuration of the selected \nsystem. You can\u2019t start system configuration until you have chosen and installed the \napplication system to be modified.\nNotice that the estimated duration for some tasks is more than the effort required \nand vice versa. If the effort is less than the duration, the people allocated to that task \nare not working full time on it. If the effort exceeds the duration, this means that \nseveral team members are working on the task at the same time.\n Figure 23.6 takes the information in Figure 23.5 and presents the project sched-\nule as a bar chart showing a project calendar and the start and finish dates of tasks. \nReading from left to right, the bar chart clearly shows when tasks start and end. The \nmilestones (M1, M2, etc.) are also shown on the bar chart. Notice that tasks that are \nindependent may be carried out in parallel. For example, tasks T1, T2, and T4 all \nstart at the beginning of the project.\nAs well as planning the delivery schedule for the software, project managers have \nto allocate resources to tasks. The key resource is, of course, the software engineers \nwho will do the work. They have to be assigned to project activities. The resource \nallocation can be analyzed by project management tools, and a bar chart can be gener-\nated showing when staff are working on the project (Figure 23.7). People may be \nworking on more than one task at the same time, and sometimes they are not working \non the project. They may be on holiday, working on other projects, or attending train-\ning courses. I show part-time assignments using a diagonal line crossing the bar.\nLarge organizations usually employ a number of specialists who work on a pro-\nject when needed. In Figure 23.7, you can see that Mary is a specialist who works on \nActivity charts\nAn activity chart is a project schedule representation that presents the project plan as a directed graph. It shows \nwhich tasks can be carried out in parallel and those that must be executed in sequence due to their dependen-\ncies on earlier activities. If a task is dependent on several other tasks, then all of these tasks must be completed \nbefore it can start. The \u201ccritical path\u201d through the activity chart is the longest sequence of dependent tasks. This \ndefines the project duration.\nhttp://software-engineering-book.com/web/planning-activities/\n", "page": 679, "type": "text", "section": "Page 679"}
{"text": "\t\n23.3\u2002 \u25a0\u2002 Project scheduling\u2002 \u2002 679\nonly a single task (T5) in the project. The use of specialists is unavoidable when \ncomplex systems are being developed, but it can lead to scheduling problems. If one \nproject is delayed while a specialist is working on it, this may affect other projects \nwhere the specialist is also required. These projects may be delayed because the \nspecialist is not available.\nIf a task is delayed, later tasks that are dependent on it may be affected. They can-\nnot start until the delayed task is completed. Delays can cause serious problems with \nstaff allocation, especially when people are working on several projects at the same \ntime. If a task (T) is delayed, the people allocated to it may be assigned to other work \n(W). To complete this work may take longer than the delay, but, once assigned, they \ncannot simply be reassigned back to the original task. This may then lead to further \ndelays in T as they complete W.\nNormally, you should use a project planning tool, such as the Basecamp or \nMicrosoft project, to create, update, and analyze project schedule information. \nProject management tools usually expect you to input project information into a \ntable, and they create a database of project information. Bar charts and activity charts \ncan then be generated automatically from this database.\nWeek 0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\nT4\nT1\nT2\n(M1/T1)\nT7\nT3\n(M5/T3 & T6)\nT8\n(M4/T1& T2)\nT6\nT5\n(M2/T4)\nT9\n(M7/T 9)\nT10\n(M6/T7 & T8)\nT11\n(M8/T10 & T11)\nT12\nStart\nFinish\n(M3/T2 & T4)\nFigure 23.6\u2002 Activity \nbar\u00a0chart\n", "page": 680, "type": "text", "section": "Page 680"}
{"text": "680\u2002 \u2002 Chapter 23\u2002 \u25a0\u2002 Project planning\n \n23.4  Agile planning\nAgile methods of software development are iterative approaches where the software \nis developed and delivered to customers in increments. Unlike plan-driven \napproaches, the functionality of these increments is not planned in advance but is \ndecided during the development. The decision on what to include in an increment \ndepends on progress and on the customer\u2019s priorities. The argument for this approach \nis that the customer\u2019s priorities and requirements change, so it makes sense to have a \nflexible plan that can accommodate these changes. Cohn\u2019s book (Cohn 2005) is an \nexcellent introduction to agile planning.\nAgile development methods such as Scrum (Rubin 2013) and Extreme \nProgramming (Beck and Andres 2004) have a two-stage approach to planning, corre-\nsponding to the startup phase in plan-driven development and development planning:\n1.\t\nRelease planning, which looks ahead for several months and decides on the \nfeatures that should be included in a release of a system.\n2.\t\nIteration planning, which has a shorter term outlook and focuses on planning the next \nincrement of a system. This usually represents 2 to 4 weeks of work for the team.\nI have already explained the Scrum approach to planning in Chapter 3, which  is \nbased on project backlogs and daily reviews of work to be done. It is primarily geared \nT1\nT3\nT9\nJane\nT3\nT10\nGeetha\nT7\nHong\nT5\nMary\nT4\nT8\nFred\nT1\nT8\nAli\nT12\nT2\nT6\nMaya\nT8\nT10\nT6\nT11\nT12\nT8\nWeek 0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\nT7\nFigure 23.7\u2002 Staff \nallocation chart\n", "page": 681, "type": "text", "section": "Page 681"}
{"text": "\t\n23.4\u2002 \u25a0\u2002 Agile planning\u2002 \u2002 681\nto iteration planning. Another approach to agile planning, which was developed as \npart of Extreme Programming, is based on user stories. The so-called planning game \ncan be used in both release planning and iteration planning.\nThe basis of the planning game (Figure 23.8) is a set of user stories (see Chapter 3) \nthat cover all of the functionality to be included in the final system. The development \nteam and the software customer work together to develop these stories. The team \nmembers read and discuss the stories and rank them based on the amount of time they \nthink it will take to implement the story. Some stories may be too large to implement \nin a single iteration, and these are broken down into smaller stories.\nThe problem with ranking stories is that people often find it difficult to estimate how \nmuch effort or time is needed to do something. To make this easier, relative ranking \nmay be used. The team compares stories in pairs and decides which will take the most \ntime and effort, without assessing exactly how much effort will be required. At the end \nof this process, the list of stories has been ordered, with the stories at the top of the list \ntaking the most effort to implement. The team then allocates notional effort points to all \nof the stories in the list. A complex story may have 8 points and a simple story 2 points.\nOnce the stories have been estimated, the relative effort is translated into the first \nestimate of the total effort required by using the idea of \u201cvelocity.\u201d Velocity is the \nnumber of effort points implemented by the team, per day. This can be estimated \neither from previous experience or by developing one or two stories to see how \nmuch time is required. The velocity estimate is approximate but is refined during the \ndevelopment process. Once you have a velocity estimate, you can calculate the total \neffort in person-days to implement the system.\nRelease planning involves selecting and refining the stories that will reflect the \nfeatures to be implemented in a release of a system and the order in which the stories \nshould be implemented. The customer has to be involved in this process. A release \ndate is then chosen, and the stories are examined to see if the effort estimate is con-\nsistent with that date. If not, stories are added or removed from the list.\nIteration planning is the first stage in developing a deliverable system increment. \nStories to be implemented during that iteration are chosen, with the number of stories \nreflecting the time to deliver an workable system (usually 2 or 3 weeks) and the team\u2019s \nvelocity. When the delivery date is reached, the development iteration is complete, \neven if all of the stories have not been implemented. The team considers the stories \nthat have been implemented and adds up their effort points. The velocity can then be \nrecalculated, and this measure is used in planning the next version of the system.\nAt the start of each development iteration, there is a task planning stage where the \ndevelopers break down stories into development tasks. A development task should \ntake 4\u201316 hours. All of the tasks that must be completed to implement all of the sto-\nries in that iteration are listed. The individual developers then sign up for the specific \nRelease\nplanning\nInitial\nestimation\nStory\nidentification\nIteration\nplanning\nTask\nplanning\nFigure 23.8\u2002 The \n\u201cplanning game\u201d\n", "page": 682, "type": "text", "section": "Page 682"}
{"text": "682\u2002 \u2002 Chapter 23\u2002 \u25a0\u2002 Project planning\ntasks that they will implement. Each developer knows their individual velocity and \nso should not sign up for more tasks than they can implement in the time allotted.\nThis approach to task allocation has two important benefits:\n1.\t\nThe whole team gets an overview of the tasks to be completed in an iteration. \nThey therefore have an understanding of what other team members are doing \nand who to talk to if task dependencies are identified.\n2.\t\nIndividual developers choose the tasks to implement; they are not simply allo-\ncated tasks by a project manager. They therefore have a sense of ownership in \nthese tasks, and this is likely to motivate them to complete the task.\nHalfway through an iteration, progress is reviewed. At this stage, half of the story \neffort points should have been completed. So, if an iteration involves 24 story points \nand 36 tasks, 12 story points and 18 tasks should have been completed. If this is not \nthe case, then there has to be discussions with the customer about which stories \nshould be removed from the system increment that is being developed.\nThis approach to planning has the advantage that a software increment is always \ndelivered at the end of each project iteration. If the features to be included in the \nincrement cannot be completed in the time allowed, the scope of the work is reduced. \nThe delivery schedule is never extended. However, this can cause problems as it \nmeans that customer plans may be affected. Reducing the scope may create extra \nwork for customers if they have to use an incomplete system or change the way they \nwork between one release of the system and another.\nA major difficulty in agile planning is that it relies on customer involvement and \navailability. This involvement can be difficult to arrange, as customer representa-\ntives sometimes have to prioritize other work and are not available for the planning \ngame. Furthermore, some customers may be more familiar with traditional project \nplans and may find it difficult to engage in an agile planning process.\nAgile planning works well with small, stable development teams that can get \ntogether and discuss the stories to be implemented. However, where teams are large \nand/or geographically distributed, or when team membership changes frequently, it \nis practically impossible for everyone to be involved in the collaborative planning \nthat is essential for agile project management. Consequently, large projects are usu-\nally planned using traditional approaches to project management.\n \n23.5  Estimation techniques\nEstimating project schedules is difficult. You have to make initial estimates on the \nbasis of an incomplete user requirements definition. The software may have to run on \nunfamiliar platforms or use new development technology. The people involved in the \nproject and their skills will probably not be known. There are so many uncertainties \nthat it is impossible to estimate system development costs accurately during the early \n", "page": 683, "type": "text", "section": "Page 683"}
{"text": "\t\n23.5\u2002 \u25a0\u2002 Estimation techniques\u2002 \u2002 683\nstages of a project. Nevertheless, organizations need to make software effort and cost \nestimates. Two types of techniques can be used for making estimates:\n1.\t\nExperience-based techniques The estimate of future effort requirements is based \non the manager\u2019s experience of past projects and the application domain. \nEssentially, the manager makes an informed judgment of what the effort require-\nments are likely to be.\n2.\t\nAlgorithmic cost modeling In this approach, a formulaic approach is used to \ncompute the project effort based on estimates of product attributes, such as size, \nprocess characteristics, and experience of staff involved.\nIn both cases, you need to use your judgment to estimate either the effort directly \nor the project and product characteristics. In the startup phase of a project, these \nestimates have a wide margin of error. Based on data collected from a large number \nof projects, Boehm et al. (B. Boehm et al. 1995) discovered that startup estimates \nvary significantly. If the initial estimate of effort required is x months of effort, they \nfound that the range may be from 0.25x to 4x of the actual effort as measured when \nthe system was delivered. During development planning, estimates become more \nand more accurate as the project progresses (Figure 23.9).\nExperience-based techniques rely on the manager\u2019s experience of past projects \nand the actual effort expended in these projects on activities that are related to soft-\nware development. Typically, you identify the deliverables to be produced in a pro-\nject and the different software components or systems that are to be developed. You \ndocument these in a spreadsheet, estimate them individually, and compute the total \neffort required. It usually helps to get a group of people involved in the effort esti-\nmation and to ask each member of the group to explain their estimate. This often \nreveals factors that others have not considered, and you then iterate toward an \nagreed group estimate.\nx\n2x\n4x\n0.5x\n0.25x\nFeasibility\nRequirements\nDesign\nCode\nDelivery\nFigure 23.9\u2002 Estimate \nuncertainty\n", "page": 684, "type": "text", "section": "Page 684"}
{"text": "684\u2002 \u2002 Chapter 23\u2002 \u25a0\u2002 Project planning\nThe difficulty with experience-based techniques is that a new software project \nmay not have much in common with previous projects. Software development \nchanges very quickly, and a project will often use unfamiliar techniques such as web \nservices, application system configuration, or HTML5. If you have not worked with \nthese techniques, your previous experience may not help you to estimate the effort \nrequired, making it more difficult to produce accurate costs and schedule estimates.\nIt is impossible to say whether experience-based or algorithmic approaches are \nmore accurate. Project estimates are often self-fulfilling. The estimate is used to \ndefine the project budget, and the product is adjusted so that the budget figure is real-\nized. A project that is within budget may have achieved this at the expense of fea-\ntures in the software being developed.\nTo make a comparison of the accuracy of these techniques, a number of controlled \nexperiments would be required where several techniques were used independently to \nestimate the project effort and costs. No changes to the project would be allowed, and the \nfinal effort could them be compared. The project manager would not know the effort \nestimates, so no bias would be introduced. However, this scenario is completely impos-\nsible in real projects, so we will never have an objective comparison of these approaches.\n\t\n23.5.1 \t Algorithmic cost modeling\nAlgorithmic cost modeling uses a mathematical formula to predict project costs \nbased on estimates of the project size, the type of software being developed, and \nother team, process, and product factors. Algorithmic cost models are developed by \nanalyzing the costs and attributes of completed projects, then finding the closest-fit \nformula to the actual costs incurred.\nAlgorithmic cost models are primarily used to make estimates of software devel-\nopment costs. However, Boehm and his collaborators (B. W. Boehm et al. 2000) \ndiscuss a range of other uses for these models, such as the preparation of estimates \nfor investors in software companies, alternative strategies to help assess risks and to \ninform decisions about reuse, redevelopment, or outsourcing.\nMost algorithmic models for estimating effort in a software project are based on a \nsimple formula:\nEffort = A 3 SizeB 3 M\nA: a constant factor, which depends on local organizational practices and the type \nof software that is developed.\nSize: an assessment of the code size of the software or a functionality estimate \nexpressed in function or application points.\nB: represents the complexity of the software and usually lies between 1 and 1.5.\nM: is a factor that takes into account process, product and development attributes, \nsuch as the dependability requirements for the software and the experience of the \ndevelopment team. These attributes may increase or decrease the overall diffi-\nculty of developing the system.\n", "page": 685, "type": "text", "section": "Page 685"}
{"text": "\t\n23.5\u2002 \u25a0\u2002 Estimation techniques\u2002 \u2002 685\nThe number of lines of source code (SLOC) in the delivered system is the funda-\nmental size metric that is used in many algorithmic cost models. To estimate the \nnumber of lines of code in a system, you may use a combination of approaches:\n1.\t\nCompare the system to be developed with similar systems and use their code \nsize as the basis for your estimate.\n2.\t\nEstimate the number of function or application points in the system (see the fol-\nlowing section) and formulaically convert these to lines of code in the program-\nming language used.\n3.\t\nRank the system components using judgment of their relative sizes and use a \nknown reference component to translate this ranking to code sizes.\nMost algorithmic estimation models have an exponential component (B in the \nabove equation) that increases with the size and complexity of the system. This \nreflects the fact that costs do not usually increase linearly with project size. As the \nsize and complexity of the software increase, extra costs are incurred because of the \ncommunication overhead of larger teams, more complex configuration management, \nmore difficult system integration, and so on. The more complex the system, the more \nthese factors affect the cost.\nThe idea of using a scientific and objective approach to cost estimation is an \nattractive one, but all algorithmic cost models suffer from two key problems:\n1.\t\nIt is practically impossible to estimate Size accurately at an early stage in a pro-\nject, when only the specification is available. Function-point and application-\npoint estimates (see later) are easier to produce than estimates of code size but \nare also usually inaccurate.\n2.\t\nThe estimates of the complexity and process factors contributing to B and M are \nsubjective. Estimates vary from one person to another, depending on their back-\nground and experience of the type of system that is being developed.\nAccurate code size estimation is difficult at an early stage in a project because the \nsize of the final program depends on design decisions that may not have been made \nwhen the estimate is required. For example, an application that requires \u00ad\nhigh-performance \ndata management may either implement its own data management system or use a \ncommercial database system. In the initial cost estimation, you are unlikely to know \nif there is a commercial database system that performs well enough to meet the per-\nformance requirements. You therefore don\u2019t know how much data management \ncode will be included in the system.\nThe programming language used for system development also affects the number \nof lines of code to be developed. A language like Java might mean that more lines of \ncode are necessary than if C (say) was used. However, this extra code allows more \ncompile-time checking, so validation costs are likely to be reduced. It is not clear \nhow this should be taken into account in the estimation process. Code reuse also \n", "page": 686, "type": "text", "section": "Page 686"}
{"text": "686\u2002 \u2002 Chapter 23\u2002 \u25a0\u2002 Project planning\nmakes a difference, and some models explicitly estimate the number of lines of code \nreused. However, if application systems or external services are reused, it is very \ndifficult to compute the number of lines of source code that these replace.\nAlgorithmic cost models are a systematic way to estimate the effort required to \ndevelop a system. However, these models are complex and difficult to use. There are \nmany attributes and considerable scope for uncertainty in estimating their values. \nThis complexity means that the practical application of algorithmic cost modeling \nhas been limited to a relatively small number of large companies, mostly working in \ndefense and aerospace systems engineering.\nAnother barrier that discourages the use of algorithmic models is the need for \ncalibration. Model users should calibrate their model and the attribute values \nusing their own historical project data, as this reflects local practice and experi-\nence. However, very few organizations have collected enough data from past pro-\njects in a form that supports model calibration. Practical use of algorithmic \nmodels, therefore, has to start with the published values for the model parameters. \nIt is practically impossible for a modeler to know how closely these relate to his \nor her organization.\nIf you use an algorithmic cost estimation model, you should develop a range of \nestimates (worst, expected, and best) rather than a single estimate and apply the \ncosting formula to all of them. Estimates are most likely to be accurate when you \nunderstand the type of software that is being developed and have calibrated the cost-\ning model using local data, or when programming language and hardware choices \nare predefined.\n \n23.6  COCOMO cost modeling\nThe best known algorithmic cost modeling technique and tool is the COCOMO II \nmodel. This empirical model was derived by collecting data from a large number of \nsoftware projects of different sizes. These data were analyzed to discover the formu-\nlas that were the best fit to the observations. These formulas linked the size of the \nSoftware productivity\nSoftware productivity is an estimate of the average amount of development work that software engineers \u00ad\ncomplete \nin a week or a month. It is therefore expressed as lines of code/month, function points/month, and so forth.\nHowever, while productivity can be easily measured where there is a tangible outcome (e.g., an administrator \nprocesses N travel claims/day), software productivity is more difficult to define. Different people may implement \nthe same functionality in different ways, using different numbers of lines of code. The quality of the code is also \nimportant but is, to some extent, subjective. Therefore, you can\u2019t really compare the productivity of individual \nengineers. It only makes sense to use productivity measures with large groups.\nhttp://software-engineering-book.com/web/productivity/\n", "page": 687, "type": "text", "section": "Page 687"}
{"text": "\t\n23.6\u2002 \u25a0\u2002 COCOMO cost modeling\u2002 \u2002 687\nsystem and product, project, and team factors to the effort to develop the system. \nCOCOMO II is a freely available model that is supported with open-source tools.\nCOCOMO II was developed from earlier COCOMO (Constructive Cost \nModeling) cost estimation models, which were largely based on original code devel-\nopment (B. W. Boehm 1981; B. Boehm and Royce 1989). The COCOMO II model \ntakes into account modern approaches to software development, such as rapid devel-\nopment using dynamic languages, development with reuse, and database program-\nming. COCOMO II embeds several submodels based on these techniques, which \nproduce increasingly detailed estimates.\nThe submodels (Figure 23.10) that are part of the COCOMO II model are:\n1.\t\nAn application composition model This models the effort required to develop \nsystems that are created from reusable components, scripting, or database pro-\ngramming. Software size estimates are based on application points, and a simple \nsize/productivity formula is used to estimate the effort required.\n2.\t\nAn early design model This model is used during early stages of the system \ndesign after the requirements have been established. The estimate is based on the \nstandard estimation formula that I discussed in the introduction of this chapter, \nwith a simplified set of seven multipliers. Estimates are based on function points, \nwhich are then converted to number of lines of source code.\n\t\nFunction points are a language-independent way of quantifying program func-\ntionality. You compute the total number of function points in a program by \nmeasuring or estimating the number of external inputs and outputs, user interac-\ntions, external interfaces, and files or database tables used by the system.\nNumber of\napplication points\nNumber of function\npoints\nBased on\nUsed for\nUsed for\nUsed for\nUsed for\nBased on\nBased on\nBased on\nNumber of lines of\ncode reused or\ngenerated\nNumber of lines of\nsource code\nApplication\ncomposition model\nEarly design model\nReuse model\nPost-architecture\nmodel\nSystems developed\nusing dynamic\nlanguages, DB\nprogramming etc.\nInitial effort\nestimation based on\nsystem requirements\nand design options\nEffort to integrate\nreusable components\nor automatically\ngenerated code\nDevelopment effort\nbased on system\ndesign specification\nFigure 23.10\u2002 COCOMO \nestimation models\n", "page": 688, "type": "text", "section": "Page 688"}
{"text": "688\u2002 \u2002 Chapter 23\u2002 \u25a0\u2002 Project planning\n3.\t\nA reuse model This model is used to compute the effort required to integrate \nreusable components and/or automatically generated program code. It is nor-\nmally used in conjunction with the post-architecture model.\n4.\t\nA post-architecture model Once the system architecture has been designed, a \nmore accurate estimate of the software size can be made. Again, this model uses \nthe standard formula for cost estimation discussed above. However, it includes \na more extensive set of 17 multipliers reflecting personnel capability, product, \nand project characteristics.\nOf course, in large systems, different parts of the system may be developed using \ndifferent technologies, and you may not have to estimate all parts of the system to \nthe same level of accuracy. In such cases, you can use the appropriate submodel for \neach part of the system and combine the results to create a composite estimate.\nThe COCOMO II model is a very complex model and, to make it easier to explain, \nI have simplified its presentation. You could use the models as I have explained them \nhere for simple cost estimation. However, to use COCOMO properly, you should refer \nto Boehm\u2019s book and the manual for the COCOMO II model (B. W. Boehm et al. \n2000; Abts et al. 2000).\n\t\n23.6.1 \t The application composition model\nThe application composition model was introduced into COCOMO II to support \nthe estimation of effort required for prototyping projects and for projects where \nthe software is developed by composing existing components. It is based on an \nestimate of weighted application points (sometimes called object points), divided \nby a standard estimate of application point productivity (B. W. Boehm et al. \n2000). The number of application points in a program is derived from four sim-\npler estimates:\n\u25a0\t the number of separate screens or web pages that are displayed;\n\u25a0\t the number of reports that are produced;\n\u25a0\t the number of modules in imperative programming languages (such as Java); and\n\u25a0\t the number of lines of scripting language or database programming code.\nThis estimate is then adjusted according to the difficulty of developing each \napplication point. Productivity depends on the developer\u2019s experience and capability \nas well as the capabilities of the software tools (ICASE) used to support develop-\nment. Figure 23.11 shows the levels of application-point productivity suggested by \nthe COCOMO model developers.\nApplication composition usually relies on reusing existing software and configur-\ning application systems. Some of the application points in the system will therefore \nbe implemented using reusable components. Consequently, you have to adjust the \n", "page": 689, "type": "text", "section": "Page 689"}
{"text": "\t\n23.6\u2002 \u25a0\u2002 COCOMO cost modeling\u2002 \u2002 689\nestimate to take into account the percentage of reuse expected. Therefore, the final \nformula for effort computation for system prototypes is:\nPM 5 (NAP 3 (1 2 %reuse/100)) / PROD\nPM: the effort estimate in person-months.\nNAP: the total number of application points in the delivered system.\n%reuse: an estimate of the amount of reused code in the development.\nPROD: the application-point productivity as shown in Figure 23.11.\n\t\n23.6.2 \t The early design model\nThis model may be used during the early stages of a project, before a detailed archi-\ntectural design for the system is available. The early design model assumes that user \nrequirements have been agreed and initial stages of the system design process are \nunderway. Your goal at this stage should be to make a quick and approximate cost \nestimate. Therefore, you have to make simplifying assumptions, such as the assump-\ntion that there is no effort involved in integrating reusable code.\nEarly design estimates are most useful for option exploration where you need to \ncompare different ways of implementing the user requirements. The estimates pro-\nduced at this stage are based on the standard formula for algorithmic models, namely:\nEffort 5 A 3 SizeB 3 M\nBased on his own large dataset, Boehm proposed that the co-efficient A should be \n2.94. The size of the system is expressed in KSLOC, which is the number of thou-\nsands of lines of source code. You calculate KSLOC by estimating the number of \nfunction points in the software. You then use standard tables, which relate software \nsize to function points for different programming languages (QSM 2014) to compute \nan initial estimate of the system size in KSLOC.\nThe exponent B reflects the increased effort required as the size of the project \nincreases. This can vary from 1.1 to 1.24 depending on the novelty of the project, the \ndevelopment flexibility, the risk resolution processes used, the cohesion of the \ndevelopment team, and the process maturity level (see web Chapter 26) of the organ-\nization. I discuss how the value of this exponent is calculated using these parameters \nin the description of the COCOMO II post-architecture model.\nDeveloper\u2019s \nexperience and \ncapability\nVery low\nLow\nNominal\nHigh\nVery high\nICASE maturity and \ncapability\nVery low\nLow\nNominal\nHigh\nVery high\nPROD (NAP/month)\n4\n7\n13\n25\n50\nFigure 23.11\u2002  \nApplication- \npoint productivity\n", "page": 690, "type": "text", "section": "Page 690"}
{"text": "690\u2002 \u2002 Chapter 23\u2002 \u25a0\u2002 Project planning\nThis results in an effort computation as follows:\nPM 5 2.94 3 Size(1.1 to 1.24) 3 M\nM 5 PERS 3 PREX 3 RCPX 3 RUSE 3 PDIF 3 SCED 3 FSIL\nPERS: personnel capability\nPREX: personnel experience\nRCPX: product reliability and complexity\nRUSE: reuse required\nPDIF: platform difficulty\nSCED: schedule\nFSIL: support facilities\nThe multiplier M is based on seven project and process attributes that increase or \ndecrease the estimate. I explain these attributes on the book\u2019s web pages. You esti-\nmate values for these attributes using a six-point scale, where 1 corresponds to \u201cvery \nlow\u201d and 6 corresponds to \u201cvery high\u201d; for example, PERS = 6 means that expert \nstaff are available to work on the project.\n\t\n23.6.3 \t The reuse model\nThe COCOMO reuse model is used to estimate the effort required to integrate reus-\nable or generated code. As I have discussed in Chapter 15, software reuse is now the \nnorm in all software development. Most large systems include a significant amount \nof code that has been reused from previous development projects.\nCOCOMO II considers two types of reused code. Black-box code is code that can be \nreused without understanding the code or making changes to it. Examples of black-box \ncode are components that are automatically generated from UML models or application \nlibraries such as graphics libraries. It is assumed that the development effort for black-\nbox code is zero. Its size is not taken into account in the overall effort computation.\nWhite-box code is reusable code that has to be adapted to integrate it with new \ncode or other reused components. Development effort is required for reuse because \nthe code has to be understood and modified before it can work correctly in the sys-\ntem. White-box code could be automatically generated code that needs manual \nchanges or additions. Alternatively, it can be reused components from other systems \nthat have to be modified in the system that is being developed.\nThree factors contribute to the effort involved in reusing white-box code components:\n1.\t\nThe effort involved in assessing whether or not a component could be reused in \na system that is being developed.\n2.\t\nThe effort required to understand the code that is being reused.\n3.\t\nThe effort required to modify the reused code to adapt it and integrate it with the \nsystem being developed.\n", "page": 691, "type": "text", "section": "Page 691"}
{"text": "\t\n23.6\u2002 \u25a0\u2002 COCOMO cost modeling\u2002 \u2002 691\nThe development effort in the reuse model is calculated using the COCOMO \nearly design model and is based on the total number of lines of code in the system. \nThe code size includes new code developed for components that are not reused plus \nan additional factor that allows for the effort involved in reusing and integrating \nexisting code. This additional factor is called ESLOC, the equivalent number of lines \nof new source code. That is, you express the reuse effort as the effort that would be \ninvolved in developing some additional source code.\nThe formula used to calculate the source code equivalence is:\nESLOC 5 (ASLOC 3 (1-AT/100) 3 AAM)\nESLOC: the equivalent number of lines of new source code.\nASLOC: an estimate of the number of lines of code in the reused components that \nhave to be changed.\nAT: the percentage of reused code that can be modified automatically.\nAAM: an Adaptation Adjustment Multiplier that reflects the additional effort \nrequired to reuse components.\nIn some cases, the adjustments required to reuse code are syntactic and can be \nimplemented by an automated tool. These do not involve significant effort, so you \nshould estimate what fraction of the changes made to reused code can be automated \n(AT). This reduces the total number of lines of code that have to be adapted.\nThe Adaptation Adjustment Multiplier (AAM) adjusts the estimate to reflect the \nadditional effort required to reuse code. The COCOMO model documentation (Abts \net al. 2000) discusses in detail how AAM should be calculated. Simplistically, AAM is \nthe sum of three components:\n1.\t\nAn assessment factor (referred to as AA)  that represents the effort involved in \ndeciding whether or not to reuse components. AA varies from 0 to 8 depending \non the amount of time you need to spend looking for and assessing potential \ncandidates for reuse.\n2.\t\nAn understanding component (referred to as SU) that represents the costs of \nunderstanding the code to be reused and the familiarity of the engineer with the \ncode that is being reused. SU ranges from 50 for complex, unstructured code to \n10 for well-written, object-oriented code.\n3.\t\nAn adaptation component (referred to as AAF) that represents the costs of making \nchanges to the reused code. These include design, code, and integration changes.\nOnce you have calculated a value for ESLOC, you apply the standard estimation \nformula to calculate the total effort required, where the Size parameter = ESLOC. \nTherefore, the formula to estimate the reuse effort is:\nEffort 5 A 3 ESLOCB 3 M\nwhere A, B, and M have the same values as used in the early design model.\n", "page": 692, "type": "text", "section": "Page 692"}
{"text": "692\u2002 \u2002 Chapter 23\u2002 \u25a0\u2002 Project planning\n\t\n23.6.4 \t The post-architecture level\nThe post-architecture model is the most detailed of the COCOMO II models. It is \nused when you have an initial architectural design for the system. The starting point \nfor estimates produced at the post-architecture level is the same basic formula used \nin the early design estimates:\nPM 5 A 3 SizeB 3 M\nBy this stage in the process, you should be able to make a more accurate estimate \nof the project size, as you know how the system will be decomposed into subsystems \nand components. You make this estimate of the overall code size by adding three \ncode size estimates:\n1.\t\nAn estimate of the total number of lines of new code to be developed (SLOC).\n2.\t\nAn estimate of the reuse costs based on an equivalent number of source lines of \ncode (ESLOC), calculated using the reuse model.\n3.\t\nAn estimate of the number of lines of code that may be changed because of \nchanges to the system requirements.\nThe final component in the estimate\u2014the number of lines of modified code\u2014\nreflects the fact that software requirements always change. This leads to rework and \ndevelopment of extra code, which you have to take into account. Of course there will \noften be even more uncertainty in this figure than in the estimates of new code to be \ndeveloped.\nThe exponent term (B) in the effort computation formula is related to the lev-\nels of project complexity. As projects become more complex, the effects of \nincreasing system size become more significant. The value of the exponent B is \nbased on five factors, as shown in Figure 23.12. These factors are rated on a six-\npoint scale from 0 to 5, where 0 means \u201cextra high\u201d and 5 means \u201cvery low.\u201d To \ncalculate B, you add the ratings, divide them by 100, and add the result to 1.01 to \nget the exponent that should be used.\nCOCOMO cost drivers\nCOCOMO II cost drivers are attributes that reflect some of the product, team, process, and organizational factors \nthat affect the amount of effort needed to develop a software system. For example, if a high level of reliability is \nrequired, extra effort will be needed; if there is a need for rapid delivery, extra effort will be required; if the team \nmembers change, extra effort will be required.\nThere are 17 of these attributes in the COCOMO II model, which have been assigned estimated values by the \nmodel developers.\nhttp://software-engineering-book.com/web/cost-drivers/\n", "page": 693, "type": "text", "section": "Page 693"}
{"text": "\t\n23.6\u2002 \u25a0\u2002 COCOMO cost modeling\u2002 \u2002 693\nFor example, imagine that an organization is taking on a project in a domain in which \nit has little previous experience. The project client has not defined the process to be used or \nallowed time in the project schedule for significant risk analysis. A new development team \nmust be put together to implement this system. The organization has recently put in place \na process improvement program and has been rated as a Level 2 organization according to \nthe SEI capability assessment, as discussed in Chapter 26 (web chapter). These character-\nistics lead to estimates of the ratings used in exponent calculation as follows:\n1.\t\nPrecedentedness, rated low (4). This is a new project for the organization.\n2.\t\nDevelopment flexibility, rated very high (1). There is no client involvement in \nthe development process, so there are few externally imposed changes.\n3.\t\nArchitecture/risk resolution, rated very low (5). There has been no risk analysis \ncarried out.\n4.\t\nTeam cohesion, rated nominal (3). This is a new team, so there is no information \navailable on cohesion.\n5.\t\nProcess maturity, rated nominal (3). Some process control is in place.\nThe sum of these values is 16. You then calculate the final value of the exponent \nby dividing this sum by 100 and adding 0.01 to the result. The adjusted value of B is \ntherefore 1.17.\nThe overall effort estimate is refined using an extensive set of 17 product, pro-\ncess, and organizational attributes (see breakout box) rather than the seven attributes \nused in the early design model. You can estimate values for these attributes because \nyou have more information about the software itself, its non-functional require-\nments, the development team, and the development process.\nScale factor\nExplanation\nArchitecture/risk resolution\nReflects the extent of risk analysis carried out. Very low means little analysis; \nextra-high means a complete and thorough risk analysis.\nDevelopment flexibility\nReflects the degree of flexibility in the development process. Very low means \na prescribed process is used; extra-high means that the client sets only \ngeneral goals.\nPrecedentedness\nReflects the previous experience of the organization with this type of project. \nVery low means no previous experience; extra-high means that the \norganization is completely familiar with this application domain.\nTeam cohesion\nReflects how well the development team knows each other and works \ntogether. Very low means very difficult interactions; extra-high means an \nintegrated and effective team with no communication problems.\nProcess maturity\nReflects the process maturity of the organization as discussed in web  \nchapter 26. The computation of this value depends on the CMM Maturity \nQuestionnaire, but an estimate can be achieved by subtracting the CMM \nprocess maturity level from 5.\nFigure 23.12\u2002 Scale \nfactors used in the \nexponent computation \nin the post-architecture \nmodel\n", "page": 694, "type": "text", "section": "Page 694"}
{"text": "694\u2002 \u2002 Chapter 23\u2002 \u25a0\u2002 Project planning\n Figure 23.13 shows how the cost driver attributes influence effort estimates. \nAssume that the exponent value is 1.17 as discussed in the above example. Reliability \n(RELY), complexity (CPLX), storage (STOR), tools (TOOL), and schedule (SCED) are \nthe key cost drivers in the project. All of the other cost drivers have a nominal value \nof 1, so they do not affect the effort computation.\nIn Figure 23.13, I have assigned maximum and minimum values to the key cost \ndrivers to show how they influence the effort estimate. The values used are those \nfrom the COCOMO II reference manual (Abts et al. 2000). You can see that high \nvalues for the cost drivers lead an effort estimate that is more than three times the \ninitial estimate, whereas low values reduce the estimate to about one third of the \noriginal. This highlights the significant differences between different types of \nproject and the difficulties of transferring experience from one application domain \nto another.\n\t\n23.6.5 \t Project duration and staffing\nAs well as estimating the overall costs of a project and the effort that is required to \ndevelop a software system, project managers must also estimate how long the soft-\nware will take to develop and when staff will be needed to work on the project. \nIncreasingly, organizations are demanding shorter development schedules so that \ntheir products can be brought to market before their competitor\u2019s.\nExponent value\n1.17\nSystem size (including factors for reuse and \nrequirements volatility)\n128 KLOC\nInitial COCOMO estimate without cost drivers\n730 person-months\nReliability\nVery high, multiplier = 1.39\nComplexity\nVery high, multiplier = 1.3\nMemory constraint\nHigh, multiplier = 1.21\nTool use\nLow, multiplier = 1.12\nSchedule\nAccelerated, multiplier = 1.29\nAdjusted COCOMO estimate\n2306 person-months\nReliability\nVery low, multiplier = 0.75\nComplexity\nVery low, multiplier = 0.75\nMemory constraint\nNone, multiplier = 1\nTool use\nVery high, multiplier = 0.72\nSchedule\nNormal, multiplier = 1\nAdjusted COCOMO estimate\n295 person-months\nFigure 23.13\u2002  \nThe effect of cost  \ndrivers on effort \nestimates\n", "page": 695, "type": "text", "section": "Page 695"}
{"text": "\t\n23.6\u2002 \u25a0\u2002 COCOMO cost modeling\u2002 \u2002 695\nThe COCOMO model includes a formula to estimate the calendar time required \nto complete a project:\nTDEV 5 3 3 (PM)(0.33 1 0.2*(B 2 1.01))\nTDEV: the nominal schedule for the project, in calendar months, ignoring any mul-\ntiplier that is related to the project schedule.\nPM: the effort computed by the COCOMO model.\nB: a complexity-related exponent, as discussed in section 23.5.2.\nIf B 5 1.17 and PM = 60 then\nTDEV 5 3 3 (60)0.36 5 13 months\nThe nominal project schedule predicted by the COCOMO model does not neces-\nsarily correspond with the schedule required by the software customer. You may \nhave to deliver the software earlier or (more rarely) later than the date suggested by \nthe nominal schedule. If the schedule is to be compressed (i.e., software is to be \ndeveloped more quickly), this increases the effort required for the project. This is \ntaken into account by the SCED multiplier in the effort estimation computation.\nAssume that a project estimated TDEV as 13 months, as suggested above, but the \nactual schedule required was 10 months. This represents a schedule compression of \napproximately 25%. Using the values for the SCED multiplier as derived by Boehm\u2019s \nteam, we see that the effort multiplier for this level of schedule compression is 1.43. \nTherefore, the actual effort that will be required if this accelerated schedule is to be \nmet is almost 50% more than the effort required to deliver the software according to \nthe nominal schedule.\nThere is a complex relationship between the number of people working on a pro-\nject, the effort that will be devoted to the project. and the project delivery schedule. \nIf four people can complete a project in 13 months (i.e., 52 person-months of effort), \nthen you might think that by adding one more person, you could complete the work \nin 11 months (55 person-months of effort). However, the COCOMO model suggests \nthat you will, in fact, need six people to finish the work in 11 months (66 person-\nmonths of effort).\nThe reason for this is that adding people to a project reduces the productivity of \nexisting team members. As the project team increases in size, team members spend \nmore time communicating and defining interfaces between the parts of the system \ndeveloped by other people. Doubling the number of staff (for example) therefore \ndoes not mean that the duration of the project will be halved.\nConsequently, when you add an extra person, the actual increment of effort added \nis less than one person as others become less productive. If the development team is \nlarge, adding more people to a project sometimes increases rather than reduces the \ndevelopment schedule because of the overall effect on productivity.\nYou cannot simply estimate the number of people required for a project team by \ndividing the total effort by the required project schedule. Usually, a small number of \npeople are needed at the start of a project to carry out the initial design. The team then \n", "page": 696, "type": "text", "section": "Page 696"}
{"text": "696\u2002 \u2002 Chapter 23\u2002 \u25a0\u2002 Project planning\nbuilds up to a peak during the development and testing of the system, and then declines \nin size as the system is prepared for deployment. A very rapid build-up of project staff \nhas been shown to correlate with project schedule slippage. As a project manager, you \nshould therefore avoid adding too many staff to a project early in its lifetime.\nKey Points\n\u25a0\t The price charged for a system does not just depend on its estimated development costs and \nthe profit required by the development company. Organizational factors may mean that the \nprice is increased to compensate for increased risk or decreased to gain competitive advantage.\n\u25a0\t Software is often priced to gain a contract, and the functionality of the system is then adjusted \nto meet the estimated price.\n\u25a0\t Plan-driven development is organized around a complete project plan that defines the project \nactivities, the planned effort, the activity schedule, and who is responsible for each activity.\n\u25a0\t Project scheduling involves the creation of various graphical representations of part of the \n\u00ad\nproject plan. Bar charts, which show the activity duration and staffing timelines, are the most \ncommonly used schedule representations.\n\u25a0\t A project milestone is a predictable outcome of an activity or set of activities. At each milestone, \na formal report of progress should be presented to management. A deliverable is a work product \nthat is delivered to the project customer.\n\u25a0\t The agile planning game involves the whole team in project planning. The plan is developed \nincrementally, and, if problems arise, it is adjusted so that software functionality is reduced \ninstead of delaying the delivery of an increment.\n\u25a0\t Estimation techniques for software may be experience-based, where managers judge the effort \nrequired, or algorithmic, where the effort required is computed from other estimated project \nparameters.\n\u25a0\t The COCOMO II costing model is a mature algorithmic cost model that takes project, product, \nhardware, and personnel attributes into account when formulating a cost estimate.\nFurther Reading\nFurther reading suggested in Chapter 22 is also relevant to this chapter.\n\u201cTen Unmyths of Project Estimation.\u201d A pragmatic article that discusses the practical difficulties of \nproject estimation and challenges some fundamental assumptions in this area. (P. Armour, Comm. \nACM, 45(11), November 2002). http://dx.doi.org/10.1145/581571.581582\n", "page": 697, "type": "text", "section": "Page 697"}
{"text": "\t\nChapter 23\u2002 \u25a0\u2002 Exercises\u2002 \u2002 697\n Agile Estimating and Planning. This book is a comprehensive description of story-based planning \nas used in XP, as well as a rationale for using an agile approach to project planning. The book also \nincludes a good, general introduction to project planning issues. (M. Cohn, 2005, Prentice-Hall).\n\u201cAchievements and Challenges in COCOMO-based Software Resource Estimation.\u201d This article \n\u00ad\npresents a history of the COCOMO models and influences on these models, and discusses the variants \nof these models that have been developed. It also identifies further possible developments in the \nCOCOMO approach. (B. W. Boehm and R. Valeridi, IEEE Software, 25 (5), September/October 2008).\nhttp://dx.doi.org/10.1109/MS.2008.133\nAll About Agile; Agile Planning. This website on agile methods includes an excellent set of articles \non agile planning from a number of different authors. (2007\u20132012). http://www.allaboutagile.com/\ncategory/agile-planning/\nProject Management Knowhow: Project Planning. This website has a number of useful articles on \nproject management in general. These are aimed at people who don\u2019t have previous experience in \nthis area. (P. Stoemmer, 2009\u20132014). http://www.project-management-knowhow.com/project_\nplanning.html\nWebsite\nPowerPoint slides for this chapter:\nwww.pearsonglobaleditions.com/Sommerville\nLinks to supporting videos:\nhttp://software-engineering-book.com/videos/software-management/\nExercises\n23.1.\t Describe the factors that affect software pricing. Define the \u201cpricing to win\u201d approach in \n\u00ad\nsoftware pricing.\n23.2.\t Explain why the process of project planning is iterative and why a plan must be continually \nreviewed during a software project.\n23.3.\t Define project scheduling. What are the things to be considered while estimating schedules?\n23.4.\t What is algorithmic cost modeling? What problems does it suffer from when compared with \nother approaches to cost estimation?\n23.5.\t Figure 23.14 sets out a number of tasks, their durations, and their dependencies. Draw a bar \nchart showing the project schedule.\n", "page": 698, "type": "text", "section": "Page 698"}
{"text": "23.6.\t Figure 23.14 shows the task durations for software project activities. Assume that a serious, \nunanticipated setback occurs, and instead of taking 10 days, task T5 takes 40 days. Draw up \nnew bar charts showing how the project might be reorganized.\n23.7.\t The planning game is based on the notion of planning to implement the stories that represent \nthe system requirements. Explain the potential problems with this approach when software \nhas high performance or dependability requirements.\n23.8.\t A software manager is in charge of the development of a safety-critical software system, \nwhich is designed to control a radiotherapy machine to treat patients suffering from cancer. \nThis system is embedded in the machine and must run on a special-purpose processor with a \nfixed amount of memory (256 Mbytes). The machine communicates with a patient database \nsystem to obtain the details of the patient and, after treatment, automatically records the \nradiation dose delivered and other treatment details in the database.\n\t \t\nThe COCOMO method is used to estimate the effort required to develop this system, and an \nestimate of 26 person-months is computed. All cost driver multipliers were set to 1 when \n\u00ad\nmaking this estimate.\nTask\nDuration\nDependencies\nT1\n10\nT2\n15\nT1\nT3\n10\nT1, T2\nT4\n20\nT5\n10\nT6\n15\nT3, T4\nT7\n20\nT3\nT8\n35\nT7\nT9\n15\nT6\nT10\n5\nT5, T9\nT11\n10\nT9\nT12\n20\nT10\nT13\n35\nT3, T4\nT14\n10\nT8, T9\nT15\n20\nT12, T14\nT16\n10\nT15\nFigure 23.14\u2002  \nScheduling example\n698\u2002 \u2002 Chapter 23\u2002 \u25a0\u2002 Project planning\n", "page": 699, "type": "text", "section": "Page 699"}
{"text": "\t\n\t \u0007\nExplain why this estimate should be adjusted to take project, personnel, product, and \n\u00ad\norganizational factors into account. Suggest four factors that might have significant effects \non the initial COCOMO estimate and propose possible values for these factors. Justify why \nyou have included each factor.\n\u2002 23.9.\t \u0007\nSome very large software projects involve writing millions of lines of code. Explain why the \neffort estimation models, such as COCOMO, might not work well when applied to very large \nsystems.\n23.10.\t \u0007\nIs it ethical for a company to quote a low price for a software contract knowing that the \nrequirements are ambiguous and that they can charge a high price for subsequent changes \nrequested by the customer?\nReferences\nAbts, C., B. Clark, S. Devnani-Chulani, and B. W. Boehm. 2000. \u201cCOCOMO II Model Definition Manual.\u201d \nCenter for Software Engineering, University of Southern California. http://csse.usc.edu/csse/\nresearch/COCOMOII/cocomo2000.0/CII_modelman2000.0.pdf\nBeck, K., and C. Andres. 2004. Extreme Programming Explained: 2nd ed. Boston: Addison-Wesley.\nBoehm, B., B. Clark, E. Horowitz, C. Westland, R. Madachy, and R. Selby. 1995. \u201cCost Models for \nFuture Software Life Cycle Processes: COCOMO 2.\u201d Annals of Software Engineering: 1\u201331. \ndoi:10.1007/BF02249046.\nBoehm, B., and W. Royce. 1989. \u201cAda COCOMO and the Ada Process Model.\u201d In Proc. 5th COCOMO \nUsers\u2019 Group Meeting. Pittsburgh: Software Engineering Institute. http://www.dtic.mil/dtic/tr/ \nfulltext/u2/a243476.pdf\nBoehm, B. W. 1981. Software Engineering Economics. Englewood Cliffs, NJ: Prentice-Hall.\nBoehm, B. W., C. Abts, A. W. Brown, S. Chulani, B K. Clark, E. Horowitz, R. Madachy, D. Reifer, and  \nB. Steece. 2000. Software Cost Estimation with COCOMO II. Englewood Cliffs, NJ: Prentice-Hall.\nCohn, M. 2005. Agile Estimating and Planning. Englewood-Cliffs, NJ: Prentice Hall.\nQSM. 2014. \u201cFunction Point Languages Table.\u201d http://www.qsm.com/resources/function-point- \nlanguages-table\nRubin, K. S. 2013. Essential Scrum. Boston: Addison-Wesley.\n\t\nChapter 23\u2002 \u25a0\u2002 References\u2002 \u2002 699\n", "page": 700, "type": "text", "section": "Page 700"}
{"text": "Quality management\n24 \nObjectives\nThe objectives of this chapter are to introduce software quality \nmanagement and software measurement. When you have read the \nchapter, you will:\n\u25a0\t have been introduced to the quality management process and \nknow why quality planning is important;\n\u25a0\t be aware of the importance of standards in the quality management \nprocess and know how standards are used in quality assurance;\n\u25a0\t understand how reviews and inspections are used as a mechanism \nfor\u00a0software quality assurance;\n\u25a0\t understand how quality management in agile methods is based on \nthe\u00a0development of a team quality culture;\n\u25a0\t understand how measurement may be helpful in assessing some \nsoftware quality attributes, the notion of software analytics, and \nthe limitations of software measurement.\nContents\n24.1 \tSoftware quality\n24.2 \tSoftware standards\n24.3 \tReviews and inspections\n24.4 \tQuality management and agile development\n24.5 \tSoftware measurement\n", "page": 701, "type": "text", "section": "Page 701"}
{"text": " \nChapter 24\u2002 \u25a0\u2002 Quality management\u2002 \u2002 701\nSoftware quality management is concerned with ensuring that developed software \nsystems are \u201cfit for purpose.\u201d That is, systems should meet the needs of their users, \nshould perform efficiently and reliably, and should be delivered on time and within \nbudget. The use of quality management techniques along with new software tech-\nnologies and testing methods has led to significant improvements in the level of \nsoftware quality over the past 20 years.\nFormalized quality management (QM) is particularly important in teams that are \ndeveloping large, long-lifetime systems that take several years to develop. These systems \nare developed for external clients, usually using a plan-based process. For these systems, \nquality management is both an organizational and an individual project issue:\n1.\t\nAt an organizational level, quality management is concerned with establishing a \nframework of organizational processes and standards that will lead to high-quality \nsoftware. The QM team should take responsibility for defining the software \ndevelopment processes to be used and standards that should apply to the software \nand related documentation, including the system requirements, design, and code.\n2.\t\nAt a project level, quality management involves the application of specific qual-\nity processes, checking that these planned processes have been followed, and \nensuring that the project outputs meet the defined project standards. Project \nquality management may also involve defining a quality plan for a project. The \nquality plan should set out the quality goals for the project and define what \n\u00ad\nprocesses and standards are to be used.\nSoftware quality management techniques have their roots in methods and techniques \nthat were developed in manufacturing industries, where the terms quality assurance and \nquality control are widely used. Quality assurance is the definition of processes and \nstandards that should lead to high-quality products and the introduction of quality pro-\ncesses into the manufacturing process. Quality control is the application of these quality \nprocesses to weed out products that are not of the required level of quality. Both quality \nassurance and quality control are part of quality management.\nIn the software industry, some companies see quality assurance as the definition \nof procedures, processes, and standards to ensure that software quality is achieved. \nIn other companies, quality assurance also includes all configuration management, \nverification, and validation activities that are applied after a product has been handed \nover by a development team.\nQuality management provides an independent check on the software develop-\nment process. The QM team checks the project deliverables to ensure that they are \nconsistent with organizational standards and goals (Figure 24.1). They also check \nprocess documentation, which records the tasks that have been completed by each \nteam working on this project. The QM team uses documentation to check that impor-\ntant tasks have not been forgotten or that one group has not made incorrect assump-\ntions about what other groups have done.\nThe QM team in large companies is usually responsible for managing the release \ntesting process. As I discussed in Chapter 8, this means that they manage the testing \nof the software before it is released to customers. In addition, they are responsible \n", "page": 702, "type": "text", "section": "Page 702"}
{"text": "702\u2002 \u2002 Chapter 24\u2002 \u25a0\u2002 Quality management\nfor checking that the system tests provide coverage of the requirements and that \nproper records of the testing process are maintained.\nThe QM team should be independent and not part of the software development \ngroup so that they can take an objective view of the quality of the software. They can \nreport on software quality without being influenced by software development issues. \nIdeally, the QM team should have organization-wide responsibility for quality man-\nagement. They should report to management above the project manager level.\nBecause project managers have to maintain the project budget and schedule, they \nmay be tempted to compromise on product quality to meet that schedule. An independ-\nent QM team ensures that the organizational goals of quality are not influenced by \nshort-term budget and schedule considerations. In smaller companies, however, this is \npractically impossible. Quality management and software development are inevitably \nintertwined with people having both development and quality responsibilities.\nFormalized quality planning is an integral part of plan-based development processes. \nIt is the process of developing a quality plan for a project. The quality plan should set \nout the desired software qualities and describe how these qualities are to be assessed. It \ndefines what \u201chigh-quality\u201d software actually means for a particular system. Engineers, \ntherefore, have a shared understanding of the most important software quality attributes.\nHumphrey (Humphrey 1989), in his classic book on software management, sug-\ngests an outline structure for a quality plan. This outline includes the following:\n1.\t\nProduct introduction A description of the product, its intended market, and the \nquality expectations for the product.\n2.\t\nProduct plans The critical release dates and responsibilities for the product, \nalong with plans for distribution and product servicing.\n3.\t\nProcess descriptions The development and service processes and standards that \nshould be used for product development and management.\n4.\t\nQuality goals The quality goals and plans for the product, including an identifi-\ncation and justification of critical product quality attributes.\n5.\t\nRisks and risk management The key risks that might affect product quality and \nthe actions to be taken to address these risks.\nSoftware development\nprocess\nQuality management\nprocess\nD1\nD2\nD3\nD4\nD5\nStandards and\nprocedures\nQuality\nplan\nQuality review reports\nFigure 24.1\u2002 Quality \nmanagement and \nsoftware development\n", "page": 703, "type": "text", "section": "Page 703"}
{"text": " \n24.1\u2002 \u25a0\u2002 Software quality\u2002 \u2002 703\nQuality plans, which are developed as part of the general project planning process, \ndiffer in detail depending on the size and type of system being developed. However, when \nwriting quality plans, you should try to keep them as short as possible. If the document is \ntoo long, people will not read it, so defeating the purpose of producing the quality plan.\nTraditional quality management is a formal process that relies on maintaining exten-\nsive documentation about testing and system validation and on how processes have \nbeen followed. In this respect, it is diametrically opposed to agile development, where \nthe aim is to spend as little time as possible in writing documents and formalizing how \nthe development work should be done. QM techniques have therefore had to evolve \nwhen agile methods are used. I discuss QM and agile development in Section 24.4.\n \n24.1  Software quality\nThe manufacturing industry established the fundamentals of quality management in \na drive to improve the quality of the products that were being made. As part of this \neffort, the industry developed a definition of quality that was based on conformance \nwith a detailed product specification. The underlying assumption was that products \ncould be completely specified and procedures could be established that could check \na manufactured product against its specification. Of course, products will never \nexactly meet a specification, so some tolerance was allowed. If the product was \n\u201calmost right,\u201d it was classed as acceptable.\nSoftware quality is not directly comparable with quality in manufacturing. The \nidea of tolerances is applicable in analog systems but does not apply to software. \nFurthermore, it is often impossible to come to an objective conclusion about whether \nor not a software system meets its specification:\n1.\t\nIt is difficult to write complete and unambiguous software requirements. \nSoftware developers and customers may interpret the requirements in different \nways, and it may be impossible to reach agreement on whether or not software \nconforms to its specification.\n2.\t\nSpecifications usually integrate requirements from several classes of stake-\nholder. These requirements are inevitably a compromise and may not include \nthe requirements of all stakeholder groups. The excluded stakeholders may \ntherefore perceive the system as a poor-quality system, even though it imple-\nments the agreed requirements.\n3.\t\nIt is impossible to measure certain quality characteristics (e.g., maintainability) \ndirectly, and so they cannot be specified in an unambiguous way. I discuss the \ndifficulties of measurement in Section 24.4.\nBecause of these problems, the assessment of software quality is a subjective \nprocess. The quality management team uses their judgment to decide if an acceptable \nlevel of quality has been achieved. They decide whether or not the software is fit for \n", "page": 704, "type": "text", "section": "Page 704"}
{"text": "704\u2002 \u2002 Chapter 24\u2002 \u25a0\u2002 Quality management\nits intended purpose. This decision involves answering questions about the system\u2019s \ncharacteristics. For example:\n1.\t\nHas the software been properly tested, and has it been shown that all require-\nments have been implemented?\n2.\t\nIs the software sufficiently dependable to be put into use?\n3.\t\nIs the performance of the software acceptable for normal use?\n4.\t\nIs the software usable?\n5.\t\nIs the software well structured and understandable?\n6.\t\nHave programming and documentation standards been followed in the develop-\nment process?\nThere is a general assumption in software quality management that the system \nwill be tested against its requirements. The judgment on whether or not it delivers \nthe required functionality should be based on the results of these tests. Therefore, the \nQM team should review the tests that have been developed and examine the test \nrecords to check that testing has been properly carried out. In some companies, the \nQM group carries out final system testing; in others, a dedicated system testing team \nreports to the system quality manager.\nThe subjective quality of a software system is largely based on its non-functional \ncharacteristics. This reflects practical user experience\u2014if the software\u2019s functional-\nity is not what is expected, then users will often just work around this deficiency and \nfind other ways to do what they want to do. However, if the software is unreliable or \ntoo slow, then it is practically impossible for them to achieve their goals.\nTherefore, software quality is not just about whether the software functionality \nhas been correctly implemented, but also depends on non-functional system attrib-\nutes as shown in Figure 24.2. These attributes reflect the software dependability, \nusability, efficiency, and maintainability.\nIt is not possible for any system to be optimized for all of these attributes. For \nexample, improving security may lead to loss of performance. The quality plan \nshould therefore define the most important quality attributes for the software that is \nbeing developed. It may be that efficiency is critical and other factors have to be \nsacrificed to achieve it. If you have emphasized the importance of efficienty in the \nquality plan, the engineers working on the development can work together to achieve \nthis. The plan should also include a definition of the quality assessment process. \nSafety\nUnderstandability\nPortability\nSecurity\nTestability\nUsability\nReliability\nAdaptability\nReusability\nResilience\nModularity\nEfficiency\nRobustness\nComplexity\nLearnability\nFigure 24.2\u2002 Software \nquality attributes\n", "page": 705, "type": "text", "section": "Page 705"}
{"text": " \n24.1\u2002 \u25a0\u2002 Software quality\u2002 \u2002 705\nThis\u00a0process should be an agreed way of assessing whether some quality, such as \nmaintainability or robustness, is present in the product.\nTraditional software quality management is based on the assumption that the qual-\nity of software is directly related to the quality of the software development process. \nThis assumption comes from manufacturing systems where product quality is inti-\nmately related to the production process. A manufacturing process involves configur-\ning, setting up, and operating the machines involved in the process. Once the machines \nare operating correctly, product quality naturally follows. You measure the quality of \nthe product and change the process until you achieve the quality level that you need. \nFigure 24.3 illustrates this process-based approach to achieving product quality.\nThere is a clear link between process and product quality in manufacturing because \nthe process is relatively easy to standardize and monitor. Once manufacturing sys-\ntems are calibrated, they can be run again and again to output high-quality products. \nHowever, software is designed rather than manufactured, and the relationship \nbetween process quality and product quality is more complex. Software design is a \ncreative process, so the influence of individual skills and experience is significant. \nExternal factors, such as the novelty of an application or commercial pressure for an \nearly product release, also affect product quality irrespective of the process used.\nWithout doubt, the development process used has a significant influence on the qual-\nity of the software, and good processes are more likely to lead to good quality software. \nProcess quality management and improvement can result in fewer defects in the software \nbeing developed. However, it is difficult to assess software quality attributes, such as reli-\nability and maintainability, without using the software for a long period. Consequently, it \nis hard to tell how process characteristics influence these attributes. Furthermore, because \nof the role of design and creativity in the software process, process standardization can \nsometimes stifle creativity, which may lead to poorer rather than better quality software.\nDefined processes are important, but quality managers should also aim to develop \na \u201cquality culture\u201d in which everyone responsible for software development is com-\nmitted to achieving a high level of product quality. They should encourage teams to \ntake responsibility for the quality of their work and to develop new approaches to \nquality improvement. While standards and procedures are the basis of quality man-\nagement, good-quality managers recognize that there are intangible aspects to software \nquality (elegance, readability, etc.) that cannot be embodied in standards. They \nshould support people who are interested in the intangible aspects of quality and \nencourage professional behavior in all team members.\nDefine process\nDevelop\nproduct\nAssess product\nquality\nStandardize\nprocess\nImprove\nprocess\nQuality\nOK\nNo\nY\nes\nFigure 24.3\u2002 Process-\nbased quality\n", "page": 706, "type": "text", "section": "Page 706"}
{"text": "706\u2002 \u2002 Chapter 24\u2002 \u25a0\u2002 Quality management\n \n24.2  Software standards\nSoftware standards play an important role in plan-based software quality management. \nAs I have discussed, an important part of quality assurance is the definition or selection \nof standards that should apply to the software development process or software product. \nAs part of this process, tools and methods to support the use of these standards may also \nbe chosen. Once standards have been selected for use, project-specific processes have to \nbe defined to monitor the use of the standards and check that they have been followed.\nSoftware standards are important for three reasons:\n1.\t\nStandards capture wisdom that is of value to the organization. They are based on \nknowledge about the best or most appropriate practice for the company. This \nknowledge is often acquired only after a great deal of trial and error. Building it into \na standard helps the company reuse this experience and avoid previous mistakes.\n2.\t\nStandards provide a framework for defining what quality means in a particular \nsetting. As I have discussed, software quality is subjective, and by using stand-\nards you establish a basis for deciding if a required level of quality has been \nachieved. Of course, this depends on setting standards that reflect user expecta-\ntions for software dependability, usability, and performance.\n3.\t\nStandards assist continuity when work carried out by one person is taken up and \ncontinued by another. Standards ensure that all engineers within an organization \nadopt the same practices. Consequently, the learning effort required when start-\ning new work is reduced.\nTwo related types of software engineering standard may be defined and used in \nsoftware quality management:\n1.\t\nProduct standards These apply to the software product being developed. They \ninclude document standards, such as the structure of requirements documents, \ndocumentation standards, such as a standard comment header for an object class \ndefinition, and coding standards, which define how a programming language \nshould be used.\nDocumentation standards\nProject documents are a tangible way of describing the different representations of a software system \n(requirements, UML, code, etc.) and its production process. Documentation standards define the organization \nof\u00a0different types of document as well as the document format. They are important because they make it easier \nto check that important material has not been omitted from documents and ensure that project documents \nhave a common \u201clook and feel.\u201d Standards may be developed for the process of writing documents, for the \n\u00ad\ndocuments themselves and for document exchange.\nhttp://software-engineering-book.com/web/documentation-standards/\n", "page": 707, "type": "text", "section": "Page 707"}
{"text": " \n24.2\u2002 \u25a0\u2002 Software standards\u2002 \u2002 707\n2.\t\nProcess standards These define the processes that should be followed during \nsoftware development. They should encapsulate good development practice. \nProcess standards may include definitions of specification, design, and valida-\ntion processes, process support tools, and a description of the documents that \nshould be written during these processes.\nExamples of product and process standards that may be used are shown in \nFigure 24.4.\nStandards have to deliver value, in the form of increased product quality. There is no \npoint in defining standards that are expensive in terms of time and effort to apply that only \nlead to marginal improvements in quality. Product standards have to be designed so that \nthey can be applied and checked in a cost-effective way, and process standards should \ninclude the definition of processes that check if product standards have been followed.\nThe software engineering standards that are used within a company are usually \nadapted from broader national or international standards. National and international \nstandards have been developed covering software engineering terminology, pro-\ngramming languages such as Java and C++, notations such as charting symbols, \nprocedures for deriving and writing software requirements, quality assurance proce-\ndures, and software verification and validation processes (IEEE 2003). More spe-\ncialized standards have been developed for safety and security critical systems.\nSoftware engineers sometimes consider standards to be overprescriptive and \nirrelevant to the technical activity of software development. This is particularly \nlikely when project standards require tedious documentation and work recording. \nAlthough they usually agree about the general need for standards, engineers often \nfind good reasons why standards are not necessarily appropriate to their particular \nproject. Quality managers who set the standards should therefore consider possible \nactions to convince engineers of the value of standards:\n1.\t\nInvolve software engineers in the selection of product standards If developers \nunderstand why standards have been selected, they are more likely to be com-\nmitted to these standards. Ideally, the standards document should not just set out \nthe standard to be followed but should also include commentary explaining why \nstandardization decisions have been made.\nProduct standards\nProcess standards\nDesign review form\nDesign review conduct\nRequirements document structure\nSubmission of new code for system building\nMethod header format\nVersion release process\nJava programming style\nProject plan approval process\nProject plan format\nChange control process\nChange request form\nTest recording process\nFigure 24.4\u2002 Product \nand process \nstandards\n", "page": 708, "type": "text", "section": "Page 708"}
{"text": "708\u2002 \u2002 Chapter 24\u2002 \u25a0\u2002 Quality management\n2.\t\nReview and modify standards regularly to reflect changing technologies \nStandards are expensive to develop, and they tend to be enshrined in a company \nstandards handbook. Because of the costs and discussion required, there is often \na reluctance to change them. A standards handbook is essential, but it should \nevolve to reflect changing circumstances and technology.\n3.\t\nMake sure that tool support is available to support standards-based development \nDevelopers often find standards to be a bugbear when conformance to them \ninvolves tedious manual work that could be done by a software tool. If tool support \nis available, standards can be followed without much extra effort. For example, \nprogram layout standards can be defined and implemented by a \u00ad\nsyntax-directed \nprogram editing system.\nDifferent types of software need different development processes, so standards \nhave to be adaptable. There is no point in prescribing a particular way of working if \nit is inappropriate for a project or project team. Each project manager should have \nthe authority to modify process standards according to individual circumstances. \nHowever, when changes are made, it is important to ensure that these changes do not \nlead to a loss of product quality.\nThe project manager and the quality manager can avoid the problems of inap-\npropriate standards by careful quality planning early in the project. They should \ndecide which of the organizational standards should be used without change, which \nshould be modified, and which should be ignored. New standards may have to be \ncreated in response to customer or project requirements. For example, standards \nfor formal specifications may be required if these standards have not been used in \nprevious projects.\n\t\n24.2.1 \t The ISO 9001 standards framework\nThe international set of standards used in the development of quality manage-\nment systems in all industries is called ISO 9000. ISO 9000 standards can be \napplied to a range of organizations from manufacturing through to service indus-\ntries. ISO 9001, the most general of these standards, applies to organizations that \ndesign, develop, and maintain products, including software. The ISO 9001 \nstandard was originally developed in 1987. I explain the 2008 version of the \nstandard here, but the standard may change in 2015 when a new version is sched-\nuled for release.\nThe ISO 9001 standard is not a standard for software development but rather is a \nframework for developing software standards. It sets out general quality principles, \ndescribes quality processes in general, and lays out the organizational standards and \nprocedures that should be defined. These should be documented in an organizational \nquality manual.\nA major revision of the ISO 9001 standard in 2000 reoriented the standard around \nnine core processes (Figure 24.5). If an organization is to be ISO 9001 conformant, \nit must document how its processes relate to these core processes. It must also define \nand maintain records demonstrating that the defined organizational processes have \n", "page": 709, "type": "text", "section": "Page 709"}
{"text": " \n24.2\u2002 \u25a0\u2002 Software standards\u2002 \u2002 709\nbeen followed. The company quality manual should describe the relevant processes \nand the process data that has to be collected and maintained.\nThe ISO 9001 standard does not define or prescribe the specific quality processes \nthat a company should use. To be conformant with ISO 9001, a company must define \nthe types of process shown in Figure 24.5 and have procedures in place demonstrat-\ning that its quality processes are being followed. This allows flexibility across indus-\ntrial sectors and company sizes.\nQuality standards can be defined that are appropriate for the type of software \nbeing developed. Small companies can have simple processes without much docu-\nmentation and still be ISO 9001 compliant. However, this flexibility means that you \ncannot make assumptions about the similarities or differences between the processes \nin different ISO 9001\u2013compliant companies. Some companies may have very rigid \nquality processes that keep detailed records while others may be much less formal, \nwith minimal additional documentation.\nThe relationships between ISO 9001, organizational quality manuals, and indi-\nvidual project quality plans are shown in Figure 24.6. This diagram has been adapted \nfrom a model given by Ince (Ince 1994), who explains how the general ISO 9001 \nstandard can be used as a basis for software quality management processes. Bamford \nand Deibler (Bamford and Deibler 2003) explain how the later ISO 9001: 2000 \nstandard can be applied in software companies.\nSome software customers demand that their suppliers be ISO 9001 certified. The \ncustomers can then be confident that the software development company has an \napproved quality management system in place. Independent accreditation authorities \nexamine the quality management processes and process documentation and decide if \nthese processes cover all of the areas specified in ISO 9001. If so, they certify that a \ncompany\u2019s quality processes, as defined in the quality manual, conform to the ISO \n9001 standard.\nSome people mistakenly think that ISO 9001 certification means that the quality \nof the software produced by certified companies will always be better than that from \nBusiness\nacquisition\nDesign and\ndevelopment\nTest\nProduction and\ndelivery\nService and\nsupport\nBusiness\nmanagement\nInventory\nmanagement\nConfiguration\nmanagement\nSupporting \nprocesses\nSupplier\nmanagement\nProduct \ndelivery processes\nFigure 24.5\u2002 ISO 9001 \ncore processes\n", "page": 710, "type": "text", "section": "Page 710"}
{"text": "710\u2002 \u2002 Chapter 24\u2002 \u25a0\u2002 Quality management\nuncertified companies. The ISO 9001 standard focuses on ensuring that the organi-\nzation has quality management procedures in place and that it follows these proce-\ndures. There is no guarantee that ISO 9001 certified companies use the best software \ndevelopment practices or that their processes lead to high-quality software.\nThe ISO 9001 certification is inadequate, in my view, because it defines quality \nto be the conformance to standards. It takes no account of quality as experienced by \nusers of the software. For example, a company could define test coverage standards \nspecifying that all methods in objects must be called at least once. Unfortunately, \nthis standard can be met by incomplete software testing that does not include tests \nwith different method parameters. As long as the defined testing procedures are fol-\nlowed and test records are maintained, the company could be ISO 9001 certified.\n \n24.3  Reviews and inspections\nReviews and inspections are quality assurance activities that check the quality of \nproject deliverables. This involves checking the software, its documentation, and \nrecords of the process to discover errors and omissions as well as standards viola-\ntions. As I explained in Chapter 8, reviews and inspections are used alongside pro-\ngram testing as part of the general process of software verification and validation.\nDuring a review, several people examine the software and its associated docu-\nmentation, looking for potential problems and nonconformance with standards. The \nreview team makes informed judgments about the level of quality of the software or \nproject documents. Project managers may then use these assessments to make plan-\nning decisions and allocate resources to the development process.\nQuality reviews are based on documents that have been produced during the soft-\nware development process. As well as software specifications, designs, code, pro-\ncess models, test plans, configuration management procedures, process standards, \nProject 1\nquality plan\nProject 2\nquality plan\nProject 3\nquality plan\nProject quality\nmanagement\nOrganization\nquality manual\nISO 9001\nquality models\nOrganization\nquality process\nis used to develop\ninstantiated as\ninstantiated as\ndocuments\nSupports\nFigure 24.6\u2002 ISO 9001 \nand quality \nmanagement\n", "page": 711, "type": "text", "section": "Page 711"}
{"text": " \n24.3\u2002 \u25a0\u2002 Reviews and inspections\u2002 \u2002 711\nand user manuals may all be reviewed. The review should check the consistency and \ncompleteness of the documents or code under review and, if standards have been \ndefined, make sure that these quality standards have been followed.\nReviews are not just about checking conformance to standards. They are also \nused to help discover problems and omissions in the software or project documenta-\ntion. The conclusions of the review should be formally recorded as part of the qual-\nity management process. If problems have been discovered, the reviewers\u2019 comments \nshould be passed to the author of the software or whoever is responsible for correct-\ning errors or omissions.\nThe purpose of reviews and inspections is to improve software quality, not to assess \nthe performance of people in the development team. Reviewing is a public process of \nerror detection, compared with the more private component-testing process. Inevitably, \nmistakes that are made by individuals are revealed to the whole programming team. To \nensure that all developers engage constructively with the review process, project man-\nagers have to be sensitive to individual concerns. They must develop a working culture \nthat provides support without blame when errors are discovered.\nQuality reviews are not management progress reviews, although information about \nthe software quality may be used in making management decisions. Progress reviews \ncompare the actual progress in a software project against the planned progress. Their \nprime concern is whether or not the project will deliver useful software on time and \non budget. Progress reviews take external factors into account, and changed circum-\nstances may mean that software under development is no longer required or has to be \nradically changed. Projects that have developed high-quality software may have to be \ncanceled because of changes to the business or its operating environment.\n\t\n24.3.1 \t The review process\nAlthough there are many variations in the details of reviews, review processes \n(Figure 24.7) are structured into three phases:\n1.\t Pre-review activities These are preparatory activities that are essential for the \nreview to be effective. Typically, pre-review activities are concerned with \nreview planning and review preparation. Review planning involves setting up \na\u00a0review team, arranging a time and place for the review, and distributing \nthe\u00a0documents to be reviewed. During review preparation, the team may meet to \nget an overview of the software to be reviewed. Individual review team mem-\nbers read and understand the software or documents and relevant standards. \nReview\nmeeting\nIndividual\npreparation\nGroup\npreparation\nPlanning\nFollow-up\nchecks\nImprovement\nError\ncorrection\n  Pre-review activities\n  Post-review activities\nFigure 24.7\u2002 The \nsoftware review  \nprocess\n", "page": 712, "type": "text", "section": "Page 712"}
{"text": "712\u2002 \u2002 Chapter 24\u2002 \u25a0\u2002 Quality management\nThey work independently to find errors, omissions, and departures from stand-\nards. Reviewers may supply written comments on the software if they cannot \nattend the review meeting.\n2.\t\nThe review meeting During the review meeting, an author of the document or \nprogram being reviewed should \u201cwalk through\u201d the document with the review \nteam. The review itself should be relatively short\u2014two hours at most. One team \nmember should chair the review, and another should formally record all review \ndecisions and actions to be taken. During the review, the chair is responsible for \nensuring that all submitted comments are considered. The review chair should \nsign a record of comments and actions agreed during the review.\n3.\t\nPost-review activities After a review meeting has ended, the issues and prob-\nlems raised during the review must be addressed. Actions may involve fixing \nsoftware bugs, refactoring software so that it conforms to quality standards, or \nrewriting documents. Sometimes the problems discovered in a quality review \nare such that a management review is also necessary to decide if more resources \nshould be made available to correct them. After changes have been made, the \nreview chair may check that all the review comments have been taken into \naccount. Sometimes a further review will be required to check that the changes \nmade cover all of the previous review comments.\nReview teams should normally have a core of three to four people who are selected \nas principal reviewers. One member should be an experienced designer who will take \nthe responsibility for making significant technical decisions. The principal reviewers \nmay invite other project members, such as the designers of related subsystems, to \ncontribute to the review. They may not be involved in reviewing the whole document \nbut should concentrate on those sections that affect their work. Alternatively, the \nreview team may circulate the document and ask for written comments from a broad \nspectrum of project members. The project manager need not be involved in the \nreview, unless problems are anticipated that require changes to the project plan.\nThe processes suggested for reviews assume that the review team has a face-to-\nface meeting to discuss the software or documents they are reviewing. However, \nproject teams are now often distributed, sometimes across countries or continents, so \nit is impractical for team members to meet face to face. Remote reviewing can be \nsupported using shared documents where each review team member can annotate \nthe document with their comments. Face-to-face meetings may be impossible \nRoles in the inspection process\nWhen program inspection was established at IBM (Fagan, 1986), a number of formal roles were defined for \nmembers of the inspection team. These included moderator, code reader, and scribe. Other users of inspections \nhave modified these roles, but it is generally accepted that an inspection should involve the code author, an \ninspector, and a scribe and should be chaired by a moderator.\nhttp://software-engineering-book.com/web/qm-roles\n", "page": 713, "type": "text", "section": "Page 713"}
{"text": " \n24.3\u2002 \u25a0\u2002 Reviews and inspections\u2002 \u2002 713\nbecause of work schedules or the fact that people work in different time zones. The \nreview chair is responsible for coordinating comments and for discussing changes \nindividually with the review team members.\n\t\n24.3.2 \t Program inspections\nProgram inspections are peer reviews where team members collaborate to find bugs \nin the program that is being developed. As I discussed in Chapter 8, inspections may \nbe part of the software verification and validation processes. They complement test-\ning as they do not require the program to be executed. Incomplete versions of the \nsystem can be verified, and representations such as UML models can be checked. \nProgram tests may be reviewed. Test reviews often find problems with tests and so \nimprove their effectiveness in detecting program bugs.\nProgram inspections involve team members from different backgrounds who \nmake a careful, line-by-line review of the program source code. They look for \ndefects and problems and describe them at an inspection meeting. Defects may be \nlogical errors, anomalies in the code that might indicate an erroneous condition or \nfeatures that have been omitted from the code. The review team examines the \ndesign models or the program code in detail and highlights anomalies and problems \nfor repair.\nDuring an inspection, a checklist of common programming errors is often used to \nfocus the search for bugs. This checklist may be based on examples from books or \nfrom knowledge of defects that are common in a particular application domain. You \nuse different checklists for different programming languages because each language \nhas its own characteristic errors. Humphrey (Humphrey, 1989), in a comprehensive \ndiscussion of inspections, gives a number of examples of inspection checklists.\nPossible checks that might be made during the inspection process are shown in \nFigure 24.8. Organizations should develop their own inspection checklists based on \nlocal standards and practices. These checklists should be regularly updated, as new \ntypes of defects are found. The items in the checklist vary according to programming \nlanguage because of the different levels of checking that are possible at compile-\ntime. For example, a Java compiler checks that functions have the correct number of \nparameters; a C compiler does not.\nCompanies that use inspections have found that they are effective in finding bugs. In \nearly work, Fagan (Fagan 1986) reported that more than 60% of the errors in a program \nwere detected using informal program inspections. McConnell (McConnell 2004) \ncompares unit testing, where the defect detection rate is about 25%, with inspections, \nwhere the defect detection rate was 60%. These comparisons were made before wide-\nspread automated testing. We don\u2019t know how inspections compare to this approach.\nIn spite of their well-publicized cost-effectiveness, many software development com-\npanies are reluctant to use inspections or peer reviews. Software engineers with experi-\nence in program testing are sometimes unwilling to accept the fact that inspections can \nbe more effective for defect detection than testing. Managers may be suspicious because \ninspections require additional costs during design and development. They may not want \nto take the risk that there will be no corresponding savings in program testing costs.\n", "page": 714, "type": "text", "section": "Page 714"}
{"text": "714\u2002 \u2002 Chapter 24\u2002 \u25a0\u2002 Quality management\n \n24.4  Quality management and agile development\nAgile methods of software engineering focus on the development of code. They \nminimize documentation and processes that are not directly concerned with code \ndevelopment and emphasize the importance of informal communications among \nteam members rather than communications based on project documents. Quality, in \nagile development, means code quality and practices such as refactoring, and test-\ndriven development are used to ensure that high-quality code is produced.\nQuality management in agile development is informal rather than document-based. It \nrelies on establishing a quality culture, where all team members feel responsible for soft-\nware quality and take actions to ensure that quality is maintained. The agile community \nis fundamentally opposed to what it sees as the bureaucratic overhead of standards-based \napproaches and quality processes as embodied in ISO 9001. Companies that use agile \ndevelopment methods are rarely concerned with ISO 9001 certification.\nIn agile development, quality management is based on shared good practice rather \nthan formal documentation. Some examples of this good practice are:\n1.\t\nCheck before check-in Programmers are responsible for organizing their own code \nreviews with other team members before the code is checked in to the build system.\nFault class\nInspection check\nData faults\n\u25a0\u2002 \u2005Are all program variables initialized before their values are used?\n\u25a0\u2002 \u2005Have all constants been named?\n\u25a0\u2002 \u2005\u0007\nShould the upper bound of arrays be equal to the size of the array or Size 21?\n\u25a0\u2002 \u2005If character strings are used, is a delimiter explicitly assigned?\n\u25a0\u2002 \u2005Is there any possibility of buffer overflow?\nControl faults\n\u25a0\u2002 \u2005For each conditional statement, is the condition correct?\n\u25a0\u2002 \u2005Is each loop certain to terminate?\n\u25a0\u2002 \u2005Are compound statements correctly bracketed?\n\u25a0\u2002 \u2005In case statements, are all possible cases accounted for?\n\u25a0\u2002 \u2005\u0007\nIf a break is required after each case in case statements, has it been included?\nInput/output faults\n\u25a0\u2002 \u2005Are all input variables used?\n\u25a0\u2002 \u2005Are all output variables assigned a value before they are output?\n\u25a0\u2002 \u2005Can unexpected inputs cause corruption?\nInterface faults\n\u25a0\u2002 \u2005\u0007\nDo all function and method calls have the correct number of parameters?\n\u25a0\u2002 \u2005Do formal and actual parameter types match?\n\u25a0\u2002 \u2005Are the parameters in the right order?\n\u25a0\u2002 \u2005\u0007\nIf components access shared memory, do they have the same model of \nthe shared memory structure?\nStorage management faults\n\u25a0\u2002 \u2005\u0007\nIf a linked structure is modified, have all links been correctly reassigned?\n\u25a0\u2002 \u2005If dynamic storage is used, has space been allocated correctly?\n\u25a0\u2002 \u2005Is space explicitly de-allocated after it is no longer required?\nException management faults\n\u25a0\u2002 \u2005Have all possible error conditions been taken into account?\nFigure 24.8\u2002 An \ninspection checklist\n", "page": 715, "type": "text", "section": "Page 715"}
{"text": " \n24.4\u2002 \u25a0\u2002 Quality management and agile development\u2002 \u2002 715\n2.\t\nNever break the build It is not acceptable for team members to check in code \nthat causes the system as a whole to fail. Therefore, individuals have to test their \ncode changes against the whole system and be confident that these codes work \nas expected. If the build is broken, the person responsible is expected to give top \npriority to fixing the problem.\n3.\t\nFix problems when you see them The code of the system belongs to the team \nrather than to individuals. Therefore, if a programmer discovers problems or \nobscurities in code developed by someone else, he or she can fix these problems \ndirectly rather than referring them back to the original developer.\nAgile processes rarely use formal inspection or review processes. In Scrum, the \ndevelopment team meets after each iteration to discuss quality issues and prob-\nlems. The team may decide on changes to the way they work to avoid any quality \nproblems that have emerged. A collective decision may be made to focus on refac-\ntoring and quality improvement during a sprint rather than the addition of new \nsystem functionality.\nCode reviews may be the responsibility of individuals (check before check-in) or \nmay rely on the use of pair programming. As I discussed in Chapter 3, pair program-\nming is an approach in which two people are responsible for code development and \nwork together to achieve it. Code developed by an individual is therefore constantly \nbeing examined and reviewed by another team member. Two people look at every \nline of code and check it before it is accepted.\nPair programming leads to a deep knowledge of a program, as both program-\nmers have to understand the program in detail to continue development. This depth \nof knowledge is sometimes difficult to achieve in other inspection processes, and \nso pair programming can find bugs that sometimes would not be discovered in \nformal inspections. However, the two people involved cannot be as objective as an \nexternal inspection team inasmuch as they are examining their own work. Potential \nproblems are:\n1.\t\nMutual misunderstandings Both members of a pair may make the same mistake \nin understanding the system requirements. Discussions may reinforce these errors.\n2.\t\nPair reputation Pairs may be reluctant to look for errors because they do not \nwant to slow down the progress of the project.\n3.\t\nWorking relationships The pair\u2019s ability to discover defects is likely to be com-\npromised by their close working relationship that often leads to reluctance to \ncriticize work partners.\nThe informal approach to quality management adopted in agile methods is par-\nticularly effective for software product development where the company develop-\ning the software also controls its specification. There is no need to deliver quality \nreports to an external customer, nor is there any need to integrate with other qual-\nity management teams. However, when a large system is being developed for an \n", "page": 716, "type": "text", "section": "Page 716"}
{"text": "716\u2002 \u2002 Chapter 24\u2002 \u25a0\u2002 Quality management\nexternal customer, agile approaches to quality management with minimal docu-\nmentation may be impractical:\n1.\t\nIf the customer is a large company, it may have its own quality management pro-\ncesses and may expect the software development company to report on progress in a \nway that is compatible with these processes. Therefore, the development team may \nhave to produce a formal quality plan and quality reports as required by the customer.\n2.\t\nWhere several geographically distributed teams are involved in development, \nperhaps from different companies, then informal communications may be \nimpractical. Different companies may have different approaches to quality man-\nagement, and you may have to agree to produce some formal documentation.\n3.\t\nFor long-lifetime systems, the team involved in development will change over \ntime. If there is no documentation, new team members may find it impossible to \nunderstand why development decisions have been made.\nConsequently, the informal approach to quality management in agile methods \nmay have to be adapted so that some quality documentation and processes are intro-\nduced. Generally, this approach is integrated with the iterative development process. \nInstead of developing software, one of the sprints or iterations should focus on pro-\nducing essential software documentation.\n \n24.5  Software measurement\nSoftware measurement is concerned with quantifying some attribute of a software \nsystem such as its complexity or its reliability. By comparing the measured values to \neach other and to the standards that apply across an organization, you may be able to \ndraw conclusions about the quality of software or assess the effectiveness of soft-\nware processes, tools, and methods. In an ideal world, quality management could \nrely on measurements of attributes that affect the software quality. You could then \nobjectively assess process and tool changes that aim to improve software quality.\nFor example, say you work in a company that plans to introduce a new software-\ntesting tool. Before introducing the tool, you record the number of software defects \ndiscovered in a given time. This is a baseline for assessing the effectiveness of the \ntool. After using the tool for some time, you repeat this process. If more defects have \nbeen found in the same amount of time, after the tool has been introduced, then you \nmay decide that it provides useful support for the software validation process.\nThe long-term goal of software measurement is to use measurement to make \njudgments about software quality. Ideally, a system could be assessed using a range \nof metrics to measure its attributes. From the measurements made, a value for the \nquality of the system could be inferred. If the software had reached a required quality \nthreshold, then it could be approved without review. When appropriate, the measure-\nment tools might also highlight areas of the software that could be improved. \n", "page": 717, "type": "text", "section": "Page 717"}
{"text": " \n24.5\u2002 \u25a0\u2002 Software measurement\u2002 \u2002 717\nHowever, we are still a long way from this ideal situation, and automated quality \nassessment is unlikely to become a reality in the near future.\nA software metric is a characteristic of a software system, system documentation, \nor development process that can be objectively measured. Examples of metrics \ninclude the size of a product in lines of code, the Fog index, which is a measure of \nthe readability of narrative text, the number of reported faults in a delivered software \nproduct, and the number of person-days required to develop a system component.\nSoftware metrics may be either control metrics or predictor metrics. As the names \nimply, control metrics support process management, and predictor metrics help you \npredict characteristics of the software. Control metrics are usually associated with soft-\nware processes. Examples of control or process metrics are the average effort and the \ntime required to repair reported defects. Three kinds of process metrics can be used:\n1.\t\nThe time taken for a particular process to be completed This can be the total \ntime devoted to the process, calendar time, the time spent on the process by \nparticular engineers, and so on.\n2.\t\nThe resources required for a particular process Resources might include total \neffort in person-days, travel costs, or computer resources.\n3.\t\nThe number of occurrences of a particular event Examples of events that might \nbe monitored include the number of defects discovered during code inspection, \nthe number of requirements changes requested, the number of bug reports in a \ndelivered system, and the average number of lines of code modified in response \nto a requirements change.\nPredictor metrics (sometimes called product metrics) are associated with the soft-\nware itself. Examples of predictor metrics are the cyclomatic complexity of a module, \nthe average length of identifiers in a program, and the number of attributes and opera-\ntions associated with object classes in a design. Both control and predictor metrics \nmay influence management decision making as shown in Figure 24.9. Managers use \nprocess measurements to decide if process changes should be made and predictor met-\nrics to decide if software changes are necessary and if the software is ready for release.\nManagement\ndecisions\nControl metric\nmeasurements\nSoftware\nprocess\nPredictor metric\nmeasurements\nSoftware\nproduct\nFigure 24.9\u2002 Predictor \nand control \nmeasurements\n", "page": 718, "type": "text", "section": "Page 718"}
{"text": "718\u2002 \u2002 Chapter 24\u2002 \u25a0\u2002 Quality management\nIn this chapter, I focus on predictor metrics, whose values are automatically \nassessed by analyzing code or documents. I discuss control metrics and how they are \nused in process improvement in web Chapter 26.\nMeasurements of a software system may be used in two ways:\n1.\t\nTo assign a value to system quality attributes By measuring the characteristics \nof system components and then aggregating these measurements, you may be \nable to assess system quality attributes, such as maintainability.\n2.\t\nTo identify the system components whose quality is substandard Measurements \ncan identify individual components with characteristics that deviate from the norm. \nFor example, you can measure components to discover those with the highest com-\nplexity. These components are most likely to contain bugs because the complexity \nmakes it more likely that the component developer has made mistakes.\nIt is difficult to make direct measurements of many of the software quality attrib-\nutes shown in Figure 24.2. Quality attributes such as maintainability, understanda-\nbility, and usability are external attributes that relate to how developers and users \nexperience the software. They are affected by subjective factors, such as user experi-\nence and education, and they cannot therefore be measured objectively. To make a \njudgment about these attributes, you have to measure some internal attributes of the \nsoftware (such as its size and complexity) and assume that these are related to the \nquality characteristics that you are concerned with.\n Figure 24.10 shows some external software quality attributes and internal attrib-\nutes that could, intuitively, be related to them. The diagram suggests that there may \nbe relationships between external and internal attributes, but it does not say how \nthese attributes are related. Kitchenham (Kitchenham 1990) suggested that if the \nmeasure of the internal attribute is to be a useful predictor of the external software \ncharacteristic, three conditions must hold:\nReliability\nDepth of inheritance tree\nCyclomatic complexity\nProgram size in lines\nof code\nNumber of error\nmessages\nLength of user manual\nMaintainability\nUsability\nReusability\nExternal quality attributes\nInternal attributes\nFigure 24.10\u2002  \nRelationships between \ninternal and external \nsoftware attributes\n", "page": 719, "type": "text", "section": "Page 719"}
{"text": " \n24.5\u2002 \u25a0\u2002 Software measurement\u2002 \u2002 719\n1.\t\nThe internal attribute must be measured accurately. However, measurement is \nnot always straightforward and may require specially developed tools.\n2.\t\nA relationship must exist between the attribute that can be measured and the exter-\nnal quality attribute that is of interest. That is, the value of the quality attribute \nmust be related, in some way, to the value of the attribute than can be measured.\n3.\t\nThis relationship between the internal and external attributes must be understood, \nvalidated, and expressed in terms of a formula or model. Model formulation \ninvolves identifying the functional form of the model (linear, exponential, etc.) \nby analysis of collected data, identifying the parameters that are to be included \nin the model and calibrating these parameters using existing data.\nRecent work in the area of software analytics (Zhang et al. 2013) has used data-\nmining and machine-learning techniques to analyze repositories of software product \nand process data. The idea behind software analytics (Menzies and Zimmermann \n2013) is that we do not, in fact, need a model that reflects the relationships between \nsoftware quality and collected data. Rather, if there is enough data, correlations can \nbe discovered and predictions made about software attributes. I discuss software \nanalytics in Section 24.5.4.\nWe have very little published information about systematic software measure-\nment in industry. Many companies do collect information about their software, \nsuch as the number of requirements change requests or the number of defects \ndiscovered in testing. However, it is not clear if they then use these measurements \nsystematically to compare software products and processes or assess the impact \nof changes to software processes and tools. There are several reasons why this \nis\u00a0difficult:\n1.\t\nIt is impossible to quantify the return on investment of introducing an organiza-\ntional metrics or software analytics program. We have seen significant improve-\nments in software quality over the past few years without the use of metrics, so \nit is difficult to justify the initial costs of introducing systematic software meas-\nurement and assessment.\n2.\t\nThere are no standards for software metrics or standardized processes for meas-\nurement and analysis. Many companies are reluctant to introduce measurement \nprograms until such standards and supporting tools are available.\n3.\t\nMeasurement may require the development and maintenance of specialized \nsoftware tools. It is difficult to justify the costs of tool development when the \nreturns from measurement are unknown.\n4.\t\nIn many companies, software processes are not standardized and are poorly \ndefined and controlled. As such, there is too much process variability within the \nsame company for measurements to be used in a meaningful way.\n5.\t\nMuch of the research on software measurement and metrics has focused on \ncode-based metrics and plan-driven development processes. However, more and \nmore software is now developed by reusing and configuring existing application \n", "page": 720, "type": "text", "section": "Page 720"}
{"text": "720\u2002 \u2002 Chapter 24\u2002 \u25a0\u2002 Quality management\nsystems, or by using agile methods. We don\u2019t know how previous research on \nmetrics applies to these software development techniques.\n6.\t\nIntroducing measurement adds overhead to processes. This contradicts the aims \nof agile methods, which recommend the elimination of process activities that \nare not directly related to program development. Companies that have adopted \nagile methods are therefore not likely to adopt a metrics program.\nSoftware measurement and metrics are the basis of empirical software engineer-\ning. In this research area, experiments on software systems and the collection of data \nabout real projects have been used to form and validate hypotheses about software \nengineering methods and techniques. Researchers working in this area argue that we \ncan be confident of the value of software engineering methods and techniques only \nif we can provide concrete evidence that they actually provide the benefits their \ninventors suggest.\nHowever, research on empirical software engineering has not had a significant \nimpact on software engineering practice. It is difficult to relate generic research to an \nindividual project that differs from the research study. Many local factors are likely \nto be more important than general empirical results. For this reason, researchers in \nsoftware analytics argue that analysts should not try to draw general conclusions but \nshould provide analyses of the data for specific systems.\n\t\n24.5.1 \t Product metrics\nProduct metrics are predictor metrics used to quantify internal attributes of a soft-\nware system. Examples of product metrics include the system size, measured in lines \nof code, or the number of methods associated with each object class. Unfortunately, \nas I have explained earlier in this section, software characteristics that can be easily \nmeasured, such as size and cyclomatic complexity, do not have a clear and consist-\nent relationship with quality attributes such as understandability and maintainability. \nThe relationships vary depending on the development processes and technology \nused and the type of system that is being developed.\nProduct metrics fall into two classes:\n1.\t\nDynamic metrics, which are collected by measurements made of a program in \nexecution. These metrics can be collected during system testing or after the sys-\ntem has gone into use. An example might be the number of bug reports or the \ntime taken to complete a computation.\n2.\t\nStatic metrics, which are collected by measurements made of representations of \nthe system, such as the design, program, or documentation. Examples of static \nmetrics are shown in Figure 24.11.\nThese types of metrics are related to different quality attributes. Dynamic metrics \nhelp to assess the efficiency and reliability of a system. Static metrics help assess the \ncomplexity, understandability, and maintainability of a system or its components.\n", "page": 721, "type": "text", "section": "Page 721"}
{"text": " \n24.5\u2002 \u25a0\u2002 Software measurement\u2002 \u2002 721\nSoftware metric\nDescription\nFan-in/Fan-out\nFan-in is a measure of the number of functions or methods that call another \nfunction or method (say X). Fan-out is the number of functions that are called by \nfunction X. A high value for fan-in means that X is tightly coupled to the rest of the \ndesign and changes to X will have extensive knock-on effects. A high value for \nfan-out suggests that the overall complexity of X may be high because of the \ncomplexity of the control logic needed to coordinate the called components.\nLength of code\nThis is a measure of the size of a program. Generally, the larger the size of the code \nof a component, the more complex and error-prone that component is likely to be. \nLength of code has been shown to be one of the most reliable metrics for \npredicting error-proneness in components.\nCyclomatic complexity\nThis is a measure of the control complexity of a program. This control complexity may \nbe related to program understandability. I discuss cyclomatic complexity in Chapter 8.\nLength of identifiers\nThis is a measure of the average length of identifiers (names for variables, classes, \nmethods, etc.) in a program. The longer the identifiers, the more likely they are to \nbe meaningful and hence the more understandable the program.\nDepth of conditional \nnesting\nThis is a measure of the depth of nesting of if-statements in a program. Deeply \nnested if-statements are hard to understand and potentially error-prone.\nFog index\nThis is a measure of the average length of words and sentences in documents. \nThe\u00a0higher the value of a document\u2019s Fog index, the more difficult the document is \nto understand.\nFigure 24.11\u2002 Static \nsoftware product  \nmetrics\nA clear relationship usually exists between dynamic metrics and software quality \ncharacteristics. It is fairly easy to measure the execution time required for particular \nfunctions and to assess the time required to start up a system. These functions relate \ndirectly to the system\u2019s efficiency. Similarly, the number of system failures and the \ntype of failure can be logged and related directly to the reliability of the software. \nI\u00a0have explained how reliability can be measured in Chapter 12.\nStatic metrics, as shown in Figure 24.11, have an indirect relationship with quality \nattributes. A large number of different metrics have been proposed, and many exper-\niments have tried to derive and validate the relationships between these metrics and \nattributes, such as system complexity and maintainability. None of these experiments \nhave been conclusive, but program size and control complexity appear be the most \nreliable predictors of understandability, system complexity, and maintainability.\nThe metrics in Figure 24.11 are applicable to any program, but more specific \nobject-oriented metrics have also been proposed. Figure 24.12 summarizes \nChidamber and Kemerer\u2019s suite (sometimes called the CK suite) of six object-\u00ad\noriented metrics (Chidamber and Kemerer 1994). Although these metrics were orig-\ninally proposed in the early 1990s, they are still the most widely used object-oriented \n(OO) metrics. Some UML design tools automatically collect values for these \nmetrics as UML \u00ad\ndiagrams are created.\nEl-Amam\u2019s review of object-oriented metrics discussed the CK metrics and other \nOO metrics (El-Amam 2001). It concluded that there was insufficient evidence to \nunderstand how these and other object-oriented metrics relate to external software \n", "page": 722, "type": "text", "section": "Page 722"}
{"text": "722\u2002 \u2002 Chapter 24\u2002 \u25a0\u2002 Quality management\nObject-oriented metric\nDescription\nWeighted methods per \nclass (WMC)\nThis is the number of methods in each class, weighted by the complexity of \neach method. Therefore, a simple method may have a complexity of 1, and a \nlarge and complex method a much higher value. The larger the value for this \nmetric, the more complex the object class. Complex objects are more likely to \nbe difficult to understand. They may not be logically cohesive, so they cannot \nbe reused effectively as superclasses in an inheritance tree.\nDepth of inheritance \ntree\u00a0(DIT)\nThis represents the number of discrete levels in the inheritance tree where \nsubclasses inherit attributes and operations (methods) from superclasses. The \ndeeper the inheritance tree, the more complex the design. Many object classes may \nhave to be understood to understand the object classes at the leaves of the tree.\nNumber of children (NOC)\nThis is a measure of the number of immediate subclasses in a class. It \nmeasures the breadth of a class hierarchy, whereas DIT measures its depth. \nA\u00a0high value for NOC may indicate greater reuse. It may mean that more effort \nshould be made in validating base classes because of the number of subclasses \nthat depend on them.\nCoupling between object \nclasses (CBO)\nClasses are coupled when methods in one class use methods or instance \nvariables defined in a different class. CBO is a measure of how much coupling \nexists. A high value for CBO means that classes are highly dependent. Therefore, \nit is more likely that changing one class will affect other classes in the program.\nResponse for a class (RFC)\nRFC is a measure of the number of methods that could potentially be executed \nin response to a message received by an object of that class. Again, RFC is \nrelated to complexity. The higher the value for RFC, the more complex a class, \nand hence the more likely it is that it will include errors.\nLack of cohesion in \nmethods (LCOM)\nLCOM is calculated by considering pairs of methods in a class. LCOM is the \ndifference between the number of method pairs without shared attributes and the \nnumber of method pairs with shared attributes. The value of this metric has been \nwidely debated, and it exists in several variations. It is not clear if it really adds any \nadditional, useful information over and above that provided by other metrics.\nFigure 24.12\u2002 The \nCK\u00a0object-oriented \nmetrics suite\nqualities. This situation has not really changed since his analysis in 2001. We still \ndon\u2019t know how to use measurements of object-oriented programs to draw reliable \nconclusions about their quality.\n\t\n24.5.2 \t Software component analysis\nA measurement process that may be part of a software quality assessment process is \nshown in Figure 24.13. Each system component can be analyzed separately using a \nrange of metrics. The values of these metrics may then be compared for different \ncomponents and, perhaps, with historical measurement data collected on previous \nprojects. Anomalous measurements, which deviate significantly from the norm, usu-\nally indicate problems with the quality of these components.\nThe key stages in this component measurement process are:\n1.\t\nChoose measurements to be made The questions that the measurement is \nintended to answer should be formulated and the measurements required to \n", "page": 723, "type": "text", "section": "Page 723"}
{"text": " \n24.5\u2002 \u25a0\u2002 Software measurement\u2002 \u2002 723\nanswer these questions defined. Measurements that are not directly relevant to \nthese questions need not be collected.\n2.\t\nSelect components to be assessed You may not need to assess metric values for \nall of the components in a software system. Sometimes you can select a repre-\nsentative selection of components for measurement, allowing you to make an \noverall assessment of system quality. At other times, you may wish to focus on \nthe core components of the system that are in almost constant use. The quality \nof these components is more important than the quality of components that are \ninfrequently executed.\n3.\t\nMeasure component characteristics The selected components are measured, \nand the associated metric values are computed. This step normally involves pro-\ncessing the component representation (design, code, etc.) using an automated \ndata collection tool. This tool may be specially written or may be a feature of \ndesign tools that are already in use.\n4.\t\nIdentify anomalous measurements After the component measurements have \nbeen made, you then compare them with each other and to previous measure-\nments that have been recorded in a measurement database. You should look for \nunusually high or low values for each metric, as these suggest that there could \nbe problems with the component exhibiting these values.\n5.\t Analyze anomalous components When you have identified components that \nhave anomalous values for your chosen metrics, you should examine them to \ndecide whether or not these anomalous metric values mean that the quality of \nthe component is compromised. An anomalous metric value for complexity \n(say) does not necessarily mean a poor-quality component. There may be \nsome other reason for the high value, so there may not be any component \nquality problems.\nIf possible, you should maintain all collected data as an organizational \nresource and keep historical records of all projects even when data has not been \nused during a particular project. Once a sufficiently large measurement database \nhas been established, you can then make comparisons of software quality across \nprojects and validate the relations between internal component attributes and \nquality characteristics.\nMeasure\ncomponent\ncharacteristics\nIdentify\nanomalous\nmeasurements\nAnalyze\nanomalous\ncomponents\nSelect\ncomponents to\nbe assessed\nChoose\nmeasurements\nto be made\nFigure 24.13\u2002 The \nprocess of product \nmeasurement\n", "page": 724, "type": "text", "section": "Page 724"}
{"text": "724\u2002 \u2002 Chapter 24\u2002 \u25a0\u2002 Quality management\n\t\n24.5.3 \t Measurement ambiguity\nWhen you collect quantitative data about software and software processes, you have \nto analyze that data to understand its meaning. It is easy to misinterpret data and to \nmake incorrect inferences. You cannot simply look at the data on its own. You must \nalso consider the context in which the data is collected.\nTo illustrate how collected data can be interpreted in different ways, consider the \nfollowing scenario, which is concerned with the number of change requests made by \na system\u2019s users:\nA manager decides to measure the number of change requests submitted by cus-\ntomers based on an assumption that there is a relationship between these change \nrequests and product usability and suitability. She assumes that the higher the \nnumber of change requests, the less the software meets the needs of the customer.\nHandling change requests and changing the software are expensive. The organ-\nization therefore decides to modify its process with the aim of improving \n\u00ad\ncustomer satisfaction and, at the same time, reducing the costs of making \nchanges. The intent is that the process changes will result in better products and \nfewer change requests. Processes are changed to increase customer involvement \nin the software design process. Beta testing of all products is introduced, and \ncustomer-requested modifications are incorporated in the delivered product.\nAfter the process changes have been made, the measurement of change \nrequests continues. New versions of products, developed with the modified \nprocess, are delivered. In some cases, the number of change requests is \nreduced; in others, it is increased. The manager is baffled and finds it impos-\nsible to understand the effects of the process changes on the product quality.\nTo understand why this kind of ambiguity can occur, you have to understand why \nusers might make change requests:\n1.\t\nThe software is not good enough and does not do what customers want it to do. \nThey therefore request changes to deliver the functionality they require.\n2.\t\nAlternatively, the software may be very good, and so it is widely and heavily \nused. Change requests may be generated because many software users crea-\ntively think of new things that could be done with the software.\nIncreasing the customer\u2019s involvement in the process may reduce the number of \nchange requests for products where the customers were unhappy. The process \nchanges have been effective and have made the software more usable and suitable. \nAlternatively, however, the process changes may not have worked, and customers \nmay have decided to look for an alternative system. The number of change requests \nmight decrease because the product has lost market share to a rival product and there \nare consequently fewer product users.\n", "page": 725, "type": "text", "section": "Page 725"}
{"text": " \n24.5\u2002 \u25a0\u2002 Software measurement\u2002 \u2002 725\nOn the other hand, the process changes might lead to many new, happy customers \nwho wish to participate in the product development process. They therefore generate \nmore change requests. Changes to the process of handling change requests may con-\ntribute to this increase. If the company is more responsive to customers, they may \ngenerate more change requests because they know that these requests will be taken \nseriously. They believe that their suggestions will probably be incorporated in later \nversions of the software. Alternatively, the number of change requests might have \nincreased because the beta-test sites were not typical of most usage of the program.\nTo analyze the change request data, you do not simply need to know the number \nof change requests. You need to know who made the request, how the software is \nused, and why the request was made. You also need information about external fac-\ntors such as modifications to the change request procedure or market changes that \nmight have an effect. With this information, you are in a better position to find out if \nthe process changes have been effective in increasing product quality.\nThis illustrates the difficulties of understanding the effects of changes. The \u201csci-\nentific\u201d approach to this problem is to reduce the number of factors that might affect \nthe measurements made. However, processes and products that are being measured \nare not insulated from their environment. The business environment is constantly \nchanging, and it is impossible to avoid changes to work practice just because they \nmay make comparisons of data invalid. As such, quantitative data about human \nactivities cannot always be taken at face value. The reasons a measured value \nchanges are often ambiguous. These reasons must be investigated in detail before \nany conclusions can be drawn from any measurements.\n\t\n24.5.4 \t Software analytics\nOver the past few years, the notion of \u201cbig data analysis\u201d has emerged as a means of \ndiscovering insights by automatically mining and analyzing very large volumes of \nautomatically collected data. It is possible to discover relationships between data items \nthat could not be found by manual data analysis and modeling. Software analytics is \nthe application of such techniques to data about software and software processes.\nTwo factors have made software analytics possible:\n1.\t\nThe automated collection of user data by software product companies when their \nproduct is used. If the software fails, information about the failure and the state of \nthe system can be sent over the Internet from the user\u2019s computer to servers run by \nthe product developer. As a result, large volumes of data about individual prod-\nucts such as Internet Explorer or Photoshop have become available for analysis.\n2.\t\nThe use of open-source software available on platforms such as Sourceforge \nand GitHub and open-source repositories of software engineering data (Menzies \nand Zimmermann 2013). The source code of open-source software is available \nfor automated analysis and can sometimes be linked with data in the open-\nsource repository.\n", "page": 726, "type": "text", "section": "Page 726"}
{"text": "726\u2002 \u2002 Chapter 24\u2002 \u25a0\u2002 Quality management\nMenzies and Zimmerman (Menzies and Zimmermann 2013) define software \nanalytics as:\nSoftware analytics is analytics on software data for managers and software \nengineers with the aim of empowering software development individuals and \nteams to gain and share insight from their data to make better decisions.\nMenzies and Zimmermann emphasize that the point of analytics is not to derive gen-\neral theories about software but to identify specific issues that are of interest to software \ndevelopers and managers. Analytics aims to provide information about these issues in real \ntime so that actions can be taken in response to the information provided by the analysis. \nIn a study of managers at Microsoft, Buse and Zimmermann (Buse and Zimmermann \n2012) identified information needs such as how to target testing, inspections, and refactor-\ning, when to release software, and how to understand the needs of software customers.\nA range of different data mining and analysis tools can be used for software ana-\nlytics (Witten, Frank, and Hall 2011). In general, it is impossible to know what are \nthe best analysis tools to use in a particular situation. You have to experiment with \nseveral tools to discover which are most effective. Buse and Zimmerman suggest a \nnumber of guidelines for tool use:\n\u25a0\t Tools should be easy to use, as managers are unlikely to have experience with analysis.\n\u25a0\t Tools should run quickly and produce concise outputs rather than large volumes \nof information.\n\u25a0\t Tools should make many measurements using as many parameters as possible. It \nis impossible to predict in advance what insights might emerge.\n\u25a0\t Tools should be interactive and allow managers and developers to explore the \nanalyses. They should recognize that managers and developers are interested in \ndifferent things. They should not be predictive but should support decision mak-\ning based on the analysis of past and current data.\nZhang and her colleagues (Zhang et al. 2013) describe an excellent practical \napplication of software analytics for performance debugging. User software was \ninstrumented to collect data on response times and the associated system state. When \nthe response time was greater than expected, this data was sent for analysis. The \nautomated analysis highlighted performance bottlenecks in the software. The devel-\nopment team could then improve the algorithms to eliminate the bottleneck so that \nperformance was improved in a later software release.\nAt the time of writing, software analytics is immature, and it is too early to say what \neffect it will have. Not only are there general problems of \u201cbig data\u201d processing (Harford \n2013), but it will always be the case that our knowledge depends on collected data from \nlarge companies. This data is primarily from software products, and it is unclear if the \ntools and techniques that are appropriate for products can also be used with custom \nsoftware. Small companies are unlikely to invest in the data collection systems that are \nrequired for automated analysis and so they may not be able to use software analytics.\n", "page": 727, "type": "text", "section": "Page 727"}
{"text": " \n24.5\u2002 \u25a0\u2002 Software measurement\u2002 \u2002 727\nKey Points\n\u25a0\t Software quality management is concerned with ensuring that software has a low number of \ndefects and that it reaches the required standards of maintainability, reliability, portability, and \nso forth. It includes defining standards for processes and products and establishing processes \nto check that these standards have been followed.\n\u25a0\t Software standards are important for quality assurance as they represent an identification of \nbest practice. When developing software, standards provide a solid foundation for building \ngood-quality software.\n\u25a0\t Reviews of the software process deliverables involve a team of people who check that quality \nstandards are being followed. Reviews are the most widely used technique for assessing quality.\n\u25a0\t In a program inspection or peer review, a small team systematically checks the code. They read \nthe code in detail and look for possible errors and omissions. The problems detected are then \ndiscussed at a code review meeting.\n\u25a0\t Agile quality management does not usually rely on a separate quality management team. \nInstead, it relies on establishing a quality culture where the development team works together \nto improve software quality.\n\u25a0\t Software measurement can be used to gather quantitative data about software and the software \nprocess. You may be able to use the values of the software metrics that are collected to make \ninferences about product and process quality.\n\u25a0\t Product quality metrics are particularly useful for highlighting anomalous components that may \nhave quality problems. These components should then be analyzed in more detail.\n\u25a0\t Software analytics is the automated analysis of large volumes of software product and process \ndata to discover relationships that may provide insights for project managers and developers.\nFurther Reading\nSoftware Quality Assurance: From Theory to Implementation. An excellent, still relevant, book on \nthe principles and practice of software quality assurance. It includes a discussion of standards such \nas ISO 9001. (D. Galin, Addison-Wesley, 2004).\n\u201cMisleading Metrics and Unsound Analyses.\u201d An excellent article by leading metrics researchers that \ndiscusses the difficulties of understanding what measurements really mean. (B. Kitchenham, R. Jeffrey \nand C. Connaughton, IEEE Software, 24 (2), March\u2013April 2007). http://dx.doi.org/10.1109/MS.2007.49\n\u201cA Practical Guide to Implementing an Agile QA Process on Scrum Projects.\u201d This slide set presents \nan overview of how to integrate software quality assurance with agile development using Scrum.  \n(S. Rayhan, 2008). https://www.scrumalliance.org/system/resource_files/0000/0459/agileqa.pdf\n\u201cSoftware Analytics: So What?\u201d This is a good introductory article that explains what software analytics is \nand why it is increasingly important. It is the introduction to a special issue on software analytics, and you \nmay find several other articles in that issue to be helpful in understanding software analytics. (T.\u00a0\u00ad\nMenzies \nand T. Zimmermann, IEEE Software, 30 (4), July\u2013August 2013). http://dx.doi.org/10.1109/MS.2013.86\n \nChapter 24\u2002 \u25a0\u2002 Further Reading\u2002 \u2002 727\n", "page": 728, "type": "text", "section": "Page 728"}
{"text": "728\u2002 \u2002 Chapter 24\u2002 \u25a0\u2002 Quality management\nWebsite\nPowerPoint slides for this chapter:\nwww.pearsonglobaleditions.com/Sommerville\nLinks to supporting videos:\nhttp://software-engineering-book.com/videos/software-management/\nExercises\n\u2002 24.1.\t \u0007\nDefine the terms quality assurance and quality control. List out the key points included in \nHumphrey\u2019s outline structure for software management. \n\u2002 24.2.\t\u0007\nExplain how standards may be used to capture organizational wisdom about effective \n\u00ad\nmethods of software development. Suggest four types of knowledge that might be captured \nin organizational standards.\n\u2002 24.3.\t \u0007\nDiscuss the assessment of software quality according to the quality attributes shown in \n\u00ad\nFigure 24.2. You should consider each attribute in turn and explain how it might be assessed\n\u2002 24.4.\t Briefly describe possible standards that might be used for:\n\u25a0\t the use of control constructs in C, C#, or Java;\n\u25a0\t reports that might be submitted for a term project in a university;\n\u25a0\t the process of making and approving program changes (web Chapter 26); and\n\u25a0\t the process of purchasing and installing a new computer.\n\u2002 24.5.\t \u0007\nAssume you work for an organization that develops database products for individuals and \nsmall businesses. This organization is interested in quantifying its software development. \nWrite a report suggesting appropriate metrics and suggest how these can be collected.\n\u2002 24.6.\t \u0007\nBriefly explain what happens during the software quality review process and the software \nquality inspection process.\n\u2002 24.7.\t \u0007\nWhat problems are likely to arise if formalized program inspections are introduced in a \n\u00ad\ncompany where some software is developed using agile methods.\n\u2002 24.8.\t \u0007\nWhat is a software metric? Define different types of software metrics with examples.\n\u2002 24.9.\t  \u0007\nYou work for a software product company and your manager has read an article on software \nanalytics. She asks you to do some research in this area. Survey the literature on analytics \nand write a short report that summarizes work in software analytics and issues to be \n\u00ad\nconsidered if analytics is introduced.\n24.10 \t \u0007\nA colleague who is a very good programmer produces software with a low number of defects \nbut consistently ignores organizational quality standards. How should her managers react to \nthis behavior?\n728\u2002 \u2002 Chapter 24\u2002 \u25a0\u2002 Quality management\n", "page": 729, "type": "text", "section": "Page 729"}
{"text": " \n24.5\u2002 \u25a0\u2002 Exercises\u2002 \u2002 729\nReferences\nBamford, R., and W. J. Deibler. 2003. \u201cISO 9001:2000 for Software and Systems Providers: An Engi-\nneering Approach.\u201d Boca Raton, FL: CRC Press.\nBuse, R. P. L., and T. Zimmermann. 2012. \u201cInformation Needs for Software Development Analytics.\u201d \nIn Int. Conf. on Software Engineering, 987\u2013996. doi:10.1109/ICSE.2012.6227122.\nChidamber, S., and C. Kemerer. 1994. \u201cA Metrics Suite for Object-Oriented Design.\u201d IEEE Trans. on \nSoftware Eng. 20 (6): 476\u2013493. doi:10.1109/32.295895.\nEl-Amam, K. 2001. \u201cObject-Oriented Metrics: A Review of Theory and Practice.\u201d National Research \nCouncil of Canada. http://seg.iit.nrc.ca/English/abstracts/NRC44190.html.\nFagan, M. E. 1986. \u201cAdvances in Software Inspections.\u201d IEEE Trans. on Software Eng. SE-12 (7): \n\u00ad\n744\u2013751. doi:10.1109/TSE.1986.6312976.\nHarford, T. 2013. \u201cBig Data: Are We Making a Big Mistake?\u201d Financial Times, March 28. http:// \ntimharford.com/2014/04/big-data-are-we-making-a-big-mistake/\nHumphrey, W. 1989. Managing the Software Process. Reading, MA: Addison-Wesley.\nIEEE. 2003. IEEE Software Engineering Standards Collection on CD-ROM. Los Alamitos, CA: IEEE \nComputer Society Press.\nInce, D. 1994. ISO 9001 and Software Quality Assurance. London: McGraw-Hill.\nKitchenham, B. 1990. \u201cSoftware Development Cost Models.\u201d In Software Reliability Handbook, \nedited by P. Rook, 487\u2013517. Amsterdam: Elsevier.\nMcConnell, S. 2004. Code Complete: A Practical Handbook of Software Construction, 2nd ed. Seat-\ntle, WA: Microsoft Press.\nMenzies, T., and T. Zimmermann. 2013. \u201cSoftware Analytics: So What?\u201d IEEE Software 30 (4): 31\u201337. \ndoi:10.1109/MS.2013.86.\nWitten, I. H., E. Frank, and M. A. Hall. 2011. Data Mining: Practical Machine Learning Tools and \n\u00ad\nTechniques. Burlington, MA: Morgan Kaufmann.\nZhang, D, S. Han, Y. Dang, J-G. Lou, H. Zhang, and T. Xie. 2013. \u201cSoftware Analytics in Practice.\u201d IEEE \nSoftware 30 (5): 30\u201337. doi:10.1109/MS.2013.94.\n \nChapter 24\u2002 \u25a0\u2002 References\u2002 \u2002 729\n", "page": 730, "type": "text", "section": "Page 730"}
{"text": "Configuration \nmanagement\n25 \nObjectives\nThe objective of this chapter is to introduce you to software configuration \nmanagement processes and tools. When you have read the chapter,  \nyou will:\n\u25a0\t know the essential functionality that should be provided by a \nversion control system, and how this is realized in centralized and \ndistributed systems;\n\u25a0\t understand the challenges of system building and the benefits of \ncontinuous integration and system building;\n\u25a0\t understand why software change management is important and \nthe essential activities in the change management process;\n\u25a0\t understand the basics of software release management and how it \ndiffers from version management.\nContents\n25.1\t Version management\n25.2\t System building\n25.3\t Change management\n25.4\t Release management\n", "page": 731, "type": "text", "section": "Page 731"}
{"text": "Software systems are constantly changing during development and use. Bugs are \ndiscovered and have to be fixed. System requirements change, and you have to \nimplement these changes in a new version of the system. New versions of hardware \nand system platforms are released, and you have to adapt your systems to work with \nthem. Competitors introduce new features in their system that you have to match. As \nchanges are made to the software, a new version of a system is created. Most sys-\ntems, therefore, can be thought of as a set of versions, each of which may have to be \nmaintained and managed.\nConfiguration management (CM) is concerned with the policies, processes, and \ntools for managing changing software systems (Aiello and Sachs 2011). You need to \nmanage evolving systems because it is easy to lose track of what changes and compo-\nnent versions have been incorporated into each system version. Versions implement \nproposals for change, corrections of faults, and adaptations for different hardware \nand operating systems. Several versions may be under development and in use at the \nsame time. If you don\u2019t have effective configuration management procedures in \nplace, you may waste effort modifying the wrong version of a system, delivering the \nwrong version of a system to customers, or forgetting where the software source code \nfor a particular version of the system or component is stored.\nConfiguration management is useful for individual projects as it is easy for one \nperson to forget what changes have been made. It is essential for team projects where \nseveral developers are working at the same time on a software system. Sometimes \nthese developers are all working in the same place, but, increasingly, development \nteams are distributed with members in different locations across the world. The con-\nfiguration management system provides team members with access to the system \nbeing developed and manages the changes that they make to the code.\nThe configuration management of a software system product involves four \nclosely related activities (Figure 25.1):\n1.\t\nVersion control This involves keeping track of the multiple versions of system \ncomponents and ensuring that changes made to components by different devel-\nopers do not interfere with each other.\n2.\t\nSystem building This is the process of assembling program components, data, \nand libraries, then compiling and linking these to create an executable system.\n3.\t\nChange management This involves keeping track of requests for changes to \ndelivered software from customers and developers, working out the costs and \nimpact of making these changes, and deciding if and when the changes should \nbe implemented.\n4.\t\nRelease management This involves preparing software for external release and \nkeeping track of the system versions that have been released for customer use.\nBecause of the large volume of information to be managed and the relationships \nbetween configuration items, tool support is essential for configuration manage-\nment. Configuration management tools are used to store versions of system compo-\nnents, build systems from these components, track the releases of system versions to \n \nChapter 25\u2002 \u25a0\u2002 Configuration management\u2002 \u2002 731\n", "page": 732, "type": "text", "section": "Page 732"}
{"text": "732\u2002 \u2002 Chapter 25\u2002 \u25a0\u2002 Configuration management\n\u00ad\ncustomers, and keep track of change proposals. CM tools range from simple tools \nthat support a single configuration management task, such as bug tracking, to inte-\ngrated environments that support all configuration management activities.\nAgile development, where components and systems are changed several times a \nday, is impossible without using CM tools. The definitive versions of components \nare held in a shared project repository, and developers copy them into their own \nworkspace. They make changes to the code and then use system-building tools to \ncreate a new system on their own computer for testing. Once they are happy with the \nchanges made, they return the modified components to the project repository. This \nmakes the modified components available to other team members.\nThe development of a software product or custom software system takes place in \nthree distinct phases:\n1.\t\nA development phase where the development team is responsible for managing \nthe software configuration and new functionality is being added to the software. \nThe development team decides on the changes to be made to the system.\n2.\t\nA system testing phase where a version of the system is released internally for \ntesting. This may be the responsibility of a quality management team or an indi-\nvidual or group within the development team. At this stage, no new functionality \nis added to the system. The changes made at this stage are bug fixes, perfor-\nmance improvements, and security vulnerability repairs. There may be some \ncustomer involvement as beta testers during this phase.\n3.\t A release phase where the software is released to customers for use. After \nthe release has been distributed, customers may submit bug reports and \nchange requests. New versions of the released system may be developed to \nrepair bugs and vulnerabilities and to include new features suggested by \ncustomers.\nFor large systems, there is never just one \u201cworking\u201d version of a system; there are \nalways several versions of the system at different stages of development. Several \nComponent\nversions\nRelease\nmanagement\nChange\nproposals\nSystem\nreleases\nChange\nmanagement\nSystem\nversions\nVersion\nmanagement\nSystem\nbuilding\nFigure 25.1\u2002  \nConfiguration  \nmanagement activities\n", "page": 733, "type": "text", "section": "Page 733"}
{"text": "teams may be involved in the development of different system versions. Figure 25.2 \nshows situations where three versions of a system are being developed:\n1.\t\nVersion 1.5 of the system has been developed to repair bug fixes and improve \nthe performance of the first release of the system. It is the basis of the second \nsystem release (R1.1).\n2.\t\nVersion 2.4 is being tested with a view to it becoming release 2.0 of the system. \nNo new features are being added at this stage.\n3.\t\nVersion 3 is a development system where new features are being added in \nresponse to change requests from customers and the development team. This \nwill eventually be released as release 3.0.\nThese different versions have many common components as well as components or \ncomponent versions that are unique to that system version. The CM system keeps track \nof the components that are part of each version and includes them as required in the \nsystem build.\nIn large software projects, configuration management is sometimes part of soft-\nware quality management (covered in Chapter 24). The quality manager is responsi-\nble for both quality management and configuration management. When a pre-release \nversion of the software is ready, the development team hands it over to the quality \nmanagement team. The QM team checks that the system quality is acceptable. If so, \nit then becomes a controlled system, which means that all changes to the system \nhave to be agreed on and recorded before they are implemented.\nMany specialized terms are used in configuration management. Unfortunately, \nthese are not standardized. Military software systems were the first systems in which \nsoftware CM was used, so the terminology for these systems reflected the processes \nand terminology used in hardware configuration management. Commercial systems \ndevelopers did not know about military procedures or terminology and so often \ninvented their own terms. Agile methods have also devised new terminology in \norder to distinguish the agile approach from traditional CM methods.\nV1.0\nV1.1\nV1.2\nDevelopment \nversions\nV1.3\nV1.4\nV1.5\nR1.0\nR1.1\nReleases\nV2.1\nV2.2\nV2.3\nV2.4\nPre-release\nversions\nVersion 1\nVersion 2\nVersion 3\n1\n2\n3\nFigure 25.2\u2002  \nMultiversion system \ndevelopment\n \nChapter 25\u2002 \u25a0\u2002 Configuration management\u2002 \u2002 733\n", "page": 734, "type": "text", "section": "Page 734"}
{"text": "734\u2002 \u2002 Chapter 25\u2002 \u25a0\u2002 Configuration management\nTerm\nExplanation\nBaseline\nA collection of component versions that make up a system. Baselines \nare controlled, which means that the component versions used in the \nbaseline cannot be changed. It is always possible to re-create a baseline \nfrom its constituent components.\nBranching\nThe creation of a new codeline from a version in an existing codeline. \nThe new codeline and the existing codeline may then develop \nindependently.\nCodeline\nA set of versions of a software component and other configuration items \non which that component depends.\nConfiguration (version) control\nThe process of ensuring that versions of systems and components are \nrecorded and maintained so that changes are managed and all versions \nof components are identified and stored for the lifetime of the system.\nConfiguration item or software \nconfiguration item (SCI)\nAnything associated with a software project (design, code, test data, \ndocument, etc.) that has been placed under configuration control. \nConfiguration items always have a unique identifier.\nMainline\nA sequence of baselines representing different versions of a system.\nMerging\nThe creation of a new version of a software component by merging \nseparate versions in different codelines. These codelines may have been \ncreated by a previous branch of one of the codelines involved.\nRelease\nA version of a system that has been released to customers (or other \nusers in an organization) for use.\nRepository\nA shared database of versions of software components and meta-\ninformation about changes to these components.\nSystem building\nThe creation of an executable system version by compiling and linking \nthe appropriate versions of the components and libraries making up the \nsystem.\nVersion\nAn instance of a configuration item that differs, in some way, from other \ninstances of that item. Versions should always have a unique identifier.\nWorkspace\nA private work area where software can be modified without affecting \nother developers who may be using or modifying that software.\nFigure 25.3\u2002 CM \nterminology\nThe definition and use of configuration management standards are essential for \nquality certification in both ISO 9000 and the SEI\u2019s capability maturity model (Bamford \nand Deibler 2003; Chrissis, Konrad, and Shrum 2011). CM standards in a company \nmay be based on generic standards such as IEEE 828-2012, an IEEE standard for \n\u00ad\nconfiguration management. These standards focus on CM processes and the docu-\nments produced during the CM process (IEEE 2012). Using the external standards as a \nstarting point, companies may then develop more detailed, company-specific standards \nthat are tailored to their specific needs. However, agile methods rarely use these stand-\nards because of the documentation overhead involved.\n", "page": 735, "type": "text", "section": "Page 735"}
{"text": " \n25.1  Version management\nVersion management is the process of keeping track of different versions of software \ncomponents and the systems in which these components are used. It also involves \nensuring that changes made by different developers to these versions do not interfere \nwith each other. In other words, version management is the process of managing code-\nlines and baselines.\nFigure 25.4 illustrates the differences between codelines and baselines. A codeline is \na sequence of versions of source code, with later versions in the sequence derived from \nearlier versions. Codelines normally apply to components of systems so that there are \ndifferent versions of each component. A baseline is a definition of a specific system. The \nbaseline specifies the component versions that are included in the system and identifies \nthe libraries used, configuration files, and other system information. In Figure 25.4, you \ncan see that different baselines use different versions of the components from each code-\nline. In the diagram, I have shaded the boxes representing components in the baseline \ndefinition to indicate that these are actually references to components in a codeline. The \nmainline is a sequence of system versions developed from an original baseline.\nBaselines may be specified using a configuration language in which you define \nwhat components should be included in a specific version of a system. It is possible to \nexplicitly specify an individual component version (X.1.2, say) or simply to specify \nthe component identifier (X). If you simply include the component identifier in the \nconfiguration description, the most recent version of the component should be used.\nBaselines are important because you often have to re-create an individual version \nof a system. For example, a product line may be instantiated so that there are specific \nsystem versions for each system customer. You may have to re-create the version \ndelivered to a customer if they report bugs in their system that have to be repaired.\nVersion control (VC) systems identify, store, and control access to the different \nversions of components. There are two types of modern version control system:\n1.\t\nCentralized systems, where a single master repository maintains all versions of the \nsoftware components that are being developed. Subversion (Pilato, Collins-Sussman, \nand Fitzpatrick 2008) is a widely used example of a centralized VC system.\n2.\t\nDistributed systems, where multiple versions of the component repository exist \nat the same time. Git (Loeliger and McCullough 2012), is a widely used exam-\nple of a distributed VC system.\nCentralized and distributed VC systems provide comparable functionality but \nimplement this functionality in different ways. Key features of these systems include:\n1.\t\nVersion and release identification Managed versions of a component are \nassigned unique identifiers when they are submitted to the system. These identi-\nfiers allow different versions of the same component to be managed, without \nchanging the component name. Versions may also be assigned attributes, with \nthe set of attributes used to uniquely identify each version.\n \n25.1\u2002 \u25a0\u2002 Version management\u2002 \u2002 735\n", "page": 736, "type": "text", "section": "Page 736"}
{"text": "736\u2002 \u2002 Chapter 25\u2002 \u25a0\u2002 Configuration management\n2.\t\nChange history recording The VC system keeps records of the changes that have \nbeen made to create a new version of a component from an earlier version. In \nsome systems, these changes may be used to select a particular system version. \nThis involves tagging components with keywords describing the changes made. \nYou then use these tags to select the components to be included in a baseline.\n3.\t\nIndependent development Different developers may be working on the same \ncomponent at the same time. The version control system keeps track of compo-\nnents that have been checked out for editing and ensures that changes made to a \ncomponent by different developers do not interfere.\n4.\t\nProject support A version control system may support the development of sev-\neral projects, which share components. It is usually possible to check in and \ncheck out all of the files associated with a project rather than having to work \nwith one file or directory at a time.\n5.\t\nStorage management Rather than maintain separate copies of all versions of a \ncomponent, the version control system may use efficient mechanisms to ensure \nthat duplicate copies of identical files are not maintained. Where there are only \nsmall differences between files, the VC system may store these differences \nrather than maintain multiple copies of files. A specific version may be auto-\nmatically re-created by applying the differences to a master version.\nMost software development is a team activity, so several team members often \nwork on the same component at the same time. For example, let\u2019s say Alice is mak-\ning some changes to a system, which involves changing components A, B, and C. At \nthe same time, Bob is working on changes that require making changes to compo-\nnents X, Y, and C. Both Alice and Bob are therefore changing C. It\u2019s important to \navoid situations where changes interfere with each other\u2014Bob\u2019s changes to C over-\nwriting Alice\u2019s or vice versa.\nTo support independent development without interference, all version control \nsystems use the concept of a project repository and a private workspace. The project \nrepository maintains the \u201cmaster\u201d version of all components, which is used to create \nbaselines for system building. When modifying components, developers copy \nA\nL1\nL2\nA1.1\nEx1\nEx2\nA1.2\nA1.3\nCodeline (A)\nB\nB1.1\nB1.2\nB1.3\nCodeline (B)\nC\nC1.1\nC1.2\nC1.3\nCodeline (C)\nLibraries and external components\nBaseline - V1\nA\nB1.2\nC1.1\nL1\nL2\nEx1\nBaseline - V2\nA1.3\nB1.2\nC1.2\nL1\nL2\nEx2\nMainline\nFigure 25.4\u2002 Codelines \nand baselines\n", "page": 737, "type": "text", "section": "Page 737"}
{"text": " \n25.1\u2002 \u25a0\u2002 Version management\u2002 \u2002 737\n(check-out) these from the repository into their workspace and work on these copies. \nWhen they have completed their changes, the changed components are returned \n(checked-in) to the repository. However, centralized and distributed VC systems \nsupport independent development of shared components in different ways.\nIn centralized systems, developers check out components or directories of com-\nponents from the project repository into their private workspace and work on these \ncopies in their private workspace. When their changes are complete, they check-in \nthe components back to the repository. This creates a new component version that \nmay then be shared. For an illustration, see Figure 25.5.\nHere, Alice has checked out versions A1.0, B1.0, and C1.0. She has worked on these \nversions and has created new versions A1.1, B1.1, and C1.1. She checks these new ver-\nsions into the repository. Bob checks out X1.0, Y1.0, and C1.0. He creates new versions \nof these components and checks them back in to the repository. However, Alice has \nalready created a new version of C, while Bob has been working on it. His check-in \ntherefore creates another version C1.2, so that Alice\u2019s changes are not overwritten.\nIf two or more people are working on a component at the same time, each must \ncheck out the component from the repository. If a component has been checked out, \nthe version control system warns other users wanting to check out that component that \nit has been checked out by someone else. The system will also ensure that when the \nmodified components are checked in, the different versions are assigned different \n\u00ad\nversion identifiers and are stored separately.\nIn a distributed VC system, such as Git, a different approach is used. A \u201cmaster\u201d \nrepository is created on a server that maintains the code produced by the development \nteam. Instead of simply checking out the files that they need, a developer creates a \nclone of the project repository that is downloaded and installed on his or her computer.\nDevelopers work on the files required and maintain the new versions on their \nprivate repository on their own computer. When they have finished making \nchanges, they \u201ccommit\u201d these changes and update their private server repository. \nThey may then \u201cpush\u201d these changes to the project repository or tell the integra-\ntion manager that changed versions are available. He or she may then \u201cpull\u201d these \nfiles to the project repository (see Figure 25.6). In this example, both Bob and \nAlice have cloned the project repository and have updated files. They have not yet \npushed these back to the project repository.\nVersion management system\nAlice\nBob\nWorkspace (Alice)\nWorkspace (Bob)\ncheck_in\ncheck_out\nA1.0\nA1.1\nB1.1\nB1.0\nC1.0\nC1.1\nX1.1\nX1.0\nY1.0\nY1.1\nQ1.0\nP1.0\nC1.2\nZ1.0\nR1.0\nA1.0\nA1.1\nB1.1\nB1.0\nC1.0\nC1.1\nX1.0\nX1.1\nY1.1\nY1.0\nC1.0\nC1.1\ncheck_in\ncheck_out\nFigure 25.5\u2002 Check-in \nand check-out from a \ncentralized version \nrepository\n", "page": 738, "type": "text", "section": "Page 738"}
{"text": "738\u2002 \u2002 Chapter 25\u2002 \u25a0\u2002 Configuration management\nThis model of development has a number of advantages:\n1.\t\nIt provides a backup mechanism for the repository. If the repository is corrupted, \nwork can continue and the project repository can be restored from local copies.\n2.\t\nIt allows for offline working so that developers can commit changes if they do \nnot have a network connection.\n3.\t\nProject support is the default way of working. Developers can compile and test \nthe entire system on their local machines and test the changes they have made.\nDistributed version control is essential for open-source development where several \npeople may be working simultaneously on the same system without any central coordina-\ntion. There is no way for the open-source system \u201cmanager\u201d to know when changes will \nbe made. In this case, as well as a private repository on their own computer, developers \nalso maintain a public server repository to which they push new versions of components \nthat they have changed. It is then up to the open-source system \u201cmanager\u201d to decide when \nto pull these changes into the definitive system. This organization is shown in Figure 25.7.\nIn this example, Charlie is the integration manager for the open-source system. \nAlice and Bob work independently on system development and clone the definitive \nproject repository (1). As well as their private repositories, both Alice and Bob \nmaintain a public repository on a server than can be accessed by Charlie. When \nthey have made and tested changes, they push the changed versions from their pri-\nvate repositories to their personal public repositories and tell Charlie that these \nrepositories are available (2). Charlie pulls these from their repositories into his \nMaster repository\nAlice\nBob\nA1.0\nB1.0\nC1.0\nX1.0\nY1.0\nQ1.0\nP1.0\nZ1.0\nR1.0\nAlice\u2019s repository\nA1.0\nB1.0\nC1.0\nX1.0\nY1.0\nQ1.0\nP1.0\nZ1.0\nR1.0\nBob\u2019s repository\nA1.0\nB1.0\nC1.0\nX1.0\nY1.0\nQ1.0\nP1.0\nZ1.0\nR1.0\nA1.1\nB1.1\nC1.1\nC1.1\nX1.1\nY1.1\nclone\nclone\nFigure 25.6\u2002 Repository \ncloning\n", "page": 739, "type": "text", "section": "Page 739"}
{"text": " \n25.1\u2002 \u25a0\u2002 Version management\u2002 \u2002 739\nown private repository for testing (3). Once he is satisfied that the changes are \nacceptable, he then updates the definitive project repository (4).\nA consequence of the independent development of the same component is that \ncodelines may branch. Rather than a linear sequence of versions that reflect changes \nto the component over time, there may be several independent sequences, as shown \nin Figure 25.8. This is normal in system development, where different developers \nwork independently on different versions of the source code and change it in differ-\nent ways. It is generally recommended when working on a system that a new branch \nshould be created so that changes do not accidentally break a working system.\nAt some stage, it may be necessary to merge codeline branches to create a new version \nof a component that includes all changes that have been made. This is also shown in \nFigure 25.8, where component versions 2.1.2 and 2.3 are merged to create version 2.4. If \nthe changes made involve completely different parts of the code, the component versions \nmay be merged automatically by the version control system by combining the code \nchanges. This is the normal mode of operation when new features have been added. These \ncode changes are merged into the master copy of the system. However, the changes made \nby different developers sometimes overlap. The changes may be incompatible and inter-\nfere with each other. In this case, a developer has to check for clashes and make changes \nto the components to resolve the incompatibilities between the different versions.\nWhen version control systems were first developed, storage management was one \nof their most important functions. Disk space was expensive, and it was important to \nAlice\nBob\nDefinitive project \nrepository\nCharlie\nAlice\u2019s public\nrepository\nAlice\u2019s private\nrepository\nBob\u2019s public\nrepository\nBob\u2019s private\nrepository\nCharlie\u2019s private\nrepository\n1\n2\n2\n3\n3\n4\nFigure 25.7\u2002 Open-\nsource development\nV1.0\nV1.1\nV1.2\nV2.2\nV2.3\nV2.0\nV2.1.1\nV2.1.2\nV2.1\nV2.4\nCodeline 1\nCodeline 2\n<branch>\n<branch>\n<merge>\nCodeline 2.1\nFigure 25.8\u2002 Branching \nand merging\n", "page": 740, "type": "text", "section": "Page 740"}
{"text": "740\u2002 \u2002 Chapter 25\u2002 \u25a0\u2002 Configuration management\nminimize the disk space used by the different copies of components. Instead of keeping \na complete copy of each version, the system stores a list of differences (deltas) between \none version and another. By applying these to a master version (usually the most recent \nversion), a target version can be re-created. This is illustrated in Figure 25.9.\nWhen a new version is created, the system simply stores a delta, a list of differ-\nences, between the new version and the older version used to create that new ver-\nsion. In Figure 25.9, the shaded boxes represent earlier versions of a component that \nare automatically re-created from the most recent component version. Deltas are \nusually stored as lists of changed lines, and, by applying these automatically, one \nversion of a component can be created from another. As the most recent version of a \ncomponent will most likely be the one used, most systems store that version in full. \nThe deltas then define how to re-create earlier system versions.\nOne of the problems with a delta-based approach to storage management is that it can \ntake a long time to apply all of the deltas. As disk storage is now relatively cheap, Git \nuses an alternative, faster approach. Git does not use deltas but applies a standard com-\npression algorithm to stored files and their associated meta-information. It does not store \nduplicate copies of files. Retrieving a file simply involves decompressing it, with no need \nto apply a chain of operations. Git also uses the notion of packfiles where several smaller \nfiles are combined into an indexed single file. This reduces the overhead associated with \nlots of small files. Deltas are used within packfiles to further reduce their size.\n \n25.2  System building\nSystem building is the process of creating a complete, executable system by compiling \nand linking the system components, external libraries, configuration files, and other \ninformation. System-building tools and version control tools must be integrated as the \nbuild process takes component versions from the repository managed by the version \ncontrol system.\nSystem building involves assembling a large amount of information about the soft-\nware and its operating environment. Therefore, it always makes sense to use an auto-\nmated build tool to create a system build (Figure 25.10). Notice that you don\u2019t just need \nthe source code files that are involved in the build. You may have to link these with \nexternally provided libraries, data files (such as a file of error messages), and configu-\nration files that define the target installation. You may have to specify the versions of \nVersion\n1.0\nVersion\n1.1\nVersion\n1.2\nVersion\n1.3\nD1\nD2\nD3\nCreation date\nVersion sequence\nMost recent\nV1.3 source\ncode\nStorage structure\nFigure 25.9\u2002 Storage \nmanagement using \ndeltas\n", "page": 741, "type": "text", "section": "Page 741"}
{"text": " \n25.2\u2002 \u25a0\u2002 System building\u2002 \u2002 741\nthe compiler and other software tools that are to be used in the build. Ideally, you \nshould be able to build a complete system with a single command or mouse click.\nTools for system integration and building include some or all of the following features:\n1.\t\nBuild script generation The build system should analyze the program that is \nbeing built, identify dependent components, and automatically generate a build \nscript (configuration file). The system should also support the manual creation \nand editing of build scripts.\n2.\t\nVersion control system integration The build system should check out the \nrequired versions of components from the version control system.\n3.\t\nMinimal recompilation The build system should work out what source code \nneeds to be recompiled and set up compilations if required.\n4.\t\nExecutable system creation The build system should link the compiled object \ncode files with each other and with other required files, such as libraries and \nconfiguration files, to create an executable system.\n5.\t\nTest automation Some build systems can automatically run automated tests \nusing test automation tools such as JUnit. These check that the build has not \nbeen \u201cbroken\u201d by changes.\n6.\t\nReporting The build system should provide reports about the success or failure \nof the build and the tests that have been run.\n7.\t\nDocumentation generation The build system may be able to generate release \nnotes about the build and system help pages.\nThe build script is a definition of the system to be built. It includes information about \ncomponents and their dependencies, and the versions of tools used to compile and link \nthe system. The configuration language used to define the build script includes constructs \nto describe the system components to be included in the build and their dependencies.\nBuilding is a complex process, which is potentially error-prone, as three different \nsystem platforms may be involved (Figure 25.11):\n 1.\t The development system, which includes development tools such as compilers and \nsource code editors. Developers check out code from the version control system into \nAutomated\nbuild system\nSource\ncode files\nData files\nLibraries\nConfiguration\nfiles\nExecutable\ntests\nExecutable\ntarget system\nTest results\nCompilers\nand tools\nFigure 25.10\u2002 System \nbuilding\n", "page": 742, "type": "text", "section": "Page 742"}
{"text": "742\u2002 \u2002 Chapter 25\u2002 \u25a0\u2002 Configuration management\na private workspace before making changes to the system. They may wish to build a \nversion of a system for testing in their development environment before committing \nchanges that they have made to the version control system. This involves using local \nbuild tools that use checked-out versions of components in the private workspace.\n2.\t\nThe build server, which is used to build definitive, executable versions of the \nsystem. This server maintains the definitive versions of a system. All of the \nsystem developers check in code to the version control system on the build \nserver for system building.\n3.\t\nThe target environment, which is the platform on which the system executes. This \nmay be the same type of computer that is used for the development and build sys-\ntems. However, for real-time and embedded systems, the target environment is often \nsmaller and simpler than the development environment (e.g., a cell phone). For large \nsystems, the target environment may include databases and other application systems \nthat cannot be installed on development machines. In these situations, it is not possi-\nble to build and test the system on the development computer or on the build server.\nAgile methods recommend that very frequent system builds should be carried \nout, with automated testing used to discover software problems. Frequent builds are \npart of a process of continuous integration as shown in Figure 25.12. In keeping with \nthe agile methods notion of making many small changes, continuous integration \ninvolves rebuilding the mainline frequently, after small source code changes have \nbeen made. The steps in continuous integration are:\n1.\t\nExtract the mainline system from the VC system into the developer\u2019s private \nworkspace.\n2.\t\nBuild the system and run automated tests to ensure that the built system passes \nall tests. If not, the build is broken, and you should inform whoever checked in \nthe last baseline system. He or she is responsible for repairing the problem.\n3.\t\nMake the changes to the system components.\n4.\t\nBuild the system in a private workspace and rerun system tests. If the tests fail, \ncontinue editing.\nDevelopment system\nDevelopment\ntools\nPrivate workspace\nBuild server\nVersion\nmanagement\nsystem\nco\nVersion management and build server\nTarget system\nExecutable system\nTarget platform\nCheck-out\n(co)\nCheck-in\nFigure 25.11\u2002  \nDevelopment, build, and \ntarget platforms\n", "page": 743, "type": "text", "section": "Page 743"}
{"text": " \n25.2\u2002 \u25a0\u2002 System building\u2002 \u2002 743\n5.\t\nOnce the system has passed its tests, check it into the build system server but do \nnot commit it as a new system baseline in the VC system.\n6.\t\nBuild the system on the build server and run the tests. Alternatively, if you are \nusing Git, you can pull recent changes from the server to your private work-\nspace. You need to do this in case others have modified components since you \nchecked out the system. If this is the case, check out the components that have \nfailed and edit these so that tests pass on your private workspace.\n7.\t\nIf the system passes its tests on the build system, then commit the changes you \nhave made as a new baseline in the system mainline.\nTools such as Jenkins (Smart 2011) are used to support continuous integration. \nThese tools can be set up to build a system as soon as a developer has completed a \nrepository update.\nThe advantage of continuous integration is that it allows problems caused by the \ninteractions between different developers to be discovered and repaired as soon as \npossible. The most recent system in the mainline is the definitive working system. \nHowever, although continuous integration is a good idea, it is not always possible to \nimplement this approach to system building:\n1.\t\nIf the system is very large, it may take a long time to build and test, especially if \nintegration with other application systems is involved. It may be impractical to \nbuild the system being developed several times per day.\n2.\t\nIf the development platform is different from the target platform, it may not be \npossible to run system tests in the developer\u2019s private workspace. There may be \ndifferences in hardware, operating system, or installed software. Therefore, \nmore time is required for testing the system.\nFor large systems or for systems where the execution platform is not the same as \nthe development platform, continuous integration is usually impossible. In those \ncircumstances, frequent system building is supported using a daily build system:\nCheck-out\nmainline\nBuild and\ntest system\nBuild and\ntest system\nMake\nchanges\nCheck-in to\nbuild server\nBuild and\ntest system\nCommit\nchanges to VM\nVersion\nmanagement\nsystem\nVersion\nmanagement\nsystem\nBuild server\nPrivate\nworkspace\nTests fail\nTests OK\nOK\nTests fail\nFigure 25.12\u2002  \nContinuous integration\n", "page": 744, "type": "text", "section": "Page 744"}
{"text": "744\u2002 \u2002 Chapter 25\u2002 \u25a0\u2002 Configuration management\n1.\t\nThe development organization sets a delivery time (say 2 p.m.) for system com-\nponents. If developers have new versions of the components that they are writ-\ning, they must deliver them by that time. Components may be incomplete but \nshould provide some basic functionality that can be tested.\n2.\t\nA new version of the system is built from these components by compiling and \nlinking them to form a complete system.\n3.\t\nThis system is then delivered to the testing team, which carries out a set of pre-\ndefined system tests.\n4.\t\nFaults that are discovered during system testing are documented and returned to the \nsystem developers. They repair these faults in a subsequent version of the component.\nThe advantages of using frequent builds of software are that the chances of \nfinding problems stemming from component interactions early in the process are \nincreased. Frequent building encourages thorough unit testing of components. \nPsychologically, developers are put under pressure not to \u201cbreak the build\u201d; that \nis, they try to avoid checking in versions of components that cause the whole sys-\ntem to fail. They are therefore reluctant to deliver new component versions that \nhave not been properly tested. Consequently, less time is spent during system \ntesting discovering and coping with software faults that could have been found by \nthe developer.\nAs compilation is a computationally intensive process, tools to support system \nbuilding may be designed to minimize the amount of compilation that is required. \nThey do this by checking if a compiled version of a component is available. If so, there \nis no need to recompile that component. Therefore, there has to be a way of unam-\nbiguously linking the source code of a component with its equivalent object code.\nThis linking is accomplished by associating a unique signature with each file \nwhere a source code component is stored. The corresponding object code, which has \nbeen compiled from the source code, has a related signature. The signature identifies \neach source code version and is changed when the source code is edited. By compar-\ning the signatures on the source and object code files, it is possible to decide if the \nsource code component was used to generate the object code component.\nTwo types of signature may be used, as shown in Figure 25.13:\n1.\t\nModification timestamps The signature on the source code file is the time and \ndate when that file was modified. If the source code file of a component has \nbeen modified after the related object code file, then the system assumes that \nrecompilation to create a new object code file is necessary.\n\t\nFor example, say components Comp.java and Comp.class have modification \nsignatures of 17:03:05:02:14:2014 and 16:58:43:02:14:2014, respectively. This \nmeans that the Java code was modified at 3 minutes and 5 seconds past 5 on the \n14th of February 2014 and the compiled version was modified at 58 minutes \nand 43 seconds past 4 on the 14th of February 2014. In this case, the system \nwould automatically recompile Comp.java because the compiled version has an \nearlier modification date than the most recent version of the component.\n", "page": 745, "type": "text", "section": "Page 745"}
{"text": " \n25.3\u2002 \u25a0\u2002 Change management\u2002 \u2002 745\n2.\t\nSource code checksums The signature on the source code file is a checksum calcu-\nlated from data in the file. A checksum function calculates a unique number using \nthe source text as input. If you change the source code (even by one character), this \nwill generate a different checksum. You can therefore be confident that source code \nfiles with different checksums are actually different. The checksum is assigned to \nthe source code just before compilation and uniquely identifies the source file. The \nbuild system then tags the generated object code file with the checksum signature. \nIf there is no object code file with the same signature as the source code file to be \nincluded in a system, then recompilation of the source code is necessary.\nAs object code files are not normally versioned, the first approach means that only \nthe most recently compiled object code file is maintained in the system. This is nor-\nmally related to the source code file by name; that is, it has the same name as the \nsource code file but with a different suffix. Therefore, the source file Comp.Java may \ngenerate the object file Comp.class. Because source and object files are linked by \nname, it is not usually possible to build different versions of a source code component \ninto the same directory at the same time. The compiler would generate object files \nwith the same name, so only the most recently compiled version would be available.\nThe checksum approach has the advantage of allowing many different versions of \nthe object code of a component to be maintained at the same time. The signature \nrather than the filename is the link between source and object code. The source code \nand object code files have the same signature. Therefore, when you recompile a \ncomponent, it does not overwrite the object code, as would normally be the case \nwhen the timestamp is used. Rather, it generates a new object code file and tags it \nwith the source code signature. Parallel compilation is possible, and different ver-\nsions of a component may be compiled at the same time.\n \n25.3  Change management\nChange is a fact of life for large software systems. Organizational needs and require-\nments change during the lifetime of a system, bugs have to be repaired, and systems \nhave to adapt to changes in their environment. To ensure that the changes are applied \nComp.java\n(V1.0)\n16583102142014\nTimestamp\nComp.java\n(V1.1)\nComp.class\n17030502142014\n16584302142014\nTimestamp\nTimestamp\nCompile\nComp.java\n(V1.0)\nComp.class\n24374509887231\n24374509887231\nChecksum\nChecksum\nComp.java\n(V1.1)\nComp.class\n37650812555734\n37650812555734\nChecksum\nChecksum\nCompile\nCompile\nTime-based identification\nChecksum-based identification\nFigure 25.13\u2002 Linking \nsource and object  \ncode\n", "page": 746, "type": "text", "section": "Page 746"}
{"text": "746\u2002 \u2002 Chapter 25\u2002 \u25a0\u2002 Configuration management\nto the system in a controlled way, you need a set of tool-supported, change manage-\nment processes. Change management is intended to ensure that the evolution of the \nsystem is controlled and that the most urgent and cost-effective changes are prioritized.\nChange management is the process of analyzing the costs and benefits of pro-\nposed changes, approving those changes that are cost-effective, and tracking which \ncomponents in the system have been changed. Figure 25.14 is a model of a change \nmanagement process that shows the main change management activities. This pro-\ncess should come into effect when the software is handed over for release to custom-\ners or for deployment within an organization.\nMany variants of this process are in use depending on whether the software is a cus-\ntom system, a product line, or an off-the-shelf product. The size of the company also \nmakes a difference\u2014small companies use a less formal process than large companies \nthat are working with corporate or government customers. However, all change manage-\nment processes should include some way of checking, costing, and approving changes.\nTools to support change management may be relatively simple issue or bug track-\ning systems or software that is integrated with a configuration management package \nfor large-scale systems, such as Rational Clearcase. Issue tracking systems allow any-\none to report a bug or make a suggestion for a system change, and they keep track of \nhow the development team has responded to the issues. These systems do not impose \na process on the users and so can be used in many different settings. More complex \nsystems are built around a process model of the change management process. They \nChange\nrequests\nSubmit\nCR\nCheck CR\nClose CR\nImplementation\nanalysis\nCost/impact\nanalysis\nAssess CRs\nSelect CRs\nModify\nsoftware\nTest software\nClose CR\nClose CRs\nValid\nInvalid\nPass\nFail\nCustomer\nCustomer support\nDevelopment\nProduct development/CCB\nRegister CR\nFigure 25.14\u2002 The \nchange management \nprocess\n", "page": 747, "type": "text", "section": "Page 747"}
{"text": " \n25.3\u2002 \u25a0\u2002 Change management\u2002 \u2002 747\nautomate the entire process of handling change requests from the initial customer \nproposal to final change approval and change submission to the development team.\nThe change management process is initiated when a system stakeholder completes and \nsubmits a change request describing the change required to the system. This could be a \nbug report, where the symptoms of the bug are described, or a request for additional func-\ntionality to be added to the system. Some companies handle bug reports and new require-\nments separately, but, in principle, both are simply change requests. Change requests may \nbe submitted using a change request form (CRF). Stakeholders may be system owners \nand users, beta testers, developers, or the marketing department of a company.\nElectronic change request forms record information that is shared between all \ngroups involved in change management. As the change request is processed, infor-\nmation is added to the CRF to record decisions made at each stage of the process. At \nany time, it therefore represents a snapshot of the state of the change request. In \naddition to recording the change required, the CRF records the recommendations \nregarding the change, the estimated costs of the change, and the dates when the \nchange was requested, approved, implemented, and validated. The CRF may also \ninclude a section where a developer outlines how the change may be implemented. \nAgain, the degree of formality in the CRF varies depending on the size and type of \norganization that is developing the system.\n Figure 25.15 is an example of a type of CRF that might be used in a large com-\nplex systems engineering project. For smaller projects, I recommend that change \nrequests should be formally recorded; the CRF should focus on describing the \nChange Request Form\nProject: SICSA/AppProcessing\t\nNumber: 23/02\nChange requester: I. Sommerville\t\nDate: 20/07/12\nRequested change: The status of applicants (rejected, accepted, etc.) should be shown \nvisually in the displayed list of applicants.\nChange analyzer: R. Looek\t\nAnalysis date: 25/07/12\nComponents affected: ApplicantListDisplay, StatusUpdater\nAssociated components: StudentDatabase\nChange assessment: Relatively simple to implement by changing the display color \naccording to status. A table must be added to relate status to colors. No changes to \nassociated components are required.\nChange priority: Medium\nChange implementation:\nEstimated effort: 2 hours\nDate to SGA app. team: 28/07/12\t\nCCB decision date: 30/07/12\nDecision: Accept change. Change to be implemented in Release 1.2\nChange implementor:\t\nDate of change:\nDate submitted to QM:\t\nQM decision:\nDate submitted to CM:\nComments:\nFigure 25.15\u2002 A partially \ncompleted change \nrequest form\n", "page": 748, "type": "text", "section": "Page 748"}
{"text": "748\u2002 \u2002 Chapter 25\u2002 \u25a0\u2002 Configuration management\nchange required, with less emphasis on implementation issues. System developers \ndecide how to implement the change and estimate the time required to complete \nthe change implementation.\nAfter a change request has been submitted, it is checked to ensure that it is valid. \nThe checker may be from a customer or application support team or, for internal \nrequests, may be a member of the development team. The change request may be \nrejected at this stage. If the change request is a bug report, the bug may have already \nbeen reported and repaired. Sometimes, what people believe to be problems are actu-\nally misunderstandings of what the system is expected to do. On occasions, people \nrequest features that have already been implemented but that they don\u2019t know about. \nIf any of these features are true, the issue is closed and the form is updated with the \nreason for closure. If it is a valid change request, it is then logged as an outstanding \nrequest for subsequent analysis.\nFor valid change requests, the next stage of the process is change assessment and \ncosting. This function is usually the responsibility of the development or mainte-\nnance team as they can work out what is involved in implementing the change. The \nimpact of the change on the rest of the system must be checked. To do this, you have \nto identify all of the components affected by the change. If making the change means \nthat further changes elsewhere in the system are needed, this will obviously increase \nthe cost of change implementation. Next, the required changes to the system mod-\nules are assessed. Finally, the cost of making the change is estimated, taking into \naccount the costs of changing related components.\nFollowing this analysis, a separate group decides if it is cost-effective for the \nbusiness to make the change to the software. For military and government systems, \nthis group is often called the change control board (CCB). In industry, it may be \ncalled something like a \u201cproduct development group\u201d responsible for making deci-\nsions about how a software system should evolve. This group should review and \napprove all change requests, unless the changes simply involve correcting minor \nerrors on screen displays, web pages, or documents. These small requests should be \npassed to the development team for immediate implementation.\nThe CCB or product development group considers the impact of the change from \na strategic and organizational rather than a technical point of view. It decides whether \nthe change in question is economically justified, and it prioritizes accepted changes \nfor implementation. Accepted changes are passed back to the development group; \nCustomers and changes\nAgile methods emphasize the importance of involving customers in the change prioritization process. The \n\u00ad\ncustomer representative helps the team decide on the changes that should be implemented in the next devel-\nopment iteration. While this can be effective for systems that are in development for a single customer, it can be \na problem in product development where no real customer is working with the team. In those cases, the team \nhas to make its own decisions on change prioritization.\nhttp://software-engineering-book.com/web/agile-changes/\n", "page": 749, "type": "text", "section": "Page 749"}
{"text": " \n25.3\u2002 \u25a0\u2002 Change management\u2002 \u2002 749\nrejected change requests are closed and no further action is taken. The factors that \ninfluence the decision on whether or not to implement a change include:\n1.\t\nThe consequences of not making the change When assessing a change request, \nyou have to consider what will happen if the change is not implemented. If the \nchange is associated with a reported system failure, the seriousness of that fail-\nure has to be taken into account. If the system failure causes the system to crash, \nthis is very serious, and failure to make the change may disrupt the operational \nuse of the system. On the other hand, if the failure has a minor effect, such as \nincorrect colors on a display, then it is not important to fix the problem quickly. \nThe change should therefore have a low priority.\n2.\t\nThe benefits of the change Will the change benefit many users of the system, or \nwill it only benefit the change proposer?\n3.\t\nThe number of users affected by the change If only a few users are affected, then \nthe change may be assigned a low priority. In fact, making the change may be \ninadvisable if it means that the majority of system users have to adapt to it.\n4.\t\nThe costs of making the change If making the change affects many system com-\nponents (hence increasing the chances of introducing new bugs) and/or takes a \nlot of time to implement, then the change may be rejected.\n5.\t\nThe product release cycle If a new version of the software has just been released \nto customers, it may make sense to delay implementation of the change until the \nnext planned release (see Section 25.4).\nChange management for software products (e.g., a CAD system product), rather than \ncustom systems specifically developed for a certain customer, are handled in a different \nway. In software products, the customer is not directly involved in decisions about sys-\ntem evolution, so the relevance of the change to the customer\u2019s business is not an issue. \nChange requests for these products come from the customer support team, the company \nmarketing team, and the developers themselves. These requests may reflect suggestions \nand feedback from customers or analyses of what is offered by competing products.\nThe customer support team may submit change requests associated with bugs that \nhave been discovered and reported by customers after the software has been released. \nCustomers may use a web page or email to report bugs. A bug management team then \nchecks that the bug reports are valid and translates them into formal system change \nrequests. Marketing staff may meet with customers and investigate competitive products. \nThey may suggest changes that should be included to make it easier to sell a new version \nof a system to new and existing customers. The system developers themselves may have \nsome good ideas about new features that can be added to the system.\nThe change request process shown in Figure 25.14 is initiated after a system has \nbeen released to customers. During development, when new versions of the system \nare created through daily (or more frequent) system builds, there is no need for a \nformal change management process. Problems and requested changes are recorded \nin an issue tracking system and discussed in daily meetings. Changes that only affect \nindividual components are passed directly to the system developer, who either \naccepts them or makes a case for why they are not required. However, an \u00ad\nindependent \n", "page": 750, "type": "text", "section": "Page 750"}
{"text": "750\u2002 \u2002 Chapter 25\u2002 \u25a0\u2002 Configuration management\nauthority, such as the system architect, should assess and prioritize changes that cut \nacross system modules that have been produced by different development teams.\nIn some agile methods, customers are directly involved in deciding whether a change \nshould be implemented. When they propose a change to the system requirements, they \nwork with the team to assess the impact of that change and then decide whether the \nchange should take priority over the features planned for the next increment of the sys-\ntem. However, changes that involve software improvement are left to the discretion of \nthe programmers working on the system. Refactoring, where the software is continually \nimproved, is not seen as an overhead but as a necessary part of the development process.\nAs the development team changes software components, they should maintain a \nrecord of the changes made to each component. This is sometimes called the derivation \nhistory of a component. A good way to keep the derivation history is in a standardized \ncomment at the beginning of the component source code (Figure 25.16). This com-\nment should reference the change request that triggered the software change. These \ncomments can be processed by scripts that scan all components for the derivation his-\ntories and then generate component change reports. For documents, records of changes \nincorporated in each version are usually maintained in a separate page at the front of \nthe document. I discuss this in the web chapter on documentation (Chapter 30).\n \n25.4  Release management\nA system release is a version of a software system that is distributed to customers. \nFor mass-market software, it is usually possible to identify two types of release: \nmajor releases, which deliver significant new functionality, and minor releases, \nwhich repair bugs and fix customer problems that have been reported. For example, \nthis book is being written on an Apple Mac computer where the operating system is \nOS 10.9.2. This means minor release 2 of major release 9 of OS 10. Major releases \nare very important economically to the software vendor, as customers usually have \nto pay for them. Minor releases are usually distributed free of charge.\n// SICSA project (XEP 6087)\n//\n// APP-SYSTEM/AUTH/RBAC/USER_ROLE\n//\n// Object: currentRole\n// Author: R. Looek\n// Creation date: 13/11/2012\n//\n// \u00a9 St Andrews University 2012\n//\n// Modification history\n// Version\t\nModifier\t\nDate\t\nChange\t\nReason\n// 1.0\t\nJ. Jones\t\n11/11/2009\t\nAdd header\t\nSubmitted to CM\n// 1.1\t\nR. Looek\t\n13/11/2009\t\nNew field\t\nChange req. R07/02\nFigure 25.16\u2002  \nDerivation history\n", "page": 751, "type": "text", "section": "Page 751"}
{"text": " \n25.4\u2002 \u25a0\u2002 Release management\u2002 \u2002 751\nA software product release is not just the executable code of the system. The \nrelease may also include:\n\u25a0\t configuration files defining how the release should be configured for particular \ninstallations;\n\u25a0\t data files, such as files of error messages in different languages, that are needed \nfor successful system operation;\n\u25a0\t an installation program that is used to help install the system on target hardware;\n\u25a0\t electronic and paper documentation describing the system;\n\u25a0\t packaging and associated publicity that have been designed for that release.\nPreparing and distributing a system release for mass-market products is an expensive \nprocess. In addition to the technical work involved in creating a release distribution, \nadvertising and publicity material have to be prepared. Marketing strategies may have \nto be designed to convince customers to buy the new release of the system. Careful \nthought must be given to release timing. If releases are too frequent or require hardware \nupgrades, customers may not move to the new release, especially if they have to pay for \nit. If system releases are infrequent, market share may be lost as customers move to \nalternative systems.\nThe various technical and organizational factors that you should take into account \nwhen deciding on when to release a new version of a software product are shown in \nFigure 25.17.\nRelease creation is the process of creating the collection of files and documentation \nthat include all components of the system release. This process involves several steps:\n1.\t\nThe executable code of the programs and all associated data files must be identi-\nfied in the version control system and tagged with the release identifier.\n2.\t\nConfiguration descriptions may have to be written for different hardware and \noperating systems.\n3.\t\nUpdated instructions may have to be written for customers who need to config-\nure their own systems.\n4.\t\nScripts for the installation program may have to be written.\n5.\t Web pages have to be created describing the release, with links to system \ndocumentation.\n6.\t\nFinally, when all information is available, an executable master image of the \nsoftware must be prepared and handed over for distribution to customers or \nsales outlets.\nFor custom software or software product lines, the complexity of the system release \nmanagement process depends on the number of system customers. Special releases \nof the system may have to be produced for each customer. Individual customers \nmay be running several different releases of the system at the same time on differ-\nent hardware. Where the software is part of a complex system of systems, several \n", "page": 752, "type": "text", "section": "Page 752"}
{"text": "752\u2002 \u2002 Chapter 25\u2002 \u25a0\u2002 Configuration management\ndifferent variants of the individual systems may have to be created. For example, in \nspecialized fire-fighting vehicles, each type of vehicle may have its own version of \na software system that is adapted to the equipment in that vehicle.\nA software company may have to manage tens or even hundreds of different \nreleases of their software. Their configuration management systems and processes \nhave to be designed to provide information about which customers have which \nreleases of the system and the relationship between releases and system versions. In \nthe event of a problem with a delivered system, you have to be able to recover all of \nthe component versions used in that specific system.\nTherefore, when a system release is produced, it must be documented to ensure \nthat it can be re-created exactly in the future. This is particularly important for cus-\ntomized, long-lifetime embedded systems, such as military systems and those that \ncontrol complex machines. These systems may have a long lifetime\u201430 years in \nsome cases. Customers may use a single release of these systems for many years and \nmay require specific changes to that release long after it has been superseded.\nTo document a release, you have to record the specific versions of the source \ncode components that were used to create the executable code. You must keep cop-\nies of the source code files, corresponding executables, and all data and configura-\ntion files. It may be necessary to keep copies of older operating systems and other \nsupport software because they may still be in operational use. Fortunately, this no \nlonger means that old hardware always has to be maintained. The older operating \nsystems can run in a virtual machine.\nYou should also record the versions of the operating system, libraries, compilers, \nand other tools used to build the software. These tools may be required in order to \nbuild exactly the same system at some later date. Accordingly, you may have to store \ncopies of the platform software and the tools used to create the system in the version \ncontrol system, along with the source code of the target system.\nWhen planning the installation of new system releases, you cannot assume that cus-\ntomers will always install new system releases. Some system users may be happy with \nFactor\nDescription\nCompetition\nFor mass-market software, a new system release may be necessary because a \ncompeting product has introduced new features and market share may be lost if \nthese are not provided to existing customers.\nMarketing requirements\nThe marketing department of an organization may have made a commitment for \nreleases to be available at a particular date. For marketing reasons, it may be \nnecessary to include new features in a system so that users can be persuaded to \nupgrade from a previous release.\nPlatform changes\nYou may have to create a new release of a software application when a new \nversion of the operating system platform is released.\nTechnical quality of the \nsystem\nIf serious system faults are reported that affect the way in which many customers \nuse the system, it may be necessary to correct them in a new system release. \nMinor system faults may be repaired by issuing patches, distributed over the \nInternet, which can be applied to the current release of the system.\nFigure 25.17\u2002 Factors \ninfluencing system \nrelease planning\n", "page": 753, "type": "text", "section": "Page 753"}
{"text": "an existing system and may not consider it worthwhile to absorb the cost of changing \nto a new release. New releases of the system cannot, therefore, rely on the installation \nof previous releases. To illustrate this problem, consider the following scenario:\n1.\t\nRelease 1 of a system is distributed and put into use.\n2.\t\nRelease 2 requires the installation of new data files, but some customers do not \nneed the facilities of release 2 and so remain with release 1.\n3.\t\nRelease 3 requires the data files installed in release 2 and has no new data files \nof its own.\nThe software distributor cannot assume that the files required for release 3 have \nalready been installed in all sites. Some sites may go directly from release 1 to \nrelease 3, skipping release 2. Some sites may have modified the data files associated \nwith release 2 to reflect local circumstances. Therefore, the data files must be distrib-\nuted and installed with release 3 of the system.\nOne benefit of delivering software as a service (SaaS) is that it avoids all of these \nproblems. It simplifies both release management and system installation for customers. \nThe software developer is responsible for replacing the existing release of a system \nwith a new release, which is made available to all customers at the same time. However, \nthis approach requires that all servers running the services be updated at the same time. \nTo support server updates, specialized distribution management tools such as Puppet \n(Loope 2011) have been developed for \u201cpushing\u201d new software to servers.\nKey Points\n\u25a0\t Configuration management is the management of an evolving software system. When maintain-\ning a system, a CM team is put in place to ensure that changes are incorporated into the system \nin a controlled way and that records are maintained with details of the changes that have been \nimplemented.\n\u25a0\t The main configuration management processes are concerned with version control, system \nbuilding, change management, and release management. Software tools are available to  \nsupport all of these processes.\n\u25a0\t Version control involves keeping track of the different versions of software components that are \ncreated as changes are made to them.\n\u25a0\t System building is the process of assembling system components into an executable program \nto run on a target computer system.\n\u25a0\t Software should be frequently rebuilt and tested immediately after a new version has been built. This \nmakes it easier to detect bugs and problems that have been introduced since the last build.\n\u25a0\t Change management involves assessing proposals for changes from system customers and \nother stakeholders and deciding if it is cost-effective to implement these changes in a new \nrelease of a system.\n \nChapter 25\u2002 \u25a0\u2002 Key Points\u2002 \u2002 753\n", "page": 754, "type": "text", "section": "Page 754"}
{"text": "754\u2002 \u2002 Chapter 25\u2002 \u25a0\u2002 Configuration management\n\u25a0\t System releases include executable code, data files, configuration files, and documentation. \nRelease management involves making decisions on system release dates, preparing all \n\u00ad\ninformation for distribution and documenting each system release.\nFurther Reading\nSoftware Configuration Management Patterns: Effective Teamwork, Practical Integration. A relatively \nshort, easy-to-read book that gives good practical advice on configuration management practice, \nespecially for agile methods of development. (S. P. Berczuk with B. Appleton, Addison-Wesley, 2003).\n\u201cAgile Configuration Management for Large Organizations.\u201d This web article describes configuration \nmanagement practices that can be used in agile development processes, with a particular emphasis \non how these can scale to large projects and companies. (P. Schuh, 2007). http://www.ibm.com/\ndeveloperworks/rational/library/mar07/schuh/index.html\nConfiguration Management Best Practices This is a nicely written book that presents a broader \nview of configuration management than I have discussed here, including hardware configuration \nmanagement. It\u2019s geared to large systems projects and does not really cover agile development \nissues. (Bob Aiello and Leslie Sachs, Addison-Wesley, 2011).\n\u201cA Behind the Scenes Look at Facebook Release Engineering.\u201d This is an interesting article that covers the \nproblems of releasing new versions of large systems in the cloud, something that I haven\u2019t \u00ad\ndiscussed in \nthis chapter. The challenge here is to make sure that all of the servers are updated at the same time so \nthat users don\u2019t see different versions of the system. (P. Ryan, arstechnica.com, 2012). http://arstechnica.\ncom/business/2012/04/exclusive-a-behind-the-scenes-look-at-facebook-release-engineering/\n\u201cGit SVn Comparison.\u201d This wiki compares the Git and Subversion version control systems. (2013, \nhttps://git.wiki.kernel.org/index.php/GitSvnComparsion).\nWebsite\nPowerPoint slides for this chapter:\nwww.pearsonglobaleditions.com/Sommerville\nLinks to supporting videos:\nhttp://software-engineering-book.com/videos/software-management/\nExercises\n25.1. \tSuggest five possible problems that could arise if a company does not develop effective \n\u00ad\nconfiguration management policies and processes.\n25.2. \tIn version management, what do codeline and baseline terminologies stand for? List the features \nincluded in a version control system.\n754\u2002 \u2002 Chapter 25\u2002 \u25a0\u2002 Configuration management\n", "page": 755, "type": "text", "section": "Page 755"}
{"text": " \n25.4\u2002 \u25a0\u2002 Release management\u2002 \u2002 755\n25.3. \tImagine a situation where two developers are simultaneously modifying three different software \ncomponents. What difficulties might arise when they try to merge the changes they have made?\n25.4. \tSoftware is now often developed by distributed teams, with team members working at  \ndifferent locations and in different time zones. Suggest features in a version control system \nthat could be included to support distributed software development.\n25.5. \tDescribe the difficulties that may arise when building a system from its components. What \nparticular problems might occur when a system is built on a host computer for some target \nmachine?\n25.6. \tWith reference to system building, explain why you may sometimes have to maintain obsolete \ncomputers on which large software systems were developed.\n25.7. \tA common problem with system building occurs when physical filenames are incorporated  \nin system code and the file structure implied in these names differs from that of the target \nmachine. Write a set of programmer\u2019s guidelines that helps avoid this and any other system-\nbuilding problems that you can think of.\n25.8. \tWhat are the factors that influence the decision on whether or not a change should be \n\u00ad\nimplemented?\n25.9. \tDescribe six essential features that should be included in a tool to support change management \nprocesses.\n25.10.\u2002 \u0007\nExplain why preparing and distributing a system release for mass-market products is an \nexpensive process.\nReferences\nAiello, B., and L. Sachs. 2011. Configuration Management Best Practices. Boston: Addison-Wesley.\nBamford, R., and W. J. Deibler. 2003. \u201cISO 9001:2000 for Software and Systems Providers: An \nEngineering Approach.\u201d Boca Raton, FL: CRC Press.\nChrissis, M. B., M. Konrad, and S. Shrum. 2011. CMMI for Development: Guidelines for Process \n\u00ad\nIntegration and Product Improvement, 3rd ed. Boston: Addison-Wesley.\nIEEE. 2012. \u201cIEEE Standard for Configuration Management in Systems and Software Engineering\u201d \n(IEEE Std 828-2012).\u201d doi:10.1109/IEEESTD.2012.6170935.\nLoeliger, J., and M. McCullough. 2012. Version Control with Git: Powerful Tools and Techniques for \nCollaborative Software Development. Sebastopol, CA: O\u2019Reilly and Associates.\nLoope, J. 2011. Managing Infrastructure with Puppet. Sebastopol, CA: O\u2019Reilly and Associates.\nPilato, C., B. Collins-Sussman, and B. Fitzpatrick. 2008. Version Control with Subversion. \n\u00ad\nSebastopol, CA: O\u2019Reilly and Associates.\nSmart, J. F. 2011. Jenkins: The Definitive Guide. Sebastopol, CA: O\u2019Reilly and Associates.\n \nChapter 25\u2002 \u25a0\u2002 References\u2002 \u2002 755\n", "page": 756, "type": "text", "section": "Page 756"}
{"text": "This page intentionally left blank\n", "page": 757, "type": "text", "section": "Page 757"}
{"text": "abstract data type\nA type that is defined by its operations rather than its representation. The represen-\ntation is private and may only be accessed by the defined operations.\nacceptance testing\nCustomer tests of a system to decide if it is adequate to meet their needs and so \nshould be accepted from a supplier.\nactivity chart\nA chart used by project managers to show the dependencies between tasks that have \nto be completed. The chart shows the tasks, the time expected to complete these tasks \nand the task dependencies. The critical path is the longest path (in terms of the time \nrequired to complete the tasks) through the activity chart. The critical path defines the \nminimum time required to complete the project. Sometimes called a PERT chart.\nAda\nA programming language that was developed for the US Department of Defense in \nthe 1980s as a standard language for developing military software. It is based on \nprogramming language research from the 1970s and includes constructs such as \nabstract data types and support for concurrency. It is still used for large, complex \nmilitary and aerospace systems.\nagile manifesto\nA set of principles encapsulating the ideas underlying agile methods of software \ndevelopment.\nagile methods\nMethods of software development that are geared to rapid software delivery. The \nsoftware is developed and delivered in increments, and process documentation and \nGlossary\n", "page": 758, "type": "text", "section": "Page 758"}
{"text": "758\u2002 \u2002 Glossary\nbureaucracy are minimized. The focus of development is on the code itself, rather \nthan supporting documents.\nalgorithmic cost modeling\nAn approach to software cost estimation where a formula is used to estimate the project \ncost. The parameters in the formula are attributes of the project and the software itself.\napplication family\nA set of software application programs that have a common architecture and \ngeneric functionality. These can be tailored to the needs of specific customers by \nmodifying components and program parameters.\napplication framework\nA set of reusable concrete and abstract classes that implement features common to \nmany applications in a domain (e.g. user interfaces). The classes in the application \nframework are specialized and instantiated to create an application.\napplication program interface (API)\nAn interface, generally specified as a set of operations, that allows access to an \napplication program\u2019s functionality. This means that this functionality can be called \non directly by other programs and not just accessed through the user interface.\narchitectural pattern (style)\nAn abstract description of a software architecture that has been tried and tested in a \nnumber of different software systems. The pattern description includes information \nabout where it is appropriate to use the pattern and the organization of the compo-\nnents of the architecture.\narchitectural view\nA description of a software architecture from a particular perspective.\navailability\nThe readiness of a system to deliver services when requested. Availability is usu-\nally expressed as a decimal number, so an availability of 0.999 means that the sys-\ntem can deliver services for 999 out of 1000 time units.\nB\nA formal method of software development that is based on implementing a system \nby systematic transformation of a formal system specification.\nbar chart (Gantt chart)\nA chart used by project managers to show the project tasks, the schedule associated \nwith these tasks and the people who will work on them. It shows the tasks\u2019 start and \nend dates and the staff allocations against a timeline.\nblack-box testing\nAn approach to testing where the testers have no access to the source code of a \n\u00ad\nsystem or its components. The tests are derived from the system specification.\n", "page": 759, "type": "text", "section": "Page 759"}
{"text": "\t\nGlossary\u2002 \u2002 759\nBPMN\nBusiness Process Modeling Notation. A notation for defining workflows that \ndescribe business processes and service composition.\nbrownfield software development\nThe development of software for an environment where there are several existing \nsystems that the software being developed must integrate with.\nC\nA programming language that was originally developed to implement the Unix sys-\ntem. C is a relatively low-level system implementation language that allows access \nto the system hardware and which can be compiled to efficient code. It is\u00a0widely \nused for low-level systems programming and embedded systems development.\nC++\nAn object-oriented programming language that is a superset of C.\nC#\nAn object-oriented programming language, developed by Microsoft, that has much \nin common with C++, but which includes features that allow more compile-time \ntype checking.\nCapability Maturity Model (CMM)\nThe Software Engineering Institute\u2019s Capability Maturity Model, which is used to \nassess the level of software development maturity in an organization. It has now \nbeen superseded by CMMI, but is still widely used.\nComputer-Aided Software Engineering (CASE)\nThe term that was invented in the 1980s to describe process of developing software \nusing automated tool support. Virtually all software development is now reliant on \ntool support so the term \u2019CASE is no longer widely used.\nCASE tool\nA software tool, such as a design editor or a program debugger, used to support an \nactivity in the software development process.\nCASE workbench\nAn integrated set of CASE tools that work together to support a major process \nactivity such as software design or configuration management. Now often called a \nprogramming environment.\nchange management\nA process to record, check, analyze, estimate and implement proposed changes to a \nsoftware system.\nclass diagram\nA UML diagram types that shows the object classes in a system and their \n\u00ad\nrelationships.\n", "page": 760, "type": "text", "section": "Page 760"}
{"text": "760\u2002 \u2002 Glossary\nclient\u2013server architecture\nAn architectural model for distributed systems where the system functionality is \noffered as a set of services provided by a server. These are accessed by client com-\nputers that make use of the services. Variants of this approach, such as three-tier \nclient\u2013server architectures, use multiple servers.\ncloud computing\nThe provision of computing and/or application services over the Internet using a \n\u2018cloud\u2019 of servers from an external provider. The \u2018cloud\u2019 is implemented using a \nlarge number of commodity computers and virtualization technology to make \n\u00ad\neffective use of these systems.\nCMMI\nAn integrated approach to process capability maturity modeling based on the adop-\ntion of good software engineering practice and integrated quality management. It \nsupports discrete and continuous maturity modeling and integrates systems and \nsoftware engineering process maturity models. Developed from the original Capa-\nbility Maturity Model.\nCOCOMO II\nSee Constructive Cost Modeling.\ncode of ethics and professional practice\nA set of guidelines that set out expected ethical and professional behavior for \nsoftware engineers. This was defined by the major US professional societies (the \nACM and the IEEE) and defines ethical behavior under eight headings: public, \nclient and employer, product, judgment, management, colleagues, profession \nand self.\nCommon Request Broker Architecture (CORBA)\nA set of standards proposed by the Object Management Group (OMG) that defines \ndistributed component models and communications. Influential in the development \nof distributed systems but no longer widely used.\ncomponent\nA deployable, independent unit of software that is completely defined and accessed \nthrough a set of interfaces.\ncomponent model\nA set of standards for component implementation, documentation and deploy-\nment. These cover the specific interfaces that may be provided by a compo-\nnent, component naming, component interoperation and component \ncomposition. Component models provide the basis for middleware to support \nexecuting components.\ncomponent-based software engineering (CBSE)\nThe development of software by composing independent, deployable software \ncomponents that are consistent with a component model.\n", "page": 761, "type": "text", "section": "Page 761"}
{"text": "\t\nGlossary\u2002 \u2002 761\nconceptual design\nThe development of a high-level vision of a complex system and a description of  \nits essential capabilities. Designed to be understood by people who are not  \nsystems engineers.\nconfigurable application system\nAn application system product, developed by a system vendor, that offers function-\nality that may be configured for use in different companies and environments.\nconfiguration item\nA machine-readable unit, such as a document or a source code file, that is subject to change \nand where the change has to be controlled by a configuration management system.\nconfiguration management\nThe process of managing the changes to an evolving software product. Configura-\ntion management involves version management, system building, change manage-\nment and release management.\nConstructive Cost Modeling (COCOMO)\nA family of algorithmic cost estimation models. COCOMO was first proposed in \nthe early-1980s and has been modified and updated since then to reflect new tech-\nnology and changing software engineering practice. COCOMO II is its latest \ninstantiation and is a freely available algorithmic cost estimation model that is sup-\nported by open source software tools.\nCORBA\nSee Common Request Broker Architecture.\ncontrol metric\nA software metric that allows managers to make planning decisions based on infor-\nmation about the software process or the software product that is being developed. \nMost control metrics are process metrics.\ncritical system\nA computer system whose failure can result in significant economic, human or \nenvironmental losses.\nCOTS system\nA Commercial Off-the-Shelf system. The term COTS is now mostly used in \n\u00ad\nmilitary systems. See configurable application system.\nCVS\nA widely used, open-source software tool used for version management.\ndata processing system\nA system that aims to process large amounts of structured data. These systems usually \nprocess the data in batches and follow an input-process-output model. Examples of \ndata processing systems are billing and invoicing systems, and payment systems.\n", "page": 762, "type": "text", "section": "Page 762"}
{"text": "762\u2002 \u2002 Glossary\ndenial of service attack\nAn attack on a web-based software system that attempts to overload the system so \nthat it cannot provide its normal service to users.\ndependability\nThe dependability of a system is an aggregate property that takes into account the \nsystem\u2019s safety, reliability, availability, security, resilience and other attributes. The \ndependability of a system reflects the extent to which it can be trusted by its users.\ndependability requirement\nA system requirement that is included to help achieve the required dependability for \na system. Non-functional dependability requirements specify dependability attribute \nvalues; functional dependability requirements are functional requirements that \n\u00ad\nspecify how to avoid, detect, tolerate or recover from system faults and failures.\ndependability case\nA structured document that is used to back up claims made by a system developer \nabout the dependability of a system. Specific types of dependability case are safety \ncases and security cases.\ndesign pattern\nA well-tried solution to a common problem that captures experience and good prac-\ntice in a form that can be reused. It is an abstract representation than can be instan-\ntiated in a number of ways.\ndigital learning environment\nAn integrated set of software tools, educational applications and content that is \ngeared to support learning.\ndistributed system\nA software system where the software sub-systems or components execute on \n\u00ad\ndifferent processors.\ndomain\nA specific problem or business area where software systems are used. Examples of \ndomains include real-time control, business data processing and telecommunica-\ntions switching.\ndomain model\nA definition of domain abstractions, such as policies, procedures, objects, relation-\nships and events. It serves as a base of knowledge about some problem area.\nDSDM\nDynamic System Development Method. Claimed to be one of the first agile devel-\nopment methods.\nembedded system\nA software system that is embedded in a hardware device e.g. the software system \nin a cell phone. Embedded systems are usually real-time systems and so have to \nrespond in a timely way to events occurring in their environment.\n", "page": 763, "type": "text", "section": "Page 763"}
{"text": "\t\nGlossary\u2002 \u2002 763\nemergent property\nA property that only becomes apparent once all of the components of the system \nhave been integrated to create the system.\nEnterprise Java Beans (EJB)\nA Java-based component model.\nenterprise resource planning (ERP) system\nA large-scale software system that includes a range of capabilities to support the \noperation of business enterprises and which provides a means of sharing informa-\ntion across these capabilities. For example, an ERP system may include support for \nsupply chain management, manufacturing and distribution. ERP systems are con-\nfigured to the requirements of each company using the system.\nethnography\nAn observational technique that may be used in requirements elicitation and analy-\nsis. The ethnographer immerses him or herself in the users\u2019 environment and \nobserves their day-to-day work habits. Requirements for software support can be \ninferred from these observations.\nevent-based systems\nSystems where the control of operation is determined by events that are generated \nin the system\u2019s environment. Most real-time systems are event-based systems.\nextreme programming (XP)\nA widely-used agile method of software development that includes practices such \nas scenario-based requirements, test-first development and pair programming.\nfault avoidance\nDeveloping software in such a way that faults are not introduced into that software.\nfault detection\nThe use of processes and run-time checking to detect and remove faults in a \n\u00ad\nprogram before these result in a system failure.\nfault tolerance\nThe ability of a system to continue in execution even after faults have occurred.\nfault-tolerant architectures\nSystem architectures that are designed to allow recovery from software faults. \nThese are based on redundant and diverse software components.\nformal methods\nMethods of software development where the software is modeled using formal math-\nematical constructs such as predicates and sets. Formal transformation \u00ad\nconverts this \nmodel to code. Mostly used in the specification and development of critical systems.\nGantt chart\nSee bar chart.\n", "page": 764, "type": "text", "section": "Page 764"}
{"text": "764\u2002 \u2002 Glossary\nGit\nA distributed version management and system building tool where developers take \ncomplete copies of the project repository to allow concurrent working.\nGitHub\nA server that maintains a large number of Git repositories. Repositories may be \u00ad\nprivate \nor public. The repositories for many open-source projects are maintained on GitHub.\nhazard\nA condition or state in a system that has the potential to cause or contribute to  \nan accident.\nhost-target development\nA mode of software development where the software is developed on a separate \ncomputer from where it is executed. The normal approach to development for \nembedded and mobile systems.\niLearn system\nA digital learning environment to support learning in schools. Used as a case study \nin this book.\nincremental development\nAn approach to software development where the software is delivered and deployed \nin increments.\ninformation hiding\nUsing programming language constructs to conceal the representation of data struc-\ntures and to control external access to these structures.\ninspection\nSee program inspection.\ninsulin pump\nA software-controlled medical device that can deliver controlled doses of insulin to \npeople suffering from diabetes. Used as a case study in this book.\nintegrated application system\nAn application system that is created by integrating two or more configurable \n\u00ad\napplication systems or legacy systems.\ninterface\nA specification of the attributes and operations associated with a software compo-\nnent. The interface is used as the means of accessing the component\u2019s functionality.\nISO 9000/9001\nA set of standards for quality management processes that is defined by the Interna-\ntional Standards Organization (ISO). ISO 9001 is the ISO standard that is most \napplicable to software development. These may be used to certify the quality \n\u00ad\nmanagement processes in an organization.\n", "page": 765, "type": "text", "section": "Page 765"}
{"text": "\t\nGlossary\u2002 \u2002 765\niterative development\nAn approach to software development where the processes of specification, design, \nprogramming and testing are interleaved.\nJ2EE\nJava 2 Platform Enterprise Edition. A complex middleware system that supports \nthe\u00a0development of component-based web applications in Java. It includes a \n\u00ad\ncomponent model for Java components, APIs, services, etc.\nJava\nA widely used object-oriented programming language that was designed by Sun \n(now Oracle) with the aim of platform independence.\nlanguage processing system\nA system that translates one language into another. For example, a compiler is a \nlanguage-processing system that translates program source code to object code.\nlegacy system\nA socio-technical system that is useful or essential to an organization but which has \nbeen developed using obsolete technology or methods. Because legacy systems \noften perform critical business functions, they have to be maintained.\nLehman\u2019s Laws\nA set of hypotheses about the factors that influence the evolution of complex \n\u00ad\nsoftware systems.\nmaintenance\nThe process of making changes to a system after it has been put into operation.\nmean time to failure (MTTF)\nThe average time between observed system failures. Used in reliability specification.\nMentcare system\nMental Health Care Patient Management System. This is a system used to record \ninformation about consultations and treatments prescribed for people suffering \nfrom mental health problems. Used as a case study in this book.\nmiddleware\nThe infrastructure software in a distributed system. It helps manage interactions \nbetween the distributed entities in the system and the system databases. Examples \nof middleware are an object request broker and a transaction management system.\nmisuse case\nA description of a possible attack on a system that is associated with a system use\u00a0case.\nmodel-driven architecture (MDA)\nAn approach to software development based on the construction of a set of system \nmodels, which can be automatically or semi-automatically processed to generate an \nexecutable system.\n", "page": 766, "type": "text", "section": "Page 766"}
{"text": "766\u2002 \u2002 Glossary\nmodel checking\nA method of static verification where a state model of a system is exhaustively ana-\nlyzed in an attempt to discover unreachable states.\nmodel-driven development (MDD)\nAn approach to software engineering centered around system models that are expressed \nin the UML, rather than programming language code. This extends MDA to consider \nactivities other than development such as requirements engineering and testing.\nmulti-tenant databases\nDatabases where information from several different organizations is stored in the \nsame database. Used in the implementation of software as a service.\nmutual exclusion\nA mechanism to ensure that a concurrent process maintains control of memory until \nupdates or accesses have been completed.\n.NET\nA very extensive framework used to develop applications for Microsoft Windows \nsystems. Includes a component model that defines standards for components in \nWindows systems and associated middleware to support component execution.\nobject class\nAn object class defines the attributes and operations of objects. Objects are created \nat run-time by instantiating the class definition. The object class name can be used \nas a type name in some object-oriented languages.\nobject model\nA model of a software system that is structured and organized as a set of object \nclasses and the relationships between these classes. Various different perspectives \non the model may exist such as a state perspective and a sequence perspective.\nobject-oriented (OO) development\nAn approach to software development where the fundamental abstractions in the \nsystem are independent objects. The same type of abstraction is used during \n\u00ad\nspecification, design and development.\nobject constraint language (OCL)\nA language that is part of the UML, used to define predicates that apply to object \nclasses and interactions in a UML model. The use of the OCL to specify compo-\nnents is a fundamental part of model-driven development.\nObject Management Group (OMG)\nA group of companies formed to develop standards for object-oriented develop-\nment. Examples of standards promoted by the OMG are CORBA, UML and MDA.\nopen source\nAn approach to software development where the source code for a system is made public \nand external users are encouraged to participate in the development of the system.\n", "page": 767, "type": "text", "section": "Page 767"}
{"text": "\t\nGlossary\u2002 \u2002 767\noperational profile\nA set of artificial system inputs that reflect the pattern of inputs that are processed \nin an operational system. Used in reliability testing.\npair programming\nA development situation where programmers work in pairs, rather than individually, \nto develop code. A fundamental part of extreme programming.\npeer-to-peer system\nA distributed system where there is no distinction between clients and servers. \nComputers in the system can act as both clients and servers. Peer-to-peer applications \ninclude file sharing, instant messaging and cooperation support systems.\nPeople Capability Maturity Model (P-CMM)\nA process maturity model that reflects how effective an organization is at managing \nthe skills, training and experience of the people in that organization.\nplan-driven process\nA software process where all of the process activities are planned before the soft-\nware is developed.\nplanning game\nAn approach to project planning based on estimating the time required to imple-\nment user stories. Used in some agile methods.\npredictor metric\nA software metric that is used as a basis for making predictions about the character-\nistics of a software system, such as its reliability or maintainability.\nprobability of failure on demand (POFOD)\nA reliability metric that is based on the likelihood of a software system failing \nwhen a demand for its services is made.\nprocess improvement\nChanging a software development process with the aim of making that process \nmore efficient or improving the quality of its outputs. For example, if your aim is \nto\u00a0reduce the number of defects in the delivered software, you might improve a \n\u00ad\nprocess by adding new validation activities.\nprocess model\nAn abstract representation of a process. Process models may be developed from \nvarious perspectives and can show the activities involved in a process, the artifacts \nused in the process, constraints that apply to the process, and the roles of the people \nenacting the process.\nprocess maturity model\nA model of the extent to which a process includes good practice and reflective and \nmeasurement capabilities that are geared to process improvement.\n", "page": 768, "type": "text", "section": "Page 768"}
{"text": "768\u2002 \u2002 Glossary\nprogram evolution dynamics\nThe study of the ways in which an evolving software system changes. It is claimed \nthat Lehman\u2019s Laws govern the dynamics of program evolution.\nprogram generator\nA program that generates another program from a high-level, abstract specification. \nThe generator embeds knowledge that is reused in each generation activity.\nprogram inspection\nA review where a group of inspectors examine a program, line by line, with the aim \nof detecting program errors. A checklist of common programming errors often \ndrives inspections.\nPython\nA programming language with dynamic types, which is particularly well-suited to \nthe development of web-based systems.\nquality management (QM)\nThe set of processes concerned with defining how software quality can be achieved \nand how the organization developing the software knows that the software has met \nthe required level of quality.\nquality plan\nA plan that defines the quality processes and procedures that should be used. This \ninvolves selecting and instantiating standards for products and processes and defin-\ning the system quality attributes that are most important.\nrapid application development (RAD)\nAn approach to software development aimed at rapid delivery of the software. It \noften involves the use of database programming and development support tools \nsuch as screen and report generators.\nrate of occurrence of failure (ROCOF)\nA reliability metric that is based on the number of observed failures of a system in a \ngiven time period.\nRational Unified Process (RUP)\nA generic software process model that presents software development as a four-\nphase iterative activity, where the phases are inception, elaboration, construction \nand transition. Inception establishes a business case for the system, elaboration \ndefines the architecture, construction implements the system, and transition deploys \nthe system in the customer\u2019s environment.\nreal-time system\nA system that has to recognize and process external events in \u2019real-time\u2019. The \n\u00ad\ncorrectness of the system does not just depend on what it does but also on how quickly \nit does it. Real-time systems are usually organized as a set of concurrent processes.\n", "page": 769, "type": "text", "section": "Page 769"}
{"text": "\t\nGlossary\u2002 \u2002 769\nreductionism\nAn engineering approach that relies on breaking down a problem to sub-problems, \nsolving these sub-problems independently then integrating these solutions to create \nthe solution to the larger problem.\nreengineering\nThe modification of a software system to make it easier to understand and change. \nReengineering often involves software and data restructuring and organization, \n\u00ad\nprogram simplification and redocumentation.\nreengineering, business process\nChanging a business process to meet a new organizational objective such as \nreduced cost and faster execution.\nrefactoring\nModifying a program to improve its structure and readability without changing its \nfunctionality.\nreference architecture\nA generic, idealized architecture that includes all the features that systems might \nincorporate. It is a way of informing designers about the general structure of that \nclass of system rather than a basis for creating a specific system architecture.\nrelease\nA version of a software system that is made available to system customers.\nreliability\nThe ability of a system to deliver services as specified. Reliability can be specified \n\u00ad\nquantitatively as a probability of failure on demand or as the rate of \u00ad\noccurrence \nof\u00a0failure.\nreliability growth modeling\nThe development of a model of how the reliability of a system changes (improves) \nas it is tested and program defects are removed.\nrequirement, functional\nA statement of some function or feature that should be implemented in a system.\nrequirement, non-functional\nA statement of a constraint or expected behavior that applies to a system. This \n\u00ad\nconstraint may refer to the emergent properties of the software that is being \n\u00ad\ndeveloped or to the development process.\nrequirements management\nThe process of managing changes to requirements to ensure that the changes made \nare properly analyzed and tracked through the system.\nresilience\nA judgement of how well a system can maintain the continuity of its critical services \nin the presence of disruptive events, such as equipment failure and cyberattacks.\n", "page": 770, "type": "text", "section": "Page 770"}
{"text": "770\u2002 \u2002 Glossary\nREST\nREST (Representational State Transfer) is a style of development based around \nsimple client/server interaction which uses the HTTP protocol for communications. \nREST is based around the idea of an identifiable resource, which has a URI. All \ninteraction with resources is based on HTTP POST, GET, PUT and DELETE. \nWidely used for implementing low overhead web services (RESTful services).\nrevision control systems\nSee version control systems.\nrisk\nAn undesirable outcome that poses a threat to the achievement of some objective. A \nprocess risk threatens the schedule or cost of a process; a product risk is a risk that \nmay mean that some of the system requirements may not be achieved. A safety risk \nis a measure of the probability that a hazard will lead to an accident.\nrisk management\nThe process of identifying risks, assessing their severity, planning measures to \nput in place if the risks arise and monitoring the software and the software process \nfor risks.\nRuby\nA programming language with dynamic types that is particularly well-suited to web \napplication programming.\nSaaS\nSee software as a service.\nsafety\nThe ability of a system to operate without behavior that may injure or kill people or \ndamage the system\u2019s environment.\nsafety case\nA body of evidence and structured argument from that evidence that a system is \nsafe and/or secure. Many critical systems must have associated safety cases that \nare assessed and approved by external regulators before the system is certified \nfor use.\nSAP\nA German company that has developed a well-known and widely-used ERP \n\u00ad\nsystem. It also refers to the name given to the ERP system itself.\nscenario\nA description of one typical way in which a system is used or a user carries out \nsome activity.\nscenario testing\nAn approach to software testing where test cases are derived from a scenario of \n\u00ad\nsystem use.\n", "page": 771, "type": "text", "section": "Page 771"}
{"text": "\t\nGlossary\u2002 \u2002 771\nScrum\nAn agile method of development, which is based on sprints \u2013 short development, \ncycles. Scrum may be used as a basis for agile project management alongside other \nagile methods such as XP.\nsecurity\nThe ability of a system to protect itself against accidental or deliberate intrusion. \nSecurity includes confidentiality, integrity and availability.\nSEI\nSoftware Engineering Institute. A software engineering research and technology \ntransfer center, founded with the aim of improving the standard of software \n\u00ad\nengineering in US companies.\nsequence diagram\nA diagram that shows the sequence of interactions required to complete some \n\u00ad\noperation. In the UML, sequence diagrams may be associated with use cases.\nserver\nA program that provides a service to other (client) programs.\nservice\nSee web service.\nsocio-technical system\nA system, including hardware and software components, that has defined \u00ad\noperational \nprocesses followed by human operators and which operates within an organization. \nIt is therefore influenced by organizational policies, procedures and structures.\nsoftware analytics\nAutomated analysis of static and dynamic data about software systems to discover \nrelationships between these data. These relationships may provide insights about \npossible ways to improve the quality of the software.\nsoftware architecture\nA model of the fundamental structure and organization of a software system.\nsoftware as a service (SaaS)\nSoftware applications that are accessed remotely through a web browser rather than \ninstalled on local computers. Increasingly used to deliver application services to \nend-users.\nsoftware development life cycle\nOften used as another name for the software process. Originally coined to refer to \nthe waterfall model of the software process.\nsoftware metric\nAn attribute of a software system or process that can be expressed numerically and \nmeasured. Process metrics are attributes of the process such as the time taken to \ncomplete a task; product metrics are attributes of the software itself such as size \nor\u00a0complexity.\n", "page": 772, "type": "text", "section": "Page 772"}
{"text": "772\u2002 \u2002 Glossary\nsoftware process\nThe activities and processes that are involved in developing and evolving a soft-\nware system.\nsoftware product line\nSee application family.\nspiral model\nA model of a development process where the process is represented as a spiral, \nwith each round of the spiral incorporating the different stages in the process. As \nyou move from one round of the spiral to another, you repeat all of the stages of \nthe\u00a0process.\nstate diagram\nA UML diagram type that shows the states of a system and the events that trigger a \ntransition from one state to another.\nstatic analysis\nTool-based analysis of a program\u2019s source code to discover errors and anomalies. \nAnomalies, such as successive assignments to a variable with no intermediate use \nmay be indicators of programming errors.\nstructured method\nA method of software design that defines the system models that should be devel-\noped, the rules and guidelines that should apply to these models and a process to be \nfollowed in developing the design.\nStructured Query Language (SQL)\nA standard language used for relational database programming.\nSubversion\nA widely-used, open source version control and system building tool that is avail-\nable on a range of platforms.\nSwiss cheese model\nA model of system defenses against operator failure or cyberattack that takes vul-\nnerabilities in these defenses into account.\nsystem\nA system is a purposeful collection of interrelated components, of different kinds, \nwhich work together to deliver a set of services to the system owner and users.\nsystem building\nThe process of compiling the components or units that make up a system and link-\ning these with other components to create an executable program. System building \nis normally automated so that recompilation is minimized. This automation may be \nbuilt in to the language processing system (as in Java) or may involve software \ntools to support system building.\nsystems engineering\nA process that is concerned with specifying a system, integrating its components \nand testing that the system meets its requirements. System engineering is concerned \n", "page": 773, "type": "text", "section": "Page 773"}
{"text": "\t\nGlossary\u2002 \u2002 773\nwith the whole socio-technical system\u2014software, hardware and operational  \nprocesses\u2014not just the system software.\nsystem of systems\nA system that is created by integrating two or more existing systems.\nsystem testing\nThe testing of a completed system before it is delivered to customers.\ntest coverage\nThe effectiveness of system tests in testing the code of an entire system. Some \ncompanies have standards for test coverage e.g. the system tests shall ensure that all \nprogram statements are executed at least once.\ntest-driven development\nAn approach to software development where executable tests are written before \nthe\u00a0program code. The set of tests are run automatically after every change to \nthe\u00a0program.\nTOGAF\nAn architectural framework, supported by the Object Management Group, that \nis\u00a0intended to support the development of enterprise architectures for systems \nof\u00a0\u00ad\nsystems.\ntransaction\nA unit of interaction with a computer system. Transactions are independent and \natomic (they are not broken down into smaller units) and are a fundamental unit of \nrecovery, consistency and concurrency.\ntransaction processing system\nA system that ensures that transactions are processed in such a way so that they do \nnot interfere with each other and so that individual transaction failure does not \naffect other transactions or the system\u2019s data.\nUnified Modeling Language (UML)\nA graphical language used in object-oriented development that includes several \ntypes of system model that provide different views of a system. The UML has \nbecome a de facto standard for object-oriented modeling.\nunit testing\nThe testing of individual program units by the software developer or development team.\nuse case\nA specification of one type of interaction with a system.\nuse-case diagram\nA UML diagram type that is used to identify use-cases and graphically depict the \nusers involved. It must be supplemented with additional information to completely \ndescribe use-cases.\n", "page": 774, "type": "text", "section": "Page 774"}
{"text": "774\u2002 \u2002 Glossary\nuser interface design\nThe process of designing the way in which system users can access system \n\u00ad\nfunctionality, and the way that information produced by the system is displayed.\nuser story\nA natural language description of a situation that explains how a system or systems \nmight be used and the interactions with the systems that might take place.\nvalidation\nThe process of checking that a system meets the needs and expectations of the customer.\nverification\nThe process of checking that a system meets its specification.\nversion control\nThe process of managing changes to a software system and its components so \nthat it is possible to know which changes have been implemented in each version \nof the component/system, and also to recover/recreate previous versions of the \ncomponent/system.\nversion control (VC) systems\nSoftware tools that have been developed to support the processes of version \u00ad\ncontrol. \nThese may be based on either centralized or distributed repositories.\nwaterfall model\nA software process model that involves discrete development stages: specification, \ndesign, implementation, testing and maintenance. In principle, one stage must be \ncomplete before progress to the next stage is possible. In practice, there is signifi-\ncant iteration between stages.\nweb service\nAn independent software component that can be accessed through the Internet \nusing standard protocols. It is completely self-contained without external \ndependencies. XML-based standards such as SOAP (Standard Object Access \nProtocol), for web service information exchange, and WSDL (Web Service \n\u00ad\nDefinition Language), for the definition of web service interfaces, have been \ndeveloped. However, the REST approach may also be used for web service \nimplementation.\nwhite-box testing\nAn approach to program testing where the tests are based on knowledge of the \nstructure of the program and its components. Access to source code is essential for \nwhite-box testing.\nwicked problem\nA problem that cannot be completely specified or understood because of the \n\u00ad\ncomplexity of the interactions between the elements that contribute to the problem.\n", "page": 775, "type": "text", "section": "Page 775"}
{"text": "\t\nGlossary\u2002 \u2002 775\nwilderness weather system\nA system to collect data about the weather conditions in remote areas. Used as a \ncase study in this book.\nworkflow\nA detailed definition of a business process that is intended to accomplish a  \ncertain task. The workflow is usually expressed graphically and shows the  \nindividual process activities and the information that is produced and consumed \nby each activity.\nWSDL\nAn XML-based notation for defining the interface of web services.\nXML\nExtended Markup Language. XML is a text markup language that supports the \ninterchange of structured data. Each data field is delimited by tags that give \n\u00ad\ninformation about that field. XML is now very widely used and has become the \nbasis of protocols for web services.\nXP\nSee Extreme Programming.\nZ\nA model-based, formal specification language developed at the University of \nOxford in England.\n", "page": 776, "type": "text", "section": "Page 776"}
{"text": "This page intentionally left blank\n", "page": 777, "type": "text", "section": "Page 777"}
{"text": "A\nabstraction level (reuse), 213\nacceptability, 22, 347\u201348\nacceptance testing, 77, 82, 249, 250\u201351, 252\naccidents (mishaps), 343\u201344, 347\nACM/IEEE-CS Joint Task Force on Software \n\u00ad\nEngineering Ethics and Professional Practices, \n29\u201330\nacquisition (procurement), 473, 553\u201354, 566\u201370\nactivities (software engineering activities), 20, 23, \n44, 47\u201348, 54\u201361, 142, 298, 643\u201344. See also \ndevelopment; evolution; specification; \n\u00ad\nvalidation\nactivity charts (planning), 678\u201380\nactivity diagrams (UML), 33\u201334, 47, 50, 56, 141, \n143\u201344, 163\nactuators, 218, 502, 613\u201314, 615\nAda programming language, 359\nadaptors, 469, 482\u201383\nadditive composition, 481\nAdobe Creative Suite, 27\naggregation, 153\nagile methods, 45, 66, 72\u2013100\narchitectural design and, 168, 175\nchange and, 76, 78, 91, 131\u201332\nchange management and, 97, 748, 750\nconfiguration management (CM) for, 732, 742\u201343, \n748, 750\ncritical systems and, 75, 92, 96\ncontinuous integration, 742\u201343\ncustom systems and, 90, 732\ncustomer involvement and, 76, 77, 91, 748, 750\ndevelopment team, 85, 90, 92\u201393\ndocumentation and, 73\u201375, 86, 89\u201390, 92\u201393, 175\nevolution and, 90, 261\nextreme programming (XP), 73, 77\u201384\nincremental development and, 45, 50, 73\u201374, 77\nlarge system complexity and, 93\u201396\nmanifesto, 75\u201376, 77\u201378\nmodel-driven architecture (MDA) and, 162\norganizations and, 91, 97\npair programming, 78, 83\u201384\n\u2018people, not process\u2019 and, 76, 77, 91\nplan-driven approach v., 45, 74\u201375, 91\u201393, 98\nprinciples of, 76\nprocess improvement and, 66\nproject management and, 84\u201388, 643, 647, 661\nproject planning, 91\u201393, 670, 680\u201383, 696\nquality management (QM), 714\u201316, 727\nrefactoring, 51, 80\u201381\nrisk management and, 647\nscaling, 88\u201397, 98\nsimplicity of, 76, 78, 91\nScrum approach and, 73, 78, 85\u201388, 96\ntest first development, 59, 78, 81\u201383\nuser stories for, 681\u201382\nuser testing, 251\nagile modeling, 50\nAgile Scaling Model (ASM), 95\nair traffic management (ATC) systems, 554\u201355, 569\nSubject Index\n", "page": 778, "type": "text", "section": "Page 778"}
{"text": "778\u2002 \u2002 Subject Index\ndistributed component systems, 501, 506\u201309, 517\ndistributed systems, 175\u201384, 192, 501\u201312, 517\nembedded software and, 620\u201326, 634\nenvironmental control, 620, 623\u201325\nlayered architecture, 177\u201379\nmaster-slave architecture, 501\u201302\nmodel-view-controller (MVC), 176\u201377\nmulti-tier client-server architecture, 501, 505\u201306\nobserve and react, 620, 621\u201323\npeer-to-peer (p2p) architecture, 501, 509\u201312, 517\npipe and filter architecture, 182\u201384\nprocess pipeline, 620, 625\u201326\nreal-time software, 620\u201326, 634\nrepository architecture, 179\u201380\nsecurity and, 172, 388, 392\u201395\nsystems of systems (SoS), 602\u2013606, 607\ntrading systems, 605\u201306\ntwo-tier client-server architecture, 501, 503\u201305\nArchitecture Development Method (ADM), 601\narchitectures (software architectures)\napplication, 184\u201391, 192\narchitecture in the large, 169\narchitecture in the small, 169\ndefined, 192\ndistributed, 171, 182\nfault-tolerant, 318\u201325\nindustrial practice v., 170\npipe and filter compiler, 190\u201391\nreference, 191\nself-monitoring, 320\u201322\nAriane 5 explosion, 296, 479, 480\narithmetic error, 351\nas low as reasonably practical (ALARP) risks, 347\naspect-oriented software development, 442\nAssertion checking, 360\nassessment\nhazards for safety requirements, 345, 346\u2013349\nsecurity risk, 381\u201382\nassets, 377, 378, 413, 414\u2013415\nassurance\nsafety processes, 353\u201356\nsecurity testing and, 402\u201304\nATMs (automated teller machines), 186\u201387, 315\u201316\nattacks, 377, 378\u201379, 389, 413, 414\u201315, 494\u201395\nattributes of software, 20, 22, 40\nauthentication, 413, 414, 416\nautomated management, 423\u201324\nautomated testing, 78, 81\u201383, 233\u201334, 242, 252\nautomatic static analysis, 359\u201360\nAirbus 340 flight control system, 321\u201322, 340\nAJAX programming, 28, 445, 512\nalgorithm error, 351\u201352\nalgorithmic cost modeling, 683, 684\u201386\nalpha testing, 249\nanalysis systems, 25\nAndroid, 219\nApache web server, 219\naperiodic stimuli, 613\nApollo 13 mission resilience, 409, 411, 416\napplication assessment (legacy systems), 269\napplication data, 262\napplication frameworks, 442, 443\u201346, 460\napplication layer, 292\napplication-level protection, 393\u2013394\napplication programming interfaces (APIs), 39, \n595\u201396\napplication security, 374\u2013375\napplication software, 262\napplication system, 53, 438, 453\u201360\nCOTS systems, 453\nERP systems, 454\u2013457\nreuse, 438, 442, 453\u201360\narchitectural description languages \n(ADLs), 175\narchitectural design, 57, 149, 167\u2013195, 570\u201371, 595, \n599\u2013606\nblock diagrams for, 170\nBooch\u2019s architecture catalog and, 170\ndecisions, 171\u201373, 192\n4+1 view model, 173\u201374\nlevels of abstraction, 169\nmaintenance and, 172\u201373, 178\nmodel-driven architecture (MDA), 159\u201362\nnon-functional requirements for, 169, 172\u201373\nobject-oriented systems, 201\u201302\npatterns, 175\u201384, 192\nrefactoring and, 168\nsecurity and, 172, 388, 392\u2013395\nstructural models for, 149\nsystem development and, 570\u201371\nsystems of systems (SoS), 595, 599\u2013606\nviews, 173\u201375, 192\narchitectural frameworks, 600\u201302\narchitectural patterns (styles), 172\nclient-server architecture, 180\u201382, 501, \n503\u201306, 517\ncontainer systems, 603\u201305\ndata-feed systems, 602\u201303\n", "page": 779, "type": "text", "section": "Page 779"}
{"text": "\t\nSubject Index\u2002 \u2002 779\nmodeling workflow, 67\u201368\nopen-source software and, 221\npolicies (rules), 262\nprocess maturity models, 67\u201368\nprocess reengineering, 276\u201378\nprocesses, 262\nrapid software development and, 73\u201374\nrequirements changes, 131\nresilience and, 426\u201327\nsecurity and, 380\u2013382\nservices, 534, 541\u201347, 548\nsocial change and, 24\nsoftware systems, 24, 27, 45, 68, 267\u201368\nsystem construction by composition, 543\u201344\nsystem values, 267\u201368, 280\nweb-based applications, 27\nworkflow, 542, 543, 544\u201346\nC\nC and C++ programming languages, 197, 327, 330, \n359, 360, 401, 444, 619\ncallbacks, 445\ncatalog interface design, 537\u2013538\ncentralized systems, version management of,  \n735, 737\ncertification (software dependability), 294, 299, 302, \n354, 355\u201356, 474, 477, 709\u201310\nchange, 61\u201365. See also process change\nagile methods and, 73\u201374, 78, 90\u201391, 97\nbusiness and social needs, 24\ncost effectiveness of, 133\ncultural (social), 24, 97\ncustomers and, 748\u201349\neffects on software engineering, 27\u201328\nextreme programming (XP) and, 78\nimplementation, 134, 259\u201360, 280\nincremental delivery, 62, 64\u201365\nplan-driven process and, 73\nproblem analysis and, 133\nprototyping, 62\u201363\nrapid software development for, 73\u201374\nrequirements management for, 111, 130\u201334\nreuse, 27\u201328\nrework for, 61, 73\navailability\nsecurity and, 374, 375, 413\nsystem availability, 172, 288, 309\u201312\navailability metric (AVAIL), 313\u2013314\navoidance\nerror discovery and, 300\u201301\nfault, 308\nhazard, 342, 351\nstrategies (risk management), 650\nvulnerability, 378\nB\nB method, 49, 300, 301, 357\nbanking system, Internet, 505\nbaselines, 734, 735, 736\nbatch processing systems, 25\nbehavioral models, 154\u201359, 163\nbeta testing, 58, 60, 249\u2013250\nbidding (projects), 669, 671\u201372\nbindings, 527\u201328\nblackboard model, 180\nblock diagrams, 170, 199\nBoehm\u2019s spiral process model, 48\nBooch\u2019s software architecture catalog, 170\nboundaries (system models), 141\u201342, 163, \n199, 556\u201357\nbranching, 734, 739\nbroadcast (listener) models, 202\nBrownfield systems, 94, 256\nBSD (Berkeley Standard Distribution) \nlicense, 220\nBugzilla, 216\nbuild system, 741\u201342\nburglar alarm system, 614, 622, 629\u201331\nbusiness-critical system, 287\nbusiness process layer, 292\nBusiness Process Modeling Notation (BPMN), \n544\u201346\nbusiness process models, 544\u201346\nbusinesses\nactivity diagrams (UML) for processes, 143\u201344\ninterrelated 4 R\u2019s approach, 426\u201327\nlegacy system evolution, 261\u201368\nmaintenance costs, 274\u201376, 279\n", "page": 780, "type": "text", "section": "Page 780"}
{"text": "780\u2002 \u2002 Subject Index\nchange anticipation, 61\nchange control board (CCB), 748\u201349\nchange management, 97, 731, 745\u201350, 753\nagile methods and, 97, 748, 750\nchange requests, 747\u201350\ndependability and, 299\ndevelopment environments and, 217\nrequirements and, 111, 130\u201334\nchange proposals, 90, 258\u201359\nchange request form (CRF), 747\u201348\nchange tolerance, 61\ncharacteristic error checking, 359\u201360\ncheck array bounds, 330\nchecking requirements, 317\nchecklists, 403, 713\u2013714\nchecksums, 745\ncircular buffer, 616\u201317\nclass diagrams, 141, 149\u201351, 163\nclass identification, 202\u201304\nCleanroom process, 230, 332\nclient-server architecture, 180\u201382, 428, 501, \n503\u201306, 517\nclient-server systems, 499\u2013501, 517\nclouds, 25, 27, 532\nCOBOL code, 263\nCOCOMO II modeling, 276, 476, 686\u201396\napplication composition model, 688\u201389\ncost drivers, 692\nearly design model, 689\u201390\npost-architectural level, 692\u201394\nproject duration and staffing, 694\u201396\nreuse model, 690\u201392\ncode coverage, 243\u201344, 252\ncode inspection and review, 83, 715\nCode of Ethics and Professional Practice (software \nengineering), 29\u201330\ncodelines, 734, 735, 736, 739\ncollaborative systems, 588\ncollective ownership, 78\nCOM platform, 466\nCommon Intermediate Language (CIL), \n470\u201371\ncommunication\ndata management layer and, 292\nmessage exchange, 496\u201397, 526\u201329, 537\nstakeholder, 169\ncommunication latency, 218\ncompartmentalization, 399\ncompetence, 28\ncompleteness, 107, 129\ncomplexity, 18, 93\u201396, 274\u201375, 278, 584\u201387, 606\ngovernance, 586\u201387, 588\u201390, 606\nlarge systems, 93\u201396\nmaintenance prediction and, 274\u201375\nmanagement, 585, 586\u201387, 587\u201390, 606\nreductionism for systems, 590\u201393, 606\nrefactoring, 278\nscaling agile methods and, 93\u201396\nsystem releases, 751\u201352\nsystems of systems (SoS), 584\u201387, 606\ntechnical, 585, 586\u201387, 590\ncompliance to software regulation, 294\u201395\ncomponent-based software engineering (CBSE), 442, \n464\u2013489\ncomponent certification, 474, 477\ncomponent management, 474, 476\ndevelopment for reuse, 473, 474\u201377\ndevelopment with reuse, 473, 477\u201380\nmiddleware and, 465, 472\u201373\nservice-oriented software v., 466\u201367\ncomponent level (reuse), 214\ncomponents (software), 52\u201353, 188, 190, 295, 424, \n465\u201373, 487, 526\u201329\narchitectural design and, 172\ncommunications, 172, 218, 526\u201329\ncomposition, 480\u201386, 487\ndefined, 465, 467, 487\ndeployment, 471, 472\u201373\ndesign and selection of, 57, 424, 452\nexternal, 330\u201331\nimplementation, 465, 466, 471\u201372, 475, 487\nincompatibility, 481\u201383\ninterfaces, 208\u2013209, 237\u2013239, 465, 468\u201369\nmeasurement (analysis), 722\u201323\nmodels, 470\u201373, 487\nopen-source, 220\u201321\nplatforms for, 466\u201367\nremote procedure calls (RPCs) \nfor, 470, 471\nreuse, 52\u201353, 212, 214, 221, 438\u2013439, \n452, 468, 487\nservices v., 521\nservice-oriented architectures (SOA), 526\u201329\ntesting, 59, 232, 237\u2013239\ntimeouts, 330\u201331\ntiming errors, 238\u2013239\ncomponents (system), procurement (acquisition) of, \n567\u201368\n", "page": 781, "type": "text", "section": "Page 781"}
{"text": "\t\nSubject Index\u2002 \u2002 781\ncomposition\nof components, 480\u201386, 487\nservice systems and, 541\u201347\ncomputation independent model (CIM), 159\u201361\ncomputer science, software engineering v., 20, 23\nconcept reuse, 439\nconceptual system design, 553, 563\u201366, 577, 594\nconceptual views, 174, 192\nconcurrency, 491\nconfidence levels (verification), 228\u201329\nconfidentiality, 28, 374, 413\nconfigurable application systems, 442, 454\u2013457\nconfiguration management (CM), 213, \n215\u2013216, 222, 730\u201355. See also change  \nmanagement\nactivities of, 215\u201316\nagile methods and, 732, 742\u201343, 748, 750\narchitectural patterns, 175\nchange management, 731, 745\u201350, 753\ndesign implementation and, 213, 215\u201316, 222\nproblem tracking, 216\nrelease management, 216, 731, 750\u201353, 754\nsystem building, 731, 740\u201345, 753\nsystem integration and, 215\u201316\nterminology for, 734\nversion management (VM), 215, 216, \n731, 735\u201340, 753\nconfiguration, software product lines, 451\u201352\nConOps document standard, 563\nconsistency, 107, 129, 652\nconstants, naming of, 331\nconstruction phase (RUP), 46\nconsumer/producer processes (circular buffer), \n616\u201317\ncontainer systems, 603\u201305\ncontext models, 141\u201344, 163, 199\u2013200\ncontingency plans, 650\u201351\ncontinuous integration, 78, 742\u201343\ncontrol\napplication frameworks and, 445\ncybersecurity, 413\u2013414\ninversion of, 445\nsafety-critical systems, 341\u201342\nsecurity, 377, 378\u201379\nvisibility of information, 325\u201326\ncontrol metrics, 717\ncontrolled systems, 319\ncooperative interaction patterns, 175\ncoordination services, 534, 548\nCORBA (Common Object Request Broker  \nArchitecture), 466, 493, 507\ncost/dependability curve, 290\u201391\ncost drivers, 692\ncosts. See also estimation techniques\nchange analysis and, 133\nCOCOMO II modeling, 686\u201396\ndependability and, 290\u201391\ndistributed systems, 495\neffort, 669\nfault removal, 308\u201309\nformal verification, 357\nmaintenance/development, 274\u201376, 279, 280\noverhead, 669\nproject planning, 669\nsafety engineering and, 357, 362\u201363\nsoftware engineering, 20\nsoftware reuse and, 214, 439\nsystem failure, 286\nCOTS (commercial-off-the-shelf) systems, 453. See \nalso application system reuse\ncritical systems, 287. See also safety-critical \nsystems\nagile methods and, 75\ndependable processes for, 297\ndocumentation for, 92, 96\nfailure of, 287, 303\nformal methods for dependability of, 302\nredundancy and, 295\ntypes of, 287, 424\nverification and validation costs, 290\ncultural change, 97\ncustomer involvement (agile methods), 76, 77, 91, \n748, 750\ncustomer testing, 59\ncustomization, 471, 732\u201333\ncybersecurity, 376, 412\u2013416, 432\nD\ndamage limitation, 342, 351\ndata clumping, 279\ndata collection systems, 25, 202\ndata flow diagrams (DFD), 154\u201355\ndata reengineering, 277\ndatabase design, 57\n", "page": 782, "type": "text", "section": "Page 782"}
{"text": "782\u2002 \u2002 Subject Index\ndata-driven modeling, 154\u201355\ndata-feed systems, 602\u201303\ndata-mining system, 508\ndeadlines (real-time systems), 627\ndebugging, 58, 216, 232, 244\ndecentralized systems, 510\u201311, 517\nDecorator pattern, 212\ndefect testing, 58, 227\u201328, 232\ndebugging v., 58, 232\nperformance, 248\nrelease testing, 248\ndeltas (storage management), 740\ndenial-of-service attacks, 289\u201390, 389, 423\nDepartment of Defense Architecture Framework \n(DODAF), 601\ndependability (software dependability), 26, 285\u2013305\nactivities for, 298\nassurance, 353\u201356, 402\u201304\ncosts of, 290\u201391\ncritical systems, 287, 290, 297, 302\ndesign considerations, 287, 295\nformal methods and, 299\u2013302, 303\nfunctionality v., 286\nproperties, 288\u201391\nredundancy and diversity, 295\u201397, 303\nreliability and, 288\u201390, 297, 303\nsafety and, 288, 299\nsecurity and, 22, 26, 288, 376\u201379\nsociotechnical systems, 291\u201395, 303\nspecification and, 300\u201302\nsystem, 268, 286\u201391, 303\ndependable programming guidelines, 325\u201331\ndeployment\ncomponent model, 471, 472\u201373\ndesign for, 399\u2013400\nservice implementation and, 540\u201341\nsystem development and, 570\nsystems of systems (SoS), 595, 597\u201399\nUML diagrams, 149, 218\ndeployment-time configuration, 451\u201352\nderivation history, 750\ndesign (software design), 44, 56\u201358, 69, 78, \n196\u2013225. See also architectural design; \nsystem design\nactivity model (diagram), 56\nconfiguration management, 212, 215\u201316, 222\nfor deployment, 399\u2013400\nengineering programming and, 23, 44, 58\nguidelines, 396\u2013401, 405\nimplementation and, 47, 56\u201358, 69, 196\u2013225\ninterface, 57, 208\u201309, 222\nlife-cycle phase, 47\nmodels, 123\u2013208, 222\nobject-oriented, 198\u2013209, 222\nopen-source development, 219\u201321, 222\npatterns, 209\u201312\nfor recovery, 400\u201301\nfor resilience, 424\u201332\nreuse and, 57, 212, 213\u201315\nservice interfaces, 533, 536\u201340\ntest-case, 234\u201337\nUML documentation, 197, 198\u2013209\nuser interface, 62\ndesign-time configuration, 451\u201352\n\u2018desk\u2019 testing, 428\ndevelopment\nagile techniques, 77\u201384, 88, 732\ncustomization stages, 732\u201333\nconfiguration management (CM) \nphases, 732\u201333\nengineering design and programming, 23, 44\nevolution and, 23, 60\u201361, 256\u201357, 280\nimplementation stage, 56\u201358\nmaintenance costs, 274\u201376, 279\nmaintenance v., 60\u201361\npair programming, 83\u201384\nplan-driven process, 59\u201360, 570\nprofessional software, 19\u201328\nrefactoring, 51, 62, 80\u201381\nregulators for safety, 353\nreuse and, 52\u201354\nreuse for (CBSE process), 473, 474\u201377\nreuse with (CBSE process), 473, 477\u201380\nsafety cases, 362\u201363\nsafety-critical systems, 352\u201353\nservices and, 541\u201347, 548\nsociotechnical systems, 291\u2013295, 303\nsoftware dependability and, 290\nspiral model for, 256\u201357\nsystem processes, 554, 570\u201374\ntesting, 58\u201360, 81\u201383, 230\u201332\ndevelopment team, 85, 90, 92\u201393\ndevelopment testing, 231\u201342, 252\ndevelopment view, 174, 192\ndigital art, 566\ndigital learning environment (iLearn), 38\u201339\napplication programming interface (API), 39\narchitecture (diagram), 38\u201339\n", "page": 783, "type": "text", "section": "Page 783"}
{"text": "\t\nSubject Index\u2002 \u2002 783\nelicitation of requirements, 118\u201320\nlayered architecture of, 179\nphoto sharing story, 118\u201320\nservices, 38\u201339\nVirtual Learning Environment (VLE), 38\ndirected systems, 588\ndistributed architectures, 171\ndistributed component systems, 501, 506\u201309, 517\ndistributed development (Scrum), 88\ndistributed systems (software engineering), 490\u2013519\nadvantages of, 491, 517\narchitectural design of, 171\u201372, 182\narchitectural patterns for, 175\u201384, 501\u201312, 517\nattack defense, 494\u201395\nclient-server architecture, 180\u201382, 501,  \n503\u201306, 517\nclient-server systems, 499\u2013501, 517\nCORBA (Common Object Request Broker  \nArchitecture), 493, 507\ndesign issues, 492\u201396, 517\ninteraction models, 496\u201397\nmiddleware, 498\u201399, 517\nopenness, 491, 492, 493\nquality of service (QoS), 492, 495\nscalability, 491, 492, 494, 514, 515\u201316\nsoftware as service (SaS), 512\u201316, 517\nversion management of, 735, 737\u201339\ndiversity (software diversity)\napplication types, 24\u201325\ndependability and, 295\u201397, 303\nfault-tolerant architecture, 318, 322, 323\u201325\nredundancy and, 318, 398\nreliability and, 318, 322, 323\u201325, 336\nrisk reduction and, 398\nsoftware engineering, 24\u201327\ndocumentation, 19, 40, 49, 56, 73\u201375, 92\u201393, 273\nagile methods and, 73\u201375, 86, 89\u201390, 92\u201393, 126\narchitectural design and, 175\ncertification and, 294, 299, 302\nchange implementation, 260\nmaintenance and, 92, 273\norganization of, 127\u201328\nreader requirements, 103\u201304\nsafety cases, 361\u201367\nsoftware requirements (SRS), 126\u201329, 135\nstandards, 129, 706\nsystem release, 741, 752\u201353\nTDD and, 244\nuser requirements, 73, 126\u201327\ndomain-specific application systems, 438, 441, 446\nduplicate code, 279\ndynamic metrics, 720\u201321\ndynamic model, 199, 205, 206, 222\ndynamic perspective (RUP), 46\ndynamic systems development method (DSDM), 73\nE\ne-commerce systems, 188\u201389\nearly design model, 689\u201390\nEclipse environment, 32, 216, 218, 219\nefficiency, 22, 422\u201323\neffort cost, 669\neffort distribution, 272\negoless programming, 83\nelaboration phase (RUP), 46\nelicit stakeholder requirements, 450\nelicitation/analysis for requirements, 55, \n112\u201320, 134\nembedded software systems, 25, 32, 634. See also \nreal-time systems\narchitectural patterns and, 620\u201326, 634\ndesign of, 217\u201318, 613\u201320\nhost-target development and, 217\nreal-time software engineering, 218, 610\u201337\nsimulators for, 217\nstimulus/response model, 613\u201314, 634\ntiming analysis, 626\u201331\nuser testing, 251\nemergency call log, 422\u201323\nemergency repair process, 260\u201361\nemergent properties, 558, 559\u201361, 577\nencryption, 413\nenduring requirements, 132\nengineering, see software engineering; systems \n\u00ad\nengineering\nEnterprise Java Beans (EJB), 446, 466, 470, 507\nEnterprise systems, 422, 552. See also \nERP systems\nentertainment systems, 25\nenvironment assessment (legacy systems), 269\nenvironmental adaptation, 271\nenvironmental control pattern, 620, 623\u201325\nenvironmental specialization (software product \nlines), 450\n", "page": 784, "type": "text", "section": "Page 784"}
{"text": "784\u2002 \u2002 Subject Index\nenvironments. See also IDEs\narchitectural patterns and, 176\nbusiness requirements changes, 131\ncontext model for, 142\u201343\nmarketing, 229\nsoftware interaction and system failure, 293\u201394\nwork, 663\nequipment layer, 292\nequity trading system, 394\u201395\nequivalence partitioning, 235\u2013236\nERP (Enterprise Resource Planning) systems, 21, \n184, 438, 442, 454\u2013457\napplication frameworks, 446\narchitecture of, 455\u2013456\nconfigurable application reuse, 454\u2013457\ncustomer adaptation of, 438\nsystem procurement and adaptation, 569\nerror-prone constructs, 308, 328\u201329\nerror tolerance, 289\nerrors\nalgorithmic, 351\u201352\narithmetic, 351\navoidance and discovery, 300\u201301\nchecking, 359\u201361\ncorrection, 48\nfailure and fault v., 308\nhuman, 307, 351\u201352, 418\u201321\nsafety engineering and, 359\u201361\nspecification, 324\u201325\nstatic analysis for, 359\u201361\nsystem, 307\u201309\ntiming, 238\u201339\nestimation techniques (project planning), 682\u201386, \n696\nalgorithmic cost modeling, 683, 684\u201386\nCOCOMO II model, 686\u201396\nexperience-based techniques, 683\u201384\nsoftware productivity and, 686\nethical/professional responsibility, 28\u201331, 40\nethnography technique, 116\u201318\nevaluation, prototype phase of, 63\nevent-driven modeling, 156\u201358\nevolution (software evolution), 69, 255\u201382\nactivity model (diagram), 61\nagile technique and, 261\nbusiness costs and, 274\u201376, 279\ndevelopment v., 60, 256\u201357, 280\nengineer activities for, 20, 23, 44\nlegacy systems, 261\u201370, 280\nlife cycle, 257\u201358, 266\nmaintenance, 22, 60\u201361, 270\u201379, 280\nprocesses, 258\u201361\nprogram evolution dynamics, 271\nrefactoring and, 61, 78, 273,  \n278\u201379, 280\nrequirements changes, 131\nservicing v., 257\u201358\nsoftware lifetime and, 256\u201357\nsoftware reengineering, 273, 276\u201378\nspiral model of, 256\u201357\nsystem evolution v., 575\u201376\nexceptions\nCBSE for reuse, 476\u201377\nhandlers for, 327\u201328\nExecutable UML (xUML), 162\nexecution time (real-time systems), 627\nexperience-based estimation, 683\u201384\nexperience-based testing, 403\nexplicitly defined process, 297\nexposure, 377, 378, 379\nexternal components, 330\u201331\nexternal requirements, 109\nextreme programming (XP), 73, 77\u201384\nacceptance testing and, 77, 82\nagile methods and, 73, 77\u201379\ncontinuous integration and, 78, 96\npair programming, 78, 83\u201384\nrelease cycle in, 77\nstory cards, 79\u201380\ntest first development, 78, 81\u201383, 242\nuser requirements, 73, 99\nF\nfa\u00e7ade pattern, 211\nfailure propagation, 560\u201361\nfailures, see also system failure\ndefinition v. judgment, 310\nerror and fault v., 308\nhardware, 287\nhuman errors and, 307, 351\u201352, 418\u201321\ninformation loss, 286\noperational, 287\nsafe state solutions to, 351\u201352\nserver safety v. privacy, 36\n", "page": 785, "type": "text", "section": "Page 785"}
{"text": "\t\nSubject Index\u2002 \u2002 785\nsoftware, 18, 22, 26, 287, 308, 310, \n340\u201341, 351\u201352\nsystem failure costs, 286\nfault (system faults), 307\u201309\navoidance, 308\ncosts of removal, 308\u201309\ndetection and correction, 308\nerror and failure v., 308\nrepair, 271\ntolerance, 308\nfault-tolerant architectures, 318\u201325, 491\ndistributed systems, 491\ndiversity of software, 323\u201325\nN-version programming, 322\u201323\nprotection systems, 319\u201320\nself-monitoring, 320\u201322\nfault tree analysis, 349\u201351\nfeasibility studies, 54, 104\nFederal Aviation Administration, 92, 290\nfederated systems, 589\nfilm library, client-server architecture for, 182\nfirewalls, 413\u201314\nflight control software, 296, 321\u201322, 340, 341\nfloating-point numbers, 329\nformal (mathematical) models, 139\nformal methods (software development), 49, 139, \n299\u2013302, 303, 356\u201358\nB method, 49\ndependability and, 299\u2013302, 303\nerror avoidance and discovery from, 300\u201301\nmathematical approach, 300, 301\nmodel-checking, 300, 358\u201359\nsafety engineering, 356\u201359\nsecurity testing, 404\nsystem models and, 139, 299\u2013301\nverification and, 300, 356\u201358\nformal specifications, 109, 300\u201302\nFortify tool, 404\n4 Rs model, 410\u201311, 414\u201315, 432\n4+1 view model, 173\u201374\nframeworks, 443\u201346, 600\u201302, 708\u201310\nFree Software Foundation, 219\nfrequency (real-time systems), 627\nfuel delivery system, 618\u201319\nfunctional requirements, 105\u201307, 134, 312, 317\u201318, \n335, 344\nfunctional specialization (software product lines), \n450\nfunctionality, 286\nG\n\u2018Gang of Four,\u2019 209\u201312\nGeneral Public License (GPL), 220\ngeneralization of structural models, 152\u201353, 205\ngenerator-based reuse, 443\nGit system, 216, 737, 740\nGitHub, 476, 478\n\u2018glue code,\u2019 466, 481, 487\nGNU build system, 216\nGNU General Public License (GPL), 220\nGoogle Apps, 27\nGoogle Code, 478\ngovernance complexity, SoS, 586\u201387,  \n588\u201390, 606\ngraphical models, 140\ngraphical notations, 121\ngroups, see teamwork\ngrowth modeling, 334\nguideline-based testing, 234\nguidelines\nhiring, 661\ndependable programming, 325\u201331\nsystem security, 401\u201302, 405\nH\nhandlers, exceptions, 327\u201328\nhardware (system), 262\nhardware failure, 287, 560\u201361\nhazard-driven approaches, 342, 349\u201351, 368\nhazards, 342, 343, 345\u201351\nanalysis of, 345, 349\u201351\nassessment, 345, 346\u201349\navoidance, 342, 351\ndamage limitation, 342, 351\ndetection and removal, 342, 351\nfault tree analysis, 349\u201351\nidentification of, 345\u201346\nprobability, 343\nsafety-critical system development, 342, 368\nseverity, 343\nheterogeneity, software development and, 24\nhierarchical composition, 480\nhierarchical groups, 661\u201362\n", "page": 786, "type": "text", "section": "Page 786"}
{"text": "786\u2002 \u2002 Subject Index\nhigh-availability systems, 172, 218\nhonesty (people management), 653\nhost-target development, 213, 216\u201318, 222\nHTML5 programming, 28, 445\nhttp and https protocols, 530\u201331\nhuman error, 307, 351\u201352, 418\u201321\nhuman needs hierarchy, 653\u201354\nI\nIDEs (Interactive Development Environments),  \n53, 217\nECLIPSE environment and, 218\ngeneral-purpose, 218\nhost-target development and, 216, 217\u201318, 222\nrepository architecture for, 180\niLearn, 38\u201339, 567. See also digital learning  \nenvironment\nimplementation (system implementation), 28, 47, \n56\u201358, 69, 196\u2013225\ncomponents, 465, 466, 471\u201372, 475, 487\nconfiguration management, 212, 215\u201316\ndesign and, 56\u201358, 69, 196\u2013225\ninterface specification, 208\u201309\nlife-cycle phase, 47\nhost-target development, 213, 216\u201318\nopen-source development, 219\u201321\nreuse and, 212, 213\u2013215\nservice deployment and, 540\u201341\nservice-oriented software for, 28\nUML documentation, 197, 198\u2013209\nunit testing and, 47\nin-car information system, 522\u201324\ninception phase (RUP), 46\ninclusion (people management), 653, 657\nincompatibility, component composition \nand, \u00ad\n481\u201383\nincremental delivery, 46, 51, 62, 64\u201365, \n76, 91\nincremental development, 46, 50\u201351, 73\u201374, 77\nincremental testing, 59, 242\nincremental integration, 242\nincremental planning, 78\ninformation loss, 286\ninformation systems, 32, 185\u201386, 187\u201389, 522\u201324\ninfrastructure security, 374, 375\u201376\ninheritance, 152, 204, 209, 233, 722. See also \n\u00ad\ngeneralization\ninput/output mapping, 310\u201311\ninputs, validity checks of, 326\u201327, 399\ninspections, 229\u201330, 239, 710\u2013714. See \nalso reviews\ninsulin pump control system, 32\u201334\nactivity model of, 33, 155\ndata-flow model (DMD) for, 155\ndependability properties for, 288\u201389\nfailure in, 316\u201317\nfunctional reliability requirements, 317\nhardware components (diagram), 33\nhazards in, 346\nnatural language specification for, 122\nnon-functional reliability requirements, 316\u201317\npermanent software failure, 316\nrisk classification for, 347\u201349\nrisk reduction for, 351\u201352\nsafety-critical system control, 341\nsafety requirements for, 346\u2013349, 351\u201352\nsafe state, 351\nsequence diagrams for, 155\nsoftware control of, 341\nsoftware failure solutions, 351\u201352\nstructured language specification for, 123\u201324\ntabular specification for, 124\ntransient software failure, 316\nissue-tracking systems, 746\u201347\nintegrated application systems, 442, 454\nintegration\nconfiguration and, 46, 52\u201354\ncontinuous, 78, 742\u201343\nsystem development and, 570\nsystem testing and, 48\nsystems of systems (SoS), 595, 597\u201399\nintegrity, security and, 374, 413\nintellectual property rights, 28\ninteracting workflows, 545\u201346\ninteraction models, 144\u201349, 163, 199\u2013200, \n496\u201397\ndistributed systems, 496\u201397\nobject-oriented design and, 199\u2013200\nsequence diagrams, 146\u201349, 163\nuse cases, 144\u201346, 163, 200\ninteractive applications, 25\ninterface design, 57, 208\u201309\ninterface misunderstanding, 238\ninterface misuse, 238\n", "page": 787, "type": "text", "section": "Page 787"}
{"text": "\t\nSubject Index\u2002 \u2002 787\ninterfaces\napplication programming interfaces (APIs), \n\u00ad\n595\u201396\ncomponent, 208\u201309, 222, 237\u2013239, 465, 468\u201369, \n470\u201371\nmodel specifications, 470\u201371\nservice design for, 533, 536\u201340, 596\nspecification, 208\u201309\nsystems of systems (SoS), 595\u201397\nunified user interface (UI), 596\u201397\nInternet banking system, 505\ninterviewing techniques, 115\u201316\nintolerable risks, 347\ninversion of control, 445\nISO 9001 standards framework, 708\u201310, 734\niteration planning, 680\niterative development/delivery, 65, 77, 98. See also \nagile methods\nIterator pattern, 212\nJ\nJava programming language, 82, 152, 161, 197, 208, \n218, 219, 327, 330, 359, 444\nembedded systems development and, 619\u201320\ninterfaces, 208\nprogram testing, 243\nreal-time systems development and, 619\nJava Virtual Machine, 217\nJavaMail library, 214\nJenkins, 743\nJSON (Javascript Object Notation), 531\nJ2EE platform, 161, 466\nJUnit, 59, 82, 217, 233, 243\nL\nlanguage processing systems, 186, 189\u201391, 192\nlarge-scale systems, 556\nlayered architecture, 177\u201379, 187\u201388, 192\nlayers\nlegacy systems, 262\u201364\nsociotechnical systems, 292\u201393, 557\u201358\nlegacy systems, 261\u201370, 280, 540, 576\nassessments, 269\nbusiness value of, 267\u201368, 280\ncomponent integration, 567\nelements of, 262\u201363\nmanagement, 266\u201370\nmaintenance of, 263\u201364, 280\nreengineering and, 276, 278\nrefactoring and, 279\nreplacement problems, 264\u201365\nsystem evolution of, 546\nwrapping, 278, 442, 540\nLehman\u2019s laws, 271\nLesser General Public License, GNU, 220\nlicensing, 220\u201321, 356\nlife cycles\napplication system reuse problems, \n459\u201360\nproject planning stages, 668\nsoftware evolution, 257\u201358, 266\nsoftware model process, 45, 47\u201349\nlifetimes, system evolution and, 575\u201376\nLinux, 219, 398\nlogging user actions, 398\nlogical view, 174, 192\nlong methods, 279\nM\nmaintainability, 22, 104, 169, 173, 198, 230, 266, \n274, 275, 289, 494\nmaintenance (software maintenance), \n22, 270\nagile methods and, 90, 92\narchitectural design and, 172\u201373, 178\ncosts, 274\u201376, 279\ndevelopment v., 60\u201361\ndocumentation and, 92, 273\nlegacy systems, 263\u201364\nlife-cycle phase, 48\nprediction, 274\u201376\nreengineering, 273, 276\u201378\nrefactoring, 278\u201379\nsoftware evolution and, 22, 263\u201364, \n270\u201379\ntypes of, 271, 280\n", "page": 788, "type": "text", "section": "Page 788"}
{"text": "788\u2002 \u2002 Subject Index\nmanagement (software management), 26, 66\u201368, \n\u00ad\n84\u201388. See also configuration management; \nprocess improvement; project management; \nproject planning; quality management; \n\u00ad\nversion management\nagile methods, 84\u201388\nautomated, 423\u201324\nCBSE process, 474, 476\ncoping with change, 63\nplanning, 132\u201333\nprocess maturity method and, 66\u201368\nreal-time system processes, 632\u201334\nrequirements change, 130\u201334\nresilience and, 421\u201324, 432\nmanagement complexity (SoS), 585, 586\u201387, \n\u00ad\n587\u201390, 606\nmanifesto, agile, 75\u201376, 77\u201378\nmarketing environment, 229\nMars exploration, 358\nmathematical specifications, 121. See also formal \nmethods\nmean time to failures (MTTF), 313, 314\nmeasurement. See also metrics\nambiguity in, 724\u201325\ncomponent analysis, 722\u201323\ncontroller/predictor metrics, 717\nquality management (QM) and, 716\u201326, 727\nsoftware analysis, 725\u201326, 727\nsoftware quality, 716\u201326, 727\nmental health care system (Mentcare), 34\u201336\nadministrative reporting, 36\naggregation association in, 153\nauthentication procedures, 416\nclass diagrams for, 149\u2013151\nclient-server architecture of, 428\ncontext model of, 141\u201342\ndesign risk assessment, 390\u201391\ndose checking test case, 80\nfail-secure approach, 397\nfunctional requirements in, 106\u201307\ngeneralization hierarchy and, 153\ngoals of, 35\nindividual care management, 35\nkey features of, 35\u201336\nlayered architecture pattern in, 179, 188\nnon-functional requirements in, \n109\u201310\norganization (diagram) of, 34\npasswords, 400\u2013101, 416\npatient monitoring, 35\nprivacy and, 36\nprocess model of involuntary detention, 143\nrelease testing, 246, 247\nrequirements-based testing and, 246\nresilience of, 289, 428\u201330\nsafety and, 36\nsafety-critical system control, 342\nscenario in, 124\u201325\nscenario testing and, 247\nsecurity of, 289, 377, 400\u201301\nsequence diagrams for, 146\u201349\nsociotechnical system for, 562\u201363\nstory cards and, 79\u201380\nsuccess criteria for, 562\u201363\nsystem boundaries, 141\u201342\ntask cards and, 79\u201380\nuse case modeling and, 145\u201346\nuse cases for, 125\u201326\nmerging, 734, 739\nmessage exchange, 496\u201397, 526\u201329, 537\nmessage passing interfaces, 238\nmetrics\nAVAIL, 243\u2013314\ncontrol/predictor, 717\ndynamic, 720\u201321\nevents, 717\nnon-functional requirements, 110\nprocess measurement, 717\u201320\nprobability of failure on demand (POFOD), \n313\u201314, 316\nproduct, 720\u201322, 727\nrate of occurrence of failures (ROCOF), 313\u2013314\nreliability, 313\u201314, 316\nresource utilization, 717\nsoftware measurement and, 716\u201326, 727\nstatic, 720\u201321\ntime, 717\nMicrosoft Office 360, 27\nmicrowave oven scenario, 156\u201358\nmiddleware, 217, 218, 446, 465, 472\u201373, \n498\u201399\nmilestones (projects), 673, 674, 677\u201378, 696\nminimization strategies (risk management), 650\u201351\nmission-critical system, 287\nMODAF, 600, 601\nmodel checking, 300, 358\u201359, 368\nmodel-driven architecture (MDA), 159\u201362\nmodel-driven engineering (MDE), 158\u201359, 442\n", "page": 789, "type": "text", "section": "Page 789"}
{"text": "\t\nSubject Index\u2002 \u2002 789\nmodeling systems, 25, 138\u201366\nmodels, 45\u201354, 138\u201366. See also spiral models; \nUML (Unified modeling Language)\nactivity diagrams (UML) for, 33\u201334, 141, \n143\u201344, 163\nactivity stages, 47\u201348, 142\nagile approach and, 50, 162\nalgorithmic cost modeling, 683, 684\u201386\napplication architecture, 185\nbehavioral, 154\u201359, 163\nclass diagrams for, 149\u201350\nCOCOMO II, 276, 476, 686\u201396\ncomponent, 470\u201373, 487\ncontext, 141\u201344, 163, 199\u2013200\ndata-driven, 154\u201355\ndynamic, 199, 205, 206, 222\nevent-driven, 156\u201357\nformal (mathematical), 139, 300\ngeneralization, 152\u201353, 205\nincremental development, 46, 49\u201351\nintegration and configuration, 46, 52\u201354\ninteraction, 144\u201349, 163, 199\u2013200, 496\u201397\nISO 9000 standards framework, \n708\u201310, 734\nobject-oriented design, 199\u2013200, 204\u201308\nopen-source licensing, 220\u201321\nprocesses, 45\u201354, 68\nproject estimation, 682\u201396, 696\nquality management (QM) and, 709\u201310, 719\nreal-time system design, 617\u201319\nreliability growth, 334\nRUP (Rational Unified Process), 46\u201347\nreuse-based development, 52\u201354\nsequence, 144, 146\u201349, 155, 163, 205, 206\u201307\nspiral, 63, 256\u201357\nstate machine, 205, 207\u201308, 222, 617\u201318, 634\nstate-based, 156\u2013158, 163\nstatic, 205, 222\nstimulus/response, 613\u201314, 634\nstructural, 149\u201354, 163, 199, 205\nsubsystem, 205\u201306\n\u2018Swiss cheese,\u2019 420\u201321\nof testing process, 230\u201331\nUML (Unified Modeling Language), 33\u201334, 139, \n140\u201341, 144\u201349, 713\nuse case, 125\u201326, 141, 144\u201346, 163, 200\u201301\nmodel-view-controller (MVC) pattern, 176\u201377, \n179, 444\nmonitoring projects, 651\u201352, 673\nmotivation (people management), 653\u201356\nmulti-tenancy, 514, 515, 516\nmulti-tier client-server architecture, 501, 505\u201306\nMySQL, 219, 445\nN\nN-version programming, 322\u201323\nnamespaces, 528\u201329\nnatural language requirements, 121\u201322\nnested technical and sociotechnical \nsystems, 416\u201317\n.NET framework, 161, 443, 446, 466, 470\u201371, \n478, 507\nnon-deterministic properties, 561\u201362\nnon-functional requirements, 105, 107\u201311, 134, 169, \n172\u201373, 312, 314\u201318, 547\nO\nobject and function reuse, 438\nobject classes, 149\u201350, 202\u201304, 470\nobject constraint language (OCL), 208, 484\u201385\nobject level (reuse), 214\nObject Management Group (OMG), 159\nobject-oriented metrics, 721\u201322\nobject-oriented systems\narchitectural design and, 201\u201302\nclass diagrams for, 149\u201350\nclass identification, 202\u201304\ndesign, 198\u2013209, 222\nframeworks in, 444\ninterface specification, 208\u201309\nsystem (design) models, 204\u201308\nUnified Modeling Language (UML) and, 140, \n198\u2013209\nuse case model, 200\u201301\nObjectory method, 125\nobserve and react pattern, 620, 621\u201323\nObserver pattern, 210\u201311\non-site customer, 78\nopenness, distributed software, 491, 492, 493\nopen-source development, 219\u201321, 222, 738\u201339\n", "page": 790, "type": "text", "section": "Page 790"}
{"text": "790\u2002 \u2002 Subject Index\noperating system layer, 292\noperating systems (real-time), 631\u201334, 635\noperation and maintenance, 48\noperation incompatibility, 481\noperation incompleteness, 481\noperation stage (systems), 554\noperational failure, 287\noperational processes, 421\u201324, 432\noperational profiles, 334\u201335\noperational security, 374, 376\noperator reliability, 287, 560\u201361\nOracle, 21, 219\norganizational design patterns, 175\norganizational layers, 292, 557\norganizational requirements, 108\u201309\norganizational systems, 589\norganizations and security, 380\u201382\noverhead costs, 669\noverspecification of reliability, 315\nP\npacking robot control system, 168\npair programming, 78, 83\u201384, 715\nparameter definition, 452\nparameter incompatibility, 481\nparameter interfaces, 237\npartition testing, 234\u201336\npartner company software systems, 49\npassword checker, 392\npasswords, 400\u201301, 413, 414, 416\npath testing, 237\npatient records system (PRS), 148\u201349\npatterns, 175\u201384, 209\u201312, 442, 444\napplication frameworks and, 444\narchitectural, 175\u201384\ndesign, 209\u201312, 442\npayment models, 547\npeer-to-peer (p2p) architecture, 501, 509\u201312, 517\npenetration testing, 403\u201304\nPeople Capability Maturity Model \n(P-CMM), 656\npeople management, 652\u201356, 664\nperformance, 172, 248\nperiodic stimuli, 613\nphoto library, 483\u201385\nphysical view, 174, 192\npipe and filter architecture, 182\u201384, 191\nplan-driven process, 45, 47, 50, 73, 570\nagile methods v., 45, 74\u201375, 91\u201393, 98\nchanging environment and, 73\nincremental development and, 50\nmodel processes, 47, 50\nproject planning and, 672\u201375, 696\nscheduling and, 675\u201376\nsystem development and, 570\ntesting (validation) phases, 59\u201360\nwaterfall model, 47\u201348\nplanning game, 681\u201382\nplanning. See also project planning\nincremental, 78\nrequirements management, 132\u201333\nrisk, 650\u201351\nScrum product backlog, 85, 86, 98\ntest, 231\nplatform-independent model (PIM), 159\u201361\nplatform-level protection, 393\u2013394\nplatform services, 472\nplatform specialization (software product \nlines), 450\nplatform-specific models (PSM), 160\u201361\nplug-in architecture, 218\npointers, 308, 329\npost-architectural level, 692\u201394\npower supply failure, 627\u201328\npractice perspective (RUP), 46\nprediction, maintenance and, 274\u201376\npredictor metrics, 717\nPRISM model checker, 358\nprobability of failure on demand (POFOD), \n313\u201314, 316\nprobability values, hazards, 343\nproblem tracking, 216\nprocedural interfaces, 238\nprocess (software processes), 23, 26, 43\u201371\nactivities, 40, 54\u201361\nagile approach, 45, 66\nanalysis, 67, 112\u201320, 626\u201331\nassurance, 353\u201356\ndesign and implementation, 56\u201358\nemergency repair, 260\u201361\nengineer activities for, 20, 23, 44, 54\u201361\nevolution, 44, 60\u201361, 258\u201361\nimprovement of, 65\u201368\nlife cycles, 45, 47\u201349\n", "page": 791, "type": "text", "section": "Page 791"}
{"text": "\t\nSubject Index\u2002 \u2002 791\nmanagement, 421\u201324, 432\nmaturity approach, 66\u201368\nmeasurement, 66\u201367, 717\u201320\nmodels, 45\u201354, 68\noperational, 421\u201324, 432\nplan-driven, 47\u201348\nprofessional, 19\u201328, 45\nprototype development, 62\u201363\nquality (process-based), 65\u201368, 705\nquality metrics, 717\u201320\nreview phases, 711\u201313\nRUP (Rational Unified Process), 46\u201347\nspecification, 44, 54\u201356\nstandards, 45, 707, 708\nvalidation, 44, 58\u201360\nprocess change, 45, 69\nagile manifesto and, 75\u201376\nCBSE, 473\u2013480\ncoping with, 61\u201365\nevolution, 258\u201361\nimplementation, 259\u201360\nfor safety assurance, 353\u201356\nsoftware processes, 61\u201365, 67\nurgent changes, 260\nprocess improvement, 69\nagile approach, 66\nbusiness values, 267\u201368\nlegacy system management, 266\u201370\nprocess maturity approach, 66\u201368\nreengineering, 276\u201378\nrefactoring, 278\u201379\nsoftware quality and, 65\u201368\nsoftware evolution and, 266\u201370, 276\u201379\nprocess management, real-time systems, 632\u201334\nprocess maturity approach, 66\u201368\nprocess pipeline pattern, 620, 625\u201326\nprocess requirements, 317\nprocess specialization (software product lines), 450\nprocess view, 174, 192\nprocurement (acquisition), 473, 553\u201354, 566\u201370, 577\nproducer/consumer pattern, 202\nproducer/consumer processes (circular buffer), \n616\u201317\nproduct\ninstance development, 450\nquality metrics, 720\u201322, 727\nrequirements, 108\u201309\nsoftware types, 20\u201321, 24\u201326\nstandards, 706, 707\nproduct architects (Scrum), 96\nproduct backlog (Scrum), 85, 86\nproduct owner (Scrum), 85\nproduct risk management, 644\u201375, 646\nprofessional software development, see \ndevelopment\nprogram evolution dynamics, 271\nprogram generators, 442\nprogram inspections, 229\u201330, 239, 713\u201314. See  \nalso reviews\nprogram libraries, 442\nprogram modularization, 277\nprogram structure improvement, 277\nprogrammer/tester pairs, 231\u201332\nprogramming. See also extreme programming\ndependable guidelines, 325\u201331\negoless, 83\nengineering design and, 23, 44, 58\nreal-time systems, 619\u201320\nsecure system guidelines, 401\u201302\ntechniques/activities, 26, 54\u201356\nproject management, 84\u201388, 641\u201366\nactivities, 643\u201344\nagile methods and, 84\u201388, 643, 647, 661\ndifferences from engineering, 642\u201343, 664\nmotivation and, 653\u201356\nrelationships with people, 652\u201356, 664\nrisk management, 644\u201352, 664\nteamwork, 656\u201364\nproject planning, 92\u201393, 667\u201399\nagile methods and, 670, 680\u201383, 696\nbidding, 669, 671\u201372\nCOCOMO II cost modeling, 686\u201396\ndevelopment team effectiveness, 92\u201393\nduration and staffing, 694\u201396\nestimation techniques, 682\u201386, 696\nlife cycle stages of, 668\nmilestones, 673, 674, 677\u201378, 696\nplan-driven development and, \n672\u201375, 696\nprocess, 673\u201375\nproject costs, 669, 696\nscaling agile methods for, 91\u201393\nscheduling and, 675\u201380, 696\nsoftware pricing for, 670\u201372, 696\nsupplements, 673\nuser stories for, 681\u201382\nproject risk management, 644\u201345\nPromela, 358\n", "page": 792, "type": "text", "section": "Page 792"}
{"text": "792\u2002 \u2002 Subject Index\nprotection, 383\nassets, 380, 384, 390\ncybersecurity, 376, 414\nfault-tolerant architecture, 319\u201320\nlayered architecture design, 393\u201395\nsystems, 319\u201320, 414\nprototyping (system prototyping), 62\u201363, 69, 117, 130\nPython, 190, 197, 198, 327, 444\nQ\nquality management (QM), 299, 700\u201329\nagile development and, 714\u201316, 727\nconfiguration management (CM) and, 733\ndocumentation standards, 706\nreviews and inspections, 710\u201314, 727\nsoftware development and, 701\u201302\nsoftware measurement/metrics and, 716\u201326, 727\nsoftware quality and, 703\u201305, 727\nsoftware standards and, 706\u201310, 727\nquality of service (QoS), 492, 495\nquantitative reliability specifications, 314\u201315\nR\nrange checks, 326\nrapid software development, 73\u201374\nrate of occurrence of failure (ROCOF), 313\u201314\nreactive systems, 612\nrealism checks, 129\nreal-time systems, 205, 218, 610\u201337\narchitectural patterns for, 620\u201326, 634\ndesign, 205, 613\u201320\nembedded systems, 218, 610\u2013637\nmodeling, 617\u201319, 634\noperating systems, 631\u201334, 635\nprocess management, 632\u201334\nprogramming, 619\u201320\nresponsiveness, 611\u201312\nsoftware engineering for, 610\u201337\nstimulus/response model, 613\u201314, 634\ntiming analysis, 626\u201331, 635\nreasonableness checks, 327\nrecognition, 410, 411, 414\u201315, 432\nrecord-level protection, 393\u2013394\nrecovery\ndatabase integrity checking and, 430\ndesign for, 400\u201301\nrequirements, 317\nresilience and, 411, 414\u201315, 430, 432\nreductionism of complex systems, 590\u201393, 606\nredundancy\ndependability and, 295\u201397, 303\ndiversity and, 318, 398\nrequirements, 317\nreengineering (software reengineering), 273, \n276\u201378, 280\nrefactoring, 51, 62, 78, 80\u201381, 83\u201384, 168, 278\u201379\nagile methods, 51, 80\u201381\narchitectural design and, 168\nextreme programming (XP) methods, 78\nmaintenance and, 278\u201379\npair programming, 83\u201384\nsoftware evolution, 273, 278\u201379, 280\nreference architectures, 191\nrefinement-based development, 300\nregression testing, 244\nregulation and compliance (software), 294\u201395, 353\nregulators, 294\u201395, 361, 362, 368\nreinstatement, 411, 414\u201315, 432\nrelease alignment (Scrum), 96\nrelease management, 216, 731, 750\u201353, 754\nrelease testing, 245\u201348\nreliability, 309\navailability and, 309\u201312\ndependability and, 288\u201390, 297, 303, 336\ndiversity and, 318, 322, 323\u201325, 336\nemergent properties, 560\u201361\nfailure and, 18, 307\u201312, 560\u201361\nfault-tolerant architectures, 318\u201325\nfunctional requirements, 312, 317\u201318, 335\ngrowth modeling, 334\nhuman error, 307\nmeasurement of, 331\u201335\nmetrics, 312\u201313, 332, 335\nnon-functional requirements, 312, 314\u201318\noperational profiles, 334\u201335\noverspecification of, 315\nprogramming guidelines, 325\u201331\nrequirements, 312\u201318, 335\nsafety and, 340\u201341\nsecurity and, 379\n", "page": 793, "type": "text", "section": "Page 793"}
{"text": "\t\nSubject Index\u2002 \u2002 793\nsociotechnical systems, 560\u201361\nsoftware, 18, 560\u201361\nspecification, 314\u201318\nsystem error, 307\u201309\nsystem fault, 307\u201309\nsystems, 18, 19, 22, 288\u201390, 297, 303, 306\u201338\nstatistical testing, 332\u201333, 336\nremote method invocations (RMIs), 497\nremote procedure calls (RPCs), 470, 471, 497\nrepairability, 289\nrepeatable process, 297, 303\nreplicated servers, 318\nrepository architectural pattern, 179\u201380, 190\nrepository cloning, 737\u201338\nrepresentation checks, 327\nrequirements, 102, 134\nagile methods and, 55, 131\u201332\nanalysis and definition (life-cycle phase), 47\navailability, 218\nbusiness changes, 131, 135\nclassification and organization of, 113\ncomponents, 218\ndiscovery and understanding, 113, 115\u201318\ndocuments (software specification), 103\u201304, 111, \n114, 126\u201329, 135\nelicitation and analysis of, 55, 112\u201320, 134\nenduring, 132\nengineering understanding of, 20, 23, 26\nevolution, 131\nfunctional, 105\u201307, 134, 317\u201318\nhazard-based, 345\nidentification, 132\nmanagement, 132\u2013134, 135\nnon-functional, 105, 107\u201311, 134, 314\u201317\nnotations for writing, 121\nprioritization and negotiation of, 113\nrefinement, 53\nreliability and, 312\u201318\nreviews, 130\nrisk-based, 344, 345\nsafety, 344\u201352\nspecification, 55, 69, 102\u201303, 106\u201307, 110,  \n120\u201329, 135, 314\u201318, 344, 345\nspiral model for, 572\nsoftware process, 44, 54\u201356\nstorage, 132\nsystem, 102\u201303, 120\u201321\ntesting (requirements-based), 245\u201346\ntraceability, 132, 133\nuser, 102\u201303\nvalidation, 55, 129\u201330, 135\nvolatile, 132\nrequirements engineering (RE), 69, 101\u201337\nchange management, 111, 130\u201334\ndocuments for, 103\u201305\nelicitation/analysis process, 112\u201320, 134\nethnography technique for, 116\u201318\nfeasibility studies, 54, 104\ninterviewing techniques for, 115\u201316\nprocesses, 111\u201312, 134\nsoftware process activities, 44, 54\u201356\nsoftware documentation (SRS) for, 126\u201327\nspiral model for, 112\nsystem development and, 570\nrequirements partitioning, 571\nresearch management systems, 448\u201349\nresilience (system resilience), 288, 409, 408\u201334\nactivities, 410\u201311\nautomated management, 423\u201324\ncybersecurity, 412\u201316, 432\ndependability and, 288, 289\ndesign for, 424\u201332\nefficiency and, 422\u201323\nengineering, 408\u201334\n4 Rs model, 410\u201311, 414\u201315, 432\nhuman error and, 418\u201321\ninterrelated business approach, 426\u201327\nmanagement, 421\u201324, 432\noperational processes, 421\u201324, 432\nsecurity and, 288, 379\nsociotechnical systems, 416\u201324\nsurvivable systems analysis, 425\u201326\nsystem failure and, 410\u201312\ntesting, 427\u2013428\nresistance, 410\u201311, 414\u201315, 432\nresource management systems, \n188\u201389, 192\nresource sharing, 491\nrespect (people management), 652\nrestart capabilities, 329\u2013330\nrestaurant interactions, 496\u201397\nRESTful services, 524, 529\u201333, 544\nreuse (software reuse), 26, 28, 46, 52\u201354, 169, \n\u00ad\n209\u201310, 212, 213\u201315, 222, 437\u201363, \n474\u2013480\napplication frameworks, 442, 443\u201346, 460\napplication system, 438, 453\u201360\napproaches supporting, 441\u201343\n", "page": 794, "type": "text", "section": "Page 794"}
{"text": "794\u2002 \u2002 Subject Index\nreuse (continued)\narchitectural design and, 169\nCBSE for, 473, 474\u201377\nCBSE with, 473, 477\u201380\ncomponent selection and design, 57\ncomponents, 52\u201353, 212, 214, 221, 438\u2013439, 452, \n468, 487\ncosts of, 214, 439\ndesign patterns, 209\u201310, 212, 442, 444\nengineering applications of, 26, 28\ngenerator-based, 443\nimplementation and, 212, 213\u201315\nintegration and configuration of, 52\u201354\nintegration problems, 459\u201360\nlandscape, 340\u2013443\nlevels of, 213\u201314\nobject and function, 438\nprocess model for, 52\u201353\nsoftware development tools, 53\nsoftware product lines, 442, 446\u201352\nsystem features and, 46\nreuse-based software engineering, 53\u201354, 438\nreuse model, 690\u201392\nreverse engineering, 277\nreverse planning, 680\nreviews, 130, 229, 239, 710\u201314\nchecklists, 713\u201314\ncode, 83, 715\nhazard register for, 355\ninspections and, 229, 710\u201314, 727\nprogram inspections, 713\u201314\nquality management (QM), 710\u201314, 727\nrequirements validation, 130\nreview process, 711\u201313\nsafety, 354, 355\nverification and validation using, 229\nrework, 49, 56, 61, 73, 75, 84, 129\nrisk\nacceptable, 347\u201348\naccidents (mishaps) and, 343\u201344, 347\nanalysis, 362, 648\u201349\nas low as reasonably practical (ALARP), 347\ndefined, 343\nredundancy and diversion for, 398\nindicators, 652\nintolerable, 347\nranking types of, 649\nreduction, 351\u201352, 398\nsecurity assessment, 381\u201382, 405\ntriangle, 347\u201348\nrisk management, 644\u201352, 664\nidentification of risk, 647\u201348\nplanning process, 650\u201351\nprocesses, 645\u201347\nproduct risks, 644\u201345\nproject risks, 644\u201345\nrisk analysis and, 648\u201349\nrisk monitoring, 651\u201352\nstrategies for, 650\u201381\nrisk-based requirements specification, 344, 345\nrobot control system, 168\nrole replication (Scrum), 96\nRuby, 190, 444\nRUP (Rational Unified Process), 46\u201347\nS\nsafety, 339\u201372, 379\narchitectural design and, 172\nassurance processes, 353\u201356\ncosts and, 357, 362\u201363\ndependability and, 288, 299\nengineering processes, 352\u201361\nethics and, 30\u201331\nformal verification, 356\u201358\nfunctional requirements, 344\nhazard-driven requirements, 345, 368\nhazards and, 342, 343, 345\u2013351\nmodel checking, 358\u201359, 368\nregulation and compliance for, 294\u201395\nregulators, 294\u201395, 361, 362\nreliability and, 340\u201341\nrequirements, 344\u201352, 362\nrisks and, 343, 343\u201344, 347\u201348, 351\u201352\nsoftware certification, 355\u201356\nstatic program analysis, 359\u201361, 368\nterminology, 343\nsafety cases, 361\u201367, 368\ndevelopment of, 362\u201363\norganization of, 361\u201362\nregulators for, 361, 362, 368\nsoftware safety arguments, 364\u201367\nstructured arguments, 363\u2013364\n", "page": 795, "type": "text", "section": "Page 795"}
{"text": "\t\nSubject Index\u2002 \u2002 795\nsafety-critical systems, 287, 340\u201344, 368\ncertification of, 294, 302, 355\u201356\ncontrol systems, 341\u201342\ndependability and, 294, 302\ndevelopment process and, 352\u201353\nerror-prone constructs and, 329\nhazard-driven techniques, 342\nprimary safety-critical software, 341\nprocess assurance and, 355\u201356\nregulation and compliance for, 294, 353\nrisk triangle for, 347\u201348\nsecondary safety-critical software, 341\u201342\nsystem failure and, 340\u201341\nsafety reviews, 355\nSAP, 21\nSarbanes Oxley accounting regulations, 51\nscalability, 491, 492, 494, 514, 515\u201316\nscale, software development and, 24\nscaling agile methods, 88\u201397, 98\nscenarios\nelicitation of requirements from, 118\u201320\ntesting, 246\u201347, 252\nuse cases, 125\u201326\nscheduling, 675\u201380, 696\nactivity charts for, 678\u201380\nproject planning and, 675\u201380, 696\nplan-driven projects, 675\u201376\npresentation (visualizing), 676\u201380\nScrum, 73, 78, 85\u201388, 96, 98\nsecure systems, 561\nsecurity, 24, 26, 373\u2013407\napplication, 374\u2013375\narchitectural design and, 172, 388, \n392\u201395\nassurance, 402\u201304\navailability, 374, 375, 379\nchecklist, 403\nconfidentiality, 374\ncontrols, 377, 378\u201379\ndependability and, 22, 26, 288, 376\u201379\ndesign for, 374, 388\u2013402, 405\nengineering, 373\u2013407\nfailure, 397\nguidelines, 396\u2013401, 404\ninfrastructure, 374, 375\u201376\nlogging user actions, 398\noperational, 374, 376\norganizations and, 380\u201382\npolicies, 396\u201397\nprogramming guidelines, 401\u201302\nprotection, 380, 384, 390, 393\u201394, 395\nregulation and compliance for, 294\u201395\nreliability and, 379\nrequirements, 382\u201388\nresilience and, 288, 379\nrisk assessment, 381\u201382, 405\nsafety and, 379\nsystem layers, 374\u201375\nterminology, 377\u2013378\ntesting, 402\u201304\nthreats, 377, 378, 404\ntrust and, 22, 24\nusability guideline, 397\u201398\nvalidation, 405\nvulnerability and, 377, 378, 391, 401\nself-monitoring architecture, 320\u201322\nSEMAT (software engineering methods and tools) \ninitiative, 24\nsemicentralized P2P architecture, 511, 512\nsensor-based data collection systems, 32\nseparation of concerns, 486\nsequence diagrams, 141, 144, 146\u201349, 155, 163, 205, \n206\u201307, 241\nsequential composition, 480\nserver overload, 512\u201313\nservice engineering, 533\u201341\ncandidate identification, 533\u201336\nimplementation and deployment, 540\u201341\ninterface design, 533, 536\u201340\nlegacy systems and, 540\nservice information exchange (SOAP), 525\u201326, \n531, 544\nservice-oriented architectures (SOAs), 513\u201314, \n520\u201350\napproach, 522, 524\ncomponents, 526\u201329\nmessage exchange, 526\u201329\nservice interface, 528\nservice protocols, 525\nsoftware as service (SaS) v., \n513\u201314, 522\nstandards, 525\u201326\nweb applications, 524\u201329\nWSDL and, 526, 527\u201329\nservice-oriented software engineering, see service \nengineering; service-oriented architectures \n(SOAs); services\nservice-oriented systems, 442, 466\u201367, 526\u201333\n", "page": 796, "type": "text", "section": "Page 796"}
{"text": "796\u2002 \u2002 Subject Index\nservice-to-service communication, see \nintegrated \u00ad\nservices\nservices, 521\nbusiness, 534, 541\u201347, 548\nclassification of, 534, 548\ncommunication and, 524\u201329\ncomponents, 521, 526\u201329\ncomposition (construction) of, 541\u201347\ncoordination, 534, 548\nincremental delivery and, 64\u201365\noperation and maintenance for, 48\nprocess models for, 544\u201346\nreusable Web components, 52, 526\u201329\nreuse of, 542\nsoftware development and, 541\u201347, 548\ntesting, 543, 546\u201347\nutility, 534, 548\nweb-based, 27\u201328, 521\nRESTful approach, 524, 529\u201333, 544\nservice information exchange (SOAP), 525\u201326, \n531, 544\nworkflow, 542, 543, 544\u201346, 548\nservicing, evolution v., 257\u201358\nshared memory interfaces, 238\nsignatures, 744\u201345\nsimple design, 78\nsimplicity (agile methods), 76, 78, 91\nsimulation systems, 25\nsimulators, 217\nsize checks, 327\nSLAM model checker, 358\nsmall releases, 78\nsocial change, business and, 24\nsocial layer, 292\nsociotechnical systems, 552, 577\ncomplexity of, 556, 558\u201359\ndefensive layers, 419\u201320\nemergent properties 544, 559\u201361, 577\nenvironment and software interaction, \n293\u201394\nfailure propagation, 560\u201361\nhuman error and, 418\u201321\nlayers of, 292\u201393, 557\nmanagement, 421\u201324, 432\nnested technical systems, 416\u201317\nnon-deterministic properties, 561\u201362\noperational processes, 421\u201324, 432\norganizational elements, 557\u201358\nregulation and compliance, 294\u201395\nresilience and, 416\u201324\nsuccess criteria, 562\u201363\nsystems engineering for, 556\u201359\nsoftware, 19, 20, 228\nattributes, 20, 22\ncustomized (bespoke), 21\nefficiency, 22\nengineering ethics, 28\u201331\nfailures, 18\ngeneric products, 20\u201321\nissues affecting, 24\nlifetime, 256\u201357\nproduct types, 20\u201321, 24\u201326\nprofessional development, 19\u201328\nregulation and compliance of, 294\u201395\nsystem boundaries and characteristics, 26\nsoftware architecture catalog, Booch\u2019s, 170\nsoftware as service (SaS), 512\u201316, 517\nconfiguration of, 514\u201315\nmulti-tenancy, 514, 515, 516\nscalability, 514, 515\u201316\nserver overload and, 512\u201313\nservice-oriented architectures (SOAs) v., \n513\u201314, 522\n\u2018software crisis\u2019, 19\nSoftware Development Life Cycle (SDLC) model, 45\nsoftware development tools, 53\nsoftware diversity, 318, 322, 323\u201325, 336\nsoftware engineering, 19\u201323, 40, 92\nactivities for software process, 20, 23, 44\ncomputer science v., 20, 23\ndiversity, 24\u201327\nengineering discipline, 21\u201322\nethical responsibility and, 28\u201331, 40\nformal verification, 356\u201358\nfundamental notions in, 26, 40\nInternet effect on, 20, 27\u201328\nlicensing for, 356\nmodel checking, 358\u201359, 368\nmodel-driven engineering (MDE), 158\u201359\nproduct development and, 20\u201321\nreuse-based, 53\u201354, 438\nsafety processes, 352\u201361\nstatic program analysis, 359\u201361, 368\nsystems engineering v., 20, 23, 40, 554\nweb-based systems, 27\u201328\nSoftware Engineering Institute (SEI), 67\n", "page": 797, "type": "text", "section": "Page 797"}
{"text": "\t\nSubject Index\u2002 \u2002 797\nsoftware measurement/metrics, 716\u201326, 727\nsoftware platform, 57\nsoftware pricing, 670\u201372, 696\nsoftware product lines, 442, 446\u201352\nsoftware quality attributes, 704\nsoftware requirements specification (SRS), \n126\u201329\nsoftware safety arguments, 364\u201367\nsource code translation, 277\nSourceForge, 476, 478\nspace shuttle (U.S.) system, 319\nspecialization, software product lines, 450\nspecifications (software specifications), 20, 54\u201356, \n208\u201309, 300\u201302\navailability, 313\nengineering definition and constraints, 23\nfunctional requirements, 106\u201307\ngraphical notations, 121\ndependability and, 300\u201302\ndesign interface, 208\u201309\nerrors, 324\u201325\nformal techniques, 300\u201302\nhazard-driven safety requirements, 345\nmanagement of, 26\nnatural language requirements, 121\u201322\nnon-functional requirements, 110\nproblem analysis and, 133\nreliability metrics, 313\u201314\nrisk-based requirements, 344, 345\nsafety requirements and, 344\u201345\nsoftware process, 44, 54\u201356\nSRS document, 126\u201329\nstructured natural language requirements, 121, \n122\u201324\nsystem failure and, 310\nsystem requirements, 102\u201303, 120\u201329, 135\nuse cases, 125\u201326\nuser requirements, 102\u201303, 120, 135\nspeculative generosity, 279\nSPIN model checker, 358\nspiral models, 48, 112, 256\u201357, 572\nsprint (Scrum), 85, 86\u201387\nSQL (Structured Query Language), 218, 399, 401, \n445, 505\nstable domain abstractions, 475\nstaff allocation charts, 678, 680\nstakeholders, 103\u201304, 107, 112\u201316\nstand-alone applications, 25\nstandards\ndocumentation, 706\nISO 9000 standards framework, 708\u201310, 734\nprocess, 45, 707, 708, 734\nproduct, 706, 707\nquality management (QM) and, 706\u201310, 727\nsoftware, 706\u201310, 727\nservice-oriented architectures (SOAs), \n524, \u00ad\n525\u201326\nvalue of, 707\u201308\nweb service, 525\u201326\nstate diagrams (UML), 141, 163, 205, 207\u201308\nstate machine models, 205, 207\u201308, 222, 617\u201318\nstate-based modeling, 156\u201358\nstatic analyzers, 217\nstatic metrics, 720\u201321\nstatic models, 143, 205, 222\nstatic perspective (RUP), 46\nstatic program analysis, 359\u201361, 368\nstatistical testing, 332\u201333, 336\nstimulus/response (embedded systems) model, \n\u00ad\n613\u201314, 634\nstorage management, 132, 740\nstories, elicitation of requirements from, 118\u201320\nstory cards, 79\u201380, 99. See also user stories\nstress testing, 248\nstructural models, 149\u201354, 163, 199, 205\nstructured arguments, 363\u201364\nstructured natural language requirements, 121, \n\u00ad\n122\u201324\nsubsystem engineering, 571, 573\nsubsystem faults, 573\nsubsystem model, 205\u201306\nSubversion system, 216, 735\nsupport environment, 32\nsupport services, 472\nsupport software, 262\nsurvivable systems analysis, 425\u201326\nsustainable pace, 78\n\u2018Swiss cheese\u2019 model, 420\u201321\nswitch (case) statements, 279\nsystem availability, see availability\nsystem boundaries, 141\u201342, 163, 199, 556\u201357\nsystem building, 731, 740\u201345, 753\nsystem construction by composition, 543\u201344\nsystem design\nactuator control processes, 613\u201314, 615\nembedded systems, 217\u201318, 613\u201320\n", "page": 798, "type": "text", "section": "Page 798"}
{"text": "798\u2002 \u2002 Subject Index\nsystem design (continued)\nhost-target development, 213, 216\u201318, 222\nmodeling, 617\u201319\nproducer/consumer processes, 616\u201317\nprogramming, 619\u201320\nreal-time systems, 205, 613\u201320\nrisk assessment, 389\u201392\nsecurity systems, 388\u2013402, 405\nstimulus response model, 613\u201314\nsystem error, 307\u201309\nsystem failure, 307\nacceptance of, 410\navailability and, 309\u201312\ncosts of, 286\ncritical systems, 287, 290, 297, 302, \n340\u201341\ndependability and, 22, 268, 286\u201391, 303\nerror and fault v., 308\nhardware failure and, 287\nhuman errors and, 287, 351\u201352\nnondeterminism and, 560\u201361\nreliability and, 307\u201312, 560\u201361\nreparability and, 289\nresilience and, 410\u201312, 420\u201321\nsafety-critical systems, 340\u201341\nsecurity and, 22, 268, 397\nsociotechnical, 560\u201361\nsoftware failures and, 287, 340\u201341\nspecifications and, 310\n\u2018Swiss cheese\u2019 model of, 420\u201321\ntypes of, 287\nsystem fault, 307\u201309\nsystem infrastructure frameworks, 446\nsystem integration, 215\u201316\nsystem level (reuse), 214\nsystem modeling, see models\nsystem of system coalitions, 589\nsystem output, 268\nsystem requirements, 52, 102\u201303\nsystem reuse, 438\nsystem selection, 594\u201395\nsystem testing, 48, 59, 231\u201332, 240\u201342\nsystem versions, 323\u2013325\nsystem vision document, 565\u201366\nsystems (software systems). See also distributed \nsystems; embedded software systems; \nsystems of systems (SoS)\nactivity models (diagram), 60, 61\nagile methods for, 93\u201396\nanalysis for architectural design, 169\ncase study types, 31\u201332\ncomplexity of, 18, 93\u201396, 274\u201375, 278, 552\u201353, \n558\u201359\ncost effectiveness of, 22\u201323\ndependability, 268, 286\u201391, 303\nengineering fundamentals for, 26, 40\nlarge-scale, 93\u201394, 556\nmodeling, 25, 138\u2013166\nsociotechnical, 291\u201395, 303, 556\u201363\nsoftware design and, 47\nspecification requirements, 120\u201329\nstate representation, 155\nsystems of systems (SoS) v., 581\u201382\ntypes of, 18, 20\u201321, 24\u201326, 32, 40, 552\nsystems engineering, 20, 23, 40, 551\u201379\nconceptual design, 553, 563\u201366, 577\ndevelopment processes, 570\u201374, 577\nenterprise systems, 552\nlifetimes and, 575\u201376\nrange of disciplines, 554\u201355\nsociotechnical systems, 552, 556\u201363, 577\nsoftware engineering v., 20, 23, 40, 554\nspiral model for requirements, 572\nstages of, 553\u201354\nsystem evolution, 575\u201376\nsystem procurement (acquisition), 453\u201354, \n566\u201370, 577\ntechnical computer-based systems, 552\nsystems of systems (SoS), 25, 256, 442, 556, \n580\u2013609\narchitectural design, 595, 599\u2013606, 607\nclassification of systems, 587\u201390, 606\ncontainer systems, 603\u201305\ndata-feed systems, 602\u201303\ndeployment and integration of, 595, 597\u201399\nengineering, 593\u201399\ngovernance complexity, 586\u201387, \n588\u201390, 606\ninterface development, 595\u201397\nlarge-scale systems, 556\nmanagement complexity, 585, 586\u201387, \n587\u201390, 606\nreductionism, 590\u201393, 606\nsoftware systems, 582\nsystem complexity, 584\u201387, 606\nsystem v., 581\u201382\ntechnical complexity, 585, 586\u201387, 590\ntrading systems, 605\u2013106\n", "page": 799, "type": "text", "section": "Page 799"}
{"text": "\t\nSubject Index\u2002 \u2002 799\nT\ntabular specification, 124\ntask cards, 79\u201380, 82. See also user stories\nteamwork, 656\u201364\ndevelopment team, 85, 90, 92\u201393\ngroup cohesion, 658\ngroup communication, 662\u201364\ngroup member selection, 659\u201360\ngroup organization, 660\u201362\nhierarchical groups, 661\u201362\nhiring people, 661\nphysical work environment and, 663\ntechnical complexity, SoS, 585, 586\u201387, 590\ntechnical computer-based systems, 552\ntest cases, 130, 234\u201337, 252\ntest-driven development (TDD), 242\u201345\ntest-first development, 59, 78, 81\u201383, 252\ntest planning, 231\ntesting (software testing), 58\u201360, 226\u201354, 402\u201304, \n427\u201328\nacceptance, 77, 82, 249, 250\u201351, 252\nagile methods for, 59, 78, 81\u201383, 251\nalpha, 249\nassurance and, 402\u201304\nautomated, 78, 81\u201383, 233\u201334, \n242, 252\nbeta, 58, 60, 249\u2013250\nchoosing test cases, 234\u201337, 252\ncomponent testing, 59, 232, 237\u201339\ncustomer, 58, 59\ndebugging v., 58, 232, 244\ndefect, 58, 227\u201328, 232, 245, 248\ndevelopment and, 59\u201360, 81\u201383, 570\ndevelopment testing, 231\u201342, 252\ngoals of, 227\nincremental approach, 59\ninspections v., 229\u201330\nmodel of, 230\u201331\npenetration, 403\u201304\nplan-driven phases, 59\u201360\nprocess, 58\u201360\nrelease testing, 245\u201348\nreliability and, 332\u201333, 336\nresilience, 427\u2013428\nsecurity, 402\u201304\nservices, 543, 546\u201347\nstages in, 59, 231\nstatistical, 332\u201333, 336\nsystem, 59, 232, 240\u201342\ntest-driven development (TDD), 242\u201345\ntool-based analysis, 404\nunit testing, 47, 232\u201337\nuser testing, 249\u201351\nvalidation, 58\u201360, 227\u201329\nthreats, 377, 378, 404, 413, 414\u201315\ntimeouts, 330\u201331\ntimestamps, 744\ntiming analysis, 626\u201331, 635\ntiming errors, 238\u201339\nTOGAF, 600, 601\ntool-based analysis, 404\ntool support, 132, 743, 744, 746\ntraceability (requirements), 132, 133\ntrading systems, 605\u201306\ntransaction-based applications, 25\ntransaction processing systems, 185, \n186\u201387, 192\ntransition phase (RUP), 46\u201347\ntriple modular redundancy (TMR), 322\ntrust, security and, 22, 24\ntwo-tier client-server architecture, 501, 503\u201305\nU\nUML (Unified Modeling Language), 140\nactivity diagrams, 33\u201334, 141, 143\u201344\narchitectural design and, 139, 175, 205\nbehavioral models, 155\u201357\nbusiness processes and, 143\u201344\nclass diagrams, 141, 149\u201350\ncomponent interface diagram, 469\ndeployment diagrams, 149, 218\ndiagram types, 139, 140\u201341, 205\nevent-driven, 156\u201357\nexecutable (xUML), 162\ngeneralization and, 152\ninteraction models, 144\u201349\nobject oriented metrics and, 721\nobject-oriented systems and, 140, 198\u2013209\npackage symbol, 37\nsequence diagrams, 141, 146\u201349, 155, 163, 205, \n206\u201307\nstate diagrams, 141, 205, 207\u201308\n", "page": 800, "type": "text", "section": "Page 800"}
{"text": "800\u2002 \u2002 Subject Index\nUML (continued)\nsubsystem models, 205\u201306\nsystem modeling using, 139, 140\nuse cases, 125\u201326, 141, 144\u201346, 163, 205\nworkflow models, 143\u201344, 544\nunified user interface (UI), 596\u201397\nUniform Resource Locator (URL), 530\u201332, 539\nunit testing, 47, 231, 232\u201337\nUniversal Description, Discovery, and Integration \n(UDDI), 526\nUniversal Resource Identifiers (URIs), 471, 527\nUnix systems, 183, 401\nurgent changes, 260\nusability\nerror tolerance, 289\npatterns, 175\nrequirements, 109\u201310\nsecurity guideline, 397\u201398\nusage, component models and, 471\nuse cases, 125\u201326, 141, 144\u201346\ninteraction models, 144\u201346, 163, 200\u201301\nrequirements specification and, 125\u201326\ntesting, 240\u201341\nUML diagram models, 141\nuser access, 392\nuser actions, logging, 398\nuser-defined error checking, 360\nuser expectations, 228\u201329\nuser interface design, 62\nuser requirements, 55, 73\u201374, 102\u201303\nuser stories, 79\u201380, 82, 86, 247, 681\u201382\nconceptual design and, 565\u201366\nproject planning (agile method) with, 681\u201382\ntask cards, 79\u201380\nuser testing, 249\u201351\nutility services, 534, 548\nV\nV & V (verification and validation), 58, 227\u201329, 356. \nSee also testing; validation\nV-model, 60\nvacation package workflow, 542, 544\u201345\nvalidation (software validation), 20, 69, 58\u201360\nengineering activities for, 23, 44\nrequirements, 55, 129\u201330, 135\ntesting, 58\u201360, 227\u201329\nverification v., 227\u201329\nvalidity checks, 129, 326\u201327, 399\nvehicle dispatcher system, 448\u201349\nvelocity (Scrum), 85\nverifiability, 129\nverification (software verification)\ncost effectiveness of, 357\nformal methods and, 300, 356\u201359\ngoal of, 228\nlevels of confidence, 228\u201329\nmodel checking, 300, 358\u201359\nsafety engineering, 356\u201359\nvalidation v., 227\u201329\nversion control (VC) systems, 731, 735, 753\nversion management (VM), 215, 216, 731,  \n735\u201340, 753\nvertical software packages, 20\nviews, architectural, 173\u2013175, 192\nVirtual Learning Environment (VLE), 38\nvirtual systems, 588\nvisibility of information, 325\u201326\nvolatile requirements, 132\nVOLERE requirements engineering method, 123\u201324\nvulnerability, 377, 378, 391, 401, 402\nW\nwaterfall model, 45, 47\u201349\nweather information database, 531\u201332\nweather stations, see wilderness weather stations\nweb application frameworks (WAFs), 444\nweb-based systems, 27\u201328\nweb services, 27, 52, 521, 524\u201333. See also services; \nWSDL\nbrowser development, 27, 521\nbusiness process model and, 544\u201346, 548\nbusiness, 534, 541\u201347, 548\nclassification of, 534, 548\nclouds, 27, 532\ncomponents for, 526\u201329\ncomposition (construction) of, 541\u201347\ncoordination, 534, 548\ndefined, 27, 521\nhttp and https protocols, 530\u201331\ninteractive transaction-based applications, 25\n", "page": 801, "type": "text", "section": "Page 801"}
{"text": "\t\nSubject Index\u2002 \u2002 801\ninterfaces, 28, 528\nresource operations, 530\nRESTful approach and, 529\u201333, 544\nreusable components as, 52, 526\u201329, 542\nservice-oriented architecture (SOA) and, 524\u201329\nSOA approach, 524\nsoftware development and, 541\u201347, 548\nstandards, 525\u201326\ntesting, 543, 546\u201347\nutility, 534, 548\nWSDL interface, 528\n\u2018wicked\u2019 problems, 130\u201331, 286, 301\nwilderness weather stations, 36\u201338\narchitectural design of, 201\u201302\navailability and reliability of, 289\n\u2018collect weather data\u2019 sequence chart for, 241\ncontext model for, 199\ndata collection (sequence diagram) in, 206\ndata collection system architecture in, 202\ndata management and archiving system, 36\nenvironment of, 36\u201337\nhigh-level architecture of, 201\ninterface specification, 208\u201309\nobject class identification, 202\u201304\nobject interface of, 233\nobjects, 203\u201304\nsequence diagram for, 241\nsociotechnical system of, 291\u201392\nstate diagram, 207\u201308\nstation maintenance system, 37\nsystem testing, 240\u201341\nuse case model for, 200\u201301\nwork environments, 663\nwork flow representation (UML), 143\u201344\nworkflow, 83, 452, 542, 543, 544\u201346, 548\nwrapping, legacy system, 278, 442, 540\nWS-BPEL, 525, 526, 544, 546\nWSDL (Web Service Definition Language), 526, \n527\u201329, 537, 540, 544\nmessage exchange, 527\u201329, 537\nmodel elements, 527\u201328\nservice deployment and, 540\nweb service interface, 528\nX\nXML, 470, 525, 527\u2013529\nlanguage processing, 186, 189, 191, 470, 544\nnamespaces, 528\u201329\nservice descriptions, 528\u201329\nweb services and, 525\nWS-BPEL workflow models, 544, 546\nWSDL message exchange, 527\u201329\nXML-based protocols, 521\n", "page": 802, "type": "text", "section": "Page 802"}
{"text": "This page intentionally left blank\n", "page": 803, "type": "text", "section": "Page 803"}
{"text": "A\nAbbott, R., 202, 224\nAbdelshafi, I., 87, 100\nAbrial, J. R., 49, 71, 300, 304, 357, 370\nAbts, C., 459, 460, 462, 594, 608, 684, 688, 691, \n694, 699\nAddy, E., 476, 489\nAiello, B., 731, 754, 755\nAlexander, C., 209, 224\nAlford, M., 552, 579\nAli Babar, M., 169, 194\nAllen, R., 459, 460, 463\nAmbler, S. W., 89, 95, 98, 99, 140, 162, 165\nAmbrosio, A. M., 341, 372\nAmelot, A., 300, 304\nAnderson, E. A., 300, 305\nAnderson, R. J., 495\nAnderson, R., 376, 402, 405, 406\nAndrea, J., 244, 254\nAndres, C., 98, 680, 699\nAppleton, B., 175, 194, 754\nArbon, J., 252\nArisholm, E., 84, 99\nArmour, P., 696\nArnold, S., 552, 579\nAsh, D., 275, 282\nAtlee, J. M., 135\nAvizienis, A. A., 286, 303, 304, \n323, 338\nB\nBadeau, F., 300, 304\nBalcer, M. J., 162, 165\nBall, T., 300, 305, 358, 361, 370\nBamford, R., 709, 729, 734, 755\nBanker, R. D., 275, 282\nBasili, V. R., 73, 100\nBass, B. M., 655, 666\nBass, L., 169, 170, 175, 192, 194\nBaumer, D., 446, 462\nBaxter, G., 559, 579\nBayersdorfer, M., 221, 224\nBeck, K., 71, 77, 80, 98, 99, 100, 203, 224, 242,  \n254, 279, 282, 680, 699\nBeedle, M., 71, 85, 100\nBehm, P., 356, 371\nBelady, L., 271\nBell, R., 347\nBellouiti, S., 87, 100\nBennett, K. H., 257, 282\nBenoit, P., 356, 371\nBentley, R., 125, 137\nBerczuk, S. P., 175, 194, 754\nBernstein, A. J., 186, 195\nBernstein, P. A., 498, 519\nBerry, G., 612, 637\nBezier, B., 235, 254\nBicarregui, J., 300, 302, 303, 305\nBird, J., 280\nAuthor Index\n", "page": 804, "type": "text", "section": "Page 804"}
{"text": "804\u2002 \u2002 Author Index\nClark, B. K., 683, 684, 688, 691, 694, 699\nCleaveland, R., 371\nClements, P., 169, 170, 175, 192, 194\nCliff, D., 583, 592, 609\nCloutier, R., 563, 579\nCohn, M., 680, 697, 699\nColeman, D., 275, 282\nCollins-Sussman, B., 216, 225, 735, 755\nConnaughton, C., 727\nConradi, R., 69\nCook, B., 300, 305\nCooling, J., 627, 637\nCoplien, J. O., 175, 194\nCoulouris, G., 491, 517, 519\nCouncill, W. T., 467, 489\nCrabtree, A., 117, 137\nCranor, L., 398, 406\nCrnkovic, I., 487, 488\nCunningham, W., 84, 100, 203, 224\nCurbera, F., 544, 550\nCusamano, M., 231, 254\nD\nDaigneau, R., 548\nDang, Y., 719, 726, 729\nDatar, S. M., 275, 282\nDavidsen, M. G., 272, 282\nDavis, A. M., 102, 137\nDeemer, P., 88, 100\nDehbonei, B., 356, 371\nDeibler, W. J., 709, 729, 734, 755\nDelmas, D., 356, 372\nDelseny, H., 356, 357, 372\nDeMarco, T., 665\nden Haan, J., 159, 165\nDevnani-Chulani, S., 688, 691, 694, 699\nDijkstra, E. W., 227, 254\nDipti, 282\nDollimore, J., 491, 517, 519\nDouglass, B. P., 299, 305, 617, 620, 637\nDuftler, M., 544, 550\nDunteman, G., 655, 666\nDuquenoy, P., 31, 42\nDyb\u00e4, T., 69, 84, 99\nBird, J., 90, 100\nBishop, P., 361, 371\nBjorke, P., 563, 579\nBlair, G., 491, 517, 519\nBloomfield, R. E., 361, 371\nBochot, T., 300, 305, 358, 371\nBoehm, B. W., 40, 45, 48, 71, 98, 227\u201328, 254, 459, \n460, 462, 594, 608, 649, 666, 683, 684, 687, \n688, 691, 694, 695, 697, 699\nBollella, G., 619, 637\nBooch, G., 140, 165, 166, 170, 193, 194\nBosch, J., 169, 173, 180, 194\nBott, F., 31, 42\nBounimova, E., 300, 305\nBrambilla, M., 139, 159, 163, 165\nBrant, J., 80, 100, 279, 282\nBrazendale, J., 347\nBrereton, P., 517\nBrilliant, S. S., 324, 338\nBrook, P., 552, 579\nBrooks, E. P., 665\nBrown, A. W., 98, 684, 688, 699\nBrown, L., 376, 405, 407\nBruno, E. J., 619, 637\nBudgen, D., 517\nBurns, A., 619, 631, 634, 635, 637\nBuschmann, F., 175, 194, 195, 209, 224, 225\nBuse, R. P. L., 726, 729\nC\nCabot, J., 139, 159, 163, 165, 488\nCalinescu, R. C., 300, 305, 583, 592, 609\nCarollo, J., 252\nCha, S. S., 349, 371\nChapman, C., 220, 225\nChapman, R., 300, 305, 404, 406\nChaudron, M. R. V., 175, 195\nCheckland, P., 559, 579\nChen, L., 169, 194\nCheng, B. H. C., 135\nChidamber, S., 721, 729\nChrissis, M. B., 67, 71, 734, 755\nChristerson, M., 125, 137, 144, 165\nChulani, S., 684, 688, 699\n", "page": 805, "type": "text", "section": "Page 805"}
{"text": "\t\nAuthor Index\u2002 \u2002 805\nGraydon, P. J., 362, 371\nGregory, G., 82, 100, 233, 243, 254\nGriss, M., 443, 463, 478, 489\nGryczan, G., 446, 462\nH\nHall, A., 300, 305, 404, 406\nHall, E., 644, 666\nHall, M. A., 726, 729\nHamilton, S., 358, 371\nHan, S., 719, 726, 729\nHarel, D., 156, 165, 617, 637\nHarford, T., 726, 729\nHarkey, D., 507, 519\nHarrison, N. B., 175, 194\nHatton, L., 325, 338\nHeimdahl, M. P. E., 300, 305\nHeineman, G. T., 467, 489\nHelm, R., 175, 194, 209, 210, 222, 225, \n444, 463\nHenney, K., 175, 194, 209, 224\nHeslin, R., 663, 666\nHitchins, D., 581, 608\nHnich, B., 487\nHofmeister, C., 174, 195\nHoldener, A. T., 28, 42, 445, 463, 512, 519\nHollnagel, E., 409, 417\u201318, 434\nHoltzman, J., 552, 579\nHolzmann, G. J., 336, 358, 371\nHopkins, R., 94, 100, 256, 282\nHorowitz, E., 683, 684, 688, 699\nHoward, M., 405\nHudepohl, J. P., 360, 372\nHull, R., 151, 165\nHumphrey, 67\nHumphrey, W., 702, 713, 729\nHutchinson, J., 162, 165\nI\nInce, D., 709, 729\nE\nEbert, C., 611, 635, 637\nEdwards, J., 507, 519\nEl-Amam, K., 721, 729\nEllison, R. J., 425, 432, 434\nErickson, J., 140, 165\nErl, T., 526, 534, 548, 550\nErlikh, L., 256, 282\nF\nFagan, M. E., 230, 254, 713, 729\nFairley, R. E., 563, 579\nFaivre, A., 356, 371\nFayad, M. E., 446, 462\nFayoumi, A., 602, 609\nFeathers, M., 280\nFielding, R., 530, 550\nFiresmith, D. G., 383, 406\nFitzgerald, J., 300, 302, 303, 305, 735, 755\nFitzpatrick, B., 216, 225\nFogel, K., 222\nFowler, M., 80, 100, 279, 282\nFox, A., 517\nFrank, E., 726, 729\nFreeman, A., 28, 42\nG\nGabriel, R. P., 581, 583, 607, 609\nGagne, G., 616, 637\nGalin, D., 727\nGallis, H., 84, 99\nGalvin, P. B., 616, 637\nGamma, E., 175, 194, 209, 210, 222, 225, 444, 463\nGarfinkel, S., 398, 406\nGarlan, D., 172, 175, 191, 192, 195, 459, \n460, 461, 463\nGokhale, A., 443, 445, 463\nGotterbarn, D., 29, 40, 42\n", "page": 806, "type": "text", "section": "Page 806"}
{"text": "806\u2002 \u2002 Author Index\nJ\nJackson, K., 552, 579\nJacobson, I., 24, 41, 42, 125, 137, 140, 144, 165,  \n166, 443, 463, 478, 489\nJain, P., 175, 195, 209, 225\nJeffrey, R., 727\nJeffries, R., 81, 84, 100, 140, 165, 242, 254\nJenkins, K., 94, 100, 256, 282\nJenney, P., 404, 407\nJhala, R., 300, 305, 358, 371\nJoannou, D., 602, 609\nJohnson, D. G., 31, 42\nJohnson, R., 175, 194, 209, 210, 222, 225, 444, 463\nJones, C., 280, 611, 635, 637\nJones, T. C., 256, 282\nJonsson, P., 125, 137, 144, 165, 443, 463, \n478, 489\nJonsson, T., 487\nK\nKaner, C., 246, 254\nKawalsky, R., 602, 609\nKazman, R., 169, 170, 175, 192, 194\nKeen, J., 583, 592, 609\nKelly, T., 583, 592, 609\nKemerer, C. F., 275, 282, 721, 729\nKennedy, D. M., 563, 579\nKerievsky, J., 279, 282\nKessler, R. R., 84, 100\nKhalaf, R., 544, 550\nKifer, M., 186, 195\nKilner, S., 90, 100\nKindberg, T., 491, 517, 519\nKing, R., 151, 165\nKircher, M., 175, 195, 209, 225\nKitchenham, B., 718, 727, 729\nKiziltan, Z., 487\nKlein, M., 581, 583, 607, 609\nKleppe, A., 485, 489\nKnight, J. C., 324, 338, 362, 371\nKnoll, R., 446, 462\nKoegel, M., 161, 165\nKonrad, M., 67, 71, 734, 755\nKopetz, H., 635\nKorfiatis, P., 563, 579\nKoskela, L., 59, 71\nKoskinen, J., 275, 282\nKotonya, G., 473, 489\nKozlov, D., 275, 282\nKrogstie, J., 272, 282\nKrutchen, P., 46, 71, 173, 175, 195\nKuehl, S., 552, 579\nKumar, Y., 280\nKwiatkowska, M. Z., 300, 305, 358, 371, 583, \n592, 609\nL\nLamport, L., 495\nLandwehr, C., 286, 303, 304\nLane, A., 392, 407\nLange, C. F. J., 175, 195\nLaprie, J. C., 286, 303, 304, 409, 434\nLarman, C., 73, 100, 222\nLarsen, P.G., 300, 302, 303, 305\nLau, K-K., 466, 470, 487, 489\nLaudon, K., 31, 42\nLeBlanc, D., 405\nLedinot, E., 357, 371\nLee, E. A., 612, 637\nLeffingwell, D., 95, 100\nLehman, M., 271\nLeme, F., 82, 100, 233, 243, 254\nLeveson, N. G., 324, 338, 368\nLeveson, N. G., 349, 371\nLevin, V., 300, 305, 358, 361, 370\nLewis, B., 521, 550\nLewis, P. M., 186, 195\nLeymann, F., 532, 550\nLichtenberg, J., 300, 305\nLidman, S., 41, 42\nLientz, B. P., 256, 282\nLilienthal, C., 446, 462\nLinger, R. C., 230, 254, 332, 338, 425, \n432, 434\nLipson, H., 425, 434\nLister, T., 665\n", "page": 807, "type": "text", "section": "Page 807"}
{"text": "\t\nAuthor Index\u2002 \u2002 807\nLoeliger, J., 216, 225, 735, 755\nLomow, G., 524, 550\nLongstaff, T., 425, 432, 434\nLoope, J., 753, 755\nLopes, R., 359, 371\nLou, J-G., 719, 726, 729\nLovelock, C., 521, 550\nLowther, B., 275, 282\nLutz, R. R., 238, 254, 371\nLutz, R. R., 340, 371\nLyu, M. R., 336, 338\nM\nMadachy, R., 683, 684, 688, 699\nMadeira, H., 341, 372\nMaier, M. W., 582, 583, 588, 589, 599\u2013600, \n607, 609\nMajumdar, R., 300, 305, 358, 371\nMarciniak, J. J., 69\nMarkkula, J., 275, 282\nMarshall, J. E., 663, 666\nMartin, D., 117, 137, 175, 195\nMartin, R. C., 244, 254\nMaslow, A. A., 383, 666\nMassol, V., 82, 100, 233, 243, 254\nMcCay, B., 552, 579\nMcComb, S. A., 563, 579\nMcConnell, S., 713, 729\nMcCullough, M., 216, 225, 735, 755\nMcDermid, J., 583, 592, 609\nMcDougall, P., 510, 519\nMcGarvey, C., 300, 305\nMcGraw, G., 333, 338, 396, 407\nMcMahon, P. E., 41, 22\nMead, N. R., 425, 434\nMejia, F., 356, 371\nMellor, S. J., 159, 162, 165\nMelnik, G., 81, 100, 242, 254\nMenzies, T., 719, 725, 726, 727, 729\nMeunier, R., 175, 194, 209, 225\nMeyer, B., 485, 489\nMeynadier, J-M., 356, 371\nMiers, D., 544, 550\nMili, A., 476, 489\nMili, H., 476, 489\nMiller, K., 29, 40, 42\nMiller, S. P., 300, 305\nMitchell, R. M., 263, 282\nMonate, B., 357, 371\nMonk, E., 455, 463\nMoore, A., 425, 432, 434\nMorisio, M., 453, 460, 461, 463\nMostashari, A., 563, 579\nMoy, Y., 357, 371\nMulder, M., 87, 100\nMusa, J. D., 334, 338\nMuskens, J., 175, 195\nN\nNagappan, N., 360, 372\nNascimento, L., 461\nNatarajan, B., 443, 445, 463\nNaur, P., 19, 42\nNewcomer, E., 524, 550\nNg, P-W., 41, 42\nNii, H. P., 180, 195\nNord, R., 174, 195\nNorman, G., 358, 371\nNorthrop, L., 581, 583, 607, 609\nNuseibeh, B., 169, 194\nO\nO\u2019Hanlon, C., 274, 282\nOckerbloom, J., 459, 460, 463\nOliver, D., 552, 579\nOman, P., 275, 282\nOndrusek, B., 300, 305\nOpdahl, A. L., 386, 407\nOpdyke, W., 80, 100, 279, 282\nOram, A., 510, 517, 519\nOrfali, R., 507, 519\nOuld, M., 644, 666\nOvergaard, G., 125, 137, 144, 165\nOwens, D., 552, 579\n", "page": 808, "type": "text", "section": "Page 808"}
{"text": "808\u2002 \u2002 Author Index\nP\nPaige, R., 583, 592, 609\nParies, J., 432, 434\nParker, D., 358, 371\nParnas, D., 296, 302, 305\nPatel, S., 162, 166\nPatterson, D., 517\nPautasso, C., 532, 550\nPerrow, C., 342, 343, 371\nPfleeger, C. P., 376, 377, 407\nPfleeger, S. L., 376, 377, 407\nPilato, C., 216, 225, 735, 755\nPooley, R., 126, 137, 163\nPoore, J. H., 230, 254, 332, 338\nPope, A., 466, 489, 493, 519\nProwell, S. J., 230, 254, 332, 338\nPullum, L., 318, 336, 338\nQ\nQuinn, M. J., 40\nR\nRajamani, S. K., 300, 305, 358, 361, 370\nRajlich, V. T., 257, 282\nRandell, B., 19, 42, 286, 303, 304,  \n307, 338\nRay, A., 368\nRayhan, S., 727\nRaymond, E. S., 219, 225\nReason, J., 418, 420\u201321, 434\nRegan, P., 358, 371\nReifer, D., 684, 688, 699\nRichardson, L., 531, 550\nRiehle, D., 446, 462\nRittel, H., 130, 137, 562, 579, 592, 609\nRitter, G., 637\nRoberts, D., 80, 100, 279, 282\nRobertson, J., 123, 135, 137\nRobertson, S., 123, 135, 137\nRodden, T., 125, 137\nRodriguez, A., 548\nRogerson, S., 29, 40, 42\nRohnert, H., 175, 194, 195, 209, 225\nRosenberg, F., 544, 550\nRouncefield, M., 162, 165\nRoyce, W. W., 47, 71, 98, 687, 699\nRubin, K. S., 78, 85, 98, 100, 680, 699\nRuby, S., 531, 550\nRumbaugh, J., 140, 165, 166\nRyan, P., 754\nS\nSachs, S., 731, 754, 755\nSakkinen, M., 275, 282\nSametinger, J., 470, 472, 489\nSami, M., 69\nSanderson, D., 516, 519\nSarris, S., 445, 463, 512, 519\nSawyer, P., 125, 137\nScacchi, W., 69\nSchatz, B., 87, 100\nSchmidt, D. C., 175, 194, 195, 209, 224, 225, 443, \n445, 446, 462, 463, 581, 583, 607, 609\nSchneider, S., 357, 371\nSchneier, B., 384, 396, 407\nSchoenfield, B., 392, 407\nSchuh, P., 754\nSchwaber, K., 71, 85, 100\nScott, J. E., 456, 463\nScott, K., 159, 165\nSelby, R. W., 231, 254, 683, 699\nShaw, M., 172, 175, 191, 192, 195\nShimeall, T. J., 349, 371\nShou, P. K., 296, 305\nShrum, S., 67, 71, 734, 755\nSiau, K., 140, 165\nSilberschaltz, A., 616, 637\nSillitto, H., 578, 596, 600, 609\nSilva, N., 341, 359, 371, 372\nSindre, G., 386, 407\nSj\u00f8berg, D. I. K., 69, 84, 99\nSmart, J. F., 743, 755\nSnipes, W., 360, 372\nSommerlad, P., 175, 194, 209, 225\nSommerville, I., 117, 135, 137, 175, 195, 461, 559, \n579, 583, 592, 607, 609\nSoni, D., 174, 195\n", "page": 809, "type": "text", "section": "Page 809"}
{"text": "\t\nAuthor Index\u2002 \u2002 809\nSouyris, J., 356, 372\nSpafford, E., 399, 401, 407\nSpence, I., 41, 42\nSt. Laurent, A., 220, 225\nStafford, J., 488\nStahl, T., 159, 166\nStal, M., 205, 209, 225\nStallings, W., 376, 405, 407,  \n616, 637\nStapleton, J., 71, 100\nSteece, B., 684, 688, 699\nStevens, P., 126, 137, 163\nStevens, R., 552, 579, 583, 609\nStewart, J., 574, 579\nStoemmer, P., 697\nStorey, N., 349, 372\nStrunk, E. A., 362, 371\nSuchman, L., 117, 137\nSwanson, E. B., 256, 282\nSwartz, A. J., 294, 305\nSzyperski, C., 467, 474, 487,  \n488, 489\nT\nTahchiev, P., 82, 100, 233, 243, 254\nTanenbaum, A. S., 491, 519\nTavani, H. T., 31, 42\nThayer, R. H., 552, 579\nThayer, R. H., 563, 579\nTian, Y., 602, 609\nTorchiano, M., 453, 460, 461, 463\nTorres-Pomales, W., 318, 338\nTrammell, C. J., 230, 254, 332, 338\nTrimble, J., 299, 305\nTully, C., 552, 579\nTurner, M., 517\nTurner, R., 45, 71\nTwidale, M., 125, 137\nU\nUlrich, W. M., 276, 282\nUlsund, T., 69\nUstuner, A., 300, 305\nV\nValeridi, R., 697\nvan Schouwen, J., 296, 305\nVan Steen, M., 491, 519\nvan Vliet, M., 87, 100\nVandermerwe, S., 521, 550\nVeras, P. C., 341, 372\nVicente, D., 359, 371\nViega, J., 396, 405, 407\nVieira, M., 341, 372\nVillani, E., 341, 372\nViller, S., 117, 137\nVirelizier, P., 300, 305, 358, 371\nVlissides, J., 175, 194, 209, 210, 222, 225, \n444, 463\nVoas, J., 333, 338\nVoelter, M., 159, 166\nVogel, L., 32, 42, 218, 225\nVouk, M. A., 360, 372\nW\nWaeselynck, H., 300, 305, 358, 371\nWagner, B., 455, 463\nWagner, L. G., 300, 305\nWallach, D. S., 512, 519\nWang, Z., 466, 470, 487, 489\nWarmer, J., 485, 489\nWarren, I., 266, 282\nWebber, M., 130, 137, 562, 579, \n592, 609\nWeils, V., 356, 357, 358, 372\nWeinberg, G., 83, 100\nWeiner, L., 203, 225\nWeinreich, R., 470, 472, 489\nWeise, D., 159, 165\nWellings, A., 619, 631, 634, 635, 637\nWestland, C., 683, 699\nWhalen, M. W., 300, 305\nWheeler, D. A., 396, 407\nWheeler, W., 52, 71, 473, 489\nWhite, J., 52, 71, 473, 489\nWhite, S. A., 544, 550\nWhite, S., 552, 579\nWhittaker, J. A., 237, 242, 252, 254\n", "page": 810, "type": "text", "section": "Page 810"}
{"text": "810\u2002 \u2002 Author Index\nWhittle, J., 162, 165\nWiels, V., 300, 305, 371\nWilkerson, B., 203, 225\nWilley, A., 552, 579\nWilliams, L., 84, 100, 360, 372\nWilliams, R., 574, 579\nWimmer, M., 139, 159, 163, 165\nWirfs-Brock, R., 203, 225\nWitten, I. H., 726, 729\nWoodcock, J., 300, 302, 303, 305\nWoods, D., 432, 434\nWreathall, J., 432, 434\nWysocki, R. K., 665\nX\nXie, T., 719, 726, 729\nY\nYacoub, S., 476, 489\nYamaura, T., 252\nZ\nZelkowitz, M., 637\nZhang, D., 719, 726, 729\nZhang, H., 719, 726, 729\nZhang, Y., 162, 166\nZheng, J., 360, 372\nZimmermann, O., 532, 550\nZimmermann, T., 719, 725, 726, 727, 729\nZullighoven, H., 446, 462\nZweig, D., 275, 282\n", "page": 811, "type": "text", "section": "Page 811"}
